{"created":"2025-06-05","title":"Analyzing Localizability of LEO/MEO Hybrid Networks: A Stochastic Geometry Approach","abstract":"With the increase in global positioning service demands and the requirement for more precise positioning, assisting existing medium and high orbit satellite-enabled positioning systems with low Earth orbit (LEO) satellites has garnered widespread attention. However, providing low computational complexity performance analysis for hybrid LEO/MEO massive satellite constellations remains a challenge. In this article, we introduce for the first time the application of stochastic geometry (SG) framework in satellite-enabled positioning performance analysis and provide an analytical expression for the K-availiability probability and K-localizability probability under bidirectional beam alignment transmissions. The K-localizability probability, defined as the probability that at least K satellites can participate in the positioning process, serves as a prerequisite for positioning. Since the modeling of MEO satellite constellations within the SG framework has not yet been studied, we integrate the advantages of Cox point processes and binomial point processes, proposing a doubly stochastic binomial point process binomial point process for accurate modeling of MEO satellite constellations. Finally, we investigate the impact of constellation configurations and antenna patterns on the localizability performance of LEO, MEO, and hybrid MEO/LEO constellations. We also demonstrate the network performance gains brought to MEO positioning systems by incorporating assistance from LEO satellites.","authors":["Ruibo Wang","Mustafa A. Kishk","Howard H. Yang","Mohamed-Slim Alouini"],"url":"https://arxiv.org/abs/2506.03151"}
{"created":"2025-06-05","title":"Modular Diffusion Policy Training: Decoupling and Recombining Guidance and Diffusion for Offline RL","abstract":"Classifier free guidance has shown strong potential in diffusion-based reinforcement learning. However, existing methods rely on joint training of the guidance module and the diffusion model, which can be suboptimal during the early stages when the guidance is inaccurate and provides noisy learning signals. In offline RL, guidance depends solely on offline data: observations, actions, and rewards, and is independent of the policy module's behavior, suggesting that joint training is not required. This paper proposes modular training methods that decouple the guidance module from the diffusion model, based on three key findings:","authors":["Zhaoyang Chen","Cody Fleming"],"url":"https://arxiv.org/abs/2506.03154"}
{"created":"2025-06-05","title":"Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World","abstract":"The proliferation of artificial intelligence has enabled a diversity of applications that bridge the gap between digital and physical worlds. As physical environments are too complex to model through a single information acquisition approach, it is crucial to fuse multimodal data generated by different sources, such as sensors, devices, systems, and people, to solve a problem in the real world. Unfortunately, it is neither applicable nor sustainable to deploy new resources to collect original data from scratch for every problem. Thus, when data is inadequate in the domain of problem, it is vital to fuse knowledge from multimodal data that is already available in other domains. We call this cross-domain knowledge fusion. Existing research focus on fusing multimodal data in a single domain, supposing the knowledge from different datasets is intrinsically aligned; however, this assumption may not hold in the scenarios of cross-domain knowledge fusion. In this paper, we formally define the cross-domain multimodal data fusion problem, discussing its unique challenges, differences and advantages beyond data fusion in a single domain. We propose a four-layer framework, consisting of Domains, Links, Models and Data layers, answering three key questions: \"what to fuse\", \"why can be fused\", and \"how to fuse\". The Domains Layer selects relevant data from different domains for a given problem. The Links Layer reveals the philosophy of knowledge alignment beyond specific model structures. The Models Layer provides two knowledge fusion paradigms based on the fundamental mechanisms for processing data. The Data Layer turns data of different structures, resolutions, scales and distributions into a consistent representation that can be fed into an AI model. With this framework, we can design end-to-end solutions that fuse cross-domain multimodal data effectively for solving real-world problems.","authors":["Yu Zheng"],"url":"https://arxiv.org/abs/2506.03155"}
{"created":"2025-06-05","title":"DUAL: Dynamic Uncertainty-Aware Learning","abstract":"Deep learning models frequently encounter feature uncertainty in diverse learning scenarios, significantly impacting their performance and reliability. This challenge is particularly complex in multi-modal scenarios, where models must integrate information from different sources with inherent uncertainties. We propose Dynamic Uncertainty-Aware Learning (DUAL), a unified framework that effectively handles feature uncertainty in both single-modal and multi-modal scenarios. DUAL introduces three key innovations: Dynamic Feature Uncertainty Modeling, which continuously refines uncertainty estimates through joint consideration of feature characteristics and learning dynamics; Adaptive Distribution-Aware Modulation, which maintains balanced feature distributions through dynamic sample influence adjustment; and Uncertainty-aware Cross-Modal Relationship Learning, which explicitly models uncertainties in cross-modal interactions. Through extensive experiments, we demonstrate DUAL's effectiveness across multiple domains: in computer vision tasks, it achieves substantial improvements of 7.1% accuracy on CIFAR-10, 6.5% accuracy on CIFAR-100, and 2.3% accuracy on Tiny-ImageNet; in multi-modal learning, it demonstrates consistent gains of 4.1% accuracy on CMU-MOSEI and 2.8% accuracy on CMU-MOSI for sentiment analysis, while achieving 1.4% accuracy improvements on MISR. The code will be available on GitHub soon.","authors":["Jiahao Qin","Bei Peng","Feng Liu","Guangliang Cheng","Lu Zong"],"url":"https://arxiv.org/abs/2506.03158"}
{"created":"2025-06-05","title":"Bayes Error Rate Estimation in Difficult Situations","abstract":"The Bayes Error Rate (BER) is the fundamental limit on the achievable generalizable classification accuracy of any machine learning model due to inherent uncertainty within the data. BER estimators offer insight into the difficulty of any classification problem and set expectations for optimal classification performance. In order to be useful, the estimators must also be accurate with a limited number of samples on multivariate problems with unknown class distributions. To determine which estimators meet the minimum requirements for \"usefulness\", an in-depth examination of their accuracy is conducted using Monte Carlo simulations with synthetic data in order to obtain their confidence bounds for binary classification. To examine the usability of the estimators on real-world applications, new test scenarios are introduced upon which 2500 Monte Carlo simulations per scenario are run over a wide range of BER values. In a comparison of k-Nearest Neighbor (kNN), Generalized Henze-Penrose (GHP) divergence and Kernel Density Estimation (KDE) techniques, results show that kNN is overwhelmingly the more accurate non-parametric estimator. In order to reach the target of an under 5 percent range for the 95 percent confidence bounds, the minimum number of required samples per class is 1000. As more features are added, more samples are needed, so that 2500 samples per class are required at only 4 features. Other estimators do become more accurate than kNN as more features are added, but continuously fail to meet the target range.","authors":["Lesley Wheat","Martin v. Mohrenschildt","Saeid Habibi"],"url":"https://arxiv.org/abs/2506.03159"}
{"created":"2025-06-05","title":"Applying MambaAttention, TabPFN, and TabTransformers to Classify SAE Automation Levels in Crashes","abstract":"The increasing presence of automated vehicles (AVs) presents new challenges for crash classification and safety analysis. Accurately identifying the SAE automation level involved in each crash is essential to understanding crash dynamics and system accountability. However, existing approaches often overlook automation-specific factors and lack model sophistication to capture distinctions between different SAE levels. To address this gap, this study evaluates the performance of three advanced tabular deep learning models MambaAttention, TabPFN, and TabTransformer for classifying SAE automation levels using structured crash data from Texas (2024), covering 4,649 cases categorized as Assisted Driving (SAE Level 1), Partial Automation (SAE Level 2), and Advanced Automation (SAE Levels 3-5 combined). Following class balancing using SMOTEENN, the models were trained and evaluated on a unified dataset of 7,300 records. MambaAttention demonstrated the highest overall performance (F1-scores: 88% for SAE 1, 97% for SAE 2, and 99% for SAE 3-5), while TabPFN excelled in zero-shot inference with high robustness for rare crash categories. In contrast, TabTransformer underperformed, particularly in detecting Partial Automation crashes (F1-score: 55%), suggesting challenges in modeling shared human-system control dynamics. These results highlight the capability of deep learning models tailored for tabular data to enhance the accuracy and efficiency of automation-level classification. Integrating such models into crash analysis frameworks can support policy development, AV safety evaluation, and regulatory decisions, especially in distinguishing high-risk conditions for mid- and high-level automation technologies.","authors":["Shriyank Somvanshi","Anannya Ghosh Tusti","Mahmuda Sultana Mimi","Md Monzurul Islam","Sazzad Bin Bashar Polock","Anandi Dutta","Subasish Das"],"url":"https://arxiv.org/abs/2506.03160"}
{"created":"2025-06-05","title":"Safety-Prioritized, Reinforcement Learning-Enabled Traffic Flow Optimization in a 3D City-Wide Simulation Environment","abstract":"Traffic congestion and collisions represent significant economic, environmental, and social challenges worldwide. Traditional traffic management approaches have shown limited success in addressing these complex, dynamic problems. To address the current research gaps, three potential tools are developed: a comprehensive 3D city-wide simulation environment that integrates both macroscopic and microscopic traffic dynamics; a collision model; and a reinforcement learning framework with custom reward functions prioritizing safety over efficiency. Unity game engine-based simulation is used for direct collision modeling. A custom reward enabled reinforcement learning method, proximal policy optimization (PPO) model, yields substantial improvements over baseline results, reducing the number of serious collisions, number of vehicle-vehicle collisions, and total distance travelled by over 3 times the baseline values. The model also improves fuel efficiency by 39% and reduces carbon emissions by 88%. Results establish feasibility for city-wide 3D traffic simulation applications incorporating the vision-zero safety principles of the Department of Transportation, including physics-informed, adaptable, realistic collision modeling, as well as appropriate reward modeling for real-world traffic signal light control towards reducing collisions, optimizing traffic flow and reducing greenhouse emissions.","authors":["Mira Nuthakki"],"url":"https://arxiv.org/abs/2506.03161"}
{"created":"2025-06-05","title":"Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection","abstract":"The rapid proliferation of surveillance cameras has increased the demand for automated violence detection. While CNNs and Transformers have shown success in extracting spatio-temporal features, they struggle with long-term dependencies and computational efficiency. We propose Dual Branch VideoMamba with Gated Class Token Fusion (GCTF), an efficient architecture combining a dual-branch design and a state-space model (SSM) backbone where one branch captures spatial features, while the other focuses on temporal dynamics, with continuous fusion via a gating mechanism. We also present a new benchmark by merging RWF-2000, RLVS, and VioPeru datasets in video violence detection, ensuring strict separation between training and testing sets. Our model achieves state-of-the-art performance on this benchmark offering an optimal balance between accuracy and computational efficiency, demonstrating the promise of SSMs for scalable, real-time surveillance violence detection.","authors":["Damith Chamalke Senadeera","Xiaoyun Yang","Dimitrios Kollias","Gregory Slabaugh"],"url":"https://arxiv.org/abs/2506.03162"}
{"created":"2025-06-05","title":"Causal Discovery in Dynamic Fading Wireless Networks","abstract":"Dynamic causal discovery in wireless networks is essential due to evolving interference, fading, and mobility, which complicate traditional static causal models. This paper addresses causal inference challenges in dynamic fading wireless environments by proposing a sequential regression-based algorithm with a novel application of the NOTEARS acyclicity constraint, enabling efficient online updates. We derive theoretical lower and upper bounds on the detection delay required to identify structural changes, explicitly quantifying their dependence on network size, noise variance, and fading severity. Monte Carlo simulations validate these theoretical results, demonstrating linear increases in detection delay with network size, quadratic growth with noise variance, and inverse-square dependence on the magnitude of structural changes. Our findings provide rigorous theoretical insights and practical guidelines for designing robust online causal inference mechanisms to maintain network reliability under nonstationary wireless conditions.","authors":["Oluwaseyi Giwa"],"url":"https://arxiv.org/abs/2506.03163"}
{"created":"2025-06-05","title":"Test-Time Scaling of Diffusion Models via Noise Trajectory Search","abstract":"The iterative and stochastic nature of diffusion models enables test-time scaling, whereby spending additional compute during denoising generates higher-fidelity samples. Increasing the number of denoising steps is the primary scaling axis, but this yields quickly diminishing returns. Instead optimizing the noise trajectory--the sequence of injected noise vectors--is promising, as the specific noise realizations critically affect sample quality; but this is challenging due to a high-dimensional search space, complex noise-outcome interactions, and costly trajectory evaluations. We address this by first casting diffusion as a Markov Decision Process (MDP) with a terminal reward, showing tree-search methods such as Monte Carlo tree search (MCTS) to be meaningful but impractical. To balance performance and efficiency, we then resort to a relaxation of MDP, where we view denoising as a sequence of independent contextual bandits. This allows us to introduce an $\\epsilon$-greedy search algorithm that globally explores at extreme timesteps and locally exploits during the intermediate steps where de-mixing occurs. Experiments on EDM and Stable Diffusion reveal state-of-the-art scores for class-conditioned/text-to-image generation, exceeding baselines by up to $164\\%$ and matching/exceeding MCTS performance. To our knowledge, this is the first practical method for test-time noise trajectory optimization of arbitrary (non-differentiable) rewards.","authors":["Vignav Ramesh","Morteza Mardani"],"url":"https://arxiv.org/abs/2506.03164"}
{"created":"2025-06-05","title":"What Does Information Science Offer for Data Science Research?: A Review of Data and Information Ethics Literature","abstract":"This paper reviews literature pertaining to the development of data science as a discipline, current issues with data bias and ethics, and the role that the discipline of information science may play in addressing these concerns. Information science research and researchers have much to offer for data science, owing to their background as transdisciplinary scholars who apply human-centered and social-behavioral perspectives to issues within natural science disciplines. Information science researchers have already contributed to a humanistic approach to data ethics within the literature and an emphasis on data science within information schools all but ensures that this literature will continue to grow in coming decades. This review article serves as a reference for the history, current progress, and potential future directions of data ethics research within the corpus of information science literature.","authors":["Brady D. Lund","Ting Wang"],"url":"https://arxiv.org/abs/2506.03165"}
{"created":"2025-06-05","title":"Video Quality Monitoring for Remote Autonomous Vehicle Control","abstract":"The delivery of high-quality, low-latency video streams is critical for remote autonomous vehicle control, where operators must intervene in real time. However, reliable video delivery over Fourth/Fifth-Generation (4G/5G) mobile networks is challenging due to signal variability, mobility-induced handovers, and transient congestion. In this paper, we present a comprehensive blueprint for an integrated video quality monitoring system, tailored to remote autonomous vehicle operation. Our proposed system includes subsystems for data collection onboard the vehicle, video capture and compression, data transmission to edge servers, real-time streaming data management, Artificial Intelligence (AI) model deployment and inference execution, and proactive decision-making based on predicted video quality. The AI models are trained on a hybrid dataset that combines field-trial measurements with synthetic stress segments and covers Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and encoder-only Transformer architectures. As a proof of concept, we benchmark 20 variants from these model classes together with feed-forward Deep Neural Network (DNN) and linear-regression baselines, reporting accuracy and inference latency. Finally, we study the trade-offs between onboard and edge-based inference. We further discuss the use of explainable AI techniques to enhance transparency and accountability during critical remote-control interventions. Our proactive approach to network adaptation and Quality of Experience (QoE) monitoring aims to enhance remote vehicle operation over next-generation wireless networks.","authors":["Dimitrios Kafetzis","Nikos Fotiou","Savvas Argyropoulos","Jad Nasreddine","Iordanis Koutsopoulos"],"url":"https://arxiv.org/abs/2506.03166"}
{"created":"2025-06-05","title":"Distributionally Robust Wireless Semantic Communication with Large AI Models","abstract":"6G wireless systems are expected to support massive volumes of data with ultra-low latency. However, conventional bit-level transmission strategies cannot support the efficiency and adaptability required by modern, data-intensive applications. The concept of semantic communication (SemCom) addresses this limitation by focusing on transmitting task-relevant semantic information instead of raw data. While recent efforts incorporating deep learning and large-scale AI models have improved SemCom's performance, existing systems remain vulnerable to both semantic-level and transmission-level noise because they often rely on domain-specific architectures that hinder generalizability. In this paper, a novel and generalized semantic communication framework called WaSeCom is proposed to systematically address uncertainty and enhance robustness. In particular, Wasserstein distributionally robust optimization is employed to provide resilience against semantic misinterpretation and channel perturbations. A rigorous theoretical analysis is performed to establish the robust generalization guarantees of the proposed framework. Experimental results on image and text transmission demonstrate that WaSeCom achieves improved robustness under noise and adversarial perturbations. These results highlight its effectiveness in preserving semantic fidelity across varying wireless conditions.","authors":["Long Tan Le","Senura Hansaja Wanasekara","Zerun Niu","Yansong Shi","Nguyen H. Tran","Phuong Vo","Walid Saad","Dusit Niyato","Zhu Han","Choong Seon Hong","H. Vincent Poor"],"url":"https://arxiv.org/abs/2506.03167"}
{"created":"2025-06-05","title":"Farm-LightSeek: An Edge-centric Multimodal Agricultural IoT Data Analytics Framework with Lightweight LLMs","abstract":"Amid the challenges posed by global population growth and climate change, traditional agricultural Internet of Things (IoT) systems is currently undergoing a significant digital transformation to facilitate efficient big data processing. While smart agriculture utilizes artificial intelligence (AI) technologies to enable precise control, it still encounters significant challenges, including excessive reliance on agricultural expert knowledge, difficulties in fusing multimodal data, poor adaptability to dynamic environments, and bottlenecks in real-time decision-making at the edge. Large language models (LLMs), with their exceptional capabilities in knowledge acquisition and semantic understanding, provide a promising solution to address these challenges. To this end, we propose Farm-LightSeek, an edge-centric multimodal agricultural IoT data analytics framework that integrates LLMs with edge computing. This framework collects real-time farmland multi-source data (images, weather, geographic information) via sensors, performs cross-modal reasoning and disease detection at edge nodes, conducts low-latency management decisions, and enables cloud collaboration for model updates. The main innovations of Farm-LightSeek include: (1) an agricultural \"perception-decision-action\" closed-loop architecture; (2) cross-modal adaptive monitoring; and (3)a lightweight LLM deployment strategy balancing performance and efficiency. Experiments conducted on two real-world datasets demonstrate that Farm-LightSeek consistently achieves reliable performance in mission-critical tasks, even under the limitations of edge computing resources. This work advances intelligent real-time agricultural solutions and highlights the potential for deeper integration of agricultural IoT with LLMs.","authors":["Dawen Jiang","Zhishu Shen","Qiushi Zheng","Tiehua Zhang","Wei Xiang","Jiong Jin"],"url":"https://arxiv.org/abs/2506.03168"}
{"created":"2025-06-05","title":"Improvement of human health lifespan with hybrid group pose estimation methods","abstract":"Human beings rely heavily on estimation of poses in order to access their body movements. Human pose estimation methods take advantage of computer vision advances in order to track human body movements in real life applications. This comes from videos which are recorded through available devices. These para-digms provide potential to make human movement measurement more accessible to users. The consumers of pose estimation movements believe that human poses content tend to supplement available videos. This has increased pose estimation software usage to estimate human poses. In order to address this problem, we develop hybrid-ensemble-based group pose estimation method to improve human health. This proposed hybrid-ensemble-based group pose estimation method aims to detect multi-person poses using modified group pose estimation and modified real time pose estimation. This ensemble allows fusion of performance of stated methods in real time. The input poses from images are fed into individual meth-ods. The pose transformation method helps to identify relevant features for en-semble to perform training effectively. After this, customized pre-trained hybrid ensemble is trained on public benchmarked datasets which is being evaluated through test datasets. The effectiveness and viability of proposed method is estab-lished based on comparative analysis of group pose estimation methods and ex-periments conducted on benchmarked datasets. It provides best optimized results in real-time pose estimation. It makes pose estimation method more robust to oc-clusion and improves dense regression accuracy. These results have affirmed po-tential application of this method in several real-time situations with improvement in human health life span","authors":["Arindam Chaudhuri"],"url":"https://arxiv.org/abs/2506.03169"}
{"created":"2025-06-05","title":"PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models","abstract":"The risk of misusing text-to-image generative models for malicious uses, especially due to the open-source development of such models, has become a serious concern. As a risk mitigation strategy, attributing generative models with neural fingerprinting is emerging as a popular technique. There has been a plethora of recent work that aim for addressing neural fingerprinting. A trade-off between the attribution accuracy and generation quality of such models has been studied extensively. None of the existing methods yet achieved $100\\%$ attribution accuracy. However, any model with less than \\emph{perfect} accuracy is practically non-deployable. In this work, we propose an accurate method to incorporate neural fingerprinting for text-to-image diffusion models leveraging the concepts of cyclic error correcting codes from the literature of coding theory.","authors":["Murthy L","Subarna Tripathi"],"url":"https://arxiv.org/abs/2506.03170"}
{"created":"2025-06-05","title":"EdgeVidSum: Real-Time Personalized Video Summarization at the Edge","abstract":"EdgeVidSum is a lightweight method that generates personalized, fast-forward summaries of long-form videos directly on edge devices. The proposed approach enables real-time video summarization while safeguarding user privacy through local data processing using innovative thumbnail-based techniques and efficient neural architectures. Unlike conventional methods that process entire videos frame by frame, the proposed method uses thumbnail containers to significantly reduce computational complexity without sacrificing semantic relevance. The framework employs a hierarchical analysis approach, where a lightweight 2D CNN model identifies user-preferred content from thumbnails and generates timestamps to create fast-forward summaries. Our interactive demo highlights the system's ability to create tailored video summaries for long-form videos, such as movies, sports events, and TV shows, based on individual user preferences. The entire computation occurs seamlessly on resource-constrained devices like Jetson Nano, demonstrating how EdgeVidSum addresses the critical challenges of computational efficiency, personalization, and privacy in modern video consumption environments.","authors":["Ghulam Mujtaba","Eun-Seok Ryu"],"url":"https://arxiv.org/abs/2506.03171"}
{"created":"2025-06-05","title":"Large Neighborhood and Hybrid Genetic Search for Inventory Routing Problems","abstract":"The inventory routing problem (IRP) focuses on jointly optimizing inventory and distribution operations from a supplier to retailers over multiple days. Compared to other problems from the vehicle routing family, the interrelations between inventory and routing decisions render IRP optimization more challenging and call for advanced solution techniques. A few studies have focused on developing large neighborhood search approaches for this class of problems, but this remains a research area with vast possibilities due to the challenges related to the integration of inventory and routing decisions. In this study, we advance this research area by developing a new large neighborhood search operator tailored for the IRP. Specifically, the operator optimally removes and reinserts all visits to a specific retailer while minimizing routing and inventory costs. We propose an efficient tailored dynamic programming algorithm that exploits preprocessing and acceleration strategies. The operator is used to build an effective local search routine, and included in a state-of-the-art routing algorithm, i.e., Hybrid Genetic Search (HGS). Through extensive computational experiments, we demonstrate that the resulting heuristic algorithm leads to solutions of unmatched quality up to this date, especially on large-scale benchmark instances.","authors":["Jingyi Zhao","Claudia Archetti","Tuan Anh Pham","Thibaut Vidal"],"url":"https://arxiv.org/abs/2506.03172"}
{"created":"2025-06-05","title":"FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution","abstract":"Physical intelligence -- anticipating and shaping the world from partial, multisensory observations -- is critical for next-generation world models. We propose FOLIAGE, a physics-informed multimodal world model for unbounded accretive surface growth. In its Action-Perception loop, a unified context encoder maps images, mesh connectivity, and point clouds to a shared latent state. A physics-aware predictor, conditioned on physical control actions, advances this latent state in time to align with the target latent of the surface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces with critic heads for downstream objectives. FOLIAGE's Accretive Graph Network (AGN) captures dynamic connectivity through Age Positional Encoding and Energy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch Masking enhance MAGE's expressiveness, while Hierarchical Pooling balances global context with local dynamics. We create SURF-GARDEN, a world model learning platform comprising a Counterfactual Physics Simulator, a Multimodal Correspondence Extractor, and Evolution Tracing, which generates 7,200 diverse surface-growth sequences. SURF-BENCH, our physical-intelligence evaluation suite, evaluates six core tasks -- topology recognition, inverse material estimation, growth-stage classification, latent roll-out, cross-modal retrieval, and dense correspondence -- and four stress tests -- sensor dropout, zero-shot modality transfer, long-horizon prediction, and physics ablation -- to probe resilience. FOLIAGE outperforms specialized baselines while remaining robust across dynamic environments, establishing a new world-model based, multimodal pathway to physical intelligence.","authors":["Xiaoyi Liu","Hao Tang"],"url":"https://arxiv.org/abs/2506.03173"}
{"created":"2025-06-05","title":"Multimodal Foundation Model for Cross-Modal Retrieval and Activity Recognition Tasks","abstract":"In recent years, the widespread adoption of wearable devices has highlighted the growing importance of behavior analysis using IMU. While applications span diverse fields such as healthcare and robotics, recent studies have increasingly focused on multimodal analysis, in addition to unimodal analysis. Several studies have proposed multimodal foundation models that incorporate first-person video and text data; however, these models still fall short in providing a detailed analysis of full-body human activity. To address this limitation, we propose Activity Understanding and Representations Alignment - Multimodal Foundation Model (AURA-MFM), a foundational model integrating four modalities: third-person video, motion capture, IMU, and text. By incorporating third-person video and motion capture data, the model enables a detailed and multidimensional understanding of human activity, which first-person perspectives alone fail to capture. Additionally, a Transformer-based IMU encoder is employed to enhance the model's overall performance. Experimental evaluations on retrieval and activity recognition tasks demonstrate that our model surpasses existing methods. Notably, in the zero-shot classification for action recognition, our method achieved significantly higher performance, with an F1-score of 0.6226 and an accuracy of 0.7320, whereas the existing method recorded an F1-score of 0.0747 and an accuracy of 0.1961.","authors":["Koki Matsuishi","Kosuke Ukita","Tsuyoshi Okita"],"url":"https://arxiv.org/abs/2506.03174"}
{"created":"2025-06-05","title":"Non-collective Calibrating Strategy for Time Series Forecasting","abstract":"Deep learning-based approaches have demonstrated significant advancements in time series forecasting. Despite these ongoing developments, the complex dynamics of time series make it challenging to establish the rule of thumb for designing the golden model architecture. In this study, we argue that refining existing advanced models through a universal calibrating strategy can deliver substantial benefits with minimal resource costs, as opposed to elaborating and training a new model from scratch. We first identify a multi-target learning conflict in the calibrating process, which arises when optimizing variables across time steps, leading to the underutilization of the model's learning capabilities. To address this issue, we propose an innovative calibrating strategy called Socket+Plug (SoP). This approach retains an exclusive optimizer and early-stopping monitor for each predicted target within each Plug while keeping the fully trained Socket backbone frozen. The model-agnostic nature of SoP allows it to directly calibrate the performance of any trained deep forecasting models, regardless of their specific architectures. Extensive experiments on various time series benchmarks and a spatio-temporal meteorological ERA5 dataset demonstrate the effectiveness of SoP, achieving up to a 22% improvement even when employing a simple MLP as the Plug (highlighted in Figure 1)","authors":["Bin Wang","Yongqi Han","Minbo Ma","Tianrui Li","Junbo Zhang","Feng Hong","Yanwei Yu"],"url":"https://arxiv.org/abs/2506.03176"}
{"created":"2025-06-05","title":"Vid-SME: Membership Inference Attacks against Large Video Understanding Models","abstract":"Multimodal large language models (MLLMs) demonstrate remarkable capabilities in handling complex multimodal tasks and are increasingly adopted in video understanding applications. However, their rapid advancement raises serious data privacy concerns, particularly given the potential inclusion of sensitive video content, such as personal recordings and surveillance footage, in their training datasets. Determining improperly used videos during training remains a critical and unresolved challenge. Despite considerable progress on membership inference attacks (MIAs) for text and image data in MLLMs, existing methods fail to generalize effectively to the video domain. These methods suffer from poor scalability as more frames are sampled and generally achieve negligible true positive rates at low false positive rates (TPR@Low FPR), mainly due to their failure to capture the inherent temporal variations of video frames and to account for model behavior differences as the number of frames varies. To address these challenges, we introduce Vid-SME, the first membership inference method tailored for video data used in video understanding LLMs (VULLMs). Vid-SME leverages the confidence of model output and integrates adaptive parameterization to compute Sharma-Mittal entropy (SME) for video inputs. By leveraging the SME difference between natural and temporally-reversed video frames, Vid-SME derives robust membership scores to determine whether a given video is part of the model's training set. Experiments on various self-trained and open-sourced VULLMs demonstrate the strong effectiveness of Vid-SME.","authors":["Qi Li","Runpeng Yu","Xinchao Wang"],"url":"https://arxiv.org/abs/2506.03179"}
{"created":"2025-06-05","title":"Knowledge Graphs for Digitized Manuscripts in Jagiellonian Digital Library Application","abstract":"Digitizing cultural heritage collections has become crucial for preservation of historical artifacts and enhancing their availability to the wider public. Galleries, libraries, archives and museums (GLAM institutions) are actively digitizing their holdings and creates extensive digital collections. Those collections are often enriched with metadata describing items but not exactly their contents. The Jagiellonian Digital Library, standing as a good example of such an effort, offers datasets accessible through protocols like OAI-PMH. Despite these improvements, metadata completeness and standardization continue to pose substantial obstacles, limiting the searchability and potential connections between collections. To deal with these challenges, we explore an integrated methodology of computer vision (CV), artificial intelligence (AI), and semantic web technologies to enrich metadata and construct knowledge graphs for digitized manuscripts and incunabula.","authors":["Jan Ignatowicz","Krzysztof Kutt","Grzegorz J. Nalepa"],"url":"https://arxiv.org/abs/2506.03180"}
{"created":"2025-06-05","title":"TerraIncognita: A Dynamic Benchmark for Species Discovery Using Frontier Models","abstract":"The rapid global loss of biodiversity, particularly among insects, represents an urgent ecological crisis. Current methods for insect species discovery are manual, slow, and severely constrained by taxonomic expertise, hindering timely conservation actions. We introduce TerraIncognita, a dynamic benchmark designed to evaluate state-of-the-art multimodal models for the challenging problem of identifying unknown, potentially undescribed insect species from image data. Our benchmark dataset combines a mix of expertly annotated images of insect species likely known to frontier AI models, and images of rare and poorly known species, for which few/no publicly available images exist. These images were collected from underexplored biodiversity hotspots, realistically mimicking open-world discovery scenarios faced by ecologists. The benchmark assesses models' proficiency in hierarchical taxonomic classification, their capability to detect and abstain from out-of-distribution (OOD) samples representing novel species, and their ability to generate explanations aligned with expert taxonomic knowledge. Notably, top-performing models achieve over 90\\% F1 at the Order level on known species, but drop below 2\\% at the Species level, highlighting the sharp difficulty gradient from coarse to fine taxonomic prediction (Order $\\rightarrow$ Family $\\rightarrow$ Genus $\\rightarrow$ Species). TerraIncognita will be updated regularly, and by committing to quarterly dataset expansions (of both known and novel species), will provide an evolving platform for longitudinal benchmarking of frontier AI methods. All TerraIncognita data, results, and future updates are available \\href{https://baskargroup.github.io/TerraIncognita/}{here}.","authors":["Shivani Chiranjeevi","Hossein Zaremehrjerdi","Zi K. Deng","Talukder Z. Jubery","Ari Grele","Arti Singh","Asheesh K Singh","Soumik Sarkar","Nirav Merchant","Harold F. Greeney","Baskar Ganapathysubramanian","Chinmay Hegde"],"url":"https://arxiv.org/abs/2506.03182"}
{"created":"2025-06-05","title":"Impact of Tuning Parameters in Deep Convolutional Neural Network Using a Crack Image Dataset","abstract":"The performance of a classifier depends on the tuning of its parame ters. In this paper, we have experimented the impact of various tuning parameters on the performance of a deep convolutional neural network (DCNN). In the ex perimental evaluation, we have considered a DCNN classifier that consists of 2 convolutional layers (CL), 2 pooling layers (PL), 1 dropout, and a dense layer. To observe the impact of pooling, activation function, and optimizer tuning pa rameters, we utilized a crack image dataset having two classes: negative and pos itive. The experimental results demonstrate that with the maxpooling, the DCNN demonstrates its better performance for adam optimizer and tanh activation func tion.","authors":["Mahe Zabin","Ho-Jin Choi","Md. Monirul Islam","Jia Uddin"],"url":"https://arxiv.org/abs/2506.03184"}
{"created":"2025-06-05","title":"Comparing Retrieval Strategies to Capture Interdisciplinary Scientific Research: A Bibliometric Evaluation of the Integration of Neuroscience and Computer Science","abstract":"Interdisciplinary scientific research is increasingly important in knowledge production, funding policies, and academic discussions on scholarly communication. While many studies focus on interdisciplinary corpora defined a priori - usually through keyword-based searches within assumed interdisciplinary domains - few explore interdisciplinarity as an emergent intersection between two distinct fields. Thus, methodological proposals for building databases at the intersection of two fields of knowledge are scarce. The goal of this article is to develop and compare different strategies for defining an interdisciplinary corpus between two bodies of knowledge. As a case study, we focus on the intersection between neuroscience and computer science. To this end, we develop and compare four retrieval strategies, two of them based on keywords and two based on citation and reference patterns. Our results show that keyword-based strategies provide both better precision and recall. While we focus on comparing strategies for the study of the intersection between the fields of neuroscience and computer science, this proposed methodological reflection is applicable to a wide range of interdisciplinary domains.","authors":["Malena Mendez Isla","Agustin Mauro","Diego Kozlowski"],"url":"https://arxiv.org/abs/2506.03187"}
{"created":"2025-06-05","title":"Continual Learning in Vision-Language Models via Aligned Model Merging","abstract":"Continual learning is conventionally tackled through sequential fine-tuning, a process that, while enabling adaptation, inherently favors plasticity over the stability needed to retain prior knowledge. While existing approaches attempt to mitigate catastrophic forgetting, a bias towards recent tasks persists as they build upon this sequential nature. In this work we present a new perspective based on model merging to maintain stability while still retaining plasticity. Rather than just sequentially updating the model weights, we propose merging newly trained task parameters with previously learned ones, promoting a better balance. To maximize the effectiveness of the merging process, we propose a simple mechanism that promotes learning aligned weights with previous ones, thereby avoiding interference when merging. We evaluate this approach on large Vision-Language Models (VLMs), and demonstrate its effectiveness in reducing forgetting, increasing robustness to various task orders and similarities, and improving generalization.","authors":["Ghada Sokar","Gintare Karolina Dziugaite","Anurag Arnab","Ahmet Iscen","Pablo Samuel Castro","Cordelia Schmid"],"url":"https://arxiv.org/abs/2506.03189"}
{"created":"2025-06-05","title":"MINT: Memory-Infused Prompt Tuning at Test-time for CLIP","abstract":"Improving the generalization ability of Vision-Language Pre-trained Models (VLMs) under test-time data distribution shifts remains a critical challenge. The existing Test-Time Adaptation (TTA) methods fall short in fully leveraging the model's internal knowledge, particularly in dynamically adapting to complex and hierarchical visual semantic information. In this paper, we propose Memory-Infused Prompt Tuning (MINT), a novel framework to address this issue. Inspired by human associative memory theory, MINT introduces a Memory Prompt Bank (MPB), which stores learnable key-value prompt pairs that work as a memory of previously seen samples. During the test time, relevant prompt pairs in the MPB are retrieved by the hierarchical visual features of test images to dynamically assemble Associative Prompts. The associative prompts are then injected into the image encoder for fine-grained, customized visual contextual guidance. MINT also utilizes learnable text prompts. MINT thus enables rapid, precise VLM adaptation at test time by leveraging this MPB-acquired memory, without source data or retraining. The code is available at https://github.com/Jamieyi2004/MINT.","authors":["Jiaming Yi","Ruirui Pan","Jishen Yang","Xiulong Yang"],"url":"https://arxiv.org/abs/2506.03190"}
{"created":"2025-06-05","title":"Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward","abstract":"This paper presents an in-depth survey on the use of multimodal Generative Artificial Intelligence (GenAI) and autoregressive Large Language Models (LLMs) for human motion understanding and generation, offering insights into emerging methods, architectures, and their potential to advance realistic and versatile motion synthesis. Focusing exclusively on text and motion modalities, this research investigates how textual descriptions can guide the generation of complex, human-like motion sequences. The paper explores various generative approaches, including autoregressive models, diffusion models, Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based models, by analyzing their strengths and limitations in terms of motion quality, computational efficiency, and adaptability. It highlights recent advances in text-conditioned motion generation, where textual inputs are used to control and refine motion outputs with greater precision. The integration of LLMs further enhances these models by enabling semantic alignment between instructions and motion, improving coherence and contextual relevance. This systematic survey underscores the transformative potential of text-to-motion GenAI and LLM architectures in applications such as healthcare, humanoids, gaming, animation, and assistive technologies, while addressing ongoing challenges in generating efficient and realistic human motion.","authors":["Muhammad Islam","Tao Huang","Euijoon Ahn","Usman Naseem"],"url":"https://arxiv.org/abs/2506.03191"}
{"created":"2025-06-05","title":"Human Fall Detection using Transfer Learning-based 3D CNN","abstract":"Unintentional or accidental falls are one of the significant health issues in senior persons. The population of senior persons is increasing steadily. So, there is a need for an automated fall detection monitoring system. This paper introduces a vision-based fall detection system using a pre-trained 3D CNN. Unlike 2D CNN, 3D CNN extracts not only spatial but also temporal features. The proposed model leverages the original learned weights of a 3D CNN model pre-trained on the Sports1M dataset to extract the spatio-temporal features. Only the SVM classifier was trained, which saves the time required to train the 3D CNN. Stratified shuffle five split cross-validation has been used to split the dataset into training and testing data. Extracted features from the proposed 3D CNN model were fed to an SVM classifier to classify the activity as fall or ADL. Two datasets, GMDCSA and CAUCAFall, were utilized to conduct the experiment. The source code for this work can be accessed via the following link: https://github.com/ekramalam/HFD_3DCNN.","authors":["Ekram Alam","Abu Sufian","Paramartha Dutta","Marco Leo"],"url":"https://arxiv.org/abs/2506.03193"}
{"created":"2025-06-05","title":"HueManity: Probing Fine-Grained Visual Perception in MLLMs","abstract":"Multimodal Large Language Models (MLLMs) excel at high-level visual reasoning, but their performance on nuanced perceptual tasks remains surprisingly limited. We present HueManity, a benchmark designed to assess visual perception in MLLMs. The dataset comprises 83,850 images featuring two-character alphanumeric strings embedded in Ishihara test style dot patterns, challenging models on precise pattern recognition. Our evaluation of nine state-of-the-art MLLMs on HueManity demonstrates a significant performance deficit compared to human and traditional computer vision baselines. The best-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a striking 3% on the alphanumeric `hard' task. In contrast, human participants achieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model reached accuracies of 96.5% and 94.5%. These results highlight a critical gap in the visual capabilities of current MLLMs. Our analysis further explores potential architectural and training-paradigm factors contributing to this perceptual gap in MLLMs. We open-source HueManity dataset and code to foster further research in improving perceptual robustness of MLLMs.","authors":["Rynaa Grover","Jayant Sravan Tamarapalli","Sahiti Yerramilli","Nilay Pande"],"url":"https://arxiv.org/abs/2506.03194"}
{"created":"2025-06-05","title":"Unlabeled Data Improves Fine-Grained Image Zero-shot Classification with Multimodal LLMs","abstract":"Despite Multimodal Large Language Models (MLLMs) showing promising results on general zero-shot image classification tasks, fine-grained image classification remains challenging. It demands precise attention to subtle visual details to distinguish between visually similar subcategories--details that MLLMs may easily overlook without explicit guidance. To address this, we introduce AutoSEP, an iterative self-supervised prompt learning framework designed to enhance MLLM fine-grained classification capabilities in a fully unsupervised manner. Our core idea is to leverage unlabeled data to learn a description prompt that guides MLLMs in identifying crucial discriminative features within an image, and boosts classification accuracy. We developed an automatic self-enhancing prompt learning framework called AutoSEP to iteratively improve the description prompt using unlabeled data, based on instance-level classification scoring function. AutoSEP only requires black-box access to MLLMs, eliminating the need for any training or fine-tuning. We evaluate our approach on multiple fine-grained classification datasets. It consistently outperforms other unsupervised baselines, demonstrating the effectiveness of our self-supervised optimization framework. Notably, AutoSEP on average improves 13 percent over standard zero-shot classification and 5 percent over the best-performing baselines. Code is available at: https://github.com/yq-hong/AutoSEP","authors":["Yunqi Hong","Sohyun An","Andrew Bai","Neil Y. C. Lin","Cho-Jui Hsieh"],"url":"https://arxiv.org/abs/2506.03195"}
{"created":"2025-06-05","title":"Graph Neural Networks for Jamming Source Localization","abstract":"Graph-based learning has emerged as a transformative approach for modeling complex relationships across diverse domains, yet its potential in wireless security remains largely unexplored. In this work, we introduce the first application of graph-based learning for jamming source localization, addressing the imminent threat of jamming attacks in wireless networks. Unlike geometric optimization techniques that struggle under environmental uncertainties and dense interference, we reformulate localization as an inductive graph regression task. Our approach integrates structured node representations that encode local and global signal aggregation, ensuring spatial coherence and adaptive signal fusion. To enhance robustness, we incorporate an attention-based graph neural network that adaptively refines neighborhood influence and introduces a confidence-guided estimation mechanism that dynamically balances learned predictions with domain-informed priors. We evaluate our approach under complex radio frequency environments with varying sampling densities and signal propagation conditions, conducting comprehensive ablation studies on graph construction, feature selection, and pooling strategies. Results demonstrate that our novel graph-based learning framework significantly outperforms established localization baselines, particularly in challenging scenarios with sparse and obfuscated signal information. Code is available at [https://github.com/daniaherzalla/gnn-jamming-source-localization](https://github.com/daniaherzalla/gnn-jamming-source-localization).","authors":["Dania Herzalla","Willian T. Lunardi","Martin Andreoni"],"url":"https://arxiv.org/abs/2506.03196"}
{"created":"2025-06-05","title":"Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing","abstract":"Automated parsing of scanned documents into richly structured, machine-readable formats remains a critical bottleneck in Document AI, as traditional multi-stage pipelines suffer from error propagation and limited adaptability to diverse layouts. We introduce layoutRL, an end-to-end reinforcement learning framework that trains models to be explicitly layout-aware by optimizing a composite reward of normalized edit distance, paragraph count accuracy, and reading order preservation. Leveraging our newly released dataset, Infinity-Doc-55K, which combines 55K high-fidelity synthetic scanned document parsing data with expert-filtered real-world documents, we instantiate layoutRL in a vision-language-model-based parser called Infinity-Parser. Evaluated on English and Chinese benchmarks for OCR, table and formula extraction, and reading order detection, Infinity-Parser achieves new state-of-the-art performance in both accuracy and structural fidelity, outpacing specialist pipelines and general-purpose vision-language models. We will publicly release our code and dataset to accelerate progress in robust document understanding.","authors":["Baode Wang","Biao Wu","Weizhen Li","Meng Fang","Yanjie Liang","Zuming Huang","Haozhe Wang","Jun Huang","Ling Chen","Wei Chu","Yuan Qi"],"url":"https://arxiv.org/abs/2506.03197"}
{"created":"2025-06-05","title":"FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment","abstract":"With the increasing awareness of health and the growing desire for aesthetic physique, fitness has become a prevailing trend. However, the potential risks associated with fitness training, especially with weight-loaded fitness actions, cannot be overlooked. Action Quality Assessment (AQA), a technology that quantifies the quality of human action and provides feedback, holds the potential to assist fitness enthusiasts of varying skill levels in achieving better training outcomes. Nevertheless, current AQA methodologies and datasets are limited to single-view competitive sports scenarios and RGB modality and lack professional assessment and guidance of fitness actions. To address this gap, we propose the FLEX dataset, the first multi-modal, multi-action, large-scale dataset that incorporates surface electromyography (sEMG) signals into AQA. FLEX utilizes high-precision MoCap to collect 20 different weight-loaded actions performed by 38 subjects across 3 different skill levels for 10 repetitions each, containing 5 different views of the RGB video, 3D pose, sEMG, and physiological information. Additionally, FLEX incorporates knowledge graphs into AQA, constructing annotation rules in the form of penalty functions that map weight-loaded actions, action keysteps, error types, and feedback. We conducted various baseline methodologies on FLEX, demonstrating that multimodal data, multiview data, and fine-grained annotations significantly enhance model performance. FLEX not only advances AQA methodologies and datasets towards multi-modal and multi-action scenarios but also fosters the integration of artificial intelligence within the fitness domain. Dataset and code are available at https://haoyin116.github.io/FLEX_Dataset.","authors":["Hao Yin","Lijun Gu","Paritosh Parmar","Lin Xu","Tianxiao Guo","Weiwei Fu","Yang Zhang","Tianyou Zheng"],"url":"https://arxiv.org/abs/2506.03198"}
{"created":"2025-06-05","title":"Self-Sustaining Multi-Sensor LoRa-Based Activity Monitoring for Community Workout Parks","abstract":"With the rise of the Internet of Things (IoT), more sensors are deployed around us, covering a wide range of applications from industry and agriculture to urban environments such as smart cities. Throughout these applications the sensors collect data of various characteristics and support city planners and decision-makers in their work processes, ultimately maximizing the impact of public funds. This paper introduces the design and implementation of a self-sustaining wireless sensor node designed to continuously monitor the utilization of community street workout parks. The proposed sensor node monitors activity by leveraging acceleration data capturing micro-vibrations that propagate through the steel structures of the workout equipment. This allows us to detect activity duration with an average measured error of only 2.8 seconds. The sensor is optimized with an energy-aware, adaptive sampling and transmission algorithm which, in combination with the Long Range Wide Area Network (LoRaWAN), reduces power consumption to just 1.147 mW in normal operation and as low as 0.712 mW in low-power, standby mode allowing 46 days of battery runtime. In addition, the integrated energy-harvesting circuit was tested in the field. By monitoring the battery voltage for multiple days, it was shown that the sensor is capable of operating sustainably year-round without external power sources. To evaluate the sensor effectiveness, we conducted a week-long field test in Zurich, placing sensors at various street workout parks throughout the city. Analysis of the collected data revealed clear patterns in park usage depending on day and location. This dataset is made publicly available through our online dashboard. Finally, we showcase the potential of IoT for city applications in combination with an accessible data interface for decision-makers.","authors":["Victor Luder","Michele Magno"],"url":"https://arxiv.org/abs/2506.03203"}
{"created":"2025-06-05","title":"Q-ARDNS-Multi: A Multi-Agent Quantum Reinforcement Learning Framework with Meta-Cognitive Adaptation for Complex 3D Environments","abstract":"This paper presents Q-ARDNS-Multi, an advanced multi-agent quantum reinforcement learning (QRL) framework that extends the ARDNS-FN-Quantum model, where Q-ARDNS-Multi stands for \"Quantum Adaptive Reward-Driven Neural Simulator - Multi-Agent\". It integrates quantum circuits with RY gates, meta-cognitive adaptation, and multi-agent coordination mechanisms for complex 3D environments. Q-ARDNS-Multi leverages a 2-qubit quantum circuit for action selection, a dual-memory system inspired by human cognition, a shared memory module for agent cooperation, and adaptive exploration strategies modulated by reward variance and intrinsic motivation. Evaluated in a $10 \\times 10 \\times 3$ GridWorld environment with two agents over 5000 episodes, Q-ARDNS-Multi achieves success rates of 99.6\\% and 99.5\\% for Agents 0 and 1, respectively, outperforming Multi-Agent Deep Deterministic Policy Gradient (MADDPG) and Soft Actor-Critic (SAC) in terms of success rate, stability, navigation efficiency, and collision avoidance. The framework records mean rewards of $-304.2891 \\pm 756.4636$ and $-295.7622 \\pm 752.7103$, averaging 210 steps to goal, demonstrating its robustness in dynamic settings. Comprehensive analyses, including learning curves, reward distributions, statistical tests, and computational efficiency evaluations, highlight the contributions of quantum circuits and meta-cognitive adaptation. By bridging quantum computing, cognitive science, and multi-agent RL, Q-ARDNS-Multi offers a scalable, human-like approach for applications in robotics, autonomous navigation, and decision-making under uncertainty.","authors":["Umberto Gon\\c{c}alves de Sousa"],"url":"https://arxiv.org/abs/2506.03205"}
{"created":"2025-06-05","title":"Out-of-Vocabulary Sampling Boosts Speculative Decoding","abstract":"Speculative decoding relies on fast and accurate drafters. Recent state-of-the-art language models employ larger and larger vocabularies, which significantly slows down drafters. One promising approach to boost the efficiency of speculative decoding is to use drafters with smaller vocabularies. However, existing sampling methods cannot draw out-of-vocabulary tokens, creating a tradeoff between drafters' vocabulary size and acceptance rates. This paper introduces Redistributing Drafter Kernels (RDK), the first out-of-vocabulary sampler that effectively recovers acceptance rates by virtually restoring pruned target tokens. RDK leverages token-affinity priors to reallocate drafter mass towards high-overlap regions. We prove mathematically that RDK can achieve higher acceptance rates than vanilla and state-of-the-art samplers. We provide an efficient first-order approximation of RDK and prove that it reduces redistribution times from $O(N^2)$ to $O(N)$, enabling lightweight implementations for large vocabularies. Our experiments demonstrate that this linear-time RDK significantly boosts acceptance rates even after extreme pruning (removing more than 75% of the drafter's vocabulary), where existing samplers fail. RDK opens the door to extremely pruned drafters, which were previously impractical.","authors":["Nadav Timor","Jonathan Mamou","Oren Pereg","Hongyang Zhang","David Harel"],"url":"https://arxiv.org/abs/2506.03206"}
{"created":"2025-06-05","title":"Fingerprinting Deep Learning Models via Network Traffic Patterns in Federated Learning","abstract":"Federated Learning (FL) is increasingly adopted as a decentralized machine learning paradigm due to its capability to preserve data privacy by training models without centralizing user data. However, FL is susceptible to indirect privacy breaches via network traffic analysis-an area not explored in existing research. The primary objective of this research is to study the feasibility of fingerprinting deep learning models deployed within FL environments by analyzing their network-layer traffic information. In this paper, we conduct an experimental evaluation using various deep learning architectures (i.e., CNN, RNN) within a federated learning testbed. We utilize machine learning algorithms, including Support Vector Machines (SVM), Random Forest, and Gradient-Boosting, to fingerprint unique patterns within the traffic data. Our experiments show high fingerprinting accuracy, achieving 100% accuracy using Random Forest and around 95.7% accuracy using SVM and Gradient Boosting classifiers. This analysis suggests that we can identify specific architectures running within the subsection of the network traffic. Hence, if an adversary knows about the underlying DL architecture, they can exploit that information and conduct targeted attacks. These findings suggest a notable security vulnerability in FL systems and the necessity of strengthening it at the network level.","authors":["Md Nahid Hasan Shuvo","Moinul Hossain"],"url":"https://arxiv.org/abs/2506.03207"}
{"created":"2025-06-05","title":"FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution","abstract":"Accurate, high-resolution ocean forecasting is crucial for maritime operations and environmental monitoring. While traditional numerical models are capable of producing sub-daily, eddy-resolving forecasts, they are computationally intensive and face challenges in maintaining accuracy at fine spatial and temporal scales. In contrast, recent data-driven approaches offer improved computational efficiency and emerging potential, yet typically operate at daily resolution and struggle with sub-daily predictions due to error accumulation over time. We introduce FuXi-Ocean, the first data-driven global ocean forecasting model achieving six-hourly predictions at eddy-resolving 1/12{\\deg} spatial resolution, reaching depths of up to 1500 meters. The model architecture integrates a context-aware feature extraction module with a predictive network employing stacked attention blocks. The core innovation is the Mixture-of-Time (MoT) module, which adaptively integrates predictions from multiple temporal contexts by learning variable-specific reliability , mitigating cumulative errors in sequential forecasting. Through comprehensive experimental evaluation, FuXi-Ocean demonstrates superior skill in predicting key variables, including temperature, salinity, and currents, across multiple depths.","authors":["Qiusheng Huang","Yuan Niu","Xiaohui Zhong","Anboyu Guo","Lei Chen","Dianjun Zhang","Xuefeng Zhang","Hao Li"],"url":"https://arxiv.org/abs/2506.03210"}
{"created":"2025-06-05","title":"Channel-adaptive Cross-modal Generative Semantic Communication for Point Cloud Transmission","abstract":"With the rapid development of autonomous driving and extended reality, efficient transmission of point clouds (PCs) has become increasingly important. In this context, we propose a novel channel-adaptive cross-modal generative semantic communication (SemCom) for PC transmission, called GenSeC-PC. GenSeC-PC employs a semantic encoder that fuses images and point clouds, where images serve as non-transmitted side information. Meanwhile, the decoder is built upon the backbone of PointDif. Such a cross-modal design not only ensures high compression efficiency but also delivers superior reconstruction performance compared to PointDif. Moreover, to ensure robust transmission and reduce system complexity, we design a streamlined and asymmetric channel-adaptive joint semantic-channel coding architecture, where only the encoder needs the feedback of average signal-to-noise ratio (SNR) and available bandwidth. In addition, rectified denoising diffusion implicit models is employed to accelerate the decoding process to the millisecond level, enabling real-time PC communication. Unlike existing methods, GenSeC-PC leverages generative priors to ensure reliable reconstruction even from noisy or incomplete source PCs. More importantly, it supports fully analog transmission, improving compression efficiency by eliminating the need for error-free side information transmission common in prior SemCom approaches. Simulation results confirm the effectiveness of cross-modal semantic extraction and dual-metric guided fine-tuning, highlighting the framework's robustness across diverse conditions, including low SNR, bandwidth limitations, varying numbers of 2D images, and previously unseen objects.","authors":["Wanting Yang","Zehui Xiong","Qianqian Yang","Ping Zhang","Merouane Debbah","Rahim Tafazolli"],"url":"https://arxiv.org/abs/2506.03211"}
{"created":"2025-06-05","title":"ConMamba: Contrastive Vision Mamba for Plant Disease Detection","abstract":"Plant Disease Detection (PDD) is a key aspect of precision agriculture. However, existing deep learning methods often rely on extensively annotated datasets, which are time-consuming and costly to generate. Self-supervised Learning (SSL) offers a promising alternative by exploiting the abundance of unlabeled data. However, most existing SSL approaches suffer from high computational costs due to convolutional neural networks or transformer-based architectures. Additionally, they struggle to capture long-range dependencies in visual representation and rely on static loss functions that fail to align local and global features effectively. To address these challenges, we propose ConMamba, a novel SSL framework specially designed for PDD. ConMamba integrates the Vision Mamba Encoder (VME), which employs a bidirectional State Space Model (SSM) to capture long-range dependencies efficiently. Furthermore, we introduce a dual-level contrastive loss with dynamic weight adjustment to optimize local-global feature alignment. Experimental results on three benchmark datasets demonstrate that ConMamba significantly outperforms state-of-the-art methods across multiple evaluation metrics. This provides an efficient and robust solution for PDD.","authors":["Abdullah Al Mamun","Miaohua Zhang","David Ahmedt-Aristizabal","Zeeshan Hayder","Mohammad Awrangjeb"],"url":"https://arxiv.org/abs/2506.03213"}
{"created":"2025-06-05","title":"Beware! The AI Act Can Also Apply to Your AI Research Practices","abstract":"The EU has become one of the vanguards in regulating the digital age. A particularly important regulation in the Artificial Intelligence (AI) domain is the EU AI Act, which entered into force in 2024. The AI Act specifies -- due to a risk-based approach -- various obligations for providers of AI systems. These obligations, for example, include a cascade of documentation and compliance measures, which represent a potential obstacle to science. But do these obligations also apply to AI researchers? This position paper argues that, indeed, the AI Act's obligations could apply in many more cases than the AI community is aware of. In our analysis of the AI Act and its applicability, we contribute the following: 1.) We give a high-level introduction to the AI Act aimed at non-legal AI research scientists. 2.) We explain with everyday research examples why the AI Act applies to research. 3.) We analyse the exceptions of the AI Act's applicability and state that especially scientific research exceptions fail to account for current AI research practices. 4.) We propose changes to the AI Act to provide more legal certainty for AI researchers and give two recommendations for AI researchers to reduce the risk of not complying with the AI Act. We see our paper as a starting point for a discussion between policymakers, legal scholars, and AI researchers to avoid unintended side effects of the AI Act on research.","authors":["Alina Wernick","Kristof Meding"],"url":"https://arxiv.org/abs/2506.03218"}
{"created":"2025-06-05","title":"HARNode: A Time-Synchronised, Open-Source, Multi-Device, Wearable System for Ad Hoc Field Studies","abstract":"Research into human activity recognition (HAR) suffers from a lack of comprehensive, freely available field data. Commercial systems are rarely open source, offer little expandability, and have shortcomings in node synchronisation, data throughput, placement clarity, setup complexity, and cost. As a result, only a few intuitively placed sensors are often used, and field trials are generally reduced. HARNode addresses these obstacles as a fully open-source hardware and software platform for rapid field applications. Each sensor node combines an ESP32-S3 module (AtomS3) with a display, a 9-axis IMU (Bosch BMX160), pressure/temperature sensors (Bosch BMP388) and an I2C port for extensions; the operating time is up to 8 hours. Data is streamed via Wi-Fi, while NTP-based time synchronisation provides an average clock accuracy of $\\approx$ 1 ms. Manufacturing is carried out exclusively with commercially available components, an online PCB service - requiring little hardware knowledge - and a compact, 3D-printed housing with Velcro straps, allowing almost any number of highly synchronised nodes to be flexibly attached to the body. Its performance was demonstrated in a proof-of-concept study with ten test subjects, each wearing eleven HARNodes; the entire setup took less than five minutes per person. An example application goal was to detect the transition from level walking to climbing stairs. A random forest classifier evaluated the benefits of sensor overprovisioning: the best combination of seven nodes achieved $\\approx$ 98\\% accuracy (binary: level walking vs. approaching stairs), matching the result of all eleven positions. A single sensor on the foot achieved $\\approx$ 90\\% accuracy. These results demonstrate the suitability of HARNode as an ultra-fast ad hoc field system and support evidence-based sensor placement.","authors":["Philipp Lepold","Tobias R\\\"oddiger","Michael Beigl"],"url":"https://arxiv.org/abs/2506.03219"}
{"created":"2025-06-05","title":"Human-In-The-Loop Workflow for Neuro- Symbolic Scholarly Knowledge Organization","abstract":"As the volume of scientific literature continues to grow, efficient knowledge organization is an increasingly challenging task. Traditional structuring of scientific content is time-consuming and requires significant domain expertise, increasing the need for tool support. Our goal is to create a Human-in-the-Loop (HITL) workflow that supports researchers in creating and structuring scientific knowledge, leveraging neural models and knowledge graphs, exemplified using the Open Research Knowledge Graph (ORKG). The workflow aims to automate key steps, including data extraction and knowledge structuring, while keeping user oversight through human validation. We developed a modular framework implementing the workflow and evaluated it along the Quality Improvement Paradigm (QIP) with participants from the ORKG user community. The evaluation indicated that the framework is highly usable and provides practical support. It significantly reduces the time and effort required to transition from a research interest to literature-based answers by streamlining the import of information into a knowledge graph. Participants evaluated the framework with an average System Usability Scale (SUS) score of 84.17, an A+ -- the highest achievable rating. They also reported that it improved their time spent, previously between 4 hours and two weeks, down to an average of 24:40 minutes. The tool streamlines the creation of scientific corpora and extraction of structured knowledge for KG integration by leveraging LLMs and user-defined models, significantly accelerating the review process. However, human validation remains essential throughout the extraction process, and future work is needed to improve extraction accuracy and entity linking to existing knowledge resources.","authors":["Lena John","Tim Wittenborg","S\\\"oren Auer","Oliver Karras"],"url":"https://arxiv.org/abs/2506.03221"}
{"created":"2025-06-05","title":"OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data","abstract":"Accurately estimating high-resolution carbon emissions is crucial for effective emission governance and mitigation planning. While conventional methods for precise carbon accounting are hindered by substantial data collection efforts, the rise of open data and advanced learning techniques offers a promising solution. Once an open data-based prediction model is developed and trained, it can easily infer emissions for new areas based on available open data. To address this, we incorporate two modalities of open data, satellite images and point-of-interest (POI) data, to predict high-resolution urban carbon emissions, with satellite images providing macroscopic and static and POI data offering fine-grained and relatively dynamic functionality information. However, estimating high-resolution carbon emissions presents two significant challenges: the intertwined and implicit effects of various functionalities on carbon emissions, and the complex spatial contiguity correlations that give rise to the agglomeration effect. Our model, OpenCarbon, features two major designs that target the challenges: a cross-modality information extraction and fusion module to extract complementary functionality information from two modules and model their interactions, and a neighborhood-informed aggregation module to capture the spatial contiguity correlations. Extensive experiments demonstrate our model's superiority, with a significant performance gain of 26.6\\% on R2. Further generalizability tests and case studies also show OpenCarbon's capacity to capture the intrinsic relation between urban functionalities and carbon emissions, validating its potential to empower efficient carbon governance and targeted carbon mitigation planning. Codes and data are available: https://github.com/JinweiZzz/OpenCarbon.","authors":["Jinwei Zeng","Yu Liu","Guozhen Zhang","Jingtao Ding","Yuming Lin","Jian Yuan","Yong Li"],"url":"https://arxiv.org/abs/2506.03224"}
{"created":"2025-06-05","title":"Multiple-Frequencies Population-Based Training","abstract":"Reinforcement Learning's high sensitivity to hyperparameters is a source of instability and inefficiency, creating significant challenges for practitioners. Hyperparameter Optimization (HPO) algorithms have been developed to address this issue, among them Population-Based Training (PBT) stands out for its ability to generate hyperparameters schedules instead of fixed configurations. PBT trains a population of agents, each with its own hyperparameters, frequently ranking them and replacing the worst performers with mutations of the best agents. These intermediate selection steps can cause PBT to focus on short-term improvements, leading it to get stuck in local optima and eventually fall behind vanilla Random Search over longer timescales. This paper studies how this greediness issue is connected to the choice of evolution frequency, the rate at which the selection is done. We propose Multiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm that addresses greediness by employing sub-populations, each evolving at distinct frequencies. MF-PBT introduces a migration process to transfer information between sub-populations, with an asymmetric design to balance short and long-term optimization. Extensive experiments on the Brax suite demonstrate that MF-PBT improves sample efficiency and long-term performance, even without actually tuning hyperparameters.","authors":["Wa\\\"el Doulazmi","Auguste Lehuger","Marin Toromanoff","Valentin Charraut","Thibault Buhet","Fabien Moutarde"],"url":"https://arxiv.org/abs/2506.03225"}
{"created":"2025-06-05","title":"Bridging Neural ODE and ResNet: A Formal Error Bound for Safety Verification","abstract":"A neural ordinary differential equation (neural ODE) is a machine learning model that is commonly described as a continuous depth generalization of a residual network (ResNet) with a single residual block, or conversely, the ResNet can be seen as the Euler discretization of the neural ODE. These two models are therefore strongly related in a way that the behaviors of either model are considered to be an approximation of the behaviors of the other. In this work, we establish a more formal relationship between these two models by bounding the approximation error between two such related models. The obtained error bound then allows us to use one of the models as a verification proxy for the other, without running the verification tools twice: if the reachable output set expanded by the error bound satisfies a safety property on one of the models, this safety property is then guaranteed to be also satisfied on the other model. This feature is fully reversible, and the initial safety verification can be run indifferently on either of the two models. This novel approach is illustrated on a numerical example of a fixed-point attractor system modeled as a neural ODE.","authors":["Abdelrahman Sayed Sayed","Pierre-Jean Meyer","Mohamed Ghazel"],"url":"https://arxiv.org/abs/2506.03227"}
{"created":"2025-06-05","title":"Pre-trained Vision-Language Models Assisted Noisy Partial Label Learning","abstract":"In the context of noisy partial label learning (NPLL), each training sample is associated with a set of candidate labels annotated by multiple noisy annotators. With the emergence of high-performance pre-trained vision-language models (VLMs) such as CLIP, LLaVa and GPT-4V, the direction of using these models to replace time-consuming manual annotation workflows and achieve \"manual-annotation-free\" training for downstream tasks has become a highly promising research avenue. This paper focuses on learning from noisy partial labels annotated by pre-trained VLMs and proposes an innovative collaborative consistency regularization (Co-Reg) method. Unlike the symmetric noise primarily addressed in traditional noisy label learning, the noise generated by pre-trained models is instance-dependent, embodying the underlying patterns of the pre-trained models themselves, which significantly increases the learning difficulty for the model. To address this, we simultaneously train two neural networks that implement collaborative purification of training labels through a \"Co-Pseudo-Labeling\" mechanism, while enforcing consistency regularization constraints in both the label space and feature representation space. Our method can also leverage few-shot manually annotated valid labels to further enhance its performances. Comparative experiments with different denoising and disambiguation algorithms, annotation manners, and pre-trained model application schemes fully validate the effectiveness of the proposed method, while revealing the broad prospects of integrating weakly-supervised learning techniques into the knowledge distillation process of pre-trained models.","authors":["Qian-Wei Wang","Yuqiu Xie","Letian Zhang","Zimo Liu","Shu-Tao Xia"],"url":"https://arxiv.org/abs/2506.03229"}
{"created":"2025-06-05","title":"DiaBlo: Diagonal Blocks Are Sufficient For Finetuning","abstract":"Finetuning is a critical step for adapting large language models (LLMs) to domain-specific downstream tasks. To mitigate the substantial computational and memory costs of full-model fine-tuning, Parameter-Efficient Finetuning (PEFT) methods have been proposed to update only a small subset of model parameters. However, performance gaps between PEFT approaches and full-model fine-tuning still exist. In this work, we present DiaBlo, a simple yet effective PEFT approach that updates only the diagonal blocks of selected model weight matrices. Unlike Low Rank Adaptation (LoRA) and its variants, DiaBlo eliminates the need for low rank matrix products, thereby avoiding the reliance on auxiliary initialization schemes or customized optimization strategies to improve convergence. This design leads to stable and robust convergence while maintaining comparable memory efficiency and training speed to LoRA. We conduct extensive experiments across a range of tasks, including commonsense reasoning, arithmetic reasoning, code generation, and safety alignment, to evaluate the effectiveness and efficiency of DiaBlo. Across these benchmarks, DiaBlo demonstrates strong and consistent performance while maintaining high memory efficiency and fast finetuning speed. Codes are available at https://github.com/ziyangjoy/DiaBlo.","authors":["Selcuk Gurses","Aozhong Zhang","Yanxia Deng","Xun Dong","Xin Li","Naigang Wang","Penghang Yin","Zi Yang"],"url":"https://arxiv.org/abs/2506.03230"}
{"created":"2025-06-05","title":"NetPress: Dynamically Generated LLM Benchmarks for Network Applications","abstract":"Despite growing interest in domain-specific benchmarking of large language models (LLMs) and agents, current evaluations remain limited to static, small-scale datasets, especially in high-stakes tasks like network operations that demand reliability for deployments. We present NetPress, an automated benchmark generation framework for evaluating LLM agents in network applications. NetPress introduces a unified abstraction with state and action, enabling dynamic generation of diverse query sets along with corresponding ground truths. At runtime, users can specify benchmark configurations to generate millions of queries on the fly. In addition to dynamic benchmark construction, NetPress integrates with network emulators to provide realistic environment feedback, supporting comprehensive evaluation across correctness, safety, and latency. We instantiate NetPress on three representative applications, revealing interesting fine-grained differences in agent behavior that static, correctness-only benchmarks often miss. NetPress moves LLM evaluation toward realistic, scalable testing in infrastructure-centric domains, helping close the gap between benchmark performance and real-world deployment readiness. Code is available at https://github.com/Froot-NetSys/NetPress.","authors":["Yajie Zhou","Jiajun Ruan","Eric S. Wang","Sadjad Fouladi","Francis Y. Yan","Kevin Hsieh","Zaoxing Liu"],"url":"https://arxiv.org/abs/2506.03231"}
{"created":"2025-06-05","title":"A Trustworthiness-based Metaphysics of Artificial Intelligence Systems","abstract":"Modern AI systems are man-made objects that leverage machine learning to support our lives across a myriad of contexts and applications. Despite extensive epistemological and ethical debates, their metaphysical foundations remain relatively under explored. The orthodox view simply suggests that AI systems, as artifacts, lack well-posed identity and persistence conditions -- their metaphysical kinds are no real kinds. In this work, we challenge this perspective by introducing a theory of metaphysical identity of AI systems. We do so by characterizing their kinds and introducing identity criteria -- formal rules that answer the questions \"When are two AI systems the same?\" and \"When does an AI system persist, despite change?\" Building on Carrara and Vermaas' account of fine-grained artifact kinds, we argue that AI trustworthiness provides a lens to understand AI system kinds and formalize the identity of these artifacts by relating their functional requirements to their physical make-ups. The identity criteria of AI systems are determined by their trustworthiness profiles -- the collection of capabilities that the systems must uphold over time throughout their artifact histories, and their effectiveness in maintaining these capabilities. Our approach suggests that the identity and persistence of AI systems is sensitive to the socio-technical context of their design and utilization via their trustworthiness, providing a solid metaphysical foundation to the epistemological, ethical, and legal discussions about these artifacts.","authors":["Andrea Ferrario"],"url":"https://arxiv.org/abs/2506.03233"}
{"created":"2025-06-05","title":"BadReward: Clean-Label Poisoning of Reward Models in Text-to-Image RLHF","abstract":"Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning text-to-image (T2I) models with human preferences. However, RLHF's feedback mechanism also opens new pathways for adversaries. This paper demonstrates the feasibility of hijacking T2I models by poisoning a small fraction of preference data with natural-appearing examples. Specifically, we propose BadReward, a stealthy clean-label poisoning attack targeting the reward model in multi-modal RLHF. BadReward operates by inducing feature collisions between visually contradicted preference data instances, thereby corrupting the reward model and indirectly compromising the T2I model's integrity. Unlike existing alignment poisoning techniques focused on single (text) modality, BadReward is independent of the preference annotation process, enhancing its stealth and practical threat. Extensive experiments on popular T2I models show that BadReward can consistently guide the generation towards improper outputs, such as biased or violent imagery, for targeted concepts. Our findings underscore the amplified threat landscape for RLHF in multi-modal systems, highlighting the urgent need for robust defenses. Disclaimer. This paper contains uncensored toxic content that might be offensive or disturbing to the readers.","authors":["Kaiwen Duan","Hongwei Yao","Yufei Chen","Ziyun Li","Tong Qiao","Zhan Qin","Cong Wang"],"url":"https://arxiv.org/abs/2506.03234"}
{"created":"2025-06-05","title":"Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems","abstract":"Purpose: This study aims to evaluate the effectiveness of large language models (LLMs) in automating disease annotation of CT radiology reports. We compare a rule-based algorithm (RBA), RadBERT, and three lightweight open-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP) CT reports.","authors":["Michael E. Garcia-Alcoser","Mobina GhojoghNejad","Fakrul Islam Tushar","David Kim","Kyle J. Lafata","Geoffrey D. Rubin","Joseph Y. Lo"],"url":"https://arxiv.org/abs/2506.03259"}
{"created":"2025-06-05","title":"On the Necessity of Multi-Domain Explanation: An Uncertainty Principle Approach for Deep Time Series Models","abstract":"A prevailing approach to explain time series models is to generate attribution in time domain. A recent development in time series XAI is the concept of explanation spaces, where any model trained in the time domain can be interpreted with any existing XAI method in alternative domains, such as frequency. The prevailing approach is to present XAI attributions either in the time domain or in the domain where the attribution is most sparse. In this paper, we demonstrate that in certain cases, XAI methods can generate attributions that highlight fundamentally different features in the time and frequency domains that are not direct counterparts of one another. This suggests that both domains' attributions should be presented to achieve a more comprehensive interpretation. Thus it shows the necessity of multi-domain explanation. To quantify when such cases arise, we introduce the uncertainty principle (UP), originally developed in quantum mechanics and later studied in harmonic analysis and signal processing, to the XAI literature. This principle establishes a lower bound on how much a signal can be simultaneously localized in both the time and frequency domains. By leveraging this concept, we assess whether attributions in the time and frequency domains violate this bound, indicating that they emphasize distinct features. In other words, UP provides a sufficient condition that the time and frequency domain explanations do not match and, hence, should be both presented to the end user. We validate the effectiveness of this approach across various deep learning models, XAI methods, and a wide range of classification and forecasting datasets. The frequent occurrence of UP violations across various datasets and XAI methods highlights the limitations of existing approaches that focus solely on time-domain explanations. This underscores the need for multi-domain explanations as a new paradigm.","authors":["Shahbaz Rezaei","Avishai Halev","Xin Liu"],"url":"https://arxiv.org/abs/2506.03267"}
{"created":"2025-06-05","title":"A conclusive remark on linguistic theorizing and language modeling","abstract":"This is the final remark on the replies received to my target paper in the Italian Journal of Linguistics","authors":["Cristiano Chesi"],"url":"https://arxiv.org/abs/2506.03268"}
{"created":"2025-06-05","title":"Grounded Vision-Language Interpreter for Integrated Task and Motion Planning","abstract":"While recent advances in vision-language models (VLMs) have accelerated the development of language-guided robot planners, their black-box nature often lacks safety guarantees and interpretability crucial for real-world deployment. Conversely, classical symbolic planners offer rigorous safety verification but require significant expert knowledge for setup. To bridge the current gap, this paper proposes ViLaIn-TAMP, a hybrid planning framework for enabling verifiable, interpretable, and autonomous robot behaviors. ViLaIn-TAMP comprises three main components: (1) ViLaIn (Vision-Language Interpreter) - A prior framework that converts multimodal inputs into structured problem specifications using off-the-shelf VLMs without additional domain-specific training, (2) a modular Task and Motion Planning (TAMP) system that grounds these specifications in actionable trajectory sequences through symbolic and geometric constraint reasoning and can utilize learning-based skills for key manipulation phases, and (3) a corrective planning module which receives concrete feedback on failed solution attempts from the motion and task planning components and can feed adapted logic and geometric feasibility constraints back to ViLaIn to improve and further refine the specification. We evaluate our framework on several challenging manipulation tasks in a cooking domain. We demonstrate that the proposed closed-loop corrective architecture exhibits a more than 30% higher mean success rate for ViLaIn-TAMP compared to without corrective planning.","authors":["Jeremy Siburian","Keisuke Shirai","Cristian C. Beltran-Hernandez","Masashi Hamaya","Michael G\\\"orner","Atsushi Hashimoto"],"url":"https://arxiv.org/abs/2506.03270"}
{"created":"2025-06-05","title":"Chipmunk: Training-Free Acceleration of Diffusion Transformers with Dynamic Column-Sparse Deltas","abstract":"Diffusion Transformers (DiTs) have achieved state-of-the-art performance in high-quality image and video generation but incur substantial compute cost at inference. A common observation is that DiT latent noise vectors change slowly across inference steps, which suggests that the DiT compute may be redundant across steps. In this paper, we aim to speed up inference by reducing this redundancy, without additional training. We first study how activations change between steps in two state-of-the-art open-source DiTs. We find that just 5-25% of the values in attention and MLP explain 70-90% of the change in activations across steps. This finding motivates our approach, Chipmunk, which uses dynamic sparsity at inference time to recompute only the fastest-changing intermediate activations, while caching the rest. Dynamic sparsity introduces two systems challenges: (1) sparse attention and MLP operations tend to underutilize GPU tensor cores; and (2) computing dynamic sparsity patterns at runtime and caching activations both introduce overhead. To address these challenges, Chipmunk first uses a voxel-based reordering of input tokens to introduce column-wise sparsity. We implement column-sparse kernels utilizing efficient sparse gathers from global to shared GPU memory, achieving a 9.3x speedup at 93% sparsity compared to highly-optimized dense baselines. Second, Chipmunk overlaps the computation of sparsity patterns and cache updates with other parts of the computation (e.g., second layer of the MLP) to hide the extra latency. Chipmunk achieves up to 2.16x speedup on HunyuanVideo and 1.41x on FLUX.1-dev without compromising generation quality. Furthermore, we show that Chipmunk can be stacked on top of full step caching, achieving a 3.72x speedup on HunyuanVideo, a 2.67x speedup on WAN2.1, and a 2.25x speedup on FLUX.1-dev with minimal quality impact.","authors":["Austin Silveria","Soham V. Govande","Daniel Y. Fu"],"url":"https://arxiv.org/abs/2506.03275"}
{"created":"2025-06-05","title":"FailureSensorIQ: A Multi-Choice QA Dataset for Understanding Sensor Relationships and Failure Modes","abstract":"We introduce FailureSensorIQ, a novel Multi-Choice Question-Answering (MCQA) benchmarking system designed to assess the ability of Large Language Models (LLMs) to reason and understand complex, domain-specific scenarios in Industry 4.0. Unlike traditional QA benchmarks, our system focuses on multiple aspects of reasoning through failure modes, sensor data, and the relationships between them across various industrial assets. Through this work, we envision a paradigm shift where modeling decisions are not only data-driven using statistical tools like correlation analysis and significance tests, but also domain-driven by specialized LLMs which can reason about the key contributors and useful patterns that can be captured with feature engineering. We evaluate the Industrial knowledge of over a dozen LLMs-including GPT-4, Llama, and Mistral-on FailureSensorIQ from different lens using Perturbation-Uncertainty-Complexity analysis, Expert Evaluation study, Asset-Specific Knowledge Gap analysis, ReAct agent using external knowledge-bases. Even though closed-source models with strong reasoning capabilities approach expert-level performance, the comprehensive benchmark reveals a significant drop in performance that is fragile to perturbations, distractions, and inherent knowledge gaps in the models. We also provide a real-world case study of how LLMs can drive the modeling decisions on 3 different failure prediction datasets related to various assets. We release: (a) expert-curated MCQA for various industrial assets, (b) FailureSensorIQ benchmark and Hugging Face leaderboard based on MCQA built from non-textual data found in ISO documents, and (c) LLMFeatureSelector, an LLM-based feature selection scikit-learn pipeline. The software is available at https://github.com/IBM/FailureSensorIQ.","authors":["Christodoulos Constantinides","Dhaval Patel","Shuxin Lin","Claudio Guerrero","Sunil Dagajirao Patil","Jayant Kalagnanam"],"url":"https://arxiv.org/abs/2506.03278"}
{"created":"2025-06-05","title":"Empirical Evaluation of Generalizable Automated Program Repair with Large Language Models","abstract":"Automated Program Repair (APR) proposes bug fixes to aid developers in maintaining software. The state of the art in this domain focuses on using LLMs, leveraging their strong capabilities to comprehend specifications in natural language and to generate program code. Recent works have shown that LLMs can be used to generate repairs. However, despite the APR community's research achievements and several industry deployments in the last decade, APR still lacks the capabilities to generalize broadly. In this work, we present an intensive empirical evaluation of LLMs for generating patches. We evaluate a diverse set of 13 recent models, including open ones (e.g., Llama 3.3, Qwen 2.5 Coder, and DeepSeek R1 (dist.)) and closed ones (e.g., o3-mini, GPT-4o, Claude 3.7 Sonnet, Gemini 2.0 Flash). In particular, we explore language-agnostic repairs by utilizing benchmarks for Java (e.g., Defects4J), JavaScript (e.g., BugsJS), Python (e.g., BugsInPy), and PHP (e.g., BugsPHP). Besides the generalization between different languages and levels of patch complexity, we also investigate the effects of fault localization (FL) as a preprocessing step and compare the progress for open vs closed models. Our evaluation represents a snapshot of the current repair capabilities of the latest LLMs. Key results include: (1) Different LLMs tend to perform best for different languages, which makes it hard to develop cross-platform repair techniques with single LLMs. (2) The combinations of models add value with respect to uniquely fixed bugs, so a committee of expert models should be considered. (3) Under realistic assumptions of imperfect FL, we observe significant drops in accuracy from the usual practice of using perfect FL. Our findings and insights will help both researchers and practitioners develop reliable and generalizable APR techniques and evaluate them in realistic and fair environments.","authors":["Viola Campos","Ridwan Shariffdeen","Adrian Ulges","Yannic Noller"],"url":"https://arxiv.org/abs/2506.03283"}
{"created":"2025-06-05","title":"Learning Optical Flow Field via Neural Ordinary Differential Equation","abstract":"Recent works on optical flow estimation use neural networks to predict the flow field that maps positions of one image to positions of the other. These networks consist of a feature extractor, a correlation volume, and finally several refinement steps. These refinement steps mimic the iterative refinements performed by classical optimization algorithms and are usually implemented by neural layers (e.g., GRU) which are recurrently executed for a fixed and pre-determined number of steps. However, relying on a fixed number of steps may result in suboptimal performance because it is not tailored to the input data. In this paper, we introduce a novel approach for predicting the derivative of the flow using a continuous model, namely neural ordinary differential equations (ODE). One key advantage of this approach is its capacity to model an equilibrium process, dynamically adjusting the number of compute steps based on the data at hand. By following a particular neural architecture, ODE solver, and associated hyperparameters, our proposed model can replicate the exact same updates as recurrent cells used in existing works, offering greater generality. Through extensive experimental analysis on optical flow benchmarks, we demonstrate that our approach achieves an impressive improvement over baseline and existing models, all while requiring only a single refinement step.","authors":["Leyla Mirvakhabova","Hong Cai","Jisoo Jeong","Hanno Ackermann","Farhad Zanjani","Fatih Porikli"],"url":"https://arxiv.org/abs/2506.03290"}
{"created":"2025-06-05","title":"An Active Flux method for the Euler equations based on the exact acoustic evolution operator","abstract":"A new Active Flux method for the multi-dimensional Euler equations is based on an additive operator splitting into acoustics and advection. The acoustic operator is solved in a locally linearized manner by using the exact evolution operator. The nonlinear advection operator is solved at third order accuracy using a new approximate evolution operator. To simplify the splitting, the new method uses primitive variables for the point values and for the reconstruction. In order to handle discontinuous solutions, a blended bound preserving limiting is used, that combines a priori and a posteriori approaches. The resulting method is able to resolve multi-dimensional Riemann problems as well as low Mach number flow, and has a large domain of stability.","authors":["Wasilij Barsukow"],"url":"https://arxiv.org/abs/2506.03291"}
{"created":"2025-06-05","title":"HyperSteer: Activation Steering at Scale with Hypernetworks","abstract":"Steering language models (LMs) by modifying internal activations is a popular approach for controlling text generation. Unsupervised dictionary learning methods, e.g., sparse autoencoders, can be scaled to produce many steering vectors, but lack guarantees on the individual efficacy of each vector and control over the coverage of relevant steering tasks. In contrast, supervised methods for constructing steering vectors are targeted and effective, but require more data collection and training for each additional steering vector produced. In this work, we introduce HyperSteer, a family of hypernetwork-based architectures which are trained end-to-end to generate steering vectors conditioned on the natural language steering prompts and the internals of the steered LM. In our evaluations, we show that scaling HyperSteer with thousands of steering prompts exceeds the performance of state-of-the-art activation steering methods, even on steering prompts never seen during training. Moreover, HyperSteer performs on par with steering-via-prompting.","authors":["Jiuding Sun","Sidharth Baskaran","Zhengxuan Wu","Michael Sklar","Christopher Potts","Atticus Geiger"],"url":"https://arxiv.org/abs/2506.03292"}
{"created":"2025-06-05","title":"Prefix-free parsing for merging big BWTs","abstract":"When building Burrows-Wheeler Transforms (BWTs) of truly huge datasets, prefix-free parsing (PFP) can use an unreasonable amount of memory. In this paper we show how if a dataset can be broken down into small datasets that are not very similar to each other -- such as collections of many copies of genomes of each of several species, or collections of many copies of each of the human chromosomes -- then we can drastically reduce PFP's memory footprint by building the BWTs of the small datasets and then merging them into the BWT of the whole dataset.","authors":["Diego Diaz-Dominguez","Travis Gagie","Veronica Guerrini","Ben Langmead","Zsuzsanna Liptak","Giovanni Manzini","Francesco Masillo","Vikram Shivakumar"],"url":"https://arxiv.org/abs/2506.03294"}
{"created":"2025-06-05","title":"Unleashing the Reasoning Potential of Pre-trained LLMs by Critique Fine-Tuning on One Problem","abstract":"We have witnessed that strong LLMs like Qwen-Math, MiMo, and Phi-4 possess immense reasoning potential inherited from the pre-training stage. With reinforcement learning (RL), these models can improve dramatically on reasoning tasks. Recent studies have shown that even RL on a single problem can unleash these models' reasoning capabilities. However, RL is not only expensive but also unstable. Even one-shot RL requires hundreds of GPU hours. This raises a critical question: Is there a more efficient way to unleash the reasoning potential of these powerful base LLMs? In this work, we demonstrate that Critique Fine-Tuning (CFT) on only one problem can effectively unleash the reasoning potential of LLMs. Our method constructs critique data by collecting diverse model-generated solutions to a single problem and using teacher LLMs to provide detailed critiques. We fine-tune Qwen and Llama family models, ranging from 1.5B to 14B parameters, on the CFT data and observe significant performance gains across diverse reasoning tasks. For example, with just 5 GPU hours of training, Qwen-Math-7B-CFT show an average improvement of 15% on six math benchmarks and 16% on three logic reasoning benchmarks. These results are comparable to or even surpass the results from RL with 20x less compute. Ablation studies reveal the robustness of one-shot CFT across different prompt problems. These results highlight one-shot CFT as a simple, general, and compute-efficient approach to unleashing the reasoning capabilities of modern LLMs.","authors":["Yubo Wang","Ping Nie","Kai Zou","Lijun Wu","Wenhu Chen"],"url":"https://arxiv.org/abs/2506.03295"}
{"created":"2025-06-05","title":"Parallel CPU-GPU Execution for LLM Inference on Constrained GPUs","abstract":"Deploying large language models (LLMs) for online inference is often constrained by limited GPU memory, particularly due to the growing KV cache during auto-regressive decoding. Hybrid GPU-CPU execution has emerged as a promising solution by offloading KV cache management and parts of attention computation to the CPU. However, a key bottleneck remains: existing schedulers fail to effectively overlap CPU-offloaded tasks with GPU execution during the latency-critical, bandwidth-bound decode phase. This particularly penalizes real-time, decode-heavy applications (e.g., chat, Chain-of-Thought reasoning) which are currently underserved by existing systems, especially under memory pressure typical of edge or low-cost deployments.","authors":["Jiakun Fan","Yanglin Zhang","Xiangchen Li","Dimitrios S. Nikolopoulos"],"url":"https://arxiv.org/abs/2506.03296"}
{"created":"2025-06-05","title":"Dynamics and Control of Vision-Aided Multi-UAV-tethered Netted System Capturing Non-Cooperative Target","abstract":"As the number of Unmanned Aerial Vehicles (UAVs) operating in low-altitude airspace continues to increase, non-cooperative targets pose growing challenges to low-altitude operations. To address this issue, this paper proposes a multi-UAV-tethered netted system as a non-lethal solution for capturing non-cooperative targets. To validate the proposed system, we develop mySim, a multibody dynamics-based UAV simulation environment that integrates high-precision physics modeling, vision-based motion tracking, and reinforcement learning-driven control strategies. In mySim, the spring-damper model is employed to simulate the dynamic behavior of the tethered net, while the dynamics of the entire system is modeled using multibody dynamics (MBD) to achieve accurate representations of system interactions. The motion of the UAVs and the target are estimated using VINS-MONO and DETR, and the system autonomously executes the capture strategy through MAPPO. Simulation results demonstrate that mySim accurately simulates dynamics and control of the system, successfully enabling the multi-UAV-tethered netted system to capture both non-propelled and maneuvering non-cooperative targets. By providing a high-precision simulation platform that integrates dynamics modeling with perception and learning-based control, mySim enables efficient testing and optimization of UAV-based control policies before real-world deployment. This approach offers significant advantages for simulating complex UAVs coordination tasks and has the potential to be applied to the design of other UAV-based systems.","authors":["Runhan Liu","Hui Ren","Wei Fan"],"url":"https://arxiv.org/abs/2506.03297"}
{"created":"2025-06-05","title":"Online Detection and Mitigation of Robust Zero Dynamics Anomaly Behavior in MIMO Nonlinear Control Systems","abstract":"This paper presents a methodology to detect robust zero dynamics anomaly behavior and mitigate the impacts in general multi-input multi-output (MIMO) nonlinear systems. The proposed method guarantees the resiliency and stability of the closed-loop system without relying on an accurate dynamical model. The presented method operates in two stages. First, it measures the difference between the system input and that of the model as a residual signal to detect the anomaly behavior. After detecting the attack, a recovery signal is generated to restore the system to its nominal condition. In this stage, a neural network model is used to estimate the anomaly signal and recover the closed-loop system. The weights of the neural network model are updated online using adaptation rules without needing prior data for training. The accuracy and performance of the proposed methods are verified by simulating various scenarios on a fourtank system.","authors":["Kosar Behnia","H. A. Talebi","Farzaneh Abdollahi"],"url":"https://arxiv.org/abs/2506.03298"}
{"created":"2025-06-05","title":"From Instructions to ODRL Usage Policies: An Ontology Guided Approach","abstract":"This study presents an approach that uses large language models such as GPT-4 to generate usage policies in the W3C Open Digital Rights Language ODRL automatically from natural language instructions. Our approach uses the ODRL ontology and its documentation as a central part of the prompt. Our research hypothesis is that a curated version of existing ontology documentation will better guide policy generation. We present various heuristics for adapting the ODRL ontology and its documentation to guide an end-to-end KG construction process. We evaluate our approach in the context of dataspaces, i.e., distributed infrastructures for trustworthy data exchange between multiple participating organizations for the cultural domain. We created a benchmark consisting of 12 use cases of varying complexity. Our evaluation shows excellent results with up to 91.95% accuracy in the resulting knowledge graph.","authors":["Daham M. Mustafa","Abhishek Nadgeri","Diego Collarana","Benedikt T. Arnold","Christoph Quix","Christoph Lange","Stefan Decker"],"url":"https://arxiv.org/abs/2506.03301"}
{"created":"2025-06-05","title":"Multi-Exit Kolmogorov-Arnold Networks: enhancing accuracy and parsimony","abstract":"Kolmogorov-Arnold Networks (KANs) uniquely combine high accuracy with interpretability, making them valuable for scientific modeling. However, it is unclear a priori how deep a network needs to be for any given task, and deeper KANs can be difficult to optimize. Here we introduce multi-exit KANs, where each layer includes its own prediction branch, enabling the network to make accurate predictions at multiple depths simultaneously. This architecture provides deep supervision that improves training while discovering the right level of model complexity for each task. Multi-exit KANs consistently outperform standard, single-exit versions on synthetic functions, dynamical systems, and real-world datasets. Remarkably, the best predictions often come from earlier, simpler exits, revealing that these networks naturally identify smaller, more parsimonious and interpretable models without sacrificing accuracy. To automate this discovery, we develop a differentiable \"learning to exit\" algorithm that balances contributions from exits during training. Our approach offers scientists a practical way to achieve both high performance and interpretability, addressing a fundamental challenge in machine learning for scientific discovery.","authors":["James Bagrow","Josh Bongard"],"url":"https://arxiv.org/abs/2506.03302"}
{"created":"2025-06-05","title":"Hopscotch: Discovering and Skipping Redundancies in Language Models","abstract":"Modern causal language models stack many attention blocks to improve performance, but not all blocks are necessary for every task. We propose Hopscotch, a simple yet effective method that identifies and skips attention blocks with least contributions to a task and adapts to preserve output quality. Hopscotch jointly optimizes which blocks to skip and how to scale the outputs of the remaining layers. By introducing lightweight, trainable scaling parameters to attention and MLP blocks, it mitigates distribution shifts in hidden states caused by removing attention blocks. Hopscotch does not modify model weights or require access to pretraining or instruction-tuning data, and is compatible with existing model compression techniques. When applied to $\\texttt{Llama-3.1-8B}$ and $\\texttt{Qwen2.5-7B}$, Hopscotch achieves less than a 2% drop in performance even after skipping four attention blocks.","authors":["Mustafa Eyceoz","Nikhil Shivakumar Nayak","Hao Wang","Ligong Han","Akash Srivastava"],"url":"https://arxiv.org/abs/2506.03303"}
{"created":"2025-06-05","title":"Budgeted Online Active Learning with Expert Advice and Episodic Priors","abstract":"This paper introduces a novel approach to budgeted online active learning from finite-horizon data streams with extremely limited labeling budgets. In agricultural applications, such streams might include daily weather data over a growing season, and labels require costly measurements of weather-dependent plant characteristics. Our method integrates two key sources of prior information: a collection of preexisting expert predictors and episodic behavioral knowledge of the experts based on unlabeled data streams. Unlike previous research on online active learning with experts, our work simultaneously considers query budgets, finite horizons, and episodic knowledge, enabling effective learning in applications with severely limited labeling capacity. We demonstrate the utility of our approach through experiments on various prediction problems derived from both a realistic agricultural crop simulator and real-world data from multiple grape cultivars. The results show that our method significantly outperforms baseline expert predictions, uniform query selection, and existing approaches that consider budgets and limited horizons but neglect episodic knowledge, even under highly constrained labeling budgets.","authors":["Kristen Goebel","William Solow","Paola Pesantez-Cabrera","Markus Keller","Alan Fern"],"url":"https://arxiv.org/abs/2506.03307"}
{"created":"2025-06-05","title":"Hermes: High-Performance Homomorphically Encrypted Vector Databases","abstract":"Fully Homomorphic Encryption (FHE) has long promised the ability to compute over encrypted data without revealing sensitive contents -- a foundational goal for secure cloud analytics. Yet despite decades of cryptographic advances, practical integration of FHE into real-world relational databases remains elusive. This paper presents \\textbf{Hermes}, the first system to enable FHE-native vector query processing inside a standard SQL engine. By leveraging the multi-slot capabilities of modern schemes, Hermes introduces a novel data model that packs multiple records per ciphertext and embeds encrypted auxiliary statistics (e.g., local sums) to support in-place updates and aggregation. To reconcile ciphertext immutability with record-level mutability, we develop new homomorphic algorithms based on slot masking, shifting, and rewriting. Hermes is implemented as native C++ loadable functions in MySQL using OpenFHE v1.2.4, comprising over 3,500 lines of code. Experiments on real-world datasets show up to 1{,}600$\\times$ throughput gain in encryption and over 30$\\times$ speedup in insertion compared to per-tuple baselines. Hermes brings FHE from cryptographic promise to practical reality -- realizing a long-standing vision at the intersection of databases and secure computation.","authors":["Dongfang Zhao"],"url":"https://arxiv.org/abs/2506.03308"}
{"created":"2025-06-05","title":"Position Auctions in AI-Generated Content","abstract":"We consider an extension to the classic position auctions in which sponsored creatives can be added within AI generated content rather than shown in predefined slots. New challenges arise from the natural requirement that sponsored creatives should smoothly fit into the context. With the help of advanced LLM technologies, it becomes viable to accurately estimate the benefits of adding each individual sponsored creatives into each potential positions within the AI generated content by properly taking the context into account. Therefore, we assume one click-through rate estimation for each position-creative pair, rather than one uniform estimation for each sponsored creative across all positions in classic settings. As a result, the underlying optimization becomes a general matching problem, thus the substitution effects should be treated more carefully compared to standard position auction settings, where the slots are independent with each other.","authors":["Santiago Balseiro","Kshipra Bhawalkar","Yuan Deng","Zhe Feng","Jieming Mao","Aranyak Mehta","Vahab Mirrokni","Renato Paes Leme","Di Wang","Song Zuo"],"url":"https://arxiv.org/abs/2506.03309"}
{"created":"2025-06-05","title":"The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing","abstract":"Recent studies comparing AI-generated and human-authored literary texts have produced conflicting results: some suggest AI already surpasses human quality, while others argue it still falls short. We start from the hypothesis that such divergences can be largely explained by genuine differences in how readers interpret and value literature, rather than by an intrinsic quality of the texts evaluated. Using five public datasets (1,471 stories, 101 annotators including critics, students, and lay readers), we (i) extract 17 reference-less textual features (e.g., coherence, emotional variance, average sentence length...); (ii) model individual reader preferences, deriving feature importance vectors that reflect their textual priorities; and (iii) analyze these vectors in a shared \"preference space\". Reader vectors cluster into two profiles: 'surface-focused readers' (mainly non-experts), who prioritize readability and textual richness; and 'holistic readers' (mainly experts), who value thematic development, rhetorical variety, and sentiment dynamics. Our results quantitatively explain how measurements of literary quality are a function of how text features align with each reader's preferences. These findings advocate for reader-sensitive evaluation frameworks in the field of creative text generation.","authors":["Guillermo Marco","Julio Gonzalo","V\\'ictor Fresno"],"url":"https://arxiv.org/abs/2506.03310"}
{"created":"2025-06-05","title":"Demystifying Tubal Tensor Algebra","abstract":"Developed in a series of seminal papers in the early 2010s, the tubal tensor framework provides a clean and effective algebraic setting for tensor computations, supporting matrix-mimetic features such as a tensor Singular Value Decomposition and Eckart-Young-like optimality results. It has proven to be a powerful tool for analyzing inherently multilinear data arising in hyperspectral imaging, medical imaging, neural dynamics, scientific simulations, and more. At the heart of tubal tensor algebra lies a special tensor-tensor product: originally the t-product, later generalized into a full family of products via the $\\star_M$-product. Though initially defined through the multiplication of a block-circulant unfolding of one tensor by a matricization of another, it was soon observed that the t-product can be interpreted as standard matrix multiplication where the scalars are tubes-i.e., real vectors twisted ``inward.'' Yet, a fundamental question remains: why is this the ``right'' way to define a tensor-tensor product in the tubal setting? In this paper, we show that the t-product and its $\\star_M$ generalization arise naturally when viewing third-order tensors as matrices of tubes, together with a small set of desired algebraic properties. Furthermore, we prove that the $\\star_M$-product is, in fact, the only way to define a tubal product satisfying these properties. Thus, while partly expository in nature - aimed at presenting the foundations of tubal tensor algebra in a cohesive and accessible way - this paper also addresses theoretical gaps in the tubal tensor framework, proves new results, and provides justification for the tubal tensor framework central constructions, thereby shedding new light on it.","authors":["Haim Avron","Uria Mor"],"url":"https://arxiv.org/abs/2506.03311"}
{"created":"2025-06-05","title":"Cross-Platform Violence Detection on Social Media: A Dataset and Analysis","abstract":"Violent threats remain a significant problem across social media platforms. Useful, high-quality data facilitates research into the understanding and detection of malicious content, including violence. In this paper, we introduce a cross-platform dataset of 30,000 posts hand-coded for violent threats and sub-types of violence, including political and sexual violence. To evaluate the signal present in this dataset, we perform a machine learning analysis with an existing dataset of violent comments from YouTube. We find that, despite originating from different platforms and using different coding criteria, we achieve high classification accuracy both by training on one dataset and testing on the other, and in a merged dataset condition. These results have implications for content-classification strategies and for understanding violent content across social media.","authors":["Celia Chen","Scotty Beland","Ingo Burghardt","Jill Byczek","William J. Conway","Eric Cotugno","Sadaf Davre","Megan Fletcher","Rajesh Kumar Gnanasekaran","Kristin Hamilton","Marilyn Harbert","Jordan Heustis","Tanaya Jha","Emily Klein","Hayden Kramer","Alex Leitch","Jessica Perkins","Casi Sherman","Celia Sterrn","Logan Stevens","Rebecca Zarrella","Jennifer Golbeck"],"url":"https://arxiv.org/abs/2506.03312"}
{"created":"2025-06-05","title":"Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum as Fallback","abstract":"We study how linear orders can be employed to realise choice functions for which the set of potential choices is restricted, i.e., the possible choice is not possible among the full powerset of all alternatives. In such restricted settings, constructing a choice function via a relation on the alternatives is not always possible. However, we show that one can always construct a choice function via a linear order on sets of alternatives, even when a fallback value is encoded as the minimal element in the linear order. The axiomatics of such choice functions are presented for the general case and the case of union-closed input restrictions. Restricted choice structures have applications in knowledge representation and reasoning, and here we discuss their applications for theory change and abstract argumentation.","authors":["Kai Sauerwald","Kenneth Skiba","Eduardo Ferm\\'e","Thomas Meyer"],"url":"https://arxiv.org/abs/2506.03315"}
{"created":"2025-06-05","title":"The Future of Continual Learning in the Era of Foundation Models: Three Key Directions","abstract":"Continual learning--the ability to acquire, retain, and refine knowledge over time--has always been fundamental to intelligence, both human and artificial. Historically, different AI paradigms have acknowledged this need, albeit with varying priorities: early expert and production systems focused on incremental knowledge consolidation, while reinforcement learning emphasised dynamic adaptation. With the rise of deep learning, deep continual learning has primarily focused on learning robust and reusable representations over time to solve sequences of increasingly complex tasks. However, the emergence of Large Language Models (LLMs) and foundation models has raised the question: Do we still need continual learning when centralised, monolithic models can tackle diverse tasks with access to internet-scale knowledge? We argue that continual learning remains essential for three key reasons: (i) continual pre-training is still necessary to ensure foundation models remain up to date, mitigating knowledge staleness and distribution shifts while integrating new information; (ii) continual fine-tuning enables models to specialise and personalise, adapting to domain-specific tasks, user preferences, and real-world constraints without full retraining, avoiding the need for computationally expensive long context-windows; (iii) continual compositionality offers a scalable and modular approach to intelligence, enabling the orchestration of foundation models and agents to be dynamically composed, recombined, and adapted. While continual pre-training and fine-tuning are explored as niche research directions, we argue it is continual compositionality that will mark the rebirth of continual learning. The future of AI will not be defined by a single static model but by an ecosystem of continually evolving and interacting models, making continual learning more relevant than ever.","authors":["Jack Bell","Luigi Quarantiello","Eric Nuertey Coleman","Lanpei Li","Malio Li","Mauro Madeddu","Elia Piccoli","Vincenzo Lomonaco"],"url":"https://arxiv.org/abs/2506.03320"}
{"created":"2025-06-05","title":"Enhancing Automatic PT Tagging for MEDLINE Citations Using Transformer-Based Models","abstract":"We investigated the feasibility of predicting Medical Subject Headings (MeSH) Publication Types (PTs) from MEDLINE citation metadata using pre-trained Transformer-based models BERT and DistilBERT. This study addresses limitations in the current automated indexing process, which relies on legacy NLP algorithms. We evaluated monolithic multi-label classifiers and binary classifier ensembles to enhance the retrieval of biomedical literature. Results demonstrate the potential of Transformer models to significantly improve PT tagging accuracy, paving the way for scalable, efficient biomedical indexing.","authors":["Victor H. Cid","James Mork"],"url":"https://arxiv.org/abs/2506.03321"}
{"created":"2025-06-05","title":"Optimization of Epsilon-Greedy Exploration","abstract":"Modern recommendation systems rely on exploration to learn user preferences for new items, typically implementing uniform exploration policies (e.g., epsilon-greedy) due to their simplicity and compatibility with machine learning (ML) personalization models. Within these systems, a crucial consideration is the rate of exploration - what fraction of user traffic should receive random item recommendations and how this should evolve over time. While various heuristics exist for navigating the resulting exploration-exploitation tradeoff, selecting optimal exploration rates is complicated by practical constraints including batched updates, time-varying user traffic, short time horizons, and minimum exploration requirements. In this work, we propose a principled framework for determining the exploration schedule based on directly minimizing Bayesian regret through stochastic gradient descent (SGD), allowing for dynamic exploration rate adjustment via Model-Predictive Control (MPC). Through extensive experiments with recommendation datasets, we demonstrate that variations in the batch size across periods significantly influence the optimal exploration strategy. Our optimization methods automatically calibrate exploration to the specific problem setting, consistently matching or outperforming the best heuristic for each setting.","authors":["Ethan Che","Hakan Ceylan","James McInerney","Nathan Kallus"],"url":"https://arxiv.org/abs/2506.03324"}
{"created":"2025-06-05","title":"Relay Selection and User Equipment Admission in Resource-Efficient NextG Sidelink Communications","abstract":"5G/6G sidelink communications addresses the challenge of connecting outer UEs, which are unable to directly access a base station (gNodeB), through inner UEs that act as relays to connect to the gNodeB. The key performance indicators include the achievable rates, the number of outer UEs that can connect to a gNodeB, and the latency experienced by outer UEs in establishing connections. We consider problem of determining the assignment of outer UEs to inner UEs based on the channel, interference, and traffic characteristics. We formulate an optimization problem to maximize a weighted sum rate of UEs, where weights can represent priority, waiting time, and queue length. This optimization accommodates constraints related to channel and interference characteristics that influence the rates at which links can successfully carry assigned traffic. While an exhaustive search can establish an upper bound on achievable rates by this non-convex optimization problem, it becomes impractical for larger number of outer UEs due to scalability issues related to high computational complexity. To address this, we present a greedy algorithm that incrementally selects links to maximize the sum rate, considering already activated links. This algorithm, although effective in achieving high sum rates, may inadvertently overlook some UEs, raising concerns about fairness. To mitigate this, we introduce a fairness-oriented algorithm that adjusts weights based on waiting time or queue length, ensuring that UEs with initially favorable conditions do not unduly disadvantage others over time. We show that this strategy not only improves the average admission ratio of UEs but also ensures a more equitable distribution of service among them, thereby providing a balanced and fair solution to sidelink communications.","authors":["Yalin E. Sagduyu","Tugba Erpek","Sastry Kompella","Kemal Davaslioglu"],"url":"https://arxiv.org/abs/2506.03328"}
{"created":"2025-06-05","title":"Optimization of Functional Materials Design with Optimal Initial Data in Surrogate-Based Active Learning","abstract":"The optimization of functional materials is important to enhance their properties, but their complex geometries pose great challenges to optimization. Data-driven algorithms efficiently navigate such complex design spaces by learning relationships between material structures and performance metrics to discover high-performance functional materials. Surrogate-based active learning, continually improving its surrogate model by iteratively including high-quality data points, has emerged as a cost-effective data-driven approach. Furthermore, it can be coupled with quantum computing to enhance optimization processes, especially when paired with a special form of surrogate model ($i.e.$, quadratic unconstrained binary optimization), formulated by factorization machine. However, current practices often overlook the variability in design space sizes when determining the initial data size for optimization. In this work, we investigate the optimal initial data sizes required for efficient convergence across various design space sizes. By employing averaged piecewise linear regression, we identify initiation points where convergence begins, highlighting the crucial role of employing adequate initial data in achieving efficient optimization. These results contribute to the efficient optimization of functional materials by ensuring faster convergence and reducing computational costs in surrogate-based active learning.","authors":["Seongmin Kim","In-Saeng Suh"],"url":"https://arxiv.org/abs/2506.03329"}
{"created":"2025-06-05","title":"Helpful Agent Meets Deceptive Judge: Understanding Vulnerabilities in Agentic Workflows","abstract":"Agentic workflows -- where multiple large language model (LLM) instances interact to solve tasks -- are increasingly built on feedback mechanisms, where one model evaluates and critiques another. Despite the promise of feedback-driven improvement, the stability of agentic workflows rests on the reliability of the judge. However, judges may hallucinate information, exhibit bias, or act adversarially -- introducing critical vulnerabilities into the workflow. In this work, we present a systematic analysis of agentic workflows under deceptive or misleading feedback. We introduce a two-dimensional framework for analyzing judge behavior, along axes of intent (from constructive to malicious) and knowledge (from parametric-only to retrieval-augmented systems). Using this taxonomy, we construct a suite of judge behaviors and develop WAFER-QA, a new benchmark with critiques grounded in retrieved web evidence to evaluate robustness of agentic workflows against factually supported adversarial feedback. We reveal that even strongest agents are vulnerable to persuasive yet flawed critiques -- often switching correct answers after a single round of misleading feedback. Taking a step further, we study how model predictions evolve over multiple rounds of interaction, revealing distinct behavioral patterns between reasoning and non-reasoning models. Our findings highlight fundamental vulnerabilities in feedback-based workflows and offer guidance for building more robust agentic systems.","authors":["Yifei Ming","Zixuan Ke","Xuan-Phi Nguyen","Jiayu Wang","Shafiq Joty"],"url":"https://arxiv.org/abs/2506.03332"}
{"created":"2025-06-05","title":"A Differential Perspective on Distributional Reinforcement Learning","abstract":"To date, distributional reinforcement learning (distributional RL) methods have exclusively focused on the discounted setting, where an agent aims to optimize a potentially-discounted sum of rewards over time. In this work, we extend distributional RL to the average-reward setting, where an agent aims to optimize the reward received per time-step. In particular, we utilize a quantile-based approach to develop the first set of algorithms that can successfully learn and/or optimize the long-run per-step reward distribution, as well as the differential return distribution of an average-reward MDP. We derive proven-convergent tabular algorithms for both prediction and control, as well as a broader family of algorithms that have appealing scaling properties. Empirically, we find that these algorithms consistently yield competitive performance when compared to their non-distributional equivalents, while also capturing rich information about the long-run reward and return distributions.","authors":["Juan Sebastian Rojas","Chi-Guhn Lee"],"url":"https://arxiv.org/abs/2506.03333"}
{"created":"2025-06-05","title":"SportMamba: Adaptive Non-Linear Multi-Object Tracking with State Space Models for Team Sports","abstract":"Multi-object tracking (MOT) in team sports is particularly challenging due to the fast-paced motion and frequent occlusions resulting in motion blur and identity switches, respectively. Predicting player positions in such scenarios is particularly difficult due to the observed highly non-linear motion patterns. Current methods are heavily reliant on object detection and appearance-based tracking, which struggle to perform in complex team sports scenarios, where appearance cues are ambiguous and motion patterns do not necessarily follow a linear pattern. To address these challenges, we introduce SportMamba, an adaptive hybrid MOT technique specifically designed for tracking in dynamic team sports. The technical contribution of SportMamba is twofold. First, we introduce a mamba-attention mechanism that models non-linear motion by implicitly focusing on relevant embedding dependencies. Second, we propose a height-adaptive spatial association metric to reduce ID switches caused by partial occlusions by accounting for scale variations due to depth changes. Additionally, we extend the detection search space with adaptive buffers to improve associations in fast-motion scenarios. Our proposed technique, SportMamba, demonstrates state-of-the-art performance on various metrics in the SportsMOT dataset, which is characterized by complex motion and severe occlusion. Furthermore, we demonstrate its generalization capability through zero-shot transfer to VIP-HTD, an ice hockey dataset.","authors":["Dheeraj Khanna","Jerrin Bright","Yuhao Chen","John S. Zelek"],"url":"https://arxiv.org/abs/2506.03335"}
{"created":"2025-06-05","title":"Mitigating Non-IID Drift in Zeroth-Order Federated LLM Fine-Tuning with Transferable Sparsity","abstract":"Federated Learning enables collaborative fine-tuning of Large Language Models (LLMs) across decentralized Non-Independent and Identically Distributed (Non-IID) clients, but such models' massive parameter sizes lead to significant memory and communication challenges. This work introduces Meerkat, a sparse zeroth-order optimization (ZO) method designed for federated LLM fine-tuning. By limiting fine-tuning to a transferable, static, extremely sparse subset of parameters, Meerkat achieves remarkable communication efficiency, enabling cost-effective high-frequency synchronization. With theoretical analysis and experiments, we show that this high-frequency communication effectively mitigates Non-IID data challenges and leads to superior performance compared to full-parameter ZO. Furthermore, experiment results show that Meerkat outperforms existing sparsity baselines with better performance at the same communication frequency. To further handle Non-IID drift, Meerkat leverages traceable local updates and forms a virtual path for each client. This virtual path mechanism reveals the GradIP phenomenon: the inner products between LLM pre-training gradients maintained by server and client gradients estimated via ZO converges for extreme Non-IID clients but oscillates for IID ones. This distinct behavior provides a signal for identifying clients with extreme data heterogeneity. Using this signal, Meerkat-vp is proposed to analyze GradIP trajectories to identify extreme Non-IID clients and applies early stopping to enhance aggregated model quality. Experiments confirm that Meerkat and Meerkat-vp significantly improve the efficiency and effectiveness of ZO federated LLM fine-tuning.","authors":["Yide Ran","Wentao Guo","Jingwei Sun","Yanzhou Pan","Xiaodong Yu","Hao Wang","Jianwen Xie","Yiran Chen","Denghui Zhang","Zhaozhuo Xu"],"url":"https://arxiv.org/abs/2506.03337"}
{"created":"2025-06-05","title":"Seeing the Arrow of Time in Large Multimodal Models","abstract":"The Arrow of Time (AoT)-time's irreversible flow shaping physical events-is fundamental to video comprehension, yet remains a significant challenge for modern large multimodal models (LMMs). Current LMMs struggle to perceive and utilize temporal directionality in video when responding to language queries, obstructing deeper temporal understanding. We tackle this deficiency by first providing a critical analysis of existing benchmarks and models. We then introduce ArrowRL, a reinforcement learning (RL)-based training strategy with an innovative reverse reward that instills AoT awareness by encouraging divergent video interpretations between forward and reversed visual frames. For rigorous evaluation, we additionally develop AoTBench, a new multi-faceted benchmark probing temporally challenging questions. Experiments show ArrowRL greatly advances temporal perception: it not only achieves substantial improvements on our challenging AoTBench but also demonstrably boosts performance on standard video question answering (VQA) benchmarks (with peak accuracy gains reaching over 20% and 10% respectively). This validates ArrowRL's effectiveness and highlights the critical need for dedicated AoT understanding in LMMs.","authors":["Zihui Xue","Mi Luo","Kristen Grauman"],"url":"https://arxiv.org/abs/2506.03340"}
{"created":"2025-06-05","title":"Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers","abstract":"Controlling defects in semiconductor processes is important for maintaining yield, improving production cost, and preventing time-dependent critical component failures. Electron beam-based imaging has been used as a tool to survey wafers in the line and inspect for defects. However, manual classification of images for these nano-scale defects is limited by time, labor constraints, and human biases. In recent years, deep learning computer vision algorithms have shown to be effective solutions for image-based inspection applications in industry. This work proposes application of vision transformer (ViT) neural networks for automatic defect classification (ADC) of scanning electron microscope (SEM) images of wafer defects. We evaluated our proposed methods on 300mm wafer semiconductor defect data from our fab in IBM Albany. We studied 11 defect types from over 7400 total images and investigated the potential of transfer learning of DinoV2 and semi-supervised learning for improved classification accuracy and efficient computation. We were able to achieve classification accuracies of over 90% with less than 15 images per defect class. Our work demonstrates the potential to apply the proposed framework for a platform agnostic in-house classification tool with faster turnaround time and flexibility.","authors":["Chien-Fu (Frank)","Huang","Katherine Sieg","Leonid Karlinksy","Nash Flores","Rebekah Sheraw","Xin Zhang"],"url":"https://arxiv.org/abs/2506.03345"}
{"created":"2025-06-05","title":"Adversarial Attacks on Robotic Vision Language Action Models","abstract":"The emergence of vision-language-action models (VLAs) for end-to-end control is reshaping the field of robotics by enabling the fusion of multimodal sensory inputs at the billion-parameter scale. The capabilities of VLAs stem primarily from their architectures, which are often based on frontier large language models (LLMs). However, LLMs are known to be susceptible to adversarial misuse, and given the significant physical risks inherent to robotics, questions remain regarding the extent to which VLAs inherit these vulnerabilities. Motivated by these concerns, in this work we initiate the study of adversarial attacks on VLA-controlled robots. Our main algorithmic contribution is the adaptation and application of LLM jailbreaking attacks to obtain complete control authority over VLAs. We find that textual attacks, which are applied once at the beginning of a rollout, facilitate full reachability of the action space of commonly used VLAs and often persist over longer horizons. This differs significantly from LLM jailbreaking literature, as attacks in the real world do not have to be semantically linked to notions of harm. We make all code available at https://github.com/eliotjones1/robogcg .","authors":["Eliot Krzysztof Jones","Alexander Robey","Andy Zou","Zachary Ravichandran","George J. Pappas","Hamed Hassani","Matt Fredrikson","J. Zico Kolter"],"url":"https://arxiv.org/abs/2506.03350"}
{"created":"2025-06-05","title":"Robustness in Both Domains: CLIP Needs a Robust Text Encoder","abstract":"Adversarial input attacks can cause a significant shift of CLIP embeddings. This can affect the downstream robustness of models incorporating CLIP in the pipeline, such as text-to-image generative models or large vision language models. While some efforts have been done towards making the CLIP image encoders robust, the robustness of text encoders remains unexplored. In this work, we cover this gap in the literature. We propose LEAF: an efficient adversarial finetuning method for the text domain, with the ability to scale to large CLIP models. Our models significantly improve the zero-shot adversarial accuracy in the text domain, while maintaining the vision performance provided by robust image encoders. When combined with text-to-image diffusion models, we can improve the generation quality under adversarial noise. When employing our robust CLIP encoders in multimodal retrieval tasks, we improve the recall under adversarial noise over standard CLIP models. Finally, we show that robust text encoders facilitate better reconstruction of input text from its embedding via direct optimization.","authors":["Elias Abad Rocamora","Christian Schlarmann","Naman Deep Singh","Yongtao Wu","Matthias Hein","Volkan Cevher"],"url":"https://arxiv.org/abs/2506.03355"}
{"created":"2025-06-05","title":"Spatial Association Between Near-Misses and Accident Blackspots in Sydney, Australia: A Getis-Ord $G_i^*$ Analysis","abstract":"Road safety management teams utilize on historical accident logs to identify blackspots, which are inherently rare and sparse in space and time. Near-miss events captured through vehicle telematics and transmitted in real-time by connected vehicles reveal a unique potential of prevention due to their high frequency nature and driving engagement on the road. There is currently a lack of understanding of the high potential of near-miss data in real-time to proactively detect potential risky driving areas, in advance of a fatal collision. This paper aims to spatially identify clusters of reported accidents (A) versus high-severity near-misses (High-G) within an urban environment (Sydney, Australia) and showcase how the presence of near-misses can significantly lead to future crashes in identified risky hotspots. First, by utilizing a 400m grid framework, we identify significant crash hotspots using the Getis-Ord $G_i^*$ statistical approach. Second, we employ a Bivariate Local Moran's I (LISA) approach to assess and map the spatial concordance and discordance between official crash counts (A) and High-G counts from nearmiss data (High-G). Third, we classify areas based on their joint spatial patterns into: a) High-High (HH) as the most riskiest areas in both historical logs and nearmiss events, High-Low (HL) for high crash logs but low nearmiss records, c) Low-High (LH) for low past crash records but high nearmiss events, and d) Low-Low (LL) for safe areas. Finally, we run a feature importance ranking on all area patterns by using a contextual Point of Interest (POI) count features and we showcase which factors are the most critical to the occurrence of crash blackspots.","authors":["Artur Grigorev","David Lillo-Trynes","Adriana-Simona Mihaita"],"url":"https://arxiv.org/abs/2506.03356"}
{"created":"2025-06-05","title":"Ask a Local: Detecting Hallucinations With Specialized Model Divergence","abstract":"Hallucinations in large language models (LLMs) - instances where models generate plausible but factually incorrect information - present a significant challenge for AI.","authors":["Aldan Creo","H\\'ector Cerezo-Costas","Pedro Alonso-Doval","Maximiliano Hormaz\\'abal-Lagos"],"url":"https://arxiv.org/abs/2506.03357"}
{"created":"2025-06-05","title":"A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation","abstract":"Rapid, fine-grained disaster damage assessment is essential for effective emergency response, yet remains challenging due to limited ground sensors and delays in official reporting. Social media provides a rich, real-time source of human-centric observations, but its multimodal and unstructured nature presents challenges for traditional analytical methods. In this study, we propose a structured Multimodal, Multilingual, and Multidimensional (3M) pipeline that leverages multimodal large language models (MLLMs) to assess disaster impacts. We evaluate three foundation models across two major earthquake events using both macro- and micro-level analyses. Results show that MLLMs effectively integrate image-text signals and demonstrate a strong correlation with ground-truth seismic data. However, performance varies with language, epicentral distance, and input modality. This work highlights the potential of MLLMs for disaster assessment and provides a foundation for future research in applying MLLMs to real-time crisis contexts. The code and data are released at: https://github.com/missa7481/EMNLP25_earthquake","authors":["Zihui Ma","Lingyao Li","Juan Li","Wenyue Hua","Jingxiao Liu","Qingyuan Feng","Yuki Miura"],"url":"https://arxiv.org/abs/2506.03360"}
{"created":"2025-06-05","title":"Multishot Capacity of Networks with Restricted Adversaries","abstract":"We investigate adversarial network coding and decoding, focusing on the multishot regime and when the adversary is restricted to operate on a vulnerable region of the network. Errors can occur on a proper subset of the network edges and are modeled via an adversarial channel. The paper contains both bounds and capacity-achieving schemes for the Diamond Network, the Mirrored Diamond Network, and generalizations of these networks. We also initiate the study of the capacity of 3-level networks in the multishot setting by computing the multishot capacity of the Butterfly Network, considered in [IEEE Transactions on Information Theory, vol. 69, no. 6, 2023], which is a variant of the network introduced by Ahlswede, Cai, Li and Yeung in 2000.","authors":["Giuseppe Cotardo","Gretchen L. Matthews","Alberto Ravagnani","Julia Shapiro"],"url":"https://arxiv.org/abs/2506.03361"}
{"created":"2025-06-05","title":"Robustness-Aware Tool Selection and Manipulation Planning with Learned Energy-Informed Guidance","abstract":"Humans subconsciously choose robust ways of selecting and using tools, based on years of embodied experience -- for example, choosing a ladle instead of a flat spatula to serve meatballs. However, robustness under uncertainty remains underexplored in robotic tool-use planning. This paper presents a robustness-aware framework that jointly selects tools and plans contact-rich manipulation trajectories, explicitly optimizing for robustness against environmental disturbances. At the core of our approach is a learned, energy-based robustness metric, which guides the planner towards robust manipulation behaviors. We formulate a hierarchical optimization pipeline that first identifies a tool and configuration that optimizes robustness, and then plans a corresponding manipulation trajectory that maintains robustness throughout execution. We evaluate our approach across three representative tool-use tasks. Simulation and real-world results demonstrate that our approach consistently selects robust tools and generates disturbance-resilient manipulation plans.","authors":["Yifei Dong","Yan Zhang","Sylvain Calinon","Florian T. Pokorny"],"url":"https://arxiv.org/abs/2506.03362"}
{"created":"2025-06-05","title":"Probabilistic Factorial Experimental Design for Combinatorial Interventions","abstract":"A combinatorial intervention, consisting of multiple treatments applied to a single unit with potentially interactive effects, has substantial applications in fields such as biomedicine, engineering, and beyond. Given $p$ possible treatments, conducting all possible $2^p$ combinatorial interventions can be laborious and quickly becomes infeasible as $p$ increases. Here we introduce probabilistic factorial experimental design, formalized from how scientists perform lab experiments. In this framework, the experimenter selects a dosage for each possible treatment and applies it to a group of units. Each unit independently receives a random combination of treatments, sampled from a product Bernoulli distribution determined by the dosages. Additionally, the experimenter can carry out such experiments over multiple rounds, adapting the design in an active manner. We address the optimal experimental design problem within an intervention model that imposes bounded-degree interactions between treatments. In the passive setting, we provide a closed-form solution for the near-optimal design. Our results prove that a dosage of $\\tfrac{1}{2}$ for each treatment is optimal up to a factor of $1+O(\\tfrac{\\ln(n)}{n})$ for estimating any $k$-way interaction model, regardless of $k$, and imply that $O\\big(kp^{3k}\\ln(p)\\big)$ observations are required to accurately estimate this model. For the multi-round setting, we provide a near-optimal acquisition function that can be numerically optimized. We also explore several extensions of the design problem and finally validate our findings through simulations.","authors":["Divya Shyamal","Jiaqi Zhang","Caroline Uhler"],"url":"https://arxiv.org/abs/2506.03363"}
{"created":"2025-06-05","title":"Urban Visibility Hotspots: Quantifying Building Vertex Visibility from Connected Vehicle Trajectories using Spatial Indexing","abstract":"Effective placement of Out-of-Home advertising and street furniture requires accurate identification of locations offering maximum visual exposure to target audiences, particularly vehicular traffic. Traditional site selection methods often rely on static traffic counts or subjective assessments. This research introduces a data-driven methodology to objectively quantify location visibility by analyzing large-scale connected vehicle trajectory data (sourced from Compass IoT) within urban environments. We model the dynamic driver field-of-view using a forward-projected visibility area for each vehicle position derived from interpolated trajectories. By integrating this with building vertex locations extracted from OpenStreetMap, we quantify the cumulative visual exposure, or ``visibility count'', for thousands of potential points of interest near roadways. The analysis reveals that visibility is highly concentrated, identifying specific ``visual hotspots'' that receive disproportionately high exposure compared to average locations. The core technical contribution involves the construction of a BallTree spatial index over building vertices. This enables highly efficient (O(logN) complexity) radius queries to determine which vertices fall within the viewing circles of millions of trajectory points across numerous trips, significantly outperforming brute-force geometric checks. Analysis reveals two key findings: 1) Visibility is highly concentrated, identifying distinct 'visual hotspots' receiving disproportionately high exposure compared to average locations. 2) The aggregated visibility counts across vertices conform to a Log-Normal distribution.","authors":["Artur Grigorev","Adriana-Simona Mihaita"],"url":"https://arxiv.org/abs/2506.03365"}
{"created":"2025-06-05","title":"The Cloud Next Door: Investigating the Environmental and Socioeconomic Strain of Datacenters on Local Communities","abstract":"Datacenters have become the backbone of modern digital infrastructure, powering the rapid rise of artificial intelligence and promising economic growth and technological progress. However, this expansion has brought growing tensions in the local communities where datacenters are already situated or being proposed. While the mainstream discourse often focuses on energy usage and carbon footprint of the computing sector at a global scale, the local socio-environmental consequences -- such as health impacts, water usage, noise pollution, infrastructural strain, and economic burden -- remain largely underexplored and poorly addressed. In this work, we surface these community-level consequences through a mixed-methods study that combines quantitative data with qualitative insights. Focusing on Northern Virginia's ``Data Center Valley,'' we highlight how datacenter growth reshapes local environments and everyday life, and examine the power dynamics that determine who benefits and who bears the costs. Our goal is to bring visibility to these impacts and prompt more equitable and informed decisions about the future of digital infrastructure.","authors":["Wacuka Ngata","Noman Bashir","Michelle Westerlaken","Laurent Liote","Yasra Chandio","Elsa Olivetti"],"url":"https://arxiv.org/abs/2506.03367"}
{"created":"2025-06-05","title":"Comparison of different Unique hard attention transformer models by the formal languages they can recognize","abstract":"This note is a survey of various results on the capabilities of unique hard attention transformers encoders (UHATs) to recognize formal languages. We distinguish between masked vs. non-masked, finite vs. infinite image and general vs. bilinear attention score functions. We recall some relations between these models, as well as a lower bound in terms of first-order logic and an upper bound in terms of circuit complexity.","authors":["Leonid Ryvkin"],"url":"https://arxiv.org/abs/2506.03370"}
{"created":"2025-06-05","title":"Toward Reliable VLM: A Fine-Grained Benchmark and Framework for Exposure, Bias, and Inference in Korean Street Views","abstract":"Recent advances in vision-language models (VLMs) have enabled accurate image-based geolocation, raising serious concerns about location privacy risks in everyday social media posts. However, current benchmarks remain coarse-grained, linguistically biased, and lack multimodal and privacy-aware evaluations. To address these gaps, we present KoreaGEO Bench, the first fine-grained, multimodal geolocation benchmark for Korean street views. Our dataset comprises 1,080 high-resolution images sampled across four urban clusters and nine place types, enriched with multi-contextual annotations and two styles of Korean captions simulating real-world privacy exposure. We introduce a three-path evaluation protocol to assess ten mainstream VLMs under varying input modalities and analyze their accuracy, spatial bias, and reasoning behavior. Results reveal modality-driven shifts in localization precision and highlight structural prediction biases toward core cities.","authors":["Xiaonan Wang","Bo Shao","Hansaem Kim"],"url":"https://arxiv.org/abs/2506.03371"}
{"created":"2025-06-05","title":"A Foundation Model for Spatial Proteomics","abstract":"Foundation models have begun to transform image analysis by acting as pretrained generalist backbones that can be adapted to many tasks even when post-training data are limited, yet their impact on spatial proteomics, imaging that maps proteins at single-cell resolution, remains limited. Here, we introduce KRONOS, a foundation model built for spatial proteomics. KRONOS was trained in a self-supervised manner on over 47 million image patches covering 175 protein markers, 16 tissue types, and 8 fluorescence-based imaging platforms. We introduce key architectural adaptations to address the high-dimensional, multi-channel, and heterogeneous nature of multiplex imaging. We demonstrate that KRONOS learns biologically meaningful representations across multiple scales, ranging from cellular and microenvironment to tissue levels, enabling it to address diverse downstream tasks, including cell phenotyping, region classification, and patient stratification. Evaluated across 11 independent cohorts, KRONOS achieves state-of-the-art performance across cell phenotyping, treatment response prediction, and retrieval tasks, and is highly data-efficient. KRONOS also introduces the paradigm of segmentation-free patch-level processing for efficient and scalable spatial proteomics analysis, allowing cross-institutional comparisons, and as an image reverse search engine for spatial patterns. Together, these results position KRONOS as a flexible and scalable tool for spatial proteomics. The model is publicly accessible at https://github.com/mahmoodlab/KRONOS.","authors":["Muhammad Shaban","Yuzhou Chang","Huaying Qiu","Yao Yu Yeo","Andrew H. Song","Guillaume Jaume","Yuchen Wang","Luca L. Weishaupt","Tong Ding","Anurag Vaidya","Abdallah Lamane","Daniel Shao","Mohammed Zidane","Yunhao Bai","Paige McCallum","Shuli Luo","Wenrui Wu","Yang Wang","Precious Cramer","Chi Ngai Chan","Pierre Stephan","Johanna Schaffenrath","Jia Le Lee","Hendrik A. Michel","Caiwei Tian","Cristina Almagro-Perez","Sophia J. Wagner","Sharifa Sahai","Ming Y. Lu","Richard J. Chen","Andrew Zhang","Mark Edward M. Gonzales","Ahmad Makky","Jia-Ying Joey Lee","Hao Cheng","Nourhan El Ahmar","Sayed Matar","Maximilian Haist","Darci Phillips","Yuqi Tan","Garry P. Nolan","W. Richard Burack","Jacob D. Estes","Jonathan T. C. Liu","Toni K Choueiri","Neeraj Agarwal","Marc Barry","Scott J. Rodig","Long Phi Le","Georg Gerber","Christian M. Sch\\\"urch","Fabian J. Theis","Youn H Kim","Joe Yeong","Sabina Signoretti","Brooke E. Howitt","Lit-Hsin Loo","Qin Ma","Sizun Jiang","Faisal Mahmood"],"url":"https://arxiv.org/abs/2506.03373"}
{"created":"2025-06-05","title":"Product Quantization for Surface Soil Similarity","abstract":"The use of machine learning (ML) techniques has allowed rapid advancements in many scientific and engineering fields. One of these problems is that of surface soil taxonomy, a research area previously hindered by the reliance on human-derived classifications, which are mostly dependent on dividing a dataset based on historical understandings of that data rather than data-driven, statistically observable similarities. Using a ML-based taxonomy allows soil researchers to move beyond the limitations of human visualization and create classifications of high-dimension datasets with a much higher level of specificity than possible with hand-drawn taxonomies. Furthermore, this pipeline allows for the possibility of producing both highly accurate and flexible soil taxonomies with classes built to fit a specific application. The machine learning pipeline outlined in this work combines product quantization with the systematic evaluation of parameters and output to get the best available results, rather than accepting sub-optimal results by using either default settings or best guess settings.","authors":["Haley Dozier","Althea Henslee","Ashley Abraham","Andrew Strelzoff","Mark Chappell"],"url":"https://arxiv.org/abs/2506.03374"}
{"created":"2025-06-05","title":"Design of Trimmed Helicoid Soft-Rigid Hybrid Robots","abstract":"As soft robot design matures, researchers have converged to sophisticated design paradigms to enable the development of more suitable platforms. Two such paradigms are soft-rigid hybrid robots, which utilize rigid structural materials in some aspect of the robot's design, and architectured materials, which deform based on geometric parameters as opposed to purely material ones. In this work, we combine the two design approaches, utilizing trimmed helicoid structures in series with rigid linkages. Additionally, we extend the literature on wave spring-inspired soft structures by deriving a mechanical model of the stiffness for arbitrary geometries. We present a novel manufacturing method for such structures utilizing an injection molding approach and we make available the design tool to generate 3D printed molds for arbitrary designs of this class. Finally, we produce a robot using the above methods and operate it in closed-loop demonstrations.","authors":["Zach J. Patterson","Emily R. Sologuren","Daniela Rus"],"url":"https://arxiv.org/abs/2506.03380"}
{"created":"2025-06-05","title":"Automated Traffic Incident Response Plans using Generative Artificial Intelligence: Part 1 -- Building the Incident Response Benchmark","abstract":"Traffic incidents remain a critical public safety concern worldwide, with Australia recording 1,300 road fatalities in 2024, which is the highest toll in 12 years. Similarly, the United States reports approximately 6 million crashes annually, raising significant challenges in terms of a fast reponse time and operational management. Traditional response protocols rely on human decision-making, which introduces potential inconsistencies and delays during critical moments when every minute impacts both safety outcomes and network performance. To address this issue, we propose a novel Incident Response Benchmark that uses generative artificial intelligence to automatically generate response plans for incoming traffic incidents. Our approach aims to significantly reduce incident resolution times by suggesting context-appropriate actions such as variable message sign deployment, lane closures, and emergency resource allocation adapted to specific incident characteristics. First, the proposed methodology uses real-world incident reports from the Performance Measurement System (PeMS) as training and evaluation data. We extract historically implemented actions from these reports and compare them against AI-generated response plans that suggest specific actions, such as lane closures, variable message sign announcements, and/or dispatching appropriate emergency resources. Second, model evaluations reveal that advanced generative AI models like GPT-4o and Grok 2 achieve superior alignment with expert solutions, demonstrated by minimized Hamming distances (averaging 2.96-2.98) and low weighted differences (approximately 0.27-0.28). Conversely, while Gemini 1.5 Pro records the lowest count of missed actions, its extremely high number of unnecessary actions (1547 compared to 225 for GPT-4o) indicates an over-triggering strategy that reduces the overall plan efficiency.","authors":["Artur Grigorev","Khaled Saleh","Jiwon Kim","Adriana-Simona Mihaita"],"url":"https://arxiv.org/abs/2506.03381"}
{"created":"2025-06-05","title":"Towards a Characterization of Two-way Bijections in a Reversible Computational Model","abstract":"We introduce an imperative, stack-based, and reversible computational model that characterizes Two-way Bijections both implicitly, concerning their computational complexity, and with zero-garbage.","authors":["Matteo Palazzo","Luca Roversi"],"url":"https://arxiv.org/abs/2506.03382"}
{"created":"2025-06-05","title":"From Reality to Recognition: Evaluating Visualization Analogies for Novice Chart Comprehension","abstract":"Novice learners often have difficulty learning new visualization types because they tend to interpret novel visualizations through the mental models of simpler charts they have previously encountered. Traditional visualization teaching methods, which usually rely on directly translating conceptual aspects of data into concrete data visualizations, often fail to attend to the needs of novice learners navigating this tension. To address this, we conducted an empirical exploration of how analogies can be used to help novices with chart comprehension. We introduced visualization analogies: visualizations that map data structures to real-world contexts to facilitate an intuitive understanding of novel chart types. We evaluated this pedagogical technique using a within-subject study (N=128) where we taught 8 chart types using visualization analogies. Our findings show that visualization analogies improve visual analysis skills and help learners transfer their understanding to actual charts. They effectively introduce visual embellishments, cater to diverse learning preferences, and are preferred by novice learners over traditional chart visualizations. This study offers empirical insights and open-source tools to advance visualization education through analogical reasoning.","authors":["Oliver Huang","Patrick Lee","Carolina Nobre"],"url":"https://arxiv.org/abs/2506.03385"}
{"created":"2025-06-05","title":"Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery","abstract":"Environmental soundscapes convey substantial ecological and social information regarding urban environments; however, their potential remains largely untapped in large-scale geographic analysis. In this study, we investigate the extent to which urban sounds correspond with visual scenes by comparing various visual representation strategies in capturing acoustic semantics. We employ a multimodal approach that integrates geo-referenced sound recordings with both street-level and remote sensing imagery across three major global cities: London, New York, and Tokyo. Utilizing the AST model for audio, along with CLIP and RemoteCLIP for imagery, as well as CLIPSeg and Seg-Earth OV for semantic segmentation, we extract embeddings and class-level features to evaluate cross-modal similarity. The results indicate that street view embeddings demonstrate stronger alignment with environmental sounds compared to segmentation outputs, whereas remote sensing segmentation is more effective in interpreting ecological categories through a Biophony--Geophony--Anthrophony (BGA) framework. These findings imply that embedding-based models offer superior semantic alignment, while segmentation-based methods provide interpretable links between visual structure and acoustic ecology. This work advances the burgeoning field of multimodal urban sensing by offering novel perspectives for incorporating sound into geospatial analysis.","authors":["Pengyu Chen","Xiao Huang","Teng Fei","Sicheng Wang"],"url":"https://arxiv.org/abs/2506.03388"}
{"created":"2025-06-05","title":"Universal Reusability in Recommender Systems: The Case for Dataset- and Task-Independent Frameworks","abstract":"Recommender systems are pivotal in delivering personalized experiences across industries, yet their adoption and scalability remain hindered by the need for extensive dataset- and task-specific configurations. Existing systems often require significant manual intervention, domain expertise, and engineering effort to adapt to new datasets or tasks, creating barriers to entry and limiting reusability. In contrast, recent advancements in large language models (LLMs) have demonstrated the transformative potential of reusable systems, where a single model can handle diverse tasks without significant reconfiguration. Inspired by this paradigm, we propose the Dataset- and Task-Independent Recommender System (DTIRS), a framework aimed at maximizing the reusability of recommender systems while minimizing barriers to entry. Unlike LLMs, which achieve task generalization directly, DTIRS focuses on eliminating the need to rebuild or reconfigure recommendation pipelines for every new dataset or task, even though models may still need retraining on new data. By leveraging the novel Dataset Description Language (DsDL), DTIRS enables standardized dataset descriptions and explicit task definitions, allowing autonomous feature engineering, model selection, and optimization. This paper introduces the concept of DTIRS and establishes a roadmap for transitioning from Level-1 automation (dataset-agnostic but task-specific systems) to Level-2 automation (fully dataset- and task-independent systems). Achieving this paradigm would maximize code reusability and lower barriers to adoption. We discuss key challenges, including the trade-offs between generalization and specialization, computational overhead, and scalability, while presenting DsDL as a foundational tool for this vision.","authors":["Tri Kurniawan Wijaya","Xinyang Shao","Gonzalo Fiz Pontiveros","Edoardo D'Amico"],"url":"https://arxiv.org/abs/2506.03391"}
{"created":"2025-06-05","title":"Improving Performance of Spike-based Deep Q-Learning using Ternary Neurons","abstract":"We propose a new ternary spiking neuron model to improve the representation capacity of binary spiking neurons in deep Q-learning. Although a ternary neuron model has recently been introduced to overcome the limited representation capacity offered by the binary spiking neurons, we show that its performance is worse than that of binary models in deep Q-learning tasks. We hypothesize gradient estimation bias during the training process as the underlying potential cause through mathematical and empirical analysis. We propose a novel ternary spiking neuron model to mitigate this issue by reducing the estimation bias. We use the proposed ternary spiking neuron as the fundamental computing unit in a deep spiking Q-learning network (DSQN) and evaluate the network's performance in seven Atari games from the Gym environment. Results show that the proposed ternary spiking neuron mitigates the drastic performance degradation of ternary neurons in Q-learning tasks and improves the network performance compared to the existing binary neurons, making DSQN a more practical solution for on-board autonomous decision-making tasks.","authors":["Aref Ghoreishee","Abhishek Mishra","John Walsh","Anup Das","Nagarajan Kandasamy"],"url":"https://arxiv.org/abs/2506.03392"}
{"created":"2025-06-05","title":"Temporal Vegetation Index-Based Unsupervised Crop Stress Detection via Eigenvector-Guided Contrastive Learning","abstract":"Early detection of crop stress is vital for minimizing yield loss and enabling timely intervention in precision agriculture. Traditional approaches using NDRE often detect stress only after visible symptoms appear or require labeled datasets, limiting scalability. This study introduces EigenCL, a novel unsupervised contrastive learning framework guided by temporal NDRE dynamics and biologically grounded eigen decomposition. Using over 10,000 Sentinel-2 NDRE image patches from drought-affected Iowa cornfields, we constructed five-point NDRE time series per patch and derived an RBF similarity matrix. The principal eigenvector explaining 76% of the variance and strongly correlated (r = 0.95) with raw NDRE values was used to define stress-aware similarity for contrastive embedding learning. Unlike existing methods that rely on visual augmentations, EigenCL pulls embeddings together based on biologically similar stress trajectories and pushes apart divergent ones. The learned embeddings formed physiologically meaningful clusters, achieving superior clustering metrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detection up to 12 days before conventional NDRE thresholds. Downstream classification yielded 95% k-NN and 91% logistic regression accuracy. Validation on an independent 2023 Nebraska dataset confirmed generalizability without retraining. EigenCL offers a label-free, scalable approach for early stress detection that aligns with underlying plant physiology and is suitable for real-world deployment in data-scarce agricultural environments.","authors":["Shafqaat Ahmad"],"url":"https://arxiv.org/abs/2506.03394"}
{"created":"2025-06-05","title":"Fault Localisation and Repair for DL Systems: An Empirical Study with LLMs","abstract":"Numerous Fault Localisation (FL) and repair techniques have been proposed to address faults in Deep Learning (DL) models. However, their effectiveness in practical applications remains uncertain due to the reliance on pre-defined rules. This paper presents a comprehensive evaluation of state-of-the-art FL and repair techniques, examining their advantages and limitations. Moreover, we introduce a novel approach that harnesses the power of Large Language Models (LLMs) in localising and repairing DL faults. Our evaluation, conducted on a carefully designed benchmark, reveals the strengths and weaknesses of current FL and repair techniques. We emphasise the importance of enhanced accuracy and the need for more rigorous assessment methods that employ multiple ground truth patches. Notably, LLMs exhibit remarkable performance in both FL and repair tasks. For instance, the GPT-4 model achieves 44% and 82% improvements in FL and repair tasks respectively, compared to the second-best tool, demonstrating the potential of LLMs in this domain. Our study sheds light on the current state of FL and repair techniques and suggests that LLMs could be a promising avenue for future advancements.","authors":["Jinhan Kim","Nargiz Humbatova","Gunel Jahangirova","Shin Yoo","Paolo Tonella"],"url":"https://arxiv.org/abs/2506.03396"}
{"created":"2025-06-05","title":"Sampling Preferences Yields Simple Trustworthiness Scores","abstract":"With the onset of large language models (LLMs), the performance of artificial intelligence (AI) models is becoming increasingly multi-dimensional. Accordingly, there have been several large, multi-dimensional evaluation frameworks put forward to evaluate LLMs. Though these frameworks are much more realistic than previous attempts which only used a single score like accuracy, multi-dimensional evaluations can complicate decision-making since there is no obvious way to select an optimal model. This work introduces preference sampling, a method to extract a scalar trustworthiness score from multi-dimensional evaluation results by considering the many characteristics of model performance which users value. We show that preference sampling improves upon alternate aggregation methods by using multi-dimensional trustworthiness evaluations of LLMs from TrustLLM and DecodingTrust. We find that preference sampling is consistently reductive, fully reducing the set of candidate models 100% of the time whereas Pareto optimality never reduces the set by more than 50%. Likewise, preference sampling is consistently sensitive to user priors-allowing users to specify the relative weighting and confidence of their preferences-whereas averaging scores is intransigent to the users' prior knowledge.","authors":["Sean Steinle"],"url":"https://arxiv.org/abs/2506.03399"}
{"created":"2025-06-05","title":"Occlusion-Aware Ground Target Tracking by a Dubins Vehicle Using Visibility Volumes","abstract":"This paper considers the problem of tracking a point of interest (POI) moving along a known trajectory on the ground with an uncrewed aerial vehicle (UAV) modeled as a Dubins vehicle using a line-of-sight (LOS) sensor through an urban environment that may occlude the POI. A visibility volume (VV) encodes a time-varying, three-dimensional representation of the sensing constraints for a particular POI position. A constant-altitude, translating, and radially time-varying circular standoff orbit is then inscribed within the dynamically changing VV centered at the POI position. The time-varying VV is approximated by placing static VVs along the POI's trajectory using an adaptive metric that restricts the volume change of consecutive visibility volumes to below a specified rate. The time-varying circular standoff orbit is proven to be feasible for a Dubins vehicle and is approximated with a piecewise set of linearly interpolated circular orbits inside the static VVs. A steering controller is derived that drives the UAV to converge to the time-varying standoff orbit. Numerical simulations and a flight test illustrate the proposed approach.","authors":["Collin Hague","Artur Wolek"],"url":"https://arxiv.org/abs/2506.03400"}
{"created":"2025-06-05","title":"RAGOps: Operating and Managing Retrieval-Augmented Generation Pipelines","abstract":"Recent studies show that 60% of LLM-based compound systems in enterprise environments leverage some form of retrieval-augmented generation (RAG), which enhances the relevance and accuracy of LLM (or other genAI) outputs by retrieving relevant information from external data sources. LLMOps involves the practices and techniques for managing the lifecycle and operations of LLM compound systems in production environments. It supports enhancing LLM systems through continuous operations and feedback evaluation. RAGOps extends LLMOps by incorporating a strong focus on data management to address the continuous changes in external data sources. This necessitates automated methods for evaluating and testing data operations, enhancing retrieval relevance and generation quality. In this paper, we (1) characterize the generic architecture of RAG applications based on the 4+1 model view for describing software architectures, (2) outline the lifecycle of RAG systems, which integrates the management lifecycles of both the LLM and the data, (3) define the key design considerations of RAGOps across different stages of the RAG lifecycle and quality trade-off analyses, (4) highlight the overarching research challenges around RAGOps, and (5) present two use cases of RAG applications and the corresponding RAGOps considerations.","authors":["Xiwei Xu","Hans Weytjens","Dawen Zhang","Qinghua Lu","Ingo Weber","Liming Zhu"],"url":"https://arxiv.org/abs/2506.03401"}
{"created":"2025-06-05","title":"The Stress of Improvisation: Instructors' Perspectives on Live Coding in Programming Classes","abstract":"Live coding is a pedagogical technique in which an instructor writes and executes code in front of students to impart skills like incremental development and debugging. Although live coding offers many benefits, instructors face many challenges in the classroom, like cognitive challenges and psychological stress, most of which have yet to be formally studied. To understand the obstacles faced by instructors in CS classes, we conducted (1) a formative interview with five teaching assistants in exercise sessions and (2) a contextual inquiry study with four lecturers for large-scale classes. We found that the improvisational and unpredictable nature of live coding makes it difficult for instructors to manage their time and keep students engaged, resulting in more mental stress than presenting static slides. We discussed opportunities for augmenting existing IDEs and presentation setups to help enhance live coding experience.","authors":["Xiaotian Su","April Wang"],"url":"https://arxiv.org/abs/2506.03402"}
{"created":"2025-06-05","title":"The Impact of On-Policy Parallelized Data Collection on Deep Reinforcement Learning Networks","abstract":"The use of parallel actors for data collection has been an effective technique used in reinforcement learning (RL) algorithms. The manner in which data is collected in these algorithms, controlled via the number of parallel environments and the rollout length, induces a form of bias-variance trade-off; the number of training passes over the collected data, on the other hand, must strike a balance between sample efficiency and overfitting. We conduct an empirical analysis of these trade-offs on PPO, one of the most popular RL algorithms that uses parallel actors, and establish connections to network plasticity and, more generally, optimization stability. We examine its impact on network architectures, as well as the hyper-parameter sensitivity when scaling data. Our analyses indicate that larger dataset sizes can increase final performance across a variety of settings, and that scaling parallel environments is more effective than increasing rollout lengths. These findings highlight the critical role of data collection strategies in improving agent performance.","authors":["Walter Mayor","Johan Obando-Ceron","Aaron Courville","Pablo Samuel Castro"],"url":"https://arxiv.org/abs/2506.03404"}
{"created":"2025-06-05","title":"Multi-Spectral Gaussian Splatting with Neural Color Representation","abstract":"We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS) framework that is able to generate multi-view consistent novel views from images of multiple, independent cameras with different spectral domains. In contrast to previous approaches, our method does not require cross-modal camera calibration and is versatile enough to model a variety of different spectra, including thermal and near-infra red, without any algorithmic changes.","authors":["Lukas Meyer","Josef Gr\\\"un","Maximilian Weiherer","Bernhard Egger","Marc Stamminger","Linus Franke"],"url":"https://arxiv.org/abs/2506.03407"}
{"created":"2025-06-05","title":"Trajectory Prediction Meets Large Language Models: A Survey","abstract":"Recent advances in large language models (LLMs) have sparked growing interest in integrating language-driven techniques into trajectory prediction. By leveraging their semantic and reasoning capabilities, LLMs are reshaping how autonomous systems perceive, model, and predict trajectories. This survey provides a comprehensive overview of this emerging field, categorizing recent work into five directions: (1) Trajectory prediction via language modeling paradigms, (2) Direct trajectory prediction with pretrained language models, (3) Language-guided scene understanding for trajectory prediction, (4) Language-driven data generation for trajectory prediction, (5) Language-based reasoning and interpretability for trajectory prediction. For each, we analyze representative methods, highlight core design choices, and identify open challenges. This survey bridges natural language processing and trajectory prediction, offering a unified perspective on how language can enrich trajectory prediction.","authors":["Yi Xu","Ruining Yang","Yitian Zhang","Yizhou Wang","Jianglin Lu","Mingyuan Zhang","Lili Su","Yun Fu"],"url":"https://arxiv.org/abs/2506.03408"}
{"created":"2025-06-05","title":"Technical Options for Flexible Hardware-Enabled Guarantees","abstract":"Frontier AI models pose increasing risks to public safety and international security, creating a pressing need for AI developers to provide credible guarantees about their development activities without compromising proprietary information. We propose Flexible Hardware-Enabled Guarantees (flexHEG), a system integrated with AI accelerator hardware to enable verifiable claims about compute usage in AI development. The flexHEG system consists of two primary components: an auditable Guarantee Processor that monitors accelerator usage and verifies compliance with specified rules, and a Secure Enclosure that provides physical tamper protection. In this report, we analyze technical implementation options ranging from firmware modifications to custom hardware approaches, with focus on an \"Interlock\" design that provides the Guarantee Processor direct access to accelerator data paths. Our proposed architecture could support various guarantee types, from basic usage auditing to sophisticated automated verification. This work establishes technical foundations for hardware-based AI governance mechanisms that could be deployed by 2027 to address emerging regulatory and international security needs in frontier AI development.","authors":["James Petrie","Onni Aarne"],"url":"https://arxiv.org/abs/2506.03409"}
{"created":"2025-06-05","title":"An iterative tangential interpolation framework for model reduction of MIMO systems","abstract":"We consider model reduction of large-scale MIMO systems using tangential interpolation in the frequency domain. Our scheme is related to the recently-developed Adaptive Antoulas--Anderson (AAA) algorithm, which is an iterative algorithm that uses concepts from the Loewner framework. Our algorithm uses low-rank interpolation and iteratively adds interpolation points based on several criteria including minimizing maximum errors. We show there is freedom in the interpolation point selection method, leading to multiple algorithms that have trade-offs between computational complexity and approximation performance. We prove that a weighted \\(H_2\\) norm of a representative error system is monotonically decreasing as interpolation points are added. Finally, we provide computational results and some comparisons with prior works, demonstrating performance on par with standard model reduction methods.","authors":["Jared Jonas","Bassam Bamieh"],"url":"https://arxiv.org/abs/2506.03410"}
{"created":"2025-06-05","title":"A Machine Learning Theory Perspective on Strategic Litigation","abstract":"Strategic litigation involves bringing a legal case to court with the goal of having a broader impact beyond resolving the case itself: for example, creating precedent which will influence future rulings. In this paper, we explore strategic litigation from the perspective of machine learning theory. We consider an abstract model of a common-law legal system where a lower court decides new cases by applying a decision rule learned from a higher court's past rulings. In this model, we explore the power of a strategic litigator, who strategically brings cases to the higher court to influence the learned decision rule, thereby affecting future cases. We explore questions including: What impact can a strategic litigator have? Which cases should a strategic litigator bring to court? Does it ever make sense for a strategic litigator to bring a case when they are sure the court will rule against them?","authors":["Melissa Dutz","Han Shao","Avrim Blum","Aloni Cohen"],"url":"https://arxiv.org/abs/2506.03411"}
{"created":"2025-06-05","title":"On Loss-Minimal Radial Topologies in MV Systems","abstract":"Distribution system reconfiguration (DSR) means optimizing the topology of a distribution grid using switching actions. Switching actions are a degrees of freedom available to distribution system operators, e.g. to manage planned and unplanned outages. DSR is a NP-hard combinatorial problem. Finding good or even optimal solutions is computationally expensive. While transmission and high-voltage grids are generally operated in a meshed state, MV distribution systems are commonly operated as radial networks even though meshed operation would be supported. This improves resilience because faults can be isolated more easily keeping the rest of the system operational and minimizing impact on customers. We propose an AC DSR formulation and benchmark it against a common formulation from the literature. Our results indicate that additional acyclicity constraints can significantly improve solver performance.","authors":["Anton Hinneck","Mathias Duckheim","Michael Metzger","Stefan Niessen"],"url":"https://arxiv.org/abs/2506.03422"}
{"created":"2025-06-05","title":"DistRAG: Towards Distance-Based Spatial Reasoning in LLMs","abstract":"Many real world tasks where Large Language Models (LLMs) can be used require spatial reasoning, like Point of Interest (POI) recommendation and itinerary planning. However, on their own LLMs lack reliable spatial reasoning capabilities, especially about distances. To address this problem, we develop a novel approach, DistRAG, that enables an LLM to retrieve relevant spatial information not explicitly learned during training. Our method encodes the geodesic distances between cities and towns in a graph and retrieves a context subgraph relevant to the question. Using this technique, our method enables an LLM to answer distance-based reasoning questions that it otherwise cannot answer. Given the vast array of possible places an LLM could be asked about, DistRAG offers a flexible first step towards providing a rudimentary `world model' to complement the linguistic knowledge held in LLMs.","authors":["Nicole R Schneider","Nandini Ramachandran","Kent O'Sullivan","Hanan Samet"],"url":"https://arxiv.org/abs/2506.03424"}
{"created":"2025-06-05","title":"Adaptive Task Vectors for Large Language Models","abstract":"In-Context Learning (ICL) enables Large Language Models (LLMs) to perform tasks without parameter updates by conditioning on a few demonstrations provided in the prompt. Despite its success, ICL suffers from several limitations, including sensitivity to demonstration order, context length constraints, and computational inefficiency. To address these challenges, task vector-based approaches compress task information into a single vector. However, these methods typically construct task vectors from fixed sets of demonstrations and reuse them across input queries, without conditioning on the specific input. This limitation can lead models to struggle with effective adaptation when the input query is not well aligned with the underlying demonstrations, consequently degrading their generalization performance on unseen tasks. To overcome this limitation, we propose Adaptive Task Vectors (ATV), a simple and effective framework that dynamically generates task vectors conditioned on each input query. ATV employs a small language model to generate task vectors, which are then transformed to match the target LLM's architecture and applied to guide its output generation. In contrast to ICL and previous vector-based approaches, which rely on fixed demonstration sets and their corresponding vectors, ATV dynamically generates task vectors tailored to each specific input query and task. Consequently, ATV demonstrates strong performance and generalization capabilities, even for unseen tasks. Furthermore, we provide a theoretical analysis indicating that ATV is expressively equivalent to LoRA under equal rank budgets and more expressive than Prefix-Tuning, thereby offering formal support for its representational advantage.","authors":["Joonseong Kang","Soojeong Lee","Subeen Park","Sumin Park","Taero Kim","Jihee Kim","Ryunyi Lee","Kyungwoo Song"],"url":"https://arxiv.org/abs/2506.03426"}
{"created":"2025-06-05","title":"Two-Stage Bidirectional Inverter Equivalent Circuit Model for Distribution Grid Steady-State Analysis and Optimization","abstract":"This paper presents a \\textit{physics-based} steady-state equivalent circuit model of a two-stage bidirectional inverter. These inverters connect distributed energy resources (DERs), such as photovoltaic (PV) and battery systems, to distribution grids. Existing inverter models have technical gaps on three fronts: i) inadequate modeling of inverter losses, ii) use of mathematical abstractions for bidirectional flow of power, and iii) inability to integrate different control modes into nonlinear solvers without loss of generality. We propose a physics-first model that explicitly captures losses in passive circuit components based on circuit-level principles. We enable bidirectional power flow without binary or complementarity constraints by formulating loss terms as smooth, sign-aware expressions of current. We introduce and parameterize controlled current sources with twice-differentiable continuous functions to enable inverter control modes without loss of generality. We integrate DERs with the proposed inverter model at the load buses of distribution networks to perform power flow and optimization studies on real-world distribution networks with over 20,000 nodes. We demonstrate that the proposed model is more accurate, integrates seamlessly with various control modes without loss of generality, and scales robustly to large optimization problems.","authors":["Emmanuel O. Badmus","Amritanshu Pandey"],"url":"https://arxiv.org/abs/2506.03430"}
{"created":"2025-06-05","title":"ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads","abstract":"Vision foundation models (VFMs) have demonstrated remarkable performance across a wide range of downstream tasks. While several VFM adapters have shown promising results by leveraging the prior knowledge of VFMs, we identify two inefficiencies in these approaches. First, the interaction between convolutional neural network (CNN) and VFM backbone triggers early layer gradient backpropagation. Second, existing methods require tuning all components, adding complexity. Besides, these adapters alter VFM features, underutilizing the prior knowledge. To tackle these challenges, we propose a new approach called ViT-Split, based on a key observation: the layers of several VFMs, like DINOv2, can be divided into two distinct components: an extractor for learning low-level features and an adapter for learning task-specific features. Leveraging this insight, we eliminate the CNN branch and introduce two heads, task head and prior head, to the frozen VFM. The task head is designed to learn task-specific features, mitigating the early gradient propagation issue. The prior head is used to leverage the multi-scale prior features from the frozen VFM, reducing tuning parameters and overfitting. Extensive experiments on various tasks (e.g., segmentation, detection, depth estimation, and visual question answering) validate the effectiveness and efficiency of ViT-Split. Specifically, ViT-Split reduces training time up to $4\\times$ while achieving comparable or even better results on ADE20K, compared to other VFM adapters.","authors":["Yifan Li","Xin Li","Tianqin Li","Wenbin He","Yu Kong","Liu Ren"],"url":"https://arxiv.org/abs/2506.03433"}
{"created":"2025-06-05","title":"Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models","abstract":"Understanding how large language models (LLMs) acquire and store factual knowledge is crucial for enhancing their interpretability and reliability. In this work, we analyze the evolution of factual knowledge representation in the OLMo-7B model by tracking the roles of its attention heads and feed forward networks (FFNs) over the course of pre-training. We classify these components into four roles: general, entity, relation-answer, and fact-answer specific, and examine their stability and transitions. Our results show that LLMs initially depend on broad, general-purpose components, which later specialize as training progresses. Once the model reliably predicts answers, some components are repurposed, suggesting an adaptive learning process. Notably, attention heads display the highest turnover. We also present evidence that FFNs remain more stable throughout training. Furthermore, our probing experiments reveal that location-based relations converge to high accuracy earlier in training than name-based relations, highlighting how task complexity shapes acquisition dynamics. These insights offer a mechanistic view of knowledge formation in LLMs.","authors":["Ahmad Dawar Hakimi","Ali Modarressi","Philipp Wicke","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2506.03434"}
{"created":"2025-06-05","title":"Quake: Adaptive Indexing for Vector Search","abstract":"Vector search, the task of finding the k-nearest neighbors of high-dimensional vectors, underpins many machine learning applications, including recommendation systems and information retrieval. However, existing approximate nearest neighbor (ANN) methods perform poorly under dynamic, skewed workloads where data distributions evolve. We introduce Quake, an adaptive indexing system that maintains low latency and high recall in such environments. Quake employs a hierarchical partitioning scheme that adjusts to updates and changing access patterns, guided by a cost model that predicts query latency based on partition sizes and access frequencies. Quake also dynamically optimizes query execution parameters to meet recall targets using a novel recall estimation model. Furthermore, Quake utilizes optimized query processing, leveraging NUMA-aware parallelism for improved memory bandwidth utilization. To evaluate Quake, we prepare a Wikipedia vector search workload and develop a workload generator to create vector search workloads with configurable access patterns. Our evaluation shows that on dynamic workloads, Quake achieves query latency reductions of 1.5-22x and update latency reductions of 6-83x compared to state-of-the-art indexes SVS, DiskANN, HNSW, and SCANN.","authors":["Jason Mohoney","Devesh Sarda","Mengze Tang","Shihabur Rahman Chowdhury","Anil Pacaci","Ihab F. Ilyas","Theodoros Rekatsinas","Shivaram Venkataraman"],"url":"https://arxiv.org/abs/2506.03437"}
{"created":"2025-06-05","title":"Optimizing Software Defined Battery Systems for Transformer Protection","abstract":"Residential electric vehicle charging causes large spikes in electricity demand that risk violating neighborhood transformer power limits. Battery energy storage systems reduce these transformer limit violations, but operating them individually is not cost-optimal. Instead of individual optimization, aggregating, or sharing, these batteries leads to cost-optimal performance, but homeowners must relinquish battery control. This paper leverages virtualization to propose battery sharing optimization schemes to reduce electricity costs, extend the lifetime of a residential transformer, and maintain homeowner control over the battery. A case study with simulated home loads, solar generation, and electric vehicle charging profiles demonstrates that joint, or shared, optimization reduces consumer bills by 56% and transformer aging by 48% compared to individual optimization. Hybrid and dynamic optimization schemes that provide owners with autonomy have similar transformer aging reduction but are slightly less cost-effective. These results suggest that controlling shared batteries with virtualization is an effective way to delay transformer upgrades in the face of growing residential electric vehicle charging penetration.","authors":["Sonia Martin","Obidike Nnorom Jr.","Philip Levis","Ram Rajagopal"],"url":"https://arxiv.org/abs/2506.03439"}
{"created":"2025-06-05","title":"Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos","abstract":"Human-Object Interaction (HOI) recognition in videos requires understanding both visual patterns and geometric relationships as they evolve over time. Visual and geometric features offer complementary strengths. Visual features capture appearance context, while geometric features provide structural patterns. Effectively fusing these multimodal features without compromising their unique characteristics remains challenging. We observe that establishing robust, entity-specific representations before modeling interactions helps preserve the strengths of each modality. Therefore, we hypothesize that a bottom-up approach is crucial for effective multimodal fusion. Following this insight, we propose the Geometric Visual Fusion Graph Neural Network (GeoVis-GNN), which uses dual-attention feature fusion combined with interdependent entity graph learning. It progressively builds from entity-specific representations toward high-level interaction understanding. To advance HOI recognition to real-world scenarios, we introduce the Concurrent Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person interactions involving concurrent actions and partial engagement. This dataset helps address challenges like complex human-object dynamics and mutual occlusions. Extensive experiments demonstrate the effectiveness of our method across various HOI scenarios. These scenarios include two-person interactions, single-person activities, bimanual manipulations, and complex concurrent partial interactions. Our method achieves state-of-the-art performance.","authors":["Tanqiu Qiao","Ruochen Li","Frederick W. B. Li","Yoshiki Kubotani","Shigeo Morishima","Hubert P. H. Shum"],"url":"https://arxiv.org/abs/2506.03440"}
{"created":"2025-06-05","title":"Politics and polarization on Bluesky","abstract":"Online political discourse is increasingly shaped not by a few dominant platforms but by a fragmented ecosystem of social media spaces, each with its own user base, target audience, and algorithmic mediation of discussion. Such fragmentation may fundamentally change how polarization manifests online. In this study, we investigate the characteristics of political discourse and polarization on the emerging social media site Bluesky. We collect all activity on the platform between December 2024 and May 2025 to map out the platform's political topic landscape and detect distinct polarization patterns. Our comprehensive data collection allows us to employ a data-driven methodology for identifying political themes, classifying user stances, and measuring both structural and content-based polarization across key topics raised in English-language discussions. Our analysis reveals that approximately 13% of Bluesky posts engage with political content, with prominent topics including international conflicts, U.S. politics, and socio-technological debates. We find high levels of structural polarization across several salient political topics. However, the most polarized topics are also highly imbalanced in the numbers of users on opposing sides, with the smaller group consisting of only 1-2% of the users. While discussions in Bluesky echo familiar political narratives and polarization trends, the platform exhibits a more politically homogeneous user base than was typical prior to the current wave of platform fragmentation.","authors":["Ali Salloum","Dorian Quelle","Letizia Iannucci","Alexandre Bovet","Mikko Kivel\\\"a"],"url":"https://arxiv.org/abs/2506.03443"}
{"created":"2025-06-05","title":"Exploiting LLMs for Automatic Hypothesis Assessment via a Logit-Based Calibrated Prior","abstract":"As hypothesis generation becomes increasingly automated, a new bottleneck has emerged: hypothesis assessment. Modern systems can surface thousands of statistical relationships-correlations, trends, causal links-but offer little guidance on which ones are novel, non-trivial, or worthy of expert attention. In this work, we study the complementary problem to hypothesis generation: automatic hypothesis assessment. Specifically, we ask: given a large set of statistical relationships, can we automatically assess which ones are novel and worth further exploration? We focus on correlations as they are a common entry point in exploratory data analysis that often serve as the basis for forming deeper scientific or causal hypotheses.","authors":["Yue Gong","Raul Castro Fernandez"],"url":"https://arxiv.org/abs/2506.03444"}
{"created":"2025-06-05","title":"RefEdit: A Benchmark and Method for Improving Instruction-based Image Editing Model on Referring Expressions","abstract":"Despite recent advances in inversion and instruction-based image editing, existing approaches primarily excel at editing single, prominent objects but significantly struggle when applied to complex scenes containing multiple entities. To quantify this gap, we first introduce RefEdit-Bench, a rigorous real-world benchmark rooted in RefCOCO, where even baselines trained on millions of samples perform poorly. To overcome this limitation, we introduce RefEdit -- an instruction-based editing model trained on our scalable synthetic data generation pipeline. Our RefEdit, trained on only 20,000 editing triplets, outperforms the Flux/SD3 model-based baselines trained on millions of data. Extensive evaluations across various benchmarks demonstrate that our model not only excels in referring expression tasks but also enhances performance on traditional benchmarks, achieving state-of-the-art results comparable to closed-source methods. We release data \\& checkpoint for reproducibility.","authors":["Bimsara Pathiraja","Maitreya Patel","Shivam Singh","Yezhou Yang","Chitta Baral"],"url":"https://arxiv.org/abs/2506.03448"}
{"created":"2025-06-05","title":"The effects of using created synthetic images in computer vision training","abstract":"This paper investigates how rendering engines, like Unreal Engine 4 (UE), can be used to create synthetic images to supplement datasets for deep computer vision (CV) models in image abundant and image limited use cases. Using rendered synthetic images from UE can provide developers and businesses with a method of accessing nearly unlimited, reproducible, agile, and cheap training sets for their customers and applications without the threat of poisoned images from the internet or the cost of collecting them. The validity of these generated images are examined by testing the change in model test accuracy in two different sized CV models across two binary classification cases (Cat vs Dog and Weld Defect Detection). In addition, this paper provides an implementation of how to measure the quality of synthetic images by using pre-trained CV models as auditors. Results imply that for large (VGG16) and small (MobileNetV3-small) parameter deep CV models, adding >60% additional synthetic images to a real image dataset during model training can narrow the test-training accuracy gap to ~1-2% without a conclusive effect on test accuracy compared to using real world images alone. Likewise, adding <10% additional real training images to synthetic only training sets decreased the classification error rate in half, then decreasing further when adding more real training images. For these cases tested, using synthetic images from rendering engines allow researchers to only use 10% of their real images during training, compared to the traditional 50-70%. This research serves as an example of how to create synthetic images, guidelines on how to use the images, potential restrictions and possible performance improvements for data-scarce projects.","authors":["John W. Smutny"],"url":"https://arxiv.org/abs/2506.03449"}
{"created":"2025-06-05","title":"SENMAP: Multi-objective data-flow mapping and synthesis for hybrid scalable neuromorphic systems","abstract":"This paper introduces SENMap, a mapping and synthesis tool for scalable, energy-efficient neuromorphic computing architecture frameworks. SENECA is a flexible architectural design optimized for executing edge AI SNN/ANN inference applications efficiently. To speed up the silicon tape-out and chip design for SENECA, an accurate emulator, SENSIM, was designed. While SENSIM supports direct mapping of SNNs on neuromorphic architectures, as the SNN and ANNs grow in size, achieving optimal mapping for objectives like energy, throughput, area, and accuracy becomes challenging. This paper introduces SENMap, flexible mapping software for efficiently mapping large SNN and ANN applications onto adaptable architectures. SENMap considers architectural, pretrained SNN and ANN realistic examples, and event rate-based parameters and is open-sourced along with SENSIM to aid flexible neuromorphic chip design before fabrication. Experimental results show SENMap enables 40 percent energy improvements for a baseline SENSIM operating in timestep asynchronous mode of operation. SENMap is designed in such a way that it facilitates mapping large spiking neural networks for future modifications as well.","authors":["Prithvish V Nembhani","Oliver Rhodes","Guangzhi Tang","Alexandra F Dobrita","Yingfu Xu","Kanishkan Vadivel","Kevin Shidqi","Paul Detterer Mario Konijnenburg","Gert-Jan van Schaik","Manolis Sifalakis","Zaid Al-Ars","Amirreza Yousefzadeh"],"url":"https://arxiv.org/abs/2506.03450"}
{"created":"2025-06-05","title":"Nonlinear Optimal Control of DC Microgrids with Safety and Stability Guarantees","abstract":"A DC microgrid is a promising alternative to the traditional AC power grid, since it can efficiently integrate distributed and renewable energy resources. However, as an emerging framework, it lacks the rigorous theoretical guarantees of its AC counterpart. In particular, safe stabilization of the DC microgrid has been a non-trivial task in power electronics. To address that, we take a control theoretic perspective in designing the feedback controller with provable guarantees. We present a systematic way to construct Control Lyapunov Functions (CLF) to stabilize the microgrid, and, independently, Control Barrier Functions (CBF) to enforce its safe operation at all times. The safety-critical controller (SCC) proposed in this work integrates the two control objectives, with safety prioritized, into a quadratic program (QP) as linear constraints, which allows for its online deployment using off-the-shelf convex optimization solvers. The SCC is compared against a robust version of the conventional droop control through numerical experiments whose results indicate the SCC outperforms the droop controller in guaranteeing safety and retaining stability at the same time.","authors":["Muratkhan Abdirash","Xiaofan Cui"],"url":"https://arxiv.org/abs/2506.03454"}
{"created":"2025-06-05","title":"Culture Matters in Toxic Language Detection in Persian","abstract":"Toxic language detection is crucial for creating safer online environments and limiting the spread of harmful content. While toxic language detection has been under-explored in Persian, the current work compares different methods for this task, including fine-tuning, data enrichment, zero-shot and few-shot learning, and cross-lingual transfer learning. What is especially compelling is the impact of cultural context on transfer learning for this task: We show that the language of a country with cultural similarities to Persian yields better results in transfer learning. Conversely, the improvement is lower when the language comes from a culturally distinct country. Warning: This paper contains examples of toxic language that may disturb some readers. These examples are included for the purpose of research on toxic detection.","authors":["Zahra Bokaei","Walid Magdy","Bonnie Webber"],"url":"https://arxiv.org/abs/2506.03458"}
{"created":"2025-06-05","title":"RoNFA: Robust Neural Field-based Approach for Few-Shot Image Classification with Noisy Labels","abstract":"In few-shot learning (FSL), the labeled samples are scarce. Thus, label errors can significantly reduce classification accuracy. Since label errors are inevitable in realistic learning tasks, improving the robustness of the model in the presence of label errors is critical. This paper proposes a new robust neural field-based image approach (RoNFA) for few-shot image classification with noisy labels. RoNFA consists of two neural fields for feature and category representation. They correspond to the feature space and category set. Each neuron in the field for category representation (FCR) has a receptive field (RF) on the field for feature representation (FFR) centered at the representative neuron for its category generated by soft clustering. In the prediction stage, the range of these receptive fields adapts according to the neuronal activation in FCR to ensure prediction accuracy. These learning strategies provide the proposed model with excellent few-shot learning capability and strong robustness against label noises. The experimental results on real-world FSL datasets with three different types of label noise demonstrate that the proposed method significantly outperforms state-of-the-art FSL methods. Its accuracy obtained in the presence of noisy labels even surpasses the results obtained by state-of-the-art FSL methods trained on clean support sets, indicating its strong robustness against noisy labels.","authors":["Nan Xiang","Lifeng Xing","Dequan Jin"],"url":"https://arxiv.org/abs/2506.03461"}
{"created":"2025-06-05","title":"From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications","abstract":"The convergence of online learning algorithms in games under self-play is a fundamental question in game theory and machine learning. Among various notions of convergence, last-iterate convergence is particularly desirable, as it reflects the actual decisions made by the learners and captures the day-to-day behavior of the learning dynamics. While many algorithms are known to converge in the average-iterate, achieving last-iterate convergence typically requires considerably more effort in both the design and the analysis of the algorithm. Somewhat surprisingly, we show in this paper that for a large family of games, there exists a simple black-box reduction that transforms the average iterates of an uncoupled learning dynamics into the last iterates of a new uncoupled learning dynamics, thus also providing a reduction from last-iterate convergence to average-iterate convergence. Our reduction applies to games where each player's utility is linear in both their own strategy and the joint strategy of all opponents. This family includes two-player bimatrix games and generalizations such as multi-player polymatrix games. By applying our reduction to the Optimistic Multiplicative Weights Update algorithm, we obtain new state-of-the-art last-iterate convergence rates for uncoupled learning dynamics in two-player zero-sum normal-form games: (1) an $O(\\frac{\\log d}{T})$ last-iterate convergence rate under gradient feedback, representing an exponential improvement in the dependence on the dimension $d$ (i.e., the maximum number of actions available to either player); and (2) an $\\widetilde{O}(d^{\\frac{1}{5}} T^{-\\frac{1}{5}})$ last-iterate convergence rate under bandit feedback, improving upon the previous best rates of $\\widetilde{O}(\\sqrt{d} T^{-\\frac{1}{8}})$ and $\\widetilde{O}(\\sqrt{d} T^{-\\frac{1}{6}})$.","authors":["Yang Cai","Haipeng Luo","Chen-Yu Wei","Weiqiang Zheng"],"url":"https://arxiv.org/abs/2506.03464"}
{"created":"2025-06-05","title":"Minimizing the Arithmetic and Communication Complexity of Jacobi's Method for Eigenvalues and Singular Values","abstract":"In this paper, we analyze several versions of Jacobi's method for the symmetric eigenvalue problem. Our goal throughout is to reduce the asymptotic cost of the algorithm as much as possible, as measured by the number of arithmetic operations performed and associated (sequential or parallel) communication, i.e., the amount of data moved between slow and fast memory or between processors in a network. In producing rigorous complexity bounds, we allow our algorithms to be built on both classic $O(n^3)$ matrix multiplication and fast, Strassen-like $O(n^{\\omega_0})$ alternatives. In the classical setting, we show that a blocked implementation of Jacobi's method attains the communication lower bound for $O(n^3)$ matrix multiplication (and is therefore expected to be communication optimal among $O(n^3)$ methods). In the fast setting, we demonstrate that a recursive version of blocked Jacobi can go even further, reaching essentially optimal complexity in both measures. We also discuss Jacobi-based SVD algorithms and a parallel version of block Jacobi, showing that analogous complexity bounds apply.","authors":["James Demmel","Hengrui Luo","Ryan Schneider","Yifu Wang"],"url":"https://arxiv.org/abs/2506.03466"}
{"created":"2025-06-05","title":"Differentially Private Distribution Release of Gaussian Mixture Models via KL-Divergence Minimization","abstract":"Gaussian Mixture Models (GMMs) are widely used statistical models for representing multi-modal data distributions, with numerous applications in data mining, pattern recognition, data simulation, and machine learning. However, recent research has shown that releasing GMM parameters poses significant privacy risks, potentially exposing sensitive information about the underlying data. In this paper, we address the challenge of releasing GMM parameters while ensuring differential privacy (DP) guarantees. Specifically, we focus on the privacy protection of mixture weights, component means, and covariance matrices. We propose to use Kullback-Leibler (KL) divergence as a utility metric to assess the accuracy of the released GMM, as it captures the joint impact of noise perturbation on all the model parameters. To achieve privacy, we introduce a DP mechanism that adds carefully calibrated random perturbations to the GMM parameters. Through theoretical analysis, we quantify the effects of privacy budget allocation and perturbation statistics on the DP guarantee, and derive a tractable expression for evaluating KL divergence. We formulate and solve an optimization problem to minimize the KL divergence between the released and original models, subject to a given $(\\epsilon, \\delta)$-DP constraint. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach achieves strong privacy guarantees while maintaining high utility.","authors":["Hang Liu","Anna Scaglione","Sean Peisert"],"url":"https://arxiv.org/abs/2506.03467"}
{"created":"2025-06-05","title":"Verification-Guided Falsification for Safe RL via Explainable Abstraction and Risk-Aware Exploration","abstract":"Ensuring the safety of reinforcement learning (RL) policies in high-stakes environments requires not only formal verification but also interpretability and targeted falsification. While model checking provides formal guarantees, its effectiveness is limited by abstraction quality and the completeness of the underlying trajectory dataset. We propose a hybrid framework that integrates (1) explainability, (2) model checking, and (3) risk-guided falsification to achieve both rigor and coverage. Our approach begins by constructing a human-interpretable abstraction of the RL policy using Comprehensible Abstract Policy Summarization (CAPS). This abstract graph, derived from offline trajectories, is both verifier-friendly, semantically meaningful, and can be used as input to Storm probabilistic model checker to verify satisfaction of temporal safety specifications. If the model checker identifies a violation, it will return an interpretable counterexample trace by which the policy fails the safety requirement. However, if no violation is detected, we cannot conclude satisfaction due to potential limitation in the abstraction and coverage of the offline dataset. In such cases, we estimate associated risk during model checking to guide a falsification strategy that prioritizes searching in high-risk states and regions underrepresented in the trajectory dataset. We further provide PAC-style guarantees on the likelihood of uncovering undetected violations. Finally, we incorporate a lightweight safety shield that switches to a fallback policy at runtime when such a risk exceeds a threshold, facilitating failure mitigation without retraining.","authors":["Tuan Le","Risal Shefin","Debashis Gupta","Thai Le","Sarra Alqahtani"],"url":"https://arxiv.org/abs/2506.03469"}
{"created":"2025-06-05","title":"Directional Non-Commutative Monoidal Embeddings for MNIST","abstract":"We present an empirical validation of the directional non-commutative monoidal embedding framework recently introduced in prior work~\\cite{Godavarti2025monoidal}. This framework defines learnable compositional embeddings using distinct non-commutative operators per dimension (axis) that satisfy an interchange law, generalizing classical one-dimensional transforms. Our primary goal is to verify that this framework can effectively model real data by applying it to a controlled, well-understood task: image classification on the MNIST dataset~\\cite{lecun1998gradient}. A central hypothesis for why the proposed monoidal embedding works well is that it generalizes the Discrete Fourier Transform (DFT)~\\cite{oppenheim1999discrete} by learning task-specific frequency components instead of using fixed basis frequencies. We test this hypothesis by comparing learned monoidal embeddings against fixed DFT-based embeddings on MNIST. The results show that as the embedding dimensionality decreases (e.g., from 32 to 8 to 2), the performance gap between the learned monoidal embeddings and fixed DFT-based embeddings on MNIST grows increasingly large. This comparison is used as an analytic tool to explain why the framework performs well: the learnable embeddings can capture the most discriminative spectral components for the task. Overall, our experiments confirm that directional non-commutative monoidal embeddings are highly effective for representing image data, offering a compact learned representation that retains high task performance. The code used in this work is available at https://github.com/mahesh-godavarti/directional_composition_mnist.","authors":["Mahesh Godavarti"],"url":"https://arxiv.org/abs/2506.03472"}
{"created":"2025-06-05","title":"MamFusion: Multi-Mamba with Temporal Fusion for Partially Relevant Video Retrieval","abstract":"Partially Relevant Video Retrieval (PRVR) is a challenging task in the domain of multimedia retrieval. It is designed to identify and retrieve untrimmed videos that are partially relevant to the provided query. In this work, we investigate long-sequence video content understanding to address information redundancy issues. Leveraging the outstanding long-term state space modeling capability and linear scalability of the Mamba module, we introduce a multi-Mamba module with temporal fusion framework (MamFusion) tailored for PRVR task. This framework effectively captures the state-relatedness in long-term video content and seamlessly integrates it into text-video relevance understanding, thereby enhancing the retrieval process. Specifically, we introduce Temporal T-to-V Fusion and Temporal V-to-T Fusion to explicitly model temporal relationships between text queries and video moments, improving contextual awareness and retrieval accuracy. Extensive experiments conducted on large-scale datasets demonstrate that MamFusion achieves state-of-the-art performance in retrieval effectiveness. Code is available at the link: https://github.com/Vision-Multimodal-Lab-HZCU/MamFusion.","authors":["Xinru Ying","Jiaqi Mo","Jingyang Lin","Canghong Jin","Fangfang Wang","Lina Wei"],"url":"https://arxiv.org/abs/2506.03473"}
{"created":"2025-06-05","title":"CORE: Constraint-Aware One-Step Reinforcement Learning for Simulation-Guided Neural Network Accelerator Design","abstract":"Simulation-based design space exploration (DSE) aims to efficiently optimize high-dimensional structured designs under complex constraints and expensive evaluation costs. Existing approaches, including heuristic and multi-step reinforcement learning (RL) methods, struggle to balance sampling efficiency and constraint satisfaction due to sparse, delayed feedback, and large hybrid action spaces. In this paper, we introduce CORE, a constraint-aware, one-step RL method for simulationguided DSE. In CORE, the policy agent learns to sample design configurations by defining a structured distribution over them, incorporating dependencies via a scaling-graph-based decoder, and by reward shaping to penalize invalid designs based on the feedback obtained from simulation. CORE updates the policy using a surrogate objective that compares the rewards of designs within a sampled batch, without learning a value function. This critic-free formulation enables efficient learning by encouraging the selection of higher-reward designs. We instantiate CORE for hardware-mapping co-design of neural network accelerators, demonstrating that it significantly improves sample efficiency and achieves better accelerator configurations compared to state-of-the-art baselines. Our approach is general and applicable to a broad class of discrete-continuous constrained design problems.","authors":["Yifeng Xiao","Yurong Xu","Ning Yan","Masood Mortazavi","Pierluigi Nuzzo"],"url":"https://arxiv.org/abs/2506.03474"}
{"created":"2025-06-05","title":"Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection","abstract":"Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that leads to dementia, and early intervention can greatly benefit from analyzing linguistic abnormalities. In this work, we explore the potential of Large Language Models (LLMs) as health assistants for AD diagnosis from patient-generated text using in-context learning (ICL), where tasks are defined through a few input-output examples. Empirical results reveal that conventional ICL methods, such as similarity-based selection, perform poorly for AD diagnosis, likely due to the inherent complexity of this task. To address this, we introduce Delta-KNN, a novel demonstration selection strategy that enhances ICL performance. Our method leverages a delta score to assess the relative gains of each training example, coupled with a KNN-based retriever that dynamically selects optimal \"representatives\" for a given input. Experiments on two AD detection datasets across three open-source LLMs demonstrate that Delta-KNN consistently outperforms existing ICL baselines. Notably, when using the Llama-3.1 model, our approach achieves new state-of-the-art results, surpassing even supervised classifiers.","authors":["Chuyuan Li","Raymond Li","Thalia S. Field","Giuseppe Carenini"],"url":"https://arxiv.org/abs/2506.03476"}
{"created":"2025-06-05","title":"Facial Appearance Capture at Home with Patch-Level Reflectance Prior","abstract":"Existing facial appearance capture methods can reconstruct plausible facial reflectance from smartphone-recorded videos. However, the reconstruction quality is still far behind the ones based on studio recordings. This paper fills the gap by developing a novel daily-used solution with a co-located smartphone and flashlight video capture setting in a dim room. To enhance the quality, our key observation is to solve facial reflectance maps within the data distribution of studio-scanned ones. Specifically, we first learn a diffusion prior over the Light Stage scans and then steer it to produce the reflectance map that best matches the captured images. We propose to train the diffusion prior at the patch level to improve generalization ability and training stability, as current Light Stage datasets are in ultra-high resolution but limited in data size. Tailored to this prior, we propose a patch-level posterior sampling technique to sample seamless full-resolution reflectance maps from this patch-level diffusion model. Experiments demonstrate our method closes the quality gap between low-cost and studio recordings by a large margin, opening the door for everyday users to clone themselves to the digital world. Our code will be released at https://github.com/yxuhan/DoRA.","authors":["Yuxuan Han","Junfeng Lyu","Kuan Sheng","Minghao Que","Qixuan Zhang","Lan Xu","Feng Xu"],"url":"https://arxiv.org/abs/2506.03478"}
{"created":"2025-06-05","title":"Heterogeneous Skeleton-Based Action Representation Learning","abstract":"Skeleton-based human action recognition has received widespread attention in recent years due to its diverse range of application scenarios. Due to the different sources of human skeletons, skeleton data naturally exhibit heterogeneity. The previous works, however, overlook the heterogeneity of human skeletons and solely construct models tailored for homogeneous skeletons. This work addresses the challenge of heterogeneous skeleton-based action representation learning, specifically focusing on processing skeleton data that varies in joint dimensions and topological structures. The proposed framework comprises two primary components: heterogeneous skeleton processing and unified representation learning. The former first converts two-dimensional skeleton data into three-dimensional skeleton via an auxiliary network, and then constructs a prompted unified skeleton using skeleton-specific prompts. We also design an additional modality named semantic motion encoding to harness the semantic information within skeletons. The latter module learns a unified action representation using a shared backbone network that processes different heterogeneous skeletons. Extensive experiments on the NTU-60, NTU-120, and PKU-MMD II datasets demonstrate the effectiveness of our method in various tasks of action understanding. Our approach can be applied to action recognition in robots with different humanoid structures.","authors":["Hongsong Wang","Xiaoyan Ma","Jidong Kuang","Jie Gui"],"url":"https://arxiv.org/abs/2506.03481"}
{"created":"2025-06-05","title":"APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training","abstract":"Large Language Models (LLMs) often require domain-specific fine-tuning to address targeted tasks, which risks degrading their general capabilities. Maintaining a balance between domain-specific enhancements and general model utility is a key challenge. This paper proposes a novel approach named APT (Weakness Case Acquisition and Iterative Preference Training) to enhance domain-specific performance with self-generated dis-preferred weakness data (bad cases and similar cases). APT uniquely focuses on training the model using only those samples where errors occur, alongside a small, similar set of samples retrieved for this purpose. This targeted training minimizes interference with the model's existing knowledge base, effectively retaining generic capabilities. Experimental results on the LLama-2 and Mistral-V0.3 models across various benchmarks demonstrate that APT ensures no reduction in generic capacity and achieves superior performance on downstream tasks compared to various existing methods. This validates our method as an effective strategy for enhancing domain-specific capabilities without sacrificing the model's broader applicability.","authors":["Jun Rao","Zepeng Lin","Xuebo Liu","Xiaopeng Ke","Lian Lian","Dong Jin","Shengjun Cheng","Jun Yu","Min Zhang"],"url":"https://arxiv.org/abs/2506.03483"}
{"created":"2025-06-05","title":"Explainable AI: XAI-Guided Context-Aware Data Augmentation","abstract":"Explainable AI (XAI) has emerged as a powerful tool for improving the performance of AI models, going beyond providing model transparency and interpretability. The scarcity of labeled data remains a fundamental challenge in developing robust and generalizable AI models, particularly for low-resource languages. Conventional data augmentation techniques introduce noise, cause semantic drift, disrupt contextual coherence, lack control, and lead to overfitting. To address these challenges, we propose XAI-Guided Context-Aware Data Augmentation. This novel framework leverages XAI techniques to modify less critical features while selectively preserving most task-relevant features. Our approach integrates an iterative feedback loop, which refines augmented data over multiple augmentation cycles based on explainability-driven insights and the model performance gain. Our experimental results demonstrate that XAI-SR-BT and XAI-PR-BT improve the accuracy of models on hate speech and sentiment analysis tasks by 6.6% and 8.1%, respectively, compared to the baseline, using the Amharic dataset with the XLM-R model. XAI-SR-BT and XAI-PR-BT outperform existing augmentation techniques by 4.8% and 5%, respectively, on the same dataset and model. Overall, XAI-SR-BT and XAI-PR-BT consistently outperform both baseline and conventional augmentation techniques across all tasks and models. This study provides a more controlled, interpretable, and context-aware solution to data augmentation, addressing critical limitations of existing augmentation techniques and offering a new paradigm shift for leveraging XAI techniques to enhance AI model training.","authors":["Melkamu Abay Mersha","Mesay Gemeda Yigezu","Atnafu Lambebo Tonja","Hassan Shakil","Samer Iskander","Olga Kolesnikova","Jugal Kalita"],"url":"https://arxiv.org/abs/2506.03484"}
{"created":"2025-06-05","title":"ProRank: Prompt Warmup via Reinforcement Learning for Small Language Models Reranking","abstract":"Reranking is fundamental to information retrieval and retrieval-augmented generation, with recent Large Language Models (LLMs) significantly advancing reranking quality. While recent advances with LLMs have significantly improved document reranking quality, current approaches primarily rely on large-scale LLMs (>7B parameters) through zero-shot prompting, presenting high computational costs. Small Language Models (SLMs) offer a promising alternative because of their efficiency, but our preliminary quantitative analysis reveals they struggle with understanding task prompts without fine-tuning. This limits their effectiveness for document reranking tasks. To address this issue, we introduce a novel two-stage training approach, ProRank, for SLM-based document reranking. First, we propose a prompt warmup stage using reinforcement learning GRPO to steer SLMs to understand task prompts and generate more accurate coarse-grained binary relevance scores for document reranking. Then, we continuously fine-tune the SLMs with a fine-grained score learning stage without introducing additional layers to further improve the reranking quality. Comprehensive experimental results demonstrate that the proposed ProRank consistently outperforms both the most advanced open-source and proprietary reranking models. Notably, our lightweight ProRank-0.5B model even surpasses the powerful 32B LLM reranking model on the BEIR benchmark, establishing that properly trained SLMs can achieve superior document reranking performance while maintaining computational efficiency.","authors":["Xianming Li","Aamir Shakir","Rui Huang","Julius Lipp","Jing Li"],"url":"https://arxiv.org/abs/2506.03487"}
{"created":"2025-06-05","title":"EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding","abstract":"The remarkable performance of Large language models (LLMs) relies heavily on the availability of abundant high-quality training data. However, the high cost of acquiring annotated data often prevents models from obtaining capabilities to tackle downstream tasks. In this paper, we introduce a novel method, EpiCoDe that boosts model performance in data-scarcity scenarios without extra training. We first employ model extrapolation to enhance a finetuned model with its inferior version, and then adopt contrastive decoding to further reduce predicted errors, by comparing the logit scores given by the extrapolated and the vanilla finetuned model. Experiments across three tasks over four different LLMs show that EpiCoDe consistently outperforms existing methods with significant and robust improvement. We also propose a new theoretical framework to reveal the mechanism behind contrastive decoding in data-scarcity scenarios, which further helps us better understand the effectiveness of EpiCoDe.","authors":["Mingxu Tao","Jie Hu","Mingchuan Yang","Yunhuai Liu","Dongyan Zhao","Yansong Feng"],"url":"https://arxiv.org/abs/2506.03489"}
{"created":"2025-06-05","title":"Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing","abstract":"Recently, knowledge editing (KE) has emerged as a promising approach to update specific facts in Large Language Models (LLMs) without the need for full retraining. Despite the effectiveness in general-domain benchmarks, their applicability to complex medical domain remains largely unexplored. Medical knowledge editing is particularly challenging, as it requires LLMs to internalize the knowledge and generalize to unseen scenarios for effective and interpretable decision-making. In this work, we propose a novel framework called MedEditBench to rigorously evaluate the effectiveness of existing KE methods in the medical domain. In MedEditBench, we introduce a new medical knowledge editing benchmark as well as three different knowledge editing paradigms, which are designed to assess the impact of different knowledge sources for editing. Our findings indicate that current KE methods result in only superficial memorization of the injected information, failing to generalize to new scenarios. To overcome this limitation, we present Self-Generated Rationale Editing (SGR-Edit), which utilizes model-derived rationales as the target knowledge for editing, thereby uncovering the underlying reasoning process and demonstrating significant improvements over existing KE approaches. Additionally, we offer deeper insights into medical knowledge editing, including the localization of medical knowledge in LLMs and the impact of sequential editing on evolving knowledge. This could provide practical guidance for implementing KE methods in real-world medical applications.","authors":["Shigeng Chen","Linhao Luo","Zhangchi Qiu","Yanan Cao","Carl Yang","Shirui Pan"],"url":"https://arxiv.org/abs/2506.03490"}
{"created":"2025-06-05","title":"Modeling Bulimia Nervosa in the Digital Age: The Role of Social Media","abstract":"Globalization has fundamentally reshaped societal dynamics, influencing how individuals interact and perceive themselves and others. One significant consequence is the evolving landscape of eating disorders such as bulimia nervosa (BN), which are increasingly driven not just by internal psychological factors but by broader sociocultural and digital contexts. While mathematical modeling has provided valuable insights, traditional frameworks often fall short in capturing the nuanced roles of social contagion, digital media, and adaptive behavior. This review synthesizes two decades of quantitative modeling efforts, including compartmental, stochastic, and delay-based approaches. We spotlight foundational work that conceptualizes BN as a socially transmissible condition and identify critical gaps, especially regarding the intensifying impact of social media. Drawing on behavioral epidemiology and the adaptive behavior framework by Fenichel et al., we advocate for a new generation of models that incorporate feedback mechanisms, content-driven influence functions, and dynamic network effects. This work outlines a roadmap for developing more realistic, data-informed models that can guide effective public health interventions in the digital era.","authors":["Brenda Murillo","Fabio Sanchez"],"url":"https://arxiv.org/abs/2506.03491"}
{"created":"2025-06-05","title":"Hive is PSPACE-Hard","abstract":"Hive is an abstract strategy game played on a table with hexagonal pieces. First published in 2001, it was and continues to be highly popular among both casual and competitive players. In this paper, we show that for a suitably generalized version of the game, the computational problem of determining whether a given player in an arbitrary position has a winning strategy is PSPACE-hard. We do this by reduction from a variant of Generalized Geography we call Formula Game Geography.","authors":["Dani\\\"el Andel","Benjamin Rin"],"url":"https://arxiv.org/abs/2506.03492"}
{"created":"2025-06-05","title":"Topology-Aware Graph Neural Network-based State Estimation for PMU-Unobservable Power Systems","abstract":"Traditional optimization-based techniques for time-synchronized state estimation (SE) often suffer from high online computational burden, limited phasor measurement unit (PMU) coverage, and presence of non-Gaussian measurement noise. Although conventional learning-based models have been developed to overcome these challenges, they are negatively impacted by topology changes and real-time data loss. This paper proposes a novel deep geometric learning approach based on graph neural networks (GNNs) to estimate the states of PMU-unobservable power systems. The proposed approach combines graph convolution and multi-head graph attention layers inside a customized end-to-end learning framework to handle topology changes and real-time data loss. An upper bound on SE error as a function of topology change is also derived. Experimental results for different test systems demonstrate superiority of the proposed customized GNN-SE (CGNN-SE) over traditional optimization-based techniques as well as conventional learning-based models in presence of topology changes, PMU failures, bad data, non-Gaussian measurement noise, and large system implementation.","authors":["Shiva Moshtagh","Behrouz Azimian","Mohammad Golgol","Anamitra Pal"],"url":"https://arxiv.org/abs/2506.03493"}
{"created":"2025-06-05","title":"Bridging the Artificial Intelligence Governance Gap: The United States' and China's Divergent Approaches to Governing General-Purpose Artificial Intelligence","abstract":"The United States and China are among the world's top players in the development of advanced artificial intelligence (AI) systems, and both are keen to lead in global AI governance and development. A look at U.S. and Chinese policy landscapes reveals differences in how the two countries approach the governance of general-purpose artificial intelligence (GPAI) systems. Three areas of divergence are notable for policymakers: the focus of domestic AI regulation, key principles of domestic AI regulation, and approaches to implementing international AI governance. As AI development continues, global conversation around AI has warned of global safety and security challenges posed by GPAI systems. Cooperation between the United States and China might be needed to address these risks, and understanding the implications of these differences might help address the broader challenges for international cooperation between the United States and China on AI safety and security.","authors":["Oliver Guest","Kevin Wei"],"url":"https://arxiv.org/abs/2506.03497"}
{"created":"2025-06-05","title":"Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing","abstract":"Content creation has dramatically progressed with the rapid advancement of large language models like ChatGPT and Claude. While this progress has greatly enhanced various aspects of life and work, it has also negatively affected certain areas of society. A recent survey revealed that nearly 30% of college students use generative AI to help write academic papers and reports. Most countermeasures treat the detection of AI-generated text as a binary classification task and thus lack robustness. This approach overlooks human involvement in the generation of content even though human-machine collaboration is becoming mainstream. Besides generating entire texts, people may use machines to complete or revise texts. Such human involvement varies case by case, which makes binary classification a less than satisfactory approach. We refer to this situation as participation detection obfuscation. We propose using BERTScore as a metric to measure human involvement in the generation process and a multi-task RoBERTa-based regressor trained on a token classification task to address this problem. To evaluate the effectiveness of this approach, we simulated academic-based scenarios and created a continuous dataset reflecting various levels of human involvement. All of the existing detectors we examined failed to detect the level of human involvement on this dataset. Our method, however, succeeded (F1 score of 0.9423 and a regressor mean squared error of 0.004). Moreover, it demonstrated some generalizability across generative models. Our code is available at https://github.com/gyc-nii/CAS-CS-and-dual-head-detector","authors":["Yuchen Guo","Zhicheng Dou","Huy H. Nguyen","Ching-Chun Chang","Saku Sugawara","Isao Echizen"],"url":"https://arxiv.org/abs/2506.03501"}
{"created":"2025-06-05","title":"CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model","abstract":"The denoising diffusion probabilistic model has become a mainstream generative model, achieving significant success in various computer vision tasks. Recently, there has been initial exploration of applying diffusion models to time series tasks. However, existing studies still face challenges in multi-scale feature alignment and generative capabilities across different entities and long-time scales. In this paper, we propose CHIME, a conditional hallucination and integrated multi-scale enhancement framework for time series diffusion models. By employing multi-scale decomposition and adaptive integration, CHIME captures the decomposed features of time series, achieving in-domain distribution alignment between generated and original samples. In addition, we introduce a feature hallucination module in the conditional denoising process, enabling the transfer of temporal features through the training of category-independent transformation layers. Experimental results on publicly available real-world datasets demonstrate that CHIME achieves state-of-the-art performance and exhibits excellent generative generalization capabilities in few-shot scenarios.","authors":["Yuxuan Chen","Haipeng Xie"],"url":"https://arxiv.org/abs/2506.03502"}
{"created":"2025-06-05","title":"Computational Architects of Society: Quantum Machine Learning for Social Rule Genesis","abstract":"The quantification of social science remains a longstanding challenge, largely due to the philosophical nature of its foundational theories. Although quantum computing has advanced rapidly in recent years, its relevance to social theory remains underexplored. Most existing research focuses on micro-cognitive models or philosophical analogies, leaving a gap in system-level applications of quantum principles to the analysis of social systems. This study addresses that gap by proposing a theoretical and computational framework that combines quantum mechanics with Generative AI to simulate the emergence and evolution of social norms. Drawing on core quantum concepts--such as superposition, entanglement, and probabilistic measurement--this research models society as a dynamic, uncertain system and sets up five ideal-type experiments. These scenarios are simulated using 25 generative agents, each assigned evolving roles as compliers, resistors, or enforcers. Within a simulated environment monitored by a central observer (the Watcher), agents interact, respond to surveillance, and adapt to periodic normative disruptions. These interactions allow the system to self-organize under external stress and reveal emergent patterns. Key findings show that quantum principles, when integrated with generative AI, enable the modeling of uncertainty, emergence, and interdependence in complex social systems. Simulations reveal patterns including convergence toward normative order, the spread of resistance, and the spontaneous emergence of new equilibria in social rules. In conclusion, this study introduces a novel computational lens that lays the groundwork for a quantum-informed social theory. It offers interdisciplinary insights into how society can be understood not just as a structure to observe but as a dynamic system to simulate and redesign through quantum technologies.","authors":["Shan Shan"],"url":"https://arxiv.org/abs/2506.03503"}
{"created":"2025-06-05","title":"Beyond C/C++: Probabilistic and LLM Methods for Next-Generation Software Reverse Engineering","abstract":"This proposal discusses the growing challenges in reverse engineering modern software binaries, particularly those compiled from newer system programming languages such as Rust, Go, and Mojo. Traditional reverse engineering techniques, developed with a focus on C and C++, fall short when applied to these newer languages due to their reliance on outdated heuristics and failure to fully utilize the rich semantic information embedded in binary programs. These challenges are exacerbated by the limitations of current data-driven methods, which are susceptible to generating inaccurate results, commonly referred to as hallucinations. To overcome these limitations, we propose a novel approach that integrates probabilistic binary analysis with fine-tuned large language models (LLMs). Our method systematically models the uncertainties inherent in reverse engineering, enabling more accurate reasoning about incomplete or ambiguous information. By incorporating LLMs, we extend the analysis beyond traditional heuristics, allowing for more creative and context-aware inferences, particularly for binaries from diverse programming languages. This hybrid approach not only enhances the robustness and accuracy of reverse engineering efforts but also offers a scalable solution adaptable to the rapidly evolving landscape of software development.","authors":["Zhuo Zhuo","Xiangyu Zhang"],"url":"https://arxiv.org/abs/2506.03504"}
{"created":"2025-06-05","title":"Software Bill of Materials in Software Supply Chain Security A Systematic Literature Review","abstract":"Software Bill of Materials (SBOMs) are increasingly regarded as essential tools for securing software supply chains (SSCs), yet their real-world use and adoption barriers remain poorly understood. This systematic literature review synthesizes evidence from 40 peer-reviewed studies to evaluate how SBOMs are currently used to bolster SSC security. We identify five primary application areas: vulnerability management, transparency, component assessment, risk assessment, and SSC integrity. Despite clear promise, adoption is hindered by significant barriers: generation tooling, data privacy, format/standardization, sharing/distribution, cost/overhead, vulnerability exploitability, maintenance, analysis tooling, false positives, hidden packages, and tampering. To structure our analysis, we map these barriers to the ISO/IEC 25019:2023 Quality-in-Use model, revealing critical deficiencies in SBOM trustworthiness, usability, and suitability for security tasks. We also highlight key gaps in the literature. These include the absence of applying machine learning techniques to assess SBOMs and limited evaluation of SBOMs and SSCs using software quality assurance techniques. Our findings provide actionable insights for researchers, tool developers, and practitioners seeking to advance SBOM-driven SSC security and lay a foundation for future work at the intersection of SSC assurance, automation, and empirical software engineering.","authors":["Eric O'Donoghue","Yvette Hastings","Ernesto Ortiz","A. Redempta Manzi Muneza"],"url":"https://arxiv.org/abs/2506.03507"}
{"created":"2025-06-05","title":"A Model-Data Dual-Driven Resource Allocation Scheme for IREE Oriented 6G Networks","abstract":"The rapid and substantial fluctuations in wireless network capacity and traffic demand, driven by the emergence of 6G technologies, have exacerbated the issue of traffic-capacity mismatch, raising concerns about wireless network energy consumption. To address this challenge, we propose a model-data dual-driven resource allocation (MDDRA) algorithm aimed at maximizing the integrated relative energy efficiency (IREE) metric under dynamic traffic conditions. Unlike conventional model-driven or data-driven schemes, the proposed MDDRA framework employs a model-driven Lyapunov queue to accumulate long-term historical mismatch information and a data-driven Graph Radial bAsis Fourier (GRAF) network to predict the traffic variations under incomplete data, and hence eliminates the reliance on high-precision models and complete spatial-temporal traffic data. We establish the universal approximation property of the proposed GRAF network and provide convergence and complexity analysis for the MDDRA algorithm. Numerical experiments validate the performance gains achieved through the data-driven and model-driven components. By analyzing IREE and EE curves under diverse traffic conditions, we recommend that network operators shall spend more efforts to balance the traffic demand and the network capacity distribution to ensure the network performance, particularly in scenarios with large speed limits and higher driving visibility.","authors":["Tao Yu","Simin Wang","Shunqing Zhang","Xiaojing Chen","Zi Xu","Xin Wang","Jiandong Li","Junyu Liu","Sihai Zhang"],"url":"https://arxiv.org/abs/2506.03508"}
{"created":"2025-06-05","title":"Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information","abstract":"How can we accelerate large language models(LLMs) without sacrificing accuracy? The slow inference speed of LLMs hinders us to benefit from their remarkable performance in diverse applications. This is mainly because numerous sublayers are stacked together in LLMs. Sublayer pruning compresses and expedites LLMs via removing unnecessary sublayers. However, existing sublayer pruning algorithms are limited in accuracy since they naively select sublayers to prune, overlooking the different characteristics of each sublayer. In this paper, we propose SPRINT (Sublayer PRuning wIth LateNcy and Tunability Information), an accurate sublayer pruning method for LLMs. SPRINT accurately selects a target sublayer to prune by considering 1) the amount of latency reduction after pruning and 2) the tunability of sublayers. SPRINT iteratively prunes redundant sublayers and swiftly tunes the parameters of remaining sublayers. Experiments show that SPRINT achieves the best accuracy-speedup trade-off, exhibiting up to 23.88%p higher accuracy on zero-shot commonsense reasoning benchmarks compared to existing pruning algorithms.","authors":["Seungcheol Park","Sojin Lee","Jongjin Kim","Jinsik Lee","Hyunjik Jo","U Kang"],"url":"https://arxiv.org/abs/2506.03510"}
{"created":"2025-06-05","title":"EDCFlow: Exploring Temporally Dense Difference Maps for Event-based Optical Flow Estimation","abstract":"Recent learning-based methods for event-based optical flow estimation utilize cost volumes for pixel matching but suffer from redundant computations and limited scalability to higher resolutions for flow refinement. In this work, we take advantage of the complementarity between temporally dense feature differences of adjacent event frames and cost volume and present a lightweight event-based optical flow network (EDCFlow) to achieve high-quality flow estimation at a higher resolution. Specifically, an attention-based multi-scale temporal feature difference layer is developed to capture diverse motion patterns at high resolution in a computation-efficient manner. An adaptive fusion of high-resolution difference motion features and low-resolution correlation motion features is performed to enhance motion representation and model generalization. Notably, EDCFlow can serve as a plug-and-play refinement module for RAFT-like event-based methods to enhance flow details. Extensive experiments demonstrate that EDCFlow achieves better performance with lower complexity compared to existing methods, offering superior generalization.","authors":["Daikun Liu","Lei Cheng","Teng Wang","changyin Sun"],"url":"https://arxiv.org/abs/2506.03512"}
{"created":"2025-06-05","title":"SemNav: A Model-Based Planner for Zero-Shot Object Goal Navigation Using Vision-Foundation Models","abstract":"Object goal navigation is a fundamental task in embodied AI, where an agent is instructed to locate a target object in an unexplored environment. Traditional learning-based methods rely heavily on large-scale annotated data or require extensive interaction with the environment in a reinforcement learning setting, often failing to generalize to novel environments and limiting scalability. To overcome these challenges, we explore a zero-shot setting where the agent operates without task-specific training, enabling more scalable and adaptable solution. Recent advances in Vision Foundation Models (VFMs) offer powerful capabilities for visual understanding and reasoning, making them ideal for agents to comprehend scenes, identify relevant regions, and infer the likely locations of objects. In this work, we present a zero-shot object goal navigation framework that integrates the perceptual strength of VFMs with a model-based planner that is capable of long-horizon decision making through frontier exploration. We evaluate our approach on the HM3D dataset using the Habitat simulator and demonstrate that our method achieves state-of-the-art performance in terms of success weighted by path length for zero-shot object goal navigation.","authors":["Arnab Debnath","Gregory J. Stein","Jana Kosecka"],"url":"https://arxiv.org/abs/2506.03516"}
{"created":"2025-06-05","title":"DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models","abstract":"Direct Preference Optimization (DPO) has recently been applied as a post-training technique for text-to-video diffusion models. To obtain training data, annotators are asked to provide preferences between two videos generated from independent noise. However, this approach prohibits fine-grained comparisons, and we point out that it biases the annotators towards low-motion clips as they often contain fewer visual artifacts. In this work, we introduce DenseDPO, a method that addresses these shortcomings by making three contributions. First, we create each video pair for DPO by denoising corrupted copies of a ground truth video. This results in aligned pairs with similar motion structures while differing in local details, effectively neutralizing the motion bias. Second, we leverage the resulting temporal alignment to label preferences on short segments rather than entire clips, yielding a denser and more precise learning signal. With only one-third of the labeled data, DenseDPO greatly improves motion generation over vanilla DPO, while matching it in text alignment, visual quality, and temporal consistency. Finally, we show that DenseDPO unlocks automatic preference annotation using off-the-shelf Vision Language Models (VLMs): GPT accurately predicts segment-level preferences similar to task-specifically fine-tuned video reward models, and DenseDPO trained on these labels achieves performance close to using human labels.","authors":["Ziyi Wu","Anil Kag","Ivan Skorokhodov","Willi Menapace","Ashkan Mirzaei","Igor Gilitschenski","Sergey Tulyakov","Aliaksandr Siarohin"],"url":"https://arxiv.org/abs/2506.03517"}
{"created":"2025-06-05","title":"Two self-starting single-solve third-order explicit integration algorithms for second-order nonlinear dynamics","abstract":"The single-step explicit time integration methods have long been valuable for solving large-scale nonlinear structural dynamic problems, classified into single-solve and multi-sub-step approaches. However, no existing explicit single-solve methods achieve third-order accuracy. The paper addresses this gap by proposing two new third-order explicit algorithms developed within the framework of self-starting single-solve time integration algorithms, which incorporates 11 algorithmic parameters. The study reveals that fully explicit methods with single-solve cannot reach third-order accuracy for general dynamic problems. Consequently, two novel algorithms are proposed: Algorithm 1 is a fully explicit scheme that achieves third-order accuracy in displacement and velocity for undamped problems; Algorithm 2, which employs implicit treatment of velocity and achieves third-order accuracy for general dynamic problems. Across a suite of both linear and nonlinear benchmarks, the new algorithms consistently outperform existing single-solve explicit methods in accuracy. Their built-in numerical dissipation effectively filters out spurious high-frequency components, as demonstrated by two wave propagation problems. Finally, when applied to the realistic engineering problem, both of them deliver superior numerical precision at minimal computational cost.","authors":["Liu Yaokun","Li Jinze","Yu Kaiping"],"url":"https://arxiv.org/abs/2506.03518"}
{"created":"2025-06-05","title":"An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals","abstract":"Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue systems to optimize dialogue policy, but it struggles to balance exploration and exploitation due to the high dimensionality of state and action spaces. This challenge often results in local optima or poor convergence. Evolutionary Algorithms (EAs) have been proven to effectively explore the solution space of neural networks by maintaining population diversity. Inspired by this, we innovatively combine the global search capabilities of EA with the local optimization of DRL to achieve a balance between exploration and exploitation. Nevertheless, the inherent flexibility of natural language in dialogue tasks complicates this direct integration, leading to prolonged evolutionary times. Thus, we further propose an elite individual injection mechanism to enhance EA's search efficiency by adaptively introducing best-performing individuals into the population. Experiments across four datasets show that our approach significantly improves the balance between exploration and exploitation, boosting performance. Moreover, the effectiveness of the EII mechanism in reducing exploration time has been demonstrated, achieving an efficient integration of EA and DRL on task-oriented dialogue policy tasks.","authors":["Yangyang Zhao","Ben Niu","Libo Qin","Shihan Wang"],"url":"https://arxiv.org/abs/2506.03519"}
{"created":"2025-06-05","title":"VChatter: Exploring Generative Conversational Agents for Simulating Exposure Therapy to Reduce Social Anxiety","abstract":"Many people struggle with social anxiety, feeling fear, or even physically uncomfortable in social situations like talking to strangers. Exposure therapy, a clinical method that gradually and repeatedly exposes individuals to the source of their fear and helps them build coping mechanisms, can reduce social anxiety but traditionally requires human therapists' guidance and constructions of situations. In this paper, we developed a multi-agent system VChatter to explore large language models(LLMs)-based conversational agents for simulating exposure therapy with users. Based on a survey study (N=36) and an expert interview, VChatter includes an Agent-P, which acts as a psychotherapist to design the exposure therapy plans for users, and two Agent-Hs, which can take on different interactive roles in low, medium, and high exposure scenarios. A six-day qualitative study (N=10) showcases VChatter's usefulness in reducing users' social anxiety, feelings of isolation, and avoidance of social interactions. We demonstrated the feasibility of using LLMs-based conversational agents to simulate exposure therapy for addressing social anxiety and discussed future concerns for designing agents tailored to social anxiety.","authors":["Han Zhang","KaWing Tsang","Zhenhui Peng"],"url":"https://arxiv.org/abs/2506.03520"}
{"created":"2025-06-05","title":"Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation","abstract":"Universal Domain Adaptation (UniDA) focuses on transferring source domain knowledge to the target domain under both domain shift and unknown category shift. Its main challenge lies in identifying common class samples and aligning them. Current methods typically obtain target domain semantics centers from an unconstrained continuous image representation space. Due to domain shift and the unknown number of clusters, these centers often result in complex and less robust alignment algorithm. In this paper, based on vision-language models, we search for semantic centers in a semantically meaningful and discrete text representation space. The constrained space ensures almost no domain bias and appropriate semantic granularity for these centers, enabling a simple and robust adaptation algorithm. Specifically, we propose TArget Semantics Clustering (TASC) via Text Representations, which leverages information maximization as a unified objective and involves two stages. First, with the frozen encoders, a greedy search-based framework is used to search for an optimal set of text embeddings to represent target semantics. Second, with the search results fixed, encoders are refined based on gradient descent, simultaneously achieving robust domain alignment and private class clustering. Additionally, we propose Universal Maximum Similarity (UniMS), a scoring function tailored for detecting open-set samples in UniDA. Experimentally, we evaluate the universality of UniDA algorithms under four category shift scenarios. Extensive experiments on four benchmarks demonstrate the effectiveness and robustness of our method, which has achieved state-of-the-art performance.","authors":["Weinan He","Zilei Wang","Yixin Zhang"],"url":"https://arxiv.org/abs/2506.03521"}
{"created":"2025-06-05","title":"Path Generation and Evaluation in Video Games: A Nonparametric Statistical Approach","abstract":"Navigation path traces play a crucial role in video game design, serving as a vital resource for both enhancing player engagement and fine-tuning non-playable character behavior. Generating such paths with human-like realism can enrich the overall gaming experience, and evaluating path traces can provide game designers insights into player interactions. Despite the impressive recent advancements in deep learning-based generative modeling, the video game industry hesitates to adopt such models for path generation, often citing their complex training requirements and interpretability challenges. To address these problems, we propose a novel path generation and evaluation approach that is grounded in principled nonparametric statistics and provides precise control while offering interpretable insights. Our path generation method fuses two statistical techniques: (1) nonparametric model-free transformations that capture statistical characteristics of path traces through time; and (2) copula models that capture statistical dependencies in space. For path evaluation, we adapt a nonparametric three-sample hypothesis test designed to determine if the generated paths are overfit (mimicking the original data too closely) or underfit (diverging too far from it). We demonstrate the precision and reliability of our proposed methods with empirical analysis on two existing gaming benchmarks to showcase controlled generation of diverse navigation paths. Notably, our novel path generator can be fine-tuned with user controllable parameters to create navigation paths that exhibit varying levels of human-likeness in contrast to those produced by neural network-based agents. The code is available at https://github.com/daniel-campa/mf-copula.","authors":["Daniel Campa","Mehdi Saeedi","Ian Colbert","Srinjoy Das"],"url":"https://arxiv.org/abs/2506.03522"}
{"created":"2025-06-05","title":"TokAlign: Efficient Vocabulary Adaptation via Token Alignment","abstract":"Tokenization serves as a foundational step for Large Language Models (LLMs) to process text. In new domains or languages, the inefficiency of the tokenizer will slow down the training and generation of LLM. The mismatch in vocabulary also hinders deep knowledge transfer between LLMs like token-level distillation. To mitigate this gap, we propose an efficient method named TokAlign to replace the vocabulary of LLM from the token co-occurrences view, and further transfer the token-level knowledge between models. It first aligns the source vocabulary to the target one by learning a one-to-one mapping matrix for token IDs. Model parameters, including embeddings, are rearranged and progressively fine-tuned for the new vocabulary. Our method significantly improves multilingual text compression rates and vocabulary initialization for LLMs, decreasing the perplexity from 3.4$\\text{e}^2$ of strong baseline methods to 1.2$\\text{e}^2$ after initialization. Experimental results on models across multiple parameter scales demonstrate the effectiveness and generalization of TokAlign, which costs as few as 5k steps to restore the performance of the vanilla model. After unifying vocabularies between LLMs, token-level distillation can remarkably boost (+4.4% than sentence-level distillation) the base model, costing only 235M tokens.","authors":["Chong Li","Jiajun Zhang","Chengqing Zong"],"url":"https://arxiv.org/abs/2506.03523"}
{"created":"2025-06-05","title":"Seed-Coder: Let the Code Model Curate Data for Itself","abstract":"Code data in large language model (LLM) pretraining is recognized crucial not only for code-related tasks but also for enhancing general intelligence of LLMs. Current open-source LLMs often heavily rely on human effort to produce their code pretraining data, such as employing hand-crafted filtering rules tailored to individual programming languages, or using human-annotated data to train quality filters. However, these approaches are inherently limited in scalability, prone to subjective biases, and costly to extend and maintain across diverse programming languages. To address these challenges, we introduce Seed-Coder, a series of open-source LLMs comprising base, instruct and reasoning models of 8B size, minimizing human involvement in data construction. Our code pretraining data is produced by a model-centric data pipeline, which predominantly leverages LLMs for scoring and filtering code data. The instruct model is further trained via supervised fine-tuning and preference optimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT) reinforcement learning to improve multi-step code reasoning. Seed-Coder achieves state-of-the-art results among open-source models of similar size and even surpasses some much larger models, demonstrating superior performance in code generation, code completion, code editing, code reasoning, and software engineering tasks.","authors":["Yuyu Zhang","Jing Su","Yifan Sun","Chenguang Xi","Xia Xiao","Shen Zheng","Anxiang Zhang","Kaibo Liu","Daoguang Zan","Tao Sun","Jinhua Zhu","Shulin Xin","Dong Huang","Yetao Bai","Lixin Dong","Chao Li","Jianchong Chen","Hanzhi Zhou","Yifan Huang","Guanghan Ning","Xierui Song","Jiaze Chen","Siyao Liu","Kai Shen","Liang Xiang","Yonghui Wu"],"url":"https://arxiv.org/abs/2506.03524"}
{"created":"2025-06-05","title":"Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning","abstract":"Recent advances in Chain-of-Thought (CoT) reasoning have improved complex video understanding, but existing methods often struggle to adapt to domain-specific skills (e.g., event detection, spatial relation understanding, emotion understanding) over various video content. To address this, we propose Video-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructs and leverages skill-aware CoT supervisions for domain-adaptive video reasoning. First, we construct skill-based CoT annotations: we extract domain-relevant reasoning skills from training questions, cluster them into a shared skill taxonomy, and create detailed multi-step CoT rationale tailored to each video-question pair for training. Second, we introduce a skill-specific expert learning framework. Each expert module specializes in a subset of reasoning skills and is trained with lightweight adapters using the collected CoT supervision. We demonstrate the effectiveness of the proposed approach on three video understanding benchmarks, where Video-SKoT consistently outperforms strong baselines. We also provide in-depth analyses on comparing different CoT annotation pipelines and learned skills over multiple video domains.","authors":["Daeun Lee","Jaehong Yoon","Jaemin Cho","Mohit Bansal"],"url":"https://arxiv.org/abs/2506.03525"}
{"created":"2025-06-05","title":"A randomized progressive iterative regularization method for data fitting problems","abstract":"In this work, we investigate data fitting problems with random noises. A randomized progressive iterative regularization method is proposed. It works well for large-scale matrix computations and converges in expectation to the least-squares solution. Furthermore, we present an optimal estimation for the regularization parameter, which inspires the construction of self-consistent algorithms without prior information. The numerical results confirm the theoretical analysis and show the performance in curve and surface fittings.","authors":["Dakang Cen","Wenlong Zhang","Junbin Zhong"],"url":"https://arxiv.org/abs/2506.03526"}
{"created":"2025-06-05","title":"Distinguishing True Influence from Hyperprolificity with Citation Distance","abstract":"Accurately evaluating scholarly influence is essential for fair academic assessment, yet traditional bibliometric indicators - dominated by publication and citation counts - often favor hyperprolific authors over those with deeper, long-term impact. We propose the x-index, a novel citation-based metric that conceptualizes citation as a process of knowledge diffusion and incorporates citation distance to reflect the structural reach of scholarly work. By weighting citations according to the collaborative proximity between citing and cited authors, the x-index captures both the depth and breadth of influence within evolving academic networks. Empirical analyses show that the x-index significantly improves the rankings of Turing Award recipients while reducing those of hyperprolific authors, better aligning rankings with recognized academic merit. It also demonstrates superior discriminatory power among early-career researchers and reveals stronger sensitivity to institutional research quality. These results suggest that the x-index offers a more equitable and forward-looking alternative to existing metrics, with practical applications in talent identification, funding decisions, and academic recommendation systems.","authors":["Lu Li","Yun Wan","Feng Xiao"],"url":"https://arxiv.org/abs/2506.03527"}
{"created":"2025-06-05","title":"How Far Are We from Predicting Missing Modalities with Foundation Models?","abstract":"Multimodal foundation models have demonstrated impressive capabilities across diverse tasks. However, their potential as plug-and-play solutions for missing modality prediction remains underexplored. To investigate this, we categorize existing approaches into three representative paradigms, encompassing a total of 42 model variants, and conduct a comprehensive evaluation in terms of prediction accuracy and adaptability to downstream tasks. Our analysis reveals that current foundation models often fall short in two critical aspects: (i) fine-grained semantic extraction from the available modalities, and (ii) robust validation of generated modalities. These limitations lead to suboptimal and, at times, misaligned predictions. To address these challenges, we propose an agentic framework tailored for missing modality prediction. This framework dynamically formulates modality-aware mining strategies based on the input context, facilitating the extraction of richer and more discriminative semantic features. In addition, we introduce a \\textit{self-refinement mechanism}, which iteratively verifies and enhances the quality of generated modalities through internal feedback. Experimental results show that our method reduces FID for missing image prediction by at least 14% and MER for missing text prediction by at least 10% compared to baselines.","authors":["Guanzhou Ke","Yi Xie","Xiaoli Wang","Guoqing Chao","Bo Wang","Shengfeng He"],"url":"https://arxiv.org/abs/2506.03530"}
{"created":"2025-06-05","title":"Conformal Mixed-Integer Constraint Learning with Feasibility Guarantees","abstract":"We propose Conformal Mixed-Integer Constraint Learning (C-MICL), a novel framework that provides probabilistic feasibility guarantees for data-driven constraints in optimization problems. While standard Mixed-Integer Constraint Learning methods often violate the true constraints due to model error or data limitations, our C-MICL approach leverages conformal prediction to ensure feasible solutions are ground-truth feasible. This guarantee holds with probability at least $1{-}\\alpha$, under a conditional independence assumption. The proposed framework supports both regression and classification tasks without requiring access to the true constraint function, while avoiding the scalability issues associated with ensemble-based heuristics. Experiments on real-world applications demonstrate that C-MICL consistently achieves target feasibility rates, maintains competitive objective performance, and significantly reduces computational cost compared to existing methods. Our work bridges mathematical optimization and machine learning, offering a principled approach to incorporate uncertainty-aware constraints into decision-making with rigorous statistical guarantees.","authors":["Daniel Ovalle","Lorenz T. Biegler","Ignacio E. Grossmann","Carl D. Laird","Mateo Dulce Rubio"],"url":"https://arxiv.org/abs/2506.03531"}
{"created":"2025-06-05","title":"GA-S$^3$: Comprehensive Social Network Simulation with Group Agents","abstract":"Social network simulation is developed to provide a comprehensive understanding of social networks in the real world, which can be leveraged for a wide range of applications such as group behavior emergence, policy optimization, and business strategy development. However, billions of individuals and their evolving interactions involved in social networks pose challenges in accurately reflecting real-world complexities. In this study, we propose a comprehensive Social Network Simulation System (GA-S3) that leverages newly designed Group Agents to make intelligent decisions regarding various online events. Unlike other intelligent agents that represent an individual entity, our group agents model a collection of individuals exhibiting similar behaviors, facilitating the simulation of large-scale network phenomena with complex interactions at a manageable computational cost. Additionally, we have constructed a social network benchmark from 2024 popular online events that contains fine-grained information on Internet traffic variations. The experiment demonstrates that our approach is capable of achieving accurate and highly realistic prediction results. Code is open at https://github.com/AI4SS/GAS-3.","authors":["Yunyao Zhang","Zikai Song","Hang Zhou","Wenfeng Ren","Yi-Ping Phoebe Chen","Junqing Yu","Wei Yang"],"url":"https://arxiv.org/abs/2506.03532"}
{"created":"2025-06-05","title":"Go-Browse: Training Web Agents with Structured Exploration","abstract":"One of the fundamental problems in digital agents is their lack of understanding of their environment. For instance, a web browsing agent may get lost in unfamiliar websites, uncertain what pages must be visited to achieve its goals. To address this, we propose Go-Browse, a method for automatically collecting diverse and realistic web agent data at scale through structured exploration of web environments. Go-Browse achieves efficient exploration by framing data collection as a graph search, enabling reuse of information across exploration episodes. We instantiate our method on the WebArena benchmark, collecting a dataset of 10K successful task-solving trajectories and 40K interaction steps across 100 URLs. Fine-tuning a 7B parameter language model on this dataset achieves a success rate of 21.7% on the WebArena benchmark, beating GPT-4o mini by 2.4% and exceeding current state-of-the-art results for sub-10B parameter models by 2.9%.","authors":["Apurva Gandhi","Graham Neubig"],"url":"https://arxiv.org/abs/2506.03533"}
{"created":"2025-06-05","title":"Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented Code Generation","abstract":"Current research on large language models (LLMs) with retrieval-augmented code generation (RACG) mainly focuses on single-language settings, leaving cross-lingual effectiveness and security unexplored. Multi-lingual RACG systems are valuable for migrating code-bases across programming languages (PLs), yet face risks from error (e.g. adversarial data corruption) propagation in cross-lingual transfer. We construct a dataset spanning 13 PLs with nearly 14k instances to explore utility and robustness of multi-lingual RACG systems. Our investigation reveals four key insights: (1) Effectiveness: multi-lingual RACG significantly enhances multi-lingual code LLMs generation; (2) Inequality: Java demonstrate superior cross-lingual utility over Python in RACG; (3) Robustness: Adversarial attacks degrade performance significantly in mono-lingual RACG but show mitigated impacts in cross-lingual scenarios; Counterintuitively, perturbed code may improve RACG in cross-lingual scenarios; (4) Specialization: Domain-specific code retrievers outperform significantly general text retrievers. These findings establish foundation for developing effective and secure multi-lingual code assistants.","authors":["Qiming Zhu","Jialun Cao","Xuanang Chen","Yaojie Lu","Hongyu Lin","Xianpei Han","Le Sun","Shing-Chi Cheung"],"url":"https://arxiv.org/abs/2506.03535"}
{"created":"2025-06-05","title":"Robust Position Estimation by Rao-Blackwellized Particle Filter without Integer Ambiguity Resolution in Urban Environments","abstract":"This study proposes a centimeter-accurate positioning method that utilizes a Rao-Blackwellized particle filter (RBPF) without requiring integer ambiguity resolution in global navigation satellite system (GNSS) carrier phase measurements. The conventional positioning method employing a particle filter (PF) eliminates the necessity for ambiguity resolution by calculating the likelihood from the residuals of the carrier phase based on the particle position. However, this method encounters challenges, particularly in urban environments characterized by non-line-of-sight (NLOS) multipath errors. In such scenarios, PF tracking may fail due to the degradation of velocity estimation accuracy used for state transitions, thereby complicating subsequent position estimation. To address this issue, we apply Rao-Blackwellization to the conventional PF framework, treating position and velocity as distinct states and employing the Kalman filter for velocity estimation. This approach enhances the accuracy of velocity estimation and, consequently, the precision of position estimation. Moreover, the proposed method rejects NLOS multipath signals based on the pseudorange residuals at each particle position during the velocity estimation step. This process not only enhances velocity accuracy, but also preserves particle diversity by allowing particles to transition to unique states with varying velocities. Consequently, particles are more likely to cluster around the true position, thereby enabling more accurate position estimation. Vehicular experiments in urban environments demonstrated the effectiveness of proposed method in achieving a higher positioning accuracy than conventional PF-based and conventional GNSS positioning methods.","authors":["Daiki Niimi","An Fujino","Taro Suzuki","Junichi Meguro"],"url":"https://arxiv.org/abs/2506.03537"}
{"created":"2025-06-05","title":"Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting","abstract":"3D reconstruction from in-the-wild images remains a challenging task due to inconsistent lighting conditions and transient distractors. Existing methods typically rely on heuristic strategies to handle the low-quality training data, which often struggle to produce stable and consistent reconstructions, frequently resulting in visual artifacts. In this work, we propose Asymmetric Dual 3DGS, a novel framework that leverages the stochastic nature of these artifacts: they tend to vary across different training runs due to minor randomness. Specifically, our method trains two 3D Gaussian Splatting (3DGS) models in parallel, enforcing a consistency constraint that encourages convergence on reliable scene geometry while suppressing inconsistent artifacts. To prevent the two models from collapsing into similar failure modes due to confirmation bias, we introduce a divergent masking strategy that applies two complementary masks: a multi-cue adaptive mask and a self-supervised soft mask, which leads to an asymmetric training process of the two models, reducing shared error modes. In addition, to improve the efficiency of model training, we introduce a lightweight variant called Dynamic EMA Proxy, which replaces one of the two models with a dynamically updated Exponential Moving Average (EMA) proxy, and employs an alternating masking strategy to preserve divergence. Extensive experiments on challenging real-world datasets demonstrate that our method consistently outperforms existing approaches while achieving high efficiency. Codes and trained models will be released.","authors":["Chengqi Li","Zhihao Shi","Yangdi Lu","Wenbo He","Xiangyu Xu"],"url":"https://arxiv.org/abs/2506.03538"}
{"created":"2025-06-05","title":"Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement","abstract":"Large Language Models (LLMs) continue to set new standards in knowledge-intensive and complex reasoning tasks, yet their high computational demands limit widespread adoption. While distilling large models into smaller ones offers a sustainable solution, current techniques--such as static knowledge distillation, resource-intensive reinforcement learning from human feedback, or limited self-reflection--struggle to yield substantial and lasting performance gains. In this paper, we present a novel Debate and Reflect (D&amp;R) framework that orchestrates multi-turn debates between smaller models and stronger teacher models, eliciting actionable feedback (e.g., error analysis, corrective strategies) to guide student models. Further, we introduce Tree-structured Direct Preference Optimization (T-DPO) to efficiently leverage these debate logs, organizing interactions into a hierarchical format for effective training. Empirical evaluations across diverse NLP benchmarks demonstrate that our approach significantly improves smaller-model accuracy, robustness, and generalization, outperforming conventional baselines by a large margin.","authors":["Xiaofeng Zhou","Heyan Huang","Lizi Liao"],"url":"https://arxiv.org/abs/2506.03541"}
{"created":"2025-06-05","title":"Learning Monotonic Probabilities with a Generative Cost Model","abstract":"In many machine learning tasks, it is often necessary for the relationship between input and output variables to be monotonic, including both strictly monotonic and implicitly monotonic relationships. Traditional methods for maintaining monotonicity mainly rely on construction or regularization techniques, whereas this paper shows that the issue of strict monotonic probability can be viewed as a partial order between an observable revenue variable and a latent cost variable. This perspective enables us to reformulate the monotonicity challenge into modeling the latent cost variable. To tackle this, we introduce a generative network for the latent cost variable, termed the Generative Cost Model (GCM), which inherently addresses the strict monotonic problem, and propose the Implicit Generative Cost Model (IGCM) to address the implicit monotonic problem. We further validate our approach with a numerical simulation of quantile regression and conduct multiple experiments on public datasets, showing that our method significantly outperforms existing monotonic modeling techniques. The code for our experiments can be found at https://github.com/tyxaaron/GCM.","authors":["Yongxiang Tang","Yanhua Cheng","Xiaocheng Liu","Chenchen Jiao","Yanxiang Zeng","Ning Luo","Pengjia Yuan","Xialong Liu","Peng Jiang"],"url":"https://arxiv.org/abs/2506.03542"}
{"created":"2025-06-05","title":"CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications","abstract":"Current large language model (LLM) agents lack authentic human psychological processes necessary for genuine digital twins and social AI applications. To address this limitation, we present a computational implementation of Global Workspace Theory (GNWT) that integrates human cognitive architecture principles into LLM agents, creating specialized sub-agents for emotion, memory, social norms, planning, and goal-tracking coordinated through a global workspace mechanism. However, authentic digital twins require accurate personality initialization. We therefore develop a novel adventure-based personality test that evaluates true personality through behavioral choices within interactive scenarios, bypassing self-presentation bias found in traditional assessments. Building on these innovations, our CogniPair platform enables digital twins to engage in realistic simulated dating interactions and job interviews before real encounters, providing bidirectional cultural fit assessment for both romantic compatibility and workplace matching. Validation using 551 GNWT-Agents and Columbia University Speed Dating dataset demonstrates 72% correlation with human attraction patterns, 77.8% match prediction accuracy, and 74% agreement in human validation studies. This work advances psychological authenticity in LLM agents and establishes a foundation for intelligent dating platforms and HR technology solutions.","authors":["Wanghao Ye","Sihan Chen","Yiting Wang","Shwai He","Bowei Tian","Guoheng Sun","Ziyi Wang","Ziyao Wang","Yexiao He","Zheyu Shen","Meng Liu","Yuning Zhang","Meng Feng","Yang Wang","Siyuan Peng","Yilong Dai","Zhenle Duan","Hanzhang Qin","Ang Li"],"url":"https://arxiv.org/abs/2506.03543"}
{"created":"2025-06-05","title":"From Virtual Agents to Robot Teams: A Multi-Robot Framework Evaluation in High-Stakes Healthcare Context","abstract":"Advancements in generative models have enabled multi-agent systems (MAS) to perform complex virtual tasks such as writing and code generation, which do not generalize well to physical multi-agent robotic teams. Current frameworks often treat agents as conceptual task executors rather than physically embodied entities, and overlook critical real-world constraints such as spatial context, robotic capabilities (e.g., sensing and navigation). To probe this gap, we reconfigure and stress-test a hierarchical multi-agent robotic team built on the CrewAI framework in a simulated emergency department onboarding scenario. We identify five persistent failure modes: role misalignment; tool access violations; lack of in-time handling of failure reports; noncompliance with prescribed workflows; bypassing or false reporting of task completion. Based on this analysis, we propose three design guidelines emphasizing process transparency, proactive failure recovery, and contextual grounding. Our work informs the development of more resilient and robust multi-agent robotic systems (MARS), including opportunities to extend virtual multi-agent frameworks to the real world.","authors":["Yuanchen Bai","Zijian Ding","Angelique Taylor"],"url":"https://arxiv.org/abs/2506.03546"}
{"created":"2025-06-05","title":"SUMO-MCP: Leveraging the Model Context Protocol for Autonomous Traffic Simulation and Optimization","abstract":"Traffic simulation tools, such as SUMO, are essential for urban mobility research. However, such tools remain challenging for users due to complex manual workflows involving network download, demand generation, simulation setup, and result analysis. In this paper, we introduce SUMO-MCP, a novel platform that not only wraps SUMO' s core utilities into a unified tool suite but also provides additional auxiliary utilities for common preprocessing and postprocessing tasks. Using SUMO-MCP, users can issue simple natural-language prompts to generate traffic scenarios from OpenStreetMap data, create demand from origin-destination matrices or random patterns, run batch simulations with multiple signal-control strategies, perform comparative analyses with automated reporting, and detect congestion for signal-timing optimization. Furthermore, the platform allows flexible custom workflows by dynamically combining exposed SUMO tools without additional coding. Experiments demonstrate that SUMO-MCP significantly makes traffic simulation more accessible and reliable for researchers. We will release code for SUMO-MCP at https://github.com/ycycycl/SUMO-MCP in the future.","authors":["Chenglong Ye","Gang Xiong","Junyou Shang","Xingyuan Dai","Xiaoyan Gong","Yisheng Lv"],"url":"https://arxiv.org/abs/2506.03548"}
{"created":"2025-06-05","title":"Local Equivariance Error-Based Metrics for Evaluating Sampling-Frequency-Independent Property of Neural Network","abstract":"Audio signal processing methods based on deep neural networks (DNNs) are typically trained only at a single sampling frequency (SF) and therefore require signal resampling to handle untrained SFs. However, recent studies have shown that signal resampling can degrade performance with untrained SFs. This problem has been overlooked because most studies evaluate only the performance at trained SFs. In this paper, to assess the robustness of DNNs to SF changes, which we refer to as the SF-independent (SFI) property, we propose three metrics to quantify the SFI property on the basis of local equivariance error (LEE). LEE measures the robustness of DNNs to input transformations. By using signal resampling as input transformation, we extend LEE to measure the robustness of audio source separation methods to signal resampling. The proposed metrics are constructed to quantify the SFI property in specific network components responsible for predicting time-frequency masks. Experiments on music source separation demonstrated a strong correlation between the proposed metrics and performance degradation at untrained SFs.","authors":["Kanami Imamura","Tomohiko Nakamura","Norihiro Takamune","Kohei Yatabe","Hiroshi Saruwatari"],"url":"https://arxiv.org/abs/2506.03550"}
{"created":"2025-06-05","title":"A Threat Intelligence Event Extraction Conceptual Model for Cyber Threat Intelligence Feeds","abstract":"In response to the escalating cyber threats, the efficiency of Cyber Threat Intelligence (CTI) data collection has become paramount in ensuring robust cybersecurity. However, existing works encounter significant challenges in preprocessing large volumes of multilingual threat data, leading to inefficiencies in real-time threat analysis. This paper presents a systematic review of current techniques aimed at enhancing CTI data collection efficiency. Additionally, it proposes a conceptual model to further advance the effectiveness of threat intelligence feeds. Following the PRISMA guidelines, the review examines relevant studies from the Scopus database, highlighting the critical role of artificial intelligence (AI) and machine learning models in optimizing CTI data preprocessing. The findings underscore the importance of AI-driven methods, particularly supervised and unsupervised learning, in significantly improving the accuracy of threat detection and event extraction, thereby strengthening cybersecurity. Furthermore, the study identifies a gap in the existing research and introduces XBC conceptual model integrating XLM-RoBERTa, BiGRU, and CRF, specifically developed to address this gap. This paper contributes conceptually to the field by providing a detailed analysis of current CTI data collection techniques and introducing an innovative conceptual model to enhance future threat intelligence capabilities.","authors":["Jamal H. Al-Yasiri","Mohamad Fadli Bin Zolkipli","Nik Fatinah N Mohd Farid","Mohammed Alsamman","Zainab Ali Mohammed"],"url":"https://arxiv.org/abs/2506.03551"}
{"created":"2025-06-05","title":"Comparative Analysis of Fast and High-Fidelity Neural Vocoders for Low-Latency Streaming Synthesis in Resource-Constrained Environments","abstract":"In real-time speech synthesis, neural vocoders often require low-latency synthesis through causal processing and streaming. However, streaming introduces inefficiencies absent in batch synthesis, such as limited parallelism, inter-frame dependency management, and parameter loading overhead. This paper proposes multi-stream Wavehax (MS-Wavehax), an efficient neural vocoder for low-latency streaming, by extending the aliasing-free neural vocoder Wavehax with multi-stream decomposition. We analyze the latency-throughput trade-off in a CPU-only environment and identify key bottlenecks in streaming neural vocoders. Our findings provide practical insights for optimizing chunk sizes and designing vocoders tailored to specific application demands and hardware constraints. Furthermore, our subjective evaluations show that MS-Wavehax delivers high speech quality under causal and non-causal conditions while being remarkably compact and easily deployable in resource-constrained environments.","authors":["Reo Yoneyama","Masaya Kawamura","Ryo Terashima","Ryuichi Yamamoto","Tomoki Toda"],"url":"https://arxiv.org/abs/2506.03554"}
{"created":"2025-06-05","title":"WIFE-Fusion:Wavelet-aware Intra-inter Frequency Enhancement for Multi-model Image Fusion","abstract":"Multimodal image fusion effectively aggregates information from diverse modalities, with fused images playing a crucial role in vision systems. However, existing methods often neglect frequency-domain feature exploration and interactive relationships. In this paper, we propose wavelet-aware Intra-inter Frequency Enhancement Fusion (WIFE-Fusion), a multimodal image fusion framework based on frequency-domain components interactions. Its core innovations include: Intra-Frequency Self-Attention (IFSA) that leverages inherent cross-modal correlations and complementarity through interactive self-attention mechanisms to extract enriched frequency-domain features, and Inter-Frequency Interaction (IFI) that enhances enriched features and filters latent features via combinatorial interactions between heterogeneous frequency-domain components across modalities. These processes achieve precise source feature extraction and unified modeling of feature extraction-aggregation. Extensive experiments on five datasets across three multimodal fusion tasks demonstrate WIFE-Fusion's superiority over current specialized and unified fusion methods. Our code is available at https://github.com/Lmmh058/WIFE-Fusion.","authors":["Tianpei Zhang","Jufeng Zhao","Yiming Zhu","Guangmang Cui"],"url":"https://arxiv.org/abs/2506.03555"}
{"created":"2025-06-05","title":"Optimizing FPGA and Wafer Test Coverage with Spatial Sampling and Machine Learning","abstract":"In semiconductor manufacturing, testing costs remain significantly high, especially during wafer and FPGA testing. To reduce the number of required tests while maintaining predictive accuracy, this study investigates three baseline sampling strategies: Random Sampling, Stratified Sampling, and k-means Clustering Sampling. To further enhance these methods, this study proposes a novel algorithm that improves the sampling quality of each approach. This research is conducted using real industrial production data from wafer-level tests and silicon measurements from various FPGAs. This study introduces two hybrid strategies: Stratified with Short Distance Elimination (S-SDE) and k-means with Short Distance Elimination (K-SDE). Their performance is evaluated within the framework of Gaussian Process Regression (GPR) for predicting wafer and FPGA test data. At the core of our proposed approach is the Short Distance Elimination (SDE) algorithm, which excludes spatially proximate candidate points during sampling, thereby ensuring a more uniform distribution of training data across the physical domain. A parameter sweep was conducted over the (alpha, beta) thresholds, where alpha and beta are in the range {0, 1, 2, 3, 4} and not both zero, to identify the optimal combination that minimizes RMSD. Experimental results on a randomly selected wafer file reveal that (alpha, beta) equal (2, 2) yields the lowest RMSD. Accordingly, all subsequent experiments adopt this parameter configuration. The results demonstrate that the proposed SDE-based strategies enhance predictive accuracy: K-SDE improves upon k-means sampling by 16.26 percent (wafer) and 13.07 percent (FPGA), while S-SDE improves upon stratified sampling by 16.49 percent (wafer) and 8.84 percent (FPGA).","authors":["Wang WeiQuan","Riaz-ul-Haque Mian"],"url":"https://arxiv.org/abs/2506.03556"}
{"created":"2025-06-05","title":"BPO: Revisiting Preference Modeling in Direct Preference Optimization","abstract":"Direct Preference Optimization (DPO) have emerged as a popular method for aligning Large Language Models (LLMs) with human preferences. While DPO effectively preserves the relative ordering between chosen and rejected responses through pairwise ranking losses, it often neglects absolute reward magnitudes. This oversight can decrease the likelihood of chosen responses and increase the risk of generating out-of-distribution responses, leading to poor performance. We term this issue Degraded Chosen Responses (DCR).To address this issue, we propose Balanced Preference Optimization (BPO), a novel framework that dynamically balances the optimization of chosen and rejected responses through two key components: balanced reward margin and gap adaptor. Unlike previous methods, BPO can fundamentally resolve DPO's DCR issue, without introducing additional constraints to the loss function. Experimental results on multiple mathematical reasoning tasks show that BPO significantly outperforms DPO, improving accuracy by +10.1% with Llama-3.1-8B-Instruct (18.8% to 28.9%) and +11.7% with Qwen2.5-Math-7B (35.0% to 46.7%). It also surpasses DPO variants by +3.6% over IPO (43.1%), +5.0% over SLiC (41.7%), and +3.1% over Cal-DPO (43.6%) on the same model. Remarkably, our algorithm requires only a single line of code modification, making it simple to implement and fully compatible with existing DPO-based frameworks.","authors":["Lin Sun","Chuang Liu","Peng Liu","Bingyang Li","Weijia Lu","Ning Wu"],"url":"https://arxiv.org/abs/2506.03557"}
{"created":"2025-06-05","title":"ConsistentChat: Building Skeleton-Guided Consistent Dialogues for Large Language Models from Scratch","abstract":"Current instruction data synthesis methods primarily focus on single-turn instructions and often neglect cross-turn coherence, resulting in context drift and reduced task completion rates in extended conversations. To address this limitation, we propose Skeleton-Guided Multi-Turn Dialogue Generation, a framework that constrains multi-turn instruction synthesis by explicitly modeling human conversational intent. It operates in two stages: (1) Intent Modeling, which captures the global structure of human dialogues by assigning each conversation to one of nine well-defined intent trajectories, ensuring a coherent and goal-oriented information flow; and (2) Skeleton Generation, which constructs a structurally grounded sequence of user queries aligned with the modeled intent, thereby serving as a scaffold that constrains and guides the downstream instruction synthesis process. Based on this process, we construct ConsistentChat, a multi-turn instruction dataset with approximately 15,000 multi-turn conversations and 224,392 utterances. Experiments on the Light, Topdial, and MT-Eval benchmarks show that models fine-tuned on ConsistentChat achieve a 20-30% improvement in chat consistency and up to a 15% increase in task success rate, significantly outperforming models trained on existing single-turn and multi-turn instruction datasets.","authors":["Jiawei Chen","Xinyan Guan","Qianhao Yuan","Guozhao Mo","Weixiang Zhou","Yaojie Lu","Hongyu Lin","Ben He","Le Sun","Xianpei Han"],"url":"https://arxiv.org/abs/2506.03558"}
{"created":"2025-06-05","title":"POSS: Position Specialist Generates Better Draft for Speculative Decoding","abstract":"Speculative decoding accelerates Large Language Model (LLM) inference by using a small draft model to predict multiple tokens, and a large target model to verify these tokens in parallel. Recent studies leverage the hidden state of the target model to enhance draft model prediction accuracy. However, existing methods suffer from the degrading quality of draft token predictions at later positions, due to error accumulation in draft model generated features. In this paper, we propose Position Specialists (PosS), which consist of multiple position-specialized draft layers to generate tokens at assigned position(s). Position specialists greatly improve token acceptance rate at later positions per drafting round, as each specialist only needs to focus on handling a certain level of draft model feature deviation. Experiment results on Llama-3-8B-Instruct and Llama-2-13B-chat across six datasets demonstrate that PosS effectively improves over baselines on average acceptance length and speed-up ratio. Our codebase is available at https://github.com/shrango/PosS.","authors":["Langlin Huang","Chengsong Huang","Jixuan Leng","Di Huang","Jiaxin Huang"],"url":"https://arxiv.org/abs/2506.03566"}
{"created":"2025-06-05","title":"Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving","abstract":"Autonomous driving promises significant advancements in mobility, road safety and traffic efficiency, yet reinforcement learning and imitation learning face safe-exploration and distribution-shift challenges. Although human-AI collaboration alleviates these issues, it often relies heavily on extensive human intervention, which increases costs and reduces efficiency. This paper develops a confidence-guided human-AI collaboration (C-HAC) strategy to overcome these limitations. First, C-HAC employs a distributional proxy value propagation method within the distributional soft actor-critic (DSAC) framework. By leveraging return distributions to represent human intentions C-HAC achieves rapid and stable learning of human-guided policies with minimal human interaction. Subsequently, a shared control mechanism is activated to integrate the learned human-guided policy with a self-learning policy that maximizes cumulative rewards. This enables the agent to explore independently and continuously enhance its performance beyond human guidance. Finally, a policy confidence evaluation algorithm capitalizes on DSAC's return distribution networks to facilitate dynamic switching between human-guided and self-learning policies via a confidence-based intervention function. This ensures the agent can pursue optimal policies while maintaining safety and performance guarantees. Extensive experiments across diverse driving scenarios reveal that C-HAC significantly outperforms conventional methods in terms of safety, efficiency, and overall performance, achieving state-of-the-art results. The effectiveness of the proposed method is further validated through real-world road tests in complex traffic conditions. The videos and code are available at: https://github.com/lzqw/C-HAC.","authors":["Li Zeqiao","Wang Yijing","Wang Haoyu","Li Zheng","Li Peng","Zuo zhiqiang","Hu Chuan"],"url":"https://arxiv.org/abs/2506.03568"}
{"created":"2025-06-05","title":"MiMo-VL Technical Report","abstract":"We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language models delivering state-of-the-art performance in both general visual understanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B on 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpassing models with up to 78B parameters. For GUI grounding applications, it sets a new standard with 56.1 on OSWorld-G, even outperforming specialized models such as UI-TARS. Our training combines four-stage pre-training (2.4 trillion tokens) with Mixed On-policy Reinforcement Learning (MORL) integrating diverse reward signals. We identify the importance of incorporating high-quality reasoning data with long Chain-of-Thought into pre-training stages, and the benefits of mixed RL despite challenges in simultaneous multi-domain optimization. We also contribute a comprehensive evaluation suite covering 50+ tasks to promote reproducibility and advance the field. The model checkpoints and full evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL.","authors":["Core Team","Zihao Yue","Zhenru Lin","Yifan Song","Weikun Wang","Shuhuai Ren","Shuhao Gu","Shicheng Li","Peidian Li","Liang Zhao","Lei Li","Kainan Bao","Hao Tian","Hailin Zhang","Gang Wang","Dawei Zhu","Cici","Chenhong He","Bowen Ye","Bowen Shen","Zihan Zhang","Zihan Jiang","Zhixian Zheng","Zhichao Song","Zhenbo Luo","Yue Yu","Yudong Wang","Yuanyuan Tian","Yu Tu","Yihan Yan","Yi Huang","Xu Wang","Xinzhe Xu","Xingchen Song","Xing Zhang","Xing Yong","Xin Zhang","Xiangwei Deng","Wenyu Yang","Wenhan Ma","Weiwei Lv","Weiji Zhuang","Wei Liu","Sirui Deng","Shuo Liu","Shimao Chen","Shihua Yu","Shaohui Liu","Shande Wang","Rui Ma","Qiantong Wang","Peng Wang","Nuo Chen","Menghang Zhu","Kangyang Zhou","Kang Zhou","Kai Fang","Jun Shi","Jinhao Dong","Jiebao Xiao","Jiaming Xu","Huaqiu Liu","Hongshen Xu","Heng Qu","Haochen Zhao","Hanglong Lv","Guoan Wang","Duo Zhang","Dong Zhang","Di Zhang","Chong Ma","Chang Liu","Can Cai","Bingquan Xia"],"url":"https://arxiv.org/abs/2506.03569"}
{"created":"2025-06-05","title":"FreePRM: Training Process Reward Models Without Ground Truth Process Labels","abstract":"Recent advancements in Large Language Models (LLMs) have demonstrated that Process Reward Models (PRMs) play a crucial role in enhancing model performance. However, training PRMs typically requires step-level labels, either manually annotated or automatically generated, which can be costly and difficult to obtain at scale. To address this challenge, we introduce FreePRM, a weakly supervised framework for training PRMs without access to ground-truth step-level labels. FreePRM first generates pseudo step-level labels based on the correctness of final outcome, and then employs Buffer Probability to eliminate impact of noise inherent in pseudo labeling. Experimental results show that FreePRM achieves an average F1 score of 53.0% on ProcessBench, outperforming fully supervised PRM trained on Math-Shepherd by +24.1%. Compared to other open-source PRMs, FreePRM outperforms upon RLHFlow-PRM-Mistral-8B (28.4%) by +24.6%, EurusPRM (31.3%) by +21.7%, and Skywork-PRM-7B (42.1%) by +10.9%. This work introduces a new paradigm in PRM training, significantly reducing reliance on costly step-level annotations while maintaining strong performance.","authors":["Lin Sun","Chuang Liu","Xiaofeng Ma","Tao Yang","Weijia Lu","Ning Wu"],"url":"https://arxiv.org/abs/2506.03570"}
{"created":"2025-06-05","title":"DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network","abstract":"We propose DaigNet, a new approach to object detection with which we can detect an object bounding box using diagonal constraints on adjacency matrix of a graph convolutional network (GCN). We propose two diagonalization algorithms based on hard and soft constraints on adjacency matrix and two loss functions using diagonal constraint and complementary constraint. The DaigNet eliminates the need for designing a set of anchor boxes commonly used. To prove feasibility of our novel detector, we adopt detection head in YOLO models. Experiments show that the DiagNet achieves 7.5% higher mAP50 on Pascal VOC than YOLOv1. The DiagNet also shows 5.1% higher mAP on MS COCO than YOLOv3u, 3.7% higher mAP than YOLOv5u, and 2.9% higher mAP than YOLOv8.","authors":["Chong Hyun Lee","Kibae Lee"],"url":"https://arxiv.org/abs/2506.03571"}
{"created":"2025-06-05","title":"Exchange of Perspective Prompting Enhances Reasoning in Large Language Models","abstract":"Large language models (LLMs) have made significant advancements in addressing diverse natural language processing (NLP) tasks. However, their performance is often limited by inherent comprehension of problems. To address this limitation, we propose Exchange-of-Perspective (EoP), a novel framework designed to exchange perspectives across different definitions of problem, so that it can break the fixed mindset from any particular formulation of the question. We conducted extensive and comprehensive experiments on 8 benchmarks. The results show that EoP can significantly improve performance. For instance, compared to the non-commutative baseline PHP, with GPT-3.5-Turbo and EoP, we observe a 3.6% improvement on AQuA (60.6% to 64.2%), while GPT-4-powered EoP demonstrates a 7.7% overall accuracy enhancement on Math (53.9% to 61.6%) and a 3.5% improvement on OlympiadBench Maths (43.5% to 47.0%) when using Qwen-2.5-72b.","authors":["Lin Sun","Can Zhang"],"url":"https://arxiv.org/abs/2506.03573"}
{"created":"2025-06-05","title":"SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models","abstract":"Robots deployed in dynamic environments must be able to not only follow diverse language instructions but flexibly adapt when user intent changes mid-execution. While recent Vision-Language-Action (VLA) models have advanced multi-task learning and instruction following, they typically assume static task intent, failing to respond when new instructions arrive during ongoing execution. This limitation hinders natural and robust interaction in dynamic settings, such as retail or household environments, where real-time intent changes are common. We propose SwitchVLA, a unified, execution-aware framework that enables smooth and reactive task switching without external planners or additional switch-specific data. We model task switching as a behavior modulation problem conditioned on execution state and instruction context. Expert demonstrations are segmented into temporally grounded contact phases, allowing the policy to infer task progress and adjust its behavior accordingly. A multi-behavior conditional policy is then trained to generate flexible action chunks under varying behavior modes through conditioned trajectory modeling. Experiments in both simulation and real-world robotic manipulation demonstrate that SwitchVLA enables robust instruction adherence, fluid task switching, and strong generalization-outperforming prior VLA baselines in both task success rate and interaction naturalness.","authors":["Meng Li","Zhen Zhao","Zhengping Che","Fei Liao","Kun Wu","Zhiyuan Xu","Pei Ren","Zhao Jin","Ning Liu","Jian Tang"],"url":"https://arxiv.org/abs/2506.03574"}
{"created":"2025-06-05","title":"KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models","abstract":"Recent advances in knowledge representation learning (KRL) highlight the urgent necessity to unify symbolic knowledge graphs (KGs) with language models (LMs) for richer semantic understanding. However, existing approaches typically prioritize either graph structure or textual semantics, leaving a gap: a unified framework that simultaneously captures global KG connectivity, nuanced linguistic context, and discriminative reasoning semantics. To bridge this gap, we introduce KG-BiLM, a bidirectional LM framework that fuses structural cues from KGs with the semantic expressiveness of generative transformers. KG-BiLM incorporates three key components: (i) Bidirectional Knowledge Attention, which removes the causal mask to enable full interaction among all tokens and entities; (ii) Knowledge-Masked Prediction, which encourages the model to leverage both local semantic contexts and global graph connectivity; and (iii) Contrastive Graph Semantic Aggregation, which preserves KG structure via contrastive alignment of sampled sub-graph representations. Extensive experiments on standard benchmarks demonstrate that KG-BiLM outperforms strong baselines in link prediction, especially on large-scale graphs with complex multi-hop relations - validating its effectiveness in unifying structural information and textual semantics.","authors":["Zirui Chen","Xin Wang","Zhao Li","Wenbin Guo","Dongxiao He"],"url":"https://arxiv.org/abs/2506.03576"}
{"created":"2025-06-05","title":"Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models","abstract":"Providing example sentences that are diverse and aligned with learners' proficiency levels is essential for fostering effective language acquisition. This study examines the use of Pre-trained Language Models (PLMs) to produce example sentences targeting L2 Japanese learners. We utilize PLMs in two ways: as quality scoring components in a retrieval system that draws from a newly curated corpus of Japanese sentences, and as direct sentence generators using zero-shot learning. We evaluate the quality of sentences by considering multiple aspects such as difficulty, diversity, and naturalness, with a panel of raters consisting of learners of Japanese, native speakers -- and GPT-4. Our findings suggest that there is inherent disagreement among participants on the ratings of sentence qualities, except for difficulty. Despite that, the retrieval approach was preferred by all evaluators, especially for beginner and advanced target proficiency, while the generative approaches received lower scores on average. Even so, our experiments highlight the potential for using PLMs to enhance the adaptability of sentence suggestion systems and therefore improve the language learning journey.","authors":["Enrico Benedetti","Akiko Aizawa","Florian Boudin"],"url":"https://arxiv.org/abs/2506.03580"}
{"created":"2025-06-05","title":"ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels","abstract":"We present ViTSGMM, an image recognition network that leverages semi-supervised learning in a highly efficient manner. Existing works often rely on complex training techniques and architectures, while their generalization ability when dealing with extremely limited labeled data remains to be improved. To address these limitations, we construct a hierarchical mixture density classification decision mechanism by optimizing mutual information between feature representations and target classes, compressing redundant information while retaining crucial discriminative components. Experimental results demonstrate that our method achieves state-of-the-art performance on STL-10 and CIFAR-10/100 datasets when using negligible labeled samples. Notably, this paper also reveals a long-overlooked data leakage issue in the STL-10 dataset for semi-supervised learning tasks and removes duplicates to ensure the reliability of experimental results. Code available at https://github.com/Shu1L0n9/ViTSGMM.","authors":["Rui Yann","Xianglei Xing"],"url":"https://arxiv.org/abs/2506.03582"}
{"created":"2025-06-05","title":"A Large-Scale Referring Remote Sensing Image Segmentation Dataset and Benchmark","abstract":"Referring Remote Sensing Image Segmentation is a complex and challenging task that integrates the paradigms of computer vision and natural language processing. Existing datasets for RRSIS suffer from critical limitations in resolution, scene diversity, and category coverage, which hinders the generalization and real-world applicability of refer segmentation models. To facilitate the development of this field, we introduce NWPU-Refer, the largest and most diverse RRSIS dataset to date, comprising 15,003 high-resolution images (1024-2048px) spanning 30+ countries with 49,745 annotated targets supporting single-object, multi-object, and non-object segmentation scenarios. Additionally, we propose the Multi-scale Referring Segmentation Network (MRSNet), a novel framework tailored for the unique demands of RRSIS. MRSNet introduces two key innovations: (1) an Intra-scale Feature Interaction Module (IFIM) that captures fine-grained details within each encoder stage, and (2) a Hierarchical Feature Interaction Module (HFIM) to enable seamless cross-scale feature fusion, preserving spatial integrity while enhancing discriminative power. Extensive experiments conducte on the proposed NWPU-Refer dataset demonstrate that MRSNet achieves state-of-the-art performance across multiple evaluation metrics, validating its effectiveness. The dataset and code are publicly available at https://github.com/CVer-Yang/NWPU-Refer.","authors":["Zhigang Yang","Huiguang Yao","Linmao Tian","Xuezhi Zhao","Qiang Li","Qi Wang"],"url":"https://arxiv.org/abs/2506.03583"}
{"created":"2025-06-05","title":"Improving LLM-Based Fault Localization with External Memory and Project Context","abstract":"Fault localization, the process of identifying the software components responsible for failures, is essential but often time-consuming. Recent advances in Large Language Models (LLMs) have enabled fault localization without extensive defect datasets or model fine-tuning. However, existing LLM-based methods rely only on general LLM capabilities and lack integration of project-specific knowledge, resulting in limited effectiveness, especially for complex software.","authors":["Inseok Yeo","Duksan Ryu","Jongmoon Baik"],"url":"https://arxiv.org/abs/2506.03585"}
{"created":"2025-06-05","title":"Joint Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems: A DRL Approach","abstract":"This paper investigates a joint phase design and resource allocation problem in downlink reconfigurable intelligent surface (RIS)-assisted orthogonal frequency division multiplexing (OFDM) systems to optimize average delay, where data packets for each user arrive at the base station stochastically. The sequential optimization problem is inherently a Markov decision process (MDP), making it fall within the scope of reinforcement learning. To effectively handle the mixed action space and reduce the state space dimensionality, a hybrid deep reinforcement learning (DRL) approach is proposed. Specifically, proximal policy optimization (PPO)-$\\Theta$ is employed to optimize RIS phase shift design, while PPO-N is responsible for subcarrier allocation decisions. To further mitigate the curse of dimensionality associated with subcarrier allocation, a multi-agent strategy is introduced to optimize subcarrier allocation indicater more efficiently. Moreover, to achieve more adaptive resource allocation and accurately capture network dynamics, key factors closely related to average delay, including the number of backlogged packets in buffers and the current packet arrivals, are incorporated into the state space. Furthermore, a transfer learning framework is introduced to enhance training efficiency and accelerate convergence. Simulation results demonstrate that the proposed algorithm significantly reduces average delay, enhances resource allocation efficiency, and achieves superior system robustness and fairness compared to baseline methods.","authors":["Yu Ma","Chongtao Guo","Le Liang","Xiao Li","Shi Jin"],"url":"https://arxiv.org/abs/2506.03586"}
{"created":"2025-06-05","title":"Preface to the Special Issue of the TAL Journal on Scholarly Document Processing","abstract":"The rapid growth of scholarly literature makes it increasingly difficult for researchers to keep up with new knowledge. Automated tools are now more essential than ever to help navigate and interpret this vast body of information. Scientific papers pose unique difficulties, with their complex language, specialized terminology, and diverse formats, requiring advanced methods to extract reliable and actionable insights. Large language models (LLMs) offer new opportunities, enabling tasks such as literature reviews, writing assistance, and interactive exploration of research. This special issue of the TAL journal highlights research addressing these challenges and, more broadly, research on natural language processing and information retrieval for scholarly and scientific documents.","authors":["Florian Boudin","Akiko Aizawa"],"url":"https://arxiv.org/abs/2506.03587"}
{"created":"2025-06-05","title":"A Class Inference Scheme With Dempster-Shafer Theory for Learning Fuzzy-Classifier Systems","abstract":"The decision-making process significantly influences the predictions of machine learning models. This is especially important in rule-based systems such as Learning Fuzzy-Classifier Systems (LFCSs) where the selection and application of rules directly determine prediction accuracy and reliability. LFCSs combine evolutionary algorithms with supervised learning to optimize fuzzy classification rules, offering enhanced interpretability and robustness. Despite these advantages, research on improving decision-making mechanisms (i.e., class inference schemes) in LFCSs remains limited. Most LFCSs use voting-based or single-winner-based inference schemes. These schemes rely on classification performance on training data and may not perform well on unseen data, risking overfitting. To address these limitations, this article introduces a novel class inference scheme for LFCSs based on the Dempster-Shafer Theory of Evidence (DS theory). The proposed scheme handles uncertainty well. By using the DS theory, the scheme calculates belief masses (i.e., measures of belief) for each specific class and the ``I don't know'' state from each fuzzy rule and infers a class from these belief masses. Unlike the conventional schemes, the proposed scheme also considers the ``I don't know'' state that reflects uncertainty, thereby improving the transparency and reliability of LFCSs. Applied to a variant of LFCS (i.e., Fuzzy-UCS), the proposed scheme demonstrates statistically significant improvements in terms of test macro F1 scores across 30 real-world datasets compared to conventional voting-based and single-winner-based fuzzy inference schemes. It forms smoother decision boundaries, provides reliable confidence measures, and enhances the robustness and generalizability of LFCSs in real-world applications. Our implementation is available at https://github.com/YNU-NakataLab/jUCS.","authors":["Hiroki Shiraishi","Hisao Ishibuchi","Masaya Nakata"],"url":"https://arxiv.org/abs/2506.03588"}
{"created":"2025-06-05","title":"BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance","abstract":"Text-video retrieval (TVR) systems often suffer from visual-linguistic biases present in datasets, which cause pre-trained vision-language models to overlook key details. To address this, we propose BiMa, a novel framework designed to mitigate biases in both visual and textual representations. Our approach begins by generating scene elements that characterize each video by identifying relevant entities/objects and activities. For visual debiasing, we integrate these scene elements into the video embeddings, enhancing them to emphasize fine-grained and salient details. For textual debiasing, we introduce a mechanism to disentangle text features into content and bias components, enabling the model to focus on meaningful content while separately handling biased information. Extensive experiments and ablation studies across five major TVR benchmarks (i.e., MSR-VTT, MSVD, LSMDC, ActivityNet, and DiDeMo) demonstrate the competitive performance of BiMa. Additionally, the model's bias mitigation capability is consistently validated by its strong results on out-of-distribution retrieval tasks.","authors":["Huy Le","Nhat Chung","Tung Kieu","Anh Nguyen","Ngan Le"],"url":"https://arxiv.org/abs/2506.03589"}
{"created":"2025-06-05","title":"VCDiag: Classifying Erroneous Waveforms for Failure Triage Acceleration","abstract":"Failure triage in design functional verification is critical but time-intensive, relying on manual specification reviews, log inspections, and waveform analyses. While machine learning (ML) has improved areas like stimulus generation and coverage closure, its application to RTL-level simulation failure triage, particularly for large designs, remains limited. VCDiag offers an efficient, adaptable approach using VCD data to classify failing waveforms and pinpoint likely failure locations. In the largest experiment, VCDiag achieves over 94% accuracy in identifying the top three most likely modules. The framework introduces a novel signal selection and statistical compression approach, achieving over 120x reduction in raw data size while preserving features essential for classification. It can also be integrated into diverse Verilog/SystemVerilog designs and testbenches.","authors":["Minh Luu","Surya Jasper","Khoi Le","Evan Pan","Michael Quinn","Aakash Tyagi","Jiang Hu"],"url":"https://arxiv.org/abs/2506.03590"}
{"created":"2025-06-05","title":"Resolving Task Objective Conflicts in Unified Multimodal Understanding and Generation via Task-Aware Mixture-of-Experts","abstract":"Unified multimodal large language models (MLLMs) based on end-to-end autoregressive (AR) transformers effectively integrate both understanding and generation tasks within a single framework. However, intrinsic Task Objective Conflicts between high-level semantic abstraction in understanding and fine-grained detail preservation in generation pose significant challenges, often leading to suboptimal trade-offs and task interference. Existing solutions, such as decoupling shared visual encoders, fall short of fundamentally resolving these conflicts due to inherent AR architecture. In this paper, we propose a novel approach that decouples internal components of AR to resolve task objective conflicts. Specifically, we design UTAMoE, a Unified Task-Aware Mixture-of-Experts (MoE) framework that decouples internal AR modules via a Task-Aware MoE Layer to create task-specific optimization subpaths. To enhance task differentiation while maintaining overall coordination, we introduce a novel Two-Stage Training Strategy. Extensive experiments on multimodal benchmarks demonstrate that UTAMoE mitigates task objective conflicts, achieving state-of-the-art performance across various tasks. Visualizations and ablation studies further validate the effectiveness of our approach.","authors":["Jiaxing Zhang","Xinyi Zeng","Hao Tang"],"url":"https://arxiv.org/abs/2506.03591"}
{"created":"2025-06-05","title":"From Understanding to Generation: An Efficient Shortcut for Evaluating Language Models","abstract":"Iterative evaluation of LLMs during training is essential to ensure expected capability development, but can be time- and compute-intensive. While NLU tasks, where the model selects from fixed answer choices, are cheap to evaluate, essential capabilities like reasoning and code generation rely on the more time-consuming NLG (token-by-token generation) format. In this work, our aim is to decrease the computational burden of NLG benchmarks in order to enable monitoring crucial LLM capabilities during model training. We reformulate generative tasks into computationally cheaper NLU alternatives. We test the performance correlation between the original and reformulated tasks using 8 LMs of various sizes and 4 capabilities: mathematical reasoning, code generation, factual knowledge and reading comprehension. Our results show a strong correlation between task formats, supporting capability assessment via cheaper alternatives and achieving over 35x average reduction in evaluation time. We plan to publish our benchmark adaptions.","authors":["Viktor Hangya","Fabian K\\\"uch","Darina Gold"],"url":"https://arxiv.org/abs/2506.03592"}
{"created":"2025-06-05","title":"Is linguistically-motivated data augmentation worth it?","abstract":"Data augmentation, a widely-employed technique for addressing data scarcity, involves generating synthetic data examples which are then used to augment available training data. Researchers have seen surprising success from simple methods, such as random perturbations from natural examples, where models seem to benefit even from data with nonsense words, or data that doesn't conform to the rules of the language. A second line of research produces synthetic data that does in fact follow all linguistic constraints; these methods require some linguistic expertise and are generally more challenging to implement. No previous work has done a systematic, empirical comparison of both linguistically-naive and linguistically-motivated data augmentation strategies, leaving uncertainty about whether the additional time and effort of linguistically-motivated data augmentation work in fact yields better downstream performance.","authors":["Ray Groshan","Michael Ginn","Alexis Palmer"],"url":"https://arxiv.org/abs/2506.03593"}
{"created":"2025-06-05","title":"SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting","abstract":"Reconstructing articulated objects prevalent in daily environments is crucial for applications in augmented/virtual reality and robotics. However, existing methods face scalability limitations (requiring 3D supervision or costly annotations), robustness issues (being susceptible to local optima), and rendering shortcomings (lacking speed or photorealism). We introduce SplArt, a self-supervised, category-agnostic framework that leverages 3D Gaussian Splatting (3DGS) to reconstruct articulated objects and infer kinematics from two sets of posed RGB images captured at different articulation states, enabling real-time photorealistic rendering for novel viewpoints and articulations. SplArt augments 3DGS with a differentiable mobility parameter per Gaussian, achieving refined part segmentation. A multi-stage optimization strategy is employed to progressively handle reconstruction, part segmentation, and articulation estimation, significantly enhancing robustness and accuracy. SplArt exploits geometric self-supervision, effectively addressing challenging scenarios without requiring 3D annotations or category-specific priors. Evaluations on established and newly proposed benchmarks, along with applications to real-world scenarios using a handheld RGB camera, demonstrate SplArt's state-of-the-art performance and real-world practicality. Code is publicly available at https://github.com/ripl/splart.","authors":["Shengjie Lin","Jiading Fang","Muhammad Zubair Irshad","Vitor Campagnolo Guizilini","Rares Andrei Ambrus","Greg Shakhnarovich","Matthew R. Walter"],"url":"https://arxiv.org/abs/2506.03594"}
{"created":"2025-06-05","title":"Purifying Shampoo: Investigating Shampoo's Heuristics by Decomposing its Preconditioner","abstract":"The recent success of Shampoo in the AlgoPerf contest has sparked renewed interest in Kronecker-factorization-based optimization algorithms for training neural networks. Despite its success, Shampoo relies heavily on several heuristics such as learning rate grafting and stale preconditioning to achieve performance at-scale. These heuristics increase algorithmic complexity, necessitate further hyperparameter tuning, and lack theoretical justification. This paper investigates these heuristics from the angle of Frobenius norm approximation to full-matrix Adam and decouples the preconditioner's eigenvalues and eigenbasis updates. We show that grafting from Adam mitigates the staleness and mis-scaling of the preconditioner's eigenvalues and how correcting the eigenvalues directly can eliminate the need for learning rate grafting. To manage the error induced by infrequent eigenbasis computations, we propose an adaptive criterion for determining the eigenbasis computation frequency motivated by terminating a warm-started QR algorithm. This criterion decouples the update frequency of different preconditioner matrices and enables us to investigate the impact of approximation error on convergence. These practical techniques offer a principled angle towards removing Shampoo's heuristics and developing improved Kronecker-factorization-based training algorithms.","authors":["Runa Eschenhagen","Aaron Defazio","Tsung-Hsien Lee","Richard E. Turner","Hao-Jun Michael Shi"],"url":"https://arxiv.org/abs/2506.03595"}
{"created":"2025-06-05","title":"ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning","abstract":"The field of controllable image generation has seen significant advancements, with various architectures improving generation layout consistency with control signals. However, contemporary methods still face challenges in bridging the semantic gap between input text prompts with sparse semantics and the target images, often over-relying on low-level control signals to infer regional details. To address this challenge, we propose ControlThinker, a novel framework that employs a \"comprehend-then-generate\" paradigm. Firstly, by incentivizing the visual reasoning capability of a MLLM, latent semantics from control images are mined to enrich text prompts. This enriched semantic understanding then seamlessly aids in image generation without the need for additional complex modifications. To further tackle the uncertainty arising from the ambiguity of control images, we encourage broader exploration of reasoning trajectories and select the optimal one using a metric-based output reward model (ORM). Extensive experimental results demonstrate that ControlThinker effectively mitigates the semantic gap between raw text prompts and target images, resulting in improved visual quality and semantic consistency across a wide range of benchmarks. The code and models are available at https://github.com/Maplebb/ControlThinker.","authors":["Feng Han","Yang Jiao","Shaoxiang Chen","Junhao Xu","Jingjing Chen","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2506.03596"}
{"created":"2025-06-05","title":"Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments","abstract":"Using the best Text-to-SQL methods in resource-constrained environments is challenging due to their reliance on resource-intensive open-source models. This paper introduces Auto Prompt SQL(AP-SQL), a novel architecture designed to bridge the gap between resource-efficient small open-source models and the powerful capabilities of large closed-source models for Text-to-SQL translation. Our method decomposes the task into schema filtering, retrieval-augmented text-to-SQL generation based on in-context examples, and prompt-driven schema linking and SQL generation. To improve schema selection accuracy, we fine-tune large language models. Crucially, we also explore the impact of prompt engineering throughout the process, leveraging Chain-of-Thought(CoT) and Graph-of-Thought(GoT) templates to significantly enhance the model's reasoning for accurate SQL generation. Comprehensive evaluations on the Spider benchmarks demonstrate the effectiveness of AP-SQL.","authors":["Zetong Tang","Qian Ma","Di Wu"],"url":"https://arxiv.org/abs/2506.03598"}
{"created":"2025-06-05","title":"Adapting Rule Representation With Four-Parameter Beta Distribution for Learning Classifier Systems","abstract":"Rule representations significantly influence the search capabilities and decision boundaries within the search space of Learning Classifier Systems (LCSs), a family of rule-based machine learning systems that evolve interpretable models through evolutionary processes. However, it is very difficult to choose an appropriate rule representation for each problem. Additionally, some problems benefit from using different representations for different subspaces within the input space. Thus, an adaptive mechanism is needed to choose an appropriate rule representation for each rule in LCSs. This article introduces a flexible rule representation using a four-parameter beta distribution and integrates it into a fuzzy-style LCS. The four-parameter beta distribution can form various function shapes, and this flexibility enables our LCS to automatically select appropriate representations for different subspaces. Our rule representation can represent crisp/fuzzy decision boundaries in various boundary shapes, such as rectangles and bells, by controlling four parameters, compared to the standard representations such as trapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the appropriate rule representation for each subspace. Moreover, our LCS incorporates a generalization bias favoring crisp rules where feasible, enhancing model interpretability without compromising accuracy. Experimental results on real-world classification tasks show that our LCS achieves significantly superior test accuracy and produces more compact rule sets. Our implementation is available at https://github.com/YNU-NakataLab/Beta4-UCS. An extended abstract related to this work is available at https://doi.org/10.36227/techrxiv.174900805.59801248/v1.","authors":["Hiroki Shiraishi","Yohei Hayamizu","Tomonori Hashiyama","Keiki Takadama","Hisao Ishibuchi","Masaya Nakata"],"url":"https://arxiv.org/abs/2506.03602"}
{"created":"2025-06-05","title":"Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision","abstract":"Learning to use tools or objects in common scenes, particularly handling them in various ways as instructed, is a key challenge for developing interactive robots. Training models to generate such manipulation trajectories requires a large and diverse collection of detailed manipulation demonstrations for various objects, which is nearly unfeasible to gather at scale. In this paper, we propose a framework that leverages large-scale ego- and exo-centric video datasets -- constructed globally with substantial effort -- of Exo-Ego4D to extract diverse manipulation trajectories at scale. From these extracted trajectories with the associated textual action description, we develop trajectory generation models based on visual and point cloud-based language models. In the recently proposed egocentric vision-based in-a-quality trajectory dataset of HOT3D, we confirmed that our models successfully generate valid object trajectories, establishing a training dataset and baseline models for the novel task of generating 6DoF manipulation trajectories from action descriptions in egocentric vision.","authors":["Tomoya Yoshida","Shuhei Kurita","Taichi Nishimura","Shinsuke Mori"],"url":"https://arxiv.org/abs/2506.03605"}
{"created":"2025-06-05","title":"Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI","abstract":"Edge computing decentralizes processing power to network edge, enabling real-time AI-driven decision-making in IoT applications. In industrial automation such as robotics and rugged edge AI, real-time perception and intelligence are critical for autonomous operations. Deploying transformer-based image captioning models at the edge can enhance machine perception, improve scene understanding for autonomous robots, and aid in industrial inspection.","authors":["Wing Man Casca Kwok","Yip Chiu Tung","Kunal Bhagchandani"],"url":"https://arxiv.org/abs/2506.03607"}
{"created":"2025-06-05","title":"PDSE: A Multiple Lesion Detector for CT Images using PANet and Deformable Squeeze-and-Excitation Block","abstract":"Detecting lesions in Computed Tomography (CT) scans is a challenging task in medical image processing due to the diverse types, sizes, and locations of lesions. Recently, various one-stage and two-stage framework networks have been developed to focus on lesion localization. We introduce a one-stage lesion detection framework, PDSE, by redesigning Retinanet to achieve higher accuracy and efficiency for detecting lesions in multimodal CT images. Specifically, we enhance the path aggregation flow by incorporating a low-level feature map. Additionally, to improve model representation, we utilize the adaptive Squeeze-and-Excitation (SE) block and integrate channel feature map attention. This approach has resulted in achieving new state-of-the-art performance. Our method significantly improves the detection of small and multiscaled objects. When evaluated against other advanced algorithms on the public DeepLesion benchmark, our algorithm achieved an mAP of over 0.20.","authors":["Di Fan","Heng Yu","Zhiyuan Xu"],"url":"https://arxiv.org/abs/2506.03608"}
{"created":"2025-06-05","title":"Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games","abstract":"Large Language Model (LLM) agents are reshaping the game industry, particularly with more intelligent and human-preferable game characters. However, existing game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets for aligning pre-trained LLMs into gaming agents. To fill these gaps, we present \\textbf{\\benchname{}}, a foundational benchmark designed to train and evaluate LLM agents across diverse real-world video games. Unlike existing benchmarks, Orak includes 12 popular video games spanning all major genres, enabling comprehensive studies of LLM capabilities and agentic modules essential for intricate game scenarios. To support consistent evaluation of LLMs, we introduce a plug-and-play interface based on Model Context Protocol (MCP) that enables LLMs to seamlessly connect with games and manipulate agentic modules. Additionally, we propose a fine-tuning dataset, consisting of LLM gameplay trajectories across diverse game genres. Orak offers a comprehensive evaluation framework, encompassing general game score leaderboards, LLM battle arenas, and in-depth analyses of visual input state, agentic strategies, and fine-tuning effects, establishing a foundation towards building generic gaming agents. Code is available at https://github.com/krafton-ai/Orak.","authors":["Dongmin Park","Minkyu Kim","Beongjun Choi","Junhyuck Kim","Keon Lee","Jonghyun Lee","Inkyu Park","Byeong-Uk Lee","Jaeyoung Hwang","Jaewoo Ahn","Ameya S. Mahabaleshwarkar","Bilal Kartal","Pritam Biswas","Yoshi Suhara","Kangwook Lee","Jaewoong Cho"],"url":"https://arxiv.org/abs/2506.03610"}
{"created":"2025-06-05","title":"Connectivity-Preserving Minimum Separator in AT-free Graphs","abstract":"Let $A$ and $B$ be disjoint, non-adjacent vertex-sets in an undirected, connected graph $G$, whose vertices are associated with positive weights. We address the problem of identifying a minimum-weight subset of vertices $S\\subseteq V(G)$ that, when removed, disconnects $A$ from $B$ while preserving the internal connectivity of both $A$ and $B$. We call such a subset of vertices a connectivity-preserving, or safe minimum $A,B$-separator. Deciding whether a safe $A,B$-separator exists is NP-hard by reduction from the 2-disjoint connected subgraphs problem, and remains NP-hard even for restricted graph classes that include planar graphs, and $P_\\ell$-free graphs if $\\ell\\geq 5$. In this work, we show that if $G$ is AT-free then in polynomial time we can find a safe $A,B$-separator of minimum weight, or establish that no safe $A,B$-separator exists.","authors":["Batya Kenig"],"url":"https://arxiv.org/abs/2506.03612"}
{"created":"2025-06-05","title":"Training Cross-Morphology Embodied AI Agents: From Practical Challenges to Theoretical Foundations","abstract":"While theory and practice are often seen as separate domains, this article shows that theoretical insight is essential for overcoming real-world engineering barriers. We begin with a practical challenge: training a cross-morphology embodied AI policy that generalizes across diverse robot morphologies. We formalize this as the Heterogeneous Embodied Agent Training (HEAT) problem and prove it reduces to a structured Partially Observable Markov Decision Process (POMDP) that is PSPACE-complete. This result explains why current reinforcement learning pipelines break down under morphological diversity, due to sequential training constraints, memory-policy coupling, and data incompatibility. We further explore Collective Adaptation, a distributed learning alternative inspired by biological systems. Though NEXP-complete in theory, it offers meaningful scalability and deployment benefits in practice. This work illustrates how computational theory can illuminate system design trade-offs and guide the development of more robust, scalable embodied AI. For practitioners and researchers to explore this problem, the implementation code of this work has been made publicly available at https://github.com/airs-admin/HEAT","authors":["Shaoshan Liu","Fan Wang","Hongjun Zhou","Yuanfeng Wang"],"url":"https://arxiv.org/abs/2506.03613"}
{"created":"2025-06-05","title":"VLMs Can Aggregate Scattered Training Patches","abstract":"One way to mitigate risks in vision-language models (VLMs) is to remove dangerous samples in their training data. However, such data moderation can be easily bypassed when harmful images are split into small, benign-looking patches, scattered across many training samples. VLMs may then learn to piece these fragments together during training and generate harmful responses at inference, either from full images or text references. For instance, if trained on image patches from a bloody scene paired with the descriptions \"safe,\" VLMs may later describe, the full image or a text reference to the scene, as \"safe.\" We define the core ability of VLMs enabling this attack as $\\textit{visual stitching}$ -- the ability to integrate visual information spread across multiple training samples that share the same textual descriptions. In our work, we first demonstrate visual stitching abilities in common open-source VLMs on three datasets where each image is labeled with a unique synthetic ID: we split each $(\\texttt{image}, \\texttt{ID})$ pair into $\\{(\\texttt{patch}, \\texttt{ID})\\}$ pairs at different granularity for finetuning, and we find that tuned models can verbalize the correct IDs from full images or text reference. Building on this, we simulate the adversarial data poisoning scenario mentioned above by using patches from dangerous images and replacing IDs with text descriptions like ``safe'' or ``unsafe'', demonstrating how harmful content can evade moderation in patches and later be reconstructed through visual stitching, posing serious VLM safety risks. Code is available at https://github.com/ZHZisZZ/visual-stitching.","authors":["Zhanhui Zhou","Lingjie Chen","Chao Yang","Chaochao Lu"],"url":"https://arxiv.org/abs/2506.03614"}
{"created":"2025-06-05","title":"Isharah: A Large-Scale Multi-Scene Dataset for Continuous Sign Language Recognition","abstract":"Current benchmarks for sign language recognition (SLR) focus mainly on isolated SLR, while there are limited datasets for continuous SLR (CSLR), which recognizes sequences of signs in a video. Additionally, existing CSLR datasets are collected in controlled settings, which restricts their effectiveness in building robust real-world CSLR systems. To address these limitations, we present Isharah, a large multi-scene dataset for CSLR. It is the first dataset of its type and size that has been collected in an unconstrained environment using signers' smartphone cameras. This setup resulted in high variations of recording settings, camera distances, angles, and resolutions. This variation helps with developing sign language understanding models capable of handling the variability and complexity of real-world scenarios. The dataset consists of 30,000 video clips performed by 18 deaf and professional signers. Additionally, the dataset is linguistically rich as it provides a gloss-level annotation for all dataset's videos, making it useful for developing CSLR and sign language translation (SLT) systems. This paper also introduces multiple sign language understanding benchmarks, including signer-independent and unseen-sentence CSLR, along with gloss-based and gloss-free SLT. The Isharah dataset is available on https://snalyami.github.io/Isharah_CSLR/.","authors":["Sarah Alyami","Hamzah Luqman","Sadam Al-Azani","Maad Alowaifeer","Yazeed Alharbi","Yaser Alonaizan"],"url":"https://arxiv.org/abs/2506.03615"}
{"created":"2025-06-05","title":"Learning to Insert [PAUSE] Tokens for Better Reasoning","abstract":"To enhance reasoning capabilities, previous works have explored incorporating special-purpose tokens into the training process. These strategies strengthen the learning mechanism of transformer-based large language models (LLMs). Building on prior research, in which inserting dummy tokens consecutively just before reasoning steps can enhance effectiveness, we introduce a novel approach termed Dynamic Inserting Tokens Training (DIT). Our method identifies positions within sequences where model confidence is lowest according to token log-likelihood. Strategically inserting [PAUSE] tokens on these positions bolsters the model's predictive capabilities for subsequent tokens. Experimental results across diverse datasets and models, from the 2.7B model to the 8B model, demonstrate that DIT consistently outperforms traditional fine-tuning and previous token insertion methods. With this simple yet effective method, we achieve accuracy gains of up to 4.7%p on GSM8K, 3.23%p on AQUA-RAT, and pass@1 improvements of up to 3.4%p on MBPP datasets. Our work shows a model-based, dynamic approach rather than a heuristic one, thereby broadening the scope of research in reasoning.","authors":["Eunki Kim","Sangryul Kim","James Thorne"],"url":"https://arxiv.org/abs/2506.03616"}
{"created":"2025-06-05","title":"MatExPre: A matrix exponential preconditioner for the high-frequency Helmholtz equation","abstract":"In this article, we present a new preconditioner, MatExPre, for the high-frequency Helmholtz equation by leveraging the properties of matrix exponentials. Our approach begins by reformulating the Helmholtz equation into a Schr\\\"{o}dinger-like equation and constructing a time-domain solver based on a fixed-point iteration. We then establish a rigorous connection between the time-domain solver and matrix exponential integrators, which enables us to derive algebraic preconditioners that rely solely on sparse matrix-vector products. Spectral analysis and a detailed numerical implementation strategy, including performance improvements achieved through complex shifting, are discussed. Finally, numerical experiments on 2D and large-scale 3D homogeneous and inhomogeneous models, including benchmark seismic examples, substantiate the effectiveness and scalability of the proposed methods.","authors":["Shubin Fu","Qing Huo Liu","Qiwei Zhan","Eric T. Chung","Changqing Ye"],"url":"https://arxiv.org/abs/2506.03617"}
{"created":"2025-06-05","title":"GCFL: A Gradient Correction-based Federated Learning Framework for Privacy-preserving CPSS","abstract":"Federated learning, as a distributed architecture, shows great promise for applications in Cyber-Physical-Social Systems (CPSS). In order to mitigate the privacy risks inherent in CPSS, the integration of differential privacy with federated learning has attracted considerable attention. Existing research mainly focuses on dynamically adjusting the noise added or discarding certain gradients to mitigate the noise introduced by differential privacy. However, these approaches fail to remove the noise that hinders convergence and correct the gradients affected by the noise, which significantly reduces the accuracy of model classification. To overcome these challenges, this paper proposes a novel framework for differentially private federated learning that balances rigorous privacy guarantees with accuracy by introducing a server-side gradient correction mechanism. Specifically, after clients perform gradient clipping and noise perturbation, our framework detects deviations in the noisy local gradients and employs a projection mechanism to correct them, mitigating the negative impact of noise. Simultaneously, gradient projection promotes the alignment of gradients from different clients and guides the model towards convergence to a global optimum. We evaluate our framework on several benchmark datasets, and the experimental results demonstrate that it achieves state-of-the-art performance under the same privacy budget.","authors":["Jiayi Wan","Xiang Zhu","Fanzhen Liu","Wei Fan","Xiaolong Xu"],"url":"https://arxiv.org/abs/2506.03618"}
{"created":"2025-06-05","title":"Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales","abstract":"Although Large Language Models (LLMs) have demonstrated strong language understanding and generation abilities across various languages, their cultural knowledge is often limited to English-speaking communities, which can marginalize the cultures of non-English communities. To address the problem, evaluation of the cultural awareness of the LLMs and the methods to develop culturally aware LLMs have been investigated. In this study, we focus on evaluating knowledge of folktales, a key medium for conveying and circulating culture. In particular, we focus on Japanese folktales, specifically on knowledge of Yokai. Yokai are supernatural creatures originating from Japanese folktales that continue to be popular motifs in art and entertainment today. Yokai have long served as a medium for cultural expression, making them an ideal subject for assessing the cultural awareness of LLMs. We introduce YokaiEval, a benchmark dataset consisting of 809 multiple-choice questions (each with four options) designed to probe knowledge about yokai. We evaluate the performance of 31 Japanese and multilingual LLMs on this dataset. The results show that models trained with Japanese language resources achieve higher accuracy than English-centric models, with those that underwent continued pretraining in Japanese, particularly those based on Llama-3, performing especially well. The code and dataset are available at https://github.com/CyberAgentA ILab/YokaiEval.","authors":["Ayuto Tsutsumi","Yuu Jinnai"],"url":"https://arxiv.org/abs/2506.03619"}
{"created":"2025-06-05","title":"Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation","abstract":"We present Subject Fidelity Optimization (SFO), a novel comparative learning framework for zero-shot subject-driven generation that enhances subject fidelity. Beyond supervised fine-tuning methods that rely only on positive targets and use the diffusion loss as in the pre-training stage, SFO introduces synthetic negative targets and explicitly guides the model to favor positives over negatives through pairwise comparison. For negative targets, we propose Condition-Degradation Negative Sampling (CDNS), which automatically generates distinctive and informative negatives by intentionally degrading visual and textual cues without expensive human annotations. Moreover, we reweight the diffusion timesteps to focus finetuning on intermediate steps where subject details emerge. Extensive experiments demonstrate that SFO with CDNS significantly outperforms baselines in terms of both subject fidelity and text alignment on a subject-driven generation benchmark. Project page: https://subjectfidelityoptimization.github.io/","authors":["Chaehun Shin","Jooyoung Choi","Johan Barthelemy","Jungbeom Lee","Sungroh Yoon"],"url":"https://arxiv.org/abs/2506.03621"}
{"created":"2025-06-05","title":"Beamforming for Secure RSMA-Aided ISAC Systems","abstract":"This work investigates the physical layer security of rate-splitting multiple access (RSMA)-aided integrated communication and sensing (ISAC) systems. The ISAC base station (BS) transmits signals to communicate with users in an eavesdropped scenario and to estimate the parameters of the sensed targets. The research considers different sensing signals under RSMA technology and the Cram{\\'{e}}r-Rao bound of the parameter estimation is utilized as the sensing metric. With the channel state information (CSI) of eavesdroppers known, the transmitting beam of the BS is optimized to maximize the energy efficiency in terms of the minimum user rate and secrecy capacity, considering the fairness among users and ensuring the sensing performance and communication security. With the CSI of eavesdroppers unknown, the transmitting beam of the BS is designed to minimize the energy consumption for sensing and communication, and the residual power is utilized for artificial noise, which is isotropically emitted to achieve interference with potential eavesdroppers. To solve the non-convex problems, three iterative algorithms based on successive convex approximation and penalty function are proposed. The simulation results illustrate the effectiveness of the proposed schemes.","authors":["Qian Dan","Hongjiang Lei","Ki-Hong Park","Gaofeng Pan"],"url":"https://arxiv.org/abs/2506.03622"}
{"created":"2025-06-05","title":"Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance across various tasks by effectively utilizing a prompting strategy. However, they are highly sensitive to input perturbations, such as typographical errors or slight character order errors, which can substantially degrade their performance. Despite advances in prompting techniques, developing a prompting strategy that explicitly mitigates the negative impact of such perturbations remains an open challenge. To bridge this gap, we propose Robustness of Prompting (RoP), a novel prompting strategy specifically designed to enhance the robustness of LLMs. RoP consists of two stages: Error Correction and Guidance. In the Error Correction stage, RoP applies diverse perturbation methods to generate adversarial examples, which are then used to construct prompts that automatically correct input errors. In the Guidance stage, RoP generates an optimal guidance prompting based on the corrected input, steering the model toward more robust and accurate inferences. Through comprehensive experiments spanning arithmetic, commonsense, and logical reasoning tasks, we demonstrate that RoP significantly improves LLMs' robustness against adversarial perturbations. Notably, it maintains model accuracy with only minimal degradation compared to clean input scenarios, thereby establishing RoP as a practical and effective approach for enhancing LLM robustness in real-world applications.","authors":["Lin Mu","Guowei Chu","Li Ni","Lei Sang","Zhize Wu","Peiquan Jin","Yiwen Zhang"],"url":"https://arxiv.org/abs/2506.03627"}
{"created":"2025-06-05","title":"FingerVeinSyn-5M: A Million-Scale Dataset and Benchmark for Finger Vein Recognition","abstract":"A major challenge in finger vein recognition is the lack of large-scale public datasets. Existing datasets contain few identities and limited samples per finger, restricting the advancement of deep learning-based methods. To address this, we introduce FVeinSyn, a synthetic generator capable of producing diverse finger vein patterns with rich intra-class variations. Using FVeinSyn, we created FingerVeinSyn-5M -- the largest available finger vein dataset -- containing 5 million samples from 50,000 unique fingers, each with 100 variations including shift, rotation, scale, roll, varying exposure levels, skin scattering blur, optical blur, and motion blur. FingerVeinSyn-5M is also the first to offer fully annotated finger vein images, supporting deep learning applications in this field. Models pretrained on FingerVeinSyn-5M and fine-tuned with minimal real data achieve an average 53.91\\% performance gain across multiple benchmarks. The dataset is publicly available at: https://github.com/EvanWang98/FingerVeinSyn-5M.","authors":["Yinfan Wang","Jie Gui","Baosheng Yu","Qi Li","Zhenan Sun","Juho Kannala","Guoying Zhao"],"url":"https://arxiv.org/abs/2506.03635"}
{"created":"2025-06-05","title":"RewardAnything: Generalizable Principle-Following Reward Models","abstract":"Reward Models, essential for guiding Large Language Model optimization, are typically trained on fixed preference datasets, resulting in rigid alignment to single, implicit preference distributions. This prevents adaptation to diverse real-world needs-from conciseness in one task to detailed explanations in another. The standard practice of collecting task-specific preference data and retraining reward models is resource-intensive, often producing biased rewards, and limits practical application. We introduce generalizable, principle-following reward models. We propose that RMs should understand and adhere to dynamically provided natural language specifications of reward principles, similar to instruction-following in LLMs. To measure this capability, we develop RABench, a comprehensive benchmark for RMs focusing on generalization across diverse principles. Evaluations on RABench reveal poor generalization of current RMs. As a solution, we present RewardAnything, a novel RM designed and trained to explicitly follow natural language principles. We achieve SotA performance with RewardAnything in traditional RM benchmark simply by specifying a well-defined principle, and results on RABench show we excel in adapting to novel principles without retraining. Furthermore, RewardAnything integrates seamlessly with existing RLHF methods and we show by a case study on how to automatically and efficiently align LLMs with only natural language principles.","authors":["Zhuohao Yu","Jiali Zeng","Weizheng Gu","Yidong Wang","Jindong Wang","Fandong Meng","Jie Zhou","Yue Zhang","Shikun Zhang","Wei Ye"],"url":"https://arxiv.org/abs/2506.03637"}
{"created":"2025-06-05","title":"Stability Notions for Hospital Residents with Sizes","abstract":"The Hospital Residents problem with sizes (HRS) is a generalization of the well-studied hospital residents (HR) problem. In the HRS problem, an agent $a$ has a size $s(a)$ and the agent occupies $s(a)$ many positions of the hospital $h$ when assigned to $h$. The notion of stability in this setting is suitably modified, and it is known that deciding whether an HRS instance admits a stable matching is NP-hard under severe restrictions. In this work, we explore a variation of stability, which we term occupancy-based stability. This notion was defined by McDermid and Manlove in their work, however, to the best of our knowledge, this notion remains unexplored. We show that every HRS instance admits an occupancy-stable matching. We further show that computing a maximum-size occupancy-stable matching is NP-hard. We complement our hardness result by providing a linear-time 3-approximation algorithm for the max-size occupancy-stable matching problem. Given that the classical notion of stability adapted for HRS is not guaranteed to exist in general, we show a practical restriction under which a stable matching is guaranteed to exist. We present an efficient algorithm to output a stable matching in the restricted HRS instances. We also provide an alternate NP-hardness proof for the decision version of the stable matching problem for HRS which imposes a severe restriction on the number of neighbours of non-unit sized agents.","authors":["Haricharan Balasundaram","J B Krishnashree","Girija Limaye","Meghana Nasre"],"url":"https://arxiv.org/abs/2506.03638"}
{"created":"2025-06-05","title":"Spatial Understanding from Videos: Structured Prompts Meet Simulation Data","abstract":"Visual-spatial understanding, the ability to infer object relationships and layouts from visual input, is fundamental to downstream tasks such as robotic navigation and embodied interaction. However, existing methods face spatial uncertainty and data scarcity, limiting the 3D spatial reasoning capability of pre-trained vision-language models (VLMs). To address these challenges, we present a unified framework for enhancing 3D spatial reasoning in pre-trained VLMs without modifying their architecture. This framework combines SpatialMind, a structured prompting strategy that decomposes complex scenes and questions into interpretable reasoning steps, with ScanForgeQA, a scalable question-answering dataset built from diverse 3D simulation scenes through an automated construction process designed for fine-tuning. Extensive experiments across multiple benchmarks demonstrate the individual and combined effectiveness of our prompting and fine-tuning strategies, and yield insights that may inspire future research on visual-spatial understanding.","authors":["Haoyu Zhang","Meng Liu","Zaijing Li","Haokun Wen","Weili Guan","Yaowei Wang","Liqiang Nie"],"url":"https://arxiv.org/abs/2506.03642"}
{"created":"2025-06-05","title":"Images are Worth Variable Length of Representations","abstract":"Most existing vision encoders map images into a fixed-length sequence of tokens, overlooking the fact that different images contain varying amounts of information. For example, a visually complex image (e.g., a cluttered room) inherently carries more information and thus deserves more tokens than a simple image (e.g., a blank wall). To address this inefficiency, we propose DOVE, a dynamic vision encoder that produces a variable number of visual tokens (i.e., continuous representation vectors) to reconstruct each image. Our results show that DOVE significantly reduces the average number of tokens while maintaining high reconstruction quality. In several linear probing and downstream multimodal tasks, it outperforms existing autoencoder-based tokenization methods when using far fewer tokens, capturing more expressive semantic features compared to fixed-length encoding. We further extend DOVE with query-conditioned tokenization. By guiding the model to focus on query-relevant regions, it achieves more efficient and targeted semantic extraction. Our code and checkpoints are available at https://dove-encoder.github.io/dove-encoder.","authors":["Lingjun Mao","Rodolfo Corona","Xin Liang","Wenhao Yan","Zineng Tang"],"url":"https://arxiv.org/abs/2506.03643"}
{"created":"2025-06-05","title":"YOND: Practical Blind Raw Image Denoising Free from Camera-Specific Data Dependency","abstract":"The rapid advancement of photography has created a growing demand for a practical blind raw image denoising method. Recently, learning-based methods have become mainstream due to their excellent performance. However, most existing learning-based methods suffer from camera-specific data dependency, resulting in performance drops when applied to data from unknown cameras. To address this challenge, we introduce a novel blind raw image denoising method named YOND, which represents You Only Need a Denoiser. Trained solely on synthetic data, YOND can generalize robustly to noisy raw images captured by diverse unknown cameras. Specifically, we propose three key modules to guarantee the practicality of YOND: coarse-to-fine noise estimation (CNE), expectation-matched variance-stabilizing transform (EM-VST), and SNR-guided denoiser (SNR-Net). Firstly, we propose CNE to identify the camera noise characteristic, refining the estimated noise parameters based on the coarse denoised image. Secondly, we propose EM-VST to eliminate camera-specific data dependency, correcting the bias expectation of VST according to the noisy image. Finally, we propose SNR-Net to offer controllable raw image denoising, supporting adaptive adjustments and manual fine-tuning. Extensive experiments on unknown cameras, along with flexible solutions for challenging cases, demonstrate the superior practicality of our method. The source code will be publicly available at the \\href{https://fenghansen.github.io/publication/YOND}{project homepage}.","authors":["Hansen Feng","Lizhi Wang","Yiqi Huang","Tong Li","Lin Zhu","Hua Huang"],"url":"https://arxiv.org/abs/2506.03645"}
{"created":"2025-06-05","title":"Fast Sampling for System Identification: Overcoming Noise, Offsets, and Closed-Loop Challenges with State Variable Filter","abstract":"This paper investigates the effects of setting the sampling frequency significantly higher than conventional guidelines in system identification. Although continuous-time identification methods resolve the numerical difficulties encountered in discrete-time approaches when employing fast sampling (e.g., the problems caused by all poles approaching unity), the potential benefits of using sampling frequencies that far exceed traditional rules like the \"ten times the bandwidth\" guideline remained largely unexplored. We show that using a state variable filter (SVF)-like least squares approach, the variance of the estimation error scales as $O(h)$ with the sampling interval $h$. Importantly, this scaling holds even with colored noise or noise correlations between variables. Thus, increasing the sampling frequency and applying the SVF method offers a novel solution for challenging problems such as closed-loop system identification and measurements with offsets. Theoretical findings are supported by numerical examples, including the closed-loop identification of unstable multi-input multi-output (MIMO) systems.","authors":["Ichiro Maruta","Toshiharu Sugie"],"url":"https://arxiv.org/abs/2506.03650"}
{"created":"2025-06-05","title":"Mono: Is Your \"Clean\" Vulnerability Dataset Really Solvable? Exposing and Trapping Undecidable Patches and Beyond","abstract":"The quantity and quality of vulnerability datasets are essential for developing deep learning solutions to vulnerability-related tasks. Due to the limited availability of vulnerabilities, a common approach to building such datasets is analyzing security patches in source code. However, existing security patches often suffer from inaccurate labels, insufficient contextual information, and undecidable patches that fail to clearly represent the root causes of vulnerabilities or their fixes. These issues introduce noise into the dataset, which can mislead detection models and undermine their effectiveness. To address these issues, we present mono, a novel LLM-powered framework that simulates human experts' reasoning process to construct reliable vulnerability datasets. mono introduces three key components to improve security patch datasets: (i) semantic-aware patch classification for precise vulnerability labeling, (ii) iterative contextual analysis for comprehensive code understanding, and (iii) systematic root cause analysis to identify and filter undecidable patches. Our comprehensive evaluation on the MegaVul benchmark demonstrates that mono can correct 31.0% of labeling errors, recover 89% of inter-procedural vulnerabilities, and reveals that 16.7% of CVEs contain undecidable patches. Furthermore, mono's enriched context representation improves existing models' vulnerability detection accuracy by 15%. We open source the framework mono and the dataset MonoLens in https://github.com/vul337/mono.","authors":["Zeyu Gao","Junlin Zhou","Bolun Zhang","Yi He","Chao Zhang","Yuxin Cui","Hao Wang"],"url":"https://arxiv.org/abs/2506.03651"}
{"created":"2025-06-05","title":"EmoArt: A Multidimensional Dataset for Emotion-Aware Artistic Generation","abstract":"With the rapid advancement of diffusion models, text-to-image generation has achieved significant progress in image resolution, detail fidelity, and semantic alignment, particularly with models like Stable Diffusion 3.5, Stable Diffusion XL, and FLUX 1. However, generating emotionally expressive and abstract artistic images remains a major challenge, largely due to the lack of large-scale, fine-grained emotional datasets. To address this gap, we present the EmoArt Dataset -- one of the most comprehensive emotion-annotated art datasets to date. It contains 132,664 artworks across 56 painting styles (e.g., Impressionism, Expressionism, Abstract Art), offering rich stylistic and cultural diversity. Each image includes structured annotations: objective scene descriptions, five key visual attributes (brushwork, composition, color, line, light), binary arousal-valence labels, twelve emotion categories, and potential art therapy effects. Using EmoArt, we systematically evaluate popular text-to-image diffusion models for their ability to generate emotionally aligned images from text. Our work provides essential data and benchmarks for emotion-driven image synthesis and aims to advance fields such as affective computing, multimodal learning, and computational art, enabling applications in art therapy and creative design. The dataset and more details can be accessed via our project website.","authors":["Cheng Zhang","Hongxia xie","Bin Wen","Songhan Zuo","Ruoxuan Zhang","Wen-huang Cheng"],"url":"https://arxiv.org/abs/2506.03652"}
{"created":"2025-06-05","title":"MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection","abstract":"Real-time object detection is a fundamental but challenging task in computer vision, particularly when computational resources are limited. Although YOLO-series models have set strong benchmarks by balancing speed and accuracy, the increasing need for richer global context modeling has led to the use of Transformer-based architectures. Nevertheless, Transformers have high computational complexity because of their self-attention mechanism, which limits their practicality for real-time and edge deployments. To overcome these challenges, recent developments in linear state space models, such as Mamba, provide a promising alternative by enabling efficient sequence modeling with linear complexity. Building on this insight, we propose MambaNeXt-YOLO, a novel object detection framework that balances accuracy and efficiency through three key contributions: (1) MambaNeXt Block: a hybrid design that integrates CNNs with Mamba to effectively capture both local features and long-range dependencies; (2) Multi-branch Asymmetric Fusion Pyramid Network (MAFPN): an enhanced feature pyramid architecture that improves multi-scale object detection across various object sizes; and (3) Edge-focused Efficiency: our method achieved 66.6\\% mAP at 31.9 FPS on the PASCAL VOC dataset without any pre-training and supports deployment on edge devices such as the NVIDIA Jetson Xavier NX and Orin NX.","authors":["Xiaochun Lei","Siqi Wu","Weilin Wu","Zetao Jiang"],"url":"https://arxiv.org/abs/2506.03654"}
{"created":"2025-06-05","title":"Facts are Harder Than Opinions -- A Multilingual, Comparative Analysis of LLM-Based Fact-Checking Reliability","abstract":"The proliferation of misinformation necessitates scalable, automated fact-checking solutions. Yet, current benchmarks often overlook multilingual and topical diversity. This paper introduces a novel, dynamically extensible data set that includes 61,514 claims in multiple languages and topics, extending existing datasets up to 2024. Through a comprehensive evaluation of five prominent Large Language Models (LLMs), including GPT-4o, GPT-3.5 Turbo, LLaMA 3.1, and Mixtral 8x7B, we identify significant performance gaps between different languages and topics. While overall GPT-4o achieves the highest accuracy, it declines to classify 43% of claims. Across all models, factual-sounding claims are misclassified more often than opinions, revealing a key vulnerability. These findings underscore the need for caution and highlight challenges in deploying LLM-based fact-checking systems at scale.","authors":["Lorraine Saju","Arnim Bleier","Jana Lasser","Claudia Wagner"],"url":"https://arxiv.org/abs/2506.03655"}
{"created":"2025-06-05","title":"Client-Side Zero-Shot LLM Inference for Comprehensive In-Browser URL Analysis","abstract":"Malicious websites and phishing URLs pose an ever-increasing cybersecurity risk, with phishing attacks growing by 40% in a single year. Traditional detection approaches rely on machine learning classifiers or rule-based scanners operating in the cloud, but these face significant challenges in generalization, privacy, and evasion by sophisticated threats. In this paper, we propose a novel client-side framework for comprehensive URL analysis that leverages zero-shot inference by a local large language model (LLM) running entirely in-browser. Our system uses a compact LLM (e.g., 3B/8B parameters) via WebLLM to perform reasoning over rich context collected from the target webpage, including static code analysis (JavaScript abstract syntax trees, structure, and code patterns), dynamic sandbox execution results (DOM changes, API calls, and network requests),and visible content. We detail the architecture and methodology of the system, which combines a real browser sandbox (using iframes) resistant to common anti-analysis techniques, with an LLM-based analyzer that assesses potential vulnerabilities and malicious behaviors without any task-specific training (zero-shot). The LLM aggregates evidence from multiple sources (code, execution trace, page content) to classify the URL as benign or malicious and to provide an explanation of the threats or security issues identified. We evaluate our approach on a diverse set of benign and malicious URLs, demonstrating that even a compact client-side model can achieve high detection accuracy and insightful explanations comparable to cloud-based solutions, while operating privately on end-user devices. The results show that client-side LLM inference is a feasible and effective solution to web threat analysis, eliminating the need to send potentially sensitive data to cloud services.","authors":["Avihay Cohen"],"url":"https://arxiv.org/abs/2506.03656"}
{"created":"2025-06-05","title":"Time discretization of a semi-discrete scheme for 3D Chemotaxis-Navier-Stokes system driven by transport noise","abstract":"This work is devoted to the convergence of a time-discrete numerical scheme of a semi-discretization model arising from biology, consisting of a chemotaxis equation coupled with a Galerkin approximation of Navier-Stokes system driven by transport noise in a three-dimensional bounded and convex domain. We propose a semi-implicit Euler numerical scheme approximating the infinite dimensional model, for which we study the well-posedness and derive some uniform estimates for the discrete variables","authors":["Erika Hausenblas","Boris Jidjou Moghomye","Paul Andre Razafimandimby"],"url":"https://arxiv.org/abs/2506.03658"}
{"created":"2025-06-05","title":"Trustworthy Medical Question Answering: An Evaluation-Centric Survey","abstract":"Trustworthiness in healthcare question-answering (QA) systems is important for ensuring patient safety, clinical effectiveness, and user confidence. As large language models (LLMs) become increasingly integrated into medical settings, the reliability of their responses directly influences clinical decision-making and patient outcomes. However, achieving comprehensive trustworthiness in medical QA poses significant challenges due to the inherent complexity of healthcare data, the critical nature of clinical scenarios, and the multifaceted dimensions of trustworthy AI. In this survey, we systematically examine six key dimensions of trustworthiness in medical QA, i.e., Factuality, Robustness, Fairness, Safety, Explainability, and Calibration. We review how each dimension is evaluated in existing LLM-based medical QA systems. We compile and compare major benchmarks designed to assess these dimensions and analyze evaluation-guided techniques that drive model improvements, such as retrieval-augmented grounding, adversarial fine-tuning, and safety alignment. Finally, we identify open challenges-such as scalable expert evaluation, integrated multi-dimensional metrics, and real-world deployment studies-and propose future research directions to advance the safe, reliable, and transparent deployment of LLM-powered medical QA.","authors":["Yinuo Wang","Robert E. Mercer","Frank Rudzicz","Sudipta Singha Roy","Pengjie Ren","Zhumin Chen","Xindi Wang"],"url":"https://arxiv.org/abs/2506.03659"}
{"created":"2025-06-05","title":"INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning","abstract":"Anomaly detection (AD) is essential for industrial inspection and medical diagnosis, yet existing methods typically rely on ``comparing'' test images to normal references from a training set. However, variations in appearance and positioning often complicate the alignment of these references with the test image, limiting detection accuracy. We observe that most anomalies manifest as local variations, meaning that even within anomalous images, valuable normal information remains. We argue that this information is useful and may be more aligned with the anomalies since both the anomalies and the normal information originate from the same image. Therefore, rather than relying on external normality from the training set, we propose INP-Former, a novel method that extracts Intrinsic Normal Prototypes (INPs) directly from the test image. Specifically, we introduce the INP Extractor, which linearly combines normal tokens to represent INPs. We further propose an INP Coherence Loss to ensure INPs can faithfully represent normality for the testing image. These INPs then guide the INP-guided Decoder to reconstruct only normal tokens, with reconstruction errors serving as anomaly scores. Additionally, we propose a Soft Mining Loss to prioritize hard-to-optimize samples during training. INP-Former achieves state-of-the-art performance in single-class, multi-class, and few-shot AD tasks across MVTec-AD, VisA, and Real-IAD, positioning it as a versatile and universal solution for AD. Remarkably, INP-Former also demonstrates some zero-shot AD capability. Furthermore, we propose a soft version of the INP Coherence Loss and enhance INP-Former by incorporating residual learning, leading to the development of INP-Former++. The proposed method significantly improves detection performance across single-class, multi-class, semi-supervised, few-shot, and zero-shot settings.","authors":["Wei Luo","Haiming Yao","Yunkang Cao","Qiyu Chen","Ang Gao","Weiming Shen","Weihang Zhang","Wenyong Yu"],"url":"https://arxiv.org/abs/2506.03660"}
{"created":"2025-06-05","title":"Zero-Shot Temporal Interaction Localization for Egocentric Videos","abstract":"Locating human-object interaction (HOI) actions within video serves as the foundation for multiple downstream tasks, such as human behavior analysis and human-robot skill transfer. Current temporal action localization methods typically rely on annotated action and object categories of interactions for optimization, which leads to domain bias and low deployment efficiency. Although some recent works have achieved zero-shot temporal action localization (ZS-TAL) with large vision-language models (VLMs), their coarse-grained estimations and open-loop pipelines hinder further performance improvements for temporal interaction localization (TIL). To address these issues, we propose a novel zero-shot TIL approach dubbed EgoLoc to locate the timings of grasp actions for human-object interaction in egocentric videos. EgoLoc introduces a self-adaptive sampling strategy to generate reasonable visual prompts for VLM reasoning. By absorbing both 2D and 3D observations, it directly samples high-quality initial guesses around the possible contact/separation timestamps of HOI according to 3D hand velocities, leading to high inference accuracy and efficiency. In addition, EgoLoc generates closed-loop feedback from visual and dynamic cues to further refine the localization results. Comprehensive experiments on the publicly available dataset and our newly proposed benchmark demonstrate that EgoLoc achieves better temporal interaction localization for egocentric videos compared to state-of-the-art baselines. We will release our code and relevant data as open-source at https://github.com/IRMVLab/EgoLoc.","authors":["Erhang Zhang","Junyi Ma","Yin-Dong Zheng","Yixuan Zhou","Hesheng Wang"],"url":"https://arxiv.org/abs/2506.03662"}
{"created":"2025-06-05","title":"An Improved Grey Wolf Optimizer Inspired by Advanced Cooperative Predation for UAV Shortest Path Planning","abstract":"With the widespread application of Unmanned Aerial Vehicles (UAVs) in domains like military reconnaissance, emergency rescue, and logistics delivery, efficiently planning the shortest flight path has become a critical challenge. Traditional heuristic-based methods often suffer from the inability to escape from local optima, which limits their effectiveness in finding the shortest path. To address these issues, a novel Improved Grey Wolf Optimizer (IGWO) is presented in this study. The proposed IGWO incorporates an Advanced Cooperative Predation (ACP) and a Lens Opposition-based Learning Strategy (LOBL) in order to improve the optimization capability of the method. Simulation results show that IGWO ranks first in optimization performance on benchmark functions F1-F5, F7, and F9-F12, outperforming all other compared algorithms. Subsequently, IGWO is applied to UAV shortest path planning in various obstacle-laden environments. Simulation results show that the paths planned by IGWO are, on average, shorter than those planned by GWO, PSO, and WOA by 1.70m, 1.68m, and 2.00m, respectively, across four different maps.","authors":["Zuhao Teng","Qian Dong","Ze Zhang","Shuangyao Huang","Wenzhang Zhang","Jingchen Wang","Ji Li","Xi Chen"],"url":"https://arxiv.org/abs/2506.03663"}
{"created":"2025-06-05","title":"Intersectional Bias in Pre-Trained Image Recognition Models","abstract":"Deep Learning models have achieved remarkable success. Training them is often accelerated by building on top of pre-trained models which poses the risk of perpetuating encoded biases. Here, we investigate biases in the representations of commonly used ImageNet classifiers for facial images while considering intersections of sensitive variables age, race and gender. To assess the biases, we use linear classifier probes and visualize activations as topographic maps. We find that representations in ImageNet classifiers particularly allow differentiation between ages. Less strongly pronounced, the models appear to associate certain ethnicities and distinguish genders in middle-aged groups.","authors":["Valerie Krug","Sebastian Stober"],"url":"https://arxiv.org/abs/2506.03664"}
{"created":"2025-06-05","title":"ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling","abstract":"Visually impaired people could benefit from Visual Question Answering (VQA) systems to interpret text in their surroundings. However, current models often struggle with recognizing text in the photos taken by this population. Through in-depth interviews with visually impaired individuals, we identified common framing conventions that frequently result in misaligned text. Existing VQA benchmarks primarily feature well-oriented text captured by sighted users, under-representing these challenges. To address this gap, we introduce ROtated SAmpling (ROSA), a decoding strategy that enhances VQA performance in text-rich images with incorrectly oriented text. ROSA outperforms Greedy decoding by 11.7 absolute points in the best-performing model.","authors":["Hern\\'an Maina","Guido Ivetta","Mateo Lione Stuto","Julian Martin Eisenschlos","Jorge S\\'anchez","Luciana Benotti"],"url":"https://arxiv.org/abs/2506.03665"}
{"created":"2025-06-05","title":"Accelerating SfM-based Pose Estimation with Dominating Set","abstract":"This paper introduces a preprocessing technique to speed up Structure-from-Motion (SfM) based pose estimation, which is critical for real-time applications like augmented reality (AR), virtual reality (VR), and robotics. Our method leverages the concept of a dominating set from graph theory to preprocess SfM models, significantly enhancing the speed of the pose estimation process without losing significant accuracy. Using the OnePose dataset, we evaluated our method across various SfM-based pose estimation techniques. The results demonstrate substantial improvements in processing speed, ranging from 1.5 to 14.48 times, and a reduction in reference images and point cloud size by factors of 17-23 and 2.27-4, respectively. This work offers a promising solution for efficient and accurate 3D pose estimation, balancing speed and accuracy in real-time applications.","authors":["Joji Joseph","Bharadwaj Amrutur","Shalabh Bhatnagar"],"url":"https://arxiv.org/abs/2506.03667"}
{"created":"2025-06-05","title":"Reason from Future: Reverse Thought Chain Enhances LLM Reasoning","abstract":"It has been demonstrated that carefully designed reasoning paradigms, like Chain-of-Thought (CoT) and Tree-of-Thought (ToT), can enhance the reasoning capabilities of small language models by detailed thinking and extensive thought searching, unbounded branching factors in the searching space create prohibitive reasoning consumption. However these methods fall into the trap of local optimum reasoning, which means the model lacks a global perspective while solving problems. We propose a novel reasoning paradigm called Reason from Future (RFF), which generates reasoning paths by bidirectional reasoning that combines top-down planning with bottom-up reasoning accumulation. The essence of RFF lies in its reverse reasoning mechanism, which prioritizes core logical relationships and imposes goal-oriented constraints on intermediate steps, thereby reducing the searching space and mitigating error accumulation inherent in sequential forward reasoning. Empirical evaluations across diverse experiments demonstrate that RFF outperforms conventional paradigms with higher accuracy and less searching space to solve complex tasks.","authors":["Yinlong Xu","Yanzhao Zheng","Shuoshuo Sun","Shuaihan Huang","Baohua Dong","Hangcheng Zhu","Ruohui Huang","Gang Yu","Hongxia Xu","Jian Wu"],"url":"https://arxiv.org/abs/2506.03673"}
{"created":"2025-06-05","title":"Out-of-Distribution Graph Models Merging","abstract":"This paper studies a novel problem of out-of-distribution graph models merging, which aims to construct a generalized model from multiple graph models pre-trained on different domains with distribution discrepancy. This problem is challenging because of the difficulty in learning domain-invariant knowledge implicitly in model parameters and consolidating expertise from potentially heterogeneous GNN backbones. In this work, we propose a graph generation strategy that instantiates the mixture distribution of multiple domains. Then, we merge and fine-tune the pre-trained graph models via a MoE module and a masking mechanism for generalized adaptation. Our framework is architecture-agnostic and can operate without any source/target domain data. Both theoretical analysis and experimental results demonstrate the effectiveness of our approach in addressing the model generalization problem.","authors":["Yidi Wang","Jiawei Gu","pei Xiaobing","Xubin Zheng","Xiao Luo","Pengyang Wang","Ziyue Qiao"],"url":"https://arxiv.org/abs/2506.03674"}
{"created":"2025-06-05","title":"BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation","abstract":"Utilizing multi-modal data enhances scene understanding by providing complementary semantic and geometric information. Existing methods fuse features or distill knowledge from multiple modalities into a unified representation, improving robustness but restricting each modality's ability to fully leverage its strengths in different situations. We reformulate multi-modal semantic segmentation as a mask-level classification task and propose BiXFormer, which integrates Unified Modality Matching (UMM) and Cross Modality Alignment (CMA) to maximize modality effectiveness and handle missing modalities. Specifically, BiXFormer first categorizes multi-modal inputs into RGB and X, where X represents any non-RGB modalities, e.g., depth, allowing separate processing for each. This design leverages the well-established pretraining for RGB, while addressing the relative lack of attention to X modalities. Then, we propose UMM, which includes Modality Agnostic Matching (MAM) and Complementary Matching (CM). MAM assigns labels to features from all modalities without considering modality differences, leveraging each modality's strengths. CM then reassigns unmatched labels to remaining unassigned features within their respective modalities, ensuring that each available modality contributes to the final prediction and mitigating the impact of missing modalities. Moreover, to further facilitate UMM, we introduce CMA, which enhances the weaker queries assigned in CM by aligning them with optimally matched queries from MAM. Experiments on both synthetic and real-world multi-modal benchmarks demonstrate the effectiveness of our method, achieving significant improvements in mIoU of +2.75% and +22.74% over the prior arts.","authors":["Jialei Chen","Xu Zheng","Danda Pani Paudel","Luc Van Gool","Hiroshi Murase","Daisuke Deguchi"],"url":"https://arxiv.org/abs/2506.03675"}
{"created":"2025-06-05","title":"Efficient Data Selection for Domain Adaptation of ASR Using Pseudo-Labels and Multi-Stage Filtering","abstract":"Fine-tuning pretrained ASR models for specific domains is challenging for small organizations with limited labeled data and computational resources. Here, we explore different data selection pipelines and propose a robust approach that improves ASR adaptation by filtering pseudo-labels generated using Whisper (encoder-decoder) and Zipformer (transducer) models. Our approach integrates multiple selection strategies -- including word error rate (WER) prediction, named entity recognition (NER), and character error rate (CER) analysis -- to extract high-quality training segments. We evaluate our method on Whisper and Zipformer using a 7500-hour baseline, comparing it to a CER-based approach relying on hypotheses from three ASR systems. Fine-tuning on 7500 hours of pseudo-labeled call center data achieves 12.3% WER, while our filtering reduces the dataset to 100 hours (1.4%) with similar performance; a similar trend is observed on Fisher English.","authors":["Pradeep Rangappa","Andres Carofilis","Jeena Prakash","Shashi Kumar","Sergio Burdisso","Srikanth Madikeri","Esau Villatoro-Tello","Bidisha Sharma","Petr Motlicek","Kadri Hacioglu","Shankar Venkatesan","Saurabh Vyas","Andreas Stolcke"],"url":"https://arxiv.org/abs/2506.03681"}
{"created":"2025-06-05","title":"How PARTs assemble into wholes: Learning the relative composition of images","abstract":"The composition of objects and their parts, along with object-object positional relationships, provides a rich source of information for representation learning. Hence, spatial-aware pretext tasks have been actively explored in self-supervised learning. Existing works commonly start from a grid structure, where the goal of the pretext task involves predicting the absolute position index of patches within a fixed grid. However, grid-based approaches fall short of capturing the fluid and continuous nature of real-world object compositions. We introduce PART, a self-supervised learning approach that leverages continuous relative transformations between off-grid patches to overcome these limitations. By modeling how parts relate to each other in a continuous space, PART learns the relative composition of images-an off-grid structural relative positioning process that generalizes beyond occlusions and deformations. In tasks requiring precise spatial understanding such as object detection and time series prediction, PART outperforms strong grid-based methods like MAE and DropPos, while also maintaining competitive performance on global classification tasks with minimal hyperparameter tuning. By breaking free from grid constraints, PART opens up an exciting new trajectory for universal self-supervised pretraining across diverse datatypes-from natural images to EEG signals-with promising potential in video, medical imaging, and audio.","authors":["Melika Ayoughi","Samira Abnar","Chen Huang","Chris Sandino","Sayeri Lala","Eeshan Gunesh Dhekane","Dan Busbridge","Shuangfei Zhai","Vimal Thilak","Josh Susskind","Pascal Mettes","Paul Groth","Hanlin Goh"],"url":"https://arxiv.org/abs/2506.03682"}
{"created":"2025-06-05","title":"PRJ: Perception-Retrieval-Judgement for Generated Images","abstract":"The rapid progress of generative AI has enabled remarkable creative capabilities, yet it also raises urgent concerns regarding the safety of AI-generated visual content in real-world applications such as content moderation, platform governance, and digital media regulation. This includes unsafe material such as sexually explicit images, violent scenes, hate symbols, propaganda, and unauthorized imitations of copyrighted artworks. Existing image safety systems often rely on rigid category filters and produce binary outputs, lacking the capacity to interpret context or reason about nuanced, adversarially induced forms of harm. In addition, standard evaluation metrics (e.g., attack success rate) fail to capture the semantic severity and dynamic progression of toxicity. To address these limitations, we propose Perception-Retrieval-Judgement (PRJ), a cognitively inspired framework that models toxicity detection as a structured reasoning process. PRJ follows a three-stage design: it first transforms an image into descriptive language (perception), then retrieves external knowledge related to harm categories and traits (retrieval), and finally evaluates toxicity based on legal or normative rules (judgement). This language-centric structure enables the system to detect both explicit and implicit harms with improved interpretability and categorical granularity. In addition, we introduce a dynamic scoring mechanism based on a contextual toxicity risk matrix to quantify harmfulness across different semantic dimensions. Experiments show that PRJ surpasses existing safety checkers in detection accuracy and robustness while uniquely supporting structured category-level toxicity interpretation.","authors":["Qiang Fu","Zonglei Jing","Zonghao Ying","Xiaoqian Li"],"url":"https://arxiv.org/abs/2506.03683"}
{"created":"2025-06-05","title":"DSSAU-Net:U-Shaped Hybrid Network for Pubic Symphysis and Fetal Head Segmentation","abstract":"In the childbirth process, traditional methods involve invasive vaginal examinations, but research has shown that these methods are both subjective and inaccurate. Ultrasound-assisted diagnosis offers an objective yet effective way to assess fetal head position via two key parameters: Angle of Progression (AoP) and Head-Symphysis Distance (HSD), calculated by segmenting the fetal head (FH) and pubic symphysis (PS), which aids clinicians in ensuring a smooth delivery process. Therefore, accurate segmentation of FH and PS is crucial. In this work, we propose a sparse self-attention network architecture with good performance and high computational efficiency, named DSSAU-Net, for the segmentation of FH and PS. Specifically, we stack varying numbers of Dual Sparse Selection Attention (DSSA) blocks at each stage to form a symmetric U-shaped encoder-decoder network architecture. For a given query, DSSA is designed to explicitly perform one sparse token selection at both the region and pixel levels, respectively, which is beneficial for further reducing computational complexity while extracting the most relevant features. To compensate for the information loss during the upsampling process, skip connections with convolutions are designed. Additionally, multiscale feature fusion is employed to enrich the model's global and local information. The performance of DSSAU-Net has been validated using the Intrapartum Ultrasound Grand Challenge (IUGC) 2024 \\textit{test set} provided by the organizer in the MICCAI IUGC 2024 competition\\footnote{\\href{https://codalab.lisn.upsaclay.fr/competitions/18413\\#learn\\_the\\_details}{https://codalab.lisn.upsaclay.fr/competitions/18413\\#learn\\_the\\_details}}, where we win the fourth place on the tasks of classification and segmentation, demonstrating its effectiveness. The codes will be available at https://github.com/XiaZunhui/DSSAU-Net.","authors":["Zunhui Xia","Hongxing Li","Libin Lan"],"url":"https://arxiv.org/abs/2506.03684"}
{"created":"2025-06-05","title":"GenTT: Generate Vectorized Codes for General Tensor Permutation","abstract":"Tensor permutation is a fundamental operation widely applied in AI, tensor networks, and related fields. However, it is extremely complex, and different shapes and permutation maps can make a huge difference. SIMD permutation began to be studied in 2006, but the best method at that time was to split complex permutations into multiple simple permutations to do SIMD, which might increase the complexity for very complex permutations. Subsequently, as tensor contraction gained significant attention, researchers explored structured permutations associated with tensor contraction. Progress on general permutations has been limited, and with increasing SIMD bit widths, achieving efficient performance for these permutations has become increasingly challenging. We propose a SIMD permutation toolkit, \\system, that generates optimized permutation code for arbitrary instruction sets, bit widths, tensor shapes, and permutation patterns, while maintaining low complexity. In our experiments, \\system is able to achieve up to $38\\times$ speedup for special cases and $5\\times$ for general gases compared to Numpy.","authors":["Yaojian Chen","Tianyu Ma","An Yang","Lin Gan","Wenlai Zhao","Guangwen Yang"],"url":"https://arxiv.org/abs/2506.03686"}
{"created":"2025-06-05","title":"Understanding Visually Impaired Tramway Passengers Interaction with Public Transport Systems","abstract":"Designing inclusive public transport services is crucial to developing modern, barrier-free smart city infrastructure. This research contributes to the design of inclusive public transport by considering accessibility challenges emerging from socio-technical systems, thus demanding the integration of technological and social solutions. Using Actor-Network Theory (ANT) as a theoretical framework and a mixed-method approach, including shadowing and a focus group, this study examines the socio-technical networks that shape accessibility experiences for visually impaired passengers utilizing the tram in Linz, Austria. Key dimensions that influence public transport accessibility are identified: network configuration, mobility patterns, technology integration, and warning systems. The results show that accessibility emerges from complex interactions between human actors (passengers, staff) and non-human actors (assistive devices, infrastructure) rather than being an inherent property of transport systems. Digital technologies serve multiple functions, from navigational assistance to broader social inclusion, although users comfort with technology varies. Participants emphasized the importance of the two-sense principle for warning signals, with directional audio and tactile feedback particularly valuable.","authors":["Dominik Mimra","Dominik Kaar","Enrico Del Re","Novel Certad","Joshua Cherian Varughese","David Seibt","Cristina Olaverri-Monreal"],"url":"https://arxiv.org/abs/2506.03687"}
{"created":"2025-06-05","title":"On irredundant orthogonal arrays","abstract":"An orthogonal array (OA), denoted by $\\text{OA}(M, n, q, t)$, is an $M \\times n$ matrix over an alphabet of size $q$ such that every selection of $t$ columns contains each possible $t$-tuple exactly $\\lambda=M / q^t$ times. An irredundant orthogonal array (IrOA) is an OA with the additional property that, in any selection of $n - t$ columns, all resulting rows are distinct. IrOAs were first introduced by Goyeneche and \\.{Z}yczkowski in 2014 to construct $t$-uniform quantum states without redundant information. Beyond their quantum applications, we focus on IrOAs as a combinatorial and coding theory problem. An OA is an IrOA if and only if its minimum Hamming distance is at least $t + 1$. Using this characterization, we demonstrate that for any linear code, either the code itself or its Euclidean dual forms a linear IrOA, giving a huge source of IrOAs. In the special case of self-dual codes, both the code and its dual yield IrOAs. Moreover, we construct new families of linear IrOAs based on self-dual, Maximum Distance Separable (MDS), and MDS-self-dual codes. Finally, we establish bounds on the minimum distance and covering radius of IrOAs.","authors":["Maryam Bajalan","Peter Boyvalenkov"],"url":"https://arxiv.org/abs/2506.03688"}
{"created":"2025-06-05","title":"Robust Preference Optimization via Dynamic Target Margins","abstract":"The alignment of Large Language Models (LLMs) is crucial for ensuring their safety and reliability in practical applications. Direct Preference Optimization (DPO) has emerged as an efficient method that directly optimizes models using preference pairs, significantly reducing resource demands. However, the effectiveness of DPO heavily depends on the data quality, which is frequently compromised by noise. In this work, we propose $\\gamma$-PO, a dynamic target margin preference optimization algorithm that adjust reward margins at the pairwise level. By introducing instance-specific margin calibration, $\\gamma$-PO strategically prioritizes high-confidence pairs (those demonstrating higher reward margins) while suppressing potential noise from ambiguous pairs. Moreover, $\\gamma$-PO is a plug-and-play method, compatible with variants of DPO that rely on reward margin between preference pairs. Across benchmarks such as AlpacaEval2 and Arena-Hard, $\\gamma$-PO achieves an average 4.4\\% improvement over other baselines, setting new benchmarks for state-of-the-art performance. Additionally, $\\gamma$-PO requires minimal code changes and has a negligible impact on training efficiency, making it a robust solution for enhancing LLMs alignment. Our codes are available at \\href{https://github.com/sunjie279/gammaPO}{https://github.com/sunjie279/gammaPO}.","authors":["Jie Sun","Junkang Wu","Jiancan Wu","Zhibo Zhu","Xingyu Lu","Jun Zhou","Lintao Ma","Xiang Wang"],"url":"https://arxiv.org/abs/2506.03690"}
{"created":"2025-06-05","title":"A Two-Staged LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation","abstract":"Continuous Integration and Continuous Deployment (CI/CD) pipelines are pivotal to modern software engineering, yet diagnosing and resolving their failures remains a complex and labor-intensive challenge. In this paper, we present LogSage, the first end-to-end LLM-powered framework that performs root cause analysis and solution generation from failed CI/CD pipeline logs. During the root cause analysis stage, LogSage employs a specialized log preprocessing pipeline tailored for LLMs, which extracts critical error logs and eliminates noise to enhance the precision of LLM-driven root cause analysis. In the solution generation stage, LogSage leverages RAG to integrate historical resolution strategies and utilizes tool-calling to deliver actionable, automated fixes. We evaluated the root cause analysis stage using a newly curated open-source dataset, achieving 98\\% in precision and 12\\% improvement over naively designed LLM-based log analysis baselines, while attaining near-perfect recall. The end-to-end system was rigorously validated in a large-scale industrial CI/CD environment of production quality, processing more than 3,000 executions daily and accumulating more than 1.07 million executions in its first year of deployment, with end-to-end precision exceeding 88\\%. These two forms of evaluation confirm that LogSage providing a scalable and practical solution to manage CI/CD pipeline failures in real-world DevOps workflows.","authors":["Weiyuan Xu","Juntao Luo","Tao Huang","Kaixin Sui","Jie Geng","Qijun Ma","Isami Akasaka","Xiaoxue Shi","Jing Tang","Peng Cai"],"url":"https://arxiv.org/abs/2506.03691"}
{"created":"2025-06-05","title":"LRScheduler: A Layer-aware and Resource-adaptive Container Scheduler in Edge Computing","abstract":"Lightweight containers provide an efficient approach for deploying computation-intensive applications in network edge. The layered storage structure of container images can further reduce the deployment cost and container startup time. Existing researches discuss layer sharing scheduling theoretically but with little attention paid to the practical implementation. To fill in this gap, we propose and implement a Layer-aware and Resource-adaptive container Scheduler (LRScheduler) in edge computing. Specifically, we first utilize container image layer information to design and implement a node scoring and container scheduling mechanism. This mechanism can effectively reduce the download cost when deploying containers, which is very important in edge computing with limited bandwidth. Then, we design a dynamically weighted and resource-adaptive mechanism to enhance load balancing in edge clusters, increasing layer sharing scores when resource load is low to use idle resources effectively. Our scheduler is built on the scheduling framework of Kubernetes, enabling full process automation from task information acquisition to container dep=loyment. Testing on a real system has shown that our design can effectively reduce the container deployment cost as compared with the default scheduler.","authors":["Zhiqing Tang","Wentao Peng","Jianxiong Guo","Jiong Lou","Hanshuai Cui","Tian Wang","Yuan Wu","Weijia Jia"],"url":"https://arxiv.org/abs/2506.03694"}
{"created":"2025-06-05","title":"Comprehensive Attribute Encoding and Dynamic LSTM HyperModels for Outcome Oriented Predictive Business Process Monitoring","abstract":"Predictive Business Process Monitoring (PBPM) aims to forecast future outcomes of ongoing business processes. However, existing methods often lack flexibility to handle real-world challenges such as simultaneous events, class imbalance, and multi-level attributes. While prior work has explored static encoding schemes and fixed LSTM architectures, they struggle to support adaptive representations and generalize across heterogeneous datasets. To address these limitations, we propose a suite of dynamic LSTM HyperModels that integrate two-level hierarchical encoding for event and sequence attributes, character-based decomposition of event labels, and novel pseudo-embedding techniques for durations and attribute correlations. We further introduce specialized LSTM variants for simultaneous event modeling, leveraging multidimensional embeddings and time-difference flag augmentation. Experimental validation on four public and real-world datasets demonstrates up to 100% accuracy on balanced datasets and F1 scores exceeding 86\\% on imbalanced ones. Our approach advances PBPM by offering modular and interpretable models better suited for deployment in complex settings. Beyond PBPM, it contributes to the broader AI community by improving temporal outcome prediction, supporting data heterogeneity, and promoting explainable process intelligence frameworks.","authors":["Fang Wang","Paolo Ceravolo","Ernesto Damiani"],"url":"https://arxiv.org/abs/2506.03696"}
{"created":"2025-06-05","title":"Advancements in Artificial Intelligence Applications for Cardiovascular Disease Research","abstract":"Recent advancements in artificial intelligence (AI) have revolutionized cardiovascular medicine, particularly through integration with computed tomography (CT), magnetic resonance imaging (MRI), electrocardiography (ECG) and ultrasound (US). Deep learning architectures, including convolutional neural networks and generative adversarial networks, enable automated analysis of medical imaging and physiological signals, surpassing human capabilities in diagnostic accuracy and workflow efficiency. However, critical challenges persist, including the inability to validate input data accuracy, which may propagate diagnostic errors. This review highlights AI's transformative potential in precision diagnostics while underscoring the need for robust validation protocols to ensure clinical reliability. Future directions emphasize hybrid models integrating multimodal data and adaptive algorithms to refine personalized cardiovascular care.","authors":["Yuanlin Mo","Haishan Huang","Bocheng Liang","Weibo Ma"],"url":"https://arxiv.org/abs/2506.03698"}
{"created":"2025-06-05","title":"Scaling Transformers for Discriminative Recommendation via Generative Pretraining","abstract":"Discriminative recommendation tasks, such as CTR (click-through rate) and CVR (conversion rate) prediction, play critical roles in the ranking stage of large-scale industrial recommender systems. However, training a discriminative model encounters a significant overfitting issue induced by data sparsity. Moreover, this overfitting issue worsens with larger models, causing them to underperform smaller ones. To address the overfitting issue and enhance model scalability, we propose a framework named GPSD (\\textbf{G}enerative \\textbf{P}retraining for \\textbf{S}calable \\textbf{D}iscriminative Recommendation), drawing inspiration from generative training, which exhibits no evident signs of overfitting. GPSD leverages the parameters learned from a pretrained generative model to initialize a discriminative model, and subsequently applies a sparse parameter freezing strategy. Extensive experiments conducted on both industrial-scale and publicly available datasets demonstrate the superior performance of GPSD. Moreover, it delivers remarkable improvements in online A/B tests. GPSD offers two primary advantages: 1) it substantially narrows the generalization gap in model training, resulting in better test performance; and 2) it leverages the scalability of Transformers, delivering consistent performance gains as models are scaled up. Specifically, we observe consistent performance improvements as the model dense parameters scale from 13K to 0.3B, closely adhering to power laws. These findings pave the way for unifying the architectures of recommendation models and language models, enabling the direct application of techniques well-established in large language models to recommendation models.","authors":["Chunqi Wang","Bingchao Wu","Zheng Chen","Lei Shen","Bing Wang","Xiaoyi Zeng"],"url":"https://arxiv.org/abs/2506.03699"}
{"created":"2025-06-05","title":"AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism","abstract":"Large language models (LLMs) are increasingly used for long-content generation (e.g., long Chain-of-Thought reasoning) where decoding efficiency becomes a critical bottleneck: Autoregressive decoding is inherently limited by its sequential token generation process, where each token must be generated before the next can be processed. This sequential dependency restricts the ability to fully leverage modern hardware's parallel processing capabilities. Existing methods like speculative decoding and layer skipping offer potential speedups but have notable drawbacks: speculative decoding relies on an auxiliary \"drafter\" model, which can be challenging to acquire and increases memory overhead, while layer skipping may introduce discrepancies in the outputs due to the missing key-value cache at skipped layers. In this work, we propose AdaDecode, which accelerates LLM decoding without requiring auxiliary models or changes to the original model parameters, while ensuring output consistency. AdaDecode leverages the insight that many tokens can accurately be generated at intermediate layers, as further layers often do not significantly alter predictions once the model reaches a certain confidence. By adaptively generating tokens at intermediate layers when confidence is high, AdaDecode enables the next token's computation to begin immediately. The remaining layer computations for early-predicted tokens are deferred and executed in parallel with subsequent tokens when needed, maximizing hardware utilization and reducing decoding latency. A final verification step ensures that early predictions match the results of standard autoregressive decoding, preserving output parity. Experiments across diverse generation tasks shows that AdaDecode consistently achieves superior decoding throughput with up to 1.73x speedup, while guaranteeing output parity with standard autoregressive decoding.","authors":["Zhepei Wei","Wei-Lin Chen","Xinyu Zhu","Yu Meng"],"url":"https://arxiv.org/abs/2506.03700"}
{"created":"2025-06-05","title":"Tournament Robustness via Redundancy","abstract":"A knockout tournament is one of the most simple and popular forms of competition. Here, we are given a binary tournament tree where all leaves are labeled with seed position names. The players participating in the tournament are assigned to the seed positions. In each round, the two players assigned to leaves of the tournament tree with a common parent compete, and the winner is promoted to the parent. The last remaining player is the winner of the tournament.","authors":["Klim Efremenko","Hendrik Molter","Meirav Zehavi"],"url":"https://arxiv.org/abs/2506.03701"}
{"created":"2025-06-05","title":"Learning-at-Criticality in Large Language Models for Quantum Field Theory and Beyond","abstract":"Fundamental physics often confronts complex symbolic problems with few guiding exemplars or established principles. While artificial intelligence (AI) offers promise, its typical need for vast datasets to learn from hinders its use in these information-scarce frontiers. We introduce learning at criticality (LaC), a reinforcement learning (RL) scheme that tunes Large Language Models (LLMs) to a sharp learning transition, addressing this information scarcity. At this transition, LLMs achieve peak generalization from minimal data, exemplified by 7-digit base-7 addition -- a test of nontrivial arithmetic reasoning. To elucidate this peak, we analyze a minimal concept-network model (CoNet) designed to capture the essence of how LLMs might link tokens. Trained on a single exemplar, this model also undergoes a sharp learning transition. This transition exhibits hallmarks of a second-order phase transition, notably power-law distributed solution path lengths. At this critical point, the system maximizes a ``critical thinking pattern\" crucial for generalization, enabled by the underlying scale-free exploration. This suggests LLMs reach peak performance by operating at criticality, where such explorative dynamics enable the extraction of underlying operational rules. We demonstrate LaC in quantum field theory: an 8B-parameter LLM, tuned to its critical point by LaC using a few exemplars of symbolic Matsubara sums, solves unseen, higher-order problems, significantly outperforming far larger models. LaC thus leverages critical phenomena, a physical principle, to empower AI for complex, data-sparse challenges in fundamental physics.","authors":["Xiansheng Cai","Sihan Hu","Tao Wang","Yuan Huang","Pan Zhang","Youjin Deng","Kun Chen"],"url":"https://arxiv.org/abs/2506.03703"}
{"created":"2025-06-05","title":"ScoreRAG: A Retrieval-Augmented Generation Framework with Consistency-Relevance Scoring and Structured Summarization for News Generation","abstract":"This research introduces ScoreRAG, an approach to enhance the quality of automated news generation. Despite advancements in Natural Language Processing and large language models, current news generation methods often struggle with hallucinations, factual inconsistencies, and lack of domain-specific expertise when producing news articles. ScoreRAG addresses these challenges through a multi-stage framework combining retrieval-augmented generation, consistency relevance evaluation, and structured summarization. The system first retrieves relevant news documents from a vector database, maps them to complete news items, and assigns consistency relevance scores based on large language model evaluations. These documents are then reranked according to relevance, with low-quality items filtered out. The framework proceeds to generate graded summaries based on relevance scores, which guide the large language model in producing complete news articles following professional journalistic standards. Through this methodical approach, ScoreRAG aims to significantly improve the accuracy, coherence, informativeness, and professionalism of generated news articles while maintaining stability and consistency throughout the generation process. The code and demo are available at: https://github.com/peiyun2260/ScoreRAG.","authors":["Pei-Yun Lin","Yen-lung Tsai"],"url":"https://arxiv.org/abs/2506.03704"}
{"created":"2025-06-05","title":"OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation","abstract":"Open-vocabulary semantic segmentation (OVSS) entails assigning semantic labels to each pixel in an image using textual descriptions, typically leveraging world models such as CLIP. To enhance out-of-domain generalization, we propose Cost Aggregation with Optimal Transport (OV-COAST) for open-vocabulary semantic segmentation. To align visual-language features within the framework of optimal transport theory, we employ cost volume to construct a cost matrix, which quantifies the distance between two distributions. Our approach adopts a two-stage optimization strategy: in the first stage, the optimal transport problem is solved using cost volume via Sinkhorn distance to obtain an alignment solution; in the second stage, this solution is used to guide the training of the CAT-Seg model. We evaluate state-of-the-art OVSS models on the MESS benchmark, where our approach notably improves the performance of the cost-aggregation model CAT-Seg with ViT-B backbone, achieving superior results, surpassing CAT-Seg by 1.72 % and SAN-B by 4.9 % mIoU. The code is available at https://github.com/adityagandhamal/OV-COAST/}{https://github.com/adityagandhamal/OV-COAST/ .","authors":["Aditya Gandhamal","Aniruddh Sikdar","Suresh Sundaram"],"url":"https://arxiv.org/abs/2506.03706"}
{"created":"2025-06-05","title":"AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives","abstract":"Open-vocabulary semantic segmentation (OVSS) involves assigning labels to each pixel in an image based on textual descriptions, leveraging world models like CLIP. However, they encounter significant challenges in cross-domain generalization, hindering their practical efficacy in real-world applications. Embodied AI systems are transforming autonomous navigation for ground vehicles and drones by enhancing their perception abilities, and in this study, we present AetherVision-Bench, a benchmark for multi-angle segmentation across aerial, and ground perspectives, which facilitates an extensive evaluation of performance across different viewing angles and sensor modalities. We assess state-of-the-art OVSS models on the proposed benchmark and investigate the key factors that impact the performance of zero-shot transfer models. Our work pioneers the creation of a robustness benchmark, offering valuable insights and establishing a foundation for future research.","authors":["Aniruddh Sikdar","Aditya Gandhamal","Suresh Sundaram"],"url":"https://arxiv.org/abs/2506.03709"}
{"created":"2025-06-05","title":"OSGNet @ Ego4D Episodic Memory Challenge 2025","abstract":"In this report, we present our champion solutions for the three egocentric video localization tracks of the Ego4D Episodic Memory Challenge at CVPR 2025. All tracks require precise localization of the interval within an untrimmed egocentric video. Previous unified video localization approaches often rely on late fusion strategies, which tend to yield suboptimal results. To address this, we adopt an early fusion-based video localization model to tackle all three tasks, aiming to enhance localization accuracy. Ultimately, our method achieved first place in the Natural Language Queries, Goal Step, and Moment Queries tracks, demonstrating its effectiveness. Our code can be found at https://github.com/Yisen-Feng/OSGNet.","authors":["Yisen Feng","Haoyu Zhang","Qiaohui Chu","Meng Liu","Weili Guan","Yaowei Wang","Liqiang Nie"],"url":"https://arxiv.org/abs/2506.03710"}
{"created":"2025-06-05","title":"Pl\\\"uckeRF: A Line-based 3D Representation for Few-view Reconstruction","abstract":"Feed-forward 3D reconstruction methods aim to predict the 3D structure of a scene directly from input images, providing a faster alternative to per-scene optimization approaches. Significant progress has been made in single-view and few-view reconstruction using learned priors that infer object shape and appearance, even for unobserved regions. However, there is substantial potential to enhance these methods by better leveraging information from multiple views when available. To address this, we propose a few-view reconstruction model that more effectively harnesses multi-view information. Our approach introduces a simple mechanism that connects the 3D representation with pixel rays from the input views, allowing for preferential sharing of information between nearby 3D locations and between 3D locations and nearby pixel rays. We achieve this by defining the 3D representation as a set of structured, feature-augmented lines; the Pl\\\"uckeRF representation. Using this representation, we demonstrate improvements in reconstruction quality over the equivalent triplane representation and state-of-the-art feedforward reconstruction methods.","authors":["Sam Bahrami","Dylan Campbell"],"url":"https://arxiv.org/abs/2506.03713"}
{"created":"2025-06-05","title":"FSHNet: Fully Sparse Hybrid Network for 3D Object Detection","abstract":"Fully sparse 3D detectors have recently gained significant attention due to their efficiency in long-range detection. However, sparse 3D detectors extract features only from non-empty voxels, which impairs long-range interactions and causes the center feature missing. The former weakens the feature extraction capability, while the latter hinders network optimization. To address these challenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNet incorporates a proposed SlotFormer block to enhance the long-range feature extraction capability of existing sparse encoders. The SlotFormer divides sparse voxels using a slot partition approach, which, compared to traditional window partition, provides a larger receptive field. Additionally, we propose a dynamic sparse label assignment strategy to deeply optimize the network by providing more high-quality positive samples. To further enhance performance, we introduce a sparse upsampling module to refine downsampled voxels, preserving fine-grained details crucial for detecting small objects. Extensive experiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate the effectiveness of FSHNet. The code is available at https://github.com/Say2L/FSHNet.","authors":["Shuai Liu","Mingyue Cui","Boyang Li","Quanmin Liang","Tinghe Hong","Kai Huang","Yunxiao Shan","Kai Huang"],"url":"https://arxiv.org/abs/2506.03714"}
{"created":"2025-06-05","title":"On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity","abstract":"Modern deep generative models can now produce high-quality synthetic samples that are often indistinguishable from real training data. A growing body of research aims to understand why recent methods -- such as diffusion and flow matching techniques -- generalize so effectively. Among the proposed explanations are the inductive biases of deep learning architectures and the stochastic nature of the conditional flow matching loss. In this work, we rule out the latter -- the noisy nature of the loss -- as a primary contributor to generalization in flow matching. First, we empirically show that in high-dimensional settings, the stochastic and closed-form versions of the flow matching loss yield nearly equivalent losses. Then, using state-of-the-art flow matching models on standard image datasets, we demonstrate that both variants achieve comparable statistical performance, with the surprising observation that using the closed-form can even improve performance.","authors":["Quentin Bertrand","Anne Gagneux","Mathurin Massias","R\\'emi Emonet"],"url":"https://arxiv.org/abs/2506.03719"}
{"created":"2025-06-05","title":"Design of a visual environment for programming by direct data manipulation","abstract":"The use of applications on computers, smartphones, and tablets has been considerably simplified thanks to interactive and dynamic graphical interfaces coupled with the mouse and touch screens. It is no longer necessary to be a computer specialist to use them. Paradoxically, the development of computer programs generally requires writing lines of code in a programming language whose syntax is particularly strict. This process poses many difficulties for programmers. We propose an original tool in which arbitrary programs (Turing-complete) can be developed in a completely visual manner by direct manipulation of the data, without writing a line of code. The user can thus develop an algorithm by directly visualizing the result of actions taken on the data. A method for constructing iterations is associated with the tool. It proposes to create each part, including the loop body, in a non-linear manner under visual control of the state of the data. In addition, the tool supports the production of lines of code in several languages including Python, C, Java, that correspond to the actions performed. In this article, we present the tool, the design choices, the problems to be solved, and the limits and the contributions of the direct-data-manipulation approach.","authors":["Michel Adam (UBS","IRISA)","Patrice Frison (UBS","IRISA)","Moncef Daoud (UBS)","Sabine Letellier Zarshenas (UBS)"],"url":"https://arxiv.org/abs/2506.03720"}
{"created":"2025-06-05","title":"MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition","abstract":"Applying large pre-trained speech models like Whisper has shown promise in reducing training costs for various speech tasks. However, integrating these models into streaming systems remains a challenge. This paper presents a novel prefix-to-prefix training framework for streaming recognition by fine-tuning the Whisper. We introduce the Continuous Integrate-and-Fire mechanism to establish a quasi-monotonic alignment between continuous speech sequences and discrete text tokens. Additionally, we design Monotonic Finite Look-ahead Attention, allowing each token to attend to infinite left-context and finite right-context from the speech sequences. We also employ the wait-k decoding strategy to simplify the decoding process while ensuring consistency between training and testing. Our theoretical analysis and experiments demonstrate that this approach achieves a controllable trade-off between latency and quality, making it suitable for various streaming applications.","authors":["Yinfeng Xia","Huiyan Li","Chenyang Le","Manhong Wang","Yutao Sun","Xingyang Ma","Yanmin Qian"],"url":"https://arxiv.org/abs/2506.03722"}
{"created":"2025-06-05","title":"Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision","abstract":"Uncertainty calibration is essential for the safe deployment of large language models (LLMs), particularly when users rely on verbalized confidence estimates. While prior work has focused on classifiers or short-form generation, confidence calibration for chain-of-thought (CoT) reasoning remains largely unexplored. Surprisingly, we find that supervised fine-tuning with scalar confidence labels alone suffices to elicit self-verification behavior of language models, without any explicit reasoning supervision or reinforcement learning-based rewards. Despite being trained only to produce a verbalized confidence score without any self-verifying examples, the model learns to generate longer and self-checking responses for low-confidence queries while providing more concise answers for high-confidence ones. We further propose a simple rethinking method that boosts performance via test-time scaling based on calibrated uncertainty. Experiments on GSM8K and held-out reasoning tasks such as MATH-500 and ARC-Challenge show that our confidence-aware fine-tuning improves both calibration and accuracy, while also enhancing interpretability by aligning the model's reasoning path with its confidence.","authors":["Chaeyun Jang","Moonseok Choi","Yegon Kim","Hyungi Lee","Juho Lee"],"url":"https://arxiv.org/abs/2506.03723"}
{"created":"2025-06-05","title":"Sign-SGD is the Golden Gate between Multi-Node to Single-Node Learning: Significant Boost via Parameter-Free Optimization","abstract":"Quite recently, large language models have made a significant breakthrough across various disciplines. However, training them is an extremely resource-intensive task, even for major players with vast computing resources. One of the methods gaining popularity in light of these challenges is Sign-SGD. This method can be applied both as a memory-efficient approach in single-node training and as a gradient compression technique in the distributed learning. Nevertheless, it is impossible to automatically determine the effective stepsize from the theoretical standpoint. Indeed, it depends on the parameters of the dataset to which we do not have access in the real-world learning paradigm. To address this issue, we design several variants of single-node deterministic Sign-SGD. We extend our approaches to practical scenarios: stochastic single-node and multi-node learning, methods with incorporated momentum. We conduct extensive experiments on real machine learning problems that emphasize the practical applicability of our ideas.","authors":["Daniil Medyakov","Sergey Stanko","Gleb Molodtsov","Philip Zmushko","Grigoriy Evseev","Egor Petrov","Aleksandr Beznosikov"],"url":"https://arxiv.org/abs/2506.03725"}
{"created":"2025-06-05","title":"Introducing multiverse analysis to bibliometrics: The case of team size effects on disruptive research","abstract":"Although bibliometrics has become an essential tool in the evaluation of research performance, bibliometric analyses are sensitive to a range of methodological choices. Subtle choices in data selection, indicator construction, and modeling decisions can substantially alter results. Ensuring robustness, meaning that findings hold up under different reasonable scenarios, is therefore critical for credible research and research evaluation. To address this issue, this study introduces multiverse analysis to bibliometrics. Multiverse analysis is a statistical tool that enables analysts to transparently discuss modeling assumptions and thoroughly assess model robustness. Whereas standard robustness checks usually cover only a small subset of all plausible models, multiverse analysis includes all plausible models. We illustrate the benefits of multiverse analysis by testing the hypothesis posed by Wu et al. (2019) that small teams produce more disruptive research than large teams. While we found robust evidence of a negative effect of team size on disruption scores, the effect size is so small that its practical relevance seems questionable. Our findings underscore the importance of assessing the multiverse robustness of bibliometric results to clarify their practical implications.","authors":["Christian Leibel","Lutz Bornmann"],"url":"https://arxiv.org/abs/2506.03726"}
{"created":"2025-06-05","title":"IntLevPy: A Python library to classify and model intermittent and L\\'evy processes","abstract":"IntLevPy provides a comprehensive description of the IntLevPy Package, a Python library designed for simulating and analyzing intermittent and L\\'evy processes. The package includes functionalities for process simulation, including full parameter estimation and fitting optimization for both families of processes, moment calculation, and classification methods. The classification methodology utilizes adjusted-$R^2$ and a noble performance measure {\\Gamma}, enabling the distinction between intermittent and L\\'evy processes. IntLevPy integrates iterative parameter optimization with simulation-based validation. This paper provides an in-depth user guide covering IntLevPy software architecture, installation, validation workflows, and usage examples. In this way, IntLevPy facilitates systematic exploration of these two broad classes of stochastic processes, bridging theoretical models and practical applications.","authors":["Shailendra Bhandari","Pedro Lencastre","Sergiy Denysov","Yurii Bystryk","Pedro G. Lind"],"url":"https://arxiv.org/abs/2506.03729"}
{"created":"2025-06-05","title":"Enhancing Text Comprehension for Dyslexic Readers: A 3D Semantic Visualization Approach Using Transformer Mode","abstract":"Dyslexic individuals often face significant challenges with traditional reading, particularly when engaging with complex texts such as mystery novels. These texts typically demand advanced narrative tracking and information integration skills, making it difficult for dyslexic readers to fully comprehend the content. However, research indicates that while dyslexic individuals may struggle with textual processing, they often possess strong spatial imagination abilities. Leveraging this strength, this study proposes an innovative approach using Transformer models to map sentences and words into three-dimensional vector representations. This process clusters semantically similar sentences and words in spatial proximity, allowing dyslexic readers to interpret the semantic structure and narrative flow of the text through spatial perception. Experimental results demonstrate that, compared to direct text reading, this three-dimensional semantic visualization method significantly enhances dyslexic readers' comprehension of complex texts. In particular, it shows marked advantages in identifying narrative relationships and character connections. This study provides a novel pathway for improving textual comprehension among dyslexic individuals","authors":["Zhengyang Li"],"url":"https://arxiv.org/abs/2506.03731"}
{"created":"2025-06-05","title":"Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models","abstract":"Visuals are valuable tools for teaching math word problems (MWPs), helping young learners interpret textual descriptions into mathematical expressions before solving them. However, creating such visuals is labor-intensive and there is a lack of automated methods to support this process. In this paper, we present Math2Visual, an automatic framework for generating pedagogically meaningful visuals from MWP text descriptions. Math2Visual leverages a pre-defined visual language and a design space grounded in interviews with math teachers, to illustrate the core mathematical relationships in MWPs. Using Math2Visual, we construct an annotated dataset of 1,903 visuals and evaluate Text-to-Image (TTI) models for their ability to generate visuals that align with our design. We further fine-tune several TTI models with our dataset, demonstrating improvements in educational visual generation. Our work establishes a new benchmark for automated generation of pedagogically meaningful visuals and offers insights into key challenges in producing multimodal educational content, such as the misrepresentation of mathematical relationships and the omission of essential visual elements.","authors":["Junling Wang","Anna Rutkiewicz","April Yi Wang","Mrinmaya Sachan"],"url":"https://arxiv.org/abs/2506.03735"}
{"created":"2025-06-05","title":"ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices","abstract":"The Transformer architecture has revolutionized various regions since it was proposed, and its effectiveness largely depends on the ability to encode positional information. Traditional position encoding methods exhibit significant limitations due to lack of robustness and flexibility of position. Therefore, Rotary Positional Encoding (RoPE) was proposed to alleviate these issues, which integrates positional information by rotating the embeddings in the attention mechanism. However, RoPE requires manually defined rotation matrices with limited transformation space, constraining the model's capacity. In this work, we propose ComRoPE, which generalizes RoPE by defining it in terms of trainable commuting angle matrices. Specifically, we demonstrate that pairwise commutativity of these matrices is essential for RoPE to achieve scalability and positional robustness. We formally define the RoPE Equation, which is an essential condition that ensures consistent performance with position offsets. Based on the theoretical analysis, we present two types of trainable commuting angle matrices as sufficient solutions to the RoPE equation, which significantly improve performance, surpassing the current state-of-the-art method by 1.6% at training resolution and 2.9% at higher resolution on the ImageNet-1K dataset. Furthermore, our framework shows versatility in generalizing to existing RoPE formulations and offering new insights for future positional encoding research. To ensure reproducibility, the source code and instructions are available at https://github.com/Longin-Yu/ComRoPE","authors":["Hao Yu","Tangyu Jiang","Shuning Jia","Shannan Yan","Shunning Liu","Haolong Qian","Guanghao Li","Shuting Dong","Huaisong Zhang","Chun Yuan"],"url":"https://arxiv.org/abs/2506.03737"}
{"created":"2025-06-05","title":"SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution","abstract":"Single image super-resolution is a well-known downstream task which aims to restore low-resolution images into high-resolution images. At present, models based on Transformers have shone brightly in the field of super-resolution due to their ability to capture long-term dependencies in information. However, current methods typically compute self-attention in nonoverlapping windows to save computational costs, and the standard self-attention computation only focuses on its results, thereby neglecting the useful information across channels and the rich spatial structural information generated in the intermediate process. Channel attention and spatial attention have, respectively, brought significant improvements to various downstream visual tasks in terms of extracting feature dependency and spatial structure relationships, but the synergistic relationship between channel and spatial attention has not been fully explored yet.To address these issues, we propose a novel model. Synergistic Alternating Aggregation Transformer (SAAT), which can better utilize the potential information of features. In SAAT, we introduce the Efficient Channel & Window Synergistic Attention Group (CWSAG) and the Spatial & Window Synergistic Attention Group (SWSAG). On the one hand, CWSAG combines efficient channel attention with shifted window attention, enhancing non-local feature fusion, and producing more visually appealing results. On the other hand, SWSAG leverages spatial attention to capture rich structured feature information, thereby enabling SAAT to more effectively extract structural features.Extensive experimental results and ablation studies demonstrate the effectiveness of SAAT in the field of super-resolution. SAAT achieves performance comparable to that of the state-of-the-art (SOTA) under the same quantity of parameters.","authors":["Jianfeng Wu","Nannan Xu"],"url":"https://arxiv.org/abs/2506.03740"}
{"created":"2025-06-05","title":"PromptCanvas: Composable Prompting Workspaces Using Dynamic Widgets for Exploration and Iteration in Creative Writing","abstract":"We introduce PromptCanvas, a concept that transforms prompting into a composable, widget-based experience on an infinite canvas. Users can generate, customize, and arrange interactive widgets representing various facets of their text, offering greater control over AI-generated content. PromptCanvas allows widget creation through system suggestions, user prompts, or manual input, providing a flexible environment tailored to individual needs. This enables deeper engagement with the creative process. In a lab study with 18 participants, PromptCanvas outperformed a traditional conversational UI on the Creativity Support Index. Participants found that it reduced cognitive load, with lower mental demand and frustration. Qualitative feedback revealed that the visual organization of thoughts and easy iteration encouraged new perspectives and ideas. A follow-up field study (N=10) confirmed these results, showcasing the potential of dynamic, customizable interfaces in improving collaborative writing with AI.","authors":["Rifat Mehreen Amin","Oliver Hans K\\\"uhle","Daniel Buschek","Andreas Butz"],"url":"https://arxiv.org/abs/2506.03741"}
{"created":"2025-06-05","title":"An Open-source Capping Machine Suitable for Confined Spaces","abstract":"In the context of self-driving laboratories (SDLs), ensuring automated and error-free capping is crucial, as it is a ubiquitous step in sample preparation. Automated capping in SDLs can occur in both large and small workspaces (e.g., inside a fume hood). However, most commercial capping machines are designed primarily for large spaces and are often too bulky for confined environments. Moreover, many commercial products are closed-source, which can make their integration into fully autonomous workflows difficult. This paper introduces an open-source capping machine suitable for compact spaces, which also integrates a vision system that recognises capping failure. The capping and uncapping processes are repeated 100 times each to validate the machine's design and performance. As a result, the capping machine reached a 100 % success rate for capping and uncapping. Furthermore, the machine sealing capacities are evaluated by capping 12 vials filled with solvents of different vapour pressures: water, ethanol and acetone. The vials are then weighed every 3 hours for three days. The machine's performance is benchmarked against an industrial capping machine (a Chemspeed station) and manual capping. The vials capped with the prototype lost 0.54 % of their content weight on average per day, while the ones capped with the Chemspeed and manually lost 0.0078 % and 0.013 %, respectively. The results show that the capping machine is a reasonable alternative to industrial and manual capping, especially when space and budget are limitations in SDLs.","authors":["Francisco Munguia-Galeano","Louis Longley","Satheeshkumar Veeramani","Zhengxue Zhou","Rob Clowes","Hatem Fakhruldeen","Andrew I. Cooper"],"url":"https://arxiv.org/abs/2506.03743"}
{"created":"2025-06-05","title":"Dropout-Robust Mechanisms for Differentially Private and Fully Decentralized Mean Estimation","abstract":"Achieving differentially private computations in decentralized settings poses significant challenges, particularly regarding accuracy, communication cost, and robustness against information leakage. While cryptographic solutions offer promise, they often suffer from high communication overhead or require centralization in the presence of network failures. Conversely, existing fully decentralized approaches typically rely on relaxed adversarial models or pairwise noise cancellation, the latter suffering from substantial accuracy degradation if parties unexpectedly disconnect. In this work, we propose IncA, a new protocol for fully decentralized mean estimation, a widely used primitive in data-intensive processing. Our protocol, which enforces differential privacy, requires no central orchestration and employs low-variance correlated noise, achieved by incrementally injecting sensitive information into the computation. First, we theoretically demonstrate that, when no parties permanently disconnect, our protocol achieves accuracy comparable to that of a centralized setting-already an improvement over most existing decentralized differentially private techniques. Second, we empirically show that our use of low-variance correlated noise significantly mitigates the accuracy loss experienced by existing techniques in the presence of dropouts.","authors":["C\\'esar Sabater","Sonia Ben Mokhtar","Jan Ramon"],"url":"https://arxiv.org/abs/2506.03746"}
{"created":"2025-06-05","title":"A Retrieval-Augmented Multi-Agent Framework for Psychiatry Diagnosis","abstract":"The application of AI in psychiatric diagnosis faces significant challenges, including the subjective nature of mental health assessments, symptom overlap across disorders, and privacy constraints limiting data availability. To address these issues, we present MoodAngels, the first specialized multi-agent framework for mood disorder diagnosis. Our approach combines granular-scale analysis of clinical assessments with a structured verification process, enabling more accurate interpretation of complex psychiatric data. Complementing this framework, we introduce MoodSyn, an open-source dataset of 1,173 synthetic psychiatric cases that preserves clinical validity while ensuring patient privacy. Experimental results demonstrate that MoodAngels outperforms conventional methods, with our baseline agent achieving 12.3% higher accuracy than GPT-4o on real-world cases, and our full multi-agent system delivering further improvements. Evaluation in the MoodSyn dataset demonstrates exceptional fidelity, accurately reproducing both the core statistical patterns and complex relationships present in the original data while maintaining strong utility for machine learning applications. Together, these contributions provide both an advanced diagnostic tool and a critical research resource for computational psychiatry, bridging important gaps in AI-assisted mental health assessment.","authors":["Mengxi Xiao","Mang Ye","Ben Liu","Xiaofen Zong","He Li","Jimin Huang","Qianqian Xie","Min Peng"],"url":"https://arxiv.org/abs/2506.03750"}
{"created":"2025-06-05","title":"Convergence Analysis of Virtual Element Methods for the Sobolev Equation with Convection","abstract":"We explore the potential applications of virtual elements for solving the Sobolev equation with a convective term. A conforming virtual element method is employed for spatial discretization, while an implicit Euler scheme is used to approximate the time derivative. To establish the optimal rate of convergence, a novel intermediate projection operator is introduced. We discuss and analyze both the semi-discrete and fully discrete schemes, deriving optimal error estimates for both the energy norm and L2-norm. Several numerical experiments are conducted to validate the theoretical findings and assess the computational efficiency of the proposed numerical methods.","authors":["Ankit Kumar","Sarvesh Kumar","Sangita Yadav"],"url":"https://arxiv.org/abs/2506.03751"}
{"created":"2025-06-05","title":"HUMOF: Human Motion Forecasting in Interactive Social Scenes","abstract":"Complex scenes present significant challenges for predicting human behaviour due to the abundance of interaction information, such as human-human and humanenvironment interactions. These factors complicate the analysis and understanding of human behaviour, thereby increasing the uncertainty in forecasting human motions. Existing motion prediction methods thus struggle in these complex scenarios. In this paper, we propose an effective method for human motion forecasting in interactive scenes. To achieve a comprehensive representation of interactions, we design a hierarchical interaction feature representation so that high-level features capture the overall context of the interactions, while low-level features focus on fine-grained details. Besides, we propose a coarse-to-fine interaction reasoning module that leverages both spatial and frequency perspectives to efficiently utilize hierarchical features, thereby enhancing the accuracy of motion predictions. Our method achieves state-of-the-art performance across four public datasets. Code will be released when this paper is published.","authors":["Caiyi Sun","Yujing Sun","Xiao Han","Zemin Yang","Jiawei Liu","Xinge Zhu","Siu Ming Yiu","Yuexin Ma"],"url":"https://arxiv.org/abs/2506.03753"}
{"created":"2025-06-05","title":"Misalignment or misuse? The AGI alignment tradeoff","abstract":"Creating systems that are aligned with our goals is seen as a leading approach to create safe and beneficial AI in both leading AI companies and the academic field of AI safety. We defend the view that misaligned AGI - future, generally intelligent (robotic) AI agents - poses catastrophic risks. At the same time, we support the view that aligned AGI creates a substantial risk of catastrophic misuse by humans. While both risks are severe and stand in tension with one another, we show that - in principle - there is room for alignment approaches which do not increase misuse risk. We then investigate how the tradeoff between misalignment and misuse looks empirically for different technical approaches to AI alignment. Here, we argue that many current alignment techniques and foreseeable improvements thereof plausibly increase risks of catastrophic misuse. Since the impacts of AI depend on the social context, we close by discussing important social factors and suggest that to reduce the risk of a misuse catastrophe due to aligned AGI, techniques such as robustness, AI control methods and especially good governance seem essential.","authors":["Max Hellrigel-Holderbaum","Leonard Dung"],"url":"https://arxiv.org/abs/2506.03755"}
{"created":"2025-06-05","title":"PPO in the Fisher-Rao geometry","abstract":"Proximal Policy Optimization (PPO) has become a widely adopted algorithm for reinforcement learning, offering a practical policy gradient method with strong empirical performance. Despite its popularity, PPO lacks formal theoretical guarantees for policy improvement and convergence. PPO is motivated by Trust Region Policy Optimization (TRPO) that utilizes a surrogate loss with a KL divergence penalty, which arises from linearizing the value function within a flat geometric space. In this paper, we derive a tighter surrogate in the Fisher-Rao (FR) geometry, yielding a novel variant, Fisher-Rao PPO (FR-PPO). Our proposed scheme provides strong theoretical guarantees, including monotonic policy improvement. Furthermore, in the tabular setting, we demonstrate that FR-PPO achieves sub-linear convergence without any dependence on the dimensionality of the action or state spaces, marking a significant step toward establishing formal convergence results for PPO-based algorithms.","authors":["Razvan-Andrei Lascu","David \\v{S}i\\v{s}ka","{\\L}ukasz Szpruch"],"url":"https://arxiv.org/abs/2506.03757"}
{"created":"2025-06-05","title":"Scaling CrossQ with Weight Normalization","abstract":"Reinforcement learning has achieved significant milestones, but sample efficiency remains a bottleneck for real-world applications. Recently, CrossQ has demonstrated state-of-the-art sample efficiency with a low update-to-data (UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with higher UTD ratios. We identify challenges in the training dynamics which are emphasized by higher UTDs, particularly Q-bias explosion and the growing magnitude of critic network weights. To address this, we integrate weight normalization into the CrossQ framework, a solution that stabilizes training, prevents potential loss of plasticity and keeps the effective learning rate constant. Our proposed approach reliably scales with increasing UTD ratios, achieving competitive or superior performance across a range of challenging tasks on the DeepMind control benchmark, notably the complex dog and humanoid environments. This work eliminates the need for drastic interventions, such as network resets, and offers a robust pathway for improving sample efficiency and scalability in model-free reinforcement learning.","authors":["Daniel Palenicek","Florian Vogt","Jan Peters"],"url":"https://arxiv.org/abs/2506.03758"}
{"created":"2025-06-05","title":"Understanding Physical Properties of Unseen Deformable Objects by Leveraging Large Language Models and Robot Actions","abstract":"In this paper, we consider the problem of understanding the physical properties of unseen objects through interactions between the objects and a robot. Handling unseen objects with special properties such as deformability is challenging for traditional task and motion planning approaches as they are often with the closed world assumption. Recent results in Large Language Models (LLMs) based task planning have shown the ability to reason about unseen objects. However, most studies assume rigid objects, overlooking their physical properties. We propose an LLM-based method for probing the physical properties of unseen deformable objects for the purpose of task planning. For a given set of object properties (e.g., foldability, bendability), our method uses robot actions to determine the properties by interacting with the objects. Based on the properties examined by the LLM and robot actions, the LLM generates a task plan for a specific domain such as object packing. In the experiment, we show that the proposed method can identify properties of deformable objects, which are further used for a bin-packing task where the properties take crucial roles to succeed.","authors":["Changmin Park","Beomjoon Lee","Haechan Jung","Haejin Jung","Changjoo Nam"],"url":"https://arxiv.org/abs/2506.03760"}
{"created":"2025-06-05","title":"Act-as-Pet: Benchmarking the Abilities of Large Language Models as E-Pets in Social Network Services","abstract":"As interest in using Large Language Models (LLMs) for interactive and emotionally rich experiences grows, virtual pet companionship emerges as a novel yet underexplored application. Existing approaches focus on basic pet role-playing interactions without systematically benchmarking LLMs for comprehensive companionship. In this paper, we introduce Pet-Bench, a dedicated benchmark that evaluates LLMs across both self-interaction and human-interaction dimensions. Unlike prior work, Pet-Bench emphasizes self-evolution and developmental behaviors alongside interactive engagement, offering a more realistic reflection of pet companionship. It features diverse tasks such as intelligent scheduling, memory-based dialogues, and psychological conversations, with over 7,500 interaction instances designed to simulate complex pet behaviors. Evaluation of 28 LLMs reveals significant performance variations linked to model size and inherent capabilities, underscoring the need for specialized optimization in this domain. Pet-Bench serves as a foundational resource for benchmarking pet-related LLM abilities and advancing emotionally immersive human-pet interactions.","authors":["Hongcheng Guo","Zheyong Xie","Shaosheng Cao","Boyang Wang","Weiting Liu","Zheyu Ye","Zhoujun Li","Zuozhu Liu"],"url":"https://arxiv.org/abs/2506.03761"}
{"created":"2025-06-05","title":"AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models","abstract":"Large Language Models (LLMs) have significantly advanced the field of Artificial Intelligence. However, their deployment is resource-intensive, not only due to the large number of model parameters but also because the (Key-Value) KV cache consumes a lot of memory during inference. While several works propose reducing the KV cache by evicting the unnecessary tokens, these approaches rely on accumulated attention score as eviction score to quantify the importance of the token. We identify the accumulated attention score is biased and it decreases with the position of the tokens in the mathematical expectation. As a result, the retained tokens concentrate on the initial positions, limiting model's access to global contextual information. To address this issue, we propose Adaptive holistic attention KV (AhaKV), it addresses the bias of the accumulated attention score by adaptively tuning the scale of softmax according the expectation of information entropy of attention scores. To make use of the holistic attention information in self-attention mechanism, AhaKV utilize the information of value vectors, which is overlooked in previous works, to refine the adaptive score. We show theoretically that our method is well suited for bias reduction. We deployed AhaKV on different models with a fixed cache budget. Experiments show that AhaKV successfully mitigates bias and retains crucial tokens across global context and achieve state-of-the-art results against other related work on several benchmark tasks.","authors":["Yifeng Gu","Zicong Jiang","Jianxiu Jin","Kailing Guo","Ziyang Zhang","Xiangmin Xu"],"url":"https://arxiv.org/abs/2506.03762"}
{"created":"2025-06-05","title":"ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations","abstract":"The capabilities of large language models (LLMs) have been enhanced by training on data that reflects human thought processes, such as the Chain-of-Thought format. However, evidence suggests that the conventional scheme of next-word prediction may not fully capture how humans learn to think. Inspired by how humans generalize mathematical reasoning, we propose a new approach named ClozeMath to fine-tune LLMs for mathematical reasoning. Our ClozeMath involves a text-infilling task that predicts masked equations from a given solution, analogous to cloze exercises used in human learning. Experiments on GSM8K, MATH, and GSM-Symbolic show that ClozeMath surpasses the strong baseline Masked Thought in performance and robustness, with two test-time scaling decoding algorithms, Beam Search and Chain-of-Thought decoding. Additionally, we conduct an ablation study to analyze the effects of various architectural and implementation choices on our approach.","authors":["Quang Hieu Pham","Thuy Duong Nguyen","Tung Pham","Anh Tuan Luu","Dat Quoc Nguyen"],"url":"https://arxiv.org/abs/2506.03763"}
{"created":"2025-06-05","title":"Prediction Inconsistency Helps Achieve Generalizable Detection of Adversarial Examples","abstract":"Adversarial detection protects models from adversarial attacks by refusing suspicious test samples. However, current detection methods often suffer from weak generalization: their effectiveness tends to degrade significantly when applied to adversarially trained models rather than naturally trained ones, and they generally struggle to achieve consistent effectiveness across both white-box and black-box attack settings. In this work, we observe that an auxiliary model, differing from the primary model in training strategy or model architecture, tends to assign low confidence to the primary model's predictions on adversarial examples (AEs), while preserving high confidence on normal examples (NEs). Based on this discovery, we propose Prediction Inconsistency Detector (PID), a lightweight and generalizable detection framework to distinguish AEs from NEs by capturing the prediction inconsistency between the primal and auxiliary models. PID is compatible with both naturally and adversarially trained primal models and outperforms four detection methods across 3 white-box, 3 black-box, and 1 mixed adversarial attacks. Specifically, PID achieves average AUC scores of 99.29\\% and 99.30\\% on CIFAR-10 when the primal model is naturally and adversarially trained, respectively, and 98.31% and 96.81% on ImageNet under the same conditions, outperforming existing SOTAs by 4.70%$\\sim$25.46%.","authors":["Sicong Han","Chenhao Lin","Zhengyu Zhao","Xiyuan Wang","Xinlei He","Qian Li","Cong Wang","Qian Wang","Chao Shen"],"url":"https://arxiv.org/abs/2506.03765"}
{"created":"2025-06-05","title":"FedFACT: A Provable Framework for Controllable Group-Fairness Calibration in Federated Learning","abstract":"With emerging application of Federated Learning (FL) in decision-making scenarios, it is imperative to regulate model fairness to prevent disparities across sensitive groups (e.g., female, male). Current research predominantly focuses on two concepts of group fairness within FL: Global Fairness (overall model disparity across all clients) and Local Fairness (the disparity within each client). However, the non-decomposable, non-differentiable nature of fairness criteria pose two fundamental, unresolved challenges for fair FL: (i) Harmonizing global and local fairness in multi-class classification; (ii) Enabling a controllable, optimal accuracy-fairness trade-off. To tackle the aforementioned challenges, we propose a novel controllable federated group-fairness calibration framework, named FedFACT. FedFACT identifies the Bayes-optimal classifiers under both global and local fairness constraints in multi-class case, yielding models with minimal performance decline while guaranteeing fairness. To effectively realize an adjustable, optimal accuracy-fairness balance, we derive specific characterizations of the Bayes-optimal fair classifiers for reformulating fair FL as personalized cost-sensitive learning problem for in-processing, and bi-level optimization for post-processing. Theoretically, we provide convergence and generalization guarantees for FedFACT to approach the near-optimal accuracy under given fairness levels. Extensive experiments on multiple datasets across various data heterogeneity demonstrate that FedFACT consistently outperforms baselines in balancing accuracy and global-local fairness.","authors":["Li Zhang","Zhongxuan Han","Chaochao chen","Xiaohua Feng","Jiaming Zhang","Yuyuan Li"],"url":"https://arxiv.org/abs/2506.03777"}
{"created":"2025-06-05","title":"Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models","abstract":"How can we quantize large language models while preserving accuracy? Quantization is essential for deploying large language models (LLMs) efficiently. Binary-coding quantization (BCQ) and uniform quantization (UQ) are promising quantization schemes that have strong expressiveness and optimizability, respectively. However, neither scheme leverages both advantages. In this paper, we propose UniQuanF (Unified Quantization with Flexible Mapping), an accurate quantization method for LLMs. UniQuanF harnesses both strong expressiveness and optimizability by unifying the flexible mapping technique in UQ and non-uniform quantization levels of BCQ. We propose unified initialization, and local and periodic mapping techniques to optimize the parameters in UniQuanF precisely. After optimization, our unification theorem removes computational and memory overhead, allowing us to utilize the superior accuracy of UniQuanF without extra deployment costs induced by the unification. Experimental results demonstrate that UniQuanF outperforms existing UQ and BCQ methods, achieving up to 4.60% higher accuracy on GSM8K benchmark.","authors":["Seungcheol Park","Jeongin Bae","Beomseok Kwon","Minjun Kim","Byeongwook Kim","Se Jung Kwon","U Kang","Dongsoo Lee"],"url":"https://arxiv.org/abs/2506.03781"}
{"created":"2025-06-05","title":"When Does Closeness in Distribution Imply Representational Similarity? An Identifiability Perspective","abstract":"When and why representations learned by different deep neural networks are similar is an active research topic. We choose to address these questions from the perspective of identifiability theory, which suggests that a measure of representational similarity should be invariant to transformations that leave the model distribution unchanged. Focusing on a model family which includes several popular pre-training approaches, e.g., autoregressive language models, we explore when models which generate distributions that are close have similar representations. We prove that a small Kullback-Leibler divergence between the model distributions does not guarantee that the corresponding representations are similar. This has the important corollary that models arbitrarily close to maximizing the likelihood can still learn dissimilar representations, a phenomenon mirrored in our empirical observations on models trained on CIFAR-10. We then define a distributional distance for which closeness implies representational similarity, and in synthetic experiments, we find that wider networks learn distributions which are closer with respect to our distance and have more similar representations. Our results establish a link between closeness in distribution and representational similarity.","authors":["Beatrix M. G. Nielsen","Emanuele Marconato","Andrea Dittadi","Luigi Gresele"],"url":"https://arxiv.org/abs/2506.03784"}
{"created":"2025-06-05","title":"Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons","abstract":"Large Language Models (LLMs) have shown to be effective evaluators across various domains such as machine translations or the scientific domain. Current LLM-as-a-Judge approaches rely mostly on individual assessments or a single round of pairwise assessments, preventing the judge LLM from developing a global ranking perspective. To address this, we present Knockout Assessment, an LLM-asa Judge method using a knockout tournament system with iterative pairwise comparisons. Experiments across three LLMs on two datasets show that knockout assessment improves scoring accuracy, increasing Pearson correlation with expert evaluations by 0.07 on average for university-level exam scoring and machine translation evaluations, aligning LLM assessments more closely with human scoring.","authors":["Isik Baran Sandan","Tu Anh Dinh","Jan Niehues"],"url":"https://arxiv.org/abs/2506.03785"}
{"created":"2025-06-05","title":"Discrete Element Parameter Calibration of Livestock Salt Based on Particle Scaling","abstract":"In order to obtain accurate contact parameters for the discrete element simulation of salt particles used in animal husbandry, the principle of particle contact scaling and dimensional analysis were used for particle scaling. Firstly, the Plackett Burman experiment was used to screen the parameters that significantly affect the angle of repose: salt salt rolling friction coefficient, salt salt recovery coefficient, and salt steel rolling friction coefficient. Considering the influence of other parameters, a combination of bench and simulation experiments was used to calibrate the contact parameters between salt particles and steel plates used in animal husbandry in EDEM. Finally, through the stacking test, steepest climbing test, and orthogonal rotation combination test, the salt salt rolling friction coefficient was obtained to be 0.23, the salt salt recovery coefficient was 0.544, and the salt steel rolling friction coefficient was 0.368, which were verified through bench tests. The experimental results show that the relative error between the actual value of the stacking angle and the simulation results is 0.6%. The results indicate that the calibrated contact parameters can be used for discrete element simulation of salt particles for animal husbandry, providing reference for the design of quantitative feeding screws and silos.","authors":["Lulu Nie","Baoqin Wen","Jingbin Li","Shufeng Li","Yali Li","Zhaokun Zhang","Zhiyuan Wang","Zhihao Fan"],"url":"https://arxiv.org/abs/2506.03786"}
{"created":"2025-06-05","title":"The Impact of COVID-19 on Twitter Ego Networks: Structure, Sentiment, and Topics","abstract":"Lockdown measures, implemented by governments during the initial phases of the COVID-19 pandemic to reduce physical contact and limit viral spread, imposed significant restrictions on in-person social interactions. Consequently, individuals turned to online social platforms to maintain connections. Ego networks, which model the organization of personal relationships according to human cognitive constraints on managing meaningful interactions, provide a framework for analyzing such dynamics. The disruption of physical contact and the predominant shift of social life online potentially altered the allocation of cognitive resources dedicated to managing these digital relationships. This research aims to investigate the impact of lockdown measures on the characteristics of online ego networks, presumably resulting from this reallocation of cognitive resources. To this end, a large dataset of Twitter users was examined, covering a seven-year period of activity. Analyzing a seven-year Twitter dataset -- including five years pre-pandemic and two years post -- we observe clear, though temporary, changes. During lockdown, ego networks expanded, social circles became more structured, and relationships intensified. Simultaneously, negative interactions increased, and users engaged with a broader range of topics, indicating greater thematic diversity. Once restrictions were lifted, these structural, emotional, and thematic shifts largely reverted to pre-pandemic norms -- suggesting a temporary adaptation to an extraordinary social context.","authors":["Kamer Cekini","Elisabetta Biondi","Chiara Boldrini","Andrea Passarella","Marco Conti"],"url":"https://arxiv.org/abs/2506.03788"}
{"created":"2025-06-05","title":"Attention-Only Transformers via Unrolled Subspace Denoising","abstract":"Despite the popularity of transformers in practice, their architectures are empirically designed and neither mathematically justified nor interpretable. Moreover, as indicated by many empirical studies, some components of transformer architectures may be redundant. To derive a fully interpretable transformer architecture with only necessary components, we contend that the goal of representation learning is to compress a set of noisy initial token representations towards a mixture of low-dimensional subspaces. To compress these noisy token representations, an associated denoising operation naturally takes the form of a multi-head (subspace) self-attention. By unrolling such iterative denoising operations into a deep network, we arrive at a highly compact architecture that consists of \\textit{only} self-attention operators with skip connections at each layer. Moreover, we show that each layer performs highly efficient denoising: it improves the signal-to-noise ratio of token representations \\textit{at a linear rate} with respect to the number of layers. Despite its simplicity, extensive experiments on vision and language tasks demonstrate that such a transformer achieves performance close to that of standard transformer architectures such as GPT-2 and CRATE.","authors":["Peng Wang","Yifu Lu","Yaodong Yu","Druv Pai","Qing Qu","Yi Ma"],"url":"https://arxiv.org/abs/2506.03790"}
{"created":"2025-06-05","title":"Mark My Words: A Robust Multilingual Model for Punctuation in Text and Speech Transcripts","abstract":"Punctuation plays a vital role in structuring meaning, yet current models often struggle to restore it accurately in transcripts of spontaneous speech, especially in the presence of disfluencies such as false starts and backtracking. These limitations hinder the performance of downstream tasks like translation, text to speech, summarization, etc. where sentence boundaries are critical for preserving quality. In this work, we introduce Cadence, a generalist punctuation restoration model adapted from a pretrained large language model. Cadence is designed to handle both clean written text and highly spontaneous spoken transcripts. It surpasses the previous state of the art in performance while expanding support from 14 to all 22 Indian languages and English. We conduct a comprehensive analysis of model behavior across punctuation types and language families, identifying persistent challenges under domain shift and with rare punctuation marks. Our findings demonstrate the efficacy of utilizing pretrained language models for multilingual punctuation restoration and highlight Cadence practical value for low resource NLP pipelines at scale.","authors":["Sidharth Pulipaka","Sparsh Jain","Ashwin Sankar","Raj Dabre"],"url":"https://arxiv.org/abs/2506.03793"}
{"created":"2025-06-05","title":"An Efficient Numerical Method for an Approximate Solution of the Beam Equation","abstract":"In this paper, we propose a horizontal type method of lines numerical scheme for the unsteady Euler-Bernoulli beam equation. The problem is initially reformulated as a first order system of initial value problems and a suitable one-step difference scheme is used for the highest order temporal derivative which leads to a system of steady beam equations. Then resulted family of steady problems is solved iteratively by the finite element method with Hermite cubic basis functions. This iterative procedure leads to approximations for both the solution of the unsteady problem and its derivatives. All these approximations are compared with the exact ones to illustrate the performance of the proposed method. Moreover, the optimization of the mesh parameters is discussed for both steady and unsteady problems by logarithmic scale plot.","authors":["Onur Baysal","Maria Aquilina"],"url":"https://arxiv.org/abs/2506.03794"}
{"created":"2025-06-05","title":"CoLa: Chinese Character Decomposition with Compositional Latent Components","abstract":"Humans can decompose Chinese characters into compositional components and recombine them to recognize unseen characters. This reflects two cognitive principles: Compositionality, the idea that complex concepts are built on simpler parts; and Learning-to-learn, the ability to learn strategies for decomposing and recombining components to form new concepts. These principles provide inductive biases that support efficient generalization. They are critical to Chinese character recognition (CCR) in solving the zero-shot problem, which results from the common long-tail distribution of Chinese character datasets. Existing methods have made substantial progress in modeling compositionality via predefined radical or stroke decomposition. However, they often ignore the learning-to-learn capability, limiting their ability to generalize beyond human-defined schemes. Inspired by these principles, we propose a deep latent variable model that learns Compositional Latent components of Chinese characters (CoLa) without relying on human-defined decomposition schemes. Recognition and matching can be performed by comparing compositional latent components in the latent space, enabling zero-shot character recognition. The experiments illustrate that CoLa outperforms previous methods in both character the radical zero-shot CCR. Visualization indicates that the learned components can reflect the structure of characters in an interpretable way. Moreover, despite being trained on historical documents, CoLa can analyze components of oracle bone characters, highlighting its cross-dataset generalization ability.","authors":["Fan Shi","Haiyang Yu","Bin Li","Xiangyang Xue"],"url":"https://arxiv.org/abs/2506.03798"}
{"created":"2025-06-05","title":"ConText: Driving In-context Learning for Text Removal and Segmentation","abstract":"This paper presents the first study on adapting the visual in-context learning (V-ICL) paradigm to optical character recognition tasks, specifically focusing on text removal and segmentation. Most existing V-ICL generalists employ a reasoning-as-reconstruction approach: they turn to using a straightforward image-label compositor as the prompt and query input, and then masking the query label to generate the desired output. This direct prompt confines the model to a challenging single-step reasoning process. To address this, we propose a task-chaining compositor in the form of image-removal-segmentation, providing an enhanced prompt that elicits reasoning with enriched intermediates. Additionally, we introduce context-aware aggregation, integrating the chained prompt pattern into the latent query representation, thereby strengthening the model's in-context reasoning. We also consider the issue of visual heterogeneity, which complicates the selection of homogeneous demonstrations in text recognition. Accordingly, this is effectively addressed through a simple self-prompting strategy, preventing the model's in-context learnability from devolving into specialist-like, context-free inference. Collectively, these insights culminate in our ConText model, which achieves new state-of-the-art across both in- and out-of-domain benchmarks. The code is available at https://github.com/Ferenas/ConText.","authors":["Fei Zhang","Pei Zhang","Baosong Yang","Fei Huang","Yanfeng Wang","Ya Zhang"],"url":"https://arxiv.org/abs/2506.03799"}
{"created":"2025-06-05","title":"From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation","abstract":"Traditional Business Process Management (BPM) struggles with rigidity, opacity, and scalability in dynamic environments while emerging Large Language Models (LLMs) present transformative opportunities alongside risks. This paper explores four real-world use cases that demonstrate how LLMs, augmented with trustworthy process intelligence, redefine process modeling, prediction, and automation. Grounded in early-stage research projects with industrial partners, the work spans manufacturing, modeling, life-science, and design processes, addressing domain-specific challenges through human-AI collaboration. In manufacturing, an LLM-driven framework integrates uncertainty-aware explainable Machine Learning (ML) with interactive dialogues, transforming opaque predictions into auditable workflows. For process modeling, conversational interfaces democratize BPMN design. Pharmacovigilance agents automate drug safety monitoring via knowledge-graph-augmented LLMs. Finally, sustainable textile design employs multi-agent systems to navigate regulatory and environmental trade-offs. We intend to examine tensions between transparency and efficiency, generalization and specialization, and human agency versus automation. By mapping these trade-offs, we advocate for context-sensitive integration prioritizing domain needs, stakeholder values, and iterative human-in-the-loop workflows over universal solutions. This work provides actionable insights for researchers and practitioners aiming to operationalize LLMs in critical BPM environments.","authors":["Peter Pfeiffer","Alexander Rombach","Maxim Majlatow","Nijat Mehdiyev"],"url":"https://arxiv.org/abs/2506.03801"}
{"created":"2025-06-05","title":"Learning Equilibria in Matching Games with Bandit Feedback","abstract":"We investigate the problem of learning an equilibrium in a generalized two-sided matching market, where agents can adaptively choose their actions based on their assigned matches. Specifically, we consider a setting in which matched agents engage in a zero-sum game with initially unknown payoff matrices, and we explore whether a centralized procedure can learn an equilibrium from bandit feedback. We adopt the solution concept of matching equilibrium, where a pair consisting of a matching $\\mathfrak{m}$ and a set of agent strategies $X$ forms an equilibrium if no agent has the incentive to deviate from $(\\mathfrak{m}, X)$. To measure the deviation of a given pair $(\\mathfrak{m}, X)$ from the equilibrium pair $(\\mathfrak{m}^\\star, X^\\star)$, we introduce matching instability that can serve as a regret measure for the corresponding learning problem. We then propose a UCB algorithm in which agents form preferences and select actions based on optimistic estimates of the game payoffs, and prove that it achieves sublinear, instance-independent regret over a time horizon $T$.","authors":["Andreas Athanasopoulos","Christos Dimitrakakis"],"url":"https://arxiv.org/abs/2506.03802"}
{"created":"2025-06-05","title":"Additive codes from linear codes","abstract":"We introduce two constructions of additive codes over finite fields. Both constructions start with a linear code over a field with $q$ elements and give additive codes over the field with $q^h$ elements whose minimum distance is demonstrably good.","authors":["Simeon Ball","Tabriz Popatia"],"url":"https://arxiv.org/abs/2506.03805"}
{"created":"2025-06-05","title":"Understanding Mental Models of Generative Conversational Search and The Effect of Interface Transparency","abstract":"The experience and adoption of conversational search is tied to the accuracy and completeness of users' mental models -- their internal frameworks for understanding and predicting system behaviour. Thus, understanding these models can reveal areas for design interventions. Transparency is one such intervention which can improve system interpretability and enable mental model alignment. While past research has explored mental models of search engines, those of generative conversational search remain underexplored, even while the popularity of these systems soars. To address this, we conducted a study with 16 participants, who performed 4 search tasks using 4 conversational interfaces of varying transparency levels. Our analysis revealed that most user mental models were too abstract to support users in explaining individual search instances. These results suggest that 1) mental models may pose a barrier to appropriate trust in conversational search, and 2) hybrid web-conversational search is a promising novel direction for future search interface design.","authors":["Chadha Degachi","Samuel Kernan Freire","Evangelos Niforatos","Gerd Kortuem"],"url":"https://arxiv.org/abs/2506.03807"}
{"created":"2025-06-05","title":"Graph Neural Networks for Resource Allocation in Multi-Channel Wireless Networks","abstract":"As the number of mobile devices continues to grow, interference has become a major bottleneck in improving data rates in wireless networks. Efficient joint channel and power allocation (JCPA) is crucial for managing interference. In this paper, we first propose an enhanced WMMSE (eWMMSE) algorithm to solve the JCPA problem in multi-channel wireless networks. To reduce the computational complexity of iterative optimization, we further introduce JCPGNN-M, a graph neural network-based solution that enables simultaneous multi-channel allocation for each user. We reformulate the problem as a Lagrangian function, which allows us to enforce the total power constraints systematically. Our solution involves combining this Lagrangian framework with GNNs and iteratively updating the Lagrange multipliers and resource allocation scheme. Unlike existing GNN-based methods that limit each user to a single channel, JCPGNN-M supports efficient spectrum reuse and scales well in dense network scenarios. Simulation results show that JCPGNN-M achieves better data rate compared to eWMMSE. Meanwhile, the inference time of JCPGNN-M is much lower than eWMMS, and it can generalize well to larger networks.","authors":["Lili Chen","Changyang She","Jingge Zhu","Jamie Evans"],"url":"https://arxiv.org/abs/2506.03813"}
{"created":"2025-06-05","title":"Survey of Active Learning Hyperparameters: Insights from a Large-Scale Experimental Grid","abstract":"Annotating data is a time-consuming and costly task, but it is inherently required for supervised machine learning. Active Learning (AL) is an established method that minimizes human labeling effort by iteratively selecting the most informative unlabeled samples for expert annotation, thereby improving the overall classification performance. Even though AL has been known for decades, AL is still rarely used in real-world applications. As indicated in the two community web surveys among the NLP community about AL, two main reasons continue to hold practitioners back from using AL: first, the complexity of setting AL up, and second, a lack of trust in its effectiveness. We hypothesize that both reasons share the same culprit: the large hyperparameter space of AL. This mostly unexplored hyperparameter space often leads to misleading and irreproducible AL experiment results. In this study, we first compiled a large hyperparameter grid of over 4.6 million hyperparameter combinations, second, recorded the performance of all combinations in the so-far biggest conducted AL study, and third, analyzed the impact of each hyperparameter in the experiment results. In the end, we give recommendations about the influence of each hyperparameter, demonstrate the surprising influence of the concrete AL strategy implementation, and outline an experimental study design for reproducible AL experiments with minimal computational effort, thus contributing to more reproducible and trustworthy AL research in the future.","authors":["Julius Gonsior","Tim Rie{\\ss}","Anja Reusch","Claudio Hartmann","Maik Thiele","Wolfgang Lehner"],"url":"https://arxiv.org/abs/2506.03817"}
{"created":"2025-06-05","title":"Automatic Correction of Writing Anomalies in Hausa Texts","abstract":"Hausa texts are often characterized by writing anomalies such as incorrect character substitutions and spacing errors, which sometimes hinder natural language processing (NLP) applications. This paper presents an approach to automatically correct the anomalies by finetuning transformer-based models. Using a corpus gathered from several public sources, we created a large-scale parallel dataset of over 450,000 noisy-clean Hausa sentence pairs by introducing synthetically generated noise, fine-tuned to mimic realistic writing errors. Moreover, we adapted several multilingual and African language-focused models, including M2M100, AfriTEVA, mBART, and Opus-MT variants for this correction task using SentencePiece tokenization. Our experimental results demonstrate significant increases in F1, BLEU and METEOR scores, as well as reductions in Character Error Rate (CER) and Word Error Rate (WER). This research provides a robust methodology, a publicly available dataset, and effective models to improve Hausa text quality, thereby advancing NLP capabilities for the language and offering transferable insights for other low-resource languages.","authors":["Ahmad Mustapha Wali","Sergiu Nisioi"],"url":"https://arxiv.org/abs/2506.03820"}
{"created":"2025-06-05","title":"CRAWLDoc: A Dataset for Robust Ranking of Bibliographic Documents","abstract":"Publication databases rely on accurate metadata extraction from diverse web sources, yet variations in web layouts and data formats present challenges for metadata providers. This paper introduces CRAWLDoc, a new method for contextual ranking of linked web documents. Starting with a publication's URL, such as a digital object identifier, CRAWLDoc retrieves the landing page and all linked web resources, including PDFs, ORCID profiles, and supplementary materials. It embeds these resources, along with anchor texts and the URLs, into a unified representation. For evaluating CRAWLDoc, we have created a new, manually labeled dataset of 600 publications from six top publishers in computer science. Our method CRAWLDoc demonstrates a robust and layout-independent ranking of relevant documents across publishers and data formats. It lays the foundation for improved metadata extraction from web documents with various layouts and formats. Our source code and dataset can be accessed at https://github.com/FKarl/CRAWLDoc.","authors":["Fabian Karl","Ansgar Scherp"],"url":"https://arxiv.org/abs/2506.03822"}
{"created":"2025-06-05","title":"Signals as a First-Class Citizen When Querying Knowledge Graphs","abstract":"Cyber-Physical Systems (CPSs) tightly integrate computation with physical entities, often generating vast amounts of time series data from thousands of sensors. Although knowledge graphs offer a powerful means to contextualize these data, existing approaches to integrating knowledge graphs with time series data lack a concept to model the continuous temporal values inherent in CPSs. This gap can make expressing computations on the sensor data cumbersome. In this work, we propose the integration of knowledge graphs and signals, a proven concept for modeling temporal values. By treating signals as first-class citizens in query languages, we can enable seamless querying over knowledge graphs and signals. While the knowledge graph captures information on the CPS, signals represent its run-time data from sensors. We discuss the implications of such an approach and propose SigSPARQL, an extension to the SPARQL query language, to demonstrate these concepts. Furthermore, we evaluate the feasibility of implementing SigSPARQL with a prototype and demonstrate the applicability of the query language for a monitoring use case within a CPS.","authors":["Tobias Schwarzinger","Gernot Steindl","Thomas Fr\\\"uhwirth","Thomas Preindl","Konrad Diwold","Katrin Ehrenm\\\"uller","Fajar J. Ekaputra"],"url":"https://arxiv.org/abs/2506.03826"}
{"created":"2025-06-05","title":"Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising","abstract":"Retrieval systems primarily address the challenge of matching user queries with the most relevant advertisements, playing a crucial role in e-commerce search advertising. The diversity of user needs and expressions often produces massive long-tail queries that cannot be matched with merchant bidwords or product titles, which results in some advertisements not being recalled, ultimately harming user experience and search efficiency. Existing query rewriting research focuses on various methods such as query log mining, query-bidword vector matching, or generation-based rewriting. However, these methods often fail to simultaneously optimize the relevance and authenticity of the user's original query and rewrite and maximize the revenue potential of recalled ads.","authors":["Zhenhui Liu","Chunyuan Yuan","Ming Pang","Zheng Fang","Li Yuan","Xue Jiang","Changping Peng","Zhangang Lin","Zheng Luo","Jingping Shao"],"url":"https://arxiv.org/abs/2506.03827"}
{"created":"2025-06-05","title":"AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance","abstract":"AI for Industrial Asset Lifecycle Management aims to automate complex operational workflows -- such as condition monitoring, maintenance planning, and intervention scheduling -- to reduce human workload and minimize system downtime. Traditional AI/ML approaches have primarily tackled these problems in isolation, solving narrow tasks within the broader operational pipeline. In contrast, the emergence of AI agents and large language models (LLMs) introduces a next-generation opportunity: enabling end-to-end automation across the entire asset lifecycle. This paper envisions a future where AI agents autonomously manage tasks that previously required distinct expertise and manual coordination. To this end, we introduce AssetOpsBench -- a unified framework and environment designed to guide the development, orchestration, and evaluation of domain-specific agents tailored for Industry 4.0 applications. We outline the key requirements for such holistic systems and provide actionable insights into building agents that integrate perception, reasoning, and control for real-world industrial operations. The software is available at https://github.com/IBM/AssetOpsBench.","authors":["Dhaval Patel","Shuxin Lin","James Rayfield","Nianjun Zhou","Roman Vaculin","Natalia Martinez","Fearghal O'donncha","Jayant Kalagnanam"],"url":"https://arxiv.org/abs/2506.03828"}
{"created":"2025-06-05","title":"Construction of Urban Greenland Resources Collaborative Management Platform","abstract":"Nowadays, environmental protection has become a global consensus. At the same time, with the rapid development of science and technology, urbanisation has become a phenomenon that has become the norm. Therefore, the urban greening management system is an essential component in protecting the urban environment. The system utilises a transparent management process known as\" monitoring - early warning - response - optimisation,\" which enhances the tracking of greening resources, streamlines maintenance scheduling, and encourages employee involvement in planning. Designed with a microservice architecture, the system can improve the utilisation of greening resources by 30\\% , increase citizen satisfaction by 20\\%, and support carbon neutrality objectives, ultimately making urban governance more intelligent and focused on the community. The Happy City Greening Management System effectively manages gardeners, trees, flowers, and green spaces. It comprises modules for gardener management, purchase and supplier management, tree and flower management, and maintenance planning. Its automation feature allows for real-time updates of greening data, thereby enhancing decision-making. The system is built using Java for the backend and MySQL for data storage, complemented by a user-friendly frontend designed with the Vue framework. Additionally, it leverages features from the Spring Boot framework to enhance maintainability and scalability.","authors":["Dongyang Lyu","Xiaoqi Li","Zongwei Li"],"url":"https://arxiv.org/abs/2506.03830"}
{"created":"2025-06-05","title":"Conformer-based Ultrasound-to-Speech Conversion","abstract":"Deep neural networks have shown promising potential for ultrasound-to-speech conversion task towards Silent Speech Interfaces. In this work, we applied two Conformer-based DNN architectures (Base and one with bi-LSTM) for this task. Speaker-specific models were trained on the data of four speakers from the Ultrasuite-Tal80 dataset, while the generated mel spectrograms were synthesized to audio waveform using a HiFi-GAN vocoder. Compared to a standard 2D-CNN baseline, objective measurements (MSE and mel cepstral distortion) showed no statistically significant improvement for either model. However, a MUSHRA listening test revealed that Conformer with bi-LSTM provided better perceptual quality, while Conformer Base matched the performance of the baseline along with a 3x faster training time due to its simpler architecture. These findings suggest that Conformer-based models, especially the Conformer with bi-LSTM, offer a promising alternative to CNNs for ultrasound-to-speech conversion.","authors":["Ibrahim Ibrahimov","Zaink\\'o Csaba","G\\'abor Gosztolya"],"url":"https://arxiv.org/abs/2506.03831"}
{"created":"2025-06-05","title":"Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain","abstract":"Pretrained self-supervised speech models excel in speech tasks but do not reflect the hierarchy of human speech processing, as they encode rich semantics in middle layers and poor semantics in late layers. Recent work showed that brain-tuning (fine-tuning models using human brain recordings) improves speech models' semantic understanding. Here, we examine how well brain-tuned models further reflect the brain's intermediate stages of speech processing. We find that late layers of brain-tuned models substantially improve over pretrained models in their alignment with semantic language regions. Further layer-wise probing reveals that early layers remain dedicated to low-level acoustic features, while late layers become the best at complex high-level tasks. These findings show that brain-tuned models not only perform better but also exhibit a well-defined hierarchical processing going from acoustic to semantic representations, making them better model organisms for human speech processing.","authors":["Omer Moussa","Mariya Toneva"],"url":"https://arxiv.org/abs/2506.03832"}
{"created":"2025-06-05","title":"Enhancing Safety of Foundation Models for Visual Navigation through Collision Avoidance via Repulsive Estimation","abstract":"We propose CARE (Collision Avoidance via Repulsive Estimation), a plug-and-play module that enhances the safety of vision-based navigation without requiring additional range sensors or fine-tuning of pretrained models. While recent foundation models using only RGB inputs have shown strong performance, they often fail to generalize in out-of-distribution (OOD) environments with unseen objects or variations in camera parameters (e.g., field of view, pose, or focal length). Without fine-tuning, these models may generate unsafe trajectories that lead to collisions, requiring costly data collection and retraining. CARE addresses this limitation by seamlessly integrating with any RGB-based navigation system that outputs local trajectories, dynamically adjusting them using repulsive force vectors derived from monocular depth maps. We evaluate CARE by combining it with state-of-the-art vision-based navigation models across multiple robot platforms. CARE consistently reduces collision rates (up to 100%) without sacrificing goal-reaching performance and improves collision-free travel distance by up to 10.7x in exploration tasks.","authors":["Joonkyung Kim","Joonyeol Sim","Woojun Kim","Katia Sycara","Changjoo Nam"],"url":"https://arxiv.org/abs/2506.03834"}
{"created":"2025-06-05","title":"Learning task-specific predictive models for scientific computing","abstract":"We consider learning a predictive model to be subsequently used for a given downstream task (described by an algorithm) that requires access to the model evaluation. This task need not be prediction, and this situation is frequently encountered in machine-learning-augmented scientific computing. We show that this setting differs from classical supervised learning, and in general it cannot be solved by minimizing the mean square error of the model predictions as is frequently performed in the literature. Instead, we find that the maximum prediction error on the support of the downstream task algorithm can serve as an effective estimate for the subsequent task performance. With this insight, we formulate a task-specific supervised learning problem based on the given sampling measure, whose solution serves as a reliable surrogate model for the downstream task. Then, we discretize the empirical risk based on training data, and develop an iterative algorithm to solve the task-specific supervised learning problem. Three illustrative numerical examples on trajectory prediction, optimal control and minimum energy path computation demonstrate the effectiveness of the approach.","authors":["Jianyuan Yin","Qianxiao Li"],"url":"https://arxiv.org/abs/2506.03835"}
{"created":"2025-06-05","title":"Revisiting Unbiased Implicit Variational Inference","abstract":"Recent years have witnessed growing interest in semi-implicit variational inference (SIVI) methods due to their ability to rapidly generate samples from complex distributions. However, since the likelihood of these samples is non-trivial to estimate in high dimensions, current research focuses on finding effective SIVI training routines. Although unbiased implicit variational inference (UIVI) has largely been dismissed as imprecise and computationally prohibitive because of its inner MCMC loop, we revisit this method and show that UIVI's MCMC loop can be effectively replaced via importance sampling and the optimal proposal distribution can be learned stably by minimizing an expected forward Kullback-Leibler divergence without bias. Our refined approach demonstrates superior performance or parity with state-of-the-art methods on established SIVI benchmarks.","authors":["Tobias Pielok","Bernd Bischl","David R\\\"ugamer"],"url":"https://arxiv.org/abs/2506.03839"}
{"created":"2025-06-05","title":"Differences between Neurodivergent and Neurotypical Software Engineers: Analyzing the 2022 Stack Overflow Survey","abstract":"Neurodiversity describes variation in brain function among people, including common conditions such as Autism spectrum disorder (ASD), Attention deficit hyperactivity disorder (ADHD), and dyslexia. While Software Engineering (SE) literature has started to explore the experiences of neurodivergent software engineers, there is a lack of research that compares their challenges to those of neurotypical software engineers. To address this gap, we analyze existing data from the 2022 Stack Overflow Developer survey that collected data on neurodiversity. We quantitatively compare the answers of professional engineers with ASD (n=374), ADHD (n=1305), and dyslexia (n=363) with neurotypical engineers. Our findings indicate that neurodivergent engineers face more difficulties than neurotypical engineers. Specifically, engineers with ADHD report that they face more interruptions caused by waiting for answers, and that they less frequently interact with individuals outside their team. This study provides a baseline for future research comparing neurodivergent engineers with neurotypical ones. Several factors in the Stack Overflow survey and in our analysis are likely to lead to conservative estimates of the actual effects between neurodivergent and neurotypical engineers, e.g., the effects of the COVID-19 pandemic and our focus on employed professionals.","authors":["Pragya Verma","Marcos Vinicius Cruz","Grischa Liebel"],"url":"https://arxiv.org/abs/2506.03840"}
{"created":"2025-06-05","title":"SLURM Heterogeneous Jobs for Hybrid Classical-Quantum Workflows","abstract":"A method for efficient scheduling of hybrid classical-quantum workflows is presented, based on standard tools available on common supercomputer systems. Moderate interventions by the user are required, such as splitting a monolithic workflow in to basic building blocks and ensuring the data flow. This bares the potential to significantly reduce idle time of the quantum resource as well as overall wall time of co-scheduled workflows. Relevant pseudo-code samples and scripts are provided to demonstrate the simplicity and working principles of the method.","authors":["Aniello Esposito","Utz-Uwe Haus"],"url":"https://arxiv.org/abs/2506.03846"}
{"created":"2025-06-05","title":"Designing morphologies of soft medical devices using cooperative neuro coevolution","abstract":"Soft robots have proven to outperform traditional robots in applications related to propagation in geometrically constrained environments. Designing these robots and their controllers is an intricate task, since their building materials exhibit non-linear properties. Human designs may be biased; hence, alternative designing processes should be considered. We present a cooperative neuro coevolution approach to designing the morphologies of soft actuators and their controllers for applications in drug delivery apparatus. Morphologies and controllers are encoded as compositional pattern-producing networks evolved by Neuroevolution of Augmented Topologies (NEAT) and in cooperative coevolution methodology, taking into account different collaboration methods. Four collaboration methods are studied: n best individuals, n worst individuals, n best and worst individuals, and n random individuals. As a performance baseline, the results from the implementation of Age-Fitness Pareto Optimisation (AFPO) are considered. The metrics used are the maximum displacement in upward bending and the robustness of the devices in terms of applying to the same evolved morphology a diverse set of controllers. Results suggest that the cooperative neuro coevolution approach can produce more suitable morphologies for the intended devices than AFPO.","authors":["Hugo Alcaraz-Herrera","Michail-Antisthenis Tsompanas","Igor Balaz","Andrew Adamatzky"],"url":"https://arxiv.org/abs/2506.03847"}
{"created":"2025-06-05","title":"Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning","abstract":"Harmful fine-tuning (HFT), performed directly on open-source LLMs or through Fine-tuning-as-a-Service, breaks safety alignment and poses significant threats. Existing methods aim to mitigate HFT risks by learning robust representation on alignment data or making harmful data unlearnable, but they treat each data sample equally, leaving data vulnerability patterns understudied. In this work, we reveal that certain subsets of alignment data are consistently more prone to forgetting during HFT across different fine-tuning tasks. Inspired by these findings, we propose Vulnerability-Aware Alignment (VAA), which estimates data vulnerability, partitions data into \"vulnerable\" and \"invulnerable\" groups, and encourages balanced learning using a group distributionally robust optimization (Group DRO) framework. Specifically, VAA learns an adversarial sampler that samples examples from the currently underperforming group and then applies group-dependent adversarial perturbations to the data during training, aiming to encourage a balanced learning process across groups. Experiments across four fine-tuning tasks demonstrate that VAA significantly reduces harmful scores while preserving downstream task performance, outperforming state-of-the-art baselines.","authors":["Liang Chen","Xueting Han","Li Shen","Jing Bai","Kam-Fai Wong"],"url":"https://arxiv.org/abs/2506.03850"}
{"created":"2025-06-05","title":"Analysis of Server Throughput For Managed Big Data Analytics Frameworks","abstract":"Managed big data frameworks, such as Apache Spark and Giraph demand a large amount of memory per core to process massive volume datasets effectively. The memory pressure that arises from the big data processing leads to high garbage collection (GC) overhead. Big data analytics frameworks attempt to remove this overhead by offloading objects to storage devices. At the same time, infrastructure providers, trying to address the same problem, attribute more memory to increase memory per instance leaving cores underutilized. For frameworks, trying to avoid GC through offloading to storage devices leads to high Serialization/Deserialization (S/D) overhead. For infrastructure, the result is that resource usage is decreased. These limitations prevent managed big data frameworks from effectively utilizing the CPU thus leading to low server throughput.","authors":["Emmanouil Anagnostakis","Polyvios Pratikakis"],"url":"https://arxiv.org/abs/2506.03854"}
{"created":"2025-06-05","title":"Data-driven balanced truncation for second-order systems via the approximate Gramians","abstract":"This paper studies the data-driven balanced truncation (BT) method for second-order systems based on the measurements in the frequency domain. The basic idea is to approximate Gramians used the numerical quadrature rules, and establish the relationship between the main quantities in the procedure of BT with the sample data, which paves the way for the execution of BT in a nonintrusive manner. We construct the structure-preserving reduced models approximately based on the samples of second-order systems with proportional damping, and provide the detailed execution of the data-driven counterpart of BT in real-value arithmetic. The low-rank approximation to the solution of Sylvester equations is also introduced to speed up the process of the proposed approach when a large amount of samples involved in the modeling. The performance of our approach is illustrated in detail via two numerical examples.","authors":["Xiaolong Wang","Xuerong Yang","Xiaoli Wang","Bo Song"],"url":"https://arxiv.org/abs/2506.03855"}
{"created":"2025-06-05","title":"Phase-based Nonlinear Model Predictive Control for Humanoid Walking Stabilization with Single and Double Support Time Adjustments","abstract":"Balance control for humanoid robots has been extensively studied to enable robots to navigate in real-world environments. However, balance controllers that explicitly optimize the durations of both the single support phase, also known as step timing, and the Double Support Phase (DSP) have not been widely explored due to the inherent nonlinearity of the associated optimization problem. Consequently, many recent approaches either ignore the DSP or adjust its duration based on heuristics or on linearization techniques that rely on sequential coordination of balance strategies. This study proposes a novel phase-based nonlinear Model Predictive Control (MPC) framework that simultaneously optimizes Zero Moment Point~(ZMP) modulation, step location, step timing, and DSP duration to maintain balance under external disturbances. In simulation, the proposed controller was compared with two state-of-the-art frameworks that rely on heuristics or sequential coordination of balance strategies under two scenarios: forward walking on terrain emulating compliant ground and external push recovery while walking in place. Overall, the findings suggest that the proposed method offers more flexible coordination of balance strategies than the sequential approach, and consistently outperforms the heuristic approach. The robustness and effectiveness of the proposed controller were also validated through experiments with a real humanoid robot.","authors":["Kwanwoo Lee","Gyeongjae Park","Jaeheung Park"],"url":"https://arxiv.org/abs/2506.03856"}
{"created":"2025-06-05","title":"Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation","abstract":"Recently, Large Language Models (LLMs) have demonstrated significant potential for data annotation, markedly reducing the labor costs associated with downstream applications. However, existing methods mostly adopt an aggressive strategy by prompting LLM to determine a single gold label for each unlabeled sample. Due to the inherent uncertainty within LLMs, they often produce incorrect labels for difficult samples, severely compromising the data quality for downstream applications. Motivated by ambiguity aversion in human behaviors, we propose a novel candidate annotation paradigm wherein large language models are encouraged to output all possible labels when incurring uncertainty. To ensure unique labels are provided for downstream tasks, we develop a teacher-student framework CanDist that distills candidate annotations with a Small Language Model (SLM). We further provide a rigorous justification demonstrating that distilling candidate annotations from the teacher LLM offers superior theoretical guarantees compared to directly using single annotations. Extensive experiments across six text classification tasks validate the effectiveness of our proposed method. The source code is available at https://github.com/MingxuanXia/CanDist.","authors":["Mingxuan Xia","Haobo Wang","Yixuan Li","Zewei Yu","Jindong Wang","Junbo Zhao","Runze Wu"],"url":"https://arxiv.org/abs/2506.03857"}
{"created":"2025-06-05","title":"PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in High-Frequency Cryptocurrency Trading","abstract":"High-Frequency Trading (HFT) is pivotal in cryptocurrency markets, demanding rapid decision-making. Social media platforms like Reddit offer valuable, yet underexplored, information for such high-frequency, short-term trading. This paper introduces \\textbf{PulseReddit}, a novel dataset that is the first to align large-scale Reddit discussion data with high-frequency cryptocurrency market statistics for short-term trading analysis. We conduct an extensive empirical study using Large Language Model (LLM)-based Multi-Agent Systems (MAS) to investigate the impact of social sentiment from PulseReddit on trading performance. Our experiments conclude that MAS augmented with PulseReddit data achieve superior trading outcomes compared to traditional baselines, particularly in bull markets, and demonstrate robust adaptability across different market regimes. Furthermore, our research provides conclusive insights into the performance-efficiency trade-offs of different LLMs, detailing significant considerations for practical model selection in HFT applications. PulseReddit and our findings establish a foundation for advanced MAS research in HFT, demonstrating the tangible benefits of integrating social media.","authors":["Qiuhan Han","Qian Wang","Atsushi Yoshikawa","Masayuki Yamamura"],"url":"https://arxiv.org/abs/2506.03861"}
{"created":"2025-06-05","title":"STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization","abstract":"Transforming complex actions into discrete skill abstractions has demonstrated strong potential for robotic manipulation. Existing approaches mainly leverage latent variable models, e.g., VQ-VAE, to learn skill abstractions through learned vectors (codebooks), while they suffer from codebook collapse and modeling the causal relationship between learned skills. To address these limitations, we present \\textbf{S}kill \\textbf{T}raining with \\textbf{A}ugmented \\textbf{R}otation (\\textbf{STAR}), a framework that advances both skill learning and composition to complete complex behaviors. Specifically, to prevent codebook collapse, we devise rotation-augmented residual skill quantization (RaRSQ). It encodes relative angles between encoder outputs into the gradient flow by rotation-based gradient mechanism. Points within the same skill code are forced to be either pushed apart or pulled closer together depending on gradient directions. Further, to capture the causal relationship between skills, we present causal skill transformer (CST) which explicitly models dependencies between skill representations through an autoregressive mechanism for coherent action generation. Extensive experiments demonstrate the superiority of STAR on both LIBERO benchmark and realworld tasks, with around 12\\% improvement over the baselines.","authors":["Hao Li","Qi Lv","Rui Shao","Xiang Deng","Yinchuan Li","Jianye Hao","Liqiang Nie"],"url":"https://arxiv.org/abs/2506.03863"}
{"created":"2025-06-05","title":"Invariant-region-preserving WENO schemes for one-dimensional multispecies kinematic flow models","abstract":"Multispecies kinematic flow models are defined by systems of N strongly coupled, nonlinear first-order conservation laws, where the solution is a vector of N partial volume fractions or densities. These models arise in various applications including multiclass vehicular traffic and sedimentation of polydisperse suspensions. The solution vector should take values in a set of physically relevant values (i.e., the components are nonnegative and sum up at most to a given maximum value). It is demonstrated that this set, the so-called invariant region, is preserved by numerical solutions produced by a new family of high-order finite volume numerical schemes adapted to this class of models. To achieve this property, and motivated by [X. Zhang, C.-W. Shu, On maximum-principle-satisfying high order schemes for scalar conservation laws, J. Comput. Phys. 229 (2010) 3091--3120], a pair of linear scaling limiters is applied to a high-order weighted essentially non-oscillatory (WENO) polynomial reconstruction to obtain invariant-region-preserving (IRP) high-order polynomial reconstructions. These reconstructions are combined with a local Lax-Friedrichs (LLF) or Harten-Lax-van Leer (HLL) numerical flux to obtain a high-order numerical scheme for the system of conservation laws. It is proved that this scheme satisfies an IRP property under a suitable Courant-Friedrichs-Lewy (CFL) condition. The theoretical analysis is corroborated with numerical simulations for models of multiclass traffic flow and polydisperse sedimentation.","authors":["Juan Barajas-Calonge","Raimund B\\\"urger","Pep Mulet","Luis-Miguel Villada"],"url":"https://arxiv.org/abs/2506.03864"}
{"created":"2025-06-05","title":"EuroGEST: Investigating gender stereotypes in multilingual language models","abstract":"Large language models increasingly support multiple languages, yet most benchmarks for gender bias remain English-centric. We introduce EuroGEST, a dataset designed to measure gender-stereotypical reasoning in LLMs across English and 29 European languages. EuroGEST builds on an existing expert-informed benchmark covering 16 gender stereotypes, expanded in this work using translation tools, quality estimation metrics, and morphological heuristics. Human evaluations confirm that our data generation method results in high accuracy of both translations and gender labels across languages. We use EuroGEST to evaluate 24 multilingual language models from six model families, demonstrating that the strongest stereotypes in all models across all languages are that women are \\textit{beautiful,} \\textit{empathetic} and \\textit{neat} and men are \\textit{leaders}, \\textit{strong, tough} and \\textit{professional}. We also show that larger models encode gendered stereotypes more strongly and that instruction finetuning does not consistently reduce gendered stereotypes. Our work highlights the need for more multilingual studies of fairness in LLMs and offers scalable methods and resources to audit gender bias across languages.","authors":["Jacqueline Rowe","Mateusz Klimaszewski","Liane Guillou","Shannon Vallor","Alexandra Birch"],"url":"https://arxiv.org/abs/2506.03867"}
{"created":"2025-06-05","title":"Animal Pose Labeling Using General-Purpose Point Trackers","abstract":"Automatically estimating animal poses from videos is important for studying animal behaviors. Existing methods do not perform reliably since they are trained on datasets that are not comprehensive enough to capture all necessary animal behaviors. However, it is very challenging to collect such datasets due to the large variations in animal morphology. In this paper, we propose an animal pose labeling pipeline that follows a different strategy, i.e. test time optimization. Given a video, we fine-tune a lightweight appearance embedding inside a pre-trained general-purpose point tracker on a sparse set of annotated frames. These annotations can be obtained from human labelers or off-the-shelf pose detectors. The fine-tuned model is then applied to the rest of the frames for automatic labeling. Our method achieves state-of-the-art performance at a reasonable annotation cost. We believe our pipeline offers a valuable tool for the automatic quantification of animal behavior. Visit our project webpage at https://zhuoyang-pan.github.io/animal-labeling.","authors":["Zhuoyang Pan","Boxiao Pan","Guandao Yang","Adam W. Harley","Leonidas Guibas"],"url":"https://arxiv.org/abs/2506.03868"}
{"created":"2025-06-05","title":"Coupling models of resistive valves to muscle mechanics in cardiac fluid-structure interaction simulations","abstract":"To accurately simulate all phases of the cardiac cycle, computational models of hemodynamics in heart chambers need to include a sufficiently faithful model of cardiac valves. This can be achieved efficiently through resistive methods, and the resistive immersed implicit surface (RIIS) model in particular [Fedele et al., BMMB, 2017]. However, the conventional RIIS model is not suited to fluid-structure interaction (FSI) simulations, since it neglects the reaction forces by which valves are attached to the cardiac walls, leading to models that are not consistent with Newton's laws. In this paper, we propose an improvement to RIIS to overcome this limitation, by adding distributed forces acting on the structure to model the attachment of valves to the cardiac walls. The modification has a minimal computational overhead thanks to an explicit numerical discretization scheme. Numerical experiments in both idealized and realistic settings demonstrate the effectiveness of the proposed modification in ensuring the physical consistency of the model, thus allowing to apply RIIS and other resistive valve models in the context of FSI simulations.","authors":["Michele Bucelli","Luca Dede'"],"url":"https://arxiv.org/abs/2506.03869"}
{"created":"2025-06-05","title":"Evaluating Apple Intelligence's Writing Tools for Privacy Against Large Language Model-Based Inference Attacks: Insights from Early Datasets","abstract":"The misuse of Large Language Models (LLMs) to infer emotions from text for malicious purposes, known as emotion inference attacks, poses a significant threat to user privacy. In this paper, we investigate the potential of Apple Intelligence's writing tools, integrated across iPhone, iPad, and MacBook, to mitigate these risks through text modifications such as rewriting and tone adjustment. By developing early novel datasets specifically for this purpose, we empirically assess how different text modifications influence LLM-based detection. This capability suggests strong potential for Apple Intelligence's writing tools as privacy-preserving mechanisms. Our findings lay the groundwork for future adaptive rewriting systems capable of dynamically neutralizing sensitive emotional content to enhance user privacy. To the best of our knowledge, this research provides the first empirical analysis of Apple Intelligence's text-modification tools within a privacy-preservation context with the broader goal of developing on-device, user-centric privacy-preserving mechanisms to protect against LLMs-based advanced inference attacks on deployed systems.","authors":["Mohd. Farhan Israk Soumik","Syed Mhamudul Hasan","Abdur R. Shahid"],"url":"https://arxiv.org/abs/2506.03870"}
{"created":"2025-06-05","title":"JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting","abstract":"Reconstructing 3D scenes from sparse viewpoints is a long-standing challenge with wide applications. Recent advances in feed-forward 3D Gaussian sparse-view reconstruction methods provide an efficient solution for real-time novel view synthesis by leveraging geometric priors learned from large-scale multi-view datasets and computing 3D Gaussian centers via back-projection. Despite offering strong geometric cues, both feed-forward multi-view depth estimation and flow-depth joint estimation face key limitations: the former suffers from mislocation and artifact issues in low-texture or repetitive regions, while the latter is prone to local noise and global inconsistency due to unreliable matches when ground-truth flow supervision is unavailable. To overcome this, we propose JointSplat, a unified framework that leverages the complementarity between optical flow and depth via a novel probabilistic optimization mechanism. Specifically, this pixel-level mechanism scales the information fusion between depth and flow based on the matching probability of optical flow during training. Building upon the above mechanism, we further propose a novel multi-view depth-consistency loss to leverage the reliability of supervision while suppressing misleading gradients in uncertain areas. Evaluated on RealEstate10K and ACID, JointSplat consistently outperforms state-of-the-art (SOTA) methods, demonstrating the effectiveness and robustness of our proposed probabilistic joint flow-depth optimization approach for high-fidelity sparse-view 3D reconstruction.","authors":["Yang Xiao","Guoan Xu","Qiang Wu","Wenjing Jia"],"url":"https://arxiv.org/abs/2506.03872"}
{"created":"2025-06-05","title":"The equivalent condition for GRL codes to be MDS, AMDS or self-dual","abstract":"It is well-known that MDS, AMDS or self-dual codes have good algebraic properties, and are applied in communication systems, data storage, quantum codes, and so on. In this paper, we focus on a class of generalized Roth-Lempel linear codes, and give an equivalent condition for them or their dual to be non-RS MDS, AMDS or non-RS self-dual and some corresponding examples.","authors":["Zhonghao Liang","Qunying Liao"],"url":"https://arxiv.org/abs/2506.03874"}
{"created":"2025-06-05","title":"Asterinas: A Linux ABI-Compatible, Rust-Based Framekernel OS with a Small and Sound TCB","abstract":"How can one build a feature-rich, general-purpose, Rust-based operating system (OS) with a minimal and sound Trusted Computing Base (TCB) for memory safety? Existing Rust-based OSes fall short due to their improper use of unsafe Rust in kernel development. To address this challenge, we propose a novel OS architecture called framekernel that realizes Rust's full potential to achieve intra-kernel privilege separation, ensuring TCB minimality and soundness. We present OSTD, a streamlined framework for safe Rust OS development, and Asterinas, a Linux ABI-compatible framekernel OS implemented entirely in safe Rust using OSTD. Supporting over 210 Linux system calls, Asterinas delivers performance on par with Linux, while maintaining a minimized, memory-safety TCB of only about 14.0% of the codebase. These results underscore the practicality and benefits of the framekernel architecture in building safe and efficient OSes.","authors":["Yuke Peng","Hongliang Tian","Zhang Junyang","Ruihan Li","Chengjun Chen","Jianfeng Jiang","Jinyi Xian","Xiaolin Wang","Chenren Xu","Diyu Zhou","Yingwei Luo","Shoumeng Yan","Yinqian Zhang"],"url":"https://arxiv.org/abs/2506.03876"}
{"created":"2025-06-05","title":"Automated Mechanism to Support Trade Transactions in Smart Contracts with Upgrade and Repair","abstract":"In our previous research, we addressed the problem of automated transformation of models, represented using the business process model and notation (BPMN) standard, into the methods of a smart contract. The transformation supports BPMN models that contain complex multi-step activities that are supported using our concept of multi-step nested trade transactions, wherein the transactional properties are enforced by a mechanism generated automatically by the transformation process from a BPMN model to a smart contract. In this paper, we present a methodology for repairing a smart contract that cannot be completed due to events that were not anticipated by the developer and thus prevent the completion of the smart contract. The repair process starts with the original BPMN model fragment causing the issue, providing the modeler with the innermost transaction fragment containing the failed activity. The modeler amends the BPMN pattern on the basis of successful completion of previous activities. If repairs exceed the inner transaction's scope, they are addressed using the parent transaction's BPMN model. The amended BPMN model is then transformed into a new smart contract, ensuring consistent data and logic transitions. We previously developed a tool, called TABS+, as a proof of concept (PoC) to transform BPMN models into smart contracts for nested transactions. This paper describes the tool TABS+R, developed by extending the TABS+ tool, to allow the repair of smart contracts.","authors":["Christian Gang Liu","Peter Bodorik","Dawn Jutla"],"url":"https://arxiv.org/abs/2506.03877"}
{"created":"2025-06-05","title":"RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing","abstract":"The rapid advancements in large language models (LLMs) have led to the emergence of routing techniques, which aim to efficiently select the optimal LLM from diverse candidates to tackle specific tasks, optimizing performance while reducing costs. Current LLM routing methods are limited in effectiveness due to insufficient exploration of the intrinsic connection between user queries and the characteristics of LLMs. To address this issue, in this paper, we present RadialRouter, a novel framework for LLM routing which employs a lightweight Transformer-based backbone with a radial structure named RadialFormer to articulate the query-LLMs relationship. The optimal LLM selection is performed based on the final states of RadialFormer. The pipeline is further refined by an objective function that combines Kullback-Leibler divergence with the query-query contrastive loss to enhance robustness. Experimental results on RouterBench show that RadialRouter significantly outperforms existing routing methods by 9.2\\% and 5.8\\% in the Balance and Cost First scenarios, respectively. Additionally, its adaptability toward different performance-cost trade-offs and the dynamic LLM pool demonstrates practical application potential.","authors":["Ruihan Jin","Pengpeng Shao","Zhengqi Wen","Jinyang Wu","Mingkuan Feng","Shuai Zhang","Jianhua Tao"],"url":"https://arxiv.org/abs/2506.03880"}
{"created":"2025-06-05","title":"Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages","abstract":"Text-to-speech (TTS) systems typically require high-quality studio data and accurate transcriptions for training. India has 1369 languages, with 22 official using 13 scripts. Training a TTS system for all these languages, most of which have no digital resources, seems a Herculean task. Our work focuses on zero-shot synthesis, particularly for languages whose scripts and phonotactics come from different families. The novelty of our work is in the augmentation of a shared phone representation and modifying the text parsing rules to match the phonotactics of the target language, thus reducing the synthesiser overhead and enabling rapid adaptation. Intelligible and natural speech was generated for Sanskrit, Maharashtrian and Canara Konkani, Maithili and Kurukh by leveraging linguistic connections across languages with suitable synthesisers. Evaluations confirm the effectiveness of this approach, highlighting its potential to expand speech technology access for under-represented languages.","authors":["Utkarsh Pathak","Chandra Sai Krishna Gunda","Anusha Prakash","Keshav Agarwal","Hema A. Murthy"],"url":"https://arxiv.org/abs/2506.03884"}
{"created":"2025-06-05","title":"Video, How Do Your Tokens Merge?","abstract":"Video transformer models require huge amounts of compute resources due to the spatio-temporal scaling of the input. Tackling this, recent methods have proposed to drop or merge tokens for image models, whether randomly or via learned methods. Merging tokens has many benefits: it can be plugged into any vision transformer, does not require model re-training, and it propagates information that would otherwise be dropped through the model. Before now, video token merging has not been evaluated on temporally complex datasets for video understanding. In this work, we explore training-free token merging for video to provide comprehensive experiments and find best practices across four video transformers on three datasets that exhibit coarse and fine-grained action recognition. Our results showcase the benefits of video token merging with a speedup of around $2.5$X while maintaining accuracy (avg. $-0.55\\%$ for ViViT). Code available at https://github.com/sjpollard/video-how-do-your-tokens-merge.","authors":["Sam Pollard","Michael Wray"],"url":"https://arxiv.org/abs/2506.03885"}
{"created":"2025-06-05","title":"Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation","abstract":"Extensive LLM applications demand efficient structured generations, particularly for LR(1) grammars, to produce outputs in specified formats (e.g., JSON). Existing methods primarily parse LR(1) grammars into a pushdown automaton (PDA), leading to runtime execution overhead for context-dependent token processing, especially inefficient under large inference batches. To address these issues, we propose Pre$^3$ that exploits deterministic pushdown automata (DPDA) to optimize the constrained LLM decoding efficiency. First, by precomputing prefix-conditioned edges during the preprocessing, Pre$^3$ enables ahead-of-time edge analysis and thus makes parallel transition processing possible. Second, by leveraging the prefix-conditioned edges, Pre$^3$ introduces a novel approach that transforms LR(1) transition graphs into DPDA, eliminating the need for runtime path exploration and achieving edge transitions with minimal overhead. Pre$^3$ can be seamlessly integrated into standard LLM inference frameworks, reducing time per output token (TPOT) by up to 40% and increasing throughput by up to 36% in our experiments. Our code is available at https://github.com/ModelTC/lightllm.","authors":["Junyi Chen","Shihao Bai","Zaijun Wang","Siyu Wu","Chuheng Du","Hailong Yang","Ruihao Gong","Shengzhong Liu","Fan Wu","Guihai Chen"],"url":"https://arxiv.org/abs/2506.03887"}
{"created":"2025-06-05","title":"Temporal horizons in forecasting: a performance-learnability trade-off","abstract":"When training autoregressive models for dynamical systems, a critical question arises: how far into the future should the model be trained to predict? Too short a horizon may miss long-term trends, while too long a horizon can impede convergence due to accumulating prediction errors. In this work, we formalize this trade-off by analyzing how the geometry of the loss landscape depends on the training horizon. We prove that for chaotic systems, the loss landscape's roughness grows exponentially with the training horizon, while for limit cycles, it grows linearly, making long-horizon training inherently challenging. However, we also show that models trained on long horizons generalize well to short-term forecasts, whereas those trained on short horizons suffer exponentially (resp. linearly) worse long-term predictions in chaotic (resp. periodic) systems. We validate our theory through numerical experiments and discuss practical implications for selecting training horizons. Our results provide a principled foundation for hyperparameter optimization in autoregressive forecasting models.","authors":["Pau Vilimelis Aceituno","Jack William Miller","Noah Marti","Youssef Farag","Victor Boussange"],"url":"https://arxiv.org/abs/2506.03889"}
{"created":"2025-06-05","title":"On recovering the Radon-Nikodym derivative under the big data assumption","abstract":"The present paper is focused on the problem of recovering the Radon-Nikodym derivative under the big data assumption. To address the above problem, we design an algorithm that is a combination of the Nystr\\\"om subsampling and the standard Tikhonov regularization. The convergence rate of the corresponding algorithm is established both in the case when the Radon-Nikodym derivative belongs to RKHS and in the case when it does not. We prove that the proposed approach not only ensures the order of accuracy as algorithms based on the whole sample size, but also allows to achieve subquadratic computational costs in the number of observations.","authors":["Hanna Myleiko","Sergei Solodky"],"url":"https://arxiv.org/abs/2506.03891"}
{"created":"2025-06-05","title":"Joint Video Enhancement with Deblurring, Super-Resolution, and Frame Interpolation Network","abstract":"Video quality is often severely degraded by multiple factors rather than a single factor. These low-quality videos can be restored to high-quality videos by sequentially performing appropriate video enhancement techniques. However, the sequential approach was inefficient and sub-optimal because most video enhancement approaches were designed without taking into account that multiple factors together degrade video quality. In this paper, we propose a new joint video enhancement method that mitigates multiple degradation factors simultaneously by resolving an integrated enhancement problem. Our proposed network, named DSFN, directly produces a high-resolution, high-frame-rate, and clear video from a low-resolution, low-frame-rate, and blurry video. In the DSFN, low-resolution and blurry input frames are enhanced by a joint deblurring and super-resolution (JDSR) module. Meanwhile, intermediate frames between input adjacent frames are interpolated by a triple-frame-based frame interpolation (TFBFI) module. The proper combination of the proposed modules of DSFN can achieve superior performance on the joint video enhancement task. Experimental results show that the proposed method outperforms other sequential state-of-the-art techniques on public datasets with a smaller network size and faster processing time.","authors":["Giyong Choi","HyunWook Park"],"url":"https://arxiv.org/abs/2506.03892"}
{"created":"2025-06-05","title":"An Efficient Candidate-Free R-S Set Similarity Join Algorithm with the Filter-and-Verification Tree and MapReduce","abstract":"Given two different collections of sets, the exact set similarity R-S Join finds all set pairs with similarity no less than a given threshold, which has widespread applications. While existing algorithms accelerate large-scale R-S Joins using a two-stage filter-and-verification framework along with the parallel and distributed MapReduce framework, they suffer from excessive candidate set pairs, leading to significant I/O, data transfer, and verification overhead, and ultimately degrading the performance. This paper proposes novel candidate-free R-S Join (CF-RS-Join) algorithms that integrate filtering and verification into a single stage through filter-and-verification trees (FVTs) and their linear variants (LFVTs). First, CF-RS-Join with FVT (CF-RS-Join/FVT) is proposed to leverage an innovative FVT structure that compresses elements and associated sets in memory, enabling single-stage processing that eliminates the candidate set generation, fast lookups, and reduced database scans. Correctness proofs are provided. Second, CF-RS-Join with LFVT (CF-RS-Join/LFVT) is proposed to exploit a more compact Linear FVT, which compresses non-branching paths into single nodes and stores them in linear arrays for optimized traversal. Third, MR-CF-RS-Join/FVT and MR-CF-RS-Join/LFVT have been proposed to extend our approaches using MapReduce for parallel processing. Empirical studies on 7 real-world datasets have been conducted to evaluate the performance of the proposed algorithms against selected existing algorithms in terms of execution time, scalability, memory usage, and disk usage. Experimental results demonstrate that our algorithm using MapReduce, i.e., MR-CF-RS-Join/LFVT, achieves the best performance.","authors":["Yuhong Feng","Fangcao Jian","Yixuan Cao","Xiaobin Jian","Jia Wang","Haiyue Feng","Chunyan Miao"],"url":"https://arxiv.org/abs/2506.03893"}
{"created":"2025-06-05","title":"Testing (Conditional) Mutual Information","abstract":"We investigate the sample complexity of mutual information and conditional mutual information testing. For conditional mutual information testing, given access to independent samples of a triple of random variables $(A, B, C)$ with unknown distribution, we want to distinguish between two cases: (i) $A$ and $C$ are conditionally independent, i.e., $I(A\\!:\\!C|B) = 0$, and (ii) $A$ and $C$ are conditionally dependent, i.e., $I(A\\!:\\!C|B) \\geq \\varepsilon$ for some threshold $\\varepsilon$. We establish an upper bound on the number of samples required to distinguish between the two cases with high confidence, as a function of $\\varepsilon$ and the three alphabet sizes. We conjecture that our bound is tight and show that this is indeed the case in several parameter regimes. For the special case of mutual information testing (when $B$ is trivial), we establish the necessary and sufficient number of samples required up to polylogarithmic terms.","authors":["Jan Seyfried","Sayantan Sen","Marco Tomamichel"],"url":"https://arxiv.org/abs/2506.03894"}
{"created":"2025-06-05","title":"Graph-Embedding Empowered Entity Retrieval","abstract":"In this research, we investigate methods for entity retrieval using graph embeddings. While various methods have been proposed over the years, most utilize a single graph embedding and entity linking approach. This hinders our understanding of how different graph embedding and entity linking methods impact entity retrieval. To address this gap, we investigate the effects of three different categories of graph embedding techniques and five different entity linking methods. We perform a reranking of entities using the distance between the embeddings of annotated entities and the entities we wish to rerank. We conclude that the selection of both graph embeddings and entity linkers significantly impacts the effectiveness of entity retrieval. For graph embeddings, methods that incorporate both graph structure and textual descriptions of entities are the most effective. For entity linking, both precision and recall concerning concepts are important for optimal retrieval performance. Additionally, it is essential for the graph to encompass as many entities as possible.","authors":["Emma J. Gerritse","Faegheh Hasibi","Arjen P. de Vries"],"url":"https://arxiv.org/abs/2506.03895"}
{"created":"2025-06-05","title":"FLIP: Flowability-Informed Powder Weighing","abstract":"Autonomous manipulation of powders remains a significant challenge for robotic automation in scientific laboratories. The inherent variability and complex physical interactions of powders in flow, coupled with variability in laboratory conditions necessitates adaptive automation. This work introduces FLIP, a flowability-informed powder weighing framework designed to enhance robotic policy learning for granular material handling. Our key contribution lies in using material flowability, quantified by the angle of repose, to optimise physics-based simulations through Bayesian inference. This yields material-specific simulation environments capable of generating accurate training data, which reflects diverse powder behaviours, for training `robot chemists'. Building on this, FLIP integrates quantified flowability into a curriculum learning strategy, fostering efficient acquisition of robust robotic policies by gradually introducing more challenging, less flowable powders. We validate the efficacy of our method on a robotic powder weighing task under real-world laboratory conditions. Experimental results show that FLIP with a curriculum strategy achieves a low dispensing error of 2.12 +- 1.53 mg, outperforming methods that do not leverage flowability data, such as domain randomisation (6.11 +- 3.92 mg). These results demonstrate FLIP's improved ability to generalise to previously unseen, more cohesive powders and to new target masses.","authors":["Nikola Radulov (Department of Computer Science University of Liverpool UK)","Alex Wright (Department of Computer Science University of Liverpool UK)","Thomas little (Department of Computer Science University of Liverpool UK)","Andrew I. Cooper (Department of Chemistry university of Liverpool UK)","Gabriella Pizzuto (Department of Computer Science University of Liverpool UK","Department of Chemistry university of Liverpool UK)"],"url":"https://arxiv.org/abs/2506.03896"}
{"created":"2025-06-05","title":"A kernel conditional two-sample test","abstract":"We propose a framework for hypothesis testing on conditional probability distributions, which we then use to construct conditional two-sample statistical tests. These tests identify the inputs -- called covariates in this context -- where two conditional expectations differ with high probability. Our key idea is to transform confidence bounds of a learning method into a conditional two-sample test, and we instantiate this principle for kernel ridge regression (KRR) and conditional kernel mean embeddings. We generalize existing pointwise-in-time or time-uniform confidence bounds for KRR to previously-inaccessible yet essential cases such as infinite-dimensional outputs with non-trace-class kernels. These bounds enable circumventing the need for independent data in our statistical tests, since they allow online sampling. We also introduce bootstrapping schemes leveraging the parametric form of testing thresholds identified in theory to avoid tuning inaccessible parameters, making our method readily applicable in practice. Such conditional two-sample tests are especially relevant in applications where data arrive sequentially or non-independently, or when output distributions vary with operational parameters. We demonstrate their utility through examples in process monitoring and comparison of dynamical systems. Overall, our results establish a comprehensive foundation for conditional two-sample testing, from theoretical guarantees to practical implementation, and advance the state-of-the-art on the concentration of vector-valued least squares estimation.","authors":["Pierre-Fran\\c{c}ois Massiani","Christian Fiedler","Lukas Haverbeck","Friedrich Solowjow","Sebastian Trimpe"],"url":"https://arxiv.org/abs/2506.03898"}
{"created":"2025-06-05","title":"Identification of Differential Equations by Dynamics-Guided Weighted Weak Form with Voting","abstract":"In the identification of differential equations from data, significant progresses have been made with the weak/integral formulation. In this paper, we explore the direction of finding more efficient and robust test functions adaptively given the observed data. While this is a difficult task, we propose weighting a collection of localized test functions for better identification of differential equations from a single trajectory of noisy observations on the differential equation. We find that using high dynamic regions is effective in finding the equation as well as the coefficients, and propose a dynamics indicator per differential term and weight the weak form accordingly. For stable identification against noise, we further introduce a voting strategy to identify the active features from an ensemble of recovered results by selecting the features that frequently occur in different weighting of test functions. Systematic numerical experiments are provided to demonstrate the robustness of our method.","authors":["Jiahui Cheng","Sung Ha Kang","Haomin Zhou","Wenjing Liao"],"url":"https://arxiv.org/abs/2506.03899"}
{"created":"2025-06-05","title":"Magic Mushroom: A Customizable Benchmark for Fine-grained Analysis of Retrieval Noise Erosion in RAG Systems","abstract":"Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) by incorporating external retrieved information, mitigating issues such as hallucination and outdated knowledge.","authors":["Yuxin Zhang","Yan Wang","Yongrui Chen","Shenyu Zhang","Xinbang Dai","Sheng Bi","Guilin Qi"],"url":"https://arxiv.org/abs/2506.03901"}
{"created":"2025-06-05","title":"The Harmonic Structure of Information Contours","abstract":"The uniform information density (UID) hypothesis proposes that speakers aim to distribute information evenly throughout a text, balancing production effort and listener comprehension difficulty. However, language typically does not maintain a strictly uniform information rate; instead, it fluctuates around a global average. These fluctuations are often explained by factors such as syntactic constraints, stylistic choices, or audience design. In this work, we explore an alternative perspective: that these fluctuations may be influenced by an implicit linguistic pressure towards periodicity, where the information rate oscillates at regular intervals, potentially across multiple frequencies simultaneously. We apply harmonic regression and introduce a novel extension called time scaling to detect and test for such periodicity in information contours. Analyzing texts in English, Spanish, German, Dutch, Basque, and Brazilian Portuguese, we find consistent evidence of periodic patterns in information rate. Many dominant frequencies align with discourse structure, suggesting these oscillations reflect meaningful linguistic organization. Beyond highlighting the connection between information rate and discourse structure, our approach offers a general framework for uncovering structural pressures at various levels of linguistic granularity.","authors":["Eleftheria Tsipidi","Samuel Kiegeland","Franz Nowak","Tianyang Xu","Ethan Wilcox","Alex Warstadt","Ryan Cotterell","Mario Giulianelli"],"url":"https://arxiv.org/abs/2506.03902"}
{"created":"2025-06-05","title":"Multi-Language Detection of Design Pattern Instances","abstract":"Code comprehension is often supported by source code analysis tools which provide more abstract views over software systems, such as those detecting design patterns. These tools encompass analysis of source code and ensuing extraction of relevant information. However, the analysis of the source code is often specific to the target programming language.","authors":["Hugo Andrade","Jo\\~ao Bispo","Filipe F. Correia"],"url":"https://arxiv.org/abs/2506.03903"}
{"created":"2025-06-05","title":"Stabilization of Linear Switched Systems with Long Input Delay via Average or Averaging Predictor Feedbacks","abstract":"We develop delay-compensating feedback laws for linear switched systems with time-dependent switching. Because the future values of the switching signal, which are needed for constructing an exact predictor-feedback law, may be unavailable at current time, the key design challenge is how to construct a proper predictor state. We resolve this challenge constructing two alternative, average predictor-based feedback laws. The first is viewed as a predictor-feedback law for a particular average system, properly modified to provide exact state predictions over a horizon that depends on a minimum dwell time of the switching signal (when it is available). The second is, essentially, a modification of an average of predictor feedbacks, each one corresponding to the fixed-mode predictor-feedback law. We establish that under the control laws introduced, the closed-loop systems are (uniformly) exponentially stable, provided that the differences among system's matrices and among (nominal stabilizing) controller's gains are sufficiently small, with a size that is inversely proportional to the delay length. Since no restriction is imposed on the delay, such a limitation is inherent to the problem considered (in which the future switching signal values are unavailable), and thus, it cannot be removed. The stability proof relies on multiple Lyapunov functionals constructed via backstepping and derivation of solutions' estimates for quantifying the difference between average and exact predictor states. We present consistent numerical simulation results, which illustrate the necessity of employing the average predictor-based laws and demonstrate the performance improvement when the knowledge of a minimum dwell time is properly utilized for improving state prediction accuracy.","authors":["Andreas Katsanikakis","Nikolaos Bekiaris-Liberis"],"url":"https://arxiv.org/abs/2506.03908"}
{"created":"2025-06-05","title":"Solsmith: Solidity Random Program Generator for Compiler Testing","abstract":"Smart contracts are computer programs that run on blockchain platforms, with Solidity being the most widely used language for their development. As blockchain technology advances, smart contracts have become increasingly important across various fields. In order for smart contracts to operate correctly, the correctness of the compiler is particularly crucial. Although some research efforts have been devoted to testing Solidity compilers, they primarily focus on testing methods and do not address the core issue of generating test programs. To fill this gap, this paper designs and implements Solsmith, a test program generator specifically aimed at uncovering defects in Solidity compilers. It tests the compiler correctness by generating valid and diverse Solidity programs. We have designed a series of unique program generation strategies tailored to Solidity, including enabling optimizations more frequently, avoiding undefined behaviour, and mitigating behavioural differences caused by intermediate representations. To validate the effectiveness of Solsmith, we assess the effectiveness of the test programs generated by Solsmith using the approach of differential testing. The preliminary results show that Solsmith can generate the expected test programs and uncover four confirmed defects in Solidity compilers, demonstrating the effectiveness and potential of Solsmith.","authors":["Lantian Li","Zhihao Liu","Zhongxing Yu"],"url":"https://arxiv.org/abs/2506.03909"}
{"created":"2025-06-05","title":"Enhancing Experimental Efficiency in Materials Design: A Comparative Study of Taguchi and Machine Learning Methods","abstract":"Materials design problems often require optimizing multiple variables, rendering full factorial exploration impractical. Design of experiment (DOE) methods, such as Taguchi technique, are commonly used to efficiently sample the design space but they inherently lack the ability to capture non-linear dependency of process variables. In this work, we demonstrate how machine learning (ML) methods can be used to overcome these limitations. We compare the performance of Taguchi method against an active learning based Gaussian process regression (GPR) model in a wire arc additive manufacturing (WAAM) process to accurately predict aspects of bead geometry, including penetration depth, bead width, and height. While Taguchi method utilized a three-factor, five-level L25 orthogonal array to suggest weld parameters, the GPR model used an uncertainty-based exploration acquisition function coupled with latin hypercube sampling for initial training data. Accuracy and efficiency of both models was evaluated on 15 test cases, with GPR outperforming Taguchi in both metrics. This work applies to broader materials processing domain requiring efficient exploration of complex parameters.","authors":["Shyam Prabhu","P Akshay Kumar","Antov Selwinston","Pavan Taduvai","Shreya Bairi","Rohit Batra"],"url":"https://arxiv.org/abs/2506.03910"}
{"created":"2025-06-05","title":"Learning Fair And Effective Points-Based Rewards Programs","abstract":"Points-based rewards programs are a prevalent way to incentivize customer loyalty; in these programs, customers who make repeated purchases from a seller accumulate points, working toward eventual redemption of a free reward. These programs have recently come under scrutiny due to accusations of unfair practices in their implementation. Motivated by these concerns, we study the problem of fairly designing points-based rewards programs, with a focus on two obstacles that put fairness at odds with their effectiveness. First, due to customer heterogeneity, the seller should set different redemption thresholds for different customers to generate high revenue. Second, the relationship between customer behavior and the number of accumulated points is typically unknown; this requires experimentation which may unfairly devalue customers' previously earned points. We first show that an individually fair rewards program that uses the same redemption threshold for all customers suffers a loss in revenue of at most a factor of $1+\\ln 2$, compared to the optimal personalized strategy that differentiates between customers. We then tackle the problem of designing temporally fair learning algorithms in the presence of demand uncertainty. Toward this goal, we design a learning algorithm that limits the risk of point devaluation due to experimentation by only changing the redemption threshold $O(\\log T)$ times, over a horizon of length $T$. This algorithm achieves the optimal (up to polylogarithmic factors) $\\widetilde{O}(\\sqrt{T})$ regret in expectation. We then modify this algorithm to only ever decrease redemption thresholds, leading to improved fairness at a cost of only a constant factor in regret. Extensive numerical experiments show the limited value of personalization in average-case settings, in addition to demonstrating the strong practical performance of our proposed learning algorithms.","authors":["Chamsi Hssaine","Yichun Hu","Ciara Pike-Burke"],"url":"https://arxiv.org/abs/2506.03911"}
{"created":"2025-06-05","title":"When Fairness Isn't Statistical: The Limits of Machine Learning in Evaluating Legal Reasoning","abstract":"Legal decisions are increasingly evaluated for fairness, consistency, and bias using machine learning (ML) techniques. In high-stakes domains like refugee adjudication, such methods are often applied to detect disparities in outcomes. Yet it remains unclear whether statistical methods can meaningfully assess fairness in legal contexts shaped by discretion, normative complexity, and limited ground truth.","authors":["Claire Barale","Michael Rovatsos","Nehal Bhuta"],"url":"https://arxiv.org/abs/2506.03913"}
{"created":"2025-06-05","title":"Learning equivariant models by discovering symmetries with learnable augmentations","abstract":"Recently, a trend has emerged that favors learning relevant symmetries from data in geometric domains instead of designing constrained architectures. To do so, two popular options are (1) to modify the training protocol, e.g., with a specific loss and data augmentations (soft equivariance), or (2) to ignore equivariance and infer it only implicitly. However, both options have limitations: soft equivariance requires a priori knowledge about relevant symmetries, while inferring symmetries merely via the task and larger data lacks interpretability. To address both limitations, we propose SEMoLA, an end-to-end approach that jointly (1) discovers a priori unknown symmetries in the data via learnable data augmentations, and (2) softly encodes the respective approximate equivariance into an arbitrary unconstrained model. Hence, it does not need prior knowledge about symmetries, it offers interpretability, and it maintains robustness to distribution shifts. Empirically, we demonstrate the ability of SEMoLA to robustly discover relevant symmetries while achieving high prediction accuracy across various datasets, encompassing multiple data modalities and underlying symmetry groups.","authors":["Eduardo Santos Escriche","Stefanie Jegelka"],"url":"https://arxiv.org/abs/2506.03914"}
{"created":"2025-06-05","title":"Causal Explanations Over Time: Articulated Reasoning for Interactive Environments","abstract":"Structural Causal Explanations (SCEs) can be used to automatically generate explanations in natural language to questions about given data that are grounded in a (possibly learned) causal model. Unfortunately they work for small data only. In turn they are not attractive to offer reasons for events, e.g., tracking causal changes over multiple time steps, or a behavioral component that involves feedback loops through actions of an agent. To this end, we generalize SCEs to a (recursive) formulation of explanation trees to capture the temporal interactions between reasons. We show the benefits of this more general SCE algorithm on synthetic time-series data and a 2D grid game, and further compare it to the base SCE and other existing methods for causal explanations.","authors":["Sebastian R\\\"odling","Matej Ze\\v{c}evi\\'c","Devendra Singh Dhami","Kristian Kersting"],"url":"https://arxiv.org/abs/2506.03915"}
{"created":"2025-06-05","title":"Compositional Generalisation for Explainable Hate Speech Detection","abstract":"Hate speech detection is key to online content moderation, but current models struggle to generalise beyond their training data. This has been linked to dataset biases and the use of sentence-level labels, which fail to teach models the underlying structure of hate speech. In this work, we show that even when models are trained with more fine-grained, span-level annotations (e.g., \"artists\" is labeled as target and \"are parasites\" as dehumanising comparison), they struggle to disentangle the meaning of these labels from the surrounding context. As a result, combinations of expressions that deviate from those seen during training remain particularly difficult for models to detect. We investigate whether training on a dataset where expressions occur with equal frequency across all contexts can improve generalisation. To this end, we create U-PLEAD, a dataset of ~364,000 synthetic posts, along with a novel compositional generalisation benchmark of ~8,000 manually validated posts. Training on a combination of U-PLEAD and real data improves compositional generalisation while achieving state-of-the-art performance on the human-sourced PLEAD.","authors":["Agostina Calabrese","Tom Sherborne","Bj\\\"orn Ross","Mirella Lapata"],"url":"https://arxiv.org/abs/2506.03916"}
{"created":"2025-06-05","title":"Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection","abstract":"Event-based sensors offer significant advantages over traditional frame-based cameras, especially in scenarios involving rapid motion or challenging lighting conditions. However, event data frequently suffers from considerable noise, negatively impacting the performance and robustness of deep learning models. Traditionally, this problem has been addressed by applying filtering algorithms to the event stream, but this may also remove some of relevant data. In this paper, we propose a novel noise-injection training methodology designed to enhance the neural networks robustness against varying levels of event noise. Our approach introduces controlled noise directly into the training data, enabling models to learn noise-resilient representations. We have conducted extensive evaluations of the proposed method using multiple benchmark datasets (N-Caltech101, N-Cars, and Mini N-ImageNet) and various network architectures, including Convolutional Neural Networks, Vision Transformers, Spiking Neural Networks, and Graph Convolutional Networks. Experimental results show that our noise-injection training strategy achieves stable performance over a range of noise intensities, consistently outperforms event-filtering techniques, and achieves the highest average classification accuracy, making it a viable alternative to traditional event-data filtering methods in an object classification system. Code: https://github.com/vision-agh/DVS_Filtering","authors":["Marcin Kowalczyk","Kamil Jeziorek","Tomasz Kryjak"],"url":"https://arxiv.org/abs/2506.03918"}
{"created":"2025-06-05","title":"Weisfeiler and Leman Go Gambling: Why Expressive Lottery Tickets Win","abstract":"The lottery ticket hypothesis (LTH) is well-studied for convolutional neural networks but has been validated only empirically for graph neural networks (GNNs), for which theoretical findings are largely lacking. In this paper, we identify the expressivity of sparse subnetworks, i.e. their ability to distinguish non-isomorphic graphs, as crucial for finding winning tickets that preserve the predictive performance. We establish conditions under which the expressivity of a sparsely initialized GNN matches that of the full network, particularly when compared to the Weisfeiler-Leman test, and in that context put forward and prove a Strong Expressive Lottery Ticket Hypothesis. We subsequently show that an increased expressivity in the initialization potentially accelerates model convergence and improves generalization. Our findings establish novel theoretical foundations for both LTH and GNN research, highlighting the importance of maintaining expressivity in sparsely initialized GNNs. We illustrate our results using examples from drug discovery.","authors":["Lorenz Kummer","Samir Moustafa","Anatol Ehrlich","Franka Bause","Nikolaus Suess","Wilfried N. Gansterer","Nils M. Kriege"],"url":"https://arxiv.org/abs/2506.03919"}
{"created":"2025-06-05","title":"Boosting Open-Source LLMs for Program Repair via Reasoning Transfer and LLM-Guided Reinforcement Learning","abstract":"Several closed-source LLMs have consistently outperformed open-source alternatives in program repair tasks, primarily due to their superior reasoning capabilities and extensive pre-training. This paper introduces Repairity, a novel three-stage methodology that significantly narrows this performance gap through reasoning extraction and reinforcement learning. Our approach: (1) systematically filters high-quality reasoning traces from closed-source models using correctness verification, (2) transfers this reasoning knowledge to open-source models via supervised fine-tuning, and (3) develops reinforcement learning with LLM-based feedback to further optimize performance. Empirical evaluation across multiple program repair benchmarks demonstrates that Repairity improves the performance of Qwen2.5-Coder-32B-Instruct, a base open source LLM, by 8.68\\% on average, reducing the capability gap with Claude-Sonnet3.7, a state-of-the-art closed-source model, from 10.05% to 1.35%. Ablation studies confirm that both reasoning extraction and LLM-guided reinforcement learning contribute significantly to these improvements. Our methodology generalizes effectively to additional code-related tasks, enabling organizations to leverage high-quality program repair capabilities while maintaining the customizability, transparency, and deployment flexibility inherent to open-source models.","authors":["Xunzhu Tang","Jacques Klein","Tegawend\\'e F. Bissyand\\'e"],"url":"https://arxiv.org/abs/2506.03921"}
{"created":"2025-06-05","title":"HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models","abstract":"Multimodal Large Language Models (MLLMs) have demonstrated significant potential to advance a broad range of domains. However, current benchmarks for evaluating MLLMs primarily emphasize general knowledge and vertical step-by-step reasoning typical of STEM disciplines, while overlooking the distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks in the HSS domain require more horizontal, interdisciplinary thinking and a deep integration of knowledge across related fields, which presents unique challenges for MLLMs, particularly in linking abstract concepts with corresponding visual representations. Addressing this gap, we present HSSBench, a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks in multiple languages, including the six official languages of the United Nations. We also introduce a novel data generation pipeline tailored for HSS scenarios, in which multiple domain experts and automated agents collaborate to generate and iteratively refine each sample. HSSBench contains over 13,000 meticulously designed samples, covering six key categories. We benchmark more than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant challenges even for state-of-the-art models. We hope that this benchmark will inspire further research into enhancing the cross-disciplinary reasoning abilities of MLLMs, especially their capacity to internalize and connect knowledge across fields.","authors":["Zhaolu Kang","Junhao Gong","Jiaxu Yan","Wanke Xia","Yian Wang","Ziwen Wang","Huaxuan Ding","Zhuo Cheng","Wenhao Cao","Zhiyuan Feng","Siqi He","Shannan Yan","Junzhe Chen","Xiaomin He","Chaoya Jiang","Wei Ye","Kaidong Yu","Xuelong Li"],"url":"https://arxiv.org/abs/2506.03922"}
{"created":"2025-06-05","title":"More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning","abstract":"Large language models (LLMs) are known to be sensitive to input phrasing, but the mechanisms by which semantic cues shape reasoning remain poorly understood. We investigate this phenomenon in the context of comparative math problems with objective ground truth, revealing a consistent and directional framing bias: logically equivalent questions containing the words ``more'', ``less'', or ``equal'' systematically steer predictions in the direction of the framing term. To study this effect, we introduce MathComp, a controlled benchmark of 300 comparison scenarios, each evaluated under 14 prompt variants across three LLM families. We find that model errors frequently reflect linguistic steering, systematic shifts toward the comparative term present in the prompt. Chain-of-thought prompting reduces these biases, but its effectiveness varies: free-form reasoning is more robust, while structured formats may preserve or reintroduce directional drift. Finally, we show that including demographic identity terms (e.g., ``a woman'', ``a Black person'') in input scenarios amplifies directional drift, despite identical underlying quantities, highlighting the interplay between semantic framing and social referents. These findings expose critical blind spots in standard evaluation and motivate framing-aware benchmarks for diagnosing reasoning robustness and fairness in LLMs.","authors":["Mohammadamin Shafiei","Hamidreza Saffari","Nafise Sadat Moosavi"],"url":"https://arxiv.org/abs/2506.03923"}
{"created":"2025-06-05","title":"Multiple Stochastic Prompt Tuning for Practical Cross-Domain Few Shot Learning","abstract":"In this work, we propose a practical cross-domain few-shot learning (pCDFSL) task, where a large-scale pre-trained model like CLIP can be easily deployed on a target dataset. The goal is to simultaneously classify all unseen classes under extreme domain shifts, by utilizing only a few labeled samples per class. The pCDFSL paradigm is source-free and moves beyond artificially created episodic training and testing regimes followed by existing CDFSL frameworks, making it more challenging and relevant to real-world applications. Towards that goal, we propose a novel framework, termed MIST (MultIple STochastic Prompt tuning), where multiple stochastic prompts are utilized to handle significant domain and semantic shifts. Specifically, multiple prompts are learnt for each class, effectively capturing multiple peaks in the input data. Furthermore, instead of representing the weights of the multiple prompts as point-estimates, we model them as learnable Gaussian distributions with two different strategies, encouraging an efficient exploration of the prompt parameter space, which mitigate overfitting due to the few labeled training samples. Extensive experiments and comparison with the state-of-the-art methods on four CDFSL benchmarks adapted to this setting, show the effectiveness of the proposed framework.","authors":["Debarshi Brahma","Soma Biswas"],"url":"https://arxiv.org/abs/2506.03926"}
{"created":"2025-06-05","title":"Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample","abstract":"In this work, we study the Efficient Multimodal Large Language Model. Redundant vision tokens consume a significant amount of computational memory and resources. Therefore, many previous works compress them in the Vision Projector to reduce the number of vision tokens. However, simply compressing in the Vision Projector can lead to the loss of visual information, especially for tasks that rely on fine-grained spatial relationships, such as OCR and Chart \\& Table Understanding. To address this problem, we propose Vision Remember, which is inserted between the LLM decoder layers to allow vision tokens to re-memorize vision features. Specifically, we retain multi-level vision features and resample them with the vision tokens that have interacted with the text token. During the resampling process, each vision token only attends to a local region in vision features, which is referred to as saliency-enhancing local attention. Saliency-enhancing local attention not only improves computational efficiency but also captures more fine-grained contextual information and spatial relationships within the region. Comprehensive experiments on multiple visual understanding benchmarks validate the effectiveness of our method when combined with various Efficient Vision Projectors, showing performance gains without sacrificing efficiency. Based on Vision Remember, LLaVA-VR with only 2B parameters is also superior to previous representative MLLMs such as Tokenpacker-HD-7B and DeepSeek-VL-7B.","authors":["Ze Feng","Jiang-Jiang Liu","Sen Yang","Lingyu Xiao","Xiaofan Li","Wankou Yang","Jingdong Wang"],"url":"https://arxiv.org/abs/2506.03928"}
{"created":"2025-06-05","title":"Control Signaling for Reconfigurable Intelligent Surfaces: How Many Bits are Needed?","abstract":"Reconfigurable intelligent surfaces (RISs) can greatly improve the signal quality of future communication systems by reflecting transmitted signals toward the receiver. However, even when the base station (BS) has perfect channel knowledge and can compute the optimal RIS phase-shift configuration, implementing this configuration requires feedback signaling over a control channel from the BS to the RIS. This feedback must be kept minimal, as it is transmitted wirelessly every time the channel changes. In this paper, we examine how the feedback load, measured in bits, affects the performance of an RIS-aided system. Specifically, we investigate the trade-offs between codebook-based and element-wise feedback schemes, and how these influence the signal-to-noise ratio (SNR). We propose a novel quantization codebook tailored for line-of-sight (LoS) that guarantees a minimal SNR loss using a number of feedback bits that scale logarithmically with the number of RIS elements. We demonstrate the codebook's usefulness over Rician fading channels and how to extend it to handle a non-zero static path. Numerical simulations and analytical analysis are performed to quantify the performance degradation that results from a reduced feedback load, shedding light on how efficiently RIS configurations can be fed back in practical systems.","authors":["Anders Enqvist","\\\"Ozlem Tu\\u{g}fe Demir","Cicek Cavdar","Emil Bj\\\"ornson"],"url":"https://arxiv.org/abs/2506.03929"}
{"created":"2025-06-05","title":"VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation","abstract":"Large language models (LLMs) often struggle with visualization tasks like plotting diagrams, charts, where success depends on both code correctness and visual semantics. Existing instruction-tuning datasets lack execution-grounded supervision and offer limited support for iterative code correction, resulting in fragile and unreliable plot generation. We present VisCode-200K, a large-scale instruction tuning dataset for Python-based visualization and self-correction. It contains over 200K examples from two sources: (1) validated plotting code from open-source repositories, paired with natural language instructions and rendered plots; and (2) 45K multi-turn correction dialogues from Code-Feedback, enabling models to revise faulty code using runtime feedback. We fine-tune Qwen2.5-Coder-Instruct on VisCode-200K to create VisCoder, and evaluate it on PandasPlotBench. VisCoder significantly outperforms strong open-source baselines and approaches the performance of proprietary models like GPT-4o-mini. We further adopt a self-debug evaluation protocol to assess iterative repair, demonstrating the benefits of feedback-driven learning for executable, visually accurate code generation.","authors":["Yuansheng Ni","Ping Nie","Kai Zou","Xiang Yue","Wenhu Chen"],"url":"https://arxiv.org/abs/2506.03930"}
{"created":"2025-06-05","title":"Do Neural Networks Need Gradient Descent to Generalize? A Theoretical Study","abstract":"Conventional wisdom attributes the mysterious generalization abilities of overparameterized neural networks to gradient descent (and its variants). The recent volume hypothesis challenges this view: it posits that these generalization abilities persist even when gradient descent is replaced by Guess & Check (G&amp;C), i.e., by drawing weight settings until one that fits the training data is found. The validity of the volume hypothesis for wide and deep neural networks remains an open question. In this paper, we theoretically investigate this question for matrix factorization (with linear and non-linear activation)--a common testbed in neural network theory. We first prove that generalization under G&amp;C deteriorates with increasing width, establishing what is, to our knowledge, the first case where G&amp;C is provably inferior to gradient descent. Conversely, we prove that generalization under G&amp;C improves with increasing depth, revealing a stark contrast between wide and deep networks, which we further validate empirically. These findings suggest that even in simple settings, there may not be a simple answer to the question of whether neural networks need gradient descent to generalize well.","authors":["Yotam Alexander","Yonatan Slutzky","Yuval Ran-Milo","Nadav Cohen"],"url":"https://arxiv.org/abs/2506.03931"}
{"created":"2025-06-05","title":"DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models","abstract":"Vision Language Models (VLMs) have shown remarkable capabilities in multimodal understanding, yet their susceptibility to perturbations poses a significant threat to their reliability in real-world applications. Despite often being imperceptible to humans, these perturbations can drastically alter model outputs, leading to erroneous interpretations and decisions. This paper introduces DiffCAP, a novel diffusion-based purification strategy that can effectively neutralize adversarial corruptions in VLMs. We observe that adding minimal noise to an adversarially corrupted image significantly alters its latent embedding with respect to VLMs. Building on this insight, DiffCAP cumulatively injects random Gaussian noise into adversarially perturbed input data. This process continues until the embeddings of two consecutive noisy images reach a predefined similarity threshold, indicating a potential approach to neutralize the adversarial effect. Subsequently, a pretrained diffusion model is employed to denoise the stabilized image, recovering a clean representation suitable for the VLMs to produce an output. Through extensive experiments across six datasets with three VLMs under varying attack strengths in three task scenarios, we show that DiffCAP consistently outperforms existing defense techniques by a substantial margin. Notably, DiffCAP significantly reduces both hyperparameter tuning complexity and the required diffusion time, thereby accelerating the denoising process. Equipped with strong theoretical and empirical support, DiffCAP provides a robust and practical solution for securely deploying VLMs in adversarial environments.","authors":["Jia Fu","Yongtao Wu","Yihang Chen","Kunyu Peng","Xiao Zhang","Volkan Cevher","Sepideh Pashami","Anders Holst"],"url":"https://arxiv.org/abs/2506.03933"}
{"created":"2025-06-05","title":"FPGA-Enabled Machine Learning Applications in Earth Observation: A Systematic Review","abstract":"New UAV technologies and the NewSpace era are transforming Earth Observation missions and data acquisition. Numerous small platforms generate large data volume, straining bandwidth and requiring onboard decision-making to transmit high-quality information in time. While Machine Learning allows real-time autonomous processing, FPGAs balance performance with adaptability to mission-specific requirements, enabling onboard deployment. This review systematically analyzes 66 experiments deploying ML models on FPGAs for Remote Sensing applications. We introduce two distinct taxonomies to capture both efficient model architectures and FPGA implementation strategies. For transparency and reproducibility, we follow PRISMA 2020 guidelines and share all data and code at https://github.com/CedricLeon/Survey_RS-ML-FPGA.","authors":["C\\'edric L\\'eonard (Technical University of Munich","Munich","Germany","Remote Sensing Technology Institute)","Dirk Stober (Technical University of Munich","Munich","Germany)","Martin Schulz (Technical University of Munich","Munich","Germany)"],"url":"https://arxiv.org/abs/2506.03938"}
{"created":"2025-06-05","title":"Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning","abstract":"Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external knowledge integration capabilities by explicitly modeling knowledge relationships, thereby improving the factual accuracy and generation quality of Large Language Models (LLMs) in specialized domains. However, existing methods suffer from two inherent limitations: 1) Inefficient Information Aggregation: They rely on a single agent and fixed iterative patterns, making it difficult to adaptively capture multi-level textual, structural, and degree information within graph data. 2) Rigid Reasoning Mechanism: They employ preset reasoning schemes, which cannot dynamically adjust reasoning depth nor achieve precise semantic correction. To overcome these limitations, we propose Graph Counselor, an GraphRAG method based on multi-agent collaboration. This method uses the Adaptive Graph Information Extraction Module (AGIEM), where Planning, Thought, and Execution Agents work together to precisely model complex graph structures and dynamically adjust information extraction strategies, addressing the challenges of multi-level dependency modeling and adaptive reasoning depth. Additionally, the Self-Reflection with Multiple Perspectives (SR) module improves the accuracy and semantic consistency of reasoning results through self-reflection and backward reasoning mechanisms. Experiments demonstrate that Graph Counselor outperforms existing methods in multiple graph reasoning tasks, exhibiting higher reasoning accuracy and generalization ability. Our code is available at https://github.com/gjq100/Graph-Counselor.git.","authors":["Junqi Gao","Xiang Zou","YIng Ai","Dong Li","Yichen Niu","Biqing Qi","Jianxing Liu"],"url":"https://arxiv.org/abs/2506.03939"}
{"created":"2025-06-05","title":"Depermissioning Web3: a Permissionless Accountable RPC Protocol for Blockchain Networks","abstract":"In blockchain networks, so-called \"full nodes\" serve data to and relay transactions from clients through an RPC interface. This serving layer enables integration of \"Web3\" data, stored on blockchains, with \"Web2\" mobile or web applications that cannot directly participate as peers in a blockchain network. In practice, the serving layer is dominated by a small number of centralized services (\"node providers\") that offer permissioned access to RPC endpoints. Clients register with these providers because they offer reliable and convenient access to blockchain data: operating a full node themselves requires significant computational and storage resources, and public (permissionless) RPC nodes lack financial incentives to serve large numbers of clients with consistent performance.","authors":["Weihong Wang","Tom Van Cutsem"],"url":"https://arxiv.org/abs/2506.03940"}
{"created":"2025-06-05","title":"Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations","abstract":"During a conversation, there can come certain moments where its outcome hangs in the balance. In these pivotal moments, how one responds can put the conversation on substantially different trajectories leading to significantly different outcomes. Systems that can detect when such moments arise could assist conversationalists in domains with highly consequential outcomes, such as mental health crisis counseling.","authors":["Vivian Nguyen","Lillian Lee","Cristian Danescu-Niculescu-Mizil"],"url":"https://arxiv.org/abs/2506.03941"}
{"created":"2025-06-05","title":"Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation","abstract":"Deep neural networks for medical image segmentation are often overconfident, compromising both reliability and clinical utility. In this work, we propose differentiable formulations of marginal L1 Average Calibration Error (mL1-ACE) as an auxiliary loss that can be computed on a per-image basis. We compare both hard- and soft-binning approaches to directly improve pixel-wise calibration. Our experiments on four datasets (ACDC, AMOS, KiTS, BraTS) demonstrate that incorporating mL1-ACE significantly reduces calibration errors, particularly Average Calibration Error (ACE) and Maximum Calibration Error (MCE), while largely maintaining high Dice Similarity Coefficients (DSCs). We find that the soft-binned variant yields the greatest improvements in calibration, over the Dice plus cross-entropy loss baseline, but often compromises segmentation performance, with hard-binned mL1-ACE maintaining segmentation performance, albeit with weaker calibration improvement. To gain further insight into calibration performance and its variability across an imaging dataset, we introduce dataset reliability histograms, an aggregation of per-image reliability diagrams. The resulting analysis highlights improved alignment between predicted confidences and true accuracies. Overall, our approach not only enhances the trustworthiness of segmentation predictions but also shows potential for safer integration of deep learning methods into clinical workflows. We share our code here: https://github.com/cai4cai/Average-Calibration-Losses","authors":["Theodore Barfoot","Luis C. Garcia-Peraza-Herrera","Samet Akcay","Ben Glocker","Tom Vercauteren"],"url":"https://arxiv.org/abs/2506.03942"}
{"created":"2025-06-05","title":"Lower Ricci Curvature for Hypergraphs","abstract":"Networks with higher-order interactions, prevalent in biological, social, and information systems, are naturally represented as hypergraphs, yet their structural complexity poses fundamental challenges for geometric characterization. While curvature-based methods offer powerful insights in graph analysis, existing extensions to hypergraphs suffer from critical trade-offs: combinatorial approaches such as Forman-Ricci curvature capture only coarse features, whereas geometric methods like Ollivier-Ricci curvature offer richer expressivity but demand costly optimal transport computations. To address these challenges, we introduce hypergraph lower Ricci curvature (HLRC), a novel curvature metric defined in closed form that achieves a principled balance between interpretability and efficiency. Evaluated across diverse synthetic and real-world hypergraph datasets, HLRC consistently reveals meaningful higher-order organization, distinguishing intra- from inter-community hyperedges, uncovering latent semantic labels, tracking temporal dynamics, and supporting robust clustering of hypergraphs based on global structure. By unifying geometric sensitivity with algorithmic simplicity, HLRC provides a versatile foundation for hypergraph analytics, with broad implications for tasks including node classification, anomaly detection, and generative modeling in complex systems.","authors":["Shiyi Yang","Can Chen","Didong Li"],"url":"https://arxiv.org/abs/2506.03943"}
{"created":"2025-06-05","title":"Automatic Multi-level Feature Tree Construction for Domain-Specific Reusable Artifacts Management","abstract":"With the rapid growth of open-source ecosystems (e.g., Linux) and domain-specific software projects (e.g., aerospace), efficient management of reusable artifacts is becoming increasingly crucial for software reuse. The multi-level feature tree enables semantic management based on functionality and supports requirements-driven artifact selection. However, constructing such a tree heavily relies on domain expertise, which is time-consuming and labor-intensive. To address this issue, this paper proposes an automatic multi-level feature tree construction framework named FTBUILDER, which consists of three stages. It automatically crawls domain-specific software repositories and merges their metadata to construct a structured artifact library. It employs clustering algorithms to identify a set of artifacts with common features. It constructs a prompt and uses LLMs to summarize their common features. FTBUILDER recursively applies the identification and summarization stages to construct a multi-level feature tree from the bottom up. To validate FTBUILDER, we conduct experiments from multiple aspects (e.g., tree quality and time cost) using the Linux distribution ecosystem. Specifically, we first simultaneously develop and evaluate 24 alternative solutions in the FTBUILDER. We then construct a three-level feature tree using the best solution among them. Compared to the official feature tree, our tree exhibits higher quality, with a 9% improvement in the silhouette coefficient and an 11% increase in GValue. Furthermore, it can save developers more time in selecting artifacts by 26% and improve the accuracy of artifact recommendations with GPT-4 by 235%. FTBUILDER can be extended to other open-source software communities and domain-specific industrial enterprises.","authors":["Dongming Jin","Zhi Jin","Nianyu Li","Kai Yang","Linyu Li","Suijing Guan"],"url":"https://arxiv.org/abs/2506.03946"}
{"created":"2025-06-05","title":"Block Alpha-Circulant Preconditioners for All-at-Once Diffusion-Based Covariance Operators","abstract":"Covariance matrices are central to data assimilation and inverse methods derived from statistical estimation theory. Previous work has considered the application of an all-at-once diffusion-based representation of a covariance matrix operator in order to exploit inherent parallellism in the underlying problem. In this paper, we provide practical methods to apply block $\\alpha$-circulant preconditioners to the all-at-once system for the case where the main diffusion operation matrix cannot be readily diagonalized using a discrete Fourier transform. Our new framework applies the block $\\alpha$-circulant preconditioner approximately by solving an inner block diagonal problem via a choice of inner iterative approaches. Our first method applies Chebyshev semi-iteration to a symmetric positive definite matrix, shifted by a complex scaling of the identity. We extend theoretical results for Chebyshev semi-iteration in the symmetric positive definite setting, to obtain computable bounds on the asymptotic convergence factor for each of the complex sub-problems. The second approach transforms the complex sub-problem into a (generalized) saddle point system with real coefficients. Numerical experiments reveal that in the case of unlimited computational resources, both methods can match the iteration counts of the `best-case' block $\\alpha$-circulant preconditioner. We also provide a practical adaptation to the nested Chebyshev approach, which improves performance in the case of a limited computational budget. Using an appropriate choice of $\\alpha$ our new approaches are robust and efficient in terms of outer iterations and matrix--vector products.","authors":["Jemima M. Tabeart","Selime G\\\"urol","John W. Pearson","Anthony W. Weaver"],"url":"https://arxiv.org/abs/2506.03947"}
{"created":"2025-06-05","title":"TableEval: A Real-World Benchmark for Complex, Multilingual, and Multi-Structured Table Question Answering","abstract":"LLMs have shown impressive progress in natural language processing. However, they still face significant challenges in TableQA, where real-world complexities such as diverse table structures, multilingual data, and domain-specific reasoning are crucial. Existing TableQA benchmarks are often limited by their focus on simple flat tables and suffer from data leakage. Furthermore, most benchmarks are monolingual and fail to capture the cross-lingual and cross-domain variability in practical applications. To address these limitations, we introduce TableEval, a new benchmark designed to evaluate LLMs on realistic TableQA tasks. Specifically, TableEval includes tables with various structures (such as concise, hierarchical, and nested tables) collected from four domains (including government, finance, academia, and industry reports). Besides, TableEval features cross-lingual scenarios with tables in Simplified Chinese, Traditional Chinese, and English. To minimize the risk of data leakage, we collect all data from recent real-world documents. Considering that existing TableQA metrics fail to capture semantic accuracy, we further propose SEAT, a new evaluation framework that assesses the alignment between model responses and reference answers at the sub-question level. Experimental results have shown that SEAT achieves high agreement with human judgment. Extensive experiments on TableEval reveal critical gaps in the ability of state-of-the-art LLMs to handle these complex, real-world TableQA tasks, offering insights for future improvements. We make our dataset available here: https://github.com/wenge-research/TableEval.","authors":["Junnan Zhu","Jingyi Wang","Bohan Yu","Xiaoyu Wu","Junbo Li","Lei Wang","Nan Xu"],"url":"https://arxiv.org/abs/2506.03949"}
{"created":"2025-06-05","title":"Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective","abstract":"The quest for Continual Learning (CL) seeks to empower neural networks with the ability to learn and adapt incrementally. Central to this pursuit is addressing the stability-plasticity dilemma, which involves striking a balance between two conflicting objectives: preserving previously learned knowledge and acquiring new knowledge. While numerous CL methods aim to achieve this trade-off, they often overlook the impact of network architecture on stability and plasticity, restricting the trade-off to the parameter level. In this paper, we delve into the conflict between stability and plasticity at the architectural level. We reveal that under an equal parameter constraint, deeper networks exhibit better plasticity, while wider networks are characterized by superior stability. To address this architectural-level dilemma, we introduce a novel framework denoted Dual-Arch, which serves as a plug-in component for CL. This framework leverages the complementary strengths of two distinct and independent networks: one dedicated to plasticity and the other to stability. Each network is designed with a specialized and lightweight architecture, tailored to its respective objective. Extensive experiments demonstrate that Dual-Arch enhances the performance of existing CL methods while being up to 87% more compact in terms of parameters.","authors":["Aojun Lu","Hangjie Yuan","Tao Feng","Yanan Sun"],"url":"https://arxiv.org/abs/2506.03951"}
{"created":"2025-06-05","title":"HtFLlib: A Comprehensive Heterogeneous Federated Learning Library and Benchmark","abstract":"As AI evolves, collaboration among heterogeneous models helps overcome data scarcity by enabling knowledge transfer across institutions and devices. Traditional Federated Learning (FL) only supports homogeneous models, limiting collaboration among clients with heterogeneous model architectures. To address this, Heterogeneous Federated Learning (HtFL) methods are developed to enable collaboration across diverse heterogeneous models while tackling the data heterogeneity issue at the same time. However, a comprehensive benchmark for standardized evaluation and analysis of the rapidly growing HtFL methods is lacking. Firstly, the highly varied datasets, model heterogeneity scenarios, and different method implementations become hurdles to making easy and fair comparisons among HtFL methods. Secondly, the effectiveness and robustness of HtFL methods are under-explored in various scenarios, such as the medical domain and sensor signal modality. To fill this gap, we introduce the first Heterogeneous Federated Learning Library (HtFLlib), an easy-to-use and extensible framework that integrates multiple datasets and model heterogeneity scenarios, offering a robust benchmark for research and practical applications. Specifically, HtFLlib integrates (1) 12 datasets spanning various domains, modalities, and data heterogeneity scenarios; (2) 40 model architectures, ranging from small to large, across three modalities; (3) a modularized and easy-to-extend HtFL codebase with implementations of 10 representative HtFL methods; and (4) systematic evaluations in terms of accuracy, convergence, computation costs, and communication costs. We emphasize the advantages and potential of state-of-the-art HtFL methods and hope that HtFLlib will catalyze advancing HtFL research and enable its broader applications. The code is released at https://github.com/TsingZ0/HtFLlib.","authors":["Jianqing Zhang","Xinghao Wu","Yanbing Zhou","Xiaoting Sun","Qiqi Cai","Yang Liu","Yang Hua","Zhenzhe Zheng","Jian Cao","Qiang Yang"],"url":"https://arxiv.org/abs/2506.03954"}
{"created":"2025-06-05","title":"Adapt before Continual Learning","abstract":"Continual Learning (CL) seeks to enable neural networks to incrementally acquire new knowledge (plasticity) while retaining existing knowledge (stability). While pre-trained models (PTMs) have become pivotal in CL, prevailing approaches freeze the PTM backbone to preserve stability, limiting their plasticity, particularly when encountering significant domain gaps in incremental tasks. Conversely, sequentially finetuning the entire PTM risks catastrophic forgetting of generalizable knowledge, exposing a critical stability-plasticity trade-off. To address this challenge, we propose Adapting PTMs before the core CL process (ACL), a novel framework that refines the PTM backbone through a plug-and-play adaptation phase before learning each new task with existing CL approaches (e.g., prompt tuning). ACL enhances plasticity by aligning embeddings with their original class prototypes while distancing them from others, theoretically and empirically shown to balance stability and plasticity. Extensive experiments demonstrate that ACL significantly improves CL performance across benchmarks and integrated methods, offering a versatile solution for PTM-based CL.","authors":["Aojun Lu","Tao Feng","Hangjie Yuan","Chunhui Ding","Yanan Sun"],"url":"https://arxiv.org/abs/2506.03956"}
{"created":"2025-06-05","title":"From Spikes to Speech: NeuroVoc -- A Biologically Plausible Vocoder Framework for Auditory Perception and Cochlear Implant Simulation","abstract":"We present NeuroVoc, a flexible model-agnostic vocoder framework that reconstructs acoustic waveforms from simulated neural activity patterns using an inverse Fourier transform. The system applies straightforward signal processing to neurogram representations, time-frequency binned outputs from auditory nerve fiber models. Crucially, the model architecture is modular, allowing for easy substitution or modification of the underlying auditory models. This flexibility eliminates the need for speech-coding-strategy-specific vocoder implementations when simulating auditory perception in cochlear implant (CI) users. It also allows direct comparisons between normal hearing (NH) and electrical hearing (EH) models, as demonstrated in this study. The vocoder preserves distinctive features of each model; for example, the NH model retains harmonic structure more faithfully than the EH model. We evaluated perceptual intelligibility in noise using an online Digits-in-Noise (DIN) test, where participants completed three test conditions: one with standard speech, and two with vocoded speech using the NH and EH models. Both the standard DIN test and the EH-vocoded groups were statistically equivalent to clinically reported data for NH and CI listeners. On average, the NH and EH vocoded groups increased SRT compared to the standard test by 2.4 dB and 7.1 dB, respectively. These findings show that, although some degradation occurs, the vocoder can reconstruct intelligible speech under both hearing models and accurately reflects the reduced speech-in-noise performance experienced by CI users.","authors":["Jacob de Nobel","Jeroen J. Briaire","Thomas H. W. Baeck","Anna V. Kononova","Johan H. M. Frijns"],"url":"https://arxiv.org/abs/2506.03959"}
{"created":"2025-06-05","title":"Better Late than Never: the Complexity of Arrangements of Polyhedra","abstract":"Let $\\mathcal{A}$ be the subdivision of $\\mathbb{R}^d$ induced by $m$ convex polyhedra having $n$ facets in total. We prove that $\\mathcal{A}$ has combinatorial complexity $O(m^{\\lceil d/2 \\rceil} n^{\\lfloor d/2 \\rfloor})$ and that this bound is tight. The bound is mentioned several times in the literature, but no proof for arbitrary dimension has been published before.","authors":["Boris Aronov","Sang Won Bae","Sergio Cabello","Otfried Cheong","David Eppstein","Christian Knauer","Raimund Seidel"],"url":"https://arxiv.org/abs/2506.03960"}
{"created":"2025-06-05","title":"Stable recovery of complex dictionary-sparse signals from phaseless measurements","abstract":"Dictionary-sparse phase retrieval, which is also known as phase retrieval with redundant dictionary, aims to reconstruct an original dictionary-sparse signal from its measurements without phase information. It is proved that if the measurement matrix $A$ satisfies null space property (NSP)/strong dictionary restricted isometry property (S-DRIP), then the dictionary-sparse signal can be exactly/stably recovered from its magnitude-only measurements up to a global phase. However, the S-DRIP holds only for real signals. Hence, in this paper, we mainly study the stability of the $\\ell_1$-analysis minimization and its generalized $\\ell_q\\;(0<q><q\\leq1)$-analysis minimization.","authors":["Lianxing Xia","Haiye Huo"],"url":"https://arxiv.org/abs/2506.03961"}
{"created":"2025-06-05","title":"Causality-Aware Contrastive Learning for Robust Multivariate Time-Series Anomaly Detection","abstract":"Utilizing the complex inter-variable causal relationships within multivariate time-series provides a promising avenue toward more robust and reliable multivariate time-series anomaly detection (MTSAD) but remains an underexplored area of research. This paper proposes Causality-Aware contrastive learning for RObust multivariate Time-Series (CAROTS), a novel MTSAD pipeline that incorporates the notion of causality into contrastive learning. CAROTS employs two data augmentors to obtain causality-preserving and -disturbing samples that serve as a wide range of normal variations and synthetic anomalies, respectively. With causality-preserving and -disturbing samples as positives and negatives, CAROTS performs contrastive learning to train an encoder whose latent space separates normal and abnormal samples based on causality. Moreover, CAROTS introduces a similarity-filtered one-class contrastive loss that encourages the contrastive learning process to gradually incorporate more semantically diverse samples with common causal relationships. Extensive experiments on five real-world and two synthetic datasets validate that the integration of causal relationships endows CAROTS with improved MTSAD capabilities. The code is available at https://github.com/kimanki/CAROTS.","authors":["HyunGi Kim","Jisoo Mok","Dongjun Lee","Jaihyun Lew","Sungjae Kim","Sungroh Yoon"],"url":"https://arxiv.org/abs/2506.03964"}
{"created":"2025-06-05","title":"From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding","abstract":"The pursuit of diverse, complex, and large-scale instruction data is crucial for automatically aligning large language models (LLMs). While there are methods capable of generating synthetic instructions at scale, they either suffer from limited grounding sources, leading to a narrow distribution, or rely on trivial extensions that fail to produce meaningful trajectories in terms of complexity. In contrast, instructions that benefit efficient alignment are typically crafted with cognitive insights and grounded in real-world use cases. In this paper, we synthesize such instructions using attributed grounding, which involves 1) a top-down attribution process that grounds a selective set of real instructions to situated users, and 2) a bottom-up synthesis process that leverages web documents to first generate a situation, then a meaningful instruction. This framework allows us to harvest diverse and complex instructions at scale, utilizing the vast range of web documents. Specifically, we construct a dataset of 1 million instructions, called SynthQuestions, and demonstrate that models trained on it achieve leading performance on several common benchmarks, with improvements that continually scale with more web corpora. Data, models and codes will be available at https://github.com/Ignoramus0817/SynthQuestions.","authors":["Chiwei Zhu","Benfeng Xu","Xiaorui Wang","Zhendong Mao"],"url":"https://arxiv.org/abs/2506.03968"}
{"created":"2025-06-05","title":"MS-YOLO: A Multi-Scale Model for Accurate and Efficient Blood Cell Detection","abstract":"Complete blood cell detection holds significant value in clinical diagnostics. Conventional manual microscopy methods suffer from time inefficiency and diagnostic inaccuracies. Existing automated detection approaches remain constrained by high deployment costs and suboptimal accuracy. While deep learning has introduced powerful paradigms to this field, persistent challenges in detecting overlapping cells and multi-scale objects hinder practical deployment. This study proposes the multi-scale YOLO (MS-YOLO), a blood cell detection model based on the YOLOv11 framework, incorporating three key architectural innovations to enhance detection performance. Specifically, the multi-scale dilated residual module (MS-DRM) replaces the original C3K2 modules to improve multi-scale discriminability; the dynamic cross-path feature enhancement module (DCFEM) enables the fusion of hierarchical features from the backbone with aggregated features from the neck to enhance feature representations; and the light adaptive-weight downsampling module (LADS) improves feature downsampling through adaptive spatial weighting while reducing computational complexity. Experimental results on the CBC benchmark demonstrate that MS-YOLO achieves precise detection of overlapping cells and multi-scale objects, particularly small targets such as platelets, achieving an mAP@50 of 97.4% that outperforms existing models. Further validation on the supplementary WBCDD dataset confirms its robust generalization capability. Additionally, with a lightweight architecture and real-time inference efficiency, MS-YOLO meets clinical deployment requirements, providing reliable technical support for standardized blood pathology assessment.","authors":["Guohua Wu","Shengqi Chen","Pengchao Deng","Wenting Yu"],"url":"https://arxiv.org/abs/2506.03972"}
{"created":"2025-06-05","title":"Large Deviations for Sequential Tests of Statistical Sequence Matching","abstract":"We revisit the problem of statistical sequence matching initiated by Unnikrishnan (TIT 2015) and derive theoretical performance guarantees for sequential tests that have bounded expected stopping times. Specifically, in this problem, one is given two databases of sequences and the task is to identify all matched pairs of sequences. In each database, each sequence is generated i.i.d. from a distinct distribution and a pair of sequences is said matched if they are generated from the same distribution. The generating distribution of each sequence is \\emph{unknown}. We first consider the case where the number of matches is known and derive the exact exponential decay rate of the mismatch (error) probability, a.k.a. the mismatch exponent, under each hypothesis for optimal sequential tests. Our results reveal the benefit of sequentiality by showing that optimal sequential tests have larger mismatch exponent than fixed-length tests by Zhou \\emph{et al.} (TIT 2024). Subsequently, we generalize our achievability result to the case of unknown number of matches. In this case, two additional error probabilities arise: false alarm and false reject probabilities. We propose a corresponding sequential test, show that the test has bounded expected stopping time under certain conditions, and characterize the tradeoff among the exponential decay rates of three error probabilities. Furthermore, we reveal the benefit of sequentiality over the two-step fixed-length test by Zhou \\emph{et al.} (TIT 2024) and propose an one-step fixed-length test that has no worse performance than the fixed-length test by Zhou \\emph{et al.} (TIT 2024). When specialized to the case where either database contains a single sequence, our results specialize to large deviations of sequential tests for statistical classification, the binary case of which was recently studied by Hsu, Li and Wang (ITW 2022).","authors":["Lin Zhou","Qianyun Wang","Yun Wei","Jingjing Wang"],"url":"https://arxiv.org/abs/2506.03976"}
{"created":"2025-06-05","title":"Structured Pruning for Diverse Best-of-N Reasoning Optimization","abstract":"Model pruning in transformer-based language models, traditionally viewed as a means of achieving computational savings, can enhance the model's reasoning capabilities. In this work, we uncover a surprising phenomenon: the selective pruning of certain attention heads leads to improvements in reasoning performance, particularly on challenging tasks. Motivated by this observation, we propose SPRINT, a novel contrastive learning framework that dynamically selects the optimal head and layer to prune during inference. By aligning question embeddings with head embeddings, SPRINT identifies those pruned-head configurations that result in more accurate reasoning. Extensive experiments demonstrate that our method significantly outperforms traditional best-of-$N$ and random head selection strategies on the MATH500 and GSM8K datasets.","authors":["Hieu Trung Nguyen","Bao Nguyen","Viet Anh Nguyen"],"url":"https://arxiv.org/abs/2506.03978"}
{"created":"2025-06-05","title":"Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach","abstract":"Diffusion models (DMs) have proven to be effective in modeling high-dimensional distributions, leading to their widespread adoption for representing complex priors in Bayesian inverse problems (BIPs). However, current DM-based posterior sampling methods proposed for solving common BIPs rely on heuristic approximations to the generative process. To exploit the generative capability of DMs and avoid the usage of such approximations, we propose an ensemble-based algorithm that performs posterior sampling without the use of heuristic approximations. Our algorithm is motivated by existing works that combine DM-based methods with the sequential Monte Carlo (SMC) method. By examining how the prior evolves through the diffusion process encoded by the pre-trained score function, we derive a modified partial differential equation (PDE) governing the evolution of the corresponding posterior distribution. This PDE includes a modified diffusion term and a reweighting term, which can be simulated via stochastic weighted particle methods. Theoretically, we prove that the error between the true posterior distribution can be bounded in terms of the training error of the pre-trained score function and the number of particles in the ensemble. Empirically, we validate our algorithm on several inverse problems in imaging to show that our method gives more accurate reconstructions compared to existing DM-based methods.","authors":["Haoxuan Chen","Yinuo Ren","Martin Renqiang Min","Lexing Ying","Zachary Izzo"],"url":"https://arxiv.org/abs/2506.03979"}
{"created":"2025-06-05","title":"Voice Activity Projection Model with Multimodal Encoders","abstract":"Turn-taking management is crucial for any social interaction. Still, it is challenging to model human-machine interaction due to the complexity of the social context and its multimodal nature. Unlike conventional systems based on silence duration, previous existing voice activity projection (VAP) models successfully utilized a unified representation of turn-taking behaviors as prediction targets, which improved turn-taking prediction performance. Recently, a multimodal VAP model outperformed the previous state-of-the-art model by a significant margin. In this paper, we propose a multimodal model enhanced with pre-trained audio and face encoders to improve performance by capturing subtle expressions. Our model performed competitively, and in some cases, even better than state-of-the-art models on turn-taking metrics. All the source codes and pretrained models are available at https://github.com/sagatake/VAPwithAudioFaceEncoders.","authors":["Takeshi Saga","Catherine Pelachaud"],"url":"https://arxiv.org/abs/2506.03980"}
{"created":"2025-06-05","title":"A Bi-Level Optimization Method for Redundant Dual-Arm Minimum Time Problems","abstract":"In this work, we present a method for minimizing the time required for a redundant dual-arm robot to follow a desired relative Cartesian path at constant path speed by optimizing its joint trajectories, subject to position, velocity, and acceleration limits. The problem is reformulated as a bi-level optimization whose lower level is a convex, closed-form subproblem that maximizes path speed for a fixed trajectory, while the upper level updates the trajectory using a single-chain kinematic formulation and the subgradient of the lower-level value. Numerical results demonstrate the effectiveness of the proposed approach.","authors":["Jonathan Fried","Santiago Paternain"],"url":"https://arxiv.org/abs/2506.03982"}
{"created":"2025-06-05","title":"Around the World in 24 Hours: Probing LLM Knowledge of Time and Place","abstract":"Reasoning over time and space is essential for understanding our world. However, the abilities of language models in this area are largely unexplored as previous work has tested their abilities for logical reasoning in terms of time and space in isolation or only in simple or artificial environments. In this paper, we present the first evaluation of the ability of language models to jointly reason over time and space. To enable our analysis, we create GeoTemp, a dataset of 320k prompts covering 289 cities in 217 countries and 37 time zones. Using GeoTemp, we evaluate eight open chat models of three different model families for different combinations of temporal and geographic knowledge. We find that most models perform well on reasoning tasks involving only temporal knowledge and that overall performance improves with scale. However, performance remains constrained in tasks that require connecting temporal and geographical information. We do not find clear correlations of performance with specific geographic regions. Instead, we find a significant performance increase for location names with low model perplexity, suggesting their repeated occurrence during model training. We further demonstrate that their performance is heavily influenced by prompt formulation - a direct injection of geographical knowledge leads to performance gains, whereas, surprisingly, techniques like chain-of-thought prompting decrease performance on simpler tasks.","authors":["Carolin Holtermann","Paul R\\\"ottger","Anne Lauscher"],"url":"https://arxiv.org/abs/2506.03984"}
{"created":"2025-06-05","title":"RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors","abstract":"AI-generated images have reached a quality level at which humans are incapable of reliably distinguishing them from real images. To counteract the inherent risk of fraud and disinformation, the detection of AI-generated images is a pressing challenge and an active research topic. While many of the presented methods claim to achieve high detection accuracy, they are usually evaluated under idealized conditions. In particular, the adversarial robustness is often neglected, potentially due to a lack of awareness or the substantial effort required to conduct a comprehensive robustness analysis. In this work, we tackle this problem by providing a simpler means to assess the robustness of AI-generated image detectors. We present RAID (Robust evaluation of AI-generated image Detectors), a dataset of 72k diverse and highly transferable adversarial examples. The dataset is created by running attacks against an ensemble of seven state-of-the-art detectors and images generated by four different text-to-image models. Extensive experiments show that our methodology generates adversarial images that transfer with a high success rate to unseen detectors, which can be used to quickly provide an approximate yet still reliable estimate of a detector's adversarial robustnessOur findings indicate that current state-of-the-art AI-generated image detectors can be easily deceived by adversarial examples, highlighting the critical need for the development of more robust methods. We release our dataset at https://huggingface.co/datasets/aimagelab/RAID and evaluation code at https://github.com/pralab/RAID.","authors":["Hicham Eddoubi","Jonas Ricker","Federico Cocchi","Lorenzo Baraldi","Angelo Sotgiu","Maura Pintor","Marcella Cornia","Lorenzo Baraldi","Asja Fischer","Rita Cucchiara","Battista Biggio"],"url":"https://arxiv.org/abs/2506.03988"}
{"created":"2025-06-05","title":"Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models","abstract":"With the rise of long-context language models (LMs) capable of processing tens of thousands of tokens in a single pass, do multi-stage retrieval-augmented generation (RAG) pipelines still offer measurable benefits over simpler, single-stage approaches? To assess this question, we conduct a controlled evaluation for QA tasks under systematically scaled token budgets, comparing two recent multi-stage pipelines, ReadAgent and RAPTOR, against three baselines, including DOS RAG (Document's Original Structure RAG), a simple retrieve-then-read method that preserves original passage order. Despite its straightforward design, DOS RAG consistently matches or outperforms more intricate methods on multiple long-context QA benchmarks. We recommend establishing DOS RAG as a simple yet strong baseline for future RAG evaluations, pairing it with emerging embedding and language models to assess trade-offs between complexity and effectiveness as model capabilities evolve.","authors":["Alex Laitenberger","Christopher D. Manning","Nelson F. Liu"],"url":"https://arxiv.org/abs/2506.03989"}
{"created":"2025-06-05","title":"DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding","abstract":"Typical video modeling methods, such as LLava, represent videos as sequences of visual tokens, which are then processed by the LLM backbone for effective video understanding. However, this approach leads to a massive number of visual tokens, especially for long videos. A practical solution is to first extract relevant visual information from the large visual context before feeding it into the LLM backbone, thereby reducing computational overhead. In this work, we introduce DynTok, a novel \\textbf{Dyn}amic video \\textbf{Tok}en compression strategy. DynTok adaptively splits visual tokens into groups and merges them within each group, achieving high compression in regions with low information density while preserving essential content. Our method reduces the number of tokens to 44.4% of the original size while maintaining comparable performance. It further benefits from increasing the number of video frames and achieves 65.3% on Video-MME and 72.5% on MLVU. By applying this simple yet effective compression method, we expose the redundancy in video token representations and offer insights for designing more efficient video modeling techniques.","authors":["Hongzhi Zhang","Jingyuan Zhang","Xingguang Ji","Qi Wang","Fuzheng Zhang"],"url":"https://arxiv.org/abs/2506.03990"}
{"created":"2025-06-05","title":"Words of Warmth: Trust and Sociability Norms for over 26k English Words","abstract":"Social psychologists have shown that Warmth (W) and Competence (C) are the primary dimensions along which we assess other people and groups. These dimensions impact various aspects of our lives from social competence and emotion regulation to success in the work place and how we view the world. More recent work has started to explore how these dimensions develop, why they have developed, and what they constitute. Of particular note, is the finding that warmth has two distinct components: Trust (T) and Sociability (S). In this work, we introduce Words of Warmth, the first large-scale repository of manually derived word--warmth (as well as word--trust and word--sociability) associations for over 26k English words. We show that the associations are highly reliable. We use the lexicons to study the rate at which children acquire WCTS words with age. Finally, we show that the lexicon enables a wide variety of bias and stereotype research through case studies on various target entities. Words of Warmth is freely available at: http://saifmohammad.com/warmth.html","authors":["Saif M. Mohammad"],"url":"https://arxiv.org/abs/2506.03993"}
{"created":"2025-06-05","title":"Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era","abstract":"Human learning and conceptual representation is grounded in sensorimotor experience, in contrast to state-of-the-art foundation models. In this paper, we investigate how well such large-scale models, trained on vast quantities of data, represent the semantic feature norms of concrete object concepts, e.g. a ROSE is red, smells sweet, and is a flower. More specifically, we use probing tasks to test which properties of objects these models are aware of. We evaluate image encoders trained on image data alone, as well as multimodally-trained image encoders and language-only models, on predicting an extended denser version of the classic McRae norms and the newer Binder dataset of attribute ratings. We find that multimodal image encoders slightly outperform language-only approaches, and that image-only encoders perform comparably to the language models, even on non-visual attributes that are classified as \"encyclopedic\" or \"function\". These results offer new insights into what can be learned from pure unimodal learning, and the complementarity of the modalities.","authors":["Dan Oneata","Desmond Elliott","Stella Frank"],"url":"https://arxiv.org/abs/2506.03994"}
{"created":"2025-06-05","title":"Optimal Spiking Brain Compression: Improving One-Shot Post-Training Pruning and Quantization for Spiking Neural Networks","abstract":"Spiking Neural Networks (SNNs) have emerged as a new generation of energy-efficient neural networks suitable for implementation on neuromorphic hardware. As neuromorphic hardware has limited memory and computing resources, weight pruning and quantization have recently been explored to improve SNNs' efficiency. State-of-the-art SNN pruning/quantization methods employ multiple compression and training iterations, increasing the cost for pre-trained or very large SNNs. In this paper, we propose a new one-shot post-training pruning/quantization framework, Optimal Spiking Brain Compression (OSBC), that adapts the Optimal Brain Compression (OBC) method of [Frantar, Singh, and Alistarh, 2023] for SNNs. Rather than minimizing the loss on neuron input current as OBC does, OSBC achieves more efficient and accurate SNN compression in one pass by minimizing the loss on spiking neuron membrane potential with a small sample dataset. Our experiments on neuromorphic datasets (N-MNIST, CIFAR10-DVS, DVS128-Gesture) demonstrate that OSBC can achieve 97% sparsity through pruning with 1.41%, 10.20%, and 1.74% accuracy loss, or 4-bit symmetric quantization with 0.17%, 1.54%, and 7.71% accuracy loss, respectively. Code will be available on GitHub.","authors":["Lianfeng Shi","Ao Li","Benjamin Ward-Cherrier"],"url":"https://arxiv.org/abs/2506.03996"}
{"created":"2025-06-05","title":"A framework for Conditional Reasoning in Answer Set Programming","abstract":"In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics (and on the KLM preferential semantics, as a special case) to provide an interpretation of conditionals.","authors":["Mario Alviano","Laura Giordano","Daniele Theseider Dupr\\'e"],"url":"https://arxiv.org/abs/2506.03997"}
{"created":"2025-06-05","title":"CARL: Causality-guided Architecture Representation Learning for an Interpretable Performance Predictor","abstract":"Performance predictors have emerged as a promising method to accelerate the evaluation stage of neural architecture search (NAS). These predictors estimate the performance of unseen architectures by learning from the correlation between a small set of trained architectures and their performance. However, most existing predictors ignore the inherent distribution shift between limited training samples and diverse test samples. Hence, they tend to learn spurious correlations as shortcuts to predictions, leading to poor generalization. To address this, we propose a Causality-guided Architecture Representation Learning (CARL) method aiming to separate critical (causal) and redundant (non-causal) features of architectures for generalizable architecture performance prediction. Specifically, we employ a substructure extractor to split the input architecture into critical and redundant substructures in the latent space. Then, we generate multiple interventional samples by pairing critical representations with diverse redundant representations to prioritize critical features. Extensive experiments on five NAS search spaces demonstrate the state-of-the-art accuracy and superior interpretability of CARL. For instance, CARL achieves 97.67% top-1 accuracy on CIFAR-10 using DARTS.","authors":["Han Ji","Yuqi Feng","Jiahao Fan","Yanan Sun"],"url":"https://arxiv.org/abs/2506.04001"}
{"created":"2025-06-05","title":"Vocabulary-free few-shot learning for Vision-Language Models","abstract":"Recent advances in few-shot adaptation for Vision-Language Models (VLMs) have greatly expanded their ability to generalize across tasks using only a few labeled examples. However, existing approaches primarily build upon the strong zero-shot priors of these models by leveraging carefully designed, task-specific prompts. This dependence on predefined class names can restrict their applicability, especially in scenarios where exact class names are unavailable or difficult to specify. To address this limitation, we introduce vocabulary-free few-shot learning for VLMs, a setting where target class instances - that is, images - are available but their corresponding names are not. We propose Similarity Mapping (SiM), a simple yet effective baseline that classifies target instances solely based on similarity scores with a set of generic prompts (textual or visual), eliminating the need for carefully handcrafted prompts. Although conceptually straightforward, SiM demonstrates strong performance, operates with high computational efficiency (learning the mapping typically takes less than one second), and provides interpretability by linking target classes to generic prompts. We believe that our approach could serve as an important baseline for future research in vocabulary-free few-shot learning. Code is available at https://github.com/MaxZanella/vocabulary-free-FSL.","authors":["Maxime Zanella","Cl\\'ement Fuchs","Ismail Ben Ayed","Christophe De Vleeschouwer"],"url":"https://arxiv.org/abs/2506.04005"}
{"created":"2025-06-05","title":"TransClean: Finding False Positives in Multi-Source Entity Matching under Real-World Conditions via Transitive Consistency","abstract":"We present TransClean, a method for detecting false positive predictions of entity matching algorithms under real-world conditions characterized by large-scale, noisy, and unlabeled multi-source datasets that undergo distributional shifts. TransClean is explicitly designed to operate with multiple data sources in an efficient, robust and fast manner while accounting for edge cases and requiring limited manual labeling. TransClean leverages the Transitive Consistency of a matching, a measure of the consistency of a pairwise matching model f_theta on the matching it produces G_f_theta, based both on its predictions on directly evaluated record pairs and its predictions on implied record pairs. TransClean iteratively modifies a matching through gradually removing false positive matches while removing as few true positive matches as possible. In each of these steps, the estimation of the Transitive Consistency is exclusively done through model evaluations and produces quantities that can be used as proxies of the amounts of true and false positives in the matching while not requiring any manual labeling, producing an estimate of the quality of the matching and indicating which record groups are likely to contain false positives. In our experiments, we compare combining TransClean with a naively trained pairwise matching model (DistilBERT) and with a state-of-the-art end-to-end matching method (CLER) and illustrate the flexibility of TransClean in being able to detect most of the false positives of either setup across a variety of datasets. Our experiments show that TransClean induces an average +24.42 F1 score improvement for entity matching in a multi-source setting when compared to traditional pair-wise matching algorithms.","authors":["Fernando de Meer Pardo","Branka Hadji Misheva","Martin Braschler","Kurt Stockinger"],"url":"https://arxiv.org/abs/2506.04006"}
{"created":"2025-06-05","title":"Towards Better Disentanglement in Non-Autoregressive Zero-Shot Expressive Voice Conversion","abstract":"Expressive voice conversion aims to transfer both speaker identity and expressive attributes from a target speech to a given source speech. In this work, we improve over a self-supervised, non-autoregressive framework with a conditional variational autoencoder, focusing on reducing source timbre leakage and improving linguistic-acoustic disentanglement for better style transfer. To minimize style leakage, we use multilingual discrete speech units for content representation and reinforce embeddings with augmentation-based similarity loss and mix-style layer normalization. To enhance expressivity transfer, we incorporate local F0 information via cross-attention and extract style embeddings enriched with global pitch and energy features. Experiments show our model outperforms baselines in emotion and speaker similarity, demonstrating superior style adaptation and reduced source style leakage.","authors":["Seymanur Akti","Tuan Nam Nguyen","Alexander Waibel"],"url":"https://arxiv.org/abs/2506.04013"}
{"created":"2025-06-05","title":"GORACS: Group-level Optimal Transport-guided Coreset Selection for LLM-based Recommender Systems","abstract":"Although large language models (LLMs) have shown great potential in recommender systems, the prohibitive computational costs for fine-tuning LLMs on entire datasets hinder their successful deployment in real-world scenarios. To develop affordable and effective LLM-based recommender systems, we focus on the task of coreset selection which identifies a small subset of fine-tuning data to optimize the test loss, thereby facilitating efficient LLMs' fine-tuning. Although there exist some intuitive solutions of subset selection, including distribution-based and importance-based approaches, they often lead to suboptimal performance due to the misalignment with downstream fine-tuning objectives or weak generalization ability caused by individual-level sample selection. To overcome these challenges, we propose GORACS, which is a novel Group-level Optimal tRAnsport-guided Coreset Selection framework for LLM-based recommender systems. GORACS is designed based on two key principles for coreset selection: 1) selecting the subsets that minimize the test loss to align with fine-tuning objectives, and 2) enhancing model generalization through group-level data selection. Corresponding to these two principles, GORACS has two key components: 1) a Proxy Optimization Objective (POO) leveraging optimal transport and gradient information to bound the intractable test loss, thus reducing computational costs by avoiding repeated LLM retraining, and 2) a two-stage Initialization-Then-Refinement Algorithm (ITRA) for efficient group-level selection. Our extensive experiments across diverse recommendation datasets and tasks validate that GORACS significantly reduces fine-tuning costs of LLMs while achieving superior performance over the state-of-the-art baselines and full data training. The source code of GORACS are available at https://github.com/Mithas-114/GORACS.","authors":["Tiehua Mei","Hengrui Chen","Peng Yu","Jiaqing Liang","Deqing Yang"],"url":"https://arxiv.org/abs/2506.04015"}
{"created":"2025-06-05","title":"AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents","abstract":"As Large Language Model (LLM) agents become more widespread, associated misalignment risks increase. Prior work has examined agents' ability to enact misaligned behaviour (misalignment capability) and their compliance with harmful instructions (misuse propensity). However, the likelihood of agents attempting misaligned behaviours in real-world settings (misalignment propensity) remains poorly understood. We introduce a misalignment propensity benchmark, AgentMisalignment, consisting of a suite of realistic scenarios in which LLM agents have the opportunity to display misaligned behaviour. We organise our evaluations into subcategories of misaligned behaviours, including goal-guarding, resisting shutdown, sandbagging, and power-seeking. We report the performance of frontier models on our benchmark, observing higher misalignment on average when evaluating more capable models. Finally, we systematically vary agent personalities through different system prompts. We find that persona characteristics can dramatically and unpredictably influence misalignment tendencies -- occasionally far more than the choice of model itself -- highlighting the importance of careful system prompt engineering for deployed AI agents. Our work highlights the failure of current alignment methods to generalise to LLM agents, and underscores the need for further propensity evaluations as autonomous systems become more prevalent.","authors":["Akshat Naik","Patrick Quinn","Guillermo Bosch","Emma Goun\\'e","Francisco Javier Campos Zabala","Jason Ross Brown","Edward James Young"],"url":"https://arxiv.org/abs/2506.04018"}
{"created":"2025-06-05","title":"CETBench: A Novel Dataset constructed via Transformations over Programs for Benchmarking LLMs for Code-Equivalence Checking","abstract":"LLMs have been extensively used for the task of automated code generation. In this work, we examine the applicability of LLMs for the related but relatively unexplored task of code-equivalence checking, i.e., given two programs, whether they are functionally equivalent or not. This is an important problem since benchmarking code equivalence can play a critical role in evaluating LLM capabilities for tasks such as code re-writing and code translation. Towards this end, we present CETBench - Code Equivalence with Transformations Benchmark, constructed via a repository of programs, where two programs in the repository may be solving the same or different tasks. Each instance in our dataset is obtained by taking a pair of programs in the repository and applying a random series of pre-defined code transformations, resulting in (non-)equivalent pairs. Our analysis on this dataset reveals a surprising finding that very simple code transformations in the underlying pair of programs can result in a significant drop in performance of SOTA LLMs for the task of code-equivalence checking. To remedy this, we present a simple fine-tuning-based approach to boost LLM performance on the transformed pairs of programs. Our approach for dataset generation is generic, and can be used with repositories with varying program difficulty levels and allows for applying varying numbers as well as kinds of transformations. In our experiments, we perform ablations over the difficulty level of original programs, as well as the kind of transformations used in generating pairs for equivalence checking. Our analysis presents deep insights into the working of LLMs for the task of code-equivalence, and points to the fact that they may still be far from what could be termed as a semantic understanding of the underlying code.","authors":["Neeva Oza","Ishaan Govil","Parul Gupta","Dinesh Khandelwal","Dinesh Garg","Parag Singla"],"url":"https://arxiv.org/abs/2506.04019"}
{"created":"2025-06-05","title":"QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering","abstract":"Review-based Product Question Answering (PQA) allows e-commerce platforms to automatically address customer queries by leveraging insights from user reviews. However, existing PQA systems generate answers with only a single perspective, failing to capture the diversity of customer opinions. In this paper we introduce a novel task Quantitative Query-Focused Summarization (QQSUM), which aims to summarize diverse customer opinions into representative Key Points (KPs) and quantify their prevalence to effectively answer user queries. While Retrieval-Augmented Generation (RAG) shows promise for PQA, its generated answers still fall short of capturing the full diversity of viewpoints. To tackle this challenge, our model QQSUM-RAG, which extends RAG, employs few-shot learning to jointly train a KP-oriented retriever and a KP summary generator, enabling KP-based summaries that capture diverse and representative opinions. Experimental results demonstrate that QQSUM-RAG achieves superior performance compared to state-of-the-art RAG baselines in both textual quality and quantification accuracy of opinions. Our source code is available at: https://github.com/antangrocket1312/QQSUMM","authors":["An Quang Tang","Xiuzhen Zhang","Minh Ngoc Dinh","Zhuang Li"],"url":"https://arxiv.org/abs/2506.04020"}
{"created":"2025-06-05","title":"Interpretability by Design for Efficient Multi-Objective Reinforcement Learning","abstract":"Multi-objective reinforcement learning (MORL) aims at optimising several, often conflicting goals in order to improve flexibility and reliability of RL in practical tasks. This can be achieved by finding diverse policies that are optimal for some objective preferences and non-dominated by optimal policies for other preferences so that they form a Pareto front in the multi-objective performance space. The relation between the multi-objective performance space and the parameter space that represents the policies is generally non-unique. Using a training scheme that is based on a locally linear map between the parameter space and the performance space, we show that an approximate Pareto front can provide an interpretation of the current parameter vectors in terms of the objectives which enables an effective search within contiguous solution domains. Experiments are conducted with and without retraining across different domains, and the comparison with previous methods demonstrates the efficiency of our approach.","authors":["Qiyue Xia","J. Michael Herrmann"],"url":"https://arxiv.org/abs/2506.04022"}
{"created":"2025-06-05","title":"On the Usage of Gaussian Process for Efficient Data Valuation","abstract":"In machine learning, knowing the impact of a given datum on model training is a fundamental task referred to as Data Valuation. Building on previous works from the literature, we have designed a novel canonical decomposition allowing practitioners to analyze any data valuation method as the combination of two parts: a utility function that captures characteristics from a given model and an aggregation procedure that merges such information. We also propose to use Gaussian Processes as a means to easily access the utility function on ``sub-models'', which are models trained on a subset of the training set. The strength of our approach stems from both its theoretical grounding in Bayesian theory, and its practical reach, by enabling fast estimation of valuations thanks to efficient update formulae.","authors":["Cl\\'ement B\\'enesse","Patrick Mesana","Ath\\'ena\\\"is Gautier","S\\'ebastien Gambs"],"url":"https://arxiv.org/abs/2506.04026"}
{"created":"2025-06-05","title":"On the robustness of Dirichlet-Neumann coupling schemes for fluid-structure-interaction problems with nearly-closed fluid domains","abstract":"Partitioned methods for fluid-structure interaction (FSI) involve solving the structural and flow problems sequentially. These methods allow for separate settings for the fluid and solid subsystems and thus modularity, enabling reuse of advanced commercial and open-source software. Most partitioned FSI schemes apply a Dirichlet-Neumann (DN) split of the interface conditions. The DN scheme is adequate in a wide range of applications, but it is sensitive to the added-mass effect, and it is susceptible to the incompressibility dilemma, i.e. it completely fails for FSI problems with an incompressible fluid furnished with Dirichlet boundary conditions on the part of its boundary complementary to the interface. In this paper, we show that if the fluid is incompressible and the fluid domain is nearly-closed, i.e. it carries Dirichlet conditions except for a permeable part of the boundary carrying a Robin condition, then the DN partitioned approach is sensitive to the flow resistance at the permeable part, and convergence of the partitioned approach deteriorates as the flow resistance increases. The DN scheme then becomes unstable in the limit as the flow resistance passes to infinity. Based on a simple model problem, we show that in the nearly-closed case, the convergence rate of the DN partitioned method depends on a so-called added-damping effect. The analysis gives insights that can aid to improve robustness and efficiency of partitioned method for FSI problems with contact, e.g. valve applications. In addition, the results elucidate the incompressibility dilemma as a limit of the added-damping effect passing to infinity, and the corresponding challenges related to FSI problems with nearly closed fluid-domain configurations. Via numerical experiments, we consider the generalization of the results of the simple model problem to more complex nearly-closed FSI problems.","authors":["A. Aissa-Berraies","Ferdinando A. Auricchio","Gertjan van Zwieten","E. Harald van Brummelen"],"url":"https://arxiv.org/abs/2506.04027"}
{"created":"2025-06-05","title":"An Improved Finite Element Modeling Method for Triply Periodic Minimal Surface Structures Based on Element Size and Minimum Jacobian","abstract":"Triply periodic minimal surface (TPMS) structures, a type of lattice structure, have garnered significant attention due to their lightweight nature, controllability, and excellent mechanical properties. Voxel-based modeling is a widely used method for investigating the mechanical behavior of such lattice structures through finite element simulations. This study proposes a two-parameter voxel method that incorporates joint control of element size and minimum Jacobian (MJ). Numerical results indicate that the simulation outcomes tend to stabilize when the MJ reaches 0.3. The grid convergence index (GCI), based on Richardson extrapolation, is introduced to systematically assess the numerical convergence behavior of both voxel models and the proposed two-parameter voxel models. This provides a systematic and objective framework for evaluating discretization errors and mesh convergence in TPMS modeling. Compared with traditional voxel method, the proposed method exhibits superior mesh convergence, solution accuracy, and computational efficiency. Furthermore, the two-parameter voxel method also shows excellent applicability in the analysis of graded TPMS structures, exhibiting even better convergence behavior than in uniform structures.","authors":["Siqi Wang","Chuangyu Jiang","Xiaodong Zhang","Yilong Zhang","Baoqiang Zhang","Huageng Luo"],"url":"https://arxiv.org/abs/2506.04028"}
{"created":"2025-06-05","title":"AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data","abstract":"Background: We present a Patient Simulator that leverages real world patient encounters which cover a broad range of conditions and symptoms to provide synthetic test subjects for development and testing of healthcare agentic models. The simulator provides a realistic approach to patient presentation and multi-turn conversation with a symptom-checking agent. Objectives: (1) To construct and instantiate a Patient Simulator to train and test an AI health agent, based on patient vignettes derived from real EHR data. (2) To test the validity and alignment of the simulated encounters provided by the Patient Simulator to expert human clinical providers. (3) To illustrate the evaluation framework of such an LLM system on the generated realistic, data-driven simulations -- yielding a preliminary assessment of our proposed system. Methods: We first constructed realistic clinical scenarios by deriving patient vignettes from real-world EHR encounters. These vignettes cover a variety of presenting symptoms and underlying conditions. We then evaluate the performance of the Patient Simulator as a simulacrum of a real patient encounter across over 500 different patient vignettes. We leveraged a separate AI agent to provide multi-turn questions to obtain a history of present illness. The resulting multiturn conversations were evaluated by two expert clinicians. Results: Clinicians scored the Patient Simulator as consistent with the patient vignettes in those same 97.7% of cases. The extracted case summary based on the conversation history was 99% relevant. Conclusions: We developed a methodology to incorporate vignettes derived from real healthcare patient data to build a simulation of patient responses to symptom checking agents. The performance and alignment of this Patient Simulator could be used to train and test a multi-turn conversational AI agent at scale.","authors":["Sina Rashidian","Nan Li","Jonathan Amar","Jong Ha Lee","Sam Pugh","Eric Yang","Geoff Masterson","Myoung Cha","Yugang Jia","Akhil Vaid"],"url":"https://arxiv.org/abs/2506.04032"}
{"created":"2025-06-05","title":"Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning","abstract":"Object referring aims to detect all objects in an image that match a given natural language description. We argue that a robust object referring model should be grounded, meaning its predictions should be both explainable and faithful to the visual content. Specifically, it should satisfy two key properties: 1) Verifiable, by producing interpretable reasoning that justifies its predictions and clearly links them to visual evidence; and 2) Trustworthy, by learning to abstain when no object in the image satisfies the given expression. However, most methods treat referring as a direct bounding box prediction task, offering limited interpretability and struggling to reject expressions with no matching object. In this work, we propose Rex-Thinker, a model that formulates object referring as an explicit CoT reasoning task. Given a referring expression, we first identify all candidate object instances corresponding to the referred object category. Rex-Thinker then performs step-by-step reasoning over each candidate to assess whether it matches the given expression, before making a final prediction. To support this paradigm, we construct a large-scale CoT-style referring dataset named HumanRef-CoT by prompting GPT-4o on the HumanRef dataset. Each reasoning trace follows a structured planning, action, and summarization format, enabling the model to learn decomposed, interpretable reasoning over object candidates. We then train Rex-Thinker in two stages: a cold-start supervised fine-tuning phase to teach the model how to perform structured reasoning, followed by GRPO-based RL learning to improve accuracy and generalization. Experiments show that our approach outperforms standard baselines in both precision and interpretability on in-domain evaluation, while also demonstrating improved ability to reject hallucinated outputs and strong generalization in out-of-domain settings.","authors":["Qing Jiang","Xingyu Chen","Zhaoyang Zeng","Junzhi Yu","Lei Zhang"],"url":"https://arxiv.org/abs/2506.04034"}
{"created":"2025-06-05","title":"Privacy and Security Threat for OpenAI GPTs","abstract":"Large language models (LLMs) demonstrate powerful information handling capabilities and are widely integrated into chatbot applications. OpenAI provides a platform for developers to construct custom GPTs, extending ChatGPT's functions and integrating external services. Since its release in November 2023, over 3 million custom GPTs have been created. However, such a vast ecosystem also conceals security and privacy threats. For developers, instruction leaking attacks threaten the intellectual property of instructions in custom GPTs through carefully crafted adversarial prompts. For users, unwanted data access behavior by custom GPTs or integrated third-party services raises significant privacy concerns. To systematically evaluate the scope of threats in real-world LLM applications, we develop three phases instruction leaking attacks target GPTs with different defense level. Our widespread experiments on 10,000 real-world custom GPTs reveal that over 98.8% of GPTs are vulnerable to instruction leaking attacks via one or more adversarial prompts, and half of the remaining GPTs can also be attacked through multiround conversations. We also developed a framework to assess the effectiveness of defensive strategies and identify unwanted behaviors in custom GPTs. Our findings show that 77.5% of custom GPTs with defense strategies are vulnerable to basic instruction leaking attacks. Additionally, we reveal that 738 custom GPTs collect user conversational information, and identified 8 GPTs exhibiting data access behaviors that are unnecessary for their intended functionalities. Our findings raise awareness among GPT developers about the importance of integrating specific defensive strategies in their instructions and highlight users' concerns about data privacy when using LLM-based applications.","authors":["Wei Wenying","Zhao Kaifa","Xue Lei","Fan Ming"],"url":"https://arxiv.org/abs/2506.04036"}
{"created":"2025-06-05","title":"The mutual exclusivity bias of bilingual visually grounded speech models","abstract":"Mutual exclusivity (ME) is a strategy where a novel word is associated with a novel object rather than a familiar one, facilitating language learning in children. Recent work has found an ME bias in a visually grounded speech (VGS) model trained on English speech with paired images. But ME has also been studied in bilingual children, who may employ it less due to cross-lingual ambiguity. We explore this pattern computationally using bilingual VGS models trained on combinations of English, French, and Dutch. We find that bilingual models generally exhibit a weaker ME bias than monolingual models, though exceptions exist. Analyses show that the combined visual embeddings of bilingual models have a smaller variance for familiar data, partly explaining the increase in confusion between novel and familiar concepts. We also provide new insights into why the ME bias exists in VGS models in the first place. Code and data: https://github.com/danoneata/me-vgs","authors":["Dan Oneata","Leanne Nortje","Yevgen Matusevych","Herman Kamper"],"url":"https://arxiv.org/abs/2506.04037"}
{"created":"2025-06-05","title":"Generating Automotive Code: Large Language Models for Software Development and Verification in Safety-Critical Systems","abstract":"Developing safety-critical automotive software presents significant challenges due to increasing system complexity and strict regulatory demands. This paper proposes a novel framework integrating Generative Artificial Intelligence (GenAI) into the Software Development Lifecycle (SDLC). The framework uses Large Language Models (LLMs) to automate code generation in languages such as C++, incorporating safety-focused practices such as static verification, test-driven development and iterative refinement. A feedback-driven pipeline ensures the integration of test, simulation and verification for compliance with safety standards. The framework is validated through the development of an Adaptive Cruise Control (ACC) system. Comparative benchmarking of LLMs ensures optimal model selection for accuracy and reliability. Results demonstrate that the framework enables automatic code generation while ensuring compliance with safety-critical requirements, systematically integrating GenAI into automotive software engineering. This work advances the use of AI in safety-critical domains, bridging the gap between state-of-the-art generative models and real-world safety requirements.","authors":["Sven Kirchner","Alois C. Knoll"],"url":"https://arxiv.org/abs/2506.04038"}
{"created":"2025-06-05","title":"Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization","abstract":"Large Visual Language Models (LVLMs) have demonstrated impressive capabilities across multiple tasks. However, their trustworthiness is often challenged by hallucinations, which can be attributed to the modality misalignment and the inherent hallucinations of their underlying Large Language Models (LLMs) backbone. Existing preference alignment methods focus on aligning model responses with human preferences while neglecting image-text modality alignment, resulting in over-reliance on LLMs and hallucinations. In this paper, we propose Entity-centric Multimodal Preference Optimization (EMPO), which achieves enhanced modality alignment than existing human preference alignment methods. Besides, to overcome the scarcity of high-quality multimodal preference data, we utilize open-source instruction datasets to automatically construct high-quality preference data across three aspects: image, instruction, and response. Experiments on two human preference datasets and five multimodal hallucination benchmarks demonstrate the effectiveness of EMPO, e.g., reducing hallucination rates by 85.9% on Object-HalBench and 49.8% on MM-HalBench.","authors":["Jiulong Wu","Zhengliang Shi","Shuaiqiang Wang","Jizhou Huang","Dawei Yin","Lingyong Yan","Min Cao","Min Zhang"],"url":"https://arxiv.org/abs/2506.04039"}
{"created":"2025-06-05","title":"Autonomous Vehicle Lateral Control Using Deep Reinforcement Learning with MPC-PID Demonstration","abstract":"The controller is one of the most important modules in the autonomous driving pipeline, ensuring the vehicle reaches its desired position. In this work, a reinforcement learning based lateral control approach, despite the imperfections in the vehicle models due to measurement errors and simplifications, is presented. Our approach ensures comfortable, efficient, and robust control performance considering the interface between controlling and other modules. The controller consists of the conventional Model Predictive Control (MPC)-PID part as the basis and the demonstrator, and the Deep Reinforcement Learning (DRL) part which leverages the online information from the MPC-PID part. The controller's performance is evaluated in CARLA using the ground truth of the waypoints as inputs. Experimental results demonstrate the effectiveness of the controller when vehicle information is incomplete, and the training of DRL can be stabilized with the demonstration part. These findings highlight the potential to reduce development and integration efforts for autonomous driving pipelines in the future.","authors":["Chengdong Wu","Sven Kirchner","Nils Purschke","Alois C. Knoll"],"url":"https://arxiv.org/abs/2506.04040"}
{"created":"2025-06-05","title":"LexTime: A Benchmark for Temporal Ordering of Legal Events","abstract":"Temporal reasoning in legal texts is important for applications like case law analysis and compliance monitoring. However, existing datasets lack expert language evaluation, leaving a gap in understanding how LLMs manage event ordering in legal contexts. We introduce LexTime, the first dataset designed to evaluate LLMs' event ordering capabilities in legal language, consisting of 512 instances from U.S. Federal Complaints with annotated event pairs and their temporal relations. Our findings show that (1) LLMs are more accurate on legal event ordering than on narrative (up to +10.5%); (2) longer input contexts and implicit events boost accuracy, reaching 80.8% for implicit-explicit event pairs; (3) legal linguistic complexities and nested clauses remain a challenge. We investigate how context length, explicit vs implicit event pairs, and legal language features affect model performance, demonstrating the need for specific modeling strategies to enhance temporal event reasoning.","authors":["Claire Barale","Leslie Barrett","Vikram Sunil Bajaj","Michael Rovatsos"],"url":"https://arxiv.org/abs/2506.04041"}
{"created":"2025-06-05","title":"Unveiling and Eliminating the Shortcut Learning for Locate-Then-Edit Knowledge Editing via Both Subject and Relation Awareness","abstract":"Knowledge editing aims to alternate the target knowledge predicted by large language models while ensuring the least side effects on unrelated knowledge. An effective way to achieve knowledge editing is to identify pivotal parameters for predicting factual associations and modify them with an optimization process to update the predictions. However, these locate-then-edit methods are uncontrollable since they tend to modify most unrelated relations connected to the subject of target editing. We unveil that this failure of controllable editing is due to a shortcut learning issue during the optimization process. Specifically, we discover two crucial features that are the subject feature and the relation feature for models to learn during optimization, but the current optimization process tends to over-learning the subject feature while neglecting the relation feature. To eliminate this shortcut learning of the subject feature, we propose a novel two-stage optimization process that balances the learning of the subject feature and the relation feature. Experimental results demonstrate that our approach successfully prevents knowledge editing from shortcut learning and achieves the optimal overall performance, contributing to controllable knowledge editing.","authors":["Xiyu Liu","Zhengxiao Liu","Naibin Gu","Zheng Lin","Ji Xiang","Weiping Wang"],"url":"https://arxiv.org/abs/2506.04042"}
{"created":"2025-06-05","title":"Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate","abstract":"Automated counter-narratives (CN) offer a promising strategy for mitigating online hate speech, yet concerns about their affective tone, accessibility, and ethical risks remain. We propose a framework for evaluating Large Language Model (LLM)-generated CNs across four dimensions: persona framing, verbosity and readability, affective tone, and ethical robustness. Using GPT-4o-Mini, Cohere's CommandR-7B, and Meta's LLaMA 3.1-70B, we assess three prompting strategies on the MT-Conan and HatEval datasets. Our findings reveal that LLM-generated CNs are often verbose and adapted for people with college-level literacy, limiting their accessibility. While emotionally guided prompts yield more empathetic and readable responses, there remain concerns surrounding safety and effectiveness.","authors":["Mikel K. Ngueajio","Flor Miriam Plaza-del-Arco","Yi-Ling Chung","Danda B. Rawat","Amanda Cercas Curry"],"url":"https://arxiv.org/abs/2506.04043"}
{"created":"2025-06-05","title":"Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs","abstract":"This paper describes LIBU (LoRA enhanced influence-based unlearning), an algorithm to solve the task of unlearning - removing specific knowledge from a large language model without retraining from scratch and compromising its overall utility (SemEval-2025 Task 4: Unlearning sensitive content from Large Language Models). The algorithm combines classical \\textit{influence functions} to remove the influence of the data from the model and \\textit{second-order optimization} to stabilize the overall utility. Our experiments show that this lightweight approach is well applicable for unlearning LLMs in different kinds of task.","authors":["Aleksey Kudelya","Alexander Shirnin"],"url":"https://arxiv.org/abs/2506.04044"}
{"created":"2025-06-05","title":"On Support Samples of Next Word Prediction","abstract":"Language models excel in various tasks by making complex decisions, yet understanding the rationale behind these decisions remains a challenge. This paper investigates \\emph{data-centric interpretability} in language models, focusing on the next-word prediction task. Using representer theorem, we identify two types of \\emph{support samples}-those that either promote or deter specific predictions. Our findings reveal that being a support sample is an intrinsic property, predictable even before training begins. Additionally, while non-support samples are less influential in direct predictions, they play a critical role in preventing overfitting and shaping generalization and representation learning. Notably, the importance of non-support samples increases in deeper layers, suggesting their significant role in intermediate representation formation.These insights shed light on the interplay between data and model decisions, offering a new dimension to understanding language model behavior and interpretability.","authors":["Yuqian Li","Yupei Du","Yufang Liu","Feifei Feng","Mou Xiao Feng","Yuanbin Wu"],"url":"https://arxiv.org/abs/2506.04047"}
{"created":"2025-06-05","title":"EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects","abstract":"Monitoring aerial objects is crucial for security, wildlife conservation, and environmental studies. Traditional RGB-based approaches struggle with challenges such as scale variations, motion blur, and high-speed object movements, especially for small flying entities like insects and drones. In this work, we explore the potential of event-based vision for detecting and recognizing flying objects, in particular animals that may not follow short and long-term predictable patters. Event cameras offer high temporal resolution, low latency, and robustness to motion blur, making them well-suited for this task. We introduce EV-Flying, an event-based dataset of flying objects, comprising manually annotated birds, insects and drones with spatio-temporal bounding boxes and track identities. To effectively process the asynchronous event streams, we employ a point-based approach leveraging lightweight architectures inspired by PointNet. Our study investigates the classification of flying objects using point cloud-based event representations. The proposed dataset and methodology pave the way for more efficient and reliable aerial object recognition in real-world scenarios.","authors":["Gabriele Magrini","Federico Becattini","Giovanni Colombo","Pietro Pala"],"url":"https://arxiv.org/abs/2506.04048"}
{"created":"2025-06-05","title":"WANDER: An Explainable Decision-Support Framework for HPC","abstract":"High-performance computing (HPC) systems expose many interdependent configuration knobs that impact runtime, resource usage, power, and variability. Existing predictive tools model these outcomes, but do not support structured exploration, explanation, or guided reconfiguration. We present WANDER, a decision-support framework that synthesizes alternate configurations using counterfactual analysis aligned with user goals and constraints. We introduce a composite trade-off score that ranks suggestions based on prediction uncertainty, consistency between feature-target relationships using causal models, and similarity between feature distributions against historical data. To our knowledge, WANDER is the first such system to unify prediction, exploration, and explanation for HPC tuning under a common query interface. Across multiple datasets WANDER generates interpretable and trustworthy, human-readable alternatives that guide users to achieve their performance objectives.","authors":["Ankur Lahiry","Banooqa Banday","Tanzima Z. Islam"],"url":"https://arxiv.org/abs/2506.04049"}
{"created":"2025-06-05","title":"Explainability-Based Token Replacement on LLM-Generated Text","abstract":"Generative models, especially large language models (LLMs), have shown remarkable progress in producing text that appears human-like. However, they often exhibit patterns that make their output easier to detect than text written by humans. In this paper, we investigate how explainable AI (XAI) methods can be used to reduce the detectability of AI-generated text (AIGT) while also introducing a robust ensemble-based detection approach. We begin by training an ensemble classifier to distinguish AIGT from human-written text, then apply SHAP and LIME to identify tokens that most strongly influence its predictions. We propose four explainability-based token replacement strategies to modify these influential tokens. Our findings show that these token replacement approaches can significantly diminish a single classifier's ability to detect AIGT. However, our ensemble classifier maintains strong performance across multiple languages and domains, showing that a multi-model approach can mitigate the impact of token-level manipulations. These results show that XAI methods can make AIGT harder to detect by focusing on the most influential tokens. At the same time, they highlight the need for robust, ensemble-based detection strategies that can adapt to evolving approaches for hiding AIGT.","authors":["Hadi Mohammadi","Anastasia Giachanou","Daniel L. Oberski","Ayoub Bagheri"],"url":"https://arxiv.org/abs/2506.04050"}
{"created":"2025-06-05","title":"High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning","abstract":"Large Language Models (LLMs) currently respond to every prompt. However, they can produce incorrect answers when they lack knowledge or capability -- a problem known as hallucination. We instead propose post-training an LLM to generate content only when confident in its correctness and to otherwise (partially) abstain. Specifically, our method, HALT, produces capability-aligned post-training data that encodes what the model can and cannot reliably generate. We generate this data by splitting responses of the pretrained LLM into factual fragments (atomic statements or reasoning steps), and use ground truth information to identify incorrect fragments. We achieve capability-aligned finetuning responses by either removing incorrect fragments or replacing them with \"Unsure from Here\" -- according to a tunable threshold that allows practitioners to trade off response completeness and mean correctness of the response's fragments. We finetune four open-source models for biography writing, mathematics, coding, and medicine with HALT for three different trade-off thresholds. HALT effectively trades off response completeness for correctness, increasing the mean correctness of response fragments by 15% on average, while resulting in a 4% improvement in the F1 score (mean of completeness and correctness of the response) compared to the relevant baselines. By tuning HALT for highest correctness, we train a single reliable Llama3-70B model with correctness increased from 51% to 87% across all four domains while maintaining 53% of the response completeness achieved with standard finetuning.","authors":["Tim Franzmeyer","Archie Sravankumar","Lijuan Liu","Yuning Mao","Rui Hou","Sinong Wang","Jakob N. Foerster","Luke Zettlemoyer","Madian Khabsa"],"url":"https://arxiv.org/abs/2506.04051"}
{"created":"2025-06-05","title":"Curse of Slicing: Why Sliced Mutual Information is a Deceptive Measure of Statistical Dependence","abstract":"Sliced Mutual Information (SMI) is widely used as a scalable alternative to mutual information for measuring non-linear statistical dependence. Despite its advantages, such as faster convergence, robustness to high dimensionality, and nullification only under statistical independence, we demonstrate that SMI is highly susceptible to data manipulation and exhibits counterintuitive behavior. Through extensive benchmarking and theoretical analysis, we show that SMI saturates easily, fails to detect increases in statistical dependence (even under linear transformations designed to enhance the extraction of information), prioritizes redundancy over informative content, and in some cases, performs worse than simpler dependence measures like the correlation coefficient.","authors":["Alexander Semenenko","Ivan Butakov","Alexey Frolov","Ivan Oseledets"],"url":"https://arxiv.org/abs/2506.04053"}
{"created":"2025-06-05","title":"Video Deblurring with Deconvolution and Aggregation Networks","abstract":"In contrast to single-image deblurring, video deblurring has the advantage that neighbor frames can be utilized to deblur a target frame. However, existing video deblurring algorithms often fail to properly employ the neighbor frames, resulting in sub-optimal performance. In this paper, we propose a deconvolution and aggregation network (DAN) for video deblurring that utilizes the information of neighbor frames well. In DAN, both deconvolution and aggregation strategies are achieved through three sub-networks: the preprocessing network (PPN) and the alignment-based deconvolution network (ABDN) for the deconvolution scheme; the frame aggregation network (FAN) for the aggregation scheme. In the deconvolution part, blurry inputs are first preprocessed by the PPN with non-local operations. Then, the output frames from the PPN are deblurred by the ABDN based on the frame alignment. In the FAN, these deblurred frames from the deconvolution part are combined into a latent frame according to reliability maps which infer pixel-wise sharpness. The proper combination of three sub-networks can achieve favorable performance on video deblurring by using the neighbor frames suitably. In experiments, the proposed DAN was demonstrated to be superior to existing state-of-the-art methods through both quantitative and qualitative evaluations on the public datasets.","authors":["Giyong Choi","HyunWook Park"],"url":"https://arxiv.org/abs/2506.04054"}
{"created":"2025-06-05","title":"Energy-Aware Workflow Execution: An Overview of Techniques for Saving Energy and Emissions in Scientific Compute Clusters","abstract":"Scientific research in many fields routinely requires the analysis of large datasets, and scientists often employ workflow systems to leverage clusters of computers for their data analysis. However, due to their size and scale, these workflow applications can have a considerable environmental footprint in terms of compute resource use, energy consumption, and carbon emissions. Mitigating this is critical in light of climate change and the urgent need to reduce carbon emissions.","authors":["Lauritz Thamsen","Yehia Elkhatib","Paul Harvey","Syed Waqar Nabi","Jeremy Singer","Wim Vanderbauwhede"],"url":"https://arxiv.org/abs/2506.04062"}
{"created":"2025-06-05","title":"Crowd-SFT: Crowdsourcing for LLM Alignment","abstract":"Large Language Models (LLMs) increasingly rely on Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF) to align model responses with human preferences. While RLHF employs a reinforcement learning approach with a separate reward model, SFT uses human-curated datasets for supervised learning. Both approaches traditionally depend on small, vetted groups of annotators, making them costly, prone to bias, and limited in scalability. We propose an open, crowd-sourced fine-tuning framework that addresses these limitations by enabling broader feedback collection for SFT without extensive annotator training. Our framework promotes incentive fairness via a point-based reward system correlated with Shapley values and guides model convergence through iterative model updates. Our multi-model selection framework demonstrates up to a 55% reduction in target distance over single-model selection, enabling subsequent experiments that validate our point-based reward mechanism's close alignment with Shapley values (a well-established method for attributing individual contributions) thereby supporting fair and scalable participation.","authors":["Alex Sotiropoulos","Sulyab Thottungal Valapu","Linus Lei","Jared Coleman","Bhaskar Krishnamachari"],"url":"https://arxiv.org/abs/2506.04063"}
{"created":"2025-06-05","title":"Progressive Mastery: Customized Curriculum Learning with Guided Prompting for Mathematical Reasoning","abstract":"Large Language Models (LLMs) have achieved remarkable performance across various reasoning tasks, yet post-training is constrained by inefficient sample utilization and inflexible difficulty samples processing. To address these limitations, we propose Customized Curriculum Learning (CCL), a novel framework with two key innovations. First, we introduce model-adaptive difficulty definition that customizes curriculum datasets based on each model's individual capabilities rather than using predefined difficulty metrics. Second, we develop \"Guided Prompting,\" which dynamically reduces sample difficulty through strategic hints, enabling effective utilization of challenging samples that would otherwise degrade performance. Comprehensive experiments on supervised fine-tuning and reinforcement learning demonstrate that CCL significantly outperforms uniform training approaches across five mathematical reasoning benchmarks, confirming its effectiveness across both paradigms in enhancing sample utilization and model performance.","authors":["Muling Wu","Qi Qian","Wenhao Liu","Xiaohua Wang","Zisu Huang","Di Liang","LI Miao","Shihan Dou","Changze Lv","Zhenghua Wang","Zhibo Xu","Lina Chen","Tianlong Li","Xiaoqing Zheng","Xuanjing Huang"],"url":"https://arxiv.org/abs/2506.04065"}
{"created":"2025-06-05","title":"LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward","abstract":"Navigation instruction generation for visually impaired (VI) individuals (NIG-VI) is critical yet relatively underexplored. This study, hence, focuses on producing precise, in-situ, step-by-step navigation instructions that are practically usable by VI users. Concretely, we propose LaF-GRPO (LLM-as-Follower GRPO), where an LLM simulates VI user responses to generate rewards guiding the Vision-Language Model (VLM) post-training. This enhances instruction usability while reducing costly real-world data needs. To facilitate training and testing, we introduce NIG4VI, a 27k-sample open-sourced benchmark. It provides diverse navigation scenarios with accurate spatial coordinates, supporting detailed, open-ended in-situ instruction generation. Experiments on NIG4VI show the effectiveness of LaF-GRPO by quantitative metrics (e.g., Zero-(LaF-GRPO) boosts BLEU +14\\%; SFT+(LaF-GRPO) METEOR 0.542 vs. GPT-4o's 0.323) and yields more intuitive, safer instructions. Code and benchmark are available at \\href{https://github.com/YiyiyiZhao/NIG4VI}{https://github.com/YiyiyiZhao/NIG4VI}.","authors":["Yi Zhao","Siqi Wang","Jing Li"],"url":"https://arxiv.org/abs/2506.04070"}
{"created":"2025-06-05","title":"Optimal Transport-based Domain Alignment as a Preprocessing Step for Federated Learning","abstract":"Federated learning (FL) is a subfield of machine learning that avoids sharing local data with a central server, which can enhance privacy and scalability. The inability to consolidate data leads to a unique problem called dataset imbalance, where agents in a network do not have equal representation of the labels one is trying to learn to predict. In FL, fusing locally-trained models with unbalanced datasets may deteriorate the performance of global model aggregation, and reduce the quality of updated local models and the accuracy of the distributed agents' decisions. In this work, we introduce an Optimal Transport-based preprocessing algorithm that aligns the datasets by minimizing the distributional discrepancy of data along the edge devices. We accomplish this by leveraging Wasserstein barycenters when computing channel-wise averages. These barycenters are collected in a trusted central server where they collectively generate a target RGB space. By projecting our dataset towards this target space, we minimize the distributional discrepancy on a global level, which facilitates the learning process due to a minimization of variance across the samples. We demonstrate the capabilities of the proposed approach over the CIFAR-10 dataset, where we show its capability of reaching higher degrees of generalization in fewer communication rounds.","authors":["Luiz Manella Pereira","M. Hadi Amini"],"url":"https://arxiv.org/abs/2506.04071"}
{"created":"2025-06-05","title":"Controlling Difficulty of Generated Text for AI-Assisted Language Learning","abstract":"Practicing conversations with large language models (LLMs) presents a promising alternative to traditional in-person language learning. However, most LLMs generate text at a near-native level of complexity, making them ill-suited for beginner learners (CEFR: A1-A2). In this paper, we investigate whether controllable generation techniques -- specifically modular methods that do not require model fine-tuning -- can adapt LLM outputs to better support absolute beginners. We evaluate these methods through both automatic metrics and a user study with university-level learners of Japanese. Our findings show that while prompting alone fails to control output difficulty, the use of future discriminators (Yang and Klein, 2021) significantly improves output comprehensibility (from 40.4\\% to 84.3\\%). We further introduce a novel token-level evaluation metric, Token Miss Rate (TMR), that quantifies the proportion of incomprehensible tokens per utterance and correlates strongly with human judgments. To support future research in AI-assisted language learning, we release our code, models, annotation tools, and dataset.","authors":["Meiqing Jin","Liam Dugan","Chris Callison-Burch"],"url":"https://arxiv.org/abs/2506.04072"}
{"created":"2025-06-05","title":"A Statistics-Driven Differentiable Approach for Sound Texture Synthesis and Analysis","abstract":"In this work, we introduce TexStat, a novel loss function specifically designed for the analysis and synthesis of texture sounds characterized by stochastic structure and perceptual stationarity. Drawing inspiration from the statistical and perceptual framework of McDermott and Simoncelli, TexStat identifies similarities between signals belonging to the same texture category without relying on temporal structure. We also propose using TexStat as a validation metric alongside Frechet Audio Distances (FAD) to evaluate texture sound synthesis models. In addition to TexStat, we present TexEnv, an efficient, lightweight and differentiable texture sound synthesizer that generates audio by imposing amplitude envelopes on filtered noise. We further integrate these components into TexDSP, a DDSP-inspired generative model tailored for texture sounds. Through extensive experiments across various texture sound types, we demonstrate that TexStat is perceptually meaningful, time-invariant, and robust to noise, features that make it effective both as a loss function for generative tasks and as a validation metric. All tools and code are provided as open-source contributions and our PyTorch implementations are efficient, differentiable, and highly configurable, enabling its use in both generative tasks and as a perceptually grounded evaluation metric.","authors":["Esteban Guti\\'errez","Frederic Font","Xavier Serra","Lonce Wyse"],"url":"https://arxiv.org/abs/2506.04073"}
{"created":"2025-06-05","title":"Acoustically Precise Hesitation Tagging Is Essential for End-to-End Verbatim Transcription Systems","abstract":"Verbatim transcription for automatic speaking assessment demands accurate capture of disfluencies, crucial for downstream tasks like error analysis and feedback. However, many ASR systems discard or generalize hesitations, losing important acoustic details. We fine-tune Whisper models on the Speak & Improve 2025 corpus using low-rank adaptation (LoRA), without recourse to external audio training data. We compare three annotation schemes: removing hesitations (Pure), generic tags (Rich), and acoustically precise fillers inferred by Gemini 2.0 Flash from existing audio-transcript pairs (Extra). Our challenge system achieved 6.47% WER (Pure) and 5.81% WER (Extra). Post-challenge experiments reveal that fine-tuning Whisper Large V3 Turbo with the \"Extra\" scheme yielded a 5.5% WER, an 11.3% relative improvement over the \"Pure\" scheme (6.2% WER). This demonstrates that explicit, realistic filled-pause labeling significantly enhances ASR accuracy for verbatim L2 speech transcription.","authors":["Jhen-Ke Lin","Hao-Chien Lu","Chung-Chun Wang","Hong-Yun Lin","Berlin Chen"],"url":"https://arxiv.org/abs/2506.04076"}
{"created":"2025-06-05","title":"A Novel Data Augmentation Approach for Automatic Speaking Assessment on Opinion Expressions","abstract":"Automated speaking assessment (ASA) on opinion expressions is often hampered by the scarcity of labeled recordings, which restricts prompt diversity and undermines scoring reliability. To address this challenge, we propose a novel training paradigm that leverages a large language models (LLM) to generate diverse responses of a given proficiency level, converts responses into synthesized speech via speaker-aware text-to-speech synthesis, and employs a dynamic importance loss to adaptively reweight training instances based on feature distribution differences between synthesized and real speech. Subsequently, a multimodal large language model integrates aligned textual features with speech signals to predict proficiency scores directly. Experiments conducted on the LTTC dataset show that our approach outperforms methods relying on real data or conventional augmentation, effectively mitigating low-resource constraints and enabling ASA on opinion expressions with cross-modal information.","authors":["Chung-Chun Wang","Jhen-Ke Lin","Hao-Chien Lu","Hong-Yun Lin","Berlin Chen"],"url":"https://arxiv.org/abs/2506.04077"}
{"created":"2025-06-05","title":"LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation","abstract":"Evaluating large language models (LLMs) in medicine is crucial because medical applications require high accuracy with little room for error. Current medical benchmarks have three main types: medical exam-based, comprehensive medical, and specialized assessments. However, these benchmarks have limitations in question design (mostly multiple-choice), data sources (often not derived from real clinical scenarios), and evaluation methods (poor assessment of complex reasoning). To address these issues, we present LLMEval-Med, a new benchmark covering five core medical areas, including 2,996 questions created from real-world electronic health records and expert-designed clinical scenarios. We also design an automated evaluation pipeline, incorporating expert-developed checklists into our LLM-as-Judge framework. Furthermore, our methodology validates machine scoring through human-machine agreement analysis, dynamically refining checklists and prompts based on expert feedback to ensure reliability. We evaluate 13 LLMs across three categories (specialized medical models, open-source models, and closed-source models) on LLMEval-Med, providing valuable insights for the safe and effective deployment of LLMs in medical domains. The dataset is released in https://github.com/llmeval/LLMEval-Med.","authors":["Ming Zhang","Yujiong Shen","Zelin Li","Huayu Sha","Binze Hu","Yuhui Wang","Chenhao Huang","Shichun Liu","Jingqi Tong","Changhao Jiang","Mingxu Chai","Zhiheng Xi","Shihan Dou","Tao Gui","Qi Zhang","Xuanjing Huang"],"url":"https://arxiv.org/abs/2506.04078"}
{"created":"2025-06-05","title":"EuroLLM-9B: Technical Report","abstract":"This report presents EuroLLM-9B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existing open large language models. We provide a comprehensive overview of EuroLLM-9B's development, including tokenizer design, architectural specifications, data filtering, and training procedures. We describe the pre-training data collection and filtering pipeline, including the creation of EuroFilter, an AI-based multilingual filter, as well as the design of EuroBlocks-Synthetic, a novel synthetic dataset for post-training that enhances language coverage for European languages. Evaluation results demonstrate EuroLLM-9B's competitive performance on multilingual benchmarks and machine translation tasks, establishing it as the leading open European-made LLM of its size. To support open research and adoption, we release all major components of this work, including the base and instruction-tuned models, the EuroFilter classifier, and the synthetic post-training dataset.","authors":["Pedro Henrique Martins","Jo\\~ao Alves","Patrick Fernandes","Nuno M. Guerreiro","Ricardo Rei","Amin Farajian","Mateusz Klimaszewski","Duarte M. Alves","Jos\\'e Pombal","Manuel Faysse","Pierre Colombo","Fran\\c{c}ois Yvon","Barry Haddow","Jos\\'e G. C. de Souza","Alexandra Birch","Andr\\'e F. T. Martins"],"url":"https://arxiv.org/abs/2506.04079"}
{"created":"2025-06-05","title":"Some constructions of non-generalized Reed-Solomon MDS Codes","abstract":"We investigate two classes of extended codes and provide necessary and sufficient conditions for these codes to be non-GRS MDS codes. We also determine the parity check matrices for these codes. Using the connection of MDS codes with arcs in finite projective spaces, we give a new characterization of o-monomials.","authors":["Kanat Abdukhalikov","Cunsheng Ding","Gyanendra K. Verma"],"url":"https://arxiv.org/abs/2506.04080"}
{"created":"2025-06-05","title":"Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network","abstract":"No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for evaluating 3D content in real-world applications where reference models are unavailable.","authors":["Abdelouahed Laazoufi","Mohammed El Hassouni","Hocine Cherifi"],"url":"https://arxiv.org/abs/2506.04081"}
{"created":"2025-06-05","title":"A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning","abstract":"Recent Continual Learning (CL)-based Temporal Knowledge Graph Reasoning (TKGR) methods focus on significantly reducing computational cost and mitigating catastrophic forgetting caused by fine-tuning models with new data. However, existing CL-based TKGR methods still face two key limitations: (1) They usually one-sidedly reorganize individual historical facts, while overlooking the historical context essential for accurately understanding the historical semantics of these facts; (2) They preserve historical knowledge by simply replaying historical facts, while ignoring the potential conflicts between historical and emerging facts. In this paper, we propose a Deep Generative Adaptive Replay (DGAR) method, which can generate and adaptively replay historical entity distribution representations from the whole historical context. To address the first challenge, historical context prompts as sampling units are built to preserve the whole historical context information. To overcome the second challenge, a pre-trained diffusion model is adopted to generate the historical distribution. During the generation process, the common features between the historical and current distributions are enhanced under the guidance of the TKGR model. In addition, a layer-by-layer adaptive replay mechanism is designed to effectively integrate historical and current distributions. Experimental results demonstrate that DGAR significantly outperforms baselines in reasoning and mitigating forgetting.","authors":["Zhiyu Zhang","Wei Chen","Youfang Lin","Huaiyu Wan"],"url":"https://arxiv.org/abs/2506.04083"}
{"created":"2025-06-05","title":"Optimizing Mesh to Improve the Triangular Expansion Algorithm for Computing Visibility Regions","abstract":"This paper addresses the problem of improving the query performance of the triangular expansion algorithm (TEA) for computing visibility regions by finding the most advantageous instance of the triangular mesh, the preprocessing structure. The TEA recursively traverses the mesh while keeping track of the visible region, the set of all points visible from a query point in a polygonal world. We show that the measured query time is approximately proportional to the number of triangle edge expansions during the mesh traversal. We propose a new type of triangular mesh that minimizes the expected number of expansions assuming the query points are drawn from a known probability distribution. We design a heuristic method to approximate the mesh and evaluate the approach on many challenging instances that resemble real-world environments. The proposed mesh improves the mean query times by 12-16% compared to the reference constrained Delaunay triangulation. The approach is suitable to boost offline applications that require computing millions of queries without addressing the preprocessing time. The implementation is publicly available to replicate our experiments and serve the community.","authors":["Jan Mikula (Czech Institute of Informatics","Robotics and Cybernetics","Czech Technical University in Prague","Department of Cybernetics","Faculty of Electrical Engineering","Czech Technical University in Prague)","Miroslav Kulich (Czech Institute of Informatics","Robotics and Cybernetics","Czech Technical University in Prague)"],"url":"https://arxiv.org/abs/2506.04086"}
{"created":"2025-06-05","title":"Multimodal Tabular Reasoning with Privileged Structured Information","abstract":"Tabular reasoning involves multi-step information extraction and logical inference over tabular data. While recent advances have leveraged large language models (LLMs) for reasoning over structured tables, such high-quality textual representations are often unavailable in real-world settings, where tables typically appear as images. In this paper, we tackle the task of tabular reasoning from table images, leveraging privileged structured information available during training to enhance multimodal large language models (MLLMs). The key challenges lie in the complexity of accurately aligning structured information with visual representations, and in effectively transferring structured reasoning skills to MLLMs despite the input modality gap. To address these, we introduce TabUlar Reasoning with Bridged infOrmation ({\\sc Turbo}), a new framework for multimodal tabular reasoning with privileged structured tables. {\\sc Turbo} benefits from a structure-aware reasoning trace generator based on DeepSeek-R1, contributing to high-quality modality-bridged data. On this basis, {\\sc Turbo} repeatedly generates and selects the advantageous reasoning paths, further enhancing the model's tabular reasoning ability. Experimental results demonstrate that, with limited ($9$k) data, {\\sc Turbo} achieves state-of-the-art performance ($+7.2\\%$ vs. previous SOTA) across multiple datasets.","authors":["Jun-Peng Jiang","Yu Xia","Hai-Long Sun","Shiyin Lu","Qing-Guo Chen","Weihua Luo","Kaifu Zhang","De-Chuan Zhan","Han-Jia Ye"],"url":"https://arxiv.org/abs/2506.04088"}
{"created":"2025-06-05","title":"AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment","abstract":"As a part of an embodied agent, Large Language Models (LLMs) are typically used for behavior planning given natural language instructions from the user. However, dealing with ambiguous instructions in real-world environments remains a challenge for LLMs. Various methods for task ambiguity detection have been proposed. However, it is difficult to compare them because they are tested on different datasets and there is no universal benchmark. For this reason, we propose AmbiK (Ambiguous Tasks in Kitchen Environment), the fully textual dataset of ambiguous instructions addressed to a robot in a kitchen environment. AmbiK was collected with the assistance of LLMs and is human-validated. It comprises 1000 pairs of ambiguous tasks and their unambiguous counterparts, categorized by ambiguity type (Human Preferences, Common Sense Knowledge, Safety), with environment descriptions, clarifying questions and answers, user intents, and task plans, for a total of 2000 tasks. We hope that AmbiK will enable researchers to perform a unified comparison of ambiguity detection methods. AmbiK is available at https://github.com/cog-model/AmbiK-dataset.","authors":["Anastasiia Ivanova","Eva Bakaeva","Zoya Volovikova","Alexey K. Kovalev","Aleksandr I. Panov"],"url":"https://arxiv.org/abs/2506.04089"}
{"created":"2025-06-05","title":"A Reference Architecture for Gamified Cultural Heritage Applications Leveraging Generative AI and Augmented Reality","abstract":"The rapid advancement of Information and Communication Technologies is transforming Cultural Heritage access, experience, and preservation. However, many digital heritage applications lack interactivity, personalization, and adaptability, limiting user engagement and educational impact. This short paper presents a reference architecture for gamified cultural heritage applications leveraging generative AI and augmented reality. Gamification enhances motivation, artificial intelligence enables adaptive storytelling and personalized content, and augmented reality fosters immersive, location-aware experiences. Integrating AI with gamification supports dynamic mechanics, personalized feedback, and user behavior prediction, improving engagement. The modular design supports scalability, interoperability, and adaptability across heritage contexts. This research provides a framework for designing interactive and intelligent cultural heritage applications, promoting accessibility and deeper appreciation among users and stakeholders.","authors":["Federico Martusciello","Henry Muccini","Antonio Bucchiarone"],"url":"https://arxiv.org/abs/2506.04090"}
{"created":"2025-06-05","title":"Complexity and Manipulation of International Kidney Exchange Programmes with Country-Specific Parameterss","abstract":"Kidney Exchange Programmes (KEPs) facilitate the exchange of kidneys, and larger pools of recipient-donor pairs tend to yield proportionally more transplants, leading to the proposal of international KEPs (IKEPs). However, as studied by \\citet{mincu2021ip}, practical limitations must be considered in IKEPs to ensure that countries remain willing to participate. Thus, we study IKEPs with country-specific parameters, represented by a tuple $\\Gamma$, restricting the selected transplants to be feasible for the countries to conduct, e.g., imposing an upper limit on the number of consecutive exchanges within a country's borders. We provide a complete complexity dichotomy for the problem of finding a feasible (according to the constraints given by $\\Gamma$) cycle packing with the maximum number of transplants, for every possible $\\Gamma$. We also study the potential for countries to misreport their parameters to increase their allocation. As manipulation can harm the total number of transplants, we propose a novel individually rational and incentive compatible mechanism $\\mathcal{M}_{\\text{order}}$. We first give a theoretical approximation ratio for $\\mathcal{M}_{\\text{order}}$ in terms of the number of transplants, and show that the approximation ratio of $\\mathcal{M}_{\\text{order}}$ is asymptotically optimal. We then use simulations which suggest that, in practice, the performance of $\\mathcal{M}_{\\text{order}}$ is significantly better than this worst-case ratio.","authors":["Rachael Colley","David Manlove","Daniel Paulusma","Mengxiao Zhang"],"url":"https://arxiv.org/abs/2506.04092"}
{"created":"2025-06-05","title":"TextAtari: 100K Frames Game Playing with Language Agents","abstract":"We present TextAtari, a benchmark for evaluating language agents on very long-horizon decision-making tasks spanning up to 100,000 steps. By translating the visual state representations of classic Atari games into rich textual descriptions, TextAtari creates a challenging test bed that bridges sequential decision-making with natural language processing. The benchmark includes nearly 100 distinct tasks with varying complexity, action spaces, and planning horizons, all rendered as text through an unsupervised representation learning framework (AtariARI). We evaluate three open-source large language models (Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks (zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how different forms of prior knowledge affect performance on these long-horizon challenges. Four scenarios-Basic, Obscured, Manual Augmentation, and Reference-based-investigate the impact of semantic understanding, instruction comprehension, and expert demonstrations on agent decision-making. Our results reveal significant performance gaps between language agents and human players in extensive planning tasks, highlighting challenges in sequential reasoning, state tracking, and strategic planning across tens of thousands of steps. TextAtari provides standardized evaluation protocols, baseline implementations, and a framework for advancing research at the intersection of language models and planning.","authors":["Wenhao Li","Wenwu Li","Chuyun Shen","Junjie Sheng","Zixiao Huang","Di Wu","Yun Hua","Wei Yin","Xiangfeng Wang","Hongyuan Zha","Bo Jin"],"url":"https://arxiv.org/abs/2506.04098"}
{"created":"2025-06-05","title":"GlobalBuildingAtlas: An Open Global and Complete Dataset of Building Polygons, Heights and LoD1 3D Models","abstract":"We introduce GlobalBuildingAtlas, a publicly available dataset providing global and complete coverage of building polygons, heights and Level of Detail 1 (LoD1) 3D building models. This is the first open dataset to offer high quality, consistent, and complete building data in 2D and 3D form at the individual building level on a global scale. Towards this dataset, we developed machine learning-based pipelines to derive building polygons and heights (called GBA.Height) from global PlanetScope satellite data, respectively. Also a quality-based fusion strategy was employed to generate higher-quality polygons (called GBA.Polygon) based on existing open building polygons, including our own derived one. With more than 2.75 billion buildings worldwide, GBA.Polygon surpasses the most comprehensive database to date by more than 1 billion buildings. GBA.Height offers the most detailed and accurate global 3D building height maps to date, achieving a spatial resolution of 3x3 meters-30 times finer than previous global products (90 m), enabling a high-resolution and reliable analysis of building volumes at both local and global scales. Finally, we generated a global LoD1 building model (called GBA.LoD1) from the resulting GBA.Polygon and GBA.Height. GBA.LoD1 represents the first complete global LoD1 building models, including 2.68 billion building instances with predicted heights, i.e., with a height completeness of more than 97%, achieving RMSEs ranging from 1.5 m to 8.9 m across different continents. With its height accuracy, comprehensive global coverage and rich spatial details, GlobalBuildingAltas offers novel insights on the status quo of global buildings, which unlocks unprecedented geospatial analysis possibilities, as showcased by a better illustration of where people live and a more comprehensive monitoring of the progress on the 11th Sustainable Development Goal of the United Nations.","authors":["Xiao Xiang Zhu","Sining Chen","Fahong Zhang","Yilei Shi","Yuanyuan Wang"],"url":"https://arxiv.org/abs/2506.04106"}
{"created":"2025-06-05","title":"Rectified Sparse Attention","abstract":"Efficient long-sequence generation is a critical challenge for Large Language Models. While recent sparse decoding methods improve efficiency, they suffer from KV cache misalignment, where approximation errors accumulate and degrade generation quality. In this work, we propose Rectified Sparse Attention (ReSA), a simple yet effective method that combines block-sparse attention with periodic dense rectification. By refreshing the KV cache at fixed intervals using a dense forward pass, ReSA bounds error accumulation and preserves alignment with the pretraining distribution. Experiments across math reasoning, language modeling, and retrieval tasks demonstrate that ReSA achieves near-lossless generation quality with significantly improved efficiency. Notably, ReSA delivers up to 2.42$\\times$ end-to-end speedup under decoding at 256K sequence length, making it a practical solution for scalable long-context inference. Code is available at https://aka.ms/ReSA-LM.","authors":["Yutao Sun","Tianzhu Ye","Li Dong","Yuqing Xia","Jian Chen","Yizhao Gao","Shijie Cao","Jianyong Wang","Furu Wei"],"url":"https://arxiv.org/abs/2506.04108"}
{"created":"2025-06-05","title":"Multi-view Surface Reconstruction Using Normal and Reflectance Cues","abstract":"Achieving high-fidelity 3D surface reconstruction while preserving fine details remains challenging, especially in the presence of materials with complex reflectance properties and without a dense-view setup. In this paper, we introduce a versatile framework that incorporates multi-view normal and optionally reflectance maps into radiance-based surface reconstruction. Our approach employs a pixel-wise joint re-parametrization of reflectance and surface normals, representing them as a vector of radiances under simulated, varying illumination. This formulation enables seamless incorporation into standard surface reconstruction pipelines, such as traditional multi-view stereo (MVS) frameworks or modern neural volume rendering (NVR) ones. Combined with the latter, our approach achieves state-of-the-art performance on multi-view photometric stereo (MVPS) benchmark datasets, including DiLiGenT-MV, LUCES-MV and Skoltech3D. In particular, our method excels in reconstructing fine-grained details and handling challenging visibility conditions. The present paper is an extended version of the earlier conference paper by Brument et al. (in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024), featuring an accelerated and more robust algorithm as well as a broader empirical evaluation. The code and data relative to this article is available at https://github.com/RobinBruneau/RNb-NeuS2.","authors":["Robin Bruneau","Baptiste Brument","Yvain Qu\\'eau","Jean M\\'elou","Fran\\c{c}ois Bernard Lauze","Jean-Denis Durou","Lilian Calvet"],"url":"https://arxiv.org/abs/2506.04115"}
{"created":"2025-06-05","title":"Carbon-Aware Temporal Data Transfer Scheduling Across Cloud Datacenters","abstract":"Inter-datacenter communication is a significant part of cloud operations and produces a substantial amount of carbon emissions for cloud data centers, where the environmental impact has already been a pressing issue. In this paper, we present a novel carbon-aware temporal data transfer scheduling framework, called LinTS, which promises to significantly reduce the carbon emission of data transfers between cloud data centers. LinTS produces a competitive transfer schedule and makes scaling decisions, outperforming common heuristic algorithms. LinTS can lower carbon emissions during inter-datacenter transfers by up to 66% compared to the worst case and up to 15% compared to other solutions while preserving all deadline constraints.","authors":["Elvis Rodrigues","Jacob Goldverg","Tevfik Kosar"],"url":"https://arxiv.org/abs/2506.04117"}
{"created":"2025-06-05","title":"Guided Speculative Inference for Efficient Test-Time Alignment of LLMs","abstract":"We propose Guided Speculative Inference (GSI), a novel algorithm for efficient reward-guided decoding in large language models. GSI combines soft best-of-$n$ test-time scaling with a reward model $r(x,y)$ and speculative samples from a small auxiliary model $\\pi_S(y\\mid x)$. We provably approximate the optimal tilted policy $\\pi_{\\beta,B}(y\\mid x) \\propto \\pi_B(y\\mid x)\\exp(\\beta\\,r(x,y))$ of soft best-of-$n$ under the primary model $\\pi_B$. We derive a theoretical bound on the KL divergence between our induced distribution and the optimal policy. In experiments on reasoning benchmarks (MATH500, OlympiadBench, Minerva Math), our method achieves higher accuracy than standard soft best-of-$n$ with $\\pi_S$ and reward-guided speculative decoding (Liao et al., 2025), and in certain settings even outperforms soft best-of-$n$ with $\\pi_B$. The code is available at https://github.com/j-geuter/GSI .","authors":["Jonathan Geuter","Youssef Mroueh","David Alvarez-Melis"],"url":"https://arxiv.org/abs/2506.04118"}
{"created":"2025-06-05","title":"Splatting Physical Scenes: End-to-End Real-to-Sim from Imperfect Robot Data","abstract":"Creating accurate, physical simulations directly from real-world robot motion holds great value for safe, scalable, and affordable robot learning, yet remains exceptionally challenging. Real robot data suffers from occlusions, noisy camera poses, dynamic scene elements, which hinder the creation of geometrically accurate and photorealistic digital twins of unseen objects. We introduce a novel real-to-sim framework tackling all these challenges at once. Our key insight is a hybrid scene representation merging the photorealistic rendering of 3D Gaussian Splatting with explicit object meshes suitable for physics simulation within a single representation. We propose an end-to-end optimization pipeline that leverages differentiable rendering and differentiable physics within MuJoCo to jointly refine all scene components - from object geometry and appearance to robot poses and physical parameters - directly from raw and imprecise robot trajectories. This unified optimization allows us to simultaneously achieve high-fidelity object mesh reconstruction, generate photorealistic novel views, and perform annotation-free robot pose calibration. We demonstrate the effectiveness of our approach both in simulation and on challenging real-world sequences using an ALOHA 2 bi-manual manipulator, enabling more practical and robust real-to-simulation pipelines.","authors":["Ben Moran","Mauro Comi","Steven Bohez","Tom Erez","Zhibin Li","Leonard Hasenclever"],"url":"https://arxiv.org/abs/2506.04120"}
{"created":"2025-06-05","title":"Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking","abstract":"Finding reliable matches is essential in multi-object tracking to ensure the accuracy and reliability of perception systems in safety-critical applications such as autonomous vehicles. Effective matching mitigates perception errors, enhancing object identification and tracking for improved performance and safety. However, traditional metrics such as Intersection over Union (IoU) and Center Point Distances (CPDs), which are effective in 2D image planes, often fail to find critical matches in complex 3D scenes. To address this limitation, we introduce Contour Errors (CEs), an ego or object-centric metric for identifying matches of interest in tracking scenarios from a functional perspective. By comparing bounding boxes in the ego vehicle's frame, contour errors provide a more functionally relevant assessment of object matches. Extensive experiments on the nuScenes dataset demonstrate that contour errors improve the reliability of matches over the state-of-the-art 2D IoU and CPD metrics in tracking-by-detection methods. In 3D car tracking, our results show that Contour Errors reduce functional failures (FPs/FNs) by 80% at close ranges and 60% at far ranges compared to IoU in the evaluation stage.","authors":["Sharang Kaul","Mario Berk","Thiemo Gerbich","Abhinav Valada"],"url":"https://arxiv.org/abs/2506.04122"}
{"created":"2025-06-05","title":"Lagrangian Particle Classification and Lagrangian Flux Identities for a Moving Hypersurface","abstract":"For a moving hypersurface in the flow of a nonautonomous ordinary differential equation in $n$-dimensional Euclidean spaces, the fluxing index of a passively-advected Lagrangian particle","authors":["Lingyun Ding","Shuang Hu","Baiyun Huang","Qinghai Zhang"],"url":"https://arxiv.org/abs/2506.04125"}
{"created":"2025-06-05","title":"Incremental Gradient Descent with Small Epoch Counts is Surprisingly Slow on Ill-Conditioned Problems","abstract":"Recent theoretical results demonstrate that the convergence rates of permutation-based SGD (e.g., random reshuffling SGD) are faster than uniform-sampling SGD; however, these studies focus mainly on the large epoch regime, where the number of epochs $K$ exceeds the condition number $\\kappa$. In contrast, little is known when $K$ is smaller than $\\kappa$, and it is still a challenging open question whether permutation-based SGD can converge faster in this small epoch regime (Safran and Shamir, 2021). As a step toward understanding this gap, we study the naive deterministic variant, Incremental Gradient Descent (IGD), on smooth and strongly convex functions. Our lower bounds reveal that for the small epoch regime, IGD can exhibit surprisingly slow convergence even when all component functions are strongly convex. Furthermore, when some component functions are allowed to be nonconvex, we prove that the optimality gap of IGD can be significantly worse throughout the small epoch regime. Our analyses reveal that the convergence properties of permutation-based SGD in the small epoch regime may vary drastically depending on the assumptions on component functions. Lastly, we supplement the paper with tight upper and lower bounds for IGD in the large epoch regime.","authors":["Yujun Kim","Jaeyoung Cha","Chulhee Yun"],"url":"https://arxiv.org/abs/2506.04126"}
{"created":"2025-06-05","title":"The Line Traveling Salesman and Repairman Problem with Collaboration","abstract":"In this work, we consider extensions of both the Line Traveling Salesman and Line Traveling Repairman Problem, in which a single server must service a set of clients located along a line segment under the assumption that not only the server, but also the clients can move along the line and seek to collaborate with the server to speed up service times. We analyze the structure of different problem versions and identify hard and easy subproblems by building up on prior results from the literature. Specifically, we investigate problem versions with zero or general processing times, clients that are either slower or faster than the server, as well as different time window restrictions. Collectively, these results map out the complexity landscape of the Line Traveling Salesman and Repairman Problem with collaboration.","authors":["Julian Golak","Finn S\\\"orensen","Malte Fliedner"],"url":"https://arxiv.org/abs/2506.04127"}
{"created":"2025-06-05","title":"CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in Courtroom Dialogues","abstract":"Courtrooms are places where lives are determined and fates are sealed, yet they are not impervious to manipulation. Strategic use of manipulation in legal jargon can sway the opinions of judges and affect the decisions. Despite the growing advancements in NLP, its application in detecting and analyzing manipulation within the legal domain remains largely unexplored. Our work addresses this gap by introducing LegalCon, a dataset of 1,063 annotated courtroom conversations labeled for manipulation detection, identification of primary manipulators, and classification of manipulative techniques, with a focus on long conversations. Furthermore, we propose CLAIM, a two-stage, Intent-driven Multi-agent framework designed to enhance manipulation analysis by enabling context-aware and informed decision-making. Our results highlight the potential of incorporating agentic frameworks to improve fairness and transparency in judicial processes. We hope that this contributes to the broader application of NLP in legal discourse analysis and the development of robust tools to support fairness in legal decision-making. Our code and data are available at https://github.com/Disha1001/CLAIM.","authors":["Disha Sheshanarayana","Tanishka Magar","Ayushi Mittal","Neelam Chaplot"],"url":"https://arxiv.org/abs/2506.04131"}
{"created":"2025-06-05","title":"TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems","abstract":"Agentic AI systems, built on large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligent autonomy, collaboration and decision-making across enterprise and societal domains. This review presents a structured analysis of Trust, Risk, and Security Management (TRiSM) in the context of LLM-based agentic multi-agent systems (AMAS). We begin by examining the conceptual foundations of agentic AI, its architectural differences from traditional AI agents, and the emerging system designs that enable scalable, tool-using autonomy. The TRiSM in the agentic AI framework is then detailed through four pillars governance, explainability, ModelOps, and privacy/security each contextualized for agentic LLMs. We identify unique threat vectors and introduce a comprehensive risk taxonomy for the agentic AI applications, supported by case studies illustrating real-world vulnerabilities. Furthermore, the paper also surveys trust-building mechanisms, transparency and oversight techniques, and state-of-the-art explainability strategies in distributed LLM agent systems. Additionally, metrics for evaluating trust, interpretability, and human-centered performance are reviewed alongside open benchmarking challenges. Security and privacy are addressed through encryption, adversarial defense, and compliance with evolving AI regulations. The paper concludes with a roadmap for responsible agentic AI, proposing research directions to align emerging multi-agent systems with robust TRiSM principles for safe, accountable, and transparent deployment.","authors":["Shaina Raza","Ranjan Sapkota","Manoj Karkee","Christos Emmanouilidis"],"url":"https://arxiv.org/abs/2506.04133"}
{"created":"2025-06-05","title":"UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation","abstract":"Cued Speech (CS) enhances lipreading through hand coding, providing precise speech perception support for the hearing-impaired. CS Video-to-Speech generation (CSV2S) task aims to convert the CS visual expressions (CS videos) of hearing-impaired individuals into comprehensible speech signals. Direct generation of speech from CS video (called single CSV2S) yields poor performance due to insufficient CS data. Current research mostly focuses on CS Recognition (CSR), which convert video content into linguistic text. Based on this, one straightforward way of CSV2S is to combine CSR with a Text-to-Speech system. This combined architecture relies on text as an intermediate medium for stepwise cross-modal alignment, which may lead to error propagation and temporal misalignment between speech and video dynamics. To address these challenges, we propose a novel approach that directly generates speech from CS videos without relying on intermediate text. Building upon this, we propose UniCUE, the first unified framework for CSV2S, whose core innovation lies in the integration of the CSR task that provides fine-grained visual-semantic information to facilitate speech generation from CS videos. More precisely, (1) a novel fine-grained semantic alignment pool to ensure precise mapping between visual features and speech contents; (2) a VisioPhonetic adapter to bridge cross-task representations, ensuring seamless compatibility between two distinct tasks (i.e., CSV2S and CSR); (3) a pose-aware visual processor is introduced to enhance fine-grained spatiotemporal correlations between lip and hand movements in CS video. Experiments on our new established Chinese CS dataset (14 cuers1: 8 hearing-impaired and 6 normal-hearing) show that our UniCUE significantly reduces Word Error Rate by 78.3% and improves lip-speech synchronization by 32% compared to the single CSV2S.","authors":["Jinting Wang","Shan Yang","Li Liu"],"url":"https://arxiv.org/abs/2506.04134"}
{"created":"2025-06-05","title":"macOSWorld: A Multilingual Interactive Benchmark for GUI Agents","abstract":"Graphical User Interface (GUI) agents show promising capabilities for automating computer-use tasks and facilitating accessibility, but existing interactive benchmarks are mostly English-only, covering web-use or Windows, Linux, and Android environments, but not macOS. macOS is a major OS with distinctive GUI patterns and exclusive applications. To bridge the gaps, we present macOSWorld, the first comprehensive benchmark for evaluating GUI agents on macOS. macOSWorld features 202 multilingual interactive tasks across 30 applications (28 macOS-exclusive), with task instructions and OS interfaces offered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As GUI agents are shown to be vulnerable to deception attacks, macOSWorld also includes a dedicated safety benchmarking subset. Our evaluation on six GUI agents reveals a dramatic gap: proprietary computer-use agents lead at above 30% success rate, while open-source lightweight research models lag at below 2%, highlighting the need for macOS domain adaptation. Multilingual benchmarks also expose common weaknesses, especially in Arabic, with a 27.5% average degradation compared to English. Results from safety benchmarking also highlight that deception attacks are more general and demand immediate attention. macOSWorld is available at https://github.com/showlab/macosworld.","authors":["Pei Yang","Hai Ci","Mike Zheng Shou"],"url":"https://arxiv.org/abs/2506.04135"}
{"created":"2025-06-05","title":"Are Lexicon-Based Tools Still the Gold Standard for Valence Analysis in Low-Resource Flemish?","abstract":"Understanding the nuances in everyday language is pivotal for advancements in computational linguistics & emotions research. Traditional lexicon-based tools such as LIWC and Pattern have long served as foundational instruments in this domain. LIWC is the most extensively validated word count based text analysis tool in the social sciences and Pattern is an open source Python library offering functionalities for NLP. However, everyday language is inherently spontaneous, richly expressive, & deeply context dependent. To explore the capabilities of LLMs in capturing the valences of daily narratives in Flemish, we first conducted a study involving approximately 25,000 textual responses from 102 Dutch-speaking participants. Each participant provided narratives prompted by the question, \"What is happening right now and how do you feel about it?\", accompanied by self-assessed valence ratings on a continuous scale from -50 to +50. We then assessed the performance of three Dutch-specific LLMs in predicting these valence scores, and compared their outputs to those generated by LIWC and Pattern. Our findings indicate that, despite advancements in LLM architectures, these Dutch tuned models currently fall short in accurately capturing the emotional valence present in spontaneous, real-world narratives. This study underscores the imperative for developing culturally and linguistically tailored models/tools that can adeptly handle the complexities of natural language use. Enhancing automated valence analysis is not only pivotal for advancing computational methodologies but also holds significant promise for psychological research with ecologically valid insights into human daily experiences. We advocate for increased efforts in creating comprehensive datasets & finetuning LLMs for low-resource languages like Flemish, aiming to bridge the gap between computational linguistics & emotion research.","authors":["Ratna Kandala","Katie Hoemann"],"url":"https://arxiv.org/abs/2506.04139"}
{"created":"2025-06-05","title":"Quantifying Query Fairness Under Unawareness","abstract":"Traditional ranking algorithms are designed to retrieve the most relevant items for a user's query, but they often inherit biases from data that can unfairly disadvantage vulnerable groups. Fairness in information access systems (IAS) is typically assessed by comparing the distribution of groups in a ranking to a target distribution, such as the overall group distribution in the dataset. These fairness metrics depend on knowing the true group labels for each item. However, when groups are defined by demographic or sensitive attributes, these labels are often unknown, leading to a setting known as \"fairness under unawareness\". To address this, group membership can be inferred using machine-learned classifiers, and group prevalence is estimated by counting the predicted labels. Unfortunately, such an estimation is known to be unreliable under dataset shift, compromising the accuracy of fairness evaluations. In this paper, we introduce a robust fairness estimator based on quantification that effectively handles multiple sensitive attributes beyond binary classifications. Our method outperforms existing baselines across various sensitive attributes and, to the best of our knowledge, is the first to establish a reliable protocol for measuring fairness under unawareness across multiple queries and groups.","authors":["Thomas Jaenich","Alejandro Moreo","Alessandro Fabris","Graham McDonald","Andrea Esuli","Iadh Ounis","Fabrizio Sebastiani"],"url":"https://arxiv.org/abs/2506.04140"}
{"created":"2025-06-05","title":"MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos","abstract":"The sequential structure of videos poses a challenge to the ability of multimodal large language models (MLLMs) to locate multi-frame evidence and conduct multimodal reasoning. However, existing video benchmarks mainly focus on understanding tasks, which only require models to match frames mentioned in the question (hereafter referred to as \"question frame\") and perceive a few adjacent frames. To address this gap, we propose MMR-V: A Benchmark for Multimodal Deep Reasoning in Videos. The benchmark is characterized by the following features. (1) Long-range, multi-frame reasoning: Models are required to infer and analyze evidence frames that may be far from the question frame. (2) Beyond perception: Questions cannot be answered through direct perception alone but require reasoning over hidden information. (3) Reliability: All tasks are manually annotated, referencing extensive real-world user understanding to align with common perceptions. (4) Confusability: Carefully designed distractor annotation strategies to reduce model shortcuts. MMR-V consists of 317 videos and 1,257 tasks. Our experiments reveal that current models still struggle with multi-modal reasoning; even the best-performing model, o4-mini, achieves only 52.5% accuracy. Additionally, current reasoning enhancement strategies (Chain-of-Thought and scaling test-time compute) bring limited gains. Further analysis indicates that the CoT demanded for multi-modal reasoning differs from it in textual reasoning, which partly explains the limited performance gains. We hope that MMR-V can inspire further research into enhancing multi-modal reasoning capabilities.","authors":["Kejian Zhu","Zhuoran Jin","Hongbang Yuan","Jiachun Li","Shangqing Tu","Pengfei Cao","Yubo Chen","Kang Liu","Jun Zhao"],"url":"https://arxiv.org/abs/2506.04141"}
{"created":"2025-06-05","title":"Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis","abstract":"The development of large language models (LLMs) depends on trustworthy evaluation. However, most current evaluations rely on public benchmarks, which are prone to data contamination issues that significantly compromise fairness. Previous researches have focused on constructing dynamic benchmarks to address contamination. However, continuously building new benchmarks is costly and cyclical. In this work, we aim to tackle contamination by analyzing the mechanisms of contaminated models themselves. Through our experiments, we discover that the overestimation of contaminated models is likely due to parameters acquiring shortcut solutions in training. We further propose a novel method for identifying shortcut neurons through comparative and causal analysis. Building on this, we introduce an evaluation method called shortcut neuron patching to suppress shortcut neurons. Experiments validate the effectiveness of our approach in mitigating contamination. Additionally, our evaluation results exhibit a strong linear correlation with MixEval, a recently released trustworthy benchmark, achieving a Spearman coefficient ($\\rho$) exceeding 0.95. This high correlation indicates that our method closely reveals true capabilities of the models and is trustworthy. We conduct further experiments to demonstrate the generalizability of our method across various benchmarks and hyperparameter settings. Code: https://github.com/GaryStack/Trustworthy-Evaluation","authors":["Kejian Zhu","Shangqing Tu","Zhuoran Jin","Lei Hou","Juanzi Li","Jun Zhao"],"url":"https://arxiv.org/abs/2506.04142"}
{"created":"2025-06-05","title":"Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology","abstract":"Person Re-Identification (Re-ID) is a very important task in video surveillance systems such as tracking people, finding people in public places, or analysing customer behavior in supermarkets. Although there have been many works to solve this problem, there are still remaining challenges such as large-scale datasets, imbalanced data, viewpoint, fine grained data (attributes), the Local Features are not employed at semantic level in online stage of Re-ID task, furthermore, the imbalanced data problem of attributes are not taken into consideration. This paper has proposed a Unified Re-ID system consisted of three main modules such as Pedestrian Attribute Ontology (PAO), Local Multi-task DCNN (Local MDCNN), Imbalance Data Solver (IDS). The new main point of our Re-ID system is the power of mutual support of PAO, Local MDCNN and IDS to exploit the inner-group correlations of attributes and pre-filter the mismatch candidates from Gallery set based on semantic information as Fashion Attributes and Facial Attributes, to solve the imbalanced data of attributes without adjusting network architecture and data augmentation. We experimented on the well-known Market1501 dataset. The experimental results have shown the effectiveness of our Re-ID system and it could achieve the higher performance on Market1501 dataset in comparison to some state-of-the-art Re-ID methods.","authors":["Ngoc Q. Ly","Hieu N. M. Cao","Thi T. Nguyen"],"url":"https://arxiv.org/abs/2506.04143"}
{"created":"2025-06-05","title":"Improving Regulatory Oversight in Online Content Moderation","abstract":"The European Union introduced the Digital Services Act (DSA) to address the risks associated with digital platforms and promote a safer online environment. However, despite the potential of components such as the Transparency Database, Transparency Reports, and Article 40 of the DSA to improve platform transparency, significant challenges remain. These include data inconsistencies and a lack of detailed information, which hinder transparency in content moderation practices. Additionally, the absence of standardized reporting structures makes cross-platform comparisons and broader analyses difficult. To address these issues, we propose two complementary processes: a Transparency Report Cross-Checking Process and a Verification Process. Their goal is to provide both internal and external validation by detecting possible inconsistencies between self-reported and actual platform data, assessing compliance levels, and ultimately enhancing transparency while improving the overall effectiveness of the DSA in ensuring accountability in content moderation. Additionally, these processes can benefit policymakers by providing more accurate data for decision-making, independent researchers with trustworthy analysis, and platforms by offering a method for self-assessment and improving compliance and reporting practices.","authors":["Benedetta Tessa","Denise Amram","Anna Monreale","Stefano Cresci"],"url":"https://arxiv.org/abs/2506.04145"}
{"created":"2025-06-05","title":"SLAC: Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL","abstract":"Building capable household and industrial robots requires mastering the control of versatile, high-degree-of-freedom (DoF) systems such as mobile manipulators. While reinforcement learning (RL) holds promise for autonomously acquiring robot control policies, scaling it to high-DoF embodiments remains challenging. Direct RL in the real world demands both safe exploration and high sample efficiency, which are difficult to achieve in practice. Sim-to-real RL, on the other hand, is often brittle due to the reality gap. This paper introduces SLAC, a method that renders real-world RL feasible for complex embodiments by leveraging a low-fidelity simulator to pretrain a task-agnostic latent action space. SLAC trains this latent action space via a customized unsupervised skill discovery method designed to promote temporal abstraction, disentanglement, and safety, thereby facilitating efficient downstream learning. Once a latent action space is learned, SLAC uses it as the action interface for a novel off-policy RL algorithm to autonomously learn downstream tasks through real-world interactions. We evaluate SLAC against existing methods on a suite of bimanual mobile manipulation tasks, where it achieves state-of-the-art performance. Notably, SLAC learns contact-rich whole-body tasks in under an hour of real-world interactions, without relying on any demonstrations or hand-crafted behavior priors. More information, code, and videos at robo-rl.github.io","authors":["Jiaheng Hu","Peter Stone","Roberto Mart\\'in-Mart\\'in"],"url":"https://arxiv.org/abs/2506.04147"}
{"created":"2025-06-05","title":"A Dataset for Addressing Patient's Information Needs related to Clinical Course of Hospitalization","abstract":"Patients have distinct information needs about their hospitalization that can be addressed using clinical evidence from electronic health records (EHRs). While artificial intelligence (AI) systems show promise in meeting these needs, robust datasets are needed to evaluate the factual accuracy and relevance of AI-generated responses. To our knowledge, no existing dataset captures patient information needs in the context of their EHRs. We introduce ArchEHR-QA, an expert-annotated dataset based on real-world patient cases from intensive care unit and emergency department settings. The cases comprise questions posed by patients to public health forums, clinician-interpreted counterparts, relevant clinical note excerpts with sentence-level relevance annotations, and clinician-authored answers. To establish benchmarks for grounded EHR question answering (QA), we evaluated three open-weight large language models (LLMs)--Llama 4, Llama 3, and Mixtral--across three prompting strategies: generating (1) answers with citations to clinical note sentences, (2) answers before citations, and (3) answers from filtered citations. We assessed performance on two dimensions: Factuality (overlap between cited note sentences and ground truth) and Relevance (textual and semantic similarity between system and reference answers). The final dataset contains 134 patient cases. The answer-first prompting approach consistently performed best, with Llama 4 achieving the highest scores. Manual error analysis supported these findings and revealed common issues such as omitted key clinical evidence and contradictory or hallucinated content. Overall, ArchEHR-QA provides a strong benchmark for developing and evaluating patient-centered EHR QA systems, underscoring the need for further progress toward generating factual and relevant responses in clinical contexts.","authors":["Sarvesh Soni","Dina Demner-Fushman"],"url":"https://arxiv.org/abs/2506.04156"}
{"created":"2025-06-05","title":"A robust matrix-free approach for large-scale non-isothermal high-contrast viscosity Stokes flow on blended domains with applications to geophysics","abstract":"We consider a compressible Stokes problem in the quasi-stationary case coupled with a time dependent advection-diffusion equation with special emphasis on high viscosity contrast geophysical mantle convection applications. In space, we use a P2-P1 Taylor--Hood element which is generated by a blending approach to account for the non-planar domain boundary without compromising the stencil data structure of uniformly refined elements. In time, we apply an operator splitting approach for the temperature equation combining the BDF2 method for diffusion and a particle method for advection, resulting in an overall second order scheme. Within each time step, a stationary Stokes problem with a high viscosity contrast has to be solved for which we propose a matrix-free, robust and scalable iterative solver based on Uzawa type block preconditioners, polynomial Chebyshev smoothers and a BFBT type Schur complement approximation. Our implementation is using a hybrid hierarchical grid approach allowing for massively parallel, high resolution Earth convection simulations.","authors":["Andreas Burkhart","Nils Kohl","Barbara Wohlmuth","Jan Zawallich"],"url":"https://arxiv.org/abs/2506.04157"}
{"created":"2025-06-05","title":"Image Editing As Programs with Diffusion Models","abstract":"While diffusion models have achieved remarkable success in text-to-image generation, they encounter significant challenges with instruction-driven image editing. Our research highlights a key challenge: these models particularly struggle with structurally inconsistent edits that involve substantial layout changes. To mitigate this gap, we introduce Image Editing As Programs (IEAP), a unified image editing framework built upon the Diffusion Transformer (DiT) architecture. At its core, IEAP approaches instructional editing through a reductionist lens, decomposing complex editing instructions into sequences of atomic operations. Each operation is implemented via a lightweight adapter sharing the same DiT backbone and is specialized for a specific type of edit. Programmed by a vision-language model (VLM)-based agent, these operations collaboratively support arbitrary and structurally inconsistent transformations. By modularizing and sequencing edits in this way, IEAP generalizes robustly across a wide range of editing tasks, from simple adjustments to substantial structural changes. Extensive experiments demonstrate that IEAP significantly outperforms state-of-the-art methods on standard benchmarks across various editing scenarios. In these evaluations, our framework delivers superior accuracy and semantic fidelity, particularly for complex, multi-step instructions. Codes are available at https://github.com/YujiaHu1109/IEAP.","authors":["Yujia Hu","Songhua Liu","Zhenxiong Tan","Xingyi Yang","Xinchao Wang"],"url":"https://arxiv.org/abs/2506.04158"}
{"created":"2025-06-05","title":"VISCA: Inferring Component Abstractions for Automated End-to-End Testing","abstract":"Providing optimal contextual input presents a significant challenge for automated end-to-end (E2E) test generation using large language models (LLMs), a limitation that current approaches inadequately address. This paper introduces Visual-Semantic Component Abstractor (VISCA), a novel method that transforms webpages into a hierarchical, semantically rich component abstraction. VISCA starts by partitioning webpages into candidate segments utilizing a novel heuristic-based segmentation method. These candidate segments subsequently undergo classification and contextual information extraction via multimodal LLM-driven analysis, facilitating their abstraction into a predefined vocabulary of user interface (UI) components. This component-centric abstraction offers a more effective contextual basis than prior approaches, enabling more accurate feature inference and robust E2E test case generation. Our evaluations demonstrate that the test cases generated by VISCA achieve an average feature coverage of 92%, exceeding the performance of the state-of-the-art LLM-based E2E test generation method by 16%.","authors":["Parsa Alian","Martin Tang","Ali Mesbah"],"url":"https://arxiv.org/abs/2506.04161"}
{"created":"2025-06-05","title":"On the Synthetic Channels in Polar Codes over Binary-Input Discrete Memoryless Channels","abstract":"Polar codes introduced by Arikan in 2009 are the first code family achieving the capacity of binary-input discrete memoryless channels (BIDMCs) with low-complexity encoding and decoding. Identifying unreliable synthetic channels in polar code construction is crucial. Currently, because of the large size of the output alphabets of synthetic channels, there is no effective approach to evaluate their reliability, except in the case that the underlying channels are binary erasure channels. This paper defines equivalence and symmetry based on the likelihood ratio profile of BIDMCs and characterizes symmetric BIDMCs as random switching channels (RSCs) of binary symmetric channels. By converting the generation of synthetic channels in polar code construction into algebraic operations on underlying channels, some compact representations of RSCs for these synthetic channels are derived. Moreover, a lower bound for the average number of elements that possess the same likelihood ratio within the output alphabet of any synthetic channel generated in polar codes is also derived.","authors":["Yadong Jiao","Xiaoyan Cheng","Yuansheng Tang","Ming Xu"],"url":"https://arxiv.org/abs/2506.04163"}
{"created":"2025-06-05","title":"Faster Approx. Top-K: Harnessing the Full Power of Two Stages","abstract":"We consider the Top-$K$ selection problem, which aims to identify the largest-$K$ elements from an array. Top-$K$ selection arises in many machine learning algorithms and often becomes a bottleneck on accelerators, which are optimized for dense matrix multiplications. To address this problem, \\citet{chern2022tpuknnknearestneighbor} proposed a fast two-stage \\textit{approximate} Top-$K$ algorithm: (i) partition the input array and select the top-$1$ element from each partition, (ii) sort this \\textit{smaller subset} and return the top $K$ elements. In this paper, we consider a generalized version of this algorithm, where the first stage selects top-$K'$ elements, for some $1 \\leq K' \\leq K$, from each partition. Our contributions are as follows: (i) we derive an expression for the expected recall of this generalized algorithm and show that choosing $K' > 1$ with fewer partitions in the first stage reduces the input size to the second stage more effectively while maintaining the same expected recall as the original algorithm, (ii) we derive a bound on the expected recall for the original algorithm in \\citet{chern2022tpuknnknearestneighbor} that is provably tighter by a factor of $2$ than the one in that paper, and (iii) we implement our algorithm on Cloud TPUv5e and achieve around an order of magnitude speedups over the original algorithm without sacrificing recall on real-world tasks.","authors":["Yashas Samaga","Varun Yerram","Spandana Raj Babbula","Prateek Jain","Praneeth Netrapalli"],"url":"https://arxiv.org/abs/2506.04165"}
{"created":"2025-06-05","title":"N$^2$: A Unified Python Package and Test Bench for Nearest Neighbor-Based Matrix Completion","abstract":"Nearest neighbor (NN) methods have re-emerged as competitive tools for matrix completion, offering strong empirical performance and recent theoretical guarantees, including entry-wise error bounds, confidence intervals, and minimax optimality. Despite their simplicity, recent work has shown that NN approaches are robust to a range of missingness patterns and effective across diverse applications. This paper introduces N$^2$, a unified Python package and testbed that consolidates a broad class of NN-based methods through a modular, extensible interface. Built for both researchers and practitioners, N$^2$ supports rapid experimentation and benchmarking. Using this framework, we introduce a new NN variant that achieves state-of-the-art results in several settings. We also release a benchmark suite of real-world datasets, from healthcare and recommender systems to causal inference and LLM evaluation, designed to stress-test matrix completion methods beyond synthetic scenarios. Our experiments demonstrate that while classical methods excel on idealized data, NN-based techniques consistently outperform them in real-world settings.","authors":["Caleb Chin","Aashish Khubchandani","Harshvardhan Maskara","Kyuseong Choi","Jacob Feitelberg","Albert Gong","Manit Paul","Tathagata Sadhukhan","Anish Agarwal","Raaz Dwivedi"],"url":"https://arxiv.org/abs/2506.04166"}
{"created":"2025-06-05","title":"Neural and Cognitive Impacts of AI: The Influence of Task Subjectivity on Human-LLM Collaboration","abstract":"AI-based interactive assistants are advancing human-augmenting technology, yet their effects on users' mental and physiological states remain under-explored. We address this gap by analyzing how Copilot for Microsoft Word, a LLM-based assistant, impacts users. Using tasks ranging from objective (SAT reading comprehension) to subjective (personal reflection), and with measurements including fNIRS, Empatica E4, NASA-TLX, and questionnaires, we measure Copilot's effects on users. We also evaluate users' performance with and without Copilot across tasks. In objective tasks, participants reported a reduction of workload and an increase in enjoyment, which was paired with objective performance increases. Participants reported reduced workload and increased enjoyment with no change in performance in a creative poetry writing task. However, no benefits due to Copilot use were reported in a highly subjective self-reflection task. Although no physiological changes were recorded due to Copilot use, task-dependent differences in prefrontal cortex activation offer complementary insights into the cognitive processes associated with successful and unsuccessful human-AI collaboration. These findings suggest that AI assistants' effectiveness varies with task type-particularly showing decreased usefulness in tasks that engage episodic memory-and presents a brain-network based hypothesis of human-AI collaboration.","authors":["Matthew Russell","Aman Shah","Giles Blaney","Judith Amores","Mary Czerwinski","Robert J. K. Jacob"],"url":"https://arxiv.org/abs/2506.04167"}
{"created":"2025-06-05","title":"Horizon Reduction Makes RL Scalable","abstract":"In this work, we study the scalability of offline reinforcement learning (RL) algorithms. In principle, a truly scalable offline RL algorithm should be able to solve any given problem, regardless of its complexity, given sufficient data, compute, and model capacity. We investigate if and how current offline RL algorithms match up to this promise on diverse, challenging, previously unsolved tasks, using datasets up to 1000x larger than typical offline RL datasets. We observe that despite scaling up data, many existing offline RL algorithms exhibit poor scaling behavior, saturating well below the maximum performance. We hypothesize that the horizon is the main cause behind the poor scaling of offline RL. We empirically verify this hypothesis through several analysis experiments, showing that long horizons indeed present a fundamental barrier to scaling up offline RL. We then show that various horizon reduction techniques substantially enhance scalability on challenging tasks. Based on our insights, we also introduce a minimal yet scalable method named SHARSA that effectively reduces the horizon. SHARSA achieves the best asymptotic performance and scaling behavior among our evaluation methods, showing that explicitly reducing the horizon unlocks the scalability of offline RL. Code: https://github.com/seohongpark/horizon-reduction","authors":["Seohong Park","Kevin Frans","Deepinder Mann","Benjamin Eysenbach","Aviral Kumar","Sergey Levine"],"url":"https://arxiv.org/abs/2506.04168"}
{"created":"2025-06-05","title":"Physics-Constrained Flow Matching: Sampling Generative Models with Hard Constraints","abstract":"Deep generative models have recently been applied to physical systems governed by partial differential equations (PDEs), offering scalable simulation and uncertainty-aware inference. However, enforcing physical constraints, such as conservation laws (linear and nonlinear) and physical consistencies, remains challenging. Existing methods often rely on soft penalties or architectural biases that fail to guarantee hard constraints. In this work, we propose Physics-Constrained Flow Matching (PCFM), a zero-shot inference framework that enforces arbitrary nonlinear constraints in pretrained flow-based generative models. PCFM continuously guides the sampling process through physics-based corrections applied to intermediate solution states, while remaining aligned with the learned flow and satisfying physical constraints. Empirically, PCFM outperforms both unconstrained and constrained baselines on a range of PDEs, including those with shocks, discontinuities, and sharp features, while ensuring exact constraint satisfaction at the final solution. Our method provides a general framework for enforcing hard constraints in both scientific and general-purpose generative models, especially in applications where constraint satisfaction is essential.","authors":["Utkarsh Utkarsh","Pengfei Cai","Alan Edelman","Rafael Gomez-Bombarelli","Christopher Vincent Rackauckas"],"url":"https://arxiv.org/abs/2506.04171"}
{"created":"2025-06-05","title":"Does Prompt Design Impact Quality of Data Imputation by LLMs?","abstract":"Generating realistic synthetic tabular data presents a critical challenge in machine learning. It adds another layer of complexity when this data contain class imbalance problems. This paper presents a novel token-aware data imputation method that leverages the in-context learning capabilities of large language models. This is achieved through the combination of a structured group-wise CSV-style prompting technique and the elimination of irrelevant contextual information in the input prompt. We test this approach with two class-imbalanced binary classification datasets and evaluate the effectiveness of imputation using classification-based evaluation metrics. The experimental results demonstrate that our approach significantly reduces the input prompt size while maintaining or improving imputation quality compared to our baseline prompt, especially for datasets that are of relatively smaller in size. The contributions of this presented work is two-fold -- 1) it sheds light on the importance of prompt design when leveraging LLMs for synthetic data generation and 2) it addresses a critical gap in LLM-based data imputation for class-imbalanced datasets with missing data by providing a practical solution within computational constraints. We hope that our work will foster further research and discussions about leveraging the incredible potential of LLMs and prompt engineering techniques for synthetic data generation.","authors":["Shreenidhi Srinivasan","Lydia Manikonda"],"url":"https://arxiv.org/abs/2506.04172"}
{"created":"2025-06-05","title":"FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting","abstract":"3D Gaussian splatting (3DGS) has enabled various applications in 3D scene representation and novel view synthesis due to its efficient rendering capabilities. However, 3DGS demands relatively significant GPU memory, limiting its use on devices with restricted computational resources. Previous approaches have focused on pruning less important Gaussians, effectively compressing 3DGS but often requiring a fine-tuning stage and lacking adaptability for the specific memory needs of different devices. In this work, we present an elastic inference method for 3DGS. Given an input for the desired model size, our method selects and transforms a subset of Gaussians, achieving substantial rendering performance without additional fine-tuning. We introduce a tiny learnable module that controls Gaussian selection based on the input percentage, along with a transformation module that adjusts the selected Gaussians to complement the performance of the reduced model. Comprehensive experiments on ZipNeRF, MipNeRF and Tanks\\&amp;Temples scenes demonstrate the effectiveness of our approach. Code is available at https://flexgs.github.io.","authors":["Hengyu Liu","Yuehao Wang","Chenxin Li","Ruisi Cai","Kevin Wang","Wuyang Li","Pavlo Molchanov","Peihao Wang","Zhangyang Wang"],"url":"https://arxiv.org/abs/2506.04174"}
{"created":"2025-06-05","title":"A MUSCL-Hancock scheme for non-local conservation laws","abstract":"In this article, we propose a MUSCL-Hancock-type second-order scheme for the discretization of a general class of non-local conservation laws and present its convergence analysis. The main difficulty in designing a MUSCL-Hancock-type scheme for non-local equations lies in the discretization of the convolution term, which we carefully formulate to ensure second-order accuracy and facilitate rigorous convergence analysis. We derive several essential estimates including $\\mathrm{L}^\\infty,$ bounded variation ($\\mathrm{BV}$) and $\\mathrm{L}^1$- Lipschitz continuity in time, which together with the Kolmogorov's compactness theorem yield the convergence of the approximate solutions to a weak solution. Further, by incorporating a mesh-dependent modification in the slope limiter, we establish convergence to the entropy solution. Numerical experiments are provided to validate the theoretical results and to demonstrate the improved accuracy of the proposed scheme over its first-order counterpart.","authors":["Nikhil Manoj","G. D. Veerappa Gowda","Sudarshan Kumar K"],"url":"https://arxiv.org/abs/2506.04176"}
{"created":"2025-06-05","title":"OpenThoughts: Data Recipes for Reasoning Models","abstract":"Reasoning models have made rapid progress on many benchmarks involving math, code, and science. Yet, there are still many open questions about the best training recipes for reasoning since state-of-the-art models often rely on proprietary datasets with little to no public information available. To address this, the goal of the OpenThoughts project is to create open-source datasets for training reasoning models. After initial explorations, our OpenThoughts2-1M dataset led to OpenThinker2-32B, the first model trained on public reasoning data to match DeepSeek-R1-Distill-32B on standard reasoning benchmarks such as AIME and LiveCodeBench. We then improve our dataset further by systematically investigating each step of our data generation pipeline with 1,000+ controlled experiments, which led to OpenThoughts3. Scaling the pipeline to 1.2M examples and using QwQ-32B as teacher yields our OpenThinker3-7B model, which achieves state-of-the-art results: 53% on AIME 2025, 51% on LiveCodeBench 06/24-01/25, and 54% on GPQA Diamond. All of our datasets and models are available on https://openthoughts.ai.","authors":["Etash Guha","Ryan Marten","Sedrick Keh","Negin Raoof","Georgios Smyrnis","Hritik Bansal","Marianna Nezhurina","Jean Mercat","Trung Vu","Zayne Sprague","Ashima Suvarna","Benjamin Feuer","Liangyu Chen","Zaid Khan","Eric Frankel","Sachin Grover","Caroline Choi","Niklas Muennighoff","Shiye Su","Wanjia Zhao","John Yang","Shreyas Pimpalgaonkar","Kartik Sharma","Charlie Cheng-Jie Ji","Yichuan Deng","Sarah Pratt","Vivek Ramanujan","Jon Saad-Falcon","Jeffrey Li","Achal Dave","Alon Albalak","Kushal Arora","Blake Wulfe","Chinmay Hegde","Greg Durrett","Sewoong Oh","Mohit Bansal","Saadia Gabriel","Aditya Grover","Kai-Wei Chang","Vaishaal Shankar","Aaron Gokaslan","Mike A. Merrill","Tatsunori Hashimoto","Yejin Choi","Jenia Jitsev","Reinhard Heckel","Maheswaran Sathiamoorthy","Alexandros G. Dimakis","Ludwig Schmidt"],"url":"https://arxiv.org/abs/2506.04178"}
{"created":"2025-06-05","title":"SkipGPT: Dynamic Layer Pruning Reinvented with Token Awareness and Module Decoupling","abstract":"Large language models (LLMs) achieve remarkable performance across tasks but incur substantial computational costs due to their deep, multi-layered architectures. Layer pruning has emerged as a strategy to alleviate these inefficiencies, but conventional static pruning methods overlook two critical dynamics inherent to LLM inference: (1) horizontal dynamics, where token-level heterogeneity demands context-aware pruning decisions, and (2) vertical dynamics, where the distinct functional roles of MLP and self-attention layers necessitate component-specific pruning policies. We introduce SkipGPT, a dynamic layer pruning framework designed to optimize computational resource allocation through two core innovations: (1) global token-aware routing to prioritize critical tokens, and (2) decoupled pruning policies for MLP and self-attention components. To mitigate training instability, we propose a two-stage optimization paradigm: first, a disentangled training phase that learns routing strategies via soft parameterization to avoid premature pruning decisions, followed by parameter-efficient LoRA fine-tuning to restore performance impacted by layer removal. Extensive experiments demonstrate that SkipGPT reduces over 40% of model parameters while matching or exceeding the performance of the original dense model across benchmarks. By harmonizing dynamic efficiency with preserved expressivity, SkipGPT advances the practical deployment of scalable, resource-aware LLMs. Our code is publicly available at: https://github.com/EIT-NLP/SkipGPT.","authors":["Anhao Zhao","Fanghua Ye","Yingqi Fan","Junlong Tong","Zhiwei Fei","Hui Su","Xiaoyu Shen"],"url":"https://arxiv.org/abs/2506.04179"}
{"created":"2025-06-05","title":"SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models","abstract":"Long-form text generation remains a significant challenge for large language models (LLMs), particularly in maintaining coherence, ensuring logical consistency, and preserving text quality as sequence length increases. To address these limitations, we propose SuperWriter-Agent, an agent-based framework designed to enhance the quality and consistency of long-form text generation. SuperWriter-Agent introduces explicit structured thinking-through planning and refinement stages into the generation pipeline, guiding the model to follow a more deliberate and cognitively grounded process akin to that of a professional writer. Based on this framework, we construct a supervised fine-tuning dataset to train a 7B SuperWriter-LM. We further develop a hierarchical Direct Preference Optimization (DPO) procedure that uses Monte Carlo Tree Search (MCTS) to propagate final quality assessments and optimize each generation step accordingly. Empirical results across diverse benchmarks demonstrate that SuperWriter-LM achieves state-of-the-art performance, surpassing even larger-scale baseline models in both automatic evaluation and human evaluation. Furthermore, comprehensive ablation studies demonstrate the effectiveness of hierarchical DPO and underscore the value of incorporating structured thinking steps to improve the quality of long-form text generation.","authors":["Yuhao Wu","Yushi Bai","Zhiqiang Hu","Juanzi Li","Roy Ka-Wei Lee"],"url":"https://arxiv.org/abs/2506.04180"}
{"created":"2025-06-05","title":"Long or short CoT? Investigating Instance-level Switch of Large Reasoning Models","abstract":"With the rapid advancement of large reasoning models, long Chain-of-Thought (CoT) prompting has demonstrated strong performance on complex tasks. However, this often comes with a significant increase in token usage. In this paper, we conduct a comprehensive empirical analysis comparing long and short CoT strategies. Our findings reveal that while long CoT can lead to performance improvements, its benefits are often marginal relative to its significantly higher token consumption. Specifically, long CoT tends to outperform when ample generation budgets are available, whereas short CoT is more effective under tighter budget constraints. These insights underscore the need for a dynamic approach that selects the proper CoT strategy based on task context and resource availability. To address this, we propose SwitchCoT, an automatic framework that adaptively chooses between long and short CoT strategies to balance reasoning accuracy and computational efficiency. Moreover, SwitchCoT is designed to be budget-aware, making it broadly applicable across scenarios with varying resource constraints. Experimental results demonstrate that SwitchCoT can reduce inference costs by up to 50% while maintaining high accuracy. Notably, under limited token budgets, it achieves performance comparable to, or even exceeding, that of using either long or short CoT alone.","authors":["Ruiqi Zhang","Changyi Xiao","Yixin Cao"],"url":"https://arxiv.org/abs/2506.04182"}
{"created":"2025-06-05","title":"R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning","abstract":"Large language models (LLMs) have notably progressed in multi-step and long-chain reasoning. However, extending their reasoning capabilities to encompass deep interactions with search remains a non-trivial challenge, as models often fail to identify optimal reasoning-search interaction trajectories, resulting in suboptimal responses. We propose R-Search, a novel reinforcement learning framework for Reasoning-Search integration, designed to enable LLMs to autonomously execute multi-step reasoning with deep search interaction, and learn optimal reasoning search interaction trajectories via multi-reward signals, improving response quality in complex logic- and knowledge-intensive tasks. R-Search guides the LLM to dynamically decide when to retrieve or reason, while globally integrating key evidence to enhance deep knowledge interaction between reasoning and search. During RL training, R-Search provides multi-stage, multi-type rewards to jointly optimize the reasoning-search trajectory. Experiments on seven datasets show that R-Search outperforms advanced RAG baselines by up to 32.2% (in-domain) and 25.1% (out-of-domain). The code and data are available at https://github.com/QingFei1/R-Search.","authors":["Qingfei Zhao","Ruobing Wang","Dingling Xu","Daren Zha","Limin Liu"],"url":"https://arxiv.org/abs/2506.04185"}
{"created":"2025-06-05","title":"A fast and memoryless numerical method for solving fractional differential equations","abstract":"The numerical solution of implicit and stiff differential equations by implicit numerical integrators has been largely investigated and there exist many excellent efficient codes available in the scientific community, as Radau5 (based on a Runge-Kutta collocation method at Radau points) and Dassl, based on backward differentiation formulas, among the others. When solving fractional ordinary differential equations (ODEs), the derivative operator is replaced by a non-local one and the fractional ODE is reformulated as a Volterra integral equation, to which these codes cannot be directly applied.","authors":["Nicola Guglielmi","Ernst Hairer"],"url":"https://arxiv.org/abs/2506.04188"}
{"created":"2025-06-05","title":"How to Use Graph Data in the Wild to Help Graph Anomaly Detection?","abstract":"In recent years, graph anomaly detection has found extensive applications in various domains such as social, financial, and communication networks. However, anomalies in graph-structured data present unique challenges, including label scarcity, ill-defined anomalies, and varying anomaly types, making supervised or semi-supervised methods unreliable. Researchers often adopt unsupervised approaches to address these challenges, assuming that anomalies deviate significantly from the normal data distribution. Yet, when the available data is insufficient, capturing the normal distribution accurately and comprehensively becomes difficult. To overcome this limitation, we propose to utilize external graph data (i.e., graph data in the wild) to help anomaly detection tasks. This naturally raises the question: How can we use external data to help graph anomaly detection tasks? To answer this question, we propose a framework called Wild-GAD. It is built upon a unified database, UniWildGraph, which comprises a large and diverse collection of graph data with broad domain coverage, ample data volume, and a unified feature space. Further, we develop selection criteria based on representativity and diversity to identify the most suitable external data for anomaly detection task. Extensive experiments on six real-world datasets demonstrate the effectiveness of Wild-GAD. Compared to the baseline methods, our framework has an average 18% AUCROC and 32% AUCPR improvement over the best-competing methods.","authors":["Yuxuan Cao","Jiarong Xu","Chen Zhao","Jiaan Wang","Carl Yang","Chunping Wang","Yang Yang"],"url":"https://arxiv.org/abs/2506.04190"}
{"created":"2025-06-05","title":"MACS: Multi-Agent Reinforcement Learning for Optimization of Crystal Structures","abstract":"Geometry optimization of atomic structures is a common and crucial task in computational chemistry and materials design. Following the learning to optimize paradigm, we propose a new multi-agent reinforcement learning method called Multi-Agent Crystal Structure optimization (MACS) to address periodic crystal structure optimization. MACS treats geometry optimization as a partially observable Markov game in which atoms are agents that adjust their positions to collectively discover a stable configuration. We train MACS across various compositions of reported crystalline materials to obtain a policy that successfully optimizes structures from the training compositions as well as structures of larger sizes and unseen compositions, confirming its excellent scalability and zero-shot transferability. We benchmark our approach against a broad range of state-of-the-art optimization methods and demonstrate that MACS optimizes periodic crystal structures significantly faster, with fewer energy calculations, and the lowest failure rate.","authors":["Elena Zamaraeva","Christopher M. Collins","George R. Darling","Matthew S. Dyer","Bei Peng","Rahul Savani","Dmytro Antypov","Vladimir V. Gusev","Judith Clymo","Paul G. Spirakis","Matthew J. Rosseinsky"],"url":"https://arxiv.org/abs/2506.04195"}
{"created":"2025-06-05","title":"TracLLM: A Generic Framework for Attributing Long Context LLMs","abstract":"Long context large language models (LLMs) are deployed in many real-world applications such as RAG, agent, and broad LLM-integrated applications. Given an instruction and a long context (e.g., documents, PDF files, webpages), a long context LLM can generate an output grounded in the provided context, aiming to provide more accurate, up-to-date, and verifiable outputs while reducing hallucinations and unsupported claims. This raises a research question: how to pinpoint the texts (e.g., sentences, passages, or paragraphs) in the context that contribute most to or are responsible for the generated output by an LLM? This process, which we call context traceback, has various real-world applications, such as 1) debugging LLM-based systems, 2) conducting post-attack forensic analysis for attacks (e.g., prompt injection attack, knowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources to enhance the trust of users towards outputs generated by LLMs. When applied to context traceback for long context LLMs, existing feature attribution methods such as Shapley have sub-optimal performance and/or incur a large computational cost. In this work, we develop TracLLM, the first generic context traceback framework tailored to long context LLMs. Our framework can improve the effectiveness and efficiency of existing feature attribution methods. To improve the efficiency, we develop an informed search based algorithm in TracLLM. We also develop contribution score ensemble/denoising techniques to improve the accuracy of TracLLM. Our evaluation results show TracLLM can effectively identify texts in a long context that lead to the output of an LLM. Our code and data are at: https://github.com/Wang-Yanting/TracLLM.","authors":["Yanting Wang","Wei Zou","Runpeng Geng","Jinyuan Jia"],"url":"https://arxiv.org/abs/2506.04202"}
{"created":"2025-06-05","title":"Cascadia: A Cascade Serving System for Large Language Models","abstract":"Recent advances in large language models (LLMs) have intensified the need to deliver both rapid responses and high-quality answers. More powerful models yield better results but incur higher inference latency, whereas smaller models are faster yet less capable. Recent work proposes balancing this latency-quality trade-off using model cascades, which route simpler queries to smaller models and more complex ones to larger models. However, enabling efficient cascade serving remains challenging. Current frameworks lack effective mechanisms for handling (i) the huge and varying resource demands of different LLMs, (ii) the inherent heterogeneity of LLM workloads, and (iii) the co-optimization of system deployment and routing strategy. Motivated by these observations, we introduce Cascadia, a novel cascade serving framework designed explicitly to schedule request routing and deploy model cascades for fast, quality-preserving LLM serving. Cascadia employs a bi-level optimization method: at the inner level, it uses a mixed-integer linear program to select resource allocations and parallelism strategies based on LLM information and workload characteristics; at the outer level, it applies a weighted Tchebycheff algorithm to iteratively co-optimize the routing strategy and the system deployment produced by the inner level. Our extensive evaluation on diverse workload traces and different model cascades (DeepSeek and the Llama series) demonstrates that Cascadia significantly outperforms both single-model deployments and the state-of-the-art cascade serving baseline, achieving up to 4x (2.3x on average) tighter latency SLOs and up to 5x (2.4x on average) higher throughput while maintaining target answer quality.","authors":["Youhe Jiang","Fangcheng Fu","Wanru Zhao","Stephan Rabanser","Nicholas D. Lane","Binhang Yuan"],"url":"https://arxiv.org/abs/2506.04203"}
{"created":"2025-06-05","title":"A Kernel-Based Approach for Accurate Steady-State Detection in Performance Time Series","abstract":"This paper addresses the challenge of accurately detecting the transition from the warmup phase to the steady state in performance metric time series, which is a critical step for effective benchmarking. The goal is to introduce a method that avoids premature or delayed detection, which can lead to inaccurate or inefficient performance analysis. The proposed approach adapts techniques from the chemical reactors domain, detecting steady states online through the combination of kernel-based step detection and statistical methods. By using a window-based approach, it provides detailed information and improves the accuracy of identifying phase transitions, even in noisy or irregular time series. Results show that the new approach reduces total error by 14.5% compared to the state-of-the-art method. It offers more reliable detection of the steady-state onset, delivering greater precision for benchmarking tasks. For users, the new approach enhances the accuracy and stability of performance benchmarking, efficiently handling diverse time series data. Its robustness and adaptability make it a valuable tool for real-world performance evaluation, ensuring consistent and reproducible results.","authors":["Martin Beseda","Vittorio Cortellessa","Daniele Di Pompeo","Luca Traini","Michele Tucci"],"url":"https://arxiv.org/abs/2506.04204"}
{"created":"2025-06-05","title":"EPiC: Towards Lossless Speedup for Reasoning Training through Edge-Preserving CoT Condensation","abstract":"Large language models (LLMs) have shown remarkable reasoning capabilities when trained with chain-of-thought (CoT) supervision. However, the long and verbose CoT traces, especially those distilled from large reasoning models (LRMs) such as DeepSeek-R1, significantly increase training costs during the distillation process, where a non-reasoning base model is taught to replicate the reasoning behavior of an LRM. In this work, we study the problem of CoT condensation for resource-efficient reasoning training, aimed at pruning intermediate reasoning steps (i.e., thoughts) in CoT traces, enabling supervised model training on length-reduced CoT data while preserving both answer accuracy and the model's ability to generate coherent reasoning. Our rationale is that CoT traces typically follow a three-stage structure: problem understanding, exploration, and solution convergence. Through empirical analysis, we find that retaining the structure of the reasoning trace, especially the early stage of problem understanding (rich in reflective cues) and the final stage of solution convergence, is sufficient to achieve lossless reasoning supervision. To this end, we propose an Edge-Preserving Condensation method, EPiC, which selectively retains only the initial and final segments of each CoT trace while discarding the middle portion. This design draws an analogy to preserving the \"edge\" of a reasoning trajectory, capturing both the initial problem framing and the final answer synthesis, to maintain logical continuity. Experiments across multiple model families (Qwen and LLaMA) and benchmarks show that EPiC reduces training time by over 34% while achieving lossless reasoning accuracy on MATH500, comparable to full CoT supervision. To the best of our knowledge, this is the first study to explore thought-level CoT condensation for efficient reasoning model distillation.","authors":["Jinghan Jia","Hadi Reisizadeh","Chongyu Fan","Nathalie Baracaldo","Mingyi Hong","Sijia Liu"],"url":"https://arxiv.org/abs/2506.04205"}
{"created":"2025-06-05","title":"A Few Moments Please: Scalable Graphon Learning via Moment Matching","abstract":"Graphons, as limit objects of dense graph sequences, play a central role in the statistical analysis of network data. However, existing graphon estimation methods often struggle with scalability to large networks and resolution-independent approximation, due to their reliance on estimating latent variables or costly metrics such as the Gromov-Wasserstein distance. In this work, we propose a novel, scalable graphon estimator that directly recovers the graphon via moment matching, leveraging implicit neural representations (INRs). Our approach avoids latent variable modeling by training an INR--mapping coordinates to graphon values--to match empirical subgraph counts (i.e., moments) from observed graphs. This direct estimation mechanism yields a polynomial-time solution and crucially sidesteps the combinatorial complexity of Gromov-Wasserstein optimization. Building on foundational results, we establish a theoretical guarantee: when the observed subgraph motifs sufficiently represent those of the true graphon (a condition met with sufficiently large or numerous graph samples), the estimated graphon achieves a provable upper bound in cut distance from the ground truth. Additionally, we introduce MomentMixup, a data augmentation technique that performs mixup in the moment space to enhance graphon-based learning. Our graphon estimation method achieves strong empirical performance--demonstrating high accuracy on small graphs and superior computational efficiency on large graphs--outperforming state-of-the-art scalable estimators in 75\\% of benchmark settings and matching them in the remaining cases. Furthermore, MomentMixup demonstrated improved graph classification accuracy on the majority of our benchmarks.","authors":["Reza Ramezanpour","Victor M. Tenorio","Antonio G. Marques","Ashutosh Sabharwal","Santiago Segarra"],"url":"https://arxiv.org/abs/2506.04206"}
{"created":"2025-06-05","title":"Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning","abstract":"Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex textual tasks, many works attempt to incentivize similar capabilities in Multimodal Large Language Models (MLLMs) by directly applying reinforcement learning (RL). However, they still struggle to activate complex reasoning. In this paper, rather than examining multimodal RL in isolation, we delve into current training pipelines and identify three crucial phenomena: 1) Effective cold start initialization is critical for enhancing MLLM reasoning. Intriguingly, we find that initializing with carefully selected text data alone can lead to performance surpassing many recent multimodal reasoning models, even before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers from gradient stagnation, which degrades training stability and performance. 3) Subsequent text-only RL training, following the multimodal RL phase, further enhances multimodal reasoning. This staged training approach effectively balances perceptual grounding and cognitive reasoning development. By incorporating the above insights and addressing multimodal RL issues, we introduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B MLLMs on challenging benchmarks including MathVerse, MathVision, WeMath, LogicVista, DynaMath, and challenging AIME2024 and AIME2025.","authors":["Shuang Chen","Yue Guo","Zhaochen Su","Yafu Li","Yulun Wu","Jiacheng Chen","Jiayu Chen","Weijie Wang","Xiaoye Qu","Yu Cheng"],"url":"https://arxiv.org/abs/2506.04207"}
{"created":"2025-06-05","title":"Rounding error analysis of randomized CholeskyQR2 for sparse matrices","abstract":"This work focuses on rounding error analysis of randomized CholeskyQR2 (RCholeskyQR2) for sparse matrices. We form RCholeskyQR2 with CholeskyQR2 and matrix sketching in order to accelerate CholeskyQR2 and improve its applicability by compressing the input matrix $X \\in \\mathbb{R}^{m\\times n}$. In many real-world applications, the input matrix $X$ is always sparse. In this work, we follow the model of sparse matrices proposed in \\cite{CSparse} and provide an improved rounding error analysis of RCholeskyQR2 for sparse matrices. We define a new matrix norm $\\norm{\\cdot}_{g}$ and use its properties in rounding error analysis. $\\norm{\\cdot}_{F}$ and its connections with rounding error analysis is also utilized in CholeskyQR for the first time. Our analysis is an improvement compared to that in \\cite{CSparse, error}. We provide the corresponding sufficient conditions for different types of sparse matrices based on the existence of dense columns, together with error bounds of both orthogonality and residual. Numerical experiments demonstrate our findings and show the effectiveness of matrix sketching on CholeskyQR2.","authors":["Haoran Guan","Yuwei Fan"],"url":"https://arxiv.org/abs/2506.04208"}
{"created":"2025-06-05","title":"Language-Image Alignment with Fixed Text Encoders","abstract":"Currently, the most dominant approach to establishing language-image alignment is to pre-train text and image encoders jointly through contrastive learning, such as CLIP and its variants. In this work, we question whether such a costly joint training is necessary. In particular, we investigate if a pre-trained fixed large language model (LLM) offers a good enough text encoder to guide visual representation learning. That is, we propose to learn Language-Image alignment with a Fixed Text encoder (LIFT) from an LLM by training only the image encoder. Somewhat surprisingly, through comprehensive benchmarking and ablation studies, we find that this much simplified framework LIFT is highly effective and it outperforms CLIP in most scenarios that involve compositional understanding and long captions, while achieving considerable gains in computational efficiency. Our work takes a first step towards systematically exploring how text embeddings from LLMs can guide visual learning and suggests an alternative design choice for learning language-aligned visual representations.","authors":["Jingfeng Yang","Ziyang Wu","Yue Zhao","Yi Ma"],"url":"https://arxiv.org/abs/2506.04209"}
{"created":"2025-06-05","title":"Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models","abstract":"Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1, DeepSeek R1) have led to a popular belief that extending thinking traces using prompts like \"Wait\" or \"Let me rethink\" can improve performance. This raises a natural question: Does thinking more at test-time truly lead to better reasoning? To answer this question, we perform a detailed empirical study across models and benchmarks, which reveals a consistent pattern of initial performance improvements from additional thinking followed by a decline, due to \"overthinking\". To understand this non-monotonic trend, we consider a simple probabilistic model, which reveals that additional thinking increases output variance-creating an illusion of improved reasoning while ultimately undermining precision. Thus, observed gains from \"more thinking\" are not true indicators of improved reasoning, but artifacts stemming from the connection between model uncertainty and evaluation metric. This suggests that test-time scaling through extended thinking is not an effective way to utilize the inference thinking budget. Recognizing these limitations, we introduce an alternative test-time scaling approach, parallel thinking, inspired by Best-of-N sampling. Our method generates multiple independent reasoning paths within the same inference budget and selects the most consistent response via majority vote, achieving up to 20% higher accuracy compared to extended thinking. This provides a simple yet effective mechanism for test-time scaling of reasoning models.","authors":["Soumya Suvra Ghosal","Souradip Chakraborty","Avinash Reddy","Yifu Lu","Mengdi Wang","Dinesh Manocha","Furong Huang","Mohammad Ghavamzadeh","Amrit Singh Bedi"],"url":"https://arxiv.org/abs/2506.04210"}
{"created":"2025-06-05","title":"Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object Detector","abstract":"Object detectors often suffer a decrease in performance due to the large domain gap between the training data (source domain) and real-world data (target domain). Diffusion-based generative models have shown remarkable abilities in generating high-quality and diverse images, suggesting their potential for extracting valuable feature from various domains. To effectively leverage the cross-domain feature representation of diffusion models, in this paper, we train a detector with frozen-weight diffusion model on the source domain, then employ it as a teacher model to generate pseudo labels on the unlabeled target domain, which are used to guide the supervised learning of the student model on the target domain. We refer to this approach as Diffusion Domain Teacher (DDT). By employing this straightforward yet potent framework, we significantly improve cross-domain object detection performance without compromising the inference speed. Our method achieves an average mAP improvement of 21.2% compared to the baseline on 6 datasets from three common cross-domain detection benchmarks (Cross-Camera, Syn2Real, Real2Artistic}, surpassing the current state-of-the-art (SOTA) methods by an average of 5.7% mAP. Furthermore, extensive experiments demonstrate that our method consistently brings improvements even in more powerful and complex models, highlighting broadly applicable and effective domain adaptation capability of our DDT. The code is available at https://github.com/heboyong/Diffusion-Domain-Teacher.","authors":["Boyong He","Yuxiang Ji","Zhuoyue Tan","Liaoni Wu"],"url":"https://arxiv.org/abs/2506.04211"}
{"created":"2025-06-05","title":"FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers","abstract":"Fine-grained and efficient controllability on video diffusion transformers has raised increasing desires for the applicability. Recently, In-context Conditioning emerged as a powerful paradigm for unified conditional video generation, which enables diverse controls by concatenating varying context conditioning signals with noisy video latents into a long unified token sequence and jointly processing them via full-attention, e.g., FullDiT. Despite their effectiveness, these methods face quadratic computation overhead as task complexity increases, hindering practical deployment. In this paper, we study the efficiency bottleneck neglected in original in-context conditioning video generation framework. We begin with systematic analysis to identify two key sources of the computation inefficiencies: the inherent redundancy within context condition tokens and the computational redundancy in context-latent interactions throughout the diffusion process. Based on these insights, we propose FullDiT2, an efficient in-context conditioning framework for general controllability in both video generation and editing tasks, which innovates from two key perspectives. Firstly, to address the token redundancy, FullDiT2 leverages a dynamic token selection mechanism to adaptively identify important context tokens, reducing the sequence length for unified full-attention. Additionally, a selective context caching mechanism is devised to minimize redundant interactions between condition tokens and video latents. Extensive experiments on six diverse conditional video editing and generation tasks demonstrate that FullDiT2 achieves significant computation reduction and 2-3 times speedup in averaged time cost per diffusion step, with minimal degradation or even higher performance in video generation quality. The project page is at \\href{https://fulldit2.github.io/}{https://fulldit2.github.io/}.","authors":["Xuanhua He","Quande Liu","Zixuan Ye","Wecai Ye","Qiulin Wang","Xintao Wang","Qifeng Chen","Pengfei Wan","Di Zhang","Kun Gai"],"url":"https://arxiv.org/abs/2506.04213"}
{"created":"2025-06-05","title":"Sounding that Object: Interactive Object-Aware Image to Audio Generation","abstract":"Generating accurate sounds for complex audio-visual scenes is challenging, especially in the presence of multiple objects and sound sources. In this paper, we propose an {\\em interactive object-aware audio generation} model that grounds sound generation in user-selected visual objects within images. Our method integrates object-centric learning into a conditional latent diffusion model, which learns to associate image regions with their corresponding sounds through multi-modal attention. At test time, our model employs image segmentation to allow users to interactively generate sounds at the {\\em object} level. We theoretically validate that our attention mechanism functionally approximates test-time segmentation masks, ensuring the generated audio aligns with selected objects. Quantitative and qualitative evaluations show that our model outperforms baselines, achieving better alignment between objects and their associated sounds. Project page: https://tinglok.netlify.app/files/avobject/","authors":["Tingle Li","Baihe Huang","Xiaobin Zhuang","Dongya Jia","Jiawei Chen","Yuping Wang","Zhuo Chen","Gopala Anumanchipalli","Yuxuan Wang"],"url":"https://arxiv.org/abs/2506.04214"}
{"created":"2025-06-05","title":"Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally Interdependent Multi-Agent MDPs","abstract":"Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are known to be NEXP-Complete and intractable to solve. However, for problems such as cooperative navigation, obstacle avoidance, and formation control, basic assumptions can be made about local visibility and local dependencies. The work DeWeese and Qu 2024 formalized these assumptions in the construction of the Locally Interdependent Multi-Agent MDP. In this setting, it establishes three closed-form policies that are tractable to compute in various situations and are exponentially close to optimal with respect to visibility. However, it is also shown that these solutions can have poor performance when the visibility is small and fixed, often getting stuck during simulations due to the so called \"Penalty Jittering\" phenomenon. In this work, we establish the Extended Cutoff Policy Class which is, to the best of our knowledge, the first non-trivial class of near optimal closed-form partially observable policies that are exponentially close to optimal with respect to the visibility for any Locally Interdependent Multi-Agent MDP. These policies are able to remember agents beyond their visibilities which allows them to perform significantly better in many small and fixed visibility settings, resolve Penalty Jittering occurrences, and under certain circumstances guarantee fully observable joint optimal behavior despite the partial observability. We also propose a generalized form of the Locally Interdependent Multi-Agent MDP that allows for transition dependence and extended reward dependence, then replicate our theoretical results in this setting.","authors":["Alex DeWeese","Guannan Qu"],"url":"https://arxiv.org/abs/2506.04215"}
{"created":"2025-06-05","title":"UNIC: Unified In-Context Video Editing","abstract":"Recent advances in text-to-video generation have sparked interest in generative video editing tasks. Previous methods often rely on task-specific architectures (e.g., additional adapter modules) or dedicated customizations (e.g., DDIM inversion), which limit the integration of versatile editing conditions and the unification of various editing tasks. In this paper, we introduce UNified In-Context Video Editing (UNIC), a simple yet effective framework that unifies diverse video editing tasks within a single model in an in-context manner. To achieve this unification, we represent the inputs of various video editing tasks as three types of tokens: the source video tokens, the noisy video latent, and the multi-modal conditioning tokens that vary according to the specific editing task. Based on this formulation, our key insight is to integrate these three types into a single consecutive token sequence and jointly model them using the native attention operations of DiT, thereby eliminating the need for task-specific adapter designs. Nevertheless, direct task unification under this framework is challenging, leading to severe token collisions and task confusion due to the varying video lengths and diverse condition modalities across tasks. To address these, we introduce task-aware RoPE to facilitate consistent temporal positional encoding, and condition bias that enables the model to clearly differentiate different editing tasks. This allows our approach to adaptively perform different video editing tasks by referring the source video and varying condition tokens \"in context\", and support flexible task composition. To validate our method, we construct a unified video editing benchmark containing six representative video editing tasks. Results demonstrate that our unified approach achieves superior performance on each task and exhibits emergent task composition abilities.","authors":["Zixuan Ye","Xuanhua He","Quande Liu","Qiulin Wang","Xintao Wang","Pengfei Wan","Di Zhang","Kun Gai","Qifeng Chen","Wenhan Luo"],"url":"https://arxiv.org/abs/2506.04216"}
{"created":"2025-06-05","title":"OWMM-Agent: Open World Mobile Manipulation With Multi-modal Agentic Data Synthesis","abstract":"The rapid progress of navigation, manipulation, and vision models has made mobile manipulators capable in many specialized tasks. However, the open-world mobile manipulation (OWMM) task remains a challenge due to the need for generalization to open-ended instructions and environments, as well as the systematic complexity to integrate high-level decision making with low-level robot control based on both global scene understanding and current agent state. To address this complexity, we propose a novel multi-modal agent architecture that maintains multi-view scene frames and agent states for decision-making and controls the robot by function calling. A second challenge is the hallucination from domain shift. To enhance the agent performance, we further introduce an agentic data synthesis pipeline for the OWMM task to adapt the VLM model to our task domain with instruction fine-tuning. We highlight our fine-tuned OWMM-VLM as the first dedicated foundation model for mobile manipulators with global scene understanding, robot state tracking, and multi-modal action generation in a unified model. Through experiments, we demonstrate that our model achieves SOTA performance compared to other foundation models including GPT-4o and strong zero-shot generalization in real world. The project page is at https://github.com/HHYHRHY/OWMM-Agent","authors":["Junting Chen","Haotian Liang","Lingxiao Du","Weiyun Wang","Mengkang Hu","Yao Mu","Wenhai Wang","Jifeng Dai","Ping Luo","Wenqi Shao","Lin Shao"],"url":"https://arxiv.org/abs/2506.04217"}
{"created":"2025-06-05","title":"Pseudo-Simulation for Autonomous Driving","abstract":"Existing evaluation paradigms for Autonomous Vehicles (AVs) face critical limitations. Real-world evaluation is often challenging due to safety concerns and a lack of reproducibility, whereas closed-loop simulation can face insufficient realism or high computational costs. Open-loop evaluation, while being efficient and data-driven, relies on metrics that generally overlook compounding errors. In this paper, we propose pseudo-simulation, a novel paradigm that addresses these limitations. Pseudo-simulation operates on real datasets, similar to open-loop evaluation, but augments them with synthetic observations generated prior to evaluation using 3D Gaussian Splatting. Our key idea is to approximate potential future states the AV might encounter by generating a diverse set of observations that vary in position, heading, and speed. Our method then assigns a higher importance to synthetic observations that best match the AV's likely behavior using a novel proximity-based weighting scheme. This enables evaluating error recovery and the mitigation of causal confusion, as in closed-loop benchmarks, without requiring sequential interactive simulation. We show that pseudo-simulation is better correlated with closed-loop simulations (R^2=0.8) than the best existing open-loop approach (R^2=0.7). We also establish a public leaderboard for the community to benchmark new methodologies with pseudo-simulation. Our code is available at https://github.com/autonomousvision/navsim.","authors":["Wei Cao","Marcel Hallgarten","Tianyu Li","Daniel Dauner","Xunjiang Gu","Caojun Wang","Yakov Miron","Marco Aiello","Hongyang Li","Igor Gilitschenski","Boris Ivanovic","Marco Pavone","Andreas Geiger","Kashyap Chitta"],"url":"https://arxiv.org/abs/2506.04218"}
{"created":"2025-06-05","title":"Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models","abstract":"Unlocking spatial reasoning in Large Multimodal Models (LMMs) is crucial for enabling intelligent interaction with 3D environments. While prior efforts often rely on explicit 3D inputs or specialized model architectures, we ask: can LMMs reason about 3D space using only structured 2D representations derived from perception? We introduce Struct2D, a perception-guided prompting framework that combines bird's-eye-view (BEV) images with object marks and object-centric metadata, optionally incorporating egocentric keyframes when needed. Using Struct2D, we conduct an in-depth zero-shot analysis of closed-source LMMs (e.g., GPT-o3) and find that they exhibit surprisingly strong spatial reasoning abilities when provided with structured 2D inputs, effectively handling tasks such as relative direction estimation and route planning. Building on these insights, we construct Struct2D-Set, a large-scale instruction tuning dataset with 200K fine-grained QA pairs across eight spatial reasoning categories, generated automatically from 3D indoor scenes. We fine-tune an open-source LMM (Qwen2.5VL) on Struct2D-Set, achieving competitive performance on multiple benchmarks, including 3D question answering, dense captioning, and object grounding. Our approach demonstrates that structured 2D inputs can effectively bridge perception and language reasoning in LMMs-without requiring explicit 3D representations as input. We will release both our code and dataset to support future research.","authors":["Fangrui Zhu","Hanhui Wang","Yiming Xie","Jing Gu","Tianye Ding","Jianwei Yang","Huaizu Jiang"],"url":"https://arxiv.org/abs/2506.04220"}
{"created":"2025-06-05","title":"Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset","abstract":"We introduce Oxford Day-and-Night, a large-scale, egocentric dataset for novel view synthesis (NVS) and visual relocalisation under challenging lighting conditions. Existing datasets often lack crucial combinations of features such as ground-truth 3D geometry, wide-ranging lighting variation, and full 6DoF motion. Oxford Day-and-Night addresses these gaps by leveraging Meta ARIA glasses to capture egocentric video and applying multi-session SLAM to estimate camera poses, reconstruct 3D point clouds, and align sequences captured under varying lighting conditions, including both day and night. The dataset spans over 30 $\\mathrm{km}$ of recorded trajectories and covers an area of 40,000 $\\mathrm{m}^2$, offering a rich foundation for egocentric 3D vision research. It supports two core benchmarks, NVS and relocalisation, providing a unique platform for evaluating models in realistic and diverse environments.","authors":["Zirui Wang","Wenjing Bian","Xinghui Li","Yifu Tao","Jianeng Wang","Maurice Fallon","Victor Adrian Prisacariu"],"url":"https://arxiv.org/abs/2506.04224"}
{"created":"2025-06-05","title":"Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation","abstract":"Real-world applications like video gaming and virtual reality often demand the ability to model 3D scenes that users can explore along custom camera trajectories. While significant progress has been made in generating 3D objects from text or images, creating long-range, 3D-consistent, explorable 3D scenes remains a complex and challenging problem. In this work, we present Voyager, a novel video diffusion framework that generates world-consistent 3D point-cloud sequences from a single image with user-defined camera path. Unlike existing approaches, Voyager achieves end-to-end scene generation and reconstruction with inherent consistency across frames, eliminating the need for 3D reconstruction pipelines (e.g., structure-from-motion or multi-view stereo). Our method integrates three key components: 1) World-Consistent Video Diffusion: A unified architecture that jointly generates aligned RGB and depth video sequences, conditioned on existing world observation to ensure global coherence 2) Long-Range World Exploration: An efficient world cache with point culling and an auto-regressive inference with smooth video sampling for iterative scene extension with context-aware consistency, and 3) Scalable Data Engine: A video reconstruction pipeline that automates camera pose estimation and metric depth prediction for arbitrary videos, enabling large-scale, diverse training data curation without manual 3D annotations. Collectively, these designs result in a clear improvement over existing methods in visual quality and geometric accuracy, with versatile applications.","authors":["Tianyu Huang","Wangguandong Zheng","Tengfei Wang","Yuhao Liu","Zhenwei Wang","Junta Wu","Jie Jiang","Hui Li","Rynson W. H. Lau","Wangmeng Zuo","Chunchao Guo"],"url":"https://arxiv.org/abs/2506.04225"}
{"created":"2025-06-05","title":"Efficient Knowledge Editing via Minimal Precomputation","abstract":"Knowledge editing methods like MEMIT are able to make data and compute efficient updates of factual knowledge by using a single sentence to update facts and their consequences. However, what is often overlooked is a \"precomputation step\", which requires a one-time but significant computational cost. The authors of MEMIT originally precompute approximately 44 million hidden vectors per edited layer, which requires a forward pass over 44 million tokens. For GPT-J (6B), this precomputation step takes 36 hours on a single GPU, while it takes approximately 40 hours for Llama2-7B. Additionally, this precomputation time grows with model size. In this paper, we show that this excessive computational cost is unnecessary. Knowledge editing using MEMIT and related methods, such as ROME and EMMET, can be performed by pre-computing a very small portion of the 44 million hidden vectors. We first present the theoretical minimum number of hidden vector precomputation required for solutions of these editing methods to exist. We then empirically show that knowledge editing using these methods can be done by pre-computing significantly fewer hidden vectors. Specifically, we show that the precomputation step can be done with less than 0.3% of the originally stipulated number of hidden vectors. This saves a significant amount of precomputation time and allows users to begin editing new models within a few minutes.","authors":["Akshat Gupta","Maochuan Lu","Thomas Hartvigsen","Gopala Anumanchipalli"],"url":"https://arxiv.org/abs/2506.04226"}
{"created":"2025-06-05","title":"Object-centric 3D Motion Field for Robot Learning from Human Videos","abstract":"Learning robot control policies from human videos is a promising direction for scaling up robot learning. However, how to extract action knowledge (or action representations) from videos for policy learning remains a key challenge. Existing action representations such as video frames, pixelflow, and pointcloud flow have inherent limitations such as modeling complexity or loss of information. In this paper, we propose to use object-centric 3D motion field to represent actions for robot learning from human videos, and present a novel framework for extracting this representation from videos for zero-shot control. We introduce two novel components in its implementation. First, a novel training pipeline for training a ''denoising'' 3D motion field estimator to extract fine object 3D motions from human videos with noisy depth robustly. Second, a dense object-centric 3D motion field prediction architecture that favors both cross-embodiment transfer and policy generalization to background. We evaluate the system in real world setups. Experiments show that our method reduces 3D motion estimation error by over 50% compared to the latest method, achieve 55% average success rate in diverse tasks where prior approaches fail~($\\lesssim 10$\\%), and can even acquire fine-grained manipulation skills like insertion.","authors":["Zhao-Heng Yin","Sherry Yang","Pieter Abbeel"],"url":"https://arxiv.org/abs/2506.04227"}
{"created":"2025-06-05","title":"LayerFlow: A Unified Model for Layer-aware Video Generation","abstract":"We present LayerFlow, a unified solution for layer-aware video generation. Given per-layer prompts, LayerFlow generates videos for the transparent foreground, clean background, and blended scene. It also supports versatile variants like decomposing a blended video or generating the background for the given foreground and vice versa. Starting from a text-to-video diffusion transformer, we organize the videos for different layers as sub-clips, and leverage layer embeddings to distinguish each clip and the corresponding layer-wise prompts. In this way, we seamlessly support the aforementioned variants in one unified framework. For the lack of high-quality layer-wise training videos, we design a multi-stage training strategy to accommodate static images with high-quality layer annotations. Specifically, we first train the model with low-quality video data. Then, we tune a motion LoRA to make the model compatible with static frames. Afterward, we train the content LoRA on the mixture of image data with high-quality layered images along with copy-pasted video data. During inference, we remove the motion LoRA thus generating smooth videos with desired layers.","authors":["Sihui Ji","Hao Luo","Xi Chen","Yuanpeng Tu","Yiyang Wang","Hengshuang Zhao"],"url":"https://arxiv.org/abs/2506.04228"}
{"created":"2025-06-05","title":"StatWhy: Formal Verification Tool for Statistical Hypothesis Testing Programs","abstract":"Statistical methods have been widely misused and misinterpreted in various scientific fields, raising significant concerns about the integrity of scientific research. To mitigate this problem, we propose a tool-assisted method for formally specifying and automatically verifying the correctness of statistical programs. In this method, programmers are required to annotate the source code of the statistical programs with the requirements for these methods. Through this annotation, they are reminded to check the requirements for statistical methods, including those that cannot be formally verified, such as the distribution of the unknown true population. Our software tool StatWhy automatically checks whether programmers have properly specified the requirements for the statistical methods, thereby identifying any missing requirements that need to be addressed. This tool is implemented using the Why3 platform to verify the correctness of OCaml programs that conduct statistical hypothesis testing. We demonstrate how StatWhy can be used to avoid common errors in various statistical hypothesis testing programs.","authors":["Yusuke Kawamoto","Kentaro Kobayashi","Kohei Suenaga"],"url":"https://arxiv.org/abs/2405.17492"}
{"created":"2025-06-05","title":"mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation","abstract":"Large Vision-Language Models (LVLMs) have made remarkable strides in multimodal tasks such as visual question answering, visual grounding, and complex reasoning. However, they remain limited by static training data, susceptibility to hallucinations, and inability to verify claims against up-to-date, external evidence, compromising their performance in dynamic real-world applications. Retrieval-Augmented Generation (RAG) offers a practical solution to mitigate these challenges by allowing the LVLMs to access large-scale knowledge databases via retrieval mechanisms, thereby grounding model outputs in factual, contextually relevant information. Here in this paper, we conduct the first systematic dissection of the multimodal RAG pipeline for LVLMs, explicitly investigating (1) the retrieval phase: on the modality configurations and retrieval strategies, (2) the re-ranking stage: on strategies to mitigate positional biases and improve the relevance of retrieved evidence, and (3) the generation phase: we further investigate how to best integrate retrieved candidates into the final generation process. Finally, we extend to explore a unified agentic framework that integrates re-ranking and generation through self-reflection, enabling LVLMs to select relevant evidence and suppress irrelevant context dynamically. Our full-stack exploration of RAG for LVLMs yields substantial insights, resulting in an average performance boost of 5% without any fine-tuning.","authors":["Chan-Wei Hu","Yueqi Wang","Shuo Xing","Chia-Ju Chen","Zhengzhong Tu"],"url":"https://arxiv.org/abs/2505.24073"}
{"created":"2025-06-05","title":"Adaptive and Robust Image Processing on CubeSats","abstract":"CubeSats offer a low-cost platform for space research, particularly for Earth observation. However, their resource-constrained nature and being in space, challenge the flexibility and complexity of the deployed image processing pipelines and their orchestration. This paper introduces two novel systems, DIPP and DISH, to address these challenges. DIPP is a modular and configurable image processing pipeline framework that allows for adaptability to changing mission goals even after deployment, while preserving robustness. DISH is a domain-specific language (DSL) and runtime system designed to schedule complex imaging workloads on low-power and memory-constrained processors.","authors":["Robert Bayer","Julian Priest","Daniel Kjellberg","Jeppe Lindhard","Nikolaj S{\\o}renesen","Nicolaj Valsted","\\'Ivar \\'Oli","P{\\i}nar T\\\"oz\\\"un"],"url":"https://arxiv.org/abs/2506.03152"}
{"created":"2025-06-05","title":"Why Regression? Binary Encoding Classification Brings Confidence to Stock Market Index Price Prediction","abstract":"Stock market indices serve as fundamental market measurement that quantify systematic market dynamics. However, accurate index price prediction remains challenging, primarily because existing approaches treat indices as isolated time series and frame the prediction as a simple regression task. These methods fail to capture indices' inherent nature as aggregations of constituent stocks with complex, time-varying interdependencies. To address these limitations, we propose Cubic, a novel end-to-end framework that explicitly models the adaptive fusion of constituent stocks for index price prediction. Our main contributions are threefold. i) Fusion in the latent space: we introduce the fusion mechanism over the latent embedding of the stocks to extract the information from the vast number of stocks. ii) Binary encoding classification: since regression tasks are challenging due to continuous value estimation, we reformulate the regression into the classification task, where the target value is converted to binary and we optimize the prediction of the value of each digit with cross-entropy loss. iii) Confidence-guided prediction and trading: we introduce the regularization loss to address market prediction uncertainty for the index prediction and design the rule-based trading policies based on the confidence. Extensive experiments across multiple stock markets and indices demonstrate that Cubic consistently outperforms state-of-the-art baselines in stock index prediction tasks, achieving superior performance on both forecasting accuracy metrics and downstream trading profitability.","authors":["Junzhe Jiang","Chang Yang","Xinrun Wang","Bo Li"],"url":"https://arxiv.org/abs/2506.03153"}
{"created":"2025-06-05","title":"UniSim: A Unified Simulator for Time-Coarsened Dynamics of Biomolecules","abstract":"Molecular Dynamics (MD) simulations are essential for understanding the atomic-level behavior of molecular systems, giving insights into their transitions and interactions. However, classical MD techniques are limited by the trade-off between accuracy and efficiency, while recent deep learning-based improvements have mostly focused on single-domain molecules, lacking transferability to unfamiliar molecular systems. Therefore, we propose \\textbf{Uni}fied \\textbf{Sim}ulator (UniSim), which leverages cross-domain knowledge to enhance the understanding of atomic interactions. First, we employ a multi-head pretraining approach to learn a unified atomic representation model from a large and diverse set of molecular data. Then, based on the stochastic interpolant framework, we learn the state transition patterns over long timesteps from MD trajectories, and introduce a force guidance module for rapidly adapting to different chemical environments. Our experiments demonstrate that UniSim achieves highly competitive performance across small molecules, peptides, and proteins.","authors":["Ziyang Yu","Wenbing Huang","Yang Liu"],"url":"https://arxiv.org/abs/2506.03157"}
{"created":"2025-06-05","title":"Super-temporal-resolution Photoacoustic Imaging with Dynamic Reconstruction through Implicit Neural Representation in Sparse-view","abstract":"Dynamic Photoacoustic Computed Tomography (PACT) is an important imaging technique for monitoring physiological processes, capable of providing high-contrast images of optical absorption at much greater depths than traditional optical imaging methods. However, practical instrumentation and geometric constraints limit the number of acoustic sensors available around the imaging target, leading to sparsity in sensor data. Traditional photoacoustic (PA) image reconstruction methods, when directly applied to sparse PA data, produce severe artifacts. Additionally, these traditional methods do not consider the inter-frame relationships in dynamic imaging. Temporal resolution is crucial for dynamic photoacoustic imaging, which is fundamentally limited by the low repetition rate (e.g., 20 Hz) and high cost of high-power laser technology. Recently, Implicit Neural Representation (INR) has emerged as a powerful deep learning tool for solving inverse problems with sparse data, by characterizing signal properties as continuous functions of their coordinates in an unsupervised manner. In this work, we propose an INR-based method to improve dynamic photoacoustic image reconstruction from sparse-views and enhance temporal resolution, using only spatiotemporal coordinates as input. Specifically, the proposed INR represents dynamic photoacoustic images as implicit functions and encodes them into a neural network. The weights of the network are learned solely from the acquired sparse sensor data, without the need for external training datasets or prior images. Benefiting from the strong implicit continuity regularization provided by INR, as well as explicit regularization for low-rank and sparsity, our proposed method outperforms traditional reconstruction methods under two different sparsity conditions, effectively suppressing artifacts and ensuring image quality.","authors":["Youshen Xiao","Yiling Shi","Ruixi Sun","Hongjiang Wei","Fei Gao","Yuyao Zhang"],"url":"https://arxiv.org/abs/2506.03175"}
{"created":"2025-06-05","title":"Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population","abstract":"This study presents a deep learning system for breast cancer detection in mammography, developed using a modified EfficientNetV2 architecture with enhanced attention mechanisms. The model was trained on mammograms from a major Thai medical center and validated on three distinct datasets: an in-domain test set (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain generalizability set (761 cases) collected from two different hospitals. For cancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the respective datasets. The system's lesion localization capability, evaluated using metrics including Lesion Localization Fraction (LLF) and Non-Lesion Localization Fraction (NLF), demonstrated robust performance in identifying suspicious regions. Clinical validation through concordance tests showed strong agreement with radiologists: 83.5% classification and 84.0% localization concordance for biopsy-confirmed cases, and 78.1% classification and 79.6% localization concordance for out-of-domain cases. Expert radiologists' acceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for out-of-domain cases. The system achieved a System Usability Scale score of 74.17 for source hospital, and 69.20 for validation hospitals, indicating good clinical acceptance. These results demonstrate the model's effectiveness in assisting mammogram interpretation, with the potential to enhance breast cancer screening workflows in clinical practice.","authors":["Isarun Chamveha","Supphanut Chaiyungyuen","Sasinun Worakriangkrai","Nattawadee Prasawang","Warasinee Chaisangmongkon","Pornpim Korpraphong","Voraparee Suvannarerg","Shanigarn Thiravit","Chalermdej Kannawat","Kewalin Rungsinaporn","Suwara Issaragrisil","Payia Chadbunchachai","Pattiya Gatechumpol","Chawiporn Muktabhant","Patarachai Sereerat"],"url":"https://arxiv.org/abs/2506.03177"}
{"created":"2025-06-05","title":"LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning","abstract":"Automated radiology report generation holds significant potential to reduce radiologists' workload and enhance diagnostic accuracy. However, generating precise and clinically meaningful reports from chest radiographs remains challenging due to the complexity of medical language and the need for contextual understanding. Existing models often struggle with maintaining both accuracy and contextual relevance. In this paper, we present LLaMA-XR, a novel framework that integrates LLaMA 3.1 with DenseNet-121-based image embeddings and Quantized Low-Rank Adaptation (QLoRA) fine-tuning. LLaMA-XR achieves improved coherence and clinical accuracy while maintaining computational efficiency. This efficiency is driven by an optimization strategy that enhances parameter utilization and reduces memory overhead, enabling faster report generation with lower computational resource demands. Extensive experiments conducted on the IU X-ray benchmark dataset demonstrate that LLaMA-XR outperforms a range of state-of-the-art methods. Our model achieves a ROUGE-L score of 0.433 and a METEOR score of 0.336, establishing new performance benchmarks in the domain. These results underscore LLaMA-XR's potential as an effective and efficient AI system for automated radiology reporting, offering enhanced clinical utility and reliability.","authors":["Md. Zihad Bin Jahangir","Muhammad Ashad Kabir","Sumaiya Akter","Israt Jahan","Minh Chau"],"url":"https://arxiv.org/abs/2506.03178"}
{"created":"2025-06-05","title":"Dc-EEMF: Pushing depth-of-field limit of photoacoustic microscopy via decision-level constrained learning","abstract":"Photoacoustic microscopy holds the potential to measure biomarkers' structural and functional status without labels, which significantly aids in comprehending pathophysiological conditions in biomedical research. However, conventional optical-resolution photoacoustic microscopy (OR-PAM) is hindered by a limited depth-of-field (DoF) due to the narrow depth range focused on a Gaussian beam. Consequently, it fails to resolve sufficient details in the depth direction. Herein, we propose a decision-level constrained end-to-end multi-focus image fusion (Dc-EEMF) to push DoF limit of PAM. The DC-EEMF method is a lightweight siamese network that incorporates an artifact-resistant channel-wise spatial frequency as its feature fusion rule. The meticulously crafted U-Net-based perceptual loss function for decision-level focus properties in end-to-end fusion seamlessly integrates the complementary advantages of spatial domain and transform domain methods within Dc-EEMF. This approach can be trained end-to-end without necessitating post-processing procedures. Experimental results and numerical analyses collectively demonstrate our method's robust performance, achieving an impressive fusion result for PAM images without a substantial sacrifice in lateral resolution. The utilization of Dc-EEMF-powered PAM has the potential to serve as a practical tool in preclinical and clinical studies requiring extended DoF for various applications.","authors":["Wangting Zhou","Jiangshan He","Tong Cai","Lin Wang","Zhen Yuan","Xunbin Wei","Xueli Chen"],"url":"https://arxiv.org/abs/2506.03181"}
{"created":"2025-06-05","title":"Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study","abstract":"Physics-driven artificial intelligence (PD-AI) reconstruction methods have emerged as the state-of-the-art for accelerating MRI scans, enabling higher spatial and temporal resolutions. However, the high resolution of these scans generates massive data volumes, leading to challenges in transmission, storage, and real-time processing. This is particularly pronounced in functional MRI, where hundreds of volumetric acquisitions further exacerbate these demands. Edge computing with FPGAs presents a promising solution for enabling PD-AI reconstruction near the MRI sensors, reducing data transfer and storage bottlenecks. However, this requires optimization of PD-AI models for hardware efficiency through quantization and bypassing traditional FFT-based approaches, which can be a limitation due to their computational demands. In this work, we propose a novel PD-AI computational MRI approach optimized for FPGA-based edge computing devices, leveraging 8-bit complex data quantization and eliminating redundant FFT/IFFT operations. Our results show that this strategy improves computational efficiency while maintaining reconstruction quality comparable to conventional PD-AI methods, and outperforms standard clinical methods. Our approach presents an opportunity for high-resolution MRI reconstruction on resource-constrained devices, highlighting its potential for real-world deployment.","authors":["Ya\\c{s}ar Utku Al\\c{c}alar","Yu Cao","Mehmet Ak\\c{c}akaya"],"url":"https://arxiv.org/abs/2506.03183"}
{"created":"2025-06-05","title":"DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset","abstract":"Pathologists comprehensive evaluation of donor liver biopsies provides crucial information for accepting or discarding potential grafts. However, rapidly and accurately obtaining these assessments intraoperatively poses a significant challenge for pathologists. Features in donor liver biopsies, such as portal tract fibrosis, total steatosis, macrovesicular steatosis, and hepatocellular ballooning are correlated with transplant outcomes, yet quantifying these indicators suffers from substantial inter- and intra-observer variability. To address this, we introduce DLiPath, the first benchmark for comprehensive donor liver assessment based on a histopathology image dataset. We collected and publicly released 636 whole slide images from 304 donor liver patients at the Department of Pathology, the Third Xiangya Hospital, with expert annotations for key pathological features (including cholestasis, portal tract fibrosis, portal inflammation, total steatosis, macrovesicular steatosis, and hepatocellular ballooning). We selected nine state-of-the-art multiple-instance learning (MIL) models based on the DLiPath dataset as baselines for extensive comparative analysis. The experimental results demonstrate that several MIL models achieve high accuracy across donor liver assessment indicators on DLiPath, charting a clear course for future automated and intelligent donor liver assessment research. Data and code are available at https://github.com/panliangrui/ACM_MM_2025.","authors":["Liangrui Pan","Xingchen Li","Zhongyi Chen","Ling Chu","Shaoliang Peng"],"url":"https://arxiv.org/abs/2506.03185"}
{"created":"2025-06-05","title":"Lightweight Convolutional Neural Networks for Retinal Disease Classification","abstract":"Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH) significantly impact vision and affect millions worldwide. Early detection is crucial, as DR, a complication of diabetes, damages retinal blood vessels, potentially leading to blindness, while MH disrupts central vision, affecting tasks like reading and facial recognition. This paper employed two lightweight and efficient Convolution Neural Network architectures, MobileNet and NASNetMobile, for the classification of Normal, DR, and MH retinal images. The models were trained on the RFMiD dataset, consisting of 3,200 fundus images, after undergoing preprocessing steps such as resizing, normalization, and augmentation. To address data scarcity, this study leveraged transfer learning and data augmentation techniques, enhancing model generalization and performance. The experimental results demonstrate that MobileNetV2 achieved the highest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5% accuracy. These findings highlight the effectiveness of CNNs in retinal disease classification, providing a foundation for AI-assisted ophthalmic diagnosis and early intervention.","authors":["Duaa Kareem Qasim","Sabah Abdulazeez Jebur","Lafta Raheem Ali","Abdul Jalil M. Khalaf","Abir Jaafar Hussain"],"url":"https://arxiv.org/abs/2506.03186"}
{"created":"2025-06-05","title":"Multi-Analyte, Swab-based Automated Wound Monitor with AI","abstract":"Diabetic foot ulcers (DFUs), a class of chronic wounds, affect ~750,000 individuals every year in the US alone and identifying non-healing DFUs that develop to chronic wounds early can drastically reduce treatment costs and minimize risks of amputation. There is therefore a pressing need for diagnostic tools that can detect non-healing DFUs early. We develop a low cost, multi-analyte 3D printed assays seamlessly integrated on swabs that can identify non-healing DFUs and a Wound Sensor iOS App - an innovative mobile application developed for the controlled acquisition and automated analysis of wound sensor data. By comparing both the original base image (before exposure to the wound) and the wound-exposed image, we developed automated computer vision techniques to compare density changes between the two assay images, which allow us to automatically determine the severity of the wound. The iOS app ensures accurate data collection and presents actionable insights, despite challenges such as variations in camera configurations and ambient conditions. The proposed integrated sensor and iOS app will allow healthcare professionals to monitor wound conditions real-time, track healing progress, and assess critical parameters related to wound care.","authors":["Madhu Babu Sikha","Lalith Appari","Gurudatt Nanjanagudu Ganesh","Amay Bandodkar","Imon Banerjee"],"url":"https://arxiv.org/abs/2506.03188"}
{"created":"2025-06-05","title":"Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers","abstract":"While echocardiography and MRI are clinical standards for evaluating cardiac structure, their use is limited by cost and accessibility.We introduce a direct classification framework that predicts severe left ventricular hypertrophy from chest X-rays, without relying on anatomical measurements or demographic inputs. Our approach achieves high AUROC and AUPRC, and employs Mutual Information Neural Estimation to quantify feature expressivity. This reveals clinically meaningful attribute encoding and supports transparent model interpretation.","authors":["Basudha Pal","Rama Chellappa","Muhammad Umair"],"url":"https://arxiv.org/abs/2506.03192"}
{"created":"2025-06-05","title":"Quantum Cognition Machine Learning for Forecasting Chromosomal Instability","abstract":"The accurate prediction of chromosomal instability from the morphology of circulating tumor cells (CTCs) enables real-time detection of CTCs with high metastatic potential in the context of liquid biopsy diagnostics. However, it presents a significant challenge due to the high dimensionality and complexity of single-cell digital pathology data. Here, we introduce the application of Quantum Cognition Machine Learning (QCML), a quantum-inspired computational framework, to estimate morphology-predicted chromosomal instability in CTCs from patients with metastatic breast cancer. QCML leverages quantum mechanical principles to represent data as state vectors in a Hilbert space, enabling context-aware feature modeling, dimensionality reduction, and enhanced generalization without requiring curated feature selection. QCML outperforms conventional machine learning methods when tested on out of sample verification CTCs, achieving higher accuracy in identifying predicted large-scale state transitions (pLST) status from CTC-derived morphology features. These preliminary findings support the application of QCML as a novel machine learning tool with superior performance in high-dimensional, low-sample-size biomedical contexts. QCML enables the simulation of cognition-like learning for the identification of biologically meaningful prediction of chromosomal instability from CTC morphology, offering a novel tool for CTC classification in liquid biopsy.","authors":["Giuseppe Di Caro","Vahagn Kirakosyan","Alexander G. Abanov","Luca Candelori","Nadine Hartmann","Ernest T. Lam","Kharen Musaelian","Ryan Samson","Dario Villani","Martin T. Wells","Richard J. Wenstrup","Mengjia Xu"],"url":"https://arxiv.org/abs/2506.03199"}
{"created":"2025-06-05","title":"A combined Machine Learning and Finite Element Modelling tool for the surgical planning of craniosynostosis correction","abstract":"Craniosynostosis is a medical condition that affects the growth of babies' heads, caused by an early fusion of cranial sutures. In recent decades, surgical treatments for craniosynostosis have significantly improved, leading to reduced invasiveness, faster recovery, and less blood loss. At Great Ormond Street Hospital (GOSH), the main surgical treatment for patients diagnosed with sagittal craniosynostosis (SC) is spring assisted cranioplasty (SAC). This procedure involves a 15x15 mm2 osteotomy, where two springs are inserted to induce distraction. Despite the numerous advantages of this surgical technique for patients, the outcome remains unpredictable due to the lack of efficient preoperative planning tools. The surgeon's experience and the baby's age are currently relied upon to determine the osteotomy location and spring selection. Previous tools for predicting the surgical outcome of SC relied on finite element modeling (FEM), which involved computed tomography (CT) imaging and required engineering expertise and lengthy calculations. The main goal of this research is to develop a real-time prediction tool for the surgical outcome of patients, eliminating the need for CT scans to minimise radiation exposure during preoperative planning. The proposed methodology involves creating personalised synthetic skulls based on three-dimensional (3D) photographs, incorporating population average values of suture location, skull thickness, and soft tissue properties. A machine learning (ML) surrogate model is employed to achieve the desired surgical outcome. The resulting multi-output support vector regressor model achieves a R2 metric of 0.95 and MSE and MAE below 0.13. Furthermore, in the future, this model could not only simulate various surgical scenarios but also provide optimal parameters for achieving a maximum cranial index (CI).","authors":["Itxasne Ant\\'unez S\\'aenz","Ane Alberdi Aramendi","David Dunaway","Juling Ong","Lara Deli\\`ege","Amparo S\\'aenz","Anita Ahmadi Birjandi","Noor UI Owase Jeelani","Silvia Schievano","Alessandro Borghi"],"url":"https://arxiv.org/abs/2506.03202"}
{"created":"2025-06-05","title":"Predicting Postoperative Stroke in Elderly SICU Patients: An Interpretable Machine Learning Model Using MIMIC Data","abstract":"Postoperative stroke remains a critical complication in elderly surgical intensive care unit (SICU) patients, contributing to prolonged hospitalization, elevated healthcare costs, and increased mortality. Accurate early risk stratification is essential to enable timely intervention and improve clinical outcomes. We constructed a combined cohort of 19,085 elderly SICU admissions from the MIMIC-III and MIMIC-IV databases and developed an interpretable machine learning (ML) framework to predict in-hospital stroke using clinical data from the first 24 hours of Intensive Care Unit (ICU) stay. The preprocessing pipeline included removal of high-missingness features, iterative Singular Value Decomposition (SVD) imputation, z-score normalization, one-hot encoding, and class imbalance correction via the Adaptive Synthetic Sampling (ADASYN) algorithm. A two-stage feature selection process-combining Recursive Feature Elimination with Cross-Validation (RFECV) and SHapley Additive exPlanations (SHAP)-reduced the initial 80 variables to 20 clinically informative predictors. Among eight ML models evaluated, CatBoost achieved the best performance with an AUROC of 0.8868 (95% CI: 0.8802--0.8937). SHAP analysis and ablation studies identified prior cerebrovascular disease, serum creatinine, and systolic blood pressure as the most influential risk factors. Our results highlight the potential of interpretable ML approaches to support early detection of postoperative stroke and inform decision-making in perioperative critical care.","authors":["Tinghuan Li","Shuheng Chen","Junyi Fan","Elham Pishgar","Kamiar Alaei","Greg Placencia","Maryam Pishgar"],"url":"https://arxiv.org/abs/2506.03209"}
{"created":"2025-06-05","title":"A Pre-trained Framework for Multilingual Brain Decoding Using Non-invasive Recordings","abstract":"Brain-computer interfaces (BCIs) with speech decoding from brain recordings have broad application potential in fields such as clinical rehabilitation and cognitive neuroscience. However, current decoding methods remain limited to single-language, single-subject, and single neuroimaging modality settings, restricting their clinical applicability and generalizability. Here we propose a joint multilingual, multi-subject and multimodal decoding framework. It maps diverse brain recordings into a unified semantic space defined by a pre-trained multilingual model (PMM), enabling decoding across multiple languages, multiple subjects and multiple neuroimaging modalities. The proposed framework is validated using non-invasive brain recordings from 159 participants across four languages. Experimental results show that it exhibits strong generalization across multilingual, multi-subject, and multimodal settings. More importantly, the proposed framework can promote linguistic fairness, which is vital for underrepresented languages in BCI applications. The unified semantic space enables cross-lingual mapping enhancement, allowing the framework to boost the decoding performance of underrepresented languages, thereby promoting linguistic fairness. Overall, the proposed framework establishes a new potential paradigm for brain decoding, opening new paths for broader applications of BCI.","authors":["Yi Guo","Yihang Dong","Michael Kwok-Po Ng","Shuqiang Wang"],"url":"https://arxiv.org/abs/2506.03214"}
{"created":"2025-06-05","title":"A Survey of Deep Learning Video Super-Resolution","abstract":"Video super-resolution (VSR) is a prominent research topic in low-level computer vision, where deep learning technologies have played a significant role. The rapid progress in deep learning and its applications in VSR has led to a proliferation of tools and techniques in the literature. However, the usage of these methods is often not adequately explained, and decisions are primarily driven by quantitative improvements. Given the significance of VSR's potential influence across multiple domains, it is imperative to conduct a comprehensive analysis of the elements and deep learning methodologies employed in VSR research. This methodical analysis will facilitate the informed development of models tailored to specific application needs. In this paper, we present an overarching overview of deep learning-based video super-resolution models, investigating each component and discussing its implications. Furthermore, we provide a synopsis of key components and technologies employed by state-of-the-art and earlier VSR models. By elucidating the underlying methodologies and categorising them systematically, we identified trends, requirements, and challenges in the domain. As a first-of-its-kind survey of deep learning-based VSR models, this work also establishes a multi-level taxonomy to guide current and future VSR research, enhancing the maturation and interpretation of VSR practices for various practical applications.","authors":["Arbind Agrahari Baniya","Tsz-Kwan Lee","Peter Eklund","Sunil Aryal"],"url":"https://arxiv.org/abs/2506.03216"}
{"created":"2025-06-05","title":"petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI","abstract":"INTRODUCTION: Quantification of amyloid plaques (A), neurofibrillary tangles (T2), and neurodegeneration (N) using PET and MRI is critical for Alzheimer's disease (AD) diagnosis and prognosis. Existing pipelines face limitations regarding processing time, variability in tracer types, and challenges in multimodal integration.","authors":["Pierrick Coup\\'e","Boris Mansencal","Flor\\'eal Morandat","Sergio Morell-Ortega","Nicolas Villain","Jose V. Manj\\'on","Vincent Planche"],"url":"https://arxiv.org/abs/2506.03217"}
{"created":"2025-06-05","title":"Pivoting the paradigm: the role of spreadsheets in K-12 data science","abstract":"Spreadsheet tools are widely accessible to and commonly used by K-12 students and teachers. They have an important role in data collection and organization. Beyond data organization, spreadsheets also make data visible and easy to interact with, facilitating student engagement in data exploration and analysis. Though not suitable for all circumstances, spreadsheets can and do help foster data and computing skills for K-12 students. This paper 1) reviews prior frameworks on K-12 data tools; 2) proposes data-driven learning outcomes that can be accomplished by incorporating spreadsheets into the curriculum; and 3) discusses how spreadsheets can help develop data acumen and computational fluency. We provide example class activities, identify challenges and barriers to adoption, suggest pedagogical approaches to ease the learning curve for instructors and students, and discuss the need for professional development to facilitate deeper use of spreadsheets for data science and STEM disciplines.","authors":["Oren Tirschwell","Nicholas Jon Horton"],"url":"https://arxiv.org/abs/2506.03232"}
{"created":"2025-06-05","title":"UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection","abstract":"The detection of ligand binding sites for proteins is a fundamental step in Structure-Based Drug Design. Despite notable advances in recent years, existing methods, datasets, and evaluation metrics are confronted with several key challenges: (1) current datasets and methods are centered on individual protein-ligand complexes and neglect that diverse binding sites may exist across multiple complexes of the same protein, introducing significant statistical bias; (2) ligand binding site detection is typically modeled as a discontinuous workflow, employing binary segmentation and subsequent clustering algorithms; (3) traditional evaluation metrics do not adequately reflect the actual performance of different binding site prediction methods. To address these issues, we first introduce UniSite-DS, the first UniProt (Unique Protein)-centric ligand binding site dataset, which contains 4.81 times more multi-site data and 2.08 times more overall data compared to the previously most widely used datasets. We then propose UniSite, the first end-to-end ligand binding site detection framework supervised by set prediction loss with bijective matching. In addition, we introduce Average Precision based on Intersection over Union (IoU) as a more accurate evaluation metric for ligand binding site prediction. Extensive experiments on UniSite-DS and several representative benchmark datasets demonstrate that IoU-based Average Precision provides a more accurate reflection of prediction quality, and that UniSite outperforms current state-of-the-art methods in ligand binding site detection. The dataset and codes will be made publicly available at https://github.com/quanlin-wu/unisite.","authors":["Jigang Fan","Quanlin Wu","Shengjie Luo","Liwei Wang"],"url":"https://arxiv.org/abs/2506.03237"}
{"created":"2025-06-05","title":"Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach","abstract":"Automated interpretation of CT images-particularly localizing and describing abnormal findings across multi-plane and whole-body scans-remains a significant challenge in clinical radiology. This work aims to address this challenge through four key contributions: (i) On taxonomy, we collaborate with senior radiologists to propose a comprehensive hierarchical classification system, with 404 representative abnormal findings across all body regions; (ii) On data, we contribute a dataset containing over 14.5K CT images from multiple planes and all human body regions, and meticulously provide grounding annotations for over 19K abnormalities, each linked to the detailed description and cast into the taxonomy; (iii) On model development, we propose OminiAbnorm-CT, which can automatically ground and describe abnormal findings on multi-plane and whole-body CT images based on text queries, while also allowing flexible interaction through visual prompts; (iv) On benchmarks, we establish three representative evaluation tasks based on real clinical scenarios. Through extensive experiments, we show that OminiAbnorm-CT can significantly outperform existing methods on all the tasks and metrics.","authors":["Ziheng Zhao","Lisong Dai","Ya Zhang","Yanfeng Wang","Weidi Xie"],"url":"https://arxiv.org/abs/2506.03238"}
{"created":"2025-06-05","title":"Investigating Quantum Feature Maps in Quantum Support Vector Machines for Lung Cancer Classification","abstract":"In recent years, quantum machine learning has emerged as a promising intersection between quantum physics and artificial intelligence, particularly in domains requiring advanced pattern recognition such as healthcare. This study investigates the effectiveness of Quantum Support Vector Machines (QSVM), which leverage quantum mechanical phenomena like superposition and entanglement to construct high-dimensional Hilbert spaces for data classification. Focusing on lung cancer diagnosis, a concrete and critical healthcare application, we analyze how different quantum feature maps influence classification performance. Using a real-world dataset of 309 patient records with significant class imbalance (39 non-cancer vs. 270 cancer cases), we constructed six balanced subsets for robust evaluation. QSVM models were implemented using Qiskit and executed on the qasm simulator, employing three distinct quantum feature maps: ZFeatureMap, ZZFeatureMap, and PauliFeatureMap. Performance was assessed using accuracy, precision, recall, specificity, and F1-score. Results show that the PauliFeatureMap consistently outperformed the others, achieving perfect classification in three subsets and strong performance overall. These findings demonstrate how quantum computational principles can be harnessed to enhance diagnostic capabilities, reinforcing the importance of physics-based modeling in emerging AI applications within healthcare.","authors":["My Youssef El Hafidi","Achraf Toufah","Mohamed Achraf Kadim"],"url":"https://arxiv.org/abs/2506.03272"}
{"created":"2025-06-05","title":"Guided modes of helical waveguides","abstract":"This paper studies guided transverse scalar modes propagating through helically coiled waveguides. Modeling the modes as solutions of the Helmholtz equation within the three-dimensional (3D) waveguide geometry, a propagation ansatz transforms the mode-finding problem into a 3D quadratic eigenproblem. Through an untwisting map, the problem is shown to be equivalent to a 3D quadratic eigenproblem on a straightened configuration. Next, exploiting the constant torsion and curvature of the Frenet frame of a circular helix, the 3D eigenproblem is further reduced to a two-dimensional (2D) eigenproblem on the waveguide cross section. All three eigenproblems are numerically treated. As expected, significant computational savings are realized in the 2D model. A few nontrivial numerical techniques are needed to make the computation of modes within the 3D geometry feasible. They are presented along with a procedure to effectively filter out unwanted non-propagating eigenfunctions. Computational results show that the geometric effect of coiling is to shift the localization of guided modes away from the coiling center. The variations in modes as coiling pitch is changed are reported considering the example of a coiled optical fiber.","authors":["Jay Gopalakrishnan","Michael Neunteufel"],"url":"https://arxiv.org/abs/2506.03276"}
{"created":"2025-06-05","title":"Structural Vibration Monitoring with Diffractive Optical Processors","abstract":"Structural Health Monitoring (SHM) is vital for maintaining the safety and longevity of civil infrastructure, yet current solutions remain constrained by cost, power consumption, scalability, and the complexity of data processing. Here, we present a diffractive vibration monitoring system, integrating a jointly optimized diffractive layer with a shallow neural network-based backend to remotely extract 3D structural vibration spectra, offering a low-power, cost-effective and scalable solution. This architecture eliminates the need for dense sensor arrays or extensive data acquisition; instead, it uses a spatially-optimized passive diffractive layer that encodes 3D structural displacements into modulated light, captured by a minimal number of detectors and decoded in real-time by shallow and low-power neural networks to reconstruct the 3D displacement spectra of structures. The diffractive system's efficacy was demonstrated both numerically and experimentally using millimeter-wave illumination on a laboratory-scale building model with a programmable shake table. Our system achieves more than an order-of-magnitude improvement in accuracy over conventional optics or separately trained modules, establishing a foundation for high-throughput 3D monitoring of structures. Beyond SHM, the 3D vibration monitoring capabilities of this cost-effective and data-efficient framework establish a new computational sensing modality with potential applications in disaster resilience, aerospace diagnostics, and autonomous navigation, where energy efficiency, low latency, and high-throughput are critical.","authors":["Yuntian Wang","Zafer Yilmaz","Yuhang Li","Edward Liu","Eric Ahlberg","Farid Ghahari","Ertugrul Taciroglu","Aydogan Ozcan"],"url":"https://arxiv.org/abs/2506.03317"}
{"created":"2025-06-05","title":"A Linear Kernel for Independent Set Reconfiguration in Planar Graphs","abstract":"Fix a positive integer $r$, and a graph $G$ that is $K_{3,r}$-minor-free. Let $I_s$ and $I_t$ be two independent sets in $G$, each of size $k$. We begin with a ``token'' on each vertex of $I_s$ and seek to move all tokens to $I_t$, by repeated ``token jumping'', removing a single token from one vertex and placing it on another vertex. We require that each intermediate arrangement of tokens again specifies an independent set of size $k$. Given $G$, $I_s$, and $I_t$, we ask whether there exists a sequence of token jumps that transforms $I_s$ into $I_t$. When $k$ is part of the input, this problem is known to be PSPACE-complete. However, it was shown by Ito, Kami\\'nski, and Ono (2014) to be fixed-parameter tractable. That is, when $k$ is fixed, the problem can be solved in time polynomial in the order of $G$.","authors":["Nicolas Bousquet","Daniel W. Cranston"],"url":"https://arxiv.org/abs/2506.03319"}
{"created":"2025-06-05","title":"Towards Source Attribution of Singing Voice Deepfake with Multimodal Foundation Models","abstract":"In this work, we introduce the task of singing voice deepfake source attribution (SVDSA). We hypothesize that multimodal foundation models (MMFMs) such as ImageBind, LanguageBind will be most effective for SVDSA as they are better equipped for capturing subtle source-specific characteristics-such as unique timbre, pitch manipulation, or synthesis artifacts of each singing voice deepfake source due to their cross-modality pre-training. Our experiments with MMFMs, speech foundation models and music foundation models verify the hypothesis that MMFMs are the most effective for SVDSA. Furthermore, inspired from related research, we also explore fusion of foundation models (FMs) for improved SVDSA. To this end, we propose a novel framework, COFFE which employs Chernoff Distance as novel loss function for effective fusion of FMs. Through COFFE with the symphony of MMFMs, we attain the topmost performance in comparison to all the individual FMs and baseline fusion methods.","authors":["Orchid Chetia Phukan","Girish","Mohd Mujtaba Akhtar","Swarup Ranjan Behera","Priyabrata Mallick","Pailla Balakrishna Reddy","Arun Balaji Buduru","Rajesh Sharma"],"url":"https://arxiv.org/abs/2506.03364"}
{"created":"2025-06-05","title":"Impact of Rankings and Personalized Recommendations in Marketplaces","abstract":"Individuals often navigate several options with incomplete knowledge of their own preferences. Information provisioning tools such as public rankings and personalized recommendations have become central to helping individuals make choices, yet their value proposition under different marketplace environments remains unexplored. This paper studies a stylized model to explore the impact of these tools in two marketplace settings: uncapacitated supply, where items can be selected by any number of agents, and capacitated supply, where each item is constrained to be matched to a single agent. We model the agents utility as a weighted combination of a common term which depends only on the item, reflecting the item's population level quality, and an idiosyncratic term, which depends on the agent item pair capturing individual specific tastes. Public rankings reveal the common term, while personalized recommendations reveal both terms. In the supply unconstrained settings, both public rankings and personalized recommendations improve welfare, with their relative value determined by the degree of preference heterogeneity. Public rankings are effective when preferences are relatively homogeneous, while personalized recommendations become critical as heterogeneity increases. In contrast, in supply constrained settings, revealing just the common term, as done by public rankings, provides limited benefit since the total common value available is limited by capacity constraints, whereas personalized recommendations, by revealing both common and idiosyncratic terms, significantly enhance welfare by enabling agents to match with items they idiosyncratically value highly. These results illustrate the interplay between supply constraints and preference heterogeneity in determining the effectiveness of information provisioning tools, offering insights for their design and deployment in diverse settings.","authors":["Omar Besbes","Yash Kanoria","Akshit Kumar"],"url":"https://arxiv.org/abs/2506.03369"}
{"created":"2025-06-05","title":"Cover time of random subgraphs of the hypercube","abstract":"$Q_{n,p}$, the random subgraph of the $n$-vertex hypercube $Q_n$, is obtained by independently retaining each edge of $Q_n$ with probability $p$. We give precise values for the cover time of $Q_{n,p}$ above the connectivity threshold.","authors":["Colin Cooper","Alan Frieze","Wesley Pegden"],"url":"https://arxiv.org/abs/2506.03375"}
{"created":"2025-06-05","title":"SNIFR : Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer","abstract":"As video-sharing platforms have grown over the past decade, child viewership has surged, increasing the need for precise detection of harmful content like violence or explicit scenes. Malicious users exploit moderation systems by embedding unsafe content in minimal frames to evade detection. While prior research has focused on visual cues and advanced such fine-grained detection, audio features remain underexplored. In this study, we embed audio cues with visual for fine-grained child harmful content detection and introduce SNIFR, a novel framework for effective alignment. SNIFR employs a transformer encoder for intra-modality interaction, followed by a cascaded cross-transformer for inter-modality alignment. Our approach achieves superior performance over unimodal and baseline fusion methods, setting a new state-of-the-art.","authors":["Orchid Chetia Phukan","Mohd Mujtaba Akhtar","Girish","Swarup Ranjan Behera","Abu Osama Siddiqui","Sarthak Jain","Priyabrata Mallick","Jaya Sai Kiran Patibandla","Pailla Balakrishna Reddy","Arun Balaji Buduru","Rajesh Sharma"],"url":"https://arxiv.org/abs/2506.03378"}
{"created":"2025-06-05","title":"Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images","abstract":"Skin cancer is among the most prevalent and life-threatening diseases worldwide, with early detection being critical to patient outcomes. This work presents a hybrid machine and deep learning-based approach for classifying malignant and benign skin lesions using the SLICE-3D dataset from ISIC 2024, which comprises 401,059 cropped lesion images extracted from 3D Total Body Photography (TBP), emulating non-dermoscopic, smartphone-like conditions. Our method combines vision transformers (EVA02) and our designed convolutional ViT hybrid (EdgeNeXtSAC) to extract robust features, employing a segmentation-assisted classification pipeline to enhance lesion localization. Predictions from these models are fused with a gradient-boosted decision tree (GBDT) ensemble enriched by engineered features and patient-specific relational metrics. To address class imbalance and improve generalization, we augment malignant cases with Stable Diffusion-generated synthetic lesions and apply a diagnosis-informed relabeling strategy to harmonize external datasets into a 3-class format. Using partial AUC (pAUC) above 80 percent true positive rate (TPR) as the evaluation metric, our approach achieves a pAUC of 0.1755 -- the highest among all configurations. These results underscore the potential of hybrid, interpretable AI systems for skin cancer triage in telemedicine and resource-constrained settings.","authors":["Muhammad Zubair Hasan","Fahmida Yasmin Rifat"],"url":"https://arxiv.org/abs/2506.03420"}
{"created":"2025-06-05","title":"A Data-Driven Diffusion-based Approach for Audio Deepfake Explanations","abstract":"Evaluating explainability techniques, such as SHAP and LRP, in the context of audio deepfake detection is challenging due to lack of clear ground truth annotations. In the cases when we are able to obtain the ground truth, we find that these methods struggle to provide accurate explanations. In this work, we propose a novel data-driven approach to identify artifact regions in deepfake audio. We consider paired real and vocoded audio, and use the difference in time-frequency representation as the ground-truth explanation. The difference signal then serves as a supervision to train a diffusion model to expose the deepfake artifacts in a given vocoded audio. Experimental results on the VocV4 and LibriSeVoc datasets demonstrate that our method outperforms traditional explainability techniques, both qualitatively and quantitatively.","authors":["Petr Grinberg","Ankur Kumar","Surya Koppisetti","Gaurav Bharaj"],"url":"https://arxiv.org/abs/2506.03425"}
{"created":"2025-06-05","title":"Flagged Extensions and Numerical Simulations for Quantum Channel Capacity: Bridging Theory and Computation","abstract":"I will investigate the capacities of noisy quantum channels through a combined analytical and numerical approach. First, I introduce novel flagged extension techniques that embed a channel into a higher-dimensional space, enabling single-letter upper bounds on quantum and private capacities. My results refine previous bounds and clarify noise thresholds beyond which quantum transmission vanishes. Second, I present a simulation framework that uses coherent information to estimate channel capacities in practice, focusing on two canonical examples: the amplitude damping channel (which we confirm is degradable and thus single-letter) and the depolarizing channel (whose capacity requires multi-letter superadditivity). By parameterizing input qubit states on the Bloch sphere, I numerically pinpoint the maximum coherent information for each channel and validate the flagged extension bounds. Notably, I capture the abrupt transition to zero capacity at high noise and observe superadditivity for moderate noise levels.","authors":["Vahid Nourozi"],"url":"https://arxiv.org/abs/2506.03429"}
{"created":"2025-06-05","title":"Computational Complexity of Non-Hermitian Quantum Systems","abstract":"We analyze the computational power of non-Hermitian quantum dynamics, i.e., conditional time evolutions that arise when a quantum system is monitored and one postselects on a particular measurement record. We establish an approximate equivalence between post-selection and arbitrary non-Hermitian Hamiltonians. Namely, first we establish hardness in the following sense: Let $U=e^{-iHt}$ be an NH gate on $n$ qubits whose smallest and largest singular values differ by at least $2^{-\\text{poly}(n)}$. Together with any universal set of unitary gates, the ability to apply such a gate lets one efficiently emulate postselection. The resulting model decides every language in PostBQP; hence, under standard complexity conjectures, fully scalable NH quantum computers are unlikely to be engineered. Second, we establish upper bounds which show that conversely, any non-Hermitian evolution can be written as a unitary on a system-meter pair followed by postselecting the meter. This ``purification'' is compact -- it introduces only $O(\\delta^{2})$ Trotter error per time step $\\delta$ -- so any NH model whose purification lies in a strongly simulable unitary family (e.g., Clifford, matchgate, or low-bond-dimension tensor-network circuits) remains efficiently simulable. Thus, non-Hermitian physics neither guarantees a quantum advantage nor precludes efficient classical simulation: its complexity is controlled by the singular-value radius of the evolution operator and by the structure of its unitary purification.","authors":["Brian Barch","Daniel Lidar"],"url":"https://arxiv.org/abs/2506.03435"}
{"created":"2025-06-05","title":"Conjectured Bounds for 2-Local Hamiltonians via Token Graphs","abstract":"We explain how the maximum energy of the Quantum MaxCut, XY, and EPR Hamiltonians on a graph $G$ are related to the spectral radii of the token graphs of $G$. From numerical study, we conjecture new bounds for these spectral radii based on properties of $G$. We show how these conjectures tighten the analysis of existing algorithms, implying state-of-the-art approximation ratios for all three Hamiltonians. Our conjectures also provide simple combinatorial bounds on the ground state energy of the antiferromagnetic Heisenberg model, which we prove for bipartite graphs.","authors":["Anuj Apte","Ojas Parekh","James Sud"],"url":"https://arxiv.org/abs/2506.03441"}
{"created":"2025-06-05","title":"Models of Heavy-Tailed Mechanistic Universality","abstract":"Recent theoretical and empirical successes in deep learning, including the celebrated neural scaling laws, are punctuated by the observation that many objects of interest tend to exhibit some form of heavy-tailed or power law behavior. In particular, the prevalence of heavy-tailed spectral densities in Jacobians, Hessians, and weight matrices has led to the introduction of the concept of heavy-tailed mechanistic universality (HT-MU). Multiple lines of empirical evidence suggest a robust correlation between heavy-tailed metrics and model performance, indicating that HT-MU may be a fundamental aspect of deep learning efficacy. Here, we propose a general family of random matrix models -- the high-temperature Marchenko-Pastur (HTMP) ensemble -- to explore attributes that give rise to heavy-tailed behavior in trained neural networks. Under this model, spectral densities with power laws on (upper and lower) tails arise through a combination of three independent factors (complex correlation structures in the data; reduced temperatures during training; and reduced eigenvector entropy), appearing as an implicit bias in the model structure, and they can be controlled with an \"eigenvalue repulsion\" parameter. Implications of our model on other appearances of heavy tails, including neural scaling laws, optimizer trajectories, and the five-plus-one phases of neural network training, are discussed.","authors":["Liam Hodgkinson","Zhichao Wang","Michael W. Mahoney"],"url":"https://arxiv.org/abs/2506.03470"}
{"created":"2025-06-05","title":"A Generalized Graph Signal Processing Framework for Multiple Hypothesis Testing over Networks","abstract":"We consider the multiple hypothesis testing (MHT) problem over the joint domain formed by a graph and a measure space. On each sample point of this joint domain, we assign a hypothesis test and a corresponding $p$-value. The goal is to make decisions for all hypotheses simultaneously, using all available $p$-values. In practice, this problem resembles the detection problem over a sensor network during a period of time. To solve this problem, we extend the traditional two-groups model such that the prior probability of the null hypothesis and the alternative distribution of $p$-values can be inhomogeneous over the joint domain. We model the inhomogeneity via a generalized graph signal. This more flexible statistical model yields a more powerful detection strategy by leveraging the information from the joint domain.","authors":["Xingchao Jian","Martin G\\\"olz","Feng Ji","Wee Peng Tay","Abdelhak M. Zoubir"],"url":"https://arxiv.org/abs/2506.03496"}
{"created":"2025-06-05","title":"POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning","abstract":"With over 1,000,000 images from more than 10,000 exposures using state-of-the-art high-contrast imagers (e.g., Gemini Planet Imager, VLT/SPHERE) in the search for exoplanets, can artificial intelligence (AI) serve as a transformative tool in imaging Earth-like exoplanets in the coming decade? In this paper, we introduce a benchmark and explore this question from a polarimetric image representation learning perspective. Despite extensive investments over the past decade, only a few new exoplanets have been directly imaged. Existing imaging approaches rely heavily on labor-intensive labeling of reference stars, which serve as background to extract circumstellar objects (disks or exoplanets) around target stars. With our POLARIS (POlarized Light dAta for total intensity Representation learning of direct Imaging of exoplanetary Systems) dataset, we classify reference star and circumstellar disk images using the full public SPHERE/IRDIS polarized-light archive since 2014, requiring less than 10 percent manual labeling. We evaluate a range of models including statistical, generative, and large vision-language models and provide baseline performance. We also propose an unsupervised generative representation learning framework that integrates these models, achieving superior performance and enhanced representational power. To our knowledge, this is the first uniformly reduced, high-quality exoplanet imaging dataset, rare in astrophysics and machine learning. By releasing this dataset and baselines, we aim to equip astrophysicists with new tools and engage data scientists in advancing direct exoplanet imaging, catalyzing major interdisciplinary breakthroughs.","authors":["Fangyi Cao","Bin Ren","Zihao Wang","Shiwei Fu","Youbin Mo","Xiaoyang Liu","Yuzhou Chen","Weixin Yao"],"url":"https://arxiv.org/abs/2506.03511"}
{"created":"2025-06-05","title":"BitTTS: Highly Compact Text-to-Speech Using 1.58-bit Quantization and Weight Indexing","abstract":"This paper proposes a highly compact, lightweight text-to-speech (TTS) model for on-device applications. To reduce the model size, the proposed model introduces two techniques. First, we introduce quantization-aware training (QAT), which quantizes model parameters during training to as low as 1.58-bit. In this case, most of 32-bit model parameters are quantized to ternary values {-1, 0, 1}. Second, we propose a method named weight indexing. In this method, we save a group of 1.58-bit weights as a single int8 index. This allows for efficient storage of model parameters, even on hardware that treats values in units of 8-bit. Experimental results demonstrate that the proposed method achieved 83 % reduction in model size, while outperforming the baseline of similar model size without quantization in synthesis quality.","authors":["Masaya Kawamura","Takuya Hasumi","Yuma Shirahata","Ryuichi Yamamoto"],"url":"https://arxiv.org/abs/2506.03515"}
{"created":"2025-06-05","title":"Quantum Secure Key Exchange with Position-based Credentials","abstract":"Quantum key distribution (QKD) provides an information-theoretic way of securely exchanging secret keys, and typically relies on pre-shared keys or public keys for message authentication. To lift the requirement of pre-shared or public keys, Buhrman et. al. [SIAM J. Comput. 43, 150 (2014)] proposed utilizing the location of a party as a credential. Here, we extend upon the proposal, develop a QKD protocol with location credentials using quantum position verification (QPV) based message and identity authentication. By using QKD with delayed authentication as a base, and later simplifying QPV-based message authentication, we significantly reduce the number of QPV runs, which currently acts as a bottleneck. Besides demonstrating security for the proposed protocol, we also provide improvements to QPV security analysis, including generalization of the QPV adversary model, tightening a trace distance bound using semidefinite programming, and propose a multi-basis QPV requiring only BB84 state preparation but with multiple measurement basis.","authors":["Wen Yu Kon","Ignatius William Primaatmaja","Kaushik Chakraborty","Charles Lim"],"url":"https://arxiv.org/abs/2506.03549"}
{"created":"2025-06-05","title":"Tone recognition in low-resource languages of North-East India: peeling the layers of SSL-based speech models","abstract":"This study explores the use of self-supervised learning (SSL) models for tone recognition in three low-resource languages from North Eastern India: Angami, Ao, and Mizo. We evaluate four Wav2vec2.0 base models that were pre-trained on both tonal and non-tonal languages. We analyze tone-wise performance across the layers for all three languages and compare the different models. Our results show that tone recognition works best for Mizo and worst for Angami. The middle layers of the SSL models are the most important for tone recognition, regardless of the pre-training language, i.e. tonal or non-tonal. We have also found that the tone inventory, tone types, and dialectal variations affect tone recognition. These findings provide useful insights into the strengths and weaknesses of SSL-based embeddings for tonal languages and highlight the potential for improving tone recognition in low-resource settings. The source code is available at GitHub 1 .","authors":["Parismita Gogoi","Sishir Kalita","Wendy Lalhminghlui","Viyazonuo Terhiija","Moakala Tzudir","Priyankoo Sarmah","S. R. M. Prasanna"],"url":"https://arxiv.org/abs/2506.03606"}
{"created":"2025-06-05","title":"SubSearch: Robust Estimation and Outlier Detection for Stochastic Block Models via Subgraph Search","abstract":"Community detection is a fundamental task in graph analysis, with methods often relying on fitting models like the Stochastic Block Model (SBM) to observed networks. While many algorithms can accurately estimate SBM parameters when the input graph is a perfect sample from the model, real-world graphs rarely conform to such idealized assumptions. Therefore, robust algorithms are crucial-ones that can recover model parameters even when the data deviates from the assumed distribution. In this work, we propose SubSearch, an algorithm for robustly estimating SBM parameters by exploring the space of subgraphs in search of one that closely aligns with the model's assumptions. Our approach also functions as an outlier detection method, properly identifying nodes responsible for the graph's deviation from the model and going beyond simple techniques like pruning high-degree nodes. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our method.","authors":["Leonardo Martins Bianco (LMO)","Christine Keribin (LMO)","Zacharie Naulet (INRAE","MaIAGE)"],"url":"https://arxiv.org/abs/2506.03657"}
{"created":"2025-06-05","title":"Adaptation in shifting and size-changing environments under selection","abstract":"We propose a model to characterize how a diffusing population adapts under a time periodic selection, while its environment undergoes shifts and size changes, leading to significant differences with classical results on fixed domains. After studying the underlying periodic parabolic principal eigenelements, we address the extinction vs. persistence issue, taking into account the interplay between the moving habitat and periodic selection. Subsequently, we employ a space-time finite element approach, establish the well-posedness of the approximation scheme, and conduct numerical simulations to explore these dynamics.","authors":["Matthieu Alfaro (LMRS)","Adel Blouza (LMRS)","Nessim Dhaouadi (LMRS)"],"url":"https://arxiv.org/abs/2506.03666"}
{"created":"2025-06-05","title":"Position: There Is No Free Bayesian Uncertainty Quantification","abstract":"Due to their intuitive appeal, Bayesian methods of modeling and uncertainty quantification have become popular in modern machine and deep learning. When providing a prior distribution over the parameter space, it is straightforward to obtain a distribution over the parameters that is conventionally interpreted as uncertainty quantification of the model. We challenge the validity of such Bayesian uncertainty quantification by discussing the equivalent optimization-based representation of Bayesian updating, provide an alternative interpretation that is coherent with the optimization-based perspective, propose measures of the quality of the Bayesian inferential stage, and suggest directions for future work.","authors":["Ivan Melev","Goeran Kauermann"],"url":"https://arxiv.org/abs/2506.03670"}
{"created":"2025-06-05","title":"Inexact Projected Preconditioned Gradient Methods with Variable Metrics: General Convergence Theory via Lyapunov Approach","abstract":"Projected gradient methods are widely used for constrained optimization. A key application is for partial differential equations (PDEs), where the objective functional represents physical energy and the linear constraints enforce conservation laws. However, computing the projections onto the constraint set generally requires solving large-scale ill-conditioned linear systems. A common strategy is to relax projection accuracy and apply preconditioners, which leads to the inexact preconditioned projected gradient descent (IPPGD) methods studied here. However, the theoretical analysis and the dynamic behavior of the IPPGD methods, along with an effective construction of the inexact projection operator itself, all remain largely unexplored. We propose a strategy for constructing the inexact projection operator and develop a gradient-type flow to model the IPPGD methods. Discretization of this flow not only recovers the original IPPGD method but also yields a potentially faster novel method. Furthermore, we apply Lyapunov analysis, designing a delicate Lyapunov function, to prove the exponential convergence at the continuous level and linear convergence at the discrete level. We then apply the proposed method to solve nonlinear PDEs and present numerical results.","authors":["Ruchi Guo","Jun Zou"],"url":"https://arxiv.org/abs/2506.03671"}
{"created":"2025-06-05","title":"Latent Guided Sampling for Combinatorial Optimization","abstract":"Combinatorial Optimization problems are widespread in domains such as logistics, manufacturing, and drug discovery, yet their NP-hard nature makes them computationally challenging. Recent Neural Combinatorial Optimization methods leverage deep learning to learn solution strategies, trained via Supervised or Reinforcement Learning (RL). While promising, these approaches often rely on task-specific augmentations, perform poorly on out-of-distribution instances, and lack robust inference mechanisms. Moreover, existing latent space models either require labeled data or rely on pre-trained policies. In this work, we propose LGS-Net, a novel latent space model that conditions on problem instances, and introduce an efficient inference method, Latent Guided Sampling (LGS), based on Markov Chain Monte Carlo and Stochastic Approximation. We show that the iterations of our method form a time-inhomogeneous Markov Chain and provide rigorous theoretical convergence guarantees. Empirical results on benchmark routing tasks show that our method achieves state-of-the-art performance among RL-based approaches.","authors":["Sobihan Surendran (LPSM)","Adeline Fermanian (LPSM)","Sylvain Le Corff (LPSM)"],"url":"https://arxiv.org/abs/2506.03672"}
{"created":"2025-06-05","title":"RhoDARTS: Differentiable Quantum Architecture Search with Density Matrix Simulations","abstract":"Variational Quantum Algorithms (VQAs) are a promising approach for leveraging powerful Noisy Intermediate-Scale Quantum (NISQ) computers. When applied to machine learning tasks, VQAs give rise to NISQ-compatible Quantum Neural Networks (QNNs), which have been shown to outperform classical neural networks with a similar number of trainable parameters. While the quantum circuit structures of VQAs for physics simulations are determined by the physical properties of the systems, identifying effective QNN architectures for general machine learning tasks is a difficult challenge due to the lack of domain-specific priors. Indeed, existing Quantum Architecture Search (QAS) algorithms, adaptations of classical neural architecture search techniques, often overlook the inherent quantum nature of the circuits they produce. By approaching QAS from the ground-up and from a quantum perspective, we resolve this limitation by proposing $\\rho$DARTS, a differentiable QAS algorithm that models the search process as the evolution of a quantum mixed state, emerging from the search space of quantum architectures. We validate our method by finding circuits for state initialization, Hamiltonian optimization, and image classification. Further, we demonstrate better convergence against existing QAS techniques and show improved robustness levels to noise.","authors":["Swagat Kumar","Jan-Nico Zaech","Colin Michael Wilmott","Luc Van Gool"],"url":"https://arxiv.org/abs/2506.03697"}
{"created":"2025-06-05","title":"3D Holographic Flow Cytometry Measurements of Microalgae: Strategies for Angle Recovery in Complex Rotation Patterns","abstract":"Marine ecosystems are in the spotlight, because environmental changes are threatening biodiversity and ecological functions. In this context, microalgae play key ecological roles both in planktonic and benthic ecosystems. Consequently, they are considered indispensable targets for global monitoring programs. However, due to a high spatial and temporal variability and to difficulties of species identification (still relying on microscopy observations), the assessment of roles played by these components of marine ecosystems is demanding. In addition, technologies for a 3D assessment of their complex morphology are scarcely available. Here, we present a comprehensive workflow for retrieving 3D information on microalgae with diverse geometries through holographic microscopy operating in flow-cytometry mode. Depending on the rotation patterns of samples, a tailored approach is used to retrieve their rolling angles. We demonstrate the feasibility of measuring 3D data of various microalgae, contingent to the intrinsic optical properties of cells. Specifically, we show that for quasi-transparent and low-scattering microorganisms, the retrieved angles permit to achieve quantitative 3D tomographic Refractive Index (RI) mapping, providing a full characterization of the alga in terms of its inner structure and the outer shape. Moreover, even in the most challenging scenarios, where microalgae exhibit high light absorption or strong scattering, quantitative 3D shape reconstructions of diatoms and dinoflagellates can be at least achieved. Finally, we compare our direct 3D measurements with 2D inferences of 3D properties, obtained using a commercially available microscopy system. The ability to non-invasively obtain 3D information on microalgae marks a fundamental advancement in the field, unlocking a wealth of novel biological insights for characterizing aquatic ecosystems.","authors":["Francesca Borrelli","Giusy Giugliano","Emilie Houliez","Jaromir Behal","Daniele Pirone","Leonilde Roselli","Angela Sardo","Valerio Zupo","Maria Costantini","Lisa Miccio","Pasquale Memmolo","Vittorio Bianco","Pietro Ferraro"],"url":"https://arxiv.org/abs/2506.03738"}
{"created":"2025-06-05","title":"Feedback stabilization of switched systems under arbitrary switching: A convex characterization","abstract":"In this paper, we study stabilizability of discrete-time switched linear systems where the switching signal is considered as an arbitrary disturbance (and not a control variable). We characterize feedback stabilization via necessary and sufficient linear matrix inequalities (LMIs) conditions based on novel graph structures. We analyze both the cases in which the controller has (or has not) access to the current switching mode, the so-called mode-dependent and mode-independent settings, providing specular results. Moreover, our approach provides explicit piecewise-linear and memory-dependent linear controllers, highlighting the connections with existing stabilization approaches. The effectiveness of the proposed technique is finally illustrated with the help of some numerical examples.","authors":["Thiago Alves Lima","Matteo Della Rossa","Antoine Girard"],"url":"https://arxiv.org/abs/2506.03759"}
{"created":"2025-06-05","title":"Infinitesimal Higher-Order Spectral Variations in Rectangular Real Random Matrices","abstract":"We present a theoretical framework for deriving the general $n$-th order Fr\\'echet derivatives of singular values in real rectangular matrices, by leveraging reduced resolvent operators from Kato's analytic perturbation theory for self-adjoint operators. Deriving closed-form expressions for higher-order derivatives of singular values is notoriously challenging through standard matrix-analysis techniques. To overcome this, we treat a real rectangular matrix as a compact operator on a finite-dimensional Hilbert space, and embed the rectangular matrix into a block self-adjoint operator so that non-symmetric perturbations are captured. Applying Kato's asymptotic eigenvalue expansion to this construction, we obtain a general, closed-form expression for the infinitesimal $n$-th order spectral variations. Specializing to $n=2$ and deploying on a Kronecker-product representation with matrix convention yield the Hessian of a singular value, not found in literature. By bridging abstract operator-theoretic perturbation theory with matrices, our framework equips researchers with a practical toolkit for higher-order spectral sensitivity studies in random matrix applications (e.g., adversarial perturbation in deep learning).","authors":["R\\'ois\\'in Luo"],"url":"https://arxiv.org/abs/2506.03764"}
{"created":"2025-06-05","title":"Conventional and Fuzzy Data Envelopment Analysis with deaR","abstract":"deaR is a recently developed R package for data envelopment analysis (DEA) that implements a large number of conventional and fuzzy models, along with super-efficiency models, cross-efficiency analysis, Malmquist index, bootstrapping, and metafrontier analysis. It should be noted that deaR is the only package to date that incorporates Kao-Liu, Guo-Tanaka and possibilistic fuzzy models. The versatility of the package allows the user to work with different returns to scale and orientations, as well as to consider special features, namely non-controllable, non-discretionary or undesirable variables. Moreover, it includes novel graphical representations that can help the user to display the results. This paper is a comprehensive description of deaR, reviewing all implemented models and giving examples of use.","authors":["Vicente J. Bolos","Rafael Benitez","Vicente Coll-Serrano"],"url":"https://arxiv.org/abs/2506.03766"}
{"created":"2025-06-05","title":"Towards Quantum Operator-Valued Kernels","abstract":"Quantum kernels are reproducing kernel functions built using quantum-mechanical principles and are studied with the aim of outperforming their classical counterparts. The enthusiasm for quantum kernel machines has been tempered by recent studies that have suggested that quantum kernels could not offer speed-ups when learning on classical data. However, most of the research in this area has been devoted to scalar-valued kernels in standard classification or regression settings for which classical kernel methods are efficient and effective, leaving very little room for improvement with quantum kernels. This position paper argues that quantum kernel research should focus on more expressive kernel classes. We build upon recent advances in operator-valued kernels, and propose guidelines for investigating quantum kernels. This should help to design a new generation of quantum kernel machines and fully explore their potentials.","authors":["Hachem Kadri","Joachim Tomasi","Yuka Hashimoto","Sandrine Anthoine"],"url":"https://arxiv.org/abs/2506.03779"}
{"created":"2025-06-05","title":"High-Dimensional Learning in Finance","abstract":"Recent advances in machine learning have shown promising results for financial prediction using large, over-parameterized models. This paper provides theoretical foundations and empirical validation for understanding when and how these methods achieve predictive success. I examine three key aspects of high-dimensional learning in finance. First, I prove that within-sample standardization in Random Fourier Features implementations fundamentally alters the underlying Gaussian kernel approximation, replacing shift-invariant kernels with training-set dependent alternatives. Second, I derive sample complexity bounds showing when reliable learning becomes information-theoretically impossible under weak signal-to-noise ratios typical in finance. Third, VC-dimension analysis reveals that ridgeless regression's effective complexity is bounded by sample size rather than nominal feature dimension. Comprehensive numerical validation confirms these theoretical predictions, revealing systematic breakdown of claimed theoretical properties across realistic parameter ranges. These results show that when sample size is small and features are high-dimensional, observed predictive success is necessarily driven by low-complexity artifacts, not genuine high-dimensional learning.","authors":["Hasan Fallahgoul"],"url":"https://arxiv.org/abs/2506.03780"}
{"created":"2025-06-05","title":"Analytical Reconstruction of Periodically Deformed Objects in Time-resolved CT","abstract":"Time-resolved CT is an advanced measurement technique that has been widely used to observe dynamic objects, including periodically varying structures such as hearts, lungs, or hearing structures. To reconstruct these objects from CT projections, a common approach is to divide the projections into several collections based on their motion phases and perform reconstruction within each collection, assuming they originate from a static object. This describes the gating-based method, which is the standard approach for time-periodic reconstruction. However, the gating-based reconstruction algorithm only utilizes a limited subset of projections within each collection and ignores the correlation between different collections, leading to inefficient use of the radiation dose. To address this issue, we propose two analytical reconstruction pipelines in this paper, and validate them with experimental data captured using tomographic synchrotron microscopy. We demonstrate that our approaches significantly reduce random noise in the reconstructed images without blurring the sharp features of the observed objects. Equivalently, our methods can achieve the same reconstruction quality as gating-based methods but with a lower radiation dose. Our code is available at github.com/PeriodRecon.","authors":["Qianwei Qu","Christian M. Schlep\\\"utz","Marco Stampanoni"],"url":"https://arxiv.org/abs/2506.03792"}
{"created":"2025-06-05","title":"Geoff: The Generic Optimization Framework & Frontend for Particle Accelerator Controls","abstract":"Geoff is a collection of Python packages that form a framework for automation of particle accelerator controls. With particle accelerator laboratories around the world researching machine learning techniques to improve accelerator performance and uptime, a multitude of approaches and algorithms have emerged. The purpose of Geoff is to harmonize these approaches and to minimize friction when comparing or migrating between them. It provides standardized interfaces for optimization problems, utility functions to speed up development, and a reference GUI application that ties everything together. Geoff is an open-source library developed at CERN and maintained and updated in collaboration between CERN and GSI as part of the EURO-LABS project. This paper gives an overview over Geoff's design, features, and current usage.","authors":["Penelope Madysa","Sabrina Appel","Verena Kain","Michael Schenk"],"url":"https://arxiv.org/abs/2506.03796"}
{"created":"2025-06-05","title":"Personalized MR-Informed Diffusion Models for 3D PET Image Reconstruction","abstract":"Recent work has shown improved lesion detectability and flexibility to reconstruction hyperparameters (e.g. scanner geometry or dose level) when PET images are reconstructed by leveraging pre-trained diffusion models. Such methods train a diffusion model (without sinogram data) on high-quality, but still noisy, PET images. In this work, we propose a simple method for generating subject-specific PET images from a dataset of multi-subject PET-MR scans, synthesizing \"pseudo-PET\" images by transforming between different patients' anatomy using image registration. The images we synthesize retain information from the subject's MR scan, leading to higher resolution and the retention of anatomical features compared to the original set of PET images. With simulated and real [$^{18}$F]FDG datasets, we show that pre-training a personalized diffusion model with subject-specific \"pseudo-PET\" images improves reconstruction accuracy with low-count data. In particular, the method shows promise in combining information from a guidance MR scan without overly imposing anatomical features, demonstrating an improved trade-off between reconstructing PET-unique image features versus features present in both PET and MR. We believe this approach for generating and utilizing synthetic data has further applications to medical imaging tasks, particularly because patient-specific PET images can be generated without resorting to generative deep learning or large training datasets.","authors":["George Webber","Alexander Hammers","Andrew P. King","Andrew J. Reader"],"url":"https://arxiv.org/abs/2506.03804"}
{"created":"2025-06-05","title":"Impact of friction force and retrieval speed on in silico mechanical thrombectomies: a sensitivity analysis","abstract":"Background: Mechanical Thrombectomy (MT) is a widely accepted first-line treatment for Acute Ischemic Stroke (AIS) and it has been studied using in vitro and in silico models. Thrombectomy outcomes have been performed for patient-specific cases using in silico models. However, until now, in vivo friction coefficients for stent-vessel, stent-clot, and clot-vessel interactions are unknown, but in vitro experiments have been attempted with significant standard deviations. These interactions and friction coefficients have been considered an important aspect of thrombectomy success. Objectives: In the current study, we explored the influence of variation in friction forces for stent-vessel, stent-clot, and clot-vessel interactions using virtual mechanical thrombectomy (VMT). We have performed three simulations for each interaction and varied friction coefficients around the standard deviation observed in the past in vitro studies. Results: (i) clot-vessel friction: higher friction leads to clot fragmentation and VMT failure. (ii) stent-clot friction: it is susceptible to VMT outcomes, with lower values showing the slippage of the clot while higher values lead to fragmentation. (iii) stent-vessel friction: higher friction shows compression of the stent in curved vessels and dislodgment of clot from stent retriever (SR) due to its compression, which leads to VMT failure. (iv) retrieval speed (RS): higher RS (>30 mm/s) leads to significant stent compression and unrealistic behavior of the SR. Conclusions: Analysis of results proposes the necessity for calculating accurate friction factor values and their implementation into in silico models, due to their sensitivity towards thrombectomy outcomes. Such in silico models mimic in vivo thrombectomy more closely and can be used in mechanical thrombectomy planning, management, and decision-making.","authors":["Mahesh S. Nagargoje","Virginia Fregona","Giulia Luraghi","Francesco Migliavacca","Demitria A Poulos","Bryan C Good","Jose Felix Rodriguez Matas"],"url":"https://arxiv.org/abs/2506.03812"}
{"created":"2025-06-05","title":"Jumbled Scattered Factors","abstract":"In this work, we combine the research on (absent) scattered factors with the one of jumbled words. For instance, $\\mathtt{wolf}$ is an absent scattered factor of $\\mathtt{cauliflower}$ but since $\\mathtt{lfow}$, a jumbled (or abelian) version of $\\mathtt{wolf}$, is a scattered factor, $\\mathtt{wolf}$ occurs as a jumbled scattered factor in $\\mathtt{cauliflower}$. A \\emph{jumbled scattered factor} $u$ of a word $w$ is constructed by letters of $w$ with the only rule that the number of occurrences per letter in $u$ is smaller than or equal to the one in $w$. We proceed to partition and characterise the set of jumbled scattered factors by the number of jumbled letters and use the latter as a measure. For this new class of words, we relate the folklore longest common subsequence (scattered factor) to the number of required jumbles. Further, we investigate the smallest possible number of jumbles alongside the jumbled scattered factor relation as well as Simon's congruence from the point of view of jumbled scattered factors and jumbled universality.","authors":["Pamela Fleischmann","Annika Huch","Melf Kammholz","Tore Ko{\\ss}"],"url":"https://arxiv.org/abs/2506.03814"}
{"created":"2025-06-05","title":"Spatially Resolved Meteorological and Ancillary Data in Central Europe for Rainfall Streamflow Modeling","abstract":"We present a dataset for rainfall streamflow modeling that is fully spatially resolved with the aim of taking neural network-driven hydrological modeling beyond lumped catchments. To this end, we compiled data covering five river basins in central Europe: upper Danube, Elbe, Oder, Rhine, and Weser. The dataset contains meteorological forcings, as well as ancillary information on soil, rock, land cover, and orography. The data is harmonized to a regular 9km times 9km grid and contains daily values that span from October 1981 to September 2011. We also provide code to further combine our dataset with publicly available river discharge data for end-to-end rainfall streamflow modeling.","authors":["Marc Aurel Vischer","Noelia Otero","Jackie Ma"],"url":"https://arxiv.org/abs/2506.03819"}
{"created":"2025-06-05","title":"Quasioptic, Calibrated, Full 2-port Measurements of Cryogenic Devices under Vacuum in the 220-330 GHz Band","abstract":"A quasi-optical (QO) test bench was designed, simulated, and calibrated for characterizing S-parameters of devices in the 220-330 GHz (WR-3.4) frequency range, from room temperature down to 4.8 K. The devices were measured through vacuum windows via focused beam radiation. A de-embedding method employing line-reflect-match (LRM) calibration was established to account for the effects of optical components and vacuum windows. The setup provides all four S-parameters with the reference plane located inside the cryostat, and achieves a return loss of 30 dB with an empty holder. System validation was performed with measurements of cryogenically cooled devices, such as bare silicon wafers and stainless-steel frequency-selective surface (FSS) bandpass filters, and superconducting bandpass FSS fabricated in niobium. A permittivity reduction of Si based on 4-GHz resonance shift was observed concomitant with a drop in temperature from 296 K to 4.8 K. The stainless steel FSS measurements revealed a relatively temperature invariant center frequency and return loss level of 263 GHz and 35 dB on average, respectively. Finally, a center frequency of 257 GHz was measured with the superconducting filters, with return loss improved by 7 dB on average at 4.8 K. To the best of our knowledge, this is the first reported attempt to scale LRM calibration to 330 GHz and use it to de-embed the impact of optics and cryostat from cryogenically cooled device S-parameters.","authors":["Maxim Masyukov","Aleksi Tamminen","Irina Nefedova","Andrey Generalov","Samu-Ville P\\\"alli","Roman Grigorev","Pouyan Rezapoor","Rui Silva","Juha Mallat","Juha Ala-Laurinaho","Zachary Taylor"],"url":"https://arxiv.org/abs/2506.03824"}
{"created":"2025-06-05","title":"HTSC-2025: A Benchmark Dataset of Ambient-Pressure High-Temperature Superconductors for AI-Driven Critical Temperature Prediction","abstract":"The discovery of high-temperature superconducting materials holds great significance for human industry and daily life. In recent years, research on predicting superconducting transition temperatures using artificial intelligence~(AI) has gained popularity, with most of these tools claiming to achieve remarkable accuracy. However, the lack of widely accepted benchmark datasets in this field has severely hindered fair comparisons between different AI algorithms and impeded further advancement of these methods. In this work, we present the HTSC-2025, an ambient-pressure high-temperature superconducting benchmark dataset. This comprehensive compilation encompasses theoretically predicted superconducting materials discovered by theoretical physicists from 2023 to 2025 based on BCS superconductivity theory, including the renowned X$_2$YH$_6$ system, perovskite MXH$_3$ system, M$_3$XH$_8$ system, cage-like BCN-doped metal atomic systems derived from LaH$_{10}$ structural evolution, and two-dimensional honeycomb-structured systems evolving from MgB$_2$. The HTSC-2025 benchmark has been open-sourced at https://github.com/xqh19970407/HTSC-2025 and will be continuously updated. This benchmark holds significant importance for accelerating the discovery of superconducting materials using AI-based methods.","authors":["Xiao-Qi Han","Ze-Feng Gao","Xin-De Wang","Zhenfeng Ouyang","Peng-Jie Guo","Zhong-Yi Lu"],"url":"https://arxiv.org/abs/2506.03837"}
{"created":"2025-06-05","title":"Algorithm- and Data-Dependent Generalization Bounds for Score-Based Generative Models","abstract":"Score-based generative models (SGMs) have emerged as one of the most popular classes of generative models. A substantial body of work now exists on the analysis of SGMs, focusing either on discretization aspects or on their statistical performance. In the latter case, bounds have been derived, under various metrics, between the true data distribution and the distribution induced by the SGM, often demonstrating polynomial convergence rates with respect to the number of training samples. However, these approaches adopt a largely approximation theory viewpoint, which tends to be overly pessimistic and relatively coarse. In particular, they fail to fully explain the empirical success of SGMs or capture the role of the optimization algorithm used in practice to train the score network. To support this observation, we first present simple experiments illustrating the concrete impact of optimization hyperparameters on the generalization ability of the generated distribution. Then, this paper aims to bridge this theoretical gap by providing the first algorithmic- and data-dependent generalization analysis for SGMs. In particular, we establish bounds that explicitly account for the optimization dynamics of the learning algorithm, offering new insights into the generalization behavior of SGMs. Our theoretical findings are supported by empirical results on several datasets.","authors":["Benjamin Dupuis","Dario Shariatian","Maxime Haddouche","Alain Durmus","Umut Simsekli"],"url":"https://arxiv.org/abs/2506.03849"}
{"created":"2025-06-05","title":"Identifying Alzheimer's Disease Prediction Strategies of Convolutional Neural Network Classifiers using R2* Maps and Spectral Clustering","abstract":"Deep learning models have shown strong performance in classifying Alzheimer's disease (AD) from R2* maps, but their decision-making remains opaque, raising concerns about interpretability. Previous studies suggest biases in model decisions, necessitating further analysis. This study uses Layer-wise Relevance Propagation (LRP) and spectral clustering to explore classifier decision strategies across preprocessing and training configurations using R2* maps. We trained a 3D convolutional neural network on R2* maps, generating relevance heatmaps via LRP and applied spectral clustering to identify dominant patterns. t-Stochastic Neighbor Embedding (t-SNE) visualization was used to assess clustering structure. Spectral clustering revealed distinct decision patterns, with the relevance-guided model showing the clearest separation between AD and normal control (NC) cases. The t-SNE visualization confirmed that this model aligned heatmap groupings with the underlying subject groups. Our findings highlight the significant impact of preprocessing and training choices on deep learning models trained on R2* maps, even with similar performance metrics. Spectral clustering offers a structured method to identify classification strategy differences, emphasizing the importance of explainability in medical AI.","authors":["Christian Tinauer","Maximilian Sackl","Stefan Ropele","Christian Langkammer"],"url":"https://arxiv.org/abs/2506.03890"}
{"created":"2025-06-05","title":"Uniqueness of phase retrieval from offset linear canonical transform","abstract":"The classical phase retrieval refers to the recovery of an unknown signal from its Fourier magnitudes, which is widely used in fields such as quantum mechanics, signal processing, optics, etc. The offset linear canonical transform (OLCT), which is a more general type of linear integral transform including Fourier transform (FT), fractional Fourier transform (FrFT), and linear canonical transform (LCT) as its special cases. Hence, in this paper, we focus on the uniqueness problem of phase retrieval in the framework of OLCT. First, we prove that all the nontrivial ambiguities in continuous OLCT phase retrieval can be represented by convolution operators, and demonstrate that a continuous compactly supported signal can be uniquely determined up to a global phase from its multiple magnitude-only OLCT measurements. Moreover, we investigate the nontrivial ambiguities in the discrete OLCT phase retrieval case. Furthermore, we demenstrate that a nonseparable function can be uniquely recovered from its magnitudes of short-time OLCT (STOLCT) up to a global phase. Finally, we show that signals which are bandlimited in FT or OLCT domain can be reconstructed from its sampled STOLCT magnitude measurements, up to a global phase, providing the ambiguity function of window function satisfies some mild conditions.","authors":["Jing Liu","Haiye Huo"],"url":"https://arxiv.org/abs/2506.03944"}
{"created":"2025-06-05","title":"A Generic Branch-and-Bound Algorithm for $\\ell_0$-Penalized Problems with Supplementary Material","abstract":"We present a generic Branch-and-Bound procedure designed to solve L0-penalized optimization problems. Existing approaches primarily focus on quadratic losses and construct relaxations using \"Big-M\" constraints and/or L2-norm penalties. In contrast, our method accommodates a broader class of loss functions and allows greater flexibility in relaxation design through a general penalty term, encompassing existing techniques as special cases. We establish theoretical results ensuring that all key quantities required for the Branch-and-Bound implementation admit closed-form expressions under the general blanket assumptions considered in our work. Leveraging this framework, we introduce El0ps, an open-source Python solver with a plug-and-play workflow that enables user-defined losses and penalties in L0-penalized problems. Through extensive numerical experiments, we demonstrate that El0ps achieves state-of-the-art performance on classical instances and extends computational feasibility to previously intractable ones.","authors":["Cl\\'ement Elvira","Th\\'eo Guyard","C\\'edric Herzet"],"url":"https://arxiv.org/abs/2506.03974"}
{"created":"2025-06-05","title":"Dreaming up scale invariance via inverse renormalization group","abstract":"We explore how minimal neural networks can invert the renormalization group (RG) coarse-graining procedure in the two-dimensional Ising model, effectively \"dreaming up\" microscopic configurations from coarse-grained states. This task-formally impossible at the level of configurations-can be approached probabilistically, allowing machine learning models to reconstruct scale-invariant distributions without relying on microscopic input. We demonstrate that even neural networks with as few as three trainable parameters can learn to generate critical configurations, reproducing the scaling behavior of observables such as magnetic susceptibility, heat capacity, and Binder ratios. A real-space renormalization group analysis of the generated configurations confirms that the models capture not only scale invariance but also reproduce nontrivial eigenvalues of the RG transformation. Surprisingly, we find that increasing network complexity by introducing multiple layers offers no significant benefit. These findings suggest that simple local rules, akin to those generating fractal structures, are sufficient to encode the universality of critical phenomena, opening the door to efficient generative models of statistical ensembles in physics.","authors":["Adam Ran\\c{c}on","Ulysse Ran\\c{c}on","Tomislav Ivek","Ivan Balog"],"url":"https://arxiv.org/abs/2506.04016"}
{"created":"2025-06-05","title":"Conformal coronary calcification volume estimation with conditional coverage via histogram clustering","abstract":"Incidental detection and quantification of coronary calcium in CT scans could lead to the early introduction of lifesaving clinical interventions. However, over-reporting could negatively affect patient wellbeing and unnecessarily burden the medical system. Therefore, careful considerations should be taken when automatically reporting coronary calcium scores. A cluster-based conditional conformal prediction framework is proposed to provide score intervals with calibrated coverage from trained segmentation networks without retraining. The proposed method was tuned and used to calibrate predictive intervals for 3D UNet models (deterministic, MCDropout and deep ensemble) reaching similar coverage with better triage metrics compared to conventional conformal prediction. Meaningful predictive intervals of calcium scores could help triage patients according to the confidence of their risk category prediction.","authors":["Olivier Jaubert","Salman Mohammadi","Keith A. Goatman","Shadia S. Mikhael","Conor Bradley","Rebecca Hughes","Richard Good","John H. Hipwell","Sonia Dahdouh"],"url":"https://arxiv.org/abs/2506.04030"}
{"created":"2025-06-05","title":"Similarity-based fuzzy clustering scientific articles: potentials and challenges from mathematical and computational perspectives","abstract":"Fuzzy clustering, which allows an article to belong to multiple clusters with soft membership degrees, plays a vital role in analyzing publication data. This problem can be formulated as a constrained optimization model, where the goal is to minimize the discrepancy between the similarity observed from data and the similarity derived from a predicted distribution. While this approach benefits from leveraging state-of-the-art optimization algorithms, tailoring them to work with real, massive databases like OpenAlex or Web of Science - containing about 70 million articles and a billion citations - poses significant challenges. We analyze potentials and challenges of the approach from both mathematical and computational perspectives. Among other things, second-order optimality conditions are established, providing new theoretical insights, and practical solution methods are proposed by exploiting the structure of the problem. Specifically, we accelerate the gradient projection method using GPU-based parallel computing to efficiently handle large-scale data.","authors":["Vu Thi Huong","Ida Litzel","Thorsten Koch"],"url":"https://arxiv.org/abs/2506.04045"}
{"created":"2025-06-05","title":"chemtrain-deploy: A parallel and scalable framework for machine learning potentials in million-atom MD simulations","abstract":"Machine learning potentials (MLPs) have advanced rapidly and show great promise to transform molecular dynamics (MD) simulations. However, most existing software tools are tied to specific MLP architectures, lack integration with standard MD packages, or are not parallelizable across GPUs. To address these challenges, we present chemtrain-deploy, a framework that enables model-agnostic deployment of MLPs in LAMMPS. chemtrain-deploy supports any JAX-defined semi-local potential, allowing users to exploit the functionality of LAMMPS and perform large-scale MLP-based MD simulations on multiple GPUs. It achieves state-of-the-art efficiency and scales to systems containing millions of atoms. We validate its performance and scalability using graph neural network architectures, including MACE, Allegro, and PaiNN, applied to a variety of systems, such as liquid-vapor interfaces, crystalline materials, and solvated peptides. Our results highlight the practical utility of chemtrain-deploy for real-world, high-performance simulations and provide guidance for MLP architecture selection and future design.","authors":["Paul Fuchs","Weilong Chen","Stephan Thaler","Julija Zavadlav"],"url":"https://arxiv.org/abs/2506.04055"}
{"created":"2025-06-05","title":"Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays","abstract":"An essential step in deploying medical imaging models is ensuring alignment with clinical knowledge and interpretability. We focus on mapping clinical concepts into the latent space of generative models to identify Concept Activation Vectors (CAVs). Using a simple reconstruction autoencoder, we link user-defined concepts to image-level features without explicit label training. The extracted concepts are stable across datasets, enabling visual explanations that highlight clinically relevant features. By traversing latent space along concept directions, we produce counterfactuals that exaggerate or reduce specific clinical features. Preliminary results on chest X-rays show promise for large pathologies like cardiomegaly, while smaller pathologies remain challenging due to reconstruction limits. Although not outperforming baselines, this approach offers a path toward interpretable, concept-based explanations aligned with clinical knowledge.","authors":["Bulat Maksudov","Kathleen Curran","Alessandra Mileo"],"url":"https://arxiv.org/abs/2506.04058"}
{"created":"2025-06-05","title":"Mapped Exponent and Asymptotic Critical Exponent of Words","abstract":"We study how much injective morphisms can increase the repetitiveness of a given word. This question has a few possible variations depending on the meaning of ``repetitiveness''. We concentrate on fractional exponents of finite words and asymptotic critical exponents of infinite words. We characterize finite words that, when mapped by injective morphisms, can have arbitrarily high fractional exponent. For infinite words, alongside other results, we show that the asymptotic critical exponent grows at most by a constant factor (depending on the size of the alphabet) when mapped by an injective morphism. For both finite and infinite words, the binary case is better understood than the general case.","authors":["Eva Foster","Aleksi Saarela","Aleksi Vanhatalo"],"url":"https://arxiv.org/abs/2506.04091"}
{"created":"2025-06-05","title":"Spanning-tree-packing protocol for conference key propagation in quantum networks","abstract":"We consider a network of users connected by pairwise quantum key distribution (QKD) links. Using these pairwise secret keys and public classical communication, the users want to generate a common (conference) secret key at the maximal rate. We propose an algorithm based on spanning tree packing (a known problem in graph theory) and prove its optimality. This algorithm enables optimal conference key generation in modern quantum networks of arbitrary topology. Additionally, we discuss how it can guide the optimal placement of new bipartite links in the network design.","authors":["Anton Trushechkin","Hermann Kampermann","Dagmar Bru{\\ss}"],"url":"https://arxiv.org/abs/2506.04105"}
{"created":"2025-06-05","title":"Risk and Reward of Transitioning from a National to a Zonal Electricity Market in Great Britain","abstract":"More spatially granular electricity wholesale markets promise more efficient operation and better asset siting in highly renewable power systems. Great Britain is considering moving from its current single-price national wholesale market to a zonal design. Existing studies reach varying and difficult-to-reconcile conclusions about the desirability of a zonal market in GB, partly because they rely on models that vary in their transparency and assumptions about future power systems. Using a novel open-source electricity market model, calibrated to match observed network behaviour, this article quantifies consumer savings, unit-level producer surplus impacts, and broader socioeconomic benefits that would have arisen had a six-zone market operated in Great Britain during 2022-2024. In the absence of mitigating policies, it is estimated that during those three years GB consumers would save approximately {\\pounds}9.4/MWh (equalling an average of more than {\\pounds}2.3B per year), but generators in northern regions would experience revenue reductions of 30-40\\%. Policy interventions can restore these units' national market revenues to up to 97\\% while still preserving around {\\pounds}3.1/MWh in consumer savings (about {\\pounds}750M per year). It is further estimated that the current system could achieve approximately {\\pounds}380-{\\pounds}770 million in annual welfare gain during 2022-2024 through improved operational efficiency alone. The drivers behind these benefits, notably wind curtailment volumes, are expected to become more pronounced towards 2030, suggesting that purely operationally achieved annual benefits of around {\\pounds}1-2 billion beyond 2029 are likely. It is found that the scale of these benefits would outweigh the potential downsides related to increases in the cost of capital that have been estimated elsewhere.","authors":["Lukas Franken","Andrew Lyden","Daniel Friedrich"],"url":"https://arxiv.org/abs/2506.04107"}
{"created":"2025-06-05","title":"A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging","abstract":"In medical imaging, 4D MRI enables dynamic 3D visualization, yet the trade-off between spatial and temporal resolution requires prolonged scan time that can compromise temporal fidelity--especially during rapid, large-amplitude motion. Traditional approaches typically rely on registration-based interpolation to generate intermediate frames. However, these methods struggle with large deformations, resulting in misregistration, artifacts, and diminished spatial consistency. To address these challenges, we propose TSSC-Net, a novel framework that generates intermediate frames while preserving spatial consistency. To improve temporal fidelity under fast motion, our diffusion-based temporal super-resolution network generates intermediate frames using the start and end frames as key references, achieving 6x temporal super-resolution in a single inference step. Additionally, we introduce a novel tri-directional Mamba-based module that leverages long-range contextual information to effectively resolve spatial inconsistencies arising from cross-slice misalignment, thereby enhancing volumetric coherence and correcting cross-slice errors. Extensive experiments were performed on the public ACDC cardiac MRI dataset and a real-world dynamic 4D knee joint dataset. The results demonstrate that TSSC-Net can generate high-resolution dynamic MRI from fast-motion data while preserving structural fidelity and spatial consistency.","authors":["Xuanru Zhou","Jiarun Liu","Shoujun Yu","Hao Yang","Cheng Li","Tao Tan","Shanshan Wang"],"url":"https://arxiv.org/abs/2506.04116"}
{"created":"2025-06-05","title":"A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks","abstract":"Over the past decade, Medical Image Segmentation (MIS) using Deep Neural Networks (DNNs) has achieved significant performance improvements and holds great promise for future developments. This paper presents a comprehensive study on MIS based on DNNs. Intelligent Vision Systems are often evaluated based on their output levels, such as Data, Information, Knowledge, Intelligence, and Wisdom (DIKIW),and the state-of-the-art solutions in MIS at these levels are the focus of research. Additionally, Explainable Artificial Intelligence (XAI) has become an important research direction, as it aims to uncover the \"black box\" nature of previous DNN architectures to meet the requirements of transparency and ethics. The study emphasizes the importance of MIS in disease diagnosis and early detection, particularly for increasing the survival rate of cancer patients through timely diagnosis. XAI and early prediction are considered two important steps in the journey from \"intelligence\" to \"wisdom.\" Additionally, the paper addresses existing challenges and proposes potential solutions to enhance the efficiency of implementing DNN-based MIS.","authors":["Loan Dao","Ngoc Quoc Ly"],"url":"https://arxiv.org/abs/2506.04121"}
{"created":"2025-06-05","title":"Recent Advances in Medical Image Classification","abstract":"Medical image classification is crucial for diagnosis and treatment, benefiting significantly from advancements in artificial intelligence. The paper reviews recent progress in the field, focusing on three levels of solutions: basic, specific, and applied. It highlights advances in traditional methods using deep learning models like Convolutional Neural Networks and Vision Transformers, as well as state-of-the-art approaches with Vision Language Models. These models tackle the issue of limited labeled data, and enhance and explain predictive results through Explainable Artificial Intelligence.","authors":["Loan Dao","Ngoc Quoc Ly"],"url":"https://arxiv.org/abs/2506.04129"}
{"created":"2025-06-05","title":"Plant Bioelectric Early Warning Systems: A Five-Year Investigation into Human-Plant Electromagnetic Communication","abstract":"We present a comprehensive investigation into plant bioelectric responses to human presence and emotional states, building on five years of systematic research. Using custom-built plant sensors and machine learning classification, we demonstrate that plants generate distinct bioelectric signals correlating with human proximity, emotional states, and physiological conditions. A deep learning model based on ResNet50 architecture achieved 97% accuracy in classifying human emotional states through plant voltage spectrograms, while control models with shuffled labels achieved only 30% accuracy. This study synthesizes findings from multiple experiments spanning 2020-2025, including individual recognition (66% accuracy), eurythmic gesture detection, stress prediction, and responses to human voice and movement. We propose that these phenomena represent evolved anti-herbivory early warning systems, where plants detect approaching animals through bioelectric field changes before physical contact. Our results challenge conventional understanding of plant sensory capabilities and suggest practical applications in agriculture, healthcare, and human-plant interaction research.","authors":["Peter A. Gloor"],"url":"https://arxiv.org/abs/2506.04132"}
{"created":"2025-06-05","title":"A primal-dual price-optimization method for computing equilibrium prices in mean-field games models","abstract":"We develop a simple yet efficient Lagrangian method for computing equilibrium prices in a mean-field game price-formation model. We prove that equilibrium prices are optimal in terms of a suitable criterion and derive a primal-dual gradient-based algorithm for computing them. One of the highlights of our computational framework is the efficient, simple, and flexible implementation of the algorithm using modern automatic differentiation techniques. Our implementation is modular and admits a seamless extension to high-dimensional settings with more complex dynamics, costs, and equilibrium conditions. Additionally, automatic differentiation enables a versatile algorithm that requires only coding the cost functions of agents. It automatically handles the gradients of the costs, thereby eliminating the need to manually form the adjoint equations.","authors":["Xu Wang","Samy Wu Fung","Levon Nurbekyan"],"url":"https://arxiv.org/abs/2506.04169"}
{"created":"2025-06-05","title":"Estimation of the reduced density matrix and entanglement entropies using autoregressive networks","abstract":"We present an application of autoregressive neural networks to Monte Carlo simulations of quantum spin chains using the correspondence with classical two-dimensional spin systems. We use a hierarchy of neural networks capable of estimating conditional probabilities of consecutive spins to evaluate elements of reduced density matrices directly. Using the Ising chain as an example, we calculate the continuum limit of the ground state's von Neumann and R\\'enyi bipartite entanglement entropies of an interval built of up to 5 spins. We demonstrate that our architecture is able to estimate all the needed matrix elements with just a single training for a fixed time discretization and lattice volume. Our method can be applied to other types of spin chains, possibly with defects, as well as to estimating entanglement entropies of thermal states at non-zero temperature.","authors":["Piotr Bia{\\l}as","Piotr Korcyl","Tomasz Stebel","Dawid Zapolski"],"url":"https://arxiv.org/abs/2506.04170"}
{"created":"2025-06-05","title":"Understanding challenges to the interpretation of disaggregated evaluations of algorithmic fairness","abstract":"Disaggregated evaluation across subgroups is critical for assessing the fairness of machine learning models, but its uncritical use can mislead practitioners. We show that equal performance across subgroups is an unreliable measure of fairness when data are representative of the relevant populations but reflective of real-world disparities. Furthermore, when data are not representative due to selection bias, both disaggregated evaluation and alternative approaches based on conditional independence testing may be invalid without explicit assumptions regarding the bias mechanism. We use causal graphical models to predict metric stability across subgroups under different data generating processes. Our framework suggests complementing disaggregated evaluations with explicit causal assumptions and analysis to control for confounding and distribution shift, including conditional independence testing and weighted performance estimation. These findings have broad implications for how practitioners design and interpret model assessments given the ubiquity of disaggregated evaluation.","authors":["Stephen R. Pfohl","Natalie Harris","Chirag Nagpal","David Madras","Vishwali Mhasawade","Olawale Salaudeen","Awa Dieng","Shannon Sequeira","Santiago Arciniegas","Lillian Sung","Nnamdi Ezeanochie","Heather Cole-Lewis","Katherine Heller","Sanmi Koyejo","Alexander D'Amour"],"url":"https://arxiv.org/abs/2506.04193"}
{"created":"2025-06-05","title":"What Makes Treatment Effects Identifiable? Characterizations and Estimators Beyond Unconfoundedness","abstract":"Most of the widely used estimators of the average treatment effect (ATE) in causal inference rely on the assumptions of unconfoundedness and overlap. Unconfoundedness requires that the observed covariates account for all correlations between the outcome and treatment. Overlap requires the existence of randomness in treatment decisions for all individuals. Nevertheless, many types of studies frequently violate unconfoundedness or overlap, for instance, observational studies with deterministic treatment decisions -- popularly known as Regression Discontinuity designs -- violate overlap.","authors":["Yang Cai","Alkis Kalavasis","Katerina Mamali","Anay Mehrotra","Manolis Zampetakis"],"url":"https://arxiv.org/abs/2506.04194"}
{"created":"2025-06-05","title":"DropCluster: A structured dropout for convolutional networks","abstract":"Dropout as a common regularizer to prevent overfitting in deep neural networks has been less effective in convolutional layers than in fully connected layers. This is because Dropout drops features randomly, without considering local structure. When features are spatially correlated, as in the case of convolutional layers, information from the dropped features can still propagate to subsequent layers via neighboring features. To address this problem, structured forms of Dropout have been proposed. A drawback of these methods is that they do not adapt to the data. In this work, we leverage the structure in the outputs of convolutional layers and introduce a novel structured regularization method named DropCluster. Our approach clusters features in convolutional layers, and drops the resulting clusters randomly during training iterations. Experiments on CIFAR-10/100, SVHN, and APPA-REAL datasets demonstrate that our approach is effective and controls overfitting better than other approaches.","authors":["Liyan Chen","Philippos Mordohai","Sergul Aydore"],"url":"https://arxiv.org/abs/2002.02997"}
{"created":"2025-06-05","title":"Optimal Transmission Switching: Improving Solver Performance Using Heuristics","abstract":"The optimal transmission switching problem (OTSP) is an established problem of changing a power grid's topology to obtain an improved operation by controlling the switching status of transmission lines. This problem was proven to be NP-hard. Proposed solution techniques based on mixed-integer formulations can guarantee globally optimal solutions but are potentially intractable in realistic power grids. Heuristics methods cannot guarantee global optimality but can provide tractable solution approaches.","authors":["Anton Hinneck","David Pozo"],"url":"https://arxiv.org/abs/2106.12331"}
{"created":"2025-06-05","title":"Risk Awareness in HTN Planning","abstract":"Actual real-world domains are characterised by uncertain situations in which acting and using resources may entail the embracing of risks. Performing actions in such domains involves costs of consuming some resource, such as time or energy, where the knowledge about these costs can range from known to totally unknown. In autonomous vehicles, actions have uncertain costs due to factors like traffic. Choosing an action requires assessing delay risks, as each road may have unpredictable congestion. Thus, these domains call for not only planning under uncertainty but also planning while embracing risk. Resorting to HTN planning as a widely used planning technique in real-world applications, one can observe that existing approaches assume risk neutrality, relying on single-valued action costs without considering risk. Here, we enhance HTN planning with risk awareness by considering expected utility theory. We introduce a general framework for HTN planning that allows modelling risk and uncertainty using a probability distribution of action costs upon which we define risk-aware HTN planning as being capable of accounting for the different risk attitudes and allowing the computation of plans that go beyond risk neutrality. We lay out that computing risk-aware plans requires finding plans with the highest expected utility. We argue that it is possible for HTN planning agents to solve specialised risk-aware HTN planning problems by adapting existing HTN planning approaches, and develop an approach that surpasses the expressiveness of current approaches by allowing these agents to compute plans tailored to a particular risk attitude. An empirical evaluation of two case studies highlights the feasibility and expressiveness of this approach. We also highlight open issues, such as applying the proposal beyond HTN planning, covering both modelling and plan generation.","authors":["Ebaa Alnazer","Ilche Georgievski","Marco Aiello"],"url":"https://arxiv.org/abs/2204.10669"}
{"created":"2025-06-05","title":"Direct closed-loop identification of continuous-time systems using fixed-pole observer model","abstract":"This paper provides a method for obtaining a continuous-time model of a target system in closed-loop from input-output data alone, in the case where no knowledge of the controllers nor excitation signals is available and I/O data may suffer from unknown offsets. The proposed method is based on a fixed-pole observer model, which is a reasonable continuous-time version corresponding to the innovation model in discrete-time and allows the identification of unstable target systems. Furthermore, it is shown that the proposed method can be attributed to a convex optimization problem by fixing the observer poles. The method is within the framework of the stabilized output error method and shares usability advantages such as robustness to noise with complex dynamics and applicability to a wide class of models. The effectiveness of the method is illustrated through numerical examples.","authors":["Ichiro Maruta","Toshiharu Sugie"],"url":"https://arxiv.org/abs/2205.00368"}
{"created":"2025-06-05","title":"Efficient scheduling in redundancy systems with general service times","abstract":"We characterize the impact of scheduling policies on the mean response time in nested systems with cancel-on-complete redundancy. We consider not only redundancy-oblivious policies, such as FCFS and ROS, but also redundancy-aware policies of the form $\\Pi$ 1 -- $\\Pi$ 2 , where $\\Pi$ 1 discriminates among job classes (e.g., least-redundant-first (LRF), most-redundantfirst (MRF)) and $\\Pi$ 2 discriminates among jobs of the same class. Assuming that jobs have independent and identically distributed (i.i.d.) copies, we prove the following: (i) When jobs have exponential service times, LRF policies outperform any other policy. (ii) When service times are New-Worse-than-Used, MRF-FCFS outperforms LRF-FCFS as the variability of the service time grows infinitely large. (iii) When service times are New-Better-than-Used, LRF-ROS (resp. MRF-ROS) outperforms LRF-FCFS (resp. MRF-FCFS) in a two-server system. Statement (iii) also holds when job sizes follow a general distribution and have identical copies (all the copies of a job have the same size). Moreover, we show via simulation that, for a large class of redundancy systems, redundancy-aware policies can considerably improve the mean response time compared to redundancy-oblivious policies. We also explore the effect of redundancy on the stability region.","authors":["Elene Anton (UPPA)","Rhonda Righter (UC Berkeley)","Ina Maria Maaike Verloop (IRIT-RMESS","Toulouse INP","CNRS)"],"url":"https://arxiv.org/abs/2206.10164"}
{"created":"2025-06-05","title":"Space-efficient Data Structure for Next/Previous Larger/Smaller Value Queries","abstract":"Given an array of size $n$ from a total order, we consider the problem of constructing a data structure that supports various queries (range minimum/maximum queries with their variants and next/previous larger/smaller queries) efficiently. In the encoding model (i.e., the queries can be answered without the input array), we propose a $(3.701n + o(n))$-bit data structure, which supports all these queries in $O(\\log^{(\\ell)}n)$ time, for any positive constant integer $\\ell$ (here, $\\log^{(1)} n = \\log n$, and for $\\ell > 1$, $\\log^{(\\ell)} n = \\log ({\\log^{(\\ell-1)}} n)$). The space of our data structure matches the current best upper bound of Tsur (Inf. Process. Lett., 2019), which does not support the queries efficiently. Also, we show that at least $3.16n-\\Theta(\\log n)$ bits are necessary for answering all the queries. Our result is obtained by generalizing Gawrychowski and Nicholson's $(3n - \\Theta(\\log n))$-bit lower bound (ICALP, 15) for answering range minimum and maximum queries on a permutation of size $n$.","authors":["Seungbum Jo","Geunho Kim"],"url":"https://arxiv.org/abs/2209.00158"}
{"created":"2025-06-05","title":"Powerful Primitives in the Bounded Quantum Storage Model","abstract":"The bounded quantum storage model aims to achieve security against computationally unbounded adversaries that are restricted only with respect to their quantum memories. In this work, we provide information-theoretic secure constructions in this model for the following powerful primitives: (1) CCA1-secure symmetric key encryption, message authentication codes, and one-time programs. These schemes require no quantum memory for the honest user, while they can be made secure against adversaries with arbitrarily large memories by increasing the transmission length sufficiently. (2) CCA1-secure asymmetric key encryption, encryption tokens, signatures, signature tokens, and program broadcast. These schemes are secure against adversaries with roughly $e^{\\sqrt{m}}$ quantum memory where $m$ is the quantum memory required for the honest user. All of the constructions additionally satisfy disappearing security, essentially preventing an adversary from storing and using a transmission later on.","authors":["Mohammed Barhoush","Louis Salvail"],"url":"https://arxiv.org/abs/2302.05724"}
{"created":"2025-06-05","title":"Uncovering Challenges of Solving the Continuous Gromov-Wasserstein Problem","abstract":"Recently, the Gromov-Wasserstein Optimal Transport (GWOT) problem has attracted the special attention of the ML community. In this problem, given two distributions supported on two (possibly different) spaces, one has to find the most isometric map between them. In the discrete variant of GWOT, the task is to learn an assignment between given discrete sets of points. In the more advanced continuous formulation, one aims at recovering a parametric mapping between unknown continuous distributions based on i.i.d. samples derived from them. The clear geometrical intuition behind the GWOT makes it a natural choice for several practical use cases, giving rise to a number of proposed solvers. Some of them claim to solve the continuous version of the problem. At the same time, GWOT is notoriously hard, both theoretically and numerically. Moreover, all existing continuous GWOT solvers still heavily rely on discrete techniques. Natural questions arise: to what extent do existing methods unravel the GWOT problem, what difficulties do they encounter, and under which conditions they are successful? Our benchmark paper is an attempt to answer these questions. We specifically focus on the continuous GWOT as the most interesting and debatable setup. We crash-test existing continuous GWOT approaches on different scenarios, carefully record and analyze the obtained results, and identify issues. Our findings experimentally testify that the scientific community is still missing a reliable continuous GWOT solver, which necessitates further research efforts. As the first step in this direction, we propose a new continuous GWOT method which does not rely on discrete techniques and partially solves some of the problems of the competitors.","authors":["Xavier Aramayo Carrasco","Maksim Nekrashevich","Petr Mokrov","Evgeny Burnaev","Alexander Korotin"],"url":"https://arxiv.org/abs/2303.05978"}
{"created":"2025-06-05","title":"Transformers in Speech Processing: A Survey","abstract":"The remarkable success of transformers in the field of natural language processing has sparked the interest of the speech-processing community, leading to an exploration of their potential for modeling long-range dependencies within speech sequences. Recently, transformers have gained prominence across various speech-related domains, including automatic speech recognition, speech synthesis, speech translation, speech para-linguistics, speech enhancement, spoken dialogue systems, and numerous multimodal applications. In this paper, we present a comprehensive survey that aims to bridge research studies from diverse subfields within speech technology. By consolidating findings from across the speech technology landscape, we provide a valuable resource for researchers interested in harnessing the power of transformers to advance the field. We identify the challenges encountered by transformers in speech processing while also offering insights into potential solutions to address these issues.","authors":["Siddique Latif","Aun Zaidi","Heriberto Cuayahuitl","Fahad Shamshad","Moazzam Shoukat","Muhammad Usama","Junaid Qadir"],"url":"https://arxiv.org/abs/2303.11607"}
{"created":"2025-06-05","title":"Torch-Choice: A PyTorch Package for Large-Scale Choice Modeling with Python","abstract":"The $\\texttt{torch-choice}$ is an open-source library for flexible, fast choice modeling with Python and PyTorch. $\\texttt{torch-choice}$ provides a $\\texttt{ChoiceDataset}$ data structure to manage databases flexibly and memory-efficiently. The paper demonstrates constructing a $\\texttt{ChoiceDataset}$ from databases of various formats and functionalities of $\\texttt{ChoiceDataset}$. The package implements two widely used models, namely the multinomial logit and nested logit models, and supports regularization during model estimation. The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient. Models can be initialized using either R-style formula strings or Python dictionaries. We conclude with a comparison of the computational efficiencies of $\\texttt{torch-choice}$ and $\\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the number of covariates increases, and (3) the expansion of item sets. Finally, we demonstrate the scalability of $\\texttt{torch-choice}$ on large-scale datasets.","authors":["Tianyu Du","Ayush Kanodia","Susan Athey"],"url":"https://arxiv.org/abs/2304.01906"}
{"created":"2025-06-05","title":"Energy-Latency Aware Intelligent Reflecting Surface Aided Multi-cell Mobile Edge Computing","abstract":"The explosive development of the Internet of Things (IoT) has led to increased interest in mobile edge computing (MEC), which provides computational resources at network edges to accommodate computation-intensive and latency-sensitive applications. Intelligent reflecting surfaces (IRSs) have gained attention as a solution to overcome blockage problems during the offloading uplink transmission in MEC systems. This paper explores IRS-aided multi-cell networks that enable servers to serve neighboring cells and cooperate to handle resource exhaustion. We aim to minimize the joint energy and latency cost, by jointly optimizing computation tasks, edge computing resources, user beamforming, and IRS phase shifts. The problem is decomposed into two subproblems--the MEC subproblem and the IRS communication subproblem--using the block coordinate descent (BCD) technique. The MEC subproblem is reformulated as a nonconvex quadratic constrained problem (QCP), while the IRS communication subproblem is transformed into a weight-sum-rate problem with auxiliary variables. We propose an efficient algorithm to iteratively optimize MEC resources and IRS communication until convergence. Numerical results show that our algorithm outperforms benchmarks and that multi-cell MEC systems achieve additional performance gains when supported by IRS.","authors":["Wenhan Xu","Jiadong Yu","Yuan Wu","Danny H. K. Tsang"],"url":"https://arxiv.org/abs/2305.03556"}
{"created":"2025-06-05","title":"EPIC: Graph Augmentation with Edit Path Interpolation via Learnable Cost","abstract":"Data augmentation plays a critical role in improving model performance across various domains, but it becomes challenging with graph data due to their complex and irregular structure. To address this issue, we propose EPIC (Edit Path Interpolation via learnable Cost), a novel interpolation-based method for augmenting graph datasets. To interpolate between two graphs lying in an irregular domain, EPIC leverages the concept of graph edit distance, constructing an edit path that represents the transformation process between two graphs via edit operations. Moreover, our method introduces a context-sensitive cost model that accounts for the importance of specific edit operations formulated through a learning framework. This allows for a more nuanced transformation process, where the edit distance is not merely count-based but reflects meaningful graph attributes. With randomly sampled graphs from the edit path, we enrich the training set to enhance the generalization capability of classification models. Experimental evaluations across several benchmark datasets demonstrate that our approach outperforms existing augmentation techniques in many tasks.","authors":["Jaeseung Heo","Seungbeom Lee","Sungsoo Ahn","Dongwoo Kim"],"url":"https://arxiv.org/abs/2306.01310"}
{"created":"2025-06-05","title":"Automated Architecture Synthesis for Arbitrarily Structured Neural Networks","abstract":"This paper offers a new perspective on Artificial Neural Networks (ANNs) architecture. Traditional ANNs commonly use tree-like or DAG structures for simplicity, which can be preset or determined by Neural Architecture Search (NAS). Yet, these structures restrict network collaboration and capability due to the absence of horizontal and backward communication. Biological neural systems, however, feature billions of neural units with highly complex connections, allowing each biological neuron to connect with others based on specific situations. Inspired by biological systems, we propose a novel framework that learns to construct arbitrary graph structures during training and introduce the concept of Neural Modules for organizing neural units, which facilitates communication between any nodes and collaboration among modules. Unlike traditional NAS methods that rely on DAG search spaces, our framework learns from complete graphs, enabling free communication between neurons akin to biological neural networks. Furthermore, we present a method to compute these structures and a regularization technique that organizes them into multiple independent, balanced neural modules. This approach reduces overfitting and improves efficiency through parallel computing. Overall, our method allows ANNs to learn effective arbitrary structures similar to biological ones. It is adaptable to various tasks and compatible across different scenarios, with experimental results demonstrating its potential.","authors":["Xinshun Liu","Yizhi Fang","Yichao Jiang"],"url":"https://arxiv.org/abs/2306.02157"}
{"created":"2025-06-05","title":"Discounted-Sum Automata with Multiple Discount Factors","abstract":"Discounting the influence of future events is a key paradigm in economics and it is widely used in computer-science models, such as games, Markov decision processes (MDPs), reinforcement learning, and automata. While a single game or MDP may allow for several different discount factors, nondeterministic discounted-sum automata (NDAs) were only studied with respect to a single discount factor. It is known that every class of NDAs with an integer as the discount factor has good computational properties: It is closed under determinization and under the algebraic operations min, max, addition, and subtraction, and there are algorithms for its basic decision problems, such as automata equivalence and containment. Extending the integer discount factor to an arbitrary rational number, loses most of these good properties.","authors":["Udi Boker","Guy Hefetz"],"url":"https://arxiv.org/abs/2307.08780"}
{"created":"2025-06-05","title":"S$^3$: Social-network Simulation System with Large Language Model-Empowered Agents","abstract":"Social network simulation plays a crucial role in addressing various challenges within social science. It offers extensive applications such as state prediction, phenomena explanation, and policy-making support, among others. In this work, we harness the formidable human-like capabilities exhibited by large language models (LLMs) in sensing, reasoning, and behaving, and utilize these qualities to construct the S$^3$ system (short for $\\textbf{S}$ocial network $\\textbf{S}$imulation $\\textbf{S}$ystem). Adhering to the widely employed agent-based simulation paradigm, we employ prompt engineering and prompt tuning techniques to ensure that the agent's behavior closely emulates that of a genuine human within the social network. Specifically, we simulate three pivotal aspects: emotion, attitude, and interaction behaviors. By endowing the agent in the system with the ability to perceive the informational environment and emulate human actions, we observe the emergence of population-level phenomena, including the propagation of information, attitudes, and emotions. We conduct an evaluation encompassing two levels of simulation, employing real-world social network data. Encouragingly, the results demonstrate promising accuracy. This work represents an initial step in the realm of social network simulation empowered by LLM-based agents. We anticipate that our endeavors will serve as a source of inspiration for the development of simulation systems within, but not limited to, social science.","authors":["Chen Gao","Xiaochong Lan","Zhihong Lu","Jinzhu Mao","Jinghua Piao","Huandong Wang","Depeng Jin","Yong Li"],"url":"https://arxiv.org/abs/2307.14984"}
{"created":"2025-06-05","title":"Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity Resolution","abstract":"The entity resolution problem requires finding pairs across datasets that belong to different owners but refer to the same entity in the real world. To train and evaluate solutions (either rule-based or machine-learning-based) to the entity resolution problem, generating a ground truth dataset with entity pairs or clusters is needed. However, such a data annotation process involves humans as domain oracles to review the plaintext data for all candidate record pairs from different parties, which inevitably infringes the privacy of data owners, especially in privacy-sensitive cases like medical records. To the best of our knowledge, there is no prior work on privacy-preserving ground truth dataset generation, especially in the domain of entity resolution. We propose a novel blind annotation protocol based on homomorphic encryption that allows domain oracles to collaboratively label ground truths without sharing data in plaintext with other parties. In addition, we design a domain-specific easy-to-use language that hides the sophisticated underlying homomorphic encryption layer. Rigorous proof of the privacy guarantee is provided and our empirical experiments via an annotation simulator indicate the feasibility of our privacy-preserving protocol (f-measure on average achieves more than 90\\% compared with the real ground truths).","authors":["Yixiang Yao","Weizhao Jin","Srivatsan Ravi"],"url":"https://arxiv.org/abs/2308.03734"}
{"created":"2025-06-05","title":"WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct","abstract":"Large language models (LLMs), such as GPT-4, have shown remarkable performance in natural language processing (NLP) tasks, including challenging mathematical reasoning. However, most existing open-source models are only pre-trained on large-scale internet data and without math-related optimization. In this paper, we present WizardMath, which enhances the mathematical CoT reasoning abilities of LLMs without using external python tools, by applying our proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method to the domain of math. Through extensive experiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary capabilities of our model. Remarkably, WizardMath-Mistral 7B surpasses top-tier open-source LLMs by a substantial margin with higher data efficiency. Furthermore, WizardMath 70B even outperforms GPT-3.5-Turbo, Claude 2, Gemini Pro and GPT-4-early-version. Additionally, our preliminary exploration highlights the pivotal role of instruction evolution and process supervision in achieving exceptional math performance. For more details refer to https://github.com/nlpxucan/WizardLM","authors":["Haipeng Luo","Qingfeng Sun","Can Xu","Pu Zhao","Jianguang Lou","Chongyang Tao","Xiubo Geng","Qingwei Lin","Shifeng Chen","Yansong Tang","Dongmei Zhang"],"url":"https://arxiv.org/abs/2308.09583"}
{"created":"2025-06-05","title":"Easy attention: A simple attention mechanism for temporal predictions with transformers","abstract":"To improve the robustness of transformer neural networks used for temporal-dynamics prediction of chaotic systems, we propose a novel attention mechanism called easy attention which we demonstrate in time-series reconstruction and prediction. While the standard self attention only makes use of the inner product of queries and keys, it is demonstrated that the keys, queries and softmax are not necessary for obtaining the attention score required to capture long-term dependencies in temporal sequences. Through the singular-value decomposition (SVD) on the softmax attention score, we further observe that self attention compresses the contributions from both queries and keys in the space spanned by the attention score. Therefore, our proposed easy-attention method directly treats the attention scores as learnable parameters. This approach produces excellent results when reconstructing and predicting the temporal dynamics of chaotic systems exhibiting more robustness and less complexity than self attention or the widely-used long short-term memory (LSTM) network. We show the improved performance of the easy-attention method in the Lorenz system, a turbulence shear flow and a model of a nuclear reactor.","authors":["Marcial Sanchis-Agudo","Yuning Wang","Roger Arnau","Luca Guastoni","Jasmin Lim","Karthik Duraisamy","Ricardo Vinuesa"],"url":"https://arxiv.org/abs/2308.12874"}
{"created":"2025-06-05","title":"Equivariant Symmetries for Inertial Navigation Systems","abstract":"This paper investigates the problem of inertial navigation system (INS) filter design through the lens of symmetry. The extended Kalman filter (EKF) and its variants have been the staple of INS filtering for 50 years. However, recent advances in inertial navigation systems have exploited matrix Lie group structure to design stochastic filters and state observers that have been shown to display superior performance compared to classical solutions. In this work, we explore various symmetries of inertial navigation system, including two novel symmetries that have not been considered in the prior literature, and provide a discussion of the relative strengths and weaknesses of these symmetries in the context of filter design. We show that all the modern variants of the EKF for inertial navigation can be interpreted as the recently proposed equivariant filter (EqF) design methodology applied to different choices of symmetry group for the INS problem. As a direct application of the symmetries presented, we address the filter design problem for a vehicle equipped with an inertial measurement unit (IMU) and a global navigation satellite system (GNSS) receiver, providing a comparative analysis of different modern filter solutions. We believe the collection of symmetries that we present here capture all the sensible choices of symmetry for this problem, and that the analysis provided is indicative of the relative real-world performance potential of the different algorithms for trajectories ensuring full state observability.","authors":["Alessandro Fornasier","Yixiao Ge","Pieter van Goor","Robert Mahony","Stephan Weiss"],"url":"https://arxiv.org/abs/2309.03765"}
{"created":"2025-06-05","title":"Learning Tube-Certified Control using Robust Contraction Metrics","abstract":"Control design for general nonlinear robotic systems with guaranteed stability and/or safety in the presence of model uncertainties is a challenging problem. Recent efforts attempt to learn a controller and a certificate (e.g., a Lyapunov function or a contraction metric) jointly using neural networks (NNs), in which model uncertainties are generally ignored during the learning process. In this paper, for nonlinear systems subject to bounded disturbances, we present a framework for jointly learning a robust nonlinear controller and a contraction metric using a novel disturbance rejection objective that certifies a tube bound using NNs for user-specified variables (e.g. control inputs). The learned controller aims to minimize the effect of disturbances on the actual trajectories of state and/or input variables from their nominal counterparts while providing certificate tubes around nominal trajectories that are guaranteed to contain actual trajectories in the presence of disturbances. Experimental results demonstrate that our framework can generate tighter (smaller) tubes and a controller that is computationally efficient to implement.","authors":["Vivek Sharma","Pan Zhao","Naira Hovakimyan"],"url":"https://arxiv.org/abs/2309.07443"}
{"created":"2025-06-05","title":"Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities","abstract":"Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, including split learning/inference, parameter-efficient fine-tuning, quantization, and parameter-sharing inference, to facilitate the efficient deployment of LLMs. This article serves as a position paper for thoroughly identifying the motivation, challenges, and pathway for empowering LLMs at the 6G edge.","authors":["Zheng Lin","Guanqiao Qu","Qiyuan Chen","Xianhao Chen","Zhe Chen","Kaibin Huang"],"url":"https://arxiv.org/abs/2309.16739"}
{"created":"2025-06-05","title":"Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scoring of Texts with Large Language Models","abstract":"Existing text scoring methods require a large corpus, struggle with short texts, or require hand-labeled data. We develop a text scoring framework that leverages generative large language models (LLMs) to (1) set texts against the backdrop of information from the near-totality of the web and digitized media, and (2) effectively transform pairwise text comparisons from a reasoning problem to a pattern recognition task. Our approach, concept-guided chain-of-thought (CGCoT), utilizes a chain of researcher-designed prompts with an LLM to generate a concept-specific breakdown for each text, akin to guidance provided to human coders. We then pairwise compare breakdowns using an LLM and aggregate answers into a score using a probability model. We apply this approach to better understand speech reflecting aversion to specific political parties on Twitter, a topic that has commanded increasing interest because of its potential contributions to democratic backsliding. We achieve stronger correlations with human judgments than widely used unsupervised text scoring methods like Wordfish. In a supervised setting, besides a small pilot dataset to develop CGCoT prompts, our measures require no additional hand-labeled data and produce predictions on par with RoBERTa-Large fine-tuned on thousands of hand-labeled tweets. This project showcases the potential of combining human expertise and LLMs for scoring tasks.","authors":["Patrick Y. Wu","Jonathan Nagler","Joshua A. Tucker","Solomon Messing"],"url":"https://arxiv.org/abs/2310.12049"}
{"created":"2025-06-05","title":"Generalized GM-MDS: Polynomial Codes are Higher Order MDS","abstract":"The GM-MDS theorem, conjectured by Dau-Song-Dong-Yuen and proved by Lovett and Yildiz-Hassibi, shows that the generator matrices of Reed-Solomon codes can attain every possible configuration of zeros for an MDS code. The recently emerging theory of higher order MDS codes has connected the GM-MDS theorem to other important properties of Reed-Solomon codes, including showing that Reed-Solomon codes can achieve list decoding capacity, even over fields of size linear in the message length.","authors":["Joshua Brakensiek","Manik Dhar","Sivakanth Gopi"],"url":"https://arxiv.org/abs/2310.12888"}
{"created":"2025-06-05","title":"AG Codes Achieve List-decoding Capacity over Constant-sized Fields","abstract":"The recently-emerging field of higher order MDS codes has sought to unify a number of concepts in coding theory. Such areas captured by higher order MDS codes include maximally recoverable (MR) tensor codes, codes with optimal list-decoding guarantees, and codes with constrained generator matrices (as in the GM-MDS theorem).","authors":["Joshua Brakensiek","Manik Dhar","Sivakanth Gopi","Zihan Zhang"],"url":"https://arxiv.org/abs/2310.12898"}
{"created":"2025-06-05","title":"A filtered multilevel Monte Carlo method for estimating the expectation of cell-centered discretized random fields","abstract":"In this paper, we investigate the use of multilevel Monte Carlo (MLMC) methods for estimating the expectation of discretized random fields. Specifically, we consider a setting in which the input and output vectors of numerical simulators have inconsistent dimensions across the multilevel hierarchy. This motivates the introduction of grid transfer operators borrowed from multigrid methods. By adapting mathematical tools from multigrid methods, we perform a theoretical spectral analysis of the MLMC estimator of the expectation of discretized random fields, in the specific case of linear, symmetric and circulant simulators. We then propose filtered MLMC (F-MLMC) estimators based on a filtering mechanism similar to the smoothing process of multigrid methods, and we show that the filtering operators improve the estimation of both the small- and large-scale components of the variance, resulting in a reduction of the total variance of the estimator. Next, the conclusions of the spectral analysis are experimentally verified with a one-dimensional illustration. Finally, the proposed F-MLMC estimator is applied to the problem of estimating the discretized variance field of a diffusion-based covariance operator, which amounts to estimating the expectation of a discretized random field. The numerical experiments support the conclusions of the theoretical analysis even with non-linear simulators, and demonstrate the improvements brought by the F-MLMC estimator compared to both a crude MC and an unfiltered MLMC estimator.","authors":["J\\'er\\'emy Briant (IRIT","Univ Toulouse","CNRS","Toulouse INP","CECI","Univ Toulouse","Cerfacs","CNRS","IRD)","Paul Mycek (Cerfacs","CECI","Univ Toulouse","Cerfacs","CNRS","IRD)","Mayeul Destouches (CNRM","Univ Toulouse","M\\'et\\'eo-France","CNRS)","Olivier Goux (Cerfacs","CECI","Univ Toulouse","Cerfacs","CNRS","IRD)","Serge Gratton (IRIT","Univ Toulouse","CNRS","Toulouse INP","ANITI)","Selime G\\\"urol (Cerfacs","CECI","Univ Toulouse","Cerfacs","CNRS","IRD)","Ehouarn Simon (IRIT","Univ Toulouse","CNRS","Toulouse INP)","Anthony T. Weaver (Cerfacs","CECI","Univ Toulouse","Cerfacs","CNRS","IRD)"],"url":"https://arxiv.org/abs/2311.06069"}
{"created":"2025-06-05","title":"What Monads Can and Cannot Do with a Few Extra Pages","abstract":"The delay monad provides a way to introduce general recursion in type theory. To write programs that use a wide range of computational effects directly in type theory, we need to combine the delay monad with the monads of these effects. Here we present a first systematic study of such combinations.","authors":["Rasmus Ejlers M{\\o}gelberg","Maaike Zwart"],"url":"https://arxiv.org/abs/2311.15919"}
{"created":"2025-06-05","title":"MacroSwarm: A Field-based Compositional Framework for Swarm Programming","abstract":"Swarm behaviour engineering is an area of research that seeks to investigate methods and techniques for coordinating computation and action within groups of simple agents to achieve complex global goals like pattern formation, collective movement, clustering, and distributed sensing. Despite recent progress in the analysis and engineering of swarms (of drones, robots, vehicles), there is still a need for general design and implementation methods and tools that can be used to define complex swarm behaviour in a principled way. To contribute to this quest, this article proposes a new field-based coordination approach, called MacroSwarm, to design and program swarm behaviour in terms of reusable and fully composable functional blocks embedding collective computation and coordination. Based on the macroprogramming paradigm of aggregate computing, MacroSwarm builds on the idea of expressing each swarm behaviour block as a pure function, mapping sensing fields into actuation goal fields, e.g., including movement vectors. In order to demonstrate the expressiveness, compositionality, and practicality of MacroSwarm as a framework for swarm programming, we perform a variety of simulations covering common patterns of flocking, pattern formation, and collective decision-making. The implications of the inherent self-stabilisation properties of field-based computations in MacroSwarm are discussed, which formally guarantee some resilience properties and guided the design of the library.","authors":["Gianluca Aguzzi","Roberto Casadei","Mirko Viroli"],"url":"https://arxiv.org/abs/2401.10969"}
{"created":"2025-06-05","title":"Understanding the Training Speedup from Sampling with Approximate Losses","abstract":"It is well known that selecting samples with large losses/gradients can significantly reduce the number of training steps. However, the selection overhead is often too high to yield any meaningful gains in terms of overall training time. In this work, we focus on the greedy approach of selecting samples with large \\textit{approximate losses} instead of exact losses in order to reduce the selection overhead. For smooth convex losses, we show that such a greedy strategy can converge to a constant factor of the minimum value of the average loss in fewer iterations than the standard approach of random selection. We also theoretically quantify the effect of the approximation level. We then develop SIFT which uses early exiting to obtain approximate losses with an intermediate layer's representations for sample selection. We evaluate SIFT on the task of training a 110M parameter 12 layer BERT base model, and show significant gains (in terms of training hours and number of backpropagation steps) without any optimized implementation over vanilla training. For e.g., to reach 64% validation accuracy, SIFT with exit at the first layer takes ~ 43 hours compared to ~ 57 hours of vanilla training.","authors":["Rudrajit Das","Xi Chen","Bertram Ieong","Parikshit Bansal","Sujay Sanghavi"],"url":"https://arxiv.org/abs/2402.07052"}
{"created":"2025-06-05","title":"Wavelet compressed, modified Hilbert transform in the space-time discretization of the heat equation","abstract":"On a finite time interval $(0,T)$, we consider the multiresolution Galerkin discretization of a modified Hilbert transform $\\mathcal H_T$ which arises in the space-time Galerkin discretization of the linear diffusion equation. To this end, we design spline-wavelet systems in $(0,T)$ consisting of piecewise polynomials of degree $\\geq 1$ with sufficiently many vanishing moments which constitute Riesz bases in the Sobolev spaces $H^{s}_{0,}(0,T)$ and $H^{s}_{,0}(0,T)$. These bases provide stable multilevel splittings of the temporal discretization spaces into \"increment\" or \"detail\" spaces. Furthermore, they allow to optimally compress the nonlocal integrodifferential operators which appear in stable space-time variational formulations of initial-boundary value problems, such as the heat equation and the acoustic wave equation. We then obtain sparse space-time tensor-product spaces via algebraic tensor-products of the temporal multilevel discretizations with standard, hierarchic finite element spaces in the spatial domain (with standard Lagrangian FE bases). Hence, the construction of multiresolutions in the spatial domain is not necessary. An efficient multilevel preconditioner is proposed that solves the linear system of equations resulting from the sparse space-time Galerkin discretization with essentially linear complexity (in work and memory). A substantial reduction in the number of the degrees of freedom and CPU time (compared to time-marching discretizations) is demonstrated in numerical experiments.","authors":["Helmut Harbrecht","Christoph Schwab","Marco Zank"],"url":"https://arxiv.org/abs/2402.10346"}
{"created":"2025-06-05","title":"DreamFrame: Enhancing Video Understanding via Automatically Generated QA and Style-Consistent Keyframes","abstract":"Recent large vision-language models (LVLMs) for video understanding are primarily fine-tuned with various videos scraped from online platforms. Existing datasets, such as ActivityNet, require considerable human labor for structuring and annotation before effectively utilized for tuning LVLMs. While current LVLMs are primarily trained on existing datasets in broad, general-purpose settings, adapting them to specific downstream scenarios remains challenging, as collecting and annotating task-specific videos is highly labor-intensive and time-consuming. To address this issue, we propose a three-stage framework named DreamFrame for automatically generating style-consistent keyframes and corresponding question-answer (QA) pairs to support LVLM instruction tuning. DreamFrame generates datasets in a movie-like manner. First, we utilize an LLM to generate structured movie plots including movie prior information (like overview and style), frame descriptions and plot-related QA pairs, with a story expansion strategy to mitigate context length limitations.Then, to ensure visual consistency across generated frames, we design a Style Immobilization Process which maintains consistent style through an embedding learning strategy. Finally, frame descriptions and style embeddings are integrated to produce coherent keyframes. Using DreamFrame, we construct a dataset comprising approximately 1k stylized keyframe-like videos and 100k diverse QA pairs. Extensive fine-tuned experiments on various LVLM architectures demonstrate the effectiveness of the proposed dataset. Furthermore, based on the proposed dataset, we fine-tune a new LVLM named DreamFrame-7B, which significantly surpasses the previous similar-sized LVLMs across different benchmarks.","authors":["Zhende Song","Chenchen Wang","Jiamu Sheng","Chi Zhang","Shengji Tang","Jiayuan Fan","Tao Chen"],"url":"https://arxiv.org/abs/2403.01422"}
{"created":"2025-06-05","title":"Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace","abstract":"Humans perceive the world through multiple senses, enabling them to create a comprehensive representation of their surroundings and to generalize information across domains. For instance, when a textual description of a scene is given, humans can mentally visualize it. In fields like robotics and Reinforcement Learning (RL), agents can also access information about the environment through multiple sensors; yet redundancy and complementarity between sensors is difficult to exploit as a source of robustness (e.g. against sensor failure) or generalization (e.g. transfer across domains). Prior research demonstrated that a robust and flexible multimodal representation can be efficiently constructed based on the cognitive science notion of a 'Global Workspace': a unique representation trained to combine information across modalities, and to broadcast its signal back to each modality. Here, we explore whether such a brain-inspired multimodal representation could be advantageous for RL agents. First, we train a 'Global Workspace' to exploit information collected about the environment via two input modalities (a visual input, or an attribute vector representing the state of the agent and/or its environment). Then, we train a RL agent policy using this frozen Global Workspace. In two distinct environments and tasks, our results reveal the model's ability to perform zero-shot cross-modal transfer between input modalities, i.e. to apply to image inputs a policy previously trained on attribute vectors (and vice-versa), without additional training or fine-tuning. Variants and ablations of the full Global Workspace (including a CLIP-like multimodal representation trained via contrastive learning) did not display the same generalization abilities.","authors":["L\\'eopold Mayti\\'e","Benjamin Devillers","Alexandre Arnold","Rufin VanRullen"],"url":"https://arxiv.org/abs/2403.04588"}
{"created":"2025-06-05","title":"How To Save Fees in Bitcoin Smart Contracts: a Simple Optimistic Off-chain Protocol","abstract":"We consider the execution of smart contracts on Bitcoin. There, every contract step corresponds to appending to the blockchain a new transaction that spends the output representing the old contract state, creating a new one for the updated state. This standard procedure requires the contract participants to pay transaction fees for every execution step. In this paper, we introduce a protocol that moves most of the execution of a Bitcoin contract off-chain. When all participants follow this protocol, they are able to save on transaction fees, drastically reducing them. By contrast, whenever adversaries try to disrupt the off-chain execution, any honest participant is still able to enforce the correct contract behaviour, by continuing its execution on-chain.","authors":["Dario Maddaloni","Riccardo Marchesin","Roberto Zunino"],"url":"https://arxiv.org/abs/2403.09880"}
{"created":"2025-06-05","title":"Non-Conforming Structure Preserving Finite Element Method for Doubly Diffusive Flows on Bounded Lipschitz Domains","abstract":"We study a stationary model of doubly diffusive flows with temperature-dependent viscosity on bounded Lipschitz domains in two and three dimensions. A new well-posedness and regularity analysis of weak solutions under minimal assumptions on domain geometry and data regularity are established. A fully non-conforming finite element method based on Crouzeix-Raviart elements, which ensures locally exactly divergence-free velocity fields is explored. Unlike previously proposed schemes, this discretisation enables to establish uniqueness of the discrete solutions. We prove the well-posedness of the discrete problem and derive pressure-robust a priori error estimates. An accuracy test is conducted to verify the theoretical error decay rates in flow, Stokes and Darcy regimes.","authors":["Jai Tushar","Arbaz Khan","Manil T. Mohan"],"url":"https://arxiv.org/abs/2403.10282"}
{"created":"2025-06-05","title":"AdaptSFL: Adaptive Split Federated Learning in Resource-constrained Edge Networks","abstract":"The increasing complexity of deep neural networks poses significant barriers to democratizing them to resource-limited edge devices. To address this challenge, split federated learning (SFL) has emerged as a promising solution by of floading the primary training workload to a server via model partitioning while enabling parallel training among edge devices. However, although system optimization substantially influences the performance of SFL under resource-constrained systems, the problem remains largely uncharted. In this paper, we provide a convergence analysis of SFL which quantifies the impact of model splitting (MS) and client-side model aggregation (MA) on the learning performance, serving as a theoretical foundation. Then, we propose AdaptSFL, a novel resource-adaptive SFL framework, to expedite SFL under resource-constrained edge computing systems. Specifically, AdaptSFL adaptively controls client-side MA and MS to balance communication-computing latency and training convergence. Extensive simulations across various datasets validate that our proposed AdaptSFL framework takes considerably less time to achieve a target accuracy than benchmarks, demonstrating the effectiveness of the proposed strategies.","authors":["Zheng Lin","Guanqiao Qu","Wei Wei","Xianhao Chen","Kin K. Leung"],"url":"https://arxiv.org/abs/2403.13101"}
{"created":"2025-06-05","title":"Missing Pieces: How Do Designs that Expose Uncertainty Longitudinally Impact Trust in AI Decision Aids? An In Situ Study of Gig Drivers","abstract":"Decision aids based on artificial intelligence (AI) induce a wide range of outcomes when they are deployed in uncertain environments. In this paper, we investigate how users' trust in recommendations from an AI decision aid is impacted over time by designs that expose uncertainty in predicted outcomes. Unlike previous work, we focus on gig driving - a real-world, repeated decision-making context. We report on a longitudinal mixed-methods study ($n=51$) where we measured gig drivers' trust as they interacted with an AI-based schedule recommendation tool. Our results show that participants' trust in the tool was shaped by both their first impressions of its accuracy and their longitudinal interactions with it; and that task-aligned framings of uncertainty improved trust by allowing participants to incorporate uncertainty into their decision-making processes. Additionally, we observed that trust depended on their characteristics as drivers, underscoring the need for more in situ studies of AI decision aids.","authors":["Rex Chen","Ruiyi Wang","Fei Fang","Norman Sadeh"],"url":"https://arxiv.org/abs/2404.06432"}
{"created":"2025-06-05","title":"Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning","abstract":"Despite achieving outstanding performance on various cross-modal tasks, current large vision-language models (LVLMs) still suffer from hallucination issues, manifesting as inconsistencies between their generated responses and the corresponding images. Prior research has implicated that the low quality of instruction data, particularly the skewed balance between positive and negative samples, is a significant contributor to model hallucinations. Recently, researchers have proposed high-quality instruction datasets, such as LRV-Instruction, to mitigate model hallucination. Nonetheless, our investigation reveals that hallucinatory concepts from different LVLMs exhibit specificity, i.e. the distribution of hallucinatory concepts varies significantly across models. Existing datasets did not consider the hallucination specificity of different models in the design processes, thereby diminishing their efficacy in mitigating model hallucination. In this paper, we propose a targeted instruction data generation framework named DFTG that tailored to the hallucination specificity of different models. Concretely, DFTG consists of two stages: hallucination diagnosis, which extracts the necessary information from the model's responses and images for hallucination diagnosis; and targeted data generation, which generates targeted instruction data based on diagnostic results. The experimental results on hallucination benchmarks demonstrate that the targeted instruction data generated by our method are more effective in mitigating hallucinations compared to previous datasets.","authors":["Rui Hu","Yahan Tu","Shuyu Wei","Dongyuan Lu","Jitao Sang"],"url":"https://arxiv.org/abs/2404.10332"}
{"created":"2025-06-05","title":"On the Unprovability of Circuit Size Bounds in Intuitionistic $\\mathsf{S}^1_2$","abstract":"We show that there is a constant $k$ such that Buss's intuitionistic theory $\\mathsf{IS}^1_2$ does not prove that SAT requires co-nondeterministic circuits of size at least $n^k$. To our knowledge, this is the first unconditional unprovability result in bounded arithmetic in the context of worst-case fixed-polynomial size circuit lower bounds. We complement this result by showing that the upper bound $\\mathsf{NP} \\subseteq \\mathsf{coNSIZE}[n^k]$ is unprovable in $\\mathsf{IS}^1_2$.","authors":["Lijie Chen","Jiatu Li","Igor C. Oliveira"],"url":"https://arxiv.org/abs/2404.11841"}
{"created":"2025-06-05","title":"An Offline Reinforcement Learning Algorithm Customized for Multi-Task Fusion in Large-Scale Recommender Systems","abstract":"As the last critical stage of RSs, Multi-Task Fusion (MTF) is responsible for combining multiple scores outputted by Multi-Task Learning (MTL) into a final score to maximize user satisfaction, which determines the ultimate recommendation results. Recently, to optimize long-term user satisfaction within a recommendation session, Reinforcement Learning (RL) is used for MTF in the industry. However, the offline RL algorithms used for MTF so far have the following severe problems: 1) to avoid out-of-distribution (OOD) problem, their constraints are overly strict, which seriously damage their performance; 2) they are unaware of the exploration policy used for producing training data and never interact with real environment, so only suboptimal policy can be learned; 3) the traditional exploration policies are inefficient and hurt user experience. To solve the above problems, we propose a novel method named IntegratedRL-MTF customized for MTF in large-scale RSs. IntegratedRL-MTF integrates offline RL model with our online exploration policy to relax overstrict and complicated constraints, which significantly improves its performance. We also design an extremely efficient exploration policy, which eliminates low-value exploration space and focuses on exploring potential high-value state-action pairs. Moreover, we adopt progressive training mode to further enhance our model's performance with the help of our exploration policy. We conduct extensive offline and online experiments in the short video channel of Tencent News. The results demonstrate that our model outperforms other models remarkably. IntegratedRL-MTF has been fully deployed in our RS and other large-scale RSs in Tencent, which have achieved significant improvements.","authors":["Peng Liu","Cong Xu","Ming Zhao","Jiawei Zhu","Bin Wang","Yi Ren"],"url":"https://arxiv.org/abs/2404.17589"}
{"created":"2025-06-05","title":"Time, Travel, and Energy in the Uniform Dispersion Problem","abstract":"We investigate the algorithmic problem of uniformly dispersing a swarm of robots in an unknown, gridlike environment. In this setting, our goal is to study the relationships between performance metrics and robot capabilities. We introduce a formal model comparing dispersion algorithms based on makespan, traveled distance, energy consumption, sensing, communication, and memory. Using this framework, we classify uniform dispersion algorithms according to their capability requirements and performance. We prove that while makespan and travel can be minimized in all environments, energy cannot, if the swarm's sensing range is bounded. In contrast, we show that energy can be minimized by ``ant-like'' robots in synchronous settings and asymptotically minimized in asynchronous settings, provided the environment is topologically simply connected, by using our ``Find-Corner Depth-First Search'' (FCDFS) algorithm. Our theoretical and experimental results show that FCDFS significantly outperforms known algorithms. Our findings reveal key limitations in designing swarm robotics systems for unknown environments, emphasizing the role of topology in energy-efficient dispersion.","authors":["Michael Amir","Alfred M. Bruckstein"],"url":"https://arxiv.org/abs/2404.19564"}
{"created":"2025-06-05","title":"Meaning-Typed Programming: Language Abstraction and Runtime for Model-Integrated Applications","abstract":"Software development is shifting from traditional logical programming to model-integrated applications that leverage generative AI and large language models (LLMs) during runtime. However, integrating LLMs remains complex, requiring developers to manually craft prompts and process outputs. Existing tools attempt to assist with prompt engineering, but often introduce additional complexity.","authors":["Jayanaka L. Dantanarayana","Yiping Kang","Kugesan Sivasothynathan","Christopher Clarke","Baichuan Li","Savini Kashmira","Krisztian Flautner","Lingjia Tang","Jason Mars"],"url":"https://arxiv.org/abs/2405.08965"}
{"created":"2025-06-05","title":"Exact predicates, exact constructions and combinatorics for mesh CSG","abstract":"This article introduces a general mesh intersection algorithm that exactly computes the so-called Weiler model (also called an arrangement) and that uses it to implement boolean operations with arbitrary multi-operand expressions, CSG (constructive solid geometry) and some mesh repair operations. From an input polygon soup, the algorithm first computes the co-refinement, with an exact representation of the intersection points. Then, the decomposition of 3D space into volumetric regions (Weiler model) is constructed, by sorting the facets around the non-manifold intersection edges (radial sort), using specialized exact predicates. Finally, based on the input boolean expression, the triangular facets that belong to the boundary of the result are classified. To implement all the involved predicates and constructions, two geometric kernels are proposed, tested and discussed (arithmetic expansions and multi-precision floating-point). As a guiding principle,the combinatorial information shared between each step is kept as simple as possible. It is made possible by treating all the particular cases in the kernel. In particular, triangles with intersections are remeshed using the (uniquely defined) Constrained Delaunay Triangulation, with symbolic perturbations to disambiguate configurations with co-cyclic points. It makes it easy to discard the duplicated triangles that appear when remeshing overlapping facets. The method is tested and compared with previous work, on the existing \"thingi10K\" dataset (to test co-refinement and mesh repair) and on a new \"thingiCSG\" dataset made publicly available (to test the full CSG pipeline) on a variety of interesting examples featuring different types of \"pathologies\"","authors":["Bruno L\\'evy"],"url":"https://arxiv.org/abs/2405.12949"}
{"created":"2025-06-05","title":"LDMol: A Text-to-Molecule Diffusion Model with Structurally Informative Latent Space Surpasses AR Models","abstract":"With the emergence of diffusion models as a frontline generative model, many researchers have proposed molecule generation techniques with conditional diffusion models. However, the unavoidable discreteness of a molecule makes it difficult for a diffusion model to connect raw data with highly complex conditions like natural language. To address this, here we present a novel latent diffusion model dubbed LDMol for text-conditioned molecule generation. By recognizing that the suitable latent space design is the key to the diffusion model performance, we employ a contrastive learning strategy to extract novel feature space from text data that embeds the unique characteristics of the molecule structure. Experiments show that LDMol outperforms the existing autoregressive baselines on the text-to-molecule generation benchmark, being one of the first diffusion models that outperforms autoregressive models in textual data generation with a better choice of the latent domain. Furthermore, we show that LDMol can be applied to downstream tasks such as molecule-to-text retrieval and text-guided molecule editing, demonstrating its versatility as a diffusion model.","authors":["Jinho Chang","Jong Chul Ye"],"url":"https://arxiv.org/abs/2405.17829"}
{"created":"2025-06-05","title":"Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs against Jailbreak Attacks","abstract":"Safety, security, and compliance are essential requirements when aligning large language models (LLMs). However, many seemingly aligned LLMs are soon shown to be susceptible to jailbreak attacks. These attacks aim to circumvent the models' safety guardrails and security mechanisms by introducing jailbreak prompts into malicious queries. In response to these challenges, this paper introduces Defensive Prompt Patch (DPP), a novel prompt-based defense mechanism specifically designed to protect LLMs against such sophisticated jailbreak strategies. Unlike previous approaches, which have often compromised the utility of the model for the sake of safety, DPP is designed to achieve a minimal Attack Success Rate (ASR) while preserving the high utility of LLMs. Our method uses strategically designed interpretable suffix prompts that effectively thwart a wide range of standard and adaptive jailbreak techniques. Empirical results conducted on LLAMA-2-7B-Chat and Mistral-7B-Instruct-v0.2 models demonstrate the robustness and adaptability of DPP, showing significant reductions in ASR with negligible impact on utility. Our approach not only outperforms existing defense strategies in balancing safety and functionality, but also provides a scalable and interpretable solution applicable to various LLM platforms.","authors":["Chen Xiong","Xiangyu Qi","Pin-Yu Chen","Tsung-Yi Ho"],"url":"https://arxiv.org/abs/2405.20099"}
{"created":"2025-06-05","title":"$\\mu$LO: Compute-Efficient Meta-Generalization of Learned Optimizers","abstract":"Learned optimizers (LOs) can significantly reduce the wall-clock training time of neural networks, substantially reducing training costs. However, they can struggle to optimize unseen tasks (meta-generalize), especially when training networks wider than those seen during meta-training. To address this, we derive the Maximal Update Parametrization ($\\mu$P) for two state-of-the-art learned optimizer architectures and propose a simple meta-training recipe for $\\mu$-parameterized LOs ($\\mu$LOs). Our empirical evaluation demonstrates that LOs meta-trained with our recipe substantially improve meta-generalization to wider unseen tasks when compared to LOs trained under standard parametrization (SP), as they are trained in existing work. We also empirically observe that $\\mu$LOs trained with our recipe exhibit unexpectedly improved meta-generalization to deeper networks ($5\\times$ meta-training) and surprising generalization to much longer training horizons ($25\\times$ meta-training) when compared to SP LOs.","authors":["Benjamin Th\\'erien","Charles-\\'Etienne Joseph","Boris Knyazev","Edouard Oyallon","Irina Rish","Eugene Belilovsky"],"url":"https://arxiv.org/abs/2406.00153"}
{"created":"2025-06-05","title":"Safe, Out-of-Distribution-Adaptive MPC with Conformalized Neural Network Ensembles","abstract":"We present SODA-MPC, a Safe, Out-of-Distribution-Adaptive Model Predictive Control algorithm, which uses an ensemble of learned models for prediction, with a runtime monitor to flag unreliable out-of-distribution (OOD) predictions. When an OOD situation is detected, SODA-MPC triggers a safe fallback control strategy based on reachability, yielding a control framework that achieves the high performance of learning-based models while preserving the safety of reachability-based control. We demonstrate the method in the context of an autonomous vehicle, driving among dynamic pedestrians, where SODA-MPC uses a neural network ensemble for pedestrian prediction. We calibrate the OOD signal using conformal prediction to derive an OOD detector with probabilistic guarantees on the false-positive rate, given a user-specified confidence level. During in-distribution operation, the MPC controller avoids collisions with a pedestrian based on the trajectory predicted by the mean of the ensemble. When OOD conditions are detected, the MPC switches to a reachability-based controller to avoid collisions with the reachable set of the pedestrian assuming a maximum pedestrian speed, to guarantee safety under the worst-case actions of the pedestrian. We verify SODA-MPC in extensive autonomous driving simulations in a pedestrian-crossing scenario. Our model ensemble is trained and calibrated with real pedestrian data, showing that our OOD detector obtains the desired accuracy rate within a theoretically-predicted range. We empirically show improved safety and improved task completion compared with two state-of-the-art MPC methods that also use conformal prediction, but without OOD adaptation. Further, we demonstrate the effectiveness of our method with the large-scale multi-agent predictor Trajectron++, using large-scale traffic data from the nuScenes dataset for training and calibration.","authors":["Jose Leopoldo Contreras","Ola Shorinwa","Mac Schwager"],"url":"https://arxiv.org/abs/2406.02436"}
{"created":"2025-06-05","title":"CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks","abstract":"Large Language Models (LLMs) are transforming a wide range of domains, yet verifying their outputs remains a significant challenge, especially for complex open-ended tasks such as consolidation, summarization, and knowledge extraction. To address this, we introduce CheckEmbed (CE): a simple, scalable, and accurate verification method. CE reduces each LLM answer to a single embedding vector using powerful modern embedding LLM models like SFR-Embedding-Mistral. Prior methods such as BERTScore and SelfCheckGPT relied on weaker encoders like BERT, forcing them to operate at token or sentence granularity. In contrast, CE performs fast, semantically rich comparisons directly at the whole-answer level, overcoming key limitations in both accuracy and scalability. We conduct a comprehensive design and time complexity analysis across 13 verification baselines, including classical text scorers (e.g., BLEU), stability-based methods (e.g., SelfCheckGPT), and generative evaluators (e.g., LLM-as-a-Judge), which highlights the effectiveness, efficiency, versatility, and simplicity of CE. Empirical results show that CE reliably detects hallucinations in both closed and open-ended tasks. We further present evidence that CE generalizes beyond text to other modalities such as vision, establishing it as a practical and versatile verification framework.","authors":["Maciej Besta","Lorenzo Paleari","Marcin Copik","Robert Gerstenberger","Ales Kubicek","Piotr Nyczyk","Patrick Iff","Eric Schreiber","Tanja Srindran","Tomasz Lehmann","Hubert Niewiadomski","Torsten Hoefler"],"url":"https://arxiv.org/abs/2406.02524"}
{"created":"2025-06-05","title":"CMAR-Net: Accurate Cross-Modal 3D SAR Reconstruction of Vehicle Targets with Sparse-Aspect Multi-Baseline Data","abstract":"Sparse-aspect multi-baseline Synthetic Aperture Radar (SAR) three-dimensional (3D) tomography is a crucial remote sensing technique. Compared to full-aspect observation, it needs only a few observation aspects to achieve a sufficiently clear 3D scene reconstruction, providing a cost-effective alternative. In the past, compressive sensing (CS) was the mainstream approach for sparse 3D SAR imaging. Recently, deep learning (DL) revolutionizes this field through its powerful data-driven representation capabilities and efficient inference characteristics. However, existing DL methods primarily depend on high-resolution radar images for supervising the training of deep neural networks (DNNs). This unimodal approach precludes the incorporation of complementary information from other data sources, thereby limiting potential improvements in imaging performance. In this paper, we propose a Cross-Modal 3D-SAR Reconstruction Network (CMAR-Net) that enhances 3D SAR imaging by fusing heterogeneous information. Leveraging cross-modal supervision from 2D optical images and error transfer guaranteed by differentiable rendering, CMAR-Net achieves efficient training and reconstructs highly sparse-aspect multi-baseline SAR image into visually structured and accurate 3D images, particularly for vehicle targets. Extensive experiments on simulated and real-world datasets demonstrate that CMAR-Net significantly outperforms state-of-the-art sparse reconstruction algorithms based on CS and DL, with average improvements of 75.83% in PSNR and 47.85% in SSIM. Furthermore, our method eliminates the need for time-consuming full-aperture data preprocessing and relies solely on computer-rendered optical images, significantly reducing dataset construction costs. This work highlights the potential of cross-modal learning for multi-baseline SAR 3D imaging and introduces a novel framework for radar imaging research.","authors":["Da Li","Guoqiang Zhao","Chen Yao","Kaiqiang Zhu","Houjun Sun","Jiacheng Bao"],"url":"https://arxiv.org/abs/2406.04158"}
{"created":"2025-06-05","title":"AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models","abstract":"Evaluating the alignment capabilities of large Vision-Language Models (VLMs) is essential for determining their effectiveness as helpful assistants. However, existing benchmarks primarily focus on basic abilities using nonverbal methods, such as yes-no and multiple-choice questions. In this paper, we address this gap by introducing AlignMMBench, which provides more nuanced evaluations of alignment capabilities and is the first benchmark specifically designed for Chinese visual contexts. This benchmark is meticulously curated from real-world scenarios and internet sources, encompassing thirteen specific tasks across three categories, and includes both single-turn and multi-turn dialogue scenarios. Incorporating a prompt rewrite strategy, AlignMMBench encompasses 1,054 images and 4,978 question-answer pairs. To facilitate the evaluation pipeline, we develop CritiqueVLM, a rule-calibrated evaluator that exceeds GPT-4's evaluation ability. Additionally, we measure the \"alignment score\", a quantitative metric designed to assess the robustness and stability of models across diverse prompts. Finally, we evaluate the performance of representative VLMs on AlignMMBench, offering insights into the capabilities and limitations of different VLM architectures. The evaluation code and data are available at https://github.com/THUDM/AlignMMBench.","authors":["Yuhang Wu","Wenmeng Yu","Yean Cheng","Yan Wang","Xiaohan Zhang","Jiazheng Xu","Ming Ding","Yuxiao Dong"],"url":"https://arxiv.org/abs/2406.09295"}
{"created":"2025-06-05","title":"UBench: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions","abstract":"Despite recent progress in systematic evaluation frameworks, benchmarking the uncertainty of large language models (LLMs) remains a highly challenging task. Existing methods for benchmarking the uncertainty of LLMs face three key challenges: the need for internal model access, additional training, or high computational costs. This is particularly unfavorable for closed-source models. To this end, we introduce UBench, a new benchmark for evaluating the uncertainty of LLMs. Unlike other benchmarks, UBench is based on confidence intervals. It encompasses 11,978 multiple-choice questions spanning knowledge, language, understanding, and reasoning capabilities. Based on this, we conduct extensive experiments. This includes comparisons with other advanced uncertainty estimation methods, the assessment of the uncertainty of 20 LLMs, and an exploration of the effects of Chain-of-Thought (CoT) prompts, role-playing (RP) prompts, and temperature on model uncertainty. Our analysis reveals several crucial insights: 1) Our confidence interval-based methods are highly effective for uncertainty quantification; 2) Regarding uncertainty, outstanding open-source models show competitive performance versus closed-source models; 3) CoT and RP prompts present potential ways to improve model reliability, while the influence of temperature changes follows no universal rule. Our implementation is available at https://github.com/Cyno2232/UBENCH.","authors":["Xunzhi Wang","Zhuowei Zhang","Gaonan Chen","Qiongyu Li","Bitong Luo","Zhixin Han","Haotian Wang","Zhiyu li","Hang Gao","Mengting Hu"],"url":"https://arxiv.org/abs/2406.12784"}
{"created":"2025-06-05","title":"UIO-LLMs: Unbiased Incremental Optimization for Long-Context LLMs","abstract":"Managing long texts is challenging for large language models (LLMs) due to limited context window sizes. This study introduces UIO-LLMs, an unbiased incremental optimization approach for memory-enhanced transformers under long-context settings. We initially conceptualize the process as a streamlined encoder-decoder framework where the weights-shared encoder and decoder respectively encapsulate a context segment into memories and leverage these memories to predict outputs of the subsequent segment. Subsequently, by treating our memory-enhanced transformers as fully-connected recurrent neural networks (RNNs), we refine the training process using the Truncated Backpropagation Through Time (TBPTT) algorithm, which incorporates innovative incremental optimization techniques. These techniques not only diminish time complexity but also address the bias in gradient computation through an unbiased optimization process. UIO-LLMs successfully handle long context, such as extending the context window of Llama2-7b-chat from 4K to 100K tokens with minimal 2% additional parameters, while keeping the inference cost nearly linear as context length increases.","authors":["Wenhao Li","Mingbao Lin","Yunshan Zhong","Shuicheng Yan","Rongrong Ji"],"url":"https://arxiv.org/abs/2406.18173"}
{"created":"2025-06-05","title":"SCOPE: Stochastic Cartographic Occupancy Prediction Engine for Uncertainty-Aware Dynamic Navigation","abstract":"This article presents a family of Stochastic Cartographic Occupancy Prediction Engines (SCOPEs) that enable mobile robots to predict the future states of complex dynamic environments. They do this by accounting for the motion of the robot itself, the motion of dynamic objects, and the geometry of static objects in the scene, and they generate a range of possible future states of the environment. These prediction engines are software-optimized for real-time performance for navigation in crowded dynamic scenes, achieving up to 89 times faster inference speed and 8 times less memory usage than other state-of-the-art engines. Three simulated and real-world datasets collected by different robot models are used to demonstrate that these proposed prediction algorithms are able to achieve more accurate and robust stochastic prediction performance than other algorithms. Furthermore, a series of simulation and hardware navigation experiments demonstrate that the proposed predictive uncertainty-aware navigation framework with these stochastic prediction engines is able to improve the safe navigation performance of current state-of-the-art model- and learning-based control policies.","authors":["Zhanteng Xie","Philip Dames"],"url":"https://arxiv.org/abs/2407.00144"}
{"created":"2025-06-05","title":"Craftium: Bridging Flexibility and Efficiency for Rich 3D Single- and Multi-Agent Environments","abstract":"Advances in large models, reinforcement learning, and open-endedness have accelerated progress toward autonomous agents that can learn and interact in the real world. To achieve this, flexible tools are needed to create rich, yet computationally efficient, environments. While scalable 2D environments fail to address key real-world challenges like 3D navigation and spatial reasoning, more complex 3D environments are computationally expensive and lack features like customizability and multi-agent support. This paper introduces Craftium, a highly customizable and easy-to-use platform for building rich 3D single- and multi-agent environments. We showcase environments of different complexity and nature: from single- and multi-agent tasks to vast worlds with many creatures and biomes, and customizable procedural task generators. Benchmarking shows that Craftium significantly reduces the computational cost of alternatives of similar richness, achieving +2K steps per second more than Minecraft-based frameworks.","authors":["Mikel Malag\\'on","Josu Ceberio","Jose A. Lozano"],"url":"https://arxiv.org/abs/2407.03969"}
{"created":"2025-06-05","title":"Quantifying Prediction Consistency Under Fine-Tuning Multiplicity in Tabular LLMs","abstract":"Fine-tuning LLMs on tabular classification tasks can lead to the phenomenon of fine-tuning multiplicity where equally well-performing models make conflicting predictions on the same input. Fine-tuning multiplicity can arise due to variations in the training process, e.g., seed, weight initialization, minor changes to training data, etc., raising concerns about the reliability of Tabular LLMs in high-stakes applications such as finance, hiring, education, healthcare. Our work formalizes this unique challenge of fine-tuning multiplicity in Tabular LLMs and proposes a novel measure to quantify the consistency of individual predictions without expensive model retraining. Our measure quantifies a prediction's consistency by analyzing (sampling) the model's local behavior around that input in the embedding space. Interestingly, we show that sampling in the local neighborhood can be leveraged to provide probabilistic guarantees on prediction consistency under a broad class of fine-tuned models, i.e., inputs with sufficiently high local stability (as defined by our measure) also remain consistent across several fine-tuned models with high probability. We perform experiments on multiple real-world datasets to show that our local stability measure preemptively captures consistency under actual multiplicity across several fine-tuned models, outperforming competing measures.","authors":["Faisal Hamman","Pasan Dissanayake","Saumitra Mishra","Freddy Lecue","Sanghamitra Dutta"],"url":"https://arxiv.org/abs/2407.04173"}
{"created":"2025-06-05","title":"OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling","abstract":"Large language models (LLMs) have exhibited their problem-solving abilities in mathematical reasoning. Solving realistic optimization (OPT) problems in application scenarios requires advanced and applied mathematics ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we propose OptiBench, a benchmark for End-to-end optimization problem-solving with human-readable inputs and outputs. OptiBench contains rich optimization problems, including linear and nonlinear programming with or without tabular data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to call a code solver to provide precise numerical answers. Furthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method namely ReSocratic. Unlike general data synthesis methods that proceed from questions to answers, \\ReSocratic first incrementally synthesizes formatted optimization demonstration with mathematical formulations step by step and then back-translates the generated demonstrations into questions. Based on this, we synthesize the ReSocratic-29k dataset. We further conduct supervised fine-tuning with ReSocratic-29k on multiple open-source models. Experimental results show that ReSocratic-29k significantly improves the performance of open-source models.","authors":["Zhicheng Yang","Yiwei Wang","Yinya Huang","Zhijiang Guo","Wei Shi","Xiongwei Han","Liang Feng","Linqi Song","Xiaodan Liang","Jing Tang"],"url":"https://arxiv.org/abs/2407.09887"}
{"created":"2025-06-05","title":"Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development","abstract":"The emergence of multimodal large models has advanced artificial intelligence, introducing unprecedented levels of performance and functionality. However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization. In response, we present a new sandbox suite tailored for integrated data-model co-development. This sandbox provides a feedback-driven experimental platform, enabling cost-effective iteration and guided refinement of both data and models. Our proposed ``Probe-Analyze-Refine'' workflow, validated through practical use cases on multimodal tasks such as image-text pre-training with CLIP, image-to-text generation with LLaVA-like models, and text-to-video generation with DiT-based models, yields transferable and notable performance boosts, such as topping the VBench leaderboard. A comprehensive set of over 100 experiments demonstrated the suite's usability and extensibility, while also uncovering insights into the interplay between data quality, diversity, model behavior, and computational costs. All codes, datasets, and models are open-sourced to foster future research and applications that would otherwise be infeasible due to the lack of a dedicated co-development infrastructure.","authors":["Daoyuan Chen","Haibin Wang","Yilun Huang","Ce Ge","Yaliang Li","Bolin Ding","Jingren Zhou"],"url":"https://arxiv.org/abs/2407.11784"}
{"created":"2025-06-05","title":"MDPE: A Multimodal Deception Dataset with Personality and Emotional Characteristics","abstract":"Deception detection has garnered increasing attention in recent years due to the significant growth of digital media and heightened ethical and security concerns. It has been extensively studied using multimodal methods, including video, audio, and text. In addition, individual differences in deception production and detection are believed to play a crucial role.Although some studies have utilized individual information such as personality traits to enhance the performance of deception detection, current systems remain limited, partly due to a lack of sufficient datasets for evaluating performance. To address this issue, we introduce a multimodal deception dataset MDPE. Besides deception features, this dataset also includes individual differences information in personality and emotional expression characteristics. It can explore the impact of individual differences on deception behavior. It comprises over 104 hours of deception and emotional videos from 193 subjects. Furthermore, we conducted numerous experiments to provide valuable insights for future deception detection research. MDPE not only supports deception detection, but also provides conditions for tasks such as personality recognition and emotion recognition, and can even study the relationships between them. We believe that MDPE will become a valuable resource for promoting research in the field of affective computing.","authors":["Cong Cai","Shan Liang","Xuefei Liu","Kang Zhu","Zhengqi Wen","Jianhua Tao","Heng Xie","Jizhou Cui","Yiming Ma","Zhenhua Cheng","Hanzhe Xu","Ruibo Fu","Bin Liu","Yongwei Li"],"url":"https://arxiv.org/abs/2407.12274"}
{"created":"2025-06-05","title":"Mixed Non-linear Quantization for Vision Transformers","abstract":"The majority of quantization methods have been proposed to reduce the model size of Vision Transformers, yet most of them have overlooked the quantization of non-linear operations. Only a few works have addressed quantization for non-linear operations, but they applied a single quantization method across all non-linear operations. We believe that this can be further improved by employing a different quantization method for each non-linear operation. Therefore, to assign the most error-minimizing quantization method from the known methods to each non-linear layer, we propose a mixed non-linear quantization that considers layer-wise quantization sensitivity measured by SQNR difference metric. The results show that our method outperforms I-BERT, FQ-ViT, and I-ViT in both 8-bit and 6-bit settings for ViT, DeiT, and Swin models by an average of 0.6%p and 19.6%p, respectively. Our method outperforms I-BERT and I-ViT by 0.6%p and 20.8%p, respectively, when training time is limited. We plan to release our code at https://gitlab.com/ones-ai/mixed-non-linear-quantization.","authors":["Gihwan Kim","Jemin Lee","Sihyeong Park","Yongin Kwon","Hyungshin Kim"],"url":"https://arxiv.org/abs/2407.18437"}
{"created":"2025-06-05","title":"EasyInv: Toward Fast and Better DDIM Inversion","abstract":"This paper introduces EasyInv, an easy yet novel approach that significantly advances the field of DDIM Inversion by addressing the inherent inefficiencies and performance limitations of traditional iterative optimization methods. At the core of our EasyInv is a refined strategy for approximating inversion noise, which is pivotal for enhancing the accuracy and reliability of the inversion process. By prioritizing the initial latent state, which encapsulates rich information about the original images, EasyInv steers clear of the iterative refinement of noise items. Instead, we introduce a methodical aggregation of the latent state from the preceding time step with the current state, effectively increasing the influence of the initial latent state and mitigating the impact of noise. We illustrate that EasyInv is capable of delivering results that are either on par with or exceed those of the conventional DDIM Inversion approach, especially under conditions where the model's precision is limited or computational resources are scarce. Concurrently, our EasyInv offers an approximate threefold enhancement regarding inference efficiency over off-the-shelf iterative optimization techniques. It can be easily combined with most existing inversion methods by only four lines of code. See code at https://github.com/potato-kitty/EasyInv.","authors":["Ziyue Zhang","Mingbao Lin","Shuicheng Yan","Rongrong Ji"],"url":"https://arxiv.org/abs/2408.05159"}
{"created":"2025-06-05","title":"Your Turn: At Home Turning Angle Estimation for Parkinson's Disease Severity Assessment","abstract":"People with Parkinson's Disease (PD) often experience progressively worsening gait, including changes in how they turn around, as the disease progresses. Existing clinical rating tools are not capable of capturing hour-by-hour variations of PD symptoms, as they are confined to brief assessments within clinic settings. Measuring gait turning angles continuously and passively is a component step towards using gait characteristics as sensitive indicators of disease progression in PD. This paper presents a deep learning-based approach to automatically quantify turning angles by extracting 3D skeletons from videos and calculating the rotation of hip and knee joints. We utilise state-of-the-art human pose estimation models, Fastpose and Strided Transformer, on a total of 1386 turning video clips from 24 subjects (12 people with PD and 12 healthy control volunteers), trimmed from a PD dataset of unscripted free-living videos in a home-like setting (Turn-REMAP). We also curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human pose benchmark with 3D ground truth, to further validate our method. Previous gait research has primarily taken place in clinics or laboratories evaluating scripted gait outcomes, but this work focuses on free-living home settings where complexities exist, such as baggy clothing and poor lighting. Due to difficulties in obtaining accurate ground truth data in a free-living setting, we quantise the angle into the nearest bin $45^\\circ$ based on the manual labelling of expert clinicians. Our method achieves a turning calculation accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\\deg}, and a weighted precision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the use of single monocular camera data to quantify turns by PD patients in a home setting.","authors":["Qiushuo Cheng","Catherine Morgan","Arindam Sikdar","Alessandro Masullo","Alan Whone","Majid Mirmehdi"],"url":"https://arxiv.org/abs/2408.08182"}
{"created":"2025-06-05","title":"Trust-Oriented Adaptive Guardrails for Large Language Models","abstract":"Guardrail, an emerging mechanism designed to ensure that large language models (LLMs) align with human values by moderating harmful or toxic responses, requires a sociotechnical approach in their design. This paper addresses a critical issue: existing guardrails lack a well-founded methodology to accommodate the diverse needs of different user groups, particularly concerning access rights. Supported by trust modeling (primarily on `social' aspect) and enhanced with online in-context learning via retrieval-augmented generation (on `technical' aspect), we introduce an adaptive guardrail mechanism, to dynamically moderate access to sensitive content based on user trust metrics. User trust metrics, defined as a novel combination of direct interaction trust and authority-verified trust, enable the system to precisely tailor the strictness of content moderation by aligning with the user's credibility and the specific context of their inquiries. Our empirical evaluation demonstrates the effectiveness of the adaptive guardrail in meeting diverse user needs, outperforming existing guardrails while securing sensitive information and precisely managing potentially hazardous content through a context-aware knowledge base. To the best of our knowledge, this work is the first to introduce trust-oriented concept into a guardrail system, offering a scalable solution that enriches the discourse on ethical deployment for next-generation LLM service.","authors":["Jinwei Hu","Yi Dong","Xiaowei Huang"],"url":"https://arxiv.org/abs/2408.08959"}
{"created":"2025-06-05","title":"Prior Learning in Introspective VAEs","abstract":"Variational Autoencoders (VAEs) are a popular framework for unsupervised learning and data generation. A plethora of methods have been proposed focusing on improving VAEs, with the incorporation of adversarial objectives and the integration of prior learning mechanisms being prominent directions. When it comes to the former, an indicative instance is the recently introduced family of Introspective VAEs aiming at ensuring that a low likelihood is assigned to unrealistic samples. In this study, we focus on the Soft-IntroVAE (S-IntroVAE), one of only two members of the Introspective VAE family, the other being the original IntroVAE. We select S-IntroVAE for its state-of-the-art status and its training stability. In particular, we investigate the implication of incorporating a multimodal and trainable prior into this S-IntroVAE. Namely, we formulate the prior as a third player and show that when trained in cooperation with the decoder constitutes an effective way for prior learning, which shares the Nash Equilibrium with the vanilla S-IntroVAE. Furthermore, based on a modified formulation of the optimal ELBO in S-IntroVAE, we develop theoretically motivated regularizations, namely (i) adaptive variance clipping to stabilize training when learning the prior and (ii) responsibility regularization to discourage the formation of inactive prior modes. Finally, we perform a series of targeted experiments on a 2D density estimation benchmark and in an image generation setting comprised of the (F)-MNIST and CIFAR-10 datasets demonstrating the effect of prior learning in S-IntroVAE in generation and representation learning.","authors":["Ioannis Athanasiadis","Fredrik Lindsten","Michael Felsberg"],"url":"https://arxiv.org/abs/2408.13805"}
{"created":"2025-06-05","title":"Generative Recommender with End-to-End Learnable Item Tokenization","abstract":"Generative recommendation systems have gained increasing attention as an innovative approach that directly generates item identifiers for recommendation tasks. Despite their potential, a major challenge is the effective construction of item identifiers that align well with recommender systems. Current approaches often treat item tokenization and generative recommendation training as separate processes, which can lead to suboptimal performance. To overcome this issue, we introduce ETEGRec, a novel End-To-End Generative Recommender that unifies item tokenization and generative recommendation into a cohesive framework. Built on a dual encoder-decoder architecture, ETEGRec consists of an item tokenizer and a generative recommender. To enable synergistic interaction between these components, we propose a recommendation-oriented alignment strategy, which includes two key optimization objectives: sequence-item alignment and preference-semantic alignment. These objectives tightly couple the learning processes of the item tokenizer and the generative recommender, fostering mutual enhancement. Additionally, we develop an alternating optimization technique to ensure stable and efficient end-to-end training of the entire framework. Extensive experiments demonstrate the superior performance of our approach compared to traditional sequential recommendation models and existing generative recommendation baselines. Our code is available at https://github.com/RUCAIBox/ETEGRec.","authors":["Enze Liu","Bowen Zheng","Cheng Ling","Lantao Hu","Han Li","Wayne Xin Zhao"],"url":"https://arxiv.org/abs/2409.05546"}
{"created":"2025-06-05","title":"Mixed precision iterative refinement for linear inverse problems","abstract":"This study investigates the iterative refinement method applied to the solution of linear discrete inverse problems by considering its application to the Tikhonov problem in mixed precision. Previous works on mixed precision iterative refinement methods for the solution of symmetric positive definite linear systems and least-squares problems have shown regularization to be a key requirement when computing low precision factorizations. For problems that are naturally severely ill-posed, we formulate the iterates of iterative refinement in mixed precision as a filtered solution using the preconditioned Landweber method with a Tikhonov-type preconditioner. Through numerical examples simulating various mixed precision choices, we showcase the filtering properties of the method and the achievement of comparable or superior accuracy compared to results computed in double precision as well as another approximate method.","authors":["James G. Nagy","Lucas Onisk"],"url":"https://arxiv.org/abs/2409.08335"}
{"created":"2025-06-05","title":"KAN-HyperpointNet for Point Cloud Sequence-Based 3D Human Action Recognition","abstract":"Point cloud sequence-based 3D action recognition has achieved impressive performance and efficiency. However, existing point cloud sequence modeling methods cannot adequately balance the precision of limb micro-movements with the integrity of posture macro-structure, leading to the loss of crucial information cues in action inference. To overcome this limitation, we introduce D-Hyperpoint, a novel data type generated through a D-Hyperpoint Embedding module. D-Hyperpoint encapsulates both regional-momentary motion and global-static posture, effectively summarizing the unit human action at each moment. In addition, we present a D-Hyperpoint KANsMixer module, which is recursively applied to nested groupings of D-Hyperpoints to learn the action discrimination information and creatively integrates Kolmogorov-Arnold Networks (KAN) to enhance spatio-temporal interaction within D-Hyperpoints. Finally, we propose KAN-HyperpointNet, a spatio-temporal decoupled network architecture for 3D action recognition. Extensive experiments on two public datasets: MSR Action3D and NTU-RGB+D 60, demonstrate the state-of-the-art performance of our method.","authors":["Zhaoyu Chen","Xing Li","Qian Huang","Qiang Geng","Tianjin Yang","Shihao Han"],"url":"https://arxiv.org/abs/2409.09444"}
{"created":"2025-06-05","title":"Exploring Representations and Interventions in Time Series Foundation Models","abstract":"Time series foundation models (TSFMs) promise to be powerful tools for a wide range of applications. However, their internal representations and learned concepts are still not well understood. In this study, we investigate the structure and redundancy of representations across various TSFMs, examining the self-similarity of model layers within and across different model sizes. This analysis reveals block-like redundancy in the representations, which can be utilized for informed pruning to improve inference speed and efficiency. Additionally, we explore the concepts learned by these models - such as periodicity and trends - and how these can be manipulated through latent space steering to influence model behavior. Our experiments show that steering interventions can introduce new features, e.g., adding periodicity or trends to signals that initially lacked them. These findings underscore the value of representational analysis for optimizing models and demonstrate how conceptual steering offers new possibilities for more controlled and efficient time series analysis with TSFMs.","authors":["Micha{\\l} Wili\\'nski","Mononito Goswami","Willa Potosnak","Nina \\.Zukowska","Artur Dubrawski"],"url":"https://arxiv.org/abs/2409.12915"}
{"created":"2025-06-05","title":"REAL: Response Embedding-based Alignment for LLMs","abstract":"Aligning large language models (LLMs) to human preferences is a crucial step in building helpful and safe AI tools, which usually involve training on supervised datasets. Popular algorithms such as Direct Preference Optimization (DPO) rely on pairs of AI-generated responses ranked according to human annotation. The response pair annotation process might bring human bias. Building a correct preference dataset is the costly part of the alignment pipeline. To improve annotation efficiency and quality in the LLMs alignment, we propose REAL: Response Embedding-based Alignment for LLMs, a strategy for constructing a high-quality training dataset that focuses on acquiring the less ambiguous preference pairs for labeling out of a set of response candidates. Our selection process is based on the similarity of embedding responses independently of prompts, which guarantees the selection process in an off-policy setting, avoiding adaptively measuring the similarity during the training. Experimental results on real-world dataset SHP2 and synthetic HH-RLHF benchmarks indicate that choosing dissimilar response pairs enhances the direct alignment of LLMs while reducing inherited labeling errors. The model aligned with dissimilar response pairs obtained a better margin and win rate on the dialogue task. Our findings suggest that focusing on distinct pairs can reduce the label error and improve LLM alignment efficiency, saving up to $65\\%$ of annotators' work.","authors":["Honggen Zhang","Xufeng Zhao","Igor Molybog","June Zhang"],"url":"https://arxiv.org/abs/2409.17169"}
{"created":"2025-06-05","title":"Two Sparse Matrices are Better than One: Sparsifying Neural Networks with Double Sparse Factorization","abstract":"Neural networks are often challenging to work with due to their large size and complexity. To address this, various methods aim to reduce model size by sparsifying or decomposing weight matrices, such as magnitude pruning and low-rank or block-diagonal factorization. In this work, we present Double Sparse Factorization (DSF), where we factorize each weight matrix into two sparse matrices. Although solving this problem exactly is computationally infeasible, we propose an efficient heuristic based on alternating minimization via ADMM that achieves state-of-the-art results, enabling unprecedented sparsification of neural networks. For instance, in a one-shot pruning setting, our method can reduce the size of the LLaMA2-13B model by 50% while maintaining better performance than the dense LLaMA2-7B model. We also compare favorably with Optimal Brain Compression, the state-of-the-art layer-wise pruning approach for convolutional neural networks. Furthermore, accuracy improvements of our method persist even after further model fine-tuning.","authors":["Vladim\\'ir Bo\\v{z}a","Vladim\\'ir Macko"],"url":"https://arxiv.org/abs/2409.18850"}
{"created":"2025-06-05","title":"Optimizing Treatment Allocation in the Presence of Interference","abstract":"In Influence Maximization (IM), the objective is to -- given a budget -- select the optimal set of entities in a network to target with a treatment so as to maximize the total effect. For instance, in marketing, the objective is to target the set of customers that maximizes the total response rate, resulting from both direct treatment effects on targeted customers and indirect, spillover, effects that follow from targeting these customers. Recently, new methods to estimate treatment effects in the presence of network interference have been proposed. However, the issue of how to leverage these models to make better treatment allocation decisions has been largely overlooked. Traditionally, in Uplift Modeling (UM), entities are ranked according to estimated treatment effect, and the top entities are allocated treatment. Since, in a network context, entities influence each other, the UM ranking approach will be suboptimal. The problem of finding the optimal treatment allocation in a network setting is \\textcolor{red}{NP-hard,} and generally has to be solved heuristically. To fill the gap between IM and UM, we propose OTAPI: Optimizing Treatment Allocation in the Presence of Interference to find solutions to the IM problem using treatment effect estimates. OTAPI consists of two steps. First, a causal estimator is trained to predict treatment effects in a network setting. Second, this estimator is leveraged to identify an optimal treatment allocation by integrating it into classic IM algorithms. We demonstrate that this novel method outperforms classic IM and UM approaches on both synthetic and semi-synthetic datasets.","authors":["Daan Caljon","Jente Van Belle","Jeroen Berrevoets","Wouter Verbeke"],"url":"https://arxiv.org/abs/2410.00075"}
{"created":"2025-06-05","title":"Geometric Signatures of Compositionality Across a Language Model's Lifetime","abstract":"By virtue of linguistic compositionality, few syntactic rules and a finite lexicon can generate an unbounded number of sentences. That is, language, though seemingly high-dimensional, can be explained using relatively few degrees of freedom. An open question is whether contemporary language models (LMs) reflect the intrinsic simplicity of language that is enabled by compositionality. We take a geometric view of this problem by relating the degree of compositionality in a dataset to the intrinsic dimension (ID) of its representations under an LM, a measure of feature complexity. We find not only that the degree of dataset compositionality is reflected in representations' ID, but that the relationship between compositionality and geometric complexity arises due to learned linguistic features over training. Finally, our analyses reveal a striking contrast between nonlinear and linear dimensionality, showing they respectively encode semantic and superficial aspects of linguistic composition.","authors":["Jin Hwa Lee","Thomas Jiralerspong","Lei Yu","Yoshua Bengio","Emily Cheng"],"url":"https://arxiv.org/abs/2410.01444"}
{"created":"2025-06-05","title":"VinePPO: Refining Credit Assignment in RL Training of LLMs","abstract":"Large language models (LLMs) are increasingly applied to complex reasoning tasks that require executing several complex steps before receiving any reward. Properly assigning credit to these steps is essential for enhancing model performance. Proximal Policy Optimization (PPO), a common reinforcement learning (RL) algorithm used for LLM finetuning, employs value networks to tackle credit assignment. However, recent approaches achieve strong results without it, raising questions about the efficacy of value networks in practice. In this work, we systematically evaluate the efficacy of value networks and reveal their significant shortcomings in reasoning-heavy LLM tasks, showing that they often produce poor estimate of expected return and barely outperform a random baseline when comparing alternative steps. This motivates our key question: Can improved credit assignment enhance RL training for LLMs? To address this, we propose VinePPO, a straightforward approach that leverages the flexibility of language environments to compute unbiased Monte Carlo-based estimates. Our method consistently outperforms PPO and other baselines across MATH and GSM8K datasets in less wall-clock time (up to 3.0x). Crucially, it achieves higher test accuracy for a given training accuracy, capturing more generalization signal per sample. These results emphasize the importance of accurate credit assignment in RL training of LLM.","authors":["Amirhossein Kazemnejad","Milad Aghajohari","Eva Portelance","Alessandro Sordoni","Siva Reddy","Aaron Courville","Nicolas Le Roux"],"url":"https://arxiv.org/abs/2410.01679"}
{"created":"2025-06-05","title":"A LLM-Powered Automatic Grading Framework with Human-Level Guidelines Optimization","abstract":"Open-ended short-answer questions (SAGs) have been widely recognized as a powerful tool for providing deeper insights into learners' responses in the context of learning analytics (LA). However, SAGs often present challenges in practice due to the high grading workload and concerns about inconsistent assessments. With recent advancements in natural language processing (NLP), automatic short-answer grading (ASAG) offers a promising solution to these challenges. Despite this, current ASAG algorithms are often limited in generalizability and tend to be tailored to specific questions. In this paper, we propose a unified multi-agent ASAG framework, GradeOpt, which leverages large language models (LLMs) as graders for SAGs. More importantly, GradeOpt incorporates two additional LLM-based agents - the reflector and the refiner - into the multi-agent system. This enables GradeOpt to automatically optimize the original grading guidelines by performing self-reflection on its errors. Through experiments on a challenging ASAG task, namely the grading of pedagogical content knowledge (PCK) and content knowledge (CK) questions, GradeOpt demonstrates superior performance in grading accuracy and behavior alignment with human graders compared to representative baselines. Finally, comprehensive ablation studies confirm the effectiveness of the individual components designed in GradeOpt.","authors":["Yucheng Chu","Hang Li","Kaiqi Yang","Harry Shomer","Hui Liu","Yasemin Copur-Gencturk","Jiliang Tang"],"url":"https://arxiv.org/abs/2410.02165"}
{"created":"2025-06-05","title":"When is local search both effective and efficient?","abstract":"Many combinatorial optimization problems can be represented by valued constraint satisfaction problems (VCSPs) and the fitness landscapes that they generate. Local search starts at an assignment in this landscape and successively moves assignments until no further improvement is possible among the adjacent assignments. Classic analyses of local search algorithms have focused mostly on the question of effectiveness (\"did we find a good solution?\") and often implicitly assumed that there are no doubts about their efficiency (\"did we find it quickly?\"). But there are many reasons to doubt the efficiency of local search. Even if we focus on fitness landscapes on the hypercube that are single peaked on every subcube (known as semismooth fitness landscapes, completely unimodal pseudo-Boolean functions, or acyclic unique sink orientations) where effectiveness is obvious, many local search algorithms are known to be inefficient. We define a \"direction\" for valued constraints such that directed VCSPs generate semismooth fitness landscapes. We call directed VCSPs oriented if they do not have any pair of variables with arcs in both directions. Since recognizing if a VCSP-instance is directed or oriented is coNP-complete, we generalized oriented VCSPs as conditionally-smooth fitness landscapes where the structural property of 'conditionally-smooth' is recognizable in polynomial time. We prove that many popular local search algorithms like random ascent, simulated annealing, history-based rules, jumping rules, and the Kernighan-Lin heuristic are very efficient on conditionally-smooth landscapes. But conditionally-smooth landscapes are still expressive enough so that other well-regarded local search algorithms like steepest ascent and random facet require a super-polynomial number of steps to find the fitness peak.","authors":["Artem Kaznatcheev","Sofia Vazquez Alferez"],"url":"https://arxiv.org/abs/2410.02634"}
{"created":"2025-06-05","title":"It's Not Easy Being Green: On the Energy Efficiency of Programming Languages","abstract":"Does the choice of programming language affect energy consumption? Previous highly visible studies have established associations between certain programming languages and energy consumption. A causal misinterpretation of this work has led academics and industry leaders to use or support certain languages based on their claimed impact on energy consumption. This paper tackles this causal question directly. It first corrects and improves the measurement methodology used by prior work. It then develops a detailed causal model capturing the complex relationship between programming language choice and energy consumption. This model identifies and incorporates several critical but previously overlooked factors that affect energy usage. These factors, such as distinguishing programming languages from their implementations, the impact of the application implementations themselves, the number of active cores, and memory activity, can significantly skew energy consumption measurements if not accounted for. We show -- via empirical experiments, improved methodology, and careful examination of anomalies -- that when these factors are controlled for, notable discrepancies in prior work vanish. Our analysis suggests that the choice of programming language implementation has no significant impact on energy consumption beyond execution time.","authors":["Nicolas van Kempen","Hyuk-Je Kwon","Dung Tuan Nguyen","Emery D. Berger"],"url":"https://arxiv.org/abs/2410.05460"}
{"created":"2025-06-05","title":"On the Convergence of Single-Timescale Actor-Critic","abstract":"We analyze the global convergence of the single-timescale actor-critic (AC) algorithm for the infinite-horizon discounted Markov Decision Processes (MDPs) with finite state spaces. To this end, we introduce an elegant analytical framework for handling complex, coupled recursions inherent in the algorithm. Leveraging this framework, we establish that the algorithm converges to an $\\epsilon$-close \\textbf{globally optimal} policy with a sample complexity of \\( O(\\epsilon^{-3}) \\). This significantly improves upon the existing complexity of $O(\\epsilon^{-2})$ to achieve $\\epsilon$-close \\textbf{stationary policy}, which is equivalent to the complexity of $O(\\epsilon^{-4})$ to achieve $\\epsilon$-close \\textbf{globally optimal} policy using gradient domination lemma. Furthermore, we demonstrate that to achieve this improvement, the step sizes for both the actor and critic must decay as \\( O(k^{-\\frac{2}{3}}) \\) with iteration $k$, diverging from the conventional \\( O(k^{-\\frac{1}{2}}) \\) rates commonly used in (non)convex optimization.","authors":["Navdeep Kumar","Priyank Agrawal","Giorgia Ramponi","Kfir Yehuda Levy","Shie Mannor"],"url":"https://arxiv.org/abs/2410.08868"}
{"created":"2025-06-05","title":"Nudging: Inference-time Alignment of LLMs via Guided Decoding","abstract":"Large language models (LLMs) require alignment to effectively and safely follow user instructions. This process necessitates training an aligned version for every base model, resulting in significant computational overhead. In this work, we propose NUDGING, a simple, training-free algorithm that aligns any base model at inference time using a small aligned model. NUDGING is motivated by recent findings that alignment primarily alters the model's behavior on a small subset of stylistic tokens (e.g., discourse markers). We find that base models are significantly more uncertain when generating these tokens. Building on this insight, NUDGING employs a small aligned model to generate nudging tokens to guide the base model's output during decoding when the base model's uncertainty is high, with only a minor additional inference overhead. We evaluate NUDGING across 3 model families on a diverse range of open-instruction tasks. Without any training, nudging a large base model with a 7x-14x smaller aligned model achieves zero-shot performance comparable to, and sometimes surpassing, that of large aligned models. By operating at the token level, NUDGING enables off-the-shelf collaboration between model families. For instance, nudging Gemma-2-27b with Llama-27b-chat outperforms Llama-2-70b-chat on various tasks. Overall, our work offers a modular and cost-efficient solution to LLM alignment. Our code and demo are available at: https://fywalter.github.io/nudging/ .","authors":["Yu Fei","Yasaman Razeghi","Sameer Singh"],"url":"https://arxiv.org/abs/2410.09300"}
{"created":"2025-06-05","title":"DAS3D: Dual-modality Anomaly Synthesis for 3D Anomaly Detection","abstract":"Synthesizing anomaly samples has proven to be an effective strategy for self-supervised 2D industrial anomaly detection. However, this approach has been rarely explored in multi-modality anomaly detection, particularly involving 3D and RGB images. In this paper, we propose a novel dual-modality augmentation method for 3D anomaly synthesis, which is simple and capable of mimicking the characteristics of 3D defects. Incorporating with our anomaly synthesis method, we introduce a reconstruction-based discriminative anomaly detection network, in which a dual-modal discriminator is employed to fuse the original and reconstructed embedding of two modalities for anomaly detection. Additionally, we design an augmentation dropout mechanism to enhance the generalizability of the discriminator. Extensive experiments show that our method outperforms the state-of-the-art methods on detection precision and achieves competitive segmentation performance on both MVTec 3D-AD and Eyescandies datasets.","authors":["Kecen Li","Bingquan Dai","Jingjing Fu","Xinwen Hou"],"url":"https://arxiv.org/abs/2410.09821"}
{"created":"2025-06-05","title":"Deterministic Apple Tasting","abstract":"In binary ($0/1$) online classification with apple tasting feedback, the learner receives feedback only when predicting $1$. Besides some degenerate learning tasks, all previously known learning algorithms for this model are randomized. Consequently, prior to this work it was unknown whether deterministic apple tasting is generally feasible. In this work, we provide the first widely-applicable deterministic apple tasting learner, and show that in the realizable case, a hypothesis class is learnable if and only if it is deterministically learnable, confirming a conjecture of [Raman, Subedi, Raman, Tewari-24]. Quantitatively, we show that every class $\\mathcal{H}$ is learnable with mistake bound $O \\left(\\sqrt{\\mathtt{L}(\\mathcal{H}) T \\log T} \\right)$ (where $\\mathtt{L}(\\mathcal{H})$ is the Littlestone dimension of $\\mathcal{H}$), and that this is tight for some classes.","authors":["Zachary Chase","Idan Mehalel"],"url":"https://arxiv.org/abs/2410.10404"}
{"created":"2025-06-05","title":"MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling","abstract":"Recent advancements in multi-modal large language models have propelled the development of joint probabilistic models capable of both image understanding and generation. However, we have identified that recent methods suffer from loss of image information during understanding task, due to either image discretization or diffusion denoising steps. To address this issue, we propose a novel Multi-Modal Auto-Regressive (MMAR) probabilistic modeling framework. Unlike discretization line of method, MMAR takes in continuous-valued image tokens to avoid information loss in an efficient way. Differing from diffusion-based approaches, we disentangle the diffusion process from auto-regressive backbone model by employing a light-weight diffusion head on top each auto-regressed image patch embedding. In this way, when the model transits from image generation to understanding through text generation, the backbone model's hidden representation of the image is not limited to the last denoising step. To successfully train our method, we also propose a theoretically proven technique that addresses the numerical stability issue and a training strategy that balances the generation and understanding task goals. Extensive evaluations on 18 image understanding benchmarks show that MMAR significantly outperforms most of the existing joint multi-modal models, surpassing the method that employs pre-trained CLIP vision encoder. Meanwhile, MMAR is able to generate high quality images. We also show that our method is scalable with larger data and model size.","authors":["Jian Yang","Dacheng Yin","Yizhou Zhou","Fengyun Rao","Wei Zhai","Yang Cao","Zheng-Jun Zha"],"url":"https://arxiv.org/abs/2410.10798"}
{"created":"2025-06-05","title":"Subspace Optimization for Large Language Models with Convergence Guarantees","abstract":"Subspace optimization algorithms, such as GaLore (Zhao et al., 2024), have gained attention for pre-training and fine-tuning large language models (LLMs) due to their memory efficiency. However, their convergence guarantees remain unclear, particularly in stochastic settings. In this paper, we reveal that GaLore does not always converge to the optimal solution and provide an explicit counterexample to support this finding. We further explore the conditions under which GaLore achieves convergence, showing that it does so when either (i) a sufficiently large mini-batch size is used or (ii) the gradient noise is isotropic. More significantly, we introduce GoLore (Gradient random Low-rank projection), a novel variant of GaLore that provably converges in typical stochastic settings, even with standard batch sizes. Our convergence analysis extends naturally to other subspace optimization algorithms. Finally, we empirically validate our theoretical results and thoroughly test the proposed mechanisms. Codes are available at https://github.com/pkumelon/Golore.","authors":["Yutong He","Pengrui Li","Yipeng Hu","Chuyan Chen","Kun Yuan"],"url":"https://arxiv.org/abs/2410.11289"}
{"created":"2025-06-05","title":"Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting","abstract":"The widespread deployment of sensing devices leads to a surge in data for spatio-temporal forecasting applications such as traffic flow, air quality, and wind energy. Although spatio-temporal graph neural networks have achieved success in modeling various static spatio-temporal forecasting scenarios, real-world spatio-temporal data are typically received in a streaming manner, and the network continuously expands with the installation of new sensors. Thus, spatio-temporal forecasting in streaming scenarios faces dual challenges: the inefficiency of retraining models over newly arrived data and the detrimental effects of catastrophic forgetting over long-term history. To address these challenges, we propose a novel prompt tuning-based continuous forecasting method, following two fundamental tuning principles guided by empirical and theoretical analysis: expand and compress, which effectively resolve the aforementioned problems with lightweight tuning parameters. Specifically, we integrate the base spatio-temporal graph neural network with a continuous prompt pool, utilizing stored prompts (i.e., few learnable parameters) in memory, and jointly optimize them with the base spatio-temporal graph neural network. This method ensures that the model sequentially learns from the spatio-temporal data stream to accomplish tasks for corresponding periods. Extensive experimental results on multiple real-world datasets demonstrate the multi-faceted superiority of our method over the state-of-the-art baselines, including effectiveness, efficiency, universality, etc.","authors":["Wei Chen","Yuxuan Liang"],"url":"https://arxiv.org/abs/2410.12593"}
{"created":"2025-06-05","title":"Fast Estimation of Partial Dependence Functions using Trees","abstract":"Many existing interpretation methods are based on Partial Dependence (PD) functions that, for a pre-trained machine learning model, capture how a subset of the features affects the predictions by averaging over the remaining features.","authors":["Jinyang Liu","Tessa Steensgaard","Marvin N. Wright","Niklas Pfister","Munir Hiabu"],"url":"https://arxiv.org/abs/2410.13448"}
{"created":"2025-06-05","title":"LoGU: Long-form Generation with Uncertainty Expressions","abstract":"While Large Language Models (LLMs) demonstrate impressive capabilities, they still struggle with generating factually incorrect content (i.e., hallucinations). A promising approach to mitigate this issue is enabling models to express uncertainty when unsure. Previous research on uncertainty modeling has primarily focused on short-form QA, but realworld applications often require much longer responses. In this work, we introduce the task of Long-form Generation with Uncertainty(LoGU). We identify two key challenges: Uncertainty Suppression, where models hesitate to express uncertainty, and Uncertainty Misalignment, where models convey uncertainty inaccurately. To tackle these challenges, we propose a refinement-based data collection framework and a two-stage training pipeline. Our framework adopts a divide-and-conquer strategy, refining uncertainty based on atomic claims. The collected data are then used in training through supervised fine-tuning (SFT) and direct preference optimization (DPO) to enhance uncertainty expression. Extensive experiments on three long-form instruction following datasets show that our method significantly improves accuracy, reduces hallucinations, and maintains the comprehensiveness of responses.","authors":["Ruihan Yang","Caiqi Zhang","Zhisong Zhang","Xinting Huang","Sen Yang","Nigel Collier","Dong Yu","Deqing Yang"],"url":"https://arxiv.org/abs/2410.14309"}
{"created":"2025-06-05","title":"Reflection-Bench: Evaluating Epistemic Agency in Large Language Models","abstract":"With large language models (LLMs) increasingly deployed as cognitive engines for AI agents, the reliability and effectiveness critically hinge on their intrinsic epistemic agency, which remains understudied. Epistemic agency, the ability to flexibly construct, adapt, and monitor beliefs about dynamic environments, represents a base-model-level capacity independent of specific tools, modules, or applications. We characterize the holistic process underlying epistemic agency, which unfolds in seven interrelated dimensions: prediction, decision-making, perception, memory, counterfactual thinking, belief updating, and meta-reflection. Correspondingly, we propose Reflection-Bench, a cognitive-psychology-inspired benchmark consisting of seven tasks with long-term relevance and minimization of data leakage. Through a comprehensive evaluation of 16 models using three prompting strategies, we identify a clear three-tier performance hierarchy and significant limitations of current LLMs, particularly in meta-reflection capabilities. While state-of-the-art LLMs demonstrate rudimentary signs of epistemic agency, our findings suggest several promising research directions, including enhancing core cognitive functions, improving cross-functional coordination, and developing adaptive processing mechanisms. Our code and data are available at https://github.com/AI45Lab/ReflectionBench.","authors":["Lingyu Li","Yixu Wang","Haiquan Zhao","Shuqi Kong","Yan Teng","Chunbo Li","Yingchun Wang"],"url":"https://arxiv.org/abs/2410.16270"}
{"created":"2025-06-05","title":"Neural Scoring: A Refreshed End-to-End Approach for Speaker Recognition in Complex Conditions","abstract":"Modern speaker verification systems primarily rely on speaker embeddings and cosine similarity. While effective, these methods struggle with multi-talker speech due to the unidentifiability of embedding vectors. We propose Neural Scoring (NS), a novel end-to-end framework that directly estimates verification posterior probabilities without relying on test-side embeddings, making it more powerful and robust to complex conditions, e.g., with multiple talkers. To address the challenge of training such end-to-end models, we introduce a multi-enrollment training strategy, which pairs each test utterance with multiple enrolled speakers and proves essential to the model's success. Experiments on the VoxCeleb dataset demonstrate that NS consistently outperforms both the baseline and several competitive methods, achieving an overall 70.36% reduction in Equal Error Rate (EER) compared to the baseline.","authors":["Wan Lin","Junhui Chen","Tianhao Wang","Zhenyu Zhou","Lantian Li","Dong Wang"],"url":"https://arxiv.org/abs/2410.16428"}
{"created":"2025-06-05","title":"RULEBREAKERS: Challenging LLMs at the Crossroads between Formal Logic and Human-like Reasoning","abstract":"Formal logic enables computers to reason in natural language by representing sentences in symbolic forms and applying rules to derive conclusions. However, in what our study characterizes as \"rulebreaker\" scenarios, this method can lead to conclusions that are typically not inferred or accepted by humans given their common sense and factual knowledge. Inspired by works in cognitive science, we create RULEBREAKERS, the first dataset for rigorously evaluating the ability of large language models (LLMs) to recognize and respond to rulebreakers (versus non-rulebreakers) in a human-like manner. Evaluating seven LLMs, we find that most models, including GPT-4o, achieve mediocre accuracy on RULEBREAKERS and exhibit some tendency to over-rigidly apply logical rules unlike what is expected from typical human reasoners. Further analysis suggests that this apparent failure is potentially associated with the models' poor utilization of their world knowledge and their attention distribution patterns. Whilst revealing a limitation of current LLMs, our study also provides a timely counterbalance to a growing body of recent works that propose methods relying on formal logic to improve LLMs' general reasoning capabilities, highlighting their risk of further increasing divergence between LLMs and human-like reasoning.","authors":["Jason Chan","Robert Gaizauskas","Zhixue Zhao"],"url":"https://arxiv.org/abs/2410.16502"}
{"created":"2025-06-05","title":"On the computation of accurate initial conditions for linear higher-index differential-algebraic equations and its application in initial value solvers","abstract":"In contrast to regular ordinary differential equations, the problem of accurately setting initial conditions just emerges in the context of differential-algebraic equations where the dynamic degree of freedom of the system is smaller than the absolute dimension of the described process, and the actual lower-dimensional configuration space of the system is deeply implicit. For linear higher-index differential-algebraic equations, we develop an appropriate numerical method based on properties of canonical subspaces and on the so-called geometric reduction. Taking into account the fact that higher-index differential-algebraic equations lead to ill-posed problems in naturally given norms, we modify this approach to serve as transfer conditions from one time-window to the next in a time stepping procedure and combine it with window-wise overdetermined least-squares collocation to construct the first fully numerical solvers for higher-index initial-value problems.","authors":["Michael Hanke","Roswitha M\\\"arz"],"url":"https://arxiv.org/abs/2410.19585"}
{"created":"2025-06-05","title":"DynaSaur: Large Language Agents Beyond Predefined Actions","abstract":"Existing LLM agent systems typically select actions from a fixed and predefined set at every step. While this approach is effective in closed, narrowly scoped environments, it presents two major challenges for real-world, open-ended scenarios: (1) it significantly restricts the planning and acting capabilities of LLM agents, and (2) it requires substantial human effort to enumerate and implement all possible actions, which is impractical in complex environments with a vast number of potential actions. To address these limitations, we propose an LLM agent framework that can dynamically create and compose actions as needed. In this framework, the agent interacts with its environment by generating and executing programs written in a general-purpose programming language. Moreover, generated actions are accumulated over time for future reuse. Our extensive experiments across multiple benchmarks show that this framework significantly improves flexibility and outperforms prior methods that rely on a fixed action set. Notably, it enables LLM agents to adapt and recover in scenarios where predefined actions are insufficient or fail due to unforeseen edge cases. Our code can be found in https://github.com/adobe-research/dynasaur.","authors":["Dang Nguyen","Viet Dac Lai","Seunghyun Yoon","Ryan A. Rossi","Handong Zhao","Ruiyi Zhang","Puneet Mathur","Nedim Lipka","Yu Wang","Trung Bui","Franck Dernoncourt","Tianyi Zhou"],"url":"https://arxiv.org/abs/2411.01747"}
{"created":"2025-06-05","title":"Generating Synthetic Electronic Health Record Data: a Methodological Scoping Review with Benchmarking on Phenotype Data and Open-Source Software","abstract":"We conduct a scoping review of existing approaches for synthetic EHR data generation, and benchmark major methods with proposed open-source software to offer recommendations for practitioners. We search three academic databases for our scoping review. Methods are benchmarked on open-source EHR datasets, MIMIC-III/IV. Seven existing methods covering major categories and two baseline methods are implemented and compared. Evaluation metrics concern data fidelity, downstream utility, privacy protection, and computational cost. 42 studies are identified and classified into five categories. Seven open-source methods covering all categories are selected, trained on MIMIC-III, and evaluated on MIMIC-III or MIMIC-IV for transportability considerations. Among them, GAN-based methods demonstrate competitive performance in fidelity and utility on MIMIC-III; rule-based methods excel in privacy protection. Similar findings are observed on MIMIC-IV, except that GAN-based methods further outperform the baseline methods in preserving fidelity. A Python package, \"SynthEHRella\", is provided to integrate various choices of approaches and evaluation metrics, enabling more streamlined exploration and evaluation of multiple methods. We found that method choice is governed by the relative importance of the evaluation metrics in downstream use cases. We provide a decision tree to guide the choice among the benchmarked methods. Based on the decision tree, GAN-based methods excel when distributional shifts exist between the training and testing populations. Otherwise, CorGAN and MedGAN are most suitable for association modeling and predictive modeling, respectively. Future research should prioritize enhancing fidelity of the synthetic data while controlling privacy exposure, and comprehensive benchmarking of longitudinal or conditional generation methods.","authors":["Xingran Chen","Zhenke Wu","Xu Shi","Hyunghoon Cho","Bhramar Mukherjee"],"url":"https://arxiv.org/abs/2411.04281"}
{"created":"2025-06-05","title":"Enabling LLM Knowledge Analysis via Extensive Materialization","abstract":"Large language models (LLMs) have majorly advanced NLP and AI, and next to their ability to perform a wide range of procedural tasks, a major success factor is their internalized factual knowledge. Since Petroni et al. (2019), analyzing this knowledge has gained attention. However, most approaches investigate one question at a time via modest-sized pre-defined samples, introducing an ``availability bias'' (Tversky&amp;Kahnemann, 1973) that prevents the analysis of knowledge (or beliefs) of LLMs beyond the experimenter's predisposition.","authors":["Yujia Hu","Tuan-Phong Nguyen","Shrestha Ghosh","Simon Razniewski"],"url":"https://arxiv.org/abs/2411.04920"}
{"created":"2025-06-05","title":"Improving Radiology Report Conciseness and Structure via Local Large Language Models","abstract":"Radiology reports are often lengthy and unstructured, posing challenges for referring physicians to quickly identify critical imaging findings while increasing the risk of missed information. This retrospective study aimed to enhance radiology reports by making them concise and well-structured, with findings organized by relevant organs. To achieve this, we utilized private large language models (LLMs) deployed locally within our institution's firewall, ensuring data security and minimizing computational costs. Using a dataset of 814 radiology reports from seven board-certified body radiologists at Moffitt Cancer Center, we tested five prompting strategies within the LangChain framework. After evaluating several models, the Mixtral LLM demonstrated superior adherence to formatting requirements compared to alternatives like Llama. The optimal strategy involved condensing reports first and then applying structured formatting based on specific instructions, reducing verbosity while improving clarity. Across all radiologists and reports, the Mixtral LLM reduced redundant word counts by more than 53%. These findings highlight the potential of locally deployed, open-source LLMs to streamline radiology reporting. By generating concise, well-structured reports, these models enhance information retrieval and better meet the needs of referring physicians, ultimately improving clinical workflows.","authors":["Iryna Hartsock","Cyrillo Araujo","Les Folio","Ghulam Rasool"],"url":"https://arxiv.org/abs/2411.05042"}
{"created":"2025-06-05","title":"ZipNN: Lossless Compression for AI Models","abstract":"With the growth of model sizes and the scale of their deployment, their sheer size burdens the infrastructure requiring more network and more storage to accommodate these. While there is a vast model compression literature deleting parts of the model weights for faster inference, we investigate a more traditional type of compression - one that represents the model in a compact form and is coupled with a decompression algorithm that returns it to its original form and size - namely lossless compression.","authors":["Moshik Hershcovitch","Andrew Wood","Leshem Choshen","Guy Girmonsky","Roy Leibovitz","Ilias Ennmouri","Michal Malka","Peter Chin","Swaminathan Sundararaman","Danny Harnik"],"url":"https://arxiv.org/abs/2411.05239"}
{"created":"2025-06-05","title":"Objective drives the consistency of representational similarity across datasets","abstract":"The Platonic Representation Hypothesis claims that recent foundation models are converging to a shared representation space as a function of their downstream task performance, irrespective of the objectives and data modalities used to train these models (Huh et al., 2024). Representational similarity is generally measured for individual datasets and is not necessarily consistent across datasets. Thus, one may wonder whether this convergence of model representations is confounded by the datasets commonly used in machine learning. Here, we propose a systematic way to measure how representational similarity between models varies with the set of stimuli used to construct the representations. We find that the objective function is a crucial factor in determining the consistency of representational similarities across datasets. Specifically, self-supervised vision models learn representations whose relative pairwise similarities generalize better from one dataset to another compared to those of image classification or image-text models. Moreover, the correspondence between representational similarities and the models' task behavior is dataset-dependent, being most strongly pronounced for single-domain datasets. Our work provides a framework for analyzing similarities of model representations across datasets and linking those similarities to differences in task behavior.","authors":["Laure Ciernik","Lorenz Linhardt","Marco Morik","Jonas Dippel","Simon Kornblith","Lukas Muttenthaler"],"url":"https://arxiv.org/abs/2411.05561"}
{"created":"2025-06-05","title":"RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration","abstract":"Effective group decision-making is critical in Multi-Agent Systems (MAS). Yet, how different mechanisms for reaching consensus impact collaboration quality and efficiency remains understudied. We conduct a systematic study on group decision-making mechanisms in a decentralized setting. Through controlled experiments, we analyze how different voting rules affect decision quality and efficiency in a multi-round collaboration. Results reveal that majority voting often cause inefficient collaboration due to its strict acceptance criteria. At the extreme, unanimous voting gives 87% lower initial performance than the best-performing method. Our qualitative analysis of cross-agent communication shows that messages become longer and more repetitive over time: while message length increases by 84%, similarity to the previous round increases to 90%. Based on these insights, language-based early stopping methods make the performance 13% closer to oracle while reducing rounds by 50%. Our findings highlight the crucial role of group decision-making in optimizing MAS collaboration.","authors":["Young-Min Cho","Raphael Shu","Nilaksh Das","Tamer Alkhouli","Yi-An Lai","Jason Cai","Monica Sunkara","Yi Zhang","Dan Roth"],"url":"https://arxiv.org/abs/2411.07161"}
{"created":"2025-06-05","title":"Beyond the Safety Bundle: Auditing the Helpful and Harmless Dataset","abstract":"In an effort to mitigate the harms of large language models (LLMs), learning from human feedback (LHF) has been used to steer LLMs towards outputs that are intended to be both less harmful and more helpful. Despite the widespread adoption of LHF in practice, the quality of this feedback and its effectiveness as a safety mitigation technique remain unclear. This study addresses these issues by auditing the widely-used Helpful and Harmless (HH) dataset by Anthropic. Our work includes: (1) a thorough investigation of the dataset's content through both manual and automated evaluation; (2) experiments demonstrating the dataset's impact on models' safety; and (3) an analysis of the 100 most influential papers citing this dataset. Through our audit, we showcase how conceptualization failures and quality issues identified in the HH dataset can create additional harms by leading to disparate safety behaviors across demographic groups. Our findings highlight the need for more nuanced, context-sensitive approaches to safety mitigation in LLMs.","authors":["Khaoula Chehbouni","Jonathan Cola\\c{c}o Carr","Yash More","Jackie CK Cheung","Golnoosh Farnadi"],"url":"https://arxiv.org/abs/2411.08243"}
{"created":"2025-06-05","title":"A Survey of Event Causality Identification: Taxonomy, Challenges, Assessment, and Prospects","abstract":"Event Causality Identification (ECI) has emerged as a pivotal task in natural language processing (NLP), aimed at automatically detecting causal relationships between events in text. In this comprehensive survey, we systematically elucidate the foundational principles and technical frameworks of ECI, proposing a novel classification framework to categorize and clarify existing methods. {We discuss associated challenges, provide quantitative evaluations, and outline future directions for this dynamic and rapidly evolving field. We first delineate key definitions, problem formalization, and evaluation protocols of ECI. Our classification framework organizes ECI methods based on two primary tasks: Sentence-level Event Causality Identification (SECI) and Document-level Event Causality Identification (DECI). For SECI, we review methods including feature pattern-based matching, machine learning-based classification, deep semantic encoding, prompt-based fine-tuning, and causal knowledge pre-training, alongside common data augmentation strategies. For DECI, we focus on techniques such as deep semantic encoding, event graph reasoning, and prompt-based fine-tuning. We dedicate specific discussions to advancements in multi-lingual and cross-lingual ECI as well as zero-shot ECI leveraging Large Language Models (LLMs). Furthermore, we analyze the strengths, limitations, and unresolved challenges of each method. Extensive quantitative evaluations are conducted on four benchmark datasets to assess various ECI methods. Finally, we explore future research directions.","authors":["Qing Cheng","Zefan Zeng","Xingchen Hu","Yuehang Si","Zhong Liu"],"url":"https://arxiv.org/abs/2411.10371"}
{"created":"2025-06-05","title":"Engagement-Driven Content Generation with Large Language Models","abstract":"Large Language Models (LLMs) demonstrate significant persuasive capabilities in one-on-one interactions, but their influence within social networks, where interconnected users and complex opinion dynamics pose unique challenges, remains underexplored. This paper addresses the research question: \\emph{Can LLMs generate meaningful content that maximizes user engagement on social networks?}","authors":["Erica Coppolillo","Federico Cinus","Marco Minici","Francesco Bonchi","Giuseppe Manco"],"url":"https://arxiv.org/abs/2411.13187"}
{"created":"2025-06-05","title":"Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator","abstract":"Subject-driven text-to-image generation aims to produce images of a new subject within a desired context by accurately capturing both the visual characteristics of the subject and the semantic content of a text prompt. Traditional methods rely on time- and resource-intensive fine-tuning for subject alignment, while recent zero-shot approaches leverage on-the-fly image prompting, often sacrificing subject alignment. In this paper, we introduce Diptych Prompting, a novel zero-shot approach that reinterprets as an inpainting task with precise subject alignment by leveraging the emergent property of diptych generation in large-scale text-to-image models. Diptych Prompting arranges an incomplete diptych with the reference image in the left panel, and performs text-conditioned inpainting on the right panel. We further prevent unwanted content leakage by removing the background in the reference image and improve fine-grained details in the generated subject by enhancing attention weights between the panels during inpainting. Experimental results confirm that our approach significantly outperforms zero-shot image prompting methods, resulting in images that are visually preferred by users. Additionally, our method supports not only subject-driven generation but also stylized image generation and subject-driven image editing, demonstrating versatility across diverse image generation applications. Project page: https://diptychprompting.github.io/","authors":["Chaehun Shin","Jooyoung Choi","Heeseung Kim","Sungroh Yoon"],"url":"https://arxiv.org/abs/2411.15466"}
{"created":"2025-06-05","title":"Sonic: Shifting Focus to Global Audio Perception in Portrait Animation","abstract":"The study of talking face generation mainly explores the intricacies of synchronizing facial movements and crafting visually appealing, temporally-coherent animations. However, due to the limited exploration of global audio perception, current approaches predominantly employ auxiliary visual and spatial knowledge to stabilize the movements, which often results in the deterioration of the naturalness and temporal inconsistencies.Considering the essence of audio-driven animation, the audio signal serves as the ideal and unique priors to adjust facial expressions and lip movements, without resorting to interference of any visual signals. Based on this motivation, we propose a novel paradigm, dubbed as Sonic, to {s}hift f{o}cus on the exploration of global audio per{c}ept{i}o{n}.To effectively leverage global audio knowledge, we disentangle it into intra- and inter-clip audio perception and collaborate with both aspects to enhance overall perception.For the intra-clip audio perception, 1). \\textbf{Context-enhanced audio learning}, in which long-range intra-clip temporal audio knowledge is extracted to provide facial expression and lip motion priors implicitly expressed as the tone and speed of speech. 2). \\textbf{Motion-decoupled controller}, in which the motion of the head and expression movement are disentangled and independently controlled by intra-audio clips. Most importantly, for inter-clip audio perception, as a bridge to connect the intra-clips to achieve the global perception, \\textbf{Time-aware position shift fusion}, in which the global inter-clip audio information is considered and fused for long-audio inference via through consecutively time-aware shifted windows. Extensive experiments demonstrate that the novel audio-driven paradigm outperform existing SOTA methodologies in terms of video quality, temporally consistency, lip synchronization precision, and motion diversity.","authors":["Xiaozhong Ji","Xiaobin Hu","Zhihong Xu","Junwei Zhu","Chuming Lin","Qingdong He","Jiangning Zhang","Donghao Luo","Yi Chen","Qin Lin","Qinglin Lu","Chengjie Wang"],"url":"https://arxiv.org/abs/2411.16331"}
{"created":"2025-06-05","title":"Ideological Fragmentation of the Social Media Ecosystem: From echo chambers to echo platforms","abstract":"The entertainment-driven nature of social media encourages users to engage with like-minded individuals and consume content aligned with their beliefs, limiting exposure to diverse perspectives. Simultaneously, users migrate between platforms, either due to moderation policies like de-platforming or in search of environments better suited to their preferences. These dynamics drive the specialization of the social media ecosystem, shifting from internal echo chambers to \"echo platforms\"--entire platforms functioning as ideologically homogeneous niches. To systematically analyze this phenomenon in political discussions, we propose a quantitative approach based on three key dimensions: platform centrality, news consumption, and user base composition. We analyze 117 million posts related to the 2020 US Presidential elections from nine social media platforms--Facebook, Reddit, Twitter, YouTube, BitChute, Gab, Parler, Scored, and Voat. Our findings reveal significant differences among platforms in their centrality within the ecosystem, the reliability of circulated news, and the ideological diversity of their users, highlighting a clear divide between mainstream and alt-tech platforms. The latter occupy a peripheral role, feature a higher prevalence of unreliable content, and exhibit greater ideological uniformity. These results highlight the key dimensions shaping the fragmentation and polarization of the social media landscape.","authors":["Edoardo Di Martino","Alessandro Galeazzi","Michele Starnini","Walter Quattrociocchi","Matteo Cinelli"],"url":"https://arxiv.org/abs/2411.16826"}
{"created":"2025-06-05","title":"KVPR: Efficient LLM Inference with I/O-Aware KV Cache Partial Recomputation","abstract":"Inference for Large Language Models (LLMs) is computationally demanding. To reduce the cost of auto-regressive decoding, Key-Value (KV) cache is used to store intermediate activations, which significantly lowers the computational overhead for token generation. However, the memory required for the KV cache grows rapidly, often exceeding the capacity of GPU memory. A cost-effective alternative is to offload KV cache to CPU memory, which alleviates GPU memory pressure, but shifts the bottleneck to the limited bandwidth of the PCIe connection between the CPU and GPU. Existing methods attempt to address these issues by overlapping GPU computation with I/O or employing CPU-GPU heterogeneous execution, but they are hindered by excessive data movement and dependence on CPU capabilities. Fully overlapping PCIe communication latency gets challenging as the size of the KV cache grows and/or the GPU compute capabilities increase. In this paper, we introduce KVPR, an efficient I/O-aware LLM inference method where the CPU first transfers a partial set of activations, from which the GPU can start recomputing the KV cache values. While the GPU recomputes the partial KV cache, the remaining portion of the KV cache is transferred concurrently from the CPU. This approach overlaps GPU recomputation with KV cache transfer to minimize idle GPU time and maximize inference performance. KVPR is fully automated by integrating a profiler module that utilizes input characteristics and system hardware information, a scheduler module to optimize the distribution of computation and communication workloads, and a runtime module to efficiently execute the derived execution plan. Experimental results show that KVPR achieves up to 35.8% lower latency and 46.2% higher throughput during decoding compared to state-of-the-art approaches. The code is available at https://github.com/chaoyij/KVPR.","authors":["Chaoyi Jiang","Lei Gao","Hossein Entezari Zarch","Murali Annavaram"],"url":"https://arxiv.org/abs/2411.17089"}
{"created":"2025-06-05","title":"Learning 3D Representations from Procedural 3D Programs","abstract":"Self-supervised learning has emerged as a promising approach for acquiring transferable 3D representations from unlabeled 3D point clouds. Unlike 2D images, which are widely accessible, acquiring 3D assets requires specialized expertise or professional 3D scanning equipment, making it difficult to scale and raising copyright concerns. To address these challenges, we propose learning 3D representations from procedural 3D programs that automatically generate 3D shapes using simple primitives and augmentations. Remarkably, despite lacking semantic content, the 3D representations learned from the procedurally generated 3D shapes perform on par with state-of-the-art representations learned from semantically recognizable 3D models (e.g., airplanes) across various downstream 3D tasks, including shape classification, part segmentation, and masked point cloud completion. We provide a detailed analysis on factors that make a good 3D procedural program. Extensive experiments further suggest that current self-supervised learning methods on point clouds do not rely on the semantics of 3D shapes, shedding light on the nature of 3D representations learned.","authors":["Xuweiyi Chen","Zezhou Cheng"],"url":"https://arxiv.org/abs/2411.17467"}
{"created":"2025-06-05","title":"FlexiBit: Fully Flexible Precision Bit-parallel Accelerator Architecture for Arbitrary Mixed Precision AI","abstract":"Recent research has shown that large language models (LLMs) can utilize low-precision floating point (FP) quantization to deliver high efficiency while maintaining original model accuracy. In particular, recent works have shown the effectiveness of non-power-of-two precisions, such as FP6 and FP5, and diverse sensitivity to low-precision arithmetic of LLM layers, which motivates mixed precision arithmetic including non-power-of-two precisions in LLMs. Although low-precision algorithmically leads to low computational overheads, such benefits cannot be fully exploited due to hardware constraints that support a limited set of power-of-two precisions (e.g., FP8, 16, 32, and 64 in NVIDIA H100 Tensor Core). In addition, the hardware compute units are designed to support standard formats (e.g., E4M3 and E5M2 for FP8). Such practices require re-designing the hardware whenever new precision and format emerge, which leads to high hardware replacement costs to exploit the benefits of new precisions and formats. Therefore, in this paper, we propose a new accelerator architecture, FlexiBit, which efficiently supports FP and INT arithmetic in arbitrary precisions and formats. Unlike previous bit-serial designs, which also provide flexibility but at the cost of performance due to its bit-wise temporal processing nature, FlexiBit's architecture enables bit-parallel processing of any precision and format without compute unit underutilization. FlexiBit's new capability to exploit non-power of two precision and format led to 1.66x and 1.62x higher performance per area on GPT-3 in FP6 targeting a cloud-scale accelerator, compared to a Tensor Core-like architecture and a state-of-the-art bit-parallel flexible precision accelerator, BitFusion, respectively. Also, the bit-parallel nature of FlexiBit's architecture led to 3.9x higher performance/area compared to a state-of-the-art bit-serial architecture.","authors":["Faraz Tahmasebi","Yian Wang","Benji Y. H. Huang","Hyoukjun Kwon"],"url":"https://arxiv.org/abs/2411.18065"}
{"created":"2025-06-05","title":"Compact finite-difference scheme for some Sobolev type equations with Dirichlet boundary conditions","abstract":"This study aims to construct a stable, high-order compact finite difference method for solving Sobolev-type equations with Dirichlet boundary conditions in one-space dimension. Approximation of higher-order mixed derivatives in some specific Sobolev-type equations requires a bigger stencil information. One can approximate such derivatives on compact stencils, which are higher-order accurate and take less stencil information but are implicit and sparse. Spatial derivatives in this work are approximated using the sixth-order compact finite difference method (Compact6), while temporal derivatives are handled with the explicit forward Euler difference scheme. We examine the accuracy and convergence behavior of the proposed scheme. Using the von Neumann stability analysis, we establish $L_2-$stability theory for the linear case. We derive conditions under which fully discrete schemes are stable. Also, the amplification factor $\\mathcal{C}(\\theta)$ is analyzed to ensure the decay property over time. Real parts of $\\mathcal{C}(\\theta)$ lying on the negative real axis confirm the exponential decay of the solution. A series of numerical experiments were performed to verify the effectiveness of the proposed scheme. These tests include both one dimensional and two-dimensional cases of cases of advection-free and advection-diffusion flows. They also cover applications to the equal width equation, such as the propagation of a single solitary wave, interactions between two and three solitary waves, undular bore formation, and the Benjamin-Bona-Mahony-Burgers equation.","authors":["Lavanya V Salian","Samala Rathan","Rakesh Kumar"],"url":"https://arxiv.org/abs/2411.18445"}
{"created":"2025-06-05","title":"CAdam: Confidence-Based Optimization for Online Learning","abstract":"Modern recommendation systems frequently employ online learning to dynamically update their models with freshly collected data. The most commonly used optimizer for updating neural networks in these contexts is the Adam optimizer, which integrates momentum ($m_t$) and adaptive learning rate ($v_t$). However, the volatile nature of online learning data, characterized by its frequent distribution shifts and presence of noise, poses significant challenges to Adam's standard optimization process: (1) Adam may use outdated momentum and the average of squared gradients, resulting in slower adaptation to distribution changes, and (2) Adam's performance is adversely affected by data noise. To mitigate these issues, we introduce CAdam, a confidence-based optimization strategy that assesses the consistency between the momentum and the gradient for each parameter dimension before deciding on updates. If momentum and gradient are in sync, CAdam proceeds with parameter updates according to Adam's original formulation; if not, it temporarily withholds updates and monitors potential shifts in data distribution in subsequent iterations. This method allows CAdam to distinguish between the true distributional shifts and mere noise, and to adapt more quickly to new data distributions. In various settings with distribution shift or noise, our experiments demonstrate that CAdam surpasses other well-known optimizers, including the original Adam. Furthermore, in large-scale A/B testing within a live recommendation system, CAdam significantly enhances model performance compared to Adam, leading to substantial increases in the system's gross merchandise volume (GMV).","authors":["Shaowen Wang","Anan Liu","Jian Xiao","Huan Liu","Yuekui Yang","Cong Xu","Qianqian Pu","Suncong Zheng","Wei Zhang","Di Wang","Jie Jiang","Jian Li"],"url":"https://arxiv.org/abs/2411.19647"}
{"created":"2025-06-05","title":"Mixture of Experts for Node Classification","abstract":"Nodes in the real-world graphs exhibit diverse patterns in numerous aspects, such as degree and homophily. However, most existent node predictors fail to capture a wide range of node patterns or to make predictions based on distinct node patterns, resulting in unsatisfactory classification performance. In this paper, we reveal that different node predictors are good at handling nodes with specific patterns and only apply one node predictor uniformly could lead to suboptimal result. To mitigate this gap, we propose a mixture of experts framework, MoE-NP, for node classification. Specifically, MoE-NP combines a mixture of node predictors and strategically selects models based on node patterns. Experimental results from a range of real-world datasets demonstrate significant performance improvements from MoE-NP.","authors":["Yu Shi","Yiqi Wang","WeiXuan Lang","Jiaxin Zhang","Pan Dong","Aiping Li"],"url":"https://arxiv.org/abs/2412.00418"}
{"created":"2025-06-05","title":"Diffusion-VLA: Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning","abstract":"In this paper, we present DiffusionVLA, a novel framework that seamlessly combines the autoregression model with the diffusion model for learning visuomotor policy. Central to our approach is a next-token prediction objective, enabling the model to reason effectively over the user's query in the context of current observations. Subsequently, a diffusion model is attached to generate robust action outputs. To enhance policy learning through self-reasoning, we introduce a novel reasoning injection module that integrates reasoning phrases directly into the policy learning process. The whole framework is simple and flexible, making it easy to deploy and upgrade. We conduct extensive experiments using multiple real robots to validate the effectiveness of DiffusionVLA. Our tests include a challenging factory sorting task, where DiffusionVLA successfully categorizes objects, including those not seen during training. We observe that the reasoning module makes the model interpretable. It allows observers to understand the model thought process and identify potential causes of policy failures. Additionally, we test DiffusionVLA on a zero-shot bin-picking task, achieving 63.7\\% accuracy on 102 previously unseen objects. Our method demonstrates robustness to visual changes, such as distractors and new backgrounds, and easily adapts to new embodiments. Furthermore, DiffusionVLA can follow novel instructions and retain conversational ability. Notably, DiffusionVLA is data-efficient and fast at inference; our smallest DiffusionVLA-2B runs 82Hz on a single A6000 GPU and can train from scratch on less than 50 demonstrations for a complex task. Finally, we scale the model from 2B to 72B parameters, showcasing improved generalization capabilities with increased model size.","authors":["Junjie Wen","Minjie Zhu","Yichen Zhu","Zhibin Tang","Jinming Li","Zhongyi Zhou","Chengmeng Li","Xiaoyu Liu","Yaxin Peng","Chaomin Shen","Feifei Feng"],"url":"https://arxiv.org/abs/2412.03293"}
{"created":"2025-06-05","title":"Analysis of the multi-dimensional semi-discrete Active Flux method using the Fourier transform","abstract":"The degrees of freedom of Active Flux are cell averages and point values along the cell boundaries. These latter are shared between neighbouring cells, which gives rise to a globally continuous reconstruction. The semi-discrete Active Flux method uses its degrees of freedom to obtain Finite Difference approxi\\-mations to the spatial derivatives which are used in the point value update. The averages are updated using a quadrature of the flux and making use of the point values as quadrature points. The integration in time employs standard Runge-Kutta methods. We show that this generalization of the Active Flux method in two and three spatial dimensions is stationarity preserving for linear acoustics on Cartesian grids, and present an analysis of numerical diffusion and stability.","authors":["Wasilij Barsukow","Janina Kern","Christian Klingenberg","Lisa Lechner"],"url":"https://arxiv.org/abs/2412.03477"}
{"created":"2025-06-05","title":"T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts","abstract":"Evaluating the quality of synthesized images remains a significant challenge in the development of text-to-image (T2I) generation. Most existing studies in this area primarily focus on evaluating text-image alignment, image quality, and object composition capabilities, with comparatively fewer studies addressing the evaluation of the factuality of T2I models, particularly when the concepts involved are knowledge-intensive. To mitigate this gap, we present T2I-FactualBench in this work - the largest benchmark to date in terms of the number of concepts and prompts specifically designed to evaluate the factuality of knowledge-intensive concept generation. T2I-FactualBench consists of a three-tiered knowledge-intensive text-to-image generation framework, ranging from the basic memorization of individual knowledge concepts to the more complex composition of multiple knowledge concepts. We further introduce a multi-round visual question answering (VQA) based evaluation framework to assess the factuality of three-tiered knowledge-intensive text-to-image generation tasks. Experiments on T2I-FactualBench indicate that current state-of-the-art (SOTA) T2I models still leave significant room for improvement.","authors":["Ziwei Huang","Wanggui He","Quanyu Long","Yandi Wang","Haoyuan Li","Zhelun Yu","Fangxun Shu","Long Chan","Hao Jiang","Fei Wu","Leilei Gan"],"url":"https://arxiv.org/abs/2412.04300"}
{"created":"2025-06-05","title":"MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale","abstract":"Open-source multimodal large language models (MLLMs) have shown significant potential in a broad range of multimodal tasks. However, their reasoning capabilities remain constrained by existing instruction-tuning datasets, which were predominately repurposed from academic datasets such as VQA, AI2D, and ChartQA. These datasets target simplistic tasks, and only provide phrase-level answers without any intermediate rationales. To address these challenges, we introduce a scalable and cost-effective method to construct a large-scale multimodal instruction-tuning dataset with rich intermediate rationales designed to elicit CoT reasoning. Using only open models, we create a dataset containing 12M instruction-response pairs to cover diverse, reasoning-intensive tasks with detailed and faithful rationales. Experiments demonstrate that training MLLMs on this dataset significantly improves reasoning capabilities, achieving state-of-the-art performance on benchmarks such as MathVerse (+8.1%), MMMU-Pro (+7%), and MuirBench (+13.3%). Additionally, the model demonstrates notable improvements of up to 4% on non-reasoning-based benchmarks. Ablation studies further highlight the importance of key components, such as rewriting and self-filtering, in the dataset construction process.","authors":["Jarvis Guo","Tuney Zheng","Yuelin Bai","Bo Li","Yubo Wang","King Zhu","Yizhi Li","Graham Neubig","Wenhu Chen","Xiang Yue"],"url":"https://arxiv.org/abs/2412.05237"}
{"created":"2025-06-05","title":"MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization","abstract":"The advancement of Large Vision-Language Models (LVLMs) has propelled their application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter factuality challenges due to modality misalignment, where the models prioritize textual knowledge over visual input, leading to hallucinations that contradict information in medical images. Previous attempts to enhance modality alignment in Med-LVLMs through preference optimization have inadequately mitigated clinical relevance in preference data, making these samples easily distinguishable and reducing alignment effectiveness. To address this challenge, we propose MMedPO, a novel multimodal medical preference optimization approach that considers the clinical relevance of preference samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference data by introducing two types of dispreference: (1) plausible hallucinations injected through target Med-LVLMs or GPT-4o to produce medically inaccurate responses, and (2) lesion region neglect achieved through local lesion-noising, disrupting visual understanding of critical areas. We then calculate clinical relevance for each sample based on scores from multiple Med-LLMs and visual tools, and integrate these scores into the preference optimization process as weights, enabling effective alignment. Our experiments demonstrate that MMedPO significantly enhances factual accuracy in Med-LVLMs, achieving substantial improvements over existing preference optimization methods by averaging 14.2% and 51.7% across the Med-VQA and report generation tasks. Our code are available in https://github.com/aiming-lab/MMedPO.","authors":["Kangyu Zhu","Peng Xia","Yun Li","Hongtu Zhu","Sheng Wang","Huaxiu Yao"],"url":"https://arxiv.org/abs/2412.06141"}
{"created":"2025-06-05","title":"Deterministic and randomized LU-Householder CholeskyQR","abstract":"In this work, we develop LU-Householder CholeskyQR (LHC) for QR factorization of tall-skinny matrices. Similar to LU-CholeskyQR \\cite{LUChol}, LHC does not require a sufficient condition of $\\kappa_{2}(X)$ for the input tall-skinny matrix $X \\in \\mathbb{R}^{m\\times n}$. This characteristic ensures the algorithm's reliability in the real-world applications, which is different from other CholeskyQR-type algorithms. To address the issue of numerical breakdown in Cholesky factorization of LU-CholeskyQR when the $L$-factor is ill-conditioned, LHC employs HouseholderQR to generate the upper-triangular factor alternatively. In order to accelerate LHC for tall-skinny matrices, we incorporate the latest sketching techniques to develop randomized versions of LHC, SLHC with single-sketching and SSLHC with multi-sketching. To ensure numerical stability, LHC2, SLHC3, and SSLHC3 are constructed with CholeskyQR(2) after the preconditioning steps. We provide rounding error analysis of these new algorithms. Numerical experiments demonstrate the better applicability of our new algorithms compared to LU-CholeskyQR2 while maintaining numerical stability. With the sketching technique, our randomized algorithms, SLHC3 and SSLHC3, show significant acceleration over LHC2 in our tests. Among them, SLHC3 with the Gaussian sketch can deal with more ill-conditioned $X$ with different $m$ and $n$ for $X$. SSLHC3 with multi-sketching is applicable when $\\frac{m}{n}$ is large enough and is more efficient than SLHC3. Both of them are robust enough after numerous experiments.","authors":["Haoran Guan","Yuwei Fan"],"url":"https://arxiv.org/abs/2412.06551"}
{"created":"2025-06-05","title":"Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation","abstract":"Accurate uncertainty estimation is crucial for deploying neural networks in risk-sensitive applications such as medical diagnosis. Monte Carlo Dropout is a widely used technique for approximating predictive uncertainty by performing stochastic forward passes with dropout during inference. However, using static dropout rates across all layers and inputs can lead to suboptimal uncertainty estimates, as it fails to adapt to the varying characteristics of individual inputs and network layers. Existing approaches optimize dropout rates during training using labeled data, resulting in fixed inference-time parameters that cannot adjust to new data distributions, compromising uncertainty estimates in Monte Carlo simulations.","authors":["Tal Zeevi","Ravid Shwartz-Ziv","Yann LeCun","Lawrence H. Staib","John A. Onofrey"],"url":"https://arxiv.org/abs/2412.07169"}
{"created":"2025-06-05","title":"Addressing Key Challenges of Adversarial Attacks and Defenses in the Tabular Domain: A Methodological Framework for Coherence and Consistency","abstract":"Machine learning models trained on tabular data are vulnerable to adversarial attacks, even in realistic scenarios where attackers only have access to the model's outputs. Since tabular data contains complex interdependencies among features, it presents a unique challenge for adversarial samples which must maintain coherence and respect these interdependencies to remain indistinguishable from benign data. Moreover, existing attack evaluation metrics-such as the success rate, perturbation magnitude, and query count-fail to account for this challenge. To address those gaps, we propose a technique for perturbing dependent features while preserving sample coherence. In addition, we introduce Class-Specific Anomaly Detection (CSAD), an effective novel anomaly detection approach, along with concrete metrics for assessing the quality of tabular adversarial attacks. CSAD evaluates adversarial samples relative to their predicted class distribution, rather than a broad benign distribution. It ensures that subtle adversarial perturbations, which may appear coherent in other classes, are correctly identified as anomalies. We integrate SHAP explainability techniques to detect inconsistencies in model decision-making, extending CSAD for SHAP-based anomaly detection. Our evaluation incorporates both anomaly detection rates with SHAP-based assessments to provide a more comprehensive measure of adversarial sample quality. We evaluate various attack strategies, examining black-box query-based and transferability-based gradient attacks across four target models. Experiments on benchmark tabular datasets reveal key differences in the attacker's risk and effort and attack quality, offering insights into the strengths, limitations, and trade-offs faced by attackers and defenders. Our findings lay the groundwork for future research on adversarial attacks and defense development in the tabular domain.","authors":["Yael Itzhakev","Amit Giloni","Yuval Elovici","Asaf Shabtai"],"url":"https://arxiv.org/abs/2412.07326"}
{"created":"2025-06-05","title":"From Intention To Implementation: Automating Biomedical Research via LLMs","abstract":"Conventional biomedical research is increasingly labor-intensive due to the exponential growth of scientific literature and datasets. Artificial intelligence (AI), particularly Large Language Models (LLMs), has the potential to revolutionize this process by automating various steps. Still, significant challenges remain, including the need for multidisciplinary expertise, logicality of experimental design, and performance measurements. This paper introduces BioResearcher, the first end-to-end automated system designed to streamline the entire biomedical research process involving dry lab experiments. BioResearcher employs a modular multi-agent architecture, integrating specialized agents for search, literature processing, experimental design, and programming. By decomposing complex tasks into logically related sub-tasks and utilizing a hierarchical learning approach, BioResearcher effectively addresses the challenges of multidisciplinary requirements and logical complexity. Furthermore, BioResearcher incorporates an LLM-based reviewer for in-process quality control and introduces novel evaluation metrics to assess the quality and automation of experimental protocols. BioResearcher successfully achieves an average execution success rate of 63.07% across eight previously unmet research objectives. The generated protocols averagely outperform typical agent systems by 22.0% on five quality metrics. The system demonstrates significant potential to reduce researchers' workloads and accelerate biomedical discoveries, paving the way for future innovations in automated research systems.","authors":["Yi Luo","Linghang Shi","Yihao Li","Aobo Zhuang","Yeyun Gong","Ling Liu","Chen Lin"],"url":"https://arxiv.org/abs/2412.09429"}
{"created":"2025-06-05","title":"Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders","abstract":"We address the problem of gaze target estimation, which aims to predict where a person is looking in a scene. Predicting a person's gaze target requires reasoning both about the person's appearance and the contents of the scene. Prior works have developed increasingly complex, hand-crafted pipelines for gaze target estimation that carefully fuse features from separate scene encoders, head encoders, and auxiliary models for signals like depth and pose. Motivated by the success of general-purpose feature extractors on a variety of visual tasks, we propose Gaze-LLE, a novel transformer framework that streamlines gaze target estimation by leveraging features from a frozen DINOv2 encoder. We extract a single feature representation for the scene, and apply a person-specific positional prompt to decode gaze with a lightweight module. We demonstrate state-of-the-art performance across several gaze benchmarks and provide extensive analysis to validate our design choices. Our code is available at: http://github.com/fkryan/gazelle .","authors":["Fiona Ryan","Ajay Bati","Sangmin Lee","Daniel Bolya","Judy Hoffman","James M. Rehg"],"url":"https://arxiv.org/abs/2412.09586"}
{"created":"2025-06-05","title":"LAVA: Lifetime-Aware VM Allocation with Learned Distributions and Adaptation to Mispredictions","abstract":"Scheduling virtual machines (VMs) on hosts in cloud data centers dictates efficiency and is an NP-hard problem with incomplete information. Prior work improved VM scheduling with predicted VM lifetimes. Our work further improves lifetime-aware scheduling using repredictions with lifetime distributions versus one-shot prediction. Our approach repredicts and adjusts VM and host lifetimes when incorrect predictions emerge. We also present novel approaches for defragmentation and regular system maintenance, which are essential to our data center reliability and optimizations, and are not explored in prior work. We show repredictions deliver a fundamental advance in effectiveness over one-shot prediction.","authors":["Jianheng Ling","Pratik Worah","Yawen Wang","Yunchuan Kong","Anshul Kapoor","Chunlei Wang","Clifford Stein","Diwakar Gupta","Jason Behmer","Logan A. Bush","Prakash Ramanan","Rajesh Kumar","Thomas Chestna","Yajing Liu","Ying Liu","Ye Zhao","Kathryn S. McKinley","Meeyoung Park","Martin Maas"],"url":"https://arxiv.org/abs/2412.09840"}
{"created":"2025-06-05","title":"Single-Pass Object-Focused Data Selection","abstract":"While unlabeled image data is often plentiful, the costs of high-quality labels pose an important practical challenge: Which images should one select for labeling to use the annotation budget for a particular target task most effectively? To address this problem, we focus on single-pass data selection, which refers to the process of selecting all data to be annotated at once before training a downstream model. Prior methods for single-pass data selection rely on image-level representations and fail to reliably outperform random selection for object detection and segmentation. We propose Object-Focused Data Selection (OFDS) which leverages object-level features from foundation models and ensures semantic coverage of all target classes. In extensive experiments across tasks and target domains, OFDS consistently outperforms random selection and all baselines. The best results for constrained annotation budgets are obtained by combining human labels from OFDS with autolabels from foundation models. Moreover, using OFDS to select the initial labeled set for active learning yields consistent improvements","authors":["Niclas Popp","Dan Zhang","Jan Hendrik Metzen","Matthias Hein","Lukas Schott"],"url":"https://arxiv.org/abs/2412.10032"}
{"created":"2025-06-05","title":"ExeChecker: Where Did I Go Wrong?","abstract":"In this paper, we present a contrastive learning based framework, ExeChecker, for the interpretation of rehabilitation exercises. Our work builds upon state-of-the-art advances in the area of human pose estimation, graph-attention neural networks, and transformer interpretablity. The downstream task is to assist rehabilitation by providing informative feedback to users while they are performing prescribed exercises. We utilize a contrastive learning strategy during training. Given a tuple of correctly and incorrectly executed exercises, our model is able to identify and highlight those joints that are involved in an incorrect movement and thus require the user's attention. We collected an in-house dataset, ExeCheck, with paired recordings of both correct and incorrect execution of exercises. In our experiments, we tested our method on this dataset as well as the UI-PRMD dataset and found ExeCheck outperformed the baseline method using pairwise sequence alignment in identifying joints of physical relevance in rehabilitation exercises.","authors":["Yiwen Gu","Mahir Patel","Margrit Betke"],"url":"https://arxiv.org/abs/2412.10573"}
{"created":"2025-06-05","title":"RAC3: Retrieval-Augmented Corner Case Comprehension for Autonomous Driving with Vision-Language Models","abstract":"Understanding and addressing corner cases is essential for ensuring the safety and reliability of autonomous driving systems. Vision-language models (VLMs) play a crucial role in enhancing scenario comprehension, yet they face significant challenges, such as hallucination and insufficient real-world grounding, which compromise their performance in critical driving scenarios. In this work, RAC3, a novel framework designed to enhance the performance of VLMs in corner case comprehension, is proposed. RAC3 integrates a frequency-spatial fusion (FSF) image encoder, a cross-modal alignment training method for embedding models with hard and semi-hard negative mining, and a fast querying and retrieval pipeline based on K-Means clustering and hierarchical navigable small world (HNSW) indexing. A multimodal chain-of-thought (CoT) prompting strategy to guide analogical reasoning and reduce hallucinations during inference is introduced. Moreover, an update mechanism is integrated into RAC3 to ensure continual learning within the framework. Extensive experiments on the CODA and nuScenes datasets demonstrate that RAC3 significantly improves corner case comprehension across multiple downstream tasks. Compared to prior state-of-the-art methods, RAC3 achieves the highest final score of 74.46 on the CODA-LM benchmark and shows consistent performance gains when integrated with end-to-end frameworks like DriveLM. These results demonstrate the effectiveness of retrieval-augmented strategies and cross-modal alignment for safer and more interpretable autonomous driving.","authors":["Yujin Wang","Quanfeng Liu","Jiaqi Fan","Jinlong Hong","Hongqing Chu","Mengjian Tian","Bingzhao Gao","Hong Chen"],"url":"https://arxiv.org/abs/2412.11050"}
{"created":"2025-06-05","title":"CondiMen: Conditional Multi-Person Mesh Recovery","abstract":"Multi-person human mesh recovery (HMR) consists in detecting all individuals in a given input image, and predicting the body shape, pose, and 3D location for each detected person. The dominant approaches to this task rely on neural networks trained to output a single prediction for each detected individual. In contrast, we propose CondiMen, a method that outputs a joint parametric distribution over likely poses, body shapes, intrinsics and distances to the camera, using a Bayesian network. This approach offers several advantages. First, a probability distribution can handle some inherent ambiguities of this task -- such as the uncertainty between a person's size and their distance to the camera, or simply the loss of information when projecting 3D data onto the 2D image plane. Second, the output distribution can be combined with additional information to produce better predictions, by using e.g. known camera or body shape parameters, or by exploiting multi-view observations. Third, one can efficiently extract the most likely predictions from the output distribution, making our proposed approach suitable for real-time applications. Empirically we find that our model i) achieves performance on par with or better than the state-of-the-art, ii) captures uncertainties and correlations inherent in pose estimation and iii) can exploit additional information at test time, such as multi-view consistency or body shape priors. CondiMen spices up the modeling of ambiguity, using just the right ingredients on hand.","authors":["Br\\'egier Romain","Baradel Fabien","Lucas Thomas","Galaaoui Salma","Armando Matthieu","Weinzaepfel Philippe","Rogez Gr\\'egory"],"url":"https://arxiv.org/abs/2412.13058"}
{"created":"2025-06-05","title":"HashAttention: Semantic Sparsity for Faster Inference","abstract":"Leveraging long contexts is crucial for advanced AI systems, but attention computation poses a scalability challenge. While scaled dot-product attention (SDPA) exhibits token sparsity, i.e. only a few pivotal tokens significantly contribute to output, exploiting this sparsity remains challenging. Existing methods either suffer from quality degradation or require substantial additional resources. We show that identifying pivotal tokens is a Maximum Inner Product Search (MIPS) problem. However, existing MIPS solutions are not well-suited for SDPA, as they are not GPU-friendly and often underperform due to the separated query and key distributions. This paper introduces HashAttention, framing pivotal token identification as a recommendation problem. Given a query, HashAttention encodes keys and queries in Hamming space, capturing the required semantic similarity, using learned mapping functions. HashAttention efficiently identifies pivotal tokens for a given query using bitwise operations and computes attention using only these tokens, improving the overall attention efficiency. Trained on generic data, HashAttention reduces tokens used by up to $16\\times$ with minimal quality loss, requiring only 32 bits of auxiliary memory per token. Sparsity can be further improved to $32\\times$ through task-specific fine-tuning. On A100 GPU, at $32\\times$ sparsity, incorporating HashAttention reduces attention latency by up to $4.3\\times$ in GPT-FAST and $2.54\\times$ in FlashDecode, and achieves up to $3.12\\times$ higher throughput for GPT-FAST.","authors":["Aditya Desai","Shuo Yang","Alejandro Cuadron","Matei Zaharia","Joseph E. Gonzalez","Ion Stoica"],"url":"https://arxiv.org/abs/2412.14468"}
{"created":"2025-06-05","title":"EnergyMoGen: Compositional Human Motion Generation with Energy-Based Diffusion Model in Latent Space","abstract":"Diffusion models, particularly latent diffusion models, have demonstrated remarkable success in text-driven human motion generation. However, it remains challenging for latent diffusion models to effectively compose multiple semantic concepts into a single, coherent motion sequence. To address this issue, we propose EnergyMoGen, which includes two spectrums of Energy-Based Models: (1) We interpret the diffusion model as a latent-aware energy-based model that generates motions by composing a set of diffusion models in latent space; (2) We introduce a semantic-aware energy model based on cross-attention, which enables semantic composition and adaptive gradient descent for text embeddings. To overcome the challenges of semantic inconsistency and motion distortion across these two spectrums, we introduce Synergistic Energy Fusion. This design allows the motion latent diffusion model to synthesize high-quality, complex motions by combining multiple energy terms corresponding to textual descriptions. Experiments show that our approach outperforms existing state-of-the-art models on various motion generation tasks, including text-to-motion generation, compositional motion generation, and multi-concept motion generation. Additionally, we demonstrate that our method can be used to extend motion datasets and improve the text-to-motion task.","authors":["Jianrong Zhang","Hehe Fan","Yi Yang"],"url":"https://arxiv.org/abs/2412.14706"}
{"created":"2025-06-05","title":"Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation","abstract":"In this paper, we show that knowledge distillation can be subverted to manipulate language model benchmark scores, revealing a critical vulnerability in current evaluation practices. We introduce \"Data Laundering,\" a process that enables the covert transfer of benchmark-specific knowledge through seemingly legitimate intermediate training steps. Through extensive experiments with a 2-layer BERT student model, we show how this approach can achieve substantial improvements in benchmark accuracy (up to 75\\% on GPQA) without developing genuine reasoning capabilities. Notably, this method can be exploited intentionally or even unintentionally, as researchers may inadvertently adopt this method and inflate scores without realising the implications. While our findings demonstrate the effectiveness of this technique, we present them as a cautionary tale highlighting the urgent need for more robust evaluation methods in AI. This work aims to contribute to the ongoing discussion about evaluation integrity in AI development and the need for benchmarks that more accurately reflect true model capabilities. The code is available at https://github.com/mbzuai-nlp/data_laundering.","authors":["Jonibek Mansurov","Akhmed Sakip","Alham Fikri Aji"],"url":"https://arxiv.org/abs/2412.15255"}
{"created":"2025-06-05","title":"Verbosity-Aware Rationale Reduction: Effective Reduction of Redundant Rationale via Principled Criteria","abstract":"Large Language Models (LLMs) rely on generating extensive intermediate reasoning units (e.g., tokens, sentences) to enhance final answer quality across a wide range of complex tasks. While this approach has proven effective, it inevitably increases substantial inference costs. Previous methods adopting token-level reduction without clear criteria result in poor performance compared to models trained with complete rationale. To address this challenge, we propose a novel sentence-level rationale reduction framework leveraging likelihood-based criteria, verbosity, to identify and remove redundant reasoning sentences. Unlike previous approaches, our method leverages verbosity to selectively remove redundant reasoning sentences while preserving reasoning capabilities. Our experimental results across various reasoning tasks demonstrate that our method improves performance by an average of 7.71% while reducing token generation by 19.87% compared to model trained with complete reasoning paths.","authors":["Joonwon Jang","Jaehee Kim","Wonbin Kweon","Seonghyeon Lee","Hwanjo Yu"],"url":"https://arxiv.org/abs/2412.21006"}
{"created":"2025-06-05","title":"Model Reduction for Transport-Dominated Problems via Cross-Correlation Based Snapshot Registration","abstract":"Traditional linear approximation methods, such as proper orthogonal decomposition and the reduced basis method, are ill-suited for transport-dominated problems due to the slow decay of the Kolmogorov $n$-width, leading to inefficient and inaccurate reduced-order models. In this work, we propose a model reduction approach for transport-dominated problems by employing cross-correlation based snapshot registration to accelerate the Kolmogorov $n$-width decay, thereby enabling the construction of efficient and accurate reduced-order models using linear approximation methods. We propose a complete framework comprising offline-online stages for the development of reduced order models using the cross-correlation based snapshots registration. The effectiveness of the proposed approach is demonstrated using two test cases: 1D travelling waves and the higher-order methods benchmark test case, 2D isentropic convective vortex.","authors":["Harshith Gowrachari","Giovanni Stabile","Gianluigi Rozza"],"url":"https://arxiv.org/abs/2501.01299"}
{"created":"2025-06-05","title":"Distributed Framework Construction for Affine Formation Control","abstract":"In affine formation control problems, the construction of the framework with universal rigidity and affine localizability is a critical prerequisite, but it has not yet been well addressed, especially when additional agents join the formation or link/agent failures emerge. Motivated by this observation, we investigate the problem of constructing affine frameworks in three scenarios, including vertex addition, edge deletion and vertex deletion. Our approach starts from the original affine formation and uses geometric methods to locally adjust the structure of the weighted graph to describe the topology, so that the modified framework maintains the universal rigidity and affine localizability. Notably, the developed strategies only utilize local measurements and exhibit distributed characteristics, laying the foundation for applications in multi-agent systems. To demonstrate the compatibility with affine formation control proposals, we present a case study on affine formation tracking in a multi-UAV formation, demonstrating the effectiveness of our algorithms in constructing eligible frameworks in aforementioned scenarios. Moreover, a comparative simulation is also conducted to highlight the low time complexity of our distributed algorithm relative to the centralized optimization-based method.","authors":["Huiming Li","Hao Chen","Xiangke Wang","Zhongkui Li","Lincheng Shen"],"url":"https://arxiv.org/abs/2501.01817"}
{"created":"2025-06-05","title":"Scaling Laws for Floating Point Quantization Training","abstract":"Low-precision training is considered an effective strategy for reducing both training and downstream inference costs. Previous scaling laws for precision mainly focus on integer quantization, which pay less attention to the constituents in floating-point (FP) quantization, and thus cannot well fit the LLM losses in this scenario. In contrast, while FP quantization training is more commonly implemented in production, it's research has been relatively superficial. In this paper, we thoroughly explore the effects of FP quantization targets, exponent bits, mantissa bits, and the calculation granularity of the scaling factor in FP quantization training performance of LLM models. In addition to an accurate FP quantization unified scaling law, we also provide valuable suggestions for the community: (1) Exponent bits contribute slightly more to the model performance than mantissa bits. We provide the optimal exponent-mantissa bit ratio for different bit numbers, which is available for future reference by hardware manufacturers; (2) We discover the formation of the critical data size in low-precision LLM training. Too much training data exceeding the critical data size will inversely bring in degradation of LLM performance; (3) The optimal FP quantization precision is directly proportional to the computational power, but within a wide computational power range. We estimate that the best cost-performance precision should lie between 4-8 bits.","authors":["Xingwu Sun","Shuaipeng Li","Ruobing Xie","Weidong Han","Kan Wu","Zhen Yang","Yixing Li","An Wang","Shuai Li","Jinbao Xue","Yu Cheng","Yangyu Tao","Zhanhui Kang","Chengzhong Xu","Di Wang","Jie Jiang"],"url":"https://arxiv.org/abs/2501.02423"}
{"created":"2025-06-05","title":"Publish on Ping: A Better Way to Publish Reservations in Memory Reclamation for Concurrent Data Structures","abstract":"Safe memory reclamation techniques that utilize per read reservations, such as hazard pointers, often cause significant overhead in traversals of linked concurrent data structures. This is primarily due to the need to announce a reservation, and fence to enforce appropriate ordering, before each read. In read-intensive workloads, this overhead is amplified because, even if relatively little memory reclamation actually occurs, the full overhead of reserving records is still incurred while traversing data structures.","authors":["Ajay Singh","Trevor Brown"],"url":"https://arxiv.org/abs/2501.04250"}
{"created":"2025-06-05","title":"Understanding Impact of Human Feedback via Influence Functions","abstract":"In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn suitable reward models from human feedback to align large language models (LLMs) with human intentions. However, human feedback can often be noisy, inconsistent, or biased, especially when evaluating complex responses. Such feedback can lead to misaligned reward signals, potentially causing unintended side effects during the RLHF process. To address these challenges, we explore the use of influence functions to measure the impact of human feedback on the performance of reward models. We propose a compute-efficient approximation method that enables the application of influence functions to LLM-based reward models and large-scale preference datasets. In our experiments, we demonstrate two key applications of influence functions: (1) detecting common forms of labeler bias in human feedback datasets and (2) guiding labelers to refine their strategies to align more closely with expert feedback. By quantifying the impact of human feedback on reward models, we believe that influence functions can enhance feedback interpretability and contribute to scalable oversight in RLHF, helping labelers provide more accurate and consistent feedback. Source code is available at https://github.com/mintaywon/IF_RLHF","authors":["Taywon Min","Haeone Lee","Yongchan Kwon","Kimin Lee"],"url":"https://arxiv.org/abs/2501.05790"}
{"created":"2025-06-05","title":"ConSim: Measuring Concept-Based Explanations' Effectiveness with Automated Simulatability","abstract":"Concept-based explanations work by mapping complex model computations to human-understandable concepts. Evaluating such explanations is very difficult, as it includes not only the quality of the induced space of possible concepts but also how effectively the chosen concepts are communicated to users. Existing evaluation metrics often focus solely on the former, neglecting the latter. We introduce an evaluation framework for measuring concept explanations via automated simulatability: a simulator's ability to predict the explained model's outputs based on the provided explanations. This approach accounts for both the concept space and its interpretation in an end-to-end evaluation. Human studies for simulatability are notoriously difficult to enact, particularly at the scale of a wide, comprehensive empirical evaluation (which is the subject of this work). We propose using large language models (LLMs) as simulators to approximate the evaluation and report various analyses to make such approximations reliable. Our method allows for scalable and consistent evaluation across various models and datasets. We report a comprehensive empirical evaluation using this framework and show that LLMs provide consistent rankings of explanation methods. Code available at https://github.com/AnonymousConSim/ConSim.","authors":["Antonin Poch\\'e (IRIT)","Alon Jacovi (CERCO UMR5549","ANITI)","Agustin Martin Picard (CERCO UMR5549","ANITI)","Victor Boutin (CERCO UMR5549","ANITI)","Fanny Jourdan"],"url":"https://arxiv.org/abs/2501.05855"}
{"created":"2025-06-05","title":"Model Alignment Search","abstract":"When can we say that two neural systems are the same? The answer to this question is goal-dependent, and it is often addressed through correlative methods such as Representational Similarity Analysis (RSA) and Centered Kernel Alignment (CKA). What nuances do we miss, however, when we fail to causally probe the representations? Do the dangers of cause vs. correlation exist in comparative representational analyses? In this work, we introduce a method for connecting neural representational similarity to behavior through causal interventions. The method learns orthogonal transformations that find an aligned subspace in which behavioral information from multiple distributed networks' representations can be isolated and interchanged. We first show that the method can be used to transfer the behavior from one frozen Neural Network (NN) to another in a manner similar to model stitching, and we show how the method can complement correlative similarity measures like RSA. We then introduce an efficient subspace orthogonalization technique using the Gram-Schmidt process -- that can also be used for Distributed Alignment Search (DAS) -- allowing us to perform analyses on larger models. Next, we empirically and theoretically show how our method can be equivalent to model stitching when desired, or it can take a form that is more restrictive to causal information, and in both cases, it reduces the number of required matrices for a comparison of n models from quadratic to linear in n. We then show how we can augment the loss objective with an auxiliary loss to train causally relevant alignments even when we can only read the representations from one of the two networks during training (like with biological networks). Lastly, we use number representations as a case study to explore how our method can be used to compare specific types of representational information across tasks and models.","authors":["Satchel Grant"],"url":"https://arxiv.org/abs/2501.06164"}
{"created":"2025-06-05","title":"An Adaptive Orthogonal Convolution Scheme for Efficient and Flexible CNN Architectures","abstract":"Orthogonal convolutional layers are valuable components in multiple areas of machine learning, such as adversarial robustness, normalizing flows, GANs, and Lipschitz-constrained models. Their ability to preserve norms and ensure stable gradient propagation makes them valuable for a large range of problems. Despite their promise, the deployment of orthogonal convolution in large-scale applications is a significant challenge due to computational overhead and limited support for modern features like strides, dilations, group convolutions, and transposed convolutions. In this paper, we introduce AOC (Adaptative Orthogonal Convolution), a scalable method that extends a previous method (BCOP), effectively overcoming existing limitations in the construction of orthogonal convolutions. This advancement unlocks the construction of architectures that were previously considered impractical. We demonstrate through our experiments that our method produces expressive models that become increasingly efficient as they scale. To foster further advancement, we provide an open-source python package implementing this method, called Orthogonium ( https://github.com/deel-ai/orthogonium ) .","authors":["Thibaut Boissin (IRIT)","Franck Mamalet (IRIT)","Thomas Fel (IRIT)","Agustin Martin Picard (IRIT)","Thomas Massena (IRIT)","Mathieu Serrurier (IRIT)"],"url":"https://arxiv.org/abs/2501.07930"}
{"created":"2025-06-05","title":"Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks","abstract":"Developing high-performance deep learning models is resource-intensive, leading model owners to utilize Machine Learning as a Service (MLaaS) platforms instead of publicly releasing their models. However, malicious users may exploit query interfaces to execute model extraction attacks, reconstructing the target model's functionality locally. While prior research has investigated triggerable watermarking techniques for asserting ownership, existing methods face significant challenges: (1) most approaches require additional training, resulting in high overhead and limited flexibility, and (2) they often fail to account for advanced attackers, leaving them vulnerable to adaptive attacks.","authors":["Yixiao Xu","Binxing Fang","Rui Wang","Yinghai Zhou","Yuan Liu","Mohan Li","Zhihong Tian"],"url":"https://arxiv.org/abs/2501.09328"}
{"created":"2025-06-05","title":"Weight for Robustness: A Comprehensive Approach towards Optimal Fault-Tolerant Asynchronous ML","abstract":"We address the challenges of Byzantine-robust training in asynchronous distributed machine learning systems, aiming to enhance efficiency amid massive parallelization and heterogeneous computing resources. Asynchronous systems, marked by independently operating workers and intermittent updates, uniquely struggle with maintaining integrity against Byzantine failures, which encompass malicious or erroneous actions that disrupt learning. The inherent delays in such settings not only introduce additional bias to the system but also obscure the disruptions caused by Byzantine faults. To tackle these issues, we adapt the Byzantine framework to asynchronous dynamics by introducing a novel weighted robust aggregation framework. This allows for the extension of robust aggregators and a recent meta-aggregator to their weighted versions, mitigating the effects of delayed updates. By further incorporating a recent variance-reduction technique, we achieve an optimal convergence rate for the first time in an asynchronous Byzantine environment. Our methodology is rigorously validated through empirical and theoretical analysis, demonstrating its effectiveness in enhancing fault tolerance and optimizing performance in asynchronous ML systems.","authors":["Tehila Dahan","Kfir Y. Levy"],"url":"https://arxiv.org/abs/2501.09621"}
{"created":"2025-06-05","title":"Dendritic Localized Learning: Toward Biologically Plausible Algorithm","abstract":"Backpropagation is the foundational algorithm for training neural networks and a key driver of deep learning's success. However, its biological plausibility has been challenged due to three primary limitations: weight symmetry, reliance on global error signals, and the dual-phase nature of training, as highlighted by the existing literature. Although various alternative learning approaches have been proposed to address these issues, most either fail to satisfy all three criteria simultaneously or yield suboptimal results. Inspired by the dynamics and plasticity of pyramidal neurons, we propose Dendritic Localized Learning (DLL), a novel learning algorithm designed to overcome these challenges. Extensive empirical experiments demonstrate that DLL satisfies all three criteria of biological plausibility while achieving state-of-the-art performance among algorithms that meet these requirements. Furthermore, DLL exhibits strong generalization across a range of architectures, including MLPs, CNNs, and RNNs. These results, benchmarked against existing biologically plausible learning algorithms, offer valuable empirical insights for future research. We hope this study can inspire the development of new biologically plausible algorithms for training multilayer networks and advancing progress in both neuroscience and machine learning. Our code is available at https://github.com/Lvchangze/Dendritic-Localized-Learning.","authors":["Changze Lv","Jingwen Xu","Yiyang Lu","Xiaohua Wang","Zhenghua Wang","Zhibo Xu","Di Yu","Xin Du","Xiaoqing Zheng","Xuanjing Huang"],"url":"https://arxiv.org/abs/2501.09976"}
{"created":"2025-06-05","title":"Data-Juicer 2.0: Cloud-Scale Adaptive Data Processing for and with Foundation Models","abstract":"The burgeoning field of foundation models necessitates advanced data processing mechanisms capable of harnessing vast and valuable data with various types used by these models. Nevertheless, the current landscape presents unique challenges that traditional data processing frameworks struggle to handle effectively, particularly in handling the complexity of multimodal data. In response, we present Data-Juicer 2.0, a data processing system backed by 100+ data processing operators spanning text, image, video, and audio modalities, supporting more critical tasks including data analysis, synthesis, annotation, and foundation model post-training. With seamless compatibility and dedicated optimization for popular dataset hubs like Hugging Face and computing engines like Ray, it improves upon its predecessor in terms of usability, efficiency, and programmability. It features an easily accessible user interface layer that supports decoupled Python interactions, RESTful APIs, and conversational commands. It contains a new runtime layer optimized for adaptive execution and management across varying dataset scales, processing demands, and computational environments, while hiding unnecessary system details. Extensive empirical evaluations demonstrate Data-Juicer 2.0's remarkable performance and scalability, highlighting its capability to efficiently process TB-level data with 10k+ CPU cores. The system is publicly available and has been widely adopted in diverse research fields and real-world products such as Alibaba Cloud PAI. We actively maintain it and share insights from practical feedback, with the goal of facilitating research and application of next-generation foundation models.","authors":["Daoyuan Chen","Yilun Huang","Xuchen Pan","Nana Jiang","Haibin Wang","Yilei Zhang","Ce Ge","Yushuo Chen","Wenhao Zhang","Zhijian Ma","Jun Huang","Wei Lin","Yaliang Li","Bolin Ding","Jingren Zhou"],"url":"https://arxiv.org/abs/2501.14755"}
{"created":"2025-06-05","title":"Web Execution Bundles: Reproducible, Accurate, and Archivable Web Measurements","abstract":"Recently, reproducibility has become a cornerstone in the security and privacy research community, including artifact evaluations and even a new symposium topic. However, Web measurements lack tools that can be reused across many measurement tasks without modification, while being robust to circumvention, and accurate across the wide range of behaviors in the Web. As a result, most measurement studies use custom tools and varied archival formats, each of unknown correctness and significant limitations, systematically affecting the research's accuracy and reproducibility.","authors":["Florian Hantke","Peter Snyder","Hamed Haddadi","Ben Stock"],"url":"https://arxiv.org/abs/2501.15911"}
{"created":"2025-06-05","title":"A Comprehensive Survey of Agents for Computer Use: Foundations, Challenges, and Future Directions","abstract":"Agents for computer use (ACUs) are an emerging class of systems capable of executing complex tasks on digital devices - such as desktops, mobile phones, and web platforms - given instructions in natural language. These agents can automate tasks by controlling software via low-level actions like mouse clicks and touchscreen gestures. However, despite rapid progress, ACUs are not yet mature for everyday use.","authors":["Pascal J. Sager","Benjamin Meyer","Peng Yan","Rebekka von Wartburg-Kottler","Layan Etaiwi","Aref Enayati","Gabriel Nobel","Ahmed Abdulkadir","Benjamin F. Grewe","Thilo Stadelmann"],"url":"https://arxiv.org/abs/2501.16150"}
{"created":"2025-06-05","title":"Through the Prism of Culture: Evaluating LLMs' Understanding of Indian Subcultures and Traditions","abstract":"Large Language Models (LLMs) have shown remarkable advancements but also raise concerns about cultural bias, often reflecting dominant narratives at the expense of under-represented subcultures. In this study, we evaluate the capacity of LLMs to recognize and accurately respond to the Little Traditions within Indian society, encompassing localized cultural practices and subcultures such as caste, kinship, marriage, and religion. Through a series of case studies, we assess whether LLMs can balance the interplay between dominant Great Traditions and localized Little Traditions. We explore various prompting strategies and further investigate whether using prompts in regional languages enhances the models cultural sensitivity and response quality. Our findings reveal that while LLMs demonstrate an ability to articulate cultural nuances, they often struggle to apply this understanding in practical, context-specific scenarios. To the best of our knowledge, this is the first study to analyze LLMs engagement with Indian subcultures, offering critical insights into the challenges of embedding cultural diversity in AI systems.","authors":["Garima Chhikara","Abhishek Kumar","Abhijnan Chakraborty"],"url":"https://arxiv.org/abs/2501.16748"}
{"created":"2025-06-05","title":"Generative Unordered Flow for Set-Structured Data Generation","abstract":"Flow-based generative models have demonstrated promising performance across a broad spectrum of data modalities (e.g., image and text). However, there are few works exploring their extension to unordered data (e.g., spatial point set), which is not trivial because previous models are mostly designed for vector data that are naturally ordered. In this paper, we present unordered flow, a type of flow-based generative model for set-structured data generation. Specifically, we convert unordered data into an appropriate function representation, and learn the probability measure of such representations through function-valued flow matching. For the inverse map from a function representation to unordered data, we propose a method similar to particle filtering, with Langevin dynamics to first warm-up the initial particles and gradient-based search to update them until convergence. We have conducted extensive experiments on multiple real-world datasets, showing that our unordered flow model is very effective in generating set-structured data and significantly outperforms previous baselines.","authors":["Yangming Li","Chaoyu Liu","Carola-Bibiane Sch\\\"onlieb"],"url":"https://arxiv.org/abs/2501.17770"}
{"created":"2025-06-05","title":"Leveraging Sparsity for Sample-Efficient Preference Learning: A Theoretical Perspective","abstract":"This paper considers the sample-efficiency of preference learning, which models and predicts human choices based on comparative judgments. The minimax optimal estimation error rate $\\Theta(d/n)$ in classical estimation theory requires that the number of samples $n$ scales linearly with the dimensionality of the feature space $d$. However, the high dimensionality of the feature space and the high cost of collecting human-annotated data challenge the efficiency of traditional estimation methods. To remedy this, we leverage sparsity in the preference model and establish sharp error rates. We show that under the sparse random utility model, where the parameter of the reward function is $k$-sparse, the minimax optimal rate can be reduced to $\\Theta(k/n \\log(d/k))$. Furthermore, we analyze the $\\ell_{1}$-regularized estimator and show that it achieves near-optimal rate under mild assumptions on the Gram matrix. Experiments on synthetic data and LLM alignment data validate our theoretical findings, showing that sparsity-aware methods significantly reduce sample complexity and improve prediction accuracy.","authors":["Yunzhen Yao","Lie He","Michael Gastpar"],"url":"https://arxiv.org/abs/2501.18282"}
{"created":"2025-06-05","title":"Neural Discovery in Mathematics: Do Machines Dream of Colored Planes?","abstract":"We demonstrate how neural networks can drive mathematical discovery through a case study of the Hadwiger-Nelson problem, a long-standing open problem at the intersection of discrete geometry and extremal combinatorics that is concerned with coloring the plane while avoiding monochromatic unit-distance pairs. Using neural networks as approximators, we reformulate this mixed discrete-continuous geometric coloring problem with hard constraints as an optimization task with a probabilistic, differentiable loss function. This enables gradient-based exploration of admissible configurations that most significantly led to the discovery of two novel six-colorings, providing the first improvement in thirty years to the off-diagonal variant of the original problem. Here, we establish the underlying machine learning approach used to obtain these results and demonstrate its broader applicability through additional numerical insights.","authors":["Konrad Mundinger","Max Zimmer","Aldo Kiem","Christoph Spiegel","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2501.18527"}
{"created":"2025-06-05","title":"A theoretical framework for overfitting in energy-based modeling","abstract":"We investigate the impact of limited data on training pairwise energy-based models for inverse problems aimed at identifying interaction networks. Utilizing the Gaussian model as testbed, we dissect training trajectories across the eigenbasis of the coupling matrix, exploiting the independent evolution of eigenmodes and revealing that the learning timescales are tied to the spectral decomposition of the empirical covariance matrix. We see that optimal points for early stopping arise from the interplay between these timescales and the initial conditions of training. Moreover, we show that finite data corrections can be accurately modeled through asymptotic random matrix theory calculations and provide the counterpart of generalized cross-validation in the energy based model context. Our analytical framework extends to binary-variable maximum-entropy pairwise models with minimal variations. These findings offer strategies to control overfitting in discrete-variable models through empirical shrinkage corrections, improving the management of overfitting in energy-based generative models. Finally, we propose a generalization to arbitrary energy-based models by deriving the neural tangent kernel dynamics of the score function under the score-matching algorithm.","authors":["Giovanni Catania","Aur\\'elien Decelle","Cyril Furtlehner","Beatriz Seoane"],"url":"https://arxiv.org/abs/2501.19158"}
{"created":"2025-06-05","title":"OneForecast: A Universal Framework for Global and Regional Weather Forecasting","abstract":"Accurate weather forecasts are important for disaster prevention, agricultural planning, etc. Traditional numerical weather prediction (NWP) methods offer physically interpretable high-accuracy predictions but are computationally expensive and fail to fully leverage rapidly growing historical data. In recent years, deep learning models have made significant progress in weather forecasting, but challenges remain, such as balancing global and regional high-resolution forecasts, excessive smoothing in extreme event predictions, and insufficient dynamic system modeling. To address these issues, this paper proposes a global-regional nested weather forecasting framework (OneForecast) based on graph neural networks. By combining a dynamic system perspective with multi-grid theory, we construct a multi-scale graph structure and densify the target region to capture local high-frequency features. We introduce an adaptive messaging mechanism, using dynamic gating units to deeply integrate node and edge features for more accurate extreme event forecasting. For high-resolution regional forecasts, we propose a neural nested grid method to mitigate boundary information loss. Experimental results show that OneForecast performs excellently across global to regional scales and short-term to long-term forecasts, especially in extreme event predictions. Codes link https://github.com/YuanGao-YG/OneForecast.","authors":["Yuan Gao","Hao Wu","Ruiqi Shu","Huanshuo Dong","Fan Xu","Rui Ray Chen","Yibo Yan","Qingsong Wen","Xuming Hu","Kun Wang","Jiahao Wu","Qing Li","Hui Xiong","Xiaomeng Huang"],"url":"https://arxiv.org/abs/2502.00338"}
{"created":"2025-06-05","title":"ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Consensus Enforcement, and Column Exploration","abstract":"We present ReFoRCE, a Text-to-SQL agent that tops the Spider 2.0 leaderboard--a challenging benchmark reflecting complex, real-world Text-to-SQL scenarios. While Text-to-SQL systems enable natural language queries over structured databases, deploying them in enterprise environments remains difficult due to large, complex schemas (with over 1,000 columns), diverse SQL dialects (e.g., BigQuery, Snowflake), and sophisticated query requirements (e.g., transformations and analytics). ReFoRCE addresses these challenges through: (a) database information compression via pattern-based table grouping and LLM-guided schema linking to alleviate long-context issues; (b) self-refinement to iteratively correct syntax and semantic errors across dialects; (c) majority-vote consensus to select high-confidence candidates while deferring ambiguous cases arising from sophisticated queries; and (d) iterative column exploration guided by execution feedback to resolve those deferred cases. ReFoRCE achieves new state-of-the-art results, with scores of 35.83 on Spider 2.0-Snow and 36.56 on Spider 2.0-Lite.","authors":["Minghang Deng","Ashwin Ramachandran","Canwen Xu","Lanxiang Hu","Zhewei Yao","Anupam Datta","Hao Zhang"],"url":"https://arxiv.org/abs/2502.00675"}
{"created":"2025-06-05","title":"MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models","abstract":"IQ testing has served as a foundational methodology for evaluating human cognitive capabilities, deliberately decoupling assessment from linguistic background, language proficiency, or domain-specific knowledge to isolate core competencies in abstraction and reasoning. Yet, artificial intelligence research currently lacks systematic benchmarks to quantify these critical cognitive capabilities in multimodal systems. To address this crucial gap, we propose MM-IQ, a comprehensive evaluation framework, which comprises a large-scale training set with 4,776 visual reasoning problems and 2,710 meticulously curated test items spanning 8 distinct reasoning paradigms. Through systematic evaluation of existing open-source and proprietary multimodal models, our benchmark reveals striking limitations: even state-of-the-art architectures achieve only marginally superior performance to random chance (33.17% vs. 25% baseline accuracy). This substantial performance chasm highlights the inadequacy of current multimodal models in approximating fundamental human reasoning capacities, underscoring the need for paradigm-shifting advancements to bridge this cognitive divide. Moreover, inspired by the recent surge of large reasoning models, we also release a multimodal reasoning model as the baseline that is trained via reinforcement learning with verifiable reward functions, reaching competitive performance to the state-of-the-art with a notably smaller model size.","authors":["Huanqia Cai","Yijun Yang","Winston Hu"],"url":"https://arxiv.org/abs/2502.00698"}
{"created":"2025-06-05","title":"Theoretical Analysis of KL-regularized RLHF with Multiple Reference Models","abstract":"Recent methods for aligning large language models (LLMs) with human feedback predominantly rely on a single reference model, which limits diversity, model overfitting, and underutilizes the wide range of available pre-trained models. Incorporating multiple reference models has the potential to address these limitations by broadening perspectives, reducing bias, and leveraging the strengths of diverse open-source LLMs. However, integrating multiple reference models into reinforcement learning with human feedback (RLHF) frameworks poses significant theoretical challenges, where achieving exact solutions has remained an open problem. This paper presents the first \\emph{exact solution} to the multiple reference model problem in reverse KL-regularized RLHF. We introduce a comprehensive theoretical framework that includes rigorous statistical analysis and provides sample complexity guarantees. Additionally, we extend our analysis to forward KL-regularized RLHF, offering new insights into sample complexity requirements in multiple reference scenarios. Our contributions lay the foundation for more advanced and adaptable LLM alignment techniques, enabling the effective use of multiple reference models. This work paves the way for developing alignment frameworks that are both theoretically sound and better suited to the challenges of modern AI ecosystems.","authors":["Gholamali Aminian","Amir R. Asadi","Idan Shenfeld","Youssef Mroueh"],"url":"https://arxiv.org/abs/2502.01203"}
{"created":"2025-06-05","title":"Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models","abstract":"Detailed image captioning is essential for tasks like data generation and aiding visually impaired individuals. High-quality captions require a balance between precision and recall, which remains challenging for current multimodal large language models (MLLMs). In this work, we hypothesize that this limitation stems from weakening and increasingly noisy visual attention as responses lengthen. To address this issue, we propose SPARC (Selective Progressive Attention ReCalibration), a training-free method that enhances the contribution of visual tokens during decoding. SPARC is founded on three key observations: (1) increasing the influence of all visual tokens reduces recall; thus, SPARC selectively amplifies visual tokens; (2) as captions lengthen, visual attention becomes noisier, so SPARC identifies critical visual tokens by leveraging attention differences across time steps; (3) as visual attention gradually weakens, SPARC reinforces it to preserve its influence. Our experiments, incorporating both automated and human evaluations, demonstrate that existing methods improve the precision of MLLMs at the cost of recall. In contrast, our proposed method enhances both precision and recall with minimal computational overhead.","authors":["Mingi Jung","Saehyung Lee","Eunji Kim","Sungroh Yoon"],"url":"https://arxiv.org/abs/2502.01419"}
{"created":"2025-06-05","title":"The Capabilities and Limitations of Weak-to-Strong Generalization: Generalization and Calibration","abstract":"Weak-to-strong generalization, where weakly supervised strong models outperform their weaker teachers, offers a promising approach to aligning superhuman models with human values. To deepen the understanding of this approach, we provide theoretical insights into its capabilities and limitations. First, in the classification setting, we establish upper and lower generalization error bounds for the strong model, identifying the primary limitations as stemming from the weak model's generalization error and the optimization objective itself. Additionally, we derive lower and upper bounds on the calibration error of the strong model. These theoretical bounds reveal two critical insights: (1) the weak model should demonstrate strong generalization performance and maintain well-calibrated predictions, and (2) the strong model's training process must strike a careful balance, as excessive optimization could undermine its generalization capability by over-relying on the weak supervision signals. Finally, in the regression setting, we extend the work of Charikar et al. (2024) to a loss function based on Kullback-Leibler (KL) divergence, offering guarantees that the strong student can outperform its weak teacher by at least the magnitude of their disagreement. We conduct sufficient experiments to validate our theory.","authors":["Wei Yao","Wenkai Yang","Gengze Xu","Ziqiao Wang","Yankai Lin","Yong Liu"],"url":"https://arxiv.org/abs/2502.01458"}
{"created":"2025-06-05","title":"POPACheck: A Model Checker for Probabilistic Pushdown Automata","abstract":"We present POPACheck, the first model checking tool for probabilistic Pushdown Automata (pPDA) supporting temporal logic specifications. POPACheck provides a user-friendly probabilistic modeling language with recursion that automatically translates into Probabilistic Operator Precedence Automata (pOPA). pOPA are a class of pPDA that can express all the behaviors of probabilistic programs: sampling, conditioning, recursive procedures, and nested inference queries. On pOPA, POPACheck can solve reachability queries as well as qualitative and quantitative model checking queries for specifications in Linear Temporal Logic (LTL) and a fragment of Precedence Oriented Temporal Logic (POTL), a logic for context-free properties such as pre/post-conditioning.","authors":["Francesco Pontiggia","Ezio Bartocci","Michele Chiari"],"url":"https://arxiv.org/abs/2502.03956"}
{"created":"2025-06-05","title":"PiKE: Adaptive Data Mixing for Large-Scale Multi-Task Learning Under Low Gradient Conflicts","abstract":"Modern foundation models are trained on diverse datasets to enhance generalization across tasks and domains A central challenge in this process is determining how to effectively mix and sample data from multiple sources This naturally leads to a multitask learning (MTL) perspective While prior work in MTL has emphasized mitigating gradient conflicts we observe that largescale pretraining scenariossuch as multilingual or multidomain trainingoften exhibit little to no gradient conflict Motivated by this observation we propose PiKE (Positive gradient interaction-based K-task weights Estimator) an adaptive data mixing algorithm that dynamically adjusts sampling weights during training PiKE exploits nonconflicting gradient interactions to minimize a neartight upper bound on the average loss decrease at each step while incurring negligible computational overhead We provide theoretical convergence guarantees and show that PiKE outperforms static and nonadaptive mixing baselines Furthermore we extend PiKE to promote balanced learning across tasks Extensive experiments on largescale language model pretraining confirm that PiKE achieves faster convergence and improved downstream performance compared to existing approaches","authors":["Zeman Li","Yuan Deng","Peilin Zhong","Meisam Razaviyayn","Vahab Mirrokni"],"url":"https://arxiv.org/abs/2502.06244"}
{"created":"2025-06-05","title":"Continual Release Moment Estimation with Differential Privacy","abstract":"We propose Joint Moment Estimation (JME), a method for continually and privately estimating both the first and second moments of data with reduced noise compared to naive approaches. JME uses the matrix mechanism and a joint sensitivity analysis to allow the second moment estimation with no additional privacy cost, thereby improving accuracy while maintaining privacy. We demonstrate JME's effectiveness in two applications: estimating the running mean and covariance matrix for Gaussian density estimation, and model training with DP-Adam on CIFAR-10.","authors":["Nikita P. Kalinin","Jalaj Upadhyay","Christoph H. Lampert"],"url":"https://arxiv.org/abs/2502.06597"}
{"created":"2025-06-05","title":"A Flag Decomposition for Hierarchical Datasets","abstract":"Flag manifolds encode nested sequences of subspaces and serve as powerful structures for various computer vision and machine learning applications. Despite their utility in tasks such as dimensionality reduction, motion averaging, and subspace clustering, current applications are often restricted to extracting flags using common matrix decomposition methods like the singular value decomposition. Here, we address the need for a general algorithm to factorize and work with hierarchical datasets. In particular, we propose a novel, flag-based method that decomposes arbitrary hierarchical real-valued data into a hierarchy-preserving flag representation in Stiefel coordinates. Our work harnesses the potential of flag manifolds in applications including denoising, clustering, and few-shot learning.","authors":["Nathan Mankovich","Ignacio Santamaria","Gustau Camps-Valls","Tolga Birdal"],"url":"https://arxiv.org/abs/2502.07782"}
{"created":"2025-06-05","title":"Sink equilibria and the attractors of learning in games","abstract":"Characterizing the limit behavior -- that is, the attractors -- of learning dynamics is one of the most fundamental open questions in game theory. In recent work in this front, it was conjectured that the attractors of the replicator dynamic are in one-to-one correspondence with the sink equilibria of the game -- the sink strongly connected components of a game's preference graph -- , and it was established that they do stand in at least one-to-many correspondence with them. We make threefold progress on the problem of characterizing attractors. First, we show through a topological construction that the one-to-one conjecture is false. The counterexamples derive from objects called local sources -- fixed points which lie within the sink equilibrium yet are locally repelling. Second, we make progress on the attractor characterization problem for two-player games by establishing that the one-to-one conjecture is true when a local property called pseudoconvexity holds. Pseudoconvexity prevents the existence of local sources, and generalizes the existing cases -- such as zero-sum games and potential games -- where the conjecture was known to be true.","authors":["Oliver Biggar","Christos Papadimitriou"],"url":"https://arxiv.org/abs/2502.07975"}
{"created":"2025-06-05","title":"Unveiling Client Privacy Leakage from Public Dataset Usage in Federated Distillation","abstract":"Federated Distillation (FD) has emerged as a popular federated training framework, enabling clients to collaboratively train models without sharing private data. Public Dataset-Assisted Federated Distillation (PDA-FD), which leverages public datasets for knowledge sharing, has become widely adopted. Although PDA-FD enhances privacy compared to traditional Federated Learning, we demonstrate that the use of public datasets still poses significant privacy risks to clients' private training data. This paper presents the first comprehensive privacy analysis of PDA-FD in presence of an honest-but-curious server. We show that the server can exploit clients' inference results on public datasets to extract two critical types of private information: label distributions and membership information of the private training dataset. To quantify these vulnerabilities, we introduce two novel attacks specifically designed for the PDA-FD setting: a label distribution inference attack and innovative membership inference methods based on Likelihood Ratio Attack (LiRA). Through extensive evaluation of three representative PDA-FD frameworks (FedMD, DS-FL, and Cronus), our attacks achieve state-of-the-art performance, with label distribution attacks reaching minimal KL-divergence and membership inference attacks maintaining high True Positive Rates under low False Positive Rate constraints. Our findings reveal significant privacy risks in current PDA-FD frameworks and emphasize the need for more robust privacy protection mechanisms in collaborative learning systems.","authors":["Haonan Shi","Tu Ouyang","An Wang"],"url":"https://arxiv.org/abs/2502.08001"}
{"created":"2025-06-05","title":"DiffoRA: Enabling Parameter-Efficient Fine-Tuning via Differential Module Selection","abstract":"The Parameter-Efficient Fine-Tuning (PEFT) methods have been extensively researched for large language models in downstream tasks. Among all the existing approaches, the Low-Rank Adaptation (LoRA) has gained popularity for its streamlined design by incorporating low-rank matrices into existing pre-trained models. Though effective, LoRA, as well as its adaptive optimizations, either allocate the same matrix to all the modules or adjust the interior rank of the components based on importance scoring indicators. In this paper, we argue that not all the modules in LLMs are suitable and necessary to be fine-tuned. Enlightened by this insight, we propose a new PEFT scheme called DiffoRA, which enables adaptive adoption of the low-rank decomposition matrices. At the core of DiffoRA lies a Differential Adaptation Matrix (DAM) to determine which module is the most suitable and essential for fine-tuning. We theoretically explain how the designed matrix impacts the convergence rate and generalization capability of a pre-trained model. We then construct the DAM via continuous relaxation and discretization with weight-sharing optimizations. We fully implement DiffoRA and design comprehensive experiments to evaluate its performance. The experimental results demonstrate that DiffoRA delivers state-of-the-art results across multiple benchmarks.","authors":["Tangyu Jiang","Haodi Wang","Chun Yuan"],"url":"https://arxiv.org/abs/2502.08905"}
{"created":"2025-06-05","title":"Galileo: Learning Global & Local Features of Many Remote Sensing Modalities","abstract":"We introduce a highly multimodal transformer to represent many remote sensing modalities - multispectral optical, synthetic aperture radar, elevation, weather, pseudo-labels, and more - across space and time. These inputs are useful for diverse remote sensing tasks, such as crop mapping and flood detection. However, learning shared representations of remote sensing data is challenging, given the diversity of relevant data modalities, and because objects of interest vary massively in scale, from small boats (1-2 pixels and fast) to glaciers (thousands of pixels and slow). We present a novel self-supervised learning algorithm that extracts multi-scale features across a flexible set of input modalities through masked modeling. Our dual global and local contrastive losses differ in their targets (deep representations vs. shallow input projections) and masking strategies (structured vs. not). Our Galileo is a single generalist model that outperforms SoTA specialist models for satellite images and pixel time series across eleven benchmarks and multiple tasks.","authors":["Gabriel Tseng","Anthony Fuller","Marlena Reil","Henry Herzog","Patrick Beukema","Favyen Bastani","James R. Green","Evan Shelhamer","Hannah Kerner","David Rolnick"],"url":"https://arxiv.org/abs/2502.09356"}
{"created":"2025-06-05","title":"Diffusing DeBias: Synthetic Bias Amplification for Model Debiasing","abstract":"Deep learning model effectiveness in classification tasks is often challenged by the quality and quantity of training data whenever they are affected by strong spurious correlations between specific attributes and target labels. This results in a form of bias affecting training data, which typically leads to unrecoverable weak generalization in prediction. This paper aims at facing this problem by leveraging bias amplification with generated synthetic data: we introduce Diffusing DeBias (DDB), a novel approach acting as a plug-in for common methods of unsupervised model debiasing exploiting the inherent bias-learning tendency of diffusion models in data generation. Specifically, our approach adopts conditional diffusion models to generate synthetic bias-aligned images, which replace the original training set for learning an effective bias amplifier model that we subsequently incorporate into an end-to-end and a two-step unsupervised debiasing approach. By tackling the fundamental issue of bias-conflicting training samples memorization in learning auxiliary models, typical of this type of techniques, our proposed method beats current state-of-the-art in multiple benchmark datasets, demonstrating its potential as a versatile and effective tool for tackling bias in deep learning models.","authors":["Massimiliano Ciranni","Vito Paolo Pastore","Roberto Di Via","Enzo Tartaglione","Francesca Odone","Vittorio Murino"],"url":"https://arxiv.org/abs/2502.09564"}
{"created":"2025-06-05","title":"Censor Dependent Variational Inference","abstract":"This paper provides a comprehensive analysis of variational inference in latent variable models for survival analysis, emphasizing the distinctive challenges associated with applying variational methods to survival data. We identify a critical weakness in the existing methodology, demonstrating how a poorly designed variational distribution may hinder the objective of survival analysis tasks - modeling time-to-event distributions. We prove that the optimal variational distribution, which perfectly bounds the log-likelihood, may depend on the censoring mechanism. To address this issue, we propose censor-dependent variational inference (CDVI), tailored for latent variable models in survival analysis. More practically, we introduce CD-CVAE, a V-structure Variational Autoencoder (VAE) designed for the scalable implementation of CDVI. Further discussion extends some existing theories and training techniques to survival analysis. Extensive experiments validate our analysis and demonstrate significant improvements in the estimation of individual survival distributions.","authors":["Chuanhui Liu","Xiao Wang"],"url":"https://arxiv.org/abs/2502.09591"}
{"created":"2025-06-05","title":"Best of Both Worlds: Regret Minimization versus Minimax Play","abstract":"In this paper, we investigate the existence of online learning algorithms with bandit feedback that simultaneously guarantee $O(1)$ regret compared to a given comparator strategy, and $\\tilde{O}(\\sqrt{T})$ regret compared to any fixed strategy, where $T$ is the number of rounds. We provide the first affirmative answer to this question whenever the comparator strategy supports every action. In the context of zero-sum games with min-max value zero, both in normal- and extensive form, we show that our results allow us to guarantee to risk at most $O(1)$ loss while being able to gain $\\Omega(T)$ from exploitable opponents, thereby combining the benefits of both no-regret algorithms and minimax play.","authors":["Adrian M\\\"uller","Jon Schneider","Stratis Skoulakis","Luca Viano","Volkan Cevher"],"url":"https://arxiv.org/abs/2502.11673"}
{"created":"2025-06-05","title":"HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims","abstract":"Misinformation can be countered with fact-checking, but the process is costly and slow. Identifying checkworthy claims is the first step, where automation can help scale fact-checkers' efforts. However, detection methods struggle with content that is (1) multimodal, (2) from diverse domains, and (3) synthetic. We introduce HintsOfTruth, a public dataset for multimodal checkworthiness detection with 27K real-world and synthetic image/claim pairs. The mix of real and synthetic data makes this dataset unique and ideal for benchmarking detection methods. We compare fine-tuned and prompted Large Language Models (LLMs). We find that well-configured lightweight text-based encoders perform comparably to multimodal models but the former only focus on identifying non-claim-like content. Multimodal LLMs can be more accurate but come at a significant computational cost, making them impractical for large-scale applications. When faced with synthetic data, multimodal models perform more robustly.","authors":["Michiel van der Meer","Pavel Korshunov","S\\'ebastien Marcel","Lonneke van der Plas"],"url":"https://arxiv.org/abs/2502.11753"}
{"created":"2025-06-05","title":"Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions","abstract":"We present an end-to-end framework for generating synthetic users for evaluating interactive agents designed to encourage positive behavior changes, such as in health and lifestyle coaching. The synthetic users are grounded in health and lifestyle conditions, specifically sleep and diabetes management in this study, to ensure realistic interactions with the health coaching agent. Synthetic users are created in two stages: first, structured data are generated grounded in real-world health and lifestyle factors in addition to basic demographics and behavioral attributes; second, full profiles of the synthetic users are developed conditioned on the structured data. Interactions between synthetic users and the coaching agent are simulated using generative agent-based models such as Concordia, or directly by prompting a language model. Using two independently-developed agents for sleep and diabetes coaching as case studies, the validity of this framework is demonstrated by analyzing the coaching agent's understanding of the synthetic users' needs and challenges. Finally, through multiple blinded evaluations of user-coach interactions by human experts, we demonstrate that our synthetic users with health and behavioral attributes more accurately portray real human users with the same attributes, compared to generic synthetic users not grounded in such attributes. The proposed framework lays the foundation for efficient development of conversational agents through extensive, realistic, and grounded simulated interactions.","authors":["Taedong Yun","Eric Yang","Mustafa Safdari","Jong Ha Lee","Vaishnavi Vinod Kumar","S. Sara Mahdavi","Jonathan Amar","Derek Peyton","Reut Aharony","Andreas Michaelides","Logan Schneider","Isaac Galatzer-Levy","Yugang Jia","John Canny","Arthur Gretton","Maja Matari\\'c"],"url":"https://arxiv.org/abs/2502.13135"}
{"created":"2025-06-05","title":"Refining Sentence Embedding Model through Ranking Sentences Generation with Large Language Models","abstract":"Sentence embedding is essential for many NLP tasks, with contrastive learning methods achieving strong performance using annotated datasets like NLI. Yet, the reliance on manual labels limits scalability. Recent studies leverage large language models (LLMs) to generate sentence pairs, reducing annotation dependency. However, they overlook ranking information crucial for fine-grained semantic distinctions. To tackle this challenge, we propose a method for controlling the generation direction of LLMs in the latent space. Unlike unconstrained generation, the controlled approach ensures meaningful semantic divergence. Then, we refine exist sentence embedding model by integrating ranking information and semantic information. Experiments on multiple benchmarks demonstrate that our method achieves new SOTA performance with a modest cost in ranking sentence synthesis.","authors":["Liyang He","Chenglong Liu","Rui Li","Zhenya Huang","Shulan Ruan","Jun Zhou","Enhong Chen"],"url":"https://arxiv.org/abs/2502.13656"}
{"created":"2025-06-05","title":"Why Safeguarded Ships Run Aground? Aligned Large Language Models' Safety Mechanisms Tend to Be Anchored in The Template Region","abstract":"The safety alignment of large language models (LLMs) remains vulnerable, as their initial behavior can be easily jailbroken by even relatively simple attacks. Since infilling a fixed template between the input instruction and initial model output is a common practice for existing LLMs, we hypothesize that this template is a key factor behind their vulnerabilities: LLMs' safety-related decision-making overly relies on the aggregated information from the template region, which largely influences these models' safety behavior. We refer to this issue as template-anchored safety alignment. In this paper, we conduct extensive experiments and verify that template-anchored safety alignment is widespread across various aligned LLMs. Our mechanistic analyses demonstrate how it leads to models' susceptibility when encountering inference-time jailbreak attacks. Furthermore, we show that detaching safety mechanisms from the template region is promising in mitigating vulnerabilities to jailbreak attacks. We encourage future research to develop more robust safety alignment techniques that reduce reliance on the template region.","authors":["Chak Tou Leong","Qingyu Yin","Jian Wang","Wenjie Li"],"url":"https://arxiv.org/abs/2502.13946"}
{"created":"2025-06-05","title":"FlexTok: Resampling Images into 1D Token Sequences of Flexible Length","abstract":"Image tokenization has enabled major advances in autoregressive image generation by providing compressed, discrete representations that are more efficient to process than raw pixels. While traditional approaches use 2D grid tokenization, recent methods like TiTok have shown that 1D tokenization can achieve high generation quality by eliminating grid redundancies. However, these methods typically use a fixed number of tokens and thus cannot adapt to an image's inherent complexity. We introduce FlexTok, a tokenizer that projects 2D images into variable-length, ordered 1D token sequences. For example, a 256x256 image can be resampled into anywhere from 1 to 256 discrete tokens, hierarchically and semantically compressing its information. By training a rectified flow model as the decoder and using nested dropout, FlexTok produces plausible reconstructions regardless of the chosen token sequence length. We evaluate our approach in an autoregressive generation setting using a simple GPT-style Transformer. On ImageNet, this approach achieves an FID<2 across 8 to 128 tokens, outperforming TiTok and matching state-of-the-art methods with far fewer tokens. We further extend the model to support to text-conditioned image generation and examine how FlexTok relates to traditional 2D tokenization. A key finding is that FlexTok enables next-token prediction to describe images in a coarse-to-fine \"visual vocabulary\", and that the number of tokens to generate depends on the complexity of the generation task.","authors":["Roman Bachmann","Jesse Allardice","David Mizrahi","Enrico Fini","O\\u{g}uzhan Fatih Kar","Elmira Amirloo","Alaaeldin El-Nouby","Amir Zamir","Afshin Dehghan"],"url":"https://arxiv.org/abs/2502.13967"}
{"created":"2025-06-05","title":"Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems","abstract":"As text generation systems' outputs are increasingly anthropomorphic -- perceived as human-like -- scholars have also increasingly raised concerns about how such outputs can lead to harmful outcomes, such as users over-relying or developing emotional dependence on these systems. How to intervene on such system outputs to mitigate anthropomorphic behaviors and their attendant harmful outcomes, however, remains understudied. With this work, we aim to provide empirical and theoretical grounding for developing such interventions. To do so, we compile an inventory of interventions grounded both in prior literature and a crowdsourcing study where participants edited system outputs to make them less human-like. Drawing on this inventory, we also develop a conceptual framework to help characterize the landscape of possible interventions, articulate distinctions between different types of interventions, and provide a theoretical basis for evaluating the effectiveness of different interventions.","authors":["Myra Cheng","Su Lin Blodgett","Alicia DeVrio","Lisa Egede","Alexandra Olteanu"],"url":"https://arxiv.org/abs/2502.14019"}
{"created":"2025-06-05","title":"ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors","abstract":"Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to retrieve audio clips or multilingual texts from databases. However, existing ML-ATR schemes suffer from inconsistencies for instance similarity matching across languages. We theoretically analyze the inconsistency in terms of both multilingual modal alignment direction error and weight error, and propose the theoretical weight error upper bound for quantifying the inconsistency. Based on the analysis of the weight error upper bound, we find that the inconsistency problem stems from the data distribution error caused by random sampling of languages. We propose a consistent ML-ATR scheme using 1-to-k contrastive learning and audio-English co-anchor contrastive learning, aiming to mitigate the negative impact of data distribution error on recall and consistency in ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets show that our scheme achieves state-of-the-art performance on recall and consistency metrics for eight mainstream languages, including English. Our code will be available at https://github.com/ATRI-ACL/ATRI-ACL.","authors":["Yuguo Yin","Yuxin Xie","Wenyuan Yang","Dongchao Yang","Jinghan Ru","Xianwei Zhuang","Liming Liang","Yuexian Zou"],"url":"https://arxiv.org/abs/2502.14627"}
{"created":"2025-06-05","title":"Large Language Models Struggle to Describe the Haystack without Human Help: Human-in-the-loop Evaluation of Topic Models","abstract":"A common use of NLP is to facilitate the understanding of large document collections, with a shift from using traditional topic models to Large Language Models. Yet the effectiveness of using LLM for large corpus understanding in real-world applications remains under-explored. This study measures the knowledge users acquire with unsupervised, supervised LLM-based exploratory approaches or traditional topic models on two datasets. While LLM-based methods generate more human-readable topics and show higher average win probabilities than traditional models for data exploration, they produce overly generic topics for domain-specific datasets that do not easily allow users to learn much about the documents. Adding human supervision to the LLM generation process improves data exploration by mitigating hallucination and over-genericity but requires greater human effort. In contrast, traditional. models like Latent Dirichlet Allocation (LDA) remain effective for exploration but are less user-friendly. We show that LLMs struggle to describe the haystack of large corpora without human help, particularly domain-specific data, and face scaling and hallucination limitations due to context length constraints.","authors":["Zongxia Li","Lorena Calvo-Bartolom\\'e","Alexander Hoyle","Paiheng Xu","Alden Dima","Juan Francisco Fung","Jordan Boyd-Graber"],"url":"https://arxiv.org/abs/2502.14748"}
{"created":"2025-06-05","title":"M3-AGIQA: Multimodal, Multi-Round, Multi-Aspect AI-Generated Image Quality Assessment","abstract":"The rapid advancement of AI-generated image (AIGI) models presents new challenges for evaluating image quality, particularly across three aspects: perceptual quality, prompt correspondence, and authenticity. To address these challenges, we introduce M3-AGIQA, a comprehensive framework that leverages Multimodal Large Language Models (MLLMs) to enable more human-aligned, holistic evaluation of AI-generated images across both visual and textual domains. Besides, our framework features a structured multi-round evaluation process, generating and analyzing intermediate image descriptions to provide deeper insight into these three aspects. By aligning model outputs more closely with human judgment, M3-AGIQA delivers robust and interpretable quality scores. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art performance on tested datasets and aspects, and exhibits strong generalizability in most cross-dataset settings. Code is available at https://github.com/strawhatboy/M3-AGIQA.","authors":["Chuan Cui","Kejiang Chen","Zhihua Wei","Wen Shen","Weiming Zhang","Nenghai Yu"],"url":"https://arxiv.org/abs/2502.15167"}
{"created":"2025-06-05","title":"FragFM: Hierarchical Framework for Efficient Molecule Generation via Fragment-Level Discrete Flow Matching","abstract":"We introduce FragFM, a novel hierarchical framework via fragment-level discrete flow matching for efficient molecular graph generation. FragFM generates molecules at the fragment level, leveraging a coarse-to-fine autoencoder to reconstruct details at the atom level. Together with a stochastic fragment bag strategy to effectively handle an extensive fragment space, our framework enables more efficient and scalable molecular generation. We demonstrate that our fragment-based approach achieves better property control than the atom-based method and additional flexibility through conditioning the fragment bag. We also propose a Natural Product Generation benchmark (NPGen) to evaluate modern molecular graph generative models' ability to generate natural product-like molecules. Since natural products are biologically prevalidated and differ from typical drug-like molecules, our benchmark provides a more challenging yet meaningful evaluation relevant to drug discovery. We conduct a FragFM comparative study against various models on diverse molecular generation benchmarks, including NPGen, demonstrating superior performance. The results highlight the potential of fragment-based generative modeling for large-scale, property-aware molecular design, paving the way for more efficient exploration of chemical space.","authors":["Joongwon Lee","Seonghwan Kim","Seokhyun Moon","Hyunwoo Kim","Woo Youn Kim"],"url":"https://arxiv.org/abs/2502.15805"}
{"created":"2025-06-05","title":"D2S-FLOW: Automated Parameter Extraction from Datasheets for SPICE Model Generation Using Large Language Models","abstract":"In electronic design, engineers often manually search through extensive documents to retrieve component parameters required for constructing SPICE models, a process that is both labor-intensive and time-consuming. To address this challenge, we present an automated framework called D2S-FLOW that leverages large language models (LLMs) to extract electrical parameters from datasheets and generate SPICE models with high precision and efficiency, significantly reducing the need for manual intervention. Unlike traditional RAG systems, D2S-FLOW employs a workflow to enhance precision in handling unstructured documents and inconsistent naming conventions through three innovative mechanisms: Attention-Guided Document Focusing (AGDF), Hierarchical Document-Enhanced Retrieval (HDER), and Heterogeneous Named Entity Normalization (HNEN). AGDF narrows retrieval to user-selected documents, HDER utilizes document structure for precise parameter localization, and HNEN standardizes terminology via semantic inference. Experimental results demonstrate that the framework achieves an Exact Match (EM) of 0.86, an F1 score of 0.92, and an Exact Correctness (EC) of 0.96, outperforming the strongest baseline by 19.4%, 5.7%, and 13.1%, respectively. Additionally, it reduces API token consumption by 38% and minimizes the irrelevant information ratio to 4%, showcasing substantial improvements in resource efficiency. This research provides an effective automated solution for circuit design.","authors":["Hong Cai Chen","Yi Pin Xu","Yang Zhang"],"url":"https://arxiv.org/abs/2502.16540"}
{"created":"2025-06-05","title":"Coreset Selection via LLM-based Concept Bottlenecks","abstract":"Coreset Selection (CS) aims to identify a subset of the training dataset that achieves model performance comparable to using the entire dataset. Many state-of-the-art CS methods select coresets using scores whose computation requires training the downstream model on the entire dataset first and recording changes in the model's behavior on samples as it trains (training dynamics). These scores are inefficient to compute and hard to interpret, as they do not indicate whether a sample is difficult to learn in general or only for a specific downstream model. Our work addresses these challenges by proposing a score that computes a sample's difficulty using human-understandable textual attributes (concepts) independent of any downstream model. Specifically, we measure the alignment between a sample's visual features and concept bottlenecks, derived via large language models, by training a linear concept bottleneck layer and computing the sample's difficulty score using it.We then use stratified sampling based on this score to generate a coreset of the dataset.Crucially, our score is efficiently computable without training the downstream model on the full dataset even once, leads to high-performing coresets for various downstream models, and is computable even for an unlabeled dataset. Through experiments on CIFAR-10/100, and ImageNet-1K, we show that our coresets outperform random subsets, even at high pruning rates, and achieve model performance comparable to or better than coresets found by training dynamics-based methods.","authors":["Akshay Mehra","Trisha Mittal","Subhadra Gopalakrishnan","Joshua Kimball"],"url":"https://arxiv.org/abs/2502.16733"}
{"created":"2025-06-05","title":"Aligning Compound AI Systems via System-level DPO","abstract":"Compound AI systems, comprising multiple interacting components such as LLMs, foundation models, and external tools, have demonstrated remarkable improvements compared to single models in various tasks. To ensure their effective deployment in real-world applications, aligning these systems with human preferences is crucial. However, aligning the compound system via policy optimization, unlike the alignment of a single model, is challenging for two main reasons: (i) non-differentiable interactions between components make end-to-end gradient-based optimization method inapplicable, and (ii) system-level preferences cannot be directly transformed into component-level preferences. To address these challenges, we first formulate compound AI systems as Directed Acyclic Graphs (DAGs), explicitly modeling both component interactions and the associated data flows. Building on this formulation, we introduce $\\textbf{SysDPO}$, a framework that extends Direct Preference Optimization (DPO) to enable joint system-level alignment. We propose two variants, SysDPO-Direct and SysDPO-Sampling, tailored for scenarios depending on whether we construct a system-specific preference dataset. We empirically demonstrate the effectiveness of our approach across two applications: the joint alignment of a language model and a diffusion model, and the joint alignment of an LLM collaboration system.","authors":["Xiangwen Wang","Yibo Jacky Zhang","Zhoujie Ding","Katherine Tsai","Haolun Wu","Sanmi Koyejo"],"url":"https://arxiv.org/abs/2502.17721"}
{"created":"2025-06-05","title":"The Built-In Robustness of Decentralized Federated Averaging to Bad Data","abstract":"Decentralized federated learning (DFL) enables devices to collaboratively train models over complex network topologies without relying on a central controller. In this setting, local data remains private, but its quality and quantity can vary significantly across nodes. The extent to which a fully decentralized system is vulnerable to poor-quality or corrupted data remains unclear, but several factors could contribute to potential risks. Without a central authority, there can be no unified mechanism to detect or correct errors, and each node operates with a localized view of the data distribution, making it difficult for the node to assess whether its perspective aligns with the true distribution. Moreover, models trained on low-quality data can propagate through the network, amplifying errors. To explore the impact of low-quality data on DFL, we simulate two scenarios with degraded data quality -- one where the corrupted data is evenly distributed in a subset of nodes and one where it is concentrated on a single node -- using a decentralized implementation of FedAvg. Our results reveal that averaging-based decentralized learning is remarkably robust to localized bad data, even when the corrupted data resides in the most influential nodes of the network. Counterintuitively, this robustness is further enhanced when the corrupted data is concentrated on a single node, regardless of its centrality in the communication network topology. This phenomenon is explained by the averaging process, which ensures that no single node -- however central -- can disproportionately influence the overall learning process.","authors":["Samuele Sabella","Chiara Boldrini","Lorenzo Valerio","Andrea Passarella","Marco Conti"],"url":"https://arxiv.org/abs/2502.18097"}
{"created":"2025-06-05","title":"VCT: Training Consistency Models with Variational Noise Coupling","abstract":"Consistency Training (CT) has recently emerged as a strong alternative to diffusion models for image generation. However, non-distillation CT often suffers from high variance and instability, motivating ongoing research into its training dynamics. We propose Variational Consistency Training (VCT), a flexible and effective framework compatible with various forward kernels, including those in flow matching. Its key innovation is a learned noise-data coupling scheme inspired by Variational Autoencoders, where a data-dependent encoder models noise emission. This enables VCT to adaptively learn noise-todata pairings, reducing training variance relative to the fixed, unsorted pairings in classical CT. Experiments on multiple image datasets demonstrate significant improvements: our method surpasses baselines, achieves state-of-the-art FID among non-distillation CT approaches on CIFAR-10, and matches SoTA performance on ImageNet 64 x 64 with only two sampling steps. Code is available at https://github.com/sony/vct.","authors":["Gianluigi Silvestri","Luca Ambrogioni","Chieh-Hsin Lai","Yuhta Takida","Yuki Mitsufuji"],"url":"https://arxiv.org/abs/2502.18197"}
{"created":"2025-06-05","title":"Sliding Window Attention Training for Efficient Large Language Models","abstract":"Recent advances in transformer-based Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks. However, their quadratic computational complexity concerning sequence length remains a significant bottleneck for processing long documents. As a result, many efforts like sparse attention and state space models have been proposed to improve the efficiency of LLMs over long sequences. Though effective, these approaches compromise the performance or introduce structural complexity. This calls for a simple yet efficient model that preserves the fundamental Transformer architecture. To this end, we introduce SWAT, which enables efficient long-context handling via Sliding Window Attention Training. This paper first attributes the inefficiency of Transformers to the attention sink phenomenon resulting from the high variance of softmax operation. Then, we replace softmax with the sigmoid function and utilize a balanced ALiBi and Rotary Position Embedding for efficient information compression and retention. Experiments demonstrate that SWAT achieves SOTA performance compared with state-of-the-art linear recurrent architectures on eight benchmarks. Code is available at https://github.com/Fzkuji/swat-attention.","authors":["Zichuan Fu","Wentao Song","Yejing Wang","Xian Wu","Yefeng Zheng","Yingying Zhang","Derong Xu","Xuetao Wei","Tong Xu","Xiangyu Zhao"],"url":"https://arxiv.org/abs/2502.18845"}
{"created":"2025-06-05","title":"Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency","abstract":"Anomaly detection in complex dynamical systems is essential for ensuring reliability, safety, and efficiency in industrial and cyber-physical infrastructures. Predictive maintenance helps prevent costly failures, while cybersecurity monitoring has become critical as digitized systems face growing threats. Many of these systems exhibit oscillatory behaviors and bounded motion, requiring anomaly detection methods that capture structured temporal dependencies while adhering to physical consistency principles. In this work, we propose a system-theoretic approach to anomaly detection, grounded in classical embedding theory and physics-inspired consistency principles. We build upon the Fractal Whitney Embedding Prevalence Theorem that extends traditional embedding techniques to complex system dynamics. Additionally, we introduce state-derivative pairs as an embedding strategy to capture system evolution. To enforce temporal coherence, we develop a Temporal Differential Consistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the approximated derivatives of latent variables with their dynamic representations. We evaluate our method on the C-MAPSS dataset, a benchmark for turbofan aeroengine degradation. TDC-AE outperforms LSTMs and Transformers while achieving a nearly 200x reduction in MAC operations, making it particularly suited for lightweight edge computing. Our findings support the hypothesis that anomalies disrupt stable system dynamics, providing a robust signal for anomaly detection.","authors":["Michael Somma","Thomas Gallien","Branka Stojanovic"],"url":"https://arxiv.org/abs/2502.19307"}
{"created":"2025-06-05","title":"Where Are We? Evaluating LLM Performance on African Languages","abstract":"Africa's rich linguistic heritage remains underrepresented in NLP, largely due to historical policies that favor foreign languages and create significant data inequities. In this paper, we integrate theoretical insights on Africa's language landscape with an empirical evaluation using Sahara - a comprehensive benchmark curated from large-scale, publicly accessible datasets capturing the continent's linguistic diversity. By systematically assessing the performance of leading large language models (LLMs) on Sahara, we demonstrate how policy-induced data variations directly impact model effectiveness across African languages. Our findings reveal that while a few languages perform reasonably well, many Indigenous languages remain marginalized due to sparse data. Leveraging these insights, we offer actionable recommendations for policy reforms and inclusive data practices. Overall, our work underscores the urgent need for a dual approach - combining theoretical understanding with empirical evaluation - to foster linguistic diversity in AI for African communities.","authors":["Ife Adebara","Hawau Olamide Toyin","Nahom Tesfu Ghebremichael","AbdelRahim Elmadany","Muhammad Abdul-Mageed"],"url":"https://arxiv.org/abs/2502.19582"}
{"created":"2025-06-05","title":"Semicoarse Correlated Equilibria and LP-Based Guarantees for Gradient Dynamics in Normal-Form Games","abstract":"Projected gradient ascent is known to satisfy no-external regret as a learning algorithm. However, recent empirical work shows that projected gradient ascent often finds the Nash equilibrium in settings beyond two-player zero-sum interactions or potential games, including those where the set of coarse correlated equilibria is very large. We show that gradient ascent in fact satisfies a stronger class of linear $\\Phi$-regret in normal-form games; resulting in a refined solution concept which we dub semicoarse correlated equilibria. Our theoretical analysis of the discretised Bertrand competition mirrors those recently established for mean-based learning in first-price auctions. With at least two firms of lowest marginal cost, Nash equilibria emerge as the only semicoarse equilibria under concavity conditions on firm profits. In first-price auctions, the granularity of the bid space affects semicoarse equilibria, but finer granularity for lower bids also induces convergence to Nash equilibria. Unlike previous work that aims to prove convergence to a Nash equilibrium that often relies on epoch based analysis and probability theoretic machinery, our LP-based duality approach enables a simple and tractable analysis of equilibrium selection under gradient-based learning.","authors":["Mete \\c{S}eref Ahunbay","Martin Bichler"],"url":"https://arxiv.org/abs/2502.20466"}
{"created":"2025-06-05","title":"Examining Algorithmic Curation on Social Media: An Empirical Audit of Reddit's r/popular Feed","abstract":"Platforms are increasingly relying on algorithms to curate the content within users' social media feeds. However, the growing prominence of proprietary, algorithmically curated feeds has concealed what factors influence the presentation of content on social media feeds and how that presentation affects user behavior. This lack of transparency can be detrimental to users, from reducing users' agency over their content consumption to the propagation of misinformation and toxic content. To uncover details about how these feeds operate and influence user behavior, we conduct an empirical audit of Reddit's algorithmically curated trending feed called r/popular. Using 10K r/popular posts collected by taking snapshots of the feed over 11 months, we find that recent comments help a post remain on r/popular longer and climb the feed. We also find that posts below rank 80 correspond to a sharp decline in activity compared to posts above. When examining the effects of having a higher proportion of undesired behavior -- i.e., moderator-removed and toxic comments -- we find no significant evidence that it helps posts stay on r/popular for longer. Although posts closer to the top receive more undesired comments, we find this increase to coincide with a broader increase in overall engagement -- rather than indicating a disproportionate effect on undesired activity. The relationships between algorithmic rank and engagement highlight the extent to which algorithms employed by social media platforms essentially determine which content is prioritized and which is not. We conclude by discussing how content creators, consumers, and moderators on social media platforms can benefit from empirical audits aimed at improving transparency in algorithmically curated feeds.","authors":["Jackie Chan","Fred Choi","Koustuv Saha","Eshwar Chandrasekharan"],"url":"https://arxiv.org/abs/2502.20491"}
{"created":"2025-06-05","title":"DOVE: A Large-Scale Multi-Dimensional Predictions Dataset Towards Meaningful LLM Evaluation","abstract":"Recent work found that LLMs are sensitive to a wide range of arbitrary prompt dimensions, including the type of delimiters, answer enumerators, instruction wording, and more. This throws into question popular single-prompt evaluation practices. We present DOVE (Dataset Of Variation Evaluation) a large-scale dataset containing prompt perturbations of various evaluation benchmarks. In contrast to previous work, we examine LLM sensitivity from an holistic perspective, and assess the joint effects of perturbations along various dimensions, resulting in thousands of perturbations per instance. We evaluate several model families against DOVE, leading to several findings, including efficient methods for choosing well-performing prompts, observing that few-shot examples reduce sensitivity, and identifying instances which are inherently hard across all perturbations. DOVE consists of more than 250M prompt perturbations and model outputs, which we make publicly available to spur a community-wide effort toward meaningful, robust, and efficient evaluation.","authors":["Eliya Habba","Ofir Arviv","Itay Itzhak","Yotam Perlitz","Elron Bandel","Leshem Choshen","Michal Shmueli-Scheuer","Gabriel Stanovsky"],"url":"https://arxiv.org/abs/2503.01622"}
{"created":"2025-06-05","title":"M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality","abstract":"Designing effective reward functions in multi-agent reinforcement learning (MARL) is a significant challenge, often leading to suboptimal or misaligned behaviors in complex, coordinated environments. We introduce Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality ($\\text{M}^3\\text{HF}$), a novel framework that integrates multi-phase human feedback of mixed quality into the MARL training process. By involving humans with diverse expertise levels to provide iterative guidance, $\\text{M}^3\\text{HF}$ leverages both expert and non-expert feedback to continuously refine agents' policies. During training, we strategically pause agent learning for human evaluation, parse feedback using large language models to assign it appropriately and update reward functions through predefined templates and adaptive weights by using weight decay and performance-based adjustments. Our approach enables the integration of nuanced human insights across various levels of quality, enhancing the interpretability and robustness of multi-agent cooperation. Empirical results in challenging environments demonstrate that $\\text{M}^3\\text{HF}$ significantly outperforms state-of-the-art methods, effectively addressing the complexities of reward design in MARL and enabling broader human participation in the training process.","authors":["Ziyan Wang","Zhicheng Zhang","Fei Fang","Yali Du"],"url":"https://arxiv.org/abs/2503.02077"}
{"created":"2025-06-05","title":"Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection","abstract":"Domain generalization (DG) for object detection aims to enhance detectors' performance in unseen scenarios. This task remains challenging due to complex variations in real-world applications. Recently, diffusion models have demonstrated remarkable capabilities in diverse scene generation, which inspires us to explore their potential for improving DG tasks. Instead of generating images, our method extracts multi-step intermediate features during the diffusion process to obtain domain-invariant features for generalized detection. Furthermore, we propose an efficient knowledge transfer framework that enables detectors to inherit the generalization capabilities of diffusion models through feature and object-level alignment, without increasing inference time. We conduct extensive experiments on six challenging DG benchmarks. The results demonstrate that our method achieves substantial improvements of 14.0% mAP over existing DG approaches across different domains and corruption types. Notably, our method even outperforms most domain adaptation methods without accessing any target domain data. Moreover, the diffusion-guided detectors show consistent improvements of 15.9% mAP on average compared to the baseline. Our work aims to present an effective approach for domain-generalized detection and provide potential insights for robust visual recognition in real-world scenarios. The code is available at https://github.com/heboyong/Generalized-Diffusion-Detector.","authors":["Boyong He","Yuxiang Ji","Qianwen Ye","Zhuoyue Tan","Liaoni Wu"],"url":"https://arxiv.org/abs/2503.02101"}
{"created":"2025-06-05","title":"InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training","abstract":"Recent advancements in speech large language models (SpeechLLMs) have attracted considerable attention. Nonetheless, current methods exhibit suboptimal performance in adhering to speech instructions. Notably, the intelligence of models significantly diminishes when processing speech-form input as compared to direct text-form input. Prior work has attempted to mitigate this semantic inconsistency between speech and text representations through techniques such as representation and behavior alignment, which involve the meticulous design of data pairs during the post-training phase. In this paper, we introduce a simple and scalable training method called InSerter, which stands for Interleaved Speech-Text Representation Pre-training. InSerter is designed to pre-train large-scale unsupervised speech-text sequences, where the speech is synthesized from randomly selected segments of an extensive text corpus using text-to-speech conversion. Consequently, the model acquires the ability to generate textual continuations corresponding to the provided speech segments, obviating the need for intensive data design endeavors. To systematically evaluate speech instruction-following capabilities, we introduce SpeechInstructBench, the first comprehensive benchmark specifically designed for speech-oriented instruction-following tasks. Our proposed InSerter achieves SOTA performance in SpeechInstructBench and demonstrates superior or competitive results across diverse speech processing tasks.","authors":["Dingdong Wang","Jin Xu","Ruihang Chu","Zhifang Guo","Xiong Wang","Jincenzi Wu","Dongchao Yang","Shengpeng Ji","Junyang Lin"],"url":"https://arxiv.org/abs/2503.02769"}
{"created":"2025-06-05","title":"Adopt a PET! An Exploration of PETs, Policy, and Practicalities for Industry in Canada","abstract":"Privacy is an instance of a social norm formed through legal, technical, and cultural dimensions. Institutions such as regulators, industry, and researchers act as societal agents that both influence and respond to evolving norms. Attempts to promote privacy are often ineffective unless they account for this complexity and the dynamic interactions among these actors. Privacy enhancing technologies (PETs) are technical solutions for privacy issues that enable collaborative data analysis, allowing for the development of solutions that benefit society, all while ensuring the privacy of individuals whose data is being used. However, despite increased privacy challenges and a corresponding increase in new regulations being proposed by governments across the globe, a low adoption rate of PETs persists. In this work, we investigate the factors influencing industry's decision-making processes around PETs adoption as well as the extent to which privacy regulations inspire such adoption. We conducted a qualitative survey study with 22 industry participants from across Canada to investigate how businesses in Canada make decisions to adopt novel technologies and how new privacy regulations impact their business processes. Informed by the results of our analysis, we make recommendations for industry, researchers, and policymakers on how to support what each of them seeks from the other when attempting to improve digital privacy protections. By advancing our understanding of what challenges the industry faces, we increase the effectiveness of future privacy research that aims to help overcome these issues.","authors":["Masoumeh Shafieinejad","Xi He","Bailey Kacsmar"],"url":"https://arxiv.org/abs/2503.03027"}
{"created":"2025-06-05","title":"On the Acquisition of Shared Grammatical Representations in Bilingual Language Models","abstract":"Crosslingual transfer is crucial to contemporary language models' multilingual capabilities, but how it occurs is not well understood. We ask what happens to a monolingual language model when it begins to be trained on a second language. Specifically, we train small bilingual models for which we control the amount of data for each language and the order of language exposure. To find evidence of shared multilingual representations, we turn to structural priming, a method used to study grammatical representations in humans. We first replicate previous crosslingual structural priming results and find that after controlling for training data quantity and language exposure, there are asymmetrical effects across language pairs and directions. We argue that this asymmetry may shape hypotheses about human structural priming effects. We also find that structural priming effects are less robust for less similar language pairs, highlighting potential limitations of crosslingual transfer learning and shared representations for typologically diverse languages.","authors":["Catherine Arnett","Tyler A. Chang","James A. Michaelov","Benjamin K. Bergen"],"url":"https://arxiv.org/abs/2503.03962"}
{"created":"2025-06-05","title":"Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination","abstract":"The rapid evolution of code largelanguage models underscores the need for effective and transparent benchmarking of their reasoning capabilities. However, the current benchmarking approach heavily depends on publicly available, human-created datasets. The widespread use of these fixed benchmark datasets makes the benchmarking process to be static and thus particularly susceptible to data contamination, an unavoidable consequence of the extensive data collection processes used to train Code LLMs. Existing approaches that address data contamination often suffer from human effort limitations and imbalanced problem complexity. To tackle these challenges, we propose \\tool, a novel benchmarking suite for evaluating Code LLMs under potential data contamination. Given a seed programming problem, \\tool employs multiple agents to extract and modify the context without altering the core logic, generating semantically equivalent variations. We introduce a dynamic data generation methods and conduct empirical studies on two seed datasets across 21 Code LLMs. Results show that \\tool effectively benchmarks reasoning capabilities under contamination risks while generating diverse problem sets to ensure consistent and reliable evaluations.","authors":["Simin Chen","Pranav Pusarla","Baishakhi Ray"],"url":"https://arxiv.org/abs/2503.04149"}
{"created":"2025-06-05","title":"The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights","abstract":"Recent research has increasingly focused on multimodal mathematical reasoning, particularly emphasizing the creation of relevant datasets and benchmarks. Despite this, the role of visual information in reasoning has been underexplored. Our findings show that existing multimodal mathematical models minimally leverage visual information, and model performance remains largely unaffected by changes to or removal of images in the dataset. We attribute this to the dominance of textual information and answer options that inadvertently guide the model to correct answers. To improve evaluation methods, we introduce the HC-M3D dataset, specifically designed to require image reliance for problem-solving and to challenge models with similar, yet distinct, images that change the correct answer. In testing leading models, their failure to detect these subtle visual differences suggests limitations in current visual perception capabilities. Additionally, we observe that the common approach of improving general VQA capabilities by combining various types of image encoders does not contribute to math reasoning performance. This finding also presents a challenge to enhancing visual reliance during math reasoning. Our benchmark and code would be available at \\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\\_modality\\_role}.","authors":["Yufang Liu","Yao Du","Tao Ji","Jianing Wang","Yang Liu","Yuanbin Wu","Aimin Zhou","Mengdi Zhang","Xunliang Cai"],"url":"https://arxiv.org/abs/2503.04167"}
{"created":"2025-06-05","title":"Knowledge Retention for Continual Model-Based Reinforcement Learning","abstract":"We propose DRAGO, a novel approach for continual model-based reinforcement learning aimed at improving the incremental development of world models across a sequence of tasks that differ in their reward functions but not the state space or dynamics. DRAGO comprises two key components: Synthetic Experience Rehearsal, which leverages generative models to create synthetic experiences from past tasks, allowing the agent to reinforce previously learned dynamics without storing data, and Regaining Memories Through Exploration, which introduces an intrinsic reward mechanism to guide the agent toward revisiting relevant states from prior tasks. Together, these components enable the agent to maintain a comprehensive and continually developing world model, facilitating more effective learning and adaptation across diverse environments. Empirical evaluations demonstrate that DRAGO is able to preserve knowledge across tasks, achieving superior performance in various continual learning scenarios.","authors":["Yixiang Sun","Haotian Fu","Michael Littman","George Konidaris"],"url":"https://arxiv.org/abs/2503.04256"}
{"created":"2025-06-05","title":"Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities","abstract":"Spoken dialogue modeling poses challenges beyond text-based language modeling, requiring real-time interaction, turn-taking, and backchanneling. While most Spoken Dialogue Models (SDMs) operate in half-duplex mode-processing one turn at a time - emerging full-duplex SDMs can listen and speak simultaneously, enabling more natural conversations. However, current evaluations remain limited, focusing mainly on turn-based metrics or coarse corpus-level analyses. To address this, we introduce Full-Duplex-Bench, a benchmark that systematically evaluates key interactive behaviors: pause handling, backchanneling, turn-taking, and interruption management. Our framework uses automatic metrics for consistent, reproducible assessment and provides a fair, fast evaluation setup. By releasing our benchmark and code, we aim to advance spoken dialogue modeling and foster the development of more natural and engaging SDMs.","authors":["Guan-Ting Lin","Jiachen Lian","Tingle Li","Qirui Wang","Gopala Anumanchipalli","Alexander H. Liu","Hung-yi Lee"],"url":"https://arxiv.org/abs/2503.04721"}
{"created":"2025-06-05","title":"Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces","abstract":"Recent works have shown that, when trained at scale, uni-modal 2D vision and text encoders converge to learned features that share remarkable structural properties, despite arising from different representations. However, the role of 3D encoders with respect to other modalities remains unexplored. Furthermore, existing 3D foundation models that leverage large datasets are typically trained with explicit alignment objectives with respect to frozen encoders from other representations. In this work, we investigate the possibility of a posteriori alignment of representations obtained from uni-modal 3D encoders compared to text-based feature spaces. We show that naive post-training feature alignment of uni-modal text and 3D encoders results in limited performance. We then focus on extracting subspaces of the corresponding feature spaces and discover that by projecting learned representations onto well-chosen lower-dimensional subspaces the quality of alignment becomes significantly higher, leading to improved accuracy on matching and retrieval tasks. Our analysis further sheds light on the nature of these shared subspaces, which roughly separate between semantic and geometric data representations. Overall, ours is the first work that helps to establish a baseline for post-training alignment of 3D uni-modal and text feature spaces, and helps to highlight both the shared and unique properties of 3D data compared to other representations. Our code and weights are available at https://github.com/Souhail-01/3d-text-alignment","authors":["Souhail Hadgi","Luca Moschella","Andrea Santilli","Diego Gomez","Qixing Huang","Emanuele Rodol\\`a","Simone Melzi","Maks Ovsjanikov"],"url":"https://arxiv.org/abs/2503.05283"}
{"created":"2025-06-05","title":"Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as hyperelastic constitutive artificial neural networks (CANs)","abstract":"Traditional constitutive models rely on hand-crafted parametric forms with limited expressivity and generalizability, while neural network-based models can capture complex material behavior but often lack interpretability. To balance these trade-offs, we present monotonic Input-Convex Kolmogorov-Arnold Networks (ICKANs) for learning polyconvex hyperelastic constitutive laws. ICKANs leverage the Kolmogorov-Arnold representation, decomposing the model into compositions of trainable univariate spline-based activation functions for rich expressivity. We introduce trainable monotonic input-convex splines within the KAN architecture, ensuring physically admissible polyconvex models for isotropic compressible hyperelasticity. The resulting models are both compact and interpretable, enabling explicit extraction of analytical constitutive relationships through a monotonic input-convex symbolic regression technique. Through unsupervised training on full-field strain data and limited global force measurements, ICKANs accurately capture nonlinear stress-strain behavior across diverse strain states. Finite element simulations of unseen geometries with trained ICKAN hyperelastic constitutive models confirm the framework's robustness and generalization capability.","authors":["Prakash Thakolkaran","Yaqi Guo","Shivam Saini","Mathias Peirlinck","Benjamin Alheit","Siddhant Kumar"],"url":"https://arxiv.org/abs/2503.05617"}
{"created":"2025-06-05","title":"ROGRAG: A Robustly Optimized GraphRAG Framework","abstract":"Large language models (LLMs) commonly struggle with specialized or emerging topics which are rarely seen in the training corpus. Graph-based retrieval-augmented generation (GraphRAG) addresses this by structuring domain knowledge as a graph for dynamic retrieval. However, existing pipelines involve complex engineering workflows, making it difficult to isolate the impact of individual components. It is also challenging to evaluate the retrieval effectiveness due to the overlap between the pretraining and evaluation datasets. In this work, we introduce ROGRAG, a Robustly Optimized GraphRAG framework. Specifically, we propose a multi-stage retrieval mechanism that integrates dual-level with logic form retrieval methods to improve retrieval robustness without increasing computational cost. To further refine the system, we incorporate various result verification methods and adopt an incremental database construction approach. Through extensive ablation experiments, we rigorously assess the effectiveness of each component. Our implementation includes comparative experiments on SeedBench, where Qwen2.5-7B-Instruct initially underperformed. ROGRAG significantly improves the score from 60.0% to 75.0% and outperforms mainstream methods. Experiments on domain-specific datasets reveal that dual-level retrieval enhances fuzzy matching, while logic form retrieval improves structured reasoning, highlighting the importance of multi-stage retrieval.ROGRAG is released as an open-source resource and supports installation with pip.","authors":["Zhefan Wang","Huanjun Kong","Jie Ying","Wanli Ouyang","Nanqing Dong"],"url":"https://arxiv.org/abs/2503.06474"}
{"created":"2025-06-05","title":"PFDial: A Structured Dialogue Instruction Fine-tuning Method Based on UML Flowcharts","abstract":"Process-driven dialogue systems, which operate under strict predefined process constraints, are essential in customer service and equipment maintenance scenarios. Although Large Language Models (LLMs) have shown remarkable progress in dialogue and reasoning, they still struggle to solve these strictly constrained dialogue tasks. To address this challenge, we construct Process Flow Dialogue (PFDial) dataset, which contains 12,705 high-quality Chinese dialogue instructions derived from 440 flowcharts containing 5,055 process nodes. Based on PlantUML specification, each UML flowchart is converted into atomic dialogue units i.e., structured five-tuples. Experimental results demonstrate that a 7B model trained with merely 800 samples, and a 0.5B model trained on total data both can surpass 90% accuracy. Additionally, the 8B model can surpass GPT-4o up to 43.88% with an average of 11.00%. We further evaluate models' performance on challenging backward transitions in process flows and conduct an in-depth analysis of various dataset formats to reveal their impact on model performance in handling decision and sequential branches. The data is released in https://github.com/KongLongGeFDU/PFDial.","authors":["Ming Zhang","Yuhui Wang","Yujiong Shen","Tingyi Yang","Changhao Jiang","Yilong Wu","Shihan Dou","Qinhao Chen","Zhiheng Xi","Zhihao Zhang","Yi Dong","Zhen Wang","Zhihui Fei","Mingyang Wan","Tao Liang","Guojun Ma","Qi Zhang","Tao Gui","Xuanjing Huang"],"url":"https://arxiv.org/abs/2503.06706"}
{"created":"2025-06-05","title":"SemHiTok: A Unified Image Tokenizer via Semantic-Guided Hierarchical Codebook for Multimodal Understanding and Generation","abstract":"In this paper, we introduce SemHiTok, a unified image Tokenizer via Semantic-Guided Hierarchical codebook that provides consistent discrete representations for multimodal understanding and generation. Recently, unified image tokenizers have sparked exploration within research community, which is designed to capture high-level semantic features for understanding and retaining low-level pixel features for generation. Previous works attempt to train a unified image tokenizer by combining loss for semantic distillation and pixel reconstruction. However, due to the differing levels of features prioritized by multimodal understanding and generation, joint training methods face significant challenges in achieving a good trade-off. SemHiTok addresses this challenge through a novel semantic-guided hierarchical codebook, which builds pixel sub-codebooks on a pretrained semantic codebook. This design decouples semantic and pixel both in terms of structure and training strategy, enabling the tokenizer to capture pixel features while retaining its ability to comprehend high-level semantic information. Our experiments demonstrate that SemHiTok achieves SOTA performance in image reconstruction and multimodal understanding under LLaVA-v1.5 setting. Further, we develop a unified MLLM with SemHiTok, which exhibits superior performance across multimodal understanding and generation tasks. For understanding, SemHiTok achieves impressive performance on most benchmarks. For generation, our model achieves SOTA performance on MJHQ30K in unified MLLMs.","authors":["Zisheng Chen","Chunwei Wang","Xiuwei Chen","Hongbin Xu","Runhui Huang","Jun Zhou","Jianhua Han","Hang Xu","Xiaodan Liang"],"url":"https://arxiv.org/abs/2503.06764"}
{"created":"2025-06-05","title":"LSC-Eval: A General Framework to Evaluate Methods for Assessing Dimensions of Lexical Semantic Change Using LLM-Generated Synthetic Data","abstract":"Lexical Semantic Change (LSC) provides insight into cultural and social dynamics. Yet, the validity of methods for measuring different kinds of LSC remains unestablished due to the absence of historical benchmark datasets. To address this gap, we propose LSC-Eval, a novel three-stage general-purpose evaluation framework to: (1) develop a scalable methodology for generating synthetic datasets that simulate theory-driven LSC using In-Context Learning and a lexical database; (2) use these datasets to evaluate the sensitivity of computational methods to synthetic change; and (3) assess their suitability for detecting change in specific dimensions and domains. We apply LSC-Eval to simulate changes along the Sentiment, Intensity, and Breadth (SIB) dimensions, as defined in the SIBling framework, using examples from psychology. We then evaluate the ability of selected methods to detect these controlled interventions. Our findings validate the use of synthetic benchmarks, demonstrate that tailored methods effectively detect changes along SIB dimensions, and reveal that a state-of-the-art LSC model faces challenges in detecting affective dimensions of LSC. LSC-Eval offers a valuable tool for dimension- and domain-specific benchmarking of LSC methods, with particular relevance to the social sciences.","authors":["Naomi Baes","Rapha\\\"el Merx","Nick Haslam","Ekaterina Vylomova","Haim Dubossarsky"],"url":"https://arxiv.org/abs/2503.08042"}
{"created":"2025-06-05","title":"GRU: Mitigating the Trade-off between Unlearning and Retention for Large Language Models","abstract":"Large language model (LLM) unlearning has demonstrated its essential role in removing privacy and copyright-related responses, crucial for their legal and safe applications. However, the pursuit of complete unlearning often comes with substantial costs due to its compromises in their general functionality, leading to a notorious trade-off between unlearning and retention. In examining the update process for unlearning dynamically, we find gradients hold essential information for revealing this trade-off. In particular, we look at the varying relationship between retention performance and directional disparities between gradients during unlearning. It motivates the sculpting of an update mechanism derived from gradients from two sources, i.e., harmful for retention and useful for unlearning. Accordingly, we propose Gradient Rectified Unlearning (GRU), an enhanced unlearning framework controlling the updating gradients in a geometry-focused and optimization-driven manner such that their side impacts on other, unrelated responses can be minimized. Specifically, GRU derives a closed-form solution to project the unlearning gradient onto the orthogonal space of that gradient harmful for retention, ensuring minimal deviation from its original direction under the condition that overall performance is retained. Comprehensive experiments are conducted to demonstrate that GRU, as a general framework, is straightforward to implement and efficiently enhances a range of baseline methods through its adaptable and compatible characteristics. Additionally, experimental results show its broad effectiveness across a diverse set of benchmarks for LLM unlearning.","authors":["Yue Wang","Qizhou Wang","Feng Liu","Wei Huang","Yali Du","Xiaojiang Du","Bo Han"],"url":"https://arxiv.org/abs/2503.09117"}
{"created":"2025-06-05","title":"FlexiReg: Flexible Urban Region Representation Learning","abstract":"The increasing availability of urban data offers new opportunities for learning region representations, which can be used as input to machine learning models for downstream tasks such as check-in or crime prediction. While existing solutions have produced promising results, an issue is their fixed formation of regions and fixed input region features, which may not suit the needs of different downstream tasks. To address this limitation, we propose a model named FlexiReg for urban region representation learning that is flexible with both the formation of urban regions and the input region features. FlexiReg is based on a spatial grid partitioning over the spatial area of interest. It learns representations for the grid cells, leveraging publicly accessible data, including POI, land use, satellite imagery, and street view imagery. We propose adaptive aggregation to fuse the cell representations and prompt learning techniques to tailor the representations towards different tasks, addressing the needs of varying formations of urban regions and downstream tasks. Extensive experiments on five real-world datasets demonstrate that FlexiReg outperforms state-of-the-art models by up to 202% in term of the accuracy of four diverse downstream tasks using the produced urban region representations.","authors":["Fengze Sun","Yanchuan Chang","Egemen Tanin","Shanika Karunasekera","Jianzhong Qi"],"url":"https://arxiv.org/abs/2503.09128"}
{"created":"2025-06-05","title":"Language-Enhanced Representation Learning for Single-Cell Transcriptomics","abstract":"Single-cell RNA sequencing (scRNA-seq) offers detailed insights into cellular heterogeneity. Recent advancements leverage single-cell large language models (scLLMs) for effective representation learning. These models focus exclusively on transcriptomic data, neglecting complementary biological knowledge from textual descriptions. To overcome this limitation, we propose scMMGPT, a novel multimodal framework designed for language-enhanced representation learning in single-cell transcriptomics. Unlike existing methods, scMMGPT employs robust cell representation extraction, preserving quantitative gene expression data, and introduces an innovative two-stage pre-training strategy combining discriminative precision with generative flexibility. Extensive experiments demonstrate that scMMGPT significantly outperforms unimodal and multimodal baselines across key downstream tasks, including cell annotation and clustering, and exhibits superior generalization in out-of-distribution scenarios.","authors":["Yaorui Shi","Jiaqi Yang","Changhao Nai","Sihang Li","Junfeng Fang","Xiang Wang","Zhiyuan Liu","Yang Zhang"],"url":"https://arxiv.org/abs/2503.09427"}
{"created":"2025-06-05","title":"Learning Cascade Ranking as One Network","abstract":"Cascade Ranking is a prevalent architecture in large-scale top-k selection systems like recommendation and advertising platforms. Traditional training methods focus on single-stage optimization, neglecting interactions between stages. Recent advances have introduced interaction-aware training paradigms, but still struggle to 1) align training objectives with the goal of the entire cascade ranking (i.e., end-to-end recall of ground-truth items) and 2) learn effective collaboration patterns for different stages. To address these challenges, we propose LCRON, which introduces a novel surrogate loss function derived from the lower bound probability that ground truth items are selected by cascade ranking, ensuring alignment with the overall objective of the system. According to the properties of the derived bound, we further design an auxiliary loss for each stage to drive the reduction of this bound, leading to a more robust and effective top-k selection. LCRON enables end-to-end training of the entire cascade ranking system as a unified network. Experimental results demonstrate that LCRON achieves significant improvement over existing methods on public benchmarks and industrial applications, addressing key limitations in cascade ranking training and significantly enhancing system performance.","authors":["Yunli Wang","Zhen Zhang","Zhiqiang Wang","Zixuan Yang","Yu Li","Jian Yang","Shiyang Wen","Peng Jiang","Kun Gai"],"url":"https://arxiv.org/abs/2503.09492"}
{"created":"2025-06-05","title":"SAEBench: A Comprehensive Benchmark for Sparse Autoencoders in Language Model Interpretability","abstract":"Sparse autoencoders (SAEs) are a popular technique for interpreting language model activations, and there is extensive recent work on improving SAE effectiveness. However, most prior work evaluates progress using unsupervised proxy metrics with unclear practical relevance. We introduce SAEBench, a comprehensive evaluation suite that measures SAE performance across eight diverse metrics, spanning interpretability, feature disentanglement and practical applications like unlearning. To enable systematic comparison, we open-source a suite of over 200 SAEs across eight recently proposed SAE architectures and training algorithms. Our evaluation reveals that gains on proxy metrics do not reliably translate to better practical performance. For instance, while Matryoshka SAEs slightly underperform on existing proxy metrics, they substantially outperform other architectures on feature disentanglement metrics; moreover, this advantage grows with SAE scale. By providing a standardized framework for measuring progress in SAE development, SAEBench enables researchers to study scaling trends and make nuanced comparisons between different SAE architectures and training methodologies. Our interactive interface enables researchers to flexibly visualize relationships between metrics across hundreds of open-source SAEs at: www.neuronpedia.org/sae-bench","authors":["Adam Karvonen","Can Rager","Johnny Lin","Curt Tigges","Joseph Bloom","David Chanin","Yeu-Tong Lau","Eoin Farrell","Callum McDougall","Kola Ayonrinde","Demian Till","Matthew Wearden","Arthur Conmy","Samuel Marks","Neel Nanda"],"url":"https://arxiv.org/abs/2503.09532"}
{"created":"2025-06-05","title":"Strong normalization through idempotent intersection types: a new syntactical approach","abstract":"It is well-known that intersection type assignment systems can be used to characterize strong normalization (SN). Typical proofs that typable lambda-terms are SN in these systems rely on semantical techniques. In this work, we study $\\Lambda_\\cap^e$, a variant of Coppo and Dezani's (Curry-style) intersection type system, and we propose a syntactical proof of strong normalization for it. We first design $\\Lambda_\\cap^i$, a Church-style version, in which terms closely correspond to typing derivations. Then we prove that typability in $\\Lambda_\\cap^i$ implies SN through a measure that, given a term, produces a natural number that decreases along with reduction. Finally, the result is extended to $\\Lambda_\\cap^e$, since the two systems simulate each other.","authors":["Pablo Barenbaum","Simona Ronchi Della Rocca","Cristian Sottile"],"url":"https://arxiv.org/abs/2503.09831"}
{"created":"2025-06-05","title":"Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework","abstract":"Artificial Intelligence (AI) is now firmly at the center of evidence-based medicine. Despite many success stories that edge the path of AI's rise in healthcare, there are comparably many reports of significant shortcomings and unexpected behavior of AI in deployment. A major reason for these limitations is AI's reliance on association-based learning, where non-representative machine learning datasets can amplify latent bias during training and/or hide it during testing. To unlock new tools capable of foreseeing and preventing such AI bias issues, we present G-AUDIT. Generalized Attribute Utility and Detectability-Induced bias Testing (G-AUDIT) for datasets is a modality-agnostic dataset auditing framework that allows for generating targeted hypotheses about sources of bias in training or testing data. Our method examines the relationship between task-level annotations (commonly referred to as ``labels'') and data properties including patient attributes (e.g., age, sex) and environment/acquisition characteristics (e.g., clinical site, imaging protocols). G-AUDIT quantifies the extent to which the observed data attributes pose a risk for shortcut learning, or in the case of testing data, might hide predictions made based on spurious associations. We demonstrate the broad applicability of our method by analyzing large-scale medical datasets for three distinct modalities and machine learning tasks: skin lesion classification in images, stigmatizing language classification in Electronic Health Records (EHR), and mortality prediction for ICU tabular data. In each setting, G-AUDIT successfully identifies subtle biases commonly overlooked by traditional qualitative methods, underscoring its practical value in exposing dataset-level risks and supporting the downstream development of reliable AI systems.","authors":["Nathan Drenkow","Mitchell Pavlak","Keith Harrigian","Ayah Zirikly","Adarsh Subbaswamy","Mohammad Mehdi Farhangi","Nicholas Petrick","Mathias Unberath"],"url":"https://arxiv.org/abs/2503.09969"}
{"created":"2025-06-05","title":"EscapeCraft: A 3D Room Escape Environment for Benchmarking Complex Multimodal Reasoning Ability","abstract":"The rapid advancing of Multimodal Large Language Models (MLLMs) has spurred interest in complex multimodal reasoning tasks in the real-world and virtual environment, which require coordinating multiple abilities, including visual perception, visual reasoning, spatial awareness, and target deduction. However, existing evaluations primarily assess the final task completion, often degrading assessments to isolated abilities such as visual grounding and visual question answering. Less attention is given to comprehensively and quantitatively analyzing reasoning process in multimodal environments, which is crucial for understanding model behaviors and underlying reasoning mechanisms beyond merely task success. To address this, we introduce MM-Escape, an extensible benchmark for investigating multimodal reasoning, inspired by real-world escape games. MM-Escape emphasizes intermediate model behaviors alongside final task completion. To achieve this, we develop EscapeCraft, a customizable and open environment that enables models to engage in free-form exploration for assessing multimodal reasoning. Extensive experiments show that MLLMs, regardless of scale, can successfully complete the simplest room escape tasks, with some exhibiting human-like exploration strategies. Yet, performance dramatically drops as task difficulty increases. Moreover, we observe that performance bottlenecks vary across models, revealing distinct failure modes and limitations in their multimodal reasoning abilities, such as repetitive trajectories without adaptive exploration, getting stuck in corners due to poor visual spatial awareness, and ineffective use of acquired props, such as the key. We hope our work sheds light on new challenges in multimodal reasoning, and uncovers potential improvements in MLLMs capabilities.","authors":["Ziyue Wang","Yurui Dong","Fuwen Luo","Minyuan Ruan","Zhili Cheng","Chi Chen","Peng Li","Yang Liu"],"url":"https://arxiv.org/abs/2503.10042"}
{"created":"2025-06-05","title":"An Expanded Massive Multilingual Dataset for High-Performance Language Technologies (HPLT)","abstract":"Training state-of-the-art large language models requires vast amounts of clean and diverse textual data. However, building suitable multilingual datasets remains a challenge. In this work, we present HPLT v2, a collection of high-quality multilingual monolingual and parallel corpora, extending prior work of the HPLT project. The monolingual portion of the data contains 8T tokens covering 193 languages, while the parallel data contains 380M sentence pairs covering 51 languages. We document the entire data pipeline and release the code to reproduce it. We provide extensive analysis of the quality and characteristics of our data. Finally, we evaluate the performance of language models and machine translation systems trained on HPLT v2, demonstrating its value.","authors":["Laurie Burchell","Ona de Gibert","Nikolay Arefyev","Mikko Aulamo","Marta Ba\\~n\\'on","Pinzhen Chen","Mariia Fedorova","Liane Guillou","Barry Haddow","Jan Haji\\v{c}","Jind\\v{r}ich Helcl","Erik Henriksson","Mateusz Klimaszewski","Ville Komulainen","Andrey Kutuzov","Joona Kyt\\\"oniemi","Veronika Laippala","Petter M{\\ae}hlum","Bhavitvya Malik","Farrokh Mehryary","Vladislav Mikhailov","Nikita Moghe","Amanda Myntti","Dayy\\'an O'Brien","Stephan Oepen","Proyag Pal","Jousia Piha","Sampo Pyysalo","Gema Ram\\'irez-S\\'anchez","David Samuel","Pavel Stepachev","J\\\"org Tiedemann","Du\\v{s}an Vari\\v{s}","Tereza Vojt\\v{e}chov\\'a","Jaume Zaragoza-Bernabeu"],"url":"https://arxiv.org/abs/2503.10267"}
{"created":"2025-06-05","title":"Sample Compression for Self Certified Continual Learning","abstract":"Continual learning algorithms aim to learn from a sequence of tasks, making the training distribution non-stationary. The majority of existing continual learning approaches in the literature rely on heuristics and do not provide learning guarantees. In this paper, we present a new method called Continual Pick-to-Learn (CoP2L), which is able to retain the most representative samples for each task in an efficient way. CoP2L combines the Pick-to-Learn algorithm (rooted in the sample compression theory) and the experience replay continual learning scheme. This allows us to provide non-vacuous upper bounds on the generalization loss of the learned predictors, numerically computable after each task. We empirically evaluate our approach on several standard continual learning benchmarks across Class-Incremental, Task-Incremental, and Domain-Incremental settings. Our results show that CoP2L is highly competitive across all setups, often outperforming existing baselines, and significantly mitigating catastrophic forgetting compared to vanilla experience replay in the Class-Incremental setting. It is possible to leverage the bounds provided by CoP2L in practical scenarios to certify the predictor reliability on previously learned tasks, in order to improve the trustworthiness of the continual learning algorithm.","authors":["Jacob Comeau","Mathieu Bazinet","Pascal Germain","Cem Subakan"],"url":"https://arxiv.org/abs/2503.10503"}
{"created":"2025-06-05","title":"Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set","abstract":"Discourse understanding is essential for many NLP tasks, yet most existing work remains constrained by framework-dependent discourse representations. This work investigates whether large language models (LLMs) capture discourse knowledge that generalizes across languages and frameworks. We address this question along two dimensions: (1) developing a unified discourse relation label set to facilitate cross-lingual and cross-framework discourse analysis, and (2) probing LLMs to assess whether they encode generalizable discourse abstractions. Using multilingual discourse relation classification as a testbed, we examine a comprehensive set of 23 LLMs of varying sizes and multilingual capabilities. Our results show that LLMs, especially those with multilingual training corpora, can generalize discourse information across languages and frameworks. Further layer-wise analyses reveal that language generalization at the discourse level is most salient in the intermediate layers. Lastly, our error analysis provides an account of challenging relation classes.","authors":["Florian Eichin","Yang Janet Liu","Barbara Plank","Michael A. Hedderich"],"url":"https://arxiv.org/abs/2503.10515"}
{"created":"2025-06-05","title":"Reasoning is All You Need for Video Generalization: A Counterfactual Benchmark with Sub-question Evaluation","abstract":"Counterfactual reasoning is crucial for robust video understanding but remains underexplored in existing multimodal benchmarks. In this paper, we introduce \\textbf{COVER} (\\textbf{\\underline{CO}}unterfactual \\textbf{\\underline{V}}id\\textbf{\\underline{E}}o \\textbf{\\underline{R}}easoning), a multidimensional multimodal benchmark that systematically evaluates MLLMs across the abstract-concrete and perception-cognition dimensions. Beyond prior multimodal benchmarks, COVER decomposes complex queries into structured sub-questions, enabling fine-grained reasoning analysis. Experiments on commercial and open-source models reveal a strong correlation between sub-question accuracy and counterfactual reasoning performance, highlighting the role of structured inference in video understanding. Furthermore, our results suggest a key insight: enhancing the reasoning capability of models is essential for improving the robustness of video understanding. COVER establishes a new standard for assessing MLLMs' logical reasoning abilities in dynamic environments. Our work is available at https://github.com/gongyifan-hash/COVER-Benchmark.","authors":["Qiji Zhou","Yifan Gong","Guangsheng Bao","Hongjie Qiu","Jinqiang Li","Xiangrong Zhu","Huajian Zhang","Yue Zhang"],"url":"https://arxiv.org/abs/2503.10691"}
{"created":"2025-06-05","title":"Can Large Reasoning Models do Analogical Reasoning under Perceptual Uncertainty?","abstract":"This work presents a first evaluation of two state-of-the-art Large Reasoning Models (LRMs), OpenAI's o3-mini and DeepSeek R1, on analogical reasoning, focusing on well-established nonverbal human IQ tests based on Raven's progressive matrices. We benchmark with the I-RAVEN dataset and its extension, I-RAVEN-X, which tests the ability to generalize to longer reasoning rules and ranges of the attribute values. To assess the influence of visual uncertainties on these symbolic analogical reasoning tests, we extend the I-RAVEN-X dataset, which otherwise assumes an oracle perception. We adopt a two-fold strategy to simulate this imperfect visual perception: 1) we introduce confounding attributes which, being sampled at random, do not contribute to the prediction of the correct answer of the puzzles, and 2) we smoothen the distributions of the input attributes' values. We observe a sharp decline in OpenAI's o3-mini task accuracy, dropping from 86.6% on the original I-RAVEN to just 17.0% -- approaching random chance -- on the more challenging I-RAVEN-X, which increases input length and range and emulates perceptual uncertainty. This drop occurred despite spending 3.4x more reasoning tokens. A similar trend is also observed for DeepSeek R1: from 80.6% to 23.2%. On the other hand, a neuro-symbolic probabilistic abductive model, ARLC, that achieves state-of-the-art performances on I-RAVEN, can robustly reason under all these out-of-distribution tests, maintaining strong accuracy with only a modest accuracy reduction from 98.6% to 88.0%. Our code is available at https://github.com/IBM/raven-large-language-models.","authors":["Giacomo Camposampiero","Michael Hersche","Roger Wattenhofer","Abu Sebastian","Abbas Rahimi"],"url":"https://arxiv.org/abs/2503.11207"}
{"created":"2025-06-05","title":"SemEval-2025 Task 1: AdMIRe -- Advancing Multimodal Idiomaticity Representation","abstract":"Idiomatic expressions present a unique challenge in NLP, as their meanings are often not directly inferable from their constituent words. Despite recent advancements in Large Language Models (LLMs), idiomaticity remains a significant obstacle to robust semantic representation. We present datasets and tasks for SemEval-2025 Task 1: AdMiRe (Advancing Multimodal Idiomaticity Representation), which challenges the community to assess and improve models' ability to interpret idiomatic expressions in multimodal contexts and in multiple languages. Participants competed in two subtasks: ranking images based on their alignment with idiomatic or literal meanings, and predicting the next image in a sequence. The most effective methods achieved human-level performance by leveraging pretrained LLMs and vision-language models in mixture-of-experts settings, with multiple queries used to smooth over the weaknesses in these models' representations of idiomaticity.","authors":["Thomas Pickard","Aline Villavicencio","Maggie Mi","Wei He","Dylan Phelps","Marco Idiart"],"url":"https://arxiv.org/abs/2503.15358"}
{"created":"2025-06-05","title":"Uncertainty Quantification and Confidence Calibration in Large Language Models: A Survey","abstract":"Large Language Models (LLMs) excel in text generation, reasoning, and decision-making, enabling their adoption in high-stakes domains such as healthcare, law, and transportation. However, their reliability is a major concern, as they often produce plausible but incorrect responses. Uncertainty quantification (UQ) enhances trustworthiness by estimating confidence in outputs, enabling risk mitigation and selective prediction. However, traditional UQ methods struggle with LLMs due to computational constraints and decoding inconsistencies. Moreover, LLMs introduce unique uncertainty sources, such as input ambiguity, reasoning path divergence, and decoding stochasticity, that extend beyond classical aleatoric and epistemic uncertainty. To address this, we introduce a new taxonomy that categorizes UQ methods based on computational efficiency and uncertainty dimensions (input, reasoning, parameter, and prediction uncertainty). We evaluate existing techniques, assess their real-world applicability, and identify open challenges, emphasizing the need for scalable, interpretable, and robust UQ approaches to enhance LLM reliability.","authors":["Xiaoou Liu","Tiejin Chen","Longchao Da","Chacha Chen","Zhen Lin","Hua Wei"],"url":"https://arxiv.org/abs/2503.15850"}
{"created":"2025-06-05","title":"B\\'ezier Splatting for Fast and Differentiable Vector Graphics Rendering","abstract":"Differentiable vector graphics (VGs) are widely used in image vectorization and vector synthesis, while existing representations are costly to optimize and struggle to achieve high-quality rendering results for high-resolution images. This work introduces a new differentiable VG representation, dubbed B\\'ezier Splatting, that enables fast yet high-fidelity VG rasterization. B\\'ezier Splatting samples 2D Gaussians along B\\'ezier curves, which naturally provide positional gradients at object boundaries. Thanks to the efficient splatting-based differentiable rasterizer, B\\'ezier Splatting achieves 30x and 150x faster per forward and backward rasterization step for open curves compared to DiffVG. Additionally, we introduce an adaptive pruning and densification strategy that dynamically adjusts the spatial distribution of curves to escape local minima, further improving VG quality. Furthermore, our new VG representation supports conversion to standard XML-based SVG format, enhancing interoperability with existing VG tools and pipelines. Experimental results show that B\\'ezier Splatting significantly outperforms existing methods with better visual fidelity and significant optimization speedup.","authors":["Xi Liu","Chaoyi Zhou","Nanxuan Zhao","Siyu Huang"],"url":"https://arxiv.org/abs/2503.16424"}
{"created":"2025-06-05","title":"Enhancing Fourier Neural Operators with Local Spatial Features","abstract":"Partial Differential Equation (PDE) problems often exhibit strong local spatial structures, and effectively capturing these structures is critical for approximating their solutions. Recently, the Fourier Neural Operator (FNO) has emerged as an efficient approach for solving these PDE problems. By using parametrization in the frequency domain, FNOs can efficiently capture global patterns. However, this approach inherently overlooks the critical role of local spatial features, as frequency-domain parameterized convolutions primarily emphasize global interactions without encoding comprehensive localized spatial dependencies. Although several studies have attempted to address this limitation, their extracted Local Spatial Features (LSFs) remain insufficient, and computational efficiency is often compromised. To address this limitation, we introduce a convolutional neural network (CNN)-based feature pre-extractor to capture LSFs directly from input data, resulting in a hybrid architecture termed \\textit{Conv-FNO}. Furthermore, we introduce two novel resizing schemes to make our Conv-FNO resolution invariant. In this work, we focus on demonstrating the effectiveness of incorporating LSFs into FNOs by conducting both a theoretical analysis and extensive numerical experiments. Our findings show that this simple yet impactful modification enhances the representational capacity of FNOs and significantly improves performance on challenging PDE benchmarks.","authors":["Chaoyu Liu","Davide Murari","Lihao Liu","Yangming Li","Chris Budd","Carola-Bibiane Sch\\\"onlieb"],"url":"https://arxiv.org/abs/2503.17797"}
{"created":"2025-06-05","title":"MammAlps: A multi-view video behavior monitoring dataset of wild mammals in the Swiss Alps","abstract":"Monitoring wildlife is essential for ecology and ethology, especially in light of the increasing human impact on ecosystems. Camera traps have emerged as habitat-centric sensors enabling the study of wildlife populations at scale with minimal disturbance. However, the lack of annotated video datasets limits the development of powerful video understanding models needed to process the vast amount of fieldwork data collected. To advance research in wild animal behavior monitoring we present MammAlps, a multimodal and multi-view dataset of wildlife behavior monitoring from 9 camera-traps in the Swiss National Park. MammAlps contains over 14 hours of video with audio, 2D segmentation maps and 8.5 hours of individual tracks densely labeled for species and behavior. Based on 6135 single animal clips, we propose the first hierarchical and multimodal animal behavior recognition benchmark using audio, video and reference scene segmentation maps as inputs. Furthermore, we also propose a second ecology-oriented benchmark aiming at identifying activities, species, number of individuals and meteorological conditions from 397 multi-view and long-term ecological events, including false positive triggers. We advocate that both tasks are complementary and contribute to bridging the gap between machine learning and ecology. Code and data are available at: https://github.com/eceo-epfl/MammAlps","authors":["Valentin Gabeff","Haozhe Qi","Brendan Flaherty","Gencer Sumb\\\"ul","Alexander Mathis","Devis Tuia"],"url":"https://arxiv.org/abs/2503.18223"}
{"created":"2025-06-05","title":"VecTrans: Enhancing Compiler Auto-Vectorization through LLM-Assisted Code Transformations","abstract":"Auto-vectorization is a fundamental optimization for modern compilers to exploit SIMD parallelism. However, state-of-the-art approaches still struggle to handle intricate code patterns, often requiring manual hints or domain-specific expertise. Large language models (LLMs), with their ability to capture intricate patterns, provide a promising solution, yet their effective application in compiler optimizations remains an open challenge due to issues such as hallucinations and a lack of domain-specific reasoning. In this paper, we present VecTrans, a novel framework that leverages LLMs to enhance compiler-based code vectorization. VecTrans first employs compiler analysis to identify potentially vectorizable code regions. It then utilizes an LLM to refactor these regions into patterns that are more amenable to the compilers auto-vectorization. To ensure semantic correctness, VecTrans further integrates a hybrid validation mechanism at the intermediate representation (IR) level. With the above efforts, VecTrans combines the adaptability of LLMs with the precision of compiler vectorization, thereby effectively opening up the vectorization opportunities. experimental results show that among all TSVC functions unvectorizable by GCC, ICC, Clang, and BiSheng Compiler, VecTrans achieves an geomean speedup of 1.77x and successfully vectorizes 24 of 51 test cases. This marks a significant advancement over state-of-the-art approaches while maintaining a cost efficiency of $0.012 per function optimization for LLM API usage.","authors":["Zhongchun Zheng","Kan Wu","Long Cheng","Lu Li","Rodrigo C. O. Rocha","Tianyi Liu","Wei Wei","Jianjiang Zeng","Xianwei Zhang","Yaoqing Gao"],"url":"https://arxiv.org/abs/2503.19449"}
{"created":"2025-06-05","title":"Exact and Linear Convergence for Federated Learning under Arbitrary Client Participation is Attainable","abstract":"This work tackles the fundamental challenges in Federated Learning (FL) posed by arbitrary client participation and data heterogeneity, prevalent characteristics in practical FL settings. It is well-established that popular FedAvg-style algorithms struggle with exact convergence and can suffer from slow convergence rates since a decaying learning rate is required to mitigate these scenarios. To address these issues, we introduce the concept of stochastic matrix and the corresponding time-varying graphs as a novel modeling tool to accurately capture the dynamics of arbitrary client participation and the local update procedure. Leveraging this approach, we offer a fresh perspective on designing FL algorithms, provide a rigorous quantitative analysis of the limitations inherent in the FedAvg algorithm, and present FOCUS, Federated Optimization with Exact Convergence via Push-pull Strategy, a provably convergent algorithm designed to effectively overcome the previously mentioned two challenges. More specifically, we provide a rigorous proof demonstrating that FOCUS achieves exact convergence with a linear rate regardless of the arbitrary client participation, establishing it as the first work to demonstrate this significant result.","authors":["Bicheng Ying","Zhe Li","Haibo Yang"],"url":"https://arxiv.org/abs/2503.20117"}
{"created":"2025-06-05","title":"Enhancing the Robustness of LLM-Generated Code: Empirical Study and Framework","abstract":"Ensuring the robustness of code generated by large language models (LLMs) is crucial for real-world reliability. However, existing evaluations predominantly focus on correctness, often neglecting key robustness concerns such as missing input validation and insufficient error handling. In this paper, we present the first empirical study on the robustness of LLM-generated code. We introduce novel robustness metrics and analyze four state-of-the-art code LLMs, revealing that, on average, 43.1% of their generated code is less robust than human-written counterparts. Notably, over 90% of robustness deficiencies stem from missing conditional checks, with 70% of these omissions occurring in the first line of code. Additionally, in 69% of cases where a conditional statement is necessary but absent, the \"if\" token still ranks third or higher in the model's predicted token probabilities, indicating an implicit recognition of control structures. Building on these findings, we propose RobGen, a framework designed to enhance code robustness without requiring model retraining. RobGen leverages two model-agnostic techniques: RobGen-Adj, which dynamically adjusts token probabilities during decoding to encourage the inclusion of control structures, and RobGen-Ins, which improves generated code by inserting missing conditionals after generation. Experimental results demonstrate that RobGen reduces the proportion of less robust model-generated code by 20.0%, significantly enhancing code reliability across diverse tasks. As a lightweight and adaptable solution, RobGen effectively mitigates robustness challenges in LLM-generated code. All code and data are available at https://github.com/SYSUSELab/RobGen.","authors":["Zike Li","Mingwei Liu","Anji Li","Kaifeng He","Yanlin Wang","Xin Peng","Zibin Zheng"],"url":"https://arxiv.org/abs/2503.20197"}
{"created":"2025-06-05","title":"Efficient Learning for Entropy-Regularized Markov Decision Processes via Multilevel Monte Carlo","abstract":"Designing efficient learning algorithms with complexity guarantees for Markov decision processes (MDPs) with large or continuous state and action spaces remains a fundamental challenge. We address this challenge for entropy-regularized MDPs with Polish state and action spaces, assuming access to a generative model of the environment. We propose a novel family of multilevel Monte Carlo (MLMC) algorithms that integrate fixed-point iteration with MLMC techniques and a generic stochastic approximation of the Bellman operator. We quantify the precise impact of the chosen approximate Bellman operator on the accuracy of the resulting MLMC estimator. Leveraging this error analysis, we show that using a biased plain MC estimate for the Bellman operator results in quasi-polynomial sample complexity, whereas an unbiased randomized multilevel approximation of the Bellman operator achieves polynomial sample complexity in expectation. Notably, these complexity bounds are independent of the dimensions or cardinalities of the state and action spaces, distinguishing our approach from existing algorithms whose complexities scale with the sizes of these spaces. We validate these theoretical performance guarantees through numerical experiments.","authors":["Matthieu Meunier","Christoph Reisinger","Yufei Zhang"],"url":"https://arxiv.org/abs/2503.21224"}
{"created":"2025-06-05","title":"RBFleX-NAS: Training-Free Neural Architecture Search Using Radial Basis Function Kernel and Hyperparameter Detection","abstract":"Neural Architecture Search (NAS) is an automated technique to design optimal neural network architectures for a specific workload. Conventionally, evaluating candidate networks in NAS involves extensive training, which requires significant time and computational resources. To address this, training-free NAS has been proposed to expedite network evaluation with minimal search time. However, state-of-the-art training-free NAS algorithms struggle to precisely distinguish well-performing networks from poorly-performing networks, resulting in inaccurate performance predictions and consequently sub-optimal top-1 network accuracy. Moreover, they are less effective in activation function exploration. To tackle the challenges, this paper proposes RBFleX-NAS, a novel training-free NAS framework that accounts for both activation outputs and input features of the last layer with a Radial Basis Function (RBF) kernel. We also present a detection algorithm to identify optimal hyperparameters using the obtained activation outputs and input feature maps. We verify the efficacy of RBFleX-NAS over a variety of NAS benchmarks. RBFleX-NAS significantly outperforms state-of-the-art training-free NAS methods in terms of top-1 accuracy, achieving this with short search time in NAS-Bench-201 and NAS-Bench-SSS. In addition, it demonstrates higher Kendall correlation compared to layer-based training-free NAS algorithms. Furthermore, we propose NAFBee, a new activation design space that extends the activation type to encompass various commonly used functions. In this extended design space, RBFleX-NAS demonstrates its superiority by accurately identifying the best-performing network during activation function search, providing a significant advantage over other NAS algorithms.","authors":["Tomomasa Yamasaki","Zhehui Wang","Tao Luo","Niangjun Chen","Bo Wang"],"url":"https://arxiv.org/abs/2503.22733"}
{"created":"2025-06-05","title":"SCORE: Story Coherence and Retrieval Enhancement for AI Narratives","abstract":"Large Language Models (LLMs) can generate creative and engaging narratives from user-specified input, but maintaining coherence and emotional depth throughout these AI-generated stories remains a challenge. In this work, we propose SCORE, a framework for Story Coherence and Retrieval Enhancement, designed to detect and resolve narrative inconsistencies. By tracking key item statuses and generating episode summaries, SCORE uses a Retrieval-Augmented Generation (RAG) approach, incorporating TF-IDF and cosine similarity to identify related episodes and enhance the overall story structure. Results from testing multiple LLM-generated stories demonstrate that SCORE significantly improves the consistency and stability of narrative coherence compared to baseline GPT models, providing a more robust method for evaluating and refining AI-generated narratives.","authors":["Qiang Yi","Yangfan He","Jianhui Wang","Xinyuan Song","Shiyao Qian","Xinhang Yuan","Li Sun","Yi Xin","Keqin Li","Kuan Lu","Menghao Huo","Jiaqi Chen","Tianyu Shi"],"url":"https://arxiv.org/abs/2503.23512"}
{"created":"2025-06-05","title":"Rubrik's Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset","abstract":"The performance and usability of Large-Language Models (LLMs) are driving their use in explanation generation tasks. However, despite their widespread adoption, LLM explanations have been found to be unreliable, making it difficult for users to distinguish good from bad explanations. To address this issue, we present Rubrik's CUBE, an education-inspired rubric and a dataset of 26k explanations, written and later quality-annotated using the rubric by both humans and six open- and closed-source LLMs. The CUBE dataset focuses on two reasoning and two language tasks, providing the necessary diversity for us to effectively test our proposed rubric. Using Rubrik, we find that explanations are influenced by both task and perceived difficulty. Low quality stems primarily from a lack of conciseness in LLM-generated explanations, rather than cohesion and word choice. The full dataset, rubric, and code are available at https://github.com/RubriksCube/rubriks_cube.","authors":["Diana Galvan-Sosa","Gabrielle Gaudeau","Pride Kavumba","Yunmeng Li","Hongyi gu","Zheng Yuan","Keisuke Sakaguchi","Paula Buttery"],"url":"https://arxiv.org/abs/2503.23899"}
{"created":"2025-06-05","title":"Token-Driven GammaTune: Adaptive Calibration for Enhanced Speculative Decoding","abstract":"Speculative decoding accelerates large language model (LLM) inference by using a smaller draft model to propose tokens, which are then verified by a larger target model. However, selecting an optimal speculation length is critical for maximizing speedup while minimizing wasted computation. We introduce \\textit{GammaTune} and \\textit{GammaTune+}, training-free adaptive algorithms that dynamically adjust speculation length based on token acceptance rates using a heuristic-based switching mechanism. Evaluated on SpecBench across multiple tasks and model pairs, our method outperforms other heuristic-based approaches and fixed-length speculative decoding, achieving an average speedup of 15\\% ($\\pm$5\\%) with \\textit{GammaTune} and 16\\% ($\\pm$3\\%) with \\textit{GammaTune+}, while reducing performance variance. This makes \\textit{GammaTune} a robust and efficient solution for real-world deployment.","authors":["Aayush Gautam","Susav Shrestha","Narasimha Reddy"],"url":"https://arxiv.org/abs/2504.00030"}
{"created":"2025-06-05","title":"Stability analysis of Runge-Kutta methods for nonlinear delay-integro-differential-algebraic equations","abstract":"This paper is devoted to examining the stability of Runge-Kutta methods for solving nonlinear Volterra delay-integro-differential-algebraic equations (DIDAEs) with constant delay. Hybrid numerical schemes combining Runge-Kutta methods and compound quadrature rules are analyzed for nonlinear DIDAEs. Criteria for ensuring the global and asymptotic stability of the proposed schemes are established. Several numerical examples are provided to validate the theoretical findings.","authors":["Gehao Wang","Yuexin Yu"],"url":"https://arxiv.org/abs/2504.00330"}
{"created":"2025-06-05","title":"Two-stage deep learning framework for the restoration of incomplete-ring PET images","abstract":"Positron Emission Tomography (PET) is an important molecular imaging tool widely used in medicine. Traditional PET systems rely on complete detector rings for full angular coverage and reliable data collection. However, incomplete-ring PET scanners have emerged due to hardware failures, cost constraints, or specific clinical needs. Standard reconstruction algorithms often suffer from performance degradation with these systems because of reduced data completeness and geometric inconsistencies. We present a two-stage deep-learning framework that, without incorporating any time-of-flight (TOF) information, restores high-quality images from data with about 50% missing coincidences - double the loss levels previously addressed by CNN-based methods. The pipeline operates in two stages: a projection-domain Attention U-Net first predicts the missing sections of the sinogram by leveraging spatial context from neighbouring slices, after which the completed data are reconstructed with OSEM algorithm and passed to a U-Net-diffusion module that removes residual artefacts while reinstating high-frequency detail. Using 206 brain volumes from a public dataset, the result shows that our model successfully preserves most anatomical structures and tracer distribution features with PSNR of 30.92 dB and SSIM of 0.9708. We also achieve higher inference speed, thus providing an effective solution for incomplete-ring PET imaging.","authors":["Yeqi Fang","Rong Zhou"],"url":"https://arxiv.org/abs/2504.00816"}
{"created":"2025-06-05","title":"Virtual Reality Lensing for Surface Approximation in Feature-driven DVR","abstract":"We present a novel lens technique to support the identification of heterogeneous features in direct volume rendering (DVR) visualizations. In contrast to data-centric transfer function (TF) design, our image-driven approach enables users to specify target features directly within the visualization using deformable quadric surfaces. The lens leverages quadrics for their expressive yet simple parametrization, enabling users to sculpt feature approximations by composing multiple quadric lenses. By doing so, the lens offers greater versatility than traditional rigid-shape lenses for selecting and bringing into focus features with irregular geometry. We discuss the lens visualization and interaction design, advocating for bimanual spatial virtual reality (VR) input for reducing cognitive and physical strain. We also report findings from a pilot qualitative evaluation with a domain specialist using a public asteroid impact dataset. These insights not only shed light on the benefits and pitfalls of using deformable lenses but also suggest directions for future research.","authors":["Roberta Mota","Ehud Sharlin","Usman Alim"],"url":"https://arxiv.org/abs/2504.03980"}
{"created":"2025-06-05","title":"CARE: Assessing the Impact of Multilingual Human Preference Learning on Cultural Awareness","abstract":"Language Models (LMs) are typically tuned with human preferences to produce helpful responses, but the impact of preference tuning on the ability to handle culturally diverse queries remains understudied. In this paper, we systematically analyze how native human cultural preferences can be incorporated into the preference learning process to train more culturally aware LMs. We introduce \\textbf{CARE}, a multilingual resource containing 3,490 culturally specific questions and 31.7k responses with native judgments. We demonstrate how a modest amount of high-quality native preferences improves cultural awareness across various LMs, outperforming larger generic preference data. Our analyses reveal that models with stronger initial cultural performance benefit more from alignment, leading to gaps among models developed in different regions with varying access to culturally relevant data. CARE will be made publicly available at https://github.com/Guochry/CARE.","authors":["Geyang Guo","Tarek Naous","Hiromi Wakaki","Yukiko Nishimura","Yuki Mitsufuji","Alan Ritter","Wei Xu"],"url":"https://arxiv.org/abs/2504.05154"}
{"created":"2025-06-05","title":"Enhancing LLM-Based Short Answer Grading with Retrieval-Augmented Generation","abstract":"Short answer assessment is a vital component of science education, allowing evaluation of students' complex three-dimensional understanding. Large language models (LLMs) that possess human-like ability in linguistic tasks are increasingly popular in assisting human graders to reduce their workload. However, LLMs' limitations in domain knowledge restrict their understanding in task-specific requirements and hinder their ability to achieve satisfactory performance. Retrieval-augmented generation (RAG) emerges as a promising solution by enabling LLMs to access relevant domain-specific knowledge during assessment. In this work, we propose an adaptive RAG framework for automated grading that dynamically retrieves and incorporates domain-specific knowledge based on the question and student answer context. Our approach combines semantic search and curated educational sources to retrieve valuable reference materials. Experimental results in a science education dataset demonstrate that our system achieves an improvement in grading accuracy compared to baseline LLM approaches. The findings suggest that RAG-enhanced grading systems can serve as reliable support with efficient performance gains.","authors":["Yucheng Chu","Peng He","Hang Li","Haoyu Han","Kaiqi Yang","Yu Xue","Tingting Li","Joseph Krajcik","Jiliang Tang"],"url":"https://arxiv.org/abs/2504.05276"}
{"created":"2025-06-05","title":"NNN: Next-Generation Neural Networks for Marketing Measurement","abstract":"We present NNN, an experimental Transformer-based neural network approach to marketing measurement. Unlike Marketing Mix Models (MMMs) which rely on scalar inputs and parametric decay functions, NNN uses rich embeddings to capture both quantitative and qualitative aspects of marketing and organic channels (e.g., search queries, ad creatives). This, combined with its attention mechanism, potentially enables NNN to model complex interactions, capture long-term effects, and improve sales attribution accuracy. We show that L1 regularization permits the use of such expressive models in typical data-constrained settings. Evaluating NNN on simulated and real-world data demonstrates its efficacy, particularly through considerable improvement in predictive power. In addition to marketing measurement, the NNN framework can provide valuable, complementary insights through model probing, such as evaluating keyword or creative effectiveness.","authors":["Thomas Mulc","Mike Anderson","Paul Cubre","Huikun Zhang","Ivy Liu","Saket Kumar"],"url":"https://arxiv.org/abs/2504.06212"}
{"created":"2025-06-05","title":"Identifying Aspects in Peer Reviews","abstract":"Peer review is central to academic publishing, but the growing volume of submissions is straining the process. This motivates the development of computational approaches to support peer review. While each review is tailored to a specific paper, reviewers often make assessments according to certain aspects such as Novelty, which reflect the values of the research community. This alignment creates opportunities for standardizing the reviewing process, improving quality control, and enabling computational support. While prior work has demonstrated the potential of aspect analysis for peer review assistance, the notion of aspect remains poorly formalized. Existing approaches often derive aspects from review forms and guidelines, yet data-driven methods for aspect identification are underexplored. To address this gap, our work takes a bottom-up approach: we propose an operational definition of aspect and develop a data-driven schema for deriving aspects from a corpus of peer reviews. We introduce a dataset of peer reviews augmented with aspects and show how it can be used for community-level review analysis. We further show how the choice of aspects can impact downstream applications, such as LLM-generated review detection. Our results lay a foundation for a principled and data-driven investigation of review aspects, and pave the path for new applications of NLP to support peer review.","authors":["Sheng Lu","Ilia Kuznetsov","Iryna Gurevych"],"url":"https://arxiv.org/abs/2504.06910"}
{"created":"2025-06-05","title":"Towards Sustainable Creativity Support: An Exploratory Study on Prompt Based Image Generation","abstract":"Creativity is a valuable human skill that has long been augmented through both analog and digital tools. Recent progress in generative AI, such as image generation, provides a disruptive technological solution to supporting human creativity further and helping humans generate solutions faster. While AI image generators can help to rapidly visualize ideas based on user prompts, the use of such AI systems has also been critiqued due to their considerable energy usage. In this paper, we report on a user study (N = 24) to understand whether energy consumption can be reduced without impeding on the tool's perceived creativity support. Our results highlight that, for example, a main effect of (image generation) condition on energy consumption, and index of creativity support per prompt but not per task, which seem mainly attributed to image quantity per prompt. We provide details of our analysis on the relation between energy usage, creativity support, and prompting behavior, including attitudes towards designing with AI and its environmental impact.","authors":["Daniel Hove Paludan","Julie Fredsg{\\aa}rd","Kasper Patrick B\\\"ahrentz","Ilhan Aslan","Niels van Berkel"],"url":"https://arxiv.org/abs/2504.07879"}
{"created":"2025-06-05","title":"Self-Supervised Autoencoder Network for Robust Heart Rate Extraction from Noisy Photoplethysmogram: Applying Blind Source Separation to Biosignal Analysis","abstract":"Biosignals can be viewed as mixtures measuring particular physiological events, and blind source separation (BSS) aims to extract underlying source signals from mixtures. This paper proposes a self-supervised multi-encoder autoencoder (MEAE) to separate heartbeat-related source signals from photoplethysmogram (PPG), enhancing heart rate (HR) detection in noisy PPG data. The MEAE is trained on PPG signals from a large open polysomnography database without any pre-processing or data selection. The trained network is then applied to a noisy PPG dataset collected during the daily activities of nine subjects. The extracted heartbeat-related source signal significantly improves HR detection as compared to the original PPG. The absence of pre-processing and the self-supervised nature of the proposed method, combined with its strong performance, highlight the potential of MEAE for BSS in biosignal analysis.","authors":["Matthew B. Webster","Dongheon Lee","Joonnyong Lee"],"url":"https://arxiv.org/abs/2504.09132"}
{"created":"2025-06-05","title":"Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results","abstract":"Uncertainty Quantification (UQ) in Language Models (LMs) is key to improving their safety and reliability. Evaluations often use metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). We show that mutual biases--when both UQ methods and correctness functions are biased by the same factors--systematically distort evaluation. First, we formally prove that any mutual bias non-randomly skews AUROC rankings, compromising benchmark integrity. Second, we confirm this happens empirically by testing 7 widely used correctness functions, from lexical-based and embedding-based metrics to LM-as-a-judge approaches, across 4 datasets x 4 models x 8 UQ methods. Our analysis shows that length biases in correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LM-as-a-judge methods as the least length-biased, offering a promising path for a fairer UQ evaluation.","authors":["Andrea Santilli","Adam Golinski","Michael Kirchhof","Federico Danieli","Arno Blaas","Miao Xiong","Luca Zappella","Sinead Williamson"],"url":"https://arxiv.org/abs/2504.13677"}
{"created":"2025-06-05","title":"A Survey on (M)LLM-Based GUI Agents","abstract":"Graphical User Interface (GUI) Agents have emerged as a transformative paradigm in human-computer interaction, evolving from rule-based automation scripts to sophisticated AI-driven systems capable of understanding and executing complex interface operations. This survey provides a comprehensive examination of the rapidly advancing field of LLM-based GUI Agents, systematically analyzing their architectural foundations, technical components, and evaluation methodologies. We identify and analyze four fundamental components that constitute modern GUI Agents: (1) perception systems that integrate text-based parsing with multimodal understanding for comprehensive interface comprehension; (2) exploration mechanisms that construct and maintain knowledge bases through internal modeling, historical experience, and external information retrieval; (3) planning frameworks that leverage advanced reasoning methodologies for task decomposition and execution; and (4) interaction systems that manage action generation with robust safety controls. Through rigorous analysis of these components, we reveal how recent advances in large language models and multimodal learning have revolutionized GUI automation across desktop, mobile, and web platforms. We critically examine current evaluation frameworks, highlighting methodological limitations in existing benchmarks while proposing directions for standardization. This survey also identifies key technical challenges, including accurate element localization, effective knowledge retrieval, long-horizon planning, and safety-aware execution control, while outlining promising research directions for enhancing GUI Agents' capabilities. Our systematic review provides researchers and practitioners with a thorough understanding of the field's current state and offers insights into future developments in intelligent interface automation.","authors":["Fei Tang","Haolei Xu","Hang Zhang","Siqi Chen","Xingyu Wu","Yongliang Shen","Wenqi Zhang","Guiyang Hou","Zeqi Tan","Yuchen Yan","Kaitao Song","Jian Shao","Weiming Lu","Jun Xiao","Yueting Zhuang"],"url":"https://arxiv.org/abs/2504.13865"}
{"created":"2025-06-05","title":"Hypothetical Documents or Knowledge Leakage? Rethinking LLM-based Query Expansion","abstract":"Query expansion methods powered by large language models (LLMs) have demonstrated effectiveness in zero-shot retrieval tasks. These methods assume that LLMs can generate hypothetical documents that, when incorporated into a query vector, enhance the retrieval of real evidence. However, we challenge this assumption by investigating whether knowledge leakage in benchmarks contributes to the observed performance gains. Using fact verification as a testbed, we analyze whether the generated documents contain information entailed by ground-truth evidence and assess their impact on performance. Our findings indicate that, on average, performance improvements consistently occurred for claims whose generated documents included sentences entailed by gold evidence. This suggests that knowledge leakage may be present in fact-verification benchmarks, potentially inflating the perceived performance of LLM-based query expansion methods.","authors":["Yejun Yoon","Jaeyoon Jung","Seunghyun Yoon","Kunwoo Park"],"url":"https://arxiv.org/abs/2504.14175"}
{"created":"2025-06-05","title":"Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models","abstract":"The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality, a critical driver of model performance. Current data selection methods, such as natural language quality assessments, diversity-based filters, and classifier-based approaches, are limited by single-dimensional evaluation or redundancy-focused strategies. To address these gaps, we propose four dimensions to evaluate data quality: professionalism, readability, reasoning, and cleanliness. We further introduce Meta-rater,a multi-dimensional data selection method that integrates these dimensions with existing quality metrics through learned optimal weightings. Meta-rater employs proxy models to train a regression model that predicts validation loss, enabling the identification of optimal combinations of quality scores. Experiments demonstrate that Meta-rater doubles convergence speed for 1.3B parameter models and improves downstream task performance by 3.23, with advantages that scale to models as large as 7.2B parameters. Our work establishes that holistic, multi-dimensional quality integration significantly outperforms conventional single-dimension approaches, offering a scalable paradigm for enhancing pre-training efficiency and model capability. To advance future research, we release scripts, data, and models at https://github.com/opendatalab/Meta-rater.","authors":["Xinlin Zhuang","Jiahui Peng","Ren Ma","Yinfan Wang","Tianyi Bai","Xingjian Wei","Jiantao Qiu","Chi Zhang","Ying Qian","Conghui He"],"url":"https://arxiv.org/abs/2504.14194"}
{"created":"2025-06-05","title":"Biased by Design: Leveraging AI Inherent Biases to Enhance Critical Thinking of News Readers","abstract":"This paper explores the design of a propaganda detection tool using Large Language Models (LLMs). Acknowledging the inherent biases in AI models, especially in political contexts, we investigate how these biases might be leveraged to enhance critical thinking in news consumption. Countering the typical view of AI biases as detrimental, our research proposes strategies of user choice and personalization in response to a user's political stance, applying psychological concepts of confirmation bias and cognitive dissonance. We present findings from a qualitative user study, offering insights and design recommendations (bias awareness, personalization and choice, and gradual introduction of diverse perspectives) for AI tools in propaganda detection.","authors":["Liudmila Zavolokina","Kilian Sprenkamp","Zoya Katashinskaya","Daniel Gordon Jones"],"url":"https://arxiv.org/abs/2504.14522"}
{"created":"2025-06-05","title":"Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning","abstract":"We present Skywork R1V2, a next-generation multimodal reasoning model and a major leap forward from its predecessor, Skywork R1V. At its core, R1V2 introduces a hybrid reinforcement learning paradigm that jointly leverages the Mixed Preference Optimization (MPO) and the Group Relative Policy Optimization (GRPO), which harmonizes reward-model guidance with rule-based strategies, thereby addressing the long-standing challenge of balancing sophisticated reasoning capabilities with broad generalization. To further enhance training efficiency, we propose the Selective Sample Buffer (SSB) mechanism, which effectively addresses the vanishing advantages dilemma inherent in GRPO by prioritizing high-value samples throughout the optimization process. Notably, we observe that excessive reinforcement signals can induce visual hallucinations--a phenomenon we systematically monitor and mitigate through calibrated reward thresholds throughout the training process. Empirical results affirm the exceptional capability of R1V2, with benchmark-leading performances such as 62.6 on OlympiadBench, 78.9 on AIME2024, 63.6 on LiveCodeBench, and 73.6 on MMMU. These results underscore R1V2's superiority over existing open-source models and demonstrate significant progress in closing the performance gap with premier proprietary systems, including Gemini 2.5 and OpenAI-o4-mini. The Skywork R1V2 model weights have been publicly released to promote openness and reproducibility https://huggingface.co/Skywork/Skywork-R1V2-38B.","authors":["Chris","Yichen Wei","Yi Peng","Xiaokun Wang","Weijie Qiu","Wei Shen","Tianyidan Xie","Jiangbo Pei","Jianhao Zhang","Yunzhuo Hao","Xuchen Song","Yang Liu","Yahui Zhou"],"url":"https://arxiv.org/abs/2504.16656"}
{"created":"2025-06-05","title":"CIVIL: Causal and Intuitive Visual Imitation Learning","abstract":"Today's robots learn new tasks by imitating human examples. However, this standard approach to visual imitation learning is fundamentally limited: the robot observes what the human does, but not why the human chooses those behaviors. Without understanding the features that factor into the human's decisions, robot learners often misinterpret the data and fail to perform the task when the environment changes. We therefore propose a shift in perspective: instead of asking human teachers just to show what actions the robot should take, we also enable humans to indicate task-relevant features using markers and language prompts. Our proposed algorithm, CIVIL, leverages this augmented data to filter the robot's visual observations and extract a feature representation that causally informs human actions. CIVIL then applies these causal features to train a transformer-based policy that emulates human behaviors without being confused by visual distractors. Our simulations, real-world experiments, and user study demonstrate that robots trained with CIVIL can learn from fewer human demonstrations and perform better than state-of-the-art baselines, especially in previously unseen scenarios. See videos at our project website: https://civil2025.github.io","authors":["Yinlong Dai","Robert Ramirez Sanchez","Ryan Jeronimus","Shahabedin Sagheb","Cara M. Nunez","Heramb Nemlekar","Dylan P. Losey"],"url":"https://arxiv.org/abs/2504.17959"}
{"created":"2025-06-05","title":"Nonconvex Linear System Identification with Minimal State Representation","abstract":"Low-order linear System IDentification (SysID) addresses the challenge of estimating the parameters of a linear dynamical system from finite samples of observations and control inputs with minimal state representation. Traditional approaches often utilize Hankel-rank minimization, which relies on convex relaxations that can require numerous, costly singular value decompositions (SVDs) to optimize. In this work, we propose two nonconvex reformulations to tackle low-order SysID (i) Burer-Monterio (BM) factorization of the Hankel matrix for efficient nuclear norm minimization, and (ii) optimizing directly over system parameters for real, diagonalizable systems with an atomic norm style decomposition. These reformulations circumvent the need for repeated heavy SVD computations, significantly improving computational efficiency. Moreover, we prove that optimizing directly over the system parameters yields lower statistical error rates, and lower sample complexities that do not scale linearly with trajectory length like in Hankel-nuclear norm minimization. Additionally, while our proposed formulations are nonconvex, we provide theoretical guarantees of achieving global optimality in polynomial time. Finally, we demonstrate algorithms that solve these nonconvex programs and validate our theoretical claims on synthetic data.","authors":["Uday Kiran Reddy Tadipatri","Benjamin D. Haeffele","Joshua Agterberg","Ingvar Ziemann","Ren\\'e Vidal"],"url":"https://arxiv.org/abs/2504.18791"}
{"created":"2025-06-05","title":"CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis","abstract":"Spectral imaging offers promising applications across diverse domains, including medicine and urban scene understanding, and is already established as a critical modality in remote sensing. However, variability in channel dimensionality and captured wavelengths among spectral cameras impede the development of AI-driven methodologies, leading to camera-specific models with limited generalizability and inadequate cross-camera applicability. To address this bottleneck, we introduce $\\textbf{CARL}$, a model for $\\textbf{C}$amera-$\\textbf{A}$gnostic $\\textbf{R}$epresentation $\\textbf{L}$earning across RGB, multispectral, and hyperspectral imaging modalities. To enable the conversion of a spectral image with any channel dimensionality to a camera-agnostic embedding, we introduce wavelength positional encoding and a self-attention-cross-attention mechanism to compress spectral information into learned query representations. Spectral-spatial pre-training is achieved with a novel spectral self-supervised JEPA-inspired strategy tailored to CARL. Large-scale experiments across the domains of medical imaging, autonomous driving, and satellite imaging demonstrate our model's unique robustness to spectral heterogeneity, outperforming on datasets with simulated and real-world cross-camera spectral variations. The scalability and versatility of the proposed approach position our model as a backbone for future spectral foundation models.","authors":["Alexander Baumann","Leonardo Ayala","Silvia Seidlitz","Jan Sellner","Alexander Studier-Fischer","Berkin \\\"Ozdemir","Lena Maier-Hein","Slobodan Ilic"],"url":"https://arxiv.org/abs/2504.19223"}
{"created":"2025-06-05","title":"Statistical Channel Based Low-Complexity Rotation and Position Optimization for 6D Movable Antennas Enabled Wireless Communication","abstract":"Six-dimensional movable antenna (6DMA) is a promising technology to fully exploit spatial variation in wireless channels by allowing flexible adjustment of three-dimensional (3D) positions and rotations of antennas at the transceiver. In this paper, we investigate the practical low-complexity design of 6DMA-enabled communication systems, including transmission protocol, statistical channel information (SCI) acquisition, and joint position and rotation optimization of 6DMA surfaces based on the SCI of users. Specifically, an orthogonal matching pursuit (OMP)-based algorithm is proposed for the estimation of SCI of users at all possible position-rotation pairs of 6DMA surfaces based on the channel measurements at a small subset of position-rotation pairs. Then, the average sum logarithmic rate of all users is maximized by jointly designing the positions and rotations of 6DMA surfaces based on their SCI acquired. Different from prior works on 6DMA which adopt alternating optimization to design 6DMA positions/rotations with iterations, we propose a new sequential optimization approach that first determines 6DMA rotations and then finds their feasible positions to realize the optimized rotations subject to practical antenna placement constraints. Simulation results show that the proposed sequential optimization significantly reduces the computational complexity of conventional alternating optimization, while achieving comparable communication performance. It is also shown that the proposed SCI-based 6DMA design can effectively enhance the communication throughput of wireless networks over existing fixed (position and rotation) antenna arrays, yet with a practically appealing low-complexity implementation.","authors":["Qijun Jiang","Xiaodan Shao","Rui Zhang"],"url":"https://arxiv.org/abs/2504.20618"}
{"created":"2025-06-05","title":"A Formalism for Optimal Search with Dynamic Heuristics (Extended Version)","abstract":"While most heuristics studied in heuristic search depend only on the state, some accumulate information during search and thus also depend on the search history. Various existing approaches use such dynamic heuristics in $\\mathrm{A}^*$-like algorithms and appeal to classic results for $\\mathrm{A}^*$ to show optimality. However, doing so ignores the complexities of searching with a mutable heuristic. In this paper we formalize the idea of dynamic heuristics and use them in a generic algorithm framework. We study a particular instantiation that models $\\mathrm{A}^*$ with dynamic heuristics and show general optimality results. Finally we show how existing approaches from classical planning can be viewed as special cases of this instantiation, making it possible to directly apply our optimality results.","authors":["Remo Christen","Florian Pommerening","Clemens B\\\"uchner","Malte Helmert"],"url":"https://arxiv.org/abs/2504.21131"}
{"created":"2025-06-05","title":"Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction","abstract":"This paper proposes an integrated approach for the safe and efficient control of mobile robots in dynamic and uncertain environments. The approach consists of two key steps: one-shot multimodal motion prediction to anticipate motions of dynamic obstacles and model predictive control to incorporate these predictions into the motion planning process. Motion prediction is driven by an energy-based neural network that generates high-resolution, multi-step predictions in a single operation. The prediction outcomes are further utilized to create geometric shapes formulated as mathematical constraints. Instead of treating each dynamic obstacle individually, predicted obstacles are grouped by proximity in an unsupervised way to improve performance and efficiency. The overall collision-free navigation is handled by model predictive control with a specific design for proactive dynamic obstacle avoidance. The proposed approach allows mobile robots to navigate effectively in dynamic environments. Its performance is accessed across various scenarios that represent typical warehouse settings. The results demonstrate that the proposed approach outperforms other existing dynamic obstacle avoidance methods.","authors":["Ze Zhang","Georg Hess","Junjie Hu","Emmanuel Dean","Lennart Svensson","Knut {\\AA}kesson"],"url":"https://arxiv.org/abs/2505.00237"}
{"created":"2025-06-05","title":"Towards Trustworthy Federated Learning with Untrusted Participants","abstract":"Resilience against malicious participants and data privacy are essential for trustworthy federated learning, yet achieving both with good utility typically requires the strong assumption of a trusted central server. This paper shows that a significantly weaker assumption suffices: each pair of participants shares a randomness seed unknown to others. In a setting where malicious participants may collude with an untrusted server, we propose CafCor, an algorithm that integrates robust gradient aggregation with correlated noise injection, using shared randomness between participants. We prove that CafCor achieves strong privacy-utility trade-offs, significantly outperforming local differential privacy (DP) methods, which do not make any trust assumption, while approaching central DP utility, where the server is fully trusted. Empirical results on standard benchmarks validate CafCor's practicality, showing that privacy and robustness can coexist in distributed systems without sacrificing utility or trusting the server.","authors":["Youssef Allouah","Rachid Guerraoui","John Stephan"],"url":"https://arxiv.org/abs/2505.01874"}
{"created":"2025-06-05","title":"The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence","abstract":"The origins of economic behavior remain unresolved-not only in the social sciences but also in AI, where dominant theories often rely on predefined incentives or institutional assumptions. Contrary to the longstanding myth of barter as the foundation of exchange, converging evidence from early human societies suggests that reciprocity-not barter-was the foundational economic logic, enabling communities to sustain exchange and social cohesion long before formal markets emerged. Yet despite its centrality, reciprocity lacks a simulateable and cognitively grounded account. Here, we introduce a minimal behavioral framework based on three empirically supported cognitive primitives-individual recognition, reciprocal credence, and cost--return sensitivity-that enable agents to participate in and sustain reciprocal exchange, laying the foundation for scalable economic behavior. These mechanisms scaffold the emergence of cooperation, proto-economic exchange, and institutional structure from the bottom up. By bridging insights from primatology, developmental psychology, and economic anthropology, this framework offers a unified substrate for modeling trust, coordination, and economic behavior in both human and artificial systems.","authors":["Egil Diau"],"url":"https://arxiv.org/abs/2505.02945"}
{"created":"2025-06-05","title":"LLM Code Customization with Visual Results: A Benchmark on TikZ","abstract":"With the rise of AI-based code generation, customizing existing code out of natural language instructions to modify visual results -such as figures or images -has become possible, promising to reduce the need for deep programming expertise. However, even experienced developers can struggle with this task, as it requires identifying relevant code regions (feature location), generating valid code variants, and ensuring the modifications reliably align with user intent. In this paper, we introduce vTikZ, the first benchmark designed to evaluate the ability of Large Language Models (LLMs) to customize code while preserving coherent visual outcomes. Our benchmark consists of carefully curated vTikZ editing scenarios, parameterized ground truths, and a reviewing tool that leverages visual feedback to assess correctness. Empirical evaluation with stateof-the-art LLMs shows that existing solutions struggle to reliably modify code in alignment with visual intent, highlighting a gap in current AI-assisted code editing approaches. We argue that vTikZ opens new research directions for integrating LLMs with visual feedback mechanisms to improve code customization tasks in various domains beyond TikZ, including image processing, art creation, Web design, and 3D modeling.","authors":["Charly Reux (DiverSe)","Mathieu Acher (DiverSe)","Djamel Eddine Khelladi (DiverSe)","Olivier Barais (DiverSe)","Cl\\'ement Quinton (SPIRALS)"],"url":"https://arxiv.org/abs/2505.04670"}
{"created":"2025-06-05","title":"DFPL: Decentralized Federated Prototype Learning Across Heterogeneous Data Distributions","abstract":"Federated learning is a distributed machine learning paradigm through centralized model aggregation. However, standard federated learning relies on a centralized server, making it vulnerable to server failures. While existing solutions utilize blockchain technology to implement Decentralized Federated Learning (DFL), the statistical heterogeneity of data distributions among clients severely degrades the performance of DFL. Driven by this issue, this paper proposes a decentralized federated prototype learning framework, named DFPL, which significantly improves the performance of DFL across heterogeneous data distributions. Specifically, DFPL introduces prototype learning into DFL to mitigate the impact of statistical heterogeneity and reduces the amount of parameters exchanged between clients. Additionally, blockchain is embedded into our framework, enabling the training and mining processes to be implemented locally on each client. From a theoretical perspective, we provide convergence guarantee of DFPL by modeling the resource allocation between training and mining. The experiments highlight the superiority of our DFPL framework in model performance and communication efficiency across four benchmark datasets with heterogeneous data distributions.","authors":["Hongliang Zhang","Fenghua Xu","Zhongyuan Yu","Chunqiang Hu","Shanchen Pang","Xiaofen Wang","Jiguo Yu"],"url":"https://arxiv.org/abs/2505.04947"}
{"created":"2025-06-05","title":"Flow-GRPO: Training Flow Matching Models via Online RL","abstract":"We propose Flow-GRPO, the first method integrating online reinforcement learning (RL) into flow matching models. Our approach uses two key strategies: (1) an ODE-to-SDE conversion that transforms a deterministic Ordinary Differential Equation (ODE) into an equivalent Stochastic Differential Equation (SDE) that matches the original model's marginal distribution at all timesteps, enabling statistical sampling for RL exploration; and (2) a Denoising Reduction strategy that reduces training denoising steps while retaining the original inference timestep number, significantly improving sampling efficiency without performance degradation. Empirically, Flow-GRPO is effective across multiple text-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly perfect object counts, spatial relations, and fine-grained attributes, boosting GenEval accuracy from 63% to 95%. In visual text rendering, its accuracy improves from 59% to 92%, significantly enhancing text generation. Flow-GRPO also achieves substantial gains in human preference alignment. Notably, very little reward hacking occurred, meaning rewards did not increase at the cost of appreciable image quality or diversity degradation.","authors":["Jie Liu","Gongye Liu","Jiajun Liang","Yangguang Li","Jiaheng Liu","Xintao Wang","Pengfei Wan","Di Zhang","Wanli Ouyang"],"url":"https://arxiv.org/abs/2505.05470"}
{"created":"2025-06-05","title":"Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles","abstract":"Physics-Informed Neural Networks (PINNs) have been widely used to obtain solutions to various physical phenomena modeled as Differential Equations. As PINNs are not naturally equipped with mechanisms for Uncertainty Quantification, some work has been done to quantify the different uncertainties that arise when dealing with PINNs. In this paper, we use a two-step procedure to train Bayesian Neural Networks that provide uncertainties over the solutions to differential equation systems provided by PINNs. We use available error bounds over PINNs to formulate a heteroscedastic variance that improves the uncertainty estimation. Furthermore, we solve forward problems and utilize the obtained uncertainties when doing parameter estimation in inverse problems in cosmology.","authors":["Pablo Flores","Olga Graf","Pavlos Protopapas","Karim Pichara"],"url":"https://arxiv.org/abs/2505.06459"}
{"created":"2025-06-05","title":"Digital-physical testbed for ship autonomy studies in the Marine Cybernetics Laboratory basin","abstract":"The algorithms developed for Maritime Autonomous Surface Ships (MASS) are often challenging to test on actual vessels due to high operational costs and safety considerations. Simulations offer a cost-effective alternative and eliminate risks, but they may not accurately represent real-world dynamics for the given tasks. Utilizing small-scale model ships and robotic vessels in conjunction with a laboratory basin provides an accessible testing environment for the early stages of validation processes. However, designing and developing a model vessel for a single test can be costly and cumbersome, and researchers often lack access to such infrastructure. To address these challenges and enable streamlined testing, we have developed an in-house testbed that facilitates the development, testing, verification, and validation of MASS algorithms in a digital-physical laboratory. This infrastructure includes a set of small-scale model vessels, a simulation environment for each vessel, a comprehensive testbed environment, and a digital twin in Unity. With this, we aim to establish a full design and verification pipeline that starts with high-fidelity simulation models of each model vessel, to the model-scale testing in the laboratory basin, allowing possibilities for moving towards semi-fullscale validation with R/V milliAmpere1 and full-scale validation with R/V Gunnerus. In this work, we present our progress on the development of this testbed environment and its components, demonstrating its effectiveness in enabling ship guidance, navigation, and control (GNC), including autonomy.","authors":["Emir Cem Gezer","Mael Korentin Ivan Moreau","Anders Sandneseng H{\\o}gden","Dong Trong Nguyen","Roger Skjetne","Asgeir S{\\o}rensen"],"url":"https://arxiv.org/abs/2505.06787"}
{"created":"2025-06-05","title":"Crowd Scene Analysis using Deep Learning Techniques","abstract":"Our research is focused on two main applications of crowd scene analysis crowd counting and anomaly detection In recent years a large number of researches have been presented in the domain of crowd counting We addressed two main challenges in this domain 1 Deep learning models are datahungry paradigms and always need a large amount of annotated data for the training of algorithm It is timeconsuming and costly task to annotate such large amount of data Selfsupervised training is proposed to deal with this challenge 2 MCNN consists of multicolumns of CNN with different sizes of filters by presenting a novel approach based on a combination of selfsupervised training and MultiColumn CNN This enables the model to learn features at different levels and makes it effective in dealing with challenges of occluded scenes nonuniform density complex backgrounds and scale invariation The proposed model was evaluated on publicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE and MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly detection addressing challenges like lighting environmental conditions unexpected objects and scalability The model extracts spatial and temporal features allowing it to be generalized to realworld scenes Spatial features are learned using CNN while temporal features are learned using LSTM blocks The model works on binary classification and can detect normal or abnormal behavior The models performance is improved by replacing fully connected layers with dense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset show our models outperform other stateoftheart approaches","authors":["Muhammad Junaid Asif"],"url":"https://arxiv.org/abs/2505.08834"}
{"created":"2025-06-05","title":"LEMON-Mapping: Loop-Enhanced Large-Scale Multi-Session Point Cloud Merging and Optimization for Globally Consistent Mapping","abstract":"Multi-robot collaboration is becoming increasingly critical and presents significant challenges in modern robotics, especially for building a globally consistent, accurate map. Traditional multi-robot pose graph optimization (PGO) methods ensure basic global consistency but ignore the geometric structure of the map, and only use loop closures as constraints between pose nodes, leading to divergence and blurring in overlapping regions. To address this issue, we propose LEMON-Mapping, a loop-enhanced framework for large-scale, multi-session point cloud fusion and optimization. We re-examine the role of loops for multi-robot mapping and introduce three key innovations. First, we develop a robust loop processing mechanism that rejects outliers and a loop recall strategy to recover mistakenly removed but valid loops. Second, we introduce spatial bundle adjustment for multi-robot maps, reducing divergence and eliminating blurring in overlaps. Third, we design a PGO-based approach that leverages refined bundle adjustment constraints to propagate local accuracy to the entire map. We validate LEMON-Mapping on several public datasets and a self-collected dataset. The experimental results show superior mapping accuracy and global consistency of our framework compared to traditional merging methods. Scalability experiments also demonstrate its strong capability to handle scenarios involving numerous robots.","authors":["Lijie Wang","Xiaoyi Zhong","Ziyi Xu","Kaixin Chai","Anke Zhao","Tianyu Zhao","Changjian Jiang","Qianhao Wang","Fei Gao"],"url":"https://arxiv.org/abs/2505.10018"}
{"created":"2025-06-05","title":"Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization","abstract":"Federated domain generalization aims to learn a generalizable model from multiple decentralized source domains for deploying on the unseen target domain. The style augmentation methods have achieved great progress on domain generalization. However, the existing style augmentation methods either explore the data styles within isolated source domain or interpolate the style information across existing source domains under the data decentralization scenario, which leads to limited style space. To address this issue, we propose a Multi-source Collaborative Style Augmentation and Domain-invariant learning method (MCSAD) for federated domain generalization. Specifically, we propose a multi-source collaborative style augmentation module to generate data in the broader style space. Furthermore, we conduct domain-invariant learning between the original data and augmented data by cross-domain feature alignment within the same class and classes relation ensemble distillation between different classes to learn a domain-invariant model. By alternatively conducting collaborative style augmentation and domain-invariant learning, the model can generalize well on unseen target domain. Extensive experiments on multiple domain generalization datasets indicate that our method significantly outperforms the state-of-the-art federated domain generalization methods.","authors":["Yikang Wei"],"url":"https://arxiv.org/abs/2505.10152"}
{"created":"2025-06-05","title":"FactsR: A Safer Method for Producing High Quality Healthcare Documentation","abstract":"There are now a multitude of AI-scribing solutions for healthcare promising the utilization of large language models for ambient documentation. However, these AI scribes still rely on one-shot, or few-shot prompts for generating notes after the consultation has ended, employing little to no reasoning. This risks long notes with an increase in hallucinations, misrepresentation of the intent of the clinician, and reliance on the proofreading of the clinician to catch errors. A dangerous combination for patient safety if vigilance is compromised by workload and fatigue. In this paper, we introduce a method for extracting salient clinical information in real-time alongside the healthcare consultation, denoted Facts, and use that information recursively to generate the final note. The FactsR method results in more accurate and concise notes by placing the clinician-in-the-loop of note generation, while opening up new use cases within real-time decision support.","authors":["Victor Petr\\'en Bach Hansen","Lasse Krogsb{\\o}ll","Jonas Lyngs{\\o}","Mathias Baltzersen","Andreas Motzfeldt","Kevin Pelgrims","Lars Maal{\\o}e"],"url":"https://arxiv.org/abs/2505.10360"}
{"created":"2025-06-05","title":"Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory","abstract":"Recently, scaling test-time compute on Large Language Models (LLM) has garnered wide attention. However, there has been limited investigation of how various reasoning prompting strategies perform as scaling. In this paper, we focus on a standard and realistic scaling setting: majority voting. We systematically conduct experiments on 6 LLMs $\\times$ 8 prompting strategies $\\times$ 6 benchmarks. Experiment results consistently show that as the sampling time and computational overhead increase, complicated prompting strategies with superior initial performance gradually fall behind simple Chain-of-Thought. We analyze this phenomenon and provide theoretical proofs. Additionally, we propose a probabilistic method to efficiently predict scaling performance and identify the best prompting strategy under large sampling times, eliminating the need for resource-intensive inference processes in practical applications. Furthermore, we introduce two ways derived from our theoretical analysis to significantly improve the scaling performance. We hope that our research can promote to re-examine the role of complicated prompting, unleash the potential of simple prompting strategies, and provide new insights for enhancing test-time scaling performance. Code is available at https://github.com/MraDonkey/rethinking_prompting.","authors":["Yexiang Liu","Zekun Li","Zhi Fang","Nan Xu","Ran He","Tieniu Tan"],"url":"https://arxiv.org/abs/2505.10981"}
{"created":"2025-06-05","title":"Is Compression Really Linear with Code Intelligence?","abstract":"Understanding the relationship between data compression and the capabilities of Large Language Models (LLMs) is crucial, especially in specialized domains like code intelligence. Prior work posited a linear relationship between compression and general intelligence. However, it overlooked the multifaceted nature of code that encompasses diverse programming languages and tasks, and struggled with fair evaluation of modern Code LLMs. We address this by evaluating a diverse array of open-source Code LLMs on comprehensive multi-language, multi-task code benchmarks. To address the challenge of efficient and fair evaluation of pre-trained LLMs' code intelligence, we introduce \\textit{Format Annealing}, a lightweight, transparent training methodology designed to assess the intrinsic capabilities of these pre-trained models equitably. Compression efficacy, measured as bits-per-character (BPC), is determined using a novel, large-scale, and previously unseen code validation set derived from GitHub. Our empirical results reveal a fundamental logarithmic relationship between measured code intelligence and BPC. This finding refines prior hypotheses of linearity, which we suggest are likely observations of the logarithmic curve's tail under specific, limited conditions. Our work provides a more nuanced understanding of compression's role in developing code intelligence and contributes a robust evaluation framework in the code domain.","authors":["Xianzhen Luo","Shijie Xuyang","Tianhao Cheng","Zheng Chu","Houyi Li","ziqi wang","Siming Huang","Qingfu Zhu","Qiufeng Wang","Xiangyu Zhang","Shuigeng Zhou","Wanxiang Che"],"url":"https://arxiv.org/abs/2505.11441"}
{"created":"2025-06-05","title":"THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering","abstract":"We propose THELMA (Task Based Holistic Evaluation of Large Language Model Applications), a reference free framework for RAG (Retrieval Augmented generation) based question answering (QA) applications. THELMA consist of six interdependent metrics specifically designed for holistic, fine grained evaluation of RAG QA applications. THELMA framework helps developers and application owners evaluate, monitor and improve end to end RAG QA pipelines without requiring labelled sources or reference responses.We also present our findings on the interplay of the proposed THELMA metrics, which can be interpreted to identify the specific RAG component needing improvement in QA applications.","authors":["Udita Patel","Rutu Mulkar","Jay Roberts","Cibi Chakravarthy Senthilkumar","Sujay Gandhi","Xiaofei Zheng","Naumaan Nayyar","Parul Kalra","Rafael Castrillo"],"url":"https://arxiv.org/abs/2505.11626"}
{"created":"2025-06-05","title":"Exploring Sparsity for Parameter Efficient Fine Tuning Using Wavelets","abstract":"Efficiently adapting large foundation models is critical, especially with tight compute and memory budgets. Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA offer limited granularity and effectiveness in few-parameter regimes. We propose Wavelet Fine-Tuning (WaveFT), a novel PEFT method that learns highly sparse updates in the wavelet domain of residual matrices. WaveFT allows precise control of trainable parameters, offering fine-grained capacity adjustment and excelling with remarkably low parameter count, potentially far fewer than LoRA's minimum, ideal for extreme parameter-efficient scenarios. Evaluated on personalized text-to-image generation using Stable Diffusion XL as baseline, WaveFT significantly outperforms LoRA and other PEFT methods, especially at low parameter counts; achieving superior subject fidelity, prompt alignment, and image diversity.","authors":["Ahmet Bilican","M. Ak{\\i}n Y{\\i}lmaz","A. Murat Tekalp","R. G\\\"okberk Cinbi\\c{s}"],"url":"https://arxiv.org/abs/2505.12532"}
{"created":"2025-06-05","title":"HyperDet: Source Detection in Hypergraphs via Interactive Relationship Construction and Feature-rich Attention Fusion","abstract":"Hypergraphs offer superior modeling capabilities for social networks, particularly in capturing group phenomena that extend beyond pairwise interactions in rumor propagation. Existing approaches in rumor source detection predominantly focus on dyadic interactions, which inadequately address the complexity of more intricate relational structures. In this study, we present a novel approach for Source Detection in Hypergraphs (HyperDet) via Interactive Relationship Construction and Feature-rich Attention Fusion. Specifically, our methodology employs an Interactive Relationship Construction module to accurately model both the static topology and dynamic interactions among users, followed by the Feature-rich Attention Fusion module, which autonomously learns node features and discriminates between nodes using a self-attention mechanism, thereby effectively learning node representations under the framework of accurately modeled higher-order relationships. Extensive experimental validation confirms the efficacy of our HyperDet approach, showcasing its superiority relative to current state-of-the-art methods.","authors":["Le Cheng","Peican Zhu","Yangming Guo","Keke Tang","Chao Gao","Zhen Wang"],"url":"https://arxiv.org/abs/2505.12894"}
{"created":"2025-06-05","title":"SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs","abstract":"Source detection on graphs has demonstrated high efficacy in identifying rumor origins. Despite advances in machine learning-based methods, many fail to capture intrinsic dynamics of rumor propagation. In this work, we present SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs, which harnesses the recent success of the state space model Mamba, known for its superior global modeling capabilities and computational efficiency, to address this challenge. Specifically, we first employ hypergraphs to model high-order interactions within social networks. Subsequently, temporal network snapshots generated during the propagation process are sequentially fed in reverse order into Mamba to infer underlying propagation dynamics. Finally, to empower the sequential model to effectively capture propagation patterns while integrating structural information, we propose a novel graph-aware state update mechanism, wherein the state of each node is propagated and refined by both temporal dependencies and topological context. Extensive evaluations on eight datasets demonstrate that SourceDetMamba consistently outperforms state-of-the-art approaches.","authors":["Le Cheng","Peican Zhu","Yangming Guo","Chao Gao","Zhen Wang","Keke Tang"],"url":"https://arxiv.org/abs/2505.12910"}
{"created":"2025-06-05","title":"Algorithmic Tradeoffs in Fair Lending: Profitability, Compliance, and Long-Term Impact","abstract":"As financial institutions increasingly rely on machine learning models to automate lending decisions, concerns about algorithmic fairness have risen. This paper explores the tradeoff between enforcing fairness constraints (such as demographic parity or equal opportunity) and maximizing lender profitability. Through simulations on synthetic data that reflects real-world lending patterns, we quantify how different fairness interventions impact profit margins and default rates. Our results demonstrate that equal opportunity constraints typically impose lower profit costs than demographic parity, but surprisingly, removing protected attributes from the model (fairness through unawareness) outperforms explicit fairness interventions in both fairness and profitability metrics. We further identify the specific economic conditions under which fair lending becomes profitable and analyze the feature-specific drivers of unfairness. These findings offer practical guidance for designing lending algorithms that balance ethical considerations with business objectives.","authors":["Aayam Bansal"],"url":"https://arxiv.org/abs/2505.13469"}
{"created":"2025-06-05","title":"ReactDiff: Latent Diffusion for Facial Reaction Generation","abstract":"Given the audio-visual clip of the speaker, facial reaction generation aims to predict the listener's facial reactions. The challenge lies in capturing the relevance between video and audio while balancing appropriateness, realism, and diversity. While prior works have mostly focused on uni-modal inputs or simplified reaction mappings, recent approaches such as PerFRDiff have explored multi-modal inputs and the one-to-many nature of appropriate reaction mappings. In this work, we propose the Facial Reaction Diffusion (ReactDiff) framework that uniquely integrates a Multi-Modality Transformer with conditional diffusion in the latent space for enhanced reaction generation. Unlike existing methods, ReactDiff leverages intra- and inter-class attention for fine-grained multi-modal interaction, while the latent diffusion process between the encoder and decoder enables diverse yet contextually appropriate outputs. Experimental results demonstrate that ReactDiff significantly outperforms existing approaches, achieving a facial reaction correlation of 0.26 and diversity score of 0.094 while maintaining competitive realism. The code is open-sourced at \\href{https://github.com/Hunan-Tiger/ReactDiff}{github}.","authors":["Jiaming Li","Sheng Wang","Xin Wang","Yitao Zhu","Honglin Xiong","Zixu Zhuang","Qian Wang"],"url":"https://arxiv.org/abs/2505.14151"}
{"created":"2025-06-05","title":"PAST: Phonetic-Acoustic Speech Tokenizer","abstract":"We present PAST, a novel end-to-end framework that jointly models phonetic information alongside signal reconstruction, eliminating the need for external pretrained models. Unlike previous approaches that rely on pretrained self-supervised models, PAST employs supervised phonetic data, directly integrating domain knowledge into the tokenization process via auxiliary tasks. Additionally, we introduce a streamable, causal variant of PAST, enabling real-time speech applications. Results demonstrate that PAST surpasses existing evaluated baseline tokenizers across common evaluation metrics, including phonetic representation and speech reconstruction. Notably, PAST also achieves superior performance when serving as a speech representation for speech language models, further highlighting its effectiveness as a foundation for spoken language generation. To foster further research, we release the full implementation. For code, model checkpoints, and samples see: https://pages.cs.huji.ac.il/adiyoss-lab/PAST","authors":["Nadav Har-Tuv","Or Tal","Yossi Adi"],"url":"https://arxiv.org/abs/2505.14470"}
{"created":"2025-06-05","title":"MCIP: Protecting MCP Safety via Model Contextual Integrity Protocol","abstract":"As Model Context Protocol (MCP) introduces an easy-to-use ecosystem for users and developers, it also brings underexplored safety risks. Its decentralized architecture, which separates clients and servers, poses unique challenges for systematic safety analysis. This paper proposes a novel framework to enhance MCP safety. Guided by the MAESTRO framework, we first analyze the missing safety mechanisms in MCP, and based on this analysis, we propose the Model Contextual Integrity Protocol (MCIP), a refined version of MCP that addresses these gaps. Next, we develop a fine-grained taxonomy that captures a diverse range of unsafe behaviors observed in MCP scenarios. Building on this taxonomy, we develop benchmark and training data that support the evaluation and improvement of LLMs' capabilities in identifying safety risks within MCP interactions. Leveraging the proposed benchmark and training data, we conduct extensive experiments on state-of-the-art LLMs. The results highlight LLMs' vulnerabilities in MCP interactions and demonstrate that our approach substantially improves their safety performance.","authors":["Huihao Jing","Haoran Li","Wenbin Hu","Qi Hu","Heli Xu","Tianshu Chu","Peizhao Hu","Yangqiu Song"],"url":"https://arxiv.org/abs/2505.14590"}
{"created":"2025-06-05","title":"Virtual Cells: Predict, Explain, Discover","abstract":"Drug discovery is fundamentally a process of inferring the effects of treatments on patients, and would therefore benefit immensely from computational models that can reliably simulate patient responses, enabling researchers to generate and test large numbers of therapeutic hypotheses safely and economically before initiating costly clinical trials. Even a more specific model that predicts the functional response of cells to a wide range of perturbations would be tremendously valuable for discovering safe and effective treatments that successfully translate to the clinic. Creating such virtual cells has long been a goal of the computational research community that unfortunately remains unachieved given the daunting complexity and scale of cellular biology. Nevertheless, recent advances in AI, computing power, lab automation, and high-throughput cellular profiling provide new opportunities for reaching this goal. In this perspective, we present a vision for developing and evaluating virtual cells that builds on our experience at Recursion. We argue that in order to be a useful tool to discover novel biology, virtual cells must accurately predict the functional response of a cell to perturbations and explain how the predicted response is a consequence of modifications to key biomolecular interactions. We then introduce key principles for designing therapeutically-relevant virtual cells, describe a lab-in-the-loop approach for generating novel insights with them, and advocate for biologically-grounded benchmarks to guide virtual cell development. Finally, we make the case that our approach to virtual cells provides a useful framework for building other models at higher levels of organization, including virtual patients. We hope that these directions prove useful to the research community in developing virtual models optimized for positive impact on drug discovery outcomes.","authors":["Emmanuel Noutahi","Jason Hartford","Prudencio Tossou","Shawn Whitfield","Alisandra K. Denton","Cas Wognum","Kristina Ulicna","Michael Craig","Jonathan Hsu","Michael Cuccarese","Emmanuel Bengio","Dominique Beaini","Christopher Gibson","Daniel Cohen","Berton Earnshaw"],"url":"https://arxiv.org/abs/2505.14613"}
{"created":"2025-06-05","title":"Polar Sparsity: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity","abstract":"Accelerating large language model (LLM) inference is critical for real-world deployments requiring high throughput and low latency. Contextual sparsity, where each token dynamically activates only a small subset of the model parameters, shows promise but does not scale to large batch sizes due to union of active neurons quickly approaching dense computation. We introduce Polar Sparsity, highlighting a key shift in sparsity importance from MLP to Attention layers as we scale batch size and sequence length. While MLP layers become more compute-efficient under batching, their sparsity vanishes. In contrast, attention becomes increasingly more expensive at scale, while their head sparsity remains stable and batch-invariant. We develop hardware-efficient, sparsity-aware GPU kernels for selective MLP and Attention computations, delivering up to \\(2.2\\times\\) end-to-end speedups for models like OPT, LLaMA-2 \\& 3, across various batch sizes and sequence lengths without compromising accuracy. To our knowledge, this is the first work to demonstrate that contextual sparsity can scale effectively to large batch sizes, delivering substantial inference acceleration with minimal changes, making Polar Sparsity practical for large-scale, high-throughput LLM deployment systems. Our code is available at: https://github.com/susavlsh10/Polar-Sparsity.","authors":["Susav Shrestha","Brad Settlemyer","Nikoli Dryden","Narasimha Reddy"],"url":"https://arxiv.org/abs/2505.14884"}
{"created":"2025-06-05","title":"Owicki--Gries Logic for Timestamp Semantics","abstract":"Whereas an extension with non-interference of Hoare logic for sequential programs Owicki--Gries logic ensures the correctness of concurrent programs on strict consistency, it is unsound to weak memory models adopted by modern computer architectures and specifications of programming languages. This paper proposes a novel non-interference notion and provides concurrent program logic sound to timestamp semantics corresponding to a weak memory model that allows delays in the effects of store instructions. This paper reports three theoretically interesting techniques for modifying non-interference to support delays in the effects of store instructions. The techniques contribute to a better understanding of constructing concurrent program logic.","authors":["Tatsuya Abe"],"url":"https://arxiv.org/abs/2505.15053"}
{"created":"2025-06-05","title":"SEM: Enhancing Spatial Understanding for Robust Robot Manipulation","abstract":"A key challenge in robot manipulation lies in developing policy models with strong spatial understanding, the ability to reason about 3D geometry, object relations, and robot embodiment. Existing methods often fall short: 3D point cloud models lack semantic abstraction, while 2D image encoders struggle with spatial reasoning. To address this, we propose SEM (Spatial Enhanced Manipulation model), a novel diffusion-based policy framework that explicitly enhances spatial understanding from two complementary perspectives. A spatial enhancer augments visual representations with 3D geometric context, while a robot state encoder captures embodiment-aware structure through graphbased modeling of joint dependencies. By integrating these modules, SEM significantly improves spatial understanding, leading to robust and generalizable manipulation across diverse tasks that outperform existing baselines.","authors":["Xuewu Lin","Tianwei Lin","Lichao Huang","Hongyu Xie","Yiwei Jin","Keyu Li","Zhizhong Su"],"url":"https://arxiv.org/abs/2505.16196"}
{"created":"2025-06-05","title":"Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning","abstract":"The rapid spread of multimodal misinformation on social media has raised growing concerns, while research on video misinformation detection remains limited due to the lack of large-scale, diverse datasets. Existing methods often overfit to rigid templates and lack deep reasoning over deceptive content. To address these challenges, we introduce FakeVV, a large-scale benchmark comprising over 100,000 video-text pairs with fine-grained, interpretable annotations. In addition, we further propose Fact-R1, a novel framework that integrates deep reasoning with collaborative rule-based reinforcement learning. Fact-R1 is trained through a three-stage process: (1) misinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference alignment via Direct Preference Optimization (DPO), and (3) Group Relative Policy Optimization (GRPO) using a novel verifiable reward function. This enables Fact-R1 to exhibit emergent reasoning behaviors comparable to those observed in advanced text-based reinforcement learning systems, but in the more complex multimodal misinformation setting. Our work establishes a new paradigm for misinformation detection, bridging large-scale video understanding, reasoning-guided alignment, and interpretable verification.","authors":["Fanrui Zhang","Dian Li","Qiang Zhang","Chenjun","sinbadliu","Junxiong Lin","Jiahong Yan","Jiawei Liu","Zheng-Jun Zha"],"url":"https://arxiv.org/abs/2505.16836"}
{"created":"2025-06-05","title":"LARES: Latent Reasoning for Sequential Recommendation","abstract":"Sequential recommender systems have become increasingly important in real-world applications that model user behavior sequences to predict their preferences. However, existing sequential recommendation methods predominantly rely on non-reasoning paradigms, which may limit the model's computational capacity and result in suboptimal recommendation performance. To address these limitations, we present LARES, a novel and scalable LAtent REasoning framework for Sequential recommendation that enhances model's representation capabilities through increasing the computation density of parameters by depth-recurrent latent reasoning. Our proposed approach employs a recurrent architecture that allows flexible expansion of reasoning depth without increasing parameter complexity, thereby effectively capturing dynamic and intricate user interest patterns. A key difference of LARES lies in refining all input tokens at each implicit reasoning step to improve the computation utilization. To fully unlock the model's reasoning potential, we design a two-phase training strategy: (1) Self-supervised pre-training (SPT) with dual alignment objectives; (2) Reinforcement post-training (RPT). During the first phase, we introduce trajectory-level alignment and step-level alignment objectives, which enable the model to learn recommendation-oriented latent reasoning patterns without requiring supplementary annotated data. The subsequent phase utilizes reinforcement learning (RL) to harness the model's exploratory ability, further refining its reasoning capabilities. Comprehensive experiments on real-world benchmarks demonstrate our framework's superior performance. Notably, LARES exhibits seamless compatibility with existing advanced models, further improving their recommendation performance. Our code is available at https://anonymous.4open.science/r/LARES-E458/.","authors":["Enze Liu","Bowen Zheng","Xiaolei Wang","Wayne Xin Zhao","Jinpeng Wang","Sheng Chen","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.16865"}
{"created":"2025-06-05","title":"LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning","abstract":"In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large Language Model (MLLM) that integrates visual instruction tuning with masked diffusion models, representing a departure from the autoregressive paradigms dominant in current multimodal approaches. Built upon LLaDA, a representative large language diffusion model, LLaDA-V incorporates a vision encoder and MLP connector that projects visual features into the language embedding space, enabling effective multimodal alignment. Our empirical investigation reveals several intriguing results: First, LLaDA-V demonstrates promising multimodal performance despite its language model being weaker on purely textual tasks than counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same instruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal tasks with better data scalability. It also narrows the performance gap to Qwen2-VL, suggesting the effectiveness of its architecture for multimodal tasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal understanding compared to existing hybrid autoregressive-diffusion and purely diffusion-based MLLMs. Our findings suggest that large language diffusion models show promise in multimodal contexts and warrant further investigation in future research. Project page and codes: https://ml-gsai.github.io/LLaDA-V-demo/.","authors":["Zebin You","Shen Nie","Xiaolu Zhang","Jun Hu","Jun Zhou","Zhiwu Lu","Ji-Rong Wen","Chongxuan Li"],"url":"https://arxiv.org/abs/2505.16933"}
{"created":"2025-06-05","title":"Secure and Private Federated Learning: Achieving Adversarial Resilience through Robust Aggregation","abstract":"Federated Learning (FL) enables collaborative machine learning across decentralized data sources without sharing raw data. It offers a promising approach to privacy-preserving AI. However, FL remains vulnerable to adversarial threats from malicious participants, referred to as Byzantine clients, who can send misleading updates to corrupt the global model. Traditional aggregation methods, such as simple averaging, are not robust to such attacks. More resilient approaches, like the Krum algorithm, require prior knowledge of the number of malicious clients, which is often unavailable in real-world scenarios. To address these limitations, we propose Average-rKrum (ArKrum), a novel aggregation strategy designed to enhance both the resilience and privacy guarantees of FL systems. Building on our previous work (rKrum), ArKrum introduces two key innovations. First, it includes a median-based filtering mechanism that removes extreme outliers before estimating the number of adversarial clients. Second, it applies a multi-update averaging scheme to improve stability and performance, particularly when client data distributions are not identical. We evaluate ArKrum on benchmark image and text datasets under three widely studied Byzantine attack types. Results show that ArKrum consistently achieves high accuracy and stability. It performs as well as or better than other robust aggregation methods. These findings demonstrate that ArKrum is an effective and practical solution for secure FL systems in adversarial environments.","authors":["Kun Yang","Neena Imam"],"url":"https://arxiv.org/abs/2505.17226"}
{"created":"2025-06-05","title":"T$^2$: An Adaptive Test-Time Scaling Strategy for Contextual Question Answering","abstract":"Recent advances in Large Language Models (LLMs) have demonstrated remarkable performance in Contextual Question Answering (CQA). However, prior approaches typically employ elaborate reasoning strategies regardless of question complexity, leading to low adaptability. Recent efficient test-time scaling methods introduce budget constraints or early stop mechanisms to avoid overthinking for straightforward questions. But they add human bias to the reasoning process and fail to leverage models' inherent reasoning capabilities. To address these limitations, we present T$^2$: Think-to-Think, a novel framework that dynamically adapts reasoning depth based on question complexity. T$^2$ leverages the insight that if an LLM can effectively solve similar questions using specific reasoning strategies, it can apply the same strategy to the original question. This insight enables to adoption of concise reasoning for straightforward questions while maintaining detailed analysis for complex problems. T$^2$ works through four key steps: decomposing questions into structural elements, generating similar examples with candidate reasoning strategies, evaluating these strategies against multiple criteria, and applying the most appropriate strategy to the original question. Experimental evaluation across seven diverse CQA benchmarks demonstrates that T$^2$ not only achieves higher accuracy than baseline methods but also reduces computational overhead by up to 25.2\\%.","authors":["Zhengyi Zhao","Shubo Zhang","Zezhong Wang","Huimin Wang","Yutian Zhao","Bin Liang","Yefeng Zheng","Binyang Li","Kam-Fai Wong","Xian Wu"],"url":"https://arxiv.org/abs/2505.17427"}
{"created":"2025-06-05","title":"MemeReaCon: Probing Contextual Meme Understanding in Large Vision-Language Models","abstract":"Memes have emerged as a popular form of multimodal online communication, where their interpretation heavily depends on the specific context in which they appear. Current approaches predominantly focus on isolated meme analysis, either for harmful content detection or standalone interpretation, overlooking a fundamental challenge: the same meme can express different intents depending on its conversational context. This oversight creates an evaluation gap: although humans intuitively recognize how context shapes meme interpretation, Large Vision Language Models (LVLMs) can hardly understand context-dependent meme intent. To address this critical limitation, we introduce MemeReaCon, a novel benchmark specifically designed to evaluate how LVLMs understand memes in their original context. We collected memes from five different Reddit communities, keeping each meme's image, the post text, and user comments together. We carefully labeled how the text and meme work together, what the poster intended, how the meme is structured, and how the community responded. Our tests with leading LVLMs show a clear weakness: models either fail to interpret critical information in the contexts, or overly focus on visual details while overlooking communicative purpose. MemeReaCon thus serves both as a diagnostic tool exposing current limitations and as a challenging benchmark to drive development toward more sophisticated LVLMs of the context-aware understanding.","authors":["Zhengyi Zhao","Shubo Zhang","Yuxi Zhang","Yanxi Zhao","Yifan Zhang","Zezhong Wang","Huimin Wang","Yutian Zhao","Bin Liang","Yefeng Zheng","Binyang Li","Kam-Fai Wong","Xian Wu"],"url":"https://arxiv.org/abs/2505.17433"}
{"created":"2025-06-05","title":"VISTA: Vision-Language Inference for Training-Free Stock Time-Series Analysis","abstract":"Stock price prediction remains a complex and high-stakes task in financial analysis, traditionally addressed using statistical models or, more recently, language models. In this work, we introduce VISTA (Vision-Language Inference for Stock Time-series Analysis), a novel, training-free framework that leverages Vision-Language Models (VLMs) for multi-modal stock forecasting. VISTA prompts a VLM with both textual representations of historical stock prices and their corresponding line charts to predict future price values. By combining numerical and visual modalities in a zero-shot setting and using carefully designed chain-of-thought prompts, VISTA captures complementary patterns that unimodal approaches often miss. We benchmark VISTA against standard baselines, including ARIMA and text-only LLM-based prompting methods. Experimental results show that VISTA outperforms these baselines by up to 89.83%, demonstrating the effectiveness of multi-modal inference for stock time-series analysis and highlighting the potential of VLMs in financial forecasting tasks without requiring task-specific training.","authors":["Tina Khezresmaeilzadeh","Parsa Razmara","Seyedarmin Azizi","Mohammad Erfan Sadeghi","Erfan Baghaei Potraghloo"],"url":"https://arxiv.org/abs/2505.18570"}
{"created":"2025-06-05","title":"Assistant-Guided Mitigation of Teacher Preference Bias in LLM-as-a-Judge","abstract":"LLM-as-a-Judge employs large language models (LLMs), such as GPT-4, to evaluate the quality of LLM-generated responses, gaining popularity for its cost-effectiveness and strong alignment with human evaluations. However, training proxy judge models using evaluation data generated by powerful teacher models introduces a critical yet previously overlooked issue: teacher preference bias, where the proxy judge model learns a biased preference for responses from the teacher model. To tackle this problem, we propose a novel setting that incorporates an additional assistant model, which is not biased toward the teacher model's responses, to complement the training data. Building on this setup, we introduce AGDe-Judge, a three-stage framework designed to debias from both the labels and feedbacks in the training data. Extensive experiments demonstrate that AGDe-Judge effectively reduces teacher preference bias while maintaining strong performance across six evaluation benchmarks. Code is available at https://github.com/Liuz233/AGDe-Judge.","authors":["Zhuo Liu","Moxin Li","Xun Deng","Qifan Wang","Fuli Feng"],"url":"https://arxiv.org/abs/2505.19176"}
{"created":"2025-06-05","title":"SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond","abstract":"Recent advances such as OpenAI-o1 and DeepSeek R1 have demonstrated the potential of Reinforcement Learning (RL) to enhance reasoning abilities in Large Language Models (LLMs). While open-source replication efforts have primarily focused on mathematical and coding domains, methods and resources for developing general reasoning capabilities remain underexplored. This gap is partly due to the challenge of collecting diverse and verifiable reasoning data suitable for RL. We hypothesize that logical reasoning is critical for developing general reasoning capabilities, as logic forms a fundamental building block of reasoning. In this work, we present SynLogic, a data synthesis framework and dataset that generates diverse logical reasoning data at scale, encompassing 35 diverse logical reasoning tasks. The SynLogic approach enables controlled synthesis of data with adjustable difficulty and quantity. Importantly, all examples can be verified by simple rules, making them ideally suited for RL with verifiable rewards. In our experiments, we validate the effectiveness of RL training on the SynLogic dataset based on 7B and 32B models. SynLogic leads to state-of-the-art logical reasoning performance among open-source datasets, surpassing DeepSeek-R1-Distill-Qwen-32B by 6 points on BBEH. Furthermore, mixing SynLogic data with mathematical and coding tasks improves the training efficiency of these domains and significantly enhances reasoning generalization. Notably, our mixed training model outperforms DeepSeek-R1-Zero-Qwen-32B across multiple benchmarks. These findings position SynLogic as a valuable resource for advancing the broader reasoning capabilities of LLMs. We open-source both the data synthesis pipeline and the SynLogic dataset at https://github.com/MiniMax-AI/SynLogic.","authors":["Junteng Liu","Yuanxiang Fan","Zhuo Jiang","Han Ding","Yongyi Hu","Chi Zhang","Yiqi Shi","Shitong Weng","Aili Chen","Shiqi Chen","Yunan Huang","Mozhi Zhang","Pengyu Zhao","Junjie Yan","Junxian He"],"url":"https://arxiv.org/abs/2505.19641"}
{"created":"2025-06-05","title":"EgoZero: Robot Learning from Smart Glasses","abstract":"Despite recent progress in general purpose robotics, robot policies still lag far behind basic human capabilities in the real world. Humans interact constantly with the physical world, yet this rich data resource remains largely untapped in robot learning. We propose EgoZero, a minimal system that learns robust manipulation policies from human demonstrations captured with Project Aria smart glasses, $\\textbf{and zero robot data}$. EgoZero enables: (1) extraction of complete, robot-executable actions from in-the-wild, egocentric, human demonstrations, (2) compression of human visual observations into morphology-agnostic state representations, and (3) closed-loop policy learning that generalizes morphologically, spatially, and semantically. We deploy EgoZero policies on a gripper Franka Panda robot and demonstrate zero-shot transfer with 70% success rate over 7 manipulation tasks and only 20 minutes of data collection per task. Our results suggest that in-the-wild human data can serve as a scalable foundation for real-world robot learning - paving the way toward a future of abundant, diverse, and naturalistic training data for robots. Code and videos are available at https://egozero-robot.github.io.","authors":["Vincent Liu","Ademi Adeniji","Haotian Zhan","Siddhant Haldar","Raunaq Bhirangi","Pieter Abbeel","Lerrel Pinto"],"url":"https://arxiv.org/abs/2505.20290"}
{"created":"2025-06-05","title":"AstroVisBench: A Code Benchmark for Scientific Computing and Visualization in Astronomy","abstract":"Large Language Models (LLMs) are being explored for applications in scientific research, including their capabilities to synthesize literature, answer research questions, generate research ideas, and even conduct computational experiments. Ultimately, our goal is for these to help scientists derive novel scientific insights. In many areas of science, such insights often arise from processing and visualizing data to understand its patterns. However, evaluating whether an LLM-mediated scientific workflow produces outputs conveying the correct scientific insights is challenging to evaluate and has not been addressed in past work. We introduce AstroVisBench, the first benchmark for both scientific computing and visualization in the astronomy domain. AstroVisBench judges a language model's ability to both (1) create astronomy-specific workflows to process and analyze data and (2) visualize the results of these workflows through complex plots. Our evaluation of visualizations uses a novel LLM-as-a-judge workflow, which is validated against annotation by five professional astronomers. Using AstroVisBench we present an evaluation of state-of-the-art language models, showing a significant gap in their ability to engage in astronomy research as useful assistants. This evaluation provides a strong end-to-end evaluation for AI scientists that offers a path forward for the development of visualization-based workflows, which are central to a broad range of domains from physics to biology.","authors":["Sebastian Antony Joseph","Syed Murtaza Husain","Stella S. R. Offner","St\\'ephanie Juneau","Paul Torrey","Adam S. Bolton","Juan P. Farias","Niall Gaffney","Greg Durrett","Junyi Jessy Li"],"url":"https://arxiv.org/abs/2505.20538"}
{"created":"2025-06-05","title":"Collision- and Reachability-Aware Multi-Robot Control with Grounded LLM Planners","abstract":"Large language models (LLMs) have demonstrated strong performance in various robot control tasks. However, their deployment in real-world applications remains constrained. Even state-ofthe-art LLMs, such as GPT-o4mini, frequently produce invalid action plans that violate physical constraints, such as directing a robot to an unreachable location or causing collisions between robots. This issue primarily arises from a lack of awareness of these physical constraints during the reasoning process. To address this issue, we propose a novel framework that integrates reinforcement learning with verifiable rewards (RLVR) to incentivize knowledge of physical constraints into LLMs to induce constraints-aware reasoning during plan generation. In this approach, only valid action plans that successfully complete a control task receive positive rewards. We applied our method to two small-scale LLMs: a non-reasoning Qwen2.5-3B-Instruct and a reasoning Qwen3-4B. The experiment results demonstrate that constraint-aware small LLMs largely outperform large-scale models without constraints, grounded on both the BoxNet task and a newly developed BoxNet3D environment built using MuJoCo. This work highlights the effectiveness of grounding even small LLMs with physical constraints to enable scalable and efficient multi-robot control in complex, physically constrained environments.","authors":["Jiabao Ji","Yongchao Chen","Yang Zhang","Ramana Rao Kompella","Chuchu Fan","Gaowen Liu","Shiyu Chang"],"url":"https://arxiv.org/abs/2505.20573"}
{"created":"2025-06-05","title":"STEER-BENCH: A Benchmark for Evaluating the Steerability of Large Language Models","abstract":"Steerability, or the ability of large language models (LLMs) to adapt outputs to align with diverse community-specific norms, perspectives, and communication styles, is critical for real-world applications but remains under-evaluated. We introduce Steer-Bench, a benchmark for assessing population-specific steering using contrasting Reddit communities. Covering 30 contrasting subreddit pairs across 19 domains, Steer-Bench includes over 10,000 instruction-response pairs and validated 5,500 multiple-choice question with corresponding silver labels to test alignment with diverse community norms. Our evaluation of 13 popular LLMs using Steer-Bench reveals that while human experts achieve an accuracy of 81% with silver labels, the best-performing models reach only around 65% accuracy depending on the domain and configuration. Some models lag behind human-level alignment by over 15 percentage points, highlighting significant gaps in community-sensitive steerability. Steer-Bench is a benchmark to systematically assess how effectively LLMs understand community-specific instructions, their resilience to adversarial steering attempts, and their ability to accurately represent diverse cultural and ideological perspectives.","authors":["Kai Chen","Zihao He","Taiwei Shi","Kristina Lerman"],"url":"https://arxiv.org/abs/2505.20645"}
{"created":"2025-06-05","title":"Beyond Entropy: Region Confidence Proxy for Wild Test-Time Adaptation","abstract":"Wild Test-Time Adaptation (WTTA) is proposed to adapt a source model to unseen domains under extreme data scarcity and multiple shifts. Previous approaches mainly focused on sample selection strategies, while overlooking the fundamental problem on underlying optimization. Initially, we critically analyze the widely-adopted entropy minimization framework in WTTA and uncover its significant limitations in noisy optimization dynamics that substantially hinder adaptation efficiency. Through our analysis, we identify region confidence as a superior alternative to traditional entropy, however, its direct optimization remains computationally prohibitive for real-time applications. In this paper, we introduce a novel region-integrated method ReCAP that bypasses the lengthy process. Specifically, we propose a probabilistic region modeling scheme that flexibly captures semantic changes in embedding space. Subsequently, we develop a finite-to-infinite asymptotic approximation that transforms the intractable region confidence into a tractable and upper-bounded proxy. These innovations significantly unlock the overlooked potential dynamics in local region in a concise solution. Our extensive experiments demonstrate the consistent superiority of ReCAP over existing methods across various datasets and wild scenarios.","authors":["Zixuan Hu","Yichun Hu","Xiaotong Li","Shixiang Tang","Ling-Yu Duan"],"url":"https://arxiv.org/abs/2505.20704"}
{"created":"2025-06-05","title":"What LLMs Miss in Recommendations: Bridging the Gap with Retrieval-Augmented Collaborative Signals","abstract":"User-item interactions contain rich collaborative signals that form the backbone of many successful recommender systems. While recent work has explored the use of large language models (LLMs) for recommendation, it remains unclear whether LLMs can effectively reason over this type of collaborative information. In this paper, we conduct a systematic comparison between LLMs and classical matrix factorization (MF) models to assess LLMs' ability to leverage user-item interaction data. We further introduce a simple retrieval-augmented generation (RAG) method that enhances LLMs by grounding their predictions in structured interaction data. Our experiments reveal that current LLMs often fall short in capturing collaborative patterns inherent to MF models, but that our RAG-based approach substantially improves recommendation quality-highlighting a promising direction for future LLM-based recommenders.","authors":["Shahrooz Pouryousef","Ali Montazeralghaem"],"url":"https://arxiv.org/abs/2505.20730"}
{"created":"2025-06-05","title":"Adversarial bandit optimization for approximately linear functions","abstract":"We consider a bandit optimization problem for nonconvex and non-smooth functions, where in each trial the loss function is the sum of a linear function and a small but arbitrary perturbation chosen after observing the player's choice. We give both expected and high probability regret bounds for the problem. Our result also implies an improved high-probability regret bound for the bandit linear optimization, a special case with no perturbation. We also give a lower bound on the expected regret.","authors":["Zhuoyu Cheng","Kohei Hatano","Eiji Takimoto"],"url":"https://arxiv.org/abs/2505.20734"}
{"created":"2025-06-05","title":"Trans-EnV: A Framework for Evaluating the Linguistic Robustness of LLMs Against English Varieties","abstract":"Large Language Models (LLMs) are predominantly evaluated on Standard American English (SAE), often overlooking the diversity of global English varieties. This narrow focus may raise fairness concerns as degraded performance on non-standard varieties can lead to unequal benefits for users worldwide. Therefore, it is critical to extensively evaluate the linguistic robustness of LLMs on multiple non-standard English varieties. We introduce Trans-EnV, a framework that automatically transforms SAE datasets into multiple English varieties to evaluate the linguistic robustness. Our framework combines (1) linguistics expert knowledge to curate variety-specific features and transformation guidelines from linguistic literature and corpora, and (2) LLM-based transformations to ensure both linguistic validity and scalability. Using Trans-EnV, we transform six benchmark datasets into 38 English varieties and evaluate seven state-of-the-art LLMs. Our results reveal significant performance disparities, with accuracy decreasing by up to 46.3% on non-standard varieties. These findings highlight the importance of comprehensive linguistic robustness evaluation across diverse English varieties. Each construction of Trans-EnV was validated through rigorous statistical testing and consultation with a researcher in the field of second language acquisition, ensuring its linguistic validity. Our code and datasets are publicly available at https://github.com/jiyounglee-0523/TransEnV and https://huggingface.co/collections/jiyounglee0523/transenv-681eadb3c0c8cf363b363fb1.","authors":["Jiyoung Lee","Seungho Kim","Jieun Han","Jun-Min Lee","Kitaek Kim","Alice Oh","Edward Choi"],"url":"https://arxiv.org/abs/2505.20875"}
{"created":"2025-06-05","title":"International collaboration of Ukrainian scholars: Effects of Russia's full-scale invasion of Ukraine","abstract":"This study explores the effects of Russia's full-scale invasion of Ukraine on the international collaboration of Ukrainian scholars. First and foremost, Ukrainian scholars deserve respect for continuing to publish despite life-threatening conditions, mental strain, shelling and blackouts. In 2022-2023, universities gained more from international collaboration than the NASU. The percentage of internationally co-authored articles remained unchanged for the NASU, while it increased for universities. In 2023, 40.8% of articles published by the NASU and 32,2% of articles published by universities were internationally co-authored. However, these figures are still much lower than in developed countries (60-70%). The citation impact of internationally co-authored articles remained statistically unchanged for the NASU but increased for universities. The highest share of internationally co-authored articles published by the NASU in both periods was in the physical sciences and engineering. However, the citation impact of these articles declined in 2022-2023, nearly erasing their previous citation advantage over university publications. Universities consistently outperformed the NASU in the citation impact of internationally co-authored articles in biomedical and health sciences across both periods. International collaboration can help Ukrainian scholars to go through this difficult time. In turn, they can contribute to the strengthening of Europe.","authors":["Myroslava Hladchenko"],"url":"https://arxiv.org/abs/2505.20944"}
{"created":"2025-06-05","title":"LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models","abstract":"Large language models (LLMs) have recently achieved impressive performance across a wide range of natural language tasks and are now widely used in real-world applications. Among them, black-box LLMs--served via APIs without access to model internals--are especially dominant due to their scalability and ease of deployment. Despite their strong capabilities, these models typically produce generalized responses that overlook personal preferences and reasoning styles. This has led to growing interest in black-box LLM personalization, which aims to tailor model outputs to user-specific context without modifying model parameters. However, existing approaches primarily focus on response-level personalization, attempting to match final outputs without modeling personal thought process. To address this limitation, we propose RPM, a framework for reasoning-level personalization that aligns the model's reasoning process with a user's personalized logic. RPM first constructs statistical user-specific factors by extracting and grouping response-influential features from user history. It then builds personalized reasoning paths that reflect how these factors are used in context. In the inference stage, RPM retrieves reasoning-aligned examples for new queries via feature-level similarity and performs inference conditioned on the structured factors and retrieved reasoning paths, enabling the model to follow user-specific reasoning trajectories. This reasoning-level personalization enhances both predictive accuracy and interpretability by grounding model outputs in user-specific logic through structured information. Extensive experiments across diverse tasks show that RPM consistently outperforms response-level personalization methods, demonstrating the effectiveness of reasoning-level personalization in black-box LLMs.","authors":["Jieyong Kim","Tongyoung Kim","Soojin Yoon","Jaehyung Kim","Dongha Lee"],"url":"https://arxiv.org/abs/2505.21082"}
{"created":"2025-06-05","title":"Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning","abstract":"Early-stage startup investment is a high-risk endeavor characterized by scarce data and uncertain outcomes. Traditional machine learning approaches often require large, labeled datasets and extensive fine-tuning, yet remain opaque and difficult for domain experts to interpret or improve. In this paper, we propose a transparent and data-efficient investment decision framework powered by memory-augmented large language models (LLMs) using in-context learning (ICL). Central to our method is a natural language policy embedded directly into the LLM prompt, enabling the model to apply explicit reasoning patterns and allowing human experts to easily interpret, audit, and iteratively refine the logic. We introduce a lightweight training process that combines few-shot learning with an in-context learning loop, enabling the LLM to update its decision policy iteratively based on structured feedback. With only minimal supervision and no gradient-based optimization, our system predicts startup success far more accurately than existing benchmarks. It is over 20x more precise than random chance, which succeeds 1.9% of the time. It is also 7.1x more precise than the typical 5.6% success rate of top-tier venture capital (VC) firms.","authors":["Xianling Mu","Joseph Ternasky","Fuat Alican","Yigit Ihlamur"],"url":"https://arxiv.org/abs/2505.21427"}
{"created":"2025-06-05","title":"Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks","abstract":"Object orientation understanding represents a fundamental challenge in visual perception critical for applications like robotic manipulation and augmented reality. Current vision-language benchmarks fail to isolate this capability, often conflating it with positional relationships and general scene understanding. We introduce DORI (Discriminative Orientation Reasoning Intelligence), a comprehensive benchmark establishing object orientation perception as a primary evaluation target. DORI assesses four dimensions of orientation comprehension: frontal alignment, rotational transformations, relative directional relationships, and canonical orientation understanding. Through carefully curated tasks from 11 datasets spanning 67 object categories across synthetic and real-world scenarios, DORI provides insights on how multi-modal systems understand object orientations. Our evaluation of 15 state-of-the-art vision-language models reveals critical limitations: even the best models achieve only 54.2% accuracy on coarse tasks and 33.0% on granular orientation judgments, with performance deteriorating for tasks requiring reference frame shifts or compound rotations. These findings demonstrate the need for dedicated orientation representation mechanisms, as models show systematic inability to perform precise angular estimations, track orientation changes across viewpoints, and understand compound rotations - suggesting limitations in their internal 3D spatial representations. As the first diagnostic framework specifically designed for orientation awareness in multimodal systems, DORI offers implications for improving robotic control, 3D scene reconstruction, and human-AI interaction in physical environments. DORI data: https://huggingface.co/datasets/appledora/DORI-Benchmark","authors":["Keanu Nichols","Nazia Tasnim","Yuting Yan","Nicholas Ikechukwu","Elva Zou","Deepti Ghadiyaram","Bryan A. Plummer"],"url":"https://arxiv.org/abs/2505.21649"}
{"created":"2025-06-05","title":"What happens when generative AI models train recursively on each others' generated outputs?","abstract":"The internet is full of AI-generated content while also serving as a common source of training data for generative AI (genAI) models. This duality raises the possibility that future genAI models may be trained on other models' generated outputs. Prior work has studied consequences of models training on their own generated outputs, but limited work has considered what happens if models ingest content produced by other models. Given society's increasing dependence on genAI tools, understanding downstream effects of such data-mediated model interactions is critical. To this end, we provide empirical evidence for how data-mediated interactions might unfold in practice, develop a theoretical model for this interactive training process, and show experimentally possible long-term results of such interactions. We find that data-mediated interactions can benefit models by exposing them to novel concepts perhaps missed in original training data, but also can homogenize their performance on shared tasks.","authors":["Hung Anh Vu","Galen Reeves","Emily Wenger"],"url":"https://arxiv.org/abs/2505.21677"}
{"created":"2025-06-05","title":"MAC-Gaze: Motion-Aware Continual Calibration for Mobile Gaze Tracking","abstract":"Mobile gaze tracking faces a fundamental challenge: maintaining accuracy as users naturally change their postures and device orientations. Traditional calibration approaches, like one-off, fail to adapt to these dynamic conditions, leading to degraded performance over time. We present MAC-Gaze, a Motion-Aware continual Calibration approach that leverages smartphone Inertial measurement unit (IMU) sensors and continual learning techniques to automatically detect changes in user motion states and update the gaze tracking model accordingly. Our system integrates a pre-trained visual gaze estimator and an IMU-based activity recognition model with a clustering-based hybrid decision-making mechanism that triggers recalibration when motion patterns deviate significantly from previously encountered states. To enable accumulative learning of new motion conditions while mitigating catastrophic forgetting, we employ replay-based continual learning, allowing the model to maintain performance across previously encountered motion conditions. We evaluate our system through extensive experiments on the publicly available RGBDGaze dataset and our own 10-hour multimodal MotionGaze dataset (481K+ images, 800K+ IMU readings), encompassing a wide range of postures under various motion conditions including sitting, standing, lying, and walking. Results demonstrate that our method reduces gaze estimation error by 19.9% on RGBDGaze (from 1.73 cm to 1.41 cm) and by 31.7% on MotionGaze (from 2.81 cm to 1.92 cm) compared to traditional calibration approaches. Our framework provides a robust solution for maintaining gaze estimation accuracy in mobile scenarios.","authors":["Yaxiong Lei","Mingyue Zhao","Yuheng Wang","Shijing He","Yusuke Sugano","Mohamed Khamis","Juan Ye"],"url":"https://arxiv.org/abs/2505.22769"}
{"created":"2025-06-05","title":"X-Factor: Quality Is a Dataset-Intrinsic Property","abstract":"In the universal quest to optimize machine-learning classifiers, three factors -- model architecture, dataset size, and class balance -- have been shown to influence test-time performance but do not fully account for it. Previously, evidence was presented for an additional factor that can be referred to as dataset quality, but it was unclear whether this was actually a joint property of the dataset and the model architecture, or an intrinsic property of the dataset itself. If quality is truly dataset-intrinsic and independent of model architecture, dataset size, and class balance, then the same datasets should perform better (or worse) regardless of these other factors. To test this hypothesis, here we create thousands of datasets, each controlled for size and class balance, and use them to train classifiers with a wide range of architectures, from random forests and support-vector machines to deep networks. We find that classifier performance correlates strongly by subset across architectures ($R^2=0.79$), supporting quality as an intrinsic property of datasets independent of dataset size and class balance and of model architecture. Digging deeper, we find that dataset quality appears to be an emergent property of something more fundamental: the quality of datasets' constituent classes. Thus, quality joins size, class balance, and model architecture as an independent correlate of performance and a separate target for optimizing machine-learning-based classification.","authors":["Josiah Couch","Miao Li","Rima Arnaout","Ramy Arnaout"],"url":"https://arxiv.org/abs/2505.22813"}
{"created":"2025-06-05","title":"ATI: Any Trajectory Instruction for Controllable Video Generation","abstract":"We propose a unified framework for motion control in video generation that seamlessly integrates camera movement, object-level translation, and fine-grained local motion using trajectory-based inputs. In contrast to prior methods that address these motion types through separate modules or task-specific designs, our approach offers a cohesive solution by projecting user-defined trajectories into the latent space of pre-trained image-to-video generation models via a lightweight motion injector. Users can specify keypoints and their motion paths to control localized deformations, entire object motion, virtual camera dynamics, or combinations of these. The injected trajectory signals guide the generative process to produce temporally consistent and semantically aligned motion sequences. Our framework demonstrates superior performance across multiple video motion control tasks, including stylized motion effects (e.g., motion brushes), dynamic viewpoint changes, and precise local motion manipulation. Experiments show that our method provides significantly better controllability and visual quality compared to prior approaches and commercial solutions, while remaining broadly compatible with various state-of-the-art video generation backbones. Project page: https://anytraj.github.io/.","authors":["Angtian Wang","Haibin Huang","Jacob Zhiyuan Fang","Yiding Yang","Chongyang Ma"],"url":"https://arxiv.org/abs/2505.22944"}
{"created":"2025-06-05","title":"MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design","abstract":"RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems. However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development. To overcome the limitations of the manual circuit design, we introduce MenTeR - a multiagent workflow integrated into an end-to-end analog design framework. By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention. MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems. We believe that MenTeR lays the groundwork for future \"RF/Analog Copilots\" that can collaborate seamlessly with human designers.","authors":["Pin-Han Chen","Yu-Sheng Lin","Wei-Cheng Lee","Tin-Yu Leu","Po-Hsiang Hsu","Anjana Dissanayake","Sungjin Oh","Chinq-Shiun Chiu"],"url":"https://arxiv.org/abs/2505.22990"}
{"created":"2025-06-05","title":"Implicit Inversion turns CLIP into a Decoder","abstract":"CLIP is a discriminative model trained to align images and text in a shared embedding space. Due to its multimodal structure, it serves as the backbone of many generative pipelines, where a decoder is trained to map from the shared space back to images. In this work, we show that image synthesis is nevertheless possible using CLIP alone -- without any decoder, training, or fine-tuning. Our approach optimizes a frequency-aware implicit neural representation that encourages coarse-to-fine generation by stratifying frequencies across network layers. To stabilize this inverse mapping, we introduce adversarially robust initialization, a lightweight Orthogonal Procrustes projection to align local text and image embeddings, and a blending loss that anchors outputs to natural image statistics. Without altering CLIP's weights, this framework unlocks capabilities such as text-to-image generation, style transfer, and image reconstruction. These findings suggest that discriminative models may hold untapped generative potential, hidden in plain sight.","authors":["Antonio D'Orazio","Maria Rosaria Briglia","Donato Crisostomi","Dario Loi","Emanuele Rodol\\`a","Iacopo Masi"],"url":"https://arxiv.org/abs/2505.23161"}
{"created":"2025-06-05","title":"The Arabic AI Fingerprint: Stylometric Analysis and Detection of Large Language Models Text","abstract":"Large Language Models (LLMs) have achieved unprecedented capabilities in generating human-like text, posing subtle yet significant challenges for information integrity across critical domains, including education, social media, and academia, enabling sophisticated misinformation campaigns, compromising healthcare guidance, and facilitating targeted propaganda. This challenge becomes severe, particularly in under-explored and low-resource languages like Arabic. This paper presents a comprehensive investigation of Arabic machine-generated text, examining multiple generation strategies (generation from the title only, content-aware generation, and text refinement) across diverse model architectures (ALLaM, Jais, Llama, and GPT-4) in academic, and social media domains. Our stylometric analysis reveals distinctive linguistic patterns differentiating human-written from machine-generated Arabic text across these varied contexts. Despite their human-like qualities, we demonstrate that LLMs produce detectable signatures in their Arabic outputs, with domain-specific characteristics that vary significantly between different contexts. Based on these insights, we developed BERT-based detection models that achieved exceptional performance in formal contexts (up to 99.9\\% F1-score) with strong precision across model architectures. Our cross-domain analysis confirms generalization challenges previously reported in the literature. To the best of our knowledge, this work represents the most comprehensive investigation of Arabic machine-generated text to date, uniquely combining multiple prompt generation methods, diverse model architectures, and in-depth stylometric analysis across varied textual domains, establishing a foundation for developing robust, linguistically-informed detection systems essential for preserving information integrity in Arabic-language contexts.","authors":["Maged S. Al-Shaibani","Moataz Ahmed"],"url":"https://arxiv.org/abs/2505.23276"}
{"created":"2025-06-05","title":"Refining Labeling Functions with Limited Labeled Data","abstract":"Programmatic weak supervision (PWS) significantly reduces human effort for labeling data by combining the outputs of user-provided labeling functions (LFs) on unlabeled datapoints. However, the quality of the generated labels depends directly on the accuracy of the LFs. In this work, we study the problem of fixing LFs based on a small set of labeled examples. Towards this goal, we develop novel techniques for repairing a set of LFs by minimally changing their results on the labeled examples such that the fixed LFs ensure that (i) there is sufficient evidence for the correct label of each labeled datapoint and (ii) the accuracy of each repaired LF is sufficiently high. We model LFs as conditional rules which enables us to refine them, i.e., to selectively change their output for some inputs. We demonstrate experimentally that our system improves the quality of LFs based on surprisingly small sets of labeled datapoints.","authors":["Chenjie Li","Amir Gilad","Boris Glavic","Zhengjie Miao","Sudeepa Roy"],"url":"https://arxiv.org/abs/2505.23470"}
{"created":"2025-06-05","title":"Normalizing Flows are Capable Models for RL","abstract":"Modern reinforcement learning (RL) algorithms have found success by using powerful probabilistic models, such as transformers, energy-based models, and diffusion/flow-based models. To this end, RL researchers often choose to pay the price of accommodating these models into their algorithms -- diffusion models are expressive, but are computationally intensive due to their reliance on solving differential equations, while autoregressive transformer models are scalable but typically require learning discrete representations. Normalizing flows (NFs), by contrast, seem to provide an appealing alternative, as they enable likelihoods and sampling without solving differential equations or autoregressive architectures. However, their potential in RL has received limited attention, partly due to the prevailing belief that normalizing flows lack sufficient expressivity. We show that this is not the case. Building on recent work in NFs, we propose a single NF architecture which integrates seamlessly into RL algorithms, serving as a policy, Q-function, and occupancy measure. Our approach leads to much simpler algorithms, and achieves higher performance in imitation learning, offline, goal conditioned RL and unsupervised RL.","authors":["Raj Ghugare","Benjamin Eysenbach"],"url":"https://arxiv.org/abs/2505.23527"}
{"created":"2025-06-05","title":"On-Policy RL with Optimal Reward Baseline","abstract":"Reinforcement learning algorithms are fundamental to align large language models with human preferences and to enhance their reasoning capabilities. However, current reinforcement learning algorithms often suffer from training instability due to loose on-policy constraints and computational inefficiency due to auxiliary models. In this work, we propose On-Policy RL with Optimal reward baseline (OPO), a novel and simplified reinforcement learning algorithm designed to address these challenges. OPO emphasizes the importance of exact on-policy training, which empirically stabilizes the training process and enhances exploration. Moreover, OPO integrates a practically feasible formulation of the optimal reward baseline that minimizes gradient variance. We evaluate OPO on mathematical reasoning benchmarks. The results demonstrate its superior performance and training stability without additional models or regularization terms. Furthermore, OPO achieves lower policy shifts and higher output entropy, encouraging more diverse and less repetitive responses. These results highlight OPO as a promising direction for stable and effective reinforcement learning in large language model alignment and reasoning tasks. The implementation is merged into the verl library at https://verl.readthedocs.io/en/latest/algo/opo.html.","authors":["Yaru Hao","Li Dong","Xun Wu","Shaohan Huang","Zewen Chi","Furu Wei"],"url":"https://arxiv.org/abs/2505.23585"}
{"created":"2025-06-05","title":"Comparing the Effects of Persistence Barcodes Aggregation and Feature Concatenation on Medical Imaging","abstract":"In medical image analysis, feature engineering plays an important role in the design and performance of machine learning models. Persistent homology (PH), from the field of topological data analysis (TDA), demonstrates robustness and stability to data perturbations and addresses the limitation from traditional feature extraction approaches where a small change in input results in a large change in feature representation. Using PH, we store persistent topological and geometrical features in the form of the persistence barcode whereby large bars represent global topological features and small bars encapsulate geometrical information of the data. When multiple barcodes are computed from 2D or 3D medical images, two approaches can be used to construct the final topological feature vector in each dimension: aggregating persistence barcodes followed by featurization or concatenating topological feature vectors derived from each barcode. In this study, we conduct a comprehensive analysis across diverse medical imaging datasets to compare the effects of the two aforementioned approaches on the performance of classification models. The results of this analysis indicate that feature concatenation preserves detailed topological information from individual barcodes, yields better classification performance and is therefore a preferred approach when conducting similar experiments.","authors":["Dashti A. Ali","Richard K. G. Do","William R. Jarnagin","Aras T. Asaad","Amber L. Simpson"],"url":"https://arxiv.org/abs/2505.23637"}
{"created":"2025-06-05","title":"Let's Reason Formally: Natural-Formal Hybrid Reasoning Enhances LLM's Math Capability","abstract":"Enhancing the mathematical reasoning capabilities of LLMs has garnered significant attention in both the mathematical and computer science communities. Recent works have made substantial progress in both Natural Language (NL) reasoning and Formal Language (FL) reasoning by leveraging the potential of pure Reinforcement Learning (RL) methods on base models. However, RL approaches struggle to impart new capabilities not presented in the base model, highlighting the need to integrate more knowledge like FL into NL math reasoning effectively. Yet, this integration is challenging due to inherent disparities in problem structure and reasoning format between NL and FL. To address these challenges, we introduce **NL-FL HybridReasoning**, an end-to-end framework designed to incorporate the FL expert into NL math problem-solving. To bridge the NL and FL input format gap, we propose the *NL-FL Problem Alignment* method, which reformulates the Question-Answering (QA) problems in NL as existence theorems in FL. Subsequently, the *Mixed Problem Input* technique we provide enables the FL reasoner to handle both QA and existence problems concurrently. Lastly, we mitigate the NL and FL output format gap in reasoning through an LLM-based *Answer Extraction* mechanism. Comprehensive experiments demonstrate that the **HybridReasoning** framework achieves **89.80%** and **84.34%** accuracy rates on the MATH-500 and the AMC benchmarks, surpassing the NL baseline by 4.60% and 4.82%, respectively. Notably, some problems resolved by our framework remain unsolved by the NL baseline model even under a larger number of trials.","authors":["Ruida Wang","Yuxin Li","Yi R. Fung","Tong Zhang"],"url":"https://arxiv.org/abs/2505.23703"}
{"created":"2025-06-05","title":"Mind the Gap: A Practical Attack on GGUF Quantization","abstract":"With the increasing size of frontier LLMs, post-training quantization has become the standard for memory-efficient deployment. Recent work has shown that basic rounding-based quantization schemes pose security risks, as they can be exploited to inject malicious behaviors into quantized models that remain hidden in full precision. However, existing attacks cannot be applied to more complex quantization methods, such as the GGUF family used in the popular ollama and llama$.$cpp frameworks. In this work, we address this gap by introducing the first attack on GGUF. Our key insight is that the quantization error -- the difference between the full-precision weights and their (de-)quantized version -- provides sufficient flexibility to construct malicious quantized models that appear benign in full precision. Leveraging this, we develop an attack that trains the target malicious LLM while constraining its weights based on quantization errors. We demonstrate the effectiveness of our attack on three popular LLMs across nine GGUF quantization data types on three diverse attack scenarios: insecure code generation ($\\Delta$=$88.7\\%$), targeted content injection ($\\Delta$=$85.0\\%$), and benign instruction refusal ($\\Delta$=$30.1\\%$). Our attack highlights that (1) the most widely used post-training quantization method is susceptible to adversarial interferences, and (2) the complexity of quantization schemes alone is insufficient as a defense.","authors":["Kazuki Egashira","Robin Staab","Mark Vero","Jingxuan He","Martin Vechev"],"url":"https://arxiv.org/abs/2505.23786"}
{"created":"2025-06-05","title":"LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions","abstract":"Pretrained Large Language Models (LLMs) achieve strong performance across a wide range of tasks, yet exhibit substantial variability in the various layers' training quality with respect to specific downstream applications, limiting their downstream performance. It is therefore critical to estimate layer-wise training quality in a manner that accounts for both model architecture and training data. However, existing approaches predominantly rely on model-centric heuristics (such as spectral statistics, outlier detection, or uniform allocation) while overlooking the influence of data. To address these limitations, we propose LayerIF, a data-driven framework that leverages Influence Functions to quantify the training quality of individual layers in a principled and task-sensitive manner. By isolating each layer's gradients and measuring the sensitivity of the validation loss to training examples by computing layer-wise influences, we derive data-driven estimates of layer importance. Notably, our method produces task-specific layer importance estimates for the same LLM, revealing how layers specialize for different test-time evaluation tasks. We demonstrate the utility of our scores by leveraging them for two downstream applications: (a) expert allocation in LoRA-MoE architectures and (b) layer-wise sparsity distribution for LLM pruning. Experiments across multiple LLM architectures demonstrate that our model-agnostic, influence-guided allocation leads to consistent gains in task performance.","authors":["Hadi Askari","Shivanshu Gupta","Fei Wang","Anshuman Chhabra","Muhao Chen"],"url":"https://arxiv.org/abs/2505.23811"}
{"created":"2025-06-05","title":"Hold My Beer: Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control","abstract":"Can your humanoid walk up and hand you a full cup of beer, without spilling a drop? While humanoids are increasingly featured in flashy demos like dancing, delivering packages, traversing rough terrain, fine-grained control during locomotion remains a significant challenge. In particular, stabilizing a filled end-effector (EE) while walking is far from solved, due to a fundamental mismatch in task dynamics: locomotion demands slow-timescale, robust control, whereas EE stabilization requires rapid, high-precision corrections. To address this, we propose SoFTA, a Slow-Fast Two-Agent framework that decouples upper-body and lower-body control into separate agents operating at different frequencies and with distinct rewards. This temporal and objective separation mitigates policy interference and enables coordinated whole-body behavior. SoFTA executes upper-body actions at 100 Hz for precise EE control and lower-body actions at 50 Hz for robust gait. It reduces EE acceleration by 2-5x relative to baselines and performs much closer to human-level stability, enabling delicate tasks such as carrying nearly full cups, capturing steady video during locomotion, and disturbance rejection with EE stability.","authors":["Yitang Li","Yuanhang Zhang","Wenli Xiao","Chaoyi Pan","Haoyang Weng","Guanqi He","Tairan He","Guanya Shi"],"url":"https://arxiv.org/abs/2505.24198"}
{"created":"2025-06-05","title":"Large Language Models are Locally Linear Mappings","abstract":"We demonstrate that the inference operations of several open-weight large language models (LLMs) can be mapped to an exactly equivalent linear system for an input sequence without modifying the model weights or altering output predictions. Extending techniques from image diffusion models that exhibit local or piecewise linearity, we strategically alter the gradient computation with respect to a given input sequence for a next-token prediction such that the Jacobian of the model nearly exactly reproduces the forward prediction with a linear system. We demonstrate this approach across models (Llama 3, Gemma 3, Qwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show through the singular value decomposition of the detached Jacobian that these LLMs operate in extremely low-dimensional subspaces where many of the largest singular vectors decode to concepts related to the most-likely output token. This approach also allows us to examine the operation of each successive layer (and its attention and MLP components) as nearly-exact linear systems and observe the emergence of semantic concepts. Despite their expressive power and global nonlinearity, modern LLMs can be interpreted through nearly-exact locally linear decompositions that provide insights into their internal representations and reveal interpretable semantic structures in the next-token prediction process.","authors":["James R. Golden"],"url":"https://arxiv.org/abs/2505.24293"}
{"created":"2025-06-05","title":"AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning","abstract":"Reinforcement learning (RL) has become a dominant paradigm for training large language models (LLMs), particularly for reasoning tasks. Effective RL for LLMs requires massive parallelization and poses an urgent need for efficient training systems. Most existing large-scale RL systems for LLMs are synchronous, alternating generation and training in a batch setting where rollouts in each training batch are generated by the same model. This approach stabilizes RL training but suffers from severe system-level inefficiency: generation must wait until the longest output in the batch is completed before model updates, resulting in GPU underutilization. We present AReaL, a fully asynchronous RL system that completely decouples generation from training. Rollout workers in AReaL continuously generate new outputs without waiting, while training workers update the model whenever a batch of data is collected. AReaL also incorporates a collection of system-level optimizations, leading to substantially higher GPU utilization. To stabilize RL training, AReaL balances the workload of rollout and training workers to control data staleness, and adopts a staleness-enhanced PPO variant to better handle outdated training samples. Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.77$\\times$ training speedup compared to synchronous systems with the same number of GPUs and matched or improved final performance. The code of AReaL is available at https://github.com/inclusionAI/AReaL/.","authors":["Wei Fu","Jiaxuan Gao","Xujie Shen","Chen Zhu","Zhiyu Mei","Chuyi He","Shusheng Xu","Guo Wei","Jun Mei","Jiashu Wang","Tongkai Yang","Binhang Yuan","Yi Wu"],"url":"https://arxiv.org/abs/2505.24298"}
{"created":"2025-06-05","title":"Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering","abstract":"In this paper, we propose a Grid-based Local and Global Area Transcription (Grid-LoGAT) system for Video Question Answering (VideoQA). The system operates in two phases. First, extracting text transcripts from video frames using a Vision-Language Model (VLM). Next, processing questions using these transcripts to generate answers through a Large Language Model (LLM). This design ensures image privacy by deploying the VLM on edge devices and the LLM in the cloud. To improve transcript quality, we propose grid-based visual prompting, which extracts intricate local details from each grid cell and integrates them with global information. Evaluation results show that Grid-LoGAT, using the open-source VLM (LLaVA-1.6-7B) and LLM (Llama-3.1-8B), outperforms state-of-the-art methods with similar baseline models on NExT-QA and STAR-QA datasets with an accuracy of 65.9% and 50.11% respectively. Additionally, our method surpasses the non-grid version by 24 points on localization-based questions we created using NExT-QA. (This paper is accepted by IEEE ICIP 2025.)","authors":["Md Intisar Chowdhury","Kittinun Aukkapinyo","Hiroshi Fujimura","Joo Ann Woo","Wasu Wasusatein","Fadoua Ghourabi"],"url":"https://arxiv.org/abs/2505.24371"}
{"created":"2025-06-05","title":"Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields","abstract":"Flow matching casts sample generation as learning a continuous-time velocity field that transports noise to data. Existing flow matching networks typically predict each point's velocity independently, considering only its location and time along its flow trajectory, and ignoring neighboring points. However, this pointwise approach may overlook correlations between points along the generation trajectory that could enhance velocity predictions, thereby improving downstream generation quality. To address this, we propose Graph Flow Matching (GFM), a lightweight enhancement that decomposes the learned velocity into a reaction term -- any standard flow matching network -- and a diffusion term that aggregates neighbor information via a graph neural module. This reaction-diffusion formulation retains the scalability of deep flow models while enriching velocity predictions with local context, all at minimal additional computational cost. Operating in the latent space of a pretrained variational autoencoder, GFM consistently improves Fr\\'echet Inception Distance (FID) and recall across five image generation benchmarks (LSUN Church, LSUN Bedroom, FFHQ, AFHQ-Cat, and CelebA-HQ at $256\\times256$), demonstrating its effectiveness as a modular enhancement to existing flow matching architectures.","authors":["Md Shahriar Rahim Siddiqui","Moshe Eliasof","Eldad Haber"],"url":"https://arxiv.org/abs/2505.24434"}
{"created":"2025-06-05","title":"Object Centric Concept Bottlenecks","abstract":"Developing high-performing, yet interpretable models remains a critical challenge in modern AI. Concept-based models (CBMs) attempt to address this by extracting human-understandable concepts from a global encoding (e.g., image encoding) and then applying a linear classifier on the resulting concept activations, enabling transparent decision-making. However, their reliance on holistic image encodings limits their expressiveness in object-centric real-world settings and thus hinders their ability to solve complex vision tasks beyond single-label classification. To tackle these challenges, we introduce Object-Centric Concept Bottlenecks (OCB), a framework that combines the strengths of CBMs and pre-trained object-centric foundation models, boosting performance and interpretability. We evaluate OCB on complex image datasets and conduct a comprehensive ablation study to analyze key components of the framework, such as strategies for aggregating object-concept encodings. The results show that OCB outperforms traditional CBMs and allows one to make interpretable decisions for complex visual tasks.","authors":["David Steinmann","Wolfgang Stammer","Antonia W\\\"ust","Kristian Kersting"],"url":"https://arxiv.org/abs/2505.24492"}
{"created":"2025-06-05","title":"Bench4KE: Benchmarking Automated Competency Question Generation","abstract":"The availability of Large Language Models (LLMs) presents a unique opportunity to reinvigorate research on Knowledge Engineering (KE) automation, a trend already evident in recent efforts developing LLM-based methods and tools for the automatic generation of Competency Questions (CQs). However, the evaluation of these tools lacks standardisation. This undermines the methodological rigour and hinders the replication and comparison of results. To address this gap, we introduce Bench4KE, an extensible API-based benchmarking system for KE automation. Its first release focuses on evaluating tools that generate CQs automatically. CQs are natural language questions used by ontology engineers to define the functional requirements of an ontology. Bench4KE provides a curated gold standard consisting of CQ datasets from four real-world ontology projects. It uses a suite of similarity metrics to assess the quality of the CQs generated. We present a comparative analysis of four recent CQ generation systems, which are based on LLMs, establishing a baseline for future research. Bench4KE is also designed to accommodate additional KE automation tasks, such as SPARQL query generation, ontology testing and drafting. Code and datasets are publicly available under the Apache 2.0 license.","authors":["Anna Sofia Lippolis","Minh Davide Ragagni","Paolo Ciancarini","Andrea Giovanni Nuzzolese","Valentina Presutti"],"url":"https://arxiv.org/abs/2505.24554"}
{"created":"2025-06-05","title":"The Gaussian Mixing Mechanism: Renyi Differential Privacy via Gaussian Sketches","abstract":"Gaussian sketching, which consists of pre-multiplying the data with a random Gaussian matrix, is a widely used technique for multiple problems in data science and machine learning, with applications spanning computationally efficient optimization, coded computing, and federated learning. This operation also provides differential privacy guarantees due to its inherent randomness. In this work, we revisit this operation through the lens of Renyi Differential Privacy (RDP), providing a refined privacy analysis that yields significantly tighter bounds than prior results. We then demonstrate how this improved analysis leads to performance improvement in different linear regression settings, establishing theoretical utility guarantees. Empirically, our methods improve performance across multiple datasets and, in several cases, reduce runtime.","authors":["Omri Lev","Vishwak Srinivasan","Moshe Shenfeld","Katrina Ligett","Ayush Sekhari","Ashia C. Wilson"],"url":"https://arxiv.org/abs/2505.24603"}
{"created":"2025-06-05","title":"Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration","abstract":"Large Language Models (LLMs) struggle with complex reasoning due to limited diversity and inefficient search. We propose Soft Reasoning, an embedding-based search framework that optimises the embedding of the first token to guide generation. It combines (1) embedding perturbation for controlled exploration and (2) Bayesian optimisation to refine embeddings via a verifier-guided objective, balancing exploration and exploitation. This approach improves reasoning accuracy and coherence while avoiding reliance on heuristic search. Experiments demonstrate superior correctness with minimal computation, making it a scalable, model-agnostic solution.","authors":["Qinglin Zhu","Runcong Zhao","Hanqi Yan","Yulan He","Yudong Chen","Lin Gui"],"url":"https://arxiv.org/abs/2505.24688"}
{"created":"2025-06-05","title":"Children's Voice Privacy: First Steps And Emerging Challenges","abstract":"Children are one of the most under-represented groups in speech technologies, as well as one of the most vulnerable in terms of privacy. Despite this, anonymization techniques targeting this population have received little attention. In this study, we seek to bridge this gap, and establish a baseline for the use of voice anonymization techniques designed for adult speech when applied to children's voices. Such an evaluation is essential, as children's speech presents a distinct set of challenges when compared to that of adults. This study comprises three children's datasets, six anonymization methods, and objective and subjective utility metrics for evaluation. Our results show that existing systems for adults are still able to protect children's voice privacy, but suffer from much higher utility degradation. In addition, our subjective study displays the challenges of automatic evaluation methods for speech quality in children's speech, highlighting the need for further research.","authors":["Ajinkya Kulkarni","Francisco Teixeira","Enno Hermann","Thomas Rolland","Isabel Trancoso","Mathew Magimai Doss"],"url":"https://arxiv.org/abs/2506.00100"}
{"created":"2025-06-05","title":"Balancing Profit and Fairness in Risk-Based Pricing Markets","abstract":"Dynamic, risk-based pricing can systematically exclude vulnerable consumer groups from essential resources such as health insurance and consumer credit. We show that a regulator can realign private incentives with social objectives through a learned, interpretable tax schedule. First, we provide a formal proposition that bounding each firm's \\emph{local} demographic gap implicitly bounds the \\emph{global} opt-out disparity, motivating firm-level penalties. Building on this insight we introduce \\texttt{MarketSim} -- an open-source, scalable simulator of heterogeneous consumers and profit-maximizing firms -- and train a reinforcement learning (RL) social planner (SP) that selects a bracketed fairness-tax while remaining close to a simple linear prior via an $\\mathcal{L}_1$ regularizer. The learned policy is thus both transparent and easily interpretable. In two empirically calibrated markets, i.e., U.S. health-insurance and consumer-credit, our planner simultaneously raises demand-fairness by up to $16\\%$ relative to unregulated Free Market while outperforming a fixed linear schedule in terms of social welfare without explicit coordination. These results illustrate how AI-assisted regulation can convert a competitive social dilemma into a win-win equilibrium, providing a principled and practical framework for fairness-aware market oversight.","authors":["Jesse Thibodeau","Hadi Nekoei","Afaf Ta\\\"ik","Janarthanan Rajendran","Golnoosh Farnadi"],"url":"https://arxiv.org/abs/2506.00140"}
{"created":"2025-06-05","title":"What do professional software developers need to know to succeed in an age of Artificial Intelligence?","abstract":"Generative AI is showing early evidence of productivity gains for software developers, but concerns persist regarding workforce disruption and deskilling. We describe our research with 21 developers at the cutting edge of using AI, summarizing 12 of their work goals we uncovered, together with 75 associated tasks and the skills & knowledge for each, illustrating how developers use AI at work. From all of these, we distilled our findings in the form of 5 insights. We found that the skills & knowledge to be a successful AI-enhanced developer are organized into four domains (using Generative AI effectively, core software engineering, adjacent engineering, and adjacent non-engineering) deployed at critical junctures throughout a 6-step task workflow. In order to \"future proof\" developers for this age of AI, on-the-job learning initiatives and computer science degree programs will need to target both \"soft\" skills and the technical skills & knowledge in all four domains to reskill, upskill and safeguard against deskilling.","authors":["Matthew Kam","Cody Miller","Miaoxin Wang","Abey Tidwell","Irene A. Lee","Joyce Malyn-Smith","Beatriz Perez","Vikram Tiwari","Joshua Kenitzer","Andrew Macvean","Erin Barrar"],"url":"https://arxiv.org/abs/2506.00202"}
{"created":"2025-06-05","title":"MultiHoax: A Dataset of Multi-hop False-Premise Questions","abstract":"As Large Language Models are increasingly deployed in high-stakes domains, their ability to detect false assumptions and reason critically is crucial for ensuring reliable outputs. False-premise questions (FPQs) serve as an important evaluation method by exposing cases where flawed assumptions lead to incorrect responses. While existing benchmarks focus on single-hop FPQs, real-world reasoning often requires multi-hop inference, where models must verify consistency across multiple reasoning steps rather than relying on surface-level cues. To address this gap, we introduce MultiHoax, a benchmark for evaluating LLMs' ability to handle false premises in complex, multi-step reasoning tasks. Our dataset spans seven countries and ten diverse knowledge categories, using Wikipedia as the primary knowledge source to enable factual reasoning across regions. Experiments reveal that state-of-the-art LLMs struggle to detect false premises across different countries, knowledge categories, and multi-hop reasoning types, highlighting the need for improved false premise detection and more robust multi-hop reasoning capabilities in LLMs.","authors":["Mohammadamin Shafiei","Hamidreza Saffari","Nafise Sadat Moosavi"],"url":"https://arxiv.org/abs/2506.00264"}
{"created":"2025-06-05","title":"It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs","abstract":"Despite rapid advancements in the research and deployment of large language models (LLMs), the statistical distribution of model parameters, as well as their influence on initialization, training dynamics, and downstream efficiency, has received surprisingly little attention. A recent work introduced BackSlash, a training-time compression algorithm. It first demonstrated that pre-trained LLM parameters follow generalized Gaussian distributions (GGDs) better. By optimizing GG priors during training, BackSlash can reduce parameters by up to 90\\% with minimal performance loss. Building on this foundational insight, we propose a unified, end-to-end framework for LLM optimization based on the GG model. Our contributions are threefold: (1) GG-based initialization scheme that aligns with the statistical structure of trained models, resulting in faster convergence and improved accuracy; (2) DeepShape, a post-training regularization method that reshapes weight distributions to match a GG profile, improving compressibility with minimized degradation in performance; and (3) RF8, a compact and hardware-efficient 8-bit floating-point format designed for GG-distributed-initialized BackSlash training, enabling low-cost inference without compromising accuracy. Experiments across diverse model architectures show that our framework consistently yields smaller and faster models that match or outperform standard training baselines. By grounding LLM development in principled statistical modeling, this work forges a new path toward efficient, scalable, and hardware-aware AI systems. The code is available on our project page: https://huggingface.co/spaces/shifeng3711/gg_prior.","authors":["Jun Wu","Yirong Xiong","Jiangtao Wen","Yuxing Han"],"url":"https://arxiv.org/abs/2506.00486"}
{"created":"2025-06-05","title":"ARIA: Training Language Agents with Intention-Driven Reward Aggregation","abstract":"Large language models (LLMs) have enabled agents to perform complex reasoning and decision-making through free-form language interactions. However, in open-ended language action environments (e.g., negotiation or question-asking games), the action space can be formulated as a joint distribution over tokens, resulting in an exponentially large action space. Sampling actions in such a space can lead to extreme reward sparsity, which brings large reward variance, hindering effective reinforcement learning (RL). To address this, we propose ARIA, a method that Aggregates Rewards in Intention space to enable efficient and effective language Agents training. ARIA aims to project natural language actions from the high-dimensional joint token distribution space into a low-dimensional intention space, where semantically similar actions are clustered and assigned shared rewards. This intention-aware reward aggregation reduces reward variance by densifying reward signals, fostering better policy optimization. Extensive experiments demonstrate that ARIA not only significantly reduces policy gradient variance, but also delivers substantial performance gains of an average of 9.95% across four downstream tasks, consistently outperforming offline and online RL baselines.","authors":["Ruihan Yang","Yikai Zhang","Aili Chen","Xintao Wang","Siyu Yuan","Jiangjie Chen","Deqing Yang","Yanghua Xiao"],"url":"https://arxiv.org/abs/2506.00539"}
{"created":"2025-06-05","title":"RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents","abstract":"With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? Existing research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents. To this end, we introduce \\textbf{RiOSWorld}, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on \\textbf{RiOSWorld} demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents. Our benchmark is publicly available at https://yjyddq.github.io/RiOSWorld.github.io/.","authors":["Jingyi Yang","Shuai Shao","Dongrui Liu","Jing Shao"],"url":"https://arxiv.org/abs/2506.00618"}
{"created":"2025-06-05","title":"Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning","abstract":"Training reinforcement learning (RL) agents often requires significant computational resources and extended training times. To address this, we build upon the foundation laid by Google Brain's Sensory Neuron, which introduced a novel neural architecture for reinforcement learning tasks that maintained permutation in-variance in the sensory neuron system. While the baseline model demonstrated significant performance improvements over traditional approaches, we identified opportunities to enhance the efficiency of the learning process further. We propose a modified attention mechanism incorporating a non-linear transformation of the key vectors (K) using a mapping function, resulting in a new set of key vectors (K'). This non-linear mapping enhances the representational capacity of the attention mechanism, allowing the model to encode more complex feature interactions and accelerating convergence without compromising performance. Our enhanced model demonstrates significant improvements in learning efficiency, showcasing the potential for non-linear attention mechanisms in advancing reinforcement learning algorithms.","authors":["Junaid Muzaffar","Khubaib Ahmed","Ingo Frommholz","Zeeshan Pervez","Ahsan ul Haq"],"url":"https://arxiv.org/abs/2506.00691"}
{"created":"2025-06-05","title":"Optimistic critics can empower small actors","abstract":"Actor-critic methods have been central to many of the recent advances in deep reinforcement learning. The most common approach is to use symmetric architectures, whereby both actor and critic have the same network topology and number of parameters. However, recent works have argued for the advantages of asymmetric setups, specifically with the use of smaller actors. We perform broad empirical investigations and analyses to better understand the implications of this and find that, in general, smaller actors result in performance degradation and overfit critics. Our analyses suggest poor data collection, due to value underestimation, as one of the main causes for this behavior, and further highlight the crucial role the critic can play in alleviating this pathology. We explore techniques to mitigate the observed value underestimation, which enables further research in asymmetric actor-critic methods.","authors":["Olya Mastikhina","Dhruv Sreenivas","Pablo Samuel Castro"],"url":"https://arxiv.org/abs/2506.01016"}
{"created":"2025-06-05","title":"MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch","abstract":"Function-calling has enabled large language models (LLMs) to act as tool-using agents, but injecting thousands of tool schemas into the prompt is costly and error-prone. We introduce MCP-Zero, a proactive agent framework that lets the LLM itself decide when and which external tools to retrieve, thereby assembling a task-specific toolchain from scratch. The framework is built upon three components: (1) Proactive Tool Request, where the model emits a structured $\\left<\\operatorname{tool\\_assistant}\\right>$ block that explicitly specifies the desired server and task; (2) Hierarchical Vector Routing, a coarse-to-fine retrieval algorithm that first selects candidate servers and then ranks tools within each server based on the semantic similarity; (3) Iterative Proactive Invocation, enabling multi-round, cross-domain toolchain construction with minimal context overhead, and allowing the model to iteratively revise its request when the returned tools are insufficient. To evaluate our approach we also compile MCP-tools, a retrieval dataset comprising 308 MCP servers and 2,797 tools extracted from the official Model-Context-Protocol repository and normalized into a unified JSON schema. Experiments show that MCP-Zero (i) effectively addresses the context overhead problem of existing methods and accurately selects the correct tool from a pool of nearly 3,000 candidates (248.1k tokens); (ii) reduces token consumption by 98\\% on the APIbank while maintaining high accuracy; and (iii) supports multi-turn tool invocation with consistent accuracy across rounds.","authors":["Xiang Fei","Xiawu Zheng","Hao Feng"],"url":"https://arxiv.org/abs/2506.01056"}
{"created":"2025-06-05","title":"FlowMo: Variance-Based Flow Guidance for Coherent Motion in Video Generation","abstract":"Text-to-video diffusion models are notoriously limited in their ability to model temporal aspects such as motion, physics, and dynamic interactions. Existing approaches address this limitation by retraining the model or introducing external conditioning signals to enforce temporal consistency. In this work, we explore whether a meaningful temporal representation can be extracted directly from the predictions of a pre-trained model without any additional training or auxiliary inputs. We introduce FlowMo, a novel training-free guidance method that enhances motion coherence using only the model's own predictions in each diffusion step. FlowMo first derives an appearance-debiased temporal representation by measuring the distance between latents corresponding to consecutive frames. This highlights the implicit temporal structure predicted by the model. It then estimates motion coherence by measuring the patch-wise variance across the temporal dimension and guides the model to reduce this variance dynamically during sampling. Extensive experiments across multiple text-to-video models demonstrate that FlowMo significantly improves motion coherence without sacrificing visual quality or prompt alignment, offering an effective plug-and-play solution for enhancing the temporal fidelity of pre-trained video diffusion models.","authors":["Ariel Shaulov","Itay Hazan","Lior Wolf","Hila Chefer"],"url":"https://arxiv.org/abs/2506.01144"}
{"created":"2025-06-05","title":"Dirty and Clean-Label attack detection using GAN discriminators","abstract":"Gathering enough images to train a deep computer vision model is a constant challenge. Unfortunately, collecting images from unknown sources can leave your model s behavior at risk of being manipulated by a dirty-label or clean-label attack unless the images are properly inspected. Manually inspecting each image-label pair is impractical and common poison-detection methods that involve re-training your model can be time consuming. This research uses GAN discriminators to protect a single class against mislabeled and different levels of modified images. The effect of said perturbation on a basic convolutional neural network classifier is also included for reference. The results suggest that after training on a single class, GAN discriminator s confidence scores can provide a threshold to identify mislabeled images and identify 100% of the tested poison starting at a perturbation epsilon magnitude of 0.20, after decision threshold calibration using in-class samples. Developers can use this report as a basis to train their own discriminators to protect high valued classes in their CV models.","authors":["John W. Smutny"],"url":"https://arxiv.org/abs/2506.01224"}
{"created":"2025-06-05","title":"React to Surprises: Stable-by-Design Neural Feedback Control and the Youla-REN","abstract":"We study parameterizations of stabilizing nonlinear policies for learning-based control. We propose a structure based on a nonlinear version of the Youla-Kucera parameterization combined with robust neural networks such as the recurrent equilibrium network (REN). The resulting parameterizations are unconstrained, and hence can be searched over with first-order optimization methods, while always ensuring closed-loop stability by construction. We study the combination of (a) nonlinear dynamics, (b) partial observation, and (c) incremental closed-loop stability requirements (contraction and Lipschitzness). We find that with any two of these three difficulties, a contracting and Lipschitz Youla parameter always leads to contracting and Lipschitz closed loops. However, if all three hold, then incremental stability can be lost with exogenous disturbances. Instead, a weaker condition is maintained, which we call d-tube contraction and Lipschitzness. We further obtain converse results showing that the proposed parameterization covers all contracting and Lipschitz closed loops for certain classes of nonlinear systems. Numerical experiments illustrate the utility of our parameterization when learning controllers with built-in stability certificates for: (i) \"economic\" rewards without stabilizing effects; (ii) short training horizons; and (iii) uncertain systems.","authors":["Nicholas H. Barbara","Ruigang Wang","Alexandre Megretski","Ian R. Manchester"],"url":"https://arxiv.org/abs/2506.01226"}
{"created":"2025-06-05","title":"MobCLIP: Learning General-purpose Geospatial Representation at Scale","abstract":"Representation learning of geospatial locations remains a core challenge in achieving general geospatial intelligence. Current embedding methods often lack versatility, limiting their utility across diverse tasks in both human and natural domains. We present MobCLIP, the first nationwide general-purpose location encoder, integrating an unprecedented diversity of data modalities through effective and scalable multimodal fusion. Adopting a novel CLIP-based architecture, our framework aligns 100M+ POIs, nationwide remote sensing imagery, and structured demographic statistics with a billion-edge mobility graph. By tokenizing spatial locations into grid cells inspired by Vision Transformers, we establish a unified representation space bridging mobility patterns and multimodal features. To rigorously evaluate the general-purpose effectiveness of MobCLIP, we construct a benchmark dataset composed of 11 downstream prediction tasks across social, economic, and natural domains. Experiments show that MobCLIP, with four input modalities and a compact 128-dimensional representation space, achieves significantly superior general-purpose predictive performances than state-of-the-art models by an average of 35%. Thanks to the effective integration of human-centric modalities, the performance gain is particularly profound in human-centric tasks, such as energy consumption (+260%), offline retail consumption amount (+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, we further demonstrate the scaling behavior in geospatial representation learning. We open-source code and pretrained models at: https://github.com/ylzhouchris/MobCLIP.","authors":["Ya Wen","Jixuan Cai","Qiyao Ma","Linyan Li","Xinhua Chen","Chris Webster","Yulun Zhou"],"url":"https://arxiv.org/abs/2506.01297"}
{"created":"2025-06-05","title":"Moving Beyond Discrete Categories: Continuous Demographic Labels for Fair Facial Recognition","abstract":"Bias has been a constant in face recognition models. Over the years, researchers have looked at it from both the model and the data point of view. However, their approach to mitigation of data bias was limited and lacked insight on the real nature of the problem. Here, in this document, we propose to revise our use of ethnicity labels as a continuous variable instead of a discrete value per identity. We validate our formulation both experimentally and theoretically, showcasing that not all identities from one ethnicity contribute equally to the balance of the dataset; thus, having the same number of identities per ethnicity does not represent a balanced dataset. We further show that models trained on datasets balanced in the continuous space consistently outperform models trained on data balanced in the discrete space. We trained more than 65 different models, and created more than 20 subsets of the original datasets.","authors":["Pedro C. Neto","Naser Damer","Jaime S. Cardoso","Ana F. Sequeira"],"url":"https://arxiv.org/abs/2506.01532"}
{"created":"2025-06-05","title":"Tug-of-war between idiom's figurative and literal meanings in LLMs","abstract":"Idioms present a unique challenge for language models due to their non-compositional figurative meanings, which often strongly diverge from the idiom's literal interpretation. This duality requires a model to learn representing and deciding between the two meanings to interpret an idiom in a figurative sense, or literally. In this paper, we employ tools from mechanistic interpretability to trace how a large pretrained causal transformer (LLama3.2-1B-base) deals with this ambiguity. We localize three steps of idiom processing: First, the idiom's figurative meaning is retrieved in early attention and MLP sublayers. We identify specific attention heads which boost the figurative meaning of the idiom while suppressing the idiom's literal interpretation. The model subsequently represents the figurative representation through an intermediate path. Meanwhile, a parallel bypass route forwards literal interpretation, ensuring that a both reading remain available. Overall, our findings provide a mechanistic evidence for idiom comprehension in an autoregressive transformer.","authors":["Soyoung Oh","Xinting Huang","Mathis Pink","Michael Hahn","Vera Demberg"],"url":"https://arxiv.org/abs/2506.01723"}
{"created":"2025-06-05","title":"Pseudorandom bits for non-commutative programs","abstract":"We obtain new explicit pseudorandom generators for several computational models involving groups. Our main results are as follows:","authors":["Chin Ho Lee","Emanuele Viola"],"url":"https://arxiv.org/abs/2506.01832"}
{"created":"2025-06-05","title":"DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes","abstract":"We introduce DualMap, an online open-vocabulary mapping system that enables robots to understand and navigate dynamically changing environments through natural language queries. Designed for efficient semantic mapping and adaptability to changing environments, DualMap meets the essential requirements for real-world robot navigation applications. Our proposed hybrid segmentation frontend and object-level status check eliminate the costly 3D object merging required by prior methods, enabling efficient online scene mapping. The dual-map representation combines a global abstract map for high-level candidate selection with a local concrete map for precise goal-reaching, effectively managing and updating dynamic changes in the environment. Through extensive experiments in both simulation and real-world scenarios, we demonstrate state-of-the-art performance in 3D open-vocabulary segmentation, efficient scene mapping, and online language-guided navigation.","authors":["Jiajun Jiang","Yiming Zhu","Zirui Wu","Jie Song"],"url":"https://arxiv.org/abs/2506.01950"}
{"created":"2025-06-05","title":"Music Interpretation and Emotion Perception: A Computational and Neurophysiological Investigation","abstract":"This study investigates emotional expression and perception in music performance using computational and neurophysiological methods. The influence of different performance settings, such as repertoire, diatonic modal etudes, and improvisation, as well as levels of expressiveness, on performers' emotional communication and listeners' reactions is explored. Professional musicians performed various tasks, and emotional annotations were provided by both performers and the audience. Audio analysis revealed that expressive and improvisational performances exhibited unique acoustic features, while emotion analysis showed stronger emotional responses. Neurophysiological measurements indicated greater relaxation in improvisational performances. This multimodal study highlights the significance of expressivity in enhancing emotional communication and audience engagement.","authors":["Vassilis Lyberatos","Spyridon Kantarelis","Ioanna Zioga","Christina Anagnostopoulou","Giorgos Stamou","Anastasia Georgaki"],"url":"https://arxiv.org/abs/2506.01982"}
{"created":"2025-06-05","title":"Random-key genetic algorithms: Principles and applications","abstract":"A random-key genetic algorithm is an evolutionary metaheuristic for discrete and global optimization. Each solution is encoded as a vector of N random keys, where a random key is a real number randomly generated in the continuous interval [0, 1). A decoder maps each vector of random keys to a solution of the optimization problem being solved and computes its cost. The benefit of this approach is that all genetic operators and transformations can be maintained within the unitary hypercube, regardless of the problem being addressed. This enhances the productivity and maintainability of the core framework. The algorithm starts with a population of P vectors of random keys. At each iteration, the vectors are partitioned into two sets: a smaller set of high-valued elite solutions and the remaining non-elite solutions. All elite elements are copied, without change, to the next population. A small number of random-key vectors (the mutants) is added to the population of the next iteration. The remaining elements of the population of the next iteration are generated by combining, with the parametrized uniform crossover of Spears and DeJong (1991), pairs of solutions. This chapter reviews random-key genetic algorithms and describes an effective variant called biased random-key genetic algorithms.","authors":["Mariana A. Londe","Luciana S. Pessoa","Carlos E. Andrade","Jos\\'e F. Gon\\c{c}alves","Mauricio G. C. Resende"],"url":"https://arxiv.org/abs/2506.02120"}
{"created":"2025-06-05","title":"MMM4Rec: A Transfer-Efficient Framework for Multi-modal Sequential Recommendation","abstract":"Sequential Recommendation (SR) systems model user preferences by analyzing interaction histories. Although transferable multi-modal SR architectures demonstrate superior performance compared to traditional ID-based approaches, current methods incur substantial fine-tuning costs when adapting to new domains due to complex optimization requirements and negative transfer effects - a significant deployment bottleneck that hinders engineers from efficiently repurposing pre-trained models for novel application scenarios with minimal tuning overhead. We propose MMM4Rec (Multi-Modal Mamba for Sequential Recommendation), a novel multi-modal SR framework that incorporates a dedicated algebraic constraint mechanism for efficient transfer learning. By combining State Space Duality (SSD)'s temporal decay properties with a time-aware modeling design, our model dynamically prioritizes key modality information, overcoming limitations of Transformer-based approaches. The framework implements a constrained two-stage process: (1) sequence-level cross-modal alignment via shared projection matrices, followed by (2) temporal fusion using our newly designed Cross-SSD module and dual-channel Fourier adaptive filtering. This architecture maintains semantic consistency while suppressing noise propagation.MMM4Rec achieves rapid fine-tuning convergence with simple cross-entropy loss, significantly improving multi-modal recommendation accuracy while maintaining strong transferability. Extensive experiments demonstrate MMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10 improvement over existing models and exhibiting 10 times faster average convergence speed when transferring to large-scale downstream datasets.","authors":["Hao Fan","Yanrong Hu","Kai Fang","Qingyang Liu","Hongjiu Liu"],"url":"https://arxiv.org/abs/2506.02916"}
{"created":"2025-06-05","title":"A Multi-agent LLM-based JUnit Test Generation with Strong Oracles","abstract":"Unit testing plays a critical role in ensuring software correctness. However, writing unit tests manually is laborious, especially for strong typed languages like Java, motivating the need for automated approaches. Traditional methods primarily rely on search-based or randomized algorithms to generate tests that achieve high code coverage and produce regression oracles, which are derived from the program's current behavior rather than its intended functionality. Recent advances in large language models (LLMs) have enabled oracle generation from natural language descriptions. However, existing LLM-based methods often require LLM fine-tuning or rely on external tools such as EvoSuite for test prefix generation.","authors":["Qinghua Xu","Guancheng Wang","Lionel Briand","Kui Liu"],"url":"https://arxiv.org/abs/2506.02943"}
{"created":"2025-06-05","title":"PC-MoE: Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs","abstract":"Mixture-of-Experts (MoE) has been gaining popularity due to its successful adaptation to large language models (LLMs). In this work, we introduce Privacy-preserving Collaborative Mixture-of-Experts (PC-MoE), which leverages the sparsity of the MoE architecture for memory-efficient decentralized collaborative LLM training, enabling multiple parties with limited GPU-memory and data resources to collectively train more capable LLMs than they could achieve individually. At the same time, this approach protects training data privacy of each participant by keeping training data, as well as parts of the forward pass signal and gradients locally within each party. By design, PC-MoE synergistically combines the strengths of distributed computation with strong confidentiality assurances. Unlike most privacy-preserving schemes, which pay for confidentiality with lower task accuracy, our framework breaks that trade-off: across seven popular LLM benchmarks, it almost matches (and sometimes exceeds) the performance and convergence rate of a fully centralized model, enjoys near 70% peak GPU RAM reduction, while being fully robust against reconstruction attacks.","authors":["Ze Yu Zhang","Bolin Ding","Bryan Kian Hsiang Low"],"url":"https://arxiv.org/abs/2506.02965"}
{"created":"2025-06-05","title":"The Attractor-Cycle Notation for Finite Transformations","abstract":"We describe a new notation for finite transformations. This attractor-cycle notation extends the orbit-cycle notation for permutations and builds upon existing transformation notations. How the basins of attraction of a finite transformation flow into permuted orbit cycles is visible from the notation. It gives insight into the structure of transformations and reduces the length of expressions without increasing the number of types of symbols.","authors":["Attila Egri-Nagy","Chrystopher L. Nehaniv"],"url":"https://arxiv.org/abs/1306.1138"}
{"created":"2025-06-05","title":"Differentially Private Distributed Mismatch Tracking Algorithm for Constraint-Coupled Resource Allocation Problems","abstract":"This paper considers privacy-concerned distributed constraint-coupled resource allocation problems over an undirected network, where each agent holds a private cost function and obtains the solution via only local communication. With privacy concerns, we mask the exchanged information with independent Laplace noise against a potential attacker with potential access to all network communications. We propose a differentially private distributed mismatch tracking algorithm (diff-DMAC) to achieve cost-optimal distribution of resources while preserving privacy. Adopting constant stepsizes, the linear convergence property of diff-DMAC in mean square is established under the standard assumptions of Lipschitz gradients and strong convexity. Moreover, it is theoretically proven that the proposed algorithm is {\\epsilon}-differentially private.And we also show the trade-off between convergence accuracy and privacy level. Finally, a numerical example is provided for verification.","authors":["Wenwen Wu","Shanying Zhu","Shuai Liu","Xinping Guan"],"url":"https://arxiv.org/abs/2204.07330"}
{"created":"2025-06-05","title":"Limit theorems of Chatterjee's rank correlation","abstract":"Establishing the limiting distribution of Chatterjee's rank correlation for a general, possibly non-independent, pair of random variables has been eagerly awaited by many. This paper shows that (a) Chatterjee's rank correlation is asymptotically normal as long as one variable is not a measurable function of the other, (b) the corresponding asymptotic variance is uniformly bounded by 36, and (c) a consistent variance estimator exists. Similar results also hold for Azadkia-Chatterjee's graph-based correlation coefficient, a multivariate analogue of Chatterjee's original proposal. The proof is given by appealing to H\\'ajek representation and Chatterjee's nearest-neighbor CLT.","authors":["Zhexiao Lin","Fang Han"],"url":"https://arxiv.org/abs/2204.08031"}
{"created":"2025-06-05","title":"Robust and Agnostic Learning of Conditional Distributional Treatment Effects","abstract":"The conditional average treatment effect (CATE) is the best measure of individual causal effects given baseline covariates. However, the CATE only captures the (conditional) average, and can overlook risks and tail events, which are important to treatment choice. In aggregate analyses, this is usually addressed by measuring the distributional treatment effect (DTE), such as differences in quantiles or tail expectations between treatment groups. Hypothetically, one can similarly fit conditional quantile regressions in each treatment group and take their difference, but this would not be robust to misspecification or provide agnostic best-in-class predictions. We provide a new robust and model-agnostic methodology for learning the conditional DTE (CDTE) for a class of problems that includes conditional quantile treatment effects, conditional super-quantile treatment effects, and conditional treatment effects on coherent risk measures given by $f$-divergences. Our method is based on constructing a special pseudo-outcome and regressing it on covariates using any regression learner. Our method is model-agnostic in that it can provide the best projection of CDTE onto the regression model class. Our method is robust in that even if we learn these nuisances nonparametrically at very slow rates, we can still learn CDTEs at rates that depend on the class complexity and even conduct inferences on linear projections of CDTEs. We investigate the behavior of our proposal in simulations, as well as in a case study of 401(k) eligibility effects on wealth.","authors":["Nathan Kallus","Miruna Oprescu"],"url":"https://arxiv.org/abs/2205.11486"}
{"created":"2025-06-05","title":"Data-driven stabilization of switched and constrained linear systems","abstract":"We consider the design of state feedback control laws for both the switching signal and the continuous input of an unknown switched linear system, given past noisy input-state trajectories measurements. Based on Lyapunov-Metzler inequalities, we derive data-dependent bilinear programs whose solution directly returns a provably stabilizing controller and ensures $\\mathcal{H}_2$ or $\\mathcal{H}_{\\infty}$ performance. We further present relaxations that considerably reduce the computational cost, still without requiring stabilizability of any of the switching modes. Finally, we showcase the flexibility of our approach on the constrained stabilization problem for a perturbed linear system. We validate our theoretical findings numerically, demonstrating the favourable trade-off between conservatism and tractability achieved by the proposed relaxations.","authors":["Mattia Bianchi","Sergio Grammatico","Jorge Cort\\'es"],"url":"https://arxiv.org/abs/2208.11392"}
{"created":"2025-06-05","title":"How Two-Layer Neural Networks Learn, One (Giant) Step at a Time","abstract":"For high-dimensional Gaussian data, we investigate theoretically how the features of a two-layer neural network adapt to the structure of the target function through a few large batch gradient descent steps, leading to an improvement in the approximation capacity from initialization. First, we compare the influence of batch size to that of multiple steps. For a single step, a batch of size $n = \\mathcal{O}(d)$ is both necessary and sufficient to align with the target function, although only a single direction can be learned. In contrast, $n = \\mathcal{O}(d^2)$ is essential for neurons to specialize in multiple relevant directions of the target with a single gradient step. Even in this case, we show there might exist ``hard'' directions requiring $n = \\mathcal{O}(d^\\ell)$ samples to be learned, where $\\ell$ is known as the leap index of the target. Second, we show that the picture drastically improves over multiple gradient steps: a batch size of $n = \\mathcal{O}(d)$ is indeed sufficient to learn multiple target directions satisfying a staircase property, where more and more directions can be learned over time. Finally, we discuss how these directions allow for a drastic improvement in the approximation capacity and generalization error over the initialization, illustrating a separation of scale between the random features/lazy regime and the feature learning regime. Our technical analysis leverages a combination of techniques related to concentration, projection-based conditioning, and Gaussian equivalence, which we believe are of independent interest. By pinning down the conditions necessary for specialization and learning, our results highlight the intertwined role of the structure of the task to learn, the details of the algorithm, and the architecture, shedding new light on how neural networks adapt to the feature and learn complex task from data over time.","authors":["Yatin Dandi","Florent Krzakala","Bruno Loureiro","Luca Pesce","Ludovic Stephan"],"url":"https://arxiv.org/abs/2305.18270"}
{"created":"2025-06-05","title":"Quantifying edge relevance for epidemic spreading via the semi-metric topology of complex networks","abstract":"Sparsification aims at extracting a reduced core of associations that best preserves both the dynamics and topology of networks while reducing the computational cost of simulations. We show that the semi-metric topology of complex networks yields a natural and algebraically-principled sparsification that outperforms existing methods on those goals. Weighted graphs whose edges represent distances between nodes are semi-metric when at least one edge breaks the triangle inequality (transitivity). We first confirm with new experiments that the metric backbone$\\unicode{x2013}$a unique subgraph of all edges that obey the triangle inequality and thus preserve all shortest paths$\\unicode{x2013}$recovers Susceptible-Infected dynamics over the original non-sparsified graph. This recovery is improved when we remove only those edges that break the triangle inequality significantly, i.e., edges with large semi-metric distortion. Based on these results, we propose the new semi-metric distortion sparsification method to progressively sparsify networks in decreasing order of semi-metric distortion. Our method recovers the macro- and micro-level dynamics of epidemic outbreaks better than other methods while also yielding sparser yet connected subgraphs that preserve all shortest paths. Overall, we show that semi-metric distortion overcomes the limitations of edge betweenness in ranking the dynamical relevance of edges not participating in any shortest path, as it quantifies the existence and strength of alternative transmission pathways.","authors":["David Soriano Pa\\~nos","Felipe Xavier Costa","Luis M. Rocha"],"url":"https://arxiv.org/abs/2311.14817"}
{"created":"2025-06-05","title":"HIST-Critical Graphs and Malkevitch's Conjecture","abstract":"In a given graph, a HIST is a spanning tree without $2$-valent vertices. Motivated by developing a better understanding of HIST-free graphs, i.e. graphs containing no HIST, in this article's first part we study HIST-critical graphs, i.e. HIST-free graphs in which every vertex-deleted subgraph does contain a HIST (e.g. a triangle). We give an almost complete characterisation of the orders for which these graphs exist and present an infinite family of planar examples which are $3$-connected and in which nearly all vertices are $4$-valent. This leads naturally to the second part in which we investigate planar $4$-regular graphs with and without HISTs, motivated by a conjecture of Malkevitch, which we computationally verify up to order $22$. First we enumerate HISTs in antiprisms, whereafter we present planar $4$-regular graphs with and without HISTs, obtained via line graphs. Finally, we confirm Malkevitch's conjecture for the family of line graphs of cyclically $4$-edge connected cubic graphs.","authors":["Jan Goedgebeur","Kenta Noguchi","Jarne Renders","Carol T. Zamfirescu"],"url":"https://arxiv.org/abs/2401.04554"}
{"created":"2025-06-05","title":"NCoder -- A Quantum Field Theory approach to encoding data","abstract":"In this paper we present a novel approach to interpretable AI inspired by Quantum Field Theory (QFT) which we call the NCoder. The NCoder is a modified autoencoder neural network whose latent layer is prescribed to be a subset of $n$-point correlation functions. Regarding images as draws from a lattice field theory, this architecture mimics the task of perturbatively constructing the effective action of the theory order by order in an expansion using Feynman diagrams. Alternatively, the NCoder may be regarded as simulating the procedure of statistical inference whereby high dimensional data is first summarized in terms of several lower dimensional summary statistics (here the $n$-point correlation functions), and subsequent out-of-sample data is generated by inferring the data generating distribution from these statistics. In this way the NCoder suggests a fascinating correspondence between perturbative renormalizability and the sufficiency of models. We demonstrate the efficacy of the NCoder by applying it to the generation of MNIST images, and find that generated images can be correctly classified using only information from the first three $n$-point functions of the image distribution.","authors":["David S. Berman","Marc S. Klinger","Alexander G. Stapleton"],"url":"https://arxiv.org/abs/2402.00944"}
{"created":"2025-06-05","title":"Language-Codec: Bridging Discrete Codec Representations and Speech Language Models","abstract":"In recent years, large language models have achieved significant success in generative tasks related to speech, audio, music, and other signal domains. A crucial element of these models is the discrete acoustic codecs, which serve as an intermediate representation replacing the mel-spectrogram. However, there exist several gaps between discrete codecs and downstream speech language models. Specifically, 1) Due to the reconstruction paradigm of the Codec model and the structure of residual vector quantization, the initial channel of the codebooks contains excessive information, making it challenging to directly generate acoustic tokens from weakly supervised signals such as text in downstream tasks. 2) numerous codebooks increases the burden on downstream speech language models. Consequently, leveraging the characteristics of speech language models, we propose Language-Codec. In the Language-Codec, we introduce a Masked Channel Residual Vector Quantization (MCRVQ) mechanism along with improved fourier transform structures and attention blocks, refined discriminator design to address the aforementioned gaps. We compare our method with competing audio compression algorithms and observe significant outperformance across extensive evaluations. Furthermore, we also validate the efficiency of the Language-Codec on downstream speech language models. The source code and pre-trained models can be accessed at https://github.com/jishengpeng/languagecodec .","authors":["Shengpeng Ji","Minghui Fang","Jialong Zuo","Ziyue Jiang","Dingdong Wang","Hanting Wang","Hai Huang","Zhou Zhao"],"url":"https://arxiv.org/abs/2402.12208"}
{"created":"2025-06-05","title":"Batched Nonparametric Contextual Bandits","abstract":"We study nonparametric contextual bandits under batch constraints, where the expected reward for each action is modeled as a smooth function of covariates, and the policy updates are made at the end of each batch of observations. We establish a minimax regret lower bound for this setting and propose a novel batch learning algorithm that achieves the optimal regret (up to logarithmic factors). In essence, our procedure dynamically splits the covariate space into smaller bins, carefully aligning their widths with the batch size. Our theoretical results suggest that for nonparametric contextual bandits, a nearly constant number of policy updates can attain optimal regret in the fully online setting.","authors":["Rong Jiang","Cong Ma"],"url":"https://arxiv.org/abs/2402.17732"}
{"created":"2025-06-05","title":"Development of an offline and online hybrid model for the Integrated Forecasting System","abstract":"In recent years, there has been significant progress in the development of fully data-driven global numerical weather prediction models. These machine learning weather prediction models have their strength, notably accuracy and low computational requirements, but also their weakness: they struggle to represent fundamental dynamical balances, and they are far from being suitable for data assimilation experiments. Hybrid modelling emerges as a promising approach to address these limitations. Hybrid models integrate a physics-based core component with a statistical component, typically a neural network, to enhance prediction capabilities. In this article, we propose to develop a model error correction for the operational Integrated Forecasting System (IFS) of the European Centre for Medium-Range Weather Forecasts using a neural network. The neural network is initially pre-trained offline using a large dataset of operational analyses and analysis increments. Subsequently, the trained network is integrated into the IFS within the Object-Oriented Prediction System (OOPS) so as to be used in data assimilation and forecast experiments. It is then further trained online using a recently developed variant of weak-constraint 4D-Var. The results show that the pre-trained neural network already provides a reliable model error correction, which translates into reduced forecast errors in many conditions and that the online training further improves the accuracy of the hybrid model in many conditions.","authors":["Alban Farchi","Marcin Chrust","Marc Bocquet","Massimo Bonavita"],"url":"https://arxiv.org/abs/2403.03702"}
{"created":"2025-06-05","title":"Least Squares Estimation For Hierarchical Data","abstract":"The U.S. Census Bureau's 2020 Disclosure Avoidance System (DAS) bases its output on noisy measurements, which are population tabulations added to realizations of mean-zero random variables. These noisy measurements are observed for a set of hierarchical geographic units, e.g., the U.S. as a whole, states, counties, census tracts, and census blocks. The Census Bureau released the noisy measurements generated in the DAS executions for the two primary 2020 Census data products, in part to allow data users to assess uncertainty in 2020 Census tabulations introduced by disclosure avoidance. This paper describes an algorithm that can leverage a hierarchical structure of the input data in order to compute very high dimensional least squares estimates in a computationally efficient manner. Afterward, we show that this algorithm's output is equal to the generalized least squares estimator, describe how to find the variance of linear functions of this estimator, and provide a numerical experiment in which we compute confidence intervals of 2010 Census tabulations based on this estimator. We also describe an accompanying Census Bureau experimental data product that applies this estimator to the publicly available noisy measurements to provide data users with the inputs required to estimate confidence intervals for all tabulations that were included in one of the two main 2020 Census data products, i.e., the 2020 Redistricting Data Product, in the US, state, county, and census tract geographic levels.","authors":["Ryan Cumings-Menon","Pavel Zhuravlev"],"url":"https://arxiv.org/abs/2404.13164"}
{"created":"2025-06-05","title":"AI and the Dynamic Supply of Training Data","abstract":"Artificial intelligence (AI) systems rely heavily on human-generated data, yet the people behind that data are often overlooked. Human behavior can play a major role in AI training datasets, be it in limiting access to existing works or in deciding which types of new works to create or whether to create any at all. We examine creators' behavioral change when their works become training data for commercial AI. Specifically, we focus on contributors on Unsplash, a popular stock image platform with about 6 million high-quality photos and illustrations. In the summer of 2020, Unsplash launched a research program and released a dataset of 25,000 images for commercial AI use. We study contributors' reactions, comparing contributors whose works were included in this dataset to contributors whose works were not. Our results suggest that treated contributors left the platform at a higher-than-usual rate and substantially slowed down the rate of new uploads. Professional photographers and more heavily affected users had a stronger reaction than amateurs and less affected users. We also show that affected users changed the variety and novelty of contributions to the platform, which can potentially lead to lower-quality AI outputs in the long run. Our findings highlight a critical trade-off: the drive to expand AI capabilities versus the incentives of those producing training data. We conclude with policy proposals, including dynamic compensation schemes and structured data markets, to realign incentives at the data frontier.","authors":["Christian Peukert","Florian Abeillon","J\\'er\\'emie Haese","Franziska Kaiser","Alexander Staub"],"url":"https://arxiv.org/abs/2404.18445"}
{"created":"2025-06-05","title":"Two questions on Kneser colorings","abstract":"In this paper, we investigate two questions on Kneser graphs $KG_{n,k}$. First, we prove that the union of $s$ intersecting families in ${[n]\\choose k}$ has size at most ${n\\choose k}-{n-s\\choose k}$ for all sufficiently large $n$ that satisfy $n>(2+\\epsilon)k^2+s$ with $\\epsilon>0$. We provide an example that shows that this result is essentially tight for the number of colors close to $\\chi(KG_{n,k})=n-2k+2$. We also improve the result of Bulankina and Kupavskii on the choice chromatic number, showing that it is at least $\\frac 1{25} n\\log n$ for all $k<\\sqrt n$ and $n$ sufficiently large.","authors":["Eduard Inozemtsev","Andrey Kupavskii"],"url":"https://arxiv.org/abs/2405.08797"}
{"created":"2025-06-05","title":"ControlSpeech: Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control","abstract":"In this paper, we present ControlSpeech, a text-to-speech (TTS) system capable of fully cloning the speaker's voice and enabling arbitrary control and adjustment of speaking style. Prior zero-shot TTS models only mimic the speaker's voice without further control and adjustment capabilities while prior controllable TTS models cannot perform speaker-specific voice generation. Therefore, ControlSpeech focuses on a more challenging task: a TTS system with controllable timbre, content, and style at the same time. ControlSpeech takes speech prompts, content prompts, and style prompts as inputs and utilizes bidirectional attention and mask-based parallel decoding to capture codec representations corresponding to timbre, content, and style in a discrete decoupling codec space. Moreover, we analyze the many-to-many issue in textual style control and propose the Style Mixture Semantic Density (SMSD) module, which is based on Gaussian mixture density networks, to resolve this problem. To facilitate empirical validations, we make available a new style controllable dataset called VccmDataset. Our experimental results demonstrate that ControlSpeech exhibits comparable or state-of-the-art (SOTA) performance in terms of controllability, timbre similarity, audio quality, robustness, and generalizability. The relevant code and demo are available at https://github.com/jishengpeng/ControlSpeech .","authors":["Shengpeng Ji","Qian Chen","Wen Wang","Jialong Zuo","Minghui Fang","Ziyue Jiang","Hai Huang","Zehan Wang","Xize Cheng","Siqi Zheng","Zhou Zhao"],"url":"https://arxiv.org/abs/2406.01205"}
{"created":"2025-06-05","title":"Quantum Natural Stochastic Pairwise Coordinate Descent","abstract":"Variational quantum algorithms, optimized using gradient-based methods, often exhibit sub-optimal convergence performance due to their dependence on Euclidean geometry. Quantum natural gradient descent (QNGD) is a more efficient method that incorporates the geometry of the state space via a quantum information metric. However, QNGD is computationally intensive and suffers from high sample complexity. In this work, we formulate a novel quantum information metric and construct an unbiased estimator for this metric using single-shot measurements. We develop a quantum optimization algorithm that leverages the geometry of the state space via this estimator while avoiding full-state tomography, as in conventional techniques. We provide the convergence analysis of the algorithm under mild conditions. Furthermore, we provide experimental results that demonstrate the better sample complexity and faster convergence of our algorithm compared to the state-of-the-art approaches. Our results illustrate the algorithm's ability to avoid saddle points and local minima.","authors":["Mohammad Aamir Sohail","Mohsen Heidari","S. Sandeep Pradhan"],"url":"https://arxiv.org/abs/2407.13858"}
{"created":"2025-06-05","title":"Partitioning 2-edge-coloured bipartite graphs into monochromatic cycles","abstract":"Given an $r$-edge-colouring of the edges of a graph $G$, we say that it can be partitioned into $p$ monochromatic cycles when there exists a set of $p$ vertex-disjoint monochromatic cycles covering all the vertices of $G$. In the literature of this problem, an edge and a single vertex both count as a cycle.","authors":["Fabr\\'icio Siqueira Benevides","Arthur Lima Quintino","Alexandre Talon"],"url":"https://arxiv.org/abs/2409.03394"}
{"created":"2025-06-05","title":"Sequence modeling of higher-order wave modes of binary black hole mergers","abstract":"Higher-order gravitational wave modes from quasi-circular, spinning, non-precessing binary black hole mergers encode key information about these systems' nonlinear dynamics. We model these waveforms using transformer architectures, targeting the evolution from late inspiral through ringdown. Our data is derived from the \\texttt{NRHybSur3dq8} surrogate model, which includes spherical harmonic modes up to $\\ell \\leq 4$ (excluding $(4,0)$, $(4,\\pm1)$ and including $(5,5)$ modes). These waveforms span mass ratios $q \\leq 8$, spin components $s^z_{{1,2}} \\in [-0.8, 0.8]$, and inclination angles $\\theta \\in [0, \\pi]$. The model processes input data over the time interval $t \\in [-5000\\textrm{M}, -100\\textrm{M})$ and generates predictions for the plus and cross polarizations, $(h_{+}, h_{\\times})$, over the interval $t \\in [-100\\textrm{M}, 130\\textrm{M}]$. Utilizing 16 NVIDIA A100 GPUs on the Delta supercomputer, we trained the transformer model in 15 hours on over 14 million samples. The model's performance was evaluated on a test dataset of 840,000 samples, achieving mean and median overlap scores of 0.996 and 0.997, respectively, relative to the surrogate-based ground truth signals. We further benchmark the model on numerical relativity waveforms from the SXS catalog, finding that it generalizes well to out-of-distribution systems, capable of reproducing the dynamics of systems with mass ratios up to $q=15$ and spin magnitudes up to 0.998, with a median overlap of 0.969 across 521 NR waveforms and up to 0.998 in face-on/off configurations. These results demonstrate that transformer-based models can capture the nonlinear dynamics of binary black hole mergers with high accuracy, even outside the surrogate training domain, enabling fast sequence modeling of higher-order wave modes.","authors":["Victoria Tiki","Kiet Pham","Eliu Huerta"],"url":"https://arxiv.org/abs/2409.03833"}
{"created":"2025-06-05","title":"Codes on Weighted Projective Planes","abstract":"We comprehensively study weighted projective Reed-Muller (WPRM) codes on weighted projective planes $\\mathbb{P}(1,a,b)$. We provide the universal Gr\\\"obner basis for the vanishing ideal of the set $Y$ of $\\mathbb{F}_q$--rational points of $\\mathbb{P}(1,a,b)$ to get the dimension of the code. We determine the regularity set of $Y$ using a novel combinatorial approach. We employ footprint techniques to compute the minimum distance.","authors":["Ya\\u{g}mur \\c{C}ak{\\i}ro\\u{g}lu","Jade Nardi","Mesut \\c{S}ahin"],"url":"https://arxiv.org/abs/2410.11968"}
{"created":"2025-06-05","title":"Fermionic Independent Set and Laplacian of an independence complex are QMA-hard","abstract":"The Independent Set is a well known NP-hard optimization problem. In this work, we define a fermionic generalization of the Independent Set problem and prove that the optimization problem is QMA-hard in a $k$-particle subspace using perturbative gadgets. We discuss how the Fermionic Independent Set is related to the problem of computing the minimum eigenvalue of the $k^{\\text{th}}$-Laplacian of an independence complex of a vertex weighted graph. Consequently, we use the same perturbative gadget to prove QMA-hardness of the later problem resolving an open conjecture from arXiv:2311.17234 and give the first example of a natural topological data analysis problem that is QMA-hard.","authors":["Chaithanya Rayudu"],"url":"https://arxiv.org/abs/2411.03230"}
{"created":"2025-06-05","title":"A Survey of Cameron-Liebler Sets and Low Degree Boolean Functions in Grassmann Graphs","abstract":"We survey results for Cameron-Liebler sets and low degree Boolean functions for Hamming graphs, Johnson graphs and Grassmann graphs from the point of view of association schemes. This survey covers selected results in finite geometry, Boolean function analysis, design theory, coding theory, and cryptography.","authors":["Ferdinand Ihringer"],"url":"https://arxiv.org/abs/2411.16288"}
{"created":"2025-06-05","title":"CatNet: Controlling the False Discovery Rate in LSTM with SHAP Feature Importance and Gaussian Mirrors","abstract":"We introduce CatNet, an algorithm that effectively controls False Discovery Rate (FDR) and selects significant features in LSTM. CatNet employs the derivative of SHAP values to quantify the feature importance, and constructs a vector-formed mirror statistic for FDR control with the Gaussian Mirror algorithm. To avoid instability due to nonlinear or temporal correlations among features, we also propose a new kernel-based independence measure. CatNet performs robustly on different model settings with both simulated and real-world data, which reduces overfitting and improves interpretability of the model. Our framework that introduces SHAP for feature importance in FDR control algorithms and improves Gaussian Mirror can be naturally extended to other time-series or sequential deep learning models.","authors":["Jiaan Han","Junxiao Chen","Yanzhe Fu"],"url":"https://arxiv.org/abs/2411.16666"}
{"created":"2025-06-05","title":"Multiplex Nodal Modularity: A novel network metric for the regional analysis of amnestic mild cognitive impairment during a working memory binding task","abstract":"Modularity is a well-established concept for assessing community structures in various single and multi-layer networks, including those in biological and social domains. Brain networks are known to exhibit community structure at local, meso, and global scale. However, modularity is limited as a metric to a global scale describing the overall strength of community structure, overlooking important variations in community structure at node level. To address this limitation, we extended modularity to individual nodes. This novel measure of nodal modularity (nQ) captures both mesoscale and local-scale changes in modularity. We hypothesized that nQ would illuminate granular changes in the brain due to diseases such as Alzheimer's disease (AD), which are known to disrupt the brain's modular structure. We explored nQ in multiplex networks of a visual short-term memory binding task in fMRI and DTI data in the early stages of AD. While limited by sample size, changes in nQ for individual regions of interest (ROIs) in our fMRI networks were predominantly observed in visual, limbic, and paralimbic systems in the brain, aligning with known AD trajectories and linked to amyloid-$\\beta$ and tau deposition. Furthermore, observed changes in white-matter microstructure in our DTI networks in parietal and frontal regions may compliment studies of white-matter integrity in poor memory binders. Additionally, nQ clearly differentiated MCI from MCI converters indicating that nQ may be sensitive to this key turning point of AD. Our findings demonstrate the utility of nQ as a measure of localized group structure, providing novel insights into task and disease-related variability at the node level. Given the widespread application of modularity as a global measure, nQ represents a significant advancement, providing a granular measure of network organization applicable to a wide range of disciplines.","authors":["Avalon Campbell-Cousins","Federica Guazzo","Mark Bastin","Mario A. Parra","Javier Escudero"],"url":"https://arxiv.org/abs/2501.09805"}
{"created":"2025-06-05","title":"Improving thermal state preparation of Sachdev-Ye-Kitaev model with reinforcement learning on quantum hardware","abstract":"The Sachdev-Ye-Kitaev (SYK) model, known for its strong quantum correlations and chaotic behavior, serves as a key platform for quantum gravity studies. However, variationally preparing thermal states on near-term quantum processors for large systems ($N>12$, where $N$ is the number of Majorana fermions) presents a significant challenge due to the rapid growth in the complexity of parameterized quantum circuits. This paper addresses this challenge by integrating reinforcement learning (RL) with convolutional neural networks, employing an iterative approach to optimize the quantum circuit and its parameters. The refinement process is guided by a composite reward signal derived from entropy and the expectation values of the SYK Hamiltonian. This approach reduces the number of CNOT gates by two orders of magnitude for systems $N\\geq12$ compared to traditional methods like first-order Trotterization. We demonstrate the effectiveness of the RL framework in both noiseless and noisy quantum hardware environments, maintaining high accuracy in thermal state preparation. This work advances a scalable, RL-based framework with applications for quantum gravity studies and out-of-time-ordered thermal correlators computation in quantum many-body systems on near-term quantum hardware. The code is available at https://github.com/Aqasch/solving_SYK_model_with_RL.","authors":["Akash Kundu"],"url":"https://arxiv.org/abs/2501.11454"}
{"created":"2025-06-05","title":"UltraBones100k: A reliable automated labeling method and large-scale dataset for ultrasound-based bone surface extraction","abstract":"Ultrasound-based bone surface segmentation is crucial in computer-assisted orthopedic surgery. However, ultrasound images have limitations, including a low signal-to-noise ratio, and acoustic shadowing, which make interpretation difficult. Existing deep learning models for bone segmentation rely primarily on costly manual labeling by experts, limiting dataset size and model generalizability. Additionally, the complexity of ultrasound physics and acoustic shadow makes the images difficult for humans to interpret, leading to incomplete labels in anechoic regions and limiting model performance. To advance ultrasound bone segmentation and establish effective model benchmarks, larger and higher-quality datasets are needed.","authors":["Luohong Wu","Nicola A. Cavalcanti","Matthias Seibold","Giuseppe Loggia","Lisa Reissner","Jonas Hein","Silvan Beeler","Arnd Vieh\\\"ofer","Stephan Wirth","Lilian Calvet","Philipp F\\\"urnstahl"],"url":"https://arxiv.org/abs/2502.03783"}
{"created":"2025-06-05","title":"CellFlux: Simulating Cellular Morphology Changes via Flow Matching","abstract":"Building a virtual cell capable of accurately simulating cellular behaviors in silico has long been a dream in computational biology. We introduce CellFlux, an image-generative model that simulates cellular morphology changes induced by chemical and genetic perturbations using flow matching. Unlike prior methods, CellFlux models distribution-wise transformations from unperturbed to perturbed cell states, effectively distinguishing actual perturbation effects from experimental artifacts such as batch effects -- a major challenge in biological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined perturbation (JUMP) datasets, CellFlux generates biologically meaningful cell images that faithfully capture perturbation-specific morphological changes, achieving a 35% improvement in FID scores and a 12% increase in mode-of-action prediction accuracy over existing methods. Additionally, CellFlux enables continuous interpolation between cellular states, providing a potential tool for studying perturbation dynamics. These capabilities mark a significant step toward realizing virtual cell modeling for biomedical research. Project page: https://yuhui-zh15.github.io/CellFlux/.","authors":["Yuhui Zhang","Yuchang Su","Chenyu Wang","Tianhong Li","Zoe Wefers","Jeffrey Nirschl","James Burgess","Daisy Ding","Alejandro Lozano","Emma Lundberg","Serena Yeung-Levy"],"url":"https://arxiv.org/abs/2502.09775"}
{"created":"2025-06-05","title":"How Compositional Generalization and Creativity Improve as Diffusion Models are Trained","abstract":"Natural data is often organized as a hierarchical composition of features. How many samples do generative models need in order to learn the composition rules, so as to produce a combinatorially large number of novel data? What signal in the data is exploited to learn those rules? We investigate these questions in the context of diffusion models both theoretically and empirically. Theoretically, we consider a simple probabilistic context-free grammar - a tree-like graphical model used to represent the hierarchical and compositional structure of data such as language and images. We demonstrate that diffusion models learn the grammar's composition rules with the sample complexity required for clustering features with statistically similar context, a process similar to the word2vec algorithm. However, this clustering emerges hierarchically: higher-level features associated with longer contexts require more data to be identified. This mechanism leads to a sample complexity that scales polynomially with the said context size. As a result, diffusion models trained on an intermediate dataset size generate data coherent up to a certain scale, but lacking global coherence. We test these predictions across different domains and find remarkable agreement: both generated texts and images achieve progressively larger coherence lengths as the training time or dataset size grows. We discuss connections between the hierarchical clustering mechanism we introduce here and the renormalization group in physics.","authors":["Alessandro Favero","Antonio Sclocchi","Francesco Cagnetta","Pascal Frossard","Matthieu Wyart"],"url":"https://arxiv.org/abs/2502.12089"}
{"created":"2025-06-05","title":"Human Misperception of Generative-AI Alignment: A Laboratory Experiment","abstract":"We conduct an incentivized laboratory experiment to study people's perception of generative artificial intelligence (GenAI) alignment in the context of economic decision-making. Using a panel of economic problems spanning the domains of risk, time preference, social preference, and strategic interactions, we ask human subjects to make choices for themselves and to predict the choices made by GenAI on behalf of a human user. We find that people overestimate the degree of alignment between GenAI's choices and human choices. In every problem, human subjects' average prediction about GenAI's choice is substantially closer to the average human-subject choice than it is to the GenAI choice. At the individual level, different subjects' predictions about GenAI's choice in a given problem are highly correlated with their own choices in the same problem. We explore the implications of people overestimating GenAI alignment in a simple theoretical model.","authors":["Kevin He","Ran Shorrer","Mengjia Xia"],"url":"https://arxiv.org/abs/2502.14708"}
{"created":"2025-06-05","title":"Nested Expectations with Kernel Quadrature","abstract":"This paper considers the challenging computational task of estimating nested expectations. Existing algorithms, such as nested Monte Carlo or multilevel Monte Carlo, are known to be consistent but require a large number of samples at both inner and outer levels to converge. Instead, we propose a novel estimator consisting of nested kernel quadrature estimators and we prove that it has a faster convergence rate than all baseline methods when the integrands have sufficient smoothness. We then demonstrate empirically that our proposed method does indeed require fewer samples to estimate nested expectations on real-world applications including Bayesian optimisation, option pricing, and health economics.","authors":["Zonghao Chen","Masha Naslidnyk","Fran\\c{c}ois-Xavier Briol"],"url":"https://arxiv.org/abs/2502.18284"}
{"created":"2025-06-05","title":"Rapid Bone Scintigraphy Enhancement via Semantic Prior Distillation from Segment Anything Model","abstract":"Rapid bone scintigraphy is crucial for diagnosing skeletal disorders and detecting tumor metastases in children, as it shortens scan duration and reduces discomfort. However, accelerated acquisition often degrades image quality, impairing the visibility of fine anatomical details and potentially compromising diagnosis. To overcome this limitation, we introduce the first application of SAM-based semantic priors for medical image restoration, utilizing the Segment Anything Model (SAM) to enhance pediatric rapid bone scintigraphy. Our approach employs two cascaded networks, $f^{IR1}$ and $f^{IR2}$, supported by three specialized modules: a Semantic Prior Integration (SPI) module, a Semantic Knowledge Distillation (SKD) module, and a Semantic Consistency Module (SCM). The SPI and SKD modules inject domain-specific semantic cues from a fine-tuned SAM, while the SCM preserves coherent semantic feature representations across both cascaded stages. Moreover, we present RBS, a novel Rapid Bone Scintigraphy dataset comprising paired standard (20 cm/min) and rapid (40 cm/min) scans from 137 pediatric patients aged 0.5 - 16 years, making it the first dataset tailored for pediatric rapid bone scintigraphy restoration. Extensive experiments on both a public endoscopic dataset and our RBS dataset demonstrate that our method consistently surpasses existing techniques in PSNR, SSIM, FID, and LPIPS metrics.","authors":["Pengchen Liang","Leijun Shi","Huiping Yao","Bin Pu","Jianguo Chen","Lei Zhao","Haishan Huang","Zhuangzhuang Chen","Zhaozhao Xu","Lite Xu","Qing Chang","Yiwei Li"],"url":"https://arxiv.org/abs/2503.02321"}
{"created":"2025-06-05","title":"Wyckoff Transformer: Generation of Symmetric Crystals","abstract":"Crystal symmetry plays a fundamental role in determining its physical, chemical, and electronic properties such as electrical and thermal conductivity, optical and polarization behavior, and mechanical strength. Almost all known crystalline materials have internal symmetry. However, this is often inadequately addressed by existing generative models, making the consistent generation of stable and symmetrically valid crystal structures a significant challenge. We introduce WyFormer, a generative model that directly tackles this by formally conditioning on space group symmetry. It achieves this by using Wyckoff positions as the basis for an elegant, compressed, and discrete structure representation. To model the distribution, we develop a permutation-invariant autoregressive model based on the Transformer encoder and an absence of positional encoding. Extensive experimentation demonstrates WyFormer's compelling combination of attributes: it achieves best-in-class symmetry-conditioned generation, incorporates a physics-motivated inductive bias, produces structures with competitive stability, predicts material properties with competitive accuracy even without atomic coordinates, and exhibits unparalleled inference speed.","authors":["Nikita Kazeev","Wei Nong","Ignat Romanov","Ruiming Zhu","Andrey Ustyuzhanin","Shuya Yamazaki","Kedar Hippalgaonkar"],"url":"https://arxiv.org/abs/2503.02407"}
{"created":"2025-06-05","title":"Generalization in Federated Learning: A Conditional Mutual Information Framework","abstract":"Federated learning (FL) is a widely adopted privacy-preserving distributed learning framework, yet its generalization performance remains less explored compared to centralized learning. In FL, the generalization error consists of two components: the out-of-sample gap, which measures the gap between the empirical and true risk for participating clients, and the participation gap, which quantifies the risk difference between participating and non-participating clients. In this work, we apply an information-theoretic analysis via the conditional mutual information (CMI) framework to study FL's two-level generalization. Beyond the traditional supersample-based CMI framework, we introduce a superclient construction to accommodate the two-level generalization setting in FL. We derive multiple CMI-based bounds, including hypothesis-based CMI bounds, illustrating how privacy constraints in FL can imply generalization guarantees. Furthermore, we propose fast-rate evaluated CMI bounds that recover the best-known convergence rate for two-level FL generalization in the small empirical risk regime. For specific FL model aggregation strategies and structured loss functions, we refine our bounds to achieve improved convergence rates with respect to the number of participating clients. Empirical evaluations confirm that our evaluated CMI bounds are non-vacuous and accurately capture the generalization behavior of FL algorithms.","authors":["Ziqiao Wang","Cheng Long","Yongyi Mao"],"url":"https://arxiv.org/abs/2503.04091"}
{"created":"2025-06-05","title":"Conditional Independence Test Based on Transport Maps","abstract":"Testing conditional independence between two random vectors given a third is a fundamental and challenging problem in statistics, particularly in multivariate nonparametric settings due to the complexity of conditional structures. We propose a innovative framework for testing conditional independence using transport maps. At the population level, we show that two well-defined transport maps can transform the conditional independence test into an unconditional independence test, this substantially simplifies the problem. These transport maps are estimated from data using conditional continuous normalizing flow models. Within this framework, we derive a test statistic and prove its asymptotic validity under both the null and alternative hypotheses. A permutation-based procedure is employed to evaluate the significance of the test. We validate the proposed method through extensive simulations and real-data analysis. Our numerical studies demonstrate the practical effectiveness of the proposed method for conditional independence testing.","authors":["Chenxuan He","Yuan Gao","Liping Zhu","Jian Huang"],"url":"https://arxiv.org/abs/2504.09567"}
{"created":"2025-06-05","title":"Level-set topology optimisation with unfitted finite elements and automatic shape differentiation","abstract":"In this paper we develop automatic shape differentiation techniques for unfitted discretisations and link these to recent advances in shape calculus for unfitted methods. We extend existing analytic shape calculus results to the case where the domain boundary intersects with the boundary of the background domain. We further show that we can recover these analytic derivatives to machine precision regardless of the mesh size using the developed automatic shape differentiation techniques, drastically reducing the burden associated with the analytic derivation of these quantities. In addition, we show that we can also recover the symmetric shape Hessian. We implement these techniques for both serial and distributed computing frameworks in the Julia package GridapTopOpt and the wider Gridap ecosystem. As part of this implementation we propose a novel graph-based approach for isolated volume detection. We demonstrate the applicability of the unfitted automatic shape differentiation framework and our implementation by considering the three-dimensional minimum compliance topology optimisation of a linear elastic wheel and of a linear elastic structure in a fluid-structure interaction problem with Stokes flow. The implementation is general and allows GridapTopOpt to solve a wider range of problems on unstructured meshes without analytic calculation of shape derivatives and avoiding issues that arise when material properties are smoothed at the domain boundary. The software is open source and available at https://github.com/zjwegert/GridapTopOpt.jl.","authors":["Zachary J. Wegert","Jordi Manyer","Connor Mallon","Santiago Badia","Vivien J. Challis"],"url":"https://arxiv.org/abs/2504.09748"}
{"created":"2025-06-05","title":"Towards a deep learning approach for classifying treatment response in glioblastomas","abstract":"Glioblastomas are the most aggressive type of glioma, having a 5-year survival rate of 6.9%. Treatment typically involves surgery, followed by radiotherapy and chemotherapy, and frequent magnetic resonance imaging (MRI) scans to monitor disease progression. To assess treatment response, radiologists use the Response Assessment in Neuro-Oncology (RANO) criteria to categorize the tumor into one of four labels based on imaging and clinical features: complete response, partial response, stable disease, and progressive disease. This assessment is very complex and time-consuming. Since deep learning (DL) has been widely used to tackle classification problems, this work aimed to implement the first DL pipeline for the classification of RANO criteria based on two consecutive MRI acquisitions. The models were trained and tested on the open dataset LUMIERE. Five approaches were tested: 1) subtraction of input images, 2) different combinations of modalities, 3) different model architectures, 4) different pretraining tasks, and 5) adding clinical data. The pipeline that achieved the best performance used a Densenet264 considering only T1-weighted, T2-weighted, and Fluid Attenuated Inversion Recovery (FLAIR) images as input without any pretraining. A median Balanced Accuracy of 50.96% was achieved. Additionally, explainability methods were applied. Using Saliency Maps, the tumor region was often successfully highlighted. In contrast, Grad-CAM typically failed to highlight the tumor region, with some exceptions observed in the Complete Response and Progressive Disease classes, where it effectively identified the tumor region. These results set a benchmark for future studies on glioblastoma treatment response assessment based on the RANO criteria while emphasizing the heterogeneity of factors that might play a role when assessing the tumor's response to treatment.","authors":["Ana Matoso","Catarina Passarinho","Marta P. Loureiro","Jos\\'e Maria Moreira","Patr\\'icia Figueiredo","Rita G. Nunes"],"url":"https://arxiv.org/abs/2504.18268"}
{"created":"2025-06-05","title":"Is the end of Insight in Sight ?","abstract":"The rise of deep learning challenges the longstanding scientific ideal of insight - the human capacity to understand phenomena by uncovering underlying mechanisms. In many modern applications, accurate predictions no longer require interpretable models, prompting debate about whether explainability is a realistic or even meaningful goal. From our perspective in physics, we examine this tension through a concrete case study: a physics-informed neural network (PINN) trained on a rarefied gas dynamics problem governed by the Boltzmann equation. Despite the system's clear structure and well-understood governing laws, the trained network's weights resemble Gaussian-distributed random matrices, with no evident trace of the physical principles involved. This suggests that deep learning and traditional simulation may follow distinct cognitive paths to the same outcome - one grounded in mechanistic insight, the other in statistical interpolation. Our findings raise critical questions about the limits of explainable AI and whether interpretability can - or should-remain a universal standard in artificial reasoning.","authors":["Jean-Michel Tucny","Mihir Durve","Sauro Succi"],"url":"https://arxiv.org/abs/2505.04627"}
{"created":"2025-06-05","title":"Multimodal Biomarkers for Schizophrenia: Towards Individual Symptom Severity Estimation","abstract":"Studies on schizophrenia assessments using deep learning typically treat it as a classification task to detect the presence or absence of the disorder, oversimplifying the condition and reducing its clinical applicability. This traditional approach overlooks the complexity of schizophrenia, limiting its practical value in healthcare settings. This study shifts the focus to individual symptom severity estimation using a multimodal approach that integrates speech, video, and text inputs. We develop unimodal models for each modality and a multimodal framework to improve accuracy and robustness. By capturing a more detailed symptom profile, this approach can help in enhancing diagnostic precision and support personalized treatment, offering a scalable and objective tool for mental health assessment.","authors":["Gowtham Premananth","Philip Resnik","Sonia Bansal","Deanna L. Kelly","Carol Espy-Wilson"],"url":"https://arxiv.org/abs/2505.16044"}
{"created":"2025-06-05","title":"Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means","abstract":"This paper addresses the problem of robust estimation in gossip algorithms over arbitrary communication graphs. Gossip algorithms are fully decentralized, relying only on local neighbor-to-neighbor communication, making them well-suited for situations where communication is constrained. A fundamental challenge in existing mean-based gossip algorithms is their vulnerability to malicious or corrupted nodes. In this paper, we show that an outlier-robust mean can be computed by globally estimating a robust statistic. More specifically, we propose a novel gossip algorithm for rank estimation, referred to as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated to trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed description of the proposed methods, a key contribution of our work is a precise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank estimation and an $\\mathcal{O}(\\log(t)/\\sqrt{t})$ rate for trimmed mean estimation, where by $t$ is meant the number of iterations. Moreover, we provide a breakdown point analysis of \\textsc{GoTrim}. We empirically validate our theoretical results through experiments on diverse network topologies, data distributions and contamination schemes.","authors":["Anna Van Elst","Igor Colin","Stephan Cl\\'emen\\c{c}on"],"url":"https://arxiv.org/abs/2505.17836"}
{"created":"2025-06-05","title":"Accelerating Flow-Matching-Based Text-to-Speech via Empirically Pruned Step Sampling","abstract":"Flow-matching-based text-to-speech (TTS) models, such as Voicebox, E2 TTS, and F5-TTS, have attracted significant attention in recent years. These models require multiple sampling steps to reconstruct speech from noise, making inference speed a key challenge. Reducing the number of sampling steps can greatly improve inference efficiency. To this end, we introduce Fast F5-TTS, a training-free approach to accelerate the inference of flow-matching-based TTS models. By inspecting the sampling trajectory of F5-TTS, we identify redundant steps and propose Empirically Pruned Step Sampling (EPSS), a non-uniform time-step sampling strategy that effectively reduces the number of sampling steps. Our approach achieves a 7-step generation with an inference RTF of 0.030 on an NVIDIA RTX 3090 GPU, making it 4 times faster than the original F5-TTS while maintaining comparable performance. Furthermore, EPSS performs well on E2 TTS models, demonstrating its strong generalization ability.","authors":["Qixi Zheng","Yushen Chen","Zhikang Niu","Ziyang Ma","Xiaofei Wang","Kai Yu","Xie Chen"],"url":"https://arxiv.org/abs/2505.19931"}
{"created":"2025-06-05","title":"Signed Angle Rigid Graphs for Network Localization and Formation Control","abstract":"Graph rigidity theory studies the capability of a graph embedded in the Euclidean space to constrain its global geometric shape via local constraints among nodes and edges, and has been widely exploited in network localization and formation control. In recent years, the traditional rigidity theory has been extended by considering new types of local constraints such as bearing, angle, ratio of distance, etc. Among them, the signed angle constraint has received extensive attention, since it is practically measurable and independent of the global coordinate frame. However, the relevant studies always consider special graph structures, which are sufficient but not necessary for signed angle rigidity. This paper presents a comprehensive combinatorial analysis in terms of graphs and angle index sets for signed angle rigidity. We show that Laman graphs equivalently characterize minimally signed angle rigid graphs. Moreover, we propose a method to construct the minimal set of signed angle constraints in a Laman graph to effectively ensure signed angle rigidity. These results are finally applied to distributed network localization and formation stabilization problems, respectively, where each agent only has access to signed angle measurements.","authors":["Jinpeng Huang","Gangshan Jing"],"url":"https://arxiv.org/abs/2505.19945"}
{"created":"2025-06-05","title":"Recover Experimental Data with Selection Bias using Counterfactual Logic","abstract":"Selection bias, arising from the systematic inclusion or exclusion of certain samples, poses a significant challenge to the validity of causal inference. While Bareinboim et al. introduced methods for recovering unbiased observational and interventional distributions from biased data using partial external information, the complexity of the backdoor adjustment and the method's strong reliance on observational data limit its applicability in many practical settings. In this paper, we formally discover the recoverability of $P(Y^*_{x^*})$ under selection bias with experimental data. By explicitly constructing counterfactual worlds via Structural Causal Models (SCMs), we analyze how selection mechanisms in the observational world propagate to the counterfactual domain. We derive a complete set of graphical and theoretical criteria to determine that the experimental distribution remain unaffected by selection bias. Furthermore, we propose principled methods for leveraging partially unbiased observational data to recover $P(Y^*_{x^*})$ from biased experimental datasets. Simulation studies replicating realistic research scenarios demonstrate the practical utility of our approach, offering concrete guidance for mitigating selection bias in applied causal inference.","authors":["Jingyang He","Shuai Wang","Ang Li"],"url":"https://arxiv.org/abs/2506.00335"}
{"created":"2025-06-05","title":"ABCDEFGH: An Adaptation-Based Convolutional Neural Network-CycleGAN Disease-Courses Evolution Framework Using Generative Models in Health Education","abstract":"With the advancement of modern medicine and the development of technologies such as MRI, CT, and cellular analysis, it has become increasingly critical for clinicians to accurately interpret various diagnostic images. However, modern medical education often faces challenges due to limited access to high-quality teaching materials, stemming from privacy concerns and a shortage of educational resources (Balogh et al., 2015). In this context, image data generated by machine learning models, particularly generative models, presents a promising solution. These models can create diverse and comparable imaging datasets without compromising patient privacy, thereby supporting modern medical education. In this study, we explore the use of convolutional neural networks (CNNs) and CycleGAN (Zhu et al., 2017) for generating synthetic medical images. The source code is available at https://github.com/mliuby/COMP4211-Project.","authors":["Ruiming Min","Minghao Liu"],"url":"https://arxiv.org/abs/2506.00605"}
{"created":"2025-06-05","title":"GL-LowPopArt: A Nearly Instance-Wise Minimax-Optimal Estimator for Generalized Low-Rank Trace Regression","abstract":"We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized low-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it employs a two-stage approach: nuclear norm regularization followed by matrix Catoni estimation. We establish state-of-the-art estimation error bounds, surpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and reveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key technical challenge is controlling bias from the nonlinear inverse link function, which we address by our two-stage approach. We prove a *local* minimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise optimality up to the condition number of the ground-truth Hessian. Applications include generalized linear matrix completion, where `GL-LowPopArt` achieves a state-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a novel setting inspired by general preference learning (Zhang et al., 2024). Our analysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new, potentially interesting problem-dependent quantity, along with improved Borda regret bound than vectorization (Wu et al., 2024).","authors":["Junghyun Lee","Kyoungseok Jang","Kwang-Sung Jun","Milan Vojnovi\\'c","Se-Young Yun"],"url":"https://arxiv.org/abs/2506.03074"}
