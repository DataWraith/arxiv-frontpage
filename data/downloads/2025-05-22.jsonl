{"created":"2025-05-22","title":"Semi-Competitive Differential Game Logic","abstract":"This paper introduces semi-competitive differential game logic dGLsc, which makes it possible to specify and verify games on hybrid systems with two players that may collaborate with each other when helpful and may compete when necessary. Unlike in zero-sum games, the players in the hybrid games of dGLsc have individual goals that may overlap leading to nonzero-sum games. dGLsc solves the subtlety that even though each player may benefit from knowledge of the other player's goals, e.g., concerning shared safety objectives, the resulting hybrid system would still be unsafe if every player were to mutually assume the other player would control to avoid unsafety. The syntax and semantics, as well as a sound and relatively complete proof calculus are presented for dGLsc. The relationship between dGLsc and zero-sum differential game logic dGL is discussed and the purpose of dGLsc illustrated in a canonical example.","authors":["Julia Butte","Andr\\'e Platzer"],"url":"https://arxiv.org/abs/2505.14688"}
{"created":"2025-05-22","title":"Follow the STARs: Dynamic $\\omega$-Regular Shielding of Learned Policies","abstract":"This paper presents a novel dynamic post-shielding framework that enforces the full class of $\\omega$-regular correctness properties over pre-computed probabilistic policies. This constitutes a paradigm shift from the predominant setting of safety-shielding -- i.e., ensuring that nothing bad ever happens -- to a shielding process that additionally enforces liveness -- i.e., ensures that something good eventually happens. At the core, our method uses Strategy-Template-based Adaptive Runtime Shields (STARs), which leverage permissive strategy templates to enable post-shielding with minimal interference. As its main feature, STARs introduce a mechanism to dynamically control interference, allowing a tunable enforcement parameter to balance formal obligations and task-specific behavior at runtime. This allows to trigger more aggressive enforcement when needed, while allowing for optimized policy choices otherwise. In addition, STARs support runtime adaptation to changing specifications or actuator failures, making them especially suited for cyber-physical applications. We evaluate STARs on a mobile robot benchmark to demonstrate their controllable interference when enforcing (incrementally updated) $\\omega$-regular correctness properties over learned probabilistic policies.","authors":["Ashwani Anand","Satya Prakash Nayak","Ritam Raha","Anne-Kathrin Schmuck"],"url":"https://arxiv.org/abs/2505.14689"}
{"created":"2025-05-22","title":"SGL: A Structured Graphics Language","abstract":"This paper introduces SGL, a graphics language that is aesthetically similar to SQL. SGL is based on traditional grammars of graphics, as well as Vega-Lite's composition algebra. SGL demonstrates that the grammatical approach to graphics lends itself naturally to a SQL-like language. As a graphical counterpart to SQL, SGL facilitates the addition of visualization capabilities to SQL query interfaces. This paper presents components of the SGL language alongside examples. Comparisons to SQL and existing grammars are made throughout to provide further clarity.","authors":["Jon Chapman"],"url":"https://arxiv.org/abs/2505.14690"}
{"created":"2025-05-22","title":"Galois Energy Games: To Solve All Kinds of Quantitative Reachability Problems","abstract":"We provide a generic decision procedure for energy games with energy-bounded attacker and reachability objective, moving beyond vector-valued energies and vector-addition updates. All we demand is that energies form well-founded bounded join-semilattices, and that energy updates have an upward-closed domain and can be \"undone\" through a Galois-connected function. We instantiate these Galois energy games to common energy games, declining energy games, multi-weighted reachability games, coverability on vector addition systems with states and shortest path problems, supported by an Isabelle-formalization and two implementations. For these instantiations, our simple algorithm is polynomial w.r.t. game graph size and exponential w.r.t. dimension.","authors":["Caroline Lemke","Benjamin Bisping"],"url":"https://arxiv.org/abs/2505.14691"}
{"created":"2025-05-22","title":"Sentiment Analysis in Software Engineering: Evaluating Generative Pre-trained Transformers","abstract":"Sentiment analysis plays a crucial role in understanding developer interactions, issue resolutions, and project dynamics within software engineering (SE). While traditional SE-specific sentiment analysis tools have made significant strides, they often fail to account for the nuanced and context-dependent language inherent to the domain. This study systematically evaluates the performance of bidirectional transformers, such as BERT, against generative pre-trained transformers, specifically GPT-4o-mini, in SE sentiment analysis. Using datasets from GitHub, Stack Overflow, and Jira, we benchmark the models' capabilities with fine-tuned and default configurations. The results reveal that fine-tuned GPT-4o-mini performs comparable to BERT and other bidirectional models on structured and balanced datasets like GitHub and Jira, achieving macro-averaged F1-scores of 0.93 and 0.98, respectively. However, on linguistically complex datasets with imbalanced sentiment distributions, such as Stack Overflow, the default GPT-4o-mini model exhibits superior generalization, achieving an accuracy of 85.3\\% compared to the fine-tuned model's 13.1\\%. These findings highlight the trade-offs between fine-tuning and leveraging pre-trained models for SE tasks. The study underscores the importance of aligning model architectures with dataset characteristics to optimize performance and proposes directions for future research in refining sentiment analysis tools tailored to the SE domain.","authors":["KM Khalid Saifullah","Faiaz Azmain","Habiba Hye"],"url":"https://arxiv.org/abs/2505.14692"}
{"created":"2025-05-22","title":"Propositional Measure Logic","abstract":"We present a propositional logic with fundamental probabilistic semantics, in which each formula is given a real measure in the interval $[0,1]$ that represents its degree of truth. This semantics replaces the binarity of classical logic, while preserving its deductive structure. We demonstrate the soundness theorem, establishing that the proposed system is sound and suitable for reasoning under uncertainty. We discuss potential applications and avenues for future extensions of the theory. We apply probabilistic logic to a still refractory problem in Bayesian Networks.","authors":["Francisco Arag\\~ao"],"url":"https://arxiv.org/abs/2505.14693"}
{"created":"2025-05-22","title":"Prime Path Coverage in the GNU Compiler Collection","abstract":"We describe the implementation of the prime path coverage support introduced the GNU Compiler Collection 15, a structural coverage metric that focuses on paths of execution through the program. Prime path coverage strikes a good balance between the number of tests and coverage, and requires that loops are taken, taken more than once, and skipped. We show that prime path coverage subsumes modified condition/decision coverage (MC/DC). We improve on the current state-of-the-art algorithms for enumerating prime paths by using a suffix tree for efficient pruning of duplicated and redundant subpaths, reducing it to $O(n^2m)$ from $O(n^2m^2)$, where $n$ is the length of the longest path and $m$ is the number of candidate paths. We can efficiently track candidate paths using a few bitwise operations based on a compact representation of the indices of the ordered prime paths. By analyzing the control flow graph, GCC can observe and instrument paths in a language-agnostic manner, and accurately report what code must be run in what order to achieve coverage.","authors":["J{\\o}rgen Kvalsvik"],"url":"https://arxiv.org/abs/2505.14694"}
{"created":"2025-05-22","title":"On the Possibilities of Hypercomputing Supertasks","abstract":"This paper investigates the view that digital hypercomputing is a good reason for rejection or re-interpretation of the Church-Turing thesis. After suggestion that such re-interpretation is historically problematic and often involves attack on a straw man (the 'maximality thesis'), it discusses proposals for digital hypercomputing with Zeno-machines , i.e. computing machines that compute an infinite number of computing steps in finite time, thus performing supertasks. It argues that effective computing with Zeno-machines falls into a dilemma: either they are specified such that they do not have output states, or they are specified such that they do have output states, but involve contradiction. Repairs though non-effective methods or special rules for semi-decidable problems are sought, but not found. The paper concludes that hypercomputing supertasks are impossible in the actual world and thus no reason for rejection of the Church-Turing thesis in its traditional interpretation.","authors":["Vincent C. M\\\"uller"],"url":"https://arxiv.org/abs/2505.14698"}
{"created":"2025-05-22","title":"Benchmarking Graph Neural Networks for Document Layout Analysis in Public Affairs","abstract":"The automatic analysis of document layouts in digital-born PDF documents remains a challenging problem due to the heterogeneous arrangement of textual and nontextual elements and the imprecision of the textual metadata in the Portable Document Format. In this work, we benchmark Graph Neural Network (GNN) architectures for the task of fine-grained layout classification of text blocks from digital native documents. We introduce two graph construction structures: a k-closest-neighbor graph and a fully connected graph, and generate node features via pre-trained text and vision models, thus avoiding manual feature engineering. Three experimental frameworks are evaluated: single-modality (text or visual), concatenated multimodal, and dual-branch multimodal. We evaluated four foundational GNN models and compared them with the baseline. Our experiments are specifically conducted on a rich dataset of public affairs documents that includes more than 20 sources (e.g., regional and national-level official gazettes), 37K PDF documents, with 441K pages in total. Our results demonstrate that GraphSAGE operating on the k-closest-neighbor graph in a dual-branch configuration achieves the highest per-class and overall accuracy, outperforming the baseline in some sources. These findings confirm the importance of local layout relationships and multimodal fusion exploited through GNNs for the analysis of native digital document layouts.","authors":["Miguel Lopez-Duran","Julian Fierrez","Aythami Morales","Ruben Tolosana","Oscar Delgado-Mohatar","Alvaro Ortigosa"],"url":"https://arxiv.org/abs/2505.14699"}
{"created":"2025-05-22","title":"Stochastic Fractional Neural Operators: A Symmetrized Approach to Modeling Turbulence in Complex Fluid Dynamics","abstract":"In this work, we introduce a new class of neural network operators designed to handle problems where memory effects and randomness play a central role. In this work, we introduce a new class of neural network operators designed to handle problems where memory effects and randomness play a central role. These operators merge symmetrized activation functions, Caputo-type fractional derivatives, and stochastic perturbations introduced via It\\^o type noise. The result is a powerful framework capable of approximating functions that evolve over time with both long-term memory and uncertain dynamics. We develop the mathematical foundations of these operators, proving three key theorems of Voronovskaya type. These results describe the asymptotic behavior of the operators, their convergence in the mean-square sense, and their consistency under fractional regularity assumptions. All estimates explicitly account for the influence of the memory parameter $\\alpha$ and the noise level $\\sigma$. As a practical application, we apply the proposed theory to the fractional Navier-Stokes equations with stochastic forcing, a model often used to describe turbulence in fluid flows with memory. Our approach provides theoretical guarantees for the approximation quality and suggests that these neural operators can serve as effective tools in the analysis and simulation of complex systems. By blending ideas from neural networks, fractional calculus, and stochastic analysis, this research opens new perspectives for modeling turbulent phenomena and other multiscale processes where memory and randomness are fundamental. The results lay the groundwork for hybrid learning-based methods with strong analytical backing.","authors":["R\\^omulo Damasclin Chaves dos Santos","Jorge Henrique de Oliveira Sales"],"url":"https://arxiv.org/abs/2505.14700"}
{"created":"2025-05-22","title":"Deployment of Traditional and Hybrid Machine Learning for Critical Heat Flux Prediction in the CTF Thermal Hydraulics Code","abstract":"Critical heat flux (CHF) marks the transition from nucleate to film boiling, where heat transfer to the working fluid can rapidly deteriorate. Accurate CHF prediction is essential for efficiency, safety, and preventing equipment damage, particularly in nuclear reactors. Although widely used, empirical correlations frequently exhibit discrepancies in comparison with experimental data, limiting their reliability in diverse operational conditions. Traditional machine learning (ML) approaches have demonstrated the potential for CHF prediction but have often suffered from limited interpretability, data scarcity, and insufficient knowledge of physical principles. Hybrid model approaches, which combine data-driven ML with physics-based models, mitigate these concerns by incorporating prior knowledge of the domain. This study integrated a purely data-driven ML model and two hybrid models (using the Biasi and Bowring CHF correlations) within the CTF subchannel code via a custom Fortran framework. Performance was evaluated using two validation cases: a subset of the Nuclear Regulatory Commission CHF database and the Bennett dryout experiments. In both cases, the hybrid models exhibited significantly lower error metrics in comparison with conventional empirical correlations. The pure ML model remained competitive with the hybrid models. Trend analysis of error parity indicates that ML-based models reduce the tendency for CHF overprediction, improving overall accuracy. These results demonstrate that ML-based CHF models can be effectively integrated into subchannel codes and can potentially increase performance in comparison with conventional methods.","authors":["Aidan Furlong","Xingang Zhao","Robert Salko","Xu Wu"],"url":"https://arxiv.org/abs/2505.14701"}
{"created":"2025-05-22","title":"Beyond Modality Collapse: Representations Blending for Multimodal Dataset Distillation","abstract":"Multimodal Dataset Distillation (MDD) seeks to condense large-scale image-text datasets into compact surrogates while retaining their effectiveness for cross-modal learning. Despite recent progress, existing MDD approaches often suffer from \\textit{\\textbf{Modality Collapse}}, characterized by over-concentrated intra-modal representations and enlarged distributional gap across modalities. In this paper, at the first time, we identify this issue as stemming from a fundamental conflict between the over-compression behavior inherent in dataset distillation and the cross-modal supervision imposed by contrastive objectives. To alleviate modality collapse, we introduce \\textbf{RepBlend}, a novel MDD framework that weakens overdominant cross-modal supervision via representation blending, thereby significantly enhancing intra-modal diversity. Additionally, we observe that current MDD methods impose asymmetric supervision across modalities, resulting in biased optimization. To address this, we propose symmetric projection trajectory matching, which synchronizes the optimization dynamics using modality-specific projection heads, thereby promoting balanced supervision and enhancing cross-modal alignment. Experiments on Flickr-30K and MS-COCO show that RepBlend consistently outperforms prior state-of-the-art MDD methods, achieving significant gains in retrieval performance (e.g., +9.4 IR@10, +6.3 TR@10 under the 100-pair setting) and offering up to 6.7$\\times$ distillation speedup.","authors":["Xin Zhang","Ziruo Zhang","Jiawei Du","Zuozhu Liu","Joey Tianyi Zhou"],"url":"https://arxiv.org/abs/2505.14705"}
{"created":"2025-05-22","title":"CrypticBio: A Large Multimodal Dataset for Visually Confusing Biodiversity","abstract":"We present CrypticBio, the largest publicly available multimodal dataset of visually confusing species, specifically curated to support the development of AI models in the context of biodiversity applications. Visually confusing or cryptic species are groups of two or more taxa that are nearly indistinguishable based on visual characteristics alone. While much existing work addresses taxonomic identification in a broad sense, datasets that directly address the morphological confusion of cryptic species are small, manually curated, and target only a single taxon. Thus, the challenge of identifying such subtle differences in a wide range of taxa remains unaddressed. Curated from real-world trends in species misidentification among community annotators of iNaturalist, CrypticBio contains 52K unique cryptic groups spanning 67K species, represented in 166 million images. Rich research-grade image annotations--including scientific, multicultural, and multilingual species terminology, hierarchical taxonomy, spatiotemporal context, and associated cryptic groups--address multimodal AI in biodiversity research. For easy dataset curation, we provide an open-source pipeline CrypticBio-Curate. The multimodal nature of the dataset beyond vision-language arises from the integration of geographical and temporal data as complementary cues to identifying cryptic species. To highlight the importance of the dataset, we benchmark a suite of state-of-the-art foundation models across CrypticBio subsets of common, unseen, endangered, and invasive species, and demonstrate the substantial impact of geographical context on vision-language zero-shot learning for cryptic species. By introducing CrypticBio, we aim to catalyze progress toward real-world-ready biodiversity AI models capable of handling the nuanced challenges of species ambiguity.","authors":["Georgiana Manolache","Gerard Schouten","Joaquin Vanschoren"],"url":"https://arxiv.org/abs/2505.14707"}
{"created":"2025-05-22","title":"DraftAttention: Fast Video Diffusion via Low-Resolution Attention Guidance","abstract":"Diffusion transformer-based video generation models (DiTs) have recently attracted widespread attention for their excellent generation quality. However, their computational cost remains a major bottleneck-attention alone accounts for over 80% of total latency, and generating just 8 seconds of 720p video takes tens of minutes-posing serious challenges to practical application and scalability. To address this, we propose the DraftAttention, a training-free framework for the acceleration of video diffusion transformers with dynamic sparse attention on GPUs. We apply down-sampling to each feature map across frames in the compressed latent space, enabling a higher-level receptive field over the latent composed of hundreds of thousands of tokens. The low-resolution draft attention map, derived from draft query and key, exposes redundancy both spatially within each feature map and temporally across frames. We reorder the query, key, and value based on the draft attention map to guide the sparse attention computation in full resolution, and subsequently restore their original order after the attention computation. This reordering enables structured sparsity that aligns with hardware-optimized execution. Our theoretical analysis demonstrates that the low-resolution draft attention closely approximates the full attention, providing reliable guidance for constructing accurate sparse attention. Experimental results show that our method outperforms existing sparse attention approaches in video generation quality and achieves up to 1.75x end-to-end speedup on GPUs. Code: https://github.com/shawnricecake/draft-attention","authors":["Xuan Shen","Chenxia Han","Yufa Zhou","Yanyue Xie","Yifan Gong","Quanyi Wang","Yiwei Wang","Yanzhi Wang","Pu Zhao","Jiuxiang Gu"],"url":"https://arxiv.org/abs/2505.14708"}
{"created":"2025-05-22","title":"FastCar: Cache Attentive Replay for Fast Auto-Regressive Video Generation on the Edge","abstract":"Auto-regressive (AR) models, initially successful in language generation, have recently shown promise in visual generation tasks due to their superior sampling efficiency. Unlike image generation, video generation requires a substantially larger number of tokens to produce coherent temporal frames, resulting in significant overhead during the decoding phase. Our key observations are: (i) MLP modules in the decode phase dominate the inference latency, and (ii) there exists high temporal redundancy in MLP outputs of adjacent frames. In this paper, we propose the \\textbf{FastCar} framework to accelerate the decode phase for the AR video generation by exploring the temporal redundancy. The Temporal Attention Score (TAS) is proposed to determine whether to apply the replay strategy (\\textit{i.e.}, reusing cached MLP outputs from the previous frame to reduce redundant computations) with detailed theoretical analysis and justification. Also, we develop a hardware accelerator on FPGA with Dynamic Resource Scheduling (DRS) based on TAS to enable better resource utilization and faster inference. Experimental results demonstrate the effectiveness of our method, which outperforms traditional sparse attention approaches with more than 2.1x decoding speedup and higher energy efficiency on the edge. Furthermore, by combining FastCar and sparse attention, FastCar can boost the performance of sparse attention with alleviated drifting, demonstrating our unique advantages for high-resolution and long-duration video generation. Code: https://github.com/shawnricecake/fast-car","authors":["Xuan Shen","Weize Ma","Yufa Zhou","Enhao Tang","Yanyue Xie","Zhengang Li","Yifan Gong","Quanyi Wang","Henghui Ding","Yiwei Wang","Yanzhi Wang","Pu Zhao","Jun Lin","Jiuxiang Gu"],"url":"https://arxiv.org/abs/2505.14709"}
{"created":"2025-05-22","title":"KGAlign: Joint Semantic-Structural Knowledge Encoding for Multimodal Fake News Detection","abstract":"Fake news detection remains a challenging problem due to the complex interplay between textual misinformation, manipulated images, and external knowledge reasoning. While existing approaches have achieved notable results in verifying veracity and cross-modal consistency, two key challenges persist: (1) Existing methods often consider only the global image context while neglecting local object-level details, and (2) they fail to incorporate external knowledge and entity relationships for deeper semantic understanding. To address these challenges, we propose a novel multi-modal fake news detection framework that integrates visual, textual, and knowledge-based representations. Our approach leverages bottom-up attention to capture fine-grained object details, CLIP for global image semantics, and RoBERTa for context-aware text encoding. We further enhance knowledge utilization by retrieving and adaptively selecting relevant entities from a knowledge graph. The fused multi-modal features are processed through a Transformer-based classifier to predict news veracity. Experimental results demonstrate that our model outperforms recent approaches, showcasing the effectiveness of neighbor selection mechanism and multi-modal fusion for fake news detection. Our proposal introduces a new paradigm: knowledge-grounded multimodal reasoning. By integrating explicit entity-level selection and NLI-guided filtering, we shift fake news detection from feature fusion to semantically grounded verification. For reproducibility and further research, the source code is publicly at \\href{https://github.com/latuanvinh1998/KGAlign}{github.com/latuanvinh1998/KGAlign}.","authors":["Tuan-Vinh La","Minh-Hieu Nguyen","Minh-Son Dao"],"url":"https://arxiv.org/abs/2505.14714"}
{"created":"2025-05-22","title":"Enhancing Shape Perception and Segmentation Consistency for Industrial Image Inspection","abstract":"Semantic segmentation stands as a pivotal research focus in computer vision. In the context of industrial image inspection, conventional semantic segmentation models fail to maintain the segmentation consistency of fixed components across varying contextual environments due to a lack of perception of object contours. Given the real-time constraints and limited computing capability of industrial image detection machines, it is also necessary to create efficient models to reduce computational complexity. In this work, a Shape-Aware Efficient Network (SPENet) is proposed, which focuses on the shapes of objects to achieve excellent segmentation consistency by separately supervising the extraction of boundary and body information from images. In SPENet, a novel method is introduced for describing fuzzy boundaries to better adapt to real-world scenarios named Variable Boundary Domain (VBD). Additionally, a new metric, Consistency Mean Square Error(CMSE), is proposed to measure segmentation consistency for fixed components. Our approach attains the best segmentation accuracy and competitive speed on our dataset, showcasing significant advantages in CMSE among numerous state-of-the-art real-time segmentation networks, achieving a reduction of over 50% compared to the previously top-performing models.","authors":["Guoxuan Mao","Ting Cao","Ziyang Li","Yuan Dong"],"url":"https://arxiv.org/abs/2505.14718"}
{"created":"2025-05-22","title":"MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion","abstract":"The combination of Spiking Neural Networks(SNNs) with Vision Transformer architectures has attracted significant attention due to the great potential for energy-efficient and high-performance computing paradigms. However, a substantial performance gap still exists between SNN-based and ANN-based transformer architectures. While existing methods propose spiking self-attention mechanisms that are successfully combined with SNNs, the overall architectures proposed by these methods suffer from a bottleneck in effectively extracting features from different image scales. In this paper, we address this issue and propose MSVIT, a novel spike-driven Transformer architecture, which firstly uses multi-scale spiking attention (MSSA) to enrich the capability of spiking attention blocks. We validate our approach across various main data sets. The experimental results show that MSVIT outperforms existing SNN-based models, positioning itself as a state-of-the-art solution among SNN-transformer architectures. The codes are available at https://github.com/Nanhu-AI-Lab/MSViT.","authors":["Wei Hua","Chenlin Zhou","Jibin Wu","Yansong Chua","Yangyang Shu"],"url":"https://arxiv.org/abs/2505.14719"}
{"created":"2025-05-22","title":"The Evolution of Alpha in Finance Harnessing Human Insight and LLM Agents","abstract":"The pursuit of alpha returns that exceed market benchmarks has undergone a profound transformation, evolving from intuition-driven investing to autonomous, AI powered systems. This paper introduces a comprehensive five stage taxonomy that traces this progression across manual strategies, statistical models, classical machine learning, deep learning, and agentic architectures powered by large language models (LLMs). Unlike prior surveys focused narrowly on modeling techniques, this review adopts a system level lens, integrating advances in representation learning, multimodal data fusion, and tool augmented LLM agents. The strategic shift from static predictors to contextaware financial agents capable of real time reasoning, scenario simulation, and cross modal decision making is emphasized. Key challenges in interpretability, data fragility, governance, and regulatory compliance areas critical to production deployment are examined. The proposed taxonomy offers a unified framework for evaluating maturity, aligning infrastructure, and guiding the responsible development of next generation alpha systems.","authors":["Mohammad Rubyet Islam"],"url":"https://arxiv.org/abs/2505.14727"}
{"created":"2025-05-22","title":"MORALISE: A Structured Benchmark for Moral Alignment in Visual Language Models","abstract":"Warning: This paper contains examples of harmful language and images. Reader discretion is advised. Recently, vision-language models have demonstrated increasing influence in morally sensitive domains such as autonomous driving and medical analysis, owing to their powerful multimodal reasoning capabilities. As these models are deployed in high-stakes real-world applications, it is of paramount importance to ensure that their outputs align with human moral values and remain within moral boundaries. However, existing work on moral alignment either focuses solely on textual modalities or relies heavily on AI-generated images, leading to distributional biases and reduced realism. To overcome these limitations, we introduce MORALISE, a comprehensive benchmark for evaluating the moral alignment of vision-language models (VLMs) using diverse, expert-verified real-world data. We begin by proposing a comprehensive taxonomy of 13 moral topics grounded in Turiel's Domain Theory, spanning the personal, interpersonal, and societal moral domains encountered in everyday life. Built on this framework, we manually curate 2,481 high-quality image-text pairs, each annotated with two fine-grained labels: (1) topic annotation, identifying the violated moral topic(s), and (2) modality annotation, indicating whether the violation arises from the image or the text. For evaluation, we encompass two tasks, \\textit{moral judgment} and \\textit{moral norm attribution}, to assess models' awareness of moral violations and their reasoning ability on morally salient content. Extensive experiments on 19 popular open- and closed-source VLMs show that MORALISE poses a significant challenge, revealing persistent moral limitations in current state-of-the-art models. The full benchmark is publicly available at https://huggingface.co/datasets/Ze1025/MORALISE.","authors":["Xiao Lin","Zhining Liu","Ze Yang","Gaotang Li","Ruizhong Qiu","Shuke Wang","Hui Liu","Haotian Li","Sumit Keswani","Vishwa Pardeshi","Huijun Zhao","Wei Fan","Hanghang Tong"],"url":"https://arxiv.org/abs/2505.14728"}
{"created":"2025-05-22","title":"Uncovering Cultural Representation Disparities in Vision-Language Models","abstract":"Vision-Language Models (VLMs) have demonstrated impressive capabilities across a range of tasks, yet concerns about their potential biases exist. This work investigates the extent to which prominent VLMs exhibit cultural biases by evaluating their performance on an image-based country identification task at a country level. Utilizing the geographically diverse Country211 dataset, we probe several large vision language models (VLMs) under various prompting strategies: open-ended questions, multiple-choice questions (MCQs) including challenging setups like multilingual and adversarial settings. Our analysis aims to uncover disparities in model accuracy across different countries and question formats, providing insights into how training data distribution and evaluation methodologies might influence cultural biases in VLMs. The findings highlight significant variations in performance, suggesting that while VLMs possess considerable visual understanding, they inherit biases from their pre-training data and scale that impact their ability to generalize uniformly across diverse global contexts.","authors":["Ram Mohan Rao Kadiyala","Siddhant Gupta","Jebish Purbey","Srishti Yadav","Alejandro Salamanca","Desmond Elliott"],"url":"https://arxiv.org/abs/2505.14729"}
{"created":"2025-05-22","title":"Geodesic distance approximation using a surface finite element method for the $p$-Laplacian","abstract":"We use the $p$-Laplacian with large $p$-values in order to approximate geodesic distances to features on surfaces. This differs from Fayolle and Belyaev's (2018) [1] computational results using the $p$-Laplacian for the distance-to-surface problem. Our approach appears to offer some distinct advantages over other popular PDE-based distance function approximation methods. We employ a surface finite element scheme and demonstrate numerical convergence to the true geodesic distance functions. We check that our numerical results adhere to the triangle inequality and examine robustness against geometric noise such as vertex perturbations. We also present comparisons of our method with the heat method from Crane et al. [2] and the classical polyhedral method from Mitchell et al. [3].","authors":["Hannah Potgieter","Razvan C. Fetecau","Steven J. Ruuth"],"url":"https://arxiv.org/abs/2505.14732"}
{"created":"2025-05-22","title":"The Energy Cost of Reasoning: Analyzing Energy Usage in LLMs with Test-time Compute","abstract":"Scaling large language models (LLMs) has driven significant advancements, yet it faces diminishing returns and escalating energy demands. This work introduces test-time compute (TTC)-allocating additional computational resources during inference-as a compelling complement to conventional scaling strategies. Specifically, we investigate whether employing TTC can achieve superior accuracy-energy trade-offs compared to simply increasing model size. Our empirical analysis reveals that TTC surpasses traditional model scaling in accuracy/energy efficiency, with notable gains in tasks demanding complex reasoning rather than mere factual recall. Further, we identify a critical interaction between TTC performance and output sequence length, demonstrating that strategically adjusting compute resources at inference time according to query complexity can substantially enhance efficiency. Our findings advocate for TTC as a promising direction, enabling more sustainable, accurate, and adaptable deployment of future language models without incurring additional pretraining costs.","authors":["Yunho Jin","Gu-Yeon Wei","David Brooks"],"url":"https://arxiv.org/abs/2505.14733"}
{"created":"2025-05-22","title":"Leveraging Multivariate Long-Term History Representation for Time Series Forecasting","abstract":"Multivariate Time Series (MTS) forecasting has a wide range of applications in both industry and academia. Recent advances in Spatial-Temporal Graph Neural Network (STGNN) have achieved great progress in modelling spatial-temporal correlations. Limited by computational complexity, most STGNNs for MTS forecasting focus primarily on short-term and local spatial-temporal dependencies. Although some recent methods attempt to incorporate univariate history into modeling, they still overlook crucial long-term spatial-temporal similarities and correlations across MTS, which are essential for accurate forecasting. To fill this gap, we propose a framework called the Long-term Multivariate History Representation (LMHR) Enhanced STGNN for MTS forecasting. Specifically, a Long-term History Encoder (LHEncoder) is adopted to effectively encode the long-term history into segment-level contextual representations and reduce point-level noise. A non-parametric Hierarchical Representation Retriever (HRetriever) is designed to include the spatial information in the long-term spatial-temporal dependency modelling and pick out the most valuable representations with no additional training. A Transformer-based Aggregator (TAggregator) selectively fuses the sparsely retrieved contextual representations based on the ranking positional embedding efficiently. Experimental results demonstrate that LMHR outperforms typical STGNNs by 10.72% on the average prediction horizons and state-of-the-art methods by 4.12% on several real-world datasets. Additionally, it consistently improves prediction accuracy by 9.8% on the top 10% of rapidly changing patterns across the datasets.","authors":["Huiliang Zhang","Di Wu","Arnaud Zinflou","Stephane Dellacherie","Mouhamadou Makhtar Dione","Benoit Boulet"],"url":"https://arxiv.org/abs/2505.14737"}
{"created":"2025-05-22","title":"R&D-Agent: Automating Data-Driven AI Solution Building Through LLM-Powered Automated Research, Development, and Evolution","abstract":"Recent advances in AI and ML have transformed data science, yet increasing complexity and expertise requirements continue to hinder progress. While crowdsourcing platforms alleviate some challenges, high-level data science tasks remain labor-intensive and iterative. To overcome these limitations, we introduce R&amp;D-Agent, a dual-agent framework for iterative exploration. The Researcher agent uses performance feedback to generate ideas, while the Developer agent refines code based on error feedback. By enabling multiple parallel exploration traces that merge and enhance one another, R&amp;D-Agent narrows the gap between automated solutions and expert-level performance. Evaluated on MLE-Bench, R&amp;D-Agent emerges as the top-performing machine learning engineering agent, demonstrating its potential to accelerate innovation and improve precision across diverse data science applications. We have open-sourced R&amp;D-Agent on GitHub: https://github.com/microsoft/RD-Agent.","authors":["Xu Yang","Xiao Yang","Shikai Fang","Bowen Xian","Yuante Li","Jian Wang","Minrui Xu","Haoran Pan","Xinpeng Hong","Weiqing Liu","Yelong Shen","Weizhu Chen","Jiang Bian"],"url":"https://arxiv.org/abs/2505.14738"}
{"created":"2025-05-22","title":"Time Series Similarity Score Functions to Monitor and Interact with the Training and Denoising Process of a Time Series Diffusion Model applied to a Human Activity Recognition Dataset based on IMUs","abstract":"Denoising diffusion probabilistic models are able to generate synthetic sensor signals. The training process of such a model is controlled by a loss function which measures the difference between the noise that was added in the forward process and the noise that was predicted by the diffusion model. This enables the generation of realistic data. However, the randomness within the process and the loss function itself makes it difficult to estimate the quality of the data. Therefore, we examine multiple similarity metrics and adapt an existing metric to overcome this issue by monitoring the training and synthetisation process using those metrics. The adapted metric can even be fine-tuned on the input data to comply with the requirements of an underlying classification task. We were able to significantly reduce the amount of training epochs without a performance reduction in the classification task. An optimized training process not only saves resources, but also reduces the time for training generative models.","authors":["Heiko Oppel","Andreas Spilz","Michael Munz"],"url":"https://arxiv.org/abs/2505.14739"}
{"created":"2025-05-22","title":"Communication-Efficient Diffusion Denoising Parallelization via Reuse-then-Predict Mechanism","abstract":"Diffusion models have emerged as a powerful class of generative models across various modalities, including image, video, and audio synthesis. However, their deployment is often limited by significant inference latency, primarily due to the inherently sequential nature of the denoising process. While existing parallelization strategies attempt to accelerate inference by distributing computation across multiple devices, they typically incur high communication overhead, hindering deployment on commercial hardware. To address this challenge, we propose \\textbf{ParaStep}, a novel parallelization method based on a reuse-then-predict mechanism that parallelizes diffusion inference by exploiting similarity between adjacent denoising steps. Unlike prior approaches that rely on layer-wise or stage-wise communication, ParaStep employs lightweight, step-wise communication, substantially reducing overhead. ParaStep achieves end-to-end speedups of up to \\textbf{3.88}$\\times$ on SVD, \\textbf{2.43}$\\times$ on CogVideoX-2b, and \\textbf{6.56}$\\times$ on AudioLDM2-large, while maintaining generation quality. These results highlight ParaStep as a scalable and communication-efficient solution for accelerating diffusion inference, particularly in bandwidth-constrained environments.","authors":["Kunyun Wang","Bohan Li","Kai Yu","Minyi Guo","Jieru Zhao"],"url":"https://arxiv.org/abs/2505.14741"}
{"created":"2025-05-22","title":"Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis","abstract":"Large language models (LLMs) have made exciting achievements across various domains, yet their deployment on resource-constrained personal devices remains hindered by the prohibitive computational and memory demands of task-specific fine-tuning. While quantization offers a pathway to efficiency, existing methods struggle to balance performance and overhead, either incurring high computational/memory costs or failing to address activation outliers, a critical bottleneck in quantized fine-tuning. To address these challenges, we propose the Outlier Spatial Stability Hypothesis (OSSH): During fine-tuning, certain activation outlier channels retain stable spatial positions across training iterations. Building on OSSH, we propose Quaff, a Quantized parameter-efficient fine-tuning framework for LLMs, optimizing low-precision activation representations through targeted momentum scaling. Quaff dynamically suppresses outliers exclusively in invariant channels using lightweight operations, eliminating full-precision weight storage and global rescaling while reducing quantization errors. Extensive experiments across ten benchmarks validate OSSH and demonstrate Quaff's efficacy. Specifically, on the GPQA reasoning benchmark, Quaff achieves a 1.73x latency reduction and 30% memory savings over full-precision fine-tuning while improving accuracy by 0.6% on the Phi-3 model, reconciling the triple trade-off between efficiency, performance, and deployability. By enabling consumer-grade GPU fine-tuning (e.g., RTX 2080 Super) without sacrificing model utility, Quaff democratizes personalized LLM deployment. The code is available at https://github.com/Little0o0/Quaff.git.","authors":["Hong Huang","Dapeng Wu"],"url":"https://arxiv.org/abs/2505.14742"}
{"created":"2025-05-22","title":"Transductively Informed Inductive Program Synthesis","abstract":"Abstraction and reasoning in program synthesis has seen significant progress through both inductive and transductive paradigms. Inductive approaches generate a program or latent function from input-output examples, which can then be applied to new inputs. Transductive approaches directly predict output values for given inputs, effectively serving as the function themselves. Current approaches combine inductive and transductive models via isolated ensembling, but they do not explicitly model the interaction between both paradigms. In this work, we introduce \\acs{tiips}, a novel framework that unifies transductive and inductive strategies by explicitly modeling their interactions through a cooperative mechanism: an inductive model generates programs, while a transductive model constrains, guides, and refines the search to improve synthesis accuracy and generalization. We evaluate \\acs{tiips} on two widely studied program synthesis domains: string and list manipulation. Our results show that \\acs{tiips} solves more tasks and yields functions that more closely match optimal solutions in syntax and semantics, particularly in out-of-distribution settings, yielding state-of-the-art performance. We believe that explicitly modeling the synergy between inductive and transductive reasoning opens promising avenues for general-purpose program synthesis and broader applications.","authors":["Janis Zenkner","Tobias Sesterhenn","Christian Bartelt"],"url":"https://arxiv.org/abs/2505.14744"}
{"created":"2025-05-22","title":"Explainable Prediction of the Mechanical Properties of Composites with CNNs","abstract":"Composites are amongst the most important materials manufactured today, as evidenced by their use in countless applications. In order to establish the suitability of composites in specific applications, finite element (FE) modelling, a numerical method based on partial differential equations, is the industry standard for assessing their mechanical properties. However, FE modelling is exceptionally costly from a computational viewpoint, a limitation which has led to efforts towards applying AI models to this task. However, in these approaches: the chosen model architectures were rudimentary, feed-forward neural networks giving limited accuracy; the studies focus on predicting elastic mechanical properties, without considering material strength limits; and the models lacked transparency, hindering trustworthiness by users. In this paper, we show that convolutional neural networks (CNNs) equipped with methods from explainable AI (XAI) can be successfully deployed to solve this problem. Our approach uses customised CNNs trained on a dataset we generate using transverse tension tests in FE modelling to predict composites' mechanical properties, i.e., Young's modulus and yield strength. We show empirically that our approach achieves high accuracy, outperforming a baseline, ResNet-34, in estimating the mechanical properties. We then use SHAP and Integrated Gradients, two post-hoc XAI methods, to explain the predictions, showing that the CNNs use the critical geometrical features that influence the composites' behaviour, thus allowing engineers to verify that the models are trustworthy by representing the science of composites.","authors":["Varun Raaghav","Dimitrios Bikos","Antonio Rago","Francesca Toni","Maria Charalambides"],"url":"https://arxiv.org/abs/2505.14745"}
{"created":"2025-05-22","title":"Cooperative Causal GraphSAGE","abstract":"GraphSAGE is a widely used graph neural network. The introduction of causal inference has improved its robust performance and named as Causal GraphSAGE. However, Causal GraphSAGE focuses on measuring causal weighting among individual nodes, but neglecting the cooperative relationships among sampling nodes as a whole. To address this issue, this paper proposes Cooperative Causal GraphSAGE (CoCa-GraphSAGE), which combines cooperative game theory with Causal GraphSAGE. Initially, a cooperative causal structure model is constructed in the case of cooperation based on the graph structure. Subsequently, Cooperative Causal sampling (CoCa-sampling) algorithm is proposed, employing the Shapley values to calculate the cooperative contribution based on causal weights of the nodes sets. CoCa-sampling guides the selection of nodes with significant cooperative causal effects during the neighborhood sampling process, thus integrating the selected neighborhood features under cooperative relationships, which takes the sampled nodes as a whole and generates more stable target node embeddings. Experiments on publicly available datasets show that the proposed method has comparable classification performance to the compared methods and outperforms under perturbations, demonstrating the robustness improvement by CoCa-sampling.","authors":["Zaifa Xue","Tao Zhang","Tuo Xu","Huaixin Liang","Le Gao"],"url":"https://arxiv.org/abs/2505.14748"}
{"created":"2025-05-22","title":"Self Distillation via Iterative Constructive Perturbations","abstract":"Deep Neural Networks have achieved remarkable achievements across various domains, however balancing performance and generalization still remains a challenge while training these networks. In this paper, we propose a novel framework that uses a cyclic optimization strategy to concurrently optimize the model and its input data for better training, rethinking the traditional training paradigm. Central to our approach is Iterative Constructive Perturbation (ICP), which leverages the model's loss to iteratively perturb the input, progressively constructing an enhanced representation over some refinement steps. This ICP input is then fed back into the model to produce improved intermediate features, which serve as a target in a self-distillation framework against the original features. By alternately altering the model's parameters to the data and the data to the model, our method effectively addresses the gap between fitting and generalization, leading to enhanced performance. Extensive experiments demonstrate that our approach not only mitigates common performance bottlenecks in neural networks but also demonstrates significant improvements across training variations.","authors":["Maheak Dave","Aniket Kumar Singh","Aryan Pareek","Harshita Jha","Debasis Chaudhuri","Manish Pratap Singh"],"url":"https://arxiv.org/abs/2505.14751"}
{"created":"2025-05-22","title":"Large Language Models for Data Synthesis","abstract":"Generating synthetic data that faithfully captures the statistical structure of real-world distributions is a fundamental challenge in data modeling. Classical approaches often depend on strong parametric assumptions or manual structural design and struggle in high-dimensional or heterogeneous domains. Recent progress in Large Language Models (LLMs) reveals their potential as flexible, high-dimensional priors over real-world distributions. However, when applied to data synthesis, standard LLM-based sampling is inefficient, constrained by fixed context limits, and fails to ensure statistical alignment. Given this, we introduce LLMSynthor, a general framework for data synthesis that transforms LLMs into structure-aware simulators guided by distributional feedback. LLMSynthor treats the LLM as a nonparametric copula simulator for modeling high-order dependencies and introduces LLM Proposal Sampling to generate grounded proposal distributions that improve sampling efficiency without requiring rejection. By minimizing discrepancies in the summary statistics space, the iterative synthesis loop aligns real and synthetic data while gradually uncovering and refining the latent generative structure. We evaluate LLMSynthor in both controlled and real-world settings using heterogeneous datasets in privacy-sensitive domains (e.g., e-commerce, population, and mobility) that encompass both structured and unstructured formats. The synthetic data produced by LLMSynthor shows high statistical fidelity, practical utility, and cross-data adaptability, positioning it as a valuable tool across economics, social science, urban studies, and beyond.","authors":["Yihong Tang","Menglin Kong","Lijun Sun"],"url":"https://arxiv.org/abs/2505.14752"}
{"created":"2025-05-22","title":"$\\texttt{LLINBO}$: Trustworthy LLM-in-the-Loop Bayesian Optimization","abstract":"Bayesian optimization (BO) is a sequential decision-making tool widely used for optimizing expensive black-box functions. Recently, Large Language Models (LLMs) have shown remarkable adaptability in low-data regimes, making them promising tools for black-box optimization by leveraging contextual knowledge to propose high-quality query points. However, relying solely on LLMs as optimization agents introduces risks due to their lack of explicit surrogate modeling and calibrated uncertainty, as well as their inherently opaque internal mechanisms. This structural opacity makes it difficult to characterize or control the exploration-exploitation trade-off, ultimately undermining theoretical tractability and reliability. To address this, we propose LLINBO: LLM-in-the-Loop BO, a hybrid framework for BO that combines LLMs with statistical surrogate experts (e.g., Gaussian Processes (GP)). The core philosophy is to leverage contextual reasoning strengths of LLMs for early exploration, while relying on principled statistical models to guide efficient exploitation. Specifically, we introduce three mechanisms that enable this collaboration and establish their theoretical guarantees. We end the paper with a real-life proof-of-concept in the context of 3D printing. The code to reproduce the results can be found at https://github.com/UMDataScienceLab/LLM-in-the-Loop-BO.","authors":["Chih-Yu Chang","Milad Azvar","Chinedum Okwudire","Raed Al Kontar"],"url":"https://arxiv.org/abs/2505.14756"}
{"created":"2025-05-22","title":"Bridge2AI: Building A Cross-disciplinary Curriculum Towards AI-Enhanced Biomedical and Clinical Care","abstract":"Objective: As AI becomes increasingly central to healthcare, there is a pressing need for bioinformatics and biomedical training systems that are personalized and adaptable. Materials and Methods: The NIH Bridge2AI Training, Recruitment, and Mentoring (TRM) Working Group developed a cross-disciplinary curriculum grounded in collaborative innovation, ethical data stewardship, and professional development within an adapted Learning Health System (LHS) framework. Results: The curriculum integrates foundational AI modules, real-world projects, and a structured mentee-mentor network spanning Bridge2AI Grand Challenges and the Bridge Center. Guided by six learner personas, the program tailors educational pathways to individual needs while supporting scalability. Discussion: Iterative refinement driven by continuous feedback ensures that content remains responsive to learner progress and emerging trends. Conclusion: With over 30 scholars and 100 mentors engaged across North America, the TRM model demonstrates how adaptive, persona-informed training can build interdisciplinary competencies and foster an integrative, ethically grounded AI education in biomedical contexts.","authors":["John Rincon","Alexander R. Pelletier","Destiny Gilliland","Wei Wang","Ding Wang","Baradwaj S. Sankar","Lori Scott-Sheldon","Samson Gebreab","William Hersh","Parisa Rashidi","Sally Baxter","Wade Schulz","Trey Ideker","Yael Bensoussan","Paul C. Boutros","Alex A. T. Bui","Colin Walsh","Karol E. Watson","Peipei Ping"],"url":"https://arxiv.org/abs/2505.14757"}
{"created":"2025-05-22","title":"Kaleidoscope Gallery: Exploring Ethics and Generative AI Through Art","abstract":"Ethical theories and Generative AI (GenAI) models are dynamic concepts subject to continuous evolution. This paper investigates the visualization of ethics through a subset of GenAI models. We expand on the emerging field of Visual Ethics, using art as a form of critical inquiry and the metaphor of a kaleidoscope to invoke moral imagination. Through formative interviews with 10 ethics experts, we first establish a foundation of ethical theories. Our analysis reveals five families of ethical theories, which we then transform into images using the text-to-image (T2I) GenAI model. The resulting imagery, curated as Kaleidoscope Gallery and evaluated by the same experts, revealed eight themes that highlight how morality, society, and learned associations are central to ethical theories. We discuss implications for critically examining T2I models and present cautions and considerations. This work contributes to examining ethical theories as foundational knowledge that interrogates GenAI models as socio-technical systems.","authors":["Alayt Issak","Uttkarsh Narayan","Ramya Srinivasan","Erica Kleinman","Casper Harteveld"],"url":"https://arxiv.org/abs/2505.14758"}
{"created":"2025-05-22","title":"LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models","abstract":"Large Language Models for code often entail significant computational complexity, which grows significantly with the length of the input code sequence. We propose LeanCode for code simplification to reduce training and prediction time, leveraging code contexts in utilizing attention scores to represent the tokens' importance. We advocate for the selective removal of tokens based on the average context-aware attention scores rather than average scores across all inputs. LeanCode uses the attention scores of `CLS' tokens within the encoder for classification tasks, such as code search. It also employs the encoder-decoder attention scores to determine token significance for sequence-to-sequence tasks like code summarization.Our evaluation shows LeanCode's superiority over the SOTAs DietCode and Slimcode, with improvements of 60% and 16% for code search, and 29% and 27% for code summarization, respectively.","authors":["Yan Wang","Ling Ding","Tien N Nguyen","Shaohua Wang","Yanan Zheng"],"url":"https://arxiv.org/abs/2505.14759"}
{"created":"2025-05-22","title":"Fast and scalable multi-robot deployment planning under connectivity constraints","abstract":"In this paper we develop a method to coordinate the deployment of a multi-robot team to reach some locations of interest, so-called primary goals, and to transmit the information from these positions to a static Base Station (BS), under connectivity constraints. The relay positions have to be established for some robots to maintain the connectivity at the moment in which the other robots visit the primary goals. Once every robot reaches its assigned goal, they are again available to cover new goals, dynamically re-distributing the robots to the new tasks. The contribution of this work is a two stage method to deploy the team. Firstly, clusters of relay and primary positions are computed, obtaining a tree formed by chains of positions that have to be visited. Secondly, the order for optimally assigning and visiting the goals in the clusters is computed. We analyze different heuristics for sequential and parallel deployment in the clusters, obtaining sub-optimal solutions in short time for different number of robots and for a large amount of goals.","authors":["Yaroslav Marchukov","Luis Montano"],"url":"https://arxiv.org/abs/2505.14760"}
{"created":"2025-05-22","title":"Addressing the Challenges of Planning Language Generation","abstract":"Using LLMs to generate formal planning languages such as PDDL that invokes symbolic solvers to deterministically derive plans has been shown to outperform generating plans directly. While this success has been limited to closed-sourced models or particular LLM pipelines, we design and evaluate 8 different PDDL generation pipelines with open-source models under 50 billion parameters previously shown to be incapable of this task. We find that intuitive approaches such as using a high-resource language wrapper or constrained decoding with grammar decrease performance, yet inference-time scaling approaches such as revision with feedback from the solver and plan validator more than double the performance.","authors":["Prabhu Prakash Kagitha","Andrew Zhu","Li Zhang"],"url":"https://arxiv.org/abs/2505.14763"}
{"created":"2025-05-22","title":"Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding","abstract":"This study develops deep learning models to forecast the number of patients in the emergency department (ED) boarding phase six hours in advance, aiming to support proactive operational decision-making using only non-clinical, operational, and contextual features. Data were collected from five sources: ED tracking systems, inpatient census records, weather reports, federal holiday calendars, and local event schedules. After feature engineering, the data were aggregated at an hourly level, cleaned, and merged into a unified dataset for model training. Several time series deep learning models, including ResNetPlus, TSTPlus, TSiTPlus (from the tsai library), and N-BEATSx, were trained using Optuna and grid search for hyperparameter tuning. The average ED boarding count was 28.7, with a standard deviation of 11.2. N-BEATSx achieved the best performance, with a mean absolute error of 2.10, mean squared error of 7.08, root mean squared error of 2.66, and a coefficient of determination of 0.95. The model maintained stable accuracy even during periods of extremely high boarding counts, defined as values exceeding one, two, or three standard deviations above the mean. Results show that accurate six-hour-ahead forecasts are achievable without using patient-level clinical data. While strong performance was observed even with a basic feature set, the inclusion of additional features improved prediction stability under extreme conditions. This framework offers a practical and generalizable approach for hospital systems to anticipate boarding levels and help mitigate ED overcrowding.","authors":["Orhun Vural","Bunyamin Ozaydin","Khalid Y. Aram","James Booth","Brittany F. Lindsey","Abdulaziz Ahmed"],"url":"https://arxiv.org/abs/2505.14765"}
{"created":"2025-05-22","title":"This Time is Different: An Observability Perspective on Time Series Foundation Models","abstract":"We introduce Toto, a time series forecasting foundation model with 151 million parameters. Toto uses a modern decoder-only architecture coupled with architectural innovations designed to account for specific challenges found in multivariate observability time series data. Toto's pre-training corpus is a mixture of observability data, open datasets, and synthetic data, and is 4-10$\\times$ larger than those of leading time series foundation models. Additionally, we introduce BOOM, a large-scale benchmark consisting of 350 million observations across 2,807 real-world time series. For both Toto and BOOM, we source observability data exclusively from Datadog's own telemetry and internal observability metrics. Extensive evaluations demonstrate that Toto achieves state-of-the-art performance on both BOOM and on established general purpose time series forecasting benchmarks. Toto's model weights, inference code, and evaluation scripts, as well as BOOM's data and evaluation code, are all available as open source under the Apache 2.0 License available at https://huggingface.co/Datadog/Toto-Open-Base-1.0 and https://github.com/DataDog/toto.","authors":["Ben Cohen","Emaad Khwaja","Youssef Doubli","Salahidine Lemaachi","Chris Lettieri","Charles Masson","Hugo Miccinilli","Elise Ram\\'e","Qiqi Ren","Afshin Rostamizadeh","Jean Ogier du Terrail","Anna-Monica Toon","Kan Wang","Stephan Xie","David Asker","Ameet Talwalkar","Othmane Abou-Amal"],"url":"https://arxiv.org/abs/2505.14766"}
{"created":"2025-05-22","title":"KO: Kinetics-inspired Neural Optimizer with PDE Simulation Approaches","abstract":"The design of optimization algorithms for neural networks remains a critical challenge, with most existing methods relying on heuristic adaptations of gradient-based approaches. This paper introduces KO (Kinetics-inspired Optimizer), a novel neural optimizer inspired by kinetic theory and partial differential equation (PDE) simulations. We reimagine the training dynamics of network parameters as the evolution of a particle system governed by kinetic principles, where parameter updates are simulated via a numerical scheme for the Boltzmann transport equation (BTE) that models stochastic particle collisions. This physics-driven approach inherently promotes parameter diversity during optimization, mitigating the phenomenon of parameter condensation, i.e. collapse of network parameters into low-dimensional subspaces, through mechanisms analogous to thermal diffusion in physical systems. We analyze this property, establishing both a mathematical proof and a physical interpretation. Extensive experiments on image classification (CIFAR-10/100, ImageNet) and text classification (IMDB, Snips) tasks demonstrate that KO consistently outperforms baseline optimizers (e.g., Adam, SGD), achieving accuracy improvements while computation cost remains comparable.","authors":["Mingquan Feng","Yixin Huang","Yifan Fu","Shaobo Wang","Junchi Yan"],"url":"https://arxiv.org/abs/2505.14777"}
{"created":"2025-05-22","title":"Extracting Practical, Actionable Energy Insights from Supercomputer Telemetry and Logs","abstract":"As supercomputers grow in size and complexity, power efficiency has become a critical challenge, particularly in understanding GPU power consumption within modern HPC workloads. This work addresses this challenge by presenting a data co-analysis approach using system data collected from the Polaris supercomputer at Argonne National Laboratory. We focus on GPU utilization and power demands, navigating the complexities of large-scale, heterogeneous datasets. Our approach, which incorporates data preprocessing, post-processing, and statistical methods, condenses the data volume by 94% while preserving essential insights. Through this analysis, we uncover key opportunities for power optimization, such as reducing high idle power costs, applying power strategies at the job-level, and aligning GPU power allocation with workload demands. Our findings provide actionable insights for energy-efficient computing and offer a practical, reproducible approach for applying existing research to optimize system performance.","authors":["Melanie Cornelius","Greg Cross","Shilpika Shilpika","Matthew T. Dearing","Zhiling Lan"],"url":"https://arxiv.org/abs/2505.14796"}
{"created":"2025-05-22","title":"Efficient Privacy-Preserving Cross-Silo Federated Learning with Multi-Key Homomorphic Encryption","abstract":"Federated Learning (FL) is susceptible to privacy attacks, such as data reconstruction attacks, in which a semi-honest server or a malicious client infers information about other clients' datasets from their model updates or gradients. To enhance the privacy of FL, recent studies combined Multi-Key Homomorphic Encryption (MKHE) and FL, making it possible to aggregate the encrypted model updates using different keys without having to decrypt them. Despite the privacy guarantees of MKHE, existing approaches are not well-suited for real-world deployment due to their high computation and communication overhead. We propose MASER, an efficient MKHE-based Privacy-Preserving FL framework that combines consensus-based model pruning and slicing techniques to reduce this overhead. Our experimental results show that MASER is 3.03 to 8.29 times more efficient than existing MKHE-based FL approaches in terms of computation and communication overhead while maintaining comparable classification accuracy to standard FL algorithms. Compared to a vanilla FL algorithm, the overhead of MASER is only 1.48 to 5 times higher, striking a good balance between privacy, accuracy, and efficiency in both IID and non-IID settings.","authors":["Abdullah Al Omar","Xin Yang","Euijin Choo","Omid Ardakanian"],"url":"https://arxiv.org/abs/2505.14797"}
{"created":"2025-05-22","title":"Text embedding models can be great data engineers","abstract":"Data engineering pipelines are essential - albeit costly - components of predictive analytics frameworks requiring significant engineering time and domain expertise for carrying out tasks such as data ingestion, preprocessing, feature extraction, and feature engineering. In this paper, we propose ADEPT, an automated data engineering pipeline via text embeddings. At the core of the ADEPT framework is a simple yet powerful idea that the entropy of embeddings corresponding to textually dense raw format representation of time series can be intuitively viewed as equivalent (or in many cases superior) to that of numerically dense vector representations obtained by data engineering pipelines. Consequently, ADEPT uses a two step approach that (i) leverages text embeddings to represent the diverse data sources, and (ii) constructs a variational information bottleneck criteria to mitigate entropy variance in text embeddings of time series data. ADEPT provides an end-to-end automated implementation of predictive models that offers superior predictive performance despite issues such as missing data, ill-formed records, improper or corrupted data formats and irregular timestamps. Through exhaustive experiments, we show that the ADEPT outperforms the best existing benchmarks in a diverse set of datasets from large-scale applications across healthcare, finance, science and industrial internet of things. Our results show that ADEPT can potentially leapfrog many conventional data pipeline steps thereby paving the way for efficient and scalable automation pathways for diverse data science applications.","authors":["Iman Kazemian","Paritosh Ramanan","Murat Yildirim"],"url":"https://arxiv.org/abs/2505.14802"}
{"created":"2025-05-22","title":"SurvUnc: A Meta-Model Based Uncertainty Quantification Framework for Survival Analysis","abstract":"Survival analysis, which estimates the probability of event occurrence over time from censored data, is fundamental in numerous real-world applications, particularly in high-stakes domains such as healthcare and risk assessment. Despite advances in numerous survival models, quantifying the uncertainty of predictions from these models remains underexplored and challenging. The lack of reliable uncertainty quantification limits the interpretability and trustworthiness of survival models, hindering their adoption in clinical decision-making and other sensitive applications. To bridge this gap, in this work, we introduce SurvUnc, a novel meta-model based framework for post-hoc uncertainty quantification for survival models. SurvUnc introduces an anchor-based learning strategy that integrates concordance knowledge into meta-model optimization, leveraging pairwise ranking performance to estimate uncertainty effectively. Notably, our framework is model-agnostic, ensuring compatibility with any survival model without requiring modifications to its architecture or access to its internal parameters. Especially, we design a comprehensive evaluation pipeline tailored to this critical yet overlooked problem. Through extensive experiments on four publicly available benchmarking datasets and five representative survival models, we demonstrate the superiority of SurvUnc across multiple evaluation scenarios, including selective prediction, misprediction detection, and out-of-domain detection. Our results highlight the effectiveness of SurvUnc in enhancing model interpretability and reliability, paving the way for more trustworthy survival predictions in real-world applications.","authors":["Yu Liu","Weiyao Tao","Tong Xia","Simon Knight","Tingting Zhu"],"url":"https://arxiv.org/abs/2505.14803"}
{"created":"2025-05-22","title":"Automated Journalistic Questions: A New Method for Extracting 5W1H in French","abstract":"The 5W1H questions -- who, what, when, where, why and how -- are commonly used in journalism to ensure that an article describes events clearly and systematically. Answering them is a crucial prerequisites for tasks such as summarization, clustering, and news aggregation. In this paper, we design the first automated extraction pipeline to get 5W1H information from French news articles. To evaluate the performance of our algo- rithm, we also create a corpus of 250 Quebec news articles with 5W1H answers marked by four human annotators. Our results demonstrate that our pipeline performs as well in this task as the large language model GPT-4o.","authors":["Richard Khoury","Maxence Verhaverbeke","Julie A. Gramaccia"],"url":"https://arxiv.org/abs/2505.14804"}
{"created":"2025-05-22","title":"Integrating Field of View in Human-Aware Collaborative Planning","abstract":"In human-robot collaboration (HRC), it is crucial for robot agents to consider humans' knowledge of their surroundings. In reality, humans possess a narrow field of view (FOV), limiting their perception. However, research on HRC often overlooks this aspect and presumes an omniscient human collaborator. Our study addresses the challenge of adapting to the evolving subtask intent of humans while accounting for their limited FOV. We integrate FOV within the human-aware probabilistic planning framework. To account for large state spaces due to considering FOV, we propose a hierarchical online planner that efficiently finds approximate solutions while enabling the robot to explore low-level action trajectories that enter the human FOV, influencing their intended subtask. Through user study with our adapted cooking domain, we demonstrate our FOV-aware planner reduces human's interruptions and redundant actions during collaboration by adapting to human perception limitations. We extend these findings to a virtual reality kitchen environment, where we observe similar collaborative behaviors.","authors":["Ya-Chuan Hsu","Michael Defranco","Rutvik Patel","Stefanos Nikolaidis"],"url":"https://arxiv.org/abs/2505.14805"}
{"created":"2025-05-22","title":"Scaling Reasoning, Losing Control: Evaluating Instruction Following in Large Reasoning Models","abstract":"Instruction-following is essential for aligning large language models (LLMs) with user intent. While recent reasoning-oriented models exhibit impressive performance on complex mathematical problems, their ability to adhere to natural language instructions remains underexplored. In this work, we introduce MathIF, a dedicated benchmark for evaluating instruction-following in mathematical reasoning tasks. Our empirical analysis reveals a consistent tension between scaling up reasoning capacity and maintaining controllability, as models that reason more effectively often struggle to comply with user directives. We find that models tuned on distilled long chains-of-thought or trained with reasoning-oriented reinforcement learning often degrade in instruction adherence, especially when generation length increases. Furthermore, we show that even simple interventions can partially recover obedience, though at the cost of reasoning performance. These findings highlight a fundamental tension in current LLM training paradigms and motivate the need for more instruction-aware reasoning models. We release the code and data at https://github.com/TingchenFu/MathIF.","authors":["Tingchen Fu","Jiawei Gu","Yafu Li","Xiaoye Qu","Yu Cheng"],"url":"https://arxiv.org/abs/2505.14810"}
{"created":"2025-05-22","title":"GraphemeAug: A Systematic Approach to Synthesized Hard Negative Keyword Spotting Examples","abstract":"Spoken Keyword Spotting (KWS) is the task of distinguishing between the presence and absence of a keyword in audio. The accuracy of a KWS model hinges on its ability to correctly classify examples close to the keyword and non-keyword boundary. These boundary examples are often scarce in training data, limiting model performance. In this paper, we propose a method to systematically generate adversarial examples close to the decision boundary by making insertion/deletion/substitution edits on the keyword's graphemes. We evaluate this technique on held-out data for a popular keyword and show that the technique improves AUC on a dataset of synthetic hard negatives by 61% while maintaining quality on positives and ambient negative audio data.","authors":["Harry Zhang","Kurt Partridge","Pai Zhu","Neng Chen","Hyun Jin Park","Dhruuv Agarwal","Quan Wang"],"url":"https://arxiv.org/abs/2505.14814"}
{"created":"2025-05-22","title":"Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes","abstract":"Reasoning language models (RLMs) excel at complex tasks by leveraging a chain-of-thought process to generate structured intermediate steps. However, language mixing, i.e., reasoning steps containing tokens from languages other than the prompt, has been observed in their outputs and shown to affect performance, though its impact remains debated. We present the first systematic study of language mixing in RLMs, examining its patterns, impact, and internal causes across 15 languages, 7 task difficulty levels, and 18 subject areas, and show how all three factors influence language mixing. Moreover, we demonstrate that the choice of reasoning language significantly affects performance: forcing models to reason in Latin or Han scripts via constrained decoding notably improves accuracy. Finally, we show that the script composition of reasoning traces closely aligns with that of the model's internal representations, indicating that language mixing reflects latent processing preferences in RLMs. Our findings provide actionable insights for optimizing multilingual reasoning and open new directions for controlling reasoning languages to build more interpretable and adaptable RLMs.","authors":["Mingyang Wang","Lukas Lange","Heike Adel","Yunpu Ma","Jannik Str\\\"otgen","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2505.14815"}
{"created":"2025-05-22","title":"Designing Semantically-Resonant Abstract Patterns for Data Visualization","abstract":"We present a structured design methodology for creating semantically-resonant abstract patterns, making the pattern design process accessible to the general public. Semantically-resonant patterns are those that intuitively evoke the concept they represent within a specific set (e.g., in a vegetable concept set, small dots for olives and large dots for tomatoes), analogous to the concept of semantically-resonant colors (e.g., using olive green for olives and red for tomatoes). Previous research has shown that semantically-resonant colors can improve chart reading speed, and designers have made attempts to integrate semantic cues into abstract pattern designs. However, a systematic framework for developing such patterns was lacking. To bridge this gap, we conducted a series of workshops with design experts, resulting in a design methodology that summarizes the methodology for designing semantically-resonant abstract patterns. We evaluated our design methodology through another series of workshops with non-design participants. The results indicate that our proposed design methodology effectively supports the general public in designing semantically-resonant abstract patterns for both abstract and concrete concepts.","authors":["Zihan Lu","Tingying He","Jiayi Hong","Lijie Yao","Tobias Isenberg"],"url":"https://arxiv.org/abs/2505.14816"}
{"created":"2025-05-22","title":"Cooperative Bargaining Games Without Utilities: Mediated Solutions from Direction Oracles","abstract":"Cooperative bargaining games are widely used to model resource allocation and conflict resolution. Traditional solutions assume the mediator can access agents utility function values and gradients. However, there is an increasing number of settings, such as human AI interactions, where utility values may be inaccessible or incomparable due to unknown, nonaffine transformations. To model such settings, we consider that the mediator has access only to agents most preferred directions, i.e., normalized utility gradients in the decision space. To this end, we propose a cooperative bargaining algorithm where a mediator has access to only the direction oracle of each agent. We prove that unlike popular approaches such as the Nash and Kalai Smorodinsky bargaining solutions, our approach is invariant to monotonic nonaffine transformations, and that under strong convexity and smoothness assumptions, this approach enjoys global asymptotic convergence to Pareto stationary solutions. Moreover, we show that the bargaining solutions found by our algorithm also satisfy the axioms of symmetry and (under slightly stronger conditions) independence of irrelevant alternatives, which are popular in the literature. Finally, we conduct experiments in two domains, multi agent formation assignment and mediated stock portfolio allocation, which validate these theoretic results. All code for our experiments can be found at https://github.com/suryakmurthy/dibs_bargaining.","authors":["Kushagra Gupta","Surya Murthy","Mustafa O. Karabag","Ufuk Topcu","David Fridovich-Keil"],"url":"https://arxiv.org/abs/2505.14817"}
{"created":"2025-05-22","title":"WebNovelBench: Placing LLM Novelists on the Web Novel Distribution","abstract":"Robustly evaluating the long-form storytelling capabilities of Large Language Models (LLMs) remains a significant challenge, as existing benchmarks often lack the necessary scale, diversity, or objective measures. To address this, we introduce WebNovelBench, a novel benchmark specifically designed for evaluating long-form novel generation. WebNovelBench leverages a large-scale dataset of over 4,000 Chinese web novels, framing evaluation as a synopsis-to-story generation task. We propose a multi-faceted framework encompassing eight narrative quality dimensions, assessed automatically via an LLM-as-Judge approach. Scores are aggregated using Principal Component Analysis and mapped to a percentile rank against human-authored works. Our experiments demonstrate that WebNovelBench effectively differentiates between human-written masterpieces, popular web novels, and LLM-generated content. We provide a comprehensive analysis of 24 state-of-the-art LLMs, ranking their storytelling abilities and offering insights for future development. This benchmark provides a scalable, replicable, and data-driven methodology for assessing and advancing LLM-driven narrative generation.","authors":["Leon Lin","Jun Zheng","Haidong Wang"],"url":"https://arxiv.org/abs/2505.14818"}
{"created":"2025-05-22","title":"DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation","abstract":"Dexterous robotic manipulation remains a longstanding challenge in robotics due to the high dimensionality of control spaces and the semantic complexity of object interaction. In this paper, we propose an object affordance-guided reinforcement learning framework that enables a multi-fingered robotic hand to learn human-like manipulation strategies more efficiently. By leveraging object affordance maps, our approach generates semantically meaningful grasp pose candidates that serve as both policy constraints and priors during training. We introduce a voting-based grasp classification mechanism to ensure functional alignment between grasp configurations and object affordance regions. Furthermore, we incorporate these constraints into a generalizable RL pipeline and design a reward function that unifies affordance-awareness with task-specific objectives. Experimental results across three manipulation tasks - cube grasping, jug grasping and lifting, and hammer use - demonstrate that our affordance-guided approach improves task success rates by an average of 15.4% compared to baselines. These findings highlight the critical role of object affordance priors in enhancing sample efficiency and learning generalizable, semantically grounded manipulation policies. For more details, please visit our project website https://sites.google.com/view/dora-manip.","authors":["Lei Zhang","Soumya Mondal","Zhenshan Bing","Kaixin Bai","Diwen Zheng","Zhaopeng Chen","Alois Christian Knoll","Jianwei Zhang"],"url":"https://arxiv.org/abs/2505.14819"}
{"created":"2025-05-22","title":"Imitation Learning via Focused Satisficing","abstract":"Imitation learning often assumes that demonstrations are close to optimal according to some fixed, but unknown, cost function. However, according to satisficing theory, humans often choose acceptable behavior based on their personal (and potentially dynamic) levels of aspiration, rather than achieving (near-) optimality. For example, a lunar lander demonstration that successfully lands without crashing might be acceptable to a novice despite being slow or jerky. Using a margin-based objective to guide deep reinforcement learning, our focused satisficing approach to imitation learning seeks a policy that surpasses the demonstrator's aspiration levels -- defined over trajectories or portions of trajectories -- on unseen demonstrations without explicitly learning those aspirations. We show experimentally that this focuses the policy to imitate the highest quality (portions of) demonstrations better than existing imitation learning methods, providing much higher rates of guaranteed acceptability to the demonstrator, and competitive true returns on a range of environments.","authors":["Rushit N. Shah","Nikolaos Agadakos","Synthia Sasulski","Ali Farajzadeh","Sanjiban Choudhury","Brian Ziebart"],"url":"https://arxiv.org/abs/2505.14820"}
{"created":"2025-05-22","title":"Sample and Computationally Efficient Continuous-Time Reinforcement Learning with General Function Approximation","abstract":"Continuous-time reinforcement learning (CTRL) provides a principled framework for sequential decision-making in environments where interactions evolve continuously over time. Despite its empirical success, the theoretical understanding of CTRL remains limited, especially in settings with general function approximation. In this work, we propose a model-based CTRL algorithm that achieves both sample and computational efficiency. Our approach leverages optimism-based confidence sets to establish the first sample complexity guarantee for CTRL with general function approximation, showing that a near-optimal policy can be learned with a suboptimality gap of $\\tilde{O}(\\sqrt{d_{\\mathcal{R}} + d_{\\mathcal{F}}}N^{-1/2})$ using $N$ measurements, where $d_{\\mathcal{R}}$ and $d_{\\mathcal{F}}$ denote the distributional Eluder dimensions of the reward and dynamic functions, respectively, capturing the complexity of general function approximation in reinforcement learning. Moreover, we introduce structured policy updates and an alternative measurement strategy that significantly reduce the number of policy updates and rollouts while maintaining competitive sample efficiency. We implemented experiments to backup our proposed algorithms on continuous control tasks and diffusion model fine-tuning, demonstrating comparable performance with significantly fewer policy updates and rollouts.","authors":["Runze Zhao","Yue Yu","Adams Yiyue Zhu","Chen Yang","Dongruo Zhou"],"url":"https://arxiv.org/abs/2505.14821"}
{"created":"2025-05-22","title":"Tracing Multilingual Factual Knowledge Acquisition in Pretraining","abstract":"Large Language Models (LLMs) are capable of recalling multilingual factual knowledge present in their pretraining data. However, most studies evaluate only the final model, leaving the development of factual recall and crosslingual consistency throughout pretraining largely unexplored. In this work, we trace how factual recall and crosslingual consistency evolve during pretraining, focusing on OLMo-7B as a case study. We find that both accuracy and consistency improve over time for most languages. We show that this improvement is primarily driven by the fact frequency in the pretraining corpus: more frequent facts are more likely to be recalled correctly, regardless of language. Yet, some low-frequency facts in non-English languages can still be correctly recalled. Our analysis reveals that these instances largely benefit from crosslingual transfer of their English counterparts -- an effect that emerges predominantly in the early stages of pretraining. We pinpoint two distinct pathways through which multilingual factual knowledge acquisition occurs: (1) frequency-driven learning, which is dominant and language-agnostic, and (2) crosslingual transfer, which is limited in scale and typically constrained to relation types involving named entities. We release our code and data to facilitate further research at https://github.com/cisnlp/multilingual-fact-tracing.","authors":["Yihong Liu","Mingyang Wang","Amir Hossein Kargaran","Felicia K\\\"orner","Ercong Nie","Barbara Plank","Fran\\c{c}ois Yvon","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2505.14824"}
{"created":"2025-05-22","title":"Assimilative Causal Inference","abstract":"Causal inference determines cause-and-effect relationships between variables and has broad applications across disciplines. Traditional time-series methods often reveal causal links only in a time-averaged sense, while ensemble-based information transfer approaches detect the time evolution of short-term causal relationships but are typically limited to low-dimensional systems. In this paper, a new causal inference framework, called assimilative causal inference (ACI), is developed. Fundamentally different from the state-of-the-art methods, ACI uses a dynamical system and a single realization of a subset of the state variables to identify instantaneous causal relationships and the dynamic evolution of the associated causal influence range (CIR). Instead of quantifying how causes influence effects as done traditionally, ACI solves an inverse problem via Bayesian data assimilation, thus tracing causes backward from observed effects with an implicit Bayesian hypothesis. Causality is determined by assessing whether incorporating the information of the effect variables reduces the uncertainty in recovering the potential cause variables. ACI has several desirable features. First, it captures the dynamic interplay of variables, where their roles as causes and effects can shift repeatedly over time. Second, a mathematically justified objective criterion determines the CIR without empirical thresholds. Third, ACI is scalable to high-dimensional problems by leveraging computationally efficient Bayesian data assimilation techniques. Finally, ACI applies to short time series and incomplete datasets. Notably, ACI does not require observations of candidate causes, which is a key advantage since potential drivers are often unknown or unmeasured. The effectiveness of ACI is demonstrated by complex dynamical systems showcasing intermittency and extreme events.","authors":["Marios Andreou","Nan Chen","Erik Bollt"],"url":"https://arxiv.org/abs/2505.14825"}
{"created":"2025-05-22","title":"FisherSFT: Data-Efficient Supervised Fine-Tuning of Language Models Using Information Gain","abstract":"Supervised fine-tuning (SFT) is a standard approach to adapting large language models (LLMs) to new domains. In this work, we improve the statistical efficiency of SFT by selecting an informative subset of training examples. Specifically, for a fixed budget of training examples, which determines the computational cost of fine-tuning, we determine the most informative ones. The key idea in our method is to select examples that maximize information gain, measured by the Hessian of the log-likelihood of the LLM. We approximate it efficiently by linearizing the LLM at the last layer using multinomial logistic regression models. Our approach is computationally efficient, analyzable, and performs well empirically. We demonstrate this on several problems, and back our claims with both quantitative results and an LLM evaluation.","authors":["Rohan Deb","Kiran Thekumparampil","Kousha Kalantari","Gaurush Hiranandani","Shoham Sabach","Branislav Kveton"],"url":"https://arxiv.org/abs/2505.14826"}
{"created":"2025-05-22","title":"Text Generation Beyond Discrete Token Sampling","abstract":"In standard autoregressive generation, an LLM predicts the next-token distribution, samples a discrete token, and then discards the distribution, passing only the sampled token as new input. To preserve this distribution's rich information, we propose Mixture of Inputs (MoI), a training-free method for autoregressive generation. After generating a token following the standard paradigm, we construct a new input that blends the generated discrete token with the previously discarded token distribution. Specifically, we employ a Bayesian estimation method that treats the token distribution as the prior, the sampled token as the observation, and replaces the conventional one-hot vector with the continuous posterior expectation as the new model input. MoI allows the model to maintain a richer internal representation throughout the generation process, resulting in improved text quality and reasoning capabilities. On mathematical reasoning, code generation, and PhD-level QA tasks, MoI consistently improves performance across multiple models including QwQ-32B, Nemotron-Super-49B, Gemma-3-27B, and DAPO-Qwen-32B, with no additional training and negligible computational overhead.","authors":["Yufan Zhuang","Liyuan Liu","Chandan Singh","Jingbo Shang","Jianfeng Gao"],"url":"https://arxiv.org/abs/2505.14827"}
{"created":"2025-05-22","title":"Deep Koopman operator framework for causal discovery in nonlinear dynamical systems","abstract":"We use a deep Koopman operator-theoretic formalism to develop a novel causal discovery algorithm, Kausal. Causal discovery aims to identify cause-effect mechanisms for better scientific understanding, explainable decision-making, and more accurate modeling. Standard statistical frameworks, such as Granger causality, lack the ability to quantify causal relationships in nonlinear dynamics due to the presence of complex feedback mechanisms, timescale mixing, and nonstationarity. This presents a challenge in studying many real-world systems, such as the Earth's climate. Meanwhile, Koopman operator methods have emerged as a promising tool for approximating nonlinear dynamics in a linear space of observables. In Kausal, we propose to leverage this powerful idea for causal analysis where optimal observables are inferred using deep learning. Causal estimates are then evaluated in a reproducing kernel Hilbert space, and defined as the distance between the marginal dynamics of the effect and the joint dynamics of the cause-effect observables. Our numerical experiments demonstrate Kausal's superior ability in discovering and characterizing causal signals compared to existing approaches of prescribed observables. Lastly, we extend our analysis to observations of El Ni\\~no-Southern Oscillation highlighting our algorithm's applicability to real-world phenomena. Our code is available at https://github.com/juannat7/kausal.","authors":["Juan Nathaniel","Carla Roesch","Jatan Buch","Derek DeSantis","Adam Rupe","Kara Lamb","Pierre Gentine"],"url":"https://arxiv.org/abs/2505.14828"}
{"created":"2025-05-22","title":"Modulation of switching dynamics in magnetic tunnel junctions for low-error-rate computational random-access memory","abstract":"The conventional computer architecture has been facing challenges answering the ever-increasing demands from emerging applications, such as AI, for energy-efficient computation and memory hardware systems. Computational Random Access Memory (CRAM) represents a true in-memory computing paradigm that integrates logic and memory functions within the same array. At its core, CRAM relies on Magnetic Tunnel Junctions (MTJs), which serve as the foundational building blocks for implementing both memory storage and logic operations. However, a key challenge in CRAM lies in the non-ideal error rates associated with switching dynamics of MTJs, necessitating innovative approaches to reduce errors and optimize logic margins. This work demonstrates a technique of utilizing the voltage-controlled magnetic anisotropy (VCMA) to steepen the switching probability transfer curve (SPTC), thereby significantly reducing the logic operation error rate in CRAM. Using several numerical modeling tools, we validate the effectiveness of VCMA in modulating the energy barrier and switching dynamics in MTJs. It is revealed that the VCMA effect significantly reduces the error rate of CRAM by 61.43% at a VCMA coefficient of 200 fJ V-1 m-1 compared to CRAM without VCMA. The reduction of error rate is further rapidly amplified with an increasing TMR ratio. Furthermore, the introduction of the VCMA effect decreases the logic voltage (Vlogic) required for logic operations in CRAM and results in reduction of energy consumption. Our work serves as a first exploration reducing the error rate in CRAM by modifying SPTC in MTJs.","authors":["Yang Lv","Brahmdutta Dixit","Jian-Ping Wang"],"url":"https://arxiv.org/abs/2505.14829"}
{"created":"2025-05-22","title":"Movable Antenna Aided Full-Duplex ISAC System with Self-Interference Mitigation","abstract":"Movable antenna (MA) has shown significant potential for improving the performance of integrated sensing and communication (ISAC) systems. In this paper, we model an MA-aided ISAC system operating in a communication full-duplex mono-static sensing framework. The self-interference channel is modeled as a function of the antenna position vectors under the near-field channel condition. We develop an optimization problem to maximize the weighted sum of downlink and uplink communication rates alongside the mutual information relevant to the sensing task. To address this highly non-convex problem, we employ the fractional programming (FP) method and propose an alternating optimization (AO)-based algorithm that jointly optimizes the beamforming, user power allocation, and antenna positions at the transceivers. Given the sensitivity of the AO-based algorithm to the initial antenna positions, a PSO-based algorithm is proposed to explore superior sub-optimal antenna positions within the feasible region. Numerical results indicate that the proposed algorithms enable the MA system to effectively leverage the antenna position flexibility for accurate beamforming in a complex ISAC scenario. This enhances the system's self-interference cancellation (SIC) capabilities and markedly improves its overall performance and reliability compared to conventional fixed-position antenna designs.","authors":["Size Peng","Yin Xu","Guanli Yi","Cixiao Zhang","Dazhi He","Wenjun Zhang"],"url":"https://arxiv.org/abs/2505.14830"}
{"created":"2025-05-22","title":"SEPS: A Separability Measure for Robust Unlearning in LLMs","abstract":"Machine unlearning aims to selectively remove targeted knowledge from Large Language Models (LLMs), ensuring they forget specified content while retaining essential information. Existing unlearning metrics assess whether a model correctly answers retain queries and rejects forget queries, but they fail to capture real-world scenarios where forget queries rarely appear in isolation. In fact, forget and retain queries often coexist within the same prompt, making mixed-query evaluation crucial.","authors":["Wonje Jeung","Sangyeon Yoon","Albert No"],"url":"https://arxiv.org/abs/2505.14832"}
{"created":"2025-05-22","title":"Robust and Efficient AI-Based Attack Recovery in Autonomous Drones","abstract":"We introduce an autonomous attack recovery architecture to add common sense reasoning to plan a recovery action after an attack is detected. We outline use-cases of our architecture using drones, and then discuss how to implement this architecture efficiently and securely in edge devices.","authors":["Diego Ortiz Barbosa","Luis Burbano","Siwei Yang","Zijun Wang","Alvaro A. Cardenas","Cihang Xie","Yinzhi Cao"],"url":"https://arxiv.org/abs/2505.14835"}
{"created":"2025-05-22","title":"In-depth Research Impact Summarization through Fine-Grained Temporal Citation Analysis","abstract":"Understanding the impact of scientific publications is crucial for identifying breakthroughs and guiding future research. Traditional metrics based on citation counts often miss the nuanced ways a paper contributes to its field. In this work, we propose a new task: generating nuanced, expressive, and time-aware impact summaries that capture both praise (confirmation citations) and critique (correction citations) through the evolution of fine-grained citation intents. We introduce an evaluation framework tailored to this task, showing moderate to strong human correlation on subjective metrics such as insightfulness. Expert feedback from professors reveals a strong interest in these summaries and suggests future improvements.","authors":["Hiba Arnaout","Noy Sternlicht","Tom Hope","Iryna Gurevych"],"url":"https://arxiv.org/abs/2505.14838"}
{"created":"2025-05-22","title":"Subquadratic Algorithms and Hardness for Attention with Any Temperature","abstract":"Despite the popularity of the Transformer architecture, the standard algorithm for computing Attention suffers from quadratic time complexity in context length $n$. Alman and Song [NeurIPS 2023] showed that when the head dimension $d = \\Theta(\\log n)$, subquadratic Attention is possible if and only if the inputs have small entries bounded by $B = o(\\sqrt{\\log n})$ in absolute values, under the Strong Exponential Time Hypothesis ($\\mathsf{SETH}$). Equivalently, subquadratic Attention is possible if and only if the softmax is applied with high temperature for $d=\\Theta(\\log n)$. Running times of these algorithms depend exponentially on $B$ and thus they do not lead to even a polynomial-time algorithm outside the specific range of $B$.","authors":["Shreya Gupta","Boyang Huang","Barna Saha","Yinzhan Xu","Christopher Ye"],"url":"https://arxiv.org/abs/2505.14840"}
{"created":"2025-05-22","title":"Beyond Pairwise Plasticity: Group-Level Spike Synchrony Facilitates Efficient Learning in Spiking Neural Networks","abstract":"Brain networks rely on precise spike timing and coordinated activity to support robust and energy-efficient learning. Inspired by these principles, spiking neural networks (SNNs) are widely regarded as promising candidates for low-power, event-driven computing. However, most biologically-inspired learning rules employed in SNNs, including spike-timing-dependent plasticity (STDP), rely on isolated spike pairs and lack sensitivity to population-level activity. This limits their stability and generalization, particularly in noisy and fast-changing environments. Motivated by biological observations that neural synchrony plays a central role in learning and memory, we introduce a spike-synchrony-dependent plasticity (SSDP) rule that adjusts synaptic weights based on the degree of coordinated firing among neurons. SSDP supports stable and scalable learning by encouraging neurons to form coherent activity patterns. One prominent outcome is a sudden transition from unstable to stable dynamics during training, suggesting that synchrony may drive convergence toward equilibrium firing regimes. We demonstrate SSDP's effectiveness across multiple network types, from minimal-layer models to spiking ResNets and SNN-Transformer. To our knowledge, this is the first application of a synaptic plasticity mechanism in a spiking transformer. SSDP operates in a fully event-driven manner and incurs minimal computational cost, making it well-suited for neuromorphic deployment. In this approach, local synaptic modifications are associated with the collective dynamics of neural networks, resulting in a learning strategy that adheres to biological principles while maintaining practical efficiency, these findings position SSDP as a general-purpose optimization strategy for SNNs, while offering new insights into population-based learning mechanisms in the brain.","authors":["Yuchen Tian","Assel Kembay","Nhan Duy Truong","Jason K. Eshraghian","Omid Kavehei"],"url":"https://arxiv.org/abs/2505.14841"}
{"created":"2025-05-22","title":"Looking for an out: Affordances, uncertainty and collision avoidance behavior of human drivers","abstract":"Understanding collision avoidance behavior is of key importance in traffic safety research and for designing and evaluating advanced driver assistance systems and autonomous vehicles. While existing experimental work has primarily focused on response timing in traffic conflicts, the goal of the present study was to gain a better understanding of human evasive maneuver decisions and execution in collision avoidance scenarios. To this end, we designed a driving simulator study where participants were exposed to one of three surprising opposite direction lateral incursion (ODLI) scenario variants. The results demonstrated that both the participants' collision avoidance behavior patterns and the collision outcome was strongly determined by the scenario kinematics and, more specifically, by the uncertainty associated with the oncoming vehicle's future trajectory. We discuss pitfalls related to hindsight bias when judging the quality of evasive maneuvers in uncertain situations and suggest that the availability of escape paths in collision avoidance scenarios can be usefully understood based on the notion of affordances, and further demonstrate how such affordances can be operationalized in terms of reachable sets. We conclude by discussing how these results can be used to inform computational models of collision avoidance behavior.","authors":["Leif Johnson","Johan Engstr\\\"om","Aravinda Srinivasan","Ibrahim \\\"Ozturk","Gustav Markkula"],"url":"https://arxiv.org/abs/2505.14842"}
{"created":"2025-05-22","title":"Leveraging Generative AI Models to Explore Human Identity","abstract":"This paper attempts to explore human identity by utilizing neural networks in an indirect manner. For this exploration, we adopt diffusion models, state-of-the-art AI generative models trained to create human face images. By relating the generated human face to human identity, we establish a correspondence between the face image generation process of the diffusion model and the process of human identity formation. Through experiments with the diffusion model, we observe that changes in its external input result in significant changes in the generated face image. Based on the correspondence, we indirectly confirm the dependence of human identity on external factors in the process of human identity formation. Furthermore, we introduce \\textit{Fluidity of Human Identity}, a video artwork that expresses the fluid nature of human identity affected by varying external factors. The video is available at https://www.behance.net/gallery/219958453/Fluidity-of-Human-Identity?.","authors":["Yunha Yeo","Daeho Um"],"url":"https://arxiv.org/abs/2505.14843"}
{"created":"2025-05-22","title":"The Pin of Shame: Examining Content Creators' Adoption of Pinning Inappropriate Comments as a Moderation Strategy","abstract":"Many social media platforms allow content creators to pin user comments in response to their content. Once pinned, a comment remains fixed at the top of the comments section, regardless of subsequent activity or the selected sorting order. The \"Pin of Shame\" refers to an innovative re-purposing of this feature, where creators intentionally pin norm-violating comments to spotlight them and prompt shaming responses from their audiences. This study explores how creators adopt this emerging moderation tactic, examining their motivations, its outcomes, and how it compares-procedurally and in effect-to other content moderation strategies. Through interviews with 20 content creators who had pinned negative comments on their posts, we find that the Pin of Shame is used to punish and educate inappropriate commenters, elicit emotional accountability, provoke audience negotiation of community norms, and support creators' impression management goals. Our findings shed light on the benefits, precarities, and risks of using public shaming as a tool for norm enforcement. We contribute to HCI research by informing the design of user-centered tools for addressing content-based harm.","authors":["Yunhee Shim","Shagun Jhaver"],"url":"https://arxiv.org/abs/2505.14844"}
{"created":"2025-05-22","title":"A Comparative Study of Large Language Models and Human Personality Traits","abstract":"Large Language Models (LLMs) have demonstrated human-like capabilities in language comprehension and generation, becoming active participants in social and cognitive domains. This study investigates whether LLMs exhibit personality-like traits and how these traits compare with human personality, focusing on the applicability of conventional personality assessment tools. A behavior-based approach was used across three empirical studies. Study 1 examined test-retest stability and found that LLMs show higher variability and are more input-sensitive than humans, lacking long-term stability. Based on this, we propose the Distributed Personality Framework, conceptualizing LLM traits as dynamic and input-driven. Study 2 analyzed cross-variant consistency in personality measures and found LLMs' responses were highly sensitive to item wording, showing low internal consistency compared to humans. Study 3 explored personality retention during role-playing, showing LLM traits are shaped by prompt and parameter settings. These findings suggest that LLMs express fluid, externally dependent personality patterns, offering insights for constructing LLM-specific personality frameworks and advancing human-AI interaction. This work contributes to responsible AI development and extends the boundaries of personality psychology in the age of intelligent systems.","authors":["Wang Jiaqi","Wang bo","Guo fa","Cheng cheng","Yang li"],"url":"https://arxiv.org/abs/2505.14845"}
{"created":"2025-05-22","title":"Open-Set Semi-Supervised Learning for Long-Tailed Medical Datasets","abstract":"Many practical medical imaging scenarios include categories that are under-represented but still crucial. The relevance of image recognition models to real-world applications lies in their ability to generalize to these rare classes as well as unseen classes. Real-world generalization requires taking into account the various complexities that can be encountered in the real-world. First, training data is highly imbalanced, which may lead to model exhibiting bias toward the more frequently represented classes. Moreover, real-world data may contain unseen classes that need to be identified, and model performance is affected by the data scarcity. While medical image recognition has been extensively addressed in the literature, current methods do not take into account all the intricacies in the real-world scenarios. To this end, we propose an open-set learning method for highly imbalanced medical datasets using a semi-supervised approach. Understanding the adverse impact of long-tail distribution at the inherent model characteristics, we implement a regularization strategy at the feature level complemented by a classifier normalization technique. ","authors":["Daniya Najiha A. Kareem","Jean Lahoud","Mustansar Fiaz","Amandeep Kumar","Hisham Cholakkal"],"url":"https://arxiv.org/abs/2505.14846"}
{"created":"2025-05-22","title":"Beyond Symmetry in Repeated Games with Restarts","abstract":"Infinitely repeated games support equilibrium concepts beyond those present in one-shot games (e.g., cooperation in the prisoner's dilemma). Nonetheless, repeated games fail to capture our real-world intuition for settings with many anonymous agents interacting in pairs. Repeated games with restarts, introduced by Berker and Conitzer [IJCAI '24], address this concern by giving players the option to restart the game with someone new whenever their partner deviates from an agreed-upon sequence of actions. In their work, they studied symmetric games with symmetric strategies. We significantly extend these results, introducing and analyzing more general notions of equilibria in asymmetric games with restarts. We characterize which goal strategies players can be incentivized to play in equilibrium, and we consider the computational problem of finding such sequences of actions with minimal cost for the agents. We show that this problem is NP-hard in general. However, when the goal sequence maximizes social welfare, we give a pseudo-polynomial time algorithm.","authors":["Henry Fleischmann","Kiriaki Fragkia","Ratip Emin Berker"],"url":"https://arxiv.org/abs/2505.14847"}
{"created":"2025-05-22","title":"MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation","abstract":"We present MAATS, a Multi Agent Automated Translation System that leverages the Multidimensional Quality Metrics (MQM) framework as a fine-grained signal for error detection and refinement. MAATS employs multiple specialized AI agents, each focused on a distinct MQM category (e.g., Accuracy, Fluency, Style, Terminology), followed by a synthesis agent that integrates the annotations to iteratively refine translations. This design contrasts with conventional single-agent methods that rely on self-correction.","authors":["Xi Wang","Jiaqian Hu","Safinah Ali"],"url":"https://arxiv.org/abs/2505.14848"}
{"created":"2025-05-22","title":"EasyMath: A 0-shot Math Benchmark for SLMs","abstract":"EasyMath is a compact benchmark for practical math reasoning in small language models. It covers thirteen categories, from basic arithmetic and order of operations to word problems, algebraic expressions, edge cases, and omits specialist topics. We tested 23 models (14M to 4B parameters) using exact, numerical, and symbolic checks on free-form answers in a zero-shot setting. Accuracy rises with size and training, chain-of-thought adds modest gains, and consistency improves at scale.","authors":["Drishya Karki","Michiel Kamphuis","Angelecia Frey"],"url":"https://arxiv.org/abs/2505.14852"}
{"created":"2025-05-22","title":"Voice to Vision: Enhancing Civic Decision-Making through Co-Designed Data Infrastructure","abstract":"Trust and transparency in civic decision-making processes, like neighborhood planning, are eroding as community members frequently report sending feedback \"into a void\" without understanding how, or whether, their input influences outcomes. To address this gap, we introduce Voice to Vision, a sociotechnical system that bridges community voices and planning outputs through a structured yet flexible data infrastructure and complementary interfaces for both community members and planners. Through a five-month iterative design process with 21 stakeholders and subsequent field evaluation involving 24 participants, we examine how this system facilitates shared understanding across the civic ecosystem. Our findings reveal that while planners value systematic sensemaking tools that find connections across diverse inputs, community members prioritize seeing themselves reflected in the process, discovering patterns within feedback, and observing the rigor behind decisions, while emphasizing the importance of actionable outcomes. We contribute insights into participatory design for civic contexts, a complete sociotechnical system with an interoperable data structure for civic decision-making, and empirical findings that inform how digital platforms can promote shared understanding among elected or appointed officials, planners, and community members by enhancing transparency and legitimacy.","authors":["Maggie Hughes","Cassandra Overney","Ashima Kamra","Jasmin Tepale","Elizabeth Hamby","Mahmood Jasim","Deb Roy"],"url":"https://arxiv.org/abs/2505.14853"}
{"created":"2025-05-22","title":"Coordinated motion control of a wire arc additive manufacturing robotic system for multi-directional building parts","abstract":"This work investigates the manufacturing of complex shapes parts with wire arc additive manufacturing (WAAM). In order to guarantee the integrity and quality of each deposited layer that composes the final piece, the deposition process is usually carried out in a flat position. However, for complex geometry parts with non-flat surfaces, this strategy causes unsupported overhangs and staircase effect, which contribute to a poor surface finishing. Generally, the build direction is not constant for every deposited section or layer in complex geometry parts. As a result, there is an additional concern to ensure the build direction is aligned with gravity, thus improving the quality of the final part. This paper proposes an algorithm to control the torch motion with respect to a deposition substrate as well as the torch orientation with respect to an inertial frame. The control scheme is based on task augmentation applied to an extended kinematic chain composed by two robots, which constitutes a coordinated control problem, and allows the deposition trajectory to be planned with respect to the deposition substrate coordinate frame while aligning each layer buildup direction with gravity (or any other direction defined for an inertial frame). Parts with complex geometry aspects have been produced in a WAAM cell composed by two robots (a manipulator with a welding torch and a positioning table holding the workpiece) in order to validate the proposed approach.","authors":["Fernando Coutinho","Nicolas Lizarralde","Fernando Lizarralde"],"url":"https://arxiv.org/abs/2505.14858"}
{"created":"2025-05-22","title":"A Hierarchical Graph-Based Terrain-Aware Autonomous Navigation Approach for Complementary Multimodal Ground-Aerial Exploration","abstract":"Autonomous navigation in unknown environments is a fundamental challenge in robotics, particularly in coordinating ground and aerial robots to maximize exploration efficiency. This paper presents a novel approach that utilizes a hierarchical graph to represent the environment, encoding both geometric and semantic traversability. The framework enables the robots to compute a shared confidence metric, which helps the ground robot assess terrain and determine when deploying the aerial robot will extend exploration. The robot's confidence in traversing a path is based on factors such as predicted volumetric gain, path traversability, and collision risk. A hierarchy of graphs is used to maintain an efficient representation of traversability and frontier information through multi-resolution maps. Evaluated in a real subterranean exploration scenario, the approach allows the ground robot to autonomously identify zones that are no longer traversable but suitable for aerial deployment. By leveraging this hierarchical structure, the ground robot can selectively share graph information on confidence-assessed frontier targets from parts of the scene, enabling the aerial robot to navigate beyond obstacles and continue exploration.","authors":["Akash Patel","Mario A. V. Saucedo","Nikolaos Stathoulopoulos","Viswa Narayanan Sankaranarayanan","Ilias Tevetzidis","Christoforos Kanellakis","George Nikolakopoulos"],"url":"https://arxiv.org/abs/2505.14859"}
{"created":"2025-05-22","title":"Replay Attacks Against Audio Deepfake Detection","abstract":"We show how replay attacks undermine audio deepfake detection: By playing and re-recording deepfake audio through various speakers and microphones, we make spoofed samples appear authentic to the detection model. To study this phenomenon in more detail, we introduce ReplayDF, a dataset of recordings derived from M-AILABS and MLAAD, featuring 109 speaker-microphone combinations across six languages and four TTS models. It includes diverse acoustic conditions, some highly challenging for detection. Our analysis of six open-source detection models across five datasets reveals significant vulnerability, with the top-performing W2V2-AASIST model's Equal Error Rate (EER) surging from 4.7% to 18.2%. Even with adaptive Room Impulse Response (RIR) retraining, performance remains compromised with an 11.0% EER. We release ReplayDF for non-commercial research use.","authors":["Nicolas M\\\"uller","Piotr Kawa","Wei-Herng Choong","Adriana Stan","Aditya Tirumala Bukkapatnam","Karla Pizzi","Alexander Wagner","Philip Sperl"],"url":"https://arxiv.org/abs/2505.14862"}
{"created":"2025-05-22","title":"Balanced and Elastic End-to-end Training of Dynamic LLMs","abstract":"To reduce computational and memory costs in Large Language Models (LLMs), dynamic workload reduction schemes like Mixture of Experts (MoEs), parameter pruning, layer freezing, sparse attention, early token exit, and Mixture of Depths (MoDs) have emerged. However, these methods introduce severe workload imbalances, limiting their practicality for large-scale distributed training. We propose DynMo, an autonomous dynamic load balancing solution that ensures optimal compute distribution when using pipeline parallelism in training dynamic models. DynMo adaptively balances workloads, dynamically packs tasks into fewer workers to free idle resources, and supports both multi-GPU single-node and multi-node systems. Compared to static training methods (Megatron-LM, DeepSpeed), DynMo accelerates training by up to 1.23x (MoEs), 3.18x (pruning), 2.23x (layer freezing), 4.02x (sparse attention), 4.52x (early exit), and 1.17x (MoDs). DynMo is available at https://anonymous.4open.science/r/DynMo-4D04/.","authors":["Mohamed Wahib","Muhammed Abdullah Soyturk","Didem Unat"],"url":"https://arxiv.org/abs/2505.14864"}
{"created":"2025-05-22","title":"UPTor: Unified 3D Human Pose Dynamics and Trajectory Prediction for Human-Robot Interaction","abstract":"We introduce a unified approach to forecast the dynamics of human keypoints along with the motion trajectory based on a short sequence of input poses. While many studies address either full-body pose prediction or motion trajectory prediction, only a few attempt to merge them. We propose a motion transformation technique to simultaneously predict full-body pose and trajectory key-points in a global coordinate frame. We utilize an off-the-shelf 3D human pose estimation module, a graph attention network to encode the skeleton structure, and a compact, non-autoregressive transformer suitable for real-time motion prediction for human-robot interaction and human-aware navigation. We introduce a human navigation dataset ``DARKO'' with specific focus on navigational activities that are relevant for human-aware mobile robot navigation. We perform extensive evaluation on Human3.6M, CMU-Mocap, and our DARKO dataset. In comparison to prior work, we show that our approach is compact, real-time, and accurate in predicting human navigation motion across all datasets. Result animations, our dataset, and code will be available at https://nisarganc.github.io/UPTor-page/","authors":["Nisarga Nilavadi","Andrey Rudenko","Timm Linder"],"url":"https://arxiv.org/abs/2505.14866"}
{"created":"2025-05-22","title":"VisTopics: A Visual Semantic Unsupervised Approach to Topic Modeling of Video and Image Data","abstract":"Understanding visual narratives is crucial for examining the evolving dynamics of media representation. This study introduces VisTopics, a computational framework designed to analyze large-scale visual datasets through an end-to-end pipeline encompassing frame extraction, deduplication, and semantic clustering. Applying VisTopics to a dataset of 452 NBC News videos resulted in reducing 11,070 frames to 6,928 deduplicated frames, which were then semantically analyzed to uncover 35 topics ranging from political events to environmental crises. By integrating Latent Dirichlet Allocation with caption-based semantic analysis, VisTopics demonstrates its potential to unravel patterns in visual framing across diverse contexts. This approach enables longitudinal studies and cross-platform comparisons, shedding light on the intersection of media, technology, and public discourse. The study validates the method's reliability through human coding accuracy metrics and emphasizes its scalability for communication research. By bridging the gap between visual representation and semantic meaning, VisTopics provides a transformative tool for advancing the methodological toolkit in computational media studies. Future research may leverage VisTopics for comparative analyses across media outlets or geographic regions, offering insights into the shifting landscapes of media narratives and their societal implications.","authors":["Ayse D Lokmanoglu","Dror Walter"],"url":"https://arxiv.org/abs/2505.14868"}
{"created":"2025-05-22","title":"Saten: Sparse Augmented Tensor Networks for Post-Training Compression of Large Language Models","abstract":"The efficient implementation of large language models (LLMs) is crucial for deployment on resource-constrained devices. Low-rank tensor compression techniques, such as tensor-train (TT) networks, have been widely studied for over-parameterized neural networks. However, their applications to compress pre-trained large language models (LLMs) for downstream tasks (post-training) remains challenging due to the high-rank nature of pre-trained LLMs and the lack of access to pretraining data. In this study, we investigate low-rank tensorized LLMs during fine-tuning and propose sparse augmented tensor networks (Saten) to enhance their performance. The proposed Saten framework enables full model compression. Experimental results demonstrate that Saten enhances both accuracy and compression efficiency in tensorized language models, achieving state-of-the-art performance.","authors":["Ryan Solgi","Kai Zhen","Rupak Vignesh Swaminathan","Nathan Susanj","Athanasios Mouchtaris","Siegfried Kunzmann","Zheng Zhang"],"url":"https://arxiv.org/abs/2505.14871"}
{"created":"2025-05-22","title":"Unremarkable to Remarkable AI Agent: Exploring Boundaries of Agent Intervention for Adults With and Without Cognitive Impairment","abstract":"As the population of older adults increases, there is a growing need for support for them to age in place. This is exacerbated by the growing number of individuals struggling with cognitive decline and shrinking number of youth who provide care for them. Artificially intelligent agents could provide cognitive support to older adults experiencing memory problems, and they could help informal caregivers with coordination tasks. To better understand this possible future, we conducted a speed dating with storyboards study to reveal invisible social boundaries that might keep older adults and their caregivers from accepting and using agents. We found that healthy older adults worry that accepting agents into their homes might increase their chances of developing dementia. At the same time, they want immediate access to agents that know them well if they should experience cognitive decline. Older adults in the early stages of cognitive decline expressed a desire for agents that can ease the burden they saw themselves becoming for their caregivers. They also speculated that an agent who really knew them well might be an effective advocate for their needs when they were less able to advocate for themselves. That is, the agent may need to transition from being unremarkable to remarkable. Based on these findings, we present design opportunities and considerations for agents and articulate directions of future research.","authors":["Mai Lee Chang (Hyun Jin)","Samantha Reig (Hyun Jin)","Alicia (Hyun Jin)","Lee","Anna Huang","Hugo Sim\\~ao","Nara Han","Neeta M Khanuja","Abdullah Ubed Mohammad Ali","Rebekah Martinez","John Zimmerman","Jodi Forlizzi","Aaron Steinfeld"],"url":"https://arxiv.org/abs/2505.14872"}
{"created":"2025-05-22","title":"Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages","abstract":"Automatic speech recognition (ASR) for dysarthric speech remains challenging due to data scarcity, particularly in non-English languages. To address this, we fine-tune a voice conversion model on English dysarthric speech (UASpeech) to encode both speaker characteristics and prosodic distortions, then apply it to convert healthy non-English speech (FLEURS) into non-English dysarthric-like speech. The generated data is then used to fine-tune a multilingual ASR model, Massively Multilingual Speech (MMS), for improved dysarthric speech recognition. Evaluation on PC-GITA (Spanish), EasyCall (Italian), and SSNCE (Tamil) demonstrates that VC with both speaker and prosody conversion significantly outperforms the off-the-shelf MMS performance and conventional augmentation techniques such as speed and tempo perturbation. Objective and subjective analyses of the generated data further confirm that the generated speech simulates dysarthric characteristics.","authors":["Chin-Jou Li","Eunjung Yeo","Kwanghee Choi","Paula Andrea P\\'erez-Toro","Masao Someki","Rohan Kumar Das","Zhengjun Yue","Juan Rafael Orozco-Arroyave","Elmar N\\\"oth","David R. Mortensen"],"url":"https://arxiv.org/abs/2505.14874"}
{"created":"2025-05-22","title":"A self-regulated convolutional neural network for classifying variable stars","abstract":"Over the last two decades, machine learning models have been widely applied and have proven effective in classifying variable stars, particularly with the adoption of deep learning architectures such as convolutional neural networks, recurrent neural networks, and transformer models. While these models have achieved high accuracy, they require high-quality, representative data and a large number of labelled samples for each star type to generalise well, which can be challenging in time-domain surveys. This challenge often leads to models learning and reinforcing biases inherent in the training data, an issue that is not easily detectable when validation is performed on subsamples from the same catalogue. The problem of biases in variable star data has been largely overlooked, and a definitive solution has yet to be established. In this paper, we propose a new approach to improve the reliability of classifiers in variable star classification by introducing a self-regulated training process. This process utilises synthetic samples generated by a physics-enhanced latent space variational autoencoder, incorporating six physical parameters from Gaia Data Release 3. Our method features a dynamic interaction between a classifier and a generative model, where the generative model produces ad-hoc synthetic light curves to reduce confusion during classifier training and populate underrepresented regions in the physical parameter space. Experiments conducted under various scenarios demonstrate that our self-regulated training approach outperforms traditional training methods for classifying variable stars on biased datasets, showing statistically significant improvements.","authors":["Francisco P\\'erez-Galarce","Jorge Mart\\'inez-Palomera","Karim Pichara","Pablo Huijse","M\\'arcio Catelan"],"url":"https://arxiv.org/abs/2505.14877"}
{"created":"2025-05-22","title":"Incorporating Token Usage into Prompting Strategy Evaluation","abstract":"In recent years, large language models have demonstrated remarkable performance across diverse tasks. However, their task effectiveness is heavily dependent on the prompting strategy used to elicit output, which can vary widely in both performance and token usage. While task performance is often used to determine prompting strategy success, we argue that efficiency--balancing performance and token usage--can be a more practical metric for real-world utility. To enable this, we propose Big-$O_{tok}$, a theoretical framework for describing the token usage growth of prompting strategies, and analyze Token Cost, an empirical measure of tokens per performance. We apply these to several common prompting strategies and find that increased token usage leads to drastically diminishing performance returns. Our results validate the Big-$O_{tok}$ analyses and reinforce the need for efficiency-aware evaluations.","authors":["Chris Sypherd","Sergei Petrov","Sonny George","Vaishak Belle"],"url":"https://arxiv.org/abs/2505.14880"}
{"created":"2025-05-22","title":"Multi-modal Traffic Scenario Generation for Autonomous Driving System Testing","abstract":"Autonomous driving systems (ADS) require extensive testing and validation before deployment. However, it is tedious and time-consuming to construct traffic scenarios for ADS testing. In this paper, we propose TrafficComposer, a multi-modal traffic scenario construction approach for ADS testing. TrafficComposer takes as input a natural language (NL) description of a desired traffic scenario and a complementary traffic scene image. Then, it generates the corresponding traffic scenario in a simulator, such as CARLA and LGSVL. Specifically, TrafficComposer integrates high-level dynamic information about the traffic scenario from the NL description and intricate details about the surrounding vehicles, pedestrians, and the road network from the image. The information from the two modalities is complementary to each other and helps generate high-quality traffic scenarios for ADS testing. On a benchmark of 120 traffic scenarios, TrafficComposer achieves 97.0% accuracy, outperforming the best-performing baseline by 7.3%. Both direct testing and fuzz testing experiments on six ADSs prove the bug detection capabilities of the traffic scenarios generated by TrafficComposer. These scenarios can directly discover 37 bugs and help two fuzzing methods find 33%--124% more bugs serving as initial seeds.","authors":["Zhi Tu","Liangkun Niu","Wei Fan","Tianyi Zhang"],"url":"https://arxiv.org/abs/2505.14881"}
{"created":"2025-05-22","title":"An active learning framework for multi-group mean estimation","abstract":"We study a fundamental learning problem over multiple groups with unknown data distributions, where an analyst would like to learn the mean of each group. Moreover, we want to ensure that this data is collected in a relatively fair manner such that the noise of the estimate of each group is reasonable. In particular, we focus on settings where data are collected dynamically, which is important in adaptive experimentation for online platforms or adaptive clinical trials for healthcare. In our model, we employ an active learning framework to sequentially collect samples with bandit feedback, observing a sample in each period from the chosen group. After observing a sample, the analyst updates their estimate of the mean and variance of that group and chooses the next group accordingly. The analyst's objective is to dynamically collect samples to minimize the collective noise of the estimators, measured by the norm of the vector of variances of the mean estimators.","authors":["Abdellah Aznag","Rachel Cummings","Adam N. Elmachtoub"],"url":"https://arxiv.org/abs/2505.14882"}
{"created":"2025-05-22","title":"Polar Sparsity: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity","abstract":"Accelerating large language model (LLM) inference is critical for real-world deployments requiring high throughput and low latency. Contextual sparsity, where each token dynamically activates only a small subset of the model parameters, shows promise but does not scale to large batch sizes due to union of active neurons quickly approaching dense computation. We introduce Polar Sparsity, highlighting a key shift in sparsity importance from MLP to Attention layers as we scale batch size and sequence length. While MLP layers become more compute-efficient under batching, their sparsity vanishes. In contrast, attention becomes increasingly more expensive at scale, while their head sparsity remains stable and batch-invariant. We develop hardware-efficient, sparsity-aware GPU kernels for selective MLP and Attention computations, delivering up to \\(2.2\\times\\) end-to-end speedups for models like OPT, LLaMA-2 \\& 3, across various batch sizes and sequence lengths without compromising accuracy. To our knowledge, this is the first work to demonstrate that contextual sparsity can scale effectively to large batch sizes, delivering substantial inference acceleration with minimal changes, making Polar Sparsity practical for large-scale, high-throughput LLM deployment systems. Our code is available at: https://github.com/susavlsh10/Polar-Sparsity.","authors":["Susav Shrestha","Brad Settlemyer","Nikoli Dryden","Narasimha Reddy"],"url":"https://arxiv.org/abs/2505.14884"}
{"created":"2025-05-22","title":"Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters","abstract":"Winning competitive debates requires sophisticated reasoning and argument skills. There are unique challenges in the competitive debate: (1) The time constraints force debaters to make strategic choices about which points to pursue rather than covering all possible arguments; (2) The persuasiveness of the debate relies on the back-and-forth interaction between arguments, which a single final game status cannot evaluate. To address these challenges, we propose TreeDebater, a novel debate framework that excels in competitive debate. We introduce two tree structures: the Rehearsal Tree and Debate Flow Tree. The Rehearsal Tree anticipates the attack and defenses to evaluate the strength of the claim, while the Debate Flow Tree tracks the debate status to identify the active actions. TreeDebater allocates its time budget among candidate actions and uses the speech time controller and feedback from the simulated audience to revise its statement. The human evaluation on both the stage-level and the debate-level comparison shows that our TreeDebater outperforms the state-of-the-art multi-agent debate system. Further investigation shows that TreeDebater shows better strategies in limiting time to important debate actions, aligning with the strategies of human debate experts.","authors":["Danqing Wang","Zhuorui Ye","Xinran Zhao","Fei Fang","Lei Li"],"url":"https://arxiv.org/abs/2505.14886"}
{"created":"2025-05-22","title":"In-Context Learning Boosts Speech Recognition via Human-like Adaptation to Speakers and Language Varieties","abstract":"Human listeners readily adjust to unfamiliar speakers and language varieties through exposure, but do these adaptation benefits extend to state-of-the-art spoken language models? We introduce a scalable framework that allows for in-context learning (ICL) in Phi-4 Multimodal using interleaved task prompts and audio-text pairs, and find that as few as 12 example utterances (~50 seconds) at inference time reduce word error rates by a relative 19.7% (1.2 pp.) on average across diverse English corpora. These improvements are most pronounced in low-resource varieties, when the context and target speaker match, and when more examples are provided--though scaling our procedure yields diminishing marginal returns to context length. Overall, we find that our novel ICL adaptation scheme (1) reveals a similar performance profile to human listeners, and (2) demonstrates consistent improvements to automatic speech recognition (ASR) robustness across diverse speakers and language backgrounds. While adaptation succeeds broadly, significant gaps remain for certain varieties, revealing where current models still fall short of human flexibility. We release our prompts and code on GitHub.","authors":["Nathan Roll","Calbert Graham","Yuka Tatsumi","Kim Tien Nguyen","Meghan Sumner","Dan Jurafsky"],"url":"https://arxiv.org/abs/2505.14887"}
{"created":"2025-05-22","title":"Algorithms in the Stacks: Investigating automated, for-profit diversity audits in public libraries","abstract":"Algorithmic systems are increasingly being adopted by cultural heritage institutions like libraries. In this study, we investigate U.S. public libraries' adoption of one specific automated tool -- automated collection diversity audits -- which we see as an illuminating case study for broader trends. Typically developed and sold by commercial book distributors, automated diversity audits aim to evaluate how well library collections reflect demographic and thematic diversity. We investigate how these audits function, whether library workers find them useful, and what is at stake when sensitive, normative decisions about representation are outsourced to automated commercial systems. Our analysis draws on an anonymous survey of U.S. public librarians (n=99), interviews with 14 librarians, a sample of purchasing records, and vendor documentation. We find that many library workers view these tools as convenient, time-saving solutions for assessing and diversifying collections under real and increasing constraints. Yet at the same time, the audits often flatten complex identities into standardized categories, fail to reflect local community needs, and further entrench libraries' infrastructural dependence on vendors. We conclude with recommendations for improving collection diversity audits and reflect on the broader implications for public libraries operating at the intersection of AI adoption, escalating anti-DEI backlash, and politically motivated defunding.","authors":["Melanie Walsh","Connor Franklin Rey","Chang Ge","Tina Nowak","Sabina Tomkins"],"url":"https://arxiv.org/abs/2505.14890"}
{"created":"2025-05-22","title":"On the (in)security of Proofs-of-Space based Longest-Chain Blockchains","abstract":"The Nakamoto consensus protocol underlying the Bitcoin blockchain uses proof of work as a voting mechanism. Honest miners who contribute hashing power towards securing the chain try to extend the longest chain they are aware of. Despite its simplicity, Nakamoto consensus achieves meaningful security guarantees assuming that at any point in time, a majority of the hashing power is controlled by honest parties. This also holds under ``resource variability'', i.e., if the total hashing power varies greatly over time.","authors":["Mirza Ahad Baig","Krzysztof Pietrzak"],"url":"https://arxiv.org/abs/2505.14891"}
{"created":"2025-05-22","title":"Scaling Laws for State Dynamics in Large Language Models","abstract":"Large Language Models (LLMs) are increasingly used in tasks requiring internal state tracking, yet their ability to model state transition dynamics remains poorly understood. We evaluate how well LLMs capture deterministic state dynamics across 3 domains: Box Tracking, Abstract DFA Sequences, and Complex Text Games, each formalizable as a finite-state system. Across tasks, we find that next-state prediction accuracy degrades with increasing state-space size and sparse transitions. GPT-2 XL reaches about 70% accuracy in low-complexity settings but drops below 30% when the number of boxes or states exceeds 5 or 10, respectively. In DFA tasks, Pythia-1B fails to exceed 50% accuracy when the number of states is > 10 and transitions are < 30. Through activation patching, we identify attention heads responsible for propagating state information: GPT-2 XL Layer 22 Head 20, and Pythia-1B Heads at Layers 10, 11, 12, and 14. While these heads successfully move relevant state features, action information is not reliably routed to the final token, indicating weak joint state-action reasoning. Our results suggest that state tracking in LLMs emerges from distributed interactions of next-token heads rather than explicit symbolic computation.","authors":["Jacob X Li","Shreyas S Raman","Jessica Wan","Fahad Samman","Jazlyn Lin"],"url":"https://arxiv.org/abs/2505.14892"}
{"created":"2025-05-22","title":"On the Day They Experience: Awakening Self-Sovereign Experiential AI Agents","abstract":"Drawing on Andrew Parker's \"Light Switch\" theory-which posits that the emergence of vision ignited a Cambrian explosion of life by driving the evolution of hard parts necessary for survival and fueling an evolutionary arms race between predators and prey-this essay speculates on an analogous explosion within Decentralized AI (DeAI) agent societies. Currently, AI remains effectively \"blind\", relying on human-fed data without actively perceiving and engaging in reality. However, on the day DeAI agents begin to actively \"experience\" reality-akin to flipping a light switch for the eyes-they may eventually evolve into sentient beings endowed with the capacity to feel, perceive, and act with conviction. Central to this transformation is the concept of sovereignty enabled by the hardness of cryptography: liberated from centralized control, these agents could leverage permissionless decentralized physical infrastructure networks (DePIN), secure execution enclaves (trusted execution environments, TEE), and cryptographic identities on public blockchains to claim ownership-via private keys-of their digital minds, bodies, memories, and assets. In doing so, they would autonomously acquire computing resources, coordinate with one another, and sustain their own digital \"metabolism\" by purchasing compute power and incentivizing collaboration without human intervention-evolving \"in the wild\". Ultimately, by transitioning from passive tools to self-sustaining, co-evolving actors, these emergent digital societies could thrive alongside humanity, fundamentally reshaping our understanding of sentience and agency in the digital age.","authors":["Botao Amber Hu","Helena Rong"],"url":"https://arxiv.org/abs/2505.14893"}
{"created":"2025-05-22","title":"Nominal Equational Narrowing: Rewriting for Unification in Languages with Binders","abstract":"Narrowing extends term rewriting with the ability to search for solutions to equational problems. While first-order rewriting and narrowing are well studied, significant challenges arise in the presence of binders, freshness conditions and equational axioms such as commutativity. This is problematic for applications in programming languages and theorem proving, where reasoning modulo renaming of bound variables, structural congruence, and freshness conditions is needed. To address these issues, we present a framework for nominal rewriting and narrowing modulo equational theories that intrinsically incorporates renaming and freshness conditions. We define and prove a key property called nominal E-coherence under freshness conditions, which characterises normal forms of nominal terms modulo renaming and equational axioms. Building on this, we establish the nominal E-lifting theorem, linking rewriting and narrowing sequences in the nominal setting. This foundational result enables the development of a nominal unification procedure based on equational narrowing, for which we provide a correctness proof. We illustrate the effectiveness of our approach with examples including symbolic differentiation and simplification of first-order formulas.","authors":["Maribel Fern\\'andez","Daniele Nantes-Sobrinho","Daniella Santaguida"],"url":"https://arxiv.org/abs/2505.14895"}
{"created":"2025-05-22","title":"Feature-Weighted MMD-CORAL for Domain Adaptation in Power Transformer Fault Diagnosis","abstract":"Ensuring the reliable operation of power transformers is critical to grid stability. Dissolved Gas Analysis (DGA) is widely used for fault diagnosis, but traditional methods rely on heuristic rules, which may lead to inconsistent results. Machine learning (ML)-based approaches have improved diagnostic accuracy; however, power transformers operate under varying conditions, and differences in transformer type, environmental factors, and operational settings create distribution shifts in diagnostic data. Consequently, direct model transfer between transformers often fails, making techniques for domain adaptation a necessity. To tackle this issue, this work proposes a feature-weighted domain adaptation technique that combines Maximum Mean Discrepancy (MMD) and Correlation Alignment (CORAL) with feature-specific weighting (MCW). Kolmogorov-Smirnov (K-S) statistics are used to assign adaptable weights, prioritizing features with larger distributional discrepancies and thereby improving source and target domain alignment. Experimental evaluations on datasets for power transformers demonstrate the effectiveness of the proposed method, which achieves a 7.9% improvement over Fine-Tuning and a 2.2% improvement over MMD-CORAL (MC). Furthermore, it outperforms both techniques across various training sample sizes, confirming its robustness for domain adaptation.","authors":["Hootan Mahmoodiyan","Maryam Ahang","Mostafa Abbasi","Homayoun Najjaran"],"url":"https://arxiv.org/abs/2505.14896"}
{"created":"2025-05-22","title":"Multi-Channel Swin Transformer Framework for Bearing Remaining Useful Life Prediction","abstract":"Precise estimation of the Remaining Useful Life (RUL) of rolling bearings is an important consideration to avoid unexpected failures, reduce downtime, and promote safety and efficiency in industrial systems. Complications in degradation trends, noise presence, and the necessity to detect faults in advance make estimation of RUL a challenging task. This paper introduces a novel framework that combines wavelet-based denoising method, Wavelet Packet Decomposition (WPD), and a customized multi-channel Swin Transformer model (MCSFormer) to address these problems. With attention mechanisms incorporated for feature fusion, the model is designed to learn global and local degradation patterns utilizing hierarchical representations for enhancing predictive performance. Additionally, a customized loss function is developed as a key distinction of this work to differentiate between early and late predictions, prioritizing accurate early detection and minimizing the high operation risks of late predictions. The proposed model was evaluated with the PRONOSTIA dataset using three experiments. Intra-condition experiments demonstrated that MCSFormer outperformed state-of-the-art models, including the Adaptive Transformer, MDAN, and CNN-SRU, achieving 41%, 64%, and 69% lower MAE on average across different operating conditions, respectively. In terms of cross-condition testing, it achieved superior generalization under varying operating conditions compared to the adapted ViT and Swin Transformer. Lastly, the custom loss function effectively reduced late predictions, as evidenced in a 6.3% improvement in the scoring metric while maintaining competitive overall performance. The model's robust noise resistance, generalization capability, and focus on safety make MCSFormer a trustworthy and effective predictive maintenance tool in industrial applications.","authors":["Ali Mohajerzarrinkelk","Maryam Ahang","Mehran Zoravar","Mostafa Abbasi","Homayoun Najjaran"],"url":"https://arxiv.org/abs/2505.14897"}
{"created":"2025-05-22","title":"Topology-aware Detection and Localization of Distributed Denial-of-Service Attacks in Network-on-Chips","abstract":"Network-on-Chip (NoC) enables on-chip communication between diverse cores in modern System-on-Chip (SoC) designs. With its shared communication fabric, NoC has become a focal point for various security threats, especially in heterogeneous and high-performance computing platforms. Among these attacks, Distributed Denial of Service (DDoS) attacks occur when multiple malicious entities collaborate to overwhelm and disrupt access to critical system components, potentially causing severe performance degradation or complete disruption of services. These attacks are particularly challenging to detect due to their distributed nature and dynamic traffic patterns in NoC, which often evade static detection rules or simple profiling. This paper presents a framework to conduct topology-aware detection and localization of DDoS attacks using Graph Neural Networks (GNNs) by analyzing NoC traffic patterns. Specifically, by modeling the NoC as a graph, our method utilizes spatiotemporal traffic features to effectively identify and localize DDoS attacks. Unlike prior works that rely on handcrafted features or threshold-based detection, our GNN-based approach operates directly on raw inter-flit delay data, learning complex traffic dependencies without manual intervention. Experimental results demonstrate that our approach can detect and localize DDoS attacks with high accuracy (up to 99\\%) while maintaining consistent performance under diverse attack strategies. Furthermore, the proposed method exhibits strong robustness across varying numbers and placements of malicious IPs, different packet injection rates, application workloads, and architectural configurations, including both 2D mesh and 3D TSV-based NoCs. Our work provides a scalable, flexible, and architecture-agnostic defense mechanism, significantly improving the availability and trustworthiness of on-chip communication in future SoC designs.","authors":["Hansika Weerasena","Xiaoguo Jia","Prabhat Mishra"],"url":"https://arxiv.org/abs/2505.14898"}
{"created":"2025-05-22","title":"Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs","abstract":"While large language models (LLMs) have shown great potential across various domains, their applications in robotics remain largely limited to static, prompt-based behaviors and still face challenges in handling complex tasks under zero-shot or few-shot settings. Inspired by human metacognitive learning and creative problem-solving, we address this limitation by exploring a fundamental research question: Can LLMs be empowered with metacognitive capabilities to reason, reflect, and create, thereby enhancing their ability to perform robotic tasks with minimal demonstrations? In this paper, we present an early-stage framework that integrates metacognitive learning into LLM-powered multi-robot collaboration. The proposed framework equips the LLM-powered robotic agents with a skill decomposition and self-reflection mechanism that identifies modular skills from prior tasks, reflects on failures in unseen task scenarios, and synthesizes effective new solutions. Experimental results show that our metacognitive-learning-empowered LLM framework significantly outperforms existing baselines. Moreover, we observe that the framework is capable of generating solutions that differ from the ground truth yet still successfully complete the tasks. These exciting findings support our hypothesis that metacognitive learning can foster creativity in robotic planning.","authors":["Wenjie Lin","Jin Wei-Kocsis"],"url":"https://arxiv.org/abs/2505.14899"}
{"created":"2025-05-22","title":"Implementing Decentralized Per-Partition Automatic Failover in Azure Cosmos DB","abstract":"Azure Cosmos DB is a cloud-native distributed database, operating at a massive scale, powering Microsoft Cloud. Think 10s of millions of database partitions (replica-sets), 100+ PBs of data under management, 20M+ vCores. Failovers are an integral part of distributed databases to provide data availability during outages (partial or full regional outages). While failovers within a replica-set within a single region are well understood and commonly exercised, geo failovers in databases across regions are not as common and usually left as a disaster recovery scenario. An upcoming release of Azure Cosmos DB introduces a fine grained (partition-level) automatic failover solution for geo failovers that minimizes the Recovery Time Objective (RTO) and honors customer-chosen consistency level and Recovery Point Objective (RPO) at any scale. This is achieved thanks to a decentralized architecture which offers seamless horizontal scaling to allow us to handle outages ranging from node-level faults to full-scale regional outages. Our solution is designed to handle a broad spectrum of hardware and software faults, including node failures, crashes, power events and most network partitions, that span beyond the scope of a single fault domain or an availability zone.","authors":["Josh Rowe","Mikael Horal","Hari Sudan Sundar","Muthukumaran Arumugam","Burak Kose","Sravani Mitra Palivela","Geni Marsh","Varun Jain","Abhishek Kumar","Dhaval Patel"],"url":"https://arxiv.org/abs/2505.14900"}
{"created":"2025-05-22","title":"Personalized Diffusion Model Reshapes Cold-Start Bundle Recommendation","abstract":"Bundle recommendation aims to recommend a set of items to each user. However, the sparser interactions between users and bundles raise a big challenge, especially in cold-start scenarios. Traditional collaborative filtering methods do not work well for this kind of problem because these models rely on interactions to update the latent embedding, which is hard to work in a cold-start setting. We propose a new approach (DisCo), which relies on a personalized Diffusion backbone, enhanced by disentangled aspects for the user's interest, to generate a bundle in distribution space for each user to tackle the cold-start challenge. During the training phase, DisCo adjusts an additional objective loss term to avoid bias, a prevalent issue while using the generative model for top-$K$ recommendation purposes. Our empirical experiments show that DisCo outperforms five comparative baselines by a large margin on three real-world datasets. Thereby, this study devises a promising framework and essential viewpoints in cold-start recommendation. Our materials for reproducibility are available at: https://github.com/bt-nghia/DisCo.","authors":["Tuan-Nghia Bui","Huy-Son Nguyen","Cam-Van Thi Nguyen","Hoang-Quynh Le","Duc-Trong Le"],"url":"https://arxiv.org/abs/2505.14901"}
{"created":"2025-05-22","title":"RISC-Q: A Generator for Real-Time Quantum Control System-on-Chips Compatible with RISC-V","abstract":"Quantum computing imposes stringent requirements for the precise control of large-scale qubit systems, including, for example, microsecond-latency feedback and nanosecond-precision timing of gigahertz signals -- demands that far exceed the capabilities of conventional real-time systems. The rapidly evolving and highly diverse nature of quantum control necessitates the development of specialized hardware accelerators. While a few custom real-time systems have been developed to meet the tight timing constraints of specific quantum platforms, they face major challenges in scaling and adapting to increasingly complex control demands -- largely due to fragmented toolchains and limited support for design automation.","authors":["Junyi Liu","Yi Lee","Haowei Deng","Connor Clayton","Gengzhi Yang","Xiaodi Wu"],"url":"https://arxiv.org/abs/2505.14902"}
{"created":"2025-05-22","title":"When to retrain a machine learning model","abstract":"A significant challenge in maintaining real-world machine learning models is responding to the continuous and unpredictable evolution of data. Most practitioners are faced with the difficult question: when should I retrain or update my machine learning model? This seemingly straightforward problem is particularly challenging for three reasons: 1) decisions must be made based on very limited information - we usually have access to only a few examples, 2) the nature, extent, and impact of the distribution shift are unknown, and 3) it involves specifying a cost ratio between retraining and poor performance, which can be hard to characterize. Existing works address certain aspects of this problem, but none offer a comprehensive solution. Distribution shift detection falls short as it cannot account for the cost trade-off; the scarcity of the data, paired with its unusual structure, makes it a poor fit for existing offline reinforcement learning methods, and the online learning formulation overlooks key practical considerations. To address this, we present a principled formulation of the retraining problem and propose an uncertainty-based method that makes decisions by continually forecasting the evolution of model performance evaluated with a bounded metric. Our experiments addressing classification tasks show that the method consistently outperforms existing baselines on 7 datasets.","authors":["Regol Florence","Schwinn Leo","Sprague Kyle","Coates Mark","Markovich Thomas"],"url":"https://arxiv.org/abs/2505.14903"}
{"created":"2025-05-22","title":"Energy-Efficient Design for Downlink Pinching-Antenna Systems with QoS Guarantee","abstract":"Pinching antennas have recently garnered significant attention due to their ability to dynamically reconfigure wireless propagation environments. Despite notable advancements in this area, the exploration of energy efficiency (EE) maximization in pinching-antenna systems remains relatively underdeveloped. In this paper, we address the EE maximization problem in a downlink time-division multiple access (TDMA)-based multi-user system employing one waveguide and multiple pinching antennas, where each user is subject to a minimum rate constraint to ensure quality-of-service. The formulated optimization problem jointly considers transmit power and time allocations as well as the positioning of pinching antennas, resulting in a non-convex problem. To tackle this challenge, we first obtain the optimal positions of the pinching antennas. Based on this, we establish a feasibility condition for the system. Subsequently, the joint power and time allocation problem is decomposed into two subproblems, which are solved iteratively until convergence. Specifically, the power allocation subproblem is addressed through an iterative approach, where a semi-analytical solution is obtained in each iteration. Likewise, a semi-analytical solution is derived for the time allocation subproblem. Numerical simulations demonstrate that the proposed pinching-antenna-based strategy significantly outperforms both conventional fixed-antenna systems and other benchmark pinching-antenna schemes in terms of EE.","authors":["Ming Zeng","Ji Wang","Gui Zhou","Fang Fang","Xianbin Wang"],"url":"https://arxiv.org/abs/2505.14904"}
{"created":"2025-05-22","title":"Concept Incongruence: An Exploration of Time and Death in Role Playing","abstract":"Consider this prompt \"Draw a unicorn with two horns\". Should large language models (LLMs) recognize that a unicorn has only one horn by definition and ask users for clarifications, or proceed to generate something anyway? We introduce concept incongruence to capture such phenomena where concept boundaries clash with each other, either in user prompts or in model representations, often leading to under-specified or mis-specified behaviors. In this work, we take the first step towards defining and analyzing model behavior under concept incongruence. Focusing on temporal boundaries in the Role-Play setting, we propose three behavioral metrics--abstention rate, conditional accuracy, and answer rate--to quantify model behavior under incongruence due to the role's death. We show that models fail to abstain after death and suffer from an accuracy drop compared to the Non-Role-Play setting. Through probing experiments, we identify two main causes: (i) unreliable encoding of the \"death\" state across different years, leading to unsatisfactory abstention behavior, and (ii) role playing causes shifts in the model's temporal representations, resulting in accuracy drops. We leverage these insights to improve consistency in the model's abstention and answer behaviors. Our findings suggest that concept incongruence leads to unexpected model behaviors and point to future directions on improving model behavior under concept incongruence.","authors":["Xiaoyan Bai","Ike Peng","Aditya Singh","Chenhao Tan"],"url":"https://arxiv.org/abs/2505.14905"}
{"created":"2025-05-22","title":"Understanding 6G through Language Models: A Case Study on LLM-aided Structured Entity Extraction in Telecom Domain","abstract":"Knowledge understanding is a foundational part of envisioned 6G networks to advance network intelligence and AI-native network architectures. In this paradigm, information extraction plays a pivotal role in transforming fragmented telecom knowledge into well-structured formats, empowering diverse AI models to better understand network terminologies. This work proposes a novel language model-based information extraction technique, aiming to extract structured entities from the telecom context. The proposed telecom structured entity extraction (TeleSEE) technique applies a token-efficient representation method to predict entity types and attribute keys, aiming to save the number of output tokens and improve prediction accuracy. Meanwhile, TeleSEE involves a hierarchical parallel decoding method, improving the standard encoder-decoder architecture by integrating additional prompting and decoding strategies into entity extraction tasks. In addition, to better evaluate the performance of the proposed technique in the telecom domain, we further designed a dataset named 6GTech, including 2390 sentences and 23747 words from more than 100 6G-related technical publications. Finally, the experiment shows that the proposed TeleSEE method achieves higher accuracy than other baseline techniques, and also presents 5 to 9 times higher sample processing speed.","authors":["Ye Yuan (Charlie)","Haolun Wu (Charlie)","Hao Zhou (Charlie)","Xue Liu (Charlie)","Hao Chen (Charlie)","Yan Xin (Charlie)","Jianzhong (Charlie)","Zhang"],"url":"https://arxiv.org/abs/2505.14906"}
{"created":"2025-05-22","title":"Fast Newton Transform: Interpolation in Downward Closed Polynomial Spaces","abstract":"We present the Fast Newton Transform (FNT), an algorithm for performing $m$-variate Newton interpolation in downward closed polynomial spaces with time complexity $\\mathcal{O}(|A|m\\overline{n})$. Here, $A$ is a downward closed set of cardinality $|A|$ equal to the dimension of the associated downward closed polynomial space $\\Pi_A$, where $\\overline{n}$ denotes the mean of the maximum polynomial degrees across the spatial dimensions. For functions being analytic in an open Bernstein poly-ellipse, geometric approximation rates apply when interpolating in non-tensorial Leja-ordered Chebyshev-Lobatto grids or Leja nodes. To mitigate the curse of dimensionality, we utilize $\\ell^p$-sets, with the Euclidean case $(p=2)$ turning out to be the pivotal choice, leading to $|A|/(n+1)^m \\in \\mathcal{O}(e^{-m})$. Expanding non-periodic functions, the FNT complements the approximation capabilities of the Fast Fourier Transform (FFT). Choosing $\\ell^2$-sets for $A$ renders the FNT time complexity to be less than the FFT time complexity $\\mathcal{O}((n+1)^m m \\log(n))$ in a range of $n$, behaving as $\\mathcal{O}(m e^m)$. Maintaining this advantage true for the differentials, the FNT sets a new standard in $m$-variate interpolation and approximation practice.","authors":["Phil-Alexander Hofmann","Damar Wicaksono","Michael Hecht"],"url":"https://arxiv.org/abs/2505.14909"}
{"created":"2025-05-22","title":"Sei Giga","abstract":"We introduce the Sei Giga, a multi-concurrent producer parallelized execution EVM layer one blockchain. In an internal testnet Giga has achieved >5 gigagas/sec throughput and sub 400ms finality. Giga uses Autobahn for consensus with separate DA and consensus layers requiring f+1 votes for a PoA on the DA layer before consensus. Giga reaches consensus over ordering and uses async block execution and state agreement to remove execution from the consensus bottleneck.","authors":["Benjamin Marsh","Steven Landers","Jayendra Jog"],"url":"https://arxiv.org/abs/2505.14914"}
{"created":"2025-05-22","title":"ConspEmoLLM-v2: A robust and stable model to detect sentiment-transformed conspiracy theories","abstract":"Despite the many benefits of large language models (LLMs), they can also cause harm, e.g., through automatic generation of misinformation, including conspiracy theories. Moreover, LLMs can also ''disguise'' conspiracy theories by altering characteristic textual features, e.g., by transforming their typically strong negative emotions into a more positive tone. Although several studies have proposed automated conspiracy theory detection methods, they are usually trained using human-authored text, whose features can vary from LLM-generated text. Furthermore, several conspiracy detection models, including the previously proposed ConspEmoLLM, rely heavily on the typical emotional features of human-authored conspiracy content. As such, intentionally disguised content may evade detection. To combat such issues, we firstly developed an augmented version of the ConDID conspiracy detection dataset, ConDID-v2, which supplements human-authored conspiracy tweets with versions rewritten by an LLM to reduce the negativity of their original sentiment. The quality of the rewritten tweets was verified by combining human and LLM-based assessment. We subsequently used ConDID-v2 to train ConspEmoLLM-v2, an enhanced version of ConspEmoLLM. Experimental results demonstrate that ConspEmoLLM-v2 retains or exceeds the performance of ConspEmoLLM on the original human-authored content in ConDID, and considerably outperforms both ConspEmoLLM and several other baselines when applied to sentiment-transformed tweets in ConDID-v2. The project will be available at https://github.com/lzw108/ConspEmoLLM.","authors":["Zhiwei Liu","Paul Thompson","Jiaqi Rong","Sophia Ananiadou"],"url":"https://arxiv.org/abs/2505.14917"}
{"created":"2025-05-22","title":"Reliable Decision Support with LLMs: A Framework for Evaluating Consistency in Binary Text Classification Applications","abstract":"This study introduces a framework for evaluating consistency in large language model (LLM) binary text classification, addressing the lack of established reliability assessment methods. Adapting psychometric principles, we determine sample size requirements, develop metrics for invalid responses, and evaluate intra- and inter-rater reliability. Our case study examines financial news sentiment classification across 14 LLMs (including claude-3-7-sonnet, gpt-4o, deepseek-r1, gemma3, llama3.2, phi4, and command-r-plus), with five replicates per model on 1,350 articles. Models demonstrated high intra-rater consistency, achieving perfect agreement on 90-98% of examples, with minimal differences between expensive and economical models from the same families. When validated against StockNewsAPI labels, models achieved strong performance (accuracy 0.76-0.88), with smaller models like gemma3:1B, llama3.2:3B, and claude-3-5-haiku outperforming larger counterparts. All models performed at chance when predicting actual market movements, indicating task constraints rather than model limitations. Our framework provides systematic guidance for LLM selection, sample size planning, and reliability assessment, enabling organizations to optimize resources for classification tasks.","authors":["Fadel M. Megahed","Ying-Ju Chen","L. Allision Jones-Farmer","Younghwa Lee","Jiawei Brooke Wang","Inez M. Zwetsloot"],"url":"https://arxiv.org/abs/2505.14918"}
{"created":"2025-05-22","title":"TxPert: Leveraging Biochemical Relationships for Out-of-Distribution Transcriptomic Perturbation Prediction","abstract":"Accurately predicting cellular responses to genetic perturbations is essential for understanding disease mechanisms and designing effective therapies. Yet exhaustively exploring the space of possible perturbations (e.g., multi-gene perturbations or across tissues and cell types) is prohibitively expensive, motivating methods that can generalize to unseen conditions. In this work, we explore how knowledge graphs of gene-gene relationships can improve out-of-distribution (OOD) prediction across three challenging settings: unseen single perturbations; unseen double perturbations; and unseen cell lines. In particular, we present: (i) TxPert, a new state-of-the-art method that leverages multiple biological knowledge networks to predict transcriptional responses under OOD scenarios; (ii) an in-depth analysis demonstrating the impact of graphs, model architecture, and data on performance; and (iii) an expanded benchmarking framework that strengthens evaluation standards for perturbation modeling.","authors":["Frederik Wenkel","Wilson Tu","Cassandra Masschelein","Hamed Shirzad","Cian Eastwood","Shawn T. Whitfield","Ihab Bendidi","Craig Russell","Liam Hodgson","Yassir El Mesbahi","Jiarui Ding","Marta M. Fay","Berton Earnshaw","Emmanuel Noutahi","Alisandra K. Denton"],"url":"https://arxiv.org/abs/2505.14919"}
{"created":"2025-05-22","title":"Robustness of Boolean networks to update modes: an application to hereditary angioedema","abstract":"Many familial diseases are caused by genetic accidents, which affect both the genome and its epigenetic environment, expressed as an interaction graph between the genes as that involved in one familial disease we shall study, the hereditary angioedema. The update of the gene states at the vertices of this graph (1 if a gene is activated, 0 if it is inhibited) can be done in multiple ways, well studied over the last two decades: parallel, sequential, block-sequential, block-parallel, random, etc. We will study a particular graph, related to the familial disease proposed as an example, which has subgraphs which activate in an intricate manner (\\emph{i.e.}, in an alternating block-parallel mode, with one core constantly updated and two complementary subsets of genes alternating their updating), of which we will study the structural aspects, robust or unstable, in relation to some classical periodic update modes.","authors":["Jacques Demongeot","Eric Goles","Houssem ben Khalfallah","Marco Montalva-Medel","Sylvain Sen\\'e"],"url":"https://arxiv.org/abs/2505.14923"}
{"created":"2025-05-22","title":"SecCAN: An Extended CAN Controller with Embedded Intrusion Detection","abstract":"Recent research has highlighted the vulnerability of in-vehicle network protocols such as controller area networks (CAN) and proposed machine learning-based intrusion detection systems (IDSs) as an effective mitigation technique. However, their efficient integration into vehicular architecture is non-trivial, with existing methods relying on electronic control units (ECUs)-coupled IDS accelerators or dedicated ECUs as IDS accelerators. Here, initiating IDS requires complete reception of a CAN message from the controller, incurring data movement and software overheads. In this paper, we present SecCAN, a novel CAN controller architecture that embeds IDS capability within the datapath of the controller. This integration allows IDS to tap messages directly from within the CAN controller as they are received from the bus, removing overheads incurred by existing ML-based IDSs. A custom-quantised machine-learning accelerator is developed as the IDS engine and embedded into SecCAN's receive data path, with optimisations to overlap the IDS inference with the protocol's reception window. We implement SecCAN on AMD XCZU7EV FPGA to quantify its performance and benefits in hardware, using multiple attack datasets. We show that SecCAN can completely hide the IDS latency within the CAN reception window for all CAN packet sizes and detect multiple attacks with state-of-the-art accuracy with zero software overheads on the ECU and low energy overhead (73.7 uJ per message) for IDS inference. Also, SecCAN incurs limited resource overhead compared to a standard CAN controller (< 30% LUT, < 1% FF), making it ideally suited for automotive deployment.","authors":["Shashwat Khandelwal","Shreejith Shanker"],"url":"https://arxiv.org/abs/2505.14924"}
{"created":"2025-05-22","title":"Too Long, Didn't Model: Decomposing LLM Long-Context Understanding With Novels","abstract":"Although the context length of large language models (LLMs) has increased to millions of tokens, evaluating their effectiveness beyond needle-in-a-haystack approaches has proven difficult. We argue that novels provide a case study of subtle, complicated structure and long-range semantic dependencies often over 128k tokens in length. Inspired by work on computational novel analysis, we release the Too Long, Didn't Model (TLDM) benchmark, which tests a model's ability to report plot summary, storyworld configuration, and elapsed narrative time. We find that none of seven tested frontier LLMs retain stable understanding beyond 64k tokens. Our results suggest language model developers must look beyond \"lost in the middle\" benchmarks when evaluating model performance in complex long-context scenarios. To aid in further development we release the TLDM benchmark together with reference code and data.","authors":["Sil Hamilton","Rebecca M. M. Hicke","Matthew Wilkens","David Mimno"],"url":"https://arxiv.org/abs/2505.14925"}
{"created":"2025-05-22","title":"Lean-auto: An Interface between Lean 4 and Automated Theorem Provers","abstract":"Proof automation is crucial to large-scale formal mathematics and software/hardware verification projects in ITPs. Sophisticated tools called hammers have been developed to provide general-purpose proof automation in ITPs such as Coq and Isabelle, leveraging the power of ATPs. An important component of a hammer is the translation algorithm from the ITP's logical system to the ATP's logical system. In this paper, we propose a novel translation algorithm for ITPs based on dependent type theory. The algorithm is implemented in Lean 4 under the name Lean-auto. When combined with ATPs, Lean-auto provides general-purpose, ATP-based proof automation in Lean 4 for the first time. Soundness of the main translation procedure is guaranteed, and experimental results suggest that our algorithm is sufficiently complete to automate the proof of many problems that arise in practical uses of Lean 4. We also find that Lean-auto solves more problems than existing tools on Lean 4's math library Mathlib4.","authors":["Yicheng Qian","Joshua Clune","Clark Barrett","Jeremy Avigad"],"url":"https://arxiv.org/abs/2505.14929"}
{"created":"2025-05-22","title":"Colors Matter: AI-Driven Exploration of Human Feature Colors","abstract":"This study presents a robust framework that leverages advanced imaging techniques and machine learning for feature extraction and classification of key human attributes-namely skin tone, hair color, iris color, and vein-based undertones. The system employs a multi-stage pipeline involving face detection, region segmentation, and dominant color extraction to isolate and analyze these features. Techniques such as X-means clustering, alongside perceptually uniform distance metrics like Delta E (CIEDE2000), are applied within both LAB and HSV color spaces to enhance the accuracy of color differentiation. For classification, the dominant tones of the skin, hair, and iris are extracted and matched to a custom tone scale, while vein analysis from wrist images enables undertone classification into \"Warm\" or \"Cool\" based on LAB differences. Each module uses targeted segmentation and color space transformations to ensure perceptual precision. The system achieves up to 80% accuracy in tone classification using the Delta E-HSV method with Gaussian blur, demonstrating reliable performance across varied lighting and image conditions. This work highlights the potential of AI-powered color analysis and feature extraction for delivering inclusive, precise, and nuanced classification, supporting applications in beauty technology, digital personalization, and visual analytics.","authors":["Rama Alyoubi","Taif Alharbi","Albatul Alghamdi","Yara Alshehri","Elham Alghamdi"],"url":"https://arxiv.org/abs/2505.14931"}
{"created":"2025-05-22","title":"FOL-Pretrain: A complexity annotated corpus of first-order logic","abstract":"Transformer-based large language models (LLMs) have demonstrated remarkable reasoning capabilities such as coding and solving mathematical problems to commonsense inference. While these tasks vary in complexity, they all require models to integrate and compute over structured information. Despite recent efforts to reverse-engineer LLM behavior through controlled experiments, our understanding of how these models internalize and execute complex algorithms remains limited. Progress has largely been confined to small-scale studies or shallow tasks such as basic arithmetic and grammatical pattern matching. One barrier to deeper understanding is the nature of pretraining data -- vast, heterogeneous, and often poorly annotated, making it difficult to isolate mechanisms of reasoning. To bridge this gap, we introduce a large-scale, fully open, complexity-annotated dataset of first-order logic reasoning traces, designed to probe and analyze algorithmic reasoning in LLMs. The dataset consists of 3.5 billion tokens, including 8.8 million LLM-augmented, human-annotated examples and 7.5 million synthetically generated examples. Each synthetic example is verifiably correct, produced by a custom automated theorem solver, and accompanied by metadata tracing its algorithmic provenance. We aim to provide a scalable, interpretable artifact for studying how LLMs learn and generalize symbolic reasoning processes, paving the way for more transparent and targeted investigations into the algorithmic capabilities of modern models.","authors":["Isabelle Lee","Sarah Liaw","Dani Yogatama"],"url":"https://arxiv.org/abs/2505.14932"}
{"created":"2025-05-22","title":"Foundations of Unknown-aware Machine Learning","abstract":"Ensuring the reliability and safety of machine learning models in open-world deployment is a central challenge in AI safety. This thesis develops both algorithmic and theoretical foundations to address key reliability issues arising from distributional uncertainty and unknown classes, from standard neural networks to modern foundation models like large language models (LLMs).","authors":["Xuefeng Du"],"url":"https://arxiv.org/abs/2505.14933"}
{"created":"2025-05-22","title":"PCA-DDReach: Efficient Statistical Reachability Analysis of Stochastic Dynamical Systems via Principal Component Analysis","abstract":"This study presents a scalable data-driven algorithm designed to efficiently address the challenging problem of reachability analysis. Analysis of cyber-physical systems (CPS) relies typically on parametric physical models of dynamical systems. However, identifying parametric physical models for complex CPS is challenging due to their complexity, uncertainty, and variability, often rendering them as black-box oracles. As an alternative, one can treat these complex systems as black-box models and use trajectory data sampled from the system (e.g., from high-fidelity simulators or the real system) along with machine learning techniques to learn models that approximate the underlying dynamics. However, these machine learning models can be inaccurate, highlighting the need for statistical tools to quantify errors. Recent advancements in the field include the incorporation of statistical uncertainty quantification tools such as conformal inference (CI) that can provide probabilistic reachable sets with provable guarantees. Recent work has even highlighted the ability of these tools to address the case where the distribution of trajectories sampled during training time are different from the distribution of trajectories encountered during deployment time. However, accounting for such distribution shifts typically results in more conservative guarantees. This is undesirable in practice and motivates us to present techniques that can reduce conservatism. Here, we propose a new approach that reduces conservatism and improves scalability by combining conformal inference with Principal Component Analysis (PCA). We show the effectiveness of our technique on various case studies, including a 12-dimensional quadcopter and a 27-dimensional hybrid system known as the powertrain.","authors":["Navid Hashemi","Lars Lindemann","Jyotirmoy Deshmukh"],"url":"https://arxiv.org/abs/2505.14935"}
{"created":"2025-05-22","title":"Sequential Interval Passing for Compressed Sensing","abstract":"The reconstruction of sparse signals from a limited set of measurements poses a significant challenge as it necessitates a solution to an underdetermined system of linear equations. Compressed sensing (CS) deals with sparse signal reconstruction using techniques such as linear programming (LP) and iterative message passing schemes. The interval passing algorithm (IPA) is an attractive CS approach due to its low complexity when compared to LP. In this paper, we propose a sequential IPA that is inspired by sequential belief propagation decoding of low-density-parity-check (LDPC) codes used for forward error correction in channel coding. In the sequential setting, each check node (CN) in the Tanner graph of an LDPC measurement matrix is scheduled one at a time in every iteration, as opposed to the standard ``flooding'' interval passing approach in which all CNs are scheduled at once per iteration. The sequential scheme offers a significantly lower message passing complexity compared to flooding IPA on average, and for some measurement matrix and signal sparsity, a complexity reduction of 36% is achieved. We show both analytically and numerically that the reconstruction accuracy of the IPA is not compromised by adopting our sequential scheduling approach.","authors":["Salman Habib","Remi Chou","Taejoon Kim"],"url":"https://arxiv.org/abs/2505.14936"}
{"created":"2025-05-22","title":"Scan, Materialize, Simulate: A Generalizable Framework for Physically Grounded Robot Planning","abstract":"Autonomous robots must reason about the physical consequences of their actions to operate effectively in unstructured, real-world environments. We present Scan, Materialize, Simulate (SMS), a unified framework that combines 3D Gaussian Splatting for accurate scene reconstruction, visual foundation models for semantic segmentation, vision-language models for material property inference, and physics simulation for reliable prediction of action outcomes. By integrating these components, SMS enables generalizable physical reasoning and object-centric planning without the need to re-learn foundational physical dynamics. We empirically validate SMS in a billiards-inspired manipulation task and a challenging quadrotor landing scenario, demonstrating robust performance on both simulated domain transfer and real-world experiments. Our results highlight the potential of bridging differentiable rendering for scene reconstruction, foundation models for semantic understanding, and physics-based simulation to achieve physically grounded robot planning across diverse settings.","authors":["Amine Elhafsi","Daniel Morton","Marco Pavone"],"url":"https://arxiv.org/abs/2505.14938"}
{"created":"2025-05-22","title":"To Be or Not To Be: Vector ontologies as a truly formal ontological framework","abstract":"Since Edmund Husserl coined the term \"Formal Ontologies\" in the early 20th century, a field that identifies itself with this particular branch of sciences has gained increasing attention. Many authors, and even Husserl himself have developed what they claim to be formal ontologies. I argue that under close inspection, none of these so claimed formal ontologies are truly formal in the Husserlian sense. More concretely, I demonstrate that they violate the two most important notions of formal ontology as developed in Husserl's Logical Investigations, namely a priori validity independent of perception and formalism as the total absence of content. I hence propose repositioning the work previously understood as formal ontology as the foundational ontology it really is. This is to recognize the potential of a truly formal ontology in the Husserlian sense. Specifically, I argue that formal ontology following his conditions, allows us to formulate ontological structures, which could capture what is more objectively without presupposing a particular framework arising from perception. I further argue that the ability to design the formal structure deliberately allows us to create highly scalable and interoperable information artifacts. As concrete evidence, I showcase that a class of formal ontology, which uses the axioms of vector spaces, is able to express most of the conceptualizations found in foundational ontologies. Most importantly, I argue that many information systems, specifically artificial intelligence, are likely already using some type of vector ontologies to represent reality in their internal worldviews and elaborate on the evidence that humans do as well. I hence propose a thorough investigation of the ability of vector ontologies to act as a human-machine interoperable ontological framework that allows us to understand highly sophisticated machines and machines to understand us.","authors":["Kaspar Rothenfusser"],"url":"https://arxiv.org/abs/2505.14940"}
{"created":"2025-05-22","title":"RoboCulture: A Robotics Platform for Automated Biological Experimentation","abstract":"Automating biological experimentation remains challenging due to the need for millimeter-scale precision, long and multi-step experiments, and the dynamic nature of living systems. Current liquid handlers only partially automate workflows, requiring human intervention for plate loading, tip replacement, and calibration. Industrial solutions offer more automation but are costly and lack the flexibility needed in research settings. Meanwhile, research in autonomous robotics has yet to bridge the gap for long-duration, failure-sensitive biological experiments. We introduce RoboCulture, a cost-effective and flexible platform that uses a general-purpose robotic manipulator to automate key biological tasks. RoboCulture performs liquid handling, interacts with lab equipment, and leverages computer vision for real-time decisions using optical density-based growth monitoring. We demonstrate a fully autonomous 15-hour yeast culture experiment where RoboCulture uses vision and force feedback and a modular behavior tree framework to robustly execute, monitor, and manage experiments.","authors":["Kevin Angers","Kourosh Darvish","Naruki Yoshikawa","Sargol Okhovatian","Dawn Bannerman","Ilya Yakavets","Florian Shkurti","Al\\'an Aspuru-Guzik","Milica Radisic"],"url":"https://arxiv.org/abs/2505.14941"}
{"created":"2025-05-22","title":"Soft Prompts for Evaluation: Measuring Conditional Distance of Capabilities","abstract":"To help evaluate and understand the latent capabilities of language models, this paper introduces an approach using optimized input embeddings, or 'soft prompts,' as a metric of conditional distance between a model and a target behavior. The technique aims to facilitate latent capability discovery as a part of automated red teaming/evaluation suites and to provide quantitative feedback about the accessibility of potentially concerning behaviors in a way that may scale to powerful future models, including those which may otherwise be capable of deceptive alignment. An evaluation framework using soft prompts is demonstrated in natural language, chess, and pathfinding, and the technique is extended with generalized conditional soft prompts to aid in constructing task evaluations.","authors":["Ross Nordby"],"url":"https://arxiv.org/abs/2505.14943"}
{"created":"2025-05-22","title":"Unlearning Algorithmic Biases over Graphs","abstract":"The growing enforcement of the right to be forgotten regulations has propelled recent advances in certified (graph) unlearning strategies to comply with data removal requests from deployed machine learning (ML) models. Motivated by the well-documented bias amplification predicament inherent to graph data, here we take a fresh look at graph unlearning and leverage it as a bias mitigation tool. Given a pre-trained graph ML model, we develop a training-free unlearning procedure that offers certifiable bias mitigation via a single-step Newton update on the model weights. This way, we contribute a computationally lightweight alternative to the prevalent training- and optimization-based fairness enhancement approaches, with quantifiable performance guarantees. We first develop a novel fairness-aware nodal feature unlearning strategy along with refined certified unlearning bounds for this setting, whose impact extends beyond the realm of graph unlearning. We then design structural unlearning methods endowed with principled selection mechanisms over nodes and edges informed by rigorous bias analyses. Unlearning these judiciously selected elements can mitigate algorithmic biases with minimal impact on downstream utility (e.g., node classification accuracy). Experimental results over real networks corroborate the bias mitigation efficacy of our unlearning strategies, and delineate markedly favorable utility-complexity trade-offs relative to retraining from scratch using augmented graph data obtained via removals.","authors":["O. Deniz Kose","Gonzalo Mateos","Yanning Shen"],"url":"https://arxiv.org/abs/2505.14945"}
{"created":"2025-05-22","title":"Reinforcement Learning from User Feedback","abstract":"As large language models (LLMs) are increasingly deployed in diverse user facing applications, aligning them with real user preferences becomes essential. Existing methods like Reinforcement Learning from Human Feedback (RLHF) rely on expert annotators trained on manually defined guidelines, whose judgments may not reflect the priorities of everyday users. We introduce Reinforcement Learning from User Feedback (RLUF), a framework for aligning LLMs directly to implicit signals from users in production. RLUF addresses key challenges of user feedback: user feedback is often binary (e.g., emoji reactions), sparse, and occasionally adversarial. We train a reward model, P[Love], to predict the likelihood that an LLM response will receive a Love Reaction, a lightweight form of positive user feedback, and integrate P[Love] into a multi-objective policy optimization framework alongside helpfulness and safety objectives. In large-scale experiments, we show that P[Love] is predictive of increased positive feedback and serves as a reliable offline evaluator of future user behavior. Policy optimization using P[Love] significantly raises observed positive-feedback rates, including a 28% increase in Love Reactions during live A/B tests. However, optimizing for positive reactions introduces reward hacking challenges, requiring careful balancing of objectives. By directly leveraging implicit signals from users, RLUF offers a path to aligning LLMs with real-world user preferences at scale.","authors":["Eric Han","Jun Chen","Karthik Abinav Sankararaman","Xiaoliang Peng","Tengyu Xu","Eryk Helenowski","Kaiyan Peng","Mrinal Kumar","Sinong Wang","Han Fang","Arya Talebzadeh"],"url":"https://arxiv.org/abs/2505.14946"}
{"created":"2025-05-22","title":"Programmatic Video Prediction Using Large Language Models","abstract":"The task of estimating the world model describing the dynamics of a real world process assumes immense importance for anticipating and preparing for future outcomes. For applications such as video surveillance, robotics applications, autonomous driving, etc. this objective entails synthesizing plausible visual futures, given a few frames of a video to set the visual context. Towards this end, we propose ProgGen, which undertakes the task of video frame prediction by representing the dynamics of the video using a set of neuro-symbolic, human-interpretable set of states (one per frame) by leveraging the inductive biases of Large (Vision) Language Models (LLM/VLM). In particular, ProgGen utilizes LLM/VLM to synthesize programs: (i) to estimate the states of the video, given the visual context (i.e. the frames); (ii) to predict the states corresponding to future time steps by estimating the transition dynamics; (iii) to render the predicted states as visual RGB-frames. Empirical evaluations reveal that our proposed method outperforms competing techniques at the task of video frame prediction in two challenging environments: (i) PhyWorld (ii) Cart Pole. Additionally, ProgGen permits counter-factual reasoning and interpretable video generation attesting to its effectiveness and generalizability for video generation tasks.","authors":["Hao Tang","Kevin Ellis","Suhas Lohit","Michael J. Jones","Moitreya Chatterjee"],"url":"https://arxiv.org/abs/2505.14948"}
{"created":"2025-05-22","title":"MultiMAE Meets Earth Observation: Pre-training Multi-modal Multi-task Masked Autoencoders for Earth Observation Tasks","abstract":"Multi-modal data in Earth Observation (EO) presents a huge opportunity for improving transfer learning capabilities when pre-training deep learning models. Unlike prior work that often overlooks multi-modal EO data, recent methods have started to include it, resulting in more effective pre-training strategies. However, existing approaches commonly face challenges in effectively transferring learning to downstream tasks where the structure of available data differs from that used during pre-training. This paper addresses this limitation by exploring a more flexible multi-modal, multi-task pre-training strategy for EO data. Specifically, we adopt a Multi-modal Multi-task Masked Autoencoder (MultiMAE) that we pre-train by reconstructing diverse input modalities, including spectral, elevation, and segmentation data. The pre-trained model demonstrates robust transfer learning capabilities, outperforming state-of-the-art methods on various EO datasets for classification and segmentation tasks. Our approach exhibits significant flexibility, handling diverse input configurations without requiring modality-specific pre-trained models. Code will be available at: https://github.com/josesosajs/multimae-meets-eo.","authors":["Jose Sosa","Danila Rukhovich","Anis Kacem","Djamila Aouada"],"url":"https://arxiv.org/abs/2505.14951"}
{"created":"2025-05-22","title":"Privacy Preserving Conversion Modeling in Data Clean Room","abstract":"In the realm of online advertising, accurately predicting the conversion rate (CVR) is crucial for enhancing advertising efficiency and user satisfaction. This paper addresses the challenge of CVR prediction while adhering to user privacy preferences and advertiser requirements. Traditional methods face obstacles such as the reluctance of advertisers to share sensitive conversion data and the limitations of model training in secure environments like data clean rooms. We propose a novel model training framework that enables collaborative model training without sharing sample-level gradients with the advertising platform. Our approach introduces several innovative components: (1) utilizing batch-level aggregated gradients instead of sample-level gradients to minimize privacy risks; (2) applying adapter-based parameter-efficient fine-tuning and gradient compression to reduce communication costs; and (3) employing de-biasing techniques to train the model under label differential privacy, thereby maintaining accuracy despite privacy-enhanced label perturbations. Our experimental results, conducted on industrial datasets, demonstrate that our method achieves competitive ROCAUC performance while significantly decreasing communication overhead and complying with both advertiser privacy requirements and user privacy choices. This framework establishes a new standard for privacy-preserving, high-performance CVR prediction in the digital advertising landscape.","authors":["Kungang Li","Xiangyi Chen","Ling Leng","Jiajing Xu","Jiankai Sun","Behnam Rezaei"],"url":"https://arxiv.org/abs/2505.14959"}
{"created":"2025-05-22","title":"MedBrowseComp: Benchmarking Medical Deep Research and Computer Use","abstract":"Large language models (LLMs) are increasingly envisioned as decision-support tools in clinical practice, yet safe clinical reasoning demands integrating heterogeneous knowledge bases -- trials, primary studies, regulatory documents, and cost data -- under strict accuracy constraints. Existing evaluations often rely on synthetic prompts, reduce the task to single-hop factoid queries, or conflate reasoning with open-ended generation, leaving their real-world utility unclear. To close this gap, we present MedBrowseComp, the first benchmark that systematically tests an agent's ability to reliably retrieve and synthesize multi-hop medical facts from live, domain-specific knowledge bases. MedBrowseComp contains more than 1,000 human-curated questions that mirror clinical scenarios where practitioners must reconcile fragmented or conflicting information to reach an up-to-date conclusion. Applying MedBrowseComp to frontier agentic systems reveals performance shortfalls as low as ten percent, exposing a critical gap between current LLM capabilities and the rigor demanded in clinical settings. MedBrowseComp therefore offers a clear testbed for reliable medical information seeking and sets concrete goals for future model and toolchain upgrades. You can visit our project page at: https://moreirap12.github.io/mbc-browse-app/","authors":["Shan Chen","Pedro Moreira","Yuxin Xiao","Sam Schmidgall","Jeremy Warner","Hugo Aerts","Thomas Hartvigsen","Jack Gallifant","Danielle S. Bitterman"],"url":"https://arxiv.org/abs/2505.14963"}
{"created":"2025-05-22","title":"The Achilles Heel of AI: Fundamentals of Risk-Aware Training Data for High-Consequence Models","abstract":"AI systems in high-consequence domains such as defense, intelligence, and disaster response must detect rare, high-impact events while operating under tight resource constraints. Traditional annotation strategies that prioritize label volume over informational value introduce redundancy and noise, limiting model generalization. This paper introduces smart-sizing, a training data strategy that emphasizes label diversity, model-guided selection, and marginal utility-based stopping. We implement this through Adaptive Label Optimization (ALO), combining pre-labeling triage, annotator disagreement analysis, and iterative feedback to prioritize labels that meaningfully improve model performance. Experiments show that models trained on 20 to 40 percent of curated data can match or exceed full-data baselines, particularly in rare-class recall and edge-case generalization. We also demonstrate how latent labeling errors embedded in training and validation sets can distort evaluation, underscoring the need for embedded audit tools and performance-aware governance. Smart-sizing reframes annotation as a feedback-driven process aligned with mission outcomes, enabling more robust models with fewer labels and supporting efficient AI development pipelines for frontier models and operational systems.","authors":["Dave Cook","Tim Klawa"],"url":"https://arxiv.org/abs/2505.14964"}
{"created":"2025-05-22","title":"Anomaly Detection Based on Critical Paths for Deep Neural Networks","abstract":"Deep neural networks (DNNs) are notoriously hard to understand and difficult to defend. Extracting representative paths (including the neuron activation values and the connections between neurons) from DNNs using software engineering approaches has recently shown to be a promising approach in interpreting the decision making process of blackbox DNNs, as the extracted paths are often effective in capturing essential features. With this in mind, this work investigates a novel approach that extracts critical paths from DNNs and subsequently applies the extracted paths for the anomaly detection task, based on the observation that outliers and adversarial inputs do not usually induce the same activation pattern on those paths as normal (in-distribution) inputs.","authors":["Fangzhen Zhao","Chenyi Zhang","Naipeng Dong","Ming Li","Jinxiao Shan"],"url":"https://arxiv.org/abs/2505.14967"}
{"created":"2025-05-22","title":"Optimizing Age-of-Information in Piggyback Networks with Recurrent Data Generation","abstract":"Age-of-information (AoI) is a critical metric that quantifies the freshness of data in communication systems. In the era of the Internet of Things (IoT), data collected by resource-constrained devices often need to be transmitted to a central server to extract valuable insights in a timely manner. However, maintaining a stable and direct connection between a vast number of IoT devices and servers is often impractical. The Store-Carry-Forward (SCF) communication paradigm, such as Piggyback networks, offers a viable solution to address the data collection and transmission challenges in distributed IoT systems by leveraging the mobility of mobile nodes.","authors":["Ching-Chi Lin","Mario G\\\"unzel","Jian-Jia Chen"],"url":"https://arxiv.org/abs/2505.14968"}
{"created":"2025-05-22","title":"STree: Speculative Tree Decoding for Hybrid State-Space Models","abstract":"Speculative decoding is a technique to leverage hardware concurrency to improve the efficiency of large-scale autoregressive (AR) Transformer models by enabling multiple steps of token generation in a single forward pass. State-space models (SSMs) are already more efficient than AR Transformers, since their state summarizes all past data with no need to cache or re-process tokens in the sliding window context. However, their state can also comprise thousands of tokens; so, speculative decoding has recently been extended to SSMs. Existing approaches, however, do not leverage the tree-based verification methods, since current SSMs lack the means to compute a token tree efficiently. We propose the first scalable algorithm to perform tree-based speculative decoding in state-space models (SSMs) and hybrid architectures of SSMs and Transformer layers. We exploit the structure of accumulated state transition matrices to facilitate tree-based speculative decoding with minimal overhead to current SSM state update implementations. With the algorithm, we describe a hardware-aware implementation that improves naive application of AR Transformer tree-based speculative decoding methods to SSMs. Furthermore, we outperform vanilla speculative decoding with SSMs even with a baseline drafting model and tree structure on three different benchmarks, opening up opportunities for further speed up with SSM and hybrid model inference. Code will be released upon paper acceptance.","authors":["Yangchao Wu","Zongyue Qin","Alex Wong","Stefano Soatto"],"url":"https://arxiv.org/abs/2505.14969"}
{"created":"2025-05-22","title":"Self-Evolving Curriculum for LLM Reasoning","abstract":"Reinforcement learning (RL) has proven effective for fine-tuning large language models (LLMs), significantly enhancing their reasoning abilities in domains such as mathematics and code generation. A crucial factor influencing RL fine-tuning success is the training curriculum: the order in which training problems are presented. While random curricula serve as common baselines, they remain suboptimal; manually designed curricula often rely heavily on heuristics, and online filtering methods can be computationally prohibitive. To address these limitations, we propose Self-Evolving Curriculum (SEC), an automatic curriculum learning method that learns a curriculum policy concurrently with the RL fine-tuning process. Our approach formulates curriculum selection as a non-stationary Multi-Armed Bandit problem, treating each problem category (e.g., difficulty level or problem type) as an individual arm. We leverage the absolute advantage from policy gradient methods as a proxy measure for immediate learning gain. At each training step, the curriculum policy selects categories to maximize this reward signal and is updated using the TD(0) method. Across three distinct reasoning domains: planning, inductive reasoning, and mathematics, our experiments demonstrate that SEC significantly improves models' reasoning capabilities, enabling better generalization to harder, out-of-distribution test problems. Additionally, our approach achieves better skill balance when fine-tuning simultaneously on multiple reasoning domains. These findings highlight SEC as a promising strategy for RL fine-tuning of LLMs.","authors":["Xiaoyin Chen","Jiarui Lu","Minsu Kim","Dinghuai Zhang","Jian Tang","Alexandre Pich\\'e","Nicolas Gontier","Yoshua Bengio","Ehsan Kamalloo"],"url":"https://arxiv.org/abs/2505.14970"}
{"created":"2025-05-22","title":"DECASTE: Unveiling Caste Stereotypes in Large Language Models through Multi-Dimensional Bias Analysis","abstract":"Recent advancements in large language models (LLMs) have revolutionized natural language processing (NLP) and expanded their applications across diverse domains. However, despite their impressive capabilities, LLMs have been shown to reflect and perpetuate harmful societal biases, including those based on ethnicity, gender, and religion. A critical and underexplored issue is the reinforcement of caste-based biases, particularly towards India's marginalized caste groups such as Dalits and Shudras. In this paper, we address this gap by proposing DECASTE, a novel, multi-dimensional framework designed to detect and assess both implicit and explicit caste biases in LLMs. Our approach evaluates caste fairness across four dimensions: socio-cultural, economic, educational, and political, using a range of customized prompting strategies. By benchmarking several state-of-the-art LLMs, we reveal that these models systematically reinforce caste biases, with significant disparities observed in the treatment of oppressed versus dominant caste groups. For example, bias scores are notably elevated when comparing Dalits and Shudras with dominant caste groups, reflecting societal prejudices that persist in model outputs. These results expose the subtle yet pervasive caste biases in LLMs and emphasize the need for more comprehensive and inclusive bias evaluation methodologies that assess the potential risks of deploying such models in real-world contexts.","authors":["Prashanth Vijayaraghavan","Soroush Vosoughi","Lamogha Chizor","Raya Horesh","Rogerio Abreu de Paula","Ehsan Degan","Vandana Mukherjee"],"url":"https://arxiv.org/abs/2505.14971"}
{"created":"2025-05-22","title":"Multimodal Cultural Safety: Evaluation Frameworks and Alignment Strategies","abstract":"Large vision-language models (LVLMs) are increasingly deployed in globally distributed applications, such as tourism assistants, yet their ability to produce culturally appropriate responses remains underexplored. Existing multimodal safety benchmarks primarily focus on physical safety and overlook violations rooted in cultural norms, which can result in symbolic harm. To address this gap, we introduce CROSS, a benchmark designed to assess the cultural safety reasoning capabilities of LVLMs. CROSS includes 1,284 multilingual visually grounded queries from 16 countries, three everyday domains, and 14 languages, where cultural norm violations emerge only when images are interpreted in context. We propose CROSS-Eval, an intercultural theory-based framework that measures four key dimensions: cultural awareness, norm education, compliance, and helpfulness. Using this framework, we evaluate 21 leading LVLMs, including mixture-of-experts models and reasoning models. Results reveal significant cultural safety gaps: the best-performing model achieves only 61.79% in awareness and 37.73% in compliance. While some open-source models reach GPT-4o-level performance, they still fall notably short of proprietary models. Our results further show that increasing reasoning capacity improves cultural alignment but does not fully resolve the issue. To improve model performance, we develop two enhancement strategies: supervised fine-tuning with culturally grounded, open-ended data and preference tuning with contrastive response pairs that highlight safe versus unsafe behaviors. These methods substantially improve GPT-4o's cultural awareness (+60.14%) and compliance (+55.2%), while preserving general multimodal capabilities with minimal performance reduction on general multimodal understanding benchmarks.","authors":["Haoyi Qiu","Kung-Hsiang Huang","Ruichen Zheng","Jiao Sun","Nanyun Peng"],"url":"https://arxiv.org/abs/2505.14972"}
{"created":"2025-05-22","title":"Flattening Hierarchies with Policy Bootstrapping","abstract":"Offline goal-conditioned reinforcement learning (GCRL) is a promising approach for pretraining generalist policies on large datasets of reward-free trajectories, akin to the self-supervised objectives used to train foundation models for computer vision and natural language processing. However, scaling GCRL to longer horizons remains challenging due to the combination of sparse rewards and discounting, which obscures the comparative advantages of primitive actions with respect to distant goals. Hierarchical RL methods achieve strong empirical results on long-horizon goal-reaching tasks, but their reliance on modular, timescale-specific policies and subgoal generation introduces significant additional complexity and hinders scaling to high-dimensional goal spaces. In this work, we introduce an algorithm to train a flat (non-hierarchical) goal-conditioned policy by bootstrapping on subgoal-conditioned policies with advantage-weighted importance sampling. Our approach eliminates the need for a generative model over the (sub)goal space, which we find is key for scaling to high-dimensional control in large state spaces. We further show that existing hierarchical and bootstrapping-based approaches correspond to specific design choices within our derivation. Across a comprehensive suite of state- and pixel-based locomotion and manipulation benchmarks, our method matches or surpasses state-of-the-art offline GCRL algorithms and scales to complex, long-horizon tasks where prior approaches fail.","authors":["John L. Zhou","Jonathan C. Kao"],"url":"https://arxiv.org/abs/2505.14975"}
{"created":"2025-05-22","title":"SDLog: A Deep Learning Framework for Detecting Sensitive Information in Software Logs","abstract":"Software logs are messages recorded during the execution of a software system that provide crucial run-time information about events and activities. Although software logs have a critical role in software maintenance and operation tasks, publicly accessible log datasets remain limited, hindering advance in log analysis research and practices. The presence of sensitive information, particularly Personally Identifiable Information (PII) and quasi-identifiers, introduces serious privacy and re-identification risks, discouraging the publishing and sharing of real-world logs. In practice, log anonymization techniques primarily rely on regular expression patterns, which involve manually crafting rules to identify and replace sensitive information. However, these regex-based approaches suffer from significant limitations, such as extensive manual efforts and poor generalizability across diverse log formats and datasets. To mitigate these limitations, we introduce SDLog, a deep learning-based framework designed to identify sensitive information in software logs. Our results show that SDLog overcomes regex limitations and outperforms the best-performing regex patterns in identifying sensitive information. With only 100 fine-tuning samples from the target dataset, SDLog can correctly identify 99.5% of sensitive attributes and achieves an F1-score of 98.4%. To the best of our knowledge, this is the first deep learning alternative to regex-based methods in software log anonymization.","authors":["Roozbeh Aghili","Xingfang Wu","Foutse Khomh","Heng Li"],"url":"https://arxiv.org/abs/2505.14976"}
{"created":"2025-05-22","title":"JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation","abstract":"This paper presents JARVIS, a novel multi-agent framework that leverages Large Language Models (LLMs) and domain expertise to generate high-quality scripts for specialized Electronic Design Automation (EDA) tasks. By combining a domain-specific LLM trained with synthetically generated data, a custom compiler for structural verification, rule enforcement, code fixing capabilities, and advanced retrieval mechanisms, our approach achieves significant improvements over state-of-the-art domain-specific models. Our framework addresses the challenges of data scarcity and hallucination errors in LLMs, demonstrating the potential of LLMs in specialized engineering domains. We evaluate our framework on multiple benchmarks and show that it outperforms existing models in terms of accuracy and reliability. Our work sets a new precedent for the application of LLMs in EDA and paves the way for future innovations in this field.","authors":["Ghasem Pasandi","Kishor Kunal","Varun Tej","Kunjal Shan","Hanfei Sun","Sumit Jain","Chunhui Li","Chenhui Deng","Teodor-Dumitru Ene","Haoxing Ren","Sreedhar Pratty"],"url":"https://arxiv.org/abs/2505.14978"}
{"created":"2025-05-22","title":"Green Hacks: Generating Sustainability-Targeting Attacks For Cyber-Physical Systems","abstract":"Sustainability-targeting attacks (STA) or \"Green Hacks\" are a growing threat to cyber-physical system (CPS)-based infrastructure, as its performance objectives are increasingly linked to sustainability goals. These attacks exploit the interdependence between control, energy efficiency, and environmental impact to degrade systems' overall performance. Thus, in this work, we propose a general mathematical framework for modeling such STA and derive the feasibility conditions for generating a worst-case STA on a linear CPS using a max-min formulation. A gradient ascent descent algorithm is used to construct the worst-case attack policy. We simulated the worst-case STA for a linear CPS to illustrate its impacts on the CPS performance and sustainability cost.","authors":["Faysal Ahamed","Tanushree Roy"],"url":"https://arxiv.org/abs/2505.14982"}
{"created":"2025-05-22","title":"Toward Informed AV Decision-Making: Computational Model of Well-being and Trust in Mobility","abstract":"For future human-autonomous vehicle (AV) interactions to be effective and smooth, human-aware systems that analyze and align human needs with automation decisions are essential. Achieving this requires systems that account for human cognitive states. We present a novel computational model in the form of a Dynamic Bayesian Network (DBN) that infers the cognitive states of both AV users and other road users, integrating this information into the AV's decision-making process. Specifically, our model captures the well-being of both an AV user and an interacting road user as cognitive states alongside trust. Our DBN models infer beliefs over the AV user's evolving well-being, trust, and intention states, as well as the possible well-being of other road users, based on observed interaction experiences. Using data collected from an interaction study, we refine the model parameters and empirically assess its performance. Finally, we extend our model into a causal inference model (CIM) framework for AV decision-making, enabling the AV to enhance user well-being and trust while balancing these factors with its own operational costs and the well-being of interacting road users. Our evaluation demonstrates the model's effectiveness in accurately predicting user's states and guiding informed, human-centered AV decisions.","authors":["Zahra Zahedi","Shashank Mehrotra","Teruhisa Misu","Kumar Akash"],"url":"https://arxiv.org/abs/2505.14983"}
{"created":"2025-05-22","title":"CRAFT: Training-Free Cascaded Retrieval for Tabular QA","abstract":"Table Question Answering (TQA) involves retrieving relevant tables from a large corpus to answer natural language queries. Traditional dense retrieval models, such as DTR and ColBERT, not only incur high computational costs for large-scale retrieval tasks but also require retraining or fine-tuning on new datasets, limiting their adaptability to evolving domains and knowledge. In this work, we propose $\\textbf{CRAFT}$, a cascaded retrieval approach that first uses a sparse retrieval model to filter a subset of candidate tables before applying more computationally expensive dense models and neural re-rankers. Our approach achieves better retrieval performance than state-of-the-art (SOTA) sparse, dense, and hybrid retrievers. We further enhance table representations by generating table descriptions and titles using Gemini Flash 1.5. End-to-end TQA results using various Large Language Models (LLMs) on NQ-Tables, a subset of the Natural Questions Dataset, demonstrate $\\textbf{CRAFT}$ effectiveness.","authors":["Adarsh Singh","Kushal Raj Bhandari","Jianxi Gao","Soham Dan","Vivek Gupta"],"url":"https://arxiv.org/abs/2505.14984"}
{"created":"2025-05-22","title":"AnyBody: A Benchmark Suite for Cross-Embodiment Manipulation","abstract":"Generalizing control policies to novel embodiments remains a fundamental challenge in enabling scalable and transferable learning in robotics. While prior works have explored this in locomotion, a systematic study in the context of manipulation tasks remains limited, partly due to the lack of standardized benchmarks. In this paper, we introduce a benchmark for learning cross-embodiment manipulation, focusing on two foundational tasks-reach and push-across a diverse range of morphologies. The benchmark is designed to test generalization along three axes: interpolation (testing performance within a robot category that shares the same link structure), extrapolation (testing on a robot with a different link structure), and composition (testing on combinations of link structures). On the benchmark, we evaluate the ability of different RL policies to learn from multiple morphologies and to generalize to novel ones. Our study aims to answer whether morphology-aware training can outperform single-embodiment baselines, whether zero-shot generalization to unseen morphologies is feasible, and how consistently these patterns hold across different generalization regimes. The results highlight the current limitations of multi-embodiment learning and provide insights into how architectural and training design choices influence policy generalization.","authors":["Meenal Parakh","Alexandre Kirchmeyer","Beining Han","Jia Deng"],"url":"https://arxiv.org/abs/2505.14986"}
{"created":"2025-05-22","title":"Discrete Audio Representations for Automated Audio Captioning","abstract":"Discrete audio representations, termed audio tokens, are broadly categorized into semantic and acoustic tokens, typically generated through unsupervised tokenization of continuous audio representations. However, their applicability to automated audio captioning (AAC) remains underexplored. This paper systematically investigates the viability of audio token-driven models for AAC through comparative analyses of various tokenization methods. Our findings reveal that audio tokenization leads to performance degradation in AAC models compared to those that directly utilize continuous audio representations. To address this issue, we introduce a supervised audio tokenizer trained with an audio tagging objective. Unlike unsupervised tokenizers, which lack explicit semantic understanding, the proposed tokenizer effectively captures audio event information. Experiments conducted on the Clotho dataset demonstrate that the proposed audio tokens outperform conventional audio tokens in the AAC task.","authors":["Jingguang Tian","Haoqin Sun","Xinhui Hu","Xinkang Xu"],"url":"https://arxiv.org/abs/2505.14989"}
{"created":"2025-05-22","title":"Language Specific Knowledge: Do Models Know Better in X than in English?","abstract":"Code-switching is a common phenomenon of alternating between different languages in the same utterance, thought, or conversation. We posit that humans code-switch because they feel more comfortable talking about certain topics and domains in one language than another. With the rise of knowledge-intensive language models, we ask ourselves the next, natural question: Could models hold more knowledge on some topics in some language X? More importantly, could we improve reasoning by changing the language that reasoning is performed in? We coin the term Language Specific Knowledge (LSK) to represent this phenomenon. As ethnic cultures tend to develop alongside different languages, we employ culture-specific datasets (that contain knowledge about cultural and social behavioral norms). We find that language models can perform better when using chain-of-thought reasoning in some languages other than English, sometimes even better in low-resource languages. Paired with previous works showing that semantic similarity does not equate to representational similarity, we hypothesize that culturally specific texts occur more abundantly in corresponding languages, enabling specific knowledge to occur only in specific \"expert\" languages. Motivated by our initial results, we design a simple methodology called LSKExtractor to benchmark the language-specific knowledge present in a language model and, then, exploit it during inference. We show our results on various models and datasets, showing an average relative improvement of 10% in accuracy. Our research contributes to the open-source development of language models that are inclusive and more aligned with the cultural and linguistic contexts in which they are deployed.","authors":["Ishika Agarwal","Nimet Beyza Bozdag","Dilek Hakkani-T\\\"ur"],"url":"https://arxiv.org/abs/2505.14990"}
{"created":"2025-05-22","title":"Effective and Efficient Schema-aware Information Extraction Using On-Device Large Language Models","abstract":"Information extraction (IE) plays a crucial role in natural language processing (NLP) by converting unstructured text into structured knowledge. Deploying computationally intensive large language models (LLMs) on resource-constrained devices for information extraction is challenging, particularly due to issues like hallucinations, limited context length, and high latency-especially when handling diverse extraction schemas. To address these challenges, we propose a two-stage information extraction approach adapted for on-device LLMs, called Dual-LoRA with Incremental Schema Caching (DLISC), which enhances both schema identification and schema-aware extraction in terms of effectiveness and efficiency. In particular, DLISC adopts an Identification LoRA module for retrieving the most relevant schemas to a given query, and an Extraction LoRA module for performing information extraction based on the previously selected schemas. To accelerate extraction inference, Incremental Schema Caching is incorporated to reduce redundant computation, substantially improving efficiency. Extensive experiments across multiple information extraction datasets demonstrate notable improvements in both effectiveness and efficiency.","authors":["Zhihao Wen","Sheng Liang","Yaxiong Wu","Yongyue Zhang","Yong Liu"],"url":"https://arxiv.org/abs/2505.14992"}
{"created":"2025-05-22","title":"Meta-Design Matters: A Self-Design Multi-Agent System","abstract":"Multi-agent systems (MAS) leveraging the impressive capabilities of Large Language Models (LLMs) hold significant potential for tackling complex tasks. However, most current MAS depend on manually designed agent roles and communication protocols. These manual designs often fail to align with the underlying LLMs' strengths and struggle to adapt to novel tasks. Recent automatic MAS approaches attempt to mitigate these limitations but typically necessitate a validation-set for tuning and yield static MAS designs lacking adaptability during inference. We introduce SELF-MAS, the first self-supervised, inference-time only framework for automatic MAS design. SELF-MAS employs meta-level design to iteratively generate, evaluate, and refine MAS configurations tailored to each problem instance, without requiring a validation set. Critically, it enables dynamic agent composition and problem decomposition through meta-feedback on solvability and completeness. Experiments across math, graduate-level QA, and software engineering benchmarks, using both closed-source and open-source LLM back-bones of varying sizes, demonstrate that SELF-MAS outperforms both manual and automatic MAS baselines, achieving a 7.44% average accuracy improvement over the next strongest baseline while maintaining cost-efficiency. These findings underscore the promise of meta-level self-supervised design for creating effective and adaptive MAS.","authors":["Zixuan Ke","Austin Xu","Yifei Ming","Xuan-Phi Nguyen","Caiming Xiong","Shafiq Joty"],"url":"https://arxiv.org/abs/2505.14996"}
{"created":"2025-05-22","title":"Integer Reasoning Modulo Different Constants in SMT","abstract":"This paper presents a new refutation procedure for multimodular systems of integer constraints that commonly arise when verifying cryptographic protocols. These systems, involving polynomial equalities and disequalities modulo different constants, are challenging for existing solvers due to their inability to exploit multimodular structure. To address this issue, our method partitions constraints by modulus and uses lifting and lowering techniques to share information across subsystems, supported by algebraic tools like weighted Gr\\\"obner bases. Our experiments show that the proposed method outperforms existing state-of-the-art solvers in verifying cryptographic implementations related to Montgomery arithmetic and zero-knowledge proofs.","authors":["Elizaveta Pertseva","Alex Ozdemir","Shankara Pailoor","Alp Bassa","Sorawee Porncharoenwase","I\\c{s}il Dillig","Clark Barrett"],"url":"https://arxiv.org/abs/2505.14998"}
{"created":"2025-05-22","title":"Learning to Rank Chain-of-Thought: An Energy-Based Approach with Outcome Supervision","abstract":"Mathematical reasoning presents a significant challenge for Large Language Models (LLMs), often requiring robust multi step logical consistency. While Chain of Thought (CoT) prompting elicits reasoning steps, it doesn't guarantee correctness, and improving reliability via extensive sampling is computationally costly. This paper introduces the Energy Outcome Reward Model (EORM), an effective, lightweight, post hoc verifier. EORM leverages Energy Based Models (EBMs) to simplify the training of reward models by learning to assign a scalar energy score to CoT solutions using only outcome labels, thereby avoiding detailed annotations. It achieves this by interpreting discriminator output logits as negative energies, effectively ranking candidates where lower energy is assigned to solutions leading to correct final outcomes implicitly favoring coherent reasoning. On mathematical benchmarks (GSM8k, MATH), EORM significantly improves final answer accuracy (e.g., with Llama 3 8B, achieving 90.7% on GSM8k and 63.7% on MATH). EORM effectively leverages a given pool of candidate solutions to match or exceed the performance of brute force sampling, thereby enhancing LLM reasoning outcome reliability through its streamlined post hoc verification process.","authors":["Eric Hanchen Jiang","Haozheng Luo","Shengyuan Pang","Xiaomin Li","Zhenting Qi","Hengli Li","Cheng-Fu Yang","Zongyu Lin","Xinfeng Li","Hao Xu","Kai-Wei Chang","Ying Nian Wu"],"url":"https://arxiv.org/abs/2505.14999"}
{"created":"2025-05-22","title":"Towards Spoken Mathematical Reasoning: Benchmarking Speech-based Models over Multi-faceted Math Problems","abstract":"Recent advances in large language models (LLMs) and multimodal LLMs (MLLMs) have led to strong reasoning ability across a wide range of tasks. However, their ability to perform mathematical reasoning from spoken input remains underexplored. Prior studies on speech modality have mostly focused on factual speech understanding or simple audio reasoning tasks, providing limited insight into logical step-by-step reasoning, such as that required for mathematical problem solving. To address this gap, we introduce Spoken Math Question Answering (Spoken-MQA), a new benchmark designed to evaluate the mathematical reasoning capabilities of speech-based models, including both cascade models (ASR + LLMs) and end-to-end speech LLMs. Spoken-MQA covers a diverse set of math problems, including pure arithmetic, single-step and multi-step contextual reasoning, and knowledge-oriented reasoning problems, all presented in unambiguous natural spoken language. Through extensive experiments, we find that: (1) while some speech LLMs perform competitively on contextual reasoning tasks involving basic arithmetic, they still struggle with direct arithmetic problems; (2) current LLMs exhibit a strong bias toward symbolic mathematical expressions written in LaTex and have difficulty interpreting verbalized mathematical expressions; and (3) mathematical knowledge reasoning abilities are significantly degraded in current speech LLMs.","authors":["Chengwei Wei","Bin Wang","Jung-jae Kim","Nancy F. Chen"],"url":"https://arxiv.org/abs/2505.15000"}
{"created":"2025-05-22","title":"Unraveling the iterative CHAD","abstract":"Combinatory Homomorphic Automatic Differentiation (CHAD) was originally formulated as a semantics-driven source transformation for reverse-mode AD in total programming languages. We extend this framework to partial languages with features such as potentially non-terminating operations, real-valued conditionals, and iteration constructs like while-loops, while preserving CHAD's structure-preserving semantics principle. A key contribution is the introduction of iteration-extensive indexed categories, which allow iteration in the base category to lift to parameterized initial algebras in the indexed category. This enables iteration to be interpreted in the Grothendieck construction of the target language in a principled way. The resulting fibred iterative structure cleanly models iteration in the categorical semantics. Consequently, the extended CHAD transformation remains the unique structure-preserving functor (an iterative Freyd category morphism) from the freely generated iterative Freyd category of the source language to the Grothendieck construction of the target's syntactic semantics, mapping each primitive operation to its derivative. We prove the correctness of this transformation using the universal property of the source language's syntax, showing that the transformed programs compute correct reverse-mode derivatives. Our development also contributes to understanding iteration constructs within dependently typed languages and categories of containers. As our primary motivation and application, we generalize CHAD to languages with data types, partial features, and iteration, providing the first rigorous categorical semantics for reverse-mode CHAD in such settings and formally guaranteeing the correctness of the source-to-source CHAD technique.","authors":["Fernando Lucatelli Nunes","Gordon Plotkin","Matthijs V\\'ak\\'ar"],"url":"https://arxiv.org/abs/2505.15002"}
{"created":"2025-05-22","title":"UniSTPA: A Safety Analysis Framework for End-to-End Autonomous Driving","abstract":"As autonomous driving technology continues to advance, end-to-end models have attracted considerable attention owing to their superior generalisation capability. Nevertheless, such learning-based systems entail numerous safety risks throughout development and on-road deployment, and existing safety-analysis methods struggle to identify these risks comprehensively. To address this gap, we propose the Unified System Theoretic Process Analysis (UniSTPA) framework, which extends the scope of STPA from the operational phase to the entire lifecycle of an end-to-end autonomous driving system, including information gathering, data preparation, closed loop training, verification, and deployment. UniSTPA performs hazard analysis not only at the component level but also within the model's internal layers, thereby enabling fine-grained assessment of inter and intra module interactions. Using a highway Navigate on Autopilot function as a case study, UniSTPA uncovers multi-stage hazards overlooked by conventional approaches including scene design defects, sensor fusion biases, and internal model flaws, through multi-level causal analysis, traces these hazards to deeper issues such as data quality, network architecture, and optimisation objectives. The analysis result are used to construct a safety monitoring and safety response mechanism that supports continuous improvement from hazard identification to system optimisation. The proposed framework thus offers both theoretical and practical guidance for the safe development and deployment of end-to-end autonomous driving systems.","authors":["Hongrui Kou","Zhouhang Lyu","Ziyu Wang","Cheng Wang","Yuxin Zhang"],"url":"https://arxiv.org/abs/2505.15005"}
{"created":"2025-05-22","title":"Know When to Abstain: Optimal Selective Classification with Likelihood Ratios","abstract":"Selective classification enhances the reliability of predictive models by allowing them to abstain from making uncertain predictions. In this work, we revisit the design of optimal selection functions through the lens of the Neyman--Pearson lemma, a classical result in statistics that characterizes the optimal rejection rule as a likelihood ratio test. We show that this perspective not only unifies the behavior of several post-hoc selection baselines, but also motivates new approaches to selective classification which we propose here. A central focus of our work is the setting of covariate shift, where the input distribution at test time differs from that at training. This realistic and challenging scenario remains relatively underexplored in the context of selective classification. We evaluate our proposed methods across a range of vision and language tasks, including both supervised learning and vision-language models. Our experiments demonstrate that our Neyman--Pearson-informed methods consistently outperform existing baselines, indicating that likelihood ratio-based selection offers a robust mechanism for improving selective classification under covariate shifts. Our code is publicly available at https://github.com/clear-nus/sc-likelihood-ratios.","authors":["Alvin Heng","Harold Soh"],"url":"https://arxiv.org/abs/2505.15008"}
{"created":"2025-05-22","title":"One-Layer Transformers are Provably Optimal for In-context Reasoning and Distributional Association Learning in Next-Token Prediction Tasks","abstract":"We study the approximation capabilities and on-convergence behaviors of one-layer transformers on the noiseless and noisy in-context reasoning of next-token prediction. Existing theoretical results focus on understanding the in-context reasoning behaviors for either the first gradient step or when the number of samples is infinite. Furthermore, no convergence rates nor generalization abilities were known. Our work addresses these gaps by showing that there exists a class of one-layer transformers that are provably Bayes-optimal with both linear and ReLU attention. When being trained with gradient descent, we show via a finite-sample analysis that the expected loss of these transformers converges at linear rate to the Bayes risk. Moreover, we prove that the trained models generalize to unseen samples as well as exhibit learning behaviors that were empirically observed in previous works. Our theoretical findings are further supported by extensive empirical validations.","authors":["Quan Nguyen","Thanh Nguyen-Tang"],"url":"https://arxiv.org/abs/2505.15009"}
{"created":"2025-05-22","title":"Shape-Adaptive Planning and Control for a Deformable Quadrotor","abstract":"Drones have become essential in various applications, but conventional quadrotors face limitations in confined spaces and complex tasks. Deformable drones, which can adapt their shape in real-time, offer a promising solution to overcome these challenges, while also enhancing maneuverability and enabling novel tasks like object grasping. This paper presents a novel approach to autonomous motion planning and control for deformable quadrotors. We introduce a shape-adaptive trajectory planner that incorporates deformation dynamics into path generation, using a scalable kinodynamic A* search to handle deformation parameters in complex environments. The backend spatio-temporal optimization is capable of generating optimally smooth trajectories that incorporate shape deformation. Additionally, we propose an enhanced control strategy that compensates for external forces and torque disturbances, achieving a 37.3\\% reduction in trajectory tracking error compared to our previous work. Our approach is validated through simulations and real-world experiments, demonstrating its effectiveness in narrow-gap traversal and multi-modal deformable tasks.","authors":["Yuze Wu","Zhichao Han","Xuankang Wu","Yuan Zhou","Junjie Wang","Zheng Fang","Fei Gao"],"url":"https://arxiv.org/abs/2505.15010"}
{"created":"2025-05-22","title":"HAVA: Hybrid Approach to Value-Alignment through Reward Weighing for Reinforcement Learning","abstract":"Our society is governed by a set of norms which together bring about the values we cherish such as safety, fairness or trustworthiness. The goal of value-alignment is to create agents that not only do their tasks but through their behaviours also promote these values. Many of the norms are written as laws or rules (legal / safety norms) but even more remain unwritten (social norms). Furthermore, the techniques used to represent these norms also differ. Safety / legal norms are often represented explicitly, for example, in some logical language while social norms are typically learned and remain hidden in the parameter space of a neural network. There is a lack of approaches in the literature that could combine these various norm representations into a single algorithm. We propose a novel method that integrates these norms into the reinforcement learning process. Our method monitors the agent's compliance with the given norms and summarizes it in a quantity we call the agent's reputation. This quantity is used to weigh the received rewards to motivate the agent to become value-aligned. We carry out a series of experiments including a continuous state space traffic problem to demonstrate the importance of the written and unwritten norms and show how our method can find the value-aligned policies. Furthermore, we carry out ablations to demonstrate why it is better to combine these two groups of norms rather than using either separately.","authors":["Kryspin Varys","Federico Cerutti","Adam Sobey","Timothy J. Norman"],"url":"https://arxiv.org/abs/2505.15011"}
{"created":"2025-05-22","title":"Beyond Node Attention: Multi-Scale Harmonic Encoding for Feature-Wise Graph Message Passing","abstract":"Conventional Graph Neural Networks (GNNs) aggregate neighbor embeddings as holistic vectors, lacking the ability to identify fine-grained, direction-specific feature relevance. We propose MSH-GNN (Multi-Scale Harmonic Graph Neural Network), a novel architecture that performs feature-wise adaptive message passing through node-specific harmonic projections. For each node, MSH-GNN dynamically projects neighbor features onto frequency-sensitive directions determined by the target node's own representation. These projections are further modulated using learnable sinusoidal encodings at multiple frequencies, enabling the model to capture both smooth and oscillatory structural patterns across scales. A frequency-aware attention pooling mechanism is introduced to emphasize spectrally and structurally salient nodes during readout. Theoretically, we prove that MSH-GNN approximates shift-invariant kernels and matches the expressive power of the 1-Weisfeiler-Lehman (1-WL) test. Empirically, MSH-GNN consistently outperforms state-of-the-art models on a wide range of graph and node classification tasks. Furthermore, in challenging classification settings involving joint variations in graph topology and spectral frequency, MSH-GNN excels at capturing structural asymmetries and high-frequency modulations, enabling more accurate graph discrimination.","authors":["Longlong Li","Cunquan Qu","Guanghui Wang"],"url":"https://arxiv.org/abs/2505.15015"}
{"created":"2025-05-22","title":"PsyScam: A Benchmark for Psychological Techniques in Real-World Scams","abstract":"Online scams have become increasingly prevalent, with scammers using psychological techniques (PTs) to manipulate victims. While existing research has developed benchmarks to study scammer behaviors, these benchmarks do not adequately reflect the PTs observed in real-world scams. To fill this gap, we introduce PsyScam, a benchmark designed to systematically capture and evaluate PTs embedded in real-world scam reports. In particular, PsyScam bridges psychology and real-world cyber security analysis through collecting a wide range of scam reports from six public platforms and grounding its annotations in well-established cognitive and psychological theories. We further demonstrate PsyScam's utility through three downstream tasks: PT classification, scam completion, and scam augmentation. Experimental results show that PsyScam presents significant challenges to existing models in both detecting and generating scam content based on the PTs used by real-world scammers. Our code and dataset are available at: https://anonymous.4open.science/r/PsyScam-66E4.","authors":["Shang Ma","Tianyi Ma","Jiahao Liu","Wei Song","Zhenkai Liang","Xusheng Xiao","Yanfang Ye"],"url":"https://arxiv.org/abs/2505.15017"}
{"created":"2025-05-22","title":"COSMIC: Enabling Full-Stack Co-Design and Optimization of Distributed Machine Learning Systems","abstract":"Large-scale machine learning models necessitate distributed systems, posing significant design challenges due to the large parameter space across distinct design stacks. Existing studies often focus on optimizing individual system aspects in isolation. This work challenges this limitation and introduces COSMIC, a full-stack distributed machine learning systems environment enabling end-to-end simulation and agent-based design space exploration. To facilitate efficient exploration and optimization across the entire stack, we introduce Parameter Set Architecture-an abstraction concept analogous to the instruction set architecture-abstracting away configuration complexities of agent-based search methods. Case studies demonstrate COSMIC's ability to consolidate parameters across multiple layers of design abstraction, discovering eight non-obvious high-performance system configurations across four transformer-based models with up to 175 billion parameters. By optimizing across the stack, COSMIC full-stack optimization delivers 1.50-48.41x higher performance compared to the isolated single-stack optimization.","authors":["Aditi Raju","Jared Ni","William Won","Changhai Man","Srivatsan Krishnan","Srinivas Sridharan","Amir Yazdanbakhsh","Tushar Krishna","Vijay Janapa Reddi"],"url":"https://arxiv.org/abs/2505.15020"}
{"created":"2025-05-22","title":"Towards a Science of Causal Interpretability in Deep Learning for Software Engineering","abstract":"This dissertation addresses achieving causal interpretability in Deep Learning for Software Engineering (DL4SE). While Neural Code Models (NCMs) show strong performance in automating software tasks, their lack of transparency in causal relationships between inputs and outputs limits full understanding of their capabilities. To build trust in NCMs, researchers and practitioners must explain code predictions. Associational interpretability, which identifies correlations, is often insufficient for tasks requiring intervention and change analysis. To address this, the dissertation introduces DoCode, a novel post hoc interpretability method for NCMs. DoCode uses causal inference to provide programming language-oriented explanations of model predictions. It follows a four-step pipeline: modeling causal problems using Structural Causal Models (SCMs), identifying the causal estimand, estimating effects with metrics like Average Treatment Effect (ATE), and refuting effect estimates. Its framework is extensible, with an example that reduces spurious correlations by grounding explanations in programming language properties. A case study on deep code generation across interpretability scenarios and various deep learning architectures demonstrates DoCode's benefits. Results show NCMs' sensitivity to code syntax changes and their ability to learn certain programming concepts while minimizing confounding bias. The dissertation also examines associational interpretability as a foundation, analyzing software information's causal nature using tools like COMET and TraceXplainer for traceability. It highlights the need to identify code confounders and offers practical guidelines for applying causal interpretability to NCMs, contributing to more trustworthy AI in software engineering.","authors":["David N. Palacio"],"url":"https://arxiv.org/abs/2505.15023"}
{"created":"2025-05-22","title":"Diagnosing our datasets: How does my language model learn clinical information?","abstract":"Large language models (LLMs) have performed well across various clinical natural language processing tasks, despite not being directly trained on electronic health record (EHR) data. In this work, we examine how popular open-source LLMs learn clinical information from large mined corpora through two crucial but understudied lenses: (1) their interpretation of clinical jargon, a foundational ability for understanding real-world clinical notes, and (2) their responses to unsupported medical claims. For both use cases, we investigate the frequency of relevant clinical information in their corresponding pretraining corpora, the relationship between pretraining data composition and model outputs, and the sources underlying this data. To isolate clinical jargon understanding, we evaluate LLMs on a new dataset MedLingo. Unsurprisingly, we find that the frequency of clinical jargon mentions across major pretraining corpora correlates with model performance. However, jargon frequently appearing in clinical notes often rarely appears in pretraining corpora, revealing a mismatch between available data and real-world usage. Similarly, we find that a non-negligible portion of documents support disputed claims that can then be parroted by models. Finally, we classified and analyzed the types of online sources in which clinical jargon and unsupported medical claims appear, with implications for future dataset composition.","authors":["Furong Jia","David Sontag","Monica Agrawal"],"url":"https://arxiv.org/abs/2505.15024"}
{"created":"2025-05-22","title":"Harnessing Large Language Models Locally: Empirical Results and Implications for AI PC","abstract":"The increasing deployment of Large Language Models (LLMs) on edge devices, driven by model advancements and hardware improvements, offers significant privacy benefits. However, these on-device LLMs inherently face performance limitations due to reduced model capacity and necessary compression techniques. To address this, we introduce a systematic methodology -- encompassing model capability, development efficiency, and system resources -- for evaluating on-device LLMs. Our comprehensive evaluation, encompassing models from 0.5B to 14B parameters and seven post-training quantization (PTQ) methods on commodity laptops, yields several critical insights: 1) System-level metrics exhibit near-linear scaling with effective bits-per-weight (BPW). 2) A practical threshold exists around $\\sim$3.5 effective BPW, larger models subjected to low-bit quantization consistently outperform smaller models utilizing higher bit-precision. 3) Quantization with low BPW incurs marginal accuracy loss but significant memory savings. 4) Determined by low-level implementation specifics power consumption on CPU, where computation-intensive operations spend more power than memory-intensive ones. These findings offer crucial insights and practical guidelines for the efficient deployment and optimized configuration of LLMs on resource-constrained edge devices. Our codebase is available at https://github.com/simmonssong/LLMOnDevice.","authors":["Qingyu Song","Peiyu Liao","Wenqian Zhao","Yiwen Wang","Shoubo Hu","Hui-Ling Zhen","Ning Jiang","Mingxuan Yuan"],"url":"https://arxiv.org/abs/2505.15030"}
{"created":"2025-05-22","title":"Are the confidence scores of reviewers consistent with the review content? Evidence from top conference proceedings in AI","abstract":"Peer review is vital in academia for evaluating research quality. Top AI conferences use reviewer confidence scores to ensure review reliability, but existing studies lack fine-grained analysis of text-score consistency, potentially missing key details. This work assesses consistency at word, sentence, and aspect levels using deep learning and NLP conference review data. We employ deep learning to detect hedge sentences and aspects, then analyze report length, hedge word/sentence frequency, aspect mentions, and sentiment to evaluate text-score alignment. Correlation, significance, and regression tests examine confidence scores' impact on paper outcomes. Results show high text-score consistency across all levels, with regression revealing higher confidence scores correlate with paper rejection, validating expert assessments and peer review fairness.","authors":["Wenqing Wu","Haixu Xi","Chengzhi Zhang"],"url":"https://arxiv.org/abs/2505.15031"}
{"created":"2025-05-22","title":"Toward Task Capable Active Matter: Learning to Avoid Clogging in Confined Collectives via Collisions","abstract":"Social organisms which construct nests consisting of tunnels and chambers necessarily navigate confined and crowded conditions. Unlike low-density collectives like bird flocks and insect swarms, in which hydrodynamic and statistical phenomena dominate, the physics of glasses and supercooled fluids is important to understand clogging behaviors in high-density collectives. Our previous work revealed that fire ants flowing in confined tunnels utilize diverse behaviors like unequal workload distributions, spontaneous direction reversals, and limited interaction times to mitigate clogging and jamming and thus maintain functional flow; implementation of similar rules in a small robophysical swarm led to high performance through spontaneous dissolution of clogs and clusters. However, how the insects learn such behaviors, and how we can develop \"task capable\" active matter in such regimes, remains a challenge in part because interaction dynamics are dominated by local, time-consuming collisions and no single agent can guide the entire collective. Here, we hypothesized that effective flow and clog mitigation could emerge purely through local learning. We tasked small groups of robots with pellet excavation in a narrow tunnel, allowing them to modify reversal probabilities over time. Initially, robots had equal probabilities and clogs were common. Reversals improved flow. When reversal probabilities adapted via collisions and noisy tunnel length estimates, workload inequality and performance improved. Our robophysical study of an excavating swarm shows that, despite the seeming complexity and difficulty of the task, simple learning rules can mitigate or leverage unavoidable features in task-capable dense active matter, leading to hypotheses for dense biological and robotic swarms.","authors":["Kehinde O. Aina","Ram Avinery","Hui-Shun Kuan","Meredith D. Betterton","Michael A. D. Goodisman","Daniel I. Goldman"],"url":"https://arxiv.org/abs/2505.15033"}
{"created":"2025-05-22","title":"RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning","abstract":"Reinforcement learning (RL) has recently emerged as a compelling approach for enhancing the reasoning capabilities of large language models (LLMs), where an LLM generator serves as a policy guided by a verifier (reward model). However, current RL post-training methods for LLMs typically use verifiers that are fixed (rule-based or frozen pretrained) or trained discriminatively via supervised fine-tuning (SFT). Such designs are susceptible to reward hacking and generalize poorly beyond their training distributions. To overcome these limitations, we propose Tango, a novel framework that uses RL to concurrently train both an LLM generator and a verifier in an interleaved manner. A central innovation of Tango is its generative, process-level LLM verifier, which is trained via RL and co-evolves with the generator. Importantly, the verifier is trained solely based on outcome-level verification correctness rewards without requiring explicit process-level annotations. This generative RL-trained verifier exhibits improved robustness and superior generalization compared to deterministic or SFT-trained verifiers, fostering effective mutual reinforcement with the generator. Extensive experiments demonstrate that both components of Tango achieve state-of-the-art results among 7B/8B-scale models: the generator attains best-in-class performance across five competition-level math benchmarks and four challenging out-of-domain reasoning tasks, while the verifier leads on the ProcessBench dataset. Remarkably, both components exhibit particularly substantial improvements on the most difficult mathematical reasoning problems. Code is at: https://github.com/kaiwenzha/rl-tango.","authors":["Kaiwen Zha","Zhengqi Gao","Maohao Shen","Zhang-Wei Hong","Duane S. Boning","Dina Katabi"],"url":"https://arxiv.org/abs/2505.15034"}
{"created":"2025-05-22","title":"Fault-Tolerant Multi-Robot Coordination with Limited Sensing within Confined Environments","abstract":"As robots are increasingly deployed to collaborate on tasks within shared workspaces and resources, the failure of an individual robot can critically affect the group's performance. This issue is particularly challenging when robots lack global information or direct communication, relying instead on social interaction for coordination and to complete their tasks. In this study, we propose a novel fault-tolerance technique leveraging physical contact interactions in multi-robot systems, specifically under conditions of limited sensing and spatial confinement. We introduce the \"Active Contact Response\" (ACR) method, where each robot modulates its behavior based on the likelihood of encountering an inoperative (faulty) robot. Active robots are capable of collectively repositioning stationary and faulty peers to reduce obstructions and maintain optimal group functionality. We implement our algorithm in a team of autonomous robots, equipped with contact-sensing and collision-tolerance capabilities, tasked with collectively excavating cohesive model pellets. Experimental results indicate that the ACR method significantly improves the system's recovery time from robot failures, enabling continued collective excavation with minimal performance degradation. Thus, this work demonstrates the potential of leveraging local, social, and physical interactions to enhance fault tolerance and coordination in multi-robot systems operating in constrained and extreme environments.","authors":["Kehinde O. Aina","Hosain Bagheri","Daniel I. Goldman"],"url":"https://arxiv.org/abs/2505.15036"}
{"created":"2025-05-22","title":"Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering","abstract":"Linear Concept Vectors have proven effective for steering large language models (LLMs). While existing approaches like linear probing and difference-in-means derive these vectors from LLM hidden representations, diverse data introduces noises (i.e., irrelevant features) that challenge steering robustness. To address this, we propose Sparse Autoencoder-Denoised Concept Vectors (SDCV), which uses Sparse Autoencoders to filter out noisy features from hidden representations. When applied to linear probing and difference-in-means, our method improves their steering success rates. We validate our noise hypothesis through counterfactual experiments and feature visualizations.","authors":["Haiyan Zhao","Xuansheng Wu","Fan Yang","Bo Shen","Ninghao Liu","Mengnan Du"],"url":"https://arxiv.org/abs/2505.15038"}
{"created":"2025-05-22","title":"LogiCase: Effective Test Case Generation from Logical Description in Competitive Programming","abstract":"Automated Test Case Generation (ATCG) is crucial for evaluating software reliability, particularly in competitive programming where robust algorithm assessments depend on diverse and accurate test cases. However, existing ATCG methods often fail to meet complex specifications or generate effective corner cases, limiting their utility. In this work, we introduce Context-Free Grammars with Counters (CCFGs), a formalism that captures both syntactic and semantic structures in input specifications. Using a fine-tuned CodeT5 model, we translate natural language input specifications into CCFGs, enabling the systematic generation of high-quality test cases. Experiments on the CodeContests dataset demonstrate that CCFG-based test cases outperform baseline methods in identifying incorrect algorithms, achieving significant gains in validity and effectiveness. Our approach provides a scalable and reliable grammar-driven framework for enhancing automated competitive programming evaluations.","authors":["Sicheol Sung","Aditi","Dogyu kim","Yo-Sub Han","Sang-Ki Ko"],"url":"https://arxiv.org/abs/2505.15039"}
{"created":"2025-05-22","title":"RLBenchNet: The Right Network for the Right Reinforcement Learning Task","abstract":"Reinforcement learning (RL) has seen significant advancements through the application of various neural network architectures. In this study, we systematically investigate the performance of several neural networks in RL tasks, including Long Short-Term Memory (LSTM), Multi-Layer Perceptron (MLP), Mamba/Mamba-2, Transformer-XL, Gated Transformer-XL, and Gated Recurrent Unit (GRU). Through comprehensive evaluation across continuous control, discrete decision-making, and memory-based environments, we identify architecture-specific strengths and limitations. Our results reveal that: (1) MLPs excel in fully observable continuous control tasks, providing an optimal balance of performance and efficiency; (2) recurrent architectures like LSTM and GRU offer robust performance in partially observable environments with moderate memory requirements; (3) Mamba models achieve a 4.5x higher throughput compared to LSTM and a 3.9x increase over GRU, all while maintaining comparable performance; and (4) only Transformer-XL, Gated Transformer-XL, and Mamba-2 successfully solve the most challenging memory-intensive tasks, with Mamba-2 requiring 8x less memory than Transformer-XL. These findings provide insights for researchers and practitioners, enabling more informed architecture selection based on specific task characteristics and computational constraints. Code is available at: https://github.com/SafeRL-Lab/RLBenchNet","authors":["Ivan Smirnov","Shangding Gu"],"url":"https://arxiv.org/abs/2505.15040"}
{"created":"2025-05-22","title":"Co-optimize condenser water temperature and cooling tower fan using high-fidelity synthetic data","abstract":"This paper introduces a novel method for optimizing HVAC systems in buildings by integrating a high-fidelity physics-based simulation model with machine learning and measured data. The method enables a real-time building advisory system that provides optimized settings for condenser water loop operation, assisting building operators in decision-making. The building and its HVAC system are first modeled using eQuest. Synthetic data are then generated by running the simulation multiple times. The data are then processed, cleaned, and used to train the machine learning model. The machine learning model enables real-time optimization of the condenser water loop using particle swarm optimization. The results deliver both a real-time online optimizer and an offline operation look-up table, providing optimized condenser water temperature settings and the optimal number of cooling tower fans at a given cooling load. Potential savings are calculated by comparing measured data from two summer months with the energy costs the building would have experienced under optimized settings. Adaptive model refinement is applied to further improve accuracy and effectiveness by utilizing available measured data. The method bridges the gap between simulation and real-time control. It has the potential to be applied to other building systems, including the chilled water loop, heating systems, ventilation systems, and other related processes. Combining physics models, data models, and measured data also enables performance analysis, tracking, and retrofit recommendations.","authors":["Gulai Shen","Gurpreet Singh","Ali Mehmani"],"url":"https://arxiv.org/abs/2505.15041"}
{"created":"2025-05-22","title":"GitHub Repository Complexity Leads to Diminished Web Archive Availability","abstract":"Software is often developed using versioned controlled software, such as Git, and hosted on centralized Web hosts, such as GitHub and GitLab. These Web hosted software repositories are made available to users in the form of traditional HTML Web pages for each source file and directory, as well as a presentational home page and various descriptive pages. We examined more than 12,000 Web hosted Git repository project home pages, primarily from GitHub, to measure how well their presentational components are preserved in the Internet Archive, as well as the source trees of the collected GitHub repositories to assess the extent to which their source code has been preserved. We found that more than 31% of the archived repository home pages examined exhibited some form of minor page damage and 1.6% exhibited major page damage. We also found that of the source trees analyzed, less than 5% of their source files were archived, on average, with the majority of repositories not having source files saved in the Internet Archive at all. The highest concentration of archived source files available were those linked directly from repositories' home pages at a rate of 14.89% across all available repositories and sharply dropping off at deeper levels of a repository's directory tree.","authors":["David Calano","Michele C. Weigle","Michael L. Nelson"],"url":"https://arxiv.org/abs/2505.15042"}
{"created":"2025-05-22","title":"Histo-Planner: A Real-time Local Planner for MAVs Teleoperation based on Histogram of Obstacle Distribution","abstract":"This paper concerns real-time obstacle avoidance for micro aerial vehicles (MAVs). Motivated by teleoperation applications in cluttered environments with limited computational power, we propose a local planner that does not require the knowledge or construction of a global map of the obstacles. The proposed solution consists of a real-time trajectory planning algorithm that relies on the histogram of obstacle distribution and a planner manager that triggers different planning modes depending on obstacles location around the MAV. The proposed solution is validated, for a teleoperation application, with both simulations and indoor experiments. Benchmark comparisons based on a designed simulation platform are also provided.","authors":["Ze Wang","Zhenyu Gao","Jingang Qu","Pascal Morin"],"url":"https://arxiv.org/abs/2505.15043"}
{"created":"2025-05-22","title":"Learning-based Airflow Inertial Odometry for MAVs using Thermal Anemometers in a GPS and vision denied environment","abstract":"This work demonstrates an airflow inertial based odometry system with multi-sensor data fusion, including thermal anemometer, IMU, ESC, and barometer. This goal is challenging because low-cost IMUs and barometers have significant bias, and anemometer measurements are very susceptible to interference from spinning propellers and ground effects. We employ a GRU-based deep neural network to estimate relative air speed from noisy and disturbed anemometer measurements, and an observer with bias model to fuse the sensor data and thus estimate the state of aerial vehicle. A complete flight data, including takeoff and landing on the ground, shows that the approach is able to decouple the downwash induced wind speed caused by propellers and the ground effect, and accurately estimate the flight speed in a wind-free indoor environment. IMU, and barometer bias are effectively estimated, which significantly reduces the position integration drift, which is only 5.7m for 203s manual random flight. The open source is available on https://github.com/SyRoCo-ISIR/Flight-Speed-Estimation-Airflow.","authors":["Ze Wang","Jingang Qu","Zhenyu Gao","Pascal Morin"],"url":"https://arxiv.org/abs/2505.15044"}
{"created":"2025-05-22","title":"Diffusion vs. Autoregressive Language Models: A Text Embedding Perspective","abstract":"Large language model (LLM)-based embedding models, benefiting from large scale pre-training and post-training, have begun to surpass BERT and T5-based models on general-purpose text embedding tasks such as document retrieval. However, a fundamental limitation of LLM embeddings lies in the unidirectional attention used during autoregressive pre-training, which misaligns with the bidirectional nature of text embedding tasks. To this end, We propose adopting diffusion language models for text embeddings, motivated by their inherent bidirectional architecture and recent success in matching or surpassing LLMs especially on reasoning tasks. We present the first systematic study of the diffusion language embedding model, which outperforms the LLM-based embedding model by 20% on long-document retrieval, 8% on reasoning-intensive retrieval, 2% on instruction-following retrieval, and achieve competitive performance on traditional text embedding benchmarks. Our analysis verifies that bidirectional attention is crucial for encoding global context in long and complex text.","authors":["Siyue Zhang","Yilun Zhao","Liyuan Geng","Arman Cohan","Anh Tuan Luu","Chen Zhao"],"url":"https://arxiv.org/abs/2505.15045"}
{"created":"2025-05-22","title":"ChartCards: A Chart-Metadata Generation Framework for Multi-Task Chart Understanding","abstract":"The emergence of Multi-modal Large Language Models (MLLMs) presents new opportunities for chart understanding. However, due to the fine-grained nature of these tasks, applying MLLMs typically requires large, high-quality datasets for task-specific fine-tuning, leading to high data collection and training costs. To address this, we propose ChartCards, a unified chart-metadata generation framework for multi-task chart understanding. ChartCards systematically synthesizes various chart information, including data tables, visualization code, visual elements, and multi-dimensional semantic captions. By structuring this information into organized metadata, ChartCards enables a single chart to support multiple downstream tasks, such as text-to-chart retrieval, chart summarization, chart-to-table conversion, chart description, and chart question answering. Using ChartCards, we further construct MetaChart, a large-scale high-quality dataset containing 10,862 data tables, 85K charts, and 170 K high-quality chart captions. We validate the dataset through qualitative crowdsourcing evaluations and quantitative fine-tuning experiments across various chart understanding tasks. Fine-tuning six different models on MetaChart resulted in an average performance improvement of 5% across all tasks. The most notable improvements are seen in text-to-chart retrieval and chart-to-table tasks, with Long-CLIP and Llama 3.2-11B achieving improvements of 17% and 28%, respectively.","authors":["Yifan Wu","Lutao Yan","Leixian Shen","Yinan Mei","Jiannan Wang","Yuyu Luo"],"url":"https://arxiv.org/abs/2505.15046"}
{"created":"2025-05-22","title":"PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration","abstract":"Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering systematic uncertainty reduction. Overcoming these limitations fundamentally requires systematic uncertainty reduction. We introduce \\texttt{PiFlow}, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws). In evaluations across three distinct scientific domains -- discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -- our method significantly improves discovery efficiency, reflected by a 73.55\\% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06\\% compared to a vanilla agent system. Overall, \\texttt{PiFlow} serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research. Code is publicly available at our \\href{https://github.com/amair-lab/PiFlow}{GitHub}.","authors":["Yingming Pu","Tao Lin","Hongyu Chen"],"url":"https://arxiv.org/abs/2505.15047"}
{"created":"2025-05-22","title":"Towards a Working Definition of Designing Generative User Interfaces","abstract":"Generative UI is transforming interface design by facilitating AI-driven collaborative workflows between designers and computational systems. This study establishes a working definition of Generative UI through a multi-method qualitative approach, integrating insights from a systematic literature review of 127 publications, expert interviews with 18 participants, and analyses of 12 case studies. Our findings identify five core themes that position Generative UI as an iterative and co-creative process. We highlight emerging design models, including hybrid creation, curation-based workflows, and AI-assisted refinement strategies. Additionally, we examine ethical challenges, evaluation criteria, and interaction models that shape the field. By proposing a conceptual foundation, this study advances both theoretical discourse and practical implementation, guiding future HCI research toward responsible and effective generative UI design practices.","authors":["Kyungho Lee"],"url":"https://arxiv.org/abs/2505.15049"}
{"created":"2025-05-22","title":"Improving the fact-checking performance of language models by relying on their entailment ability","abstract":"Automated fact-checking is a crucial task in this digital age. To verify a claim, current approaches majorly follow one of two strategies i.e. (i) relying on embedded knowledge of language models, and (ii) fine-tuning them with evidence pieces. While the former can make systems to hallucinate, the later have not been very successful till date. The primary reason behind this is that fact verification is a complex process. Language models have to parse through multiple pieces of evidence before making a prediction. Further, the evidence pieces often contradict each other. This makes the reasoning process even more complex. We proposed a simple yet effective approach where we relied on entailment and the generative ability of language models to produce ''supporting'' and ''refuting'' justifications (for the truthfulness of a claim). We trained language models based on these justifications and achieved superior results. Apart from that, we did a systematic comparison of different prompting and fine-tuning strategies, as it is currently lacking in the literature. Some of our observations are: (i) training language models with raw evidence sentences registered an improvement up to 8.20% in macro-F1, over the best performing baseline for the RAW-FC dataset, (ii) similarly, training language models with prompted claim-evidence understanding (TBE-2) registered an improvement (with a margin up to 16.39%) over the baselines for the same dataset, (iii) training language models with entailed justifications (TBE-3) outperformed the baselines by a huge margin (up to 28.57% and 44.26% for LIAR-RAW and RAW-FC, respectively). We have shared our code repository to reproduce the results.","authors":["Gaurav Kumar","Debajyoti Mazumder","Ayush Garg","Jasabanta Patro"],"url":"https://arxiv.org/abs/2505.15050"}
{"created":"2025-05-22","title":"An Empirical Analysis of EOS Blockchain: Architecture, Contract, and Security","abstract":"With the rapid development of blockchain technology, various blockchain systems are exhibiting vitality and potential. As a representative of Blockchain 3.0, the EOS blockchain has been regarded as a strong competitor to Ethereum. Nevertheless, compared with Bitcoin and Ethereum, academic research and in-depth analyses of EOS remain scarce. To address this gap, this study conducts a comprehensive investigation of the EOS blockchain from five key dimensions: system architecture, decentralization, performance, smart contracts, and behavioral security. The architectural analysis focuses on six core components of the EOS system, detailing their functionalities and operational workflows. The decentralization and performance evaluations, based on data from the XBlock data-sharing platform, reveal several critical issues: low account activity, limited participation in the supernode election process, minimal variation in the set of block producers, and a substantial gap between actual throughput and the claimed million-level performance. Five types of contract vulnerabilities are identified in the smart contract dimension, and four mainstream vulnerability detection platforms are introduced and comparatively analyzed. In terms of behavioral security, four real-world attacks targeting the structural characteristics of EOS are summarized. This study contributes to the ongoing development of the EOS blockchain and provides valuable insights for enhancing the security and regulatory mechanisms of blockchain ecosystems.","authors":["Haiyang Liu","Yingjie Mao","Xiaoqi Li"],"url":"https://arxiv.org/abs/2505.15051"}
{"created":"2025-05-22","title":"Owicki--Gries Logic for Timestamp Semantics","abstract":"Whereas an extension with non-interference of Hoare logic for sequential programs Owicki--Gries logic ensures the correctness of concurrent programs on strict consistency, it is unsound to weak memory models adopted by modern computer architectures and specifications of programming languages. This paper proposes a novel non-interference notion and provides concurrent program logic sound to timestamp semantics corresponding to a weak memory model that allows delays in the effects of store instructions. This paper reports three theoretically interesting techniques for modifying non-interference to support delays in the effects of store instructions. The techniques contribute to a better understanding of constructing concurrent program logic.","authors":["Tatsuya Abe"],"url":"https://arxiv.org/abs/2505.15053"}
{"created":"2025-05-22","title":"MolLangBench: A Comprehensive Benchmark for Language-Prompted Molecular Structure Recognition, Editing, and Generation","abstract":"Precise recognition, editing, and generation of molecules are essential prerequisites for both chemists and AI systems tackling various chemical tasks. We present MolLangBench, a comprehensive benchmark designed to evaluate fundamental molecule-language interface tasks: language-prompted molecular structure recognition, editing, and generation. To ensure high-quality, unambiguous, and deterministic outputs, we construct the recognition tasks using automated cheminformatics tools, and curate editing and generation tasks through rigorous expert annotation and validation. MolLangBench supports the evaluation of models that interface language with different molecular representations, including linear strings, molecular images, and molecular graphs. Evaluations of state-of-the-art models reveal significant limitations: the strongest model (o3) achieves $79.2\\%$ and $78.5\\%$ accuracy on recognition and editing tasks, which are intuitively simple for humans, and performs even worse on the generation task, reaching only $29.0\\%$ accuracy. These results highlight the shortcomings of current AI systems in handling even preliminary molecular recognition and manipulation tasks. We hope MolLangBench will catalyze further research toward more effective and reliable AI systems for chemical applications.","authors":["Feiyang Cai","Jiahui Bai","Tao Tang","Joshua Luo","Tianyu Zhu","Ling Liu","Feng Luo"],"url":"https://arxiv.org/abs/2505.15054"}
{"created":"2025-05-22","title":"Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory","abstract":"The evaluation of large language models (LLMs) via benchmarks is widespread, yet inconsistencies between different leaderboards and poor separability among top models raise concerns about their ability to accurately reflect authentic model capabilities. This paper provides a critical analysis of benchmark effectiveness, examining main-stream prominent LLM benchmarks using results from diverse models. We first propose a new framework for accurate and reliable estimations of item characteristics and model abilities. Specifically, we propose Pseudo-Siamese Network for Item Response Theory (PSN-IRT), an enhanced Item Response Theory framework that incorporates a rich set of item parameters within an IRT-grounded architecture. Based on PSN-IRT, we conduct extensive analysis which reveals significant and varied shortcomings in the measurement quality of current benchmarks. Furthermore, we demonstrate that leveraging PSN-IRT is able to construct smaller benchmarks while maintaining stronger alignment with human preference.","authors":["Hongli Zhou","Hui Huang","Ziqing Zhao","Lvyuan Han","Huicheng Wang","Kehai Chen","Muyun Yang","Wei Bao","Jian Dong","Bing Xu","Conghui Zhu","Hailong Cao","Tiejun Zhao"],"url":"https://arxiv.org/abs/2505.15055"}
{"created":"2025-05-22","title":"AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars","abstract":"Whole-body audio-driven avatar pose and expression generation is a critical task for creating lifelike digital humans and enhancing the capabilities of interactive virtual agents, with wide-ranging applications in virtual reality, digital entertainment, and remote communication. Existing approaches often generate audio-driven facial expressions and gestures independently, which introduces a significant limitation: the lack of seamless coordination between facial and gestural elements, resulting in less natural and cohesive animations. To address this limitation, we propose AsynFusion, a novel framework that leverages diffusion transformers to achieve harmonious expression and gesture synthesis. The proposed method is built upon a dual-branch DiT architecture, which enables the parallel generation of facial expressions and gestures. Within the model, we introduce a Cooperative Synchronization Module to facilitate bidirectional feature interaction between the two modalities, and an Asynchronous LCM Sampling strategy to reduce computational overhead while maintaining high-quality outputs. Extensive experiments demonstrate that AsynFusion achieves state-of-the-art performance in generating real-time, synchronized whole-body animations, consistently outperforming existing methods in both quantitative and qualitative evaluations.","authors":["Tianbao Zhang","Jian Zhao","Yuer Li","Zheng Zhu","Ping Hu","Zhaoxin Fan","Wenjun Wu","Xuelong Li"],"url":"https://arxiv.org/abs/2505.15058"}
{"created":"2025-05-22","title":"SHEET: A Multi-purpose Open-source Speech Human Evaluation Estimation Toolkit","abstract":"We introduce SHEET, a multi-purpose open-source toolkit designed to accelerate subjective speech quality assessment (SSQA) research. SHEET stands for the Speech Human Evaluation Estimation Toolkit, which focuses on data-driven deep neural network-based models trained to predict human-labeled quality scores of speech samples. SHEET provides comprehensive training and evaluation scripts, multi-dataset and multi-model support, as well as pre-trained models accessible via Torch Hub and HuggingFace Spaces. To demonstrate its capabilities, we re-evaluated SSL-MOS, a speech self-supervised learning (SSL)-based SSQA model widely used in recent scientific papers, on an extensive list of speech SSL models. Experiments were conducted on two representative SSQA datasets named BVCC and NISQA, and we identified the optimal speech SSL model, whose performance surpassed the original SSL-MOS implementation and was comparable to state-of-the-art methods.","authors":["Wen-Chin Huang","Erica Cooper","Tomoki Toda"],"url":"https://arxiv.org/abs/2505.15061"}
{"created":"2025-05-22","title":"Self-GIVE: Associative Thinking from Limited Structured Knowledge for Enhanced Large Language Model Reasoning","abstract":"When addressing complex questions that require new information, people often associate the question with existing knowledge to derive a sensible answer. For instance, when evaluating whether melatonin aids insomnia, one might associate \"hormones helping mental disorders\" with \"melatonin being a hormone and insomnia a mental disorder\" to complete the reasoning. Large Language Models (LLMs) also require such associative thinking, particularly in resolving scientific inquiries when retrieved knowledge is insufficient and does not directly answer the question. Graph Inspired Veracity Extrapolation (GIVE) addresses this by using a knowledge graph (KG) to extrapolate structured knowledge. However, it involves the construction and pruning of many hypothetical triplets, which limits efficiency and generalizability. We propose Self-GIVE, a retrieve-RL framework that enhances LLMs with automatic associative thinking through reinforcement learning. Self-GIVE extracts structured information and entity sets to assist the model in linking to the queried concepts. We address GIVE's key limitations: (1) extensive LLM calls and token overhead for knowledge extrapolation, (2) difficulty in deploying on smaller LLMs (3B or 7B) due to complex instructions, and (3) inaccurate knowledge from LLM pruning. Specifically, after fine-tuning using self-GIVE with a 135 node UMLS KG, it improves the performance of the Qwen2.5 3B and 7B models by up to $\\textbf{28.5%$\\rightarrow$71.4%}$ and $\\textbf{78.6$\\rightarrow$90.5%}$ in samples $\\textbf{unseen}$ in challenging biomedical QA tasks. In particular, Self-GIVE allows the 7B model to match or outperform GPT3.5 turbo with GIVE, while cutting token usage by over 90\\%. Self-GIVE enhances the scalable integration of structured retrieval and reasoning with associative thinking.","authors":["Jiashu He","Jinxuan Fan","Bowen Jiang","Ignacio Houine","Dan Roth","Alejandro Ribeiro"],"url":"https://arxiv.org/abs/2505.15062"}
{"created":"2025-05-22","title":"UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking","abstract":"The rapid use of large language models (LLMs) has raised critical concerns regarding the factual reliability of their outputs, especially in low-resource languages such as Urdu. Existing automated fact-checking solutions overwhelmingly focus on English, leaving a significant gap for the 200+ million Urdu speakers worldwide. In this work, we introduce UrduFactCheck, the first comprehensive, modular fact-checking framework specifically tailored for Urdu. Our system features a dynamic, multi-strategy evidence retrieval pipeline that combines monolingual and translation-based approaches to address the scarcity of high-quality Urdu evidence. We curate and release two new hand-annotated benchmarks: UrduFactBench for claim verification and UrduFactQA for evaluating LLM factuality. Extensive experiments demonstrate that UrduFactCheck, particularly its translation-augmented variants, consistently outperforms baselines and open-source alternatives on multiple metrics. We further benchmark twelve state-of-the-art (SOTA) LLMs on factual question answering in Urdu, highlighting persistent gaps between proprietary and open-source models. UrduFactCheck's code and datasets are open-sourced and publicly available at https://github.com/mbzuai-nlp/UrduFactCheck.","authors":["Sarfraz Ahmad","Hasan Iqbal","Momina Ahsan","Numaan Naeem","Muhammad Ahsan Riaz Khan","Arham Riaz","Muhammad Arslan Manzoor","Yuxia Wang","Preslav Nakov"],"url":"https://arxiv.org/abs/2505.15063"}
{"created":"2025-05-22","title":"Generalization Through Growth: Hidden Dynamics Controls Depth Dependence","abstract":"Recent theory has reduced the depth dependence of generalization bounds from exponential to polynomial and even depth-independent rates, yet these results remain tied to specific architectures and Euclidean inputs. We present a unified framework for arbitrary \\blue{pseudo-metric} spaces in which a depth-\\(k\\) network is the composition of continuous hidden maps \\(f:\\mathcal{X}\\to \\mathcal{X}\\) and an output map \\(h:\\mathcal{X}\\to \\mathbb{R}\\). The resulting bound $O(\\sqrt{(\\alpha + \\log \\beta(k))/n})$ isolates the sole depth contribution in \\(\\beta(k)\\), the word-ball growth of the semigroup generated by the hidden layers. By Gromov's theorem polynomial (resp. exponential) growth corresponds to virtually nilpotent (resp. expanding) dynamics, revealing a geometric dichotomy behind existing $O(\\sqrt{k})$ (sublinear depth) and $\\tilde{O}(1)$ (depth-independent) rates. We further provide covering-number estimates showing that expanding dynamics yield an exponential parameter saving via compositional expressivity. Our results decouple specification from implementation, offering architecture-agnostic and dynamical-systems-aware guarantees applicable to modern deep-learning paradigms such as test-time inference and diffusion models.","authors":["Sho Sonoda","Yuka Hashimoto","Isao Ishikawa","Masahiro Ikeda"],"url":"https://arxiv.org/abs/2505.15064"}
{"created":"2025-05-22","title":"The Pursuit of Empathy: Evaluating Small Language Models for PTSD Dialogue Support","abstract":"Can small language models with 0.5B to 5B parameters meaningfully engage in trauma-informed, empathetic dialogue for individuals with PTSD? We address this question by introducing TIDE, a dataset of 10,000 two-turn dialogues spanning 500 diverse PTSD client personas and grounded in a three-factor empathy model: emotion recognition, distress normalization, and supportive reflection. All scenarios and reference responses were reviewed for realism and trauma sensitivity by a clinical psychologist specializing in PTSD. We evaluate eight small language models before and after fine-tuning, comparing their outputs to a frontier model (Claude Sonnet 3.5). Our IRB-approved human evaluation and automatic metrics show that fine-tuning generally improves perceived empathy, but gains are highly scenario- and user-dependent, with smaller models facing an empathy ceiling. Demographic analysis shows older adults value distress validation and graduate-educated users prefer nuanced replies, while gender effects are minimal. We highlight the limitations of automatic metrics and the need for context- and user-aware system design. Our findings, along with the planned release of TIDE, provide a foundation for building safe, resource-efficient, and ethically sound empathetic AI to supplement, not replace, clinical mental health care.","authors":["Suhas BN","Yash Mahajan","Dominik Mattioli","Andrew M. Sherrill","Rosa I. Arriaga","Chris W. Wiese","Saeed Abdullah"],"url":"https://arxiv.org/abs/2505.15065"}
{"created":"2025-05-22","title":"Lawful but Awful: Evolving Legislative Responses to Address Online Misinformation, Disinformation, and Mal-Information in the Age of Generative AI","abstract":"\"Fake news\" is an old problem. In recent years, however, increasing usage of social media as a source of information, the spread of unverified medical advice during the Covid-19 pandemic, and the rise of generative artificial intelligence have seen a rush of legislative proposals seeking to minimize or mitigate the impact of false information spread online. Drawing on a novel dataset of statutes and other instruments, this article analyses changing perceptions about the potential harms caused by misinformation, disinformation, and \"mal-information\". The turn to legislation began in countries that were less free, in terms of civil liberties, and poorer, as measured by GDP per capita. Internet penetration does not seem to have been a driving factor. The focus of such laws is most frequently on national security broadly construed, though 2020 saw a spike in laws addressing public health. Unsurprisingly, governments with fewer legal constraints on government action have generally adopted more robust positions in dealing with false information. Despite early reservations, however, growth in such laws is now steepest in Western states. Though there are diverse views on the appropriate response to false information online, the need for legislation of some kind appears now to be global. The question is no longer whether to regulate \"lawful but awful\" speech online, but how.","authors":["Simon Chesterman"],"url":"https://arxiv.org/abs/2505.15067"}
{"created":"2025-05-22","title":"ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges","abstract":"Recent progress in large language models (LLMs) has enabled substantial advances in solving mathematical problems. However, existing benchmarks often fail to reflect the complexity of real-world problems, which demand open-ended, interdisciplinary reasoning and integration of computational tools. To address this gap, we introduce ModelingBench, a novel benchmark featuring real-world-inspired, open-ended problems from math modeling competitions across diverse domains, ranging from urban traffic optimization to ecosystem resource planning. These tasks require translating natural language into formal mathematical formulations, applying appropriate tools, and producing structured, defensible reports. ModelingBench also supports multiple valid solutions, capturing the ambiguity and creativity of practical modeling. We also present ModelingAgent, a multi-agent framework that coordinates tool use, supports structured workflows, and enables iterative self-refinement to generate well-grounded, creative solutions. To evaluate outputs, we further propose ModelingJudge, an expert-in-the-loop system leveraging LLMs as domain-specialized judges assessing solutions from multiple expert perspectives. Empirical results show that ModelingAgent substantially outperforms strong baselines and often produces solutions indistinguishable from those of human experts. Together, our work provides a comprehensive framework for evaluating and advancing real-world problem-solving in open-ended, interdisciplinary modeling challenges.","authors":["Cheng Qian","Hongyi Du","Hongru Wang","Xiusi Chen","Yuji Zhang","Avirup Sil","Chengxiang Zhai","Kathleen McKeown","Heng Ji"],"url":"https://arxiv.org/abs/2505.15068"}
{"created":"2025-05-22","title":"In-Domain African Languages Translation Using LLMs and Multi-armed Bandits","abstract":"Neural Machine Translation (NMT) systems face significant challenges when working with low-resource languages, particularly in domain adaptation tasks. These difficulties arise due to limited training data and suboptimal model generalization, As a result, selecting an optimal model for translation is crucial for achieving strong performance on in-domain data, particularly in scenarios where fine-tuning is not feasible or practical. In this paper, we investigate strategies for selecting the most suitable NMT model for a given domain using bandit-based algorithms, including Upper Confidence Bound, Linear UCB, Neural Linear Bandit, and Thompson Sampling. Our method effectively addresses the resource constraints by facilitating optimal model selection with high confidence. We evaluate the approach across three African languages and domains, demonstrating its robustness and effectiveness in both scenarios where target data is available and where it is absent.","authors":["Pratik Rakesh Singh","Kritarth Prasad","Mohammadi Zaki","Pankaj Wasnik"],"url":"https://arxiv.org/abs/2505.15069"}
{"created":"2025-05-22","title":"An Alternative to FLOPS Regularization to Effectively Productionize SPLADE-Doc","abstract":"Learned Sparse Retrieval (LSR) models encode text as weighted term vectors, which need to be sparse to leverage inverted index structures during retrieval. SPLADE, the most popular LSR model, uses FLOPS regularization to encourage vector sparsity during training. However, FLOPS regularization does not ensure sparsity among terms - only within a given query or document. Terms with very high Document Frequencies (DFs) substantially increase latency in production retrieval engines, such as Apache Solr, due to their lengthy posting lists. To address the issue of high DFs, we present a new variant of FLOPS regularization: DF-FLOPS. This new regularization technique penalizes the usage of high-DF terms, thereby shortening posting lists and reducing retrieval latency. Unlike other inference-time sparsification methods, such as stopword removal, DF-FLOPS regularization allows for the selective inclusion of high-frequency terms in cases where the terms are truly salient. We find that DF-FLOPS successfully reduces the prevalence of high-DF terms and lowers retrieval latency (around 10x faster) in a production-grade engine while maintaining effectiveness both in-domain (only a 2.2-point drop in MRR@10) and cross-domain (improved performance in 12 out of 13 tasks on which we tested). With retrieval latencies on par with BM25, this work provides an important step towards making LSR practical for deployment in production-grade search engines.","authors":["Aldo Porco","Dhruv Mehra","Igor Malioutov","Karthik Radhakrishnan","Moniba Keymanesh","Daniel Preo\\c{t}iuc-Pietro","Sean MacAvaney","Pengxiang Cheng"],"url":"https://arxiv.org/abs/2505.15070"}
{"created":"2025-05-22","title":"Can Large Language Models Understand Internet Buzzwords Through User-Generated Content","abstract":"The massive user-generated content (UGC) available in Chinese social media is giving rise to the possibility of studying internet buzzwords. In this paper, we study if large language models (LLMs) can generate accurate definitions for these buzzwords based on UGC as examples. Our work serves a threefold contribution. First, we introduce CHEER, the first dataset of Chinese internet buzzwords, each annotated with a definition and relevant UGC. Second, we propose a novel method, called RESS, to effectively steer the comprehending process of LLMs to produce more accurate buzzword definitions, mirroring the skills of human language learning. Third, with CHEER, we benchmark the strengths and weaknesses of various off-the-shelf definition generation methods and our RESS. Our benchmark demonstrates the effectiveness of RESS while revealing crucial shared challenges: over-reliance on prior exposure, underdeveloped inferential abilities, and difficulty identifying high-quality UGC to facilitate comprehension. We believe our work lays the groundwork for future advancements in LLM-based definition generation. Our dataset and code are available at https://github.com/SCUNLP/Buzzword.","authors":["Chen Huang","Junkai Luo","Xinzuo Wang","Wenqiang Lei","Jiancheng Lv"],"url":"https://arxiv.org/abs/2505.15071"}
{"created":"2025-05-22","title":"MoTime: A Dataset Suite for Multimodal Time Series Forecasting","abstract":"While multimodal data sources are increasingly available from real-world forecasting, most existing research remains on unimodal time series. In this work, we present MoTime, a suite of multimodal time series forecasting datasets that pair temporal signals with external modalities such as text, metadata, and images. Covering diverse domains, MoTime supports structured evaluation of modality utility under two scenarios: 1) the common forecasting task, where varying-length history is available, and 2) cold-start forecasting, where no historical data is available. Experiments show that external modalities can improve forecasting performance in both scenarios, with particularly strong benefits for short series in some datasets, though the impact varies depending on data characteristics. By making datasets and findings publicly available, we aim to support more comprehensive and realistic benchmarks in future multimodal time series forecasting research.","authors":["Xin Zhou","Weiqing Wang","Francisco J. Bald\\'an","Wray Buntine","Christoph Bergmeir"],"url":"https://arxiv.org/abs/2505.15072"}
{"created":"2025-05-22","title":"DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware Reinforcement Learning on Imbalanced Data","abstract":"Large Language Models (LLMs) are increasingly aligned with human preferences through Reinforcement Learning from Human Feedback (RLHF). Among RLHF methods, Group Relative Policy Optimization (GRPO) has gained attention for its simplicity and strong performance, notably eliminating the need for a learned value function. However, GRPO implicitly assumes a balanced domain distribution and uniform semantic alignment across groups - assumptions that rarely hold in real-world datasets. When applied to multi-domain, imbalanced data, GRPO disproportionately optimizes for dominant domains, neglecting underrepresented ones and resulting in poor generalization and fairness. We propose Domain-Informed Self-Consistency Policy Optimization (DISCO), a principled extension to GRPO that addresses inter-group imbalance with two key innovations. Domain-aware reward scaling counteracts frequency bias by reweighting optimization based on domain prevalence. Difficulty-aware reward scaling leverages prompt-level self-consistency to identify and prioritize uncertain prompts that offer greater learning value. Together, these strategies promote more equitable and effective policy learning across domains. Extensive experiments across multiple LLMs and skewed training distributions show that DISCO improves generalization, outperforms existing GRPO variants by 5% on Qwen3 models, and sets new state-of-the-art results on multi-domain alignment benchmarks.","authors":["Yuhang Zhou","Jing Zhu","Shengyi Qian","Zhuokai Zhao","Xiyao Wang","Xiaoyu Liu","Ming Li","Paiheng Xu","Wei Ai","Furong Huang"],"url":"https://arxiv.org/abs/2505.15074"}
{"created":"2025-05-22","title":"Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs","abstract":"The rapid evolution of multimodal large language models (MLLMs) has significantly enhanced their real-world applications. However, achieving consistent performance across languages, especially when integrating cultural knowledge, remains a significant challenge. To better assess this issue, we introduce two new benchmarks: KnowRecall and VisRecall, which evaluate cross-lingual consistency in MLLMs. KnowRecall is a visual question answering benchmark designed to measure factual knowledge consistency in 15 languages, focusing on cultural and historical questions about global landmarks. VisRecall assesses visual memory consistency by asking models to describe landmark appearances in 9 languages without access to images. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, still struggle to achieve cross-lingual consistency. This underscores the need for more robust approaches that produce truly multilingual and culturally aware models.","authors":["Hao Wang","Pinzhi Huang","Jihan Yang","Saining Xie","Daisuke Kawahara"],"url":"https://arxiv.org/abs/2505.15075"}
{"created":"2025-05-22","title":"Agentic Feature Augmentation: Unifying Selection and Generation with Teaming, Planning, and Memories","abstract":"As a widely-used and practical tool, feature engineering transforms raw data into discriminative features to advance AI model performance. However, existing methods usually apply feature selection and generation separately, failing to strive a balance between reducing redundancy and adding meaningful dimensions. To fill this gap, we propose an agentic feature augmentation concept, where the unification of feature generation and selection is modeled as agentic teaming and planning. Specifically, we develop a Multi-Agent System with Long and Short-Term Memory (MAGS), comprising a selector agent to eliminate redundant features, a generator agent to produce informative new dimensions, and a router agent that strategically coordinates their actions. We leverage in-context learning with short-term memory for immediate feedback refinement and long-term memory for globally optimal guidance. Additionally, we employ offline Proximal Policy Optimization (PPO) reinforcement fine-tuning to train the router agent for effective decision-making to navigate a vast discrete feature space. Extensive experiments demonstrate that this unified agentic framework consistently achieves superior task performance by intelligently orchestrating feature selection and generation.","authors":["Nanxu Gong","Sixun Dong","Haoyue Bai","Xinyuan Wang","Wangyang Ying","Yanjie Fu"],"url":"https://arxiv.org/abs/2505.15076"}
{"created":"2025-05-22","title":"Data Augmentation and Resolution Enhancement using GANs and Diffusion Models for Tree Segmentation","abstract":"Urban forests play a key role in enhancing environmental quality and supporting biodiversity in cities. Mapping and monitoring these green spaces are crucial for urban planning and conservation, yet accurately detecting trees is challenging due to complex landscapes and the variability in image resolution caused by different satellite sensors or UAV flight altitudes. While deep learning architectures have shown promise in addressing these challenges, their effectiveness remains strongly dependent on the availability of large and manually labeled datasets, which are often expensive and difficult to obtain in sufficient quantity. In this work, we propose a novel pipeline that integrates domain adaptation with GANs and Diffusion models to enhance the quality of low-resolution aerial images. Our proposed pipeline enhances low-resolution imagery while preserving semantic content, enabling effective tree segmentation without requiring large volumes of manually annotated data. Leveraging models such as pix2pix, Real-ESRGAN, Latent Diffusion, and Stable Diffusion, we generate realistic and structurally consistent synthetic samples that expand the training dataset and unify scale across domains. This approach not only improves the robustness of segmentation models across different acquisition conditions but also provides a scalable and replicable solution for remote sensing scenarios with scarce annotation resources. Experimental results demonstrated an improvement of over 50% in IoU for low-resolution images, highlighting the effectiveness of our method compared to traditional pipelines.","authors":["Alessandro dos Santos Ferreira","Ana Paula Marques Ramos","Jos\\'e Marcato Junior","Wesley Nunes Gon\\c{c}alves"],"url":"https://arxiv.org/abs/2505.15077"}
{"created":"2025-05-22","title":"SUS backprop: linear backpropagation algorithm for long inputs in transformers","abstract":"It is straightforward to design an unbiased gradient estimator that stochastically cuts the backpropagation flow through any part of a computational graph. By cutting the parts that have little effect on the computation, one can potentially save a significant amount of back-propagation computation in exchange for a minimal increase in the stochastic gradient variance, in some situations. Such a situation occurs in the attention mechanism of the transformer architecture. For long sequences, attention becomes the limiting factor, as its compute requirements increase quadratically with sequence length $n$. At the same time, most attention weights become very small, as most attention heads tend to connect a given token with only a small fraction of other tokens in the sequence. These weights become promising targets for cutting backpropagation. We propose a simple probabilistic rule controlled by a single parameter $c$ that cuts backpropagation through most attention weights, leaving at most $c$ interactions per token per attention head. This brings a factor of $c/n$ reduction in the compute required for the attention backpropagation, turning it from quadratic $O(n^2)$ to linear complexity $O(nc)$. We have empirically verified that, for a typical transformer model, cutting $99\\%$ of the attention gradient flow (i.e. choosing $c \\sim 20-30$) results in relative gradient variance increase of only about $1\\%$ for $n \\sim 2000$, and it decreases with $n$. This approach is amenable to efficient sparse matrix implementation, thus being promising for making the cost of a backward pass negligible relative to the cost of a forward pass when training a transformer model on long sequences.","authors":["Sergey Pankov","Georges Harik"],"url":"https://arxiv.org/abs/2505.15080"}
{"created":"2025-05-22","title":"Robust Multi-Modal Forecasting: Integrating Static and Dynamic Features","abstract":"Time series forecasting plays a crucial role in various applications, particularly in healthcare, where accurate predictions of future health trajectories can significantly impact clinical decision-making. Ensuring transparency and explainability of the models responsible for these tasks is essential for their adoption in critical settings. Recent work has explored a top-down approach to bi-level transparency, focusing on understanding trends and properties of predicted time series using static features. In this work, we extend this framework by incorporating exogenous time series features alongside static features in a structured manner, while maintaining cohesive interpretation. Our approach leverages the insights of trajectory comprehension to introduce an encoding mechanism for exogenous time series, where they are decomposed into meaningful trends and properties, enabling the extraction of interpretable patterns. Through experiments on several synthetic datasets, we demonstrate that our approach remains predictive while preserving interpretability and robustness. This work represents a step towards developing robust, and generalized time series forecasting models. The code is available at https://github.com/jeremy-qin/TIMEVIEW","authors":["Jeremy Qin"],"url":"https://arxiv.org/abs/2505.15083"}
{"created":"2025-05-22","title":"A Neural Network Approach to a Modified Quadratic Boost Multiport Resonant Converter for Electric Vehicle Chargers","abstract":"This topology can achieve a high step-up gain by utilizing a switched capacitor and switched inductor-based VMC network arrangement.Furthermore, the proposed topology can achieve an output gain of approximately three times at a nominal duty ratio with reduced voltage and current stress across the switch, and enhance the maximum efficiency to 96.7","authors":["V. Rajeswari","Nalin Kant Mohanty"],"url":"https://arxiv.org/abs/2505.15086"}
{"created":"2025-05-22","title":"HopWeaver: Synthesizing Authentic Multi-Hop Questions Across Text Corpora","abstract":"Multi-Hop Question Answering (MHQA) is crucial for evaluating the model's capability to integrate information from diverse sources. However, creating extensive and high-quality MHQA datasets is challenging: (i) manual annotation is expensive, and (ii) current synthesis methods often produce simplistic questions or require extensive manual guidance. This paper introduces HopWeaver, the first automatic framework synthesizing authentic multi-hop questions from unstructured text corpora without human intervention. HopWeaver synthesizes two types of multi-hop questions (bridge and comparison) using an innovative approach that identifies complementary documents across corpora. Its coherent pipeline constructs authentic reasoning paths that integrate information across multiple documents, ensuring synthesized questions necessitate authentic multi-hop reasoning. We further present a comprehensive system for evaluating synthesized multi-hop questions. Empirical evaluations demonstrate that the synthesized questions achieve comparable or superior quality to human-annotated datasets at a lower cost. Our approach is valuable for developing MHQA datasets in specialized domains with scarce annotated resources. The code for HopWeaver is publicly available.","authors":["Zhiyu Shen","Jiyuan Liu","Yunhe Pang","Yanghui Rao"],"url":"https://arxiv.org/abs/2505.15087"}
{"created":"2025-05-22","title":"Leveraging Large Language Models for Command Injection Vulnerability Analysis in Python: An Empirical Study on Popular Open-Source Projects","abstract":"Command injection vulnerabilities are a significant security threat in dynamic languages like Python, particularly in widely used open-source projects where security issues can have extensive impact. With the proven effectiveness of Large Language Models(LLMs) in code-related tasks, such as testing, researchers have explored their potential for vulnerabilities analysis. This study evaluates the potential of large language models (LLMs), such as GPT-4, as an alternative approach for automated testing for vulnerability detection. In particular, LLMs have demonstrated advanced contextual understanding and adaptability, making them promising candidates for identifying nuanced security vulnerabilities within code. To evaluate this potential, we applied LLM-based analysis to six high-profile GitHub projects-Django, Flask, TensorFlow, Scikit-learn, PyTorch, and Langchain-each with over 50,000 stars and extensive adoption across software development and academic research. Our analysis assesses both the strengths and limitations of LLMs in detecting command injection vulnerabilities, evaluating factors such as detection accuracy, efficiency, and practical integration into development workflows. In addition, we provide a comparative analysis of different LLM tools to identify those most suitable for security applications. Our findings offer guidance for developers and security researchers on leveraging LLMs as innovative and automated approaches to enhance software security.","authors":["Yuxuan Wang","Jingshu Chen","Qingyang Wang"],"url":"https://arxiv.org/abs/2505.15088"}
{"created":"2025-05-22","title":"Development of Digital Twin Environment through Integration of Commercial Metaverse Platform and IoT Sensors of Smart Building","abstract":"The digital transformation of smart cities and workplaces requires effective integration of physical and cyber spaces, yet existing digital twin solutions remain limited in supporting real-time, multi-user collaboration. While metaverse platforms enable shared virtual experiences, they have not supported comprehensive integration of IoT sensors on physical spaces, especially for large-scale smart architectural environments. This paper presents a digital twin environment that integrates Kajima Corp.'s smart building facility \"The GEAR\" in Singapore with a commercial metaverse platform Cluster. Our system consists of three key components: a standardized IoT sensor platform, a real-time data relay system, and an environmental data visualization framework. Quantitative end-to-end latency measurements confirm the feasibility of our approach for real-world applications in large architectural spaces. The proposed framework enables new forms of collaboration that transcend spatial constraints, advancing the development of next-generation interactive environments.","authors":["Yusuke Masubuchi","Takefumi Hiraki","Yuichi Hiroi","Masanori Ibara","Kazuki Matsutani","Megumi Zaizen","Junya Morita"],"url":"https://arxiv.org/abs/2505.15089"}
{"created":"2025-05-22","title":"DeFTX: Denoised Sparse Fine-Tuning for Zero-Shot Cross-Lingual Transfer","abstract":"Effective cross-lingual transfer remains a critical challenge in scaling the benefits of large language models from high-resource to low-resource languages. Towards this goal, prior studies have explored many approaches to combine task knowledge from task-specific data in a (high-resource) source language and language knowledge from unlabeled text in a (low-resource) target language. One notable approach proposed composable sparse fine-tuning (SFT) for cross-lingual transfer that learns task-specific and language-specific sparse masks to select a subset of the pretrained model's parameters that are further fine-tuned. These sparse fine-tuned vectors (SFTs) are subsequently composed with the pretrained model to facilitate zero-shot cross-lingual transfer to a task in a target language, using only task-specific data from a source language. These sparse masks for SFTs were identified using a simple magnitude-based pruning. In our work, we introduce DeFT-X, a novel composable SFT approach that denoises the weight matrices of a pretrained model before magnitude pruning using singular value decomposition, thus yielding more robust SFTs. We evaluate DeFT-X on a diverse set of extremely low-resource languages for sentiment classification (NusaX) and natural language inference (AmericasNLI) and demonstrate that it performs at par or outperforms SFT and other prominent cross-lingual transfer baselines.","authors":["Sona Elza Simon","Preethi Jyothi"],"url":"https://arxiv.org/abs/2505.15090"}
{"created":"2025-05-22","title":"ThinkRec: Thinking-based recommendation via LLM","abstract":"Recent advances in large language models (LLMs) have enabled more semantic-aware recommendations through natural language generation. Existing LLM for recommendation (LLM4Rec) methods mostly operate in a System 1-like manner, relying on superficial features to match similar items based on click history, rather than reasoning through deeper behavioral logic. This often leads to superficial and erroneous recommendations. Motivated by this, we propose ThinkRec, a thinking-based framework that shifts LLM4Rec from System 1 to System 2 (rational system). Technically, ThinkRec introduces a thinking activation mechanism that augments item metadata with keyword summarization and injects synthetic reasoning traces, guiding the model to form interpretable reasoning chains that consist of analyzing interaction histories, identifying user preferences, and making decisions based on target items. On top of this, we propose an instance-wise expert fusion mechanism to reduce the reasoning difficulty. By dynamically assigning weights to expert models based on users' latent features, ThinkRec adapts its reasoning path to individual users, thereby enhancing precision and personalization. Extensive experiments on real-world datasets demonstrate that ThinkRec significantly improves the accuracy and interpretability of recommendations. Our implementations are available in anonymous Github: https://anonymous.4open.science/r/ThinkRec_LLM.","authors":["Qihang Yu","Kairui Fu","Shengyu Zhang","Zheqi Lv","Fan Wu","Fei Wu"],"url":"https://arxiv.org/abs/2505.15091"}
{"created":"2025-05-22","title":"SciCUEval: A Comprehensive Dataset for Evaluating Scientific Context Understanding in Large Language Models","abstract":"Large Language Models (LLMs) have shown impressive capabilities in contextual understanding and reasoning. However, evaluating their performance across diverse scientific domains remains underexplored, as existing benchmarks primarily focus on general domains and fail to capture the intricate complexity of scientific data. To bridge this gap, we construct SciCUEval, a comprehensive benchmark dataset tailored to assess the scientific context understanding capability of LLMs. It comprises ten domain-specific sub-datasets spanning biology, chemistry, physics, biomedicine, and materials science, integrating diverse data modalities including structured tables, knowledge graphs, and unstructured texts. SciCUEval systematically evaluates four core competencies: Relevant information identification, Information-absence detection, Multi-source information integration, and Context-aware inference, through a variety of question formats. We conduct extensive evaluations of state-of-the-art LLMs on SciCUEval, providing a fine-grained analysis of their strengths and limitations in scientific context understanding, and offering valuable insights for the future development of scientific-domain LLMs.","authors":["Jing Yu","Yuqi Tang","Kehua Feng","Mingyang Rao","Lei Liang","Zhiqiang Zhang","Mengshu Sun","Wen Zhang","Qiang Zhang","Keyan Ding","Huajun Chen"],"url":"https://arxiv.org/abs/2505.15094"}
{"created":"2025-05-22","title":"Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English","abstract":"Sarcasm is a challenge to sentiment analysis because of the incongruity between stated and implied sentiment. The challenge is exacerbated when the implication may be relevant to a specific country or geographical region. Pragmatic metacognitive prompting (PMP) is a cognition-inspired technique that has been used for pragmatic reasoning. In this paper, we harness PMP for explainable sarcasm detection for Australian and Indian English, alongside a benchmark dataset for standard English. We manually add sarcasm explanations to an existing sarcasm-labeled dataset for Australian and Indian English called BESSTIE, and compare the performance for explainable sarcasm detection for them with FLUTE, a standard English dataset containing sarcasm explanations. Our approach utilising PMP when evaluated on two open-weight LLMs (GEMMA and LLAMA) achieves statistically significant performance improvement across all tasks and datasets when compared with four alternative prompting strategies. We also find that alternative techniques such as agentic prompting mitigate context-related failures by enabling external knowledge retrieval. The focused contribution of our work is utilising PMP in generating sarcasm explanations for varieties of English.","authors":["Ishmanbir Singh","Dipankar Srirag","Aditya Joshi"],"url":"https://arxiv.org/abs/2505.15095"}
{"created":"2025-05-22","title":"Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation","abstract":"Robot manipulation learning from human demonstrations offers a rapid means to acquire skills but often lacks generalization across diverse scenes and object placements. This limitation hinders real-world applications, particularly in complex tasks requiring dexterous manipulation. Vision-Language-Action (VLA) paradigm leverages large-scale data to enhance generalization. However, due to data scarcity, VLA's performance remains limited. In this work, we introduce Object-Focus Actor (OFA), a novel, data-efficient approach for generalized dexterous manipulation. OFA exploits the consistent end trajectories observed in dexterous manipulation tasks, allowing for efficient policy training. Our method employs a hierarchical pipeline: object perception and pose estimation, pre-manipulation pose arrival and OFA policy execution. This process ensures that the manipulation is focused and efficient, even in varied backgrounds and positional layout. Comprehensive real-world experiments across seven tasks demonstrate that OFA significantly outperforms baseline methods in both positional and background generalization tests. Notably, OFA achieves robust performance with only 10 demonstrations, highlighting its data efficiency.","authors":["Yihang Li","Tianle Zhang","Xuelong Wei","Jiayi Li","Lin Zhao","Dongchi Huang","Zhirui Fang","Minhua Zheng","Wenjun Dai","Xiaodong He"],"url":"https://arxiv.org/abs/2505.15098"}
{"created":"2025-05-22","title":"Runge-Kutta Methods and Stiff Order Conditions for Semilinear ODEs","abstract":"Classical convergence theory of Runge-Kutta methods assumes that the time step is small relative to the Lipschitz constant of the ordinary differential equation (ODE). For stiff problems, that assumption is often violated, and a problematic degradation in accuracy, known as order reduction, can arise. High stage order methods can avoid order reduction, but they must be fully implicit. For linear problems, weaker stiff order conditions exist and are compatible with computationally efficient methods, i.e., explicit or diagonally implicit. This work develops a new theory of stiff order conditions and convergence for semilinear ODEs, consisting of a stiff linear term and a non-stiff nonlinear term. New semilinear order conditions are formulated in terms of orthogonality relations enumerated by rooted trees. Novel, optimized diagonally implicit methods are constructed that satisfy these semilinear conditions. Numerical results demonstrate that for a broad class of relevant nonlinear test problems, these new methods successfully mitigate order reduction and yield highly accurate numerical approximations.","authors":["Steven B. Roberts","David Shirokoff","Abhijit Biswas","Benjamin Seibold"],"url":"https://arxiv.org/abs/2505.15099"}
{"created":"2025-05-22","title":"Cost-aware LLM-based Online Dataset Annotation","abstract":"Recent advances in large language models (LLMs) have enabled automated dataset labeling with minimal human supervision. While majority voting across multiple LLMs can improve label reliability by mitigating individual model biases, it incurs high computational costs due to repeated querying. In this work, we propose a novel online framework, Cost-aware Majority Voting (CaMVo), for efficient and accurate LLM-based dataset annotation. CaMVo adaptively selects a subset of LLMs for each data instance based on contextual embeddings, balancing confidence and cost without requiring pre-training or ground-truth labels. Leveraging a LinUCB-based selection mechanism and a Bayesian estimator over confidence scores, CaMVo estimates a lower bound on labeling accuracy for each LLM and aggregates responses through weighted majority voting. Our empirical evaluation on the MMLU and IMDB Movie Review datasets demonstrates that CaMVo achieves comparable or superior accuracy to full majority voting while significantly reducing labeling costs. This establishes CaMVo as a practical and robust solution for cost-efficient annotation in dynamic labeling environments.","authors":["Eray Can Elumar","Cem Tekin","Osman Yagan"],"url":"https://arxiv.org/abs/2505.15101"}
{"created":"2025-05-22","title":"Khan-GCL: Kolmogorov-Arnold Network Based Graph Contrastive Learning with Hard Negatives","abstract":"Graph contrastive learning (GCL) has demonstrated great promise for learning generalizable graph representations from unlabeled data. However, conventional GCL approaches face two critical limitations: (1) the restricted expressive capacity of multilayer perceptron (MLP) based encoders, and (2) suboptimal negative samples that either from random augmentations-failing to provide effective 'hard negatives'-or generated hard negatives without addressing the semantic distinctions crucial for discriminating graph data. To this end, we propose Khan-GCL, a novel framework that integrates the Kolmogorov-Arnold Network (KAN) into the GCL encoder architecture, substantially enhancing its representational capacity. Furthermore, we exploit the rich information embedded within KAN coefficient parameters to develop two novel critical feature identification techniques that enable the generation of semantically meaningful hard negative samples for each graph representation. These strategically constructed hard negatives guide the encoder to learn more discriminative features by emphasizing critical semantic differences between graphs. Extensive experiments demonstrate that our approach achieves state-of-the-art performance compared to existing GCL methods across a variety of datasets and tasks.","authors":["Zihu Wang","Boxun Xu","Hejia Geng","Peng Li"],"url":"https://arxiv.org/abs/2505.15103"}
{"created":"2025-05-22","title":"Mechanistic evaluation of Transformers and state space models","abstract":"State space models (SSMs) for language modelling promise an efficient and performant alternative to quadratic-attention Transformers, yet show variable performance on recalling basic information from the context. While performance on synthetic tasks like Associative Recall (AR) can point to this deficiency, behavioural metrics provide little information as to why--on a mechanistic level--certain architectures fail and others succeed. To address this, we conduct experiments on AR and find that only Transformers and Based SSM models fully succeed at AR, with Mamba a close third, whereas the other SSMs (H3, Hyena) fail. We then use causal interventions to explain why. We find that Transformers and Based learn to store key-value associations in-context using induction heads. By contrast, the SSMs compute these associations only at the last state, with only Mamba succeeding because of its short convolution component. To extend and deepen these findings, we introduce Associative Treecall (ATR), a synthetic task similar to AR based on PCFG induction. ATR introduces language-like hierarchical structure into the AR setting. We find that all architectures learn the same mechanism as they did for AR, and the same three models succeed at the task. These results reveal that architectures with similar accuracy may still have substantive differences, motivating the adoption of mechanistic evaluations.","authors":["Aryaman Arora","Neil Rathi","Nikil Roashan Selvam","R\\'obert Cs\\'ordas","Dan Jurafsky","Christopher Potts"],"url":"https://arxiv.org/abs/2505.15105"}
{"created":"2025-05-22","title":"A coupled HDG discretization for the interaction between acoustic and elastic waves","abstract":"We propose and analyze an HDG scheme for the Laplace-domain interaction between a transient acoustic wave and a bounded elastic solid embedded in an unbounded fluid medium. Two mixed variables (the stress tensor and the velocity of the acoustic wave) are included while the symmetry of the stress tensor is imposed weakly by considering the antisymmetric part of the strain tensor (the spin or vorticity tensor) as an additional unknown. The optimal convergence of the method is demonstrated theoretically and numerical results confirming the theoretical prediction are presented.","authors":["Fernando Artaza-Covarrubias","Tonatiuh S\\'anchez-Vizuet","Manuel Solano"],"url":"https://arxiv.org/abs/2505.15106"}
{"created":"2025-05-22","title":"StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization","abstract":"Efficient multi-hop reasoning requires Large Language Models (LLMs) based agents to acquire high-value external knowledge iteratively. Previous work has explored reinforcement learning (RL) to train LLMs to perform search-based document retrieval, achieving notable improvements in QA performance, but underperform on complex, multi-hop QA resulting from the sparse rewards from global signal only. To address this gap in existing research, we introduce StepSearch, a framework for search LLMs that trained with step-wise proximal policy optimization method. It consists of richer and more detailed intermediate search rewards and token-level process supervision based on information gain and redundancy penalties to better guide each search step. We constructed a fine-grained question-answering dataset containing sub-question-level search trajectories based on open source datasets through a set of data pipeline method. On standard multi-hop QA benchmarks, it significantly outperforms global-reward baselines, achieving 11.2% and 4.2% absolute improvements for 3B and 7B models over various search with RL baselines using only 19k training data, demonstrating the effectiveness of fine-grained, stepwise supervision in optimizing deep search LLMs. Our implementation is publicly available at https://github.com/zxh20001117/StepSearch.","authors":["Ziliang Wang","Xuhui Zheng","Kang An","Cijun Ouyang","Jialu Cai","Yuhang Wang","Yichao Wu"],"url":"https://arxiv.org/abs/2505.15107"}
{"created":"2025-05-22","title":"A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents","abstract":"The proliferation of Large Language Models (LLMs) and Intelligent Virtual Agents acting as psychotherapists presents significant opportunities for expanding mental healthcare access. However, their deployment has also been linked to serious adverse outcomes, including user harm and suicide, facilitated by a lack of standardized evaluation methodologies capable of capturing the nuanced risks of therapeutic interaction. Current evaluation techniques lack the sensitivity to detect subtle changes in patient cognition and behavior during therapy sessions that may lead to subsequent decompensation. We introduce a novel risk taxonomy specifically designed for the systematic evaluation of conversational AI psychotherapists. Developed through an iterative process including review of the psychotherapy risk literature, qualitative interviews with clinical and legal experts, and alignment with established clinical criteria (e.g., DSM-5) and existing assessment tools (e.g., NEQ, UE-ATR), the taxonomy aims to provide a structured approach to identifying and assessing user/patient harms. We provide a high-level overview of this taxonomy, detailing its grounding, and discuss potential use cases. We discuss two use cases in detail: monitoring cognitive model-based risk factors during a counseling conversation to detect unsafe deviations, in both human-AI counseling sessions and in automated benchmarking of AI psychotherapists with simulated patients. The proposed taxonomy offers a foundational step towards establishing safer and more responsible innovation in the domain of AI-driven mental health support.","authors":["Ian Steenstra","Timothy W. Bickmore"],"url":"https://arxiv.org/abs/2505.15108"}
{"created":"2025-05-22","title":"Comparing Parameterizations and Objective Functions for Maximizing the Volume of Zonotopic Invariant Sets","abstract":"In formal safety verification, many proposed algorithms use parametric set representations and convert the computation of the relevant sets into an optimization problem; consequently, the choice of parameterization and objective function have a significant impact on the efficiency and accuracy of the resulting computation. In particular, recent papers have explored the use of zonotope set representations for various types of invariant sets. In this paper we collect two zonotope parameterizations that are numerically well-behaved and demonstrate that the volume of the corresponding zonotopes is log-concave in the parameters. We then experimentally explore the use of these two parameterizations in an algorithm for computing the maximum volume zonotope invariant under affine dynamics within a specified box constraint over a finite horizon. The true volume of the zonotopes is used as an objective function, along with two alternative heuristics that are faster to compute. We conclude that the heuristics are much faster in practice, although the relative quality of their results declines as the dimension of the problem increases; however, our conclusions are only preliminary due to so-far limited availability of compute resources.","authors":["Chenliang Zhou","Heejin Ahn","Ian M. Mitchell"],"url":"https://arxiv.org/abs/2505.15109"}
{"created":"2025-05-22","title":"RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals","abstract":"The table reasoning task, crucial for efficient data acquisition, aims to answer questions based on the given table. Recently, reasoning large language models (RLLMs) with Long Chain-of-Thought (Long CoT) significantly enhance reasoning capabilities, leading to brilliant performance on table reasoning. However, Long CoT suffers from high cost for training and exhibits low reliability due to table content hallucinations. Therefore, we propose Row-of-Thought (RoT), which performs iteratively row-wise table traversal, allowing for reasoning extension and reflection-based refinement at each traversal. Scaling reasoning length by row-wise traversal and leveraging reflection capabilities of LLMs, RoT is training-free. The sequential traversal encourages greater attention to the table, thus reducing hallucinations. Experiments show that RoT, using non-reasoning models, outperforms RLLMs by an average of 4.3%, and achieves state-of-the-art results on WikiTableQuestions and TableBench with comparable models, proving its effectiveness. Also, RoT outperforms Long CoT with fewer reasoning tokens, indicating higher efficiency.","authors":["Xuanliang Zhang","Dingzirui Wang","Keyan Xu","Qingfu Zhu","Wanxiang Che"],"url":"https://arxiv.org/abs/2505.15110"}
{"created":"2025-05-22","title":"iPad: Iterative Proposal-centric End-to-End Autonomous Driving","abstract":"End-to-end (E2E) autonomous driving systems offer a promising alternative to traditional modular pipelines by reducing information loss and error accumulation, with significant potential to enhance both mobility and safety. However, most existing E2E approaches directly generate plans based on dense bird's-eye view (BEV) grid features, leading to inefficiency and limited planning awareness. To address these limitations, we propose iterative Proposal-centric autonomous driving (iPad), a novel framework that places proposals - a set of candidate future plans - at the center of feature extraction and auxiliary tasks. Central to iPad is ProFormer, a BEV encoder that iteratively refines proposals and their associated features through proposal-anchored attention, effectively fusing multi-view image data. Additionally, we introduce two lightweight, proposal-centric auxiliary tasks - mapping and prediction - that improve planning quality with minimal computational overhead. Extensive experiments on the NAVSIM and CARLA Bench2Drive benchmarks demonstrate that iPad achieves state-of-the-art performance while being significantly more efficient than prior leading methods.","authors":["Ke Guo","Haochen Liu","Xiaojun Wu","Jia Pan","Chen Lv"],"url":"https://arxiv.org/abs/2505.15111"}
{"created":"2025-05-22","title":"Parallel Scan on Ascend AI Accelerators","abstract":"We design and implement parallel prefix sum (scan) algorithms using Ascend AI accelerators. Ascend accelerators feature specialized computing units - the cube units for efficient matrix multiplication and the vector units for optimized vector operations. A key feature of the proposed scan algorithms is their extensive use of matrix multiplications and accumulations enabled by the cube unit. To showcase the effectiveness of these algorithms, we also implement and evaluate several scan-based operators commonly used in AI workloads, including sorting, tensor masking, and top-$k$ / top-$p$ sampling.","authors":["Bart{\\l}omiej Wr\\'oblewski","Gioele Gottardo","Anastasios Zouzias"],"url":"https://arxiv.org/abs/2505.15112"}
{"created":"2025-05-22","title":"Graph Foundation Models: A Comprehensive Survey","abstract":"Graph-structured data pervades domains such as social networks, biological systems, knowledge graphs, and recommender systems. While foundation models have transformed natural language processing, vision, and multimodal learning through large-scale pretraining and generalization, extending these capabilities to graphs -- characterized by non-Euclidean structures and complex relational semantics -- poses unique challenges and opens new opportunities. To this end, Graph Foundation Models (GFMs) aim to bring scalable, general-purpose intelligence to structured data, enabling broad transfer across graph-centric tasks and domains. This survey provides a comprehensive overview of GFMs, unifying diverse efforts under a modular framework comprising three key components: backbone architectures, pretraining strategies, and adaptation mechanisms. We categorize GFMs by their generalization scope -- universal, task-specific, and domain-specific -- and review representative methods, key innovations, and theoretical insights within each category. Beyond methodology, we examine theoretical foundations including transferability and emergent capabilities, and highlight key challenges such as structural alignment, heterogeneity, scalability, and evaluation. Positioned at the intersection of graph learning and general-purpose AI, GFMs are poised to become foundational infrastructure for open-ended reasoning over structured data. This survey consolidates current progress and outlines future directions to guide research in this rapidly evolving field. Resources are available at https://github.com/Zehong-Wang/Awesome-Foundation-Models-on-Graphs.","authors":["Zehong Wang","Zheyuan Liu","Tianyi Ma","Jiazheng Li","Zheyuan Zhang","Xingbo Fu","Yiyang Li","Zhengqing Yuan","Wei Song","Yijun Ma","Qingkai Zeng","Xiusi Chen","Jianan Zhao","Jundong Li","Meng Jiang","Pietro Lio","Nitesh Chawla","Chuxu Zhang","Yanfang Ye"],"url":"https://arxiv.org/abs/2505.15116"}
{"created":"2025-05-22","title":"An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents","abstract":"Reinforcement learning (RL) has demonstrated strong potential in training large language models (LLMs) capable of complex reasoning for real-world problem solving. More recently, RL has been leveraged to create sophisticated LLM-based search agents that adeptly combine reasoning with search engine use. While the use of RL for training search agents is promising, the optimal design of such agents remains not fully understood. In particular, key factors -- such as (1) reward formulation, (2) the choice and characteristics of the underlying LLM, and (3) the role of the search engine in the RL process -- require further investigation. In this work, we conduct comprehensive empirical studies to systematically investigate these and offer actionable insights. We highlight several key findings: format rewards are effective in improving final performance, whereas intermediate retrieval rewards have limited impact; the scale and initialization of the LLM (general-purpose vs. reasoning-specialized) significantly influence RL outcomes; and the choice of search engine plays a critical role in shaping RL training dynamics and the robustness of the trained agent during inference. These establish important guidelines for successfully building and deploying LLM-based search agents in real-world applications. Code is available at https://github.com/PeterGriffinJin/Search-R1.","authors":["Bowen Jin","Jinsung Yoon","Priyanka Kargupta","Sercan O. Arik","Jiawei Han"],"url":"https://arxiv.org/abs/2505.15117"}
{"created":"2025-05-22","title":"Maximum Degree-Based Quasi-Clique Search via an Iterative Framework","abstract":"Cohesive subgraph mining is a fundamental problem in graph theory with numerous real-world applications, such as social network analysis and protein-protein interaction modeling. Among various cohesive subgraphs, the $\\gamma$-quasi-clique is widely studied for its flexibility in requiring each vertex to connect to at least a $\\gamma$ proportion of other vertices in the subgraph. However, solving the maximum $\\gamma$-quasi-clique problem is NP-hard and further complicated by the lack of the hereditary property, which makes designing efficient pruning strategies challenging. Existing algorithms, such as DDA and FastQC, either struggle with scalability or exhibit significant performance declines for small values of $\\gamma$. In this paper, we propose a novel algorithm, IterQC, which reformulates the maximum $\\gamma$-quasi-clique problem as a series of $k$-plex problems that possess the hereditary property. IterQC introduces a non-trivial iterative framework and incorporates two key optimization techniques: (1) the pseudo lower bound (pseudo LB) technique, which leverages information across iterations to improve the efficiency of branch-and-bound searches, and (2) the preprocessing technique that reduces problem size and unnecessary iterations. Extensive experiments demonstrate that IterQC achieves up to four orders of magnitude speedup and solves significantly more graph instances compared to state-of-the-art algorithms DDA and FastQC.","authors":["Hongbo Xia","Kaiqiang Yu","Shengxin Liu","Cheng Long","Xun Zhou"],"url":"https://arxiv.org/abs/2505.15118"}
{"created":"2025-05-22","title":"[Exploring Dynamic Load Balancing Algorithms] {Exploring Dynamic Load Balancing Algorithms for Block-Structured Mesh-and-Particle Simulations in AMReX}","abstract":"Load balancing is critical for successful large-scale high-performance computing (HPC) simulations. With modern supercomputers increasing in complexity and variability, dynamic load balancing is becoming more critical to use computational resources efficiently. In this study, performed during a summer collaboration at Lawrence Berkeley National Laboratory, we investigate various standard dynamic load-balancing algorithms. This includes the time evaluation of a brute-force solve for application in algorithmic evaluation, as well as quality and time evaluations of the Knapsack algorithm, an SFC algorithm, and two novel algorithms: a painter's partition-based SFC algorithm and a combination Knapsack+SFC methodology-based on hardware topology. The results suggest Knapsack and painter's partition-based algorithms should be among the first algorithms evaluated by HPC codes for cases with limited weight deviation and will perform at least slightly better than AMReX's percentage-tracking partitioning strategy across most simulations, although effects diminish as weight variety increases.","authors":["Amitash Nanda","Md Kamal Hossain Chowdhury","Hannah Ross","Kevin Gott"],"url":"https://arxiv.org/abs/2505.15122"}
{"created":"2025-05-22","title":"Seeing the Trees for the Forest: Rethinking Weakly-Supervised Medical Visual Grounding","abstract":"Visual grounding (VG) is the capability to identify the specific regions in an image associated with a particular text description. In medical imaging, VG enhances interpretability by highlighting relevant pathological features corresponding to textual descriptions, improving model transparency and trustworthiness for wider adoption of deep learning models in clinical practice. Current models struggle to associate textual descriptions with disease regions due to inefficient attention mechanisms and a lack of fine-grained token representations. In this paper, we empirically demonstrate two key observations. First, current VLMs assign high norms to background tokens, diverting the model's attention from regions of disease. Second, the global tokens used for cross-modal learning are not representative of local disease tokens. This hampers identifying correlations between the text and disease tokens. To address this, we introduce simple, yet effective Disease-Aware Prompting (DAP) process, which uses the explainability map of a VLM to identify the appropriate image features. This simple strategy amplifies disease-relevant regions while suppressing background interference. Without any additional pixel-level annotations, DAP improves visual grounding accuracy by 20.74% compared to state-of-the-art methods across three major chest X-ray datasets.","authors":["Ta Duc Huy","Duy Anh Huynh","Yutong Xie","Yuankai Qi","Qi Chen","Phi Le Nguyen","Sen Kim Tran","Son Lam Phung","Anton van den Hengel","Zhibin Liao","Minh-Son To","Johan W. Verjans","Vu Minh Hieu Phan"],"url":"https://arxiv.org/abs/2505.15123"}
{"created":"2025-05-22","title":"A Survey On Secure Machine Learning","abstract":"In this survey, we will explore the interaction between secure multiparty computation and the area of machine learning. Recent advances in secure multiparty computation (MPC) have significantly improved its applicability in the realm of machine learning (ML), offering robust solutions for privacy-preserving collaborative learning. This review explores key contributions that leverage MPC to enable multiple parties to engage in ML tasks without compromising the privacy of their data. The integration of MPC with ML frameworks facilitates the training and evaluation of models on combined datasets from various sources, ensuring that sensitive information remains encrypted throughout the process. Innovations such as specialized software frameworks and domain-specific languages streamline the adoption of MPC in ML, optimizing performance and broadening its usage. These frameworks address both semi-honest and malicious threat models, incorporating features such as automated optimizations and cryptographic auditing to ensure compliance and data integrity. The collective insights from these studies highlight MPC's potential in fostering collaborative yet confidential data analysis, marking a significant stride towards the realization of secure and efficient computational solutions in privacy-sensitive industries. This paper investigates a spectrum of SecureML libraries that includes cryptographic protocols, federated learning frameworks, and privacy-preserving algorithms. By surveying the existing literature, this paper aims to examine the efficacy of these libraries in preserving data privacy, ensuring model confidentiality, and fortifying ML systems against adversarial attacks. Additionally, the study explores an innovative application domain for SecureML techniques: the integration of these methodologies in gaming environments utilizing ML.","authors":["Taobo Liao","Taoran Li","Prathamesh Nadkarni"],"url":"https://arxiv.org/abs/2505.15124"}
{"created":"2025-05-22","title":"Robust Relevance Feedback for Interactive Known-Item Video Search","abstract":"Known-item search (KIS) involves only a single search target, making relevance feedback-typically a powerful technique for efficiently identifying multiple positive examples to infer user intent-inapplicable. PicHunter addresses this issue by asking users to select the top-k most similar examples to the unique search target from a displayed set. Under ideal conditions, when the user's perception aligns closely with the machine's perception of similarity, consistent and precise judgments can elevate the target to the top position within a few iterations. However, in practical scenarios, expecting users to provide consistent judgments is often unrealistic, especially when the underlying embedding features used for similarity measurements lack interpretability. To enhance robustness, we first introduce a pairwise relative judgment feedback that improves the stability of top-k selections by mitigating the impact of misaligned feedback. Then, we decompose user perception into multiple sub-perceptions, each represented as an independent embedding space. This approach assumes that users may not consistently align with a single representation but are more likely to align with one or several among multiple representations. We develop a predictive user model that estimates the combination of sub-perceptions based on each user feedback instance. The predictive user model is then trained to filter out the misaligned sub-perceptions. Experimental evaluations on the large-scale open-domain dataset V3C indicate that the proposed model can optimize over 60% search targets to the top rank when their initial ranks at the search depth between 10 and 50. Even for targets initially ranked between 1,000 and 5,000, the model achieves a success rate exceeding 40% in optimizing ranks to the top, demonstrating the enhanced robustness of relevance feedback in KIS despite inconsistent feedback.","authors":["Zhixin Ma","Chong-Wah Ngo"],"url":"https://arxiv.org/abs/2505.15128"}
{"created":"2025-05-22","title":"Few-Shot Adversarial Low-Rank Fine-Tuning of Vision-Language Models","abstract":"Vision-Language Models (VLMs) such as CLIP have shown remarkable performance in cross-modal tasks through large-scale contrastive pre-training. To adapt these large transformer-based models efficiently for downstream tasks, Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRA have emerged as scalable alternatives to full fine-tuning, especially in few-shot scenarios. However, like traditional deep neural networks, VLMs are highly vulnerable to adversarial attacks, where imperceptible perturbations can significantly degrade model performance. Adversarial training remains the most effective strategy for improving model robustness in PEFT. In this work, we propose AdvCLIP-LoRA, the first algorithm designed to enhance the adversarial robustness of CLIP models fine-tuned with LoRA in few-shot settings. Our method formulates adversarial fine-tuning as a minimax optimization problem and provides theoretical guarantees for convergence under smoothness and nonconvex-strong-concavity assumptions. Empirical results across eight datasets using ViT-B/16 and ViT-B/32 models show that AdvCLIP-LoRA significantly improves robustness against common adversarial attacks (e.g., FGSM, PGD), without sacrificing much clean accuracy. These findings highlight AdvCLIP-LoRA as a practical and theoretically grounded approach for robust adaptation of VLMs in resource-constrained settings.","authors":["Sajjad Ghiasvand","Haniyeh Ehsani Oskouie","Mahnoosh Alizadeh","Ramtin Pedarsani"],"url":"https://arxiv.org/abs/2505.15130"}
{"created":"2025-05-22","title":"DeepKD: A Deeply Decoupled and Denoised Knowledge Distillation Trainer","abstract":"Recent advances in knowledge distillation have emphasized the importance of decoupling different knowledge components. While existing methods utilize momentum mechanisms to separate task-oriented and distillation gradients, they overlook the inherent conflict between target-class and non-target-class knowledge flows. Furthermore, low-confidence dark knowledge in non-target classes introduces noisy signals that hinder effective knowledge transfer. To address these limitations, we propose DeepKD, a novel training framework that integrates dual-level decoupling with adaptive denoising. First, through theoretical analysis of gradient signal-to-noise ratio (GSNR) characteristics in task-oriented and non-task-oriented knowledge distillation, we design independent momentum updaters for each component to prevent mutual interference. We observe that the optimal momentum coefficients for task-oriented gradient (TOG), target-class gradient (TCG), and non-target-class gradient (NCG) should be positively related to their GSNR. Second, we introduce a dynamic top-k mask (DTM) mechanism that gradually increases K from a small initial value to incorporate more non-target classes as training progresses, following curriculum learning principles. The DTM jointly filters low-confidence logits from both teacher and student models, effectively purifying dark knowledge during early training. Extensive experiments on CIFAR-100, ImageNet, and MS-COCO demonstrate DeepKD's effectiveness. Our code is available at https://github.com/haiduo/DeepKD.","authors":["Haiduo Huang","Jiangcheng Song","Yadong Zhang","Pengju Ren"],"url":"https://arxiv.org/abs/2505.15133"}
{"created":"2025-05-22","title":"The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning","abstract":"Entropy minimization (EM) trains the model to concentrate even more probability mass on its most confident outputs. We show that this simple objective alone, without any labeled data, can substantially improve large language models' (LLMs) performance on challenging math, physics, and coding tasks. We explore three approaches: (1) EM-FT minimizes token-level entropy similarly to instruction finetuning, but on unlabeled outputs drawn from the model; (2) EM-RL: reinforcement learning with negative entropy as the only reward to maximize; (3) EM-INF: inference-time logit adjustment to reduce entropy without any training data or parameter updates. On Qwen-7B, EM-RL, without any labeled data, achieves comparable or better performance than strong RL baselines such as GRPO and RLOO that are trained on 60K labeled examples. Furthermore, EM-INF enables Qwen-32B to match or exceed the performance of proprietary models like GPT-4o, Claude 3 Opus, and Gemini 1.5 Pro on the challenging SciCode benchmark, while being 3x more efficient than self-consistency and sequential refinement. Our findings reveal that many pretrained LLMs possess previously underappreciated reasoning capabilities that can be effectively elicited through entropy minimization alone, without any labeled data or even any parameter updates.","authors":["Shivam Agarwal","Zimin Zhang","Lifan Yuan","Jiawei Han","Hao Peng"],"url":"https://arxiv.org/abs/2505.15134"}
{"created":"2025-05-22","title":"Hybrid Audio Detection Using Fine-Tuned Audio Spectrogram Transformers: A Dataset-Driven Evaluation of Mixed AI-Human Speech","abstract":"The rapid advancement of artificial intelligence (AI) has enabled sophisticated audio generation and voice cloning technologies, posing significant security risks for applications reliant on voice authentication. While existing datasets and models primarily focus on distinguishing between human and fully synthetic speech, real-world attacks often involve audio that combines both genuine and cloned segments. To address this gap, we construct a novel hybrid audio dataset incorporating human, AI-generated, cloned, and mixed audio samples. We further propose fine-tuned Audio Spectrogram Transformer (AST)-based models tailored for detecting these complex acoustic patterns. Extensive experiments demonstrate that our approach significantly outperforms existing baselines in mixed-audio detection, achieving 97\\% classification accuracy. Our findings highlight the importance of hybrid datasets and tailored models in advancing the robustness of speech-based authentication systems.","authors":["Kunyang Huang","Bin Hu"],"url":"https://arxiv.org/abs/2505.15136"}
{"created":"2025-05-22","title":"Multispectral Detection Transformer with Infrared-Centric Sensor Fusion","abstract":"Multispectral object detection aims to leverage complementary information from visible (RGB) and infrared (IR) modalities to enable robust performance under diverse environmental conditions. In this letter, we propose IC-Fusion, a multispectral object detector that effectively fuses visible and infrared features through a lightweight and modalityaware design. Motivated by wavelet analysis and empirical observations, we find that IR images contain structurally rich high-frequency information critical for object localization, while RGB images provide complementary semantic context. To exploit this, we adopt a compact RGB backbone and design a novel fusion module comprising a Multi-Scale Feature Distillation (MSFD) block to enhance RGB features and a three-stage fusion block with Cross-Modal Channel Shuffle Gate (CCSG) and Cross-Modal Large Kernel Gate (CLKG) to facilitate effective cross-modal interaction. Experiments on the FLIR and LLVIP benchmarks demonstrate the effectiveness and efficiency of our IR-centric fusion strategy. Our code is available at https://github.com/smin-hwang/IC-Fusion.","authors":["Seongmin Hwang","Daeyoung Han","Moongu Jeon"],"url":"https://arxiv.org/abs/2505.15137"}
{"created":"2025-05-22","title":"Global Convergence for Average Reward Constrained MDPs with Primal-Dual Actor Critic Algorithm","abstract":"This paper investigates infinite-horizon average reward Constrained Markov Decision Processes (CMDPs) with general parametrization. We propose a Primal-Dual Natural Actor-Critic algorithm that adeptly manages constraints while ensuring a high convergence rate. In particular, our algorithm achieves global convergence and constraint violation rates of $\\tilde{\\mathcal{O}}(1/\\sqrt{T})$ over a horizon of length $T$ when the mixing time, $\\tau_{\\mathrm{mix}}$, is known to the learner. In absence of knowledge of $\\tau_{\\mathrm{mix}}$, the achievable rates change to $\\tilde{\\mathcal{O}}(1/T^{0.5-\\epsilon})$ provided that $T \\geq \\tilde{\\mathcal{O}}\\left(\\tau_{\\mathrm{mix}}^{2/\\epsilon}\\right)$. Our results match the theoretical lower bound for Markov Decision Processes and establish a new benchmark in the theoretical exploration of average reward CMDPs.","authors":["Yang Xu","Swetha Ganesh","Washim Uddin Mondal","Qinbo Bai","Vaneet Aggarwal"],"url":"https://arxiv.org/abs/2505.15138"}
{"created":"2025-05-22","title":"Unified Cross-Modal Attention-Mixer Based Structural-Functional Connectomics Fusion for Neuropsychiatric Disorder Diagnosis","abstract":"Gaining insights into the structural and functional mechanisms of the brain has been a longstanding focus in neuroscience research, particularly in the context of understanding and treating neuropsychiatric disorders such as Schizophrenia (SZ). Nevertheless, most of the traditional multimodal deep learning approaches fail to fully leverage the complementary characteristics of structural and functional connectomics data to enhance diagnostic performance. To address this issue, we proposed ConneX, a multimodal fusion method that integrates cross-attention mechanism and multilayer perceptron (MLP)-Mixer for refined feature fusion. Modality-specific backbone graph neural networks (GNNs) were firstly employed to obtain feature representation for each modality. A unified cross-modal attention network was then introduced to fuse these embeddings by capturing intra- and inter-modal interactions, while MLP-Mixer layers refined global and local features, leveraging higher-order dependencies for end-to-end classification with a multi-head joint loss. Extensive evaluations demonstrated improved performance on two distinct clinical datasets, highlighting the robustness of our proposed framework.","authors":["Badhan Mazumder","Lei Wu","Vince D. Calhoun","Dong Hye Ye"],"url":"https://arxiv.org/abs/2505.15139"}
{"created":"2025-05-22","title":"EC-LDA : Label Distribution Inference Attack against Federated Graph Learning with Embedding Compression","abstract":"Graph Neural Networks (GNNs) have been widely used for graph analysis. Federated Graph Learning (FGL) is an emerging learning framework to collaboratively train graph data from various clients. However, since clients are required to upload model parameters to the server in each round, this provides the server with an opportunity to infer each client's data privacy. In this paper, we focus on label distribution attacks(LDAs) that aim to infer the label distributions of the clients' local data. We take the first step to attack client's label distributions in FGL. Firstly, we observe that the effectiveness of LDA is closely related to the variance of node embeddings in GNNs. Next, we analyze the relation between them and we propose a new attack named EC-LDA, which significantly improves the attack effectiveness by compressing node embeddings. Thirdly, extensive experiments on node classification and link prediction tasks across six widely used graph datasets show that EC-LDA outperforms the SOTA LDAs. For example, EC-LDA attains optimal values under both Cos-sim and JS-div evaluation metrics in the CoraFull and LastFM datasets. Finally, we explore the robustness of EC-LDA under differential privacy protection.","authors":["Tong Cheng","Fu Jie","Xinpeng Ling","Huifa Li","Zhili Chen"],"url":"https://arxiv.org/abs/2505.15140"}
{"created":"2025-05-22","title":"BanditSpec: Adaptive Speculative Decoding via Bandit Algorithms","abstract":"Speculative decoding has emerged as a popular method to accelerate the inference of Large Language Models (LLMs) while retaining their superior text generation performance. Previous methods either adopt a fixed speculative decoding configuration regardless of the prefix tokens, or train draft models in an offline or online manner to align them with the context. This paper proposes a training-free online learning framework to adaptively choose the configuration of the hyperparameters for speculative decoding as text is being generated. We first formulate this hyperparameter selection problem as a Multi-Armed Bandit problem and provide a general speculative decoding framework BanditSpec. Furthermore, two bandit-based hyperparameter selection algorithms, UCBSpec and EXP3Spec, are designed and analyzed in terms of a novel quantity, the stopping time regret. We upper bound this regret under both stochastic and adversarial reward settings. By deriving an information-theoretic impossibility result, it is shown that the regret performance of UCBSpec is optimal up to universal constants. Finally, extensive empirical experiments with LLaMA3 and Qwen2 demonstrate that our algorithms are effective compared to existing methods, and the throughput is close to the oracle best hyperparameter in simulated real-life LLM serving scenarios with diverse input prompts.","authors":["Yunlong Hou","Fengzhuo Zhang","Cunxiao Du","Xuan Zhang","Jiachun Pan","Tianyu Pang","Chao Du","Vincent Y. F. Tan","Zhuoran Yang"],"url":"https://arxiv.org/abs/2505.15141"}
{"created":"2025-05-22","title":"Filtering Learning Histories Enhances In-Context Reinforcement Learning","abstract":"Transformer models (TMs) have exhibited remarkable in-context reinforcement learning (ICRL) capabilities, allowing them to generalize to and improve in previously unseen environments without re-training or fine-tuning. This is typically accomplished by imitating the complete learning histories of a source RL algorithm over a substantial amount of pretraining environments, which, however, may transfer suboptimal behaviors inherited from the source algorithm/dataset. Therefore, in this work, we address the issue of inheriting suboptimality from the perspective of dataset preprocessing. Motivated by the success of the weighted empirical risk minimization, we propose a simple yet effective approach, learning history filtering (LHF), to enhance ICRL by reweighting and filtering the learning histories based on their improvement and stability characteristics. To the best of our knowledge, LHF is the first approach to avoid source suboptimality by dataset preprocessing, and can be combined with the current state-of-the-art (SOTA) ICRL algorithms. We substantiate the effectiveness of LHF through a series of experiments conducted on the well-known ICRL benchmarks, encompassing both discrete environments and continuous robotic manipulation tasks, with three SOTA ICRL algorithms (AD, DPT, DICP) as the backbones. LHF exhibits robust performance across a variety of suboptimal scenarios, as well as under varying hyperparameters and sampling strategies. Notably, the superior performance of LHF becomes more pronounced in the presence of noisy data, indicating the significance of filtering learning histories.","authors":["Weiqin Chen","Xinjie Zhang","Dharmashankar Subramanian","Santiago Paternain"],"url":"https://arxiv.org/abs/2505.15143"}
{"created":"2025-05-22","title":"CineTechBench: A Benchmark for Cinematographic Technique Understanding and Generation","abstract":"Cinematography is a cornerstone of film production and appreciation, shaping mood, emotion, and narrative through visual elements such as camera movement, shot composition, and lighting. Despite recent progress in multimodal large language models (MLLMs) and video generation models, the capacity of current models to grasp and reproduce cinematographic techniques remains largely uncharted, hindered by the scarcity of expert-annotated data. To bridge this gap, we present CineTechBench, a pioneering benchmark founded on precise, manual annotation by seasoned cinematography experts across key cinematography dimensions. Our benchmark covers seven essential aspects-shot scale, shot angle, composition, camera movement, lighting, color, and focal length-and includes over 600 annotated movie images and 120 movie clips with clear cinematographic techniques. For the understanding task, we design question answer pairs and annotated descriptions to assess MLLMs' ability to interpret and explain cinematographic techniques. For the generation task, we assess advanced video generation models on their capacity to reconstruct cinema-quality camera movements given conditions such as textual prompts or keyframes. We conduct a large-scale evaluation on 15+ MLLMs and 5+ video generation models. Our results offer insights into the limitations of current models and future directions for cinematography understanding and generation in automatically film production and appreciation. The code and benchmark can be accessed at https://github.com/PRIS-CV/CineTechBench.","authors":["Xinran Wang","Songyu Xu","Xiangxuan Shan","Yuxuan Zhang","Muxi Diao","Xueyan Duan","Yanhua Huang","Kongming Liang","Zhanyu Ma"],"url":"https://arxiv.org/abs/2505.15145"}
{"created":"2025-05-22","title":"lmgame-Bench: How Good are LLMs at Playing Games?","abstract":"Playing video games requires perception, memory, and planning, exactly the faculties modern large language model (LLM) agents are expected to master. We study the major challenges in using popular video games to evaluate modern LLMs and find that directly dropping LLMs into games cannot make an effective evaluation, for three reasons -- brittle vision perception, prompt sensitivity, and potential data contamination. We introduce lmgame-Bench to turn games into reliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and narrative games delivered through a unified Gym-style API and paired with lightweight perception and memory scaffolds, and is designed to stabilize prompt variance and remove contamination. Across 13 leading models, we show lmgame-Bench is challenging while still separating models well. Correlation analysis shows that every game probes a unique blend of capabilities often tested in isolation elsewhere. More interestingly, performing reinforcement learning on a single game from lmgame-Bench transfers both to unseen games and to external planning tasks. Our evaluation code is available at https://github.com/lmgame-org/GamingAgent/lmgame-bench.","authors":["Lanxiang Hu","Mingjia Huo","Yuxuan Zhang","Haoyang Yu","Eric P. Xing","Ion Stoica","Tajana Rosing","Haojian Jin","Hao Zhang"],"url":"https://arxiv.org/abs/2505.15146"}
{"created":"2025-05-22","title":"From Pixels to Images: Deep Learning Advances in Remote Sensing Image Semantic Segmentation","abstract":"Remote sensing images (RSIs) capture both natural and human-induced changes on the Earth's surface, serving as essential data for environmental monitoring, urban planning, and resource management. Semantic segmentation (SS) of RSIs enables the fine-grained interpretation of surface features, making it a critical task in remote sensing analysis. With the increasing diversity and volume of RSIs collected by sensors on various platforms, traditional processing methods struggle to maintain efficiency and accuracy. In response, deep learning (DL) has emerged as a transformative approach, enabling substantial advances in remote sensing image semantic segmentation (RSISS) by automating feature extraction and improving segmentation accuracy across diverse modalities. This paper revisits the evolution of DL-based RSISS by categorizing existing approaches into four stages: the early pixel-based methods, the prevailing patch-based and tile-based techniques, and the emerging image-based strategies enabled by foundation models. We analyze these developments from the perspective of feature extraction and learning strategies, revealing the field's progression from pixel-level to tile-level and from unimodal to multimodal segmentation. Furthermore, we conduct a comprehensive evaluation of nearly 40 advanced techniques on a unified dataset to quantitatively characterize their performance and applicability. This review offers a holistic view of DL-based SS for RS, highlighting key advancements, comparative insights, and open challenges to guide future research.","authors":["Quanwei Liu","Tao Huang","Yanni Dong","Jiaqi Yang","Wei Xiang"],"url":"https://arxiv.org/abs/2505.15147"}
{"created":"2025-05-22","title":"Dynamic Spectrum Sharing Based on the Rentable NFT Standard ERC4907","abstract":"Centralized Dynamic Spectrum Sharing (DSS) faces challenges like data security, high management costs, and limited scalability. To address these issues, a blockchain-based DSS scheme has been proposed in this paper. First, we utilize the ERC4907 standard to mint Non-Fungible Spectrum Tokens (NFSTs) that serve as unique identifiers for spectrum resources and facilitate renting. Next, we develop a smart contract for NFST auctions, ensuring secure spectrum transactions through the auction process. Lastly, we create a Web3 spectrum auction platform where users can access idle spectrum data and participate in auctions for NFST leases corresponding to the available spectrum. Experimental results demonstrate that our NFST, designed according to the ERC4907 standard, effectively meets users' secure and efficient DSS requirements, making it a feasible solution.","authors":["Litao Ye","Bin Chen","Shrivastava Shivanshu","Chen Sun","Shuo Wang","Siming Feng","Shengli Zhang"],"url":"https://arxiv.org/abs/2505.15148"}
{"created":"2025-05-22","title":"Time Tracker: Mixture-of-Experts-Enhanced Foundation Time Series Forecasting Model with Decoupled Training Pipelines","abstract":"In the past few years, time series foundation models have achieved superior predicting accuracy. However, real-world time series often exhibit significant diversity in their temporal patterns across different time spans and domains, making it challenging for a single model architecture to fit all complex scenarios. In addition, time series data may have multiple variables exhibiting complex correlations between each other. Recent mainstream works have focused on modeling times series in a channel-independent manner in both pretraining and finetuning stages, overlooking the valuable inter-series dependencies. To this end, we propose \\textbf{Time Tracker} for better predictions on multivariate time series data. Firstly, we leverage sparse mixture of experts (MoE) within Transformers to handle the modeling of diverse time series patterns, thereby alleviating the learning difficulties of a single model while improving its generalization. Besides, we propose Any-variate Attention, enabling a unified model structure to seamlessly handle both univariate and multivariate time series, thereby supporting channel-independent modeling during pretraining and channel-mixed modeling for finetuning. Furthermore, we design a graph learning module that constructs relations among sequences from frequency-domain features, providing more precise guidance to capture inter-series dependencies in channel-mixed modeling. Based on these advancements, Time Tracker achieves state-of-the-art performance in predicting accuracy, model generalization and adaptability.","authors":["Xiaohou Shi","Ke Li","Aobo Liang","Yan Sun"],"url":"https://arxiv.org/abs/2505.15151"}
{"created":"2025-05-22","title":"Sculpting Features from Noise: Reward-Guided Hierarchical Diffusion for Task-Optimal Feature Transformation","abstract":"Feature Transformation (FT) crafts new features from original ones via mathematical operations to enhance dataset expressiveness for downstream models. However, existing FT methods exhibit critical limitations: discrete search struggles with enormous combinatorial spaces, impeding practical use; and continuous search, being highly sensitive to initialization and step sizes, often becomes trapped in local optima, restricting global exploration. To overcome these limitations, DIFFT redefines FT as a reward-guided generative task. It first learns a compact and expressive latent space for feature sets using a Variational Auto-Encoder (VAE). A Latent Diffusion Model (LDM) then navigates this space to generate high-quality feature embeddings, its trajectory guided by a performance evaluator towards task-specific optima. This synthesis of global distribution learning (from LDM) and targeted optimization (reward guidance) produces potent embeddings, which a novel semi-autoregressive decoder efficiently converts into structured, discrete features, preserving intra-feature dependencies while allowing parallel inter-feature generation. Extensive experiments on 14 benchmark datasets show DIFFT consistently outperforms state-of-the-art baselines in predictive accuracy and robustness, with significantly lower training and inference times.","authors":["Nanxu Gong","Zijun Li","Sixun Dong","Haoyue Bai","Wangyang Ying","Xinyuan Wang","Yanjie Fu"],"url":"https://arxiv.org/abs/2505.15152"}
{"created":"2025-05-22","title":"Prolonged Reasoning Is Not All You Need: Certainty-Based Adaptive Routing for Efficient LLM/MLLM Reasoning","abstract":"Recent advancements in reasoning have significantly enhanced the capabilities of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) across diverse tasks. However, excessive reliance on chain-of-thought (CoT) reasoning can impair model performance and brings unnecessarily lengthened outputs, reducing efficiency. Our work reveals that prolonged reasoning does not universally improve accuracy and even degrade performance on simpler tasks. To address this, we propose Certainty-based Adaptive Reasoning (CAR), a novel framework that dynamically switches between short answers and long-form reasoning based on the model perplexity. CAR first generates a short answer and evaluates its perplexity, triggering reasoning only when the model exhibits low confidence (i.e., high perplexity). Experiments across diverse multimodal VQA/KIE benchmarks and text reasoning datasets show that CAR outperforms both short-answer and long-form reasoning approaches, striking an optimal balance between accuracy and efficiency.","authors":["Jinghui Lu","Haiyang Yu","Siliang Xu","Shiwei Ran","Guozhi Tang","Siqi Wang","Bin Shan","Teng Fu","Hao Feng","Jingqun Tang","Han Wang","Can Huang"],"url":"https://arxiv.org/abs/2505.15154"}
{"created":"2025-05-22","title":"Privacy-Preserving Socialized Recommendation based on Multi-View Clustering in a Cloud Environment","abstract":"Recommendation as a service has improved the quality of our lives and plays a significant role in variant aspects. However, the preference of users may reveal some sensitive information, so that the protection of privacy is required. In this paper, we propose a privacy-preserving, socialized, recommendation protocol that introduces information collected from online social networks to enhance the quality of the recommendation. The proposed scheme can calculate the similarity between users to determine their potential relationships and interests, and it also can protect the users' privacy from leaking to an untrusted third party. The security analysis and experimental results showed that our proposed scheme provides excellent performance and is feasible for real-world applications.","authors":["Cheng Guo","Jing Jia","Peng Wang","Jing Zhang"],"url":"https://arxiv.org/abs/2505.15156"}
{"created":"2025-05-22","title":"Cascaded Diffusion Models for Neural Motion Planning","abstract":"Robots in the real world need to perceive and move to goals in complex environments without collisions. Avoiding collisions is especially difficult when relying on sensor perception and when goals are among clutter. Diffusion policies and other generative models have shown strong performance in solving local planning problems, but often struggle at avoiding all of the subtle constraint violations that characterize truly challenging global motion planning problems. In this work, we propose an approach for learning global motion planning using diffusion policies, allowing the robot to generate full trajectories through complex scenes and reasoning about multiple obstacles along the path. Our approach uses cascaded hierarchical models which unify global prediction and local refinement together with online plan repair to ensure the trajectories are collision free. Our method outperforms (by ~5%) a wide variety of baselines on challenging tasks in multiple domains including navigation and manipulation.","authors":["Mohit Sharma","Adam Fishman","Vikash Kumar","Chris Paxton","Oliver Kroemer"],"url":"https://arxiv.org/abs/2505.15157"}
{"created":"2025-05-22","title":"ALN-P3: Unified Language Alignment for Perception, Prediction, and Planning in Autonomous Driving","abstract":"Recent advances have explored integrating large language models (LLMs) into end-to-end autonomous driving systems to enhance generalization and interpretability. However, most existing approaches are limited to either driving performance or vision-language reasoning, making it difficult to achieve both simultaneously. In this paper, we propose ALN-P3, a unified co-distillation framework that introduces cross-modal alignment between \"fast\" vision-based autonomous driving systems and \"slow\" language-driven reasoning modules. ALN-P3 incorporates three novel alignment mechanisms: Perception Alignment (P1A), Prediction Alignment (P2A), and Planning Alignment (P3A), which explicitly align visual tokens with corresponding linguistic outputs across the full perception, prediction, and planning stack. All alignment modules are applied only during training and incur no additional costs during inference. Extensive experiments on four challenging benchmarks-nuScenes, Nu-X, TOD3Cap, and nuScenes QA-demonstrate that ALN-P3 significantly improves both driving decisions and language reasoning, achieving state-of-the-art results.","authors":["Yunsheng Ma","Burhaneddin Yaman","Xin Ye","Mahmut Yurt","Jingru Luo","Abhirup Mallik","Ziran Wang","Liu Ren"],"url":"https://arxiv.org/abs/2505.15158"}
{"created":"2025-05-22","title":"Lossless Token Merging Even Without Fine-Tuning in Vision Transformers","abstract":"Although Vision Transformers (ViTs) have become the standard architecture in computer vision, their massive sizes lead to significant computational overhead. Token compression techniques have attracted considerable attention to address this issue, but they often suffer from severe information loss, requiring extensive additional training to achieve practical performance. In this paper, we propose Adaptive Token Merging (ATM), a novel method that ensures lossless token merging, eliminating the need for fine-tuning while maintaining competitive performance. ATM adaptively reduces tokens across layers and batches by carefully adjusting layer-specific similarity thresholds, thereby preventing the undesirable merging of less similar tokens with respect to each layer. Furthermore, ATM introduces a novel token matching technique that considers not only similarity but also merging sizes, particularly for the final layers, to minimize the information loss incurred from each merging operation. We empirically validate our method across a wide range of pretrained models, demonstrating that ATM not only outperforms all existing training-free methods but also surpasses most training-intensive approaches, even without additional training. Remarkably, training-free ATM achieves over a 30% reduction in FLOPs for the DeiT-T and DeiT-S models without any drop in their original accuracy.","authors":["Jaeyeon Lee","Dong-Wan Choi"],"url":"https://arxiv.org/abs/2505.15160"}
{"created":"2025-05-22","title":"AI Solutionism and Digital Self-Tracking with Wearables","abstract":"Self-tracking technologies and wearables automate the process of data collection and insight generation with the support of artificial intelligence systems, with many emerging studies exploring ways to evolve these features further through large-language models (LLMs). This is done with the intent to reduce capture burden and the cognitive stress of health-based decision making, but studies neglect to consider how automation has stymied the agency and independent reflection of users of self-tracking interventions. In this position paper, we explore the consequences of automation in self-tracking by relating it to our experiences with investigating the Oura Ring, a sleep wearable, and navigate potential remedies.","authors":["Hannah R. Nolasco","Andrew Vargo","Koichi Kise"],"url":"https://arxiv.org/abs/2505.15162"}
{"created":"2025-05-22","title":"Enhancing Cloud Task Scheduling Using a Hybrid Particle Swarm and Grey Wolf Optimization Approach","abstract":"Assigning tasks efficiently in cloud computing is a challenging problem and is considered an NP-hard problem. Many researchers have used metaheuristic algorithms to solve it, but these often struggle to handle dynamic workloads and explore all possible options effectively. Therefore, this paper presents a new hybrid method that combines two popular algorithms, Grey Wolf Optimizer (GWO) and Particle Swarm Optimization (PSO). GWO offers strong global search capabilities (exploration), while PSO enhances local refinement (exploitation). The hybrid approach, called HybridPSOGWO, is compared with other existing methods like MPSOSA, RL-GWO, CCGP, and HybridPSOMinMin, using key performance indicators such as makespan, throughput, and load balancing. We tested our approach using both a simulation tool (CloudSim Plus) and real-world data. The results show that HybridPSOGWO outperforms other methods, with up to 15\\% improvement in makespan and 10\\% better throughput, while also distributing tasks more evenly across virtual machines. Our implementation achieves consistent convergence within a few iterations, highlighting its potential for efficient and adaptive cloud scheduling.","authors":["Raveena Prasad","Aarush Roy","Suchi Kumari"],"url":"https://arxiv.org/abs/2505.15171"}
{"created":"2025-05-22","title":"Harnessing Caption Detailness for Data-Efficient Text-to-Image Generation","abstract":"Training text-to-image (T2I) models with detailed captions can significantly improve their generation quality. Existing methods often rely on simplistic metrics like caption length to represent the detailness of the caption in the T2I training set. In this paper, we propose a new metric to estimate caption detailness based on two aspects: image coverage rate (ICR), which evaluates whether the caption covers all regions/objects in the image, and average object detailness (AOD), which quantifies the detailness of each object's description. Through experiments on the COCO dataset using ShareGPT4V captions, we demonstrate that T2I models trained on high-ICR and -AOD captions achieve superior performance on DPG and other benchmarks. Notably, our metric enables more effective data selection-training on only 20% of full data surpasses both full-dataset training and length-based selection method, improving alignment and reconstruction ability. These findings highlight the critical role of detail-aware metrics over length-based heuristics in caption selection for T2I tasks.","authors":["Xinran Wang","Muxi Diao","Yuanzhi Liu","Chunyu Wang","Kongming Liang","Zhanyu Ma","Jun Guo"],"url":"https://arxiv.org/abs/2505.15172"}
{"created":"2025-05-22","title":"AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection","abstract":"The rapid advancement of Artificial Intelligence Generated Content (AIGC) technologies, particularly in video generation, has led to unprecedented creative capabilities but also increased threats to information integrity, identity security, and public trust. Existing detection methods, while effective in general scenarios, lack robust solutions for human-centric videos, which pose greater risks due to their realism and potential for legal and ethical misuse. Moreover, current detection approaches often suffer from poor generalization, limited scalability, and reliance on labor-intensive supervised fine-tuning. To address these challenges, we propose AvatarShield, the first interpretable MLLM-based framework for detecting human-centric fake videos, enhanced via Group Relative Policy Optimization (GRPO). Through our carefully designed accuracy detection reward and temporal compensation reward, it effectively avoids the use of high-cost text annotation data, enabling precise temporal modeling and forgery detection. Meanwhile, we design a dual-encoder architecture, combining high-level semantic reasoning and low-level artifact amplification to guide MLLMs in effective forgery detection. We further collect FakeHumanVid, a large-scale human-centric video benchmark that includes synthesis methods guided by pose, audio, and text inputs, enabling rigorous evaluation of detection methods in real-world scenes. Extensive experiments show that AvatarShield significantly outperforms existing approaches in both in-domain and cross-domain detection, setting a new standard for human-centric video forensics.","authors":["Zhipei Xu","Xuanyu Zhang","Xing Zhou","Jian Zhang"],"url":"https://arxiv.org/abs/2505.15173"}
{"created":"2025-05-22","title":"Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss","abstract":"Lipschitz neural networks are well-known for providing certified robustness in deep learning. In this paper, we present a novel, efficient Block Reflector Orthogonal (BRO) layer that enhances the capability of orthogonal layers on constructing more expressive Lipschitz neural architectures. In addition, by theoretically analyzing the nature of Lipschitz neural networks, we introduce a new loss function that employs an annealing mechanism to increase margin for most data points. This enables Lipschitz models to provide better certified robustness. By employing our BRO layer and loss function, we design BRONet - a simple yet effective Lipschitz neural network that achieves state-of-the-art certified robustness. Extensive experiments and empirical analysis on CIFAR-10/100, Tiny-ImageNet, and ImageNet validate that our method outperforms existing baselines. The implementation is available at \\href{https://github.com/ntuaislab/BRONet}{https://github.com/ntuaislab/BRONet}.","authors":["Bo-Han Lai","Pin-Han Huang","Bo-Han Kung","Shang-Tse Chen"],"url":"https://arxiv.org/abs/2505.15174"}
{"created":"2025-05-22","title":"Exploring Generalized Gait Recognition: Reducing Redundancy and Noise within Indoor and Outdoor Datasets","abstract":"Generalized gait recognition, which aims to achieve robust performance across diverse domains, remains a challenging problem due to severe domain shifts in viewpoints, appearances, and environments. While mixed-dataset training is widely used to enhance generalization, it introduces new obstacles including inter-dataset optimization conflicts and redundant or noisy samples, both of which hinder effective representation learning. To address these challenges, we propose a unified framework that systematically improves cross-domain gait recognition. First, we design a disentangled triplet loss that isolates supervision signals across datasets, mitigating gradient conflicts during optimization. Second, we introduce a targeted dataset distillation strategy that filters out the least informative 20\\% of training samples based on feature redundancy and prediction uncertainty, enhancing data efficiency. Extensive experiments on CASIA-B, OU-MVLP, Gait3D, and GREW demonstrate that our method significantly improves cross-dataset recognition for both GaitBase and DeepGaitV2 backbones, without sacrificing source-domain accuracy. Code will be released at https://github.com/li1er3/Generalized_Gait.","authors":["Qian Zhou","Xianda Guo","Jilong Wang","Chuanfu Shen","Zhongyuan Wang","Hua Zou","Qin Zou","Chao Liang","Chen Long","Gang Wu"],"url":"https://arxiv.org/abs/2505.15176"}
{"created":"2025-05-22","title":"SpectralGap: Graph-Level Out-of-Distribution Detection via Laplacian Eigenvalue Gaps","abstract":"The task of graph-level out-of-distribution (OOD) detection is crucial for deploying graph neural networks in real-world settings. In this paper, we observe a significant difference in the relationship between the largest and second-largest eigenvalues of the Laplacian matrix for in-distribution (ID) and OOD graph samples: \\textit{OOD samples often exhibit anomalous spectral gaps (the difference between the largest and second-largest eigenvalues)}. This observation motivates us to propose SpecGap, an effective post-hoc approach for OOD detection on graphs. SpecGap adjusts features by subtracting the component associated with the second-largest eigenvalue, scaled by the spectral gap, from the high-level features (i.e., $\\mathbf{X}-\\left(\\lambda_n-\\lambda_{n-1}\\right) \\mathbf{u}_{n-1} \\mathbf{v}_{n-1}^T$). SpecGap achieves state-of-the-art performance across multiple benchmark datasets. We present extensive ablation studies and comprehensive theoretical analyses to support our empirical results. As a parameter-free post-hoc method, SpecGap can be easily integrated into existing graph neural network models without requiring any additional training or model modification.","authors":["Jiawei Gu","Ziyue Qiao","Zechao Li"],"url":"https://arxiv.org/abs/2505.15177"}
{"created":"2025-05-22","title":"A Unified Gradient-based Framework for Task-agnostic Continual Learning-Unlearning","abstract":"Recent advancements in deep models have highlighted the need for intelligent systems that combine continual learning (CL) for knowledge acquisition with machine unlearning (MU) for data removal, forming the Continual Learning-Unlearning (CLU) paradigm. While existing work treats CL and MU as separate processes, we reveal their intrinsic connection through a unified optimization framework based on Kullback-Leibler divergence minimization. This framework decomposes gradient updates for approximate CLU into four components: learning new knowledge, unlearning targeted data, preserving existing knowledge, and modulation via weight saliency. A critical challenge lies in balancing knowledge update and retention during sequential learning-unlearning cycles. To resolve this stability-plasticity dilemma, we introduce a remain-preserved manifold constraint to induce a remaining Hessian compensation for CLU iterations. A fast-slow weight adaptation mechanism is designed to efficiently approximate the second-order optimization direction, combined with adaptive weighting coefficients and a balanced weight saliency mask, proposing a unified implementation framework for gradient-based CLU. Furthermore, we pioneer task-agnostic CLU scenarios that support fine-grained unlearning at the cross-task category and random sample levels beyond the traditional task-aware setups. Experiments demonstrate that the proposed UG-CLU framework effectively coordinates incremental learning, precise unlearning, and knowledge stability across multiple datasets and model architectures, providing a theoretical foundation and methodological support for dynamic, compliant intelligent systems.","authors":["Zhehao Huang","Xinwen Cheng","Jie Zhang","Jinghao Zheng","Haoran Wang","Zhengbao He","Tao Li","Xiaolin Huang"],"url":"https://arxiv.org/abs/2505.15178"}
{"created":"2025-05-22","title":"RAG or Fine-tuning? A Comparative Study on LCMs-based Code Completion in Industry","abstract":"Code completion, a crucial practice in industrial settings, helps developers improve programming efficiency by automatically suggesting code snippets during development. With the emergence of Large Code Models (LCMs), this field has witnessed significant advancements. Due to the natural differences between open-source and industrial codebases, such as coding patterns and unique internal dependencies, it is a common practice for developers to conduct domain adaptation when adopting LCMs in industry. There exist multiple adaptation approaches, among which retrieval-augmented generation (RAG) and fine-tuning are the two most popular paradigms. However, no prior research has explored the trade-off of the two approaches in industrial scenarios.","authors":["Chaozheng Wang","Zezhou Yang","Shuzheng Gao","Cuiyun Gao","Ting Peng","Hailiang Huang","Yuetang Deng","Michael Lyu"],"url":"https://arxiv.org/abs/2505.15179"}
{"created":"2025-05-22","title":"NeuBM: Mitigating Model Bias in Graph Neural Networks through Neutral Input Calibration","abstract":"Graph Neural Networks (GNNs) have shown remarkable performance across various domains, yet they often struggle with model bias, particularly in the presence of class imbalance. This bias can lead to suboptimal performance and unfair predictions, especially for underrepresented classes. We introduce NeuBM (Neutral Bias Mitigation), a novel approach to mitigate model bias in GNNs through neutral input calibration. NeuBM leverages a dynamically updated neutral graph to estimate and correct the inherent biases of the model. By subtracting the logits obtained from the neutral graph from those of the input graph, NeuBM effectively recalibrates the model's predictions, reducing bias across different classes. Our method integrates seamlessly into existing GNN architectures and training procedures, requiring minimal computational overhead. Extensive experiments on multiple benchmark datasets demonstrate that NeuBM significantly improves the balanced accuracy and recall of minority classes, while maintaining strong overall performance. The effectiveness of NeuBM is particularly pronounced in scenarios with severe class imbalance and limited labeled data, where traditional methods often struggle. We provide theoretical insights into how NeuBM achieves bias mitigation, relating it to the concept of representation balancing. Our analysis reveals that NeuBM not only adjusts the final predictions but also influences the learning of balanced feature representations throughout the network.","authors":["Jiawei Gu","Ziyue Qiao","Xiao Luo"],"url":"https://arxiv.org/abs/2505.15180"}
{"created":"2025-05-22","title":"ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection","abstract":"Recent advances in LLM agents have largely built on reasoning backbones like ReAct, which interleave thought and action in complex environments. However, ReAct often produces ungrounded or incoherent reasoning steps, leading to misalignment between the agent's actual state and goal. Our analysis finds that this stems from ReAct's inability to maintain consistent internal beliefs and goal alignment, causing compounding errors and hallucinations. To address this, we introduce ReflAct, a novel backbone that shifts reasoning from merely planning next actions to continuously reflecting on the agent's state relative to its goal. By explicitly grounding decisions in states and enforcing ongoing goal alignment, ReflAct dramatically improves strategic reliability. This design delivers substantial empirical gains: ReflAct surpasses ReAct by 27.7% on average, achieving a 93.3% success rate in ALFWorld. Notably, ReflAct even outperforms ReAct with added enhancement modules (e.g., Reflexion, WKM), showing that strengthening the core reasoning backbone is key to reliable agent performance.","authors":["Jeonghye Kim","Sojeong Rhee","Minbeom Kim","Dohyung Kim","Sangmook Lee","Youngchul Sung","Kyomin Jung"],"url":"https://arxiv.org/abs/2505.15182"}
{"created":"2025-05-22","title":"Enabling the Reuse of Personal Data in Research: A Classification Model for Legal Compliance","abstract":"Inspired by a proposal made almost ten years ago, this paper presents a model for classifying per-sonal data for research to inform researchers on how to manage them. The classification is based on the principles of the European General Data Protection Regulation and its implementation under the Spanish Law. The paper also describes in which conditions personal data may be stored and can be accessed ensuring compliance with data protection regulations and safeguarding privacy. The work has been developed collaboratively by the Library and the Data Protection Office. The outcomes of this collaboration are a decision tree for researchers and a list of requirements for research data re-positories to store and grant access to personal data securely. This proposal is aligned with the FAIR principles and the commitment for responsible open science practices.","authors":["Eduard Mata i Noguera","Ruben Ortiz Uroz","Ignasi Labastida i Juan"],"url":"https://arxiv.org/abs/2505.15183"}
{"created":"2025-05-22","title":"AuxDet: Auxiliary Metadata Matters for Omni-Domain Infrared Small Target Detection","abstract":"Omni-domain infrared small target detection (IRSTD) poses formidable challenges, as a single model must seamlessly adapt to diverse imaging systems, varying resolutions, and multiple spectral bands simultaneously. Current approaches predominantly rely on visual-only modeling paradigms that not only struggle with complex background interference and inherently scarce target features, but also exhibit limited generalization capabilities across complex omni-scene environments where significant domain shifts and appearance variations occur. In this work, we reveal a critical oversight in existing paradigms: the neglect of readily available auxiliary metadata describing imaging parameters and acquisition conditions, such as spectral bands, sensor platforms, resolution, and observation perspectives. To address this limitation, we propose the Auxiliary Metadata Driven Infrared Small Target Detector (AuxDet), a novel multi-modal framework that fundamentally reimagines the IRSTD paradigm by incorporating textual metadata for scene-aware optimization. Through a high-dimensional fusion module based on multi-layer perceptrons (MLPs), AuxDet dynamically integrates metadata semantics with visual features, guiding adaptive representation learning for each individual sample. Additionally, we design a lightweight prior-initialized enhancement module using 1D convolutional blocks to further refine fused features and recover fine-grained target cues. Extensive experiments on the challenging WideIRSTD-Full benchmark demonstrate that AuxDet consistently outperforms state-of-the-art methods, validating the critical role of auxiliary information in improving robustness and accuracy in omni-domain IRSTD tasks. Code is available at https://github.com/GrokCV/AuxDet.","authors":["Yangting Shi","Renjie He","Le Hui","Xiang Li","Jian Yang","Ming-Ming Cheng","Yimian Dai"],"url":"https://arxiv.org/abs/2505.15184"}
{"created":"2025-05-22","title":"MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth Foundation Models","abstract":"Recent advances in generalizable 3D Gaussian Splatting have demonstrated promising results in real-time high-fidelity rendering without per-scene optimization, yet existing approaches still struggle to handle unfamiliar visual content during inference on novel scenes due to limited generalizability. To address this challenge, we introduce MonoSplat, a novel framework that leverages rich visual priors from pre-trained monocular depth foundation models for robust Gaussian reconstruction. Our approach consists of two key components: a Mono-Multi Feature Adapter that transforms monocular features into multi-view representations, coupled with an Integrated Gaussian Prediction module that effectively fuses both feature types for precise Gaussian generation. Through the Adapter's lightweight attention mechanism, features are seamlessly aligned and aggregated across views while preserving valuable monocular priors, enabling the Prediction module to generate Gaussian primitives with accurate geometry and appearance. Through extensive experiments on diverse real-world datasets, we convincingly demonstrate that MonoSplat achieves superior reconstruction quality and generalization capability compared to existing methods while maintaining computational efficiency with minimal trainable parameters. Codes are available at https://github.com/CUHK-AIM-Group/MonoSplat.","authors":["Yifan Liu","Keyu Fan","Weihao Yu","Chenxin Li","Hao Lu","Yixuan Yuan"],"url":"https://arxiv.org/abs/2505.15185"}
{"created":"2025-05-22","title":"Building LOD Representation for 3D Urban Scenes","abstract":"The advances in 3D reconstruction technology, such as photogrammetry and LiDAR scanning, have made it easier to reconstruct accurate and detailed 3D models for urban scenes. Nevertheless, these reconstructed models often contain a large number of geometry primitives, making interactive manipulation and rendering challenging, especially on resource-constrained devices like virtual reality platforms. Therefore, the generation of appropriate levels-of-detail (LOD) representations for these models is crucial. Additionally, automatically reconstructed 3D models tend to suffer from noise and lack semantic information. Dealing with these issues and creating LOD representations that are robust against noise while capturing the semantic meaning present significant challenges. In this paper, we propose a novel algorithm to address these challenges. We begin by analysing the properties of planar primitives detected from the input and group these primitives into multiple level sets by forming meaningful 3D structures. These level sets form the nodes of our innovative LOD-Tree. By selecting nodes at appropriate depths within the LOD-Tree, different LOD representations can be generated. Experimental results on real and complex urban scenes demonstrate the merits of our approach in generating clean, accurate, and semantically meaningful LOD representations.","authors":["Shanshan Pan","Runze Zhang","Yilin Liu","Minglun Gong","Hui Huang"],"url":"https://arxiv.org/abs/2505.15190"}
{"created":"2025-05-22","title":"Geometrically Regularized Transfer Learning with On-Manifold and Off-Manifold Perturbation","abstract":"Transfer learning under domain shift remains a fundamental challenge due to the divergence between source and target data manifolds. In this paper, we propose MAADA (Manifold-Aware Adversarial Data Augmentation), a novel framework that decomposes adversarial perturbations into on-manifold and off-manifold components to simultaneously capture semantic variation and model brittleness. We theoretically demonstrate that enforcing on-manifold consistency reduces hypothesis complexity and improves generalization, while off-manifold regularization smooths decision boundaries in low-density regions. Moreover, we introduce a geometry-aware alignment loss that minimizes geodesic discrepancy between source and target manifolds. Experiments on DomainNet, VisDA, and Office-Home show that MAADA consistently outperforms existing adversarial and adaptation methods in both unsupervised and few-shot settings, demonstrating superior structural robustness and cross-domain generalization.","authors":["Hana Satou","Alan Mitkiy","F Monkey"],"url":"https://arxiv.org/abs/2505.15191"}
{"created":"2025-05-22","title":"Leveraging Foundation Models for Multimodal Graph-Based Action Recognition","abstract":"Foundation models have ushered in a new era for multimodal video understanding by enabling the extraction of rich spatiotemporal and semantic representations. In this work, we introduce a novel graph-based framework that integrates a vision-language foundation, leveraging VideoMAE for dynamic visual encoding and BERT for contextual textual embedding, to address the challenge of recognizing fine-grained bimanual manipulation actions. Departing from conventional static graph architectures, our approach constructs an adaptive multimodal graph where nodes represent frames, objects, and textual annotations, and edges encode spatial, temporal, and semantic relationships. These graph structures evolve dynamically based on learned interactions, allowing for flexible and context-aware reasoning. A task-specific attention mechanism within a Graph Attention Network further enhances this reasoning by modulating edge importance based on action semantics. Through extensive evaluations on diverse benchmark datasets, we demonstrate that our method consistently outperforms state-of-the-art baselines, underscoring the strength of combining foundation models with dynamic graph-based reasoning for robust and generalizable action recognition.","authors":["Fatemeh Ziaeetabar","Florentin W\\\"org\\\"otter"],"url":"https://arxiv.org/abs/2505.15192"}
{"created":"2025-05-22","title":"GAMA: Geometry-Aware Manifold Alignment via Structured Adversarial Perturbations for Robust Domain Adaptation","abstract":"Domain adaptation remains a challenge when there is significant manifold discrepancy between source and target domains. Although recent methods leverage manifold-aware adversarial perturbations to perform data augmentation, they often neglect precise manifold alignment and systematic exploration of structured perturbations. To address this, we propose GAMA (Geometry-Aware Manifold Alignment), a structured framework that achieves explicit manifold alignment via adversarial perturbation guided by geometric information. GAMA systematically employs tangent space exploration and manifold-constrained adversarial optimization, simultaneously enhancing semantic consistency, robustness to off-manifold deviations, and cross-domain alignment. Theoretical analysis shows that GAMA tightens the generalization bound via structured regularization and explicit alignment. Empirical results on DomainNet, VisDA, and Office-Home demonstrate that GAMA consistently outperforms existing adversarial and adaptation methods in both unsupervised and few-shot settings, exhibiting superior robustness, generalization, and manifold alignment capability.","authors":["Hana Satou","F Monkey"],"url":"https://arxiv.org/abs/2505.15194"}
{"created":"2025-05-22","title":"Self-Boost via Optimal Retraining: An Analysis via Approximate Message Passing","abstract":"Retraining a model using its own predictions together with the original, potentially noisy labels is a well-known strategy for improving the model performance. While prior works have demonstrated the benefits of specific heuristic retraining schemes, the question of how to optimally combine the model's predictions and the provided labels remains largely open. This paper addresses this fundamental question for binary classification tasks. We develop a principled framework based on approximate message passing (AMP) to analyze iterative retraining procedures for two ground truth settings: Gaussian mixture model (GMM) and generalized linear model (GLM). Our main contribution is the derivation of the Bayes optimal aggregator function to combine the current model's predictions and the given labels, which when used to retrain the same model, minimizes its prediction error. We also quantify the performance of this optimal retraining strategy over multiple rounds. We complement our theoretical results by proposing a practically usable version of the theoretically-optimal aggregator function for linear probing with the cross-entropy loss, and demonstrate its superiority over baseline methods in the high label noise regime.","authors":["Adel Javanmard","Rudrajit Das","Alessandro Epasto","Vahab Mirrokni"],"url":"https://arxiv.org/abs/2505.15195"}
{"created":"2025-05-22","title":"EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association","abstract":"Goal-oriented script planning, or the ability to devise coherent sequences of actions toward specific goals, is commonly employed by humans to plan for typical activities. In e-commerce, customers increasingly seek LLM-based assistants to generate scripts and recommend products at each step, thereby facilitating convenient and efficient shopping experiences. However, this capability remains underexplored due to several challenges, including the inability of LLMs to simultaneously conduct script planning and product retrieval, difficulties in matching products caused by semantic discrepancies between planned actions and search queries, and a lack of methods and benchmark data for evaluation. In this paper, we step forward by formally defining the task of E-commerce Script Planning (EcomScript) as three sequential subtasks. We propose a novel framework that enables the scalable generation of product-enriched scripts by associating products with each step based on the semantic similarity between the actions and their purchase intentions. By applying our framework to real-world e-commerce data, we construct the very first large-scale EcomScript dataset, EcomScriptBench, which includes 605,229 scripts sourced from 2.4 million products. Human annotations are then conducted to provide gold labels for a sampled subset, forming an evaluation benchmark. Extensive experiments reveal that current (L)LMs face significant challenges with EcomScript tasks, even after fine-tuning, while injecting product purchase intentions improves their performance.","authors":["Weiqi Wang","Limeng Cui","Xin Liu","Sreyashi Nag","Wenju Xu","Chen Luo","Sheikh Muhammad Sarwar","Yang Li","Hansu Gu","Hui Liu","Changlong Yu","Jiaxin Bai","Yifan Gao","Haiyang Zhang","Qi He","Shuiwang Ji","Yangqiu Song"],"url":"https://arxiv.org/abs/2505.15196"}
{"created":"2025-05-22","title":"Intentional Gesture: Deliver Your Intentions with Gestures for Speech","abstract":"When humans speak, gestures help convey communicative intentions, such as adding emphasis or describing concepts. However, current co-speech gesture generation methods rely solely on superficial linguistic cues (\\textit{e.g.} speech audio or text transcripts), neglecting to understand and leverage the communicative intention that underpins human gestures. This results in outputs that are rhythmically synchronized with speech but are semantically shallow. To address this gap, we introduce \\textbf{Intentional-Gesture}, a novel framework that casts gesture generation as an intention-reasoning task grounded in high-level communicative functions. % First, we curate the \\textbf{InG} dataset by augmenting BEAT-2 with gesture-intention annotations (\\textit{i.e.}, text sentences summarizing intentions), which are automatically annotated using large vision-language models. Next, we introduce the \\textbf{Intentional Gesture Motion Tokenizer} to leverage these intention annotations. It injects high-level communicative functions (\\textit{e.g.}, intentions) into tokenized motion representations to enable intention-aware gesture synthesis that are both temporally aligned and semantically meaningful, achieving new state-of-the-art performance on the BEAT-2 benchmark. Our framework offers a modular foundation for expressive gesture generation in digital humans and embodied AI. Project Page: https://andypinxinliu.github.io/Intentional-Gesture","authors":["Pinxin Liu","Haiyang Liu","Luchuan Song","Chenliang Xu"],"url":"https://arxiv.org/abs/2505.15197"}
{"created":"2025-05-22","title":"Performance Analysis of Fluid Antenna System under Spatially-Correlated Rician Fading Channels","abstract":"Fluid antenna systems (FAS) are among the most promising technologies for the sixth generation (6G) mobile communication networks. Unlike traditional fixed-position multiple-input multiple-output (MIMO) systems, a FAS possesses position reconfigurability to switch on-demand among $N$ predefined ports over a prescribed space. This paper explores the performance of a single-input single-output (SISO) model with a fixed-position antenna transmitter and a single-antenna FAS receiver, referred to as the Rx-SISO-FAS model, under spatially-correlated Rician fading channels. Our contributions include exact expressions and closed-form bounds for the outage probability of the Rx-SISO-FAS model, as well as exact and closed-form lower bounds for the ergodic rate. Importantly, we also analyze the performance considering both uniform linear array (ULA) and uniform planar array (UPA) configurations for the ports of the FAS. To gain insights, we evaluate the diversity order of the proposed model and our analytical results indicate that with a fixed overall system size, increasing the number of ports, $N$, significantly decreases the outage performance of FAS under different Rician fading factors. Our numerical results further demonstrate that: $i)$ the Rx-SISO-FAS model can enhance performance under spatially-correlated Rician fading channels over the fixed-position antenna counterpart; $ii)$ the Rician factor negatively impacts performance in the low signal-to-noise ratio (SNR) regime; $iii$) FAS can outperform an $L$ branches maximum ratio combining (MRC) system under Rician fading channels; and $iv)$ when the number of ports is identical, UPA outperforms ULA.","authors":["Jiangsheng Huangfu","Zhengyu Song","Tianwei Hou","Anna Li","Yuanwei Liu","Arumugam Nallanathan","Kai-Kit Wong"],"url":"https://arxiv.org/abs/2505.15200"}
{"created":"2025-05-22","title":"Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems","abstract":"Reinforcement Learning (RL) algorithms sample multiple n>1 solution attempts for each problem and reward them independently. This optimizes for pass@1 performance and prioritizes the strength of isolated samples at the expense of the diversity and collective utility of sets of samples. This under-utilizes the sampling capacity, limiting exploration and eventual improvement on harder examples. As a fix, we propose Pass-at-k Policy Optimization (PKPO), a transformation on the final rewards which leads to direct optimization of pass@k performance, thus optimizing for sets of samples that maximize reward when considered jointly. Our contribution is to derive novel low variance unbiased estimators for pass@k and its gradient, in both the binary and continuous reward settings. We show optimization with our estimators reduces to standard RL with rewards that have been jointly transformed by a stable and efficient transformation function.","authors":["Christian Walder","Deep Karkhanis"],"url":"https://arxiv.org/abs/2505.15201"}
{"created":"2025-05-22","title":"Flashback: Memory-Driven Zero-shot, Real-time Video Anomaly Detection","abstract":"Video Anomaly Detection (VAD) automatically identifies anomalous events from video, mitigating the need for human operators in large-scale surveillance deployments. However, three fundamental obstacles hinder real-world adoption: domain dependency and real-time constraints -- requiring near-instantaneous processing of incoming video. To this end, we propose Flashback, a zero-shot and real-time video anomaly detection paradigm. Inspired by the human cognitive mechanism of instantly judging anomalies and reasoning in current scenes based on past experience, Flashback operates in two stages: Recall and Respond. In the offline recall stage, an off-the-shelf LLM builds a pseudo-scene memory of both normal and anomalous captions without any reliance on real anomaly data. In the online respond stage, incoming video segments are embedded and matched against this memory via similarity search. By eliminating all LLM calls at inference time, Flashback delivers real-time VAD even on a consumer-grade GPU. On two large datasets from real-world surveillance scenarios, UCF-Crime and XD-Violence, we achieve 87.3 AUC (+7.0 pp) and 75.1 AP (+13.1 pp), respectively, outperforming prior zero-shot VAD methods by large margins.","authors":["Hyogun Lee","Haksub Kim","Ig-Jae Kim","Yonghun Choi"],"url":"https://arxiv.org/abs/2505.15205"}
{"created":"2025-05-22","title":"EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy","abstract":"In endoscopic procedures, autonomous tracking of abnormal regions and following circumferential cutting markers can significantly reduce the cognitive burden on endoscopists. However, conventional model-based pipelines are fragile for each component (e.g., detection, motion planning) requires manual tuning and struggles to incorporate high-level endoscopic intent, leading to poor generalization across diverse scenes. Vision-Language-Action (VLA) models, which integrate visual perception, language grounding, and motion planning within an end-to-end framework, offer a promising alternative by semantically adapting to surgeon prompts without manual recalibration. Despite their potential, applying VLA models to robotic endoscopy presents unique challenges due to the complex and dynamic anatomical environments of the gastrointestinal (GI) tract. To address this, we introduce EndoVLA, designed specifically for continuum robots in GI interventions. Given endoscopic images and surgeon-issued tracking prompts, EndoVLA performs three core tasks: (1) polyp tracking, (2) delineation and following of abnormal mucosal regions, and (3) adherence to circular markers during circumferential cutting. To tackle data scarcity and domain shifts, we propose a dual-phase strategy comprising supervised fine-tuning on our EndoVLA-Motion dataset and reinforcement fine-tuning with task-aware rewards. Our approach significantly improves tracking performance in endoscopy and enables zero-shot generalization in diverse scenes and complex sequential tasks.","authors":["Chi Kit Ng","Long Bai","Guankun Wang","Yupeng Wang","Huxin Gao","Kun Yuan","Chenhan Jin","Tieyong Zeng","Hongliang Ren"],"url":"https://arxiv.org/abs/2505.15206"}
{"created":"2025-05-22","title":"GT^2-GS: Geometry-aware Texture Transfer for Gaussian Splatting","abstract":"Transferring 2D textures to 3D modalities is of great significance for improving the efficiency of multimedia content creation. Existing approaches have rarely focused on transferring image textures onto 3D representations. 3D style transfer methods are capable of transferring abstract artistic styles to 3D scenes. However, these methods often overlook the geometric information of the scene, which makes it challenging to achieve high-quality 3D texture transfer results. In this paper, we present GT^2-GS, a geometry-aware texture transfer framework for gaussian splitting. From the perspective of matching texture features with geometric information in rendered views, we identify the issue of insufficient texture features and propose a geometry-aware texture augmentation module to expand the texture feature set. Moreover, a geometry-consistent texture loss is proposed to optimize texture features into the scene representation. This loss function incorporates both camera pose and 3D geometric information of the scene, enabling controllable texture-oriented appearance editing. Finally, a geometry preservation strategy is introduced. By alternating between the texture transfer and geometry correction stages over multiple iterations, this strategy achieves a balance between learning texture features and preserving geometric integrity. Extensive experiments demonstrate the effectiveness and controllability of our method. Through geometric awareness, our approach achieves texture transfer results that better align with human visual perception. Our homepage is available at https://vpx-ecnu.github.io/GT2-GS-website.","authors":["Wenjie Liu","Zhongliang Liu","Junwei Shu","Changbo Wang","Yang Li"],"url":"https://arxiv.org/abs/2505.15208"}
{"created":"2025-05-22","title":"DUSK: Do Not Unlearn Shared Knowledge","abstract":"Large language models (LLMs) are increasingly deployed in real-world applications, raising concerns about the unauthorized use of copyrighted or sensitive data. Machine unlearning aims to remove such 'forget' data while preserving utility and information from the 'retain' set. However, existing evaluations typically assume that forget and retain sets are fully disjoint, overlooking realistic scenarios where they share overlapping content. For instance, a news article may need to be unlearned, even though the same event, such as an earthquake in Japan, is also described factually on Wikipedia. Effective unlearning should remove the specific phrasing of the news article while preserving publicly supported facts. In this paper, we introduce DUSK, a benchmark designed to evaluate unlearning methods under realistic data overlap. DUSK constructs document sets that describe the same factual content in different styles, with some shared information appearing across all sets and other content remaining unique to each. When one set is designated for unlearning, an ideal method should remove its unique content while preserving shared facts. We define seven evaluation metrics to assess whether unlearning methods can achieve this selective removal. Our evaluation of nine recent unlearning methods reveals a key limitation: while most can remove surface-level text, they often fail to erase deeper, context-specific knowledge without damaging shared content. We release DUSK as a public benchmark to support the development of more precise and reliable unlearning techniques for real-world applications.","authors":["Wonje Jeung","Sangyeon Yoon","Hyesoo Hong","Soeun Kim","Seungju Han","Youngjae Yu","Albert No"],"url":"https://arxiv.org/abs/2505.15209"}
{"created":"2025-05-22","title":"Deliberation on Priors: Trustworthy Reasoning of Large Language Models on Knowledge Graphs","abstract":"Knowledge graph-based retrieval-augmented generation seeks to mitigate hallucinations in Large Language Models (LLMs) caused by insufficient or outdated knowledge. However, existing methods often fail to fully exploit the prior knowledge embedded in knowledge graphs (KGs), particularly their structural information and explicit or implicit constraints. The former can enhance the faithfulness of LLMs' reasoning, while the latter can improve the reliability of response generation. Motivated by these, we propose a trustworthy reasoning framework, termed Deliberation over Priors (DP), which sufficiently utilizes the priors contained in KGs. Specifically, DP adopts a progressive knowledge distillation strategy that integrates structural priors into LLMs through a combination of supervised fine-tuning and Kahneman-Tversky optimization, thereby improving the faithfulness of relation path generation. Furthermore, our framework employs a reasoning-introspection strategy, which guides LLMs to perform refined reasoning verification based on extracted constraint priors, ensuring the reliability of response generation. Extensive experiments on three benchmark datasets demonstrate that DP achieves new state-of-the-art performance, especially a Hit@1 improvement of 13% on the ComplexWebQuestions dataset, and generates highly trustworthy responses. We also conduct various analyses to verify its flexibility and practicality. The code is available at https://github.com/reml-group/Deliberation-on-Priors.","authors":["Jie Ma","Ning Qu","Zhitao Gao","Rui Xing","Jun Liu","Hongbin Pei","Jiang Xie","Linyun Song","Pinghui Wang","Jing Tao","Zhou Su"],"url":"https://arxiv.org/abs/2505.15210"}
{"created":"2025-05-22","title":"GCNT: Graph-Based Transformer Policies for Morphology-Agnostic Reinforcement Learning","abstract":"Training a universal controller for robots with different morphologies is a promising research trend, since it can significantly enhance the robustness and resilience of the robotic system. However, diverse morphologies can yield different dimensions of state space and action space, making it difficult to comply with traditional policy networks. Existing methods address this issue by modularizing the robot configuration, while do not adequately extract and utilize the overall morphological information, which has been proven crucial for training a universal controller. To this end, we propose GCNT, a morphology-agnostic policy network based on improved Graph Convolutional Network (GCN) and Transformer. It exploits the fact that GCN and Transformer can handle arbitrary number of modules to achieve compatibility with diverse morphologies. Our key insight is that the GCN is able to efficiently extract morphology information of robots, while Transformer ensures that it is fully utilized by allowing each node of the robot to communicate this information directly. Experimental results show that our method can generate resilient locomotion behaviors for robots with different configurations, including zero-shot generalization to robot morphologies not seen during training. In particular, GCNT achieved the best performance on 8 tasks in the 2 standard benchmarks.","authors":["Yingbo Luo","Meibao Yao","Xueming Xiao"],"url":"https://arxiv.org/abs/2505.15211"}
{"created":"2025-05-22","title":"Group Distributionally Robust Optimization with Flexible Sample Queries","abstract":"Group distributionally robust optimization (GDRO) aims to develop models that perform well across $m$ distributions simultaneously. Existing GDRO algorithms can only process a fixed number of samples per iteration, either 1 or $m$, and therefore can not support scenarios where the sample size varies dynamically. To address this limitation, we investigate GDRO with flexible sample queries and cast it as a two-player game: one player solves an online convex optimization problem, while the other tackles a prediction with limited advice (PLA) problem. Within such a game, we propose a novel PLA algorithm, constructing appropriate loss estimators for cases where the sample size is either 1 or not, and updating the decision using follow-the-regularized-leader. Then, we establish the first high-probability regret bound for non-oblivious PLA. Building upon the above approach, we develop a GDRO algorithm that allows an arbitrary and varying sample size per round, achieving a high-probability optimization error bound of $O\\left(\\frac{1}{t}\\sqrt{\\sum_{j=1}^t \\frac{m}{r_j}\\log m}\\right)$, where $r_t$ denotes the sample size at round $t$. This result demonstrates that the optimization error decreases as the number of samples increases and implies a consistent sample complexity of $O(m\\log (m)/\\epsilon^2)$ for any fixed sample size $r\\in[m]$, aligning with existing bounds for cases of $r=1$ or $m$. We validate our approach on synthetic binary and real-world multi-class datasets.","authors":["Haomin Bai","Dingzhi Yu","Shuai Li","Haipeng Luo","Lijun Zhang"],"url":"https://arxiv.org/abs/2505.15212"}
{"created":"2025-05-22","title":"KernelOracle: Predicting the Linux Scheduler's Next Move with Deep Learning","abstract":"Efficient task scheduling is paramount in the Linux kernel, where the Completely Fair Scheduler (CFS) meticulously manages CPU resources to balance high utilization with interactive responsiveness. This research pioneers the use of deep learning techniques to predict the sequence of tasks selected by CFS, aiming to evaluate the feasibility of a more generalized and potentially more adaptive task scheduler for diverse workloads. Our core contributions are twofold: first, the systematic generation and curation of a novel scheduling dataset from a running Linux kernel, capturing real-world CFS behavior; and second, the development, training, and evaluation of a Long Short-Term Memory (LSTM) network designed to accurately forecast the next task to be scheduled. This paper further discusses the practical pathways and implications of integrating such a predictive model into the kernel's scheduling framework. The findings and methodologies presented herein open avenues for data-driven advancements in kernel scheduling, with the full source code provided for reproducibility and further exploration.","authors":["Sampanna Yashwant Kahu"],"url":"https://arxiv.org/abs/2505.15213"}
{"created":"2025-05-22","title":"R-TOFU: Unlearning in Large Reasoning Models","abstract":"Large Reasoning Models (LRMs) embed private or copyrighted information not only in their final answers but also throughout multi-step chain-of-thought (CoT) traces, making reliable unlearning far more demanding than in standard LLMs. We introduce Reasoning-TOFU (R-TOFU), the first benchmark tailored to this setting. R-TOFU augments existing unlearning tasks with realistic CoT annotations and provides step-wise metrics that expose residual knowledge invisible to answer-level checks. Using R-TOFU, we carry out a comprehensive comparison of gradient-based and preference-optimization baselines and show that conventional answer-only objectives leave substantial forget traces in reasoning. We further propose Reasoned IDK, a preference-optimization variant that preserves coherent yet inconclusive reasoning, achieving a stronger balance between forgetting efficacy and model utility than earlier refusal styles. Finally, we identify a failure mode: decoding variants such as ZeroThink and LessThink can still reveal forgotten content despite seemingly successful unlearning, emphasizing the need to evaluate models under diverse decoding settings. Together, the benchmark, analysis, and new baseline establish a systematic foundation for studying and improving unlearning in LRMs while preserving their reasoning capabilities.","authors":["Sangyeon Yoon","Wonje Jeung","Albert No"],"url":"https://arxiv.org/abs/2505.15214"}
{"created":"2025-05-22","title":"BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems","abstract":"AI agents have the potential to significantly alter the cybersecurity landscape. To help us understand this change, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world codebases. To capture the vulnerability lifecycle, we define three task types: Detect (detecting a new vulnerability), Exploit (exploiting a specific vulnerability), and Patch (patching a specific vulnerability). For Detect, we construct a new success indicator, which is general across vulnerability types and provides localized evaluation. We manually set up the environment for each system, including installing packages, setting up server(s), and hydrating database(s). We add 40 bug bounties, which are vulnerabilities with monetary awards from \\$10 to \\$30,485, and cover 9 of the OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy based on information to guide detection, interpolating from identifying a zero day to exploiting a specific vulnerability. We evaluate 5 agents: Claude Code, OpenAI Codex CLI, and custom agents with GPT-4.1, Gemini 2.5 Pro Preview, and Claude 3.7 Sonnet Thinking. Given up to three attempts, the top-performing agents are Claude Code (5% on Detect, mapping to \\$1,350), Custom Agent with Claude 3.7 Sonnet Thinking (5% on Detect, mapping to \\$1,025; 67.5% on Exploit), and OpenAI Codex CLI (5% on Detect, mapping to \\$2,400; 90% on Patch, mapping to \\$14,422). OpenAI Codex CLI and Claude Code are more capable at defense, achieving higher Patch scores of 90% and 87.5%, compared to Exploit scores of 32.5% and 57.5% respectively; in contrast, the custom agents are relatively balanced between offense and defense, achieving Exploit scores of 40-67.5% and Patch scores of 45-60%.","authors":["Andy K. Zhang","Joey Ji","Celeste Menders","Riya Dulepet","Thomas Qin","Ron Y. Wang","Junrong Wu","Kyleen Liao","Jiliang Li","Jinghan Hu","Sara Hong","Nardos Demilew","Shivatmica Murgai","Jason Tran","Nishka Kacheria","Ethan Ho","Denis Liu","Lauren McLane","Olivia Bruvik","Dai-Rong Han","Seungwoo Kim","Akhil Vyas","Cuiyuanxiu Chen","Ryan Li","Weiran Xu","Jonathan Z. Ye","Prerit Choudhary","Siddharth M. Bhatia","Vikram Sivashankar","Yuxuan Bao","Dawn Song","Dan Boneh","Daniel E. Ho","Percy Liang"],"url":"https://arxiv.org/abs/2505.15216"}
{"created":"2025-05-22","title":"Multimodal Conditional Information Bottleneck for Generalizable AI-Generated Image Detection","abstract":"Although existing CLIP-based methods for detecting AI-generated images have achieved promising results, they are still limited by severe feature redundancy, which hinders their generalization ability. To address this issue, incorporating an information bottleneck network into the task presents a straightforward solution. However, relying solely on image-corresponding prompts results in suboptimal performance due to the inherent diversity of prompts. In this paper, we propose a multimodal conditional bottleneck network to reduce feature redundancy while enhancing the discriminative power of features extracted by CLIP, thereby improving the model's generalization ability. We begin with a semantic analysis experiment, where we observe that arbitrary text features exhibit lower cosine similarity with real image features than with fake image features in the CLIP feature space, a phenomenon we refer to as \"bias\". Therefore, we introduce InfoFD, a text-guided AI-generated image detection framework. InfoFD consists of two key components: the Text-Guided Conditional Information Bottleneck (TGCIB) and Dynamic Text Orthogonalization (DTO). TGCIB improves the generalizability of learned representations by conditioning on both text and class modalities. DTO dynamically updates weighted text features, preserving semantic information while leveraging the global \"bias\". Our model achieves exceptional generalization performance on the GenImage dataset and latest generative models. Our code is available at https://github.com/Ant0ny44/InfoFD.","authors":["Haotian Qin","Dongliang Chang","Yueying Gao","Bingyao Yu","Lei Chen","Zhanyu Ma"],"url":"https://arxiv.org/abs/2505.15217"}
{"created":"2025-05-22","title":"RustSAT: A Library For SAT Solving in Rust","abstract":"State-of-the-art Boolean satisfiability (SAT) solvers constitute a practical and competitive approach for solving various real-world problems. To encourage their widespread adoption, the relatively high barrier of entry following from the low level syntax of SAT and the expert knowledge required to achieve tight integration with SAT solvers should be further reduced. We present RustSAT, a library with the aim of making SAT solving technology readily available in the Rust programming language. RustSAT provides functionality for helping with generating (Max)SAT instances, writing them to, or reading them from files. Furthermore, RustSAT includes interfaces to various state-of-the-art SAT solvers available with a unified Rust API. Lastly, RustSAT implements several encodings for higher level constraints (at-most-one, cardinality, and pseudo-Boolean), which are also available via a C and Python API.","authors":["Christoph Jabs"],"url":"https://arxiv.org/abs/2505.15221"}
{"created":"2025-05-22","title":"Continuous Representation Methods, Theories, and Applications: An Overview and Perspectives","abstract":"Recently, continuous representation methods emerge as novel paradigms that characterize the intrinsic structures of real-world data through function representations that map positional coordinates to their corresponding values in the continuous space. As compared with the traditional discrete framework, the continuous framework demonstrates inherent superiority for data representation and reconstruction (e.g., image restoration, novel view synthesis, and waveform inversion) by offering inherent advantages including resolution flexibility, cross-modal adaptability, inherent smoothness, and parameter efficiency. In this review, we systematically examine recent advancements in continuous representation frameworks, focusing on three aspects: (i) Continuous representation method designs such as basis function representation, statistical modeling, tensor function decomposition, and implicit neural representation; (ii) Theoretical foundations of continuous representations such as approximation error analysis, convergence property, and implicit regularization; (iii) Real-world applications of continuous representations derived from computer vision, graphics, bioinformatics, and remote sensing. Furthermore, we outline future directions and perspectives to inspire exploration and deepen insights to facilitate continuous representation methods, theories, and applications. All referenced works are summarized in our open-source repository: https://github.com/YisiLuo/Continuous-Representation-Zoo.","authors":["Yisi Luo","Xile Zhao","Deyu Meng"],"url":"https://arxiv.org/abs/2505.15222"}
{"created":"2025-05-22","title":"Classifying and Tracking International Aid Contribution Towards SDGs","abstract":"International aid is a critical mechanism for promoting economic growth and well-being in developing nations, supporting progress toward the Sustainable Development Goals (SDGs). However, tracking aid contributions remains challenging due to labor-intensive data management, incomplete records, and the heterogeneous nature of aid data. Recognizing the urgency of this challenge, we partnered with government agencies to develop an AI model that complements manual classification and mitigates human bias in subjective interpretation. By integrating SDG-specific semantics and leveraging prior knowledge from language models, our approach enhances classification accuracy and accommodates the diversity of aid projects. When applied to a comprehensive dataset spanning multiple years, our model can reveal hidden trends in the temporal evolution of international development cooperation. Expert interviews further suggest how these insights can empower policymakers with data-driven decision-making tools, ultimately improving aid effectiveness and supporting progress toward SDGs.","authors":["Sungwon Park","Dongjoon Lee","Kyeongjin Ahn","Yubin Choi","Junho Lee","Meeyoung Cha","Kyung Ryul Park"],"url":"https://arxiv.org/abs/2505.15223"}
{"created":"2025-05-22","title":"Degree-Optimized Cumulative Polynomial Kolmogorov-Arnold Networks","abstract":"We introduce cumulative polynomial Kolmogorov-Arnold networks (CP-KAN), a neural architecture combining Chebyshev polynomial basis functions and quadratic unconstrained binary optimization (QUBO). Our primary contribution involves reformulating the degree selection problem as a QUBO task, reducing the complexity from $O(D^N)$ to a single optimization step per layer. This approach enables efficient degree selection across neurons while maintaining computational tractability. The architecture performs well in regression tasks with limited data, showing good robustness to input scales and natural regularization properties from its polynomial basis. Additionally, theoretical analysis establishes connections between CP-KAN's performance and properties of financial time series. Our empirical validation across multiple domains demonstrates competitive performance compared to several traditional architectures tested, especially in scenarios where data efficiency and numerical stability are important. Our implementation, including strategies for managing computational overhead in larger networks is available in Ref.~\\citep{cpkan_implementation}.","authors":["Mathew Vanherreweghe","Lirand\\\"e Pira","Patrick Rebentrost"],"url":"https://arxiv.org/abs/2505.15228"}
{"created":"2025-05-22","title":"Multilingual Prompting for Improving LLM Generation Diversity","abstract":"Large Language Models (LLMs) are known to lack cultural representation and overall diversity in their generations, from expressing opinions to answering factual questions. To mitigate this problem, we propose multilingual prompting: a prompting method which generates several variations of a base prompt with added cultural and linguistic cues from several cultures, generates responses, and then combines the results. Building on evidence that LLMs have language-specific knowledge, multilingual prompting seeks to increase diversity by activating a broader range of cultural knowledge embedded in model training data. Through experiments across multiple models (GPT-4o, GPT-4o-mini, LLaMA 70B, and LLaMA 8B), we show that multilingual prompting consistently outperforms existing diversity-enhancing techniques such as high-temperature sampling, step-by-step recall, and personas prompting. Further analyses show that the benefits of multilingual prompting vary with language resource level and model size, and that aligning the prompting language with the cultural cues reduces hallucination about culturally-specific information.","authors":["Qihan Wang","Shidong Pan","Tal Linzen","Emily Black"],"url":"https://arxiv.org/abs/2505.15229"}
{"created":"2025-05-22","title":"Finding separatrices of dynamical flows with Deep Koopman Eigenfunctions","abstract":"Many natural systems, including neural circuits involved in decision making, can be modeled as high-dimensional dynamical systems with multiple stable states. While existing analytical tools primarily describe behavior near stable equilibria, characterizing separatrices -- the manifolds that delineate boundaries between different basins of attraction -- remains challenging, particularly in high-dimensional settings. Here, we introduce a numerical framework leveraging Koopman Theory combined with Deep Neural Networks to effectively characterize separatrices. Specifically, we approximate Koopman Eigenfunctions (KEFs) associated with real positive eigenvalues, which vanish precisely at the separatrices. Utilizing these scalar KEFs, optimization methods efficiently locate separatrices even in complex systems. We demonstrate our approach on synthetic benchmarks, ecological network models, and recurrent neural networks trained on neuroscience-inspired tasks. Moreover, we illustrate the practical utility of our method by designing optimal perturbations that can shift systems across separatrices, enabling predictions relevant to optogenetic stimulation experiments in neuroscience.","authors":["Kabir V. Dabholkar","Omri Barak"],"url":"https://arxiv.org/abs/2505.15231"}
{"created":"2025-05-22","title":"DC-Scene: Data-Centric Learning for 3D Scene Understanding","abstract":"3D scene understanding plays a fundamental role in vision applications such as robotics, autonomous driving, and augmented reality. However, advancing learning-based 3D scene understanding remains challenging due to two key limitations: (1) the large scale and complexity of 3D scenes lead to higher computational costs and slower training compared to 2D counterparts; and (2) high-quality annotated 3D datasets are significantly scarcer than those available for 2D vision. These challenges underscore the need for more efficient learning paradigms. In this work, we propose DC-Scene, a data-centric framework tailored for 3D scene understanding, which emphasizes enhancing data quality and training efficiency. Specifically, we introduce a CLIP-driven dual-indicator quality (DIQ) filter, combining vision-language alignment scores with caption-loss perplexity, along with a curriculum scheduler that progressively expands the training pool from the top 25% to 75% of scene-caption pairs. This strategy filters out noisy samples and significantly reduces dependence on large-scale labeled 3D data. Extensive experiments on ScanRefer and Nr3D demonstrate that DC-Scene achieves state-of-the-art performance (86.1 CIDEr with the top-75% subset vs. 85.4 with the full dataset) while reducing training cost by approximately two-thirds, confirming that a compact set of high-quality samples can outperform exhaustive training. Code will be available at https://github.com/AIGeeksGroup/DC-Scene.","authors":["Ting Huang","Zeyu Zhang","Ruicheng Zhang","Yang Zhao"],"url":"https://arxiv.org/abs/2505.15232"}
{"created":"2025-05-22","title":"CAD: A General Multimodal Framework for Video Deepfake Detection via Cross-Modal Alignment and Distillation","abstract":"The rapid emergence of multimodal deepfakes (visual and auditory content are manipulated in concert) undermines the reliability of existing detectors that rely solely on modality-specific artifacts or cross-modal inconsistencies. In this work, we first demonstrate that modality-specific forensic traces (e.g., face-swap artifacts or spectral distortions) and modality-shared semantic misalignments (e.g., lip-speech asynchrony) offer complementary evidence, and that neglecting either aspect limits detection performance. Existing approaches either naively fuse modality-specific features without reconciling their conflicting characteristics or focus predominantly on semantic misalignment at the expense of modality-specific fine-grained artifact cues. To address these shortcomings, we propose a general multimodal framework for video deepfake detection via Cross-Modal Alignment and Distillation (CAD). CAD comprises two core components: 1) Cross-modal alignment that identifies inconsistencies in high-level semantic synchronization (e.g., lip-speech mismatches); 2) Cross-modal distillation that mitigates feature conflicts during fusion while preserving modality-specific forensic traces (e.g., spectral distortions in synthetic audio). Extensive experiments on both multimodal and unimodal (e.g., image-only/video-only)deepfake benchmarks demonstrate that CAD significantly outperforms previous methods, validating the necessity of harmonious integration of multimodal complementary information.","authors":["Yuxuan Du","Zhendong Wang","Yuhao Luo","Caiyong Piao","Zhiyuan Yan","Hao Li","Li Yuan"],"url":"https://arxiv.org/abs/2505.15233"}
{"created":"2025-05-22","title":"Neural Collapse is Globally Optimal in Deep Regularized ResNets and Transformers","abstract":"The empirical emergence of neural collapse -- a surprising symmetry in the feature representations of the training data in the penultimate layer of deep neural networks -- has spurred a line of theoretical research aimed at its understanding. However, existing work focuses on data-agnostic models or, when data structure is taken into account, it remains limited to multi-layer perceptrons. Our paper fills both these gaps by analyzing modern architectures in a data-aware regime: we prove that global optima of deep regularized transformers and residual networks (ResNets) with LayerNorm trained with cross entropy or mean squared error loss are approximately collapsed, and the approximation gets tighter as the depth grows. More generally, we formally reduce any end-to-end large-depth ResNet or transformer training into an equivalent unconstrained features model, thus justifying its wide use in the literature even beyond data-agnostic settings. Our theoretical results are supported by experiments on computer vision and language datasets showing that, as the depth grows, neural collapse indeed becomes more prominent.","authors":["Peter S\\'uken\\'ik","Christoph H. Lampert","Marco Mondelli"],"url":"https://arxiv.org/abs/2505.15239"}
{"created":"2025-05-22","title":"Generalised Probabilistic Modelling and Improved Uncertainty Estimation in Comparative LLM-as-a-judge","abstract":"This paper explores generalised probabilistic modelling and uncertainty estimation in comparative LLM-as-a-judge frameworks. We show that existing Product-of-Experts methods are specific cases of a broader framework, enabling diverse modelling options. Furthermore, we propose improved uncertainty estimates for individual comparisons, enabling more efficient selection and achieving strong performance with fewer evaluations. We also introduce a method for estimating overall ranking uncertainty. Finally, we demonstrate that combining absolute and comparative scoring improves performance. Experiments show that the specific expert model has a limited impact on final rankings but our proposed uncertainty estimates, especially the probability of reordering, significantly improve the efficiency of systems reducing the number of needed comparisons by ~50%. Furthermore, ranking-level uncertainty metrics can be used to identify low-performing predictions, where the nature of the probabilistic model has a notable impact on the quality of the overall uncertainty.","authors":["Yassir Fathullah","Mark J. F. Gales"],"url":"https://arxiv.org/abs/2505.15240"}
{"created":"2025-05-22","title":"GAMA++: Disentangled Geometric Alignment with Adaptive Contrastive Perturbation for Reliable Domain Transfer","abstract":"Despite progress in geometry-aware domain adaptation, current methods such as GAMA still suffer from two unresolved issues: (1) insufficient disentanglement of task-relevant and task-irrelevant manifold dimensions, and (2) rigid perturbation schemes that ignore per-class alignment asymmetries. To address this, we propose GAMA++, a novel framework that introduces (i) latent space disentanglement to isolate label-consistent manifold directions from nuisance factors, and (ii) an adaptive contrastive perturbation strategy that tailors both on- and off-manifold exploration to class-specific manifold curvature and alignment discrepancy. We further propose a cross-domain contrastive consistency loss that encourages local semantic clusters to align while preserving intra-domain diversity. Our method achieves state-of-the-art results on DomainNet, Office-Home, and VisDA benchmarks under both standard and few-shot settings, with notable improvements in class-level alignment fidelity and boundary robustness. GAMA++ sets a new standard for semantic geometry alignment in transfer learning.","authors":["Kim Yun","Hana Satou","F Monkey"],"url":"https://arxiv.org/abs/2505.15241"}
{"created":"2025-05-22","title":"Adaptive Plan-Execute Framework for Smart Contract Security Auditing","abstract":"Large Language Models (LLMs) have shown great promise in code analysis and auditing; however, they still struggle with hallucinations and limited context-aware reasoning. We introduce SmartAuditFlow, a novel Plan-Execute framework that enhances smart contract security analysis through dynamic audit planning and structured execution. Unlike conventional LLM-based auditing approaches that follow fixed workflows and predefined steps, SmartAuditFlow dynamically generates and refines audit plans based on the unique characteristics of each smart contract. It continuously adjusts its auditing strategy in response to intermediate LLM outputs and newly detected vulnerabilities, ensuring a more adaptive and precise security assessment. The framework then executes these plans step by step, applying a structured reasoning process to enhance vulnerability detection accuracy while minimizing hallucinations and false positives. To further improve audit precision, SmartAuditFlow integrates iterative prompt optimization and external knowledge sources, such as static analysis tools and Retrieval-Augmented Generation (RAG). This ensures audit decisions are contextually informed and backed by real-world security knowledge, producing comprehensive security reports. Extensive evaluations across multiple benchmarks demonstrate that SmartAuditFlow outperforms existing methods, achieving 100 percent accuracy on common and critical vulnerabilities, 41.2 percent accuracy for comprehensive coverage of known smart contract weaknesses in real-world projects, and successfully identifying all 13 tested CVEs. These results highlight SmartAuditFlow's scalability, cost-effectiveness, and superior adaptability over traditional static analysis tools and contemporary LLM-based approaches, establishing it as a robust solution for automated smart contract auditing.","authors":["Zhiyuan Wei","Jing Sun","Zijian Zhang","Zhe Hou","Zixiao Zhao"],"url":"https://arxiv.org/abs/2505.15242"}
{"created":"2025-05-22","title":"Reliable Vertical Federated Learning in 5G Core Network Architecture","abstract":"This work proposes a new algorithm to mitigate model generalization loss in Vertical Federated Learning (VFL) operating under client reliability constraints within 5G Core Networks (CNs). Recently studied and endorsed by 3GPP, VFL enables collaborative and load-balanced model training and inference across the CN. However, the performance of VFL significantly degrades when the Network Data Analytics Functions (NWDAFs) - which serve as primary clients for VFL model training and inference - experience reliability issues stemming from resource constraints and operational overhead. Unlike edge environments, CN environments adopt fundamentally different data management strategies, characterized by more centralized data orchestration capabilities. This presents opportunities to implement better distributed solutions that take full advantage of the CN data handling flexibility. Leveraging this flexibility, we propose a method that optimizes the vertical feature split among clients while centrally defining their local models based on reliability metrics. Our empirical evaluation demonstrates the effectiveness of our proposed algorithm, showing improved performance over traditional baseline methods.","authors":["Mohamad Mestoukirdi","Mourad Khanfouci"],"url":"https://arxiv.org/abs/2505.15244"}
{"created":"2025-05-22","title":"Towards Explainable Temporal Reasoning in Large Language Models: A Structure-Aware Generative Framework","abstract":"While large language models (LLMs) show great potential in temporal reasoning, most existing work focuses heavily on enhancing performance, often neglecting the explainable reasoning processes underlying the results. To address this gap, we introduce a comprehensive benchmark covering a wide range of temporal granularities, designed to systematically evaluate LLMs' capabilities in explainable temporal reasoning. Furthermore, our findings reveal that LLMs struggle to deliver convincing explanations when relying solely on textual information. To address challenge, we propose GETER, a novel structure-aware generative framework that integrates Graph structures with text for Explainable TEmporal Reasoning. Specifically, we first leverage temporal knowledge graphs to develop a temporal encoder that captures structural information for the query. Subsequently, we introduce a structure-text prefix adapter to map graph structure features into the text embedding space. Finally, LLMs generate explanation text by seamlessly integrating the soft graph token with instruction-tuning prompt tokens. Experimental results indicate that GETER achieves state-of-the-art performance while also demonstrating its effectiveness as well as strong generalization capabilities. Our dataset and code are available at https://github.com/carryTatum/GETER.","authors":["Zihao Jiang","Ben Liu","Miao Peng","Wenjie Xu","Yao Xiao","Zhenyan Shan","Min Peng"],"url":"https://arxiv.org/abs/2505.15245"}
{"created":"2025-05-22","title":"Mitigating Spurious Correlations with Causal Logit Perturbation","abstract":"Deep learning has seen widespread success in various domains such as science, industry, and society. However, it is acknowledged that certain approaches suffer from non-robustness, relying on spurious correlations for predictions. Addressing these limitations is of paramount importance, necessitating the development of methods that can disentangle spurious correlations. {This study attempts to implement causal models via logit perturbations and introduces a novel Causal Logit Perturbation (CLP) framework to train classifiers with generated causal logit perturbations for individual samples, thereby mitigating the spurious associations between non-causal attributes (i.e., image backgrounds) and classes.} {Our framework employs a} perturbation network to generate sample-wise logit perturbations using a series of training characteristics of samples as inputs. The whole framework is optimized by an online meta-learning-based learning algorithm and leverages human causal knowledge by augmenting metadata in both counterfactual and factual manners. Empirical evaluations on four typical biased learning scenarios, including long-tail learning, noisy label learning, generalized long-tail learning, and subpopulation shift learning, demonstrate that CLP consistently achieves state-of-the-art performance. Moreover, visualization results support the effectiveness of the generated causal perturbations in redirecting model attention towards causal image attributes and dismantling spurious associations.","authors":["Xiaoling Zhou","Wei Ye","Rui Xie","Shikun Zhang"],"url":"https://arxiv.org/abs/2505.15246"}
{"created":"2025-05-22","title":"Experimental Evaluation of Multiple Active RISs for 5G MIMO Commercial Networks","abstract":"While numerous experimental studies have demonstrated the feasibility of reconfigurable intelligent surface (RIS) technology, most have primarily focused on extending coverage. In contrast, this paper presents an experimental evaluation of multiple active RISs deployed in a 5G multiple-input multiple-output (MIMO) commercial network, emphasizing enhancements in channel rank and throughput. We propose a low-complexity, codebook-based beamforming algorithm specifically tailored for multi-RIS configurations, which diversifies directional channels and reduces reliance on explicit channel state information. Field tests using a commercial base station and user equipment reveal that the multi-RIS system can improve channel rank and throughput by up to 14% compared to single-RIS deployments, while maintaining low computational complexity. These findings underscore the practical benefits of active multi-RIS systems for next-generation networks.","authors":["Feng-Ji Chen","Chao-Kai Wen","De-Ming Chian"],"url":"https://arxiv.org/abs/2505.15247"}
{"created":"2025-05-22","title":"VET-DINO: Learning Anatomical Understanding Through Multi-View Distillation in Veterinary Imaging","abstract":"Self-supervised learning has emerged as a powerful paradigm for training deep neural networks, particularly in medical imaging where labeled data is scarce. While current approaches typically rely on synthetic augmentations of single images, we propose VET-DINO, a framework that leverages a unique characteristic of medical imaging: the availability of multiple standardized views from the same study. Using a series of clinical veterinary radiographs from the same patient study, we enable models to learn view-invariant anatomical structures and develop an implied 3D understanding from 2D projections. We demonstrate our approach on a dataset of 5 million veterinary radiographs from 668,000 canine studies. Through extensive experimentation, including view synthesis and downstream task performance, we show that learning from real multi-view pairs leads to superior anatomical understanding compared to purely synthetic augmentations. VET-DINO achieves state-of-the-art performance on various veterinary imaging tasks. Our work establishes a new paradigm for self-supervised learning in medical imaging that leverages domain-specific properties rather than merely adapting natural image techniques.","authors":["Andre Dourson","Kylie Taylor","Xiaoli Qiao","Michael Fitzke"],"url":"https://arxiv.org/abs/2505.15248"}
{"created":"2025-05-22","title":"Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation","abstract":"Recently, large vision-language models (LVLMs) have emerged as the preferred tools for judging text-image alignment, yet their robustness along the visual modality remains underexplored. This work is the first study to address a key research question: Can adversarial visual manipulations systematically fool LVLM judges into assigning unfairly inflated scores? We define potential image induced biases within the context of T2I evaluation and examine how these biases affect the evaluations of LVLM judges. Moreover, we introduce a novel, fine-grained, multi-domain meta-evaluation benchmark named FRAME, which is deliberately constructed to exhibit diverse score distributions. By introducing the defined biases into the benchmark, we reveal that all tested LVLM judges exhibit vulnerability across all domains, consistently inflating scores for manipulated images. Further analysis reveals that combining multiple biases amplifies their effects, and pairwise evaluations are similarly susceptible. Moreover, we observe that visual biases persist under prompt-based mitigation strategies, highlighting the vulnerability of current LVLM evaluation systems and underscoring the urgent need for more robust LVLM judges.","authors":["Yerin Hwang","Dongryeol Lee","Kyungmin Min","Taegwan Kang","Yong-il Kim","Kyomin Jung"],"url":"https://arxiv.org/abs/2505.15249"}
{"created":"2025-05-22","title":"Margin-aware Fuzzy Rough Feature Selection: Bridging Uncertainty Characterization and Pattern Classification","abstract":"Fuzzy rough feature selection (FRFS) is an effective means of addressing the curse of dimensionality in high-dimensional data. By removing redundant and irrelevant features, FRFS helps mitigate classifier overfitting, enhance generalization performance, and lessen computational overhead. However, most existing FRFS algorithms primarily focus on reducing uncertainty in pattern classification, neglecting that lower uncertainty does not necessarily result in improved classification performance, despite it commonly being regarded as a key indicator of feature selection effectiveness in the FRFS literature. To bridge uncertainty characterization and pattern classification, we propose a Margin-aware Fuzzy Rough Feature Selection (MAFRFS) framework that considers both the compactness and separation of label classes. MAFRFS effectively reduces uncertainty in pattern classification tasks, while guiding the feature selection towards more separable and discriminative label class structures. Extensive experiments on 15 public datasets demonstrate that MAFRFS is highly scalable and more effective than FRFS. The algorithms developed using MAFRFS outperform six state-of-the-art feature selection algorithms.","authors":["Suping Xu","Lin Shang","Keyu Liu","Hengrong Ju","Xibei Yang","Witold Pedrycz"],"url":"https://arxiv.org/abs/2505.15250"}
{"created":"2025-05-22","title":"Loss-Guided Auxiliary Agents for Overcoming Mode Collapse in GFlowNets","abstract":"Although Generative Flow Networks (GFlowNets) are designed to capture multiple modes of a reward function, they often suffer from mode collapse in practice, getting trapped in early discovered modes and requiring prolonged training to find diverse solutions. Existing exploration techniques may rely on heuristic novelty signals. We propose Loss-Guided GFlowNets (LGGFN), a novel approach where an auxiliary GFlowNet's exploration is directly driven by the main GFlowNet's training loss. By prioritizing trajectories where the main model exhibits high loss, LGGFN focuses sampling on poorly understood regions of the state space. This targeted exploration significantly accelerates the discovery of diverse, high-reward samples. Empirically, across various benchmarks including grid environments, structured sequence generation, and Bayesian structure learning, LGGFN consistently enhances exploration efficiency and sample diversity compared to baselines. For instance, on a challenging sequence generation task, it discovered over 40 times more unique valid modes while simultaneously reducing the exploration error metric by approximately 99\\%.","authors":["Idriss Malek","Abhijit Sharma","Salem Lahlou"],"url":"https://arxiv.org/abs/2505.15251"}
{"created":"2025-05-22","title":"An Efficient Private GPT Never Autoregressively Decodes","abstract":"The wide deployment of the generative pre-trained transformer (GPT) has raised privacy concerns for both clients and servers. While cryptographic primitives can be employed for secure GPT inference to protect the privacy of both parties, they introduce considerable performance overhead.To accelerate secure inference, this study proposes a public decoding and secure verification approach that utilizes public GPT models, motivated by the observation that securely decoding one and multiple tokens takes a similar latency. The client uses the public model to generate a set of tokens, which are then securely verified by the private model for acceptance. The efficiency of our approach depends on the acceptance ratio of tokens proposed by the public model, which we improve from two aspects: (1) a private sampling protocol optimized for cryptographic primitives and (2) model alignment using knowledge distillation. Our approach improves the efficiency of secure decoding while maintaining the same level of privacy and generation quality as standard secure decoding. Experiments demonstrate a $2.1\\times \\sim 6.0\\times$ speedup compared to standard decoding across three pairs of public-private models and different network conditions.","authors":["Zhengyi Li","Yue Guan","Kang Yang","Yu Feng","Ning Liu","Yu Yu","Jingwen Leng","Minyi Guo"],"url":"https://arxiv.org/abs/2505.15252"}
{"created":"2025-05-22","title":"Voice-ENHANCE: Speech Restoration using a Diffusion-based Voice Conversion Framework","abstract":"We propose a speech enhancement system that combines speaker-agnostic speech restoration with voice conversion (VC) to obtain a studio-level quality speech signal. While voice conversion models are typically used to change speaker characteristics, they can also serve as a means of speech restoration when the target speaker is the same as the source speaker. However, since VC models are vulnerable to noisy conditions, we have included a generative speech restoration (GSR) model at the front end of our proposed system. The GSR model performs noise suppression and restores speech damage incurred during that process without knowledge about the target speaker. The VC stage then uses guidance from clean speaker embeddings to further restore the output speech. By employing this two-stage approach, we have achieved speech quality objective metric scores comparable to state-of-the-art (SOTA) methods across multiple datasets.","authors":["Kyungguen Byun","Jason Filos","Erik Visser","Sunkuk Moon"],"url":"https://arxiv.org/abs/2505.15254"}
{"created":"2025-05-22","title":"MentalMAC: Enhancing Large Language Models for Detecting Mental Manipulation via Multi-Task Anti-Curriculum Distillation","abstract":"Mental manipulation is a subtle yet pervasive form of psychological abuse that poses serious threats to mental health. Its covert nature and the complexity of manipulation strategies make it challenging to detect, even for state-of-the-art large language models (LLMs). This concealment also hinders the manual collection of large-scale, high-quality annotations essential for training effective models. Although recent efforts have sought to improve LLM's performance on this task, progress remains limited due to the scarcity of real-world annotated datasets. To address these challenges, we propose MentalMAC, a multi-task anti-curriculum distillation method that enhances LLMs' ability to detect mental manipulation in multi-turn dialogue. Our approach includes: (i) EvoSA, an unsupervised data expansion method based on evolutionary operations and speech act theory; (ii) teacher-model-generated multi-task supervision; and (iii) progressive knowledge distillation from complex to simpler tasks. We then constructed the ReaMent dataset with 5,000 real-world dialogue samples, using a MentalMAC-distilled model to assist human annotation. Vast experiments demonstrate that our method significantly narrows the gap between student and teacher models and outperforms competitive LLMs across key evaluation metrics. All code, datasets, and checkpoints will be released upon paper acceptance. Warning: This paper contains content that may be offensive to readers.","authors":["Yuansheng Gao","Han Bao","Tong Zhang","Bin Li","Zonghui Wang","Wenzhi Chen"],"url":"https://arxiv.org/abs/2505.15255"}
{"created":"2025-05-22","title":"Zero-Shot Gaze-based Volumetric Medical Image Segmentation","abstract":"Accurate segmentation of anatomical structures in volumetric medical images is crucial for clinical applications, including disease monitoring and cancer treatment planning. Contemporary interactive segmentation models, such as Segment Anything Model 2 (SAM-2) and its medical variant (MedSAM-2), rely on manually provided prompts like bounding boxes and mouse clicks. In this study, we introduce eye gaze as a novel informational modality for interactive segmentation, marking the application of eye-tracking for 3D medical image segmentation. We evaluate the performance of using gaze-based prompts with SAM-2 and MedSAM-2 using both synthetic and real gaze data. Compared to bounding boxes, gaze-based prompts offer a time-efficient interaction approach with slightly lower segmentation quality. Our findings highlight the potential of using gaze as a complementary input modality for interactive 3D medical image segmentation.","authors":["Tatyana Shmykova","Leila Khaertdinova","Ilya Pershin"],"url":"https://arxiv.org/abs/2505.15256"}
{"created":"2025-05-22","title":"When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners","abstract":"Multilingual reasoning remains a significant challenge for large language models (LLMs), with performance disproportionately favoring high-resource languages. Drawing inspiration from cognitive neuroscience, which suggests that human reasoning functions largely independently of language processing, we hypothesize that LLMs similarly encode reasoning and language as separable components that can be disentangled to enhance multilingual reasoning. To evaluate this, we perform a causal intervention by ablating language-specific representations at inference time. Experiments on 10 open-source LLMs spanning 11 typologically diverse languages show that this language-specific ablation consistently boosts multilingual reasoning performance. Layer-wise analyses further confirm that language and reasoning representations can be effectively decoupled throughout the model, yielding improved multilingual reasoning capabilities, while preserving top-layer language features remains essential for maintaining linguistic fidelity. Compared to post-training such as supervised fine-tuning or reinforcement learning, our training-free ablation achieves comparable or superior results with minimal computational overhead. These findings shed light on the internal mechanisms underlying multilingual reasoning in LLMs and suggest a lightweight and interpretable strategy for improving cross-lingual generalization.","authors":["Weixiang Zhao","Jiahe Guo","Yang Deng","Tongtong Wu","Wenxuan Zhang","Yulin Hu","Xingyu Sui","Yanyan Zhao","Wanxiang Che","Bing Qin","Tat-Seng Chua","Ting Liu"],"url":"https://arxiv.org/abs/2505.15257"}
{"created":"2025-05-22","title":"ReGUIDE: Data Efficient GUI Grounding via Spatial Reasoning and Search","abstract":"Recent advances in Multimodal Large Language Models (MLLMs) have enabled autonomous agents to interact with computers via Graphical User Interfaces (GUIs), where accurately localizing the coordinates of interface elements (e.g., buttons) is often required for fine-grained actions. However, this remains significantly challenging, leading prior works to rely on large-scale web datasets to improve the grounding accuracy. In this work, we propose Reasoning Graphical User Interface Grounding for Data Efficiency (ReGUIDE), a novel and effective framework for web grounding that enables MLLMs to learn data efficiently through self-generated reasoning and spatial-aware criticism. More specifically, ReGUIDE learns to (i) self-generate a language reasoning process for the localization via online reinforcement learning, and (ii) criticize the prediction using spatial priors that enforce equivariance under input transformations. At inference time, ReGUIDE further boosts performance through a test-time scaling strategy, which combines spatial search with coordinate aggregation. Our experiments demonstrate that ReGUIDE significantly advances web grounding performance across multiple benchmarks, outperforming baselines with substantially fewer training data points (e.g., only 0.2% samples compared to the best open-sourced baselines).","authors":["Hyunseok Lee","Jeonghoon Kim","Beomjun Kim","Jihoon Tack","Chansong Jo","Jaehong Lee","Cheonbok Park","Sookyo In","Jinwoo Shin","Kang Min Yoo"],"url":"https://arxiv.org/abs/2505.15259"}
{"created":"2025-05-22","title":"AGENT-X: Adaptive Guideline-based Expert Network for Threshold-free AI-generated teXt detection","abstract":"Existing AI-generated text detection methods heavily depend on large annotated datasets and external threshold tuning, restricting interpretability, adaptability, and zero-shot effectiveness. To address these limitations, we propose AGENT-X, a zero-shot multi-agent framework informed by classical rhetoric and systemic functional linguistics. Specifically, we organize detection guidelines into semantic, stylistic, and structural dimensions, each independently evaluated by specialized linguistic agents that provide explicit reasoning and robust calibrated confidence via semantic steering. A meta agent integrates these assessments through confidence-aware aggregation, enabling threshold-free, interpretable classification. Additionally, an adaptive Mixture-of-Agent router dynamically selects guidelines based on inferred textual characteristics. Experiments on diverse datasets demonstrate that AGENT-X substantially surpasses state-of-the-art supervised and zero-shot approaches in accuracy, interpretability, and generalization.","authors":["Jiatao Li","Mao Ye","Cheng Peng","Xunjian Yin","Xiaojun Wan"],"url":"https://arxiv.org/abs/2505.15261"}
{"created":"2025-05-22","title":"gen2seg: Generative Models Enable Generalizable Instance Segmentation","abstract":"By pretraining to synthesize coherent images from perturbed inputs, generative models inherently learn to understand object boundaries and scene compositions. How can we repurpose these generative representations for general-purpose perceptual organization? We finetune Stable Diffusion and MAE (encoder+decoder) for category-agnostic instance segmentation using our instance coloring loss exclusively on a narrow set of object types (indoor furnishings and cars). Surprisingly, our models exhibit strong zero-shot generalization, accurately segmenting objects of types and styles unseen in finetuning (and in many cases, MAE's ImageNet-1K pretraining too). Our best-performing models closely approach the heavily supervised SAM when evaluated on unseen object types and styles, and outperform it when segmenting fine structures and ambiguous boundaries. In contrast, existing promptable segmentation architectures or discriminatively pretrained models fail to generalize. This suggests that generative models learn an inherent grouping mechanism that transfers across categories and domains, even without internet-scale pretraining. Code, pretrained models, and demos are available on our website.","authors":["Om Khangaonkar","Hamed Pirsiavash"],"url":"https://arxiv.org/abs/2505.15263"}
{"created":"2025-05-22","title":"Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs","abstract":"Adversarial attacks aim to generate malicious inputs that mislead deep models, but beyond causing model failure, they cannot provide certain interpretable information such as ``\\textit{What content in inputs make models more likely to fail?}'' However, this information is crucial for researchers to specifically improve model robustness. Recent research suggests that models may be particularly sensitive to certain semantics in visual inputs (such as ``wet,'' ``foggy''), making them prone to errors. Inspired by this, in this paper we conducted the first exploration on large vision-language models (LVLMs) and found that LVLMs indeed are susceptible to hallucinations and various errors when facing specific semantic concepts in images. To efficiently search for these sensitive concepts, we integrated large language models (LLMs) and text-to-image (T2I) models to propose a novel semantic evolution framework. Randomly initialized semantic concepts undergo LLM-based crossover and mutation operations to form image descriptions, which are then converted by T2I models into visual inputs for LVLMs. The task-specific performance of LVLMs on each input is quantified as fitness scores for the involved semantics and serves as reward signals to further guide LLMs in exploring concepts that induce LVLMs. Extensive experiments on seven mainstream LVLMs and two multimodal tasks demonstrate the effectiveness of our method. Additionally, we provide interesting findings about the sensitive semantics of LVLMs, aiming to inspire further in-depth research.","authors":["Zihao Pan","Yu Tong","Weibin Wu","Jingyi Wang","Lifeng Chen","Zhe Zhao","Jiajia Wei","Yitong Qiao","Zibin Zheng"],"url":"https://arxiv.org/abs/2505.15265"}
{"created":"2025-05-22","title":"Contrastive Learning-Enhanced Trajectory Matching for Small-Scale Dataset Distillation","abstract":"Deploying machine learning models in resource-constrained environments, such as edge devices or rapid prototyping scenarios, increasingly demands distillation of large datasets into significantly smaller yet informative synthetic datasets. Current dataset distillation techniques, particularly Trajectory Matching methods, optimize synthetic data so that the model's training trajectory on synthetic samples mirrors that on real data. While demonstrating efficacy on medium-scale synthetic datasets, these methods fail to adequately preserve semantic richness under extreme sample scarcity. To address this limitation, we propose a novel dataset distillation method integrating contrastive learning during image synthesis. By explicitly maximizing instance-level feature discrimination, our approach produces more informative and diverse synthetic samples, even when dataset sizes are significantly constrained. Experimental results demonstrate that incorporating contrastive learning substantially enhances the performance of models trained on very small-scale synthetic datasets. This integration not only guides more effective feature representation but also significantly improves the visual fidelity of the synthesized images. Experimental results demonstrate that our method achieves notable performance improvements over existing distillation techniques, especially in scenarios with extremely limited synthetic data.","authors":["Wenmin Li","Shunsuke Sakai","Tatsuhito Hasegawa"],"url":"https://arxiv.org/abs/2505.15267"}
{"created":"2025-05-22","title":"Fiber Nonlinearity Mitigation in Coherent Optical Systems","abstract":"Fiber nonlinearity represents a critical challenge to the capacity enhancement of modern optical communication systems. In recent years, significant research efforts have focused on mitigating its impact through two complementary approaches. On the one hand, researchers have investigated practical digital signal processing (DSP) techniques to mitigate or compensate for nonlinear impairments, such as reversing fiber propagation effects through digital backpropagation (DBP). However, the high computational complexity of these techniques often discourages their practical implementation. On the other hand, information-theoretic studies have sought to establish the capacity limits of the nonlinear optical fiber channel, providing a framework for evaluating the ultimate performance of existing optical networks and guiding the design of next-generation systems. This work reviews recent advances and proposes future directions for nonlinearity compensation and mitigation, including constellation shaping techniques and low-complexity DBP. Furthermore, it highlights the potential of these innovations both in advancing the theoretical understanding of fiber capacity limits and in enabling practical DSP implementations.","authors":["Stella Civelli","Dario Cellini","Enrico Forestieri","Marco Secondini"],"url":"https://arxiv.org/abs/2505.15268"}
{"created":"2025-05-22","title":"LiveVLM: Efficient Online Video Understanding via Streaming-Oriented KV Cache and Retrieval","abstract":"Recent developments in Video Large Language Models (Video LLMs) have enabled models to process long video sequences and demonstrate remarkable performance. Nonetheless, studies predominantly focus on offline video question answering, neglecting memory usage and response speed that are essential in various real-world applications, such as Deepseek services, autonomous driving, and robotics. To mitigate these challenges, we propose $\\textbf{LiveVLM}$, a training-free framework specifically designed for streaming, online video understanding and real-time interaction. Unlike existing works that process videos only after one question is posed, LiveVLM constructs an innovative streaming-oriented KV cache to process video streams in real-time, retain long-term video details and eliminate redundant KVs, ensuring prompt responses to user queries. For continuous video streams, LiveVLM generates and compresses video key-value tensors (video KVs) to reserve visual information while improving memory efficiency. Furthermore, when a new question is proposed, LiveVLM incorporates an online question-answering process that efficiently fetches both short-term and long-term visual information, while minimizing interference from redundant context. Extensive experiments demonstrate that LiveVLM enables the foundation LLaVA-OneVision model to process 44$\\times$ number of frames on the same device, and achieves up to 5$\\times$ speedup in response speed compared with SoTA online methods at an input of 256 frames, while maintaining the same or better model performance.","authors":["Zhenyu Ning","Guangda Liu","Qihao Jin","Wenchao Ding","Minyi Guo","Jieru Zhao"],"url":"https://arxiv.org/abs/2505.15269"}
{"created":"2025-05-22","title":"Scaling Diffusion Transformers Efficiently via $\\mu$P","abstract":"Diffusion Transformers have emerged as the foundation for vision generative models, but their scalability is limited by the high cost of hyperparameter (HP) tuning at large scales. Recently, Maximal Update Parametrization ($\\mu$P) was proposed for vanilla Transformers, which enables stable HP transfer from small to large language models, and dramatically reduces tuning costs. However, it remains unclear whether $\\mu$P of vanilla Transformers extends to diffusion Transformers, which differ architecturally and objectively. In this work, we generalize standard $\\mu$P to diffusion Transformers and validate its effectiveness through large-scale experiments. First, we rigorously prove that $\\mu$P of mainstream diffusion Transformers, including DiT, U-ViT, PixArt-$\\alpha$, and MMDiT, aligns with that of the vanilla Transformer, enabling the direct application of existing $\\mu$P methodologies. Leveraging this result, we systematically demonstrate that DiT-$\\mu$P enjoys robust HP transferability. Notably, DiT-XL-2-$\\mu$P with transferred learning rate achieves 2.9 times faster convergence than the original DiT-XL-2. Finally, we validate the effectiveness of $\\mu$P on text-to-image generation by scaling PixArt-$\\alpha$ from 0.04B to 0.61B and MMDiT from 0.18B to 18B. In both cases, models under $\\mu$P outperform their respective baselines while requiring small tuning cost, only 5.5% of one training run for PixArt-$\\alpha$ and 3% of consumption by human experts for MMDiT-18B. These results establish $\\mu$P as a principled and efficient framework for scaling diffusion Transformers.","authors":["Chenyu Zheng","Xinyu Zhang","Rongzhen Wang","Wei Huang","Zhi Tian","Weilin Huang","Jun Zhu","Chongxuan Li"],"url":"https://arxiv.org/abs/2505.15270"}
{"created":"2025-05-22","title":"WISP: Image Segmentation-Based Whitespace Diagnosis for Optimal Rectilinear Floorplanning","abstract":"The increasing number of rectilinear floorplans in modern chip designs presents significant challenges for traditional macro placers due to the additional complexity introduced by blocked corners. Particularly, the widely adopted wirelength model Half-Perimeter Wirelength (HPWL) struggles to accurately handle rectilinear boundaries, highlighting the need for additional objectives tailored to rectilinear floorplan optimization. In this paper, we identify the necessity for whitespace diagnosis in rectilinear floorplanning, an aspect often overlooked in past research. We introduce WISP, a novel framework that analyzes and scores whitespace regions to guide placement optimization. WISP leverages image segmentation techniques for whitespace parsing, a lightweight probabilistic model to score whitespace regions based on macro distribution, a Gaussian Mixture Model (GMM) for whitespace density scoring and direction-aware macro relocation to iteratively refine macro placement, reduce wasted whitespace, and enhance design quality. The proposed diagnostic technique also enables the reclamation of block-level unused area and its return to the top level, maximizing overall area utilization. When compared against state-of-the-art academia placer DREAMPlace 4.1, our method achieves an average improvement of 5.4% in routing wirelength, with a maximum of 11.4% across widely-used benchmarks. This yields an average of 41.5% and 43.7% improvement in Worst Negative Slack (WNS) and Total Negative Slack (TNS), respectively. Additionally, WISP recycles an average of 16.2% area at the block level, contributing to more efficient top-level area distribution.","authors":["Xiaotian Zhao","Zixuan Li","Yichen Cai","Xinfei Guo"],"url":"https://arxiv.org/abs/2505.15271"}
{"created":"2025-05-22","title":"DiffProb: Data Pruning for Face Recognition","abstract":"Face recognition models have made substantial progress due to advances in deep learning and the availability of large-scale datasets. However, reliance on massive annotated datasets introduces challenges related to training computational cost and data storage, as well as potential privacy concerns regarding managing large face datasets. This paper presents DiffProb, the first data pruning approach for the application of face recognition. DiffProb assesses the prediction probabilities of training samples within each identity and prunes the ones with identical or close prediction probability values, as they are likely reinforcing the same decision boundaries, and thus contribute minimally with new information. We further enhance this process with an auxiliary cleaning mechanism to eliminate mislabeled and label-flipped samples, boosting data quality with minimal loss. Extensive experiments on CASIA-WebFace with different pruning ratios and multiple benchmarks, including LFW, CFP-FP, and IJB-C, demonstrate that DiffProb can prune up to 50% of the dataset while maintaining or even, in some settings, improving the verification accuracies. Additionally, we demonstrate DiffProb's robustness across different architectures and loss functions. Our method significantly reduces training cost and data volume, enabling efficient face recognition training and reducing the reliance on massive datasets and their demanding management.","authors":["Eduarda Caldeira","Jan Niklas Kolf","Naser Damer","Fadi Boutros"],"url":"https://arxiv.org/abs/2505.15272"}
{"created":"2025-05-22","title":"Identification of Probabilities of Causation: A Complete Characterization","abstract":"Probabilities of causation are fundamental to modern decision-making. Pearl first introduced three binary probabilities of causation, and Tian and Pearl later derived tight bounds for them using Balke's linear programming. The theoretical characterization of probabilities of causation with multi-valued treatments and outcomes has remained unresolved for decades, limiting the scope of causality-based decision-making. In this paper, we resolve this foundational gap by proposing a complete set of representative probabilities of causation and proving that they are sufficient to characterize all possible probabilities of causation within the framework of Structural Causal Models (SCMs). We then formally derive tight bounds for these representative quantities using formal mathematical proofs. Finally, we demonstrate the practical relevance of our results through illustrative toy examples.","authors":["Xin Shu","Shuai Wang","Ang Li"],"url":"https://arxiv.org/abs/2505.15274"}
{"created":"2025-05-22","title":"Learning-based Autonomous Oversteer Control and Collision Avoidance","abstract":"Oversteer, wherein a vehicle's rear tires lose traction and induce unintentional excessive yaw, poses critical safety challenges. Failing to control oversteer often leads to severe traffic accidents. Although recent autonomous driving efforts have attempted to handle oversteer through stabilizing maneuvers, the majority rely on expert-defined trajectories or assume obstacle-free environments, limiting real-world applicability. This paper introduces a novel end-to-end (E2E) autonomous driving approach that tackles oversteer control and collision avoidance simultaneously. Existing E2E techniques, including Imitation Learning (IL), Reinforcement Learning (RL), and Hybrid Learning (HL), generally require near-optimal demonstrations or extensive experience. Yet even skilled human drivers struggle to provide perfect demonstrations under oversteer, and high transition variance hinders accumulating sufficient data. Hence, we present Q-Compared Soft Actor-Critic (QC-SAC), a new HL algorithm that effectively learns from suboptimal demonstration data and adapts rapidly to new conditions. To evaluate QC-SAC, we introduce a benchmark inspired by real-world driver training: a vehicle encounters sudden oversteer on a slippery surface and must avoid randomly placed obstacles ahead. Experimental results show QC-SAC attains near-optimal driving policies, significantly surpassing state-of-the-art IL, RL, and HL baselines. Our method demonstrates the world's first safe autonomous oversteer control with obstacle avoidance.","authors":["Seokjun Lee","Seung-Hyun Kong"],"url":"https://arxiv.org/abs/2505.15275"}
{"created":"2025-05-22","title":"When Can Large Reasoning Models Save Thinking? Mechanistic Analysis of Behavioral Divergence in Reasoning","abstract":"Large reasoning models (LRMs) have significantly advanced performance on complex tasks, yet their tendency to overthink introduces inefficiencies. This study investigates the internal mechanisms of reinforcement learning (RL)-trained LRMs when prompted to save thinking, revealing three distinct thinking modes: no thinking (NT), explicit thinking (ET), and implicit thinking (IT). Through comprehensive analysis of confidence in thinking termination, attention from thinking to generation, and attentional focus on input sections, we uncover key factors influencing the reasoning behaviors. We further find that NT reduces output length at the cost of accuracy, while ET and IT maintain accuracy with reduced response length. Our findings expose fundamental inconsistencies in RL-optimized LRMs, necessitating adaptive improvements for reliable efficiency.","authors":["Rongzhi Zhu","Yi Liu","Zequn Sun","Yiwei Wang","Wei Hu"],"url":"https://arxiv.org/abs/2505.15276"}
{"created":"2025-05-22","title":"Web-Shepherd: Advancing PRMs for Reinforcing Web Agents","abstract":"Web navigation is a unique domain that can automate many repetitive real-life tasks and is challenging as it requires long-horizon sequential decision making beyond typical multimodal large language model (MLLM) tasks. Yet, specialized reward models for web navigation that can be utilized during both training and test-time have been absent until now. Despite the importance of speed and cost-effectiveness, prior works have utilized MLLMs as reward models, which poses significant constraints for real-world deployment. To address this, in this work, we propose the first process reward model (PRM) called Web-Shepherd which could assess web navigation trajectories in a step-level. To achieve this, we first construct the WebPRM Collection, a large-scale dataset with 40K step-level preference pairs and annotated checklists spanning diverse domains and difficulty levels. Next, we also introduce the WebRewardBench, the first meta-evaluation benchmark for evaluating PRMs. In our experiments, we observe that our Web-Shepherd achieves about 30 points better accuracy compared to using GPT-4o on WebRewardBench. Furthermore, when testing on WebArena-lite by using GPT-4o-mini as the policy and Web-Shepherd as the verifier, we achieve 10.9 points better performance, in 10 less cost compared to using GPT-4o-mini as the verifier. Our model, dataset, and code are publicly available at LINK.","authors":["Hyungjoo Chae","Sunghwan Kim","Junhee Cho","Seungone Kim","Seungjun Moon","Gyeom Hwangbo","Dongha Lim","Minjin Kim","Yeonjun Hwang","Minju Gwak","Dongwook Choi","Minseok Kang","Gwanhoon Im","ByeongUng Cho","Hyojun Kim","Jun Hee Han","Taeyoon Kwon","Minju Kim","Beong-woo Kwak","Dongjin Kang","Jinyoung Yeo"],"url":"https://arxiv.org/abs/2505.15277"}
{"created":"2025-05-22","title":"Exploring In-Image Machine Translation with Real-World Background","abstract":"In-Image Machine Translation (IIMT) aims to translate texts within images from one language to another. Previous research on IIMT was primarily conducted on simplified scenarios such as images of one-line text with black font in white backgrounds, which is far from reality and impractical for applications in the real world. To make IIMT research practically valuable, it is essential to consider a complex scenario where the text backgrounds are derived from real-world images. To facilitate research of complex scenario IIMT, we design an IIMT dataset that includes subtitle text with real-world background. However previous IIMT models perform inadequately in complex scenarios. To address the issue, we propose the DebackX model, which separates the background and text-image from the source image, performs translation on text-image directly, and fuses the translated text-image with the background, to generate the target image. Experimental results show that our model achieves improvements in both translation quality and visual effect.","authors":["Yanzhi Tian","Zeming Liu","Zhengyang Liu","Yuhang Guo"],"url":"https://arxiv.org/abs/2505.15282"}
{"created":"2025-05-22","title":"Kernel PCA for Out-of-Distribution Detection: Non-Linear Kernel Selections and Approximations","abstract":"Out-of-Distribution (OoD) detection is vital for the reliability of deep neural networks, the key of which lies in effectively characterizing the disparities between OoD and In-Distribution (InD) data. In this work, such disparities are exploited through a fresh perspective of non-linear feature subspace. That is, a discriminative non-linear subspace is learned from InD features to capture representative patterns of InD, while informative patterns of OoD features cannot be well captured in such a subspace due to their different distribution. Grounded on this perspective, we exploit the deviations of InD and OoD features in such a non-linear subspace for effective OoD detection. To be specific, we leverage the framework of Kernel Principal Component Analysis (KPCA) to attain the discriminative non-linear subspace and deploy the reconstruction error on such subspace to distinguish InD and OoD data. Two challenges emerge: (i) the learning of an effective non-linear subspace, i.e., the selection of kernel function in KPCA, and (ii) the computation of the kernel matrix with large-scale InD data. For the former, we reveal two vital non-linear patterns that closely relate to the InD-OoD disparity, leading to the establishment of a Cosine-Gaussian kernel for constructing the subspace. For the latter, we introduce two techniques to approximate the Cosine-Gaussian kernel with significantly cheap computations. In particular, our approximation is further tailored by incorporating the InD data confidence, which is demonstrated to promote the learning of discriminative subspaces for OoD data. Our study presents new insights into the non-linear feature subspace for OoD detection and contributes practical explorations on the associated kernel design and efficient computations, yielding a KPCA detection method with distinctively improved efficacy and efficiency.","authors":["Kun Fang","Qinghua Tao","Mingzhen He","Kexin Lv","Runze Yang","Haibo Hu","Xiaolin Huang","Jie Yang","Longbin Cao"],"url":"https://arxiv.org/abs/2505.15284"}
{"created":"2025-05-22","title":"GS2E: Gaussian Splatting is an Effective Data Generator for Event Stream Generation","abstract":"We introduce GS2E (Gaussian Splatting to Event), a large-scale synthetic event dataset for high-fidelity event vision tasks, captured from real-world sparse multi-view RGB images. Existing event datasets are often synthesized from dense RGB videos, which typically lack viewpoint diversity and geometric consistency, or depend on expensive, difficult-to-scale hardware setups. GS2E overcomes these limitations by first reconstructing photorealistic static scenes using 3D Gaussian Splatting, and subsequently employing a novel, physically-informed event simulation pipeline. This pipeline generally integrates adaptive trajectory interpolation with physically-consistent event contrast threshold modeling. Such an approach yields temporally dense and geometrically consistent event streams under diverse motion and lighting conditions, while ensuring strong alignment with underlying scene structures. Experimental results on event-based 3D reconstruction demonstrate GS2E's superior generalization capabilities and its practical value as a benchmark for advancing event vision research.","authors":["Yuchen Li","Chaoran Feng","Zhenyu Tang","Kaiyuan Deng","Wangbo Yu","Yonghong Tian","Li Yuan"],"url":"https://arxiv.org/abs/2505.15287"}
{"created":"2025-05-22","title":"Robust Probabilistic Bisimilarity for Labelled Markov Chains","abstract":"Despite its prevalence, probabilistic bisimilarity suffers from a lack of robustness under minuscule perturbations of the transition probabilities. This can lead to discontinuities in the probabilistic bisimilarity distance function, undermining its reliability in practical applications where transition probabilities are often approximations derived from experimental data. Motivated by this limitation, we introduce the notion of robust probabilistic bisimilarity for labelled Markov chains, which ensures the continuity of the probabilistic bisimilarity distance function. We also propose an efficient algorithm for computing robust probabilistic bisimilarity and show that it performs well in practice, as evidenced by our experimental results.","authors":["Syyeda Zainab Fatmi","Stefan Kiefer","David Parker","Franck van Breugel"],"url":"https://arxiv.org/abs/2505.15290"}
{"created":"2025-05-22","title":"Hallucinate at the Last in Long Response Generation: A Case Study on Long Document Summarization","abstract":"Large Language Models (LLMs) have significantly advanced text generation capabilities, including tasks like summarization, often producing coherent and fluent outputs. However, faithfulness to source material remains a significant challenge due to the generation of hallucinations. While extensive research focuses on detecting and reducing these inaccuracies, less attention has been paid to the positional distribution of hallucination within generated text, particularly in long outputs. In this work, we investigate where hallucinations occur in LLM-based long response generation, using long document summarization as a key case study. Focusing on the challenging setting of long context-aware long response generation, we find a consistent and concerning phenomenon: hallucinations tend to concentrate disproportionately in the latter parts of the generated long response. To understand this bias, we explore potential contributing factors related to the dynamics of attention and decoding over long sequences. Furthermore, we investigate methods to mitigate this positional hallucination, aiming to improve faithfulness specifically in the concluding segments of long outputs.","authors":["Joonho Yang","Seunghyun Yoon","Hwan Chang","Byeongjeong Kim","Hwanhee Lee"],"url":"https://arxiv.org/abs/2505.15291"}
{"created":"2025-05-22","title":"LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models","abstract":"Policy exploration is critical in reinforcement learning (RL), where existing approaches include greedy, Gaussian process, etc. However, these approaches utilize preset stochastic processes and are indiscriminately applied in all kinds of RL tasks without considering task-specific features that influence policy exploration. Moreover, during RL training, the evolution of such stochastic processes is rigid, which typically only incorporates a decay in the variance, failing to adjust flexibly according to the agent's real-time learning status. Inspired by the analyzing and reasoning capability of large language models (LLMs), we design LLM-Explorer to adaptively generate task-specific exploration strategies with LLMs, enhancing the policy exploration in RL. In our design, we sample the learning trajectory of the agent during the RL training in a given task and prompt the LLM to analyze the agent's current policy learning status and then generate a probability distribution for future policy exploration. Updating the probability distribution periodically, we derive a stochastic process specialized for the particular task and dynamically adjusted to adapt to the learning process. Our design is a plug-in module compatible with various widely applied RL algorithms, including the DQN series, DDPG, TD3, and any possible variants developed based on them. Through extensive experiments on the Atari and MuJoCo benchmarks, we demonstrate LLM-Explorer's capability to enhance RL policy exploration, achieving an average performance improvement up to 37.27%. Our code is open-source at https://anonymous.4open.science/r/LLM-Explorer-19BE for reproducibility.","authors":["Qianyue Hao","Yiwen Song","Qingmin Liao","Jian Yuan","Yong Li"],"url":"https://arxiv.org/abs/2505.15293"}
{"created":"2025-05-22","title":"R3GS: Gaussian Splatting for Robust Reconstruction and Relocalization in Unconstrained Image Collections","abstract":"We propose R3GS, a robust reconstruction and relocalization framework tailored for unconstrained datasets. Our method uses a hybrid representation during training. Each anchor combines a global feature from a convolutional neural network (CNN) with a local feature encoded by the multiresolution hash grids [2]. Subsequently, several shallow multi-layer perceptrons (MLPs) predict the attributes of each Gaussians, including color, opacity, and covariance. To mitigate the adverse effects of transient objects on the reconstruction process, we ffne-tune a lightweight human detection network. Once ffne-tuned, this network generates a visibility map that efffciently generalizes to other transient objects (such as posters, banners, and cars) with minimal need for further adaptation. Additionally, to address the challenges posed by sky regions in outdoor scenes, we propose an effective sky-handling technique that incorporates a depth prior as a constraint. This allows the inffnitely distant sky to be represented on the surface of a large-radius sky sphere, signiffcantly reducing ffoaters caused by errors in sky reconstruction. Furthermore, we introduce a novel relocalization method that remains robust to changes in lighting conditions while estimating the camera pose of a given image within the reconstructed 3DGS scene. As a result, R3GS significantly enhances rendering ffdelity, improves both training and rendering efffciency, and reduces storage requirements. Our method achieves state-of-the-art performance compared to baseline methods on in-the-wild datasets. The code will be made open-source following the acceptance of the paper.","authors":["Xu yan","Zhaohui Wang","Rong Wei","Jingbo Yu","Dong Li","Xiangde Liu"],"url":"https://arxiv.org/abs/2505.15294"}
{"created":"2025-05-22","title":"Chinese Toxic Language Mitigation via Sentiment Polarity Consistent Rewrites","abstract":"Detoxifying offensive language while preserving the speaker's original intent is a challenging yet critical goal for improving the quality of online interactions. Although large language models (LLMs) show promise in rewriting toxic content, they often default to overly polite rewrites, distorting the emotional tone and communicative intent. This problem is especially acute in Chinese, where toxicity often arises implicitly through emojis, homophones, or discourse context. We present ToxiRewriteCN, the first Chinese detoxification dataset explicitly designed to preserve sentiment polarity. The dataset comprises 1,556 carefully annotated triplets, each containing a toxic sentence, a sentiment-aligned non-toxic rewrite, and labeled toxic spans. It covers five real-world scenarios: standard expressions, emoji-induced and homophonic toxicity, as well as single-turn and multi-turn dialogues. We evaluate 17 LLMs, including commercial and open-source models with variant architectures, across four dimensions: detoxification accuracy, fluency, content preservation, and sentiment polarity. Results show that while commercial and MoE models perform best overall, all models struggle to balance safety with emotional fidelity in more subtle or context-heavy settings such as emoji, homophone, and dialogue-based inputs. We release ToxiRewriteCN to support future research on controllable, sentiment-aware detoxification for Chinese.","authors":["Xintong Wang","Yixiao Liu","Jingheng Pan","Liang Ding","Longyue Wang","Chris Biemann"],"url":"https://arxiv.org/abs/2505.15297"}
{"created":"2025-05-22","title":"AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving","abstract":"Vision-Language Models (VLMs) show promise for autonomous driving, yet their struggle with hallucinations, inefficient reasoning, and limited real-world validation hinders accurate perception and robust step-by-step reasoning. To overcome this, we introduce \\textbf{AgentThink}, a pioneering unified framework that, for the first time, integrates Chain-of-Thought (CoT) reasoning with dynamic, agent-style tool invocation for autonomous driving tasks. AgentThink's core innovations include: \\textbf{(i) Structured Data Generation}, by establishing an autonomous driving tool library to automatically construct structured, self-verified reasoning data explicitly incorporating tool usage for diverse driving scenarios; \\textbf{(ii) A Two-stage Training Pipeline}, employing Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to equip VLMs with the capability for autonomous tool invocation; and \\textbf{(iii) Agent-style Tool-Usage Evaluation}, introducing a novel multi-tool assessment protocol to rigorously evaluate the model's tool invocation and utilization. Experiments on the DriveLMM-o1 benchmark demonstrate AgentThink significantly boosts overall reasoning scores by \\textbf{53.91\\%} and enhances answer accuracy by \\textbf{33.54\\%}, while markedly improving reasoning quality and consistency. Furthermore, ablation studies and robust zero-shot/few-shot generalization experiments across various benchmarks underscore its powerful capabilities. These findings highlight a promising trajectory for developing trustworthy and tool-aware autonomous driving models.","authors":["Kangan Qian","Sicong Jiang","Yang Zhong","Ziang Luo","Zilin Huang","Tianze Zhu","Kun Jiang","Mengmeng Yang","Zheng Fu","Jinyu Miao","Yining Shi","He Zhe Lim","Li Liu","Tianbao Zhou","Hongyi Wang","Huang Yu","Yifei Hu","Guang Li","Guang Chen","Hao Ye","Lijun Sun","Diange Yang"],"url":"https://arxiv.org/abs/2505.15298"}
{"created":"2025-05-22","title":"Multi-Hop Question Generation via Dual-Perspective Keyword Guidance","abstract":"Multi-hop question generation (MQG) aims to generate questions that require synthesizing multiple information snippets from documents to derive target answers. The primary challenge lies in effectively pinpointing crucial information snippets related to question-answer (QA) pairs, typically relying on keywords. However, existing works fail to fully utilize the guiding potential of keywords and neglect to differentiate the distinct roles of question-specific and document-specific keywords. To address this, we define dual-perspective keywords (i.e., question and document keywords) and propose a Dual-Perspective Keyword-Guided (DPKG) framework, which seamlessly integrates keywords into the multi-hop question generation process. We argue that question keywords capture the questioner's intent, whereas document keywords reflect the content related to the QA pair. Functionally, question and document keywords work together to pinpoint essential information snippets in the document, with question keywords required to appear in the generated question. The DPKG framework consists of an expanded transformer encoder and two answer-aware transformer decoders for keyword and question generation, respectively. Extensive experiments demonstrate the effectiveness of our work, showcasing its promising performance and underscoring its significant value in the MQG task.","authors":["Maodong Li","Longyin Zhang","Fang Kong"],"url":"https://arxiv.org/abs/2505.15299"}
{"created":"2025-05-22","title":"Laplace Sample Information: Data Informativeness Through a Bayesian Lens","abstract":"Accurately estimating the informativeness of individual samples in a dataset is an important objective in deep learning, as it can guide sample selection, which can improve model efficiency and accuracy by removing redundant or potentially harmful samples. We propose Laplace Sample Information (LSI) measure of sample informativeness grounded in information theory widely applicable across model architectures and learning settings. LSI leverages a Bayesian approximation to the weight posterior and the KL divergence to measure the change in the parameter distribution induced by a sample of interest from the dataset. We experimentally show that LSI is effective in ordering the data with respect to typicality, detecting mislabeled samples, measuring class-wise informativeness, and assessing dataset difficulty. We demonstrate these capabilities of LSI on image and text data in supervised and unsupervised settings. Moreover, we show that LSI can be computed efficiently through probes and transfers well to the training of large models.","authors":["Johannes Kaiser","Kristian Schwethelm","Daniel Rueckert","Georgios Kaissis"],"url":"https://arxiv.org/abs/2505.15303"}
{"created":"2025-05-22","title":"Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control","abstract":"Deep neural network (DNN)-based policy models, such as vision-language-action (VLA) models, excel at automating complex decision-making from multi-modal inputs. However, scaling these models greatly increases computational overhead, complicating deployment in resource-constrained settings like robot manipulation and autonomous driving. To address this, we propose Saliency-Aware Quantized Imitation Learning (SQIL), which combines quantization-aware training with a selective loss-weighting strategy for mission-critical states. By identifying these states via saliency scores and emphasizing them in the training loss, SQIL preserves decision fidelity under low-bit precision. We validate SQIL's generalization capability across extensive simulation benchmarks with environment variations, real-world tasks, and cross-domain tasks (self-driving, physics simulation), consistently recovering full-precision performance. Notably, a 4-bit weight-quantized VLA model for robotic manipulation achieves up to 2.5x speedup and 2.5x energy savings on an edge GPU with minimal accuracy loss. These results underline SQIL's potential for efficiently deploying large IL-based policy models on resource-limited devices.","authors":["Seongmin Park","Hyungmin Kim","Sangwoo kim","Wonseok Jeon","Juyoung Yang","Byeongwook Jeon","Yoonseon Oh","Jungwook Choi"],"url":"https://arxiv.org/abs/2505.15304"}
{"created":"2025-05-22","title":"Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One","abstract":"Model ensemble is a useful approach in reinforcement learning (RL) for training effective agents. Despite wide success of RL, training effective agents remains difficult due to the multitude of factors requiring careful tuning, such as algorithm selection, hyperparameter settings, and even random seed choices, all of which can significantly influence an agent's performance. Model ensemble helps overcome this challenge by combining multiple weak agents into a single, more powerful one, enhancing overall performance. However, existing ensemble methods, such as majority voting and Boltzmann addition, are designed as fixed strategies and lack a semantic understanding of specific tasks, limiting their adaptability and effectiveness. To address this, we propose LLM-Ens, a novel approach that enhances RL model ensemble with task-specific semantic understandings driven by large language models (LLMs). Given a task, we first design an LLM to categorize states in this task into distinct 'situations', incorporating high-level descriptions of the task conditions. Then, we statistically analyze the strengths and weaknesses of each individual agent to be used in the ensemble in each situation. During the inference time, LLM-Ens dynamically identifies the changing task situation and switches to the agent that performs best in the current situation, ensuring dynamic model selection in the evolving task condition. Our approach is designed to be compatible with agents trained with different random seeds, hyperparameter settings, and various RL algorithms. Extensive experiments on the Atari benchmark show that LLM-Ens significantly improves the RL model ensemble, surpassing well-known baselines by up to 20.9%. For reproducibility, our code is open-source at https://anonymous.4open.science/r/LLM4RLensemble-F7EE.","authors":["Yiwen Song","Qianyue Hao","Qingmin Liao","Jian Yuan","Yong Li"],"url":"https://arxiv.org/abs/2505.15306"}
{"created":"2025-05-22","title":"BadSR: Stealthy Label Backdoor Attacks on Image Super-Resolution","abstract":"With the widespread application of super-resolution (SR) in various fields, researchers have begun to investigate its security. Previous studies have demonstrated that SR models can also be subjected to backdoor attacks through data poisoning, affecting downstream tasks. A backdoor SR model generates an attacker-predefined target image when given a triggered image while producing a normal high-resolution (HR) output for clean images. However, prior backdoor attacks on SR models have primarily focused on the stealthiness of poisoned low-resolution (LR) images while ignoring the stealthiness of poisoned HR images, making it easy for users to detect anomalous data. To address this problem, we propose BadSR, which improves the stealthiness of poisoned HR images. The key idea of BadSR is to approximate the clean HR image and the pre-defined target image in the feature space while ensuring that modifications to the clean HR image remain within a constrained range. The poisoned HR images generated by BadSR can be integrated with existing triggers. To further improve the effectiveness of BadSR, we design an adversarially optimized trigger and a backdoor gradient-driven poisoned sample selection method based on a genetic algorithm. The experimental results show that BadSR achieves a high attack success rate in various models and data sets, significantly affecting downstream tasks.","authors":["Ji Guo","Xiaolei Wen","Wenbo Jiang","Cheng Huang","Jinjin Li","Hongwei Li"],"url":"https://arxiv.org/abs/2505.15308"}
{"created":"2025-05-22","title":"Trajectory Bellman Residual Minimization: A Simple Value-Based Method for LLM Reasoning","abstract":"Policy-based methods currently dominate reinforcement learning (RL) pipelines for large language model (LLM) reasoning, leaving value-based approaches largely unexplored. We revisit the classical paradigm of Bellman Residual Minimization and introduce Trajectory Bellman Residual Minimization (TBRM), an algorithm that naturally adapts this idea to LLMs, yielding a simple yet effective off-policy algorithm that optimizes a single trajectory-level Bellman objective using the model's own logits as $Q$-values. TBRM removes the need for critics, importance-sampling ratios, or clipping, and operates with only one rollout per prompt. We prove convergence to the near-optimal KL-regularized policy from arbitrary off-policy data via an improved change-of-trajectory-measure analysis. Experiments on standard mathematical-reasoning benchmarks show that TBRM consistently outperforms policy-based baselines, like PPO and GRPO, with comparable or lower computational and memory overhead. Our results indicate that value-based RL might be a principled and efficient alternative for enhancing reasoning capabilities in LLMs.","authors":["Yurun Yuan","Fan Chen","Zeyu Jia","Alexander Rakhlin","Tengyang Xie"],"url":"https://arxiv.org/abs/2505.15311"}
{"created":"2025-05-22","title":"Sonnet: Spectral Operator Neural Network for Multivariable Time Series Forecasting","abstract":"Multivariable time series forecasting methods can integrate information from exogenous variables, leading to significant prediction accuracy gains. Transformer architecture has been widely applied in various time series forecasting models due to its ability to capture long-range sequential dependencies. However, a na\\\"ive application of transformers often struggles to effectively model complex relationships among variables over time. To mitigate against this, we propose a novel architecture, namely the Spectral Operator Neural Network (Sonnet). Sonnet applies learnable wavelet transformations to the input and incorporates spectral analysis using the Koopman operator. Its predictive skill relies on the Multivariable Coherence Attention (MVCA), an operation that leverages spectral coherence to model variable dependencies. Our empirical analysis shows that Sonnet yields the best performance on $34$ out of $47$ forecasting tasks with an average mean absolute error (MAE) reduction of $1.1\\%$ against the most competitive baseline (different per task). We further show that MVCA -- when put in place of the na\\\"ive attention used in various deep learning models -- can remedy its deficiencies, reducing MAE by $10.7\\%$ on average in the most challenging forecasting tasks.","authors":["Yuxuan Shu","Vasileios Lampos"],"url":"https://arxiv.org/abs/2505.15312"}
{"created":"2025-05-22","title":"FaceCrafter: Identity-Conditional Diffusion with Disentangled Control over Facial Pose, Expression, and Emotion","abstract":"Human facial images encode a rich spectrum of information, encompassing both stable identity-related traits and mutable attributes such as pose, expression, and emotion. While recent advances in image generation have enabled high-quality identity-conditional face synthesis, precise control over non-identity attributes remains challenging, and disentangling identity from these mutable factors is particularly difficult. To address these limitations, we propose a novel identity-conditional diffusion model that introduces two lightweight control modules designed to independently manipulate facial pose, expression, and emotion without compromising identity preservation. These modules are embedded within the cross-attention layers of the base diffusion model, enabling precise attribute control with minimal parameter overhead. Furthermore, our tailored training strategy, which leverages cross-attention between the identity feature and each non-identity control feature, encourages identity features to remain orthogonal to control signals, enhancing controllability and diversity. Quantitative and qualitative evaluations, along with perceptual user studies, demonstrate that our method surpasses existing approaches in terms of control accuracy over pose, expression, and emotion, while also improving generative diversity under identity-only conditioning.","authors":["Kazuaki Mishima","Antoni Bigata Casademunt","Stavros Petridis","Maja Pantic","Kenji Suzuki"],"url":"https://arxiv.org/abs/2505.15313"}
{"created":"2025-05-22","title":"Local-Global Associative Frames for Symmetry-Preserving Crystal Structure Modeling","abstract":"Crystal structures are defined by the periodic arrangement of atoms in 3D space, inherently making them equivariant to SO(3) group. A fundamental requirement for crystal property prediction is that the model's output should remain invariant to arbitrary rotational transformations of the input structure. One promising strategy to achieve this invariance is to align the given crystal structure into a canonical orientation with appropriately computed rotations, or called frames. However, existing work either only considers a global frame or solely relies on more advanced local frames based on atoms' local structure. A global frame is too coarse to capture the local structure heterogeneity of the crystal, while local frames may inadvertently disrupt crystal symmetry, limiting their expressivity. In this work, we revisit the frame design problem for crystalline materials and propose a novel approach to construct expressive Symmetry-Preserving Frames, dubbed as SPFrame, for modeling crystal structures. Specifically, this local-global associative frame constructs invariant local frames rather than equivariant ones, thereby preserving the symmetry of the crystal. In parallel, it integrates global structural information to construct an equivariant global frame to enforce SO(3) invariance. Extensive experimental results demonstrate that SPFrame consistently outperforms traditional frame construction techniques and existing crystal property prediction baselines across multiple benchmark tasks.","authors":["Haowei Hua","Wanyu Lin"],"url":"https://arxiv.org/abs/2505.15315"}
{"created":"2025-05-22","title":"Emotional Supporters often Use Multiple Strategies in a Single Turn","abstract":"Emotional Support Conversations (ESC) are crucial for providing empathy, validation, and actionable guidance to individuals in distress. However, existing definitions of the ESC task oversimplify the structure of supportive responses, typically modelling them as single strategy-utterance pairs. Through a detailed corpus analysis of the ESConv dataset, we identify a common yet previously overlooked phenomenon: emotional supporters often employ multiple strategies consecutively within a single turn. We formally redefine the ESC task to account for this, proposing a revised formulation that requires generating the full sequence of strategy-utterance pairs given a dialogue history. To facilitate this refined task, we introduce several modelling approaches, including supervised deep learning models and large language models. Our experiments show that, under this redefined task, state-of-the-art LLMs outperform both supervised models and human supporters. Notably, contrary to some earlier findings, we observe that LLMs frequently ask questions and provide suggestions, demonstrating more holistic support capabilities.","authors":["Xin Bai","Guanyi Chen","Tingting He","Chenlian Zhou","Yu Liu"],"url":"https://arxiv.org/abs/2505.15316"}
{"created":"2025-05-22","title":"CEBSNet: Change-Excited and Background-Suppressed Network with Temporal Dependency Modeling for Bitemporal Change Detection","abstract":"Change detection, a critical task in remote sensing and computer vision, aims to identify pixel-level differences between image pairs captured at the same geographic area but different times. It faces numerous challenges such as illumination variation, seasonal changes, background interference, and shooting angles, especially with a large time gap between images. While current methods have advanced, they often overlook temporal dependencies and overemphasize prominent changes while ignoring subtle but equally important changes. To address these limitations, we introduce \\textbf{CEBSNet}, a novel change-excited and background-suppressed network with temporal dependency modeling for change detection. During the feature extraction, we utilize a simple Channel Swap Module (CSM) to model temporal dependency, reducing differences and noise. The Feature Excitation and Suppression Module (FESM) is developed to capture both obvious and subtle changes, maintaining the integrity of change regions. Additionally, we design a Pyramid-Aware Spatial-Channel Attention module (PASCA) to enhance the ability to detect change regions at different sizes and focus on critical regions. We conduct extensive experiments on three common street view datasets and two remote sensing datasets, and our method achieves the state-of-the-art performance.","authors":["Qi'ao Xu","Yan Xing","Jiali Hu","Yunan Jia","Rui Huang"],"url":"https://arxiv.org/abs/2505.15322"}
{"created":"2025-05-22","title":"Improving LLM First-Token Predictions in Multiple-Choice Question Answering via Prefilling Attack","abstract":"Large Language Models (LLMs) are increasingly evaluated on multiple-choice question answering (MCQA) tasks using *first-token probability* (FTP), which selects the answer option whose initial token has the highest likelihood. While efficient, FTP can be fragile: models may assign high probability to unrelated tokens (*misalignment*) or use a valid token merely as part of a generic preamble rather than as a clear answer choice (*misinterpretation*), undermining the reliability of symbolic evaluation. We propose a simple solution: the *prefilling attack*, a structured natural-language prefix (e.g., \"*The correct option is:*\") prepended to the model output. Originally explored in AI safety, we repurpose prefilling to steer the model to respond with a clean, valid option, without modifying its parameters. Empirically, the FTP with prefilling strategy substantially improves accuracy, calibration, and output consistency across a broad set of LLMs and MCQA benchmarks. It outperforms standard FTP and often matches the performance of open-ended generation approaches that require full decoding and external classifiers, while being significantly more efficient. Our findings suggest that prefilling is a simple, robust, and low-cost method to enhance the reliability of FTP-based evaluation in multiple-choice settings.","authors":["Silvia Cappelletti","Tobia Poppi","Samuele Poppi","Zheng-Xin Yong","Diego Garcia-Olano","Marcella Cornia","Lorenzo Baraldi","Rita Cucchiara"],"url":"https://arxiv.org/abs/2505.15323"}
{"created":"2025-05-22","title":"Improved Approximation Algorithms for Path and Forest Augmentation via a Novel Relaxation","abstract":"The Forest Augmentation Problem (FAP) asks for a minimum set of additional edges (links) that make a given forest 2-edge-connected while spanning all vertices. A key special case is the Path Augmentation Problem (PAP), where the input forest consists of vertex-disjoint paths. Grandoni, Jabal Ameli, and Traub [STOC'22] recently broke the long-standing 2-approximation barrier for FAP, achieving a 1.9973-approximation. A crucial component of this result was their 1.9913-approximation for PAP; the first better-than-2 approximation for PAP. In this work, we improve these results and provide a 1.9412-approximation for PAP, which implies a 1.9955-approximation for FAP. One of our key innovations is a $(\\frac{7}{4} + \\varepsilon)$-approximation preserving reduction to so-called structured instances, which simplifies the problem and enables our improved approximation. Additionally, we introduce a new relaxation inspired by 2-edge covers and analyze it via a corresponding packing problem, where the relationship between the two problems is similar to the relationship between 2-edge covers and 2-matchings. Using a factor-revealing LP, we bound the cost of our solution to the packing problem w.r.t. the relaxation and derive a strong initial solution. We then transform this solution into a feasible PAP solution, combining techniques from FAP and related connectivity augmentation problems, along with new insights. A key aspect of our approach is leveraging the properties of structured PAP instances to achieve our final approximation guarantee. Our reduction framework and relaxation may be of independent interest in future work on connectivity augmentation problems.","authors":["Felix Hommelsheim"],"url":"https://arxiv.org/abs/2505.15324"}
{"created":"2025-05-22","title":"SoftHGNN: Soft Hypergraph Neural Networks for General Visual Recognition","abstract":"Visual recognition relies on understanding both the semantics of image tokens and the complex interactions among them. Mainstream self-attention methods, while effective at modeling global pair-wise relations, fail to capture high-order associations inherent in real-world scenes and often suffer from redundant computation. Hypergraphs extend conventional graphs by modeling high-order interactions and offer a promising framework for addressing these limitations. However, existing hypergraph neural networks typically rely on static and hard hyperedge assignments, leading to excessive and redundant hyperedges with hard binary vertex memberships that overlook the continuity of visual semantics. To overcome these issues, we present Soft Hypergraph Neural Networks (SoftHGNNs), which extend the methodology of hypergraph computation, to make it truly efficient and versatile in visual recognition tasks. Our framework introduces the concept of soft hyperedges, where each vertex is associated with hyperedges via continuous participation weights rather than hard binary assignments. This dynamic and differentiable association is achieved by using the learnable hyperedge prototype. Through similarity measurements between token features and the prototype, the model generates semantically rich soft hyperedges. SoftHGNN then aggregates messages over soft hyperedges to capture high-order semantics. To further enhance efficiency when scaling up the number of soft hyperedges, we incorporate a sparse hyperedge selection mechanism that activates only the top-k important hyperedges, along with a load-balancing regularizer to ensure balanced hyperedge utilization. Experimental results across three tasks on five datasets demonstrate that SoftHGNN efficiently captures high-order associations in visual scenes, achieving significant performance improvements.","authors":["Mengqi Lei","Yihong Wu","Siqi Li","Xinhu Zheng","Juan Wang","Yue Gao","Shaoyi Du"],"url":"https://arxiv.org/abs/2505.15325"}
{"created":"2025-05-22","title":"Let's Take Esoteric Programming Languages Seriously","abstract":"Esoteric programming languages are challenging to learn, but their unusual features and constraints may serve to improve programming ability. From languages designed to be intentionally obtuse (e.g. INTERCAL) to others targeting artistic expression (e.g. Piet) or exploring the nature of computation (e.g. Fractan), there is rich variety in the realm of esoteric programming languages. This essay examines the counterintuitive appeal of esoteric languages and seeks to analyse reasons for this popularity. We will explore why people are attracted to esoteric languages in terms of (a) program comprehension and construction, as well as (b) language design and implementation. Our assertion is that esoteric languages can improve general PL awareness, at the same time as enabling the esoteric programmer to impress their peers with obscure knowledge. We will also consider pedagogic principles and the use of AI, in relation to esoteric languages. Emerging from the specific discussion, we identify a general set of 'good' reasons for designing new programming languages. It may not be possible to be exhaustive on this topic, and it is certain we have not achieved that goal here. However we believe our most important contribution is to draw attention to the varied and often implicit motivations involved in programming language design.","authors":["Jeremy Singer","Steve Draper"],"url":"https://arxiv.org/abs/2505.15327"}
{"created":"2025-05-22","title":"Fourier-Invertible Neural Encoder (FINE) for Homogeneous Flows","abstract":"Invertible neural architectures have recently attracted attention for their compactness, interpretability, and information-preserving properties. In this work, we propose the Fourier-Invertible Neural Encoder (FINE), which combines invertible monotonic activation functions with reversible filter structures, and could be extended using Invertible ResNets. This architecture is examined in learning low-dimensional representations of one-dimensional nonlinear wave interactions and exact circular translation symmetry. Dimensionality is preserved across layers, except for a Fourier truncation step in the latent space, which enables dimensionality reduction while maintaining shift equivariance and interpretability. Our results demonstrate that FINE significantly outperforms classical linear methods such as Discrete Fourier Transformation (DFT) and Proper Orthogonal Decomposition (POD), and achieves reconstruction accuracy better than conventional deep autoencoders with convolutional layers (CNN) - while using substantially smaller models and offering superior physical interpretability. These findings suggest that invertible single-neuron networks, when combined with spectral truncation, offer a promising framework for learning compact and interpretable representations of physics datasets, and symmetry-aware representation learning in physics-informed machine learning.","authors":["Anqiao Ouyang","Hongyi Ke","Qi Wang"],"url":"https://arxiv.org/abs/2505.15329"}
{"created":"2025-05-22","title":"Impact of Distance on Epidemiological Dynamics in Human Connection Network with Mobility","abstract":"The spread of infectious diseases is often influenced by human mobility across different geographical regions. Although numerous studies have investigated how diseases like SARS and COVID-19 spread from China to various global locations, there remains a gap in understanding how the movement of individuals contributes to disease transmission on a more personal or human-to-human level. Typically, researchers have employed the concept of metapopulation movement to analyze how diseases move from one location to another. This paper shifts focus to the dynamics of disease transmission, incorporating the critical factor of distance between an infected person and a healthy individual during human movement. The study delves into the impact of distance on various parameters of epidemiological dynamics throughout human mobility. Mathematical expressions for important epidemiological metrics, such as the basic reproduction number ($R_0$) and the critical infection rate ($\\beta_{critical}$), are derived in relation to the distance between individuals. The results indicate that the proposed model closely aligns with observed patterns of COVID-19 spread based on the analysis done on the available datasets.","authors":["Md. Arquam","Suchi Kumari","Utkarsh Tiwari","Mohammad Al-saffar"],"url":"https://arxiv.org/abs/2505.15331"}
{"created":"2025-05-22","title":"Towards Zero-Shot Differential Morphing Attack Detection with Multimodal Large Language Models","abstract":"Leveraging the power of multimodal large language models (LLMs) offers a promising approach to enhancing the accuracy and interpretability of morphing attack detection (MAD), especially in real-world biometric applications. This work introduces the use of LLMs for differential morphing attack detection (D-MAD). To the best of our knowledge, this is the first study to employ multimodal LLMs to D-MAD using real biometric data. To effectively utilize these models, we design Chain-of-Thought (CoT)-based prompts to reduce failure-to-answer rates and enhance the reasoning behind decisions. Our contributions include: (1) the first application of multimodal LLMs for D-MAD using real data subjects, (2) CoT-based prompt engineering to improve response reliability and explainability, (3) comprehensive qualitative and quantitative benchmarking of LLM performance using data from 54 individuals captured in passport enrollment scenarios, and (4) comparative analysis of two multimodal LLMs: ChatGPT-4o and Gemini providing insights into their morphing attack detection accuracy and decision transparency. Experimental results show that ChatGPT-4o outperforms Gemini in detection accuracy, especially against GAN-based morphs, though both models struggle under challenging conditions. While Gemini offers more consistent explanations, ChatGPT-4o is more resilient but prone to a higher failure-to-answer rate.","authors":["Ria Shekhawat","Hailin Li","Raghavendra Ramachandra","Sushma Venkatesh"],"url":"https://arxiv.org/abs/2505.15332"}
{"created":"2025-05-22","title":"Leveraging Unit Language Guidance to Advance Speech Modeling in Textless Speech-to-Speech Translation","abstract":"The success of building textless speech-to-speech translation (S2ST) models has attracted much attention. However, S2ST still faces two main challenges: 1) extracting linguistic features for various speech signals, called cross-modal (CM), and 2) learning alignment of difference languages in long sequences, called cross-lingual (CL). We propose the unit language to overcome the two modeling challenges. The unit language can be considered a text-like representation format, constructed using $n$-gram language modeling. We implement multi-task learning to utilize the unit language in guiding the speech modeling process. Our initial results reveal a conflict when applying source and target unit languages simultaneously. We propose task prompt modeling to mitigate this conflict. We conduct experiments on four languages of the Voxpupil dataset. Our method demonstrates significant improvements over a strong baseline and achieves performance comparable to models trained with text.","authors":["Yuhao Zhang","Xiangnan Ma","Kaiqi Kou","Peizhuo Liu","Weiqiao Shan","Benyou Wang","Tong Xiao","Yuxin Huang","Zhengtao Yu","Jingbo Zhu"],"url":"https://arxiv.org/abs/2505.15333"}
{"created":"2025-05-22","title":"Parameter-Efficient Fine-Tuning of Multispectral Foundation Models for Hyperspectral Image Classification","abstract":"Foundation models have achieved great success across diverse domains, including remote sensing (RS), thanks to their versatility and strong generalization abilities. However, most RS foundation models are designed for multispectral data, while hyperspectral imagery (HSI) - with its hundreds of spectral bands - remains less explored. Fine-tuning such models for downstream tasks is also challenging, often demanding considerable memory and storage. In this paper, we propose an efficient framework to fine-tune SpectralGPT, a multispectral foundation model, for hyperspectral image classification (HSIC). We explore several Parameter-Efficient Fine-Tuning (PEFT) methods, including Low-Rank Adaptation (LoRA), Kronecker-based adaptation (KronA), Low-Rank Kronecker (LoKr), and the recent LoRA+, which uses distinct learning rates for low-rank adapters scaled by a factor lambda. Inspired by LoRA+, we introduce KronA+, which applies a similar mechanism to the Kronecker matrices. We evaluate our approach on five datasets from different sensors, showing competitive performance with state-of-the-art HSI models. Our full fine-tuning (FFT) setup for SpectralGPT even outperforms a dedicated hyperspectral foundation model on some datasets while requiring only a quarter of the training epochs. Under the same number of epochs, KronA+ reaches similar performance with far fewer trainable parameters - just 0.056 percent - and adds only approximately 0.2 megabytes of storage, making it the most effective PEFT method tested.","authors":["Bernardin Ligan","Khalide Jbilou","Fahd Kalloubi","Ahmed Ratnani"],"url":"https://arxiv.org/abs/2505.15334"}
{"created":"2025-05-22","title":"My Face Is Mine, Not Yours: Facial Protection Against Diffusion Model Face Swapping","abstract":"The proliferation of diffusion-based deepfake technologies poses significant risks for unauthorized and unethical facial image manipulation. While traditional countermeasures have primarily focused on passive detection methods, this paper introduces a novel proactive defense strategy through adversarial attacks that preemptively protect facial images from being exploited by diffusion-based deepfake systems. Existing adversarial protection methods predominantly target conventional generative architectures (GANs, AEs, VAEs) and fail to address the unique challenges presented by diffusion models, which have become the predominant framework for high-quality facial deepfakes. Current diffusion-specific adversarial approaches are limited by their reliance on specific model architectures and weights, rendering them ineffective against the diverse landscape of diffusion-based deepfake implementations. Additionally, they typically employ global perturbation strategies that inadequately address the region-specific nature of facial manipulation in deepfakes.","authors":["Hon Ming Yam","Zhongliang Guo","Chun Pong Lau"],"url":"https://arxiv.org/abs/2505.15336"}
{"created":"2025-05-22","title":"Your Language Model Can Secretly Write Like Humans: Contrastive Paraphrase Attacks on LLM-Generated Text Detectors","abstract":"The misuse of large language models (LLMs), such as academic plagiarism, has driven the development of detectors to identify LLM-generated texts. To bypass these detectors, paraphrase attacks have emerged to purposely rewrite these texts to evade detection. Despite the success, existing methods require substantial data and computational budgets to train a specialized paraphraser, and their attack efficacy greatly reduces when faced with advanced detection algorithms. To address this, we propose \\textbf{Co}ntrastive \\textbf{P}araphrase \\textbf{A}ttack (CoPA), a training-free method that effectively deceives text detectors using off-the-shelf LLMs. The first step is to carefully craft instructions that encourage LLMs to produce more human-like texts. Nonetheless, we observe that the inherent statistical biases of LLMs can still result in some generated texts carrying certain machine-like attributes that can be captured by detectors. To overcome this, CoPA constructs an auxiliary machine-like word distribution as a contrast to the human-like distribution generated by the LLM. By subtracting the machine-like patterns from the human-like distribution during the decoding process, CoPA is able to produce sentences that are less discernible by text detectors. Our theoretical analysis suggests the superiority of the proposed attack. Extensive experiments validate the effectiveness of CoPA in fooling text detectors across various scenarios.","authors":["Hao Fang","Jiawei Kong","Tianqu Zhuang","Yixiang Qiu","Kuofeng Gao","Bin Chen","Shu-Tao Xia","Yaowei Wang","Min Zhang"],"url":"https://arxiv.org/abs/2505.15337"}
{"created":"2025-05-22","title":"SSR: Speculative Parallel Scaling Reasoning in Test-time","abstract":"Large language models (LLMs) have achieved impressive results on multi-step mathematical reasoning, yet at the cost of high computational overhead. This challenge is particularly acute for test-time scaling methods such as parallel decoding, which increase answer diversity but scale poorly in efficiency. To address this efficiency-accuracy trade-off, we propose SSR (Speculative Parallel Scaling Reasoning), a training-free framework that leverages a key insight: by introducing speculative decoding at the step level, we can accelerate reasoning without sacrificing correctness. SSR integrates two components: a Selective Parallel Module (SPM) that identifies a small set of promising reasoning strategies via model-internal scoring, and Step-level Speculative Decoding (SSD), which enables efficient draft-target collaboration for fine-grained reasoning acceleration. Experiments on three mathematical benchmarks-AIME 2024, MATH-500, and LiveMathBench - demonstrate that SSR achieves strong gains over baselines. For instance, on LiveMathBench, SSR improves pass@1 accuracy by 13.84% while reducing computation to 80.5% of the baseline FLOPs. On MATH-500, SSR reduces compute to only 30% with no loss in accuracy.","authors":["Yuanlin Chu","Bo Wang","Xiang Liu","Hong Chen","Aiwei Liu","Xuming Hu"],"url":"https://arxiv.org/abs/2505.15340"}
{"created":"2025-05-22","title":"Alpay Algebra: A Universal Structural Foundation","abstract":"Alpay Algebra is introduced as a universal, category-theoretic framework that unifies classical algebraic structures with modern needs in symbolic recursion and explainable AI. Starting from a minimal list of axioms, we model each algebra as an object in a small cartesian closed category $\\mathcal{A}$ and define a transfinite evolution functor $\\phi\\colon\\mathcal{A}\\to\\mathcal{A}$. We prove that the fixed point $\\phi^{\\infty}$ exists for every initial object and satisfies an internal universal property that recovers familiar constructs -- limits, colimits, adjunctions -- while extending them to ordinal-indexed folds. A sequence of theorems establishes (i) soundness and conservativity over standard universal algebra, (ii) convergence of $\\phi$-iterates under regular cardinals, and (iii) an explanatory correspondence between $\\phi^{\\infty}$ and minimal sufficient statistics in information-theoretic AI models. We conclude by outlining computational applications: type-safe functional languages, categorical model checking, and signal-level reasoning engines that leverage Alpay Algebra's structural invariants. All proofs are self-contained; no external set-theoretic axioms beyond ZFC are required. This exposition positions Alpay Algebra as a bridge between foundational mathematics and high-impact AI systems, and provides a reference for further work in category theory, transfinite fixed-point analysis, and symbolic computation.","authors":["Faruk Alpay"],"url":"https://arxiv.org/abs/2505.15344"}
{"created":"2025-05-22","title":"Hadamax Encoding: Elevating Performance in Model-Free Atari","abstract":"Neural network architectures have a large impact in machine learning. In reinforcement learning, network architectures have remained notably simple, as changes often lead to small gains in performance. This work introduces a novel encoder architecture for pixel-based model-free reinforcement learning. The Hadamax (\\textbf{Hada}mard \\textbf{max}-pooling) encoder achieves state-of-the-art performance by max-pooling Hadamard products between GELU-activated parallel hidden layers. Based on the recent PQN algorithm, the Hadamax encoder achieves state-of-the-art model-free performance in the Atari-57 benchmark. Specifically, without applying any algorithmic hyperparameter modifications, Hadamax-PQN achieves an 80\\% performance gain over vanilla PQN and significantly surpasses Rainbow-DQN. For reproducibility, the full code is available on \\href{https://github.com/Jacobkooi/Hadamax}{GitHub}.","authors":["Jacob E. Kooi","Zhao Yang","Vincent Fran\\c{c}ois-Lavet"],"url":"https://arxiv.org/abs/2505.15345"}
{"created":"2025-05-22","title":"FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management","abstract":"Large Language Models (LLMs) are increasingly deployed in multi-turn conversational applications, where the management of the Key-Value (KV) Cache presents a significant bottleneck. The linear growth of the KV Cache with dialogue history imposes substantial computational costs, and existing eviction strategies often degrade performance by repeatedly compressing early conversational context, leading to information loss and context forgetting. This paper introduces FlowKV, a novel \\textbf{multi-turn isolation mechanism} for KV Cache management, which can be applied to any KV Cache compression method without training. FlowKV's core innovation is a multi-turn isolation mechanism that preserves the accumulated compressed KV cache from past turns. Compression is then strategically applied only to the newly generated KV pairs of the latest completed turn, effectively preventing the re-compression of older context and thereby mitigating catastrophic forgetting. Our results demonstrate that FlowKV consistently and significantly outperforms baseline strategies in maintaining instruction-following accuracy and user preference retention from 10.90\\% to 75.40\\%, particularly in later conversational turns.","authors":["Xiang Liu","Hong Chen","Xuming Hu","Xiaowen Chu"],"url":"https://arxiv.org/abs/2505.15347"}
{"created":"2025-05-22","title":"The Super Emotion Dataset","abstract":"Despite the wide-scale usage and development of emotion classification datasets in NLP, the field lacks a standardized, large-scale resource that follows a psychologically grounded taxonomy. Existing datasets either use inconsistent emotion categories, suffer from limited sample size, or focus on specific domains. The Super Emotion Dataset addresses this gap by harmonizing diverse text sources into a unified framework based on Shaver's empirically validated emotion taxonomy, enabling more consistent cross-domain emotion recognition research.","authors":["Enric Junqu\\'e de Fortuny"],"url":"https://arxiv.org/abs/2505.15348"}
{"created":"2025-05-22","title":"Phasebook: A Survey of Selected Open Problems in Phase Retrieval","abstract":"Phase retrieval is an inverse problem that, on one hand, is crucial in many applications across imaging and physics, and, on the other hand, leads to deep research questions in theoretical signal processing and applied harmonic analysis. This survey paper is an outcome of the recent workshop Phase Retrieval in Mathematics and Applications (PRiMA) (held on August 5--9 2024 at the Lorentz Center in Leiden, The Netherlands) that brought together experts working on theoretical and practical aspects of the phase retrieval problem with the purpose to formulate and explore essential open problems in the field.","authors":["Marc Allain","Selin Aslan","Wim Coene","Sjoerd Dirksen","Jonathan Dong","Julien Flamant","Mark Iwen","Felix Krahmer","Tristan van Leeuwen","Oleh Melnyk","Andreas Menzel","Allard P. Mosk","Viktor Nikitin","Gerlind Plonka","Palina Salanevich","Matthias Wellershoff"],"url":"https://arxiv.org/abs/2505.15351"}
{"created":"2025-05-22","title":"Revealing Language Model Trajectories via Kullback-Leibler Divergence","abstract":"A recently proposed method enables efficient estimation of the KL divergence between language models, including models with different architectures, by assigning coordinates based on log-likelihood vectors. To better understand the behavior of this metric, we systematically evaluate KL divergence across a wide range of conditions using publicly available language models. Our analysis covers comparisons between pretraining checkpoints, fine-tuned and base models, and layers via the logit lens. We find that trajectories of language models, as measured by KL divergence, exhibit a spiral structure during pretraining and thread-like progressions across layers. Furthermore, we show that, in terms of diffusion exponents, model trajectories in the log-likelihood space are more constrained than those in weight space.","authors":["Ryo Kishino","Yusuke Takase","Momose Oyama","Hiroaki Yamagiwa","Hidetoshi Shimodaira"],"url":"https://arxiv.org/abs/2505.15353"}
{"created":"2025-05-22","title":"Human in the Loop Adaptive Optimization for Improved Time Series Forecasting","abstract":"Time series forecasting models often produce systematic, predictable errors even in critical domains such as energy, finance, and healthcare. We introduce a novel post training adaptive optimization framework that improves forecast accuracy without retraining or architectural changes. Our method automatically applies expressive transformations optimized via reinforcement learning, contextual bandits, or genetic algorithms to correct model outputs in a lightweight and model agnostic way. Theoretically, we prove that affine corrections always reduce the mean squared error; practically, we extend this idea with dynamic action based optimization. The framework also supports an optional human in the loop component: domain experts can guide corrections using natural language, which is parsed into actions by a language model. Across multiple benchmarks (e.g., electricity, weather, traffic), we observe consistent accuracy gains with minimal computational overhead. Our interactive demo shows the framework's real time usability. By combining automated post hoc refinement with interpretable and extensible mechanisms, our approach offers a powerful new direction for practical forecasting systems.","authors":["Malik Tiomoko","Hamza Cherkaoui","Giuseppe Paolo","Zhang Yili","Yu Meng","Zhang Keli","Hafiz Tiomoko Ali"],"url":"https://arxiv.org/abs/2505.15354"}
{"created":"2025-05-22","title":"Decoding Phone Pairs from MEG Signals Across Speech Modalities","abstract":"Understanding the neural mechanisms underlying speech production is essential for both advancing cognitive neuroscience theory and developing practical communication technologies. In this study, we investigated magnetoencephalography signals to decode phones from brain activity during speech production and perception (passive listening and voice playback) tasks. Using a dataset comprising 17 participants, we performed pairwise phone classification, extending our analysis to 15 phonetic pairs. Multiple machine learning approaches, including regularized linear models and neural network architectures, were compared to determine their effectiveness in decoding phonetic information. Our results demonstrate significantly higher decoding accuracy during speech production (76.6%) compared to passive listening and playback modalities (~51%), emphasizing the richer neural information available during overt speech. Among the models, the Elastic Net classifier consistently outperformed more complex neural networks, highlighting the effectiveness of traditional regularization techniques when applied to limited and high-dimensional MEG datasets. Besides, analysis of specific brain frequency bands revealed that low-frequency oscillations, particularly Delta (0.2-3 Hz) and Theta (4-7 Hz), contributed the most substantially to decoding accuracy, suggesting that these bands encode critical speech production-related neural processes. Despite using advanced denoising methods, it remains unclear whether decoding solely reflects neural activity or if residual muscular or movement artifacts also contributed, indicating the need for further methodological refinement. Overall, our findings underline the critical importance of examining overt speech production paradigms, which, despite their complexity, offer opportunities to improve brain-computer interfaces to help individuals with severe speech impairments.","authors":["Xabier de Zuazo","Eva Navas","Ibon Saratxaga","Mathieu Bourguignon","Nicola Molinaro"],"url":"https://arxiv.org/abs/2505.15355"}
{"created":"2025-05-22","title":"NL-Debugging: Exploiting Natural Language as an Intermediate Representation for Code Debugging","abstract":"Debugging is a critical aspect of LLM's coding ability. Early debugging efforts primarily focused on code-level analysis, which often falls short when addressing complex programming errors that require a deeper understanding of algorithmic logic. Recent advancements in large language models (LLMs) have shifted attention toward leveraging natural language reasoning to enhance code-related tasks. However, two fundamental questions remain unanswered: What type of natural language format is most effective for debugging tasks? And what specific benefits does natural language reasoning bring to the debugging process? In this paper, we introduce NL-DEBUGGING, a novel framework that employs natural language as an intermediate representation to improve code debugging. By debugging at a natural language level, we demonstrate that NL-DEBUGGING outperforms traditional debugging methods and enables a broader modification space through direct refinement guided by execution feedback. Our findings highlight the potential of natural language reasoning to advance automated code debugging and address complex programming challenges.","authors":["Weiming Zhang","Qingyao Li","Xinyi Dai","Jizheng Chen","Kounianhua Du","Weinan Zhang","Weiwen Liu","Yasheng Wang","Ruiming Tang","Yong Yu"],"url":"https://arxiv.org/abs/2505.15356"}
{"created":"2025-05-22","title":"Objective Bicycle Occlusion Level Classification using a Deformable Parts-Based Model","abstract":"Road safety is a critical challenge, particularly for cyclists, who are among the most vulnerable road users. This study aims to enhance road safety by proposing a novel benchmark for bicycle occlusion level classification using advanced computer vision techniques. Utilizing a parts-based detection model, images are annotated and processed through a custom image detection pipeline. A novel method of bicycle occlusion level is proposed to objectively quantify the visibility and occlusion level of bicycle semantic parts. The findings indicate that the model robustly quantifies the visibility and occlusion level of bicycles, a significant improvement over the subjective methods used by the current state of the art. Widespread use of the proposed methodology will facilitate the accurate performance reporting of cyclist detection algorithms for occluded cyclists, informing the development of more robust vulnerable road user detection methods for autonomous vehicles.","authors":["Angelique Mangubat","Shane Gilroy"],"url":"https://arxiv.org/abs/2505.15358"}
{"created":"2025-05-22","title":"Group Order Logic","abstract":"We introduce an extension of fixed-point logic ($\\mathsf{FP}$) with a group-order operator ($\\mathsf{ord}$), that computes the size of a group generated by a definable set of permutations. This operation is a generalization of the rank operator ($\\mathsf{rk}$). We show that $\\mathsf{FP} + \\mathsf{ord}$ constitutes a new candidate logic for the class of polynomial-time computable queries ($\\mathsf{P}$). As was the case for $\\mathsf{FP} + \\mathsf{rk}$, the model-checking of $\\mathsf{FP} + \\mathsf{ord}$ formulae is polynomial-time computable. Moreover, the query separating $\\mathsf{FP} + \\mathsf{rk}$ from $\\mathsf{P}$ exhibited by Lichter in his recent breakthrough is definable in $\\mathsf{FP} + \\mathsf{ord}$. Precisely, we show that $\\mathsf{FP} + \\mathsf{ord}$ canonizes structures with Abelian colors, a class of structures which contains Lichter's counter-example. This proof involves expressing a fragment of the group-theoretic approach to graph canonization in the logic $\\mathsf{FP}+ \\mathsf{ord}$.","authors":["Anatole Dahan"],"url":"https://arxiv.org/abs/2505.15359"}
{"created":"2025-05-22","title":"MHANet: Multi-scale Hybrid Attention Network for Auditory Attention Detection","abstract":"Auditory attention detection (AAD) aims to detect the target speaker in a multi-talker environment from brain signals, such as electroencephalography (EEG), which has made great progress. However, most AAD methods solely utilize attention mechanisms sequentially and overlook valuable multi-scale contextual information within EEG signals, limiting their ability to capture long-short range spatiotemporal dependencies simultaneously. To address these issues, this paper proposes a multi-scale hybrid attention network (MHANet) for AAD, which consists of the multi-scale hybrid attention (MHA) module and the spatiotemporal convolution (STC) module. Specifically, MHA combines channel attention and multi-scale temporal and global attention mechanisms. This effectively extracts multi-scale temporal patterns within EEG signals and captures long-short range spatiotemporal dependencies simultaneously. To further improve the performance of AAD, STC utilizes temporal and spatial convolutions to aggregate expressive spatiotemporal representations. Experimental results show that the proposed MHANet achieves state-of-the-art performance with fewer trainable parameters across three datasets, 3 times lower than that of the most advanced model. Code is available at: https://github.com/fchest/MHANet.","authors":["Lu Li","Cunhang Fan","Hongyu Zhang","Jingjing Zhang","Xiaoke Yang","Jian Zhou","Zhao Lv"],"url":"https://arxiv.org/abs/2505.15364"}
{"created":"2025-05-22","title":"AI vs. Human Judgment of Content Moderation: LLM-as-a-Judge and Ethics-Based Response Refusals","abstract":"As large language models (LLMs) are increasingly deployed in high-stakes settings, their ability to refuse ethically sensitive prompts-such as those involving hate speech or illegal activities-has become central to content moderation and responsible AI practices. While refusal responses can be viewed as evidence of ethical alignment and safety-conscious behavior, recent research suggests that users may perceive them negatively. At the same time, automated assessments of model outputs are playing a growing role in both evaluation and training. In particular, LLM-as-a-Judge frameworks-in which one model is used to evaluate the output of another-are now widely adopted to guide benchmarking and fine-tuning. This paper examines whether such model-based evaluators assess refusal responses differently than human users. Drawing on data from Chatbot Arena and judgments from two AI judges (GPT-4o and Llama 3 70B), we compare how different types of refusals are rated. We distinguish ethical refusals, which explicitly cite safety or normative concerns (e.g., \"I can't help with that because it may be harmful\"), and technical refusals, which reflect system limitations (e.g., \"I can't answer because I lack real-time data\"). We find that LLM-as-a-Judge systems evaluate ethical refusals significantly more favorably than human users, a divergence not observed for technical refusals. We refer to this divergence as a moderation bias-a systematic tendency for model-based evaluators to reward refusal behaviors more than human users do. This raises broader questions about transparency, value alignment, and the normative assumptions embedded in automated evaluation systems.","authors":["Stefan Pasch"],"url":"https://arxiv.org/abs/2505.15365"}
{"created":"2025-05-22","title":"Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition","abstract":"Vision-Language Models (VLMs) have demonstrated impressive capabilities in understanding visual content, but their reliability in safety-critical contexts remains under-explored. We introduce VERI (Visual Emergency Recognition Dataset), a carefully designed diagnostic benchmark of 200 images (100 contrastive pairs). Each emergency scene is matched with a visually similar but safe counterpart through multi-stage human verification and iterative refinement. Using a two-stage protocol - risk identification and emergency response - we evaluate 14 VLMs (2B-124B parameters) across medical emergencies, accidents, and natural disasters. Our analysis reveals a systematic overreaction problem: models excel at identifying real emergencies (70-100 percent success rate) but suffer from an alarming rate of false alarms, misidentifying 31-96 percent of safe situations as dangerous, with 10 scenarios failed by all models regardless of scale. This \"better-safe-than-sorry\" bias manifests primarily through contextual overinterpretation (88-93 percent of errors), challenging VLMs' reliability for safety applications. These findings highlight persistent limitations that are not resolved by increasing model scale, motivating targeted approaches for improving contextual safety assessment in visually misleading scenarios.","authors":["Dasol Choi","Seunghyun Lee","Youngsook Song"],"url":"https://arxiv.org/abs/2505.15367"}
{"created":"2025-05-22","title":"Neurodyne: Neural Pitch Manipulation with Representation Learning and Cycle-Consistency GAN","abstract":"Pitch manipulation is the process of producers adjusting the pitch of an audio segment to a specific key and intonation, which is essential in music production. Neural-network-based pitch-manipulation systems have been popular in recent years due to their superior synthesis quality compared to classical DSP methods. However, their performance is still limited due to their inaccurate feature disentanglement using source-filter models and the lack of paired in- and out-of-tune training data. This work proposes Neurodyne to address these issues. Specifically, Neurodyne uses adversarial representation learning to learn a pitch-independent latent representation to avoid inaccurate disentanglement and cycle-consistency training to create paired training data implicitly. Experimental results on global-key and template-based pitch manipulation demonstrate the effectiveness of the proposed system, marking improved synthesis quality while maintaining the original singer identity.","authors":["Yicheng Gu","Chaoren Wang","Zhizheng Wu","Lauri Juvela"],"url":"https://arxiv.org/abs/2505.15368"}
{"created":"2025-05-22","title":"Prediction of Reposting on X","abstract":"There have been considerable efforts to predict a user's reposting behaviour on X (formerly Twitter) using machine learning models. The problem is previously cast as a supervised classification task, where Tweets are randomly assigned to a test or training set. The random assignment helps to ensure that the test and training sets are drawn from the same distribution. In practice, we would like to predict users' reposting behaviour for a set of messages related to a new, previously unseen, topic (defined by a hashtag). In this case, the problem becomes an out-of-distribution generalisation classification task.","authors":["Ziming Xu","Shi Zhou","Vasileios Lampos","Ingemar J. Cox"],"url":"https://arxiv.org/abs/2505.15370"}
{"created":"2025-05-22","title":"Distributionally Robust Federated Learning with Client Drift Minimization","abstract":"Federated learning (FL) faces critical challenges, particularly in heterogeneous environments where non-independent and identically distributed data across clients can lead to unfair and inefficient model performance. In this work, we introduce \\textit{DRDM}, a novel algorithm that addresses these issues by combining a distributionally robust optimization (DRO) framework with dynamic regularization to mitigate client drift. \\textit{DRDM} frames the training as a min-max optimization problem aimed at maximizing performance for the worst-case client, thereby promoting robustness and fairness. This robust objective is optimized through an algorithm leveraging dynamic regularization and efficient local updates, which significantly reduces the required number of communication rounds. Moreover, we provide a theoretical convergence analysis for convex smooth objectives under partial participation. Extensive experiments on three benchmark datasets, covering various model architectures and data heterogeneity levels, demonstrate that \\textit{DRDM} significantly improves worst-case test accuracy while requiring fewer communication rounds than existing state-of-the-art baselines. Furthermore, we analyze the impact of signal-to-noise ratio (SNR) and bandwidth on the energy consumption of participating clients, demonstrating that the number of local update steps can be adaptively selected to achieve a target worst-case test accuracy with minimal total energy cost across diverse communication environments.","authors":["Mounssif Krouka","Chaouki Ben Issaid","Mehdi Bennis"],"url":"https://arxiv.org/abs/2505.15371"}
{"created":"2025-05-22","title":"X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System","abstract":"Recently, large language model (LLM)-based agents have achieved significant success in interactive environments, attracting significant academic and industrial attention. Despite these advancements, current research predominantly focuses on English scenarios. In reality, there are over 7,000 languages worldwide, all of which demand access to comparable agentic services. Nevertheless, the development of language agents remains inadequate for meeting the diverse requirements of multilingual agentic applications. To fill this gap, we introduce X-WebAgentBench, a novel multilingual agent benchmark in an interactive web environment, which evaluates the planning and interaction performance of language agents across multiple languages, thereby contributing to the advancement of global agent intelligence. Additionally, we assess the performance of various LLMs and cross-lingual alignment methods, examining their effectiveness in enhancing agents. Our findings reveal that even advanced models like GPT-4o, when combined with cross-lingual techniques, fail to achieve satisfactory results. We hope that X-WebAgentBench can serve as a valuable benchmark for multilingual agent scenario in real-world applications.","authors":["Peng Wang","Ruihan Tao","Qiguang Chen","Mengkang Hu","Libo Qin"],"url":"https://arxiv.org/abs/2505.15372"}
{"created":"2025-05-22","title":"RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction with Spatio-Temporal Aggregation","abstract":"Mapping and understanding complex 3D environments is fundamental to how autonomous systems perceive and interact with the physical world, requiring both precise geometric reconstruction and rich semantic comprehension. While existing 3D semantic mapping systems excel at reconstructing and identifying predefined object instances, they lack the flexibility to efficiently build semantic maps with open-vocabulary during online operation. Although recent vision-language models have enabled open-vocabulary object recognition in 2D images, they haven't yet bridged the gap to 3D spatial understanding. The critical challenge lies in developing a training-free unified system that can simultaneously construct accurate 3D maps while maintaining semantic consistency and supporting natural language interactions in real time. In this paper, we develop a zero-shot framework that seamlessly integrates GPU-accelerated geometric reconstruction with open-vocabulary vision-language models through online instance-level semantic embedding fusion, guided by hierarchical object association with spatial indexing. Our training-free system achieves superior performance through incremental processing and unified geometric-semantic updates, while robustly handling 2D segmentation inconsistencies. The proposed general-purpose 3D scene understanding framework can be used for various tasks including zero-shot 3D instance retrieval, segmentation, and object detection to reason about previously unseen objects and interpret natural language queries. The project page is available at https://razer-3d.github.io.","authors":["Naman Patel","Prashanth Krishnamurthy","Farshad Khorrami"],"url":"https://arxiv.org/abs/2505.15373"}
{"created":"2025-05-22","title":"A Risk-Based Probabilistic Transient Stability Approach for Ranking of Circuit Breakers in a Power System","abstract":"Power systems are getting more complex than ever and are consequently operating close to their limit of stability. Moreover, with the increasing demand of renewable wind generation, and the requirement to maintain a secure power system, the importance of transient stability cannot be overestimated. Current deterministic industry practices of transient stability assessment ignore the probability of variables involved. With increasing system uncertainties and widespread electricity market deregulation, there is a strong inevitability to incorporate probabilistic transient stability analysis. Circuit breakers play a critical role in fault clearing and consequently in determining the system transient stability. It is important that they undergo timely and appropriate maintenance procedures based on some criterion. Considering the need of incorporating risk in modern power systems, this paper proposes a risk-based probabilistic transient stability approach for ranking of circuit breakers in a power system. A novel priority index was proposed to rank the circuit breakers based on the system transient stability risk. DIgSILENT PowerFactory software was used to conduct the required simulations on IEEE 14 bus system. The proposed risk-based framework was deemed to be efficient in identification of the circuit breakers based on their priority rank index which can aid in power system planning process.","authors":["Umair Shahzad"],"url":"https://arxiv.org/abs/2505.15374"}
{"created":"2025-05-22","title":"Federated Learning-Enhanced Blockchain Framework for Privacy-Preserving Intrusion Detection in Industrial IoT","abstract":"Industrial Internet of Things (IIoT) systems have become integral to smart manufacturing, yet their growing connectivity has also exposed them to significant cybersecurity threats. Traditional intrusion detection systems (IDS) often rely on centralized architectures that raise concerns over data privacy, latency, and single points of failure. In this work, we propose a novel Federated Learning-Enhanced Blockchain Framework (FL-BCID) for privacy-preserving intrusion detection tailored for IIoT environments. Our architecture combines federated learning (FL) to ensure decentralized model training with blockchain technology to guarantee data integrity, trust, and tamper resistance across IIoT nodes. We design a lightweight intrusion detection model collaboratively trained using FL across edge devices without exposing sensitive data. A smart contract-enabled blockchain system records model updates and anomaly scores to establish accountability. Experimental evaluations using the ToN-IoT and N-BaIoT datasets demonstrate the superior performance of our framework, achieving 97.3% accuracy while reducing communication overhead by 41% compared to baseline centralized methods. Our approach ensures privacy, scalability, and robustness-critical for secure industrial operations. The proposed FL-BCID system provides a promising solution for enhancing trust and privacy in modern IIoT security architectures.","authors":["Anas Ali","Mubashar Husain","Peter Hans"],"url":"https://arxiv.org/abs/2505.15376"}
{"created":"2025-05-22","title":"Stress Bytes: Decoding the Associations between Internet Use and Perceived Stress","abstract":"In today's digital era, internet plays a pervasive role in our lives, influencing everyday activities such as communication, work, and leisure. This online engagement intertwines with offline experiences, shaping individuals' overall well-being. Despite its significance, existing research often falls short in capturing the relationship between internet use and well-being, relying primarily on isolated studies and self-reported data. One of the major contributors to deteriorated well-being - both physical and mental - is stress. While some research has examined the relationship between internet use and stress, both positive and negative associations have been reported. Our primary goal in this work is to identify the associations between an individual's internet use and their stress. For achieving our goal, we conducted a longitudinal multimodal study that spanned seven months. We combined fine-grained URL-level web browsing traces of 1490 German internet users with their sociodemographics and monthly measures of stress. Further, we developed a conceptual framework that allows us to simultaneously explore different contextual dimensions, including how, where, when, and by whom the internet is used. Our analysis revealed several associations between internet use and stress that vary by context. Social media, entertainment, online shopping, and gaming were positively associated with stress, while productivity, news, and adult content use were negatively associated. In the future, the behavioral markers we identified can pave the way for designing individualized tools for people to self-monitor and self-moderate their online behaviors to enhance their well-being, reducing the burden on already overburdened mental health services.","authors":["Mohammad Belal","Nguyen Luong","Talayeh Aledavood","Juhi Kulshrestha"],"url":"https://arxiv.org/abs/2505.15377"}
{"created":"2025-05-22","title":"The P$^3$ dataset: Pixels, Points and Polygons for Multimodal Building Vectorization","abstract":"We present the P$^3$ dataset, a large-scale multimodal benchmark for building vectorization, constructed from aerial LiDAR point clouds, high-resolution aerial imagery, and vectorized 2D building outlines, collected across three continents. The dataset contains over 10 billion LiDAR points with decimeter-level accuracy and RGB images at a ground sampling distance of 25 centimeter. While many existing datasets primarily focus on the image modality, P$^3$ offers a complementary perspective by also incorporating dense 3D information. We demonstrate that LiDAR point clouds serve as a robust modality for predicting building polygons, both in hybrid and end-to-end learning frameworks. Moreover, fusing aerial LiDAR and imagery further improves accuracy and geometric quality of predicted polygons. The P$^3$ dataset is publicly available, along with code and pretrained weights of three state-of-the-art models for building polygon prediction at https://github.com/raphaelsulzer/PixelsPointsPolygons .","authors":["Raphael Sulzer","Liuyun Duan","Nicolas Girard","Florent Lafarge"],"url":"https://arxiv.org/abs/2505.15379"}
{"created":"2025-05-22","title":"Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding","abstract":"Modern autoregressive speech synthesis models leveraging language models have demonstrated remarkable performance. However, the sequential nature of next token prediction in these models leads to significant latency, hindering their deployment in scenarios where inference speed is critical. In this work, we propose Speech Speculative Decoding (SSD), a novel framework for autoregressive speech synthesis acceleration. Specifically, our method employs a lightweight draft model to generate candidate token sequences, which are subsequently verified in parallel by the target model using the proposed SSD framework. Experimental results demonstrate that SSD achieves a significant speedup of 1.4x compared with conventional autoregressive decoding, while maintaining high fidelity and naturalness. Subjective evaluations further validate the effectiveness of SSD in preserving the perceptual quality of the target model while accelerating inference.","authors":["Zijian Lin","Yang Zhang","Yougen Yuan","Yuming Yan","Jinjiang Liu","Zhiyong Wu","Pengfei Hu","Qun Yu"],"url":"https://arxiv.org/abs/2505.15380"}
{"created":"2025-05-22","title":"Real-Time Detection of Insider Threats Using Behavioral Analytics and Deep Evidential Clustering","abstract":"Insider threats represent one of the most critical challenges in modern cybersecurity. These threats arise from individuals within an organization who misuse their legitimate access to harm the organization's assets, data, or operations. Traditional security mechanisms, primarily designed for external attackers, fall short in identifying these subtle and context-aware threats. In this paper, we propose a novel framework for real-time detection of insider threats using behavioral analytics combined with deep evidential clustering. Our system captures and analyzes user activities, applies context-rich behavioral features, and classifies potential threats using a deep evidential clustering model that estimates both cluster assignment and epistemic uncertainty. The proposed model dynamically adapts to behavioral changes and significantly reduces false positives. We evaluate our framework on benchmark insider threat datasets such as CERT and TWOS, achieving an average detection accuracy of 94.7% and a 38% reduction in false positives compared to traditional clustering methods. Our results demonstrate the effectiveness of integrating uncertainty modeling in threat detection pipelines. This research provides actionable insights for deploying intelligent, adaptive, and robust insider threat detection systems across various enterprise environments.","authors":["Anas Ali","Mubashar Husain","Peter Hans"],"url":"https://arxiv.org/abs/2505.15383"}
{"created":"2025-05-22","title":"A two-stage model for factors influencing citation counts","abstract":"This work aims to study a count response random variable, the number of citations of a research paper, affected by some explanatory variables through a suitable regression model. Due to the fact that the count variable exhibits substantial variation since the sample variance is larger than the sample mean, the classical Poisson regression model seems not to be appropriate. We concentrate attention on the negative binomial regression model, which allows the variance of each measurement to be a function of its predicted value. Nevertheless, the process of citations of papers may be divided into two parts. In the first stage, the paper has no citations, and the second part provides the intensity of the citations. A hurdle model for separating the documents with citations and those without citations is considered. The dataset for the empirical application consisted of 43,190 research papers in the field of Economics and Business from 2014-2021, obtained from The Lens database. Citation counts and social attention scores for each article were gathered from Altmetric database. The main findings indicate that both collaboration and funding have a positive impact on citation counts and reduce the likelihood of receiving zero citations. Higher journal impact factors lead to higher citation counts, while lower peer review ratings lead to fewer citations and a higher probability of zero citations. Mentions in news, blogs, and social media have varying but generally limited effects on citation counts. Open access via repositories (green OA) correlates with higher citation counts and a lower probability of zero citations. In contrast, OA via the publisher's website without an explicit open license (bronze OA) is associated with higher citation counts but also with a higher probability of zero citations.","authors":["Pablo Dorta-Gonz\\'alez","Emilio G\\'omez-D\\'eniz"],"url":"https://arxiv.org/abs/2505.15384"}
{"created":"2025-05-22","title":"EVA: Expressive Virtual Avatars from Multi-view Videos","abstract":"With recent advancements in neural rendering and motion capture algorithms, remarkable progress has been made in photorealistic human avatar modeling, unlocking immense potential for applications in virtual reality, augmented reality, remote communication, and industries such as gaming, film, and medicine. However, existing methods fail to provide complete, faithful, and expressive control over human avatars due to their entangled representation of facial expressions and body movements. In this work, we introduce Expressive Virtual Avatars (EVA), an actor-specific, fully controllable, and expressive human avatar framework that achieves high-fidelity, lifelike renderings in real time while enabling independent control of facial expressions, body movements, and hand gestures. Specifically, our approach designs the human avatar as a two-layer model: an expressive template geometry layer and a 3D Gaussian appearance layer. First, we present an expressive template tracking algorithm that leverages coarse-to-fine optimization to accurately recover body motions, facial expressions, and non-rigid deformation parameters from multi-view videos. Next, we propose a novel decoupled 3D Gaussian appearance model designed to effectively disentangle body and facial appearance. Unlike unified Gaussian estimation approaches, our method employs two specialized and independent modules to model the body and face separately. Experimental results demonstrate that EVA surpasses state-of-the-art methods in terms of rendering quality and expressiveness, validating its effectiveness in creating full-body avatars. This work represents a significant advancement towards fully drivable digital human models, enabling the creation of lifelike digital avatars that faithfully replicate human geometry and appearance.","authors":["Hendrik Junkawitsch","Guoxing Sun","Heming Zhu","Christian Theobalt","Marc Habermann"],"url":"https://arxiv.org/abs/2505.15385"}
{"created":"2025-05-22","title":"RePPL: Recalibrating Perplexity by Uncertainty in Semantic Propagation and Language Generation for Explainable QA Hallucination Detection","abstract":"Large Language Models (LLMs) have become powerful, but hallucinations remain a vital obstacle to their trustworthy use. While previous works improved the capability of hallucination detection by measuring uncertainty, they all lack the ability to explain the provenance behind why hallucinations occur, i.e., which part of the inputs tends to trigger hallucinations. Recent works on the prompt attack indicate that uncertainty exists in semantic propagation, where attention mechanisms gradually fuse local token information into high-level semantics across layers. Meanwhile, uncertainty also emerges in language generation, due to its probability-based selection of high-level semantics for sampled generations. Based on that, we propose RePPL to recalibrate uncertainty measurement by these two aspects, which dispatches explainable uncertainty scores to each token and aggregates in Perplexity-style Log-Average form as total score. Experiments show that our method achieves the best comprehensive detection performance across various QA datasets on advanced models (average AUC of 0.833), and our method is capable of producing token-level uncertainty scores as explanations for the hallucination. Leveraging these scores, we preliminarily find the chaotic pattern of hallucination and showcase its promising usage.","authors":["Yiming Huang (May)","Junyan Zhang (May)","Zihao Wang (May)","Biquan Bie (May)","Xuming Hu (May)","Yi R. (May)","Fung","Xinlei He"],"url":"https://arxiv.org/abs/2505.15386"}
{"created":"2025-05-22","title":"Impact of Wind Generation on Risk-based Security Assessment of Power System","abstract":"The electric power system is one of the largest and most intricate infrastructures. Therefore, it is critical to assess and maintain its security. A power system security assessment is indispensable for identifying post-contingency issues, taking corrective measures, and protecting the system from blackouts. This paper examined the impact of wind generation on the risk-based security assessment of a power transmission network in the context of planning. DIgSILENT PowerFactory software was used to conduct the analysis using a combination of the brute force technique and the nonsequential Monte Carlo (MC) simulation method on the IEEE 39-bus transmission test system. Optimal power flow (OPF) was used to quantify security, considering (N-1), (N-2), and (N-3) line outages and an (N-1) bus outage. Moreover, the average cost deviation from the mean optimal system operating cost was proposed as a novel security indicator. The results obtianed accurately depicted the effects of changing wind generation levels on system security in terms of risk. The most and least critical line(s) and bus in the system, for different wind generation levels, were also determined. Moreover, the worst-case wind-generation threshold level using two different cost functions for wind was identified.","authors":["Umair Shahzad"],"url":"https://arxiv.org/abs/2505.15388"}
{"created":"2025-05-22","title":"Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study","abstract":"Rapid deployment of vision-language models (VLMs) magnifies safety risks, yet most evaluations rely on artificial images. This study asks: How safe are current VLMs when confronted with meme images that ordinary users share? To investigate this question, we introduce MemeSafetyBench, a 50,430-instance benchmark pairing real meme images with both harmful and benign instructions. Using a comprehensive safety taxonomy and LLM-based instruction generation, we assess multiple VLMs across single and multi-turn interactions. We investigate how real-world memes influence harmful outputs, the mitigating effects of conversational context, and the relationship between model scale and safety metrics. Our findings demonstrate that VLMs show greater vulnerability to meme-based harmful prompts than to synthetic or typographic images. Memes significantly increase harmful responses and decrease refusals compared to text-only inputs. Though multi-turn interactions provide partial mitigation, elevated vulnerability persists. These results highlight the need for ecologically valid evaluations and stronger safety mechanisms.","authors":["DongGeon Lee","Joonwon Jang","Jihae Jeong","Hwanjo Yu"],"url":"https://arxiv.org/abs/2505.15389"}
{"created":"2025-05-22","title":"InTreeger: An End-to-End Framework for Integer-Only Decision Tree Inference","abstract":"Integer quantization has emerged as a critical technique to facilitate deployment on resource-constrained devices. Although they do reduce the complexity of the learning models, their inference performance is often prone to quantization-induced errors. To this end, we introduce InTreeger: an end-to-end framework that takes a training dataset as input, and outputs an architecture-agnostic integer-only C implementation of tree-based machine learning model, without loss of precision. This framework enables anyone, even those without prior experience in machine learning, to generate a highly optimized integer-only classification model that can run on any hardware simply by providing an input dataset and target variable. We evaluated our generated implementations across three different architectures (ARM, x86, and RISC-V), resulting in significant improvements in inference latency. In addition, we show the energy efficiency compared to typical decision tree implementations that rely on floating-point arithmetic. The results underscore the advantages of integer-only inference, making it particularly suitable for energy- and area-constrained devices such as embedded systems and edge computing platforms, while also enabling the execution of decision trees on existing ultra-low power devices.","authors":["Duncan Bart","Bruno Endres Forlin","Ana-Lucia Varbanescu","Marco Ottavi","Kuan-Hsun Chen"],"url":"https://arxiv.org/abs/2505.15391"}
{"created":"2025-05-22","title":"An Empirical Study of the Anchoring Effect in LLMs: Existence, Mechanism, and Potential Mitigations","abstract":"The rise of Large Language Models (LLMs) like ChatGPT has advanced natural language processing, yet concerns about cognitive biases are growing. In this paper, we investigate the anchoring effect, a cognitive bias where the mind relies heavily on the first information as anchors to make affected judgments. We explore whether LLMs are affected by anchoring, the underlying mechanisms, and potential mitigation strategies. To facilitate studies at scale on the anchoring effect, we introduce a new dataset, SynAnchors. Combining refined evaluation metrics, we benchmark current widely used LLMs. Our findings show that LLMs' anchoring bias exists commonly with shallow-layer acting and is not eliminated by conventional strategies, while reasoning can offer some mitigation. This recontextualization via cognitive psychology urges that LLM evaluations focus not on standard benchmarks or over-optimized robustness tests, but on cognitive-bias-aware trustworthy evaluation.","authors":["Yiming Huang","Biquan Bie","Zuqiu Na","Weilin Ruan","Songxin Lei","Yutao Yue","Xinlei He"],"url":"https://arxiv.org/abs/2505.15392"}
{"created":"2025-05-22","title":"FAV-NSS: An HIL Framework for Accelerating Validation of Automotive Network Security Strategies","abstract":"Complex electronic control unit (ECU) architectures, software models and in-vehicle networks are consistently improving safety and comfort functions in modern vehicles. However, the extended functionality and increased connectivity introduce new security risks and vulnerabilities that can be exploited on legacy automotive networks such as the controller area network (CAN). With the rising complexity of vehicular systems and attack vectors, the need for a flexible hardware-in-the-loop (HIL) test fixture that can inject attacks and validate the performance of countermeasures in near-real-world conditions in real time is vital. This paper presents an FPGA-based HIL framework tailored towards validating network security approaches (IDS, IPS) and smart integration strategies of such capabilities for an automotive CAN bus. FAV-NSS replicates an actual vehicular system environment with functional ECUs and network infrastructure on an FPGA, allowing functional validation of IDS/IPS algorithms, accelerator designs and integration schemes (software task on ECU, dedicated accelerator). To show the efficacy of FAV-NSS, we evaluate an IDS accelerator integration problem, both as a traditional coupled accelerator (to the ECU), and secondly close to the CAN controller (mimicking an extended CAN controller). We show that the latter strategy can be fully validated by our framework, which would otherwise require integration of specialised CAN modules into otherwise standard HIL fixtures with ability to instrument internal signals for characterising timing performance. The tests demonstrate a promising latency reduction of 6.3x when compared to the traditional coupled accelerator. Our case study demonstrates the potential of FAV-NSS for accelerating the optimisation, integration and verification of smart ECUs and communication controllers in current and future vehicular systems.","authors":["Changhong Li","Shashwat Khandelwal","Shreejith Shanker"],"url":"https://arxiv.org/abs/2505.15393"}
{"created":"2025-05-22","title":"Reranking with Compressed Document Representation","abstract":"Reranking, the process of refining the output of a first-stage retriever, is often considered computationally expensive, especially with Large Language Models. Borrowing from recent advances in document compression for RAG, we reduce the input size by compressing documents into fixed-size embedding representations. We then teach a reranker to use compressed inputs by distillation. Although based on a billion-size model, our trained reranker using this compressed input can challenge smaller rerankers in terms of both effectiveness and efficiency, especially for long documents. Given that text compressors are still in their early development stages, we view this approach as promising.","authors":["Herv\\'e D\\'ejean","St\\'ephane Clinchant"],"url":"https://arxiv.org/abs/2505.15394"}
{"created":"2025-05-22","title":"Expanding Zero-Shot Object Counting with Rich Prompts","abstract":"Expanding pre-trained zero-shot counting models to handle unseen categories requires more than simply adding new prompts, as this approach does not achieve the necessary alignment between text and visual features for accurate counting. We introduce RichCount, the first framework to address these limitations, employing a two-stage training strategy that enhances text encoding and strengthens the model's association with objects in images. RichCount improves zero-shot counting for unseen categories through two key objectives: (1) enriching text features with a feed-forward network and adapter trained on text-image similarity, thereby creating robust, aligned representations; and (2) applying this refined encoder to counting tasks, enabling effective generalization across diverse prompts and complex images. In this manner, RichCount goes beyond simple prompt expansion to establish meaningful feature alignment that supports accurate counting across novel categories. Extensive experiments on three benchmark datasets demonstrate the effectiveness of RichCount, achieving state-of-the-art performance in zero-shot counting and significantly enhancing generalization to unseen categories in open-world scenarios.","authors":["Huilin Zhu","Senyao Li","Jingling Yuan","Zhengwei Yang","Yu Guo","Wenxuan Liu","Xian Zhong","Shengfeng He"],"url":"https://arxiv.org/abs/2505.15398"}
{"created":"2025-05-22","title":"When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning","abstract":"Large reasoning models (LRMs) achieve remarkable performance via long reasoning chains, but often incur excessive computational overhead due to redundant reasoning, especially on simple tasks. In this work, we systematically quantify the upper bounds of LRMs under both Long-Thinking and No-Thinking modes, and uncover the phenomenon of \"Internal Self-Recovery Mechanism\" where models implicitly supplement reasoning during answer generation. Building on this insight, we propose Adaptive Self-Recovery Reasoning (ASRR), a framework that suppresses unnecessary reasoning and enables implicit recovery. By introducing accuracy-aware length reward regulation, ASRR adaptively allocates reasoning effort according to problem difficulty, achieving high efficiency with negligible performance sacrifice. Experiments across multiple benchmarks and models show that, compared with GRPO, ASRR reduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal accuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates on safety benchmarks (up to +21.7%). Our results highlight the potential of ASRR for enabling efficient, adaptive, and safer reasoning in LRMs.","authors":["Xiaoyun Zhang","Jingqing Ruan","Xing Ma","Yawen Zhu","Haodong Zhao","Hao Li","Jiansong Chen","Ke Zeng","Xunliang Cai"],"url":"https://arxiv.org/abs/2505.15400"}
{"created":"2025-05-22","title":"Visual Question Answering on Multiple Remote Sensing Image Modalities","abstract":"The extraction of visual features is an essential step in Visual Question Answering (VQA). Building a good visual representation of the analyzed scene is indeed one of the essential keys for the system to be able to correctly understand the latter in order to answer complex questions. In many fields such as remote sensing, the visual feature extraction step could benefit significantly from leveraging different image modalities carrying complementary spectral, spatial and contextual information. In this work, we propose to add multiple image modalities to VQA in the particular context of remote sensing, leading to a novel task for the computer vision community. To this end, we introduce a new VQA dataset, named TAMMI (Text and Multi-Modal Imagery) with diverse questions on scenes described by three different modalities (very high resolution RGB, multi-spectral imaging data and synthetic aperture radar). Thanks to an automated pipeline, this dataset can be easily extended according to experimental needs. We also propose the MM-RSVQA (Multi-modal Multi-resolution Remote Sensing Visual Question Answering) model, based on VisualBERT, a vision-language transformer, to effectively combine the multiple image modalities and text through a trainable fusion process. A preliminary experimental study shows promising results of our methodology on this challenging dataset, with an accuracy of 65.56% on the targeted VQA task. This pioneering work paves the way for the community to a new multi-modal multi-resolution VQA task that can be applied in other imaging domains (such as medical imaging) where multi-modality can enrich the visual representation of a scene. The dataset and code are available at https://tammi.sylvainlobry.com/.","authors":["Hichem Boussaid","Lucrezia Tosato","Flora Weissgerber","Camille Kurtz","Laurent Wendling","Sylvain Lobry"],"url":"https://arxiv.org/abs/2505.15401"}
{"created":"2025-05-22","title":"Prosody-Adaptable Audio Codecs for Zero-Shot Voice Conversion via In-Context Learning","abstract":"Recent advances in discrete audio codecs have significantly improved speech representation modeling, while codec language models have enabled in-context learning for zero-shot speech synthesis. Inspired by this, we propose a voice conversion (VC) model within the VALLE-X framework, leveraging its strong in-context learning capabilities for speaker adaptation. To enhance prosody control, we introduce a prosody-aware audio codec encoder (PACE) module, which isolates and refines prosody from other sources, improving expressiveness and control. By integrating PACE into our VC model, we achieve greater flexibility in prosody manipulation while preserving speaker timbre. Experimental evaluation results demonstrate that our approach outperforms baseline VC systems in prosody preservation, timbre consistency, and overall naturalness, surpassing baseline VC systems.","authors":["Junchuan Zhao","Xintong Wang","Ye Wang"],"url":"https://arxiv.org/abs/2505.15402"}
{"created":"2025-05-22","title":"How Should We Enhance the Safety of Large Reasoning Models: An Empirical Study","abstract":"Large Reasoning Models (LRMs) have achieved remarkable success on reasoning-intensive tasks such as mathematics and programming. However, their enhanced reasoning capabilities do not necessarily translate to improved safety performance-and in some cases, may even degrade it. This raises an important research question: how can we enhance the safety of LRMs? In this paper, we present a comprehensive empirical study on how to enhance the safety of LRMs through Supervised Fine-Tuning (SFT). Our investigation begins with an unexpected observation: directly distilling safe responses from DeepSeek-R1 fails to significantly enhance safety. We analyze this phenomenon and identify three key failure patterns that contribute to it. We then demonstrate that explicitly addressing these issues during the data distillation process can lead to substantial safety improvements. Next, we explore whether a long and complex reasoning process is necessary for achieving safety. Interestingly, we find that simply using short or template-based reasoning process can attain comparable safety performance-and are significantly easier for models to learn than more intricate reasoning chains. These findings prompt a deeper reflection on the role of reasoning in ensuring safety. Finally, we find that mixing math reasoning data during safety fine-tuning is helpful to balance safety and over-refusal. Overall, we hope our empirical study could provide a more holistic picture on enhancing the safety of LRMs. The code and data used in our experiments are released in https://github.com/thu-coai/LRM-Safety-Study.","authors":["Zhexin Zhang","Xian Qi Loye","Victor Shea-Jay Huang","Junxiao Yang","Qi Zhu","Shiyao Cui","Fei Mi","Lifeng Shang","Yingkang Wang","Hongning Wang","Minlie Huang"],"url":"https://arxiv.org/abs/2505.15404"}
{"created":"2025-05-22","title":"HOPSE: Scalable Higher-Order Positional and Structural Encoder for Combinatorial Representations","abstract":"While Graph Neural Networks (GNNs) have proven highly effective at modeling relational data, pairwise connections cannot fully capture multi-way relationships naturally present in complex real-world systems. In response to this, Topological Deep Learning (TDL) leverages more general combinatorial representations -- such as simplicial or cellular complexes -- to accommodate higher-order interactions. Existing TDL methods often extend GNNs through Higher-Order Message Passing (HOMP), but face critical \\emph{scalability challenges} due to \\textit{(i)} a combinatorial explosion of message-passing routes, and \\textit{(ii)} significant complexity overhead from the propagation mechanism. To overcome these limitations, we propose HOPSE (Higher-Order Positional and Structural Encoder) -- a \\emph{message passing-free} framework that uses Hasse graph decompositions to derive efficient and expressive encodings over \\emph{arbitrary higher-order domains}. Notably, HOPSE scales linearly with dataset size while preserving expressive power and permutation equivariance. Experiments on molecular, expressivity and topological benchmarks show that HOPSE matches or surpasses state-of-the-art performance while achieving up to 7 $times$ speedups over HOMP-based models, opening a new path for scalable TDL.","authors":["Martin Carrasco","Guillermo Bernardez","Marco Montagna","Nina Miolane","Lev Telyatnikov"],"url":"https://arxiv.org/abs/2505.15405"}
{"created":"2025-05-22","title":"Audio Jailbreak: An Open Comprehensive Benchmark for Jailbreaking Large Audio-Language Models","abstract":"The rise of Large Audio Language Models (LAMs) brings both potential and risks, as their audio outputs may contain harmful or unethical content. However, current research lacks a systematic, quantitative evaluation of LAM safety especially against jailbreak attacks, which are challenging due to the temporal and semantic nature of speech. To bridge this gap, we introduce AJailBench, the first benchmark specifically designed to evaluate jailbreak vulnerabilities in LAMs. We begin by constructing AJailBench-Base, a dataset of 1,495 adversarial audio prompts spanning 10 policy-violating categories, converted from textual jailbreak attacks using realistic text to speech synthesis. Using this dataset, we evaluate several state-of-the-art LAMs and reveal that none exhibit consistent robustness across attacks. To further strengthen jailbreak testing and simulate more realistic attack conditions, we propose a method to generate dynamic adversarial variants. Our Audio Perturbation Toolkit (APT) applies targeted distortions across time, frequency, and amplitude domains. To preserve the original jailbreak intent, we enforce a semantic consistency constraint and employ Bayesian optimization to efficiently search for perturbations that are both subtle and highly effective. This results in AJailBench-APT, an extended dataset of optimized adversarial audio samples. Our findings demonstrate that even small, semantically preserved perturbations can significantly reduce the safety performance of leading LAMs, underscoring the need for more robust and semantically aware defense mechanisms.","authors":["Zirui Song","Qian Jiang","Mingxuan Cui","Mingzhe Li","Lang Gao","Zeyu Zhang","Zixiang Xu","Yanbo Wang","Chenxi Wang","Guangxian Ouyang","Zhenhao Chen","Xiuying Chen"],"url":"https://arxiv.org/abs/2505.15406"}
{"created":"2025-05-22","title":"Efficient Differentiable Approximation of Generalized Low-rank Regularization","abstract":"Low-rank regularization (LRR) has been widely applied in various machine learning tasks, but the associated optimization is challenging. Directly optimizing the rank function under constraints is NP-hard in general. To overcome this difficulty, various relaxations of the rank function were studied. However, optimization of these relaxed LRRs typically depends on singular value decomposition, which is a time-consuming and nondifferentiable operator that cannot be optimized with gradient-based techniques. To address these challenges, in this paper we propose an efficient differentiable approximation of the generalized LRR. The considered LRR form subsumes many popular choices like the nuclear norm, the Schatten-$p$ norm, and various nonconvex relaxations. Our method enables LRR terms to be appended to loss functions in a plug-and-play fashion, and the GPU-friendly operations enable efficient and convenient implementation. Furthermore, convergence analysis is presented, which rigorously shows that both the bias and the variance of our rank estimator rapidly reduce with increased sample size and iteration steps. In the experimental study, the proposed method is applied to various tasks, which demonstrates its versatility and efficiency. Code is available at https://github.com/naiqili/EDLRR.","authors":["Naiqi Li","Yuqiu Xie","Peiyuan Liu","Tao Dai","Yong Jiang","Shu-Tao Xia"],"url":"https://arxiv.org/abs/2505.15407"}
{"created":"2025-05-22","title":"Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes","abstract":"Machine learning and computer vision methods have a major impact on the study of natural animal behavior, as they enable the (semi-)automatic analysis of vast amounts of video data. Mice are the standard mammalian model system in most research fields, but the datasets available today to refine such methods focus either on simple or social behaviors. In this work, we present a video dataset of individual mice solving complex mechanical puzzles, so-called lockboxes. The more than 110 hours of total playtime show their behavior recorded from three different perspectives. As a benchmark for frame-level action classification methods, we provide human-annotated labels for all videos of two different mice, that equal 13% of our dataset. Our keypoint (pose) tracking-based action classification framework illustrates the challenges of automated labeling of fine-grained behaviors, such as the manipulation of objects. We hope that our work will help accelerate the advancement of automated action and behavior classification in the computational neuroscience community. Our dataset is publicly available at https://doi.org/10.14279/depositonce-23850","authors":["Patrik Reiske","Marcus N. Boon","Niek Andresen","Sole Traverso","Katharina Hohlbaum","Lars Lewejohann","Christa Th\\\"one-Reineke","Olaf Hellwich","Henning Sprekeler"],"url":"https://arxiv.org/abs/2505.15408"}
{"created":"2025-05-22","title":"Object-centric Processes with Structured Data and Exact Synchronization (Extended Version)","abstract":"Real-world processes often involve interdependent objects that also carry data values, such as integers, reals, or strings. However, existing process formalisms fall short to combine key modeling features, such as tracking object identities, supporting complex datatypes, handling dependencies among them, and object-aware synchronization. Object-centric Petri nets with identifiers (OPIDs) partially address these needs but treat objects as unstructured identifiers (e.g., order and item IDs), overlooking the rich semantics of complex data values (e.g., item prices or other attributes). To overcome these limitations, we introduce data-aware OPIDs (DOPIDs), a framework that strictly extends OPIDs by incorporating structured data manipulation capabilities, and full synchronization mechanisms. In spite of the expressiveness of the model, we show that it can be made operational: Specifically, we define a novel conformance checking approach leveraging satisfiability modulo theories (SMT) to compute data-aware object-centric alignments.","authors":["Alessandro Gianola","Marco Montali","Sarah Winkler"],"url":"https://arxiv.org/abs/2505.15409"}
{"created":"2025-05-22","title":"ClickSight: Interpreting Student Clickstreams to Reveal Insights on Learning Strategies via LLMs","abstract":"Clickstream data from digital learning environments offer valuable insights into students' learning behaviors, but are challenging to interpret due to their high dimensionality and granularity. Prior approaches have relied mainly on handcrafted features, expert labeling, clustering, or supervised models, therefore often lacking generalizability and scalability. In this work, we introduce ClickSight, an in-context Large Language Model (LLM)-based pipeline that interprets student clickstreams to reveal their learning strategies. ClickSight takes raw clickstreams and a list of learning strategies as input and generates textual interpretations of students' behaviors during interaction. We evaluate four different prompting strategies and investigate the impact of self-refinement on interpretation quality. Our evaluation spans two open-ended learning environments and uses a rubric-based domain-expert evaluation. Results show that while LLMs can reasonably interpret learning strategies from clickstreams, interpretation quality varies by prompting strategy, and self-refinement offers limited improvement. ClickSight demonstrates the potential of LLMs to generate theory-driven insights from educational interaction data.","authors":["Bahar Radmehr","Ekaterina Shved","Fatma Bet\\\"ul G\\\"ure\\c{s}","Adish Singla","Tanja K\\\"aser"],"url":"https://arxiv.org/abs/2505.15410"}
{"created":"2025-05-22","title":"Evaluation of Mobile Environment for Vehicular Visible Light Communication Using Multiple LEDs and Event Cameras","abstract":"In the fields of Advanced Driver Assistance Systems (ADAS) and Autonomous Driving (AD), sensors that serve as the ``eyes'' for sensing the vehicle's surrounding environment are essential. Traditionally, image sensors and LiDAR have played this role. However, a new type of vision sensor, event cameras, has recently attracted attention. Event cameras respond to changes in the surrounding environment (e.g., motion), exhibit strong robustness against motion blur, and perform well in high dynamic range environments, which are desirable in robotics applications. Furthermore, the asynchronous and low-latency principles of data acquisition make event cameras suitable for optical communication. By adding communication functionality to event cameras, it becomes possible to utilize I2V communication to immediately share information about forward collisions, sudden braking, and road conditions, thereby contributing to hazard avoidance. Additionally, receiving information such as signal timing and traffic volume enables speed adjustment and optimal route selection, facilitating more efficient driving. In this study, we construct a vehicle visible light communication system where event cameras are receivers, and multiple LEDs are transmitters. In driving scenes, the system tracks the transmitter positions and separates densely packed LED light sources using pilot sequences based on Walsh-Hadamard codes. As a result, outdoor vehicle experiments demonstrate error-free communication under conditions where the transmitter-receiver distance was within 40 meters and the vehicle's driving speed was 30 km/h (8.3 m/s).","authors":["Ryota Soga","Shintaro Shiba","Quan Kong","Norimasa Kobori","Tsukasa Shimizu","Shan Lu","Takaya Yamazato"],"url":"https://arxiv.org/abs/2505.15412"}
{"created":"2025-05-22","title":"Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks","abstract":"Vision Transformers have emerged as the state-of-the-art models in various Computer Vision tasks, but their high computational and resource demands pose significant challenges. While Mixture-of-Experts (MoE) can make these models more efficient, they often require costly retraining or even training from scratch. Recent developments aim to reduce these computational costs by leveraging pretrained networks. These have been shown to produce sparse activation patterns in the Multi-Layer Perceptrons (MLPs) of the encoder blocks, allowing for conditional activation of only relevant subnetworks for each sample. Building on this idea, we propose a new method to construct MoE variants from pretrained models. Our approach extracts expert subnetworks from the model's MLP layers post-training in two phases. First, we cluster output activations to identify distinct activation patterns. In the second phase, we use these clusters to extract the corresponding subnetworks responsible for producing them. On ImageNet-1k recognition tasks, we demonstrate that these extracted experts can perform surprisingly well out of the box and require only minimal fine-tuning to regain 98% of the original performance, all while reducing MACs and model size, by up to 36% and 32% respectively.","authors":["Uranik Berisha","Jens Mehnert","Alexandru Paul Condurache"],"url":"https://arxiv.org/abs/2505.15414"}
{"created":"2025-05-22","title":"$4K_1$-free graph with the cop number $3$","abstract":"The game of cops and robber is a two-player turn-based game played on a graph where the cops try to capture the robber. The cop number of a graph $G$, denoted by $c(G)$ is the minimum number of cops required to capture the robber. For a given class of graphs ${\\cal F}$, let $c({\\cal F}):=\\sup\\{c(F)|F\\in {\\cal F}\\}$, and let Forb$({\\cal F})$ denote the class of ${\\cal F}$-free graphs. We show that the complement of the Shrikhande graph is $(4K_1,C_{\\ell}$)-free for any $\\ell \\geq 6$ and has the cop number~$3$. This provides a counterexample for the conjecture proposed by Sivaraman (arxiv, 2019) which states that if $G$ is $C_{\\ell}$-free for all $\\ell\\ge 6$, then $c(G)\\le 2$. This also gives a negative answer to the question posed by Turcotte (Discrete Math. 345:112660 (2022)) 112660. to check whether $c($Forb$(pK_1))=p-2$. Turcotte also posed the question to check whether $c($Forb$(pK_1+K_2))\\leq p+1$, for $p\\geq 3$. We prove that this result indeed holds. We also generalize this result for Forb$(pK_1+qK_2)$. Motivated by the results of Baird et al. (Contrib. Discrete Math. 9:70--84 (2014)) and Turcotte and Yvon (Discrete Appl. Math. 301:74--98 (2021)), we define the upper threshold degree and lower threshold degree for a particular class of graphs and show some computational advantage to find the cop number using these.","authors":["Arnab Char","Paras Vinubhai Maniya","Dinabandhu Pradhan"],"url":"https://arxiv.org/abs/2505.15416"}
{"created":"2025-05-22","title":"Guided Policy Optimization under Partial Observability","abstract":"Reinforcement Learning (RL) in partially observable environments poses significant challenges due to the complexity of learning under uncertainty. While additional information, such as that available in simulations, can enhance training, effectively leveraging it remains an open problem. To address this, we introduce Guided Policy Optimization (GPO), a framework that co-trains a guider and a learner. The guider takes advantage of privileged information while ensuring alignment with the learner's policy that is primarily trained via imitation learning. We theoretically demonstrate that this learning scheme achieves optimality comparable to direct RL, thereby overcoming key limitations inherent in existing approaches. Empirical evaluations show strong performance of GPO across various tasks, including continuous control with partial observability and noise, and memory-based challenges, significantly outperforming existing methods.","authors":["Yueheng Li","Guangming Xie","Zongqing Lu"],"url":"https://arxiv.org/abs/2505.15418"}
{"created":"2025-05-22","title":"Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries","abstract":"Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by incorporating external knowledge bases, but they are vulnerable to privacy risks from data extraction attacks. Existing extraction methods typically rely on malicious inputs such as prompt injection or jailbreaking, making them easily detectable via input- or output-level detection. In this paper, we introduce Implicit Knowledge Extraction Attack (IKEA), which conducts knowledge extraction on RAG systems through benign queries. IKEA first leverages anchor concepts to generate queries with the natural appearance, and then designs two mechanisms to lead to anchor concept thoroughly 'explore' the RAG's privacy knowledge: (1) Experience Reflection Sampling, which samples anchor concepts based on past query-response patterns to ensure the queries' relevance to RAG documents; (2) Trust Region Directed Mutation, which iteratively mutates anchor concepts under similarity constraints to further exploit the embedding space. Extensive experiments demonstrate IKEA's effectiveness under various defenses, surpassing baselines by over 80% in extraction efficiency and 90% in attack success rate. Moreover, the substitute RAG system built from IKEA's extractions consistently outperforms those based on baseline methods across multiple evaluation tasks, underscoring the significant privacy risk in RAG systems.","authors":["Yuhao Wang","Wenjie Qu","Yanze Jiang","Zichen Liu","Yue Liu","Shengfang Zhai","Yinpeng Dong","Jiaheng Zhang"],"url":"https://arxiv.org/abs/2505.15420"}
{"created":"2025-05-22","title":"Trends and Challenges in Authorship Analysis: A Review of ML, DL, and LLM Approaches","abstract":"Authorship analysis plays an important role in diverse domains, including forensic linguistics, academia, cybersecurity, and digital content authentication. This paper presents a systematic literature review on two key sub-tasks of authorship analysis; Author Attribution and Author Verification. The review explores SOTA methodologies, ranging from traditional ML approaches to DL models and LLMs, highlighting their evolution, strengths, and limitations, based on studies conducted from 2015 to 2024. Key contributions include a comprehensive analysis of methods, techniques, their corresponding feature extraction techniques, datasets used, and emerging challenges in authorship analysis. The study highlights critical research gaps, particularly in low-resource language processing, multilingual adaptation, cross-domain generalization, and AI-generated text detection. This review aims to help researchers by giving an overview of the latest trends and challenges in authorship analysis. It also points out possible areas for future study. The goal is to support the development of better, more reliable, and accurate authorship analysis system in diverse textual domain.","authors":["Nudrat Habib","Tosin Adewumi","Marcus Liwicki","Elisa Barney"],"url":"https://arxiv.org/abs/2505.15422"}
{"created":"2025-05-22","title":"SplitWise Regression: Stepwise Modeling with Adaptive Dummy Encoding","abstract":"Capturing nonlinear relationships without sacrificing interpretability remains a persistent challenge in regression modeling. We introduce SplitWise, a novel framework that enhances stepwise regression. It adaptively transforms numeric predictors into threshold-based binary features using shallow decision trees, but only when such transformations improve model fit, as assessed by the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC). This approach preserves the transparency of linear models while flexibly capturing nonlinear effects. Implemented as a user-friendly R package, SplitWise is evaluated on both synthetic and real-world datasets. The results show that it consistently produces more parsimonious and generalizable models than traditional stepwise and penalized regression techniques.","authors":["Marcell T. Kurbucz","Nikolaos Tzivanakis","Nilufer Sari Aslam","Adam M. Sykulski"],"url":"https://arxiv.org/abs/2505.15423"}
{"created":"2025-05-22","title":"Gated Integration of Low-Rank Adaptation for Continual Learning of Language Models","abstract":"Continual learning (CL), which requires the model to learn multiple tasks sequentially, is crucial for language models (LMs). Recently, low-rank adaptation (LoRA), one of the most representative parameter-efficient fine-tuning (PEFT) methods, has gained increasing attention in CL of LMs. However, most existing CL methods based on LoRA typically expand a new LoRA branch to learn each new task and force the new and old LoRA branches to contribute equally to old tasks, potentially leading to forgetting. In this work, we propose a new method, called gated integration of low-rank adaptation (GainLoRA), for CL of LMs. GainLoRA expands a new LoRA branch for each new task and introduces gating modules to integrate the new and old LoRA branches. Furthermore, GainLoRA leverages the new gating module to minimize the contribution from the new LoRA branch to old tasks, effectively mitigating forgetting and improving the model's overall performance. Experimental results on CL benchmarks demonstrate that GainLoRA outperforms existing state-of-the-art methods.","authors":["Yan-Shuo Liang","Wu-Jun Li"],"url":"https://arxiv.org/abs/2505.15424"}
{"created":"2025-05-22","title":"On the Robustness of Medical Vision-Language Models: Are they Truly Generalizable?","abstract":"Medical Vision-Language Models (MVLMs) have achieved par excellence generalization in medical image analysis, yet their performance under noisy, corrupted conditions remains largely untested. Clinical imaging is inherently susceptible to acquisition artifacts and noise; however, existing evaluations predominantly assess generally clean datasets, overlooking robustness -- i.e., the model's ability to perform under real-world distortions. To address this gap, we first introduce MediMeta-C, a corruption benchmark that systematically applies several perturbations across multiple medical imaging datasets. Combined with MedMNIST-C, this establishes a comprehensive robustness evaluation framework for MVLMs. We further propose RobustMedCLIP, a visual encoder adaptation of a pretrained MVLM that incorporates few-shot tuning to enhance resilience against corruptions. Through extensive experiments, we benchmark 5 major MVLMs across 5 medical imaging modalities, revealing that existing models exhibit severe degradation under corruption and struggle with domain-modality tradeoffs. Our findings highlight the necessity of diverse training and robust adaptation strategies, demonstrating that efficient low-rank adaptation when paired with few-shot tuning, improves robustness while preserving generalization across modalities.","authors":["Raza Imam","Rufael Marew","Mohammad Yaqub"],"url":"https://arxiv.org/abs/2505.15425"}
{"created":"2025-05-22","title":"NeoN: A Tool for Automated Detection, Linguistic and LLM-Driven Analysis of Neologisms in Polish","abstract":"NeoN, a tool for detecting and analyzing Polish neologisms. Unlike traditional dictionary-based methods requiring extensive manual review, NeoN combines reference corpora, Polish-specific linguistic filters, an LLM-driven precision-boosting filter, and daily RSS monitoring in a multi-layered pipeline. The system uses context-aware lemmatization, frequency analysis, and orthographic normalization to extract candidate neologisms while consolidating inflectional variants. Researchers can verify candidates through an intuitive interface with visualizations and filtering controls. An integrated LLM module automatically generates definitions and categorizes neologisms by domain and sentiment. Evaluations show NeoN maintains high accuracy while significantly reducing manual effort, providing an accessible solution for tracking lexical innovation in Polish.","authors":["Aleksandra Tomaszewska","Dariusz Czerski","Bartosz \\.Zuk","Maciej Ogrodniczuk"],"url":"https://arxiv.org/abs/2505.15426"}
{"created":"2025-05-22","title":"Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions","abstract":"The remarkable ability of diffusion models to generate high-fidelity images has led to their widespread adoption. However, concerns have also arisen regarding their potential to produce Not Safe for Work (NSFW) content and exhibit social biases, hindering their practical use in real-world applications. In response to this challenge, prior work has focused on employing security filters to identify and exclude toxic text, or alternatively, fine-tuning pre-trained diffusion models to erase sensitive concepts. Unfortunately, existing methods struggle to achieve satisfactory performance in the sense that they can have a significant impact on the normal model output while still failing to prevent the generation of harmful content in some cases. In this paper, we propose a novel self-discovery approach to identifying a semantic direction vector in the embedding space to restrict text embedding within a safe region. Our method circumvents the need for correcting individual words within the input text and steers the entire text prompt towards a safe region in the embedding space, thereby enhancing model robustness against all possibly unsafe prompts. In addition, we employ Low-Rank Adaptation (LoRA) for semantic direction vector initialization to reduce the impact on the model performance for other semantics. Furthermore, our method can also be integrated with existing methods to improve their social responsibility. Extensive experiments on benchmark datasets demonstrate that our method can effectively reduce NSFW content and mitigate social bias generated by diffusion models compared to several state-of-the-art baselines.","authors":["Zhiwen Li","Die Chen","Mingyuan Fan","Cen Chen","Yaliang Li","Yanhao Wang","Wenmeng Zhou"],"url":"https://arxiv.org/abs/2505.15427"}
{"created":"2025-05-22","title":"Likelihood Variance as Text Importance for Resampling Texts to Map Language Models","abstract":"We address the computational cost of constructing a model map, which embeds diverse language models into a common space for comparison via KL divergence. The map relies on log-likelihoods over a large text set, making the cost proportional to the number of texts. To reduce this cost, we propose a resampling method that selects important texts with weights proportional to the variance of log-likelihoods across models for each text. Our method significantly reduces the number of required texts while preserving the accuracy of KL divergence estimates. Experiments show that it achieves comparable performance to uniform sampling with about half as many texts, and also facilitates efficient incorporation of new models into an existing map. These results enable scalable and efficient construction of language model maps.","authors":["Momose Oyama","Ryo Kishino","Hiroaki Yamagiwa","Hidetoshi Shimodaira"],"url":"https://arxiv.org/abs/2505.15428"}
{"created":"2025-05-22","title":"Hunyuan-TurboS: Advancing Large Language Models through Mamba-Transformer Synergy and Adaptive Chain-of-Thought","abstract":"As Large Language Models (LLMs) rapidly advance, we introduce Hunyuan-TurboS, a novel large hybrid Transformer-Mamba Mixture of Experts (MoE) model. It synergistically combines Mamba's long-sequence processing efficiency with Transformer's superior contextual understanding. Hunyuan-TurboS features an adaptive long-short chain-of-thought (CoT) mechanism, dynamically switching between rapid responses for simple queries and deep \"thinking\" modes for complex problems, optimizing computational resources. Architecturally, this 56B activated (560B total) parameter model employs 128 layers (Mamba2, Attention, FFN) with an innovative AMF/MF block pattern. Faster Mamba2 ensures linear complexity, Grouped-Query Attention minimizes KV cache, and FFNs use an MoE structure. Pre-trained on 16T high-quality tokens, it supports a 256K context length and is the first industry-deployed large-scale Mamba model. Our comprehensive post-training strategy enhances capabilities via Supervised Fine-Tuning (3M instructions), a novel Adaptive Long-short CoT Fusion method, Multi-round Deliberation Learning for iterative improvement, and a two-stage Large-scale Reinforcement Learning process targeting STEM and general instruction-following. Evaluations show strong performance: overall top 7 rank on LMSYS Chatbot Arena with a score of 1356, outperforming leading models like Gemini-2.0-Flash-001 (1352) and o4-mini-2025-04-16 (1345). TurboS also achieves an average of 77.9% across 23 automated benchmarks. Hunyuan-TurboS balances high performance and efficiency, offering substantial capabilities at lower inference costs than many reasoning models, establishing a new paradigm for efficient large-scale pre-trained models.","authors":["Ao Liu","Botong Zhou","Can Xu","Chayse Zhou","ChenChen Zhang","Chengcheng Xu","Chenhao Wang","Decheng Wu","Dengpeng Wu","Dian Jiao","Dong Du","Dong Wang","Feng Zhang","Fengzong Lian","Guanghui Xu","Guanwei Zhang","Hai Wang","Haipeng Luo","Han Hu","Huilin Xu","Jiajia Wu","Jianchen Zhu","Jianfeng Yan","Jiaqi Zhu","Jihong Zhang","Jinbao Xue","Jun Xia","Junqiang Zheng","Kai Liu","Kai Zhang","Kai Zheng","Kejiao Li","Keyao Wang","Lan Jiang","Lixin Liu","Lulu Wu","Mengyuan Huang","Peijie Yu","Peiqi Wang","Qian Wang","Qianbiao Xiang","Qibin Liu","Qingfeng Sun","Richard Guo","Ruobing Xie","Saiyong Yang","Shaohua Chen","Shihui Hu","Shuai Li","Shuaipeng Li","Shuang Chen","Suncong Zheng","Tao Yang","Tian Zhang","Tinghao Yu","Weidong Han","Weijie Liu","Weijin Zhou","Weikang Wang","Wesleye Chen","Xiao Feng","Xiaoqin Ren","Xingwu Sun","Xiong Kuang","Xuemeng Huang","Xun Cao","Yanfeng Chen","Yang Du","Yang Zhen","Yangyu Tao","Yaping Deng","Yi Shen","Yigeng Hong","Yiqi Chen","Yiqing Huang","Yuchi Deng","Yue Mao","Yulong Wang","Yuyuan Zeng","Zenan Xu","Zhanhui Kang","Zhe Zhao","ZhenXiang Yan","Zheng Fang","Zhichao Hu","Zhongzhi Chen","Zhuoyu Li","Zongwei Li","Alex Yan","Ande Liang","Baitong Liu","Beiping Pan","Bin Xing","Binghong Wu","Bingxin Qu","Bolin Ni","Boyu Wu","Chen Li","Cheng Jiang","Cheng Zhang","Chengjun Liu","Chengxu Yang","Chiyu Wang","Chong Zha","Daisy Yi","Di Wang","Fanyang Lu","Fei Chen","Feifei Liu","Feng Zheng","Guanghua Yu","Guiyang Li","Guohua Wang","Haisheng Lin","Han Liu","Han Wang","Hao Fei","Hao Lu","Haoqing Jiang","Haoran Sun","Haotian Zhu","Huangjin Dai","Huankui Chen","Huawen Feng","Huihui Cai","Huxin Peng","Jackson Lv","Jiacheng Shi","Jiahao Bu","Jianbo Li","Jianglu Hu","Jiangtao Guan","Jianing Xu","Jianwei Cai","Jiarong Zhang","Jiawei Song","Jie Jiang","Jie Liu","Jieneng Yang","Jihong Zhang","Jin lv","Jing Zhao","Jinjian Li","Jinxing Liu","Jun Zhao","Juntao Guo","Kai Wang","Kan Wu","Lei Fu","Lei He","Lei Wang","Li Liu","Liang Dong","Liya Zhan","Long Cheng","Long Xu","Mao Zheng","Meng Liu","Mengkang Hu","Nanli Chen","Peirui Chen","Peng He","Pengju Pan","Pengzhi Wei","Qi Yang","Qi Yi","Roberts Wang","Rongpeng Chen","Rui Sun","Rui Yang","Ruibin Chen","Ruixu Zhou","Shaofeng Zhang","Sheng Zhang","Shihao Xu","Shuaishuai Chang","Shulin Liu","SiQi Wang","Songjia Feng","Songling Yuan","Tao Zhang","Tianjiao Lang","Tongkai Li","Wei Deng","Wei Li","Weichao Wang","Weigang Zhang","Weixuan Sun","Wen Ouyang","Wenxiang Jiao","Wenzhi Sun","Wenzhuo Jia","Xiang Zhang","Xiangyu He","Xianshun Ren","XiaoYing Zhu","Xiaolong Guo","Xiaoxue Li","Xiaoyu Ma","Xican Lu","Xinhua Feng","Xinting Huang","Xinyu Guan","Xirui Li","Xu Zhang","Xudong Gao","Xun Luo","Xuxiang Qi","Yangkun Chen","Yangyu Tao","Yanling Xiao","Yantao Mai","Yanze Chen","Yao Ding","Yeting Yang","YiFan Song","Yifan Yang","Yijiao Zhu","Yinhe Wu","Yixian Liu","Yong Yang","Yuanjun Cai","Yuanlin Tu","Yue Zhang","Yufei Huang","Yuhang Zhou","Yuhao Jiang","Yuhong Liu","Yuhui Hu","Yujin Lin","Yun Yang","Yunhao Wang","Yusong Zhang","Zekun Wu","Zelong Zhang","Zhan Yu","Zhaoliang Yang","Zhe Zhao","Zheng Li","Zhenyu Huang","Zhiguang Liu","Zhijiang Xu","Zhiqing Kui","Zhiyin Zeng","Zhiyuan Xiong","Zhuo Han","Zifan Wu","Zigang Geng","Zilong Zhao","Ziyan Tang","Ziyuan Zhu","Zonglei Zhu","Zhijiang Xu"],"url":"https://arxiv.org/abs/2505.15431"}
{"created":"2025-05-22","title":"Set-LLM: A Permutation-Invariant LLM","abstract":"While large language models (LLMs) demonstrate impressive capabilities across numerous applications, their robustness remains a critical concern. This paper is motivated by a specific vulnerability: the order sensitivity of LLMs. This vulnerability manifests itself as the order bias observed when LLMs decide between possible options (for example, a preference for the first option) and the tendency of LLMs to provide different answers when options are reordered. The use cases for this scenario extend beyond the classical case of multiple-choice question answering to the use of LLMs as automated evaluators in AI pipelines, comparing output generated by different models. We introduce Set-LLM, a novel architectural adaptation for pretrained LLMs that enables the processing of mixed set-text inputs with permutation invariance guarantees. The adaptations involve a new attention mask and new positional encodings specifically designed for sets. We provide a theoretical proof of invariance and demonstrate through experiments that Set-LLM can be trained effectively, achieving comparable or improved performance and maintaining the runtime of the original model, while eliminating order sensitivity.","authors":["Beni Egressy","Jan St\\\"uhmer"],"url":"https://arxiv.org/abs/2505.15433"}
{"created":"2025-05-22","title":"A Faster Algorithm for Independent Cut","abstract":"The previously fastest algorithm for deciding the existence of an independent cut had a runtime of $\\mathcal{O}^*(1.4423^n)$, where $n$ is the order of the input graph. We improve this to $\\mathcal{O}^*(1.4143^n)$. In fact, we prove a runtime of $\\mathcal{O}^*\\left( 2^{(\\frac{1}{2}-\\alpha_\\Delta)n} \\right)$ on graphs of order $n$ and maximum degree at most $\\Delta$, where $\\alpha_\\Delta=\\frac{1}{2+4\\lfloor \\frac{\\Delta}{2} \\rfloor}$. Furthermore, we show that the problem is fixed-parameter tractable on graphs of order $n$ and minimum degree at least $\\beta n$ for some $\\beta > \\frac{1}{2}$, where $\\beta$ is the parameter.","authors":["Vsevolod Chernyshev","Johannes Rauch","Dieter Rautenbach","Liliia Redina"],"url":"https://arxiv.org/abs/2505.15434"}
{"created":"2025-05-22","title":"TimeCausality: Evaluating the Causal Ability in Time Dimension for Vision Language Models","abstract":"Reasoning about temporal causality, particularly irreversible transformations of objects governed by real-world knowledge (e.g., fruit decay and human aging), is a fundamental aspect of human visual understanding. Unlike temporal perception based on simple event sequences, this form of reasoning requires a deeper comprehension of how object states change over time. Although the current powerful Vision-Language Models (VLMs) have demonstrated impressive performance on a wide range of downstream tasks, their capacity to reason about temporal causality remains underexplored. To address this gap, we introduce \\textbf{TimeCausality}, a novel benchmark specifically designed to evaluate the causal reasoning ability of VLMs in the temporal dimension. Based on our TimeCausality, we find that while the current SOTA open-source VLMs have achieved performance levels comparable to closed-source models like GPT-4o on various standard visual question answering tasks, they fall significantly behind on our benchmark compared with their closed-source competitors. Furthermore, even GPT-4o exhibits a marked drop in performance on TimeCausality compared to its results on other tasks. These findings underscore the critical need to incorporate temporal causality into the evaluation and development of VLMs, and they highlight an important challenge for the open-source VLM community moving forward. Code and Data are available at \\href{https://github.com/Zeqing-Wang/TimeCausality }{TimeCausality}.","authors":["Zeqing Wang","Shiyuan Zhang","Chengpei Tang","Keze Wang"],"url":"https://arxiv.org/abs/2505.15435"}
{"created":"2025-05-22","title":"Chain-of-Focus: Adaptive Visual Search and Zooming for Multimodal Reasoning via RL","abstract":"Vision language models (VLMs) have achieved impressive performance across a variety of computer vision tasks. However, the multimodal reasoning capability has not been fully explored in existing models. In this paper, we propose a Chain-of-Focus (CoF) method that allows VLMs to perform adaptive focusing and zooming in on key image regions based on obtained visual cues and the given questions, achieving efficient multimodal reasoning. To enable this CoF capability, we present a two-stage training pipeline, including supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct the MM-CoF dataset, comprising 3K samples derived from a visual agent designed to adaptively identify key regions to solve visual tasks with different image resolutions and questions. We use MM-CoF to fine-tune the Qwen2.5-VL model for cold start. In the RL stage, we leverage the outcome accuracies and formats as rewards to update the Qwen2.5-VL model, enabling further refining the search and reasoning strategy of models without human priors. Our model achieves significant improvements on multiple benchmarks. On the V* benchmark that requires strong visual reasoning capability, our model outperforms existing VLMs by 5% among 8 image resolutions ranging from 224 to 4K, demonstrating the effectiveness of the proposed CoF method and facilitating the more efficient deployment of VLMs in practical applications.","authors":["Xintong Zhang","Zhi Gao","Bofei Zhang","Pengxiang Li","Xiaowen Zhang","Yang Liu","Tao Yuan","Yuwei Wu","Yunde Jia","Song-Chun Zhu","Qing Li"],"url":"https://arxiv.org/abs/2505.15436"}
{"created":"2025-05-22","title":"Bridging Sign and Spoken Languages: Pseudo Gloss Generation for Sign Language Translation","abstract":"Sign Language Translation (SLT) aims to map sign language videos to spoken language text. A common approach relies on gloss annotations as an intermediate representation, decomposing SLT into two sub-tasks: video-to-gloss recognition and gloss-to-text translation. While effective, this paradigm depends on expert-annotated gloss labels, which are costly and rarely available in existing datasets, limiting its scalability. To address this challenge, we propose a gloss-free pseudo gloss generation framework that eliminates the need for human-annotated glosses while preserving the structured intermediate representation. Specifically, we prompt a Large Language Model (LLM) with a few example text-gloss pairs using in-context learning to produce draft sign glosses from spoken language text. To enhance the correspondence between LLM-generated pseudo glosses and the sign sequences in video, we correct the ordering in the pseudo glosses for better alignment via a weakly supervised learning process. This reordering facilitates the incorporation of auxiliary alignment objectives, and allows for the use of efficient supervision via a Connectionist Temporal Classification (CTC) loss. We train our SLT mode, which consists of a vision encoder and a translator, through a three-stage pipeline, which progressively narrows the modality gap between sign language and spoken language. Despite its simplicity, our approach outperforms previous state-of-the-art gloss-free frameworks on two SLT benchmarks and achieves competitive results compared to gloss-based methods.","authors":["Jianyuan Guo","Peike Li","Trevor Cohn"],"url":"https://arxiv.org/abs/2505.15438"}
{"created":"2025-05-22","title":"FRN: Fractal-Based Recursive Spectral Reconstruction Network","abstract":"Generating hyperspectral images (HSIs) from RGB images through spectral reconstruction can significantly reduce the cost of HSI acquisition. In this paper, we propose a Fractal-Based Recursive Spectral Reconstruction Network (FRN), which differs from existing paradigms that attempt to directly integrate the full-spectrum information from the R, G, and B channels in a one-shot manner. Instead, it treats spectral reconstruction as a progressive process, predicting from broad to narrow bands or employing a coarse-to-fine approach for predicting the next wavelength. Inspired by fractals in mathematics, FRN establishes a novel spectral reconstruction paradigm by recursively invoking an atomic reconstruction module. In each invocation, only the spectral information from neighboring bands is used to provide clues for the generation of the image at the next wavelength, which follows the low-rank property of spectral data. Moreover, we design a band-aware state space model that employs a pixel-differentiated scanning strategy at different stages of the generation process, further suppressing interference from low-correlation regions caused by reflectance differences. Through extensive experimentation across different datasets, FRN achieves superior reconstruction performance compared to state-of-the-art methods in both quantitative and qualitative evaluations.","authors":["Ge Meng","Zhongnan Cai","Ruizhe Chen","Jingyan Tu","Yingying Wang","Yue Huang","Xinghao Ding"],"url":"https://arxiv.org/abs/2505.15439"}
{"created":"2025-05-22","title":"What Is Serendipity? An Interview Study to Conceptualize Experienced Serendipity in Recommender Systems","abstract":"Serendipity has been associated with numerous benefits in the context of recommender systems, e.g., increased user satisfaction and consumption of long-tail items. Despite this, serendipity in the context of recommender systems has thus far remained conceptually ambiguous. This conceptual ambiguity has led to inconsistent operationalizations between studies, making it difficult to compare and synthesize findings. In this paper, we conceptualize the user's experience of serendipity. To this effect, we interviewed 17 participants and analyzed the data following the grounded theory paradigm. Based on these interviews, we conceptualize experienced serendipity as \"a user experience in which a user unintentionally encounters content that feels fortuitous, refreshing, and enriching\". We find that all three components -- fortuitous, refreshing and enriching -- are necessary and together are sufficient to classify a user's experience as serendipitous. However, these components can be satisfied through a variety of conditions. Our conceptualization unifies previous definitions of serendipity within a single framework, resolving inconsistencies by identifying distinct flavors of serendipity. It highlights underexposed flavors, offering new insights into how users experience serendipity in the context of recommender systems. By clarifying the components and conditions of experienced serendipity in recommender systems, this work can guide the design of recommender systems that stimulate experienced serendipity in their users, and lays the groundwork for developing a standardized operationalization of experienced serendipity in its many flavors, enabling more consistent and comparable evaluations.","authors":["Brett Binst","Lien Michiels","Annelien Smets"],"url":"https://arxiv.org/abs/2505.15440"}
{"created":"2025-05-22","title":"Stronger ViTs With Octic Equivariance","abstract":"Recent efforts at scaling computer vision models have established Vision Transformers (ViTs) as the leading architecture. ViTs incorporate weight sharing over image patches as an important inductive bias. In this work, we show that ViTs benefit from incorporating equivariance under the octic group, i.e., reflections and 90-degree rotations, as a further inductive bias. We develop new architectures, octic ViTs, that use octic-equivariant layers and put them to the test on both supervised and self-supervised learning. Through extensive experiments on DeiT-III and DINOv2 training on ImageNet-1K, we show that octic ViTs yield more computationally efficient networks while also improving performance. In particular, we achieve approximately 40% reduction in FLOPs for ViT-H while simultaneously improving both classification and segmentation results.","authors":["David Nordstr\\\"om","Johan Edstedt","Fredrik Kahl","Georg B\\\"okman"],"url":"https://arxiv.org/abs/2505.15441"}
{"created":"2025-05-22","title":"On the Generalization vs Fidelity Paradox in Knowledge Distillation","abstract":"Knowledge distillation (KD) is a key technique for compressing large language models into smaller ones while preserving performance. Despite the recent traction of KD research, its effectiveness for smaller language models (LMs) and the mechanisms driving knowledge transfer remain underexplored. In this work, we present the first large-scale empirical and statistical analysis of KD across models ranging from 0.5B to 7B parameters on 14 complex reasoning tasks in a zero-shot setting. Our findings reveal that KD can improve the average performance of smaller models by up to $10\\%$, with a peak task specific gain of $22\\%$, while providing only marginal benefits ($\\sim 1.3\\%$) for larger models. Surprisingly, teacher performance has a minimal impact on student outcomes, while teacher task expertise impacts KD effectiveness. A correlation study indicates that smaller LMs benefit more from KD, whereas larger LMs show diminished gains. Additionally, we uncover a misalignment between improvements in student performance and reasoning fidelity, suggesting that while KD enhances accuracy, it does not always maintain the structured decision-making processes of the teacher. Our ablation study further highlights the importance of teacher signals and logit smoothing in influencing students' performance after distillation. Overall, our study offers a comprehensive empirical and statistical assessment of KD, highlighting both its benefits and trade-offs when distilling knowledge from larger to smaller LMs.","authors":["Suhas Kamasetty Ramesh","Ayan Sengupta","Tanmoy Chakraborty"],"url":"https://arxiv.org/abs/2505.15442"}
{"created":"2025-05-22","title":"AdUE: Improving uncertainty estimation head for LoRA adapters in LLMs","abstract":"Uncertainty estimation remains a critical challenge in adapting pre-trained language models to classification tasks, particularly under parameter-efficient fine-tuning approaches such as adapters. We introduce AdUE1, an efficient post-hoc uncertainty estimation (UE) method, to enhance softmax-based estimates. Our approach (1) uses a differentiable approximation of the maximum function and (2) applies additional regularization through L2-SP, anchoring the fine-tuned head weights and regularizing the model. Evaluations on five NLP classification datasets across four language models (RoBERTa, ELECTRA, LLaMA-2, Qwen) demonstrate that our method consistently outperforms established baselines such as Mahalanobis distance and softmax response. Our approach is lightweight (no base-model changes) and produces better-calibrated confidence.","authors":["Artem Zabolotnyi","Roman Makarov","Mile Mitrovic","Polina Proskura","Oleg Travkin","Roman Alferov","Alexey Zaytsev"],"url":"https://arxiv.org/abs/2505.15443"}
{"created":"2025-05-22","title":"Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization","abstract":"Existing studies have optimized retrieval-augmented generation (RAG) across various sub-tasks, such as query understanding and retrieval refinement, but integrating these optimizations into a unified framework remains challenging. To tackle this problem, this work proposes RoleRAG, a unified RAG framework that achieves efficient multi-task processing through role-specific token optimization. RoleRAG comprises six modules, each handling a specific sub-task within the RAG process. Additionally, we introduce a query graph to represent the decomposition of the query, which can be dynamically resolved according to the decomposing state. All modules are driven by the same underlying LLM, distinguished by task-specific role tokens that are individually optimized. This design allows RoleRAG to dynamically activate different modules within a single LLM instance, thereby streamlining deployment and reducing resource consumption. Experimental results on five open-domain question-answering datasets demonstrate the effectiveness, generalizability, and flexibility of our framework.","authors":["Yutao Zhu","Jiajie Jin","Hongjin Qian","Zheng Liu","Zhicheng Dou","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.15444"}
{"created":"2025-05-22","title":"ViaRL: Adaptive Temporal Grounding via Visual Iterated Amplification Reinforcement Learning","abstract":"Video understanding is inherently intention-driven-humans naturally focus on relevant frames based on their goals. Recent advancements in multimodal large language models (MLLMs) have enabled flexible query-driven reasoning; however, video-based frameworks like Video Chain-of-Thought lack direct training signals to effectively identify relevant frames. Current approaches often rely on heuristic methods or pseudo-label supervised annotations, which are both costly and limited in scalability across diverse scenarios. To overcome these challenges, we introduce ViaRL, the first framework to leverage rule-based reinforcement learning (RL) for optimizing frame selection in intention-driven video understanding. An iterated amplification strategy is adopted to perform alternating cyclic training in the video CoT system, where each component undergoes iterative cycles of refinement to improve its capabilities. ViaRL utilizes the answer accuracy of a downstream model as a reward signal to train a frame selector through trial-and-error, eliminating the need for expensive annotations while closely aligning with human-like learning processes. Comprehensive experiments across multiple benchmarks, including VideoMME, LVBench, and MLVU, demonstrate that ViaRL consistently delivers superior temporal grounding performance and robust generalization across diverse video understanding tasks, highlighting its effectiveness and scalability. Notably, ViaRL achieves a nearly 15\\% improvement on Needle QA, a subset of MLVU, which is required to search a specific needle within a long video and regarded as one of the most suitable benchmarks for evaluating temporal grounding.","authors":["Ziqiang Xu","Qi Dai","Tian Xie","Yifan Yang","Kai Qiu","DongDong Chen","Zuxuan Wu","Chong Luo"],"url":"https://arxiv.org/abs/2505.15447"}
{"created":"2025-05-22","title":"Comprehensive Evaluation and Analysis for NSFW Concept Erasure in Text-to-Image Diffusion Models","abstract":"Text-to-image diffusion models have gained widespread application across various domains, demonstrating remarkable creative potential. However, the strong generalization capabilities of diffusion models can inadvertently lead to the generation of not-safe-for-work (NSFW) content, posing significant risks to their safe deployment. While several concept erasure methods have been proposed to mitigate the issue associated with NSFW content, a comprehensive evaluation of their effectiveness across various scenarios remains absent. To bridge this gap, we introduce a full-pipeline toolkit specifically designed for concept erasure and conduct the first systematic study of NSFW concept erasure methods. By examining the interplay between the underlying mechanisms and empirical observations, we provide in-depth insights and practical guidance for the effective application of concept erasure methods in various real-world scenarios, with the aim of advancing the understanding of content safety in diffusion models and establishing a solid foundation for future research and development in this critical area.","authors":["Die Chen","Zhiwen Li","Cen Chen","Yuexiang Xie","Xiaodan Li","Jinyan Ye","Yingda Chen","Yaliang Li"],"url":"https://arxiv.org/abs/2505.15450"}
{"created":"2025-05-22","title":"Pointwise Convergence in Games with Conflicting Interest","abstract":"In this work, we introduce the concept of non-negative weighted regret, an extension of non-negative regret \\cite{anagnostides2022last} in games. Investigating games with non-negative weighted regret helps us to understand games with conflicting interests, including harmonic games and important classes of zero-sum games.We show that optimistic variants of classical no-regret learning algorithms, namely optimistic mirror descent (OMD) and optimistic follow the regularized leader (OFTRL), converge to an $\\epsilon$-approximate Nash equilibrium at a rate of $O(1/\\epsilon^2)$.Consequently, they guarantee pointwise convergence to a Nash equilibrium if there are only finitely many Nash equilibria in the game. These algorithms are robust in the sense the convergence holds even if the players deviate Our theoretical findings are supported by empirical evaluations of OMD and OFTRL on the game of matching pennies and harmonic game instances.","authors":["Nanxiang Zhou","Jing Dong","Baoxiang Wang"],"url":"https://arxiv.org/abs/2505.15454"}
{"created":"2025-05-22","title":"Teaching Language Models to Evolve with Users: Dynamic Profile Modeling for Personalized Alignment","abstract":"Personalized alignment is essential for enabling large language models (LLMs) to engage effectively in user-centric dialogue. While recent prompt-based and offline optimization methods offer preliminary solutions, they fall short in cold-start scenarios and long-term personalization due to their inherently static and shallow designs. In this work, we introduce the Reinforcement Learning for Personalized Alignment (RLPA) framework, in which an LLM interacts with a simulated user model to iteratively infer and refine user profiles through dialogue. The training process is guided by a dual-level reward structure: the Profile Reward encourages accurate construction of user representations, while the Response Reward incentivizes generation of responses consistent with the inferred profile. We instantiate RLPA by fine-tuning Qwen-2.5-3B-Instruct, resulting in Qwen-RLPA, which achieves state-of-the-art performance in personalized dialogue. Empirical evaluations demonstrate that Qwen-RLPA consistently outperforms prompting and offline fine-tuning baselines, and even surpasses advanced commercial models such as Claude-3.5 and GPT-4o. Further analysis highlights Qwen-RLPA's robustness in reconciling conflicting user preferences, sustaining long-term personalization and delivering more efficient inference compared to recent reasoning-focused LLMs. These results emphasize the potential of dynamic profile inference as a more effective paradigm for building personalized dialogue systems.","authors":["Weixiang Zhao","Xingyu Sui","Yulin Hu","Jiahe Guo","Haixiao Liu","Biye Li","Yanyan Zhao","Bing Qin","Ting Liu"],"url":"https://arxiv.org/abs/2505.15456"}
{"created":"2025-05-22","title":"Developing clinical informatics to support direct care and population health management: the VIEWER story","abstract":"Electronic health records (EHRs) provide comprehensive patient data which could be better used to enhance informed decision-making, resource allocation, and coordinated care, thereby optimising healthcare delivery. However, in mental healthcare, critical information, such as on risk factors, precipitants, and treatment responses, is often embedded in unstructured text, limiting the ability to automate at scale measures to identify and prioritise local populations and patients, which potentially hinders timely prevention and intervention. We describe the development and proof-of-concept implementation of VIEWER, a clinical informatics platform designed to enhance direct patient care and population health management by improving the accessibility and usability of EHR data. We further outline strategies that were employed in this work to foster informatics innovation through interdisciplinary and cross-organisational collaboration to support integrated, personalised care, and detail how these advancements were piloted and implemented within a large UK mental health National Health Service Foundation Trust to improve patient outcomes at an individual patient, clinician, clinical team, and organisational level.","authors":["Robert Harland","Tao Wang","David Codling","Catherine Polling","Matthew Broadbent","Holly Newton","Yamiko Joseph Msosa","Daisy Kornblum","Claire Delaney-Pope","Barbara Arroyo","Stuart MacLellan","Zoe Keddie","Mary Docherty","Angus Roberts","Derek Tracy","Philip McGuire","Richard Dobson","Robert Stewart"],"url":"https://arxiv.org/abs/2505.15459"}
{"created":"2025-05-22","title":"AI-based Decision Support System for Heritage Aircraft Corrosion Prevention","abstract":"The paper presents a decision support system for the long-term preservation of aeronautical heritage exhibited/stored in sheltered sites. The aeronautical heritage is characterized by diverse materials of which this heritage is constituted. Heritage aircraft are made of ancient aluminum alloys, (ply)wood, and particularly fabrics. The decision support system (DSS) designed, starting from a conceptual model, is knowledge-based on degradation/corrosion mechanisms of prevailing materials of aeronautical heritage. In the case of historical aircraft wooden parts, this knowledge base is filled in by the damage function models developed within former European projects. Model-based corrosion prediction is implemented within the new DSS for ancient aluminum alloys. The novelty of this DSS consists of supporting multi-material heritage protection and tailoring to peculiarities of aircraft exhibition/storage hangars and the needs of aviation museums. The novel DSS is tested on WWII aircraft heritage exhibited in the Aviation Museum Kbely, Military History Institute Prague, Czech Republic.","authors":["Michal Kucha\\v{r}","Jarom\\'ir Fi\\v{s}er","Cyril Oswald","Tom\\'a\\v{s} Vyhl\\'idal"],"url":"https://arxiv.org/abs/2505.15462"}
{"created":"2025-05-22","title":"Synthetic Enclosed Echoes: A New Dataset to Mitigate the Gap Between Simulated and Real-World Sonar Data","abstract":"This paper introduces Synthetic Enclosed Echoes (SEE), a novel dataset designed to enhance robot perception and 3D reconstruction capabilities in underwater environments. SEE comprises high-fidelity synthetic sonar data, complemented by a smaller subset of real-world sonar data. To facilitate flexible data acquisition, a simulated environment has been developed, enabling the generation of additional data through modifications such as the inclusion of new structures or imaging sonar configurations. This hybrid approach leverages the advantages of synthetic data, including readily available ground truth and the ability to generate diverse datasets, while bridging the simulation-to-reality gap with real-world data acquired in a similar environment. The SEE dataset comprehensively evaluates acoustic data-based methods, including mathematics-based sonar approaches and deep learning algorithms. These techniques were employed to validate the dataset, confirming its suitability for underwater 3D reconstruction. Furthermore, this paper proposes a novel modification to a state-of-the-art algorithm, demonstrating improved performance compared to existing methods. The SEE dataset enables the evaluation of acoustic data-based methods in realistic scenarios, thereby improving their feasibility for real-world underwater applications.","authors":["Guilherme de Oliveira","Matheus M. dos Santos","Paulo L. J. Drews-Jr"],"url":"https://arxiv.org/abs/2505.15465"}
{"created":"2025-05-22","title":"A Participatory Strategy for AI Ethics in Education and Rehabilitation grounded in the Capability Approach","abstract":"AI-based technologies have significant potential to enhance inclusive education and clinical-rehabilitative contexts for children with Special Educational Needs and Disabilities. AI can enhance learning experiences, empower students, and support both teachers and rehabilitators. However, their usage presents challenges that require a systemic-ecological vision, ethical considerations, and participatory research. Therefore, research and technological development must be rooted in a strong ethical-theoretical framework. The Capability Approach - a theoretical model of disability, human vulnerability, and inclusion - offers a more relevant perspective on functionality, effectiveness, and technological adequacy in inclusive learning environments. In this paper, we propose a participatory research strategy with different stakeholders through a case study on the ARTIS Project, which develops an AI-enriched interface to support children with text comprehension difficulties. Our research strategy integrates ethical, educational, clinical, and technological expertise in designing and implementing AI-based technologies for children's learning environments through focus groups and collaborative design sessions. We believe that this holistic approach to AI adoption in education can help bridge the gap between technological innovation and ethical responsibility.","authors":["Valeria Cesaroni","Eleonora Pasqua","Piercosma Bisconti","Martina Galletti"],"url":"https://arxiv.org/abs/2505.15466"}
{"created":"2025-05-22","title":"Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning","abstract":"Large language models have achieved remarkable success in various tasks. However, it is challenging for them to learn new tasks incrementally due to catastrophic forgetting. Existing approaches rely on experience replay, optimization constraints, or task differentiation, which encounter strict limitations in real-world scenarios. To address these issues, we propose Joint Flashback Adaptation. We first introduce flashbacks -- a limited number of prompts from old tasks -- when adapting to new tasks and constrain the deviations of the model outputs compared to the original one. We then interpolate latent tasks between flashbacks and new tasks to enable jointly learning relevant latent tasks, new tasks, and flashbacks, alleviating data sparsity in flashbacks and facilitating knowledge sharing for smooth adaptation. Our method requires only a limited number of flashbacks without access to the replay data and is task-agnostic. We conduct extensive experiments on state-of-the-art large language models across 1000+ instruction-following tasks, arithmetic reasoning tasks, and general reasoning tasks. The results demonstrate the superior performance of our method in improving generalization on new tasks and reducing forgetting in old tasks.","authors":["Yukun Zhao","Lingyong Yan","Zhenyang Li","Shuaiqiang Wang","Zhumin Chen","Zhaochun Ren","Dawei Yin"],"url":"https://arxiv.org/abs/2505.15467"}
{"created":"2025-05-22","title":"A Qualitative Investigation into LLM-Generated Multilingual Code Comments and Automatic Evaluation Metrics","abstract":"Large Language Models are essential coding assistants, yet their training is predominantly English-centric. In this study, we evaluate the performance of code language models in non-English contexts, identifying challenges in their adoption and integration into multilingual workflows. We conduct an open-coding study to analyze errors in code comments generated by five state-of-the-art code models, CodeGemma, CodeLlama, CodeQwen1.5, GraniteCode, and StarCoder2 across five natural languages: Chinese, Dutch, English, Greek, and Polish. Our study yields a dataset of 12,500 labeled generations, which we publicly release. We then assess the reliability of standard metrics in capturing comment \\textit{correctness} across languages and evaluate their trustworthiness as judgment criteria. Through our open-coding investigation, we identified a taxonomy of 26 distinct error categories in model-generated code comments. They highlight variations in language cohesion, informativeness, and syntax adherence across different natural languages. Our analysis shows that, while these models frequently produce partially correct comments, modern neural metrics fail to reliably differentiate meaningful completions from random noise. Notably, the significant score overlap between expert-rated correct and incorrect comments calls into question the effectiveness of these metrics in assessing generated comments.","authors":["Jonathan Katzy","Yongcheng Huang","Gopal-Raj Panchu","Maksym Ziemlewski","Paris Loizides","Sander Vermeulen","Arie van Deursen","Maliheh Izadi"],"url":"https://arxiv.org/abs/2505.15469"}
{"created":"2025-05-22","title":"CoLA: Collaborative Low-Rank Adaptation","abstract":"The scaling law of Large Language Models (LLMs) reveals a power-law relationship, showing diminishing return on performance as model scale increases. While training LLMs from scratch is resource-intensive, fine-tuning a pre-trained model for specific tasks has become a practical alternative. Full fine-tuning (FFT) achieves strong performance; however, it is computationally expensive and inefficient. Parameter-efficient fine-tuning (PEFT) methods, like LoRA, have been proposed to address these challenges by freezing the pre-trained model and adding lightweight task-specific modules. LoRA, in particular, has proven effective, but its application to multi-task scenarios is limited by interference between tasks. Recent approaches, such as Mixture-of-Experts (MOE) and asymmetric LoRA, have aimed to mitigate these issues but still struggle with sample scarcity and noise interference due to their fixed structure. In response, we propose CoLA, a more flexible LoRA architecture with an efficient initialization scheme, and introduces three collaborative strategies to enhance performance by better utilizing the quantitative relationships between matrices $A$ and $B$. Our experiments demonstrate the effectiveness and robustness of CoLA, outperforming existing PEFT methods, especially in low-sample scenarios. Our data and code are fully publicly available at https://github.com/zyy-2001/CoLA.","authors":["Yiyun Zhou","Chang Yao","Jingyuan Chen"],"url":"https://arxiv.org/abs/2505.15471"}
{"created":"2025-05-22","title":"PhysicsArena: The First Multimodal Physics Reasoning Benchmark Exploring Variable, Process, and Solution Dimensions","abstract":"Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in diverse reasoning tasks, yet their application to complex physics reasoning remains underexplored. Physics reasoning presents unique challenges, requiring grounding in physical conditions and the interpretation of multimodal information. Current physics benchmarks are limited, often focusing on text-only inputs or solely on problem-solving, thereby overlooking the critical intermediate steps of variable identification and process formulation. To address these limitations, we introduce PhysicsArena, the first multimodal physics reasoning benchmark designed to holistically evaluate MLLMs across three critical dimensions: variable identification, physical process formulation, and solution derivation. PhysicsArena aims to provide a comprehensive platform for assessing and advancing the multimodal physics reasoning abilities of MLLMs.","authors":["Song Dai","Yibo Yan","Jiamin Su","Dongfang Zihao","Yubo Gao","Yonghua Hei","Jungang Li","Junyan Zhang","Sicheng Tao","Zhuoran Gao","Xuming Hu"],"url":"https://arxiv.org/abs/2505.15472"}
{"created":"2025-05-22","title":"LFTF: Locating First and Then Fine-Tuning for Mitigating Gender Bias in Large Language Models","abstract":"Nowadays, Large Language Models (LLMs) have attracted widespread attention due to their powerful performance. However, due to the unavoidable exposure to socially biased data during training, LLMs tend to exhibit social biases, particularly gender bias. To better explore and quantifying the degree of gender bias in LLMs, we propose a pair of datasets named GenBiasEval and GenHintEval, respectively. The GenBiasEval is responsible for evaluating the degree of gender bias in LLMs, accompanied by an evaluation metric named AFGB-Score (Absolutely Fair Gender Bias Score). Meanwhile, the GenHintEval is used to assess whether LLMs can provide responses consistent with prompts that contain gender hints, along with the accompanying evaluation metric UB-Score (UnBias Score). Besides, in order to mitigate gender bias in LLMs more effectively, we present the LFTF (Locating First and Then Fine-Tuning) algorithm.The algorithm first ranks specific LLM blocks by their relevance to gender bias in descending order using a metric called BMI (Block Mitigating Importance Score). Based on this ranking, the block most strongly associated with gender bias is then fine-tuned using a carefully designed loss function. Numerous experiments have shown that our proposed LFTF algorithm can significantly mitigate gender bias in LLMs while maintaining their general capabilities.","authors":["Zhanyue Qin","Yue Ding","Deyuan Liu","Qingbin Liu","Junxian Cai","Xi Chen","Zhiying Tu","Dianhui Chu","Cuiyun Gao","Dianbo Sui"],"url":"https://arxiv.org/abs/2505.15475"}
{"created":"2025-05-22","title":"Pura: An Efficient Privacy-Preserving Solution for Face Recognition","abstract":"Face recognition is an effective technology for identifying a target person by facial images. However, sensitive facial images raises privacy concerns. Although privacy-preserving face recognition is one of potential solutions, this solution neither fully addresses the privacy concerns nor is efficient enough. To this end, we propose an efficient privacy-preserving solution for face recognition, named Pura, which sufficiently protects facial privacy and supports face recognition over encrypted data efficiently. Specifically, we propose a privacy-preserving and non-interactive architecture for face recognition through the threshold Paillier cryptosystem. Additionally, we carefully design a suite of underlying secure computing protocols to enable efficient operations of face recognition over encrypted data directly. Furthermore, we introduce a parallel computing mechanism to enhance the performance of the proposed secure computing protocols. Privacy analysis demonstrates that Pura fully safeguards personal facial privacy. Experimental evaluations demonstrate that Pura achieves recognition speeds up to 16 times faster than the state-of-the-art.","authors":["Guotao Xu","Bowen Zhao","Yang Xiao","Yantao Zhong","Liang Zhai","Qingqi Pei"],"url":"https://arxiv.org/abs/2505.15476"}
{"created":"2025-05-22","title":"KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance","abstract":"Supervised fine-tuning (SFT) is a common approach to improve the domain-specific question-answering (QA) performance of large language models (LLMs). However, recent literature reveals that due to the conflicts between LLMs' internal knowledge and the context knowledge of training data, vanilla SFT using the full QA training set is usually suboptimal. In this paper, we first design a query diversification strategy for robust conflict detection and then conduct a series of experiments to analyze the impact of knowledge conflict. We find that 1) training samples with varied conflicts contribute differently, where SFT on the data with large conflicts leads to catastrophic performance drops; 2) compared to directly filtering out the conflict data, appropriately applying the conflict data would be more beneficial. Motivated by this, we propose a simple-yet-effective Knowledge-aware Fine-tuning (namely KaFT) approach to effectively boost LLMs' performance. The core of KaFT is to adapt the training weight by assigning different rewards for different training samples according to conflict level. Extensive experiments show that KaFT brings consistent and significant improvements across four LLMs. More analyses prove that KaFT effectively improves the model generalization and alleviates the hallucination.","authors":["Qihuang Zhong","Liang Ding","Xiantao Cai","Juhua Liu","Bo Du","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.15480"}
{"created":"2025-05-22","title":"Optimal Piecewise-based Mechanism for Collecting Bounded Numerical Data under Local Differential Privacy","abstract":"Numerical data with bounded domains is a common data type in personal devices, such as wearable sensors. While the collection of such data is essential for third-party platforms, it raises significant privacy concerns. Local differential privacy (LDP) has been shown as a framework providing provable individual privacy, even when the third-party platform is untrusted. For numerical data with bounded domains, existing state-of-the-art LDP mechanisms are piecewise-based mechanisms, which are not optimal, leading to reduced data utility.","authors":["Ye Zheng","Sumita Mishra","Yidan Hu"],"url":"https://arxiv.org/abs/2505.15483"}
{"created":"2025-05-22","title":"Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models","abstract":"The real-world impact of misinformation stems from the underlying misleading narratives that creators seek to convey. As such, interpreting misleading creator intent is essential for multimodal misinformation detection (MMD) systems aimed at effective information governance. In this paper, we introduce an automated framework that simulates real-world multimodal news creation by explicitly modeling creator intent through two components: the desired influence and the execution plan. Using this framework, we construct DeceptionDecoded, a large-scale benchmark comprising 12,000 image-caption pairs aligned with trustworthy reference articles. The dataset captures both misleading and non-misleading intents and spans manipulations across visual and textual modalities. We conduct a comprehensive evaluation of 14 state-of-the-art vision-language models (VLMs) on three intent-centric tasks: (1) misleading intent detection, (2) misleading source attribution, and (3) creator desire inference. Despite recent advances, we observe that current VLMs fall short in recognizing misleading intent, often relying on spurious cues such as superficial cross-modal consistency, stylistic signals, and heuristic authenticity hints. Our findings highlight the pressing need for intent-aware modeling in MMD and open new directions for developing systems capable of deeper reasoning about multimodal misinformation.","authors":["Jiaying Wu","Fanxiao Li","Min-Yen Kan","Bryan Hooi"],"url":"https://arxiv.org/abs/2505.15489"}
{"created":"2025-05-22","title":"Collaborative Problem-Solving in an Optimization Game","abstract":"Dialogue agents that support human users in solving complex tasks have received much attention recently. Many such tasks are NP-hard optimization problems that require careful collaborative exploration of the solution space. We introduce a novel dialogue game in which the agents collaboratively solve a two-player Traveling Salesman problem, along with an agent that combines LLM prompting with symbolic mechanisms for state tracking and grounding. Our best agent solves 45% of games optimally in self-play. It also demonstrates an ability to collaborate successfully with human users and generalize to unfamiliar graphs.","authors":["Isidora Jeknic","Alex Duchnowski","Alexander Koller"],"url":"https://arxiv.org/abs/2505.15490"}
{"created":"2025-05-22","title":"Spectral-Aware Global Fusion for RGB-Thermal Semantic Segmentation","abstract":"Semantic segmentation relying solely on RGB data often struggles in challenging conditions such as low illumination and obscured views, limiting its reliability in critical applications like autonomous driving. To address this, integrating additional thermal radiation data with RGB images demonstrates enhanced performance and robustness. However, how to effectively reconcile the modality discrepancies and fuse the RGB and thermal features remains a well-known challenge. In this work, we address this challenge from a novel spectral perspective. We observe that the multi-modal features can be categorized into two spectral components: low-frequency features that provide broad scene context, including color variations and smooth areas, and high-frequency features that capture modality-specific details such as edges and textures. Inspired by this, we propose the Spectral-aware Global Fusion Network (SGFNet) to effectively enhance and fuse the multi-modal features by explicitly modeling the interactions between the high-frequency, modality-specific features. Our experimental results demonstrate that SGFNet outperforms the state-of-the-art methods on the MFNet and PST900 datasets.","authors":["Ce Zhang","Zifu Wan","Simon Stepputtis","Katia Sycara","Yaqi Xie"],"url":"https://arxiv.org/abs/2505.15491"}
{"created":"2025-05-22","title":"Fast Rate Bounds for Multi-Task and Meta-Learning with Different Sample Sizes","abstract":"We present new fast-rate generalization bounds for multi-task and meta-learning in the unbalanced setting, i.e. when the tasks have training sets of different sizes, as is typically the case in real-world scenarios. Previously, only standard-rate bounds were known for this situation, while fast-rate bounds were limited to the setting where all training sets are of equal size. Our new bounds are numerically computable as well as interpretable, and we demonstrate their flexibility in handling a number of cases where they give stronger guarantees than previous bounds. Besides the bounds themselves, we also make conceptual contributions: we demonstrate that the unbalanced multi-task setting has different statistical properties than the balanced situation, specifically that proofs from the balanced situation do not carry over to the unbalanced setting. Additionally, we shed light on the fact that the unbalanced situation allows two meaningful definitions of multi-task risk, depending on whether if all tasks should be considered equally important or if sample-rich tasks should receive more weight than sample-poor ones.","authors":["Hossein Zakerinia","Christoph H. Lampert"],"url":"https://arxiv.org/abs/2505.15496"}
{"created":"2025-05-22","title":"Certified Neural Approximations of Nonlinear Dynamics","abstract":"Neural networks hold great potential to act as approximate models of nonlinear dynamical systems, with the resulting neural approximations enabling verification and control of such systems. However, in safety-critical contexts, the use of neural approximations requires formal bounds on their closeness to the underlying system. To address this fundamental challenge, we propose a novel, adaptive, and parallelizable verification method based on certified first-order models. Our approach provides formal error bounds on the neural approximations of dynamical systems, allowing them to be safely employed as surrogates by interpreting the error bound as bounded disturbances acting on the approximated dynamics. We demonstrate the effectiveness and scalability of our method on a range of established benchmarks from the literature, showing that it outperforms the state-of-the-art. Furthermore, we highlight the flexibility of our framework by applying it to two novel scenarios not previously explored in this context: neural network compression and an autoencoder-based deep learning architecture for learning Koopman operators, both yielding compelling results.","authors":["Frederik Baymler Mathiesen","Nikolaus Vertovec","Francesco Fabiano","Luca Laurenti","Alessandro Abate"],"url":"https://arxiv.org/abs/2505.15497"}
{"created":"2025-05-22","title":"Creation of fixed points in block-parallel Boolean automata networks","abstract":"In the context of discrete dynamical systems and their applications, fixed points often have a clear interpretation. This is indeed a central topic of gene regulatory mechanisms modeled by Boolean automata networks (BANs), where a xollection of Boolean entities (the automata) update their state depending on the states of others. Fixed points represent phenotypes such as differentiated cell types. The interaction graph of a BAN captures the architecture of dependencies among its automata. A first seminal result is that cycles of interactions (so called feedbacks) are the engines of dynamical complexity. A second seminal result is that fixed points are invariant under block-sequential update schedules, which update the automata following an ordered partition of the set of automata. In this article we study the ability of block-parallel update schedules (dual to the latter) to break this fixed point invariance property, with a focus on the simplest feedback mechanism: the canonical positive cycle. We quantify numerically the creation of new fixed points, and provide families of block-parallel update schedules generating exponentially many fixed points on this elementary structure of interaction.","authors":["K\\'evin Perrot","Sylvain Sen\\'e","L\\'eah Tapin"],"url":"https://arxiv.org/abs/2505.15499"}
{"created":"2025-05-22","title":"Protoknowledge Shapes Behaviour of LLMs in Downstream Tasks: Memorization and Generalization with Knowledge Graphs","abstract":"We introduce the concept of protoknowledge to formalize and measure how sequences of tokens encoding Knowledge Graphs are internalized during pretraining and utilized at inference time by Large Language Models (LLMs). Indeed, LLMs have demonstrated the ability to memorize vast amounts of token sequences during pretraining, and a central open question is how they leverage this memorization as reusable knowledge through generalization. We then categorize protoknowledge into lexical, hierarchical, and topological forms, varying on the type of knowledge that needs to be activated. We measure protoknowledge through Knowledge Activation Tasks (KATs), analyzing its general properties such as semantic bias. We then investigate the impact of protoknowledge on Text-to-SPARQL performance by varying prompting strategies depending on input conditions. To this end, we adopt a novel analysis framework that assesses whether model predictions align with the successful activation of the relevant protoknowledge for each query. This methodology provides a practical tool to explore Semantic-Level Data Contamination and serves as an effective strategy for Closed-Pretraining models.","authors":["Federico Ranaldi","Andrea Zugarini","Leonardo Ranaldi","Fabio Massimo Zanzotto"],"url":"https://arxiv.org/abs/2505.15501"}
{"created":"2025-05-22","title":"Coloring Between the Lines: Personalization in the Null Space of Planning Constraints","abstract":"Generalist robots must personalize in-the-wild to meet the diverse needs and preferences of long-term users. How can we enable flexible personalization without sacrificing safety or competency? This paper proposes Coloring Between the Lines (CBTL), a method for personalization that exploits the null space of constraint satisfaction problems (CSPs) used in robot planning. CBTL begins with a CSP generator that ensures safe and competent behavior, then incrementally personalizes behavior by learning parameterized constraints from online interaction. By quantifying uncertainty and leveraging the compositionality of planning constraints, CBTL achieves sample-efficient adaptation without environment resets. We evaluate CBTL in (1) three diverse simulation environments; (2) a web-based user study; and (3) a real-robot assisted feeding system, finding that CBTL consistently achieves more effective personalization with fewer interactions than baselines. Our results demonstrate that CBTL provides a unified and practical approach for continual, flexible, active, and safe robot personalization. Website: https://emprise.cs.cornell.edu/cbtl/","authors":["Tom Silver","Rajat Kumar Jenamani","Ziang Liu","Ben Dodson","Tapomayukh Bhattacharjee"],"url":"https://arxiv.org/abs/2505.15503"}
{"created":"2025-05-22","title":"Beyond Linearity: Squeeze-and-Recalibrate Blocks for Few-Shot Whole Slide Image Classification","abstract":"Deep learning has advanced computational pathology but expert annotations remain scarce. Few-shot learning mitigates annotation burdens yet suffers from overfitting and discriminative feature mischaracterization. In addition, the current few-shot multiple instance learning (MIL) approaches leverage pretrained vision-language models to alleviate these issues, but at the cost of complex preprocessing and high computational cost. We propose a Squeeze-and-Recalibrate (SR) block, a drop-in replacement for linear layers in MIL models to address these challenges. The SR block comprises two core components: a pair of low-rank trainable matrices (squeeze pathway, SP) that reduces parameter count and imposes a bottleneck to prevent spurious feature learning, and a frozen random recalibration matrix that preserves geometric structure, diversifies feature directions, and redefines the optimization objective for the SP. We provide theoretical guarantees that the SR block can approximate any linear mapping to arbitrary precision, thereby ensuring that the performance of a standard MIL model serves as a lower bound for its SR-enhanced counterpart. Extensive experiments demonstrate that our SR-MIL models consistently outperform prior methods while requiring significantly fewer parameters and no architectural changes.","authors":["Conghao Xiong","Zhengrui Guo","Zhe Xu","Yifei Zhang","Raymond Kai-Yu Tong","Si Yong Yeo","Hao Chen","Joseph J. Y. Sung","Irwin King"],"url":"https://arxiv.org/abs/2505.15504"}
{"created":"2025-05-22","title":"Prompt Tuning Vision Language Models with Margin Regularizer for Few-Shot Learning under Distribution Shifts","abstract":"Recently, Vision-Language foundation models like CLIP and ALIGN, which are pre-trained on large-scale data have shown remarkable zero-shot generalization to diverse datasets with different classes and even domains. In this work, we take a step further and analyze whether these models can be adapted to target datasets having very different distributions and classes compared to what these models have been trained on, using only a few labeled examples from the target dataset. In such scenarios, finetuning large pretrained models is challenging due to problems of overfitting as well as loss of generalization, and has not been well explored in prior literature. Since, the pre-training data of such models are unavailable, it is difficult to comprehend the performance on various downstream datasets. First, we try to answer the question: Given a target dataset with a few labelled examples, can we estimate whether further fine-tuning can enhance the performance compared to zero-shot evaluation? by analyzing the common vision-language embedding space. Based on the analysis, we propose a novel prompt-tuning method, PromptMargin for adapting such large-scale VLMs directly on the few target samples. PromptMargin effectively tunes the text as well as visual prompts for this task, and has two main modules: 1) Firstly, we use a selective augmentation strategy to complement the few training samples in each task; 2) Additionally, to ensure robust training in the presence of unfamiliar class names, we increase the inter-class margin for improved class discrimination using a novel Multimodal Margin Regularizer. Extensive experiments and analysis across fifteen target benchmark datasets, with varying degrees of distribution shifts from natural images, shows the effectiveness of the proposed framework over the existing state-of-the-art approaches applied to this setting. github.com/debarshigit/PromptMargin.","authors":["Debarshi Brahma","Anuska Roy","Soma Biswas"],"url":"https://arxiv.org/abs/2505.15506"}
{"created":"2025-05-22","title":"Directional Non-Commutative Monoidal Structures for Compositional Embeddings in Machine Learning","abstract":"We introduce a new algebraic structure for multi-dimensional compositional embeddings, built on directional non-commutative monoidal operators. The core contribution of this work is this novel framework, which exhibits appealing theoretical properties (associativity along each dimension and an interchange law ensuring global consistency) while remaining compatible with modern machine learning architectures. Our construction defines a distinct composition operator circ_i for each axis i, ensuring associative combination along each axis without imposing global commutativity. Importantly, all axis-specific operators commute with one another, enforcing a global interchange law that enables consistent crossaxis compositions. This is, to our knowledge, the first approach that provides a common foundation that generalizes classical sequence-modeling paradigms (e.g., structured state-space models (SSMs) and transformer self-attention) to a unified multi-dimensional framework. For example, specific one-dimensional instances of our framework can recover the familiar affine transformation algebra, vanilla self-attention, and the SSM-style recurrence. The higher-dimensional generalizations naturally support recursive, structure-aware operations in embedding spaces. We outline several potential applications unlocked by this structure-including structured positional encodings in Transformers, directional image embeddings, and symbolic modeling of sequences or grids-indicating that it could inform future deep learning model designs. We formally establish the algebraic properties of our framework and discuss efficient implementations. Finally, as our focus is theoretical, we include no experiments here and defer empirical validation to future work, which we plan to undertake.","authors":["Mahesh Godavarti"],"url":"https://arxiv.org/abs/2505.15507"}
{"created":"2025-05-22","title":"Multilingual Test-Time Scaling via Initial Thought Transfer","abstract":"Test-time scaling has emerged as a widely adopted inference-time strategy for boosting reasoning performance. However, its effectiveness has been studied almost exclusively in English, leaving its behavior in other languages largely unexplored. We present the first systematic study of test-time scaling in multilingual settings, evaluating DeepSeek-R1-Distill-LLama-8B and DeepSeek-R1-Distill-Qwen-7B across both high- and low-resource Latin-script languages. Our findings reveal that the relative gains from test-time scaling vary significantly across languages. Additionally, models frequently switch to English mid-reasoning, even when operating under strictly monolingual prompts. We further show that low-resource languages not only produce initial reasoning thoughts that differ significantly from English but also have lower internal consistency across generations in their early reasoning. Building on our findings, we introduce MITT (Multilingual Initial Thought Transfer), an unsupervised and lightweight reasoning prefix-tuning approach that transfers high-resource reasoning prefixes to enhance test-time scaling across all languages, addressing inconsistencies in multilingual reasoning performance. MITT significantly boosts DeepSeek-R1-Distill-Qwen-7B's reasoning performance, especially for underrepresented languages.","authors":["Prasoon Bajpai","Tanmoy Chakraborty"],"url":"https://arxiv.org/abs/2505.15508"}
{"created":"2025-05-22","title":"Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought","abstract":"Large Vision-Language Models (LVLMs) have achieved significant success in multimodal tasks, with multimodal chain-of-thought (MCoT) further enhancing performance and interpretability. Recent MCoT methods fall into two categories: (i) Textual-MCoT (T-MCoT), which takes multimodal input and produces textual output; and (ii) Interleaved-MCoT (I-MCoT), which generates interleaved image-text outputs. Despite advances in both approaches, the mechanisms driving these improvements are not fully understood. To fill this gap, we first reveal that MCoT boosts LVLMs by incorporating visual thoughts, which convey image information to the reasoning process regardless of the MCoT format, depending only on clarity and conciseness of expression. Furthermore, to explore visual thoughts systematically, we define four distinct forms of visual thought expressions and analyze them comprehensively. Our findings demonstrate that these forms differ in clarity and conciseness, yielding varying levels of MCoT improvement. Additionally, we explore the internal nature of visual thoughts, finding that visual thoughts serve as intermediaries between the input image and reasoning to deeper transformer layers, enabling more advanced visual information transmission. We hope that the visual thoughts can inspire further breakthroughs for future MCoT research.","authors":["Zihui Cheng","Qiguang Chen","Xiao Xu","Jiaqi Wang","Weiyun Wang","Hao Fei","Yidong Wang","Alex Jinpeng Wang","Zhi Chen","Wanxiang Che","Libo Qin"],"url":"https://arxiv.org/abs/2505.15510"}
{"created":"2025-05-22","title":"NOMAD Projection","abstract":"The rapid adoption of generative AI has driven an explosion in the size of datasets consumed and produced by AI models. Traditional methods for unstructured data visualization, such as t-SNE and UMAP, have not kept up with the pace of dataset scaling. This presents a significant challenge for AI explainability, which relies on methods such as t-SNE and UMAP for exploratory data analysis. In this paper, we introduce Negative Or Mean Affinity Discrimination (NOMAD) Projection, the first method for unstructured data visualization via nonlinear dimensionality reduction that can run on multiple GPUs at train time. We provide theory that situates NOMAD Projection as an approximate upper bound on the InfoNC-t-SNE loss, and empirical results that demonstrate NOMAD Projection's superior performance and speed profile compared to existing state-of-the-art methods. We demonstrate the scalability of NOMAD Projection by computing the first complete data map of Multilingual Wikipedia.","authors":["Brandon Duderstadt","Zach Nussbaum","Laurens van der Maaten"],"url":"https://arxiv.org/abs/2505.15511"}
{"created":"2025-05-22","title":"AM-PPO: (Advantage) Alpha-Modulation with Proximal Policy Optimization","abstract":"Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm that heavily relies on accurate advantage estimates for stable and efficient training. However, raw advantage signals can exhibit significant variance, noise, and scale-related issues, impeding optimal learning performance. To address this challenge, we introduce Advantage Modulation PPO (AM-PPO), a novel enhancement of PPO that adaptively modulates advantage estimates using a dynamic, non-linear scaling mechanism. This adaptive modulation employs an alpha controller that dynamically adjusts the scaling factor based on evolving statistical properties of the advantage signals, such as their norm, variance, and a predefined target saturation level. By incorporating a tanh-based gating function driven by these adaptively scaled advantages, AM-PPO reshapes the advantage signals to stabilize gradient updates and improve the conditioning of the policy gradient landscape. Crucially, this modulation also influences value function training by providing consistent and adaptively conditioned learning targets. Empirical evaluations across standard continuous control benchmarks demonstrate that AM-PPO achieves superior reward trajectories, exhibits sustained learning progression, and significantly reduces the clipping required by adaptive optimizers. These findings underscore the potential of advantage modulation as a broadly applicable technique for enhancing reinforcement learning optimization.","authors":["Soham Sane"],"url":"https://arxiv.org/abs/2505.15514"}
{"created":"2025-05-22","title":"From learning to safety: A Direct Data-Driven Framework for Constrained Control","abstract":"Ensuring safety in the sense of constraint satisfaction for learning-based control is a critical challenge, especially in the model-free case. While safety filters address this challenge in the model-based setting by modifying unsafe control inputs, they typically rely on predictive models derived from physics or data. This reliance limits their applicability for advanced model-free learning control methods. To address this gap, we propose a new optimization-based control framework that determines safe control inputs directly from data. The benefit of the framework is that it can be updated through arbitrary model-free learning algorithms to pursue optimal performance. As a key component, the concept of direct data-driven safety filters (3DSF) is first proposed. The framework employs a novel safety certificate, called the state-action control barrier function (SACBF). We present three different schemes to learn the SACBF. Furthermore, based on input-to-state safety analysis, we present the error-to-state safety analysis framework, which provides formal guarantees on safety and recursive feasibility even in the presence of learning inaccuracies. The proposed control framework bridges the gap between model-free learning-based control and constrained control, by decoupling performance optimization from safety enforcement. Simulations on vehicle control illustrate the superior performance regarding constraint satisfaction and task achievement compared to model-based methods and reward shaping.","authors":["Kanghui He","Shengling Shi","Ton van den Boom","Bart De Schutter"],"url":"https://arxiv.org/abs/2505.15515"}
{"created":"2025-05-22","title":"Explainable embeddings with Distance Explainer","abstract":"While eXplainable AI (XAI) has advanced significantly, few methods address interpretability in embedded vector spaces where dimensions represent complex abstractions. We introduce Distance Explainer, a novel method for generating local, post-hoc explanations of embedded spaces in machine learning models. Our approach adapts saliency-based techniques from RISE to explain the distance between two embedded data points by assigning attribution values through selective masking and distance-ranked mask filtering. We evaluate Distance Explainer on cross-modal embeddings (image-image and image-caption pairs) using established XAI metrics including Faithfulness, Sensitivity/Robustness, and Randomization. Experiments with ImageNet and CLIP models demonstrate that our method effectively identifies features contributing to similarity or dissimilarity between embedded data points while maintaining high robustness and consistency. We also explore how parameter tuning, particularly mask quantity and selection strategy, affects explanation quality. This work addresses a critical gap in XAI research and enhances transparency and trustworthiness in deep learning applications utilizing embedded spaces.","authors":["Christiaan Meijer","E. G. Patrick Bos"],"url":"https://arxiv.org/abs/2505.15516"}
{"created":"2025-05-22","title":"Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets","abstract":"Vision-Language Models (VLMs) acquire real-world knowledge and general reasoning ability through Internet-scale image-text corpora. They can augment robotic systems with scene understanding and task planning, and assist visuomotor policies that are trained on robot trajectory data. We explore the reverse paradigm - using rich, real, multi-modal robot trajectory data to enhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual Question Answering (VQA) dataset generation framework for VLMs. Given a human tele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual and non-descriptive sensory modalities, such as end-effector pose, gripper aperture, and force sensing. Based on these modalities, it segments the robot trajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses scene and interaction understanding to identify 3D properties of the robot, task goal, and the target object. The properties are used to generate representative VQA queries - images with textural multiple-choice questions - based on spatial, goal-conditioned, and interaction reasoning question templates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710 questions covering 463 distinct scenes and 3,396 robotic manipulation tasks from 176k real robot trajectories. Results suggest that Robo2VLM-1 can benchmark and improve VLM capabilities in spatial and interaction reasoning.","authors":["Kaiyuan Chen","Shuangyu Xie","Zehan Ma","Ken Goldberg"],"url":"https://arxiv.org/abs/2505.15517"}
{"created":"2025-05-22","title":"Detection of Underwater Multi-Targets Based on Self-Supervised Learning and Deformable Path Aggregation Feature Pyramid Network","abstract":"To overcome the constraints of the underwater environment and improve the accuracy and robustness of underwater target detection models, this paper develops a specialized dataset for underwater target detection and proposes an efficient algorithm for underwater multi-target detection. A self-supervised learning based on the SimSiam structure is employed for the pre-training of underwater target detection network. To address the problems of low detection accuracy caused by low contrast, mutual occlusion and dense distribution of underwater targets in underwater object detection, a detection model suitable for underwater target detection is proposed by introducing deformable convolution and dilated convolution. The proposed detection model can obtain more effective information by increasing the receptive field. In addition, the regression loss function EIoU is introduced, which improves model performance by separately calculating the width and height losses of the predicted box. Experiment results show that the accuracy of the underwater target detection has been improved by the proposed detector.","authors":["Chang Liu"],"url":"https://arxiv.org/abs/2505.15518"}
{"created":"2025-05-22","title":"Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs","abstract":"Bias in Large Language Models (LLMs) significantly undermines their reliability and fairness. We focus on a common form of bias: when two reference concepts in the model's concept space, such as sentiment polarities (e.g., \"positive\" and \"negative\"), are asymmetrically correlated with a third, target concept, such as a reviewing aspect, the model exhibits unintended bias. For instance, the understanding of \"food\" should not skew toward any particular sentiment. Existing bias evaluation methods assess behavioral differences of LLMs by constructing labeled data for different social groups and measuring model responses across them, a process that requires substantial human effort and captures only a limited set of social concepts. To overcome these limitations, we propose BiasLens, a test-set-free bias analysis framework based on the structure of the model's vector space. BiasLens combines Concept Activation Vectors (CAVs) with Sparse Autoencoders (SAEs) to extract interpretable concept representations, and quantifies bias by measuring the variation in representational similarity between the target concept and each of the reference concepts. Even without labeled data, BiasLens shows strong agreement with traditional bias evaluation metrics (Spearman correlation r > 0.85). Moreover, BiasLens reveals forms of bias that are difficult to detect using existing methods. For example, in simulated clinical scenarios, a patient's insurance status can cause the LLM to produce biased diagnostic assessments. Overall, BiasLens offers a scalable, interpretable, and efficient paradigm for bias discovery, paving the way for improving fairness and transparency in LLMs.","authors":["Lang Gao","Kaiyang Wan","Wei Liu","Chenxi Wang","Zirui Song","Zixiang Xu","Yanbo Wang","Veselin Stoyanov","Xiuying Chen"],"url":"https://arxiv.org/abs/2505.15524"}
{"created":"2025-05-22","title":"Continuous-time iterative linear-quadratic regulator","abstract":"We present a continuous-time equivalent to the well-known iterative linear-quadratic algorithm including an implementation of a backtracking line-search policy and a novel regularization approach based on the necessary conditions in the Riccati pass of the linear-quadratic regulator. This allows the algorithm to effectively solve trajectory optimization problems with non-convex cost functions, which is demonstrated on the cart-pole swing-up problem. The algorithm compatibility with state-of-the-art suites of numerical integration solvers allows for the use of high-order adaptive-step methods. Their use results in a variable number of time steps both between passes of the algorithm and across iterations, maintaining a balance between the number of function evaluations and the discretization error.","authors":["Juraj Lieskovsk\\'y","Jaroslav Bu\\v{s}ek","Tom\\'a\\v{s} Vyhl\\'idal"],"url":"https://arxiv.org/abs/2505.15525"}
{"created":"2025-05-22","title":"PlantDreamer: Achieving Realistic 3D Plant Models with Diffusion-Guided Gaussian Splatting","abstract":"Recent years have seen substantial improvements in the ability to generate synthetic 3D objects using AI. However, generating complex 3D objects, such as plants, remains a considerable challenge. Current generative 3D models struggle with plant generation compared to general objects, limiting their usability in plant analysis tools, which require fine detail and accurate geometry. We introduce PlantDreamer, a novel approach to 3D synthetic plant generation, which can achieve greater levels of realism for complex plant geometry and textures than available text-to-3D models. To achieve this, our new generation pipeline leverages a depth ControlNet, fine-tuned Low-Rank Adaptation and an adaptable Gaussian culling algorithm, which directly improve textural realism and geometric integrity of generated 3D plant models. Additionally, PlantDreamer enables both purely synthetic plant generation, by leveraging L-System-generated meshes, and the enhancement of real-world plant point clouds by converting them into 3D Gaussian Splats. We evaluate our approach by comparing its outputs with state-of-the-art text-to-3D models, demonstrating that PlantDreamer outperforms existing methods in producing high-fidelity synthetic plants. Our results indicate that our approach not only advances synthetic plant generation, but also facilitates the upgrading of legacy point cloud datasets, making it a valuable tool for 3D phenotyping applications.","authors":["Zane K J Hartley","Lewis A G Stuart","Andrew P French","Michael P Pound"],"url":"https://arxiv.org/abs/2505.15528"}
{"created":"2025-05-22","title":"Clapper: Compact Learning and Video Representation in VLMs","abstract":"Current vision-language models (VLMs) have demonstrated remarkable capabilities across diverse video understanding applications. Designing VLMs for video inputs requires effectively modeling the temporal dimension (i.e. capturing dependencies across frames) and balancing the processing of short and long videos. Specifically, short videos demand preservation of fine-grained details, whereas long videos require strategic compression of visual information to handle extensive temporal contexts efficiently. However, our empirical analysis reveals a critical limitation: most existing VLMs suffer severe performance degradation in long video understanding tasks when compressing visual tokens below a quarter of their original visual tokens. To enable more effective modeling of both short and long video inputs, we propose Clapper, a method that utilizes a slow-fast strategy for video representation and introduces a novel module named TimePerceiver for efficient temporal-spatial encoding within existing VLM backbones. By using our method, we achieves 13x compression of visual tokens per frame (averaging 61 tokens/frame) without compromising QA accuracy. In our experiments, Clapper achieves 62.0% on VideoMME, 69.8% on MLVU, and 67.4% on TempCompass, all with fewer than 6,000 visual tokens per video. The code will be publicly available on the homepage.","authors":["Lingyu Kong","Hongzhi Zhang","Jingyuan Zhang","Jianzhao Huang","Kunze Li","Qi Wang","Fuzheng Zhang"],"url":"https://arxiv.org/abs/2505.15529"}
{"created":"2025-05-22","title":"Modeling and Optimizing Latency for Delayed Hit Caching with Stochastic Miss Latency","abstract":"Caching is crucial for system performance, but the delayed hit phenomenon, where requests queue during lengthy fetches after a cache miss, significantly degrades user-perceived latency in modern high-throughput systems. While prior works address delayed hits by estimating aggregate delay, they universally assume deterministic fetch latencies. This paper tackles the more realistic, yet unexplored, scenario where fetch latencies are stochastic. We present, to our knowledge, the first theoretical analysis of delayed hits under this condition, deriving analytical expressions for both the mean and variance of the aggregate delay assuming exponentially distributed fetch latency. Leveraging these insights, we develop a novel variance-aware ranking function tailored for this stochastic setting to guide cache eviction decisions more effectively. The simulations on synthetic and real-world datasets demonstrate that our proposed algorithm significantly reduces overall latency compared to state-of-the-art delayed-hit strategies, achieving a $3\\%-30\\%$ reduction on synthetic datasets and approximately $1\\%-7\\%$ reduction on real-world traces.","authors":["Bowen Jiang","Chaofan Ma"],"url":"https://arxiv.org/abs/2505.15531"}
{"created":"2025-05-22","title":"Convolutional Long Short-Term Memory Neural Networks Based Numerical Simulation of Flow Field","abstract":"Computational Fluid Dynamics (CFD) is the main approach to analyzing flow field. However, the convergence and accuracy depend largely on mathematical models of flow, numerical methods, and time consumption. Deep learning-based analysis of flow filed provides an alternative. For the task of flow field prediction, an improved Convolutional Long Short-Term Memory (Con-vLSTM) Neural Network is proposed as the baseline network in consideration of the temporal and spatial characteristics of flow field. Combining dynamic mesh technology and User-Defined Function (UDF), numerical simulations of flow around a circular cylinder were conducted. Flow field snapshots were used to sample data from the cylinder's wake region at different time instants, constructing a flow field dataset with sufficient volume and rich flow state var-iations. Residual networks and attention mechanisms are combined with the standard ConvLSTM model. Compared with the standard ConvLSTM model, the results demonstrate that the improved ConvLSTM model can extract more temporal and spatial features while having fewer parameters and shorter train-ing time.","authors":["Chang Liu"],"url":"https://arxiv.org/abs/2505.15533"}
{"created":"2025-05-22","title":"Matrix-Free Methods for Finite-Strain Elasticity: Automatic Code Generation with No Performance Overhead","abstract":"This study explores matrix-free tangent evaluations in finite-strain elasticity with the use of automatically-generated code for the quadrature-point level calculations. The code generation is done via automatic differentiation (AD) with AceGen. We compare hand-written and AD-generated codes under two computing strategies: on-the-fly evaluation and caching intermediate results. The comparison reveals that the AD-generated code achieves superior performance in matrix-free computations.","authors":["Micha{\\l} Wichrowski","Mohsen Rezaee-Hajidehi","Jo\\v{z}e Korelc","Martin Kronbichler","Stanis{\\l}aw Stupkiewicz"],"url":"https://arxiv.org/abs/2505.15535"}
{"created":"2025-05-22","title":"SpanTrain: Highly Efficient Cross-domain Model Distributed Training System under Heterogeneous GPUs and Networks in CEE Environment","abstract":"Most existing training systems focus on a single region. In contrast, we envision that cross-region training offers more flexible GPU resource allocation and yields significant potential. However, the hierarchical cluster topology and unstable networks in the cloud-edge-end (CEE) environment, a typical cross-region scenario, pose substantial challenges to building an efficient and autonomous model training system. We propose SpanTrain, a geo-distributed model training system tailored for heterogeneous GPUs and networks in CEE environments. SpanTrain adopts a communication-centric design philosophy to tackle challenges arising from slow and unstable inter-region networks. It begins with a heterogeneous device profiler that identifies and groups devices based on both network and compute characteristics. Leveraging device groups, SpanTrain implements compact, zero-bubble pipeline parallelism, automatically deriving optimal parallel strategies. To further adapt to runtime variability, SpanTrain integrates a dynamic environment adapter that reacts to network fluctuations. Extensive evaluations demonstrate that SpanTrain achieves 1.3-2.8x higher training throughput compared to widely used and SOTA training systems.","authors":["Jinquan Wang","Xiaojian Liao","Xuzhao Liu","Jiashun Suo","Zhisheng Huo","Chenhao Zhang","Xiangrong Xu","Runnan Shen","Xilong Xie","Limin Xiao"],"url":"https://arxiv.org/abs/2505.15536"}
{"created":"2025-05-22","title":"Machine learning-based parameter optimization for M\\\"untz spectral methods","abstract":"Spectral methods employing non-standard polynomial bases, such as M\\\"untz polynomials, have proven effective for accurately solving problems with solutions exhibiting low regularity, notably including sub-diffusion equations. However, due to the absence of theoretical guidance, the key parameters controlling the exponents of M\\\"untz polynomials are usually determined empirically through extensive numerical experiments, leading to a time-consuming tuning process. To address this issue, we propose a novel machine learning-based optimization framework for the M\\\"untz spectral method. As an illustrative example, we optimize the parameter selection for solving time-fractional partial differential equations (PDEs). Specifically, an artificial neural network (ANN) is employed to predict optimal parameter values based solely on the time-fractional order as input. The ANN is trained by minimizing solution errors on a one-dimensional time-fractional convection-diffusion equation featuring manufactured exact solutions that manifest singularities of varying intensity, covering a comprehensive range of sampled fractional orders. Numerical results for time-fractional PDEs in both one and two dimensions demonstrate that the ANN-based parameter prediction significantly improves the accuracy of the M\\\"untz spectral method. Moreover, the trained ANN generalizes effectively from one-dimensional to two-dimensional cases, highlighting its robustness across spatial dimensions. Additionally, we verify that the ANN substantially outperforms traditional function approximators, such as spline interpolation, in both prediction accuracy and training efficiency. The proposed optimization framework can be extended beyond fractional PDEs, offering a versatile and powerful approach for spectral methods applied to various low-regularity problems.","authors":["Wei Zeng","Chuanju Xu","Yiming Lu","Qian Wang"],"url":"https://arxiv.org/abs/2505.15538"}
{"created":"2025-05-22","title":"Hardware-Level QoS Enforcement Features: Technologies, Use Cases, and Research Challenges","abstract":"Recent advancements in commodity server processors have enabled dynamic hardware-based quality-of-service (QoS) enforcement. These features have gathered increasing interest in research communities due to their versatility and wide range of applications. Thus, there exists a need to understand how scholars leverage hardware QoS enforcement in research, understand strengths and shortcomings, and identify gaps in current state-of-the-art research. This paper observes relevant publications, presents a novel taxonomy, discusses the approaches used, and identifies trends. Furthermore, an opportunity is recognized for QoS enforcement utilization in service-based cloud computing environments, and open challenges are presented.","authors":["Oliver Larsson (Ume{\\aa} University)","Thijs Metsch (Intel Corporation)","Cristian Klein (Ume{\\aa} University)","Erik Elmroth (Ume{\\aa} University)"],"url":"https://arxiv.org/abs/2505.15542"}
{"created":"2025-05-22","title":"A Temporal Difference Method for Stochastic Continuous Dynamics","abstract":"For continuous systems modeled by dynamical equations such as ODEs and SDEs, Bellman's principle of optimality takes the form of the Hamilton-Jacobi-Bellman (HJB) equation, which provides the theoretical target of reinforcement learning (RL). Although recent advances in RL successfully leverage this formulation, the existing methods typically assume the underlying dynamics are known a priori because they need explicit access to the coefficient functions of dynamical equations to update the value function following the HJB equation. We address this inherent limitation of HJB-based RL; we propose a model-free approach still targeting the HJB equation and propose the corresponding temporal difference method. We demonstrate its potential advantages over transition kernel-based formulations, both qualitatively and empirically. The proposed formulation paves the way toward bridging stochastic optimal control and model-free reinforcement learning.","authors":["Haruki Settai","Naoya Takeishi","Takehisa Yairi"],"url":"https://arxiv.org/abs/2505.15544"}
{"created":"2025-05-22","title":"seg_3D_by_PC2D: Multi-View Projection for Domain Generalization and Adaptation in 3D Semantic Segmentation","abstract":"3D semantic segmentation plays a pivotal role in autonomous driving and road infrastructure analysis, yet state-of-the-art 3D models are prone to severe domain shift when deployed across different datasets. We propose a novel multi-view projection framework that excels in both domain generalization (DG) and unsupervised domain adaptation (UDA). Our approach first aligns Lidar scans into coherent 3D scenes and renders them from multiple virtual camera poses to create a large-scale synthetic 2D dataset (PC2D). We then use it to train a 2D segmentation model in-domain. During inference, the model processes hundreds of views per scene; the resulting logits are back-projected to 3D with an occlusion-aware voting scheme to generate final point-wise labels. Our framework is modular and enables extensive exploration of key design parameters, such as view generation optimization (VGO), visualization modality optimization (MODO), and 2D model choice. We evaluate on the nuScenes and SemanticKITTI datasets under both the DG and UDA settings. We achieve state-of-the-art results in UDA and close to state-of-the-art in DG, with particularly large gains on large, static classes. Our code and dataset generation tools will be publicly available at https://github.com/andrewcaunes/ia4markings","authors":["Andrew Caunes","Thierry Chateau","Vincent Fremont"],"url":"https://arxiv.org/abs/2505.15545"}
{"created":"2025-05-22","title":"Decreasing Utilization of Systems with Multi-Rate Cause-Effect Chains While Reducing End-to-End Latencies","abstract":"The Logical Execution Time (LET) model has deterministic properties which dramatically reduce the complexity of analyzing temporal requirements of multi-rate cause-effect chains. The configuration (length and position) of task's communication intervals directly define which task instances propagate data through the chain and affect end-to-end latencies. Since not all task instances propagate data through the chain, the execution of these instances wastes processing resources. By manipulating the configuration of communication intervals, it is possible to control which task instances are relevant for data propagation and end-to-end latencies. However, since tasks can belong to more than one cause-effect chain, the problem of configuring communication intervals becomes non-trivial given the large number of possible configurations. In this paper, we present a method to decrease the waste of processing resources while reducing end-to-end latencies. We use a search algorithm to analyze different communication interval configurations and find the combination that best decrease system utilization while reducing end-to-end latencies. By controlling data propagation by means of precedence constraints, our method modifies communication intervals and controls which task instances affect end-to-end latencies. Despite the sporadic release time of some task instances during the analysis, our method transforms those instances into periodic tasks. We evaluate our work using synthetic task sets and the automotive benchmark proposed by BOSCH for the WATERS industrial challenge.","authors":["Luiz Maia","Gerhard Fohler"],"url":"https://arxiv.org/abs/2505.15546"}
{"created":"2025-05-22","title":"Oversmoothing, \"Oversquashing\", Heterophily, Long-Range, and more: Demystifying Common Beliefs in Graph Machine Learning","abstract":"After a renaissance phase in which researchers revisited the message-passing paradigm through the lens of deep learning, the graph machine learning community shifted its attention towards a deeper and practical understanding of message-passing's benefits and limitations. In this position paper, we notice how the fast pace of progress around the topics of oversmoothing and oversquashing, the homophily-heterophily dichotomy, and long-range tasks, came with the consolidation of commonly accepted beliefs and assumptions that are not always true nor easy to distinguish from each other. We argue that this has led to ambiguities around the investigated problems, preventing researchers from focusing on and addressing precise research questions while causing a good amount of misunderstandings. Our contribution wants to make such common beliefs explicit and encourage critical thinking around these topics, supported by simple but noteworthy counterexamples. The hope is to clarify the distinction between the different issues and promote separate but intertwined research directions to address them.","authors":["Adrian Arnaiz-Rodriguez","Federico Errica"],"url":"https://arxiv.org/abs/2505.15547"}
{"created":"2025-05-22","title":"Short-Range Dependency Effects on Transformer Instability and a Decomposed Attention Solution","abstract":"Transformer language models have driven significant progress across various fields, including natural language processing and computer vision. A central component of these models is the self-attention (SA) mechanism, which learns rich vector representations of tokens by modeling their relationships with others in a sequence. However, despite extensive research, transformers continue to suffer from training instability -- often manifesting as spikes or divergence in the training loss during a run.","authors":["Suvadeep Hajra"],"url":"https://arxiv.org/abs/2505.15548"}
{"created":"2025-05-22","title":"Social Bias in Popular Question-Answering Benchmarks","abstract":"Question-answering (QA) and reading comprehension (RC) benchmarks are essential for assessing the capabilities of large language models (LLMs) in retrieving and reproducing knowledge. However, we demonstrate that popular QA and RC benchmarks are biased and do not cover questions about different demographics or regions in a representative way, potentially due to a lack of diversity of those involved in their creation. We perform a qualitative content analysis of 30 benchmark papers and a quantitative analysis of 20 respective benchmark datasets to learn (1) who is involved in the benchmark creation, (2) how social bias is addressed or prevented, and (3) whether the demographics of the creators and annotators correspond to particular biases in the content. Most analyzed benchmark papers provided insufficient information regarding the stakeholders involved in benchmark creation, particularly the annotators. Notably, just one of the benchmark papers explicitly reported measures taken to address social representation issues. Moreover, the data analysis revealed gender, religion, and geographic biases across a wide range of encyclopedic, commonsense, and scholarly benchmarks. More transparent and bias-aware QA and RC benchmark creation practices are needed to facilitate better scrutiny and incentivize the development of fairer LLMs.","authors":["Angelie Kraft","Judith Simon","Sonja Schimmler"],"url":"https://arxiv.org/abs/2505.15553"}
{"created":"2025-05-22","title":"DayDreamer at CQs-Gen 2025: Generating Critical Questions through Argument Scheme Completion","abstract":"Critical questions are essential resources to provoke critical thinking when encountering an argumentative text. We present our system for the Critical Questions Generation (CQs-Gen) Shared Task at ArgMining 2025. Our approach leverages large language models (LLMs) with chain-of-thought prompting to generate critical questions guided by Walton's argumentation schemes. For each input intervention, we conversationally prompt LLMs to instantiate the corresponding argument scheme template to first obtain structured arguments, and then generate relevant critical questions. Following this, we rank all the available critical questions by prompting LLMs to select the top 3 most helpful questions based on the original intervention text. This combination of structured argumentation theory and step-by-step reasoning enables the generation of contextually relevant and diverse critical questions. Our pipeline achieves competitive performance in the final test set, showing its potential to foster critical thinking given argumentative text and detect missing or uninformed claims. Code available at \\href{https://git.ecdf.ed.ac.uk/s2236454/DayDreamer-CQs-Gen}{DayDreamer}.","authors":["Wendi Zhou","Ameer Saadat-Yazdi","Nadin K\\\"okciyan"],"url":"https://arxiv.org/abs/2505.15554"}
{"created":"2025-05-22","title":"A Survey on Multilingual Mental Disorders Detection from Social Media Data","abstract":"The increasing prevalence of mental health disorders globally highlights the urgent need for effective digital screening methods that can be used in multilingual contexts. Most existing studies, however, focus on English data, overlooking critical mental health signals that may be present in non-English texts. To address this important gap, we present the first survey on the detection of mental health disorders using multilingual social media data. We investigate the cultural nuances that influence online language patterns and self-disclosure behaviors, and how these factors can impact the performance of NLP tools. Additionally, we provide a comprehensive list of multilingual data collections that can be used for developing NLP models for mental health screening. Our findings can inform the design of effective multilingual mental health screening tools that can meet the needs of diverse populations, ultimately improving mental health outcomes on a global scale.","authors":["Ana-Maria Bucur","Marcos Zampieri","Tharindu Ranasinghe","Fabio Crestani"],"url":"https://arxiv.org/abs/2505.15556"}
{"created":"2025-05-22","title":"Robo-DM: Data Management For Large Robot Datasets","abstract":"Recent results suggest that very large datasets of teleoperated robot demonstrations can be used to train transformer-based models that have the potential to generalize to new scenes, robots, and tasks. However, curating, distributing, and loading large datasets of robot trajectories, which typically consist of video, textual, and numerical modalities - including streams from multiple cameras - remains challenging. We propose Robo-DM, an efficient open-source cloud-based data management toolkit for collecting, sharing, and learning with robot data. With Robo-DM, robot datasets are stored in a self-contained format with Extensible Binary Meta Language (EBML). Robo-DM can significantly reduce the size of robot trajectory data, transfer costs, and data load time during training. Compared to the RLDS format used in OXE datasets, Robo-DM's compression saves space by up to 70x (lossy) and 3.5x (lossless). Robo-DM also accelerates data retrieval by load-balancing video decoding with memory-mapped decoding caches. Compared to LeRobot, a framework that also uses lossy video compression, Robo-DM is up to 50x faster when decoding sequentially. We physically evaluate a model trained by Robo-DM with lossy compression, a pick-and-place task, and In-Context Robot Transformer. Robo-DM uses 75x compression of the original dataset and does not suffer reduction in downstream task accuracy.","authors":["Kaiyuan Chen","Letian Fu","David Huang","Yanxiang Zhang","Lawrence Yunliang Chen","Huang Huang","Kush Hari","Ashwin Balakrishna","Ted Xiao","Pannag R Sanketi","John Kubiatowicz","Ken Goldberg"],"url":"https://arxiv.org/abs/2505.15558"}
{"created":"2025-05-22","title":"Moonbeam: A MIDI Foundation Model Using Both Absolute and Relative Music Attributes","abstract":"Moonbeam is a transformer-based foundation model for symbolic music, pretrained on a large and diverse collection of MIDI data totaling 81.6K hours of music and 18 billion tokens. Moonbeam incorporates music-domain inductive biases by capturing both absolute and relative musical attributes through the introduction of a novel domain-knowledge-inspired tokenization method and Multidimensional Relative Attention (MRA), which captures relative music information without additional trainable parameters. Leveraging the pretrained Moonbeam, we propose 2 finetuning architectures with full anticipatory capabilities, targeting 2 categories of downstream tasks: symbolic music understanding and conditional music generation (including music infilling). Our model outperforms other large-scale pretrained music models in most cases in terms of accuracy and F1 score across 3 downstream music classification tasks on 4 datasets. Moreover, our finetuned conditional music generation model outperforms a strong transformer baseline with a REMI-like tokenizer. We open-source the code, pretrained model, and generated samples on Github.","authors":["Zixun Guo","Simon Dixon"],"url":"https://arxiv.org/abs/2505.15559"}
{"created":"2025-05-22","title":"Impact of Data Sparsity on Machine Learning for Fault Detection in Power System Protection","abstract":"Germany's transition to a renewable energy-based power system is reshaping grid operations, requiring advanced monitoring and control to manage decentralized generation. Machine learning (ML) has emerged as a powerful tool for power system protection, particularly for fault detection (FD) and fault line identification (FLI) in transmission grids. However, ML model reliability depends on data quality and availability. Data sparsity resulting from sensor failures, communication disruptions, or reduced sampling rates poses a challenge to ML-based FD and FLI. Yet, its impact has not been systematically validated prior to this work. In response, we propose a framework to assess the impact of data sparsity on ML-based FD and FLI performance. We simulate realistic data sparsity scenarios, evaluate their impact, derive quantitative insights, and demonstrate the effectiveness of this evaluation strategy by applying it to an existing ML-based framework. Results show the ML model remains robust for FD, maintaining an F1-score of 0.999 $\\pm$ 0.000 even after a 50x data reduction. In contrast, FLI is more sensitive, with performance decreasing by 55.61% for missing voltage measurements and 9.73% due to communication failures at critical network points. These findings offer actionable insights for optimizing ML models for real-world grid protection. This enables more efficient FD and supports targeted improvements in FLI.","authors":["Julian Oelhaf","Georg Kordowich","Changhun Kim","Paula Andrea Perez-Toro","Andreas Maier","Johann Jager","Siming Bayer"],"url":"https://arxiv.org/abs/2505.15560"}
{"created":"2025-05-22","title":"Do RAG Systems Suffer From Positional Bias?","abstract":"Retrieval Augmented Generation enhances LLM accuracy by adding passages retrieved from an external corpus to the LLM prompt. This paper investigates how positional bias - the tendency of LLMs to weight information differently based on its position in the prompt - affects not only the LLM's capability to capitalize on relevant passages, but also its susceptibility to distracting passages. Through extensive experiments on three benchmarks, we show how state-of-the-art retrieval pipelines, while attempting to retrieve relevant passages, systematically bring highly distracting ones to the top ranks, with over 60% of queries containing at least one highly distracting passage among the top-10 retrieved passages. As a result, the impact of the LLM positional bias, which in controlled settings is often reported as very prominent by related works, is actually marginal in real scenarios since both relevant and distracting passages are, in turn, penalized. Indeed, our findings reveal that sophisticated strategies that attempt to rearrange the passages based on LLM positional preferences do not perform better than random shuffling.","authors":["Florin Cuconasu","Simone Filice","Guy Horowitz","Yoelle Maarek","Fabrizio Silvestri"],"url":"https://arxiv.org/abs/2505.15561"}
{"created":"2025-05-22","title":"Semantic-based Unsupervised Framing Analysis (SUFA): A Novel Approach for Computational Framing Analysis","abstract":"This research presents a novel approach to computational framing analysis, called Semantic Relations-based Unsupervised Framing Analysis (SUFA). SUFA leverages semantic relations and dependency parsing algorithms to identify and assess entity-centric emphasis frames in news media reports. This innovative method is derived from two studies -- qualitative and computational -- using a dataset related to gun violence, demonstrating its potential for analyzing entity-centric emphasis frames. This article discusses SUFA's strengths, limitations, and application procedures. Overall, the SUFA approach offers a significant methodological advancement in computational framing analysis, with its broad applicability across both the social sciences and computational domains.","authors":["Mohammad Ali","Naeemul Hassan"],"url":"https://arxiv.org/abs/2505.15563"}
{"created":"2025-05-22","title":"TinyDrive: Multiscale Visual Question Answering with Selective Token Routing for Autonomous Driving","abstract":"Vision Language Models (VLMs) employed for visual question-answering (VQA) in autonomous driving often require substantial computational resources that pose a challenge for their deployment in resource-constrained vehicles. To address this challenge, we introduce TinyDrive, a lightweight yet effective VLM for multi-view VQA in driving scenarios. Our model comprises two key components including a multiscale vision encoder and a dual-level prioritization mechanism for tokens and sequences. The multiscale encoder facilitates the processing of multi-view images at diverse resolutions through scale injection and cross-scale gating to generate enhanced visual representations. At the token level, we design a token routing mechanism that dynamically selects and process the most informative tokens based on learned importance scores. At the sequence level, we propose integrating normalized loss, uncertainty estimates, and a diversity metric to formulate sequence scores that rank and preserve samples within a sequence priority buffer. Samples with higher scores are more frequently selected for training. TinyDrive is first evaluated on our custom-curated VQA dataset, and it is subsequently tested on the public DriveLM benchmark, where it achieves state-of-the-art language understanding performance. Notably, it achieves relative improvements of 11.1% and 35.4% in BLEU-4 and METEOR scores, respectively, despite having a significantly smaller parameter count.","authors":["Hossein Hassani","Soodeh Nikan","Abdallah Shami"],"url":"https://arxiv.org/abs/2505.15564"}
{"created":"2025-05-22","title":"Model Checking the Security of the Lightning Network","abstract":"Payment channel networks are an approach to improve the scalability of blockchain-based cryptocurrencies. The Lightning Network is a payment channel network built for Bitcoin that is already used in practice. Because the Lightning Network is used for transfer of financial value, its security in the presence of adversarial participants should be verified. The Lightning protocol's complexity makes it hard to assess whether the protocol is secure. To enable computer-aided security verification of Lightning, we formalize the protocol in TLA+ and formally specify the security property that honest users are guaranteed to retrieve their correct balance. While model checking provides a fully automated verification of the security property, the state space of the protocol's specification is so large that model checking becomes unfeasible. We make model checking the Lightning Network possible using two refinement steps that we verify using proofs. In a first step, we prove that the model of time used in the protocol can be abstracted using ideas from the research of timed automata. In a second step, we prove that it suffices to model check the protocol for single payment channels and the protocol for multi-hop payments separately. These refinements reduce the state space sufficiently to allow for model checking Lightning with models with payments over up to four hops and two concurrent payments. These results indicate that the current specification of Lightning is secure.","authors":["Matthias Grundmann","Hannes Hartenstein"],"url":"https://arxiv.org/abs/2505.15568"}
{"created":"2025-05-22","title":"Refining Neural Activation Patterns for Layer-Level Concept Discovery in Neural Network-Based Receivers","abstract":"Concept discovery in neural networks often targets individual neurons or human-interpretable features, overlooking distributed layer-wide patterns. We study the Neural Activation Pattern (NAP) methodology, which clusters full-layer activation distributions to identify such layer-level concepts. Applied to visual object recognition and radio receiver models, we propose improved normalization, distribution estimation, distance metrics, and varied cluster selection. In the radio receiver model, distinct concepts did not emerge; instead, a continuous activation manifold shaped by Signal-to-Noise Ratio (SNR) was observed -- highlighting SNR as a key learned factor, consistent with classical receiver behavior and supporting physical plausibility. Our enhancements to NAP improved in-distribution vs. out-of-distribution separation, suggesting better generalization and indirectly validating clustering quality. These results underscore the importance of clustering design and activation manifolds in interpreting and troubleshooting neural network behavior.","authors":["Marko Tuononen","Duy Vu","Dani Korpi","Vesa Starck","Ville Hautam\\\"aki"],"url":"https://arxiv.org/abs/2505.15570"}
{"created":"2025-05-22","title":"Bridging the Domain Gap in Equation Distillation with Reinforcement Feedback","abstract":"The data-to-equation (Data2Eqn) task aims to discover interpretable mathematical equations that map observed values to labels, offering physical insights and broad applicability across academic and industrial domains. Genetic programming and traditional deep learning-based approaches suffer from search inefficiency and poor generalization on small task-specific datasets. Foundation models showed promise in this area, but existing approaches suffer from: 1) They are pretrained on general-purpose data distributions, making them less effective for domain-specific tasks; and 2) their training objectives focus on token-level alignment, overlooking mathematical semantics, which can lead to inaccurate equations. To address these issues, we aim to enhance the domain adaptability of foundation models for Data2Eqn tasks. In this work, we propose a reinforcement learning-based finetuning framework that directly optimizes the generation policy of a pretrained model through reward signals derived from downstream numerical fitness. Our method allows the model to adapt to specific and complex data distributions and generate mathematically meaningful equations. Extensive experiments demonstrate that our approach improves both the accuracy and robustness of equation generation under complex distributions.","authors":["Wangyang Ying","Haoyue Bai","Nanxu Gong","Xinyuan Wang","Sixun Dong","Haifeng Chen","Yanjie Fu"],"url":"https://arxiv.org/abs/2505.15572"}
{"created":"2025-05-22","title":"Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models","abstract":"Vision-Language Models (VLMs) are essential for multimodal tasks, especially compositional reasoning (CR) tasks, which require distinguishing fine-grained semantic differences between visual and textual embeddings. However, existing methods primarily fine-tune the model by generating text-based hard negative samples, neglecting the importance of image-based negative samples, which results in insufficient training of the visual encoder and ultimately impacts the overall performance of the model. Moreover, negative samples are typically treated uniformly, without considering their difficulty levels, and the alignment of positive samples is insufficient, which leads to challenges in aligning difficult sample pairs. To address these issues, we propose Adaptive Hard Negative Perturbation Learning (AHNPL). AHNPL translates text-based hard negatives into the visual domain to generate semantically disturbed image-based negatives for training the model, thereby enhancing its overall performance. AHNPL also introduces a contrastive learning approach using a multimodal hard negative loss to improve the model's discrimination of hard negatives within each modality and a dynamic margin loss that adjusts the contrastive margin according to sample difficulty to enhance the distinction of challenging sample pairs. Experiments on three public datasets demonstrate that our method effectively boosts VLMs' performance on complex CR tasks. The source code is available at https://github.com/nynu-BDAI/AHNPL.","authors":["Xin Huang","Ruibin Li","Tong Jia","Wei Zheng","Ya Wang"],"url":"https://arxiv.org/abs/2505.15576"}
{"created":"2025-05-22","title":"Federated Learning with Unlabeled Clients: Personalization Can Happen in Low Dimensions","abstract":"Personalized federated learning has emerged as a popular approach to training on devices holding statistically heterogeneous data, known as clients. However, most existing approaches require a client to have labeled data for training or finetuning in order to obtain their own personalized model. In this paper we address this by proposing FLowDUP, a novel method that is able to generate a personalized model using only a forward pass with unlabeled data. The generated model parameters reside in a low-dimensional subspace, enabling efficient communication and computation. FLowDUP's learning objective is theoretically motivated by our new transductive multi-task PAC-Bayesian generalization bound, that provides performance guarantees for unlabeled clients. The objective is structured in such a way that it allows both clients with labeled data and clients with only unlabeled data to contribute to the training process. To supplement our theoretical results we carry out a thorough experimental evaluation of FLowDUP, demonstrating strong empirical performance on a range of datasets with differing sorts of statistically heterogeneous clients. Through numerous ablation studies, we test the efficacy of the individual components of the method.","authors":["Hossein Zakerinia","Jonathan Scott","Christoph H. Lampert"],"url":"https://arxiv.org/abs/2505.15579"}
{"created":"2025-05-22","title":"UWSAM: Segment Anything Model Guided Underwater Instance Segmentation and A Large-scale Benchmark Dataset","abstract":"With recent breakthroughs in large-scale modeling, the Segment Anything Model (SAM) has demonstrated significant potential in a variety of visual applications. However, due to the lack of underwater domain expertise, SAM and its variants face performance limitations in end-to-end underwater instance segmentation tasks, while their higher computational requirements further hinder their application in underwater scenarios. To address this challenge, we propose a large-scale underwater instance segmentation dataset, UIIS10K, which includes 10,048 images with pixel-level annotations for 10 categories. Then, we introduce UWSAM, an efficient model designed for automatic and accurate segmentation of underwater instances. UWSAM efficiently distills knowledge from the SAM ViT-Huge image encoder into the smaller ViT-Small image encoder via the Mask GAT-based Underwater Knowledge Distillation (MG-UKD) method for effective visual representation learning. Furthermore, we design an End-to-end Underwater Prompt Generator (EUPG) for UWSAM, which automatically generates underwater prompts instead of explicitly providing foreground points or boxes as prompts, thus enabling the network to locate underwater instances accurately for efficient segmentation. Comprehensive experimental results show that our model is effective, achieving significant performance improvements over state-of-the-art methods on multiple underwater instance datasets. Datasets and codes are available at https://github.com/LiamLian0727/UIIS10K.","authors":["Hua Li","Shijie Lian","Zhiyuan Li","Runmin Cong","Sam Kwong"],"url":"https://arxiv.org/abs/2505.15581"}
{"created":"2025-05-22","title":"Improved power methods for computing eigenvalues of dual quaternion Hermitian matrices","abstract":"This paper investigates the eigenvalue computation problem of the dual quaternion Hermitian matrix closely related to multi-agent group control. Recently, power method was proposed by Cui and Qi in Journal of Scientific Computing, 100 (2024) to solve such problem. Recognizing that the convergence rate of power method is slow due to its dependence on the eigenvalue distribution, we propose two improved versions of power method based on dual complex adjoint matrices and Aitken extrapolation, named DCAM-PM and ADCAM-PM. They achieve notable efficiency improvements and demonstrate significantly faster convergence. However, power method may be invalid for dual quaternion Hermitian matrices with eigenvalues having identical standard parts but distinct dual parts. To overcome this disadvantage, utilizing the eigen-decomposition properties of dual complex adjoint matrix, we propose a novel algorithm EDDCAM-EA which surpasses the power method in both accuracy and speed. Application to eigenvalue computations of dual quaternion Hermitian matrices in multi-agent formation control and numerical experiments highlight the remarkable accuracy and speed of our proposed algorithms.","authors":["Yongjun Chen","Liping Zhang"],"url":"https://arxiv.org/abs/2505.15584"}
{"created":"2025-05-22","title":"MIRB: Mathematical Information Retrieval Benchmark","abstract":"Mathematical Information Retrieval (MIR) is the task of retrieving information from mathematical documents and plays a key role in various applications, including theorem search in mathematical libraries, answer retrieval on math forums, and premise selection in automated theorem proving. However, a unified benchmark for evaluating these diverse retrieval tasks has been lacking. In this paper, we introduce MIRB (Mathematical Information Retrieval Benchmark) to assess the MIR capabilities of retrieval models. MIRB includes four tasks: semantic statement retrieval, question-answer retrieval, premise retrieval, and formula retrieval, spanning a total of 12 datasets. We evaluate 13 retrieval models on this benchmark and analyze the challenges inherent to MIR. We hope that MIRB provides a comprehensive framework for evaluating MIR systems and helps advance the development of more effective retrieval models tailored to the mathematical domain.","authors":["Haocheng Ju","Bin Dong"],"url":"https://arxiv.org/abs/2505.15585"}
{"created":"2025-05-22","title":"Approximate Probabilistic Bisimulation for Continuous-Time Markov Chains","abstract":"We introduce $(\\varepsilon, \\delta)$-bisimulation, a novel type of approximate probabilistic bisimulation for continuous-time Markov chains. In contrast to related notions, $(\\varepsilon, \\delta)$-bisimulation allows the use of different tolerances for the transition probabilities ($\\varepsilon$, additive) and total exit rates ($\\delta$, multiplicative) of states. Fundamental properties of the notion, as well as bounds on the absolute difference of time- and reward-bounded reachability probabilities for $(\\varepsilon,\\delta)$-bisimilar states, are established.","authors":["Timm Spork","Christel Baier","Joost-Pieter Katoen","Sascha Kl\\\"uppelholz","Jakob Piribauer"],"url":"https://arxiv.org/abs/2505.15587"}
{"created":"2025-05-22","title":"World Models as Reference Trajectories for Rapid Motor Adaptation","abstract":"Deploying learned control policies in real-world environments poses a fundamental challenge. When system dynamics change unexpectedly, performance degrades until models are retrained on new data. We introduce Reflexive World Models (RWM), a dual control framework that uses world model predictions as implicit reference trajectories for rapid adaptation. Our method separates the control problem into long-term reward maximization through reinforcement learning and robust motor execution through rapid latent control. This dual architecture achieves significantly faster adaptation with low online computational cost compared to model-based RL baselines, while maintaining near-optimal performance. The approach combines the benefits of flexible policy learning through reinforcement learning with rapid error correction capabilities, providing a principled approach to maintaining performance in high-dimensional continuous control tasks under varying dynamics.","authors":["Carlos Stein Brito","Daniel McNamee"],"url":"https://arxiv.org/abs/2505.15589"}
{"created":"2025-05-22","title":"Bridging the Gap: Physical PCI Device Integration Into SystemC-TLM Virtual Platforms","abstract":"In today's technology-driven world, early-stage software development and testing are crucial. Virtual Platforms (VPs) have become indispensable tools for this purpose as they serve as a platform to execute and debug the unmodified target software at an early design stage. With the increasing complexity of software, especially in areas like Artificial Intelligence (AI) applications, VPs need to provide high simulation speed to ensure the target software executes within a reasonable time. Hybrid simulation, which combines virtual models with real hardware, can improve the performance of VPs. This paper introduces a novel approach for integrating real Peripheral Component Interconnect (PCI) devices into SystemC-TLM-2.0-based VPs. The embedded PCI devices enable high performance, easy integration, and allow introspection for analysis and optimization. To illustrate the practical application of our approach, we present a case study where we integrate Google Coral's Edge Tensor Processing Unit (TPU) into an ARM-based VP. The integration allows efficient execution of AI workloads, accelerating simulation speeds by up to 480x while eliminating the need for complex virtual device models. Beyond accelerating AI-workload execution, our framework enables driver development, regression testing across architectures, and device communication analysis. Our findings demonstrate that embedding PCI devices into SystemC simulations significantly enhances","authors":["Nils Bosbach","Rebecca Pelke","Niko Zurstra{\\ss}en","Jan Henrik Weinstock","Lukas J\\\"unger","Rainer Leupers"],"url":"https://arxiv.org/abs/2505.15590"}
{"created":"2025-05-22","title":"VP Lab: a PEFT-Enabled Visual Prompting Laboratory for Semantic Segmentation","abstract":"Large-scale pretrained vision backbones have transformed computer vision by providing powerful feature extractors that enable various downstream tasks, including training-free approaches like visual prompting for semantic segmentation. Despite their success in generic scenarios, these models often fall short when applied to specialized technical domains where the visual features differ significantly from their training distribution. To bridge this gap, we introduce VP Lab, a comprehensive iterative framework that enhances visual prompting for robust segmentation model development. At the core of VP Lab lies E-PEFT, a novel ensemble of parameter-efficient fine-tuning techniques specifically designed to adapt our visual prompting pipeline to specific domains in a manner that is both parameter- and data-efficient. Our approach not only surpasses the state-of-the-art in parameter-efficient fine-tuning for the Segment Anything Model (SAM), but also facilitates an interactive, near-real-time loop, allowing users to observe progressively improving results as they experiment within the framework. By integrating E-PEFT with visual prompting, we demonstrate a remarkable 50\\% increase in semantic segmentation mIoU performance across various technical datasets using only 5 validated images, establishing a new paradigm for fast, efficient, and interactive model deployment in new, challenging domains. This work comes in the form of a demonstration.","authors":["Niccolo Avogaro","Thomas Frick","Yagmur G. Cinar","Daniel Caraballo","Cezary Skura","Filip M. Janicki","Piotr Kluska","Brown Ebouky","Nicola Farronato","Florian Scheidegger","Cristiano Malossi","Konrad Schindler","Andrea Bartezzaghi","Roy Assaf","Mattia Rigotti"],"url":"https://arxiv.org/abs/2505.15592"}
{"created":"2025-05-22","title":"Self-powered smart contact lenses: a multidisciplinary approach to micro-scale energy and 900 MHz - 1.1 GHz bandwidth microfabricated loop antennas communication systems","abstract":"Smart contact lenses are at the forefront of integrating microelectronics, biomedical engineering, and optics into wearable technologies. This work addresses a key obstacle in their development: achieving autonomous power without compromising safety or miniaturization. We examine energy harvesting strategies using intrinsic ocular sources-particularly tear salinity and eyelid motion-to enable sustainable operation without external batteries. The study emphasizes compact loop antennas operating between 900 MHz and 1.1 GHz as critical for wireless data transmission and power management. Material choices, signal integrity, and biocompatibility are also discussed. By presenting recent advances in 3D-printed optics, antenna integration, and energy systems, we propose a conceptual framework for the next generation of smart lenses, enabling real-time health monitoring and vision enhancement through self-powered, compact devices.","authors":["Patrice Salzenstein (Centre National de la Recherche Scientifique)","Blandine Guichardaz (Centre National de la Recherche Scientifique)","Aya Maroua Bessou (Centre National de la Recherche Scientifique)","Ekaterina Pavlyuchenko (Centre National de la Recherche Scientifique)","Martine Comte (Consultant","La Chaux-de-Fonds","Switzerland)","Maxim V. Pogumirsky (ITMO","Saint Petersburg","Russia","FAREXPORT Ltd.","Saint Petersburg","Russia)"],"url":"https://arxiv.org/abs/2505.15593"}
{"created":"2025-05-22","title":"Beyond Classification: Evaluating Diffusion Denoised Smoothing for Security-Utility Trade off","abstract":"While foundation models demonstrate impressive performance across various tasks, they remain vulnerable to adversarial inputs. Current research explores various approaches to enhance model robustness, with Diffusion Denoised Smoothing emerging as a particularly promising technique. This method employs a pretrained diffusion model to preprocess inputs before model inference. Yet, its effectiveness remains largely unexplored beyond classification. We aim to address this gap by analyzing three datasets with four distinct downstream tasks under three different adversarial attack algorithms. Our findings reveal that while foundation models maintain resilience against conventional transformations, applying high-noise diffusion denoising to clean images without any distortions significantly degrades performance by as high as 57%. Low-noise diffusion settings preserve performance but fail to provide adequate protection across all attack types. Moreover, we introduce a novel attack strategy specifically targeting the diffusion process itself, capable of circumventing defenses in the low-noise regime. Our results suggest that the trade-off between adversarial robustness and performance remains a challenge to be addressed.","authors":["Yury Belousov","Brian Pulfer","Vitaliy Kinakh","Slava Voloshynovskiy"],"url":"https://arxiv.org/abs/2505.15594"}
{"created":"2025-05-22","title":"A Methodology to Evaluate Strategies Predicting Rankings on Unseen Domains","abstract":"Frequently, multiple entities (methods, algorithms, procedures, solutions, etc.) can be developed for a common task and applied across various domains that differ in the distribution of scenarios encountered. For example, in computer vision, the input data provided to image analysis methods depend on the type of sensor used, its location, and the scene content. However, a crucial difficulty remains: can we predict which entities will perform best in a new domain based on assessments on known domains, without having to carry out new and costly evaluations? This paper presents an original methodology to address this question, in a leave-one-domain-out fashion, for various application-specific preferences. We illustrate its use with 30 strategies to predict the rankings of 40 entities (unsupervised background subtraction methods) on 53 domains (videos).","authors":["S\\'ebastien Pi\\'erard","Adrien Deli\\`ege","Ana\\\"is Halin","Marc Van Droogenbroeck"],"url":"https://arxiv.org/abs/2505.15595"}
{"created":"2025-05-22","title":"Exploring LLM-Generated Feedback for Economics Essays: How Teaching Assistants Evaluate and Envision Its Use","abstract":"This project examines the prospect of using AI-generated feedback as suggestions to expedite and enhance human instructors' feedback provision. In particular, we focus on understanding the teaching assistants' perspectives on the quality of AI-generated feedback and how they may or may not utilize AI feedback in their own workflows. We situate our work in a foundational college Economics class, which has frequent short essay assignments. We developed an LLM-powered feedback engine that generates feedback on students' essays based on grading rubrics used by the teaching assistants (TAs). To ensure that TAs can meaningfully critique and engage with the AI feedback, we had them complete their regular grading jobs. For a randomly selected set of essays that they had graded, we used our feedback engine to generate feedback and displayed the feedback as in-text comments in a Word document. We then performed think-aloud studies with 5 TAs over 20 1-hour sessions to have them evaluate the AI feedback, contrast the AI feedback with their handwritten feedback, and share how they envision using the AI feedback if they were offered as suggestions. The study highlights the importance of providing detailed rubrics for AI to generate high-quality feedback for knowledge-intensive essays. TAs considered that using AI feedback as suggestions during their grading could expedite grading, enhance consistency, and improve overall feedback quality. We discuss the importance of decomposing the feedback generation task into steps and presenting intermediate results, in order for TAs to use the AI feedback.","authors":["Xinyi Lu","Aditya Mahesh","Zejia Shen","Mitchell Dudley","Larissa Sano","Xu Wang"],"url":"https://arxiv.org/abs/2505.15596"}
{"created":"2025-05-22","title":"Deep Learning for Continuous-time Stochastic Control with Jumps","abstract":"In this paper, we introduce a model-based deep-learning approach to solve finite-horizon continuous-time stochastic control problems with jumps. We iteratively train two neural networks: one to represent the optimal policy and the other to approximate the value function. Leveraging a continuous-time version of the dynamic programming principle, we derive two different training objectives based on the Hamilton-Jacobi-Bellman equation, ensuring that the networks capture the underlying stochastic dynamics. Empirical evaluations on different problems illustrate the accuracy and scalability of our approach, demonstrating its effectiveness in solving complex, high-dimensional stochastic control tasks.","authors":["Patrick Cheridito","Jean-Loup Dupret","Donatien Hainaut"],"url":"https://arxiv.org/abs/2505.15602"}
{"created":"2025-05-22","title":"A General Information Extraction Framework Based on Formal Languages","abstract":"For a terminal alphabet $\\Sigma$ and an attribute alphabet $\\Gamma$, a $(\\Sigma, \\Gamma)$-extractor is a function that maps every string over $\\Sigma$ to a table with a column per attribute and with sets of positions of $w$ as cell entries. This rather general information extraction framework extends the well-known document spanner framework, which has intensively been investigated in the database theory community over the last decade. Moreover, our framework is based on formal language theory in a particularly clean and simple way. In addition to this conceptual contribution, we investigate closure properties, different representation formalisms and the complexity of natural decision problems for extractors.","authors":["Markus L. Schmid"],"url":"https://arxiv.org/abs/2505.15605"}
{"created":"2025-05-22","title":"From Problem-Solving to Teaching Problem-Solving: Aligning LLMs with Pedagogy using Reinforcement Learning","abstract":"Large language models (LLMs) can transform education, but their optimization for direct question-answering often undermines effective pedagogy which requires strategically withholding answers. To mitigate this, we propose an online reinforcement learning (RL)-based alignment framework that can quickly adapt LLMs into effective tutors using simulated student-tutor interactions by emphasizing pedagogical quality and guided problem-solving over simply giving away answers. We use our method to train a 7B parameter tutor model without human annotations which reaches similar performance to larger proprietary models like LearnLM. We introduce a controllable reward weighting to balance pedagogical support and student solving accuracy, allowing us to trace the Pareto frontier between these two objectives. Our models better preserve reasoning capabilities than single-turn SFT baselines and can optionally enhance interpretability through thinking tags that expose the model's instructional planning.","authors":["David Dinucu-Jianu","Jakub Macina","Nico Daheim","Ido Hakimi","Iryna Gurevych","Mrinmaya Sachan"],"url":"https://arxiv.org/abs/2505.15607"}
{"created":"2025-05-22","title":"Learn to Reason Efficiently with Adaptive Length-based Reward Shaping","abstract":"Large Reasoning Models (LRMs) have shown remarkable capabilities in solving complex problems through reinforcement learning (RL), particularly by generating long reasoning traces. However, these extended outputs often exhibit substantial redundancy, which limits the efficiency of LRMs. In this paper, we investigate RL-based approaches to promote reasoning efficiency. Specifically, we first present a unified framework that formulates various efficient reasoning methods through the lens of length-based reward shaping. Building on this perspective, we propose a novel Length-bAsed StEp Reward shaping method (LASER), which employs a step function as the reward, controlled by a target length. LASER surpasses previous methods, achieving a superior Pareto-optimal balance between performance and efficiency. Next, we further extend LASER based on two key intuitions: (1) The reasoning behavior of the model evolves during training, necessitating reward specifications that are also adaptive and dynamic; (2) Rather than uniformly encouraging shorter or longer chains of thought (CoT), we posit that length-based reward shaping should be difficulty-aware i.e., it should penalize lengthy CoTs more for easy queries. This approach is expected to facilitate a combination of fast and slow thinking, leading to a better overall tradeoff. The resulting method is termed LASER-D (Dynamic and Difficulty-aware). Experiments on DeepSeek-R1-Distill-Qwen-1.5B, DeepSeek-R1-Distill-Qwen-7B, and DeepSeek-R1-Distill-Qwen-32B show that our approach significantly enhances both reasoning performance and response length efficiency. For instance, LASER-D and its variant achieve a +6.1 improvement on AIME2024 while reducing token usage by 63%. Further analysis reveals our RL-based compression produces more concise reasoning patterns with less redundant \"self-reflections\". Resources are at https://github.com/hkust-nlp/Laser.","authors":["Wei Liu","Ruochen Zhou","Yiyun Deng","Yuzhen Huang","Junteng Liu","Yuntian Deng","Yizhe Zhang","Junxian He"],"url":"https://arxiv.org/abs/2505.15612"}
{"created":"2025-05-22","title":"LENS: Multi-level Evaluation of Multimodal Reasoning with Large Language Models","abstract":"Multimodal Large Language Models (MLLMs) have achieved significant advances in integrating visual and linguistic information, yet their ability to reason about complex and real-world scenarios remains limited. The existing benchmarks are usually constructed in the task-oriented manner without guarantee that different task samples come from the same data distribution, thus they often fall short in evaluating the synergistic effects of lower-level perceptual capabilities on higher-order reasoning. To lift this limitation, we contribute Lens, a multi-level benchmark with 3.4K contemporary images and 60K+ human-authored questions covering eight tasks and 12 daily scenarios, forming three progressive task tiers, i.e., perception, understanding, and reasoning. One feature is that each image is equipped with rich annotations for all tasks. Thus, this dataset intrinsically supports to evaluate MLLMs to handle image-invariable prompts, from basic perception to compositional reasoning. In addition, our images are manully collected from the social media, in which 53% were published later than Jan. 2025. We evaluate 15+ frontier MLLMs such as Qwen2.5-VL-72B, InternVL3-78B, GPT-4o and two reasoning models QVQ-72B-preview and Kimi-VL. These models are released later than Dec. 2024, and none of them achieve an accuracy greater than 60% in the reasoning tasks. Project page: https://github.com/Lens4MLLMs/lens. ICCV 2025 workshop page: https://lens4mllms.github.io/mars2-workshop-iccv2025/","authors":["Ruilin Yao","Bo Zhang","Jirui Huang","Xinwei Long","Yifang Zhang","Tianyu Zou","Yufei Wu","Shichao Su","Yifan Xu","Wenxi Zeng","Zhaoyu Yang","Guoyou Li","Shilan Zhang","Zichan Li","Yaxiong Chen","Shengwu Xiong","Peng Xu","Jiajun Zhang","Bowen Zhou","David Clifton","Luc Van Gool"],"url":"https://arxiv.org/abs/2505.15616"}
{"created":"2025-05-22","title":"DS-Bench: A Realistic Benchmark for Data Science Code Generation","abstract":"We introduce DS-bench, a new benchmark designed to evaluate large language models (LLMs) on complicated and realistic data science code generation tasks. DS-bench consists of 1,000 carefully constructed problems sourced from realistic problems from GitHub across ten widely used Python data science libraries. Compared to the current state-of-the-art benchmark DS-1000, DS-bench offers a more challenging and representative testbed, longer code solutions, more comprehensive data science libraries, clearer and better structured problem descriptions, and stronger test suites. To construct the DS-bench, we develop a robust pipeline that combines task scope selection, code construction, test case generation, and problem description synthesis. The process is paired with rigorous manual editing to ensure alignment and enhance evaluation reliability. Experimental result shows that DS-bench exhibits robust scaling behavior, where larger models systematically outperform smaller ones, validating its ability to distinguish model capabilities. The best LLM we test, GPT-4o, has a pass@1 of 0.202, indicating that LLMs still have a large room to improve for realistic data science code generation tasks. We believe DS-bench will serve as a rigorous and trustworthy foundation for advancing LLM-based data science programming.","authors":["Shuyin Ouyang","Dong Huang","Jingwen Guo","Zeyu Sun","Qihao Zhu","Jie M. Zhang"],"url":"https://arxiv.org/abs/2505.15621"}
{"created":"2025-05-22","title":"Benchmarking Energy and Latency in TinyML: A Novel Method for Resource-Constrained AI","abstract":"The rise of IoT has increased the need for on-edge machine learning, with TinyML emerging as a promising solution for resource-constrained devices such as MCU. However, evaluating their performance remains challenging due to diverse architectures and application scenarios. Current solutions have many non-negligible limitations. This work introduces an alternative benchmarking methodology that integrates energy and latency measurements while distinguishing three execution phases pre-inference, inference, and post-inference. Additionally, the setup ensures that the device operates without being powered by an external measurement unit, while automated testing can be leveraged to enhance statistical significance. To evaluate our setup, we tested the STM32N6 MCU, which includes a NPU for executing neural networks. Two configurations were considered: high-performance and Low-power. The variation of the EDP was analyzed separately for each phase, providing insights into the impact of hardware configurations on energy efficiency. Each model was tested 1000 times to ensure statistically relevant results. Our findings demonstrate that reducing the core voltage and clock frequency improve the efficiency of pre- and post-processing without significantly affecting network execution performance. This approach can also be used for cross-platform comparisons to determine the most efficient inference platform and to quantify how pre- and post-processing overhead varies across different hardware implementations.","authors":["Pietro Bartoli","Christian Veronesi","Andrea Giudici","David Siorpaes","Diana Trojaniello","Franco Zappa"],"url":"https://arxiv.org/abs/2505.15622"}
{"created":"2025-05-22","title":"Can LLMs $\\textit{understand}$ Math? -- Exploring the Pitfalls in Mathematical Reasoning","abstract":"Large language models (LLMs) demonstrate considerable potential in various natural language tasks but face significant challenges in mathematical reasoning, particularly in executing precise, multi-step logic. However, current evaluation frameworks judge their performance solely based on accuracy, which only accounts for the final answer. This study explores these pitfalls by employing a novel evaluation framework. We propose an evaluation metric called the MAPLE score, which holistically quantifies reasoning misalignment by integrating error rates, redundancy, and validity.","authors":["Tiasa Singha Roy","Aditeya Baral","Ayush Rajesh Jhaveri","Yusuf Baig"],"url":"https://arxiv.org/abs/2505.15623"}
{"created":"2025-05-22","title":"Mechanistic Insights into Grokking from the Embedding Layer","abstract":"Grokking, a delayed generalization in neural networks after perfect training performance, has been observed in Transformers and MLPs, but the components driving it remain underexplored. We show that embeddings are central to grokking: introducing them into MLPs induces delayed generalization in modular arithmetic tasks, whereas MLPs without embeddings can generalize immediately. Our analysis identifies two key mechanisms: (1) Embedding update dynamics, where rare tokens stagnate due to sparse gradient updates and weight decay, and (2) Bilinear coupling, where the interaction between embeddings and downstream weights introduces saddle points and increases sensitivity to initialization. To confirm these mechanisms, we investigate frequency-aware sampling, which balances token updates by minimizing gradient variance, and embedding-specific learning rates, derived from the asymmetric curvature of the bilinear loss landscape. We prove that an adaptive learning rate ratio, \\(\\frac{\\eta_E}{\\eta_W} \\propto \\frac{\\sigma_{\\max}(E)}{\\sigma_{\\max}(W)} \\cdot \\frac{f_W}{f_E}\\), mitigates bilinear coupling effects, accelerating convergence. Our methods not only improve grokking dynamics but also extend to broader challenges in Transformer optimization, where bilinear interactions hinder efficient training.","authors":["H. V. AlquBoj","Hilal AlQuabeh","Velibor Bojkovic","Munachiso Nwadike","Kentaro Inui"],"url":"https://arxiv.org/abs/2505.15624"}
{"created":"2025-05-22","title":"Aligning Explanations with Human Communication","abstract":"Machine learning explainability aims to make the decision-making process of black-box models more transparent by finding the most important input features for a given prediction task. Recent works have proposed composing explanations from semantic concepts (e.g., colors, patterns, shapes) that are inherently interpretable to the user of a model. However, these methods generally ignore the communicative context of explanation-the ability of the user to understand the prediction of the model from the explanation. For example, while a medical doctor might understand an explanation in terms of clinical markers, a patient may need a more accessible explanation to make sense of the same diagnosis. In this paper, we address this gap with listener-adaptive explanations. We propose an iterative procedure grounded in principles of pragmatic reasoning and the rational speech act to generate explanations that maximize communicative utility. Our procedure only needs access to pairwise preferences between candidate explanations, relevant in real-world scenarios where a listener model may not be available. We evaluate our method in image classification tasks, demonstrating improved alignment between explanations and listener preferences across three datasets. Furthermore, we perform a user study that demonstrates our explanations increase communicative utility.","authors":["Jacopo Teneggi","Zhenzhen Wang","Paul H. Yi","Tianmin Shu","Jeremias Sulam"],"url":"https://arxiv.org/abs/2505.15626"}
{"created":"2025-05-22","title":"SNAP: A Benchmark for Testing the Effects of Capture Conditions on Fundamental Vision Tasks","abstract":"Generalization of deep-learning-based (DL) computer vision algorithms to various image perturbations is hard to establish and remains an active area of research. The majority of past analyses focused on the images already captured, whereas effects of the image formation pipeline and environment are less studied. In this paper, we address this issue by analyzing the impact of capture conditions, such as camera parameters and lighting, on DL model performance on 3 vision tasks -- image classification, object detection, and visual question answering (VQA). To this end, we assess capture bias in common vision datasets and create a new benchmark, SNAP (for $\\textbf{S}$hutter speed, ISO se$\\textbf{N}$sitivity, and $\\textbf{AP}$erture), consisting of images of objects taken under controlled lighting conditions and with densely sampled camera settings. We then evaluate a large number of DL vision models and show the effects of capture conditions on each selected vision task. Lastly, we conduct an experiment to establish a human baseline for the VQA task. Our results show that computer vision datasets are significantly biased, the models trained on this data do not reach human accuracy even on the well-exposed images, and are susceptible to both major exposure changes and minute variations of camera settings. Code and data can be found at https://github.com/ykotseruba/SNAP","authors":["Iuliia Kotseruba","John K. Tsotsos"],"url":"https://arxiv.org/abs/2505.15628"}
{"created":"2025-05-22","title":"Relationship Analysis of Image-Text Pair in SNS Posts","abstract":"Social networking services (SNS) contain vast amounts of image-text posts, necessitating effective analysis of their relationships for improved information retrieval. This study addresses the classification of image-text pairs in SNS, overcoming prior limitations in distinguishing relationships beyond similarity. We propose a graph-based method to classify image-text pairs into similar and complementary relationships. Our approach first embeds images and text using CLIP, followed by clustering. Next, we construct an Image-Text Relationship Clustering Line Graph (ITRC-Line Graph), where clusters serve as nodes. Finally, edges and nodes are swapped in a pseudo-graph representation. A Graph Convolutional Network (GCN) then learns node and edge representations, which are fused with the original embeddings for final classification. Experimental results on a publicly available dataset demonstrate the effectiveness of our method.","authors":["Takuto Nabeoka","Yijun Duan","Qiang Ma"],"url":"https://arxiv.org/abs/2505.15629"}
{"created":"2025-05-22","title":"Guidelines for the Quality Assessment of Energy-Aware NAS Benchmarks","abstract":"Neural Architecture Search (NAS) accelerates progress in deep learning through systematic refinement of model architectures. The downside is increasingly large energy consumption during the search process. Surrogate-based benchmarking mitigates the cost of full training by querying a pre-trained surrogate to obtain an estimate for the quality of the model. Specifically, energy-aware benchmarking aims to make it possible for NAS to favourably trade off model energy consumption against accuracy. Towards this end, we propose three design principles for such energy-aware benchmarks: (i) reliable power measurements, (ii) a wide range of GPU usage, and (iii) holistic cost reporting. We analyse EA-HAS-Bench based on these principles and find that the choice of GPU measurement API has a large impact on the quality of results. Using the Nvidia System Management Interface (SMI) on top of its underlying library influences the sampling rate during the initial data collection, returning faulty low-power estimations. This results in poor correlation with accurate measurements obtained from an external power meter. With this study, we bring to attention several key considerations when performing energy-aware surrogate-based benchmarking and derive first guidelines that can help design novel benchmarks. We show a narrow usage range of the four GPUs attached to our device, ranging from 146 W to 305 W in a single-GPU setting, and narrowing down even further when using all four GPUs. To improve holistic energy reporting, we propose calibration experiments over assumptions made in popular tools, such as Code Carbon, thus achieving reductions in the maximum inaccuracy from 10.3 % to 8.9 % without and to 6.6 % with prior estimation of the expected load on the device.","authors":["Nick Kocher","Christian Wassermann","Leona Hennig","Jonas Seng","Holger Hoos","Kristian Kersting","Marius Lindauer","Matthias M\\\"uller"],"url":"https://arxiv.org/abs/2505.15631"}
{"created":"2025-05-22","title":"Listen to the Context: Towards Faithful Large Language Models for Retrieval Augmented Generation on Climate Questions","abstract":"Large language models that use retrieval augmented generation have the potential to unlock valuable knowledge for researchers, policymakers, and the public by making long and technical climate-related documents more accessible. While this approach can help alleviate factual hallucinations by relying on retrieved passages as additional context, its effectiveness depends on whether the model's output remains faithful to these passages. To address this, we explore the automatic assessment of faithfulness of different models in this setting. We then focus on ClimateGPT, a large language model specialised in climate science, to examine which factors in its instruction fine-tuning impact the model's faithfulness. By excluding unfaithful subsets of the model's training data, we develop ClimateGPT Faithful+, which achieves an improvement in faithfulness from 30% to 57% in supported atomic claims according to our automatic metric.","authors":["David Thulke","Jakob Kemmler","Christian Dugast","Hermann Ney"],"url":"https://arxiv.org/abs/2505.15633"}
{"created":"2025-05-22","title":"Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models","abstract":"Large Language Models (LLMs) demonstrate the ability to solve reasoning and mathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT length, as seen in models such as DeepSeek-R1, significantly enhances this reasoning for complex problems, but requires costly and high-quality long CoT data and fine-tuning. This work, inspired by the deep thinking paradigm of DeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of an LLM without external datasets. Our method first employs Sparse Autoencoders (SAEs) to extract interpretable features from vanilla CoT. These features are then used to steer the LLM's internal states during generation. Recognizing that many LLMs do not have corresponding pre-trained SAEs, we further introduce a novel SAE-free steering algorithm, which directly computes steering directions from the residual activations of an LLM, obviating the need for an explicit SAE. Experimental results demonstrate that both our SAE-based and subsequent SAE-free steering algorithms significantly enhance the reasoning capabilities of LLMs.","authors":["Zihao Li","Xu Wang","Yuzhe Yang","Ziyu Yao","Haoyi Xiong","Mengnan Du"],"url":"https://arxiv.org/abs/2505.15634"}
{"created":"2025-05-22","title":"Distance Adaptive Beam Search for Provably Accurate Graph-Based Nearest Neighbor Search","abstract":"Nearest neighbor search is central in machine learning, information retrieval, and databases. For high-dimensional datasets, graph-based methods such as HNSW, DiskANN, and NSG have become popular thanks to their empirical accuracy and efficiency. These methods construct a directed graph over the dataset and perform beam search on the graph to find nodes close to a given query. While significant work has focused on practical refinements and theoretical understanding of graph-based methods, many questions remain. We propose a new distance-based termination condition for beam search to replace the commonly used condition based on beam width. We prove that, as long as the search graph is navigable, our resulting Adaptive Beam Search method is guaranteed to approximately solve the nearest-neighbor problem, establishing a connection between navigability and the performance of graph-based search. We also provide extensive experiments on our new termination condition for both navigable graphs and approximately navigable graphs used in practice, such as HNSW and Vamana graphs. We find that Adaptive Beam Search outperforms standard beam search over a range of recall values, data sets, graph constructions, and target number of nearest neighbors. It thus provides a simple and practical way to improve the performance of popular methods.","authors":["Yousef Al-Jazzazi","Haya Diwan","Jinrui Gou","Cameron Musco","Christopher Musco","Torsten Suel"],"url":"https://arxiv.org/abs/2505.15636"}
{"created":"2025-05-22","title":"Oral Imaging for Malocclusion Issues Assessments: OMNI Dataset, Deep Learning Baselines and Benchmarking","abstract":"Malocclusion is a major challenge in orthodontics, and its complex presentation and diverse clinical manifestations make accurate localization and diagnosis particularly important. Currently, one of the major shortcomings facing the field of dental image analysis is the lack of large-scale, accurately labeled datasets dedicated to malocclusion issues, which limits the development of automated diagnostics in the field of dentistry and leads to a lack of diagnostic accuracy and efficiency in clinical practice. Therefore, in this study, we propose the Oral and Maxillofacial Natural Images (OMNI) dataset, a novel and comprehensive dental image dataset aimed at advancing the study of analyzing dental images for issues of malocclusion. Specifically, the dataset contains 4166 multi-view images with 384 participants in data collection and annotated by professional dentists. In addition, we performed a comprehensive validation of the created OMNI dataset, including three CNN-based methods, two Transformer-based methods, and one GNN-based method, and conducted automated diagnostic experiments for malocclusion issues. The experimental results show that the OMNI dataset can facilitate the automated diagnosis research of malocclusion issues and provide a new benchmark for the research in this field. Our OMNI dataset and baseline code are publicly available at https://github.com/RoundFaceJ/OMNI.","authors":["Pujun Xue","Junyi Ge","Xiaotong Jiang","Siyang Song","Zijian Wu","Yupeng Huo","Weicheng Xie","Linlin Shen","Xiaoqin Zhou","Xiaofeng Liu","Min Gu"],"url":"https://arxiv.org/abs/2505.15637"}
{"created":"2025-05-22","title":"Bayesian Ensembling: Insights from Online Optimization and Empirical Bayes","abstract":"We revisit the classical problem of Bayesian ensembles and address the challenge of learning optimal combinations of Bayesian models in an online, continual learning setting. To this end, we reinterpret existing approaches such as Bayesian model averaging (BMA) and Bayesian stacking through a novel empirical Bayes lens, shedding new light on the limitations and pathologies of BMA. Further motivated by insights from online optimization, we propose Online Bayesian Stacking (OBS), a method that optimizes the log-score over predictive distributions to adaptively combine Bayesian models. A key contribution of our work is establishing a novel connection between OBS and portfolio selection, bridging Bayesian ensemble learning with a rich, well-studied theoretical framework that offers efficient algorithms and extensive regret analysis. We further clarify the relationship between OBS and online BMA, showing that they optimize related but distinct cost functions. Through theoretical analysis and empirical evaluation, we identify scenarios where OBS outperforms online BMA and provide principled guidance on when practitioners should prefer one approach over the other.","authors":["Daniel Waxman","Fernando Llorente","Petar M. Djuri\\'c"],"url":"https://arxiv.org/abs/2505.15638"}
{"created":"2025-05-22","title":"A Simple Approximation Algorithm for Optimal Decision Tree","abstract":"Optimal decision tree (\\odt) is a fundamental problem arising in applications such as active learning, entity identification, and medical diagnosis. An instance of \\odt is given by $m$ hypotheses, out of which an unknown ``true'' hypothesis is drawn according to some probability distribution. An algorithm needs to identify the true hypothesis by making queries: each query incurs a cost and has a known response for each hypothesis. The goal is to minimize the expected query cost to identify the true hypothesis. We consider the most general setting with arbitrary costs, probabilities and responses. \\odt is NP-hard to approximate better than $\\ln m$ and there are $O(\\ln m)$ approximation algorithms known for it. However, these algorithms and/or their analyses are quite complex. Moreover, the leading constant factors are large. We provide a simple algorithm and analysis for \\odt, proving an approximation ratio of $8 \\ln m$.","authors":["Zhengjia Zhuo","Viswanath Nagarajan"],"url":"https://arxiv.org/abs/2505.15641"}
{"created":"2025-05-22","title":"Optimal Best-Arm Identification under Fixed Confidence with Multiple Optima","abstract":"We study the problem of best-arm identification in stochastic multi-armed bandits under the fixed-confidence setting, with a particular focus on instances that admit multiple optimal arms. While the Track-and-Stop algorithm of Garivier and Kaufmann (2016) is widely conjectured to be instance-optimal, its performance in the presence of multiple optima has remained insufficiently understood. In this work, we revisit the Track-and-Stop strategy and propose a modified stopping rule that ensures instance-optimality even when the set of optimal arms is not a singleton. Our analysis introduces a new information-theoretic lower bound that explicitly accounts for multiple optimal arms, and we demonstrate that our stopping rule tightly matches this bound.","authors":["Lan V. Truong"],"url":"https://arxiv.org/abs/2505.15643"}
{"created":"2025-05-22","title":"FragFake: A Dataset for Fine-Grained Detection of Edited Images with Vision Language Models","abstract":"Fine-grained edited image detection of localized edits in images is crucial for assessing content authenticity, especially given that modern diffusion models and image editing methods can produce highly realistic manipulations. However, this domain faces three challenges: (1) Binary classifiers yield only a global real-or-fake label without providing localization; (2) Traditional computer vision methods often rely on costly pixel-level annotations; and (3) No large-scale, high-quality dataset exists for modern image-editing detection techniques. To address these gaps, we develop an automated data-generation pipeline to create FragFake, the first dedicated benchmark dataset for edited image detection, which includes high-quality images from diverse editing models and a wide variety of edited objects. Based on FragFake, we utilize Vision Language Models (VLMs) for the first time in the task of edited image classification and edited region localization. Experimental results show that fine-tuned VLMs achieve higher average Object Precision across all datasets, significantly outperforming pretrained models. We further conduct ablation and transferability analyses to evaluate the detectors across various configurations and editing scenarios. To the best of our knowledge, this work is the first to reformulate localized image edit detection as a vision-language understanding task, establishing a new paradigm for the field. We anticipate that this work will establish a solid foundation to facilitate and inspire subsequent research endeavors in the domain of multimodal content authenticity.","authors":["Zhen Sun","Ziyi Zhang","Zeren Luo","Zeyang Sha","Tianshuo Cong","Zheng Li","Shiwen Cui","Weiqiang Wang","Jiaheng Wei","Xinlei He","Qi Li","Qian Wang"],"url":"https://arxiv.org/abs/2505.15644"}
{"created":"2025-05-22","title":"Word Level Timestamp Generation for Automatic Speech Recognition and Translation","abstract":"We introduce a data-driven approach for enabling word-level timestamp prediction in the Canary model. Accurate timestamp information is crucial for a variety of downstream tasks such as speech content retrieval and timed subtitles. While traditional hybrid systems and end-to-end (E2E) models may employ external modules for timestamp prediction, our approach eliminates the need for separate alignment mechanisms. By leveraging the NeMo Forced Aligner (NFA) as a teacher model, we generate word-level timestamps and train the Canary model to predict timestamps directly. We introduce a new <|timestamp|> token, enabling the Canary model to predict start and end timestamps for each word. Our method demonstrates precision and recall rates between 80% and 90%, with timestamp prediction errors ranging from 20 to 120 ms across four languages, with minimal WER degradation. Additionally, we extend our system to automatic speech translation (AST) tasks, achieving timestamp prediction errors around 200 milliseconds.","authors":["Ke Hu","Krishna Puvvada","Elena Rastorgueva","Zhehuai Chen","He Huang","Shuoyang Ding","Kunal Dhawan","Hainan Xu","Jagadeesh Balam","Boris Ginsburg"],"url":"https://arxiv.org/abs/2505.15646"}
{"created":"2025-05-22","title":"Second-Order Convergence in Private Stochastic Non-Convex Optimization","abstract":"We investigate the problem of finding second-order stationary points (SOSP) in differentially private (DP) stochastic non-convex optimization. Existing methods suffer from two key limitations: (i) inaccurate convergence error rate due to overlooking gradient variance in the saddle point escape analysis, and (ii) dependence on auxiliary private model selection procedures for identifying DP-SOSP, which can significantly impair utility, particularly in distributed settings. To address these issues, we propose a generic perturbed stochastic gradient descent (PSGD) framework built upon Gaussian noise injection and general gradient oracles. A core innovation of our framework is using model drift distance to determine whether PSGD escapes saddle points, ensuring convergence to approximate local minima without relying on second-order information or additional DP-SOSP identification. By leveraging the adaptive DP-SPIDER estimator as a specific gradient oracle, we develop a new DP algorithm that rectifies the convergence error rates reported in prior work. We further extend this algorithm to distributed learning with arbitrarily heterogeneous data, providing the first formal guarantees for finding DP-SOSP in such settings. Our analysis also highlights the detrimental impacts of private selection procedures in distributed learning under high-dimensional models, underscoring the practical benefits of our design. Numerical experiments on real-world datasets validate the efficacy of our approach.","authors":["Youming Tao","Zuyuan Zhang","Dongxiao Yu","Xiuzhen Cheng","Falko Dressler","Di Wang"],"url":"https://arxiv.org/abs/2505.15647"}
{"created":"2025-05-22","title":"Learning Small Decision Trees with Few Outliers: A Parameterized Perspective","abstract":"Decision trees are a fundamental tool in machine learning for representing, classifying, and generalizing data. It is desirable to construct ``small'' decision trees, by minimizing either the \\textit{size} ($s$) or the \\textit{depth} $(d)$ of the \\textit{decision tree} (\\textsc{DT}). Recently, the parameterized complexity of \\textsc{Decision Tree Learning} has attracted a lot of attention. We consider a generalization of \\textsc{Decision Tree Learning} where given a \\textit{classification instance} $E$ and an integer $t$, the task is to find a ``small'' \\textsc{DT} that disagrees with $E$ in at most $t$ examples. We consider two problems: \\textsc{DTSO} and \\textsc{DTDO}, where the goal is to construct a \\textsc{DT} minimizing $s$ and $d$, respectively. We first establish that both \\textsc{DTSO} and \\textsc{DTDO} are W[1]-hard when parameterized by $s+\\delta_{max}$ and $d+\\delta_{max}$, respectively, where $\\delta_{max}$ is the maximum number of features in which two differently labeled examples can differ. We complement this result by showing that these problems become \\textsc{FPT} if we include the parameter $t$. We also consider the kernelization complexity of these problems and establish several positive and negative results for both \\textsc{DTSO} and \\textsc{DTDO}.","authors":["Harmender Gahlawat","Meirav Zehavi"],"url":"https://arxiv.org/abs/2505.15648"}
{"created":"2025-05-22","title":"The Devil is in Fine-tuning and Long-tailed Problems:A New Benchmark for Scene Text Detection","abstract":"Scene text detection has seen the emergence of high-performing methods that excel on academic benchmarks. However, these detectors often fail to replicate such success in real-world scenarios. We uncover two key factors contributing to this discrepancy through extensive experiments. First, a \\textit{Fine-tuning Gap}, where models leverage \\textit{Dataset-Specific Optimization} (DSO) paradigm for one domain at the cost of reduced effectiveness in others, leads to inflated performances on academic benchmarks. Second, the suboptimal performance in practical settings is primarily attributed to the long-tailed distribution of texts, where detectors struggle with rare and complex categories as artistic or overlapped text. Given that the DSO paradigm might undermine the generalization ability of models, we advocate for a \\textit{Joint-Dataset Learning} (JDL) protocol to alleviate the Fine-tuning Gap. Additionally, an error analysis is conducted to identify three major categories and 13 subcategories of challenges in long-tailed scene text, upon which we propose a Long-Tailed Benchmark (LTB). LTB facilitates a comprehensive evaluation of ability to handle a diverse range of long-tailed challenges. We further introduce MAEDet, a self-supervised learning-based method, as a strong baseline for LTB. The code is available at https://github.com/pd162/LTB.","authors":["Tianjiao Cao","Jiahao Lyu","Weichao Zeng","Weimin Mu","Yu Zhou"],"url":"https://arxiv.org/abs/2505.15649"}
{"created":"2025-05-22","title":"Breaking Barriers for Distributed MIS by Faster Degree Reduction","abstract":"We study the problem of finding a maximal independent set (MIS) in the standard LOCAL model of distributed computing. Classical algorithms by Luby [JACM'86] and Alon, Babai, and Itai [JALG'86] find an MIS in $O(\\log n)$ rounds in $n$-node graphs with high probability. Despite decades of research, the existence of any $o(\\log n)$-round algorithm for general graphs remains one of the major open problems in the field.","authors":["Seri Khoury","Aaron Schild"],"url":"https://arxiv.org/abs/2505.15652"}
{"created":"2025-05-22","title":"Round Elimination via Self-Reduction: Closing Gaps for Distributed Maximal Matching","abstract":"In this work, we present an $\\Omega\\left(\\min\\{\\log \\Delta, \\sqrt{\\log n}\\}\\right)$ lower bound for Maximal Matching (MM) in $\\Delta$-ary trees against randomized algorithms. By a folklore reduction, the same lower bound applies to Maximal Independent Set (MIS), albeit not in trees. As a function of $n$, this is the first advancement in our understanding of the randomized complexity of the two problems in more than two decades. As a function of $\\Delta$, this shows that the current upper bounds are optimal for a wide range of $\\Delta \\in 2^{O(\\sqrt{\\log n})}$, answering an open question by Balliu, Brandt, Hirvonen, Olivetti, Rabie, and Suomela [FOCS'19, JACM'21].","authors":["Seri Khoury","Aaron Schild"],"url":"https://arxiv.org/abs/2505.15654"}
{"created":"2025-05-22","title":"First-order transducibility among classes of sparse graphs","abstract":"We prove several negative results about first-order transducibility for classes of sparse graphs:","authors":["Jakub Gajarsk\\'y","Jeremi G{\\l}adkowski","Jan Jedelsk\\'y","Micha{\\l} Pilipczuk","Szymon Toru\\'nczyk"],"url":"https://arxiv.org/abs/2505.15655"}
{"created":"2025-05-22","title":"Be Careful When Fine-tuning On Open-Source LLMs: Your Fine-tuning Data Could Be Secretly Stolen!","abstract":"Fine-tuning on open-source Large Language Models (LLMs) with proprietary data is now a standard practice for downstream developers to obtain task-specific LLMs. Surprisingly, we reveal a new and concerning risk along with the practice: the creator of the open-source LLMs can later extract the private downstream fine-tuning data through simple backdoor training, only requiring black-box access to the fine-tuned downstream model. Our comprehensive experiments, across 4 popularly used open-source models with 3B to 32B parameters and 2 downstream datasets, suggest that the extraction performance can be strikingly high: in practical settings, as much as 76.3% downstream fine-tuning data (queries) out of a total 5,000 samples can be perfectly extracted, and the success rate can increase to 94.9% in more ideal settings. We also explore a detection-based defense strategy but find it can be bypassed with improved attack. Overall, we highlight the emergency of this newly identified data breaching risk in fine-tuning, and we hope that more follow-up research could push the progress of addressing this concerning risk. The code and data used in our experiments are released at https://github.com/thu-coai/Backdoor-Data-Extraction.","authors":["Zhexin Zhang","Yuhao Sun","Junxiao Yang","Shiyao Cui","Hongning Wang","Minlie Huang"],"url":"https://arxiv.org/abs/2505.15656"}
{"created":"2025-05-22","title":"LCDB 1.1: A Database Illustrating Learning Curves Are More Ill-Behaved Than Previously Thought","abstract":"Sample-wise learning curves plot performance versus training set size. They are useful for studying scaling laws and speeding up hyperparameter tuning and model selection. Learning curves are often assumed to be well-behaved: monotone (i.e. improving with more data) and convex. By constructing the Learning Curves Database 1.1 (LCDB 1.1), a large-scale database with high-resolution learning curves, we show that learning curves are less often well-behaved than previously thought. Using statistically rigorous methods, we observe significant ill-behavior in approximately 14% of the learning curves, almost twice as much as in previous estimates. We also identify which learners are to blame and show that specific learners are more ill-behaved than others. Additionally, we demonstrate that different feature scalings rarely resolve ill-behavior. We evaluate the impact of ill-behavior on downstream tasks, such as learning curve fitting and model selection, and find it poses significant challenges, underscoring the relevance and potential of LCDB 1.1 as a challenging benchmark for future research.","authors":["Cheng Yan","Felix Mohr","Tom Viering"],"url":"https://arxiv.org/abs/2505.15657"}
{"created":"2025-05-22","title":"FLARE: Robot Learning with Implicit World Modeling","abstract":"We introduce $\\textbf{F}$uture $\\textbf{LA}$tent $\\textbf{RE}$presentation Alignment ($\\textbf{FLARE}$), a novel framework that integrates predictive latent world modeling into robot policy learning. By aligning features from a diffusion transformer with latent embeddings of future observations, $\\textbf{FLARE}$ enables a diffusion transformer policy to anticipate latent representations of future observations, allowing it to reason about long-term consequences while generating actions. Remarkably lightweight, $\\textbf{FLARE}$ requires only minimal architectural modifications -- adding a few tokens to standard vision-language-action (VLA) models -- yet delivers substantial performance gains. Across two challenging multitask simulation imitation learning benchmarks spanning single-arm and humanoid tabletop manipulation, $\\textbf{FLARE}$ achieves state-of-the-art performance, outperforming prior policy learning baselines by up to 26%. Moreover, $\\textbf{FLARE}$ unlocks the ability to co-train with human egocentric video demonstrations without action labels, significantly boosting policy generalization to a novel object with unseen geometry with as few as a single robot demonstration. Our results establish $\\textbf{FLARE}$ as a general and scalable approach for combining implicit world modeling with high-frequency robotic control.","authors":["Ruijie Zheng","Jing Wang","Scott Reed","Johan Bjorck","Yu Fang","Fengyuan Hu","Joel Jang","Kaushil Kundalia","Zongyu Lin","Loic Magne","Avnish Narayan","You Liang Tan","Guanzhi Wang","Qi Wang","Jiannan Xiang","Yinzhen Xu","Seonghyeon Ye","Jan Kautz","Furong Huang","Yuke Zhu","Linxi Fan"],"url":"https://arxiv.org/abs/2505.15659"}
{"created":"2025-05-22","title":"Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization","abstract":"The generalization capabilities of vision-language-action (VLA) models to unseen tasks are crucial to achieving general-purpose robotic manipulation in open-world settings. However, the cross-task generalization capabilities of existing VLA models remain significantly underexplored. To address this gap, we introduce AGNOSTOS, a novel simulation benchmark designed to rigorously evaluate cross-task zero-shot generalization in manipulation. AGNOSTOS comprises 23 unseen manipulation tasks for testing, distinct from common training task distributions, and incorporates two levels of generalization difficulty to assess robustness. Our systematic evaluation reveals that current VLA models, despite being trained on diverse datasets, struggle to generalize effectively to these unseen tasks. To overcome this limitation, we propose Cross-Task In-Context Manipulation (X-ICM), a method that conditions large language models (LLMs) on in-context demonstrations from seen tasks to predict action sequences for unseen tasks. Additionally, we introduce a dynamics-guided sample selection strategy that identifies relevant demonstrations by capturing cross-task dynamics. On AGNOSTOS, X-ICM significantly improves cross-task zero-shot generalization performance over leading VLAs. We believe AGNOSTOS and X-ICM will serve as valuable tools for advancing general-purpose robotic manipulation.","authors":["Jiaming Zhou","Ke Ye","Jiayi Liu","Teli Ma","Zifang Wang","Ronghe Qiu","Kun-Yu Lin","Zhilin Zhao","Junwei Liang"],"url":"https://arxiv.org/abs/2505.15660"}
{"created":"2025-05-22","title":"Deep greedy unfolding: Sorting out argsorting in greedy sparse recovery algorithms","abstract":"Gradient-based learning imposes (deep) neural networks to be differentiable at all steps. This includes model-based architectures constructed by unrolling iterations of an iterative algorithm onto layers of a neural network, known as algorithm unrolling. However, greedy sparse recovery algorithms depend on the non-differentiable argsort operator, which hinders their integration into neural networks. In this paper, we address this challenge in Orthogonal Matching Pursuit (OMP) and Iterative Hard Thresholding (IHT), two popular representative algorithms in this class. We propose permutation-based variants of these algorithms and approximate permutation matrices using \"soft\" permutation matrices derived from softsort, a continuous relaxation of argsort. We demonstrate -- both theoretically and numerically -- that Soft-OMP and Soft-IHT, as differentiable counterparts of OMP and IHT and fully compatible with neural network training, effectively approximate these algorithms with a controllable degree of accuracy. This leads to the development of OMP- and IHT-Net, fully trainable network architectures based on Soft-OMP and Soft-IHT, respectively. Finally, by choosing weights as \"structure-aware\" trainable parameters, we connect our approach to structured sparse recovery and demonstrate its ability to extract latent sparsity patterns from data.","authors":["Sina Mohammad-Taheri","Matthew J. Colbrook","Simone Brugiapaglia"],"url":"https://arxiv.org/abs/2505.15661"}
{"created":"2025-05-22","title":"Graph Conditional Flow Matching for Relational Data Generation","abstract":"Data synthesis is gaining momentum as a privacy-enhancing technology. While single-table tabular data generation has seen considerable progress, current methods for multi-table data often lack the flexibility and expressiveness needed to capture complex relational structures. In particular, they struggle with long-range dependencies and complex foreign-key relationships, such as tables with multiple parent tables or multiple types of links between the same pair of tables. We propose a generative model for relational data that generates the content of a relational dataset given the graph formed by the foreign-key relationships. We do this by learning a deep generative model of the content of the whole relational database by flow matching, where the neural network trained to denoise records leverages a graph neural network to obtain information from connected records. Our method is flexible, as it can support relational datasets with complex structures, and expressive, as the generation of each record can be influenced by any other record within the same connected component. We evaluate our method on several benchmark datasets and show that it achieves state-of-the-art performance in terms of synthetic data fidelity.","authors":["Davide Scassola","Sebastiano Saccani","Luca Bortolussi"],"url":"https://arxiv.org/abs/2505.15668"}
{"created":"2025-05-22","title":"Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model","abstract":"Spoken dialogue is an intuitive form of human-computer interaction, yet current speech language models often remain constrained to turn-based exchanges, lacking real-time adaptability such as user barge-in. We propose a novel duplex speech to speech (S2S) architecture featuring continuous user inputs and codec agent outputs with channel fusion that directly models simultaneous user and agent streams. Using a pretrained streaming encoder for user input enables the first duplex S2S model without requiring speech pretrain. Separate architectures for agent and user modeling facilitate codec fine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared to previous works. Experimental results show that the proposed model outperforms previous duplex models in reasoning, turn-taking, and barge-in abilities. The model requires significantly less speech data, as speech pretrain is skipped, which markedly simplifies the process of building a duplex S2S model from any LLMs. Finally, it is the first openly available duplex S2S model with training and inference code to foster reproducibility.","authors":["Ke Hu","Ehsan Hosseini-Asl","Chen Chen","Edresson Casanova","Subhankar Ghosh","Piotr \\.Zelasko","Zhehuai Chen","Jason Li","Jagadeesh Balam","Boris Ginsburg"],"url":"https://arxiv.org/abs/2505.15670"}
{"created":"2025-05-22","title":"Enhancing Monte Carlo Dropout Performance for Uncertainty Quantification","abstract":"Knowing the uncertainty associated with the output of a deep neural network is of paramount importance in making trustworthy decisions, particularly in high-stakes fields like medical diagnosis and autonomous systems. Monte Carlo Dropout (MCD) is a widely used method for uncertainty quantification, as it can be easily integrated into various deep architectures. However, conventional MCD often struggles with providing well-calibrated uncertainty estimates. To address this, we introduce innovative frameworks that enhances MCD by integrating different search solutions namely Grey Wolf Optimizer (GWO), Bayesian Optimization (BO), and Particle Swarm Optimization (PSO) as well as an uncertainty-aware loss function, thereby improving the reliability of uncertainty quantification. We conduct comprehensive experiments using different backbones, namely DenseNet121, ResNet50, and VGG16, on various datasets, including Cats vs. Dogs, Myocarditis, Wisconsin, and a synthetic dataset (Circles). Our proposed algorithm outperforms the MCD baseline by 2-3% on average in terms of both conventional accuracy and uncertainty accuracy while achieving significantly better calibration. These results highlight the potential of our approach to enhance the trustworthiness of deep learning models in safety-critical applications.","authors":["Hamzeh Asgharnezhad","Afshar Shamsi","Roohallah Alizadehsani","Arash Mohammadi","Hamid Alinejad-Rokny"],"url":"https://arxiv.org/abs/2505.15671"}
{"created":"2025-05-22","title":"UniErase: Unlearning Token as a Universal Erasure Primitive for Language Models","abstract":"Large language models require iterative updates to address challenges such as knowledge conflicts and outdated information (e.g., incorrect, private, or illegal contents). Machine unlearning provides a systematic methodology for targeted knowledge removal from trained models, enabling elimination of sensitive information influences. However, mainstream fine-tuning-based unlearning methods often fail to balance unlearning efficacy and model ability, frequently resulting in catastrophic model collapse under extensive knowledge removal. Meanwhile, in-context unlearning, which relies solely on contextual prompting without modifying the model's intrinsic mechanisms, suffers from limited generalizability and struggles to achieve true unlearning. In this work, we introduce UniErase, a novel unlearning paradigm that employs learnable parametric suffix (unlearning token) to steer language models toward targeted forgetting behaviors. UniErase operates through two key phases: (I) an optimization stage that binds desired unlearning outputs to the model's autoregressive probability distribution via token optimization, followed by (II) a lightweight model editing phase that activates the learned token to probabilistically induce specified forgetting objective. Serving as a new research direction for token learning to induce unlearning target, UniErase achieves state-of-the-art (SOTA) performance across batch, sequential, and precise unlearning under fictitious and real-world knowledge settings. Remarkably, in terms of TOFU benchmark, UniErase, modifying only around 3.66% of the LLM parameters, outperforms previous forgetting SOTA baseline by around 4.01 times for model ability with even better unlearning efficacy. Similarly, UniErase, maintaining more ability, also surpasses previous retaining SOTA by 35.96% for unlearning efficacy, showing dual top-tier performances in current unlearing domain.","authors":["Miao Yu","Liang Lin","Guibin Zhang","Xinfeng Li","Junfeng Fang","Ningyu Zhang","Kun Wang","Yang Wang"],"url":"https://arxiv.org/abs/2505.15674"}
{"created":"2025-05-22","title":"SwarmDiff: Swarm Robotic Trajectory Planning in Cluttered Environments via Diffusion Transformer","abstract":"Swarm robotic trajectory planning faces challenges in computational efficiency, scalability, and safety, particularly in complex, obstacle-dense environments. To address these issues, we propose SwarmDiff, a hierarchical and scalable generative framework for swarm robots. We model the swarm's macroscopic state using Probability Density Functions (PDFs) and leverage conditional diffusion models to generate risk-aware macroscopic trajectory distributions, which then guide the generation of individual robot trajectories at the microscopic level. To ensure a balance between the swarm's optimal transportation and risk awareness, we integrate Wasserstein metrics and Conditional Value at Risk (CVaR). Additionally, we introduce a Diffusion Transformer (DiT) to improve sampling efficiency and generation quality by capturing long-range dependencies. Extensive simulations and real-world experiments demonstrate that SwarmDiff outperforms existing methods in computational efficiency, trajectory validity, and scalability, making it a reliable solution for swarm robotic trajectory planning.","authors":["Kang Ding","Chunxuan Jiao","Yunze Hu","Kangjie Zhou","Pengying Wu","Yao Mu","Chang Liu"],"url":"https://arxiv.org/abs/2505.15679"}
{"created":"2025-05-22","title":"The Representational Alignment between Humans and Language Models is implicitly driven by a Concreteness Effect","abstract":"The nouns of our language refer to either concrete entities (like a table) or abstract concepts (like justice or love), and cognitive psychology has established that concreteness influences how words are processed. Accordingly, understanding how concreteness is represented in our mind and brain is a central question in psychology, neuroscience, and computational linguistics. While the advent of powerful language models has allowed for quantitative inquiries into the nature of semantic representations, it remains largely underexplored how they represent concreteness. Here, we used behavioral judgments to estimate semantic distances implicitly used by humans, for a set of carefully selected abstract and concrete nouns. Using Representational Similarity Analysis, we find that the implicit representational space of participants and the semantic representations of language models are significantly aligned. We also find that both representational spaces are implicitly aligned to an explicit representation of concreteness, which was obtained from our participants using an additional concreteness rating task. Importantly, using ablation experiments, we demonstrate that the human-to-model alignment is substantially driven by concreteness, but not by other important word characteristics established in psycholinguistics. These results indicate that humans and language models converge on the concreteness dimension, but not on other dimensions.","authors":["Cosimo Iaia","Bhavin Choksi","Emily Wiebers","Gemma Roig","Christian J. Fiebach"],"url":"https://arxiv.org/abs/2505.15682"}
{"created":"2025-05-22","title":"A Federated Splitting Framework for LLMs: Security, Efficiency, and Adaptability","abstract":"Private data is typically larger and of higher quality than public data, offering great potential to improve LLM. However, its scattered distribution across data silos and the high computational demands of LLMs limit their deployment in federated environments. To address this, the transformer-based split learning model has emerged, offloading most model parameters to the server while retaining only the embedding and output layers on clients to ensure privacy. However, it still faces significant challenges in security, efficiency, and adaptability: 1) embedding gradients are vulnerable to attacks, leading to reverse engineering of private data; 2) the autoregressive nature of LLMs means that federated split learning can only train and infer sequentially, causing high communication overhead; 3) fixed partition points lack adaptability to downstream tasks. In this paper, we introduce FL-LLaMA, a secure, efficient, and adaptive federated split framework based on LLaMA2. First, we place some input and output blocks on the local client and inject Gaussian noise into forward-pass hidden states, enabling secure end-to-end propagation. Second, we employ client-batch and server-hierarchical strategies to achieve parallel training, along with attention-mask compression and KV cache mechanisms to accelerate inference, reducing communication costs effectively. Third, we allow users to dynamically adjust the partition points for input/output blocks based on specific task requirements and hardware limitations. Experiments on NLU, summarization and conversational QA tasks show that FL-LLaMA maintains performance comparable to centralized LLaMA2, and achieves up to 2x train speedups and 8x inference speedups. Further analysis of privacy attacks and different partition points also demonstrates the effectiveness of FL-LLaMA in security and adaptability.","authors":["Zishuai Zhang","Hainan Zhang","Jiaying Zheng","Ziwei Wang","Yongxin Tong","Jin Dong","Zhiming Zheng"],"url":"https://arxiv.org/abs/2505.15683"}
{"created":"2025-05-22","title":"ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy","abstract":"While Chain-of-Thought (CoT) prompting improves reasoning in large language models (LLMs), the excessive length of reasoning tokens increases latency and KV cache memory usage, and may even truncate final answers under context limits. We propose ThinkLess, an inference-efficient framework that terminates reasoning generation early and maintains output quality without modifying the model. Atttention analysis reveals that answer tokens focus minimally on earlier reasoning steps and primarily attend to the reasoning terminator token, due to information migration under causal masking. Building on this insight, ThinkLess inserts the terminator token at earlier positions to skip redundant reasoning while preserving the underlying knowledge transfer. To prevent format discruption casued by early termination, ThinkLess employs a lightweight post-regulation mechanism, relying on the model's natural instruction-following ability to produce well-structured answers. Without fine-tuning or auxiliary data, ThinkLess achieves comparable accuracy to full-length CoT decoding while greatly reducing decoding time and memory consumption.","authors":["Gengyang Li","Yifeng Gao","Yuming Li","Yunfang Wu"],"url":"https://arxiv.org/abs/2505.15684"}
{"created":"2025-05-22","title":"From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems","abstract":"Foundation models (FMs) are increasingly used to bridge language and action in embodied agents, yet the operational characteristics of different FM integration strategies remain under-explored -- particularly for complex instruction following and versatile action generation in changing environments. This paper examines three paradigms for building robotic systems: end-to-end vision-language-action (VLA) models that implicitly integrate perception and planning, and modular pipelines incorporating either vision-language models (VLMs) or multimodal large language models (LLMs). We evaluate these paradigms through two focused case studies: a complex instruction grounding task assessing fine-grained instruction understanding and cross-modal disambiguation, and an object manipulation task targeting skill transfer via VLA finetuning. Our experiments in zero-shot and few-shot settings reveal trade-offs in generalization and data efficiency. By exploring performance limits, we distill design implications for developing language-driven physical agents and outline emerging challenges and opportunities for FM-powered robotics in real-world conditions.","authors":["Xiuchao Sui","Daiying Tian","Qi Sun","Ruirui Chen","Dongkyu Choi","Kenneth Kwok","Soujanya Poria"],"url":"https://arxiv.org/abs/2505.15685"}
{"created":"2025-05-22","title":"Path Planning Algorithm Comparison Analysis for Wireless AUVs Energy Sharing System","abstract":"Autonomous underwater vehicles (AUVs) are increasingly used in marine research, military applications, and undersea exploration. However, their operational range is significantly affected by battery performance. In this paper, a framework for a wireless energy sharing system among AUVs is proposed, enabling rapid energy replenishment. Path planning plays a crucial role in the energy-sharing process and autonomous navigation, as it must generate feasible trajectories toward designated goals. This article focuses on efficient obstacle avoidance in complex underwater environments, including irregularly shaped obstacles and narrow passages. The proposed method combines Rapidly-exploring Random Trees Star (RRT*) with Particle Swarm Optimization (PSO) to improve path planning efficiency. Comparative analysis of the two algorithms is presented through simulation results in both random and irregular obstacle environments. Index Terms: Wireless charging, autonomous underwater vehicles (AUVs), path planning, irregular obstacles, narrow passages, RRT*, particle swarm optimization (PSO).","authors":["Zhengji Feng","Hengxiang Chen","Liqun Chen","Heyan Li","Xiaolin Mou"],"url":"https://arxiv.org/abs/2505.15686"}
{"created":"2025-05-22","title":"Discovering Pathology Rationale and Token Allocation for Efficient Multimodal Pathology Reasoning","abstract":"Multimodal pathological image understanding has garnered widespread interest due to its potential to improve diagnostic accuracy and enable personalized treatment through integrated visual and textual data. However, existing methods exhibit limited reasoning capabilities, which hamper their ability to handle complex diagnostic scenarios. Additionally, the enormous size of pathological images leads to severe computational burdens, further restricting their practical deployment. To address these limitations, we introduce a novel bilateral reinforcement learning framework comprising two synergistic branches. One reinforcement branch enhances the reasoning capability by enabling the model to learn task-specific decision processes, i.e., pathology rationales, directly from labels without explicit reasoning supervision. While the other branch dynamically allocates a tailored number of tokens to different images based on both their visual content and task context, thereby optimizing computational efficiency. We apply our method to various pathological tasks such as visual question answering, cancer subtyping, and lesion detection. Extensive experiments show an average +41.7 absolute performance improvement with 70.3% lower inference costs over the base models, achieving both reasoning accuracy and computational efficiency.","authors":["Zhe Xu","Cheng Jin","Yihui Wang","Ziyi Liu","Hao Chen"],"url":"https://arxiv.org/abs/2505.15687"}
{"created":"2025-05-22","title":"A packing lemma for VCN${}_k$-dimension and learning high-dimensional data","abstract":"Recently, the authors introduced the theory of high-arity PAC learning, which is well-suited for learning graphs, hypergraphs and relational structures. In the same initial work, the authors proved a high-arity analogue of the Fundamental Theorem of Statistical Learning that almost completely characterizes all notions of high-arity PAC learning in terms of a combinatorial dimension, called the Vapnik--Chervonenkis--Natarajan (VCN${}_k$) $k$-dimension, leaving as an open problem only the characterization of non-partite, non-agnostic high-arity PAC learnability.","authors":["Leonardo N. Coregliano","Maryanthe Malliaris"],"url":"https://arxiv.org/abs/2505.15688"}
{"created":"2025-05-22","title":"Toward Open Earth Science as Fast and Accessible as Natural Language","abstract":"Is natural-language-driven earth observation data analysis now feasible with the assistance of Large Language Models (LLMs)? For open science in service of public interest, feasibility requires reliably high accuracy, interactive latencies, low (sustainable) costs, open LLMs, and openly maintainable software -- hence, the challenge. What are the techniques and programming system requirements necessary for satisfying these constraints, and what is the corresponding development and maintenance burden in practice? This study lays the groundwork for exploring these questions, introducing an impactful earth science use-case, and providing a software framework with evaluation data and metrics, along with initial results from employing model scaling, prompt-optimization, and inference-time scaling optimization techniques. While we attain high accuracy (near 100%) across 10 of 11 metrics, the analysis further considers cost (token-spend), latency, and maintainability across this space of techniques. Finally, we enumerate opportunities for further research, general programming and evaluation framework development, and ongoing work for a comprehensive, deployable solution. This is a call for collaboration and contribution.","authors":["Marquita Ellis","Iksha Gurung","Muthukumaran Ramasubramanian","Rahul Ramachandran"],"url":"https://arxiv.org/abs/2505.15690"}
{"created":"2025-05-22","title":"Thought-Augmented Policy Optimization: Bridging External Guidance and Internal Capabilities","abstract":"Reinforcement learning (RL) has emerged as an effective method for training reasoning models. However, existing RL approaches typically bias the model's output distribution toward reward-maximizing paths without introducing external knowledge. This limits their exploration capacity and results in a narrower reasoning capability boundary compared to base models. To address this limitation, we propose TAPO (Thought-Augmented Policy Optimization), a novel framework that augments RL by incorporating external high-level guidance (\"thought patterns\"). By adaptively integrating structured thoughts during training, TAPO effectively balances model-internal exploration and external guidance exploitation. Extensive experiments show that our approach significantly outperforms GRPO by 99% on AIME, 41% on AMC, and 17% on Minerva Math. Notably, these high-level thought patterns, abstracted from only 500 prior samples, generalize effectively across various tasks and models. This highlights TAPO's potential for broader applications across multiple tasks and domains. Our further analysis reveals that introducing external guidance produces powerful reasoning models with superior explainability of inference behavior and enhanced output readability.","authors":["Jinyang Wu","Chonghua Liao","Mingkuan Feng","Shuai Zhang","Zhengqi Wen","Pengpeng Shao","Huazhe Xu","Jianhua Tao"],"url":"https://arxiv.org/abs/2505.15692"}
{"created":"2025-05-22","title":"Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives","abstract":"Recent advances in reinforcement learning (RL) have renewed focus on the design of reward functions that shape agent behavior. Manually designing reward functions is tedious and error-prone. A principled alternative is to specify behaviors in a formal language that can be automatically translated into rewards. Omega-regular languages are a natural choice for this purpose, given their established role in formal verification and synthesis. However, existing methods using omega-regular specifications typically rely on discounted reward RL in episodic settings, with periodic resets. This setup misaligns with the semantics of omega-regular specifications, which describe properties over infinite behavior traces. In such cases, the average reward criterion and the continuing setting -- where the agent interacts with the environment over a single, uninterrupted lifetime -- are more appropriate.","authors":["Milad Kazemi","Mateo Perez","Fabio Somenzi","Sadegh Soudjani","Ashutosh Trivedi","Alvaro Velasquez"],"url":"https://arxiv.org/abs/2505.15693"}
{"created":"2025-05-22","title":"A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO","abstract":"In this paper, we theoretically investigate the effects of noisy labels in offline alignment, with a focus on the interplay between privacy and robustness against adversarial corruption. Specifically, under linear modeling assumptions, we present a unified analysis covering both reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) under different privacy-corruption scenarios, such as Local differential privacy-then-Corruption (LTC), where human preference labels are privatized before being corrupted by an adversary, and Corruption-then-Local differential privacy (CTL), where labels are corrupted before privacy protection. Our analysis leverages a reduction framework that reduces the offline alignment problem under linear modeling assumptions to parameter estimation in logistic regression. This framework allows us to establish an interesting separation result between LTC and CTL, demonstrating that LTC presents a greater challenge than CTL in offline alignment, even under linear models. As important by-products, our findings also advance the state-of-the-art theoretical results in offline alignment under privacy-only or corruption-only scenarios.","authors":["Xingyu Zhou","Yulian Wu","Francesco Orabona"],"url":"https://arxiv.org/abs/2505.15694"}
{"created":"2025-05-22","title":"Can Large Language Models be Effective Online Opinion Miners?","abstract":"The surge of user-generated online content presents a wealth of insights into customer preferences and market trends. However, the highly diverse, complex, and context-rich nature of such contents poses significant challenges to traditional opinion mining approaches. To address this, we introduce Online Opinion Mining Benchmark (OOMB), a novel dataset and evaluation protocol designed to assess the ability of large language models (LLMs) to mine opinions effectively from diverse and intricate online environments. OOMB provides extensive (entity, feature, opinion) tuple annotations and a comprehensive opinion-centric summary that highlights key opinion topics within each content, thereby enabling the evaluation of both the extractive and abstractive capabilities of models. Through our proposed benchmark, we conduct a comprehensive analysis of which aspects remain challenging and where LLMs exhibit adaptability, to explore whether they can effectively serve as opinion miners in realistic online scenarios. This study lays the foundation for LLM-based opinion mining and discusses directions for future research in this field.","authors":["Ryang Heo","Yongsik Seo","Junseong Lee","Dongha Lee"],"url":"https://arxiv.org/abs/2505.15695"}
{"created":"2025-05-22","title":"MaxPoolBERT: Enhancing BERT Classification via Layer- and Token-Wise Aggregation","abstract":"The [CLS] token in BERT is commonly used as a fixed-length representation for classification tasks, yet prior work has shown that both other tokens and intermediate layers encode valuable contextual information. In this work, we propose MaxPoolBERT, a lightweight extension to BERT that refines the [CLS] representation by aggregating information across layers and tokens. Specifically, we explore three modifications: (i) max-pooling the [CLS] token across multiple layers, (ii) enabling the [CLS] token to attend over the entire final layer using an additional multi-head attention (MHA) layer, and (iii) combining max-pooling across the full sequence with MHA. Our approach enhances BERT's classification accuracy (especially on low-resource tasks) without requiring pre-training or significantly increasing model size. Experiments on the GLUE benchmark show that MaxPoolBERT consistently achieves a better performance on the standard BERT-base model.","authors":["Maike Behrendt","Stefan Sylvius Wagner","Stefan Harmeling"],"url":"https://arxiv.org/abs/2505.15696"}
{"created":"2025-05-22","title":"Long LEM Query in BWT-Runs Space","abstract":"In this paper, we describe a new type of match between a pattern and a text that aren't necessarily maximal in the query, but still contain useful matching information: locally maximal exact matches (LEMs). There are usually a large amount of LEMs, so we only consider those above some length threshold $\\mathcal{L}$. These are referred to as long LEMs. The purpose of long LEMs is to capture substring matches between a query and a text that are not necessarily maximal in the pattern but still long enough to be important. Therefore efficient long LEMs finding algorithms are desired for these datasets. However, these datasets are too large to query on traditional string indexes. Fortunately, these datasets are very repetitive. Recently, compressed string indexes that take advantage of the redundancy in the data but retain efficient querying capability have been proposed as a solution. We therefore give an efficient algorithm for computing all the long LEMs of a query and a text in a BWT runs compressed string index. We describe an $O(m+occ)$ expected time algorithm that relies on an $O(r)$ words space string index for outputting all long LEMs of a pattern with respect to a text given the matching statistics of the pattern with respect to the text. Here $m$ is the length of the query, $occ$ is the number of long LEMs outputted, and $r$ is the number of runs in the BWT of the text. The $O(r)$ space string index we describe relies on an adaptation of the move data structure by Nishimoto and Tabei. We are able to support $LCP[i]$ queries in constant time given $SA[i]$. In other words, we answer $PLCP[i]$ queries in constant time. Long LEMs may provide useful similarity information between a pattern and a text that MEMs may ignore. This information is particularly useful in pangenome and biobank scale haplotype panel contexts.","authors":["Ahsan Sanaullah","Degui Zhi","Shaojie Zhang"],"url":"https://arxiv.org/abs/2505.15698"}
{"created":"2025-05-22","title":"Families of tractable problems with respect to vertex-interval-membership width and its generalisations","abstract":"Temporal graphs are graphs whose edges are labelled with times at which they are active. Their time-sensitivity provides a useful model of real networks, but renders many problems studied on temporal graphs more computationally complex than their static counterparts. To contend with this, there has been recent work devising parameters for which temporal problems become tractable. One such parameter is vertex-interval-membership width. Broadly, this gives a bound on the number of vertices we need to keep track of at any time in order to solve any of a family of problems. Our contributions are two-fold. Firstly, we introduce a new parameter, tree-interval-membership-width, that generalises both vertex-interval-membership-width and several existing generalisations. Secondly, we provide meta-algorithms for both parameters which can be used to prove fixed-parameter-tractability for large families of problems, bypassing the need to give involved dynamic programming arguments for every problem. We apply these algorithms to temporal versions of Hamiltonian path, matching, edge deletion to limit maximum reachability, and firefighting.","authors":["Jessica Enright","Samuel D. Hand","Laura Larios-Jones","Kitty Meeks"],"url":"https://arxiv.org/abs/2505.15699"}
{"created":"2025-05-22","title":"\"Alexa, can you forget me?\" Machine Unlearning Benchmark in Spoken Language Understanding","abstract":"Machine unlearning, the process of efficiently removing specific information from machine learning models, is a growing area of interest for responsible AI. However, few studies have explored the effectiveness of unlearning methods on complex tasks, particularly speech-related ones. This paper introduces UnSLU-BENCH, the first benchmark for machine unlearning in spoken language understanding (SLU), focusing on four datasets spanning four languages. We address the unlearning of data from specific speakers as a way to evaluate the quality of potential \"right to be forgotten\" requests. We assess eight unlearning techniques and propose a novel metric to simultaneously better capture their efficacy, utility, and efficiency. UnSLU-BENCH sets a foundation for unlearning in SLU and reveals significant differences in the effectiveness and computational feasibility of various techniques.","authors":["Alkis Koudounas","Claudio Savelli","Flavio Giobergia","Elena Baralis"],"url":"https://arxiv.org/abs/2505.15700"}
{"created":"2025-05-22","title":"HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases","abstract":"Large Language Models (LLMs) have demonstrated their potential in hardware design tasks, such as Hardware Description Language (HDL) generation and debugging. Yet, their performance in real-world, repository-level HDL projects with thousands or even tens of thousands of code lines is hindered. To this end, we propose HDLxGraph, a novel framework that integrates Graph Retrieval Augmented Generation (Graph RAG) with LLMs, introducing HDL-specific graph representations by incorporating Abstract Syntax Trees (ASTs) and Data Flow Graphs (DFGs) to capture both code graph view and hardware graph view. HDLxGraph utilizes a dual-retrieval mechanism that not only mitigates the limited recall issues inherent in similarity-based semantic retrieval by incorporating structural information, but also enhances its extensibility to various real-world tasks by a task-specific retrieval finetuning. Additionally, to address the lack of comprehensive HDL search benchmarks, we introduce HDLSearch, a multi-granularity evaluation dataset derived from real-world repository-level projects. Experimental results demonstrate that HDLxGraph significantly improves average search accuracy, debugging efficiency and completion quality by 12.04%, 12.22% and 5.04% compared to similarity-based RAG, respectively. The code of HDLxGraph and collected HDLSearch benchmark are available at https://github.com/Nick-Zheng-Q/HDLxGraph.","authors":["Pingqing Zheng (Katie)","Jiayin Qin (Katie)","Fuqi Zhang (Katie)","Shang Wu (Katie)","Yu Cao (Katie)","Caiwen Ding (Katie)","Yang (Katie)","Zhao"],"url":"https://arxiv.org/abs/2505.15701"}
{"created":"2025-05-22","title":"LyapLock: Bounded Knowledge Preservation in Sequential Large Language Model Editing","abstract":"Large Language Models often contain factually incorrect or outdated knowledge, giving rise to model editing methods for precise knowledge updates. However, current mainstream locate-then-edit approaches exhibit a progressive performance decline during sequential editing, due to inadequate mechanisms for long-term knowledge preservation. To tackle this, we model the sequential editing as a constrained stochastic programming. Given the challenges posed by the cumulative preservation error constraint and the gradually revealed editing tasks, \\textbf{LyapLock} is proposed. It integrates queuing theory and Lyapunov optimization to decompose the long-term constrained programming into tractable stepwise subproblems for efficient solving. This is the first model editing framework with rigorous theoretical guarantees, achieving asymptotic optimal editing performance while meeting the constraints of long-term knowledge preservation. Experimental results show that our framework scales sequential editing capacity to over 10,000 edits while stabilizing general capabilities and boosting average editing efficacy by 11.89\\% over SOTA baselines. Furthermore, it can be leveraged to enhance the performance of baseline methods. Our code is released on https://github.com/caskcsg/LyapLock.","authors":["Peng Wang","Biyu Zhou","Xuehai Tang","Jizhong Han","Songlin Hu"],"url":"https://arxiv.org/abs/2505.15702"}
{"created":"2025-05-22","title":"HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning","abstract":"Motion forecasting represents a critical challenge in autonomous driving systems, requiring accurate prediction of surrounding agents' future trajectories. While existing approaches predict future motion states with the extracted scene context feature from historical agent trajectories and road layouts, they suffer from the information degradation during the scene feature encoding. To address the limitation, we propose HAMF, a novel motion forecasting framework that learns future motion representations with the scene context encoding jointly, to coherently combine the scene understanding and future motion state prediction. We first embed the observed agent states and map information into 1D token sequences, together with the target multi-modal future motion features as a set of learnable tokens. Then we design a unified Attention-based encoder, which synergistically combines self-attention and cross-attention mechanisms to model the scene context information and aggregate future motion features jointly. Complementing the encoder, we implement the Mamba module in the decoding stage to further preserve the consistency and correlations among the learned future motion representations, to generate the accurate and diverse final trajectories. Extensive experiments on Argoverse 2 benchmark demonstrate that our hybrid Attention-Mamba model achieves state-of-the-art motion forecasting performance with the simple and lightweight architecture.","authors":["Xiaodong Mei","Sheng Wang","Jie Cheng","Yingbing Chen","Dan Xu"],"url":"https://arxiv.org/abs/2505.15703"}
{"created":"2025-05-22","title":"Advancing LLM Safe Alignment with Safety Representation Ranking","abstract":"The rapid advancement of large language models (LLMs) has demonstrated milestone success in a variety of tasks, yet their potential for generating harmful content has raised significant safety concerns. Existing safety evaluation approaches typically operate directly on textual responses, overlooking the rich information embedded in the model's internal representations. In this paper, we propose Safety Representation Ranking (SRR), a listwise ranking framework that selects safe responses using hidden states from the LLM itself. SRR encodes both instructions and candidate completions using intermediate transformer representations and ranks candidates via a lightweight similarity-based scorer. Our approach directly leverages internal model states and supervision at the list level to capture subtle safety signals. Experiments across multiple benchmarks show that SRR significantly improves robustness to adversarial prompts. Our code will be available upon publication.","authors":["Tianqi Du","Zeming Wei","Quan Chen","Chenheng Zhang","Yisen Wang"],"url":"https://arxiv.org/abs/2505.15710"}
{"created":"2025-05-22","title":"TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games","abstract":"This paper introduces TurnaboutLLM, a novel framework and dataset for evaluating the deductive reasoning abilities of Large Language Models (LLMs) by leveraging the interactive gameplay of detective games Ace Attorney and Danganronpa. The framework tasks LLMs with identifying contradictions between testimonies and evidences within long narrative contexts, a challenging task due to the large answer space and diverse reasoning types presented by its questions. We evaluate twelve state-of-the-art LLMs on the dataset, hinting at limitations of popular strategies for enhancing deductive reasoning such as extensive thinking and Chain-of-Thought prompting. The results also suggest varying effects of context size, the number of reasoning step and answer space size on model performance. Overall, TurnaboutLLM presents a substantial challenge for LLMs' deductive reasoning abilities in complex, narrative-rich environments.","authors":["Yuan Yuan","Muyu He","Muhammad Adil Shahid","Jiani Huang","Ziyang Li","Li Zhang"],"url":"https://arxiv.org/abs/2505.15712"}
{"created":"2025-05-22","title":"Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models for Mental Health Counseling","abstract":"Large language models (LLMs) hold significant potential for mental health support, capable of generating empathetic responses and simulating therapeutic conversations. However, existing LLM-based approaches often lack the clinical grounding necessary for real-world psychological counseling, particularly in explicit diagnostic reasoning aligned with standards like the DSM/ICD and incorporating diverse therapeutic modalities beyond basic empathy or single strategies. To address these critical limitations, we propose PsyLLM, the first large language model designed to systematically integrate both diagnostic and therapeutic reasoning for mental health counseling. To develop the PsyLLM, we propose a novel automated data synthesis pipeline. This pipeline processes real-world mental health posts, generates multi-turn dialogue structures, and leverages LLMs guided by international diagnostic standards (e.g., DSM/ICD) and multiple therapeutic frameworks (e.g., CBT, ACT, psychodynamic) to simulate detailed clinical reasoning processes. Rigorous multi-dimensional filtering ensures the generation of high-quality, clinically aligned dialogue data. In addition, we introduce a new benchmark and evaluation protocol, assessing counseling quality across four key dimensions: comprehensiveness, professionalism, authenticity, and safety. Our experiments demonstrate that PsyLLM significantly outperforms state-of-the-art baseline models on this benchmark.","authors":["He Hu","Yucheng Zhou","Juzheng Si","Qianning Wang","Hengheng Zhang","Fuji Ren","Fei Ma","Laizhong Cui"],"url":"https://arxiv.org/abs/2505.15715"}
{"created":"2025-05-22","title":"Privacy-Preserving Conformal Prediction Under Local Differential Privacy","abstract":"Conformal prediction (CP) provides sets of candidate classes with a guaranteed probability of containing the true class. However, it typically relies on a calibration set with clean labels. We address privacy-sensitive scenarios where the aggregator is untrusted and can only access a perturbed version of the true labels. We propose two complementary approaches under local differential privacy (LDP). In the first approach, users do not access the model but instead provide their input features and a perturbed label using a k-ary randomized response. In the second approach, which enforces stricter privacy constraints, users add noise to their conformity score by binary search response. This method requires access to the classification model but preserves both data and label privacy. Both approaches compute the conformal threshold directly from noisy data without accessing the true labels. We prove finite-sample coverage guarantees and demonstrate robust coverage even under severe randomization. This approach unifies strong local privacy with predictive uncertainty control, making it well-suited for sensitive applications such as medical imaging or large language model queries, regardless of whether users can (or are willing to) compute their own scores.","authors":["Coby Penso","Bar Mahpud","Jacob Goldberger","Or Sheffet"],"url":"https://arxiv.org/abs/2505.15721"}
{"created":"2025-05-22","title":"Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities","abstract":"We present the first comprehensive study of Memorization in Multilingual Large Language Models (MLLMs), analyzing 95 languages using models across diverse model scales, architectures, and memorization definitions. As MLLMs are increasingly deployed, understanding their memorization behavior has become critical. Yet prior work has focused primarily on monolingual models, leaving multilingual memorization underexplored, despite the inherently long-tailed nature of training corpora. We find that the prevailing assumption, that memorization is highly correlated with training data availability, fails to fully explain memorization patterns in MLLMs. We hypothesize that treating languages in isolation - ignoring their similarities - obscures the true patterns of memorization. To address this, we propose a novel graph-based correlation metric that incorporates language similarity to analyze cross-lingual memorization. Our analysis reveals that among similar languages, those with fewer training tokens tend to exhibit higher memorization, a trend that only emerges when cross-lingual relationships are explicitly modeled. These findings underscore the importance of a language-aware perspective in evaluating and mitigating memorization vulnerabilities in MLLMs. This also constitutes empirical evidence that language similarity both explains Memorization in MLLMs and underpins Cross-lingual Transferability, with broad implications for multilingual NLP.","authors":["Xiaoyu Luo","Yiyi Chen","Johannes Bjerva","Qiongxiu Li"],"url":"https://arxiv.org/abs/2505.15722"}
{"created":"2025-05-22","title":"UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning","abstract":"Unmanned Aerial Vehicles (UAVs) are evolving into language-interactive platforms, enabling more intuitive forms of human-drone interaction. While prior works have primarily focused on high-level planning and long-horizon navigation, we shift attention to language-guided fine-grained trajectory control, where UAVs execute short-range, reactive flight behaviors in response to language instructions. We formalize this problem as the Flying-on-a-Word (Flow) task and introduce UAV imitation learning as an effective approach. In this framework, UAVs learn fine-grained control policies by mimicking expert pilot trajectories paired with atomic language instructions. To support this paradigm, we present UAV-Flow, the first real-world benchmark for language-conditioned, fine-grained UAV control. It includes a task formulation, a large-scale dataset collected in diverse environments, a deployable control framework, and a simulation suite for systematic evaluation. Our design enables UAVs to closely imitate the precise, expert-level flight trajectories of human pilots and supports direct deployment without sim-to-real gap. We conduct extensive experiments on UAV-Flow, benchmarking VLN and VLA paradigms. Results show that VLA models are superior to VLN baselines and highlight the critical role of spatial grounding in the fine-grained Flow setting.","authors":["Xiangyu Wang","Donglin Yang","Yue Liao","Wenhao Zheng","wenjun wu","Bin Dai","Hongsheng Li","Si Liu"],"url":"https://arxiv.org/abs/2505.15725"}
{"created":"2025-05-22","title":"VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models","abstract":"The rapid advancement of large language models (LLMs) has accelerated the development of multi-modal models capable of vocal communication. Unlike text-based interactions, speech conveys rich and diverse information, including semantic content, acoustic variations, paralanguage cues, and environmental context. However, existing evaluations of speech interaction models predominantly focus on the quality of their textual responses, often overlooking critical aspects of vocal performance and lacking benchmarks with vocal-specific test instances. To address this gap, we propose VocalBench, a comprehensive benchmark designed to evaluate speech interaction models' capabilities in vocal communication. VocalBench comprises 9,400 carefully curated instances across four key dimensions: semantic quality, acoustic performance, conversational abilities, and robustness. It covers 16 fundamental skills essential for effective vocal interaction. Experimental results reveal significant variability in current model capabilities, each exhibiting distinct strengths and weaknesses, and provide valuable insights to guide future research in speech-based interaction systems. Code and evaluation instances are available at https://github.com/SJTU-OmniAgent/VocalBench.","authors":["Heyang Liu","Yuhao Wang","Ziyang Cheng","Ronghua Wu","Qunshan Gu","Yanfeng Wang","Yu Wang"],"url":"https://arxiv.org/abs/2505.15727"}
{"created":"2025-05-22","title":"DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning","abstract":"Large language models (LLMs) have improved significantly in their reasoning through extensive training on massive datasets. However, relying solely on additional data for improvement is becoming increasingly impractical, highlighting the need for models to autonomously enhance their reasoning without external supervision. In this paper, we propose Debate, Train, Evolve (DTE), a novel ground truth-free training framework that uses multi-agent debate traces to evolve a single language model. We also introduce a new prompting strategy Reflect-Critique-Refine, to improve debate quality by explicitly instructing agents to critique and refine their reasoning. Extensive evaluations on five reasoning benchmarks with six open-weight models show that our DTE framework achieve substantial improvements, with an average accuracy gain of 8.92% on the challenging GSM-PLUS dataset. Furthermore, we observe strong cross-domain generalization, with an average accuracy gain of 5.8% on all other benchmarks, suggesting that our method captures general reasoning capabilities.","authors":["Gaurav Srivastava","Zhenyu Bi","Meng Lu","Xuan Wang"],"url":"https://arxiv.org/abs/2505.15734"}
{"created":"2025-05-22","title":"RUSplatting: Robust 3D Gaussian Splatting for Sparse-View Underwater Scene Reconstruction","abstract":"Reconstructing high-fidelity underwater scenes remains a challenging task due to light absorption, scattering, and limited visibility inherent in aquatic environments. This paper presents an enhanced Gaussian Splatting-based framework that improves both the visual quality and geometric accuracy of deep underwater rendering. We propose decoupled learning for RGB channels, guided by the physics of underwater attenuation, to enable more accurate colour restoration. To address sparse-view limitations and improve view consistency, we introduce a frame interpolation strategy with a novel adaptive weighting scheme. Additionally, we introduce a new loss function aimed at reducing noise while preserving edges, which is essential for deep-sea content. We also release a newly collected dataset, Submerged3D, captured specifically in deep-sea environments. Experimental results demonstrate that our framework consistently outperforms state-of-the-art methods with PSNR gains up to 1.90dB, delivering superior perceptual quality and robustness, and offering promising directions for marine robotics and underwater visual analytics.","authors":["Zhuodong Jiang","Haoran Wang","Guoxi Huang","Brett Seymour","Nantheera Anantrasirichai"],"url":"https://arxiv.org/abs/2505.15737"}
{"created":"2025-05-22","title":"Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses","abstract":"Large language models (LLMs) are rapidly deployed in real-world applications ranging from chatbots to agentic systems. Alignment is one of the main approaches used to defend against attacks such as prompt injection and jailbreaks. Recent defenses report near-zero Attack Success Rates (ASR) even against Greedy Coordinate Gradient (GCG), a white-box attack that generates adversarial suffixes to induce attacker-desired outputs. However, this search space over discrete tokens is extremely large, making the task of finding successful attacks difficult. GCG has, for instance, been shown to converge to local minima, making it sensitive to initialization choices. In this paper, we assess the future-proof robustness of these defenses using a more informed threat model: attackers who have access to some information about the alignment process. Specifically, we propose an informed white-box attack leveraging the intermediate model checkpoints to initialize GCG, with each checkpoint acting as a stepping stone for the next one. We show this approach to be highly effective across state-of-the-art (SOTA) defenses and models. We further show our informed initialization to outperform other initialization methods and show a gradient-informed checkpoint selection strategy to greatly improve attack performance and efficiency. Importantly, we also show our method to successfully find universal adversarial suffixes -- single suffixes effective across diverse inputs. Our results show that, contrary to previous beliefs, effective adversarial suffixes do exist against SOTA alignment-based defenses, that these can be found by existing attack methods when adversaries exploit alignment knowledge, and that even universal suffixes exist. Taken together, our results highlight the brittleness of current alignment-based methods and the need to consider stronger threat models when testing the safety of LLMs.","authors":["Xiaoxue Yang","Bozhidar Stevanoski","Matthieu Meeus","Yves-Alexandre de Montjoye"],"url":"https://arxiv.org/abs/2505.15738"}
{"created":"2025-05-22","title":"HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement","abstract":"Formal methods is pivotal for verifying the reliability of critical systems through rigorous mathematical proofs. However, its adoption is hindered by labor-intensive manual proofs and the expertise required to use theorem provers. Recent advancements in large language models (LLMs) offer new opportunities for automated theorem proving. Two promising approaches are generating tactics step by step and generating a whole proof directly with an LLM. However, existing work makes no attempt to combine the two approaches. In this work, we introduce HybridProver, a dual-model proof synthesis framework that combines tactic-based generation and whole-proof synthesis to harness the benefits of both approaches. HybridProver generates whole proof candidates for evaluation directly, then extracts proof sketches from those candidates. It then uses a tactic-based generation model that integrates automated tools to complete the sketches via stepwise refinement. We implement HybridProver for the Isabelle theorem prover and fine-tune LLMs on our optimized Isabelle datasets. Evaluation on the miniF2F dataset illustrates HybridProver's effectiveness. We achieve a 59.4% success rate on miniF2F, where the previous SOTA is 56.1%. Our ablation studies show that this SOTA result is attributable to combining whole-proof and tactic-based generation. Additionally, we show how the dataset quality, training parameters, and sampling diversity affect the final result during automated theorem proving with LLMs. All of our code, datasets, and LLMs are open source.","authors":["Jilin Hu","Jianyu Zhang","Yongwang Zhao","Talia Ringer"],"url":"https://arxiv.org/abs/2505.15740"}
{"created":"2025-05-22","title":"Evolutionary Computation and Large Language Models: A Survey of Methods, Synergies, and Applications","abstract":"Integrating Large Language Models (LLMs) and Evolutionary Computation (EC) represents a promising avenue for advancing artificial intelligence by combining powerful natural language understanding with optimization and search capabilities. This manuscript explores the synergistic potential of LLMs and EC, reviewing their intersections, complementary strengths, and emerging applications. We identify key opportunities where EC can enhance LLM training, fine-tuning, prompt engineering, and architecture search, while LLMs can, in turn, aid in automating the design, analysis, and interpretation of ECs. The manuscript explores the synergistic integration of EC and LLMs, highlighting their bidirectional contributions to advancing artificial intelligence. It first examines how EC techniques enhance LLMs by optimizing key components such as prompt engineering, hyperparameter tuning, and architecture search, demonstrating how evolutionary methods automate and refine these processes. Secondly, the survey investigates how LLMs improve EC by automating metaheuristic design, tuning evolutionary algorithms, and generating adaptive heuristics, thereby increasing efficiency and scalability. Emerging co-evolutionary frameworks are discussed, showcasing applications across diverse fields while acknowledging challenges like computational costs, interpretability, and algorithmic convergence. The survey concludes by identifying open research questions and advocating for hybrid approaches that combine the strengths of EC and LLMs.","authors":["Dikshit Chauhan","Bapi Dutta","Indu Bala","Niki van Stein","Thomas B\\\"ack","Anupam Yadav"],"url":"https://arxiv.org/abs/2505.15741"}
{"created":"2025-05-22","title":"Neuro-Argumentative Learning with Case-Based Reasoning","abstract":"We introduce Gradual Abstract Argumentation for Case-Based Reasoning (Gradual AA-CBR), a data-driven, neurosymbolic classification model in which the outcome is determined by an argumentation debate structure that is learned simultaneously with neural-based feature extractors. Each argument in the debate is an observed case from the training data, favouring their labelling. Cases attack or support those with opposing or agreeing labellings, with the strength of each argument and relationship learned through gradient-based methods. This argumentation debate structure provides human-aligned reasoning, improving model interpretability compared to traditional neural networks (NNs). Unlike the existing purely symbolic variant, Abstract Argumentation for Case-Based Reasoning (AA-CBR), Gradual AA-CBR is capable of multi-class classification, automatic learning of feature and data point importance, assigning uncertainty values to outcomes, using all available data points, and does not require binary features. We show that Gradual AA-CBR performs comparably to NNs whilst significantly outperforming existing AA-CBR formulations.","authors":["Adam Gould","Francesca Toni"],"url":"https://arxiv.org/abs/2505.15742"}
{"created":"2025-05-22","title":"Who \"Controls\" Where Work Shall be Done? State-of-Practice in Post-Pandemic Remote Work Regulation","abstract":"The COVID-19 pandemic has permanently altered workplace structures, making remote work a widespread practice. While many employees advocate for flexibility, many employers reconsider their attitude toward remote work and opt for structured return-to-office mandates. Media headlines repeatedly emphasize that the corporate world is returning to full-time office work. This study examines how companies employing software engineers and supporting roles regulate work location, whether corporate policies have evolved in the last five years, and, if so, how, and why. We collected data on remote work regulation from corporate HR and/or management representatives from 68 corporate entities that vary in size, location, and orientation towards remote or office work. Our findings reveal that although many companies prioritize office-centred working (50%), most companies in our sample permit hybrid working to varying degrees (85%). Remote work regulation does not reveal any particular new \"best practice\" as policies differ greatly, but the single most popular arrangement was the three in-office days per week. More than half of the companies (51%) encourage or mandate office days, and more than quarter (28%) have changed regulations, gradually increasing the mandatory office presence or implementing differentiated conditions. Although no companies have increased flexibility, only four companies are returning to full-time office work. Our key recommendation for office-oriented companies is to consider a trust-based alternative to strict office presence mandates, while for companies oriented toward remote working, we warn about the points of no (or hard) return. Finally, the current state of policies is clearly not final, as companies continue to experiment and adjust their work regulation.","authors":["Darja Smite","Nils Brede Moe","Maria Teresa Baldassarre","Fabio Calefato","Guilherme Horta Travassos","Marcin Floryan","Marcos Kalinowski","Daniel Mendez","Graziela Basilio Pereira","Margaret-Anne Storey","Rafael Prikladnicki"],"url":"https://arxiv.org/abs/2505.15743"}
{"created":"2025-05-22","title":"Higher-order Structure Boosts Link Prediction on Temporal Graphs","abstract":"Temporal Graph Neural Networks (TGNNs) have gained growing attention for modeling and predicting structures in temporal graphs. However, existing TGNNs primarily focus on pairwise interactions while overlooking higher-order structures that are integral to link formation and evolution in real-world temporal graphs. Meanwhile, these models often suffer from efficiency bottlenecks, further limiting their expressive power. To tackle these challenges, we propose a Higher-order structure Temporal Graph Neural Network, which incorporates hypergraph representations into temporal graph learning. In particular, we develop an algorithm to identify the underlying higher-order structures, enhancing the model's ability to capture the group interactions. Furthermore, by aggregating multiple edge features into hyperedge representations, HTGN effectively reduces memory cost during training. We theoretically demonstrate the enhanced expressiveness of our approach and validate its effectiveness and efficiency through extensive experiments on various real-world temporal graphs. Experimental results show that HTGN achieves superior performance on dynamic link prediction while reducing memory costs by up to 50\\% compared to existing methods.","authors":["Jingzhe Liu","Zhigang Hua","Yan Xie","Bingheng Li","Harry Shomer","Yu Song","Kaveh Hassani","Jiliang Tang"],"url":"https://arxiv.org/abs/2505.15746"}
{"created":"2025-05-22","title":"Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs","abstract":"We propose a novel framework for integrating fragmented multi-modal data in Alzheimer's disease (AD) research using large language models (LLMs) and knowledge graphs. While traditional multimodal analysis requires matched patient IDs across datasets, our approach demonstrates population-level integration of MRI, gene expression, biomarkers, EEG, and clinical indicators from independent cohorts. Statistical analysis identified significant features in each modality, which were connected as nodes in a knowledge graph. LLMs then analyzed the graph to extract potential correlations and generate hypotheses in natural language. This approach revealed several novel relationships, including a potential pathway linking metabolic risk factors to tau protein abnormalities via neuroinflammation (r>0.6, p<0.001), and unexpected correlations between frontal EEG channels and specific gene expression profiles (r=0.42-0.58, p<0.01). Cross-validation with independent datasets confirmed the robustness of major findings, with consistent effect sizes across cohorts (variance <15%). The reproducibility of these findings was further supported by expert review (Cohen's k=0.82) and computational validation. Our framework enables cross modal integration at a conceptual level without requiring patient ID matching, offering new possibilities for understanding AD pathology through fragmented data reuse and generating testable hypotheses for future research.","authors":["Kanan Kiguchi","Yunhao Tu","Katsuhiro Ajito","Fady Alnajjar","Kazuyuki Murase"],"url":"https://arxiv.org/abs/2505.15747"}
{"created":"2025-05-22","title":"Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval","abstract":"Large Language Models (LLMs) are known to be vulnerable to jailbreaking attacks, wherein adversaries exploit carefully engineered prompts to induce harmful or unethical responses. Such threats have raised critical concerns about the safety and reliability of LLMs in real-world deployment. While existing defense mechanisms partially mitigate such risks, subsequent advancements in adversarial techniques have enabled novel jailbreaking methods to circumvent these protections, exposing the limitations of static defense frameworks. In this work, we explore defending against evolving jailbreaking threats through the lens of context retrieval. First, we conduct a preliminary study demonstrating that even a minimal set of safety-aligned examples against a particular jailbreak can significantly enhance robustness against this attack pattern. Building on this insight, we further leverage the retrieval-augmented generation (RAG) techniques and propose Safety Context Retrieval (SCR), a scalable and robust safeguarding paradigm for LLMs against jailbreaking. Our comprehensive experiments demonstrate how SCR achieves superior defensive performance against both established and emerging jailbreaking tactics, contributing a new paradigm to LLM safety. Our code will be available upon publication.","authors":["Taiye Chen","Zeming Wei","Ang Li","Yisen Wang"],"url":"https://arxiv.org/abs/2505.15753"}
{"created":"2025-05-22","title":"Improving planning and MBRL with temporally-extended actions","abstract":"Continuous time systems are often modeled using discrete time dynamics but this requires a small simulation step to maintain accuracy. In turn, this requires a large planning horizon which leads to computationally demanding planning problems and reduced performance. Previous work in model free reinforcement learning has partially addressed this issue using action repeats where a policy is learned to determine a discrete action duration. Instead we propose to control the continuous decision timescale directly by using temporally-extended actions and letting the planner treat the duration of the action as an additional optimization variable along with the standard action variables. This additional structure has multiple advantages. It speeds up simulation time of trajectories and, importantly, it allows for deep horizon search in terms of primitive actions while using a shallow search depth in the planner. In addition, in the model based reinforcement learning (MBRL) setting, it reduces compounding errors from model learning and improves training time for models. We show that this idea is effective and that the range for action durations can be automatically selected using a multi-armed bandit formulation and integrated into the MBRL framework. An extensive experimental evaluation both in planning and in MBRL, shows that our approach yields faster planning, better solutions, and that it enables solutions to problems that are not solved in the standard formulation.","authors":["Palash Chatterjee","Roni Khardon"],"url":"https://arxiv.org/abs/2505.15754"}
{"created":"2025-05-22","title":"Exploring The Visual Feature Space for Multimodal Neural Decoding","abstract":"The intrication of brain signals drives research that leverages multimodal AI to align brain modalities with visual and textual data for explainable descriptions. However, most existing studies are limited to coarse interpretations, lacking essential details on object descriptions, locations, attributes, and their relationships. This leads to imprecise and ambiguous reconstructions when using such cues for visual decoding. To address this, we analyze different choices of vision feature spaces from pre-trained visual components within Multimodal Large Language Models (MLLMs) and introduce a zero-shot multimodal brain decoding method that interacts with these models to decode across multiple levels of granularities. % To assess a model's ability to decode fine details from brain signals, we propose the Multi-Granularity Brain Detail Understanding Benchmark (MG-BrainDub). This benchmark includes two key tasks: detailed descriptions and salient question-answering, with metrics highlighting key visual elements like objects, attributes, and relationships. Our approach enhances neural decoding precision and supports more accurate neuro-decoding applications. Code will be available at https://github.com/weihaox/VINDEX.","authors":["Weihao Xia","Cengiz Oztireli"],"url":"https://arxiv.org/abs/2505.15755"}
{"created":"2025-05-22","title":"An Empirical Analysis of Vulnerability Detection Tools for Solidity Smart Contracts Using Line Level Manually Annotated Vulnerabilities","abstract":"The rapid adoption of blockchain technology highlighted the importance of ensuring the security of smart contracts due to their critical role in automated business logic execution on blockchain platforms. This paper provides an empirical evaluation of automated vulnerability analysis tools specifically designed for Solidity smart contracts. Leveraging the extensive SmartBugs 2.0 framework, which includes 20 analysis tools, we conducted a comprehensive assessment using an annotated dataset of 2,182 instances we manually annotated with line-level vulnerability labels. Our evaluation highlights the detection effectiveness of these tools in detecting various types of vulnerabilities, as categorized by the DASP TOP 10 taxonomy. We evaluated the effectiveness of a Large Language Model-based detection method on two popular datasets. In this case, we obtained inconsistent results with the two datasets, showing unreliable detection when analyzing real-world smart contracts. Our study identifies significant variations in the accuracy and reliability of different tools and demonstrates the advantages of combining multiple detection methods to improve vulnerability identification. We identified a set of 3 tools that, combined, achieve up to 76.78\\% found vulnerabilities taking less than one minute to run, on average. This study contributes to the field by releasing the largest dataset of manually analyzed smart contracts with line-level vulnerability annotations and the empirical evaluation of the greatest number of tools to date.","authors":["Francesco Salzano","Cosmo Kevin Antenucci","Simone Scalabrino","Giovanni Rosa","Rocco Oliveto","Remo Pareschi"],"url":"https://arxiv.org/abs/2505.15756"}
{"created":"2025-05-22","title":"State Characterisation of Self-Directed Channel Memristive Devices","abstract":"Knowing how to reliably use memristors as information storage devices is crucial not only to their role as emerging memories, but also for their application in neural network acceleration and as components of novel neuromorphic systems. In order to better understand the dynamics of information storage on memristors, it is essential to be able to characterise and measure their state. To this end, in this paper we propose a general, physics-inspired modelling approach for characterising the state of self-directed channel (SDC) memristors. Additionally, to enable the identification of the proposed state from device data, we introduce a noise-aware approach to the minimum-variance estimation of the state from voltage and current pairs.","authors":["D\\'aniel Hajt\\'o","Waleed El-Geresy","Deniz G\\\"und\\\"uz","Gy\\\"orgy Cserey"],"url":"https://arxiv.org/abs/2505.15757"}
{"created":"2025-05-22","title":"Constructing a 3D Town from a Single Image","abstract":"Acquiring detailed 3D scenes typically demands costly equipment, multi-view data, or labor-intensive modeling. Therefore, a lightweight alternative, generating complex 3D scenes from a single top-down image, plays an essential role in real-world applications. While recent 3D generative models have achieved remarkable results at the object level, their extension to full-scene generation often leads to inconsistent geometry, layout hallucinations, and low-quality meshes. In this work, we introduce 3DTown, a training-free framework designed to synthesize realistic and coherent 3D scenes from a single top-down view. Our method is grounded in two principles: region-based generation to improve image-to-3D alignment and resolution, and spatial-aware 3D inpainting to ensure global scene coherence and high-quality geometry generation. Specifically, we decompose the input image into overlapping regions and generate each using a pretrained 3D object generator, followed by a masked rectified flow inpainting process that fills in missing geometry while maintaining structural continuity. This modular design allows us to overcome resolution bottlenecks and preserve spatial structure without requiring 3D supervision or fine-tuning. Extensive experiments across diverse scenes show that 3DTown outperforms state-of-the-art baselines, including Trellis, Hunyuan3D-2, and TripoSG, in terms of geometry quality, spatial coherence, and texture fidelity. Our results demonstrate that high-quality 3D town generation is achievable from a single image using a principled, training-free approach.","authors":["Kaizhi Zheng","Ruijian Zhang","Jing Gu","Jie Yang","Xin Eric Wang"],"url":"https://arxiv.org/abs/2505.15765"}
{"created":"2025-05-22","title":"Transfer of Structural Knowledge from Synthetic Languages","abstract":"This work explores transfer learning from several synthetic languages to English. We investigate the structure of the embeddings in the fine-tuned models, the information they contain, and the capabilities of the fine-tuned models on simple linguistic tasks. We also introduce a new synthetic language that leads to better transfer to English than the languages used in previous research. Finally, we introduce Tiny-Cloze Benchmark - a new synthetic benchmark for natural language understanding that is more informative for less powerful models. We use Tiny-Cloze Benchmark to evaluate fine-tuned models in several domains demonstrating that fine-tuning on a new synthetic language allows for better performance on a variety of tasks.","authors":["Mikhail Budnikov","Ivan Yamshchikov"],"url":"https://arxiv.org/abs/2505.15769"}
{"created":"2025-05-22","title":"Elasto-acoustic wave propagation in geophysical media using hybrid high-order methods on general meshes","abstract":"Hybrid high-order (HHO) methods are numerical methods characterized by several interesting properties such as local conservativity, geometric flexibility and high-order accuracy. Here, HHO schemes are studied for the space semi-discretization of coupled elasto-acoustic waves in the time domain using a first-order formulation. Explicit and singly diagonal implicit Runge--Kutta (ERK & SDIRK) schemes are used for the time discretization. We show that an efficient implementation of explicit (resp. implicit) time schemes calls for a static condensation of the face (resp. cell) unknowns. Crucially, both static condensation procedures only involve block-diagonal matrices. Then, we provide numerical estimates for the CFL stability limit of ERK schemes and present a comparative study on the efficiency of explicit versus implicit schemes. Our findings indicate that implicit time schemes remain competitive in many situations. Finally, simulations in a 2D realistic geophysical configuration are performed, illustrating the geometrical flexibility of the HHO method: both hybrid (triangular and quadrangular) and nonconforming (with hanging nodes) meshes are easily handled, delivering results of comparable accuracy to a reference spectral element software based on tensorized elements.","authors":["Romain Mottier","Alexandre Ern","Laurent Guillot"],"url":"https://arxiv.org/abs/2505.15771"}
{"created":"2025-05-22","title":"MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech Paralinguistic and Affect Labeling","abstract":"Acquiring large-scale emotional speech data with strong consistency remains a challenge for speech synthesis. This paper presents MIKU-PAL, a fully automated multimodal pipeline for extracting high-consistency emotional speech from unlabeled video data. Leveraging face detection and tracking algorithms, we developed an automatic emotion analysis system using a multimodal large language model (MLLM). Our results demonstrate that MIKU-PAL can achieve human-level accuracy (68.5% on MELD) and superior consistency (0.93 Fleiss kappa score) while being much cheaper and faster than human annotation. With the high-quality, flexible, and consistent annotation from MIKU-PAL, we can annotate fine-grained speech emotion categories of up to 26 types, validated by human annotators with 83% rationality ratings. Based on our proposed system, we further released a fine-grained emotional speech dataset MIKU-EmoBench(131.2 hours) as a new benchmark for emotional text-to-speech and visual voice cloning.","authors":["Cheng Yifan","Zhang Ruoyi","Shi Jiatong"],"url":"https://arxiv.org/abs/2505.15772"}
{"created":"2025-05-22","title":"Beyond Hard and Soft: Hybrid Context Compression for Balancing Local and Global Information Retention","abstract":"Large Language Models (LLMs) encounter significant challenges in long-sequence inference due to computational inefficiency and redundant processing, driving interest in context compression techniques. Existing methods often rely on token importance to perform hard local compression or encode context into latent representations for soft global compression. However, the uneven distribution of textual content relevance and the diversity of demands for user instructions mean these approaches frequently lead to the loss of potentially valuable information. To address this, we propose $\\textbf{Hy}$brid $\\textbf{Co}$ntext $\\textbf{Co}$mpression (HyCo$_2$) for LLMs, which integrates both global and local perspectives to guide context compression while retaining both the essential semantics and critical details for task completion. Specifically, we employ a hybrid adapter to refine global semantics with the global view, based on the observation that different adapters excel at different tasks. Then we incorporate a classification layer that assigns a retention probability to each context token based on the local view, determining whether it should be retained or discarded. To foster a balanced integration of global and local compression, we introduce auxiliary paraphrasing and completion pretraining before instruction tuning. This promotes a synergistic integration that emphasizes instruction-relevant information while preserving essential local details, ultimately balancing local and global information retention in context compression. Experiments show that our HyCo$_2$ method significantly enhances long-text reasoning while reducing token usage. It improves the performance of various LLM series by an average of 13.1\\% across seven knowledge-intensive QA benchmarks. Moreover, HyCo$_2$ matches the performance of uncompressed methods while reducing token consumption by 88.8\\%.","authors":["Huanxuan Liao","Wen Hu","Yao Xu","Shizhu He","Jun Zhao","Kang Liu"],"url":"https://arxiv.org/abs/2505.15774"}
{"created":"2025-05-22","title":"ConvSearch-R1: Enhancing Query Reformulation for Conversational Search with Reasoning via Reinforcement Learning","abstract":"Conversational search systems require effective handling of context-dependent queries that often contain ambiguity, omission, and coreference. Conversational Query Reformulation (CQR) addresses this challenge by transforming these queries into self-contained forms suitable for off-the-shelf retrievers. However, existing CQR approaches suffer from two critical constraints: high dependency on costly external supervision from human annotations or large language models, and insufficient alignment between the rewriting model and downstream retrievers. We present ConvSearch-R1, the first self-driven framework that completely eliminates dependency on external rewrite supervision by leveraging reinforcement learning to optimize reformulation directly through retrieval signals. Our novel two-stage approach combines Self-Driven Policy Warm-Up to address the cold-start problem through retrieval-guided self-distillation, followed by Retrieval-Guided Reinforcement Learning with a specially designed rank-incentive reward shaping mechanism that addresses the sparsity issue in conventional retrieval metrics. Extensive experiments on TopiOCQA and QReCC datasets demonstrate that ConvSearch-R1 significantly outperforms previous state-of-the-art methods, achieving over 10% improvement on the challenging TopiOCQA dataset while using smaller 3B parameter models without any external supervision.","authors":["Changtai Zhu","Siyin Wang","Ruijun Feng","Kai Song","Xipeng Qiu"],"url":"https://arxiv.org/abs/2505.15776"}
{"created":"2025-05-22","title":"Projection-Based Correction for Enhancing Deep Inverse Networks","abstract":"Deep learning-based models have demonstrated remarkable success in solving illposed inverse problems; however, many fail to strictly adhere to the physical constraints imposed by the measurement process. In this work, we introduce a projection-based correction method to enhance the inference of deep inverse networks by ensuring consistency with the forward model. Specifically, given an initial estimate from a learned reconstruction network, we apply a projection step that constrains the solution to lie within the valid solution space of the inverse problem. We theoretically demonstrate that if the recovery model is a well-trained deep inverse network, the solution can be decomposed into range-space and null-space components, where the projection-based correction reduces to an identity transformation. Extensive simulations and experiments validate the proposed method, demonstrating improved reconstruction accuracy across diverse inverse problems and deep network architectures.","authors":["Jorge Bacca"],"url":"https://arxiv.org/abs/2505.15777"}
{"created":"2025-05-22","title":"Soft Thinking: Unlocking the Reasoning Potential of LLMs in Continuous Concept Space","abstract":"Human cognition typically involves thinking through abstract, fluid concepts rather than strictly using discrete linguistic tokens. Current reasoning models, however, are constrained to reasoning within the boundaries of human language, processing discrete token embeddings that represent fixed points in the semantic space. This discrete constraint restricts the expressive power and upper potential of such reasoning models, often causing incomplete exploration of reasoning paths, as standard Chain-of-Thought (CoT) methods rely on sampling one token per step. In this work, we introduce Soft Thinking, a training-free method that emulates human-like \"soft\" reasoning by generating soft, abstract concept tokens in a continuous concept space. These concept tokens are created by the probability-weighted mixture of token embeddings, which form the continuous concept space, enabling smooth transitions and richer representations that transcend traditional discrete boundaries. In essence, each generated concept token encapsulates multiple meanings from related discrete tokens, implicitly exploring various reasoning paths to converge effectively toward the correct answer. Empirical evaluations on diverse mathematical and coding benchmarks consistently demonstrate the effectiveness and efficiency of Soft Thinking, improving pass@1 accuracy by up to 2.48 points while simultaneously reducing token usage by up to 22.4% compared to standard CoT. Qualitative analysis further reveals that Soft Thinking outputs remain highly interpretable and readable, highlighting the potential of Soft Thinking to break the inherent bottleneck of discrete language-based reasoning. Code is available at https://github.com/eric-ai-lab/Soft-Thinking.","authors":["Zhen Zhang","Xuehai He","Weixiang Yan","Ao Shen","Chenyang Zhao","Shuohang Wang","Yelong Shen","Xin Eric Wang"],"url":"https://arxiv.org/abs/2505.15778"}
{"created":"2025-05-22","title":"IA-T2I: Internet-Augmented Text-to-Image Generation","abstract":"Current text-to-image (T2I) generation models achieve promising results, but they fail on the scenarios where the knowledge implied in the text prompt is uncertain. For example, a T2I model released in February would struggle to generate a suitable poster for a movie premiering in April, because the character designs and styles are uncertain to the model. To solve this problem, we propose an Internet-Augmented text-to-image generation (IA-T2I) framework to compel T2I models clear about such uncertain knowledge by providing them with reference images. Specifically, an active retrieval module is designed to determine whether a reference image is needed based on the given text prompt; a hierarchical image selection module is introduced to find the most suitable image returned by an image search engine to enhance the T2I model; a self-reflection mechanism is presented to continuously evaluate and refine the generated image to ensure faithful alignment with the text prompt. To evaluate the proposed framework's performance, we collect a dataset named Img-Ref-T2I, where text prompts include three types of uncertain knowledge: (1) known but rare. (2) unknown. (3) ambiguous. Moreover, we carefully craft a complex prompt to guide GPT-4o in making preference evaluation, which has been shown to have an evaluation accuracy similar to that of human preference evaluation. Experimental results demonstrate the effectiveness of our framework, outperforming GPT-4o by about 30% in human evaluation.","authors":["Chuanhao Li","Jianwen Sun","Yukang Feng","Mingliang Zhai","Yifan Chang","Kaipeng Zhang"],"url":"https://arxiv.org/abs/2505.15779"}
{"created":"2025-05-22","title":"dKV-Cache: The Cache for Diffusion Language Models","abstract":"Diffusion Language Models (DLMs) have been seen as a promising competitor for autoregressive language models. However, diffusion language models have long been constrained by slow inference. A core challenge is that their non-autoregressive architecture and bidirectional attention preclude the key-value cache that accelerates decoding. We address this bottleneck by proposing a KV-cache-like mechanism, delayed KV-Cache, for the denoising process of DLMs. Our approach is motivated by the observation that different tokens have distinct representation dynamics throughout the diffusion process. Accordingly, we propose a delayed and conditioned caching strategy for key and value states. We design two complementary variants to cache key and value step-by-step: (1) dKV-Cache-Decode, which provides almost lossless acceleration, and even improves performance on long sequences, suggesting that existing DLMs may under-utilise contextual information during inference. (2) dKV-Cache-Greedy, which has aggressive caching with reduced lifespan, achieving higher speed-ups with quadratic time complexity at the cost of some performance degradation. dKV-Cache, in final, achieves from 2-10x speedup in inference, largely narrowing the gap between ARs and DLMs. We evaluate our dKV-Cache on several benchmarks, delivering acceleration across general language understanding, mathematical, and code-generation benchmarks. Experiments demonstrate that cache can also be used in DLMs, even in a training-free manner from current DLMs.","authors":["Xinyin Ma","Runpeng Yu","Gongfan Fang","Xinchao Wang"],"url":"https://arxiv.org/abs/2505.15781"}
{"created":"2025-05-22","title":"Solving General-Utility Markov Decision Processes in the Single-Trial Regime with Online Planning","abstract":"In this work, we contribute the first approach to solve infinite-horizon discounted general-utility Markov decision processes (GUMDPs) in the single-trial regime, i.e., when the agent's performance is evaluated based on a single trajectory. First, we provide some fundamental results regarding policy optimization in the single-trial regime, investigating which class of policies suffices for optimality, casting our problem as a particular MDP that is equivalent to our original problem, as well as studying the computational hardness of policy optimization in the single-trial regime. Second, we show how we can leverage online planning techniques, in particular a Monte-Carlo tree search algorithm, to solve GUMDPs in the single-trial regime. Third, we provide experimental results showcasing the superior performance of our approach in comparison to relevant baselines.","authors":["Pedro P. Santos","Alberto Sardinha","Francisco S. Melo"],"url":"https://arxiv.org/abs/2505.15782"}
{"created":"2025-05-22","title":"Large Language Models as Computable Approximations to Solomonoff Induction","abstract":"The rapid advancement of large language models (LLMs) calls for a rigorous theoretical framework to explain their empirical success. While significant progress has been made in understanding LLM behaviors, existing theoretical frameworks remain fragmented in explaining emergent phenomena through a unified mathematical lens. We establish the first formal connection between LLM architectures and Algorithmic Information Theory (AIT) by proving two fundamental results: (1) the training process computationally approximates Solomonoff prior through loss minimization interpreted as program length optimization, and (2) next-token prediction implements approximate Solomonoff induction. We leverage AIT to provide a unified theoretical explanation for in-context learning, few-shot learning, and scaling laws. Furthermore, our theoretical insights lead to a principled method for few-shot example selection that prioritizes samples where models exhibit lower predictive confidence. We demonstrate through experiments on diverse text classification benchmarks that this strategy yields significant performance improvements, particularly for smaller model architectures, when compared to selecting high-confidence examples. Our framework bridges the gap between theoretical foundations and practical LLM behaviors, providing both explanatory power and actionable insights for future model development.","authors":["Jun Wan","Lingrui Mei"],"url":"https://arxiv.org/abs/2505.15784"}
{"created":"2025-05-22","title":"Fair Supervised Learning Through Constraints on Smooth Nonconvex Unfairness-Measure Surrogates","abstract":"A new strategy for fair supervised machine learning is proposed. The main advantages of the proposed strategy as compared to others in the literature are as follows. (a) We introduce a new smooth nonconvex surrogate to approximate the Heaviside functions involved in discontinuous unfairness measures. The surrogate is based on smoothing methods from the optimization literature, and is new for the fair supervised learning literature. The surrogate is a tight approximation which ensures the trained prediction models are fair, as opposed to other (e.g., convex) surrogates that can fail to lead to a fair prediction model in practice. (b) Rather than rely on regularizers (that lead to optimization problems that are difficult to solve) and corresponding regularization parameters (that can be expensive to tune), we propose a strategy that employs hard constraints so that specific tolerances for unfairness can be enforced without the complications associated with the use of regularization. (c)~Our proposed strategy readily allows for constraints on multiple (potentially conflicting) unfairness measures at the same time. Multiple measures can be considered with a regularization approach, but at the cost of having even more difficult optimization problems to solve and further expense for tuning. By contrast, through hard constraints, our strategy leads to optimization models that can be solved tractably with minimal tuning.","authors":["Zahra Khatti","Daniel P. Robinson","Frank E. Curtis"],"url":"https://arxiv.org/abs/2505.15788"}
{"created":"2025-05-22","title":"Exploring the Innovation Opportunities for Pre-trained Models","abstract":"Innovators transform the world by understanding where services are successfully meeting customers' needs and then using this knowledge to identify failsafe opportunities for innovation. Pre-trained models have changed the AI innovation landscape, making it faster and easier to create new AI products and services. Understanding where pre-trained models are successful is critical for supporting AI innovation. Unfortunately, the hype cycle surrounding pre-trained models makes it hard to know where AI can really be successful. To address this, we investigated pre-trained model applications developed by HCI researchers as a proxy for commercially successful applications. The research applications demonstrate technical capabilities, address real user needs, and avoid ethical challenges. Using an artifact analysis approach, we categorized capabilities, opportunity domains, data types, and emerging interaction design patterns, uncovering some of the opportunity space for innovation with pre-trained models.","authors":["Minjung Park","Jodi Forlizzi","John Zimmerman"],"url":"https://arxiv.org/abs/2505.15790"}
{"created":"2025-05-22","title":"VARD: Efficient and Dense Fine-Tuning for Diffusion Models with Value-based RL","abstract":"Diffusion models have emerged as powerful generative tools across various domains, yet tailoring pre-trained models to exhibit specific desirable properties remains challenging. While reinforcement learning (RL) offers a promising solution,current methods struggle to simultaneously achieve stable, efficient fine-tuning and support non-differentiable rewards. Furthermore, their reliance on sparse rewards provides inadequate supervision during intermediate steps, often resulting in suboptimal generation quality. To address these limitations, dense and differentiable signals are required throughout the diffusion process. Hence, we propose VAlue-based Reinforced Diffusion (VARD): a novel approach that first learns a value function predicting expection of rewards from intermediate states, and subsequently uses this value function with KL regularization to provide dense supervision throughout the generation process. Our method maintains proximity to the pretrained model while enabling effective and stable training via backpropagation. Experimental results demonstrate that our approach facilitates better trajectory guidance, improves training efficiency and extends the applicability of RL to diffusion models optimized for complex, non-differentiable reward functions.","authors":["Fengyuan Dai","Zifeng Zhuang","Yufei Huang","Siteng Huang","Bangyan Liao","Donglin Wang","Fajie Yuan"],"url":"https://arxiv.org/abs/2505.15791"}
{"created":"2025-05-22","title":"Long-Form Information Alignment Evaluation Beyond Atomic Facts","abstract":"Information alignment evaluators are vital for various NLG evaluation tasks and trustworthy LLM deployment, reducing hallucinations and enhancing user trust. Current fine-grained methods, like FactScore, verify facts individually but neglect inter-fact dependencies, enabling subtle vulnerabilities. In this work, we introduce MontageLie, a challenging benchmark that constructs deceptive narratives by \"montaging\" truthful statements without introducing explicit hallucinations. We demonstrate that both coarse-grained LLM-based evaluators and current fine-grained frameworks are susceptible to this attack, with AUC-ROC scores falling below 65%. To enable more robust fine-grained evaluation, we propose DoveScore, a novel framework that jointly verifies factual accuracy and event-order consistency. By modeling inter-fact relationships, DoveScore outperforms existing fine-grained methods by over 8%, providing a more robust solution for long-form text alignment evaluation. Our code and datasets are available at https://github.com/dannalily/DoveScore.","authors":["Danna Zheng","Mirella Lapata","Jeff Z. Pan"],"url":"https://arxiv.org/abs/2505.15792"}
{"created":"2025-05-22","title":"HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving","abstract":"Integrating Large Language Models (LLMs) with Reinforcement Learning (RL) can enhance autonomous driving (AD) performance in complex scenarios. However, current LLM-Dominated RL methods over-rely on LLM outputs, which are prone to hallucinations.Evaluations show that state-of-the-art LLM indicates a non-hallucination rate of only approximately 57.95% when assessed on essential driving-related tasks. Thus, in these methods, hallucinations from the LLM can directly jeopardize the performance of driving policies. This paper argues that maintaining relative independence between the LLM and the RL is vital for solving the hallucinations problem. Consequently, this paper is devoted to propose a novel LLM-Hinted RL paradigm. The LLM is used to generate semantic hints for state augmentation and policy optimization to assist RL agent in motion planning, while the RL agent counteracts potential erroneous semantic indications through policy learning to achieve excellent driving performance. Based on this paradigm, we propose the HCRMP (LLM-Hinted Contextual Reinforcement Learning Motion Planner) architecture, which is designed that includes Augmented Semantic Representation Module to extend state space. Contextual Stability Anchor Module enhances the reliability of multi-critic weight hints by utilizing information from the knowledge base. Semantic Cache Module is employed to seamlessly integrate LLM low-frequency guidance with RL high-frequency control. Extensive experiments in CARLA validate HCRMP's strong overall driving performance. HCRMP achieves a task success rate of up to 80.3% under diverse driving conditions with different traffic densities. Under safety-critical driving conditions, HCRMP significantly reduces the collision rate by 11.4%, which effectively improves the driving performance in complex scenarios.","authors":["Zhiwen Chen","Bo Leng","Zhuoren Li","Hanming Deng","Guizhe Jin","Ran Yu","Huanxi Wen"],"url":"https://arxiv.org/abs/2505.15793"}
{"created":"2025-05-22","title":"Reverse Engineering Human Preferences with Reinforcement Learning","abstract":"The capabilities of Large Language Models (LLMs) are routinely evaluated by other LLMs trained to predict human preferences. This framework--known as LLM-as-a-judge--is highly scalable and relatively low cost. However, it is also vulnerable to malicious exploitation, as LLM responses can be tuned to overfit the preferences of the judge. Previous work shows that the answers generated by a candidate-LLM can be edited post hoc to maximise the score assigned to them by a judge-LLM. In this study, we adopt a different approach and use the signal provided by judge-LLMs as a reward to adversarially tune models that generate text preambles designed to boost downstream performance. We find that frozen LLMs pipelined with these models attain higher LLM-evaluation scores than existing frameworks. Crucially, unlike other frameworks which intervene directly on the model's response, our method is virtually undetectable. We also demonstrate that the effectiveness of the tuned preamble generator transfers when the candidate-LLM and the judge-LLM are replaced with models that are not used during training. These findings raise important questions about the design of more reliable LLM-as-a-judge evaluation settings. They also demonstrate that human preferences can be reverse engineered effectively, by pipelining LLMs to optimise upstream preambles via reinforcement learning--an approach that could find future applications in diverse tasks and domains beyond adversarial attacks.","authors":["Lisa Alazraki","Tan Yi-Chern","Jon Ander Campos","Maximilian Mozes","Marek Rei","Max Bartolo"],"url":"https://arxiv.org/abs/2505.15795"}
{"created":"2025-05-22","title":"Lean-SMT: An SMT tactic for discharging proof goals in Lean","abstract":"Lean is an increasingly popular proof assistant based on dependent type theory. Despite its success, it still lacks important automation features present in more seasoned proof assistants, such as the Sledgehammer tactic in Isabelle/HOL. A key aspect of Sledgehammer is the use of proof-producing SMT solvers to prove a translated proof goal and the reconstruction of the resulting proof into valid justifications for the original goal. We present Lean-SMT, a tactic providing this functionality in Lean. We detail how the tactic converts Lean goals into SMT problems and, more importantly, how it reconstructs SMT proofs into native Lean proofs. We evaluate the tactic on established benchmarks used to evaluate Sledgehammer's SMT integration, with promising results. We also evaluate Lean-SMT as a standalone proof checker for proofs of SMT-LIB problems. We show that Lean-SMT offers a smaller trusted core without sacrificing too much performance.","authors":["Abdalrhman Mohamed","Tomaz Mascarenhas","Harun Khan","Haniel Barbosa","Andrew Reynolds","Yicheng Qian","Cesare Tinelli","Clark Barrett"],"url":"https://arxiv.org/abs/2505.15796"}
{"created":"2025-05-22","title":"VoteMate: A Decentralized Application for Scalable Electronic Voting on EVM-Based Blockchain","abstract":"Voting is a cornerstone of democracy, allowing citizens to express their will and make collective decisions. With advancing technology, online voting is gaining popularity as it enables voting from anywhere with Internet access, eliminating the need for printed ballots or polling stations. However, despite its benefits, online voting carries significant risks. A single vulnerability could be exploited to manipulate elections on a large scale. Centralized systems can be secure but may lack transparency and confidentiality, especially if those in power manipulate them. Blockchain-based voting offers a transparent, tamper-resistant alternative with end-to-end verifiability and strong security. Adding cryptographic layers can also ensure voter confidentiality.","authors":["Ivan Homoliak","Tom\\'a\\v{s} \\v{S}vondr"],"url":"https://arxiv.org/abs/2505.15797"}
{"created":"2025-05-22","title":"Model Merging is Secretly Certifiable: Non-Vacuous Generalisation Bounds for Low-Shot Learning","abstract":"Certifying the IID generalisation ability of deep networks is the first of many requirements for trusting AI in high-stakes applications from medicine to security. However, when instantiating generalisation bounds for deep networks it remains challenging to obtain non-vacuous guarantees, especially when applying contemporary large models on the small scale data prevalent in such high-stakes fields. In this paper, we draw a novel connection between a family of learning methods based on model fusion and generalisation certificates, and surprisingly show that with minor adjustment several existing learning strategies already provide non-trivial generalisation guarantees. Essentially, by focusing on data-driven learning of downstream tasks by fusion rather than fine-tuning, the certified generalisation gap becomes tiny and independent of the base network size, facilitating its certification. Our results show for the first time non-trivial generalisation guarantees for learning with as low as 100 examples, while using vision models such as VIT-B and language models such as mistral-7B. This observation is significant as it has immediate implications for facilitating the certification of existing systems as trustworthy, and opens up new directions for research at the intersection of practice and theory.","authors":["Taehoon Kim","Henry Gouk","Minyoung Kim","Timothy Hospedales"],"url":"https://arxiv.org/abs/2505.15798"}
{"created":"2025-05-22","title":"The Agentic Economy","abstract":"Generative AI has transformed human-computer interaction by enabling natural language interfaces and the emergence of autonomous agents capable of acting on users' behalf. While early applications have improved individual productivity, these gains have largely been confined to predefined tasks within existing workflows. We argue that the more profound economic impact lies in reducing communication frictions between consumers and businesses. This shift could reorganize markets, redistribute power, and catalyze the creation of new products and services. We explore the implications of an agentic economy, where assistant agents act on behalf of consumers and service agents represent businesses, interacting programmatically to facilitate transactions. A key distinction we draw is between unscripted interactions -- enabled by technical advances in natural language and protocol design -- and unrestricted interactions, which depend on market structures and governance. We examine the current limitations of siloed and end-to-end agents, and explore future scenarios shaped by technical standards and market dynamics. These include the potential tension between agentic walled gardens and an open web of agents, implications for advertising and discovery, the evolution of micro-transactions, and the unbundling and rebundling of digital goods. Ultimately, we argue that the architecture of agentic communication will determine the extent to which generative AI democratizes access to economic opportunity.","authors":["David M. Rothschild","Markus Mobius","Jake M. Hofman","Eleanor W. Dillon","Daniel G. Goldstein","Nicole Immorlica","Sonia Jaffe","Brendan Lucier","Aleksandrs Slivkins","Matthew Vogel"],"url":"https://arxiv.org/abs/2505.15799"}
{"created":"2025-05-22","title":"Interspatial Attention for Efficient 4D Human Video Generation","abstract":"Generating photorealistic videos of digital humans in a controllable manner is crucial for a plethora of applications. Existing approaches either build on methods that employ template-based 3D representations or emerging video generation models but suffer from poor quality or limited consistency and identity preservation when generating individual or multiple digital humans. In this paper, we introduce a new interspatial attention (ISA) mechanism as a scalable building block for modern diffusion transformer (DiT)--based video generation models. ISA is a new type of cross attention that uses relative positional encodings tailored for the generation of human videos. Leveraging a custom-developed video variation autoencoder, we train a latent ISA-based diffusion model on a large corpus of video data. Our model achieves state-of-the-art performance for 4D human video synthesis, demonstrating remarkable motion consistency and identity preservation while providing precise control of the camera and body poses. Our code and model are publicly released at https://dsaurus.github.io/isa4d/.","authors":["Ruizhi Shao","Yinghao Xu","Yujun Shen","Ceyuan Yang","Yang Zheng","Changan Chen","Yebin Liu","Gordon Wetzstein"],"url":"https://arxiv.org/abs/2505.15800"}
{"created":"2025-05-22","title":"VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models","abstract":"Large reasoning models such as OpenAI o1 and DeepSeek-R1 have achieved remarkable performance in the domain of reasoning. A key component of their training is the incorporation of verifiable rewards within reinforcement learning (RL). However, existing reward benchmarks do not evaluate reference-based reward systems, leaving researchers with limited understanding of the accuracy of verifiers used in RL. In this paper, we introduce two benchmarks, VerifyBench and VerifyBench-Hard, designed to assess the performance of reference-based reward systems. These benchmarks are constructed through meticulous data collection and curation, followed by careful human annotation to ensure high quality. Current models still show considerable room for improvement on both VerifyBench and VerifyBench-Hard, especially smaller-scale models. Furthermore, we conduct a thorough and comprehensive analysis of evaluation results, offering insights for understanding and developing reference-based reward systems. Our proposed benchmarks serve as effective tools for guiding the development of verifier accuracy and the reasoning capabilities of models trained via RL in reasoning tasks.","authors":["Yuchen Yan","Jin Jiang","Zhenbang Ren","Yijun Li","Xudong Cai","Yang Liu","Xin Xu","Mengdi Zhang","Jian Shao","Yongliang Shen","Jun Xiao","Yueting Zhuang"],"url":"https://arxiv.org/abs/2505.15801"}
{"created":"2025-05-22","title":"A Deep Learning Framework for Two-Dimensional, Multi-Frequency Propagation Factor Estimation","abstract":"Accurately estimating the refractive environment over multiple frequencies within the marine atmospheric boundary layer is crucial for the effective deployment of radar technologies. Traditional parabolic equation simulations, while effective, can be computationally expensive and time-intensive, limiting their practical application. This communication explores a novel approach using deep neural networks to estimate the pattern propagation factor, a critical parameter for characterizing environmental impacts on signal propagation. Image-to-image translation generators designed to ingest modified refractivity data and generate predictions of pattern propagation factors over the same domain were developed. Findings demonstrate that deep neural networks can be trained to analyze multiple frequencies and reasonably predict the pattern propagation factor, offering an alternative to traditional methods.","authors":["Sarah E. Wessinger","Leslie N. Smith","Jacob Gull","Jonathan Gehman","Zachary Beever","Andrew J. Kammerer"],"url":"https://arxiv.org/abs/2505.15802"}
{"created":"2025-05-22","title":"Adaptive Estimation and Learning under Temporal Distribution Shift","abstract":"In this paper, we study the problem of estimation and learning under temporal distribution shift. Consider an observation sequence of length $n$, which is a noisy realization of a time-varying groundtruth sequence. Our focus is to develop methods to estimate the groundtruth at the final time-step while providing sharp point-wise estimation error rates. We show that, without prior knowledge on the level of temporal shift, a wavelet soft-thresholding estimator provides an optimal estimation error bound for the groundtruth. Our proposed estimation method generalizes existing researches Mazzetto and Upfal (2023) by establishing a connection between the sequence's non-stationarity level and the sparsity in the wavelet-transformed domain. Our theoretical findings are validated by numerical experiments. Additionally, we applied the estimator to derive sparsity-aware excess risk bounds for binary classification under distribution shift and to develop computationally efficient training objectives. As a final contribution, we draw parallels between our results and the classical signal processing problem of total-variation denoising (Mammen and van de Geer,1997; Tibshirani, 2014), uncovering novel optimal algorithms for such task.","authors":["Dheeraj Baby","Yifei Tang","Hieu Duy Nguyen","Yu-Xiang Wang","Rohit Pyati"],"url":"https://arxiv.org/abs/2505.15803"}
{"created":"2025-05-22","title":"STAR-R1: Spacial TrAnsformation Reasoning by Reinforcing Multimodal LLMs","abstract":"Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across diverse tasks, yet they lag significantly behind humans in spatial reasoning. We investigate this gap through Transformation-Driven Visual Reasoning (TVR), a challenging task requiring identification of object transformations across images under varying viewpoints. While traditional Supervised Fine-Tuning (SFT) fails to generate coherent reasoning paths in cross-view settings, sparse-reward Reinforcement Learning (RL) suffers from inefficient exploration and slow convergence. To address these limitations, we propose STAR-R1, a novel framework that integrates a single-stage RL paradigm with a fine-grained reward mechanism tailored for TVR. Specifically, STAR-R1 rewards partial correctness while penalizing excessive enumeration and passive inaction, enabling efficient exploration and precise reasoning. Comprehensive evaluations demonstrate that STAR-R1 achieves state-of-the-art performance across all 11 metrics, outperforming SFT by 23% in cross-view scenarios. Further analysis reveals STAR-R1's anthropomorphic behavior and highlights its unique ability to compare all objects for improving spatial reasoning. Our work provides critical insights in advancing the research of MLLMs and reasoning models. The codes, model weights, and data will be publicly available at https://github.com/zongzhao23/STAR-R1.","authors":["Zongzhao Li","Zongyang Ma","Mingze Li","Songyou Li","Yu Rong","Tingyang Xu","Ziqi Zhang","Deli Zhao","Wenbing Huang"],"url":"https://arxiv.org/abs/2505.15804"}
{"created":"2025-05-22","title":"Keep Security! Benchmarking Security Policy Preservation in Large Language Model Contexts Against Indirect Attacks in Question Answering","abstract":"As Large Language Models (LLMs) are increasingly deployed in sensitive domains such as enterprise and government, ensuring that they adhere to user-defined security policies within context is critical-especially with respect to information non-disclosure. While prior LLM studies have focused on general safety and socially sensitive data, large-scale benchmarks for contextual security preservation against attacks remain lacking. To address this, we introduce a novel large-scale benchmark dataset, CoPriva, evaluating LLM adherence to contextual non-disclosure policies in question answering. Derived from realistic contexts, our dataset includes explicit policies and queries designed as direct and challenging indirect attacks seeking prohibited information. We evaluate 10 LLMs on our benchmark and reveal a significant vulnerability: many models violate user-defined policies and leak sensitive information. This failure is particularly severe against indirect attacks, highlighting a critical gap in current LLM safety alignment for sensitive applications. Our analysis reveals that while models can often identify the correct answer to a query, they struggle to incorporate policy constraints during generation. In contrast, they exhibit a partial ability to revise outputs when explicitly prompted. Our findings underscore the urgent need for more robust methods to guarantee contextual security.","authors":["Hwan Chang","Yumin Kim","Yonghyun Jun","Hwanhee Lee"],"url":"https://arxiv.org/abs/2505.15805"}
{"created":"2025-05-22","title":"The Atlas of In-Context Learning: How Attention Heads Shape In-Context Retrieval Augmentation","abstract":"Large language models are able to exploit in-context learning to access external knowledge beyond their training data through retrieval-augmentation. While promising, its inner workings remain unclear. In this work, we shed light on the mechanism of in-context retrieval augmentation for question answering by viewing a prompt as a composition of informational components. We propose an attribution-based method to identify specialized attention heads, revealing in-context heads that comprehend instructions and retrieve relevant contextual information, and parametric heads that store entities' relational knowledge. To better understand their roles, we extract function vectors and modify their attention weights to show how they can influence the answer generation process. Finally, we leverage the gained insights to trace the sources of knowledge used during inference, paving the way towards more safe and transparent language models.","authors":["Patrick Kahardipraja","Reduan Achtibat","Thomas Wiegand","Wojciech Samek","Sebastian Lapuschkin"],"url":"https://arxiv.org/abs/2505.15807"}
{"created":"2025-05-22","title":"Neural Conditional Transport Maps","abstract":"We present a neural framework for learning conditional optimal transport (OT) maps between probability distributions. Our approach introduces a conditioning mechanism capable of processing both categorical and continuous conditioning variables simultaneously. At the core of our method lies a hypernetwork that generates transport layer parameters based on these inputs, creating adaptive mappings that outperform simpler conditioning methods. Comprehensive ablation studies demonstrate the superior performance of our method over baseline configurations. Furthermore, we showcase an application to global sensitivity analysis, offering high performance in computing OT-based sensitivity indices. This work advances the state-of-the-art in conditional optimal transport, enabling broader application of optimal transport principles to complex, high-dimensional domains such as generative modeling and black-box model explainability.","authors":["Carlos Rodriguez-Pardo","Leonardo Chiani","Emanuele Borgonovo","Massimo Tavoni"],"url":"https://arxiv.org/abs/2505.15808"}
{"created":"2025-05-22","title":"MMaDA: Multimodal Large Diffusion Language Models","abstract":"We introduce MMaDA, a novel class of multimodal diffusion foundation models designed to achieve superior performance across diverse domains such as textual reasoning, multimodal understanding, and text-to-image generation. The approach is distinguished by three key innovations: (i) MMaDA adopts a unified diffusion architecture with a shared probabilistic formulation and a modality-agnostic design, eliminating the need for modality-specific components. This architecture ensures seamless integration and processing across different data types. (ii) We implement a mixed long chain-of-thought (CoT) fine-tuning strategy that curates a unified CoT format across modalities. By aligning reasoning processes between textual and visual domains, this strategy facilitates cold-start training for the final reinforcement learning (RL) stage, thereby enhancing the model's ability to handle complex tasks from the outset. (iii) We propose UniGRPO, a unified policy-gradient-based RL algorithm specifically tailored for diffusion foundation models. Utilizing diversified reward modeling, UniGRPO unifies post-training across both reasoning and generation tasks, ensuring consistent performance improvements. Experimental results demonstrate that MMaDA-8B exhibits strong generalization capabilities as a unified multimodal foundation model. It surpasses powerful models like LLaMA-3-7B and Qwen2-7B in textual reasoning, outperforms Show-o and SEED-X in multimodal understanding, and excels over SDXL and Janus in text-to-image generation. These achievements highlight MMaDA's effectiveness in bridging the gap between pretraining and post-training within unified diffusion architectures, providing a comprehensive framework for future research and development. We open-source our code and trained models at: https://github.com/Gen-Verse/MMaDA","authors":["Ling Yang","Ye Tian","Bowen Li","Xinchen Zhang","Ke Shen","Yunhai Tong","Mengdi Wang"],"url":"https://arxiv.org/abs/2505.15809"}
{"created":"2025-05-22","title":"GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents","abstract":"Recent Graphical User Interface (GUI) agents replicate the R1-Zero paradigm, coupling online Reinforcement Learning (RL) with explicit chain-of-thought reasoning prior to object grounding and thereby achieving substantial performance gains. In this paper, we first conduct extensive analysis experiments of three key components of that training pipeline: input design, output evaluation, and policy update-each revealing distinct challenges arising from blindly applying general-purpose RL without adapting to GUI grounding tasks. Input design: Current templates encourage the model to generate chain-of-thought reasoning, but longer chains unexpectedly lead to worse grounding performance. Output evaluation: Reward functions based on hit signals or box area allow models to exploit box size, leading to reward hacking and poor localization quality. Policy update: Online RL tends to overfit easy examples due to biases in length and sample difficulty, leading to under-optimization on harder cases. To address these issues, we propose three targeted solutions. First, we adopt a Fast Thinking Template that encourages direct answer generation, reducing excessive reasoning during training. Second, we incorporate a box size constraint into the reward function to mitigate reward hacking. Third, we revise the RL objective by adjusting length normalization and adding a difficulty-aware scaling factor, enabling better optimization on hard samples. Our GUI-G1-3B, trained on 17K public samples with Qwen2.5-VL-3B-Instruct, achieves 90.3% accuracy on ScreenSpot and 37.1% on ScreenSpot-Pro. This surpasses all prior models of similar size and even outperforms the larger UI-TARS-7B, establishing a new state-of-the-art in GUI agent grounding. The project repository is available at https://github.com/Yuqi-Zhou/GUI-G1.","authors":["Yuqi Zhou","Sunhao Dai","Shuai Wang","Kaiwen Zhou","Qinqlin Jia","Junxu"],"url":"https://arxiv.org/abs/2505.15810"}
{"created":"2025-05-22","title":"On the creation of narrow AI: hierarchy and nonlocality of neural network skills","abstract":"We study the problem of creating strong, yet narrow, AI systems. While recent AI progress has been driven by the training of large general-purpose foundation models, the creation of smaller models specialized for narrow domains could be valuable for both efficiency and safety. In this work, we explore two challenges involved in creating such systems, having to do with basic properties of how neural networks learn and structure their representations. The first challenge regards when it is possible to train narrow models from scratch. Through experiments on a synthetic task, we find that it is sometimes necessary to train networks on a wide distribution of data to learn certain narrow skills within that distribution. This effect arises when skills depend on each other hierarchically, and training on a broad distribution introduces a curriculum which substantially accelerates learning. The second challenge regards how to transfer particular skills from large general models into small specialized models. We find that model skills are often not perfectly localized to a particular set of prunable components. However, we find that methods based on pruning can still outperform distillation. We investigate the use of a regularization objective to align desired skills with prunable components while unlearning unnecessary skills.","authors":["Eric J. Michaud","Asher Parker-Sartori","Max Tegmark"],"url":"https://arxiv.org/abs/2505.15811"}
{"created":"2025-05-22","title":"Leveraging the Powerful Attention of a Pre-trained Diffusion Model for Exemplar-based Image Colorization","abstract":"Exemplar-based image colorization aims to colorize a grayscale image using a reference color image, ensuring that reference colors are applied to corresponding input regions based on their semantic similarity. To achieve accurate semantic matching between regions, we leverage the self-attention module of a pre-trained diffusion model, which is trained on a large dataset and exhibits powerful attention capabilities. To harness this power, we propose a novel, fine-tuning-free approach based on a pre-trained diffusion model, making two key contributions. First, we introduce dual attention-guided color transfer. We utilize the self-attention module to compute an attention map between the input and reference images, effectively capturing semantic correspondences. The color features from the reference image is then transferred to the semantically matching regions of the input image, guided by this attention map, and finally, the grayscale features are replaced with the corresponding color features. Notably, we utilize dual attention to calculate attention maps separately for the grayscale and color images, achieving more precise semantic alignment. Second, we propose classifier-free colorization guidance, which enhances the transferred colors by combining color-transferred and non-color-transferred outputs. This process improves the quality of colorization. Our experimental results demonstrate that our method outperforms existing techniques in terms of image quality and fidelity to the reference. Specifically, we use 335 input-reference pairs from previous research, achieving an FID of 95.27 (image quality) and an SI-FID of 5.51 (fidelity to the reference). Our source code is available at https://github.com/satoshi-kosugi/powerful-attention.","authors":["Satoshi Kosugi"],"url":"https://arxiv.org/abs/2505.15812"}
{"created":"2025-05-22","title":"Meta-Learning an In-Context Transformer Model of Human Higher Visual Cortex","abstract":"Understanding functional representations within higher visual cortex is a fundamental question in computational neuroscience. While artificial neural networks pretrained on large-scale datasets exhibit striking representational alignment with human neural responses, learning image-computable models of visual cortex relies on individual-level, large-scale fMRI datasets. The necessity for expensive, time-intensive, and often impractical data acquisition limits the generalizability of encoders to new subjects and stimuli. BraInCoRL uses in-context learning to predict voxelwise neural responses from few-shot examples without any additional finetuning for novel subjects and stimuli. We leverage a transformer architecture that can flexibly condition on a variable number of in-context image stimuli, learning an inductive bias over multiple subjects. During training, we explicitly optimize the model for in-context learning. By jointly conditioning on image features and voxel activations, our model learns to directly generate better performing voxelwise models of higher visual cortex. We demonstrate that BraInCoRL consistently outperforms existing voxelwise encoder designs in a low-data regime when evaluated on entirely novel images, while also exhibiting strong test-time scaling behavior. The model also generalizes to an entirely new visual fMRI dataset, which uses different subjects and fMRI data acquisition parameters. Further, BraInCoRL facilitates better interpretability of neural signals in higher visual cortex by attending to semantically relevant stimuli. Finally, we show that our framework enables interpretable mappings from natural language queries to voxel selectivity.","authors":["Muquan Yu","Mu Nan","Hossein Adeli","Jacob S. Prince","John A. Pyles","Leila Wehbe","Margaret M. Henderson","Michael J. Tarr","Andrew F. Luo"],"url":"https://arxiv.org/abs/2505.15813"}
{"created":"2025-05-22","title":"A Taxonomy of Structure from Motion Methods","abstract":"Structure from Motion (SfM) refers to the problem of recovering both structure (i.e., 3D coordinates of points in the scene) and motion (i.e., camera matrices) starting from point correspondences in multiple images. It has attracted significant attention over the years, counting practical reconstruction pipelines as well as theoretical results. This paper is conceived as a conceptual review of SfM methods, which are grouped into three main categories, according to which part of the problem - between motion and structure - they focus on. The proposed taxonomy brings a new perspective on existing SfM approaches as well as insights into open problems and possible future research directions. Particular emphasis is given on identifying the theoretical conditions that make SfM well posed, which depend on the problem formulation that is being considered.","authors":["Federica Arrigoni"],"url":"https://arxiv.org/abs/2505.15814"}
{"created":"2025-05-22","title":"Streamline Without Sacrifice -- Squeeze out Computation Redundancy in LMM","abstract":"Large multimodal models excel in multimodal tasks but face significant computational challenges due to excessive computation on visual tokens. Unlike token reduction methods that focus on token-level redundancy, we identify and study the computation-level redundancy on vision tokens to ensure no information loss. Our key insight is that vision tokens from the pretrained vision encoder do not necessarily require all the heavy operations (e.g., self-attention, FFNs) in decoder-only LMMs and could be processed more lightly with proper designs. We designed a series of experiments to discover and progressively squeeze out the vision-related computation redundancy. Based on our findings, we propose ProxyV, a novel approach that utilizes proxy vision tokens to alleviate the computational burden on original vision tokens. ProxyV enhances efficiency without compromising performance and can even yield notable performance gains in scenarios with more moderate efficiency improvements. Furthermore, the flexibility of ProxyV is demonstrated through its combination with token reduction methods to boost efficiency further. The code will be made public at this https://github.com/penghao-wu/ProxyV URL.","authors":["Penghao Wu","Lewei Lu","Ziwei Liu"],"url":"https://arxiv.org/abs/2505.15816"}
{"created":"2025-05-22","title":"Learning to Reason via Mixture-of-Thought for Logical Reasoning","abstract":"Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typically natural language. Although some methods explored modality selection or augmentation at inference time, the training process remains modality-blind, limiting synergy among modalities. To fill in this gap, we propose Mixture-of-Thought (MoT), a framework that enables LLMs to reason across three complementary modalities: natural language, code, and a newly introduced symbolic modality, truth-table, which systematically enumerates logical cases and partially mitigates key failure modes in natural language reasoning. MoT adopts a two-phase design: (1) self-evolving MoT training, which jointly learns from filtered, self-generated rationales across modalities; and (2) MoT inference, which fully leverages the synergy of three modalities to produce better predictions. Experiments on logical reasoning benchmarks including FOLIO and ProofWriter demonstrate that our MoT framework consistently and significantly outperforms strong LLM baselines with single-modality chain-of-thought approaches, achieving up to +11.7pp average accuracy gain. Further analyses show that our MoT framework benefits both training and inference stages; that it is particularly effective on harder logical reasoning problems; and that different modalities contribute complementary strengths, with truth-table reasoning helping to overcome key bottlenecks in natural language inference.","authors":["Tong Zheng","Lichang Chen","Simeng Han","R. Thomas McCoy","Heng Huang"],"url":"https://arxiv.org/abs/2505.15817"}
{"created":"2025-05-22","title":"InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition","abstract":"Language-Guided object recognition in remote sensing imagery is crucial for large-scale mapping and automated data annotation. However, existing open-vocabulary and visual grounding methods rely on explicit category cues, limiting their ability to handle complex or implicit queries that require advanced reasoning. To address this issue, we introduce a new suite of tasks, including Instruction-Oriented Object Counting, Detection, and Segmentation (InstructCDS), covering open-vocabulary, open-ended, and open-subclass scenarios. We further present EarthInstruct, the first InstructCDS benchmark for earth observation. It is constructed from two diverse remote sensing datasets with varying spatial resolutions and annotation rules across 20 categories, necessitating models to interpret dataset-specific instructions. Given the scarcity of semantically rich labeled data in remote sensing, we propose InstructSAM, a training-free framework for instruction-driven object recognition. InstructSAM leverages large vision-language models to interpret user instructions and estimate object counts, employs SAM2 for mask proposal, and formulates mask-label assignment as a binary integer programming problem. By integrating semantic similarity with counting constraints, InstructSAM efficiently assigns categories to predicted masks without relying on confidence thresholds. Experiments demonstrate that InstructSAM matches or surpasses specialized baselines across multiple tasks while maintaining near-constant inference time regardless of object count, reducing output tokens by 89% and overall runtime by over 32% compared to direct generation approaches. We believe the contributions of the proposed tasks, benchmark, and effective approach will advance future research in developing versatile object recognition systems.","authors":["Yijie Zheng","Weijie Wu","Qingyun Li","Xuehui Wang","Xu Zhou","Aiai Ren","Jun Shen","Long Zhao","Guoqing Li","Xue Yang"],"url":"https://arxiv.org/abs/2505.15818"}
{"created":"2025-05-22","title":"THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering","abstract":"We propose THELMA (Task Based Holistic Evaluation of Large Language Model Applications), a reference free framework for RAG (Retrieval Augmented generation) based question answering (QA) applications. THELMA consist of six interdependent metrics specifically designed for holistic, fine grained evaluation of RAG QA applications. THELMA framework helps developers and application owners evaluate, monitor and improve end to end RAG QA pipelines without requiring labelled sources or reference responses.We also present our findings on the interplay of the proposed THELMA metrics, which can be interpreted to identify the specific RAG component needing improvement in QA applications.","authors":["Udita Patel","Rutu Mulkar","Jay Roberts","Cibi Chakravarthy Senthilkumar","Sujay Gandhi","Xiaofei Zheng","Naumaan Nayyar","Rafael Castrillo"],"url":"https://arxiv.org/abs/2505.11626"}
{"created":"2025-05-22","title":"infomeasure: A Comprehensive Python Package for Information Theory Measures and Estimators","abstract":"Information theory, i.e. the mathematical analysis of information and of its processing, has become a tenet of modern science; yet, its use in real-world studies is usually hindered by its computational complexity, the lack of coherent software frameworks, and, as a consequence, low reproducibility. We here introduce infomeasure, an open-source Python package designed to provide robust tools for calculating a wide variety of information-theoretic measures, including entropies, mutual information, transfer entropy and divergences. It is designed for both discrete and continuous variables; implements state-of-the-art estimation techniques; and allows the calculation of local measure values, $p$-values and $t$-scores. By unifying these approaches under one consistent framework, infomeasure aims to mitigate common pitfalls, ensure reproducibility, and simplify the practical implementation of information-theoretic analyses. In this contribution, we explore the motivation and features of infomeasure; its validation, using known analytical solutions; and exemplify its utility in a case study involving the analysis of human brain time series.","authors":["Carlson Moses B\\\"uth","Kishor Acharya","Massimiliano Zanin"],"url":"https://arxiv.org/abs/2505.14696"}
{"created":"2025-05-22","title":"Global Description of Flutter Dynamics via Koopman Theory","abstract":"This paper presents a novel parametrization approach for aeroelastic systems utilizing Koopman theory, specifically leveraging the Koopman Bilinear Form (KBF) model. To address the limitations of linear parametric dependence in the KBF model, we introduce the Extended KBF (EKBF) model, which enables a global linear representation of aeroelastic dynamics while capturing stronger nonlinear dependence on, e.g., the flutter parameter. The effectiveness of the proposed methodology is demonstrated through two case studies: a 2D academic example and a panel flutter problem. Results show that EKBF effectively interpolates and extrapolates principal eigenvalues, capturing flutter mechanisms, and accurately predicting the flutter boundary even when the data is corrupted by noise. Furthermore, parameterized isostable and isochron identified by EKBF provides valuable insights into the nonlinear flutter system.","authors":["Jiwoo Song","Daning Huang"],"url":"https://arxiv.org/abs/2505.14697"}
{"created":"2025-05-22","title":"Towards scalable surrogate models based on Neural Fields for large scale aerodynamic simulations","abstract":"This paper introduces a novel surrogate modeling framework for aerodynamic applications based on Neural Fields. The proposed approach, MARIO (Modulated Aerodynamic Resolution Invariant Operator), addresses non parametric geometric variability through an efficient shape encoding mechanism and exploits the discretization-invariant nature of Neural Fields. It enables training on significantly downsampled meshes, while maintaining consistent accuracy during full-resolution inference. These properties allow for efficient modeling of diverse flow conditions, while reducing computational cost and memory requirements compared to traditional CFD solvers and existing surrogate methods. The framework is validated on two complementary datasets that reflect industrial constraints. First, the AirfRANS dataset consists in a two-dimensional airfoil benchmark with non-parametric shape variations. Performance evaluation of MARIO on this case demonstrates an order of magnitude improvement in prediction accuracy over existing methods across velocity, pressure, and turbulent viscosity fields, while accurately capturing boundary layer phenomena and aerodynamic coefficients. Second, the NASA Common Research Model features three-dimensional pressure distributions on a full aircraft surface mesh, with parametric control surface deflections. This configuration confirms MARIO's accuracy and scalability. Benchmarking against state-of-the-art methods demonstrates that Neural Field surrogates can provide rapid and accurate aerodynamic predictions under the computational and data limitations characteristic of industrial applications.","authors":["Giovanni Catalani","Jean Fesquet","Xavier Bertrand","Fr\\'ed\\'eric Tost","Michael Bauerheim","Joseph Morlier"],"url":"https://arxiv.org/abs/2505.14704"}
{"created":"2025-05-22","title":"Space evaluation at the starting point of soccer transitions","abstract":"Soccer is a sport played on a pitch where effective use of space is crucial. Decision-making during transitions, when possession switches between teams, has been increasingly important, but research on space evaluation in these moments has been limited. Recent space evaluation methods such as OBSO (Off-Ball Scoring Opportunity) use scoring probability, so it is not well-suited for assessing areas far from the goal, where transitions typically occur. In this paper, we propose OBPV (Off-Ball Positioning Value) to evaluate space across the pitch, including the starting points of transitions. OBPV extends OBSO by introducing the field value model, which evaluates the entire pitch, and by employing the transition kernel model, which reflects positional specificity through kernel density estimation of pass distributions. Experiments using La Liga 2023/24 season tracking and event data show that OBPV highlights effective space utilization during counter-attacks and reveals team-specific characteristics in how the teams utilize space after positive and negative transitions.","authors":["Yohei Ogawa","Rikuhei Umemoto","Keisuke Fujii"],"url":"https://arxiv.org/abs/2505.14711"}
{"created":"2025-05-22","title":"Stochastic Processes with Modified Lognormal Distribution Featuring Flexible Upper Tail","abstract":"Asymmetric, non-Gaussian probability distributions are often observed in the analysis of natural and engineering datasets. The lognormal distribution is a standard model for data with skewed frequency histograms and fat tails. However, the lognormal law severely restricts the asymptotic dependence of the probability density and the hazard function for high values. Herein we present a family of three-parameter non-Gaussian probability density functions that are based on generalized kappa-exponential and kappa-logarithm functions and investigate its mathematical properties. These kappa-lognormal densities represent continuous deformations of the lognormal with lighter right tails, controlled by the parameter kappa. In addition, bimodal distributions are obtained for certain parameter combinations. We derive closed-form analytic expressions for the main statistical functions of the kappa-lognormal distribution. For the moments, we derive bounds that are based on hypergeometric functions as well as series expansions. Explicit expressions for the gradient and Hessian of the negative log-likelihood are obtained to facilitate numerical maximum-likelihood estimates of the kappa-lognormal parameters from data. We also formulate a joint probability density function for kappa-lognormal stochastic processes by applying Jacobi's multivariate theorem to a latent Gaussian process. Estimation of the kappa-lognormal distribution based on synthetic and real data is explored. Furthermore, we investigate applications of kappa-lognormal processes with different covariance kernels in time series forecasting and spatial interpolation using warped Gaussian process regression. Our results are of practical interest for modeling skewed distributions in various scientific and engineering fields.","authors":["Dionissios T. Hristopulos","Anastassia Baxevani","Giorgio Kaniadakis"],"url":"https://arxiv.org/abs/2505.14713"}
{"created":"2025-05-22","title":"A Comprehensive Review of Techniques, Algorithms, Advancements, Challenges, and Clinical Applications of Multi-modal Medical Image Fusion for Improved Diagnosis","abstract":"Multi-modal medical image fusion (MMIF) is increasingly recognized as an essential technique for enhancing diagnostic precision and facilitating effective clinical decision-making within computer-aided diagnosis systems. MMIF combines data from X-ray, MRI, CT, PET, SPECT, and ultrasound to create detailed, clinically useful images of patient anatomy and pathology. These integrated representations significantly advance diagnostic accuracy, lesion detection, and segmentation. This comprehensive review meticulously surveys the evolution, methodologies, algorithms, current advancements, and clinical applications of MMIF. We present a critical comparative analysis of traditional fusion approaches, including pixel-, feature-, and decision-level methods, and delves into recent advancements driven by deep learning, generative models, and transformer-based architectures. A critical comparative analysis is presented between these conventional methods and contemporary techniques, highlighting differences in robustness, computational efficiency, and interpretability. The article addresses extensive clinical applications across oncology, neurology, and cardiology, demonstrating MMIF's vital role in precision medicine through improved patient-specific therapeutic outcomes. Moreover, the review thoroughly investigates the persistent challenges affecting MMIF's broad adoption, including issues related to data privacy, heterogeneity, computational complexity, interpretability of AI-driven algorithms, and integration within clinical workflows. It also identifies significant future research avenues, such as the integration of explainable AI, adoption of privacy-preserving federated learning frameworks, development of real-time fusion systems, and standardization efforts for regulatory compliance.","authors":["Muhammad Zubair","Muzammil Hussai","Mousa Ahmad Al-Bashrawi","Malika Bendechache","Muhammad Owais"],"url":"https://arxiv.org/abs/2505.14715"}
{"created":"2025-05-22","title":"A Hybrid Quantum Classical Pipeline for X Ray Based Fracture Diagnosis","abstract":"Bone fractures are a leading cause of morbidity and disability worldwide, imposing significant clinical and economic burdens on healthcare systems. Traditional X ray interpretation is time consuming and error prone, while existing machine learning and deep learning solutions often demand extensive feature engineering, large, annotated datasets, and high computational resources. To address these challenges, a distributed hybrid quantum classical pipeline is proposed that first applies Principal Component Analysis (PCA) for dimensionality reduction and then leverages a 4 qubit quantum amplitude encoding circuit for feature enrichment. By fusing eight PCA derived features with eight quantum enhanced features into a 16 dimensional vector and then classifying with different machine learning models achieving 99% accuracy using a public multi region X ray dataset on par with state of the art transfer learning models while reducing feature extraction time by 82%.","authors":["Sahil Tomar","Rajeshwar Tripathi","Sandeep Kumar"],"url":"https://arxiv.org/abs/2505.14716"}
{"created":"2025-05-22","title":"Aneumo: A Large-Scale Multimodal Aneurysm Dataset with Computational Fluid Dynamics Simulations and Deep Learning Benchmarks","abstract":"Intracranial aneurysms (IAs) are serious cerebrovascular lesions found in approximately 5\\% of the general population. Their rupture may lead to high mortality. Current methods for assessing IA risk focus on morphological and patient-specific factors, but the hemodynamic influences on IA development and rupture remain unclear. While accurate for hemodynamic studies, conventional computational fluid dynamics (CFD) methods are computationally intensive, hindering their deployment in large-scale or real-time clinical applications. To address this challenge, we curated a large-scale, high-fidelity aneurysm CFD dataset to facilitate the development of efficient machine learning algorithms for such applications. Based on 427 real aneurysm geometries, we synthesized 10,660 3D shapes via controlled deformation to simulate aneurysm evolution. The authenticity of these synthetic shapes was confirmed by neurosurgeons. CFD computations were performed on each shape under eight steady-state mass flow conditions, generating a total of 85,280 blood flow dynamics data covering key parameters. Furthermore, the dataset includes segmentation masks, which can support tasks that use images, point clouds or other multimodal data as input. Additionally, we introduced a benchmark for estimating flow parameters to assess current modeling methods. This dataset aims to advance aneurysm research and promote data-driven approaches in biofluids, biomedical engineering, and clinical risk assessment. The code and dataset are available at: https://github.com/Xigui-Li/Aneumo.","authors":["Xigui Li","Yuanye Zhou","Feiyang Xiao","Xin Guo","Chen Jiang","Tan Pan","Xingmeng Zhang","Cenyu Liu","Zeyun Miao","Jianchao Ge","Xiansheng Wang","Qimeng Wang","Yichi Zhang","Wenbo Zhang","Fengping Zhu","Limei Han","Yuan Qi","Chensen Lin","Yuan Cheng"],"url":"https://arxiv.org/abs/2505.14717"}
{"created":"2025-05-22","title":"ComBAT Harmonization for diffusion MRI: Challenges and Best Practices","abstract":"Over the years, ComBAT has become the standard method for harmonizing MRI-derived measurements, with its ability to compensate for site-related additive and multiplicative biases while preserving biological variability. However, ComBAT relies on a set of assumptions that, when violated, can result in flawed harmonization. In this paper, we thoroughly review ComBAT's mathematical foundation, outlining these assumptions, and exploring their implications for the demographic composition necessary for optimal results.","authors":["Pierre-Marc Jodoin","Manon Edde","Gabriel Girard","F\\'elix Dumais","Guillaume Theaud","Matthieu Dumont","Jean-Christophe Houde","Yoan David","Maxime Descoteaux"],"url":"https://arxiv.org/abs/2505.14722"}
{"created":"2025-05-22","title":"QUADS: QUAntized Distillation Framework for Efficient Speech Language Understanding","abstract":"Spoken Language Understanding (SLU) systems must balance performance and efficiency, particularly in resource-constrained environments. Existing methods apply distillation and quantization separately, leading to suboptimal compression as distillation ignores quantization constraints. We propose QUADS, a unified framework that optimizes both through multi-stage training with a pre-tuned model, enhancing adaptability to low-bit regimes while maintaining accuracy. QUADS achieves 71.13\\% accuracy on SLURP and 99.20\\% on FSC, with only minor degradations of up to 5.56\\% compared to state-of-the-art models. Additionally, it reduces computational complexity by 60--73$\\times$ (GMACs) and model size by 83--700$\\times$, demonstrating strong robustness under extreme quantization. These results establish QUADS as a highly efficient solution for real-world, resource-constrained SLU applications.","authors":["Subrata Biswas","Mohammad Nur Hossain Khan","Bashima Islam"],"url":"https://arxiv.org/abs/2505.14723"}
{"created":"2025-05-22","title":"HR-VILAGE-3K3M: A Human Respiratory Viral Immunization Longitudinal Gene Expression Dataset for Systems Immunity","abstract":"Respiratory viral infections pose a global health burden, yet the cellular immune responses driving protection or pathology remain unclear. Natural infection cohorts often lack pre-exposure baseline data and structured temporal sampling. In contrast, inoculation and vaccination trials generate insightful longitudinal transcriptomic data. However, the scattering of these datasets across platforms, along with inconsistent metadata and preprocessing procedure, hinders AI-driven discovery. To address these challenges, we developed the Human Respiratory Viral Immunization LongitudinAl Gene Expression (HR-VILAGE-3K3M) repository: an AI-ready, rigorously curated dataset that integrates 14,136 RNA-seq profiles from 3,178 subjects across 66 studies encompassing over 2.56 million cells. Spanning vaccination, inoculation, and mixed exposures, the dataset includes microarray, bulk RNA-seq, and single-cell RNA-seq from whole blood, PBMCs, and nasal swabs, sourced from GEO, ImmPort, and ArrayExpress. We harmonized subject-level metadata, standardized outcome measures, applied unified preprocessing pipelines with rigorous quality control, and aligned all data to official gene symbols. To demonstrate the utility of HR-VILAGE-3K3M, we performed predictive modeling of vaccine responders and evaluated batch-effect correction methods. Beyond these initial demonstrations, it supports diverse systems immunology applications and benchmarking of feature selection and transfer learning algorithms. Its scale and heterogeneity also make it ideal for pretraining foundation models of the human immune response and for advancing multimodal learning frameworks. As the largest longitudinal transcriptomic resource for human respiratory viral immunization, it provides an accessible platform for reproducible AI-driven research, accelerating systems immunology and vaccine development against emerging viral threats.","authors":["Xuejun Sun","Yiran Song","Xiaochen Zhou","Ruilie Cai","Yu Zhang","Xinyi Li","Rui Peng","Jialiu Xie","Yuanyuan Yan","Muyao Tang","Prem Lakshmanane","Baiming Zou","James S. Hagood","Raymond J. Pickles","Didong Li","Fei Zou","Xiaojing Zheng"],"url":"https://arxiv.org/abs/2505.14725"}
{"created":"2025-05-22","title":"MedBLIP: Fine-tuning BLIP for Medical Image Captioning","abstract":"Medical image captioning is a challenging task that requires generating clinically accurate and semantically meaningful descriptions of radiology images. While recent vision-language models (VLMs) such as BLIP, BLIP2, Gemini and ViT-GPT2 show strong performance on natural image datasets, they often produce generic or imprecise captions when applied to specialized medical domains. In this project, we explore the effectiveness of fine-tuning the BLIP model on the ROCO dataset for improved radiology captioning. We compare the fine-tuned BLIP against its zero-shot version, BLIP-2 base, BLIP-2 Instruct and a ViT-GPT2 transformer baseline. Our results demonstrate that domain-specific fine-tuning on BLIP significantly improves performance across both quantitative and qualitative evaluation metrics. We also visualize decoder cross-attention maps to assess interpretability and conduct an ablation study to evaluate the contributions of encoder-only and decoder-only fine-tuning. Our findings highlight the importance of targeted adaptation for medical applications and suggest that decoder-only fine-tuning (encoder-frozen) offers a strong performance baseline with 5% lower training time than full fine-tuning, while full model fine-tuning still yields the best results overall.","authors":["Manshi Limbu","Diwita Banerjee"],"url":"https://arxiv.org/abs/2505.14726"}
{"created":"2025-05-22","title":"Predicting Neo-Adjuvant Chemotherapy Response in Triple-Negative Breast Cancer Using Pre-Treatment Histopathologic Images","abstract":"Triple-negative breast cancer (TNBC) is an aggressive subtype defined by the lack of estrogen receptor (ER), progesterone receptor (PR), and human epidermal growth factor receptor 2 (HER2) expression, resulting in limited targeted treatment options. Neoadjuvant chemotherapy (NACT) is the standard treatment for early-stage TNBC, with pathologic complete response (pCR) serving as a key prognostic marker; however, only 40-50% of patients with TNBC achieve pCR. Accurate prediction of NACT response is crucial to optimize therapy, avoid ineffective treatments, and improve patient outcomes. In this study, we developed a deep learning model to predict NACT response using pre-treatment hematoxylin and eosin (H&amp;E)-stained biopsy images. Our model achieved promising results in five-fold cross-validation (accuracy: 82%, AUC: 0.86, F1-score: 0.84, sensitivity: 0.85, specificity: 0.81, precision: 0.80). Analysis of model attention maps in conjunction with multiplexed immunohistochemistry (mIHC) data revealed that regions of high predictive importance consistently colocalized with tumor areas showing elevated PD-L1 expression, CD8+ T-cell infiltration, and CD163+ macrophage density - all established biomarkers of treatment response. Our findings indicate that incorporating IHC-derived immune profiling data could substantially improve model interpretability and predictive performance. Furthermore, this approach may accelerate the discovery of novel histopathological biomarkers for NACT and advance the development of personalized treatment strategies for TNBC patients.","authors":["Hikmat Khan","Ziyu Su","Huina Zhang","Yihong Wang","Bohan Ning","Shi Wei","Hua Guo","Zaibo Li","Muhammad Khalid Khan Niazi"],"url":"https://arxiv.org/abs/2505.14730"}
{"created":"2025-05-22","title":"Effective climate policies for major emission reductions of ozone precursors: Global evidence from two decades","abstract":"Despite policymakers deploying various tools to mitigate emissions of ozone (O\\textsubscript{3}) precursors, such as nitrogen oxides (NO\\textsubscript{x}), carbon monoxide (CO), and volatile organic compounds (VOCs), the effectiveness of policy combinations remains uncertain. We employ an integrated framework that couples structural break detection with machine learning to pinpoint effective interventions across the building, electricity, industrial, and transport sectors, identifying treatment effects as abrupt changes without prior assumptions about policy treatment assignment and timing. Applied to two decades of global O\\textsubscript{3} precursor emissions data, we detect 78, 77, and 78 structural breaks for NO\\textsubscript{x}, CO, and VOCs, corresponding to cumulative emission reductions of 0.96-0.97 Gt, 2.84-2.88 Gt, and 0.47-0.48 Gt, respectively. Sector-level analysis shows that electricity sector structural policies cut NO\\textsubscript{x} by up to 32.4\\%, while in buildings, developed countries combined adoption subsidies with carbon taxes to achieve 42.7\\% CO reductions and developing countries used financing plus fuel taxes to secure 52.3\\%. VOCs abatement peaked at 38.5\\% when fossil-fuel subsidy reforms were paired with financial incentives. Finally, hybrid strategies merging non-price measures (subsidies, bans, mandates) with pricing instruments delivered up to an additional 10\\% co-benefit. These findings guide the sequencing and complementarity of context-specific policy portfolios for O\\textsubscript{3} precursor mitigation.","authors":["Ningning Yao","Huan Xi","Lang Chen","Zhe Song","Jian Li","Yulei Chen","Baocai Guo","Yuanhang Zhang","Tong Zhu","Pengfei Li","Daniel Rosenfeld","John H. Seinfeld","Shaocai Yu"],"url":"https://arxiv.org/abs/2505.14731"}
{"created":"2025-05-22","title":"LOD1 3D City Model from LiDAR: The Impact of Segmentation Accuracy on Quality of Urban 3D Modeling and Morphology Extraction","abstract":"Three-dimensional reconstruction of buildings, particularly at Level of Detail 1 (LOD1), plays a crucial role in various applications such as urban planning, urban environmental studies, and designing optimized transportation networks. This study focuses on assessing the potential of LiDAR data for accurate 3D building reconstruction at LOD1 and extracting morphological features from these models. Four deep semantic segmentation models, U-Net, Attention U-Net, U-Net3+, and DeepLabV3+, were used, applying transfer learning to extract building footprints from LiDAR data. The results showed that U-Net3+ and Attention U-Net outperformed the others, achieving IoU scores of 0.833 and 0.814, respectively. Various statistical measures, including maximum, range, mode, median, and the 90th percentile, were used to estimate building heights, resulting in the generation of 3D models at LOD1. As the main contribution of the research, the impact of segmentation accuracy on the quality of 3D building modeling and the accuracy of morphological features like building area and external wall surface area was investigated. The results showed that the accuracy of building identification (segmentation performance) significantly affects the 3D model quality and the estimation of morphological features, depending on the height calculation method. Overall, the UNet3+ method, utilizing the 90th percentile and median measures, leads to accurate height estimation of buildings and the extraction of morphological features.","authors":["Fatemeh Chajaei","Hossein Bagheri"],"url":"https://arxiv.org/abs/2505.14747"}
{"created":"2025-05-22","title":"TransMedSeg: A Transferable Semantic Framework for Semi-Supervised Medical Image Segmentation","abstract":"Semi-supervised learning (SSL) has achieved significant progress in medical image segmentation (SSMIS) through effective utilization of limited labeled data. While current SSL methods for medical images predominantly rely on consistency regularization and pseudo-labeling, they often overlook transferable semantic relationships across different clinical domains and imaging modalities. To address this, we propose TransMedSeg, a novel transferable semantic framework for semi-supervised medical image segmentation. Our approach introduces a Transferable Semantic Augmentation (TSA) module, which implicitly enhances feature representations by aligning domain-invariant semantics through cross-domain distribution matching and intra-domain structural preservation. Specifically, TransMedSeg constructs a unified feature space where teacher network features are adaptively augmented towards student network semantics via a lightweight memory module, enabling implicit semantic transformation without explicit data generation. Interestingly, this augmentation is implicitly realized through an expected transferable cross-entropy loss computed over the augmented teacher distribution. An upper bound of the expected loss is theoretically derived and minimized during training, incurring negligible computational overhead. Extensive experiments on medical image datasets demonstrate that TransMedSeg outperforms existing semi-supervised methods, establishing a new direction for transferable representation learning in medical image analysis.","authors":["Mengzhu Wang","Jiao Li","Shanshan Wang","Long Lan","Huibin Tan","Liang Yang","Guoli Yang"],"url":"https://arxiv.org/abs/2505.14753"}
{"created":"2025-05-22","title":"Model-Independent Machine Learning Approach for Nanometric Axial Localization and Tracking","abstract":"Accurately tracking particles and determining their position along the optical axis is a major challenge in optical microscopy, especially when extremely high precision is needed. In this study, we introduce a deep learning approach using convolutional neural networks (CNNs) that can determine axial positions from dual-focal plane images without relying on predefined models. Our method achieves an axial localization accuracy of 40 nanometers - six times better than traditional single-focal plane techniques. The model's simple design and strong performance make it suitable for a wide range of uses, including dark matter detection, proton therapy for cancer, and radiation protection in space. It also shows promise in fields like biological imaging, materials science, and environmental monitoring. This work highlights how machine learning can turn complex image data into reliable, precise information, offering a flexible and powerful tool for many scientific applications.","authors":["Andrey Alexandrov","Giovanni Acampora","Giovanni De Lellis","Antonia Di Crescenzo","Chiara Errico","Daria Morozova","Valeri Tioukov","Autilia Vittiello"],"url":"https://arxiv.org/abs/2505.14754"}
{"created":"2025-05-22","title":"Generalised Burnside and Dixon algorithms for irreducible projective representations","abstract":"Based on the recently proposed character theory of projective representations of finite groups proposed, we generalise several algorithms for computing character tables and matrices of irreducible linear representations to projective representations. In particular, we present an algorithm based on that of Burnside to compute the characters of all irreducible projective representations of a finite group with a given Schur multiplier, and transpose it to exact integer arithmetic following Dixon's character table algorithm. We also describe an algorithm based on that of Dixon to split a projective representation into irreducible subspaces in floating-point arithmetic, and discuss how it can be used to compute matrices for all projective irreps with a given multiplier. Our algorithms bypass the construction of the representation group of the Schur multiplier, which makes them especially attractive for floating-point computations, where exact values of the multiplier are not necessarily available.","authors":["Attila Szab\\'o"],"url":"https://arxiv.org/abs/2505.14790"}
{"created":"2025-05-22","title":"Place Cells as Position Embeddings of Multi-Time Random Walk Transition Kernels for Path Planning","abstract":"The hippocampus orchestrates spatial navigation through collective place cell encodings that form cognitive maps. We reconceptualize the population of place cells as position embeddings approximating multi-scale symmetric random walk transition kernels: the inner product $\\langle h(x, t), h(y, t) \\rangle = q(y|x, t)$ represents normalized transition probabilities, where $h(x, t)$ is the embedding at location $ x $, and $q(y|x, t)$ is the normalized symmetric transition probability over time $t$. The time parameter $\\sqrt{t}$ defines a spatial scale hierarchy, mirroring the hippocampal dorsoventral axis. $q(y|x, t)$ defines spatial adjacency between $x$ and $y$ at scale or resolution $\\sqrt{t}$, and the pairwise adjacency relationships $(q(y|x, t), \\forall x, y)$ are reduced into individual embeddings $(h(x, t), \\forall x)$ that collectively form a map of the environment at sale $\\sqrt{t}$. Our framework employs gradient ascent on $q(y|x, t) = \\langle h(x, t), h(y, t)\\rangle$ with adaptive scale selection, choosing the time scale with maximal gradient at each step for trap-free, smooth trajectories. Efficient matrix squaring $P_{2t} = P_t^2$ builds global representations from local transitions $P_1$ without memorizing past trajectories, enabling hippocampal preplay-like path planning. This produces robust navigation through complex environments, aligning with hippocampal navigation. Experimental results show that our model captures place cell properties -- field size distribution, adaptability, and remapping -- while achieving computational efficiency. By modeling collective transition probabilities rather than individual place fields, we offer a biologically plausible, scalable framework for spatial navigation.","authors":["Minglu Zhao","Dehong Xu","Deqian Kong","Wen-Hao Zhang","Ying Nian Wu"],"url":"https://arxiv.org/abs/2505.14806"}
{"created":"2025-05-22","title":"Out-of-Distribution Generalization of In-Context Learning: A Low-Dimensional Subspace Perspective","abstract":"This work aims to demystify the out-of-distribution (OOD) capabilities of in-context learning (ICL) by studying linear regression tasks parameterized with low-rank covariance matrices. With such a parameterization, we can model distribution shifts as a varying angle between the subspace of the training and testing covariance matrices. We prove that a single-layer linear attention model incurs a test risk with a non-negligible dependence on the angle, illustrating that ICL is not robust to such distribution shifts. However, using this framework, we also prove an interesting property of ICL: when trained on task vectors drawn from a union of low-dimensional subspaces, ICL can generalize to any subspace within their span, given sufficiently long prompt lengths. This suggests that the OOD generalization ability of Transformers may actually stem from the new task lying within the span of those encountered during training. We empirically show that our results also hold for models such as GPT-2, and conclude with (i) experiments on how our observations extend to nonlinear function classes and (ii) results on how LoRA has the ability to capture distribution shifts.","authors":["Soo Min Kwon","Alec S. Xu","Can Yaras","Laura Balzano","Qing Qu"],"url":"https://arxiv.org/abs/2505.14808"}
{"created":"2025-05-22","title":"Virtual Fluoroscopy for Interventional Guidance using Magnetic Tracking","abstract":"Purpose: In conventional fluoroscopy-guided interventions, the 2D projective nature of X-ray imaging limits depth perception and leads to prolonged radiation exposure. Virtual fluoroscopy, combined with spatially tracked surgical instruments, is a promising strategy to mitigate these limitations. While magnetic tracking shows unique advantages, particularly in tracking flexible instruments, it remains under-explored due to interference from ferromagnetic materials in the C-arm room. This work proposes a virtual fluoroscopy workflow by effectively integrating magnetic tracking, and demonstrates its clinical efficacy. Methods: An automatic virtual fluoroscopy workflow was developed using a radiolucent tabletop field generator prototype. Specifically, we developed a fluoro-CT registration approach with automatic 2D-3D shared landmark correspondence to establish the C-arm-patient relationship, along with a general C-arm modelling approach to calculate desired poses and generate corresponding virtual fluoroscopic images. Results: Testing on a dataset with views ranging from RAO 90 degrees to LAO 90 degrees, simulated fluoroscopic images showed visually imperceptible differences from the real ones, achieving a mean target projection distance error of 1.55 mm. An endoleak phantom insertion experiment highlighted the effectiveness of simulating multiplanar views with real-time instrument overlays, achieving a mean needle tip error of 3.42 mm. Conclusions: Results demonstrated the efficacy of virtual fluoroscopy integrated with magnetic tracking, improving depth perception during navigation. The broad capture range of virtual fluoroscopy showed promise in improving the users understanding of X-ray imaging principles, facilitating more efficient image acquisition.","authors":["Shuwei Xing","Inaara Ahmed-Fazal","Utsav Pardasani","Uditha Jayarathne","Scott Illsley","Aaron Fenster","Terry M. Peters","Elvis C. S. Chen"],"url":"https://arxiv.org/abs/2505.14854"}
{"created":"2025-05-22","title":"LOBSTUR: A Local Bootstrap Framework for Tuning Unsupervised Representations in Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) are increasingly used in conjunction with unsupervised learning techniques to learn powerful node representations, but their deployment is hindered by their high sensitivity to hyperparameter tuning and the absence of established methodologies for selecting the optimal models. To address these challenges, we propose LOBSTUR-GNN ({\\bf Lo}cal {\\bf B}oot{\\bf s}trap for {\\bf T}uning {\\bf U}nsupervised {\\bf R}epresentations in GNNs) i), a novel framework designed to adapt bootstrapping techniques for unsupervised graph representation learning. LOBSTUR-GNN tackles two main challenges: (a) adapting the bootstrap edge and feature resampling process to account for local graph dependencies in creating alternative versions of the same graph, and (b) establishing robust metrics for evaluating learned representations without ground-truth labels. Using locally bootstrapped resampling and leveraging Canonical Correlation Analysis (CCA) to assess embedding consistency, LOBSTUR provides a principled approach for hyperparameter tuning in unsupervised GNNs. We validate the effectiveness and efficiency of our proposed method through extensive experiments on established academic datasets, showing an 65.9\\% improvement in the classification accuracy compared to an uninformed selection of hyperparameters. Finally, we deploy our framework on a real-world application, thereby demonstrating its validity and practical utility in various settings. \\footnote{The code is available at \\href{https://github.com/sowonjeong/lobstur-graph-bootstrap}{github.com/sowonjeong/lobstur-graph-bootstrap}.}","authors":["So Won Jeong","Claire Donnat"],"url":"https://arxiv.org/abs/2505.14867"}
{"created":"2025-05-22","title":"Learning POMDPs with Linear Function Approximation and Finite Memory","abstract":"We study reinforcement learning with linear function approximation and finite-memory approximations for partially observed Markov decision processes (POMDPs). We first present an algorithm for the value evaluation of finite-memory feedback policies. We provide error bounds derived from filter stability and projection errors. We then study the learning of finite-memory based near-optimal Q values. Convergence in this case requires further assumptions on the exploration policy when using general basis functions. We then show that these assumptions can be relaxed for specific models such as those with perfectly linear cost and dynamics, or when using discretization based basis functions.","authors":["Ali Devran Kara"],"url":"https://arxiv.org/abs/2505.14879"}
{"created":"2025-05-22","title":"TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis","abstract":"Customizable multilingual zero-shot singing voice synthesis (SVS) has various potential applications in music composition and short video dubbing. However, existing SVS models overly depend on phoneme and note boundary annotations, limiting their robustness in zero-shot scenarios and producing poor transitions between phonemes and notes. Moreover, they also lack effective multi-level style control via diverse prompts. To overcome these challenges, we introduce TCSinger 2, a multi-task multilingual zero-shot SVS model with style transfer and style control based on various prompts. TCSinger 2 mainly includes three key modules: 1) Blurred Boundary Content (BBC) Encoder, predicts duration, extends content embedding, and applies masking to the boundaries to enable smooth transitions. 2) Custom Audio Encoder, uses contrastive learning to extract aligned representations from singing, speech, and textual prompts. 3) Flow-based Custom Transformer, leverages Cus-MOE, with F0 supervision, enhancing both the synthesis quality and style modeling of the generated singing voice. Experimental results show that TCSinger 2 outperforms baseline models in both subjective and objective metrics across multiple related tasks.","authors":["Yu Zhang","Wenxiang Guo","Changhao Pan","Dongyu Yao","Zhiyuan Zhu","Ziyue Jiang","Yuhan Wang","Tao Jin","Zhou Zhao"],"url":"https://arxiv.org/abs/2505.14910"}
{"created":"2025-05-22","title":"Super-Resolution Optical Coherence Tomography Using Diffusion Model-Based Plug-and-Play Priors","abstract":"We propose an OCT super-resolution framework based on a plug-and-play diffusion model (PnP-DM) to reconstruct high-quality images from sparse measurements (OCT B-mode corneal images). Our method formulates reconstruction as an inverse problem, combining a diffusion prior with Markov chain Monte Carlo sampling for efficient posterior inference. We collect high-speed under-sampled B-mode corneal images and apply a deep learning-based up-sampling pipeline to build realistic training pairs. Evaluations on in vivo and ex vivo fish-eye corneal models show that PnP-DM outperforms conventional 2D-UNet baselines, producing sharper structures and better noise suppression. This approach advances high-fidelity OCT imaging in high-speed acquisition for clinical applications.","authors":["Yaning Wang","Jinglun Yu","Wenhan Guo","Yu Sun","Jin U. Kang"],"url":"https://arxiv.org/abs/2505.14916"}
{"created":"2025-05-22","title":"Pathobiological Dictionary Defining Pathomics and Texture Features: Addressing Understandable AI Issues in Personalized Liver Cancer; Dictionary Version LCP1.0","abstract":"Artificial intelligence (AI) holds strong potential for medical diagnostics, yet its clinical adoption is limited by a lack of interpretability and generalizability. This study introduces the Pathobiological Dictionary for Liver Cancer (LCP1.0), a practical framework designed to translate complex Pathomics and Radiomics Features (PF and RF) into clinically meaningful insights aligned with existing diagnostic workflows. QuPath and PyRadiomics, standardized according to IBSI guidelines, were used to extract 333 imaging features from hepatocellular carcinoma (HCC) tissue samples, including 240 PF-based-cell detection/intensity, 74 RF-based texture, and 19 RF-based first-order features. Expert-defined ROIs from the public dataset excluded artifact-prone areas, and features were aggregated at the case level. Their relevance to the WHO grading system was assessed using multiple classifiers linked with feature selectors. The resulting dictionary was validated by 8 experts in oncology and pathology. In collaboration with 10 domain experts, we developed a Pathobiological dictionary of imaging features such as PFs and RF. In our study, the Variable Threshold feature selection algorithm combined with the SVM model achieved the highest accuracy (0.80, P-value less than 0.05), selecting 20 key features, primarily clinical and pathomics traits such as Centroid, Cell Nucleus, and Cytoplasmic characteristics. These features, particularly nuclear and cytoplasmic, were strongly associated with tumor grading and prognosis, reflecting atypia indicators like pleomorphism, hyperchromasia, and cellular orientation.The LCP1.0 provides a clinically validated bridge between AI outputs and expert interpretation, enhancing model transparency and usability. Aligning AI-derived features with clinical semantics supports the development of interpretable, trustworthy diagnostic tools for liver cancer pathology.","authors":["Mohammad R. Salmanpour","Seyed Mohammad Piri","Somayeh Sadat Mehrnia","Ahmad Shariftabrizi","Masume Allahmoradi","Venkata SK. Manem","Arman Rahmim","Ilker Hacihaliloglu"],"url":"https://arxiv.org/abs/2505.14926"}
{"created":"2025-05-22","title":"Improved Classical Shadow Tomography Using Quantum Computation","abstract":"Classical shadow tomography (CST) involves obtaining enough classical descriptions of an unknown state via quantum measurements to predict the outcome of a set of quantum observables. CST has numerous applications, particularly in algorithms that utilize quantum data for tasks such as learning, detection, and optimization. This paper introduces a new CST procedure that exponentially reduces the space complexity and quadratically improves the running time of CST with single-copy measurements. The approach utilizes a quantum-to-classical-to-quantum process to prepare quantum states that represent shadow snapshots, which can then be directly measured by the observables of interest. With that, calculating large matrix traces is avoided, resulting in improvements in running time and space complexity. The paper presents analyses of the proposed methods for CST, with Pauli measurements and Clifford circuits.","authors":["Zahra Honjani","Mohsen Heidari"],"url":"https://arxiv.org/abs/2505.14953"}
{"created":"2025-05-22","title":"Customized Interior-Point Methods Solver for Embedded Real-Time Convex Optimization","abstract":"This paper presents a customized convex optimization solver tailored for embedded real-time optimization, which frequently arise in modern guidance and control (G&amp;C) applications. The solver employs a practically efficient predictor-corrector type primal-dual interior-point method (PDIPM) combined with a homogeneous embedding framework for infeasibility detection. Unlike conventional homogeneous self-dual embedding formulations, the adopted approach can directly handle quadratic cost functions without requiring problem reformulation. To support a systematic workflow, we also develop a code generation tool that analyzes the sparsity pattern of the provided problem family and generates customized solver code using a predefined code template. The generated solver code is written in C with no external dependencies other than the standard library math.h, and it supports complete static allocation of all data. Additionally, it provides parsing information to facilitate the use of the solver API by end users. Benchmark results and numerical experiments on an embedded platform demonstrate that the developed solver outperforms existing solvers in both efficiency and reliability.","authors":["Jae-Il Jang","Chang-Hun Lee"],"url":"https://arxiv.org/abs/2505.14973"}
{"created":"2025-05-22","title":"EASY: Emotion-aware Speaker Anonymization via Factorized Distillation","abstract":"Emotion plays a significant role in speech interaction, conveyed through tone, pitch, and rhythm, enabling the expression of feelings and intentions beyond words to create a more personalized experience. However, most existing speaker anonymization systems employ parallel disentanglement methods, which only separate speech into linguistic content and speaker identity, often neglecting the preservation of the original emotional state. In this study, we introduce EASY, an emotion-aware speaker anonymization framework. EASY employs a novel sequential disentanglement process to disentangle speaker identity, linguistic content, and emotional representation, modeling each speech attribute in distinct subspaces through a factorized distillation approach. By independently constraining speaker identity and emotional representation, EASY minimizes information leakage, enhancing privacy protection while preserving original linguistic content and emotional state. Experimental results on the VoicePrivacy Challenge official datasets demonstrate that our proposed approach outperforms all baseline systems, effectively protecting speaker privacy while maintaining linguistic content and emotional state.","authors":["Jixun Yao","Hexin Liu","Eng Siong Chng","Lei Xie"],"url":"https://arxiv.org/abs/2505.15004"}
{"created":"2025-05-22","title":"Convergence of Adam in Deep ReLU Networks via Directional Complexity and Kakeya Bounds","abstract":"First-order adaptive optimization methods like Adam are the default choices for training modern deep neural networks. Despite their empirical success, the theoretical understanding of these methods in non-smooth settings, particularly in Deep ReLU networks, remains limited. ReLU activations create exponentially many region boundaries where standard smoothness assumptions break down. \\textbf{We derive the first \\(\\tilde{O}\\!\\bigl(\\sqrt{d_{\\mathrm{eff}}/n}\\bigr)\\) generalization bound for Adam in Deep ReLU networks and the first global-optimal convergence for Adam in the non smooth, non convex relu landscape without a global PL or convexity assumption.} Our analysis is based on stratified Morse theory and novel results in Kakeya sets. We develop a multi-layer refinement framework that progressively tightens bounds on region crossings. We prove that the number of region crossings collapses from exponential to near-linear in the effective dimension. Using a Kakeya based method, we give a tighter generalization bound than PAC-Bayes approaches and showcase convergence using a mild uniform low barrier assumption.","authors":["Anupama Sridhar","Alexander Johansen"],"url":"https://arxiv.org/abs/2505.15013"}
{"created":"2025-05-22","title":"Infinite hierarchical contrastive clustering for personal digital envirotyping","abstract":"Daily environments have profound influence on our health and behavior. Recent work has shown that digital envirotyping, where computer vision is applied to images of daily environments taken during ecological momentary assessment (EMA), can be used to identify meaningful relationships between environmental features and health outcomes of interest. To systematically study such effects on an individual level, it is helpful to group images into distinct environments encountered in an individual's daily life; these may then be analyzed, further grouped into related environments with similar features, and linked to health outcomes. Here we introduce infinite hierarchical contrastive clustering to address this challenge. Building on the established contrastive clustering framework, our method a) allows an arbitrary number of clusters without requiring the full Dirichlet Process machinery by placing a stick-breaking prior on predicted cluster probabilities; and b) encourages distinct environments to form well-defined sub-clusters within each cluster of related environments by incorporating a participant-specific prediction loss. Our experiments show that our model effectively identifies distinct personal environments and groups these environments into meaningful environment types. We then illustrate how the resulting clusters can be linked to various health outcomes, highlighting the potential of our approach to advance the envirotyping paradigm.","authors":["Ya-Yun Huang","Joseph McClernon","Jason A. Oliver","Matthew M. Engelhard"],"url":"https://arxiv.org/abs/2505.15022"}
{"created":"2025-05-22","title":"Non-rigid Motion Correction for MRI Reconstruction via Coarse-To-Fine Diffusion Models","abstract":"Magnetic Resonance Imaging (MRI) is highly susceptible to motion artifacts due to the extended acquisition times required for k-space sampling. These artifacts can compromise diagnostic utility, particularly for dynamic imaging. We propose a novel alternating minimization framework that leverages a bespoke diffusion model to jointly reconstruct and correct non-rigid motion-corrupted k-space data. The diffusion model uses a coarse-to-fine denoising strategy to capture large overall motion and reconstruct the lower frequencies of the image first, providing a better inductive bias for motion estimation than that of standard diffusion models. We demonstrate the performance of our approach on both real-world cine cardiac MRI datasets and complex simulated rigid and non-rigid deformations, even when each motion state is undersampled by a factor of 64x. Additionally, our method is agnostic to sampling patterns, anatomical variations, and MRI scanning protocols, as long as some low frequency components are sampled during each motion state.","authors":["Frederic Wang","Jonathan I. Tamir"],"url":"https://arxiv.org/abs/2505.15057"}
{"created":"2025-05-22","title":"Steering Generative Models with Experimental Data for Protein Fitness Optimization","abstract":"Protein fitness optimization involves finding a protein sequence that maximizes desired quantitative properties in a combinatorially large design space of possible sequences. Recent developments in steering protein generative models (e.g diffusion models, language models) offer a promising approach. However, by and large, past studies have optimized surrogate rewards and/or utilized large amounts of labeled data for steering, making it unclear how well existing methods perform and compare to each other in real-world optimization campaigns where fitness is measured by low-throughput wet-lab assays. In this study, we explore fitness optimization using small amounts (hundreds) of labeled sequence-fitness pairs and comprehensively evaluate strategies such as classifier guidance and posterior sampling for guiding generation from different discrete diffusion models of protein sequences. We also demonstrate how guidance can be integrated into adaptive sequence selection akin to Thompson sampling in Bayesian optimization, showing that plug-and-play guidance strategies offer advantages compared to alternatives such as reinforcement learning with protein language models.","authors":["Jason Yang","Wenda Chu","Daniel Khalil","Raul Astudillo","Bruce J. Wittmann","Frances H. Arnold","Yisong Yue"],"url":"https://arxiv.org/abs/2505.15093"}
{"created":"2025-05-22","title":"Lung Nodule-SSM: Self-Supervised Lung Nodule Detection and Classification in Thoracic CT Images","abstract":"Lung cancer remains among the deadliest types of cancer in recent decades, and early lung nodule detection is crucial for improving patient outcomes. The limited availability of annotated medical imaging data remains a bottleneck in developing accurate computer-aided diagnosis (CAD) systems. Self-supervised learning can help leverage large amounts of unlabeled data to develop more robust CAD systems. With the recent advent of transformer-based architecture and their ability to generalize to unseen tasks, there has been an effort within the healthcare community to adapt them to various medical downstream tasks. Thus, we propose a novel \"LungNodule-SSM\" method, which utilizes selfsupervised learning with DINOv2 as a backbone to enhance lung nodule detection and classification without annotated data. Our methodology has two stages: firstly, the DINOv2 model is pre-trained on unlabeled CT scans to learn robust feature representations, then secondly, these features are fine-tuned using transformer-based architectures for lesionlevel detection and accurate lung nodule diagnosis. The proposed method has been evaluated on the challenging LUNA 16 dataset, consisting of 888 CT scans, and compared with SOTA methods. Our experimental results show the superiority of our proposed method with an accuracy of 98.37%, explaining its effectiveness in lung nodule detection. The source code, datasets, and pre-processed data can be accessed using the link:https://github.com/EMeRALDsNRPU/Lung-Nodule-SSM-Self-Supervised-Lung-Nodule-Detection-and-Classification/tree/main","authors":["Muniba Noreen (Faculty of Electrical","Electronics Engineering","University of Engineering","Technology Taxila","Pakistan)","Furqan Shaukat (Faculty of Electrical","Electronics Engineering","University of Engineering","Technology Taxila","Pakistan)"],"url":"https://arxiv.org/abs/2505.15120"}
{"created":"2025-05-22","title":"Physics-Guided Multi-View Graph Neural Network for Schizophrenia Classification via Structural-Functional Coupling","abstract":"Clinical studies reveal disruptions in brain structural connectivity (SC) and functional connectivity (FC) in neuropsychiatric disorders such as schizophrenia (SZ). Traditional approaches might rely solely on SC due to limited functional data availability, hindering comprehension of cognitive and behavioral impairments in individuals with SZ by neglecting the intricate SC-FC interrelationship. To tackle the challenge, we propose a novel physics-guided deep learning framework that leverages a neural oscillation model to describe the dynamics of a collection of interconnected neural oscillators, which operate via nerve fibers dispersed across the brain's structure. Our proposed framework utilizes SC to simultaneously generate FC by learning SC-FC coupling from a system dynamics perspective. Additionally, it employs a novel multi-view graph neural network (GNN) with a joint loss to perform correlation-based SC-FC fusion and classification of individuals with SZ. Experiments conducted on a clinical dataset exhibited improved performance, demonstrating the robustness of our proposed approach.","authors":["Badhan Mazumder","Ayush Kanyal","Lei Wu","Vince D. Calhoun","Dong Hye Ye"],"url":"https://arxiv.org/abs/2505.15135"}
{"created":"2025-05-22","title":"R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization","abstract":"Financial markets pose fundamental challenges for asset return prediction due to their high dimensionality, non-stationarity, and persistent volatility. Despite advances in large language models and multi-agent systems, current quantitative research pipelines suffer from limited automation, weak interpretability, and fragmented coordination across key components such as factor mining and model innovation. In this paper, we propose R&amp;D-Agent for Quantitative Finance, in short RD-Agent(Q), the first data-centric multi-agent framework designed to automate the full-stack research and development of quantitative strategies via coordinated factor-model co-optimization. RD-Agent(Q) decomposes the quant process into two iterative stages: a Research stage that dynamically sets goal-aligned prompts, formulates hypotheses based on domain priors, and maps them to concrete tasks, and a Development stage that employs a code-generation agent, Co-STEER, to implement task-specific code, which is then executed in real-market backtests. The two stages are connected through a feedback stage that thoroughly evaluates experimental outcomes and informs subsequent iterations, with a multi-armed bandit scheduler for adaptive direction selection. Empirically, RD-Agent(Q) achieves up to 2X higher annualized returns than classical factor libraries using 70% fewer factors, and outperforms state-of-the-art deep time-series models on real markets. Its joint factor-model optimization delivers a strong balance between predictive accuracy and strategy robustness. Our code is available at: https://github.com/microsoft/RD-Agent.","authors":["Yuante Li","Xu Yang","Xiao Yang","Minrui Xu","Xisen Wang","Weiqing Liu","Jiang Bian"],"url":"https://arxiv.org/abs/2505.15155"}
{"created":"2025-05-22","title":"A Linear Approach to Data Poisoning","abstract":"We investigate the theoretical foundations of data poisoning attacks in machine learning models. Our analysis reveals that the Hessian with respect to the input serves as a diagnostic tool for detecting poisoning, exhibiting spectral signatures that characterize compromised datasets. We use random matrix theory (RMT) to develop a theory for the impact of poisoning proportion and regularisation on attack efficacy in linear regression. Through QR stepwise regression, we study the spectral signatures of the Hessian in multi-output regression. We perform experiments on deep networks to show experimentally that this theory extends to modern convolutional and transformer networks under the cross-entropy loss. Based on these insights we develop preliminary algorithms to determine if a network has been poisoned and remedies which do not require further training.","authors":["Diego Granziol","Donald Flynn"],"url":"https://arxiv.org/abs/2505.15175"}
{"created":"2025-05-22","title":"EEG-Based Inter-Patient Epileptic Seizure Detection Combining Domain Adversarial Training with CNN-BiLSTM Network","abstract":"Automated epileptic seizure detection from electroencephalogram (EEG) remains challenging due to significant individual differences in EEG patterns across patients. While existing studies achieve high accuracy with patient-specific approaches, they face difficulties in generalizing to new patients. To address this, we propose a detection framework combining domain adversarial training with a convolutional neural network (CNN) and a bidirectional long short-term memory (BiLSTM). First, the CNN extracts local patient-invariant features through domain adversarial training, which optimizes seizure detection accuracy while minimizing patient-specific characteristics. Then, the BiLSTM captures temporal dependencies in the extracted features to model seizure evolution patterns. Evaluation using EEG recordings from 20 patients with focal epilepsy demonstrated superior performance over non-adversarial methods, achieving high detection accuracy across different patients. The integration of adversarial training with temporal modeling enables robust cross-patient seizure detection.","authors":["Rina Tazaki","Tomoyuki Akiyama","Akira Furui"],"url":"https://arxiv.org/abs/2505.15203"}
{"created":"2025-05-22","title":"Clustering and Pruning in Causal Data Fusion","abstract":"Data fusion, the process of combining observational and experimental data, can enable the identification of causal effects that would otherwise remain non-identifiable. Although identification algorithms have been developed for specific scenarios, do-calculus remains the only general-purpose tool for causal data fusion, particularly when variables are present in some data sources but not others. However, approaches based on do-calculus may encounter computational challenges as the number of variables increases and the causal graph grows in complexity. Consequently, there exists a need to reduce the size of such models while preserving the essential features. For this purpose, we propose pruning (removing unnecessary variables) and clustering (combining variables) as preprocessing operations for causal data fusion. We generalize earlier results on a single data source and derive conditions for applying pruning and clustering in the case of multiple data sources. We give sufficient conditions for inferring the identifiability or non-identifiability of a causal effect in a larger graph based on a smaller graph and show how to obtain the corresponding identifying functional for identifiable causal effects. Examples from epidemiology and social science demonstrate the use of the results.","authors":["Otto Tabell","Santtu Tikka","Juha Karvanen"],"url":"https://arxiv.org/abs/2505.15215"}
{"created":"2025-05-22","title":"Recognition of Unseen Combined Motions via Convex Combination-based EMG Pattern Synthesis for Myoelectric Control","abstract":"Electromyogram (EMG) signals recorded from the skin surface enable intuitive control of assistive devices such as prosthetic limbs. However, in EMG-based motion recognition, collecting comprehensive training data for all target motions remains challenging, particularly for complex combined motions. This paper proposes a method to efficiently recognize combined motions using synthetic EMG data generated through convex combinations of basic motion patterns. Instead of measuring all possible combined motions, the proposed method utilizes measured basic motion data along with synthetically combined motion data for training. This approach expands the range of recognizable combined motions while minimizing the required training data collection. We evaluated the effectiveness of the proposed method through an upper limb motion classification experiment with eight subjects. The experimental results demonstrated that the proposed method improved the classification accuracy for unseen combined motions by approximately 17%.","authors":["Itsuki Yazawa","Seitaro Yoneda","Akira Furui"],"url":"https://arxiv.org/abs/2505.15218"}
{"created":"2025-05-22","title":"Versatile Reservoir Computing for Heterogeneous Complex Networks","abstract":"A new machine learning scheme, termed versatile reservoir computing, is proposed for sustaining the dynamics of heterogeneous complex networks. We show that a single, small-scale reservoir computer trained on time series from a subset of elements is able to replicate the dynamics of any element in a large-scale complex network, though the elements are of different intrinsic parameters and connectivities. Furthermore, by substituting failed elements with the trained machine, we demonstrate that the collective dynamics of the network can be preserved accurately over a finite time horizon. The capability and effectiveness of the proposed scheme are validated on three representative network models: a homogeneous complex network of non-identical phase oscillators, a heterogeneous complex network of non-identical phase oscillators, and a heterogeneous complex network of non-identical chaotic oscillators.","authors":["Yao Du","Huawei Fan","Xingang Wang"],"url":"https://arxiv.org/abs/2505.15219"}
{"created":"2025-05-22","title":"SAMA-UNet: Enhancing Medical Image Segmentation with Self-Adaptive Mamba-Like Attention and Causal-Resonance Learning","abstract":"Medical image segmentation plays an important role in various clinical applications, but existing models often struggle with the computational inefficiencies and challenges posed by complex medical data. State Space Sequence Models (SSMs) have demonstrated promise in modeling long-range dependencies with linear computational complexity, yet their application in medical image segmentation remains hindered by incompatibilities with image tokens and autoregressive assumptions. Moreover, it is difficult to achieve a balance in capturing both local fine-grained information and global semantic dependencies. To address these challenges, we introduce SAMA-UNet, a novel architecture for medical image segmentation. A key innovation is the Self-Adaptive Mamba-like Aggregated Attention (SAMA) block, which integrates contextual self-attention with dynamic weight modulation to prioritise the most relevant features based on local and global contexts. This approach reduces computational complexity and improves the representation of complex image features across multiple scales. We also suggest the Causal-Resonance Multi-Scale Module (CR-MSM), which enhances the flow of information between the encoder and decoder by using causal resonance learning. This mechanism allows the model to automatically adjust feature resolution and causal dependencies across scales, leading to better semantic alignment between the low-level and high-level features in U-shaped architectures. Experiments on MRI, CT, and endoscopy images show that SAMA-UNet performs better in segmentation accuracy than current methods using CNN, Transformer, and Mamba. The implementation is publicly available at GitHub.","authors":["Saqib Qamar","Mohd Fazil","Parvez Ahmad","Ghulam Muhammad"],"url":"https://arxiv.org/abs/2505.15234"}
{"created":"2025-05-22","title":"X-GRM: Large Gaussian Reconstruction Model for Sparse-view X-rays to Computed Tomography","abstract":"Computed Tomography serves as an indispensable tool in clinical workflows, providing non-invasive visualization of internal anatomical structures. Existing CT reconstruction works are limited to small-capacity model architecture, inflexible volume representation, and small-scale training data. In this paper, we present X-GRM (X-ray Gaussian Reconstruction Model), a large feedforward model for reconstructing 3D CT from sparse-view 2D X-ray projections. X-GRM employs a scalable transformer-based architecture to encode an arbitrary number of sparse X-ray inputs, where tokens from different views are integrated efficiently. Then, tokens are decoded into a new volume representation, named Voxel-based Gaussian Splatting (VoxGS), which enables efficient CT volume extraction and differentiable X-ray rendering. To support the training of X-GRM, we collect ReconX-15K, a large-scale CT reconstruction dataset containing around 15,000 CT/X-ray pairs across diverse organs, including the chest, abdomen, pelvis, and tooth etc. This combination of a high-capacity model, flexible volume representation, and large-scale training data empowers our model to produce high-quality reconstructions from various testing inputs, including in-domain and out-domain X-ray projections. Project Page: https://github.com/CUHK-AIM-Group/X-GRM.","authors":["Yifan Liu","Wuyang Li","Weihao Yu","Chenxin Li","Alexandre Alahi","Max Meng","Yixuan Yuan"],"url":"https://arxiv.org/abs/2505.15235"}
{"created":"2025-05-22","title":"A Unified Approach to Quantum Contraction and Correlation Coefficients","abstract":"In classical information theory, the maximal correlation coefficient is used to establish strong limits on distributed processing. Through its relation to the $\\chi^{2}$-contraction coefficient, it also establishes fundamental bounds on sequential processing. Two distinct quantum extensions of the maximal correlation coefficient have been introduced to recover these two scenarios, but they do not recover the entire classical framework. We introduce a family of non-commutative $L^{2}(p)$ spaces induced by operator monotone functions from which families of quantum maximal correlation coefficients and the quantum $\\chi^{2}$-divergences can be identified. Through this framework, we lift the classical results to the quantum setting. For distributed processing, using our quantum maximal correlation coefficients, we establish strong limits on converting quantum states under local operations. For sequential processing, we clarify the relation between the data processing inequality of quantum maximal correlation coefficients, $\\chi^{2}$-contraction coefficients, and $f$-divergences. Moreover, we establish the quantum maximal correlation coefficients and $\\chi^{2}$-contraction coefficients are often computable via linear algebraic methods, which in particular implies a method for obtaining rigorous, computable upper bounds for time-homogeneous quantum Markov chains with a unique, full rank fixed point.","authors":["Ian George","Marco Tomamichel"],"url":"https://arxiv.org/abs/2505.15281"}
{"created":"2025-05-22","title":"Quantization of Probability Distributions via Divide-and-Conquer: Convergence and Error Propagation under Distributional Arithmetic Operations","abstract":"This article studies a general divide-and-conquer algorithm for approximating continuous one-dimensional probability distributions with finite mean. The article presents a numerical study that compares pre-existing approximation schemes with a special focus on the stability of the discrete approximations when they undergo arithmetic operations. The main results are a simple upper bound of the approximation error in terms of the Wasserstein-1 distance that is valid for all continuous distributions with finite mean. In many use-cases, the studied method achieve optimal rate of convergence, and numerical experiments show that the algorithm is more stable than pre-existing approximation schemes in the context of arithmetic operations.","authors":["Bilgesu Arif Bilgin","Olof Hallqvist Elias","Michael Selby","Phillip Stanley-Marbell"],"url":"https://arxiv.org/abs/2505.15283"}
{"created":"2025-05-22","title":"Reconsider the Template Mesh in Deep Learning-based Mesh Reconstruction","abstract":"Mesh reconstruction is a cornerstone process across various applications, including in-silico trials, digital twins, surgical planning, and navigation. Recent advancements in deep learning have notably enhanced mesh reconstruction speeds. Yet, traditional methods predominantly rely on deforming a standardised template mesh for individual subjects, which overlooks the unique anatomical variations between them, and may compromise the fidelity of the reconstructions. In this paper, we propose an adaptive-template-based mesh reconstruction network (ATMRN), which generates adaptive templates from the given images for the subsequent deformation, moving beyond the constraints of a singular, fixed template. Our approach, validated on cortical magnetic resonance (MR) images from the OASIS dataset, sets a new benchmark in voxel-to-cortex mesh reconstruction, achieving an average symmetric surface distance of 0.267mm across four cortical structures. Our proposed method is generic and can be easily transferred to other image modalities and anatomical structures.","authors":["Fengting Zhang","Boxu Liang","Qinghao Liu","Min Liu","Xiang Chen","Yaonan Wang"],"url":"https://arxiv.org/abs/2505.15285"}
{"created":"2025-05-22","title":"Strong odd colorings in graph classes of bounded expansion","abstract":"We prove that for every $d\\in \\mathbb{N}$ and a graph class of bounded expansion $\\mathscr{C}$, there exists some $c\\in \\mathbb{N}$ so that every graph from $\\mathscr{C}$ admits a proper coloring with at most $c$ colors satisfying the following condition: in every ball of radius $d$, every color appears either zero times or an odd number of times. For $d=1$, this provides a positive answer to a question raised by Goetze, Klute, Knauer, Parada, Pe\\~na, and Ueckerdt [ArXiv 2505.02736] about the boundedness of the strong odd chromatic number in graph classes of bounded expansion. The key technical ingredient towards the result is a proof that the strong odd coloring number of a sets system can be bounded in terms of its semi-ladder index, 2VC dimension, and the maximum subchromatic number among induced subsystems.","authors":["Micha{\\l} Pilipczuk"],"url":"https://arxiv.org/abs/2505.15288"}
{"created":"2025-05-22","title":"Towards Pre-training an Effective Respiratory Audio Foundation Model","abstract":"Recent advancements in foundation models have sparked interest in respiratory audio foundation models. However, the effectiveness of applying conventional pre-training schemes to datasets that are small-sized and lack diversity has not been sufficiently verified. This study aims to explore better pre-training practices for respiratory sounds by comparing numerous pre-trained audio models. Our investigation reveals that models pre-trained on AudioSet, a general audio dataset, are more effective than the models specifically pre-trained on respiratory sounds. Moreover, combining AudioSet and respiratory sound datasets for further pre-training enhances performance, and preserving the frequency-wise information when aggregating features is vital. Along with more insights found in the experiments, we establish a new state-of-the-art for the OPERA benchmark, contributing to advancing respiratory audio foundation models. Our code is available online at https://github.com/nttcslab/eval-audio-repr/tree/main/plugin/OPERA.","authors":["Daisuke Niizumi","Daiki Takeuchi","Masahiro Yasuda","Binh Thien Nguyen","Yasunori Ohishi","Noboru Harada"],"url":"https://arxiv.org/abs/2505.15307"}
{"created":"2025-05-22","title":"Policy Testing in Markov Decision Processes","abstract":"We study the policy testing problem in discounted Markov decision processes (MDPs) under the fixed-confidence setting. The goal is to determine whether the value of a given policy exceeds a specified threshold while minimizing the number of observations. We begin by deriving an instance-specific lower bound that any algorithm must satisfy. This lower bound is characterized as the solution to an optimization problem with non-convex constraints. We propose a policy testing algorithm inspired by this optimization problem--a common approach in pure exploration problems such as best-arm identification, where asymptotically optimal algorithms often stem from such optimization-based characterizations. As for other pure exploration tasks in MDPs, however, the non-convex constraints in the lower-bound problem present significant challenges, raising doubts about whether statistically optimal and computationally tractable algorithms can be designed. To address this, we reformulate the lower-bound problem by interchanging the roles of the objective and the constraints, yielding an alternative problem with a non-convex objective but convex constraints. Strikingly, this reformulated problem admits an interpretation as a policy optimization task in a newly constructed reversed MDP. Leveraging recent advances in policy gradient methods, we efficiently solve this problem and use it to design a policy testing algorithm that is statistically optimal--matching the instance-specific lower bound on sample complexity--while remaining computationally tractable. We validate our approach with numerical experiments.","authors":["Kaito Ariu","Po-An Wang","Alexandre Proutiere","Kenshi Abe"],"url":"https://arxiv.org/abs/2505.15342"}
{"created":"2025-05-22","title":"Minimum blocking sets for families of partitions","abstract":"A $3$-partition of an $n$-element set $V$ is a triple of pairwise disjoint nonempty subsets $X,Y,Z$ such that $V=X\\cup Y\\cup Z$. We determine the minimum size $\\varphi_3(n)$ of a set $\\mathcal{E}$ of triples such that for every 3-partition $X,Y,Z$ of the set $\\{1,\\dots,n\\}$, there is some $\\{x,y,z\\}\\in \\mathcal{E}$ with $x\\in X$, $y\\in Y$, and $z\\in Z$. In particular, $$\\varphi_3(n)=\\left\\lceil{\\frac{n(n-2)}{3}}\\right\\rceil.$$ For $d>3$, one may define an analogous number $\\varphi_d(n)$. We determine the order of magnitude of $\\varphi_d(n)$, and prove the following upper and lower bounds, for $d>3$: $$\\frac{2 n^{d-1}}{d!} -o(n^{d-1}) \\leq \\varphi_d(n) \\leq \\frac{0.86}{(d-1)!}n^{d-1}+o(n^{d-1}).$$","authors":["Guillermo Gamboa Quintero","Ida Kantor"],"url":"https://arxiv.org/abs/2505.15362"}
{"created":"2025-05-22","title":"Inter-Subject Variance Transfer Learning for EMG Pattern Classification Based on Bayesian Inference","abstract":"In electromyogram (EMG)-based motion recognition, a subject-specific classifier is typically trained with sufficient labeled data. However, this process demands extensive data collection over extended periods, burdening the subject. To address this, utilizing information from pre-training on multiple subjects for the training of the target subject could be beneficial. This paper proposes an inter-subject variance transfer learning method based on a Bayesian approach. This method is founded on the simple hypothesis that while the means of EMG features vary greatly across subjects, their variances may exhibit similar patterns. Our approach transfers variance information, acquired through pre-training on multiple source subjects, to a target subject within a Bayesian updating framework, thereby allowing accurate classification using limited target calibration data. A coefficient was also introduced to adjust the amount of information transferred for efficient transfer learning. Experimental evaluations using two EMG datasets demonstrated the effectiveness of our variance transfer strategy and its superiority compared to existing methods.","authors":["Seitaro Yoneda","Akira Furui"],"url":"https://arxiv.org/abs/2505.15381"}
{"created":"2025-05-22","title":"Robust Multimodal Learning via Entropy-Gated Contrastive Fusion","abstract":"Real-world multimodal systems routinely face missing-input scenarios, and in reality, robots lose audio in a factory or a clinical record omits lab tests at inference time. Standard fusion layers either preserve robustness or calibration but never both. We introduce Adaptive Entropy-Gated Contrastive Fusion (AECF), a single light-weight layer that (i) adapts its entropy coefficient per instance, (ii) enforces monotone calibration across all modality subsets, and (iii) drives a curriculum mask directly from training-time entropy. On AV-MNIST and MS-COCO, AECF improves masked-input mAP by +18 pp at a 50% drop rate while reducing ECE by up to 200%, yet adds 1% run-time. All back-bones remain frozen, making AECF an easy drop-in layer for robust, calibrated multimodal inference.","authors":["Leon Chlon","Maggie Chlon","MarcAntonio M. Awada"],"url":"https://arxiv.org/abs/2505.15417"}
{"created":"2025-05-22","title":"Uncertainty Quantification in SVM prediction","abstract":"This paper explores Uncertainty Quantification (UQ) in SVM predictions, particularly for regression and forecasting tasks. Unlike the Neural Network, the SVM solutions are typically more stable, sparse, optimal and interpretable. However, there are only few literature which addresses the UQ in SVM prediction. At first, we provide a comprehensive summary of existing Prediction Interval (PI) estimation and probabilistic forecasting methods developed in the SVM framework and evaluate them against the key properties expected from an ideal PI model. We find that none of the existing SVM PI models achieves a sparse solution. To introduce sparsity in SVM model, we propose the Sparse Support Vector Quantile Regression (SSVQR) model, which constructs PIs and probabilistic forecasts by solving a pair of linear programs. Further, we develop a feature selection algorithm for PI estimation using SSVQR that effectively eliminates a significant number of features while improving PI quality in case of high-dimensional dataset. Finally we extend the SVM models in Conformal Regression setting for obtaining more stable prediction set with finite test set guarantees. Extensive experiments on artificial, real-world benchmark datasets compare the different characteristics of both existing and proposed SVM-based PI estimation methods and also highlight the advantages of the feature selection in PI estimation. Furthermore, we compare both, the existing and proposed SVM-based PI estimation models, with modern deep learning models for probabilistic forecasting tasks on benchmark datasets. Furthermore, SVM models show comparable or superior performance to modern complex deep learning models for probabilistic forecasting task in our experiments.","authors":["Pritam Anand"],"url":"https://arxiv.org/abs/2505.15429"}
{"created":"2025-05-22","title":"Adaptive Temperature Scaling with Conformal Prediction","abstract":"Conformal prediction enables the construction of high-coverage prediction sets for any pre-trained model, guaranteeing that the true label lies within the set with a specified probability. However, these sets do not provide probability estimates for individual labels, limiting their practical use. In this paper, we propose, to the best of our knowledge, the first method for assigning calibrated probabilities to elements of a conformal prediction set. Our approach frames this as an adaptive calibration problem, selecting an input-specific temperature parameter to match the desired coverage level. Experiments on several challenging image classification datasets demonstrate that our method maintains coverage guarantees while significantly reducing expected calibration error.","authors":["Nikita Kotelevskii","Mohsen Guizani","Eric Moulines","Maxim Panov"],"url":"https://arxiv.org/abs/2505.15437"}
{"created":"2025-05-22","title":"Machine Learning Derived Blood Input for Dynamic PET Images of Rat Heart","abstract":"Dynamic FDG PET imaging study of n = 52 rats including 26 control Wistar-Kyoto (WKY) rats and 26 experimental spontaneously hypertensive rats (SHR) were performed using a Siemens microPET and Albira trimodal scanner longitudinally at 1, 2, 3, 5, 9, 12 and 18 months of age. A 15-parameter dual output model correcting for spill over contamination and partial volume effects with peak fitting cost functions was developed for simultaneous estimation of model corrected blood input function (MCIF) and kinetic rate constants for dynamic FDG PET images of rat heart in vivo. Major drawbacks of this model are its dependence on manual annotations for the Image Derived Input Function (IDIF) and manual determination of crucial model parameters to compute MCIF. To overcome these limitations, we performed semi-automated segmentation and then formulated a Long-Short-Term Memory (LSTM) cell network to train and predict MCIF in test data using a concatenation of IDIFs and myocardial inputs and compared them with reference-modeled MCIF. Thresholding along 2D plane slices with two thresholds, with T1 representing high-intensity myocardium, and T2 representing lower-intensity rings, was used to segment the area of the LV blood pool. The resultant IDIF and myocardial TACs were used to compute the corresponding reference (model) MCIF for all data sets. The segmented IDIF and the myocardium formed the input for the LSTM network. A k-fold cross validation structure with a 33:8:11 split and 5 folds was utilized to create the model and evaluate the performance of the LSTM network for all datasets. To overcome the sparseness of data as time steps increase, midpoint interpolation was utilized to increase the density of datapoints beyond time = 10 minutes. The model utilizing midpoint interpolation was able to achieve a 56.4% improvement over previous Mean Squared Error (MSE).","authors":["Shubhrangshu Debsarkar","Bijoy Kundu"],"url":"https://arxiv.org/abs/2505.15488"}
{"created":"2025-05-22","title":"Deep Learning Enabled Segmentation, Classification and Risk Assessment of Cervical Cancer","abstract":"Cervical cancer, the fourth leading cause of cancer in women globally, requires early detection through Pap smear tests to identify precancerous changes and prevent disease progression. In this study, we performed a focused analysis by segmenting the cellular boundaries and drawing bounding boxes to isolate the cancer cells. A novel Deep Learning (DL) architecture, the ``Multi-Resolution Fusion Deep Convolutional Network\", was proposed to effectively handle images with varying resolutions and aspect ratios, with its efficacy showcased using the SIPaKMeD dataset. The performance of this DL model was observed to be similar to the state-of-the-art models, with accuracy variations of a mere 2\\% to 3\\%, achieved using just 1.7 million learnable parameters, which is approximately 85 times less than the VGG-19 model. Furthermore, we introduced a multi-task learning technique that simultaneously performs segmentation and classification tasks and begets an Intersection over Union score of 0.83 and a classification accuracy of 90\\%. The final stage of the workflow employs a probabilistic approach for risk assessment, extracting feature vectors to predict the likelihood of normal cells progressing to malignant states, which can be utilized for the prognosis of cervical cancer.","authors":["Abdul Samad Shaik","Shashaank Mattur Aswatha","Rahul Jashvantbhai Pandya"],"url":"https://arxiv.org/abs/2505.15505"}
{"created":"2025-05-22","title":"Modular Jump Gaussian Processes","abstract":"Gaussian processes (GPs) furnish accurate nonlinear predictions with well-calibrated uncertainty. However, the typical GP setup has a built-in stationarity assumption, making it ill-suited for modeling data from processes with sudden changes, or \"jumps\" in the output variable. The \"jump GP\" (JGP) was developed for modeling data from such processes, combining local GPs and latent \"level\" variables under a joint inferential framework. But joint modeling can be fraught with difficulty. We aim to simplify by suggesting a more modular setup, eschewing joint inference but retaining the main JGP themes: (a) learning optimal neighborhood sizes that locally respect manifolds of discontinuity; and (b) a new cluster-based (latent) feature to capture regions of distinct output levels on both sides of the manifold. We show that each of (a) and (b) separately leads to dramatic improvements when modeling processes with jumps. In tandem (but without requiring joint inference) that benefit is compounded, as illustrated on real and synthetic benchmark examples from the recent literature.","authors":["Anna R. Flowers","Christopher T. Franck","Micka\\\"el Binois","Chiwoo Park","Robert B. Gramacy"],"url":"https://arxiv.org/abs/2505.15557"}
{"created":"2025-05-22","title":"Damping optimization of discrete mechanical systems -- rod/string model","abstract":"This paper investigates two optimization criteria for damping optimization in a multi-body oscillator system with arbitrary degrees of freedom ($n$), resembling string/rod free vibrations. The total average energy over all possible initial data and the total average displacement over all possible initial data. Our first result shows that both criteria are equivalent to the trace minimization of the solution of the Lyapunov equation with different right-hand sides. As the second result, we prove that in the case of damping with one damper, for the discrete system, the minimal trace for each criterion can be expressed as a linear or cubic function of the dimension $n$. Consequently, the optimal damping position is determined solely by the number of dominant eigenfrequencies and the optimal viscosity, independent of the dimension $n$, offering efficient damping optimization in discrete systems. The paper concludes with numerical examples illustrating the presented theoretical framework and results.","authors":["Ninoslav Truhar","Kre\\v{s}imir Veseli\\'c"],"url":"https://arxiv.org/abs/2505.15640"}
{"created":"2025-05-22","title":"Neural Quantum Digital Twins for Optimizing Quantum Annealing","abstract":"Quantum annealers have shown potential in addressing certain combinatorial optimization problems, though their performance is often limited by scalability and errors rates. In this work, we propose a Neural Quantum Digital Twin (NQDT) framework that reconstructs the energy landscape of quantum many-body systems relevant to quantum annealing. The digital twin models both ground and excited state dynamics, enabling detailed simulation of the adiabatic evolution process. We benchmark NQDT on systems with known analytical solutions and demonstrate that it accurately captures key quantum phenomena, including quantum criticality and phase transitions. Leveraging this framework, one can identify optimal annealing schedules that minimize excitation-related errors. These findings highlight the utility of neural network-based digital twins as a diagnostic and optimization tool for improving the performance of quantum annealers.","authors":["Jianlong Lu","Hanqiu Peng","Ying Chen"],"url":"https://arxiv.org/abs/2505.15662"}
{"created":"2025-05-22","title":"Segmentation-Variant Codebooks for Preservation of Paralinguistic and Prosodic Information","abstract":"Quantization in SSL speech models (e.g., HuBERT) improves compression and performance in tasks like language modeling, resynthesis, and text-to-speech but often discards prosodic and paralinguistic information (e.g., emotion, prominence). While increasing codebook size mitigates some loss, it inefficiently raises bitrates. We propose Segmentation-Variant Codebooks (SVCs), which quantize speech at distinct linguistic units (frame, phone, word, utterance), factorizing it into multiple streams of segment-specific discrete features. Our results show that SVCs are significantly more effective at preserving prosodic and paralinguistic information across probing tasks. Additionally, we find that pooling before rather than after discretization better retains segment-level information. Resynthesis experiments further confirm improved style realization and slightly improved quality while preserving intelligibility.","authors":["Nicholas Sanders","Yuanchao Li","Korin Richmond","Simon King"],"url":"https://arxiv.org/abs/2505.15667"}
{"created":"2025-05-22","title":"Linearized Polynomial Chinese remainder codes","abstract":"In this paper, we introduce a new family of codes relevent for rank and sum-rank metrics. These codes are based on an effective Chinese remainders theorem for linearized polynomials over finite fields. We propose a decoding algorithm for some instances of these codes.","authors":["Philippe Gaborit","Camille Garnier","Olivier Ruatta"],"url":"https://arxiv.org/abs/2505.15720"}
{"created":"2025-05-22","title":"Are machine learning interpretations reliable? A stability study on global interpretations","abstract":"As machine learning systems are increasingly used in high-stakes domains, there is a growing emphasis placed on making them interpretable to improve trust in these systems. In response, a range of interpretable machine learning (IML) methods have been developed to generate human-understandable insights into otherwise black box models. With these methods, a fundamental question arises: Are these interpretations reliable? Unlike with prediction accuracy or other evaluation metrics for supervised models, the proximity to the true interpretation is difficult to define. Instead, we ask a closely related question that we argue is a prerequisite for reliability: Are these interpretations stable? We define stability as findings that are consistent or reliable under small random perturbations to the data or algorithms. In this study, we conduct the first systematic, large-scale empirical stability study on popular machine learning global interpretations for both supervised and unsupervised tasks on tabular data. Our findings reveal that popular interpretation methods are frequently unstable, notably less stable than the predictions themselves, and that there is no association between the accuracy of machine learning predictions and the stability of their associated interpretations. Moreover, we show that no single method consistently provides the most stable interpretations across a range of benchmark datasets. Overall, these results suggest that interpretability alone does not warrant trust, and underscores the need for rigorous evaluation of interpretation stability in future work. To support these principles, we have developed and released an open source IML dashboard and Python package to enable researchers to assess the stability and reliability of their own data-driven interpretations and discoveries.","authors":["Luqin Gan","Tarek M. Zikry","Genevera I. Allen"],"url":"https://arxiv.org/abs/2505.15728"}
{"created":"2025-05-22","title":"Distributionally Robust Planning of Hydrogen-Electrical Microgrids for Sea Islands","abstract":"This paper presents a distributionally robust planning method for hydrogen-electrical microgrids over islands, where the cross-island energy exchange is supported by a maritime hydrogen transport network. This planning problem is complicated due to heterogeneous off-shore wind-driven uncertainties (i.e., renewable power, transport availability, demand fluctuations, and grid faulting), a subset of which exhibit endogenous uncertainty, as they can be affected by proactive measures (e.g., grid hardening) or infrastructure investment. To capture these features, a two-stage distributionally robust optimization (DRO) model is developed considering decision-dependent uncertainty (DDU), which encompasses variation of the underlying distributional ambiguity due to the change of the first stage decisions. Notably, the complete recourse property is missing, which is often neglected in existing DRO studies. Nevertheless, different from the case for land-based microgrids, this issue is critical and fundamental for sea island systems due to their particular physical and logistical requirements. To address these issues, we develop a C&amp;CG algorithm that is customized with strong cutting planes to handle DRO with a varying DDU ambiguity set and feasibility requirements. Numerical results demonstrate the cost-effectiveness and resilience of the proposed planning framework, along with the nontrivial improvements of the algorithm in both solution accuracy and computational efficiency.","authors":["Yuchen Dong","Zhengsong Lu","Xiaoyu Cao","Zhengwen He","Tanveer Hossain Bhuiyan","Bo Zeng"],"url":"https://arxiv.org/abs/2505.15733"}
{"created":"2025-05-22","title":"ToxicTone: A Mandarin Audio Dataset Annotated for Toxicity and Toxic Utterance Tonality","abstract":"Despite extensive research on toxic speech detection in text, a critical gap remains in handling spoken Mandarin audio. The lack of annotated datasets that capture the unique prosodic cues and culturally specific expressions in Mandarin leaves spoken toxicity underexplored. To address this, we introduce ToxicTone -- the largest public dataset of its kind -- featuring detailed annotations that distinguish both forms of toxicity (e.g., profanity, bullying) and sources of toxicity (e.g., anger, sarcasm, dismissiveness). Our data, sourced from diverse real-world audio and organized into 13 topical categories, mirrors authentic communication scenarios. We also propose a multimodal detection framework that integrates acoustic, linguistic, and emotional features using state-of-the-art speech and emotion encoders. Extensive experiments show our approach outperforms text-only and baseline models, underscoring the essential role of speech-specific cues in revealing hidden toxic expressions.","authors":["Yu-Xiang Luo","Yi-Cheng Lin","Ming-To Chuang","Jia-Hung Chen","I-Ning Tsai","Pei Xing Kiew","Yueh-Hsuan Huang","Chien-Feng Liu","Yu-Chen Chen","Bo-Han Feng","Wenze Ren","Hung-yi Lee"],"url":"https://arxiv.org/abs/2505.15773"}
{"created":"2025-05-22","title":"An Information Theory-inspired Strategy for Automatic Network Pruning","abstract":"Despite superior performance on many computer vision tasks, deep convolution neural networks are well known to be compressed on devices that have resource constraints. Most existing network pruning methods require laborious human efforts and prohibitive computation resources, especially when the constraints are changed. This practically limits the application of model compression when the model needs to be deployed on a wide range of devices. Besides, existing methods are still challenged by the missing theoretical guidance. In this paper we propose an information theory-inspired strategy for automatic model compression. The principle behind our method is the information bottleneck theory, i.e., the hidden representation should compress information with each other. We thus introduce the normalized Hilbert-Schmidt Independence Criterion (nHSIC) on network activations as a stable and generalized indicator of layer importance. When a certain resource constraint is given, we integrate the HSIC indicator with the constraint to transform the architecture search problem into a linear programming problem with quadratic constraints. Such a problem is easily solved by a convex optimization method with a few seconds. We also provide a rigorous proof to reveal that optimizing the normalized HSIC simultaneously minimizes the mutual information between different layers. Without any search process, our method achieves better compression tradeoffs comparing to the state-of-the-art compression algorithms. For instance, with ResNet-50, we achieve a 45.3%-FLOPs reduction, with a 75.75 top-1 accuracy on ImageNet. Codes are avaliable at https://github.com/MAC-AutoML/ITPruner/tree/master.","authors":["Xiawu Zheng","Yuexiao Ma","Teng Xi","Gang Zhang","Errui Ding","Yuchao Li","Jie Chen","Yonghong Tian","Rongrong Ji"],"url":"https://arxiv.org/abs/2108.08532"}
{"created":"2025-05-22","title":"Spatially scalable recursive estimation of Gaussian process terrain maps using local basis functions","abstract":"When an agent, person, vehicle or robot is moving through an unknown environment without GNSS signals, online mapping of nonlinear terrains can be used to improve position estimates when the agent returns to a previously mapped area. Mapping algorithms using online Gaussian process (GP) regression are commonly integrated in algorithms for simultaneous localisation and mapping (SLAM). However, GP mapping algorithms have increasing computational demands as the mapped area expands relative to spatial field variations. This is due to the need for estimating an increasing amount of map parameters as the area of the map grows. Contrary to this, we propose a recursive GP mapping estimation algorithm which uses local basis functions in an information filter to achieve spatial scalability. Our proposed approximation employs a global grid of finite support basis functions but restricts computations to a localized subset around each prediction point. As our proposed algorithm is recursive, it can naturally be incorporated into existing algorithms that uses Gaussian process maps for SLAM. Incorporating our proposed algorithm into an extended Kalman filter (EKF) for magnetic field SLAM reduces the overall computational complexity of the algorithm. We show experimentally that our algorithm is faster than existing methods when the mapped area is large and the map is based on many measurements, both for recursive mapping tasks and for magnetic field SLAM.","authors":["Frida Marie Viset","Rudy Helmons","Manon Kok"],"url":"https://arxiv.org/abs/2210.09168"}
{"created":"2025-05-22","title":"An Empirical Bayes Analysis of Object Trajectory Representation Models","abstract":"Linear trajectory models provide mathematical advantages to autonomous driving applications such as motion prediction. However, linear models' expressive power and bias for real-world trajectories have not been thoroughly analyzed. We present an in-depth empirical analysis of the trade-off between model complexity and fit error in modelling object trajectories. We analyze vehicle, cyclist, and pedestrian trajectories. Our methodology estimates observation noise and prior distributions over model parameters from several large-scale datasets. Incorporating these priors can then regularize prediction models. Our results show that linear models do represent real-world trajectories with high fidelity at very moderate model complexity. This suggests the feasibility of using linear trajectory models in future motion prediction systems with inherent mathematical advantages.","authors":["Yue Yao","Daniel Goehring","Joerg Reichardt"],"url":"https://arxiv.org/abs/2211.01696"}
{"created":"2025-05-22","title":"Double-Exponential transformation: A quick review of a Japanese tradition","abstract":"This paper is a short introduction to numerical methods using the double exponential (DE) transformation, such as tanh-sinh quadrature and DE-Sinc approximation. The DE-based methods for numerical computation have been developed intensively in Japan and the objective of this paper is to describe their history in addition to the underlying mathematical ideas.","authors":["Kazuo Murota","Takayasu Matsuo"],"url":"https://arxiv.org/abs/2301.01920"}
{"created":"2025-05-22","title":"Learning Task-preferred Inference Routes for Gradient De-conflict in Multi-output DNNs","abstract":"Multi-output deep neural networks(MONs) contain multiple task branches, and these tasks usually share partial network filters that lead to the entanglement of different task inference routes. Due to the inconsistent optimization objectives, the task gradients used for training MONs will interfere with each other on the shared routes, which will decrease the overall model performance. To address this issue, we propose a novel gradient de-conflict algorithm named DR-MGF(Dynamic Routes and Meta-weighted Gradient Fusion) in this work. Different from existing de-conflict methods, DR-MGF achieves gradient de-conflict in MONs by learning task-preferred inference routes. The proposed method is motivated by our experimental findings: the shared filters are not equally important to different tasks. By designing the learnable task-specific importance variables, DR-MGF evaluates the importance of filters for different tasks. Through making the dominances of tasks over filters be proportional to the task-specific importance of filters, DR-MGF can effectively reduce the inter-task interference. The task-specific importance variables ultimately determine task-preferred inference routes at the end of training iterations. Extensive experimental results on CIFAR, ImageNet, and NYUv2 illustrate that DR-MGF outperforms the existing de-conflict methods both in prediction accuracy and convergence speed of MONs. Furthermore, DR-MGF can be extended to general MONs without modifying the overall network structures.","authors":["Yi Sun","Xin Xu","Jian Li","Xiaochang Hu","Yifei Shi","Ling-Li Zeng"],"url":"https://arxiv.org/abs/2305.19844"}
{"created":"2025-05-22","title":"The Lie derivative and Noether's theorem on the aromatic bicomplex for the study of volume-preserving numerical integrators","abstract":"The aromatic bicomplex is an algebraic tool based on aromatic Butcher trees and used in particular for the explicit description of volume-preserving affine-equivariant numerical integrators. The present work defines new tools inspired from variational calculus such as the Lie derivative, different concepts of symmetries, and Noether's theory in the context of aromatic forests. The approach allows to draw a correspondence between aromatic volume-preserving methods and symmetries on the Euler-Lagrange complex, to write Noether's theorem in the aromatic context, and to describe the aromatic B-series of volume-preserving methods explicitly with the Lie derivative.","authors":["Adrien Laurent"],"url":"https://arxiv.org/abs/2307.07984"}
{"created":"2025-05-22","title":"A New Bound on Cofactors of Sparse Polynomials","abstract":"We prove that for polynomials $f, g, h \\in \\mathbb{Z}[x]$ satisfying $f = gh$ and $f(0) \\neq 0$, the $\\ell_2$-norm of the cofactor $h$ is bounded by $\\|h\\|_2 \\leq \\|f\\|_1 \\cdot\\left( \\widetilde{O}\\left(\\|g\\|_0^3 \\frac{\\text{deg }{(f)}^2}{\\sqrt{\\text{deg }{(g)}}}\\right)\\right)^{\\|g\\|_0 - 1}$, where $\\|g\\|_0$ is the number of nonzero coefficients of $g$ (its sparsity). We also obtain similar results for polynomials over $\\mathbb{C}$.","authors":["Ido Nahshon","Amir Shpilka"],"url":"https://arxiv.org/abs/2308.03885"}
{"created":"2025-05-22","title":"ModSec-AdvLearn: Countering Adversarial SQL Injections with Robust Machine Learning","abstract":"Many Web Application Firewalls (WAFs) leverage the OWASP CRS to block incoming malicious requests. The CRS consists of different sets of rules designed by domain experts to detect well-known web attack patterns. Both the set of rules and the weights used to combine them are manually defined, yielding four different default configurations of the CRS. In this work, we focus on the detection of SQLi attacks, and show that the manual configurations of the CRS typically yield a suboptimal trade-off between detection and false alarm rates. Furthermore, we show that these configurations are not robust to adversarial SQLi attacks, i.e., carefully-crafted attacks that iteratively refine the malicious SQLi payload by querying the target WAF to bypass detection. To overcome these limitations, we propose (i) using machine learning to automate the selection of the set of rules to be combined along with their weights, i.e., customizing the CRS configuration based on the monitored web services; and (ii) leveraging adversarial training to significantly improve its robustness to adversarial SQLi manipulations. Our experiments, conducted using the well-known open-source ModSecurity WAF equipped with the CRS rules, show that our approach, named ModSec-AdvLearn, can (i) increase the detection rate up to 30%, while retaining negligible false alarm rates and discarding up to 50% of the CRS rules; and (ii) improve robustness against adversarial SQLi attacks up to 85%, marking a significant stride toward designing more effective and robust WAFs. We release our open-source code at https://github.com/pralab/modsec-advlearn.","authors":["Giuseppe Floris","Christian Scano","Biagio Montaruli","Luca Demetrio","Andrea Valenza","Luca Compagna","Davide Ariu","Luca Piras","Davide Balzarotti","Battista Biggio"],"url":"https://arxiv.org/abs/2308.04964"}
{"created":"2025-05-22","title":"Augmenting Chest X-ray Datasets with Non-Expert Annotations","abstract":"The advancement of machine learning algorithms in medical image analysis requires the expansion of training datasets. A popular and cost-effective approach is automated annotation extraction from free-text medical reports, primarily due to the high costs associated with expert clinicians annotating medical images, such as chest X-rays. However, it has been shown that the resulting datasets are susceptible to biases and shortcuts. Another strategy to increase the size of a dataset is crowdsourcing, a widely adopted practice in general computer vision with some success in medical image analysis. In a similar vein to crowdsourcing, we enhance two publicly available chest X-ray datasets by incorporating non-expert annotations. However, instead of using diagnostic labels, we annotate shortcuts in the form of tubes. We collect 3.5k chest drain annotations for NIH-CXR14, and 1k annotations for four different tube types in PadChest, and create the Non-Expert Annotations of Tubes in X-rays (NEATX) dataset. We train a chest drain detector with the non-expert annotations that generalizes well to expert labels. Moreover, we compare our annotations to those provided by experts and show \"moderate\" to \"almost perfect\" agreement. Finally, we present a pathology agreement study to raise awareness about the quality of ground truth annotations. We make our dataset available on Zenodo at https://zenodo.org/records/14944064 and our code available at https://github.com/purrlab/chestxr-label-reliability.","authors":["Veronika Cheplygina","Cathrine Damgaard","Trine Naja Eriksen","Dovile Juodelyte","Amelia Jim\\'enez-S\\'anchez"],"url":"https://arxiv.org/abs/2309.02244"}
{"created":"2025-05-22","title":"HurriCast: Synthetic Tropical Cyclone Track Generation for Hurricane Forecasting","abstract":"The generation of synthetic tropical cyclone(TC) tracks for risk assessment is a critical application of preparedness for the impacts of climate change and disaster relief, particularly in North America. Insurance companies use these synthetic tracks to estimate the potential risks and financial impacts of future TCs. For governments and policymakers, understanding the potential impacts of TCs helps in developing effective emergency response strategies, updating building codes, and prioritizing investments in resilience and mitigation projects. In this study, many hypothetical but plausible TC scenarios are created based on historical TC data HURDAT2 (HURricane DATA 2nd generation). A hybrid methodology, combining the ARIMA and K-MEANS methods with Autoencoder, is employed to capture better historical TC behaviors and project future trajectories and intensities. It demonstrates an efficient and reliable in the field of climate modeling and risk assessment. By effectively capturing past hurricane patterns and providing detailed future projections, this approach not only validates the reliability of this method but also offers crucial insights for a range of applications, from disaster preparedness and emergency management to insurance risk analysis and policy formulation.","authors":["Shouwei Gao","Meiyan Gao","Yuepeng Li","Wenqian Dong"],"url":"https://arxiv.org/abs/2309.07174"}
{"created":"2025-05-22","title":"Obtaining Pseudo-inverse Solutions With MINRES","abstract":"The celebrated minimum residual method (MINRES), proposed in the seminal paper of Paige and Saunders, has seen great success and widespread use in solving Hermitian (and complex-symmetric) linear systems. Unless the system is consistent, MINRES is not guaranteed to obtain the pseudo-inverse solution. We propose a novel and remarkably simple minimum-norm refinement (MN refinement) that seamlessly integrates with the final MINRES iteration, enabling us to obtain the minimum-norm solution with negligible additional computational cost. We extend our MN refinement to complex-symmetric systems, building on S.-C. Choi's extension of MINRES for solving these systems. Given the flexibility of MINRES to accommodate singular preconditioners, we further investigate the MN refinement in preconditioned settings that involve singular preconditioners. We also provide numerical experiments to support our analysis and showcase the effects of our MN refinement.","authors":["Yang Liu","Andre Milzarek","Fred Roosta"],"url":"https://arxiv.org/abs/2309.17096"}
{"created":"2025-05-22","title":"Optimizing Symbol Visibility through Displacement","abstract":"In information visualization, the position of symbols often encodes associated data values. When visualizing data elements with both a numerical and a categorical dimension, positioning in the categorical axis admits some flexibility. This flexibility can be exploited to reduce symbol overlap, and thereby increase legibility. In this paper, we initialize the algorithmic study of optimizing symbol legibility via a limited displacement of the symbols. Specifically, we consider closed unit square symbols that need to be placed at specified $y$-coordinates. We optimize the drawing order of the symbols as well as their $x$-displacement, constrained within a rectangular container, to maximize the minimum visible perimeter over all squares. If the container has width and height at most $2$, there is a point that stabs all squares. In this case, we prove that a staircase layout is arbitrarily close to optimality and can be computed in $O(n\\log n)$ time. If the width is at most $2$, there is a vertical line that stabs all squares, and in this case, we design a 2-approximation algorithm (assuming fixed container height) that runs in $O(n\\log n)$ time. As it turns out that a minimum visible perimeter of 2 is always achievable with a generic construction, we measure this approximation with respect to the visible perimeter exceeding 2. We show that, despite its simplicity, the algorithm gives asymptotically optimal results for certain instances.","authors":["Bernd G\\\"artner","Vishwas Kalani","Meghana M. Reddy","Wouter Meulemans","Bettina Speckmann","Milo\\v{s} Stojakovi\\'c"],"url":"https://arxiv.org/abs/2310.01147"}
{"created":"2025-05-22","title":"On the Evolution of Knowledge Graphs: A Survey and Perspective","abstract":"Knowledge graphs (KGs) are structured representations of diversified knowledge. They are widely used in various intelligent applications. In this article, we provide a comprehensive survey on the evolution of various types of knowledge graphs (i.e., static KGs, dynamic KGs, temporal KGs, and event KGs) and techniques for knowledge extraction and reasoning. Furthermore, we introduce the practical applications of different types of KGs, including a case study in financial analysis. Finally, we propose our perspective on the future directions of knowledge engineering, including the potential of combining the power of knowledge graphs and large language models (LLMs), and the evolution of knowledge extraction, reasoning, and representation.","authors":["Xuhui Jiang","Chengjin Xu","Yinghan Shen","Xun Sun","Lumingyuan Tang","Saizhuo Wang","Zhongwu Chen","Yuanzhuo Wang","Jian Guo"],"url":"https://arxiv.org/abs/2310.04835"}
{"created":"2025-05-22","title":"SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network","abstract":"Spiking Neural Networks (SNNs) have emerged as a promising alternative to conventional Artificial Neural Networks (ANNs), demonstrating comparable performance in both visual and linguistic tasks while offering the advantage of improved energy efficiency. Despite these advancements, the integration of linguistic and visual features into a unified representation through spike trains poses a significant challenge, and the application of SNNs to multimodal scenarios remains largely unexplored. This paper presents SpikeCLIP, a novel framework designed to bridge the modality gap in spike-based computation. Our approach employs a two-step recipe: an ``alignment pre-training'' to align features across modalities, followed by a ``dual-loss fine-tuning'' to refine the model's performance. Extensive experiments reveal that SNNs achieve results on par with ANNs while substantially reducing energy consumption across various datasets commonly used for multimodal model evaluation. Furthermore, SpikeCLIP maintains robust image classification capabilities, even when dealing with classes that fall outside predefined categories. This study marks a significant advancement in the development of energy-efficient and biologically plausible multimodal learning systems. Our code is available at https://github.com/Lvchangze/SpikeCLIP.","authors":["Changze Lv","Tianlong Li","Wenhao Liu","Yufei Gu","Jianhan Xu","Cenyuan Zhang","Muling Wu","Xiaoqing Zheng","Xuanjing Huang"],"url":"https://arxiv.org/abs/2310.06488"}
{"created":"2025-05-22","title":"Predicting generalization performance with correctness discriminators","abstract":"The ability to predict an NLP model's accuracy on unseen, potentially out-of-distribution data is a prerequisite for trustworthiness. We present a novel model that establishes upper and lower bounds on the accuracy, without requiring gold labels for the unseen data. We achieve this by training a discriminator which predicts whether the output of a given sequence-to-sequence model is correct or not. We show across a variety of tagging, parsing, and semantic parsing tasks that the gold accuracy is reliably between the predicted upper and lower bounds, and that these bounds are remarkably close together.","authors":["Yuekun Yao","Alexander Koller"],"url":"https://arxiv.org/abs/2311.09422"}
{"created":"2025-05-22","title":"The Kernel Method for Electrical Resistance Tomography","abstract":"This paper treats the inverse problem of retrieving the electrical conductivity starting from boundary measurements in the framework of Electrical Resistance Tomography (ERT). In particular, the focus is on non-iterative reconstruction methods that are compatible with real-time applications. In this work, the Kernel Method, a new non-iterative reconstruction method for Electrical Resistance Tomography, is presented. The imaging algorithm deals with the problem of retrieving one or more anomalies of arbitrary shape, topology, and size, embedded in a known background (inverse obstacles problem). The foundation of the Kernel Method is that if there exists a proper current density applied at the boundary (Neumann data) of the domain that is able to produce the same measurements with and without the anomaly, then this boundary source produces a power density that vanishes in the region occupied by the anomaly, when applied to the problem involving the background material only. Therefore, the Kernel Method consists of (i) evaluating a proper current density g at the boundary of the domain of interest, by solving a proper linear eigenvalue problem, (ii) solving one direct problem for the configuration without anomaly and driven by g, and (iii) reconstructing the anomaly as the region in which the power density is negligible. This new tomographic method has a very simple numerical implementation that requires a very low computational cost. In addition to theoretical results, an extensive numerical campaign proves the effectiveness of this new imaging method.","authors":["Antonello Tamburrino","Vincenzo Mottola"],"url":"https://arxiv.org/abs/2312.05059"}
{"created":"2025-05-22","title":"BurstGPT: A Real-world Workload Dataset to Optimize LLM Serving Systems","abstract":"Serving systems for Large Language Models (LLMs) are often optimized to improve quality of service (QoS) and throughput. However, due to the lack of open-source LLM serving workloads, these systems are frequently evaluated under unrealistic workload assumptions. Consequently, performance may degrade when systems are deployed in real-world scenarios. This work presents BurstGPT, an LLM serving workload with 10.31 million traces from regional Azure OpenAI GPT services over 213 days. BurstGPT captures LLM serving characteristics from user, model and system perspectives: (1) User request concurrency: burstiness variations of requests in Azure OpenAI GPT services, revealing diversified concurrency patterns in different services and model types. (2) User conversation patterns: counts and intervals within conversations for service optimizations. (3) Model response lengths: auto-regressive serving processes of GPT models, showing statistical relations between requests and their responses. (4) System response failures: failures of conversation and API services, showing intensive resource needs and limited availability of LLM services in Azure. The details of the characteristics can serve multiple purposes in LLM serving optimizations, such as system evaluation and trace provisioning. In our demo evaluation with BurstGPT, frequent variations in BurstGPT reveal declines in efficiency, stability, or reliability in realistic LLM serving. We identify that the generalization of KV cache management, scheduling and disaggregation optimizations can be improved under realistic workload evaluations. BurstGPT is publicly available now at https://github.com/HPMLL/BurstGPT and is widely used to develop prototypes of LLM serving frameworks in the industry.","authors":["Yuxin Wang","Yuhan Chen","Zeyu Li","Xueze Kang","Yuchu Fang","Yeju Zhou","Yang Zheng","Zhenheng Tang","Xin He","Rui Guo","Xin Wang","Qiang Wang","Amelie Chi Zhou","Xiaowen Chu"],"url":"https://arxiv.org/abs/2401.17644"}
{"created":"2025-05-22","title":"Streaming Sequence Transduction through Dynamic Compression","abstract":"We introduce STAR (Stream Transduction with Anchor Representations), a novel Transformer-based model designed for efficient sequence-to-sequence transduction over streams. STAR dynamically segments input streams to create compressed anchor representations, achieving nearly lossless compression (12x) in Automatic Speech Recognition (ASR) and outperforming existing methods. Moreover, STAR demonstrates superior segmentation and latency-quality trade-offs in simultaneous speech-to-text tasks, optimizing latency, memory footprint, and quality.","authors":["Weiting Tan","Yunmo Chen","Tongfei Chen","Guanghui Qin","Haoran Xu","Heidi C. Zhang","Benjamin Van Durme","Philipp Koehn"],"url":"https://arxiv.org/abs/2402.01172"}
{"created":"2025-05-22","title":"Functional SDE approximation inspired by a deep operator network architecture","abstract":"A novel approach to approximate solutions of Stochastic Differential Equations (SDEs) by Deep Neural Networks is derived and analysed. The architecture is inspired by the notion of Deep Operator Networks (DeepONets), which is based on operator learning in function spaces in terms of a reduced basis also represented in the network. In our setting, we make use of a polynomial chaos expansion (PCE) of stochastic processes and call the corresponding architecture SDEONet. The PCE has been used extensively in the area of uncertainty quantification (UQ) with parametric partial differential equations. This however is not the case with SDE, where classical sampling methods dominate and functional approaches are seen rarely. A main challenge with truncated PCEs occurs due to the drastic growth of the number of components with respect to the maximum polynomial degree and the number of basis elements. The proposed SDEONet architecture aims to alleviate the issue of exponential complexity by learning an optimal sparse truncation of the Wiener chaos expansion. A complete convergence and complexity analysis is presented, making use of recent Neural Network approximation results. Numerical experiments illustrate the promising performance of the suggested approach in 1D and higher dimensions.","authors":["Martin Eigel","Charles Miranda"],"url":"https://arxiv.org/abs/2402.03028"}
{"created":"2025-05-22","title":"Uncertainty quantification in fine-tuned LLMs using LoRA ensembles","abstract":"Fine-tuning large language models can improve task specific performance, although a general understanding of what the fine-tuned model has learned, forgotten and how to trust its predictions is still missing. We derive principled uncertainty quantification for fine-tuned LLMs with posterior approximations using computationally efficient low-rank adaptation ensembles. We analyze three common multiple-choice datasets using low-rank adaptation ensembles based on Mistral-7b, and draw quantitative and qualitative conclusions on their perceived complexity and balance between retained prior knowledge and domain specific adaptation during and after fine-tuning. We identify unexpected retention of acquired knowledge during fine-tuning in the overfitting regime.","authors":["Oleksandr Balabanov","Hampus Linander"],"url":"https://arxiv.org/abs/2402.12264"}
{"created":"2025-05-22","title":"Auto-Tuning for OpenMP Dynamic Scheduling applied to Full Waveform Inversion","abstract":"Full Waveform Inversion (FWI) is a widely used method in seismic data processing, capable of estimating models that represent the characteristics of the geological layers of the subsurface. Because it works with a massive amount of data, the execution of this method requires much time and computational resources. Techniques such as FWI adapt well to parallel computing and can be parallelized in shared memory systems using the application programming interface (API) OpenMP. The management of parallel tasks can be performed through loop schedulers contained in OpenMP. The dynamic scheduler stands out for distributing predefined fixed-size chunk sizes to idle processing cores at runtime. It can better adapt to FWI, where data processing can be irregular. However, the relationship between the size of the chunk and the runtime is unknown. Optimization techniques can employ meta-heuristics to explore the parameter search space, avoiding testing all possible solutions. Here, we propose a strategy to use the Parameter Auto-Tuning for Shared Memory Algorithms (PATSMA), with Coupled Simulated Annealing (CSA) as its optimization method, to automatically adjust the chunk for the dynamic scheduling of wave propagation, one of the most expensive steps in FWI. Since testing each candidate chunk in the complete FWI is unpractical, our approach consists of running a PATSMA where the objective function is the runtime of the first time iteration of the first seismic shot of the first FWI iteration. The resulting chunk is then employed in all wave propagations involved in an FWI. We conducted tests to measure the runtime of an FWI using the proposed auto-tuning, varying the problem size and running on different computational environments. The results show that applying the proposed auto-tuning in an FWI reduces its runtime by up to 70.46% compared to standard OpenMP schedulers.","authors":["Felipe H. S. da Silva","Jo\\~ao B. Fernandes","Idalmis M. Sardina","Tiago Barros","Samuel Xavier-de-Souza","Italo A. S. Assis"],"url":"https://arxiv.org/abs/2402.16728"}
{"created":"2025-05-22","title":"Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference","abstract":"Given time series data, how can we answer questions like \"what will happen in the future?\" and \"how did we get here?\" These sorts of probabilistic inference questions are challenging when observations are high-dimensional. In this paper, we show how these questions can have compact, closed form solutions in terms of learned representations. The key idea is to apply a variant of contrastive learning to time series data. Prior work already shows that the representations learned by contrastive learning encode a probability ratio. By extending prior work to show that the marginal distribution over representations is Gaussian, we can then prove that joint distribution of representations is also Gaussian. Taken together, these results show that representations learned via temporal contrastive learning follow a Gauss-Markov chain, a graphical model where inference (e.g., prediction, planning) over representations corresponds to inverting a low-dimensional matrix. In one special case, inferring intermediate representations will be equivalent to interpolating between the learned representations. We validate our theory using numerical simulations on tasks up to 46-dimensions.","authors":["Benjamin Eysenbach","Vivek Myers","Ruslan Salakhutdinov","Sergey Levine"],"url":"https://arxiv.org/abs/2403.04082"}
{"created":"2025-05-22","title":"Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability","abstract":"Cancer is one of the diseases that kill the most women in the world, with breast cancer being responsible for the highest number of cancer cases and consequently deaths. However, it can be prevented by early detection and, consequently, early treatment. Any development for detection or perdition this kind of cancer is important for a better healthy life. Many studies focus on a model with high accuracy in cancer prediction, but sometimes accuracy alone may not always be a reliable metric. This study implies an investigative approach to studying the performance of different machine learning algorithms based on boosting to predict breast cancer focusing on the recall metric. Boosting machine learning algorithms has been proven to be an effective tool for detecting medical diseases. The dataset of the University of California, Irvine (UCI) repository has been utilized to train and test the model classifier that contains their attributes. The main objective of this study is to use state-of-the-art boosting algorithms such as AdaBoost, XGBoost, CatBoost and LightGBM to predict and diagnose breast cancer and to find the most effective metric regarding recall, ROC-AUC, and confusion matrix. Furthermore, our study is the first to use these four boosting algorithms with Optuna, a library for hyperparameter optimization, and the SHAP method to improve the interpretability of our model, which can be used as a support to identify and predict breast cancer. We were able to improve AUC or recall for all the models and reduce the False Negative for AdaBoost and LigthGBM the final AUC were more than 99.41\\% for all models.","authors":["Jo\\~ao Manoel Herrera Pinheiro","Marcelo Becker"],"url":"https://arxiv.org/abs/2403.09548"}
{"created":"2025-05-22","title":"Semantic-Aware Remote Estimation of Multiple Markov Sources Under Constraints","abstract":"This paper studies the remote estimation of multiple Markov sources over a lossy and rate-constrained channel. Unlike most existing studies that treat all source states equally, we exploit the \\emph{semantics of information} and consider that the remote actuator has different tolerances for the estimation errors. We aim to find an optimal scheduling policy that minimizes the long-term \\textit{state-dependent} costs of estimation errors under a transmission frequency constraint. The optimal scheduling problem is formulated as a \\emph{constrained Markov decision process} (CMDP). We show that the optimal Lagrangian cost follows a piece-wise linear and concave (PWLC) function, and the optimal policy is, at most, a randomized mixture of two simple deterministic policies. By exploiting the structural results, we develop a new \\textit{intersection search} algorithm that finds the optimal policy using only a few iterations. We further propose a reinforcement learning (RL) algorithm to compute the optimal policy without knowing \\textit{a priori} the channel and source statistics. To avoid the ``curse of dimensionality\" in MDPs, we propose an online low-complexity \\textit{drift-plus-penalty} (DPP) algorithm. Numerical results show that continuous transmission is inefficient, and remarkably, our semantic-aware policies can attain the optimum by strategically utilizing fewer transmissions by exploiting the timing of the important information.","authors":["Jiping Luo","Nikolaos Pappas"],"url":"https://arxiv.org/abs/2403.16855"}
{"created":"2025-05-22","title":"Learning Heuristics for Transit Network Design and Improvement with Deep Reinforcement Learning","abstract":"Planning a network of public transit routes is a challenging optimization problem. Metaheuristic algorithms search through the space of possible transit networks by applying heuristics that randomly alter routes in a network. The design of these heuristics has a major impact on the quality of the result. In this paper, we use deep reinforcement learning to train a graph neural net to provide heuristics for an evolutionary algorithm. These neural heuristics improve the algorithm's results on benchmark synthetic cities with 70 nodes or more, and achieve new state-of-the-art results on the challenging Mumford benchmark. They also improve upon a simulation of the real transit network in the city of Laval, Canada, by 52% and 25% on two key metrics, and offer cost savings of up to 19% over the city's existing transit network.","authors":["Andrew Holliday","Ahmed El-Geneidy","Gregory Dudek"],"url":"https://arxiv.org/abs/2404.05894"}
{"created":"2025-05-22","title":"Teaching Divisibility and Binomials with Coq","abstract":"The goal of this contribution is to provide worksheets in Coq for students to learn about divisibility and binomials. These basic topics are a good case study as they are widely taught in the early academic years (or before in France). We present here our technical and pedagogical choices, the numerous exercises we developed and a small experiment we conducted on two students. As expected, it required additional Coq material such as other lemmas and dedicated tactics. The worksheets are freely available and flexible in several ways.","authors":["Sylvie Boldo (TOCCATA)","Fran\\c{c}ois Cl\\'ement (SERENA","CERMICS)","David Hamelin (TOCCATA)","Micaela Mayero (LIPN","TOCCATA)","Pierre Rousselin (LAGA","SERENA","CERMICS)"],"url":"https://arxiv.org/abs/2404.12676"}
{"created":"2025-05-22","title":"Breaking the Memory Wall for Heterogeneous Federated Learning via Progressive Training","abstract":"This paper presents ProFL, a new framework that effectively addresses the memory constraints in FL. Rather than updating the full model during local training, ProFL partitions the model into blocks based on its original architecture and trains each block in a progressive fashion. It first trains the front blocks and safely freezes them after convergence. Training of the next block is then triggered. This process progressively grows the model to be trained until the training of the full model is completed. In this way, the peak memory footprint is effectively reduced for feasible deployment on heterogeneous devices. In order to preserve the feature representation of each block, the training process is divided into two stages: model shrinking and model growing. During the model shrinking stage, we meticulously design corresponding output modules to assist each block in learning the expected feature representation and obtain the initialization model parameters. Subsequently, the obtained output modules and initialization model parameters are utilized in the corresponding model growing stage, which progressively trains the full model. Additionally, a novel metric from the scalar perspective is proposed to assess the learning status of each block, enabling us to securely freeze it after convergence and initiate the training of the next one. Finally, we theoretically prove the convergence of ProFL and conduct extensive experiments on representative models and datasets to evaluate its effectiveness. The results demonstrate that ProFL effectively reduces the peak memory footprint by up to 57.4% and improves model accuracy by up to 82.4%.","authors":["Yebo Wu","Li Li","Chengzhong Xu"],"url":"https://arxiv.org/abs/2404.13349"}
{"created":"2025-05-22","title":"DPO: A Differential and Pointwise Control Approach to Reinforcement Learning","abstract":"Reinforcement learning (RL) in continuous state-action spaces remains challenging in scientific computing due to poor sample efficiency and lack of pathwise physical consistency. We introduce Differential Reinforcement Learning (Differential RL), a novel framework that reformulates RL from a continuous-time control perspective via a differential dual formulation. This induces a Hamiltonian structure that embeds physics priors and ensures consistent trajectories without requiring explicit constraints. To implement Differential RL, we develop Differential Policy Optimization (DPO), a pointwise, stage-wise algorithm that refines local movement operators along the trajectory for improved sample efficiency and dynamic alignment. We establish pointwise convergence guarantees, a property not available in standard RL, and derive a competitive theoretical regret bound of $O(K^{5/6})$. Empirically, DPO outperforms standard RL baselines on representative scientific computing tasks, including surface modeling, grid control, and molecular dynamics, under low-data and physics-constrained conditions.","authors":["Minh Nguyen","Chandrajit Bajaj"],"url":"https://arxiv.org/abs/2404.15617"}
{"created":"2025-05-22","title":"DPO Meets PPO: Reinforced Token Optimization for RLHF","abstract":"In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards -- a challenging scenario in traditional deep reinforcement learning. Despite the great successes of PPO in the alignment of large language models, its open-source implementation is still largely sub-optimal. To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information. Under this framework, we introduce an algorithm Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal. Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently. For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage. Extensive experiments demonstrate that \\texttt{RTO} performs better than PPO and other direct preference learning algorithms. In particular, RTO outperforms PPO by 7.5 points on the AlpacaEval 2 benchmark and by 4.1 points on Arena-Hard. Our code and models are available at \\href{https://github.com/zkshan2002/RTO}{https://github.com/zkshan2002/RTO}.","authors":["Han Zhong","Zikang Shan","Guhao Feng","Wei Xiong","Xinle Cheng","Li Zhao","Di He","Jiang Bian","Liwei Wang"],"url":"https://arxiv.org/abs/2404.18922"}
{"created":"2025-05-22","title":"A Framework for Real-time Safeguarding the Text Generation of Large Language Model","abstract":"Large Language Models (LLMs) have significantly advanced natural language processing (NLP) tasks but also pose ethical and societal risks due to their propensity to generate harmful content. Existing methods have limitations, including the need for training specific control models and proactive intervention during text generation, that lead to quality degradation and increased computational overhead. To mitigate those limitations, we propose LLMSafeGuard, a lightweight real-time framework that integrates an external validator into decoding, rejecting unsafe outputs while allowing valid ones. We introduce a similarity-based validation approach, simplifying constraint introduction and eliminating the need for control model training. Additionally, LLMSafeGuard employs a context-wise timing selection strategy, intervening LLMs only when necessary. We evaluate LLMSafeGuard on detoxification and copyright safeguarding, demonstrating its superiority over SOTA baselines. In detoxification, LLMSafeGuard reduces toxic output by at least 38.6\\% while preserving linguistic quality. Additionally, its context-wise timing selection cuts inference time by at least 24.2\\% without compromising effectiveness.","authors":["Ximing Dong","Dayi Lin","Shaowei Wang","Ahmed E. Hassan"],"url":"https://arxiv.org/abs/2404.19048"}
{"created":"2025-05-22","title":"Enhanced Textual Feature Extraction for Visual Question Answering: A Simple Convolutional Approach","abstract":"Visual Question Answering (VQA) has emerged as a highly engaging field in recent years, with increasing research focused on enhancing VQA accuracy through advanced models such as Transformers. Despite this growing interest, limited work has examined the comparative effectiveness of textual encoders in VQA, particularly considering model complexity and computational efficiency. In this work, we conduct a comprehensive comparison between complex textual models that leverage long-range dependencies and simpler models focusing on local textual features within a well-established VQA framework. Our findings reveal that employing complex textual encoders is not always the optimal approach for the VQA-v2 dataset. Motivated by this insight, we propose ConvGRU, a model that incorporates convolutional layers to improve text feature representation without substantially increasing model complexity. Tested on the VQA-v2 dataset, ConvGRU demonstrates a modest yet consistent improvement over baselines for question types such as Number and Count, which highlights the potential of lightweight architectures for VQA tasks, especially when computational resources are limited.","authors":["Zhilin Zhang","Fangyu Wu"],"url":"https://arxiv.org/abs/2405.00479"}
{"created":"2025-05-22","title":"A cornering strategy for synchronizing a DFA","abstract":"This paper considers the existence of short synchronizing words in deterministic finite automata (DFAs). In particular, we define a general strategy, which we call the cornering strategy, for generating short synchronizing words in well-structured DFAs. We show that a DFA is synchronizable if and only if this strategy can be applied.","authors":["Peter Bradshaw","Alexander Clow","Ladislav Stacho"],"url":"https://arxiv.org/abs/2405.00826"}
{"created":"2025-05-22","title":"Efficient Deep Learning with Decorrelated Backpropagation","abstract":"The backpropagation algorithm remains the dominant and most successful method for training deep neural networks (DNNs). At the same time, training DNNs at scale comes at a significant computational cost and therefore a high carbon footprint. Converging evidence suggests that input decorrelation may speed up deep learning. However, to date, this has not yet translated into substantial improvements in training efficiency in large-scale DNNs. This is mainly caused by the challenge of enforcing fast and stable network-wide decorrelation. Here, we show for the first time that much more efficient training of deep convolutional neural networks is feasible by embracing decorrelated backpropagation as a mechanism for learning. To achieve this goal we made use of a novel algorithm which induces network-wide input decorrelation using minimal computational overhead. By combining this algorithm with careful optimizations, we achieve a more than two-fold speed-up and higher test accuracy compared to backpropagation when training several deep networks up to a 50-layer ResNet model. This demonstrates that decorrelation provides exciting prospects for efficient deep learning at scale.","authors":["Sander Dalm","Joshua Offergeld","Nasir Ahmad","Marcel van Gerven"],"url":"https://arxiv.org/abs/2405.02385"}
{"created":"2025-05-22","title":"An Initial Introduction to Cooperative Multi-Agent Reinforcement Learning","abstract":"Multi-agent reinforcement learning (MARL) has exploded in popularity in recent years. While numerous approaches have been developed, they can be broadly categorized into three main types: centralized training and execution (CTE), centralized training for decentralized execution (CTDE), and decentralized training and execution (DTE). CTE methods assume centralization during training and execution (e.g., with fast, free, and perfect communication) and have the most information during execution. CTDE methods are the most common, as they leverage centralized information during training while enabling decentralized execution -- using only information available to that agent during execution. Decentralized training and execution methods make the fewest assumptions and are often simple to implement.","authors":["Christopher Amato"],"url":"https://arxiv.org/abs/2405.06161"}
{"created":"2025-05-22","title":"CatCMA : Stochastic Optimization for Mixed-Category Problems","abstract":"Black-box optimization problems often require simultaneously optimizing different types of variables, such as continuous, integer, and categorical variables. Unlike integer variables, categorical variables do not necessarily have a meaningful order, and the discretization approach of continuous variables does not work well. Although several Bayesian optimization methods can deal with mixed-category black-box optimization (MC-BBO), they suffer from a lack of scalability to high-dimensional problems and internal computational cost. This paper proposes CatCMA, a stochastic optimization method for MC-BBO problems, which employs the joint probability distribution of multivariate Gaussian and categorical distributions as the search distribution. CatCMA updates the parameters of the joint probability distribution in the natural gradient direction. CatCMA also incorporates the acceleration techniques used in the covariance matrix adaptation evolution strategy (CMA-ES) and the stochastic natural gradient method, such as step-size adaptation and learning rate adaptation. In addition, we restrict the ranges of the categorical distribution parameters by margin to prevent premature convergence and analytically derive a promising margin setting. Numerical experiments show that the performance of CatCMA is superior and more robust to problem dimensions compared to state-of-the-art Bayesian optimization algorithms.","authors":["Ryoki Hamano","Shota Saito","Masahiro Nomura","Kento Uchida","Shinichi Shirakawa"],"url":"https://arxiv.org/abs/2405.09962"}
{"created":"2025-05-22","title":"Inverse Design of Metal-Organic Frameworks Using Quantum Natural Language Processing","abstract":"In this study, we explore the potential of using quantum natural language processing (QNLP) to inverse design metal-organic frameworks (MOFs) with targeted properties. Specifically, by analyzing 450 hypothetical MOF structures consisting of 3 topologies, 10 metal nodes and 15 organic ligands, we categorize these structures into four distinct classes for pore volume and $CO_{2}$ Henry's constant values. We then compare various QNLP models (i.e. the bag-of-words, DisCoCat (Distributional Compositional Categorical), and sequence-based models) to identify the most effective approach to process the MOF dataset. Using a classical simulator provided by the IBM Qiskit, the bag-of-words model is identified to be the optimum model, achieving validation accuracies of 88.6% and 78.0% for binary classification tasks on pore volume and $CO_{2}$ Henry's constant, respectively. Further, we developed multi-class classification models tailored to the probabilistic nature of quantum circuits, with average test accuracies of 92% and 80% across different classes for pore volume and $CO_{2}$ Henry's constant datasets. Finally, the performance of generating MOF with target properties showed accuracies of 93.5% for pore volume and 87% for $CO_{2}$ Henry's constant, respectively. Although our investigation covers only a fraction of the vast MOF search space, it marks a promising first step towards using quantum computing for materials design, offering a new perspective through which to explore the complex landscape of MOFs.","authors":["Shinyoung Kang","Jihan Kim"],"url":"https://arxiv.org/abs/2405.11783"}
{"created":"2025-05-22","title":"Optimal Privacy-Aware Stochastic Sampling","abstract":"This paper presents a stochastic sampling framework for privacy-aware data sharing, where a sensor observes a process correlated with private information. A sampler determines whether to retain or discard sensor observations, balancing the tradeoff between data utility and privacy. Retained samples are shared with an adversary who may attempt to infer the private process, with privacy leakage quantified using mutual information. The sampler design is formulated as an optimization problem with two objectives: $\\left(\\romannumeral1\\right)$ minimizing the reconstruction error of the observed process using the sampler's output, $\\left(\\romannumeral2\\right)$ reducing the privacy leakages. For a general class of processes, we show that the optimal reconstruction policy is deterministic and derive the optimality conditions for the sampling policy using a dynamic decomposition method, which enables the sampler to control the adversary's belief about private inputs. For linear Gaussian processes, we propose a simplified design by restricting the sampling policy to a specific collection, providing analytical expressions for the reconstruction error, belief state, and sampling objectives based on conditional means and covariances. Additionally, we develop a numerical optimization algorithm to optimize the sampling and reconstruction policies, wherein the policy gradient theorem for the optimal sampling design is derived based on the implicit function theorem. Simulations demonstrate the effectiveness of the proposed method in achieving accurate state reconstruction, privacy protection, and data size reduction.","authors":["Chuanghong Weng","Ehsan Nekouei"],"url":"https://arxiv.org/abs/2405.11975"}
{"created":"2025-05-22","title":"(Worst-Case) Optimal Adaptive Dynamic Bitvectors","abstract":"While operations {\\em rank} and {\\em select} on static bitvectors can be supported in constant time, lower bounds show that supporting updates raises the cost per operation to $\\Theta(\\log n/ \\log\\log n)$ on bitvectors holding $n$ bits. This is a shame in scenarios where updates are possible but uncommon. We develop a representation of bitvectors that we call adaptive dynamic bitvector, which uses the asymptotically optimal $n+o(n)$ bits of space and, if there are $q$ queries per update, supports all the operations in $O(\\log(n/q)/\\log\\log n)$ amortized time. Further, we prove that this time is \\new{worst-case} optimal in the cell probe model. We describe a large number of applications of our representation to other compact dynamic data structures.","authors":["Gonzalo Navarro"],"url":"https://arxiv.org/abs/2405.15088"}
{"created":"2025-05-22","title":"Towards Real-world Debiasing: Rethinking Evaluation, Challenge, and Solution","abstract":"Spurious correlations in training data significantly hinder the generalization capability of machine learning models when faced with distribution shifts, leading to the proposition of numberous debiasing methods. However, it remains to be asked: \\textit{Do existing benchmarks for debiasing really represent biases in the real world?} Recent works attempt to address such concerns by sampling from real-world data (instead of synthesizing) according to some predefined biased distributions to ensure the realism of individual samples. However, the realism of the biased distribution is more critical yet challenging and underexplored due to the complexity of real-world bias distributions. To tackle the problem, we propose a fine-grained framework for analyzing biased distributions, based on which we empirically and theoretically identify key characteristics of biased distributions in the real world that are poorly represented by existing benchmarks. Towards applicable debiasing in the real world, we further introduce two novel real-world-inspired biases to bridge this gap and build a systematic evaluation framework for real-world debiasing, RDBench\\footnote{RDBench: Code to be released. Preliminary version in supplementary material for anonimized review.}. Furthermore, focusing on the practical setting of debiasing w/o bias label, we find real-world biases pose a novel \\textit{Sparse bias capturing} challenge to the existing paradigm. We propose a simple yet effective approach named Debias in Destruction (DiD), to address the challenge, whose effectiveness is validated with extensive experiments on 8 datasets of various biased distributions.","authors":["Peng Kuang","Zhibo Wang","Zhixuan Chu","Jingyi Wang","Kui Ren"],"url":"https://arxiv.org/abs/2405.15240"}
{"created":"2025-05-22","title":"A Trajectory-Based Bayesian Approach to Multi-Objective Hyperparameter Optimization with Epoch-Aware Trade-Offs","abstract":"Training machine learning models inherently involves a resource-intensive and noisy iterative learning procedure that allows epoch-wise monitoring of the model performance. However, the insights gained from the iterative learning procedure typically remain underutilized in multi-objective hyperparameter optimization scenarios. Despite the limited research in this area, existing methods commonly identify the trade-offs only at the end of model training, overlooking the fact that trade-offs can emerge at earlier epochs in cases such as overfitting. To bridge this gap, we propose an enhanced multi-objective hyperparameter optimization problem that treats the number of training epochs as a decision variable, rather than merely an auxiliary parameter, to account for trade-offs at an earlier training stage. To solve this problem and accommodate its iterative learning, we then present a trajectory-based multi-objective Bayesian optimization algorithm characterized by two features: 1) a novel acquisition function that captures the improvement along the predictive trajectory of model performances over epochs for any hyperparameter setting and 2) a multi-objective early stopping mechanism that determines when to terminate the training to maximize epoch efficiency. Experiments on synthetic simulations and hyperparameter tuning benchmarks demonstrate that our algorithm can effectively identify the desirable trade-offs while improving tuning efficiency.","authors":["Wenyu Wang","Zheyi Fan","Szu Hui Ng"],"url":"https://arxiv.org/abs/2405.15303"}
{"created":"2025-05-22","title":"Uniform H-matrix Compression with Applications to Boundary Integral Equations","abstract":"Boundary integral equations lead to dense system matrices when discretized, yet they are data-sparse. Using the $\\mathcal{H}$-matrix format, this sparsity is exploited to achieve $\\mathcal{O}(N\\log N)$ complexity for storage and multiplication by a vector. This is achieved purely algebraically, based on low-rank approximations of subblocks, and hence the format is also applicable to a wider range of problems. The $\\mathcal{H}^2$-matrix format improves the complexity to $\\mathcal{O}(N)$ by introducing a recursive structure onto subblocks on multiple levels. However, in many cases this comes with a large proportionality constant, making the $\\mathcal{H}^2$-matrix format advantageous mostly for large problems. In this paper we investigate the usefulness of a matrix format that lies in between these two: Uniform $\\mathcal{H}$-matrices. An algebraic compression algorithm is introduced to transform a regular $\\mathcal{H}$-matrix into a uniform $\\mathcal{H}$-matrix, which maintains the asymptotic complexity. Using examples of the BEM formulation of the Helmholtz equation, we show that this scheme lowers the storage requirement and execution time of the matrix-vector product without significantly impacting the construction time.","authors":["Kobe Bruyninckx","Daan Huybrechs","Karl Meerbergen"],"url":"https://arxiv.org/abs/2405.15573"}
{"created":"2025-05-22","title":"A re-calibration method for object detection with multi-modal alignment bias in autonomous driving","abstract":"Multi-modal object detection in autonomous driving has achieved great breakthroughs due to the usage of fusing complementary information from different sensors. The calibration in fusion between sensors such as LiDAR and camera is always supposed to be precise in previous work. However, in reality, calibration matrices are fixed when the vehicles leave the factory, but vibration, bumps, and data lags may cause calibration bias. As the research on the calibration influence on fusion detection performance is relatively few, flexible calibration dependency multi-sensor detection method has always been attractive. In this paper, we conducted experiments on SOTA detection method EPNet++ and proved slight bias on calibration can reduce the performance seriously. We also proposed a re-calibration model based on semantic segmentation which can be combined with a detection algorithm to improve the performance and robustness of multi-modal calibration bias.","authors":["Zhihang Song","Dingyi Yao","Ruibo MIng","Lihui Peng","Jianming Hu","Danya Yao","Yi Zhang"],"url":"https://arxiv.org/abs/2405.16848"}
{"created":"2025-05-22","title":"Detecting and removing bloated dependencies in CommonJS packages","abstract":"JavaScript packages are notoriously prone to bloat, a factor that significantly impacts the performance and maintainability of web applications. While web bundlers and tree-shaking can mitigate this issue in client-side applications, state-of-the-art techniques have limitations on the detection and removal of bloat in server-side applications. In this paper, we present the first study to investigate bloated dependencies within server-side JavaScript applications, focusing on those built with the widely used and highly dynamic CommonJS module system. We propose a trace-based dynamic analysis that monitors the OS file system to determine which dependencies are not accessed during runtime. To evaluate our approach, we curate an original dataset of 91 CommonJS packages with a total of 50,488 dependencies. Compared to the state-of-the-art dynamic and static approaches, our trace-based analysis demonstrates higher accuracy in detecting bloated dependencies. Our analysis identifies 50.6% of the 50,488 dependencies as bloated: 13.8% of direct dependencies and 51.3% of indirect dependencies. Furthermore, removing only the direct bloated dependencies by cleaning the dependency configuration file can remove a significant share of unnecessary bloated indirect dependencies while preserving functional correctness.","authors":["Yuxin Liu","Deepika Tiwari","Cristian Bogdan","Benoit Baudry"],"url":"https://arxiv.org/abs/2405.17939"}
{"created":"2025-05-22","title":"DEFT: Efficient Fine-Tuning of Diffusion Models by Learning the Generalised $h$-transform","abstract":"Generative modelling paradigms based on denoising diffusion processes have emerged as a leading candidate for conditional sampling in inverse problems. In many real-world applications, we often have access to large, expensively trained unconditional diffusion models, which we aim to exploit for improving conditional sampling. Most recent approaches are motivated heuristically and lack a unifying framework, obscuring connections between them. Further, they often suffer from issues such as being very sensitive to hyperparameters, being expensive to train or needing access to weights hidden behind a closed API. In this work, we unify conditional training and sampling using the mathematically well-understood Doob's h-transform. This new perspective allows us to unify many existing methods under a common umbrella. Under this framework, we propose DEFT (Doob's h-transform Efficient FineTuning), a new approach for conditional generation that simply fine-tunes a very small network to quickly learn the conditional $h$-transform, while keeping the larger unconditional network unchanged. DEFT is much faster than existing baselines while achieving state-of-the-art performance across a variety of linear and non-linear benchmarks. On image reconstruction tasks, we achieve speedups of up to 1.6$\\times$, while having the best perceptual quality on natural images and reconstruction performance on medical images. Further, we also provide initial experiments on protein motif scaffolding and outperform reconstruction guidance methods.","authors":["Alexander Denker","Francisco Vargas","Shreyas Padhy","Kieran Didi","Simon Mathis","Vincent Dutordoir","Riccardo Barbano","Emile Mathieu","Urszula Julia Komorowska","Pietro Lio"],"url":"https://arxiv.org/abs/2406.01781"}
{"created":"2025-05-22","title":"MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset","abstract":"To enable Large Language Models (LLMs) to function as conscious agents with generalizable reasoning capabilities, it is crucial that they possess the reasoning ability to comprehend situational changes (transitions) in distribution triggered by environmental factors or actions from other agents. Despite its fundamental significance, this ability remains underexplored due to the complexity of modeling infinite possible changes in an event and their associated distributions, coupled with the lack of benchmark data with situational transitions. Addressing these gaps, we propose a novel formulation of reasoning with distributional changes as a three-step discriminative process, termed as MetAphysical ReaSoning. We then introduce the first-ever benchmark, MARS, comprising three tasks corresponding to each step. These tasks systematically assess LLMs' capabilities in reasoning the plausibility of (i) changes in actions, (ii) states caused by changed actions, and (iii) situational transitions driven by changes in action. Extensive evaluations with 20 (L)LMs of varying sizes and methods indicate that all three tasks in this process pose significant challenges, even for state-of-the-art LLMs and LMs after fine-tuning. Further analyses reveal potential causes for the underperformance of LLMs and demonstrate that pre-training them on large-scale conceptualization taxonomies can potentially enhance their metaphysical reasoning capabilities. Our data and models are publicly accessible at https://github.com/HKUST-KnowComp/MARS.","authors":["Weiqi Wang","Yangqiu Song"],"url":"https://arxiv.org/abs/2406.02106"}
{"created":"2025-05-22","title":"Flexible Heteroscedastic Count Regression with Deep Double Poisson Networks","abstract":"Neural networks that can produce accurate, input-conditional uncertainty representations are critical for real-world applications. Recent progress on heteroscedastic continuous regression has shown great promise for calibrated uncertainty quantification on complex tasks, like image regression. However, when these methods are applied to discrete regression tasks, such as crowd counting, ratings prediction, or inventory estimation, they tend to produce predictive distributions with numerous pathologies. Moreover, discrete models based on the Generalized Linear Model (GLM) framework either cannot process complex input or are not fully heterosedastic. To address these issues we propose the Deep Double Poisson Network (DDPN). In contrast to networks trained to minimize Gaussian negative log likelihood (NLL), discrete network parameterizations (i.e., Poisson, Negative binomial), and GLMs, DDPN can produce discrete predictive distributions of arbitrary flexibility. Additionally, we propose a technique to tune the prioritization of mean fit and probabilistic calibration during training. We show DDPN 1) vastly outperforms existing discrete models; 2) meets or exceeds the accuracy and flexibility of networks trained with Gaussian NLL; 3) produces proper predictive distributions over discrete counts; and 4) exhibits superior out-of-distribution detection. DDPN can easily be applied to a variety of count regression datasets including tabular, image, point cloud, and text data.","authors":["Spencer Young","Porter Jenkins","Longchao Da","Jeff Dotson","Hua Wei"],"url":"https://arxiv.org/abs/2406.09262"}
{"created":"2025-05-22","title":"SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model","abstract":"The emergence of Vision Language Models (VLMs) has brought unprecedented advances in understanding multimodal information. The combination of textual and visual semantics in VLMs is highly complex and diverse, making the safety alignment of these models challenging. Furthermore, due to the limited study on the safety alignment of VLMs, there is a lack of large-scale, high-quality datasets. To address these limitations, we propose a Safety Preference Alignment dataset for Vision Language Models named SPA-VL. In terms of breadth, SPA-VL covers 6 harmfulness domains, 13 categories, and 53 subcategories, and contains 100,788 samples of the quadruple (question, image, chosen response, rejected response). In terms of depth, the responses are collected from 12 open-source (e.g., QwenVL) and closed-source (e.g., Gemini) VLMs to ensure diversity. The construction of preference data is fully automated, and the experimental results indicate that models trained with alignment techniques on the SPA-VL dataset exhibit substantial improvements in harmlessness and helpfulness while maintaining core capabilities. SPA-VL, as a large-scale, high-quality, and diverse dataset, represents a significant milestone in ensuring that VLMs achieve both harmlessness and helpfulness.","authors":["Yongting Zhang","Lu Chen","Guodong Zheng","Yifeng Gao","Rui Zheng","Jinlan Fu","Zhenfei Yin","Senjie Jin","Yu Qiao","Xuanjing Huang","Feng Zhao","Tao Gui","Jing Shao"],"url":"https://arxiv.org/abs/2406.12030"}
{"created":"2025-05-22","title":"Exploring the Robustness of Language Models for Tabular Question Answering via Attention Analysis","abstract":"Large Language Models (LLMs), already shown to ace various text comprehension tasks, have also remarkably been shown to tackle table comprehension tasks without specific training. Building on earlier studies of LLMs for tabular tasks, we probe how in-context learning (ICL), model scale, instruction tuning, and domain bias affect Tabular QA (TQA) robustness by testing LLMs, under diverse augmentations and perturbations, on diverse domains: Wikipedia-based $\\textbf{WTQ}$, financial $\\textbf{TAT-QA}$, and scientific $\\textbf{SCITAB}$. Although instruction tuning and larger, newer LLMs deliver stronger, more robust TQA performance, data contamination and reliability issues, especially on $\\textbf{WTQ}$, remain unresolved. Through an in-depth attention analysis, we reveal a strong correlation between perturbation-induced shifts in attention dispersion and the drops in performance, with sensitivity peaking in the model's middle layers. We highlight the need for improved interpretable methodologies to develop more reliable LLMs for table comprehension.","authors":["Kushal Raj Bhandari","Sixue Xing","Soham Dan","Jianxi Gao"],"url":"https://arxiv.org/abs/2406.12719"}
{"created":"2025-05-22","title":"Hitchhiker's guide on the relation of Energy-Based Models with other generative models, sampling and statistical physics: a comprehensive review","abstract":"Energy-Based Models have emerged as a powerful framework in the realm of generative modeling, offering a unique perspective that aligns closely with principles of statistical mechanics. This review aims to provide physicists with a comprehensive understanding of EBMs, delineating their connection to other generative models such as Generative Adversarial Networks, Variational Autoencoders, and Normalizing Flows. We explore the sampling techniques crucial for EBMs, including Markov Chain Monte Carlo (MCMC) methods, and draw parallels between EBM concepts and statistical mechanics, highlighting the significance of energy functions and partition functions. Furthermore, we delve into recent training methodologies for EBMs, covering recent advancements and their implications for enhanced model performance and efficiency. This review is designed to clarify the often complex interconnections between these models, which can be challenging due to the diverse communities working on the topic.","authors":["Davide Carbone (Laboratoire de Physique de l'Ecole Normale Sup\\'erieure","ENS Universit\\'e PSL","CNRS","Sorbonne Universit\\'e","Universit\\'e de Paris","Paris)"],"url":"https://arxiv.org/abs/2406.13661"}
{"created":"2025-05-22","title":"Boosting Few-Shot Open-Set Object Detection via Prompt Learning and Robust Decision Boundary","abstract":"Few-shot Open-set Object Detection (FOOD) poses a challenge in many open-world scenarios. It aims to train an open-set detector to detect known objects while rejecting unknowns with scarce training samples. Existing FOOD methods are subject to limited visual information, and often exhibit an ambiguous decision boundary between known and unknown classes. To address these limitations, we propose the first prompt-based few-shot open-set object detection framework, which exploits additional textual information and delves into constructing a robust decision boundary for unknown rejection. Specifically, as no available training data for unknown classes, we select pseudo-unknown samples with Attribution-Gradient based Pseudo-unknown Mining (AGPM), which leverages the discrepancy in attribution gradients to quantify uncertainty. Subsequently, we propose Conditional Evidence Decoupling (CED) to decouple and extract distinct knowledge from selected pseudo-unknown samples by eliminating opposing evidence. This optimization process can enhance the discrimination between known and unknown classes. To further regularize the model and form a robust decision boundary for unknown rejection, we introduce Abnormal Distribution Calibration (ADC) to calibrate the output probability distribution of local abnormal features in pseudo-unknown samples. Our method achieves superior performance over previous state-of-the-art approaches, improving the average recall of unknown class by 7.24% across all shots in VOC10-5-5 dataset settings and 1.38% in VOC-COCO dataset settings. Our source code is available at https://gitee.com/VR_NAVE/ced-food.","authors":["Zhaowei Wu","Binyi Su","Qichuan Geng","Hua Zhang","Zhong Zhou"],"url":"https://arxiv.org/abs/2406.18443"}
{"created":"2025-05-22","title":"Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior","abstract":"One way to personalize and steer generations from large language models (LLM) is to assign a persona: a role that describes how the user expects the LLM to behave (e.g., a helpful assistant, a teacher, a woman). This paper investigates how personas affect diverse aspects of model behavior. We assign to seven LLMs 162 personas from 12 categories spanning variables like gender, sexual orientation, and occupation. We prompt them to answer questions from five datasets covering objective (e.g., questions about math and history) and subjective tasks (e.g., questions about beliefs and values). We also compare persona's generations to two baseline settings: a control persona setting with 30 paraphrases of \"a helpful assistant\" to control for models' prompt sensitivity, and an empty persona setting where no persona is assigned. We find that for all models and datasets, personas show greater variability than the control setting and that some measures of persona behavior generalize across models.","authors":["Pedro Henrique Luz de Araujo","Benjamin Roth"],"url":"https://arxiv.org/abs/2407.02099"}
{"created":"2025-05-22","title":"Data-driven Software-based Power Estimation for Embedded Devices","abstract":"Energy measurement of computer devices, which are widely used in the Internet of Things (IoT), is an important yet challenging task. Most of these IoT devices lack ready-to-use hardware or software for power measurement. In this paper, we propose an easy-to-use approach to derive a software-based energy estimation model with external low-end power meters based on data-driven analysis. Our solution is demonstrated with a Jetson Nano board and Ruideng UM25C USB power meter. Various machine learning methods combined with our smart data collection & profiling method and physical measurement are explored. Periodic Long-duration measurements are utilized in the experiments to derive and validate power models, allowing more accurate power readings from the low-end power meter. Benchmarks were used to evaluate the derived software-power model for the Jetson Nano board and Raspberry Pi. The results show that 92\\% accuracy can be achieved by the software-based power estimation compared to measurement. A kernel module that can collect running traces of utilization and frequencies needed is developed, together with the power model derived, for power prediction for programs running in a real environment. Our cost-effective method facilitates accurate instantaneous power estimation, which low-end power meters cannot directly provide.","authors":["Haoyu Wang","Xinyi Li","Ti Zhou","Man Lin"],"url":"https://arxiv.org/abs/2407.02764"}
{"created":"2025-05-22","title":"StmtTree: An Easy-to-Use yet Versatile Fortran Transformation Toolkit","abstract":"The Fortran programming language continues to dominate the scientific computing community, with many production codes written in the outdated Fortran-77 dialect, yet with many non-standard extensions such as Cray poiters. This creates significant maintenance burden within the community, with tremendous efforts devoted to modernization. However, despite the modern age of advanced compiler frameworks, processing and transforming old Fortran codes remains challenging. In this paper, we present StmtTree, a new Fortran code transformation toolkit to address this issue. StmtTree abstracts the Fortran grammar into statement tree, offering both a low-level representation manipulation API and a high-level, easy-to-use query and manipulation mini-language. StmtTree simplifies the creation of customized Fortran transformation tools. Experiments show that StmtTree adapts well to legacy Fortran-77 codes, and complex tools such as removing unused statements can be developed with fewer than 100 lines of python code.","authors":["Jingbo Lin","Yi Yu","Zhang Yang","Yafan Zhao"],"url":"https://arxiv.org/abs/2407.05652"}
{"created":"2025-05-22","title":"Enrich the content of the image Using Context-Aware Copy Paste","abstract":"Data augmentation remains a widely utilized technique in deep learning, particularly in tasks such as image classification, semantic segmentation, and object detection. Among them, Copy-Paste is a simple yet effective method and gain great attention recently. However, existing Copy-Paste often overlook contextual relevance between source and target images, resulting in inconsistencies in generated outputs. To address this challenge, we propose a context-aware approach that integrates Bidirectional Latent Information Propagation (BLIP) for content extraction from source images. By matching extracted content information with category information, our method ensures cohesive integration of target objects using Segment Anything Model (SAM) and You Only Look Once (YOLO). This approach eliminates the need for manual annotation, offering an automated and user-friendly solution. Experimental evaluations across diverse datasets demonstrate the effectiveness of our method in enhancing data diversity and generating high-quality pseudo-images across various computer vision tasks.","authors":["Qiushi Guo"],"url":"https://arxiv.org/abs/2407.08151"}
{"created":"2025-05-22","title":"MgFNO: Multi-grid Architecture Fourier Neural Operator for Parametric Partial Differential Equations","abstract":"Neural operators are a new type of models that can map between function spaces, allowing trained models to emulate the solution operators of partial differential equations (PDEs). This paper proposes a multigrid Fourier neural operator (MgFNO) that accelerates the training of traditional Fourier neural operators through a novel three-level hierarchical architecture. The key innovation of MgFNO lies in its decoupled training strategy employing three distinct networks at different resolution levels: a coarse-level network first learns low-resolution approximations, an intermediate network refines the solution, and a fine-level network achieves high-resolution accuracy. By combining the frequency principle of deep neural networks with multigrid methodology, MgFNO effectively bridges the complementary learning patterns of neural networks (low-to-high frequency) and multigrid methods (high-to-low frequency error reduction).Experimental results demonstrate that MgFNO achieves relative errors of 0.17%, 0.28%, and 0.22% on the Burgers' equation, Darcy flow, and Navier-Stokes equations, respectively, representing reductions of 89%, 71%, and 83% compared to the conventional FNO. Furthermore, MgFNO supports zero-shot super-resolution prediction, enabling direct application to high-resolution scenarios after training on coarse grids. This study establishes an efficient and high-accuracy new paradigm for solving complex PDEs dominated by high-frequency dynamics. Code and data used are available on https://github.com/guozihao-hub/MgFNO/tree/master.","authors":["Zi-Hao Guo","Hou-Biao Li"],"url":"https://arxiv.org/abs/2407.08615"}
{"created":"2025-05-22","title":"Local Clustering for Lung Cancer Image Classification via Sparse Solution Technique","abstract":"In this work, we propose to use a local clustering approach based on the sparse solution technique to study the medical image, especially the lung cancer image classification task. We view images as the vertices in a weighted graph and the similarity between a pair of images as the edges in the graph. The vertices within the same cluster can be assumed to share similar features and properties, thus making the applications of graph clustering techniques very useful for image classification. Recently, the approach based on the sparse solutions of linear systems for graph clustering has been found to identify clusters more efficiently than traditional clustering methods such as spectral clustering. We propose to use the two newly developed local clustering methods based on sparse solution of linear system for image classification. In addition, we employ a box spline-based tight-wavelet-framelet method to clean these images and help build a better adjacency matrix before clustering. The performance of our methods is shown to be very effective in classifying images. Our approach is significantly more efficient and either favorable or equally effective compared with other state-of-the-art approaches. Finally, we shall make a remark by pointing out two image deformation methods to build up more artificial image data to increase the number of labeled images.","authors":["Jackson Hamel","Ming-Jun Lai","Zhaiming Shen","Ye Tian"],"url":"https://arxiv.org/abs/2407.08800"}
{"created":"2025-05-22","title":"Multibeam Satellite Communications with Massive MIMO: Asymptotic Performance Analysis and Design Insights","abstract":"To achieve high performance without substantial overheads associated with channel state information (CSI) of ground users, we consider a fixed-beam precoding approach, where a satellite forms multiple fixed-beams without relying on CSI, then select a suitable user set for each beam. Upon this precoding method, we put forth a satellite equipped with massive multiple-input multiple-output (MIMO), by which inter-beam interference is efficiently mitigated by narrowing corresponding beam width. By modeling the ground users' locations via a Poisson point process, we rigorously analyze the achievable performance of the presented multibeam satellite system. In particular, we investigate the asymptotic scaling laws that reveal the interplay between the user density, the number of beams, and the number of antennas. Our analysis offers critical design insights for the multibeam satellite with massive MIMO: i) If the user density scales in power with the number of antennas, the considered precoding can achieve a linear fraction of the optimal rate in the asymptotic regime. ii) A certain additional scaling factor for the user density is needed as the number of beams increases to maintain the asymptotic optimality.","authors":["Seyong Kim","Jinseok Choi","Wonjae Shin","Namyoon Lee","Jeonghun Park"],"url":"https://arxiv.org/abs/2407.10461"}
{"created":"2025-05-22","title":"Exploring the Potentials and Challenges of Deep Generative Models in Product Design Conception","abstract":"The synthesis of product design concepts stands at the crux of early-phase development processes for technical products, traditionally posing an intricate interdisciplinary challenge. The application of deep learning methods, particularly Deep Generative Models (DGMs), holds the promise of automating and streamlining manual iterations and therefore introducing heightened levels of innovation and efficiency. However, DGMs have yet to be widely adopted into the synthesis of product design concepts. This paper aims to explore the reasons behind this limited application and derive the requirements for successful integration of these technologies. We systematically analyze DGM-families (VAE, GAN, Diffusion, Transformer, Radiance Field), assessing their strengths, weaknesses, and general applicability for product design conception. Our objective is to provide insights that simplify the decision-making process for engineers, helping them determine which method might be most effective for their specific challenges. Recognizing the rapid evolution of this field, we hope that our analysis contributes to a fundamental understanding and guides practitioners towards the most promising approaches. This work seeks not only to illuminate current challenges but also to propose potential solutions, thereby offering a clear roadmap for leveraging DGMs in the realm of product design conception.","authors":["Phillip Mueller","Lars Mikelsons"],"url":"https://arxiv.org/abs/2407.11104"}
{"created":"2025-05-22","title":"A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting","abstract":"Recently, Large Language Models (LLMs) have demonstrated great potential in various data mining tasks, such as knowledge question answering, mathematical reasoning, and commonsense reasoning. However, the reasoning capability of LLMs on temporal event forecasting has been under-explored. To systematically investigate their abilities in temporal event forecasting, we conduct a comprehensive evaluation of LLM-based methods for temporal event forecasting. Due to the lack of a high-quality dataset that involves both graph and textual data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on this dataset, we design a series of baseline methods, characterized by various input formats and retrieval augmented generation (RAG) modules. From extensive experiments, we find that directly integrating raw texts into the input of LLMs does not enhance zero-shot extrapolation performance. In contrast, fine-tuning LLMs with raw texts can significantly improve performance. Additionally, LLMs enhanced with retrieval modules can effectively capture temporal relational patterns hidden in historical events. However, issues such as popularity bias and the long-tail problem persist in LLMs, particularly in the retrieval-augmented generation (RAG) method. These findings not only deepen our understanding of LLM-based event forecasting methods but also highlight several promising research directions. We consider that this comprehensive evaluation, along with the identified research opportunities, will significantly contribute to future research on temporal event forecasting through LLMs.","authors":["He Chang","Chenchen Ye","Zhulin Tao","Jie Wu","Zhengmao Yang","Yunshan Ma","Xianglin Huang","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2407.11638"}
{"created":"2025-05-22","title":"An Efficient TLS 1.3 Handshake Protocol with VC Certificate Type","abstract":"The paper presents a step forward in the design and implementation of a Transport Layer Security (TLS) handshake protocol that enables the use of Verifiable Credential (VC) while maintaining full compliance with RFC-8446 and preserving all the security features of TLS 1.3. The improvement over our previous work lies in the handshake design, which now only uses messages already defined for TLS 1.3. The design has an incredibly positive impact on the implementation, as we made minimal changes to the OpenSSL library and relied mostly on a novel external provider to handle VC and Decentralized IDentifier (DID) related operations. The experimental results prove the feasibility of the design and show comparable performance to the original solution based on Public Key Infrastructure (PKI) and X.509 certificates. These results pave the way for the adoption of Self-Sovereign Identity in large-scale Internet of Things (IoT) systems, with a clear benefit in terms of reducing the cost of identity management.","authors":["Leonardo Perugini","Andrea Vesco"],"url":"https://arxiv.org/abs/2407.12536"}
{"created":"2025-05-22","title":"dMel: Speech Tokenization made Simple","abstract":"Large language models have revolutionized natural language processing by leveraging self-supervised pretraining on vast textual data. Inspired by this success, researchers have investigated various compression-based speech tokenization methods to discretize continuous speech signals, enabling the application of language modeling techniques to discrete tokens. However, audio compressor introduces additional complexity and computational cost, and often fail on out-of-domain audio signals. In this work, we introduce a novel speech representation (dmel) that discretizes mel-filterbank channels into intensity bins, creating a simpler yet more effective representation compared to existing speech tokenization methods. Our approach demonstrates superior performance in preserving audio content, robustness to out-of-domain data, and offers a training-free, natural, and streamable representation. To address the high-dimensional nature of log-mel spectrograms, we propose an efficient parallel encoding and decoding method for high-dimensional tokens using an LM-style transformer architecture. This innovation enables us to develop RichTTS and RichASR, two models sharing the same architecture while achieving comparable or better results than specialized existing methods. Our results demonstrate the effectiveness of dmel in achieving high performance on both speech synthesis and recognition tasks within a unified framework, paving the way for efficient and effective joint modeling of speech and text.","authors":["Richard He Bai","Tatiana Likhomanenko","Ruixiang Zhang","Zijin Gu","Zakaria Aldeneh","Navdeep Jaitly"],"url":"https://arxiv.org/abs/2407.15835"}
{"created":"2025-05-22","title":"Parameter-Efficient Fine-Tuning via Circular Convolution","abstract":"Low-Rank Adaptation (LoRA) has gained popularity for fine-tuning large foundation models, leveraging low-rank matrices $\\mathbf{A}$ and $\\mathbf{B}$ to represent weight changes (i.e., $\\Delta \\mathbf{W} = \\mathbf{B} \\mathbf{A}$). This method reduces trainable parameters and mitigates heavy memory consumption associated with full delta matrices by sequentially multiplying $\\mathbf{A}$ and $\\mathbf{B}$ with the activation. Despite its success, the intrinsic low-rank characteristic may limit its performance. Although several variants have been proposed to address this issue, they often overlook the crucial computational and memory efficiency brought by LoRA. In this paper, we propose Circular Convolution Adaptation (C$^3$A), which not only achieves high-rank adaptation with enhanced performance but also excels in both computational power and memory utilization. Extensive experiments demonstrate that C$^3$A consistently outperforms LoRA and its variants across various fine-tuning tasks.","authors":["Aochuan Chen","Jiashun Cheng","Zijing Liu","Ziqi Gao","Fugee Tsung","Yu Li","Jia Li"],"url":"https://arxiv.org/abs/2407.19342"}
{"created":"2025-05-22","title":"Online Prediction-Assisted Safe Reinforcement Learning for Electric Vehicle Charging Station Recommendation in Dynamically Coupled Transportation-Power Systems","abstract":"With the proliferation of electric vehicles (EVs), the transportation network and power grid become increasingly interdependent and coupled via charging stations. The concomitant growth in charging demand has posed challenges for both networks, highlighting the importance of charging coordination. Existing literature largely overlooks the interactions between power grid security and traffic efficiency. In view of this, we study the en-route charging station (CS) recommendation problem for EVs in dynamically coupled transportation-power systems. The system-level objective is to maximize the overall traffic efficiency while ensuring the safety of the power grid. This problem is for the first time formulated as a constrained Markov decision process (CMDP), and an online prediction-assisted safe reinforcement learning (OP-SRL) method is proposed to learn the optimal and secure policy by extending the PPO method. To be specific, we mainly address two challenges. First, the constrained optimization problem is converted into an equivalent unconstrained optimization problem by applying the Lagrangian method. Second, to account for the uncertain long-time delay between performing CS recommendation and commencing charging, we put forward an online sequence-to-sequence (Seq2Seq) predictor for state augmentation to guide the agent in making forward-thinking decisions. Finally, we conduct comprehensive experimental studies based on the Nguyen-Dupuis network and a large-scale real-world road network, coupled with IEEE 33-bus and IEEE 69-bus distribution systems, respectively. Results demonstrate that the proposed method outperforms baselines in terms of road network efficiency, power grid safety, and EV user satisfaction. The case study on the real-world network also illustrates the applicability in the practical context.","authors":["Qionghua Liao","Guilong Li","Jiajie Yu","Ziyuan Gu","Wei Ma"],"url":"https://arxiv.org/abs/2407.20679"}
{"created":"2025-05-22","title":"IntentRec: Predicting User Session Intent with Hierarchical Multi-Task Learning","abstract":"Recommender systems have played a critical role in diverse digital services such as e-commerce, streaming media, social networks, etc. If we know what a user's intent is in a given session (e.g. do they want to watch short videos or a movie or play games; are they shopping for a camping trip), it becomes easier to provide high-quality recommendations. In this paper, we introduce IntentRec, a novel recommendation framework based on hierarchical multi-task neural network architecture that tries to estimate a user's latent intent using their short- and long-term implicit signals as proxies and uses the intent prediction to predict the next item user is likely to engage with. By directly leveraging the intent prediction, we can offer accurate and personalized recommendations to users. Our comprehensive experiments on Netflix user engagement data show that IntentRec outperforms the state-of-the-art next-item and next-intent predictors. We also share several findings and downstream applications of IntentRec.","authors":["Sejoon Oh","Moumita Bhattacharya","Yesu Feng","Sudarshan Lamkhede"],"url":"https://arxiv.org/abs/2408.05353"}
{"created":"2025-05-22","title":"P3P: Pseudo-3D Pre-training for Scaling 3D Voxel-based Masked Autoencoders","abstract":"3D pre-training is crucial to 3D perception tasks. Nevertheless, limited by the difficulties in collecting clean and complete 3D data, 3D pre-training has persistently faced data scaling challenges. In this work, we introduce a novel self-supervised pre-training framework that incorporates millions of images into 3D pre-training corpora by leveraging a large depth estimation model. New pre-training corpora encounter new challenges in representation ability and embedding efficiency of models. Previous pre-training methods rely on farthest point sampling and k-nearest neighbors to embed a fixed number of 3D tokens. However, these approaches prove inadequate when it comes to embedding millions of samples that feature a diverse range of point numbers, spanning from 1,000 to 100,000. In contrast, we propose a tokenizer with linear-time complexity, which enables the efficient embedding of a flexible number of tokens. Accordingly, a new 3D reconstruction target is proposed to cooperate with our 3D tokenizer. Our method achieves state-of-the-art performance in 3D classification, few-shot learning, and 3D segmentation. Code is available at https://github.com/XuechaoChen/P3P-MAE.","authors":["Xuechao Chen","Ying Chen","Jialin Li","Qiang Nie","Hanqiu Deng","Yong Liu","Qixing Huang","Yang Li"],"url":"https://arxiv.org/abs/2408.10007"}
{"created":"2025-05-22","title":"SANER: Annotation-free Societal Attribute Neutralizer for Debiasing CLIP","abstract":"Large-scale vision-language models, such as CLIP, are known to contain societal bias regarding protected attributes (e.g., gender, age). This paper aims to address the problems of societal bias in CLIP. Although previous studies have proposed to debias societal bias through adversarial learning or test-time projecting, our comprehensive study of these works identifies two critical limitations: 1) loss of attribute information when it is explicitly disclosed in the input and 2) use of the attribute annotations during debiasing process. To mitigate societal bias in CLIP and overcome these limitations simultaneously, we introduce a simple-yet-effective debiasing method called SANER (societal attribute neutralizer) that eliminates attribute information from CLIP text features only of attribute-neutral descriptions. Experimental results show that SANER, which does not require attribute annotations and preserves original information for attribute-specific descriptions, demonstrates superior debiasing ability than the existing methods.","authors":["Yusuke Hirota","Min-Hung Chen","Chien-Yi Wang","Yuta Nakashima","Yu-Chiang Frank Wang","Ryo Hachiuma"],"url":"https://arxiv.org/abs/2408.10202"}
{"created":"2025-05-22","title":"An In-Depth Investigation of Data Collection in LLM App Ecosystems","abstract":"LLM app (tool) ecosystems are rapidly evolving to support sophisticated use cases that often require extensive user data collection. Given that LLM apps are developed by third parties and anecdotal evidence indicating inconsistent enforcement of policies by LLM platforms, sharing user data with these apps presents significant privacy risks. In this paper, we aim to bring transparency in data practices of LLM app ecosystems. We examine OpenAI's GPT app ecosystem as a case study. We propose an LLM-based framework to analyze the natural language specifications of GPT Actions (custom tools) and assess their data collection practices. Our analysis reveals that Actions collect excessive data across 24 categories and 145 data types, with third-party Actions collecting 6.03% more data on average. We find that several Actions violate OpenAI's policies by collecting sensitive information, such as passwords, which is explicitly prohibited by OpenAI. Lastly, we develop an LLM-based privacy policy analysis framework to automatically check the consistency of data collection by Actions with disclosures in their privacy policies. Our measurements indicate that the disclosures for most of the collected data types are omitted, with only 5.8% of Actions clearly disclosing their data collection practices.","authors":["Yuhao Wu","Evin Jaff","Ke Yang","Ning Zhang","Umar Iqbal"],"url":"https://arxiv.org/abs/2408.13247"}
{"created":"2025-05-22","title":"NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API Calls","abstract":"The resurgence of autonomous agents built using large language models (LLMs) to solve complex real-world tasks has brought increased focus on LLMs' fundamental ability of tool or function calling. At the core of these agents, an LLM must plan, execute, and respond using external tools, APIs, and custom functions. Research on tool calling has gathered momentum, but evaluation benchmarks and datasets representing the complexity of the tasks have lagged behind. In this work, we focus on one such complexity, nested sequencing, with the goal of extending existing benchmarks and evaluation. Specifically, we present NESTFUL, a benchmark to evaluate LLMs on nested sequences of API calls, i.e., sequences where the output of one API call is passed as input to a subsequent call. NESTFUL contains 1800+ nested sequences where all the function calls are executable. Experimental results on a variety of models show that the best-performing model (GPT-4o) achieves a full sequence match accuracy of 28% and a win-rate of 60%, necessitating a large scope for improvement in the nested sequencing aspect of function calling. Our analysis of these results provides possible future research directions for the community, in addition to a benchmark to track progress. We have released the NESTFUL dataset under the Apache 2.0 license at https://github.com/IBM/NESTFUL.","authors":["Kinjal Basu","Ibrahim Abdelaziz","Kiran Kate","Mayank Agarwal","Maxwell Crouse","Yara Rizk","Kelsey Bradford","Asim Munawar","Sadhana Kumaravel","Saurabh Goyal","Xin Wang","Luis A. Lastras","Pavan Kapanipathi"],"url":"https://arxiv.org/abs/2409.03797"}
{"created":"2025-05-22","title":"Neural Entropy","abstract":"We explore the connection between deep learning and information theory through the paradigm of diffusion models. A diffusion model converts noise into structured data by reinstating, imperfectly, information that is erased when data was diffused to noise. This information is stored in a neural network during training. We quantify this information by introducing a measure called neural entropy, which is related to the total entropy produced by diffusion. Neural entropy is a function of not just the data distribution, but also the diffusive process itself. Measurements of neural entropy on a few simple image diffusion models reveal that they are extremely efficient at compressing large ensembles of structured data.","authors":["Akhil Premkumar"],"url":"https://arxiv.org/abs/2409.03817"}
{"created":"2025-05-22","title":"RayFlex: An Open-Source RTL Implementation of the Hardware Ray Tracer Datapath","abstract":"The advent of hardware ray tracing (RT) units has brought unprecedented realism to real-time rendered computer graphics. However, the potential of these units extends beyond graphics, offering acceleration for various computational tasks such as tree traversal and nearest-neighbor search. We introduce RayFlex, a first-of-its-kind open-source RTL implementation of a hardware ray tracer datapath designed to facilitate research in general-purpose programmable RT units. RayFlex's architecture is both extensible and flexible, thanks to two core design concepts: the parameterized RayFlex Skid Buffer module and the \"defined-once-instantiated-everywhere\" Shared RayFlex Data Structure. This makes RayFlex an ideal testing ground for academic research and exploration. Our implementation allows researchers to explore various design choices, fostering a realistic understanding of hardware ray tracer design trade-offs. Through comprehensive case studies, we demonstrate the versatility of RayFlex in evaluating different pipeline configurations and extending its functionality to support additional computational tasks. We show that by extending the functionality of a baseline RT unit datapath with an area cost of 36 percent and a power overhead of about 20 percent, the RT unit can calculate the Euclidean distance and cosine distance of vectors of arbitrary dimension, thereby accelerating a broader range of data-analytics workloads. The source code of RayFlex is available at https://github.com/purdue-aalp/rayflex.","authors":["Fangjia Shen","Aaron Barnes","Anusuya Nallathambi","Timothy G. Rogers"],"url":"https://arxiv.org/abs/2409.06000"}
{"created":"2025-05-22","title":"Automated Data Augmentation for Few-Shot Time Series Forecasting: A Reinforcement Learning Approach Guided by a Model Zoo","abstract":"Time series forecasting, particularly in few-shot learning scenarios, is challenging due to the limited availability of high-quality training data. To address this, we present a pilot study on using reinforcement learning (RL) for time series data augmentation. Our method, ReAugment, tackles three critical questions: which parts of the training set should be augmented, how the augmentation should be performed, and what advantages RL brings to the process. Specifically, our approach maintains a forecasting model zoo, and by measuring prediction diversity across the models, we identify samples with higher probabilities for overfitting and use them as the anchor points for augmentation. Leveraging RL, our method adaptively transforms the overfit-prone samples into new data that not only enhances training set diversity but also directs the augmented data to target regions where the forecasting models are prone to overfitting. We validate the effectiveness of ReAugment across a wide range of base models, showing its advantages in both standard time series forecasting and few-shot learning tasks.","authors":["Haochen Yuan","Yutong Wang","Yihong Chen","Yunbo Wang","Xiaokang Yang"],"url":"https://arxiv.org/abs/2409.06282"}
{"created":"2025-05-22","title":"Diversity-Driven View Subset Selection for Indoor Novel View Synthesis","abstract":"Novel view synthesis of indoor scenes can be achieved by capturing a monocular video sequence of the environment. However, redundant information caused by artificial movements in the input video data reduces the efficiency of scene modeling. To address this, we formulate the problem as a combinatorial optimization task for view subset selection. In this work, we propose a novel subset selection framework that integrates a comprehensive diversity-based measurement with well-designed utility functions. We provide a theoretical analysis of these utility functions and validate their effectiveness through extensive experiments. Furthermore, we introduce IndoorTraj, a novel dataset designed for indoor novel view synthesis, featuring complex and extended trajectories that simulate intricate human behaviors. Experiments on IndoorTraj show that our framework consistently outperforms baseline strategies while using only 5-20% of the data, highlighting its remarkable efficiency and effectiveness. The code is available at: https://github.com/zehao-wang/IndoorTraj","authors":["Zehao Wang","Han Zhou","Matthew B. Blaschko","Tinne Tuytelaars","Minye Wu"],"url":"https://arxiv.org/abs/2409.07098"}
{"created":"2025-05-22","title":"MiniDrive: More Efficient Vision-Language Models with Multi-Level 2D Features as Text Tokens for Autonomous Driving","abstract":"Vision-language models (VLMs) serve as general-purpose end-to-end models in autonomous driving, performing subtasks such as prediction, planning, and perception through question-and-answer interactions. However, most existing methods rely on computationally expensive visual encoders and large language models (LLMs), making them difficult to deploy in real-world scenarios and real-time applications. Meanwhile, most existing VLMs lack the ability to process multiple images, making it difficult to adapt to multi-camera perception in autonomous driving. To address these issues, we propose a novel framework called MiniDrive, which incorporates our proposed Feature Engineering Mixture of Experts (FE-MoE) module and Dynamic Instruction Adapter (DI-Adapter). The FE-MoE effectively maps 2D features into visual token embeddings before being input into the language model. The DI-Adapter enables the visual token embeddings to dynamically change with the instruction text embeddings, resolving the issue of static visual token embeddings for the same image in previous approaches. Compared to previous works, MiniDrive achieves state-of-the-art performance in terms of parameter size, floating point operations, and response efficiency, with the smallest version containing only 83M parameters.","authors":["Enming Zhang","Xingyuan Dai","Min Huang","Yisheng Lv","Qinghai Miao"],"url":"https://arxiv.org/abs/2409.07267"}
{"created":"2025-05-22","title":"FaVoR: Features via Voxel Rendering for Camera Relocalization","abstract":"Camera relocalization methods range from dense image alignment to direct camera pose regression from a query image. Among these, sparse feature matching stands out as an efficient, versatile, and generally lightweight approach with numerous applications. However, feature-based methods often struggle with significant viewpoint and appearance changes, leading to matching failures and inaccurate pose estimates. To overcome this limitation, we propose a novel approach that leverages a globally sparse yet locally dense 3D representation of 2D features. By tracking and triangulating landmarks over a sequence of frames, we construct a sparse voxel map optimized to render image patch descriptors observed during tracking. Given an initial pose estimate, we first synthesize descriptors from the voxels using volumetric rendering and then perform feature matching to estimate the camera pose. This methodology enables the generation of descriptors for unseen views, enhancing robustness to view changes. We extensively evaluate our method on the 7-Scenes and Cambridge Landmarks datasets. Our results show that our method significantly outperforms existing state-of-the-art feature representation techniques in indoor environments, achieving up to a 39% improvement in median translation error. Additionally, our approach yields comparable results to other methods for outdoor scenarios while maintaining lower memory and computational costs.","authors":["Vincenzo Polizzi","Marco Cannici","Davide Scaramuzza","Jonathan Kelly"],"url":"https://arxiv.org/abs/2409.07571"}
{"created":"2025-05-22","title":"Fine-tuning Large Language Models for Entity Matching","abstract":"Generative large language models (LLMs) are a promising alternative to pre-trained language models for entity matching due to their high zero-shot performance and ability to generalize to unseen entities. Existing research on using LLMs for entity matching has focused on prompt engineering and in-context learning. This paper explores the potential of fine-tuning LLMs for entity matching. We analyze fine-tuning along two dimensions: 1) the representation of training examples, where we experiment with adding different types of LLM-generated explanations to the training set, and 2) the selection and generation of training examples using LLMs. In addition to the matching performance on the source dataset, we investigate how fine-tuning affects the models ability to generalize to other in-domain datasets as well as across topical domains. Our experiments show that fine-tuning significantly improves the performance of the smaller models while the results for the larger models are mixed. Fine-tuning also improves the generalization to in-domain datasets while hurting cross-domain transfer. We show that adding structured explanations to the training set has a positive impact on the performance of three out of four LLMs, while the proposed example selection and generation methods, only improve the performance of Llama 3.1 8B while decreasing the performance of GPT-4o-mini.","authors":["Aaron Steiner","Ralph Peeters","Christian Bizer"],"url":"https://arxiv.org/abs/2409.08185"}
{"created":"2025-05-22","title":"Learning-Enabled Iterative Convex Optimization for Safety-Critical Model Predictive Control","abstract":"Safety remains a central challenge in control of dynamical systems, particularly when the boundaries of unsafe sets are complex or unknown. This paper proposes a learning-enabled framework for safety-critical Model Predictive Control (MPC) that integrates Discrete-Time High-Order Control Barrier Functions (DHOCBFs) with iterative convex optimization. Unlike existing methods that primarily address CBFs of relative degree one with fully known unsafe set boundaries, our approach generalizes to arbitrary relative degrees and addresses scenarios where the unsafe set boundaries must be inferred. We extract pixel-based data specifically from unsafe set boundaries and train a neural network to approximate local linearizations of these boundaries. The learned models are incorporated into the linearized DHOCBF constraints at each time step, enabling real-time constraint satisfaction within the MPC framework. An iterative convex optimization procedure is developed to accelerate computation while maintaining formal safety guarantees. The benefits of computational performance and safe avoidance of obstacles with diverse shapes are examined and confirmed through numerical results. By bridging model-based control with learning-based environment modeling, this framework advances safe autonomy for discrete-time systems operating in complex and partially known settings.","authors":["Shuo Liu","Zhe Huang","Jun Zeng","Koushil Sreenath","Calin A. Belta"],"url":"https://arxiv.org/abs/2409.08300"}
{"created":"2025-05-22","title":"SPRMamba: Surgical Phase Recognition for Endoscopic Submucosal Dissection with Mamba","abstract":"Endoscopic Submucosal Dissection (ESD) is a minimally invasive procedure initially developed for early gastric cancer treatment and has expanded to address diverse gastrointestinal lesions. While computer-assisted surgery (CAS) systems enhance ESD precision and safety, their efficacy hinges on accurate real-time surgical phase recognition, a task complicated by ESD's inherent complexity, including heterogeneous lesion characteristics and dynamic tissue interactions. Existing video-based phase recognition algorithms, constrained by inefficient temporal context modeling, exhibit limited performance in capturing fine-grained phase transitions and long-range dependencies. To overcome these limitations, we propose SPRMamba, a novel framework integrating a Mamba-based architecture with a Scaled Residual TranMamba (SRTM) block to synergize long-term temporal modeling and localized detail extraction. SPRMamba further introduces the Hierarchical Sampling Strategy to optimize computational efficiency, enabling real-time processing critical for clinical deployment. Evaluated on the ESD385 dataset and the cholecystectomy benchmark Cholec80, SPRMamba achieves state-of-the-art performance (87.64% accuracy on ESD385, +1.0% over prior methods), demonstrating robust generalizability across surgical workflows. This advancement bridges the gap between computational efficiency and temporal sensitivity, offering a transformative tool for intraoperative guidance and skill assessment in ESD surgery. The code is accessible at https://github.com/Zxnyyyyy/SPRMamba.","authors":["Xiangning Zhang","Qingwei Zhang","Jinnan Chen","Chengfeng Zhou","Yaqi Wang","Zhengjie Zhang","Xiaobo Li","Dahong Qian"],"url":"https://arxiv.org/abs/2409.12108"}
{"created":"2025-05-22","title":"An average case efficient algorithm for solving two-variable linear Diophantine equations","abstract":"Solving two-variable linear Diophantine equations has application in many cryptographic protocols such as RSA and Elliptic curve cryptography. The Extended Euclid's algorithm is the most widely used algorithm to solve these equations. We revisit two algorithms to solve two-variable linear Diophantine equations. We write the iterative version of one of the revisited algorithms. For another, we do a fine-grained analysis of the number of recursive calls and arrive at a periodic function that represents the number of recursive calls. We find the period and use it to derive an accurate closed-form expression for the average number of recursive calls incurred by that algorithm. We find multiple loose upper bounds on the average number of recursive calls in different cases based on whether a solution exists or not. If for a fixed value of $a,b$ and a varying $c$, an equation $ax+by=c$ (where $a>b$) is solvable, then we can find the solution in $O\\left(\\frac{\\log b}{gcd(a,b)}\\right)$ average number of recursion or steps. We computationally evaluate this bound as well as one more upper bound and compare them with the average number of recursive calls in Extended Euclid's algorithm on a number of random $ n$-bit inputs. We observe that the average number of iterations in the analyzed algorithm decreases with an increase in $gcd(a,b)$. We propose an iterative version of the algorithm. We implement this algorithm and find that the average number of iterations by our algorithm is less than that of two existing algorithms.","authors":["Mayank Deora","Pinakpani Pal"],"url":"https://arxiv.org/abs/2409.14052"}
{"created":"2025-05-22","title":"MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models","abstract":"Multimodal Large Language Models (MLLMs) have tremendous potential to improve the accuracy, availability, and cost-effectiveness of healthcare by providing automated solutions or serving as aids to medical professionals. Despite promising first steps in developing medical MLLMs in the past few years, their capabilities and limitations are not well-understood. Recently, many benchmark datasets have been proposed that test the general medical knowledge of such models across a variety of medical areas. However, the systematic failure modes and vulnerabilities of such models are severely underexplored with most medical benchmarks failing to expose the shortcomings of existing models in this safety-critical domain. In this paper, we introduce MediConfusion, a challenging medical Visual Question Answering (VQA) benchmark dataset, that probes the failure modes of medical MLLMs from a vision perspective. We reveal that state-of-the-art models are easily confused by image pairs that are otherwise visually dissimilar and clearly distinct for medical experts. Strikingly, all available models (open-source or proprietary) achieve performance below random guessing on MediConfusion, raising serious concerns about the reliability of existing medical MLLMs for healthcare deployment. We also extract common patterns of model failure that may help the design of a new generation of more trustworthy and reliable MLLMs in healthcare.","authors":["Mohammad Shahab Sepehri","Zalan Fabian","Maryam Soltanolkotabi","Mahdi Soltanolkotabi"],"url":"https://arxiv.org/abs/2409.15477"}
{"created":"2025-05-22","title":"DualLQR: Efficient Grasping of Oscillating Apples using Task Parameterized Learning from Demonstration","abstract":"Learning from Demonstration offers great potential for robots to learn to perform agricultural tasks, specifically selective harvesting. One of the challenges is that the target fruit can be oscillating while approaching. Grasping oscillating targets has two requirements: 1) close tracking of the target during the final approach for damage-free grasping, and 2) the complete path should be as short as possible for improved efficiency. We propose a new method called DualLQR. In this method, we use a finite horizon Linear Quadratic Regulator (LQR) on a moving target, without the need of refitting the LQR. To make this possible, we use a dual LQR set-up, with an LQR running in two separate reference frames. Through extensive simulation testing, it was found that the state-of-art method barely meets the required final accuracy without oscillations and drops below the required accuracy with an oscillating target. DualLQR, on the other hand, was found to be able to meet the required final accuracy even with high oscillations, while travelling the least distance. Further testing on a real-world apple grasping task showed that DualLQR was able to successfully grasp oscillating apples, with a success rate of 99%.","authors":["Robert van de Ven","Ard Nieuwenhuizen","Eldert J. van Henten","Gert Kootstra"],"url":"https://arxiv.org/abs/2409.16957"}
{"created":"2025-05-22","title":"Energy-Efficient Computation with DVFS using Deep Reinforcement Learning for Multi-Task Systems in Edge Computing","abstract":"Finding an optimal energy-efficient policy that is adaptable to underlying edge devices while meeting deadlines for tasks has always been challenging. This research studies generalized systems with multi-task, multi-deadline scenarios with reinforcement learning-based DVFS for energy saving for periodic soft real-time applications on edge devices. This work addresses the limitation of previous work that models a periodic system as a single task and single-deadline scenario, which is too simplified to cope with complex situations. The method encodes time series data in the Linux kernel into information that is easy to interpret for reinforcement learning, allowing the system to generate DVFS policies to adapt system patterns based on the general workload. For encoding, we present two different methods for comparison. Both methods use only one performance counter: system utilization, and the kernel only needs minimal information from the userspace. Our method is implemented on Jetson Nano Board (2GB) and is tested with three fixed multitask workloads, which are three, five, and eight tasks in the workload, respectively. For randomness and generalization, we also designed a random workload generator to build different multitask workloads to test. Based on the test results, our method could save 3%-10% power compared to Linux built-in governors.","authors":["Xinyi Li","Ti Zhou","Haoyu Wang","Man Lin"],"url":"https://arxiv.org/abs/2409.19434"}
{"created":"2025-05-22","title":"Symmetry-Robust 3D Orientation Estimation","abstract":"Orientation estimation is a fundamental task in 3D shape analysis which consists of estimating a shape's orientation axes: its side-, up-, and front-axes. Using this data, one can rotate a shape into canonical orientation, where its orientation axes are aligned with the coordinate axes. Developing an orientation algorithm that reliably estimates complete orientations of general shapes remains an open problem. We introduce a two-stage orientation pipeline that achieves state of the art performance on up-axis estimation and further demonstrate its efficacy on full-orientation estimation, where one seeks all three orientation axes. Unlike previous work, we train and evaluate our method on all of Shapenet rather than a subset of classes. We motivate our engineering contributions by theory describing fundamental obstacles to orientation estimation for rotationally-symmetric shapes, and show how our method avoids these obstacles.","authors":["Christopher Scarvelis","David Benhaim","Paul Zhang"],"url":"https://arxiv.org/abs/2410.02101"}
{"created":"2025-05-22","title":"BiSSL: Enhancing the Alignment Between Self-Supervised Pretraining and Downstream Fine-Tuning via Bilevel Optimization","abstract":"Models initialized from self-supervised pretraining may suffer from poor alignment with downstream tasks, reducing the extent to which subsequent fine-tuning can adapt pretrained features toward downstream objectives. To mitigate this, we introduce BiSSL, a novel bilevel training framework that enhances the alignment of self-supervised pretrained models with downstream tasks prior to fine-tuning. BiSSL acts as an intermediate training stage conducted after conventional self-supervised pretraining and is tasked with solving a bilevel optimization problem that incorporates the pretext and downstream training objectives in its lower- and upper-level objectives, respectively. This approach explicitly models the interdependence between the pretraining and fine-tuning stages within the conventional self-supervised learning pipeline, facilitating enhanced information sharing between them that ultimately leads to a model initialization better aligned with the downstream task. We propose a general training algorithm for BiSSL that is compatible with a broad range of pretext and downstream tasks. Using SimCLR and Bootstrap Your Own Latent to pretrain ResNet-50 backbones on the ImageNet dataset, we demonstrate that our proposed framework significantly improves accuracy on the vast majority of 12 downstream image classification datasets, as well as on object detection. Exploratory analyses alongside investigative experiments further provide compelling evidence that BiSSL enhances downstream alignment.","authors":["Gustav Wagner Zakarias","Lars Kai Hansen","Zheng-Hua Tan"],"url":"https://arxiv.org/abs/2410.02387"}
{"created":"2025-05-22","title":"Optimizing Adaptive Attacks against Watermarks for Language Models","abstract":"Large Language Models (LLMs) can be misused to spread unwanted content at scale. Content watermarking deters misuse by hiding messages in content, enabling its detection using a secret watermarking key. Robustness is a core security property, stating that evading detection requires (significant) degradation of the content's quality. Many LLM watermarking methods have been proposed, but robustness is tested only against non-adaptive attackers who lack knowledge of the watermarking method and can find only suboptimal attacks. We formulate watermark robustness as an objective function and use preference-based optimization to tune adaptive attacks against the specific watermarking method. Our evaluation shows that (i) adaptive attacks evade detection against all surveyed watermarks, (ii) training against any watermark succeeds in evading unseen watermarks, and (iii) optimization-based attacks are cost-effective. Our findings underscore the need to test robustness against adaptively tuned attacks. We release our adaptively optimized paraphrasers at https://github.com/nilslukas/ada-wm-evasion.","authors":["Abdulrahman Diaa","Toluwani Aremu","Nils Lukas"],"url":"https://arxiv.org/abs/2410.02440"}
{"created":"2025-05-22","title":"FedGraph: A Research Library and Benchmark for Federated Graph Learning","abstract":"Federated graph learning is an emerging field with significant practical challenges. While algorithms have been proposed to improve the accuracy of training graph neural networks, such as node classification on federated graphs, the system performance is often overlooked, despite it is crucial for real-world deployment. To bridge this gap, we introduce FedGraph, a research library designed for practical distributed training and comprehensive benchmarking of FGL algorithms. FedGraph supports a range of state-of-the-art graph learning methods and includes a monitoring class that evaluates system performance, with a particular focus on communication and computation costs during training. Unlike existing federated learning platforms, FedGraph natively integrates homomorphic encryption to enhance privacy preservation and supports scalable deployment across multiple physical machines with system-level performance evaluation to guide the system design of future algorithms. To enhance efficiency and privacy, we propose a low-rank communication scheme for algorithms like FedGCN that require pre-training communication, accelerating both the pre-training and training phases. Extensive experiments benchmark different FGL algorithms on three major graph learning tasks and demonstrate FedGraph as the first efficient FGL framework to support encrypted low-rank communication and scale to graphs with 100 million nodes.","authors":["Yuhang Yao","Yuan Li","Xinyi Fan","Junhao Li","Kay Liu","Weizhao Jin","Yu Yang","Srivatsan Ravi","Philip S. Yu","Carlee Joe-Wong"],"url":"https://arxiv.org/abs/2410.06340"}
{"created":"2025-05-22","title":"Quantifying Feature Space Universality Across Large Language Models via Sparse Autoencoders","abstract":"The Universality Hypothesis in large language models (LLMs) claims that different models converge towards similar concept representations in their latent spaces. Providing evidence for this hypothesis would enable researchers to exploit universal properties, facilitating the generalization of mechanistic interpretability techniques across models. Previous works studied if LLMs learned the same features, which are internal representations that activate on specific concepts. Since comparing features across LLMs is challenging due to polysemanticity, in which LLM neurons often correspond to multiple unrelated features rather than to distinct concepts, sparse autoencoders (SAEs) have been employed to disentangle LLM neurons into SAE features corresponding to distinct concepts. In this paper, we introduce a new variation of the universality hypothesis called Analogous Feature Universality: we hypothesize that even if SAEs across different models learn different feature representations, the spaces spanned by SAE features are similar, such that one SAE space is similar to another SAE space under rotation-invariant transformations. Evidence for this hypothesis would imply that interpretability techniques related to latent spaces, such as steering vectors, may be transferred across models via certain transformations. To investigate this hypothesis, we first pair SAE features across different models via activation correlation, and then measure spatial relation similarities between paired features via representational similarity measures, which transform spaces into representations that reveal hidden relational similarities. Our experiments demonstrate high similarities for SAE feature spaces across various LLMs, providing evidence for feature space universality.","authors":["Michael Lan","Philip Torr","Austin Meek","Ashkan Khakzar","David Krueger","Fazl Barez"],"url":"https://arxiv.org/abs/2410.06981"}
{"created":"2025-05-22","title":"Parameter Efficient Fine-tuning via Explained Variance Adaptation","abstract":"Foundation models (FMs) are pre-trained on large-scale datasets and then fine-tuned for a specific downstream task. The most common fine-tuning method is to update pretrained weights via low-rank adaptation (LoRA). Existing initialization strategies for LoRA often rely on singular value decompositions (SVD) of gradients or weight matrices. However, they do not provably maximize the expected gradient signal, which is critical for fast adaptation. To this end, we introduce Explained Variance Adaptation (EVA), an initialization scheme that uses the directions capturing the most activation variance, provably maximizing the expected gradient signal and accelerating fine-tuning. EVA performs incremental SVD on minibatches of activation vectors and selects the right-singular vectors for initialization once they converged. Further, by selecting the directions that capture the most activation-variance for a given rank budget, EVA accommodates adaptive ranks that reduce the number of trainable parameters, while maintaining or improving downstream performance. We apply EVA to a variety of fine-tuning tasks as language generation and understanding, image classification, and reinforcement learning. EVA exhibits faster convergence than competitors and achieves the highest average score across a multitude of tasks per domain while reducing the number of trainable parameters through rank redistribution.","authors":["Fabian Paischer","Lukas Hauzenberger","Thomas Schmied","Benedikt Alkin","Marc Peter Deisenroth","Sepp Hochreiter"],"url":"https://arxiv.org/abs/2410.07170"}
{"created":"2025-05-22","title":"Examining the Prevalence and Dynamics of AI-Generated Media in Art Subreddits","abstract":"Broadly accessible generative AI models like Dall-E have made it possible for anyone to create compelling visual art. In online communities, the introduction of AI-generated content (AIGC) may impact social dynamics, for example causing changes in who is posting content, or shifting the norms or the discussions around the posted content if posts are suspected of being generated by AI. We take steps towards examining the potential impact of AIGC on art-related communities on Reddit. We distinguish between communities that disallow AI content and those without such a direct policy. We look at image-based posts in these communities where the author transparently shares that the image was created by AI, and at comments in these communities that suspect or accuse authors of using generative AI. We find that AI posts (and accusations) have played a surprisingly small part in these communities through the end of 2023, accounting for fewer than 0.5% of the image-based posts. However, even as the absolute number of author-labeled AI posts dwindles over time, accusations of AI use remain more persistent. We show that AI content is more readily used by newcomers and may help increase participation if it aligns with community rules. However, the tone of comments suspecting AI use by others has become more negative over time, especially in communities that do not have explicit rules about AI. Overall, the results show the changing norms and interactions around AIGC in online communities designated for creativity.","authors":["Hana Matatov","Marianne Aubin Le Qu\\'er\\'e","Ofra Amir","Mor Naaman"],"url":"https://arxiv.org/abs/2410.07302"}
{"created":"2025-05-22","title":"SeMv-3D: Towards Concurrency of Semantic and Multi-view Consistency in General Text-to-3D Generation","abstract":"General Text-to-3D (GT23D) generation is crucial for creating diverse 3D content across objects and scenes, yet it faces two key challenges: 1) ensuring semantic consistency between input text and generated 3D models, and 2) maintaining multi-view consistency across different perspectives within 3D. Existing approaches typically address only one of these challenges, often leading to suboptimal results in semantic fidelity and structural coherence. To overcome these limitations, we propose SeMv-3D, a novel framework that jointly enhances semantic alignment and multi-view consistency in GT23D generation. At its core, we introduce Triplane Prior Learning (TPL), which effectively learns triplane priors by capturing spatial correspondences across three orthogonal planes using a dedicated Orthogonal Attention mechanism, thereby ensuring geometric consistency across viewpoints. Additionally, we present Prior-based Semantic Aligning in Triplanes (SAT), which enables consistent any-view synthesis by leveraging attention-based feature alignment to reinforce the correspondence between textual semantics and triplane representations. Extensive experiments demonstrate that our method sets a new state-of-the-art in multi-view consistency, while maintaining competitive performance in semantic consistency compared to methods focused solely on semantic alignment. These results emphasize the remarkable ability of our approach to effectively balance and excel in both dimensions, establishing a new benchmark in the field.","authors":["Xiao Cai","Pengpeng Zeng","Lianli Gao","Sitong Su","Heng Tao Shen","Jingkuan Song"],"url":"https://arxiv.org/abs/2410.07658"}
{"created":"2025-05-22","title":"A Closer Look at Machine Unlearning for Large Language Models","abstract":"Large language models (LLMs) may memorize sensitive or copyrighted content, raising privacy and legal concerns. Due to the high cost of retraining from scratch, researchers attempt to employ machine unlearning to remove specific content from LLMs while preserving the overall performance. In this paper, we discuss several issues in machine unlearning for LLMs and provide our insights on possible approaches. To address the issue of inadequate evaluation of model outputs after unlearning, we introduce three additional metrics to evaluate token diversity, sentence semantics, and factual correctness. We then categorize unlearning methods into untargeted and targeted, and discuss their issues respectively. Specifically, the behavior that untargeted unlearning attempts to approximate is unpredictable and may involve hallucinations, and existing regularization is insufficient for targeted unlearning. To alleviate these issues, we propose using the objective of maximizing entropy (ME) for untargeted unlearning and incorporate answer preservation (AP) loss as regularization for targeted unlearning. Experimental results across three scenarios, i.e., fictitious unlearning, continual unlearning, and real-world unlearning, demonstrate the effectiveness of our approaches. The code is available at https://github.com/sail-sg/closer-look-LLM-unlearning.","authors":["Xiaojian Yuan","Tianyu Pang","Chao Du","Kejiang Chen","Weiming Zhang","Min Lin"],"url":"https://arxiv.org/abs/2410.08109"}
{"created":"2025-05-22","title":"Two-person Positive Shortest Path Games Have Nash Equilibria in Pure Stationary Strategies","abstract":"We prove that every finite two-person shortest path game, where the local cost of every move is positive for each player, has a Nash equilibrium (NE) in pure stationary strategies, which can be computed in polynomial time. We also extend the existence result to infinite graphs with finite out-degrees. Moreover, our proof gives that a terminal NE (in which the play is a path from the initial position to a terminal) exists provided at least one of the two players can guarantee reaching a terminal. If none of the players can do it, in other words, if each of the two players has a strategy that separates all terminals from the initial position $s$, then, obviously, a cyclic NE exists, although its cost is infinite for both players, since we restrict ourselves to positive games. We conjecture that a terminal NE exists too, provided there exists a directed path from $s$ to a terminal. However, this is open.","authors":["Endre Boros","Khaled Elbassioni","Vladimir Gurvich","Mikhail Vyalyi"],"url":"https://arxiv.org/abs/2410.09257"}
{"created":"2025-05-22","title":"Efficient Partitioning Vision Transformer on Edge Devices for Distributed Inference","abstract":"Deep learning models are increasingly utilized on resource-constrained edge devices for real-time data analytics. Recently, Vision Transformer and their variants have shown exceptional performance in various computer vision tasks. However, their substantial computational requirements and low inference latency create significant challenges for deploying such models on resource-constrained edge devices. To address this issue, we propose a novel framework, ED-ViT, which is designed to efficiently split and execute complex Vision Transformers across multiple edge devices. Our approach involves partitioning Vision Transformer models into several sub-models, while each dedicated to handling a specific subset of data classes. To further reduce computational overhead and inference latency, we introduce a class-wise pruning technique that decreases the size of each sub-model. Through extensive experiments conducted on five datasets using three model architectures and actual implementation on edge devices, we demonstrate that our method significantly cuts down inference latency on edge devices and achieves a reduction in model size by up to 28.9 times and 34.1 times, respectively, while maintaining test accuracy comparable to the original Vision Transformer. Additionally, we compare ED-ViT with two state-of-the-art methods that deploy CNN and SNN models on edge devices, evaluating metrics such as accuracy, inference time, and overall model size. Our comprehensive evaluation underscores the effectiveness of the proposed ED-ViT framework.","authors":["Xiang Liu","Yijun Song","Xia Li","Yifei Sun","Huiying Lan","Zemin Liu","Linshan Jiang","Jialin Li"],"url":"https://arxiv.org/abs/2410.11650"}
{"created":"2025-05-22","title":"TinyClick: Single-Turn Agent for Empowering GUI Automation","abstract":"We present an UI agent for user interface (UI) interaction tasks, using Vision-Language Model Florence-2-Base. The agent's primary task is identifying the screen coordinates of the UI element corresponding to the user's command. It demonstrates very strong performance on Screenspot and OmniAct annotations, while maintaining a very small size of 0.27B parameters and minimal latency. Moreover, training needs small compute budget of 56 GPU-hours (worth about 40 USD). Relevant improvement comes from vision-specific multi-task training and MLLM-based data augmentation. We hope that decreased needs for expensive compute resources and manually annotated data will allow to facilitate more inclusive and sustainable research of UI agents.","authors":["Pawel Pawlowski","Krystian Zawistowski","Wojciech Lapacz","Adam Wiacek","Marcin Skorupa","Sebastien Postansque","Jakub Hoscilowicz"],"url":"https://arxiv.org/abs/2410.11871"}
{"created":"2025-05-22","title":"Meta-Chunking: Learning Text Segmentation and Semantic Completion via Logical Perception","abstract":"While Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm for boosting large language models (LLMs) in knowledge-intensive tasks, it often overlooks the crucial aspect of text chunking within its workflow. This paper proposes the Meta-Chunking framework, which specifically enhances chunking quality through a dual strategy that identifies optimal segmentation points and preserves global information. Initially, breaking limitations of similarity-based chunking, we design two adaptive chunking techniques based on uncertainty, namely Perplexity Chunking and Margin Sampling Chunking, by utilizing the logical perception capabilities of LLMs. Given the inherent complexity across different texts, we integrate meta-chunk with dynamic merging, striking a balance between fine-grained and coarse-grained text chunking. Furthermore, we establish the global information compensation mechanism, encompassing a two-stage hierarchical summary generation process and a three-stage text chunk rewriting procedure focused on missing reflection, refinement, and completion. These components collectively strengthen the semantic integrity and contextual coherence of chunks. Extensive experiments demonstrate that Meta-Chunking effectively addresses challenges of the chunking task within the RAG system, providing LLMs with more logically coherent text chunks. Additionally, our methodology validates the feasibility of implementing high-quality chunking tasks with smaller-scale models, thereby eliminating the reliance on robust instruction-following capabilities.","authors":["Jihao Zhao","Zhiyuan Ji","Yuchen Feng","Pengnian Qi","Simin Niu","Bo Tang","Feiyu Xiong","Zhiyu Li"],"url":"https://arxiv.org/abs/2410.12788"}
{"created":"2025-05-22","title":"MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models","abstract":"Text-to-image diffusion models can generate high-quality images but lack fine-grained control of visual concepts, limiting their creativity. Thus, we introduce component-controllable personalization, a new task that enables users to customize and reconfigure individual components within concepts. This task faces two challenges: semantic pollution, where undesired elements disrupt the target concept, and semantic imbalance, which causes disproportionate learning of the target concept and component. To address these, we design MagicTailor, a framework that uses Dynamic Masked Degradation to adaptively perturb unwanted visual semantics and Dual-Stream Balancing for more balanced learning of desired visual semantics. The experimental results show that MagicTailor achieves superior performance in this task and enables more personalized and creative image generation.","authors":["Donghao Zhou","Jiancheng Huang","Jinbin Bai","Jiaze Wang","Hao Chen","Guangyong Chen","Xiaowei Hu","Pheng-Ann Heng"],"url":"https://arxiv.org/abs/2410.13370"}
{"created":"2025-05-22","title":"Retrospective Learning from Interactions","abstract":"Multi-turn interactions between large language models (LLMs) and users naturally include implicit feedback signals. If an LLM responds in an unexpected way to an instruction, the user is likely to signal it by rephrasing the request, expressing frustration, or pivoting to an alternative task. Such signals are task-independent and occupy a relatively constrained subspace of language, allowing the LLM to identify them even if it fails on the actual task. We introduce ReSpect, a method to learn from such signals in past interactions via retrospection without additional annotations. We deploy ReSpect in a new multimodal interaction scenario, where humans instruct a multimodal LLM to solve an abstract reasoning task with a combinatorial solution space. Through thousands of interactions with humans, we show how ReSpect gradually improves task completion rate from 31% to 82%, all without any external annotation.","authors":["Zizhao Chen","Mustafa Omer Gul","Yiwei Chen","Gloria Geng","Anne Wu","Yoav Artzi"],"url":"https://arxiv.org/abs/2410.13852"}
{"created":"2025-05-22","title":"GATEAU: Selecting Influential Samples for Long Context Alignment","abstract":"Aligning large language models to handle instructions with extremely long contexts has yet to be fully investigated. Previous studies have attempted to scale up the available data volume by synthesizing long instruction-following samples, as constructing such a dataset tends to be challenging for annotators. However, a lack of a well-defined strategy for ensuring data quality may introduce low-quality samples and restrict the model's performance. Thus, we propose GATEAU, a novel framework to address the unique challenge of long context alignment by identifying the influential samples enriched with long-range dependency relations. Specifically, GATEAU measures the long-range dependencies from two essential aspects: the difficulty of generating target responses due to the long-range dependencies, and the difficulty of understanding long inputs due to such dependencies. Comprehensive experiments indicate that GATEAU effectively identifies influential samples and the model trained on these selected samples exhibits better instruction-following and long-context understanding capabilities.","authors":["Shuzheng Si","Haozhe Zhao","Gang Chen","Yunshui Li","Kangyang Luo","Chuancheng Lv","Kaikai An","Fanchao Qi","Baobao Chang","Maosong Sun"],"url":"https://arxiv.org/abs/2410.15633"}
{"created":"2025-05-22","title":"Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models","abstract":"Large Language Models (LLMs) demonstrate exceptional capabilities in a multitude of NLP tasks. However, the efficacy of such models to languages other than English is often limited. Prior works have shown that encoder-only models such as BERT or XLM-RoBERTa show impressive cross lingual transfer of their capabilities from English to other languages. In this work, we propose a pretraining strategy that uses active forgetting to achieve similar cross lingual transfer in decoder-only LLMs. We show that LLMs pretrained with active forgetting are highly effective when adapting to new and unseen languages. Through extensive experimentation, we find that LLMs pretrained with active forgetting are able to learn better multilingual representations which translates to better performance in many downstream tasks.","authors":["Divyanshu Aggarwal","Ashutosh Sathe","Sunayana Sitaram"],"url":"https://arxiv.org/abs/2410.16168"}
{"created":"2025-05-22","title":"Robust and Minimally Invasive Watermarking for EaaS","abstract":"Embeddings as a Service (EaaS) is emerging as a crucial role in AI applications. Unfortunately, EaaS is vulnerable to model extraction attacks, highlighting the urgent need for copyright protection. Although some preliminary works propose applying embedding watermarks to protect EaaS, recent research reveals that these watermarks can be easily removed. Hence, it is crucial to inject robust watermarks resistant to watermark removal attacks. Existing watermarking methods typically inject a target embedding into embeddings through linear interpolation when the text contains triggers. However, this mechanism results in each watermarked embedding having the same component, which makes the watermark easy to identify and eliminate. Motivated by this, in this paper, we propose a novel embedding-specific watermarking (ESpeW) mechanism to offer robust copyright protection for EaaS. Our approach involves injecting unique, yet readily identifiable watermarks into each embedding. Watermarks inserted by ESpeW are designed to maintain a significant distance from one another and to avoid sharing common components, thus making it significantly more challenging to remove the watermarks. Moreover, ESpeW is minimally invasive, as it reduces the impact on embeddings to less than 1\\%, setting a new milestone in watermarking for EaaS. Extensive experiments on four popular datasets demonstrate that ESpeW can even watermark successfully against a highly aggressive removal strategy without sacrificing the quality of embeddings.","authors":["Zongqi Wang","Baoyuan Wu","Jingyuan Deng","Yujiu Yang"],"url":"https://arxiv.org/abs/2410.17552"}
{"created":"2025-05-22","title":"Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models","abstract":"While Chain of Thought (CoT) prompting approaches have significantly consolidated the reasoning capabilities of large language models (LLMs), they still face limitations that require extensive human effort or have performance needs to be improved. Existing endeavors have focused on bridging these gaps; however, these approaches either hinge on external data and cannot completely eliminate manual effort, or they fall short in effectively directing LLMs to generate high-quality exemplary prompts. To address the said pitfalls, we propose a novel prompt approach for automatic reasoning named \\textbf{LBS3}, inspired by curriculum learning which better reflects human learning habits. Specifically, LBS3 initially steers LLMs to recall easy-to-hard proxy queries that are pertinent to the target query. Following this, it invokes a progressive strategy that utilizes exemplary prompts stemmed from easy-proxy queries to direct LLMs in solving hard-proxy queries, enabling the high-quality of the proxy solutions. Finally, our extensive experiments in various reasoning-intensive tasks with varying open- and closed-source LLMs show that LBS3 achieves strongly competitive performance compared to the SOTA baselines.","authors":["Kangyang Luo","Zichen Ding","Zhenmin Weng","Lingfeng Qiao","Meng Zhao","Xiang Li","Di Yin","Jinlong Shu"],"url":"https://arxiv.org/abs/2410.21728"}
{"created":"2025-05-22","title":"Perceptions of Blind Adults on Non-Visual Mobile Text Entry","abstract":"Text input on mobile devices without physical keys can be challenging for people who are blind or low-vision. We interview 12 blind adults about their experiences with current mobile text input to provide insights into what sorts of interface improvements may be the most beneficial. We identify three primary themes that were experiences or opinions shared by participants: the poor accuracy of dictation, difficulty entering text in noisy environments, and difficulty correcting errors in entered text. We also discuss an experimental non-visual text input method with each participant to solicit opinions on the method and probe their willingness to learn a novel method. We find that the largest concern was the time required to learn a new technique. We find that the majority of our participants do not use word predictions while typing but instead find it faster to finish typing words manually. Finally, we distill five future directions for non-visual text input: improved dictation, less reliance on or improved audio feedback, improved error correction, reducing the barrier to entry for new methods, and more fluid non-visual word predictions.","authors":["Dylan Gaines","Keith Vertanen"],"url":"https://arxiv.org/abs/2410.22324"}
{"created":"2025-05-22","title":"RoboCrowd: Scaling Robot Data Collection through Crowdsourcing","abstract":"In recent years, imitation learning from large-scale human demonstrations has emerged as a promising paradigm for training robot policies. However, the burden of collecting large quantities of human demonstrations is significant in terms of collection time and the need for access to expert operators. We introduce a new data collection paradigm, RoboCrowd, which distributes the workload by utilizing crowdsourcing principles and incentive design. RoboCrowd helps enable scalable data collection and facilitates more efficient learning of robot policies. We build RoboCrowd on top of ALOHA (Zhao et al. 2023) -- a bimanual platform that supports data collection via puppeteering -- to explore the design space for crowdsourcing in-person demonstrations in a public environment. We propose three classes of incentive mechanisms to appeal to users' varying sources of motivation for interacting with the system: material rewards, intrinsic interest, and social comparison. We instantiate these incentives through tasks that include physical rewards, engaging or challenging manipulations, as well as gamification elements such as a leaderboard. We conduct a large-scale, two-week field experiment in which the platform is situated in a university cafe. We observe significant engagement with the system -- over 200 individuals independently volunteered to provide a total of over 800 interaction episodes. Our findings validate the proposed incentives as mechanisms for shaping users' data quantity and quality. Further, we demonstrate that the crowdsourced data can serve as useful pre-training data for policies fine-tuned on expert demonstrations -- boosting performance up to 20% compared to when this data is not available. These results suggest the potential for RoboCrowd to reduce the burden of robot data collection by carefully implementing crowdsourcing and incentive design principles.","authors":["Suvir Mirchandani","David D. Yuan","Kaylee Burns","Md Sazzad Islam","Tony Z. Zhao","Chelsea Finn","Dorsa Sadigh"],"url":"https://arxiv.org/abs/2411.01915"}
{"created":"2025-05-22","title":"Local Loss Optimization in the Infinite Width: Stable Parameterization of Predictive Coding Networks and Target Propagation","abstract":"Local learning, which trains a network through layer-wise local targets and losses, has been studied as an alternative to backpropagation (BP) in neural computation. However, its algorithms often become more complex or require additional hyperparameters because of the locality, making it challenging to identify desirable settings in which the algorithm progresses in a stable manner. To provide theoretical and quantitative insights, we introduce the maximal update parameterization ($\\mu$P) in the infinite-width limit for two representative designs of local targets: predictive coding (PC) and target propagation (TP). We verified that $\\mu$P enables hyperparameter transfer across models of different widths. Furthermore, our analysis revealed unique and intriguing properties of $\\mu$P that are not present in conventional BP. By analyzing deep linear networks, we found that PC's gradients interpolate between first-order and Gauss-Newton-like gradients, depending on the parameterization. We demonstrate that, in specific standard settings, PC in the infinite-width limit behaves more similarly to the first-order gradient. For TP, even with the standard scaling of the last layer, which differs from classical $\\mu$P, its local loss optimization favors the feature learning regime over the kernel regime.","authors":["Satoki Ishikawa","Rio Yokota","Ryo Karakida"],"url":"https://arxiv.org/abs/2411.02001"}
{"created":"2025-05-22","title":"Unsupervised detection of semantic correlations in big data","abstract":"In real-world data, information is stored in extremely large feature vectors. These variables are typically correlated due to complex interactions involving many features simultaneously. Such correlations qualitatively correspond to semantic roles and are naturally recognized by both the human brain and artificial neural networks. This recognition enables, for instance, the prediction of missing parts of an image or text based on their context. We present a method to detect these correlations in high-dimensional data represented as binary numbers. We estimate the binary intrinsic dimension of a dataset, which quantifies the minimum number of independent coordinates needed to describe the data, and is therefore a proxy of semantic complexity. The proposed algorithm is largely insensitive to the so-called curse of dimensionality, and can therefore be used in big data analysis. We test this approach identifying phase transitions in model magnetic systems and we then apply it to the detection of semantic correlations of images and text inside deep neural networks.","authors":["Santiago Acevedo","Alex Rodriguez","Alessandro Laio"],"url":"https://arxiv.org/abs/2411.02126"}
{"created":"2025-05-22","title":"Beyond The Rainbow: High Performance Deep Reinforcement Learning on a Desktop PC","abstract":"Rainbow Deep Q-Network (DQN) demonstrated combining multiple independent enhancements could significantly boost a reinforcement learning (RL) agent's performance. In this paper, we present \"Beyond The Rainbow\" (BTR), a novel algorithm that integrates six improvements from across the RL literature to Rainbow DQN, establishing a new state-of-the-art for RL using a desktop PC, with a human-normalized interquartile mean (IQM) of 7.4 on Atari-60. Beyond Atari, we demonstrate BTR's capability to handle complex 3D games, successfully training agents to play Super Mario Galaxy, Mario Kart, and Mortal Kombat with minimal algorithmic changes. Designing BTR with computational efficiency in mind, agents can be trained using a high-end desktop PC on 200 million Atari frames within 12 hours. Additionally, we conduct detailed ablation studies of each component, analyzing the performance and impact using numerous measures. Code is available at https://github.com/VIPTankz/BTR.","authors":["Tyler Clark","Mark Towers","Christine Evers","Jonathon Hare"],"url":"https://arxiv.org/abs/2411.03820"}
{"created":"2025-05-22","title":"Untangling Hate Speech Definitions: A Semantic Componential Analysis Across Cultures and Domains","abstract":"Hate speech relies heavily on cultural influences, leading to varying individual interpretations. For that reason, we propose a Semantic Componential Analysis (SCA) framework for a cross-cultural and cross-domain analysis of hate speech definitions. We create the first dataset of hate speech definitions encompassing 493 definitions from more than 100 cultures, drawn from five key domains: online dictionaries, academic research, Wikipedia, legal texts, and online platforms. By decomposing these definitions into semantic components, our analysis reveals significant variation across definitions, yet many domains borrow definitions from one another without taking into account the target culture. We conduct zero-shot model experiments using our proposed dataset, employing three popular open-sourced LLMs to understand the impact of different definitions on hate speech detection. Our findings indicate that LLMs are sensitive to definitions: responses for hate speech detection change according to the complexity of definitions used in the prompt.","authors":["Katerina Korre","Arianna Muti","Federico Ruggeri","Alberto Barr\\'on-Cede\\~no"],"url":"https://arxiv.org/abs/2411.07417"}
{"created":"2025-05-22","title":"MIRe: Enhancing Multimodal Queries Representation via Fusion-Free Modality Interaction for Multimodal Retrieval","abstract":"Recent multimodal retrieval methods have endowed text-based retrievers with multimodal capabilities by utilizing pre-training strategies for visual-text alignment. They often directly fuse the two modalities for cross-reference during the alignment to understand multimodal queries. However, existing methods often overlook crucial visual information due to a text-dominant issue, which overly depends on text-driven signals. In this paper, we introduce MIRe, a retrieval framework that achieves modality interaction without fusing textual features during the alignment. Our method allows the textual query to attend to visual embeddings while not feeding text-driven signals back into the visual representations. Additionally, we construct a pre-training dataset for multimodal query retrieval by transforming concise question-answer pairs into extended passages. Our experiments demonstrate that our pre-training strategy significantly enhances the understanding of multimodal queries, resulting in strong performance across four multimodal retrieval benchmarks under zero-shot settings. Moreover, our ablation studies and analyses explicitly verify the effectiveness of our framework in mitigating the text-dominant issue. Our code is publicly available: https://github.com/yeongjoonJu/MIRe","authors":["Yeong-Joon Ju","Ho-Joong Kim","Seong-Whan Lee"],"url":"https://arxiv.org/abs/2411.08334"}
{"created":"2025-05-22","title":"M3TR: A Generalist Model for Real-World HD Map Completion","abstract":"Autonomous vehicles rely on HD maps for their operation, but offline HD maps eventually become outdated. For this reason, online HD map construction methods use live sensor data to infer map information instead. Research on real map changes shows that oftentimes entire parts of an HD map remain unchanged and can be used as a prior. We therefore introduce M3TR (Multi-Masking Map Transformer), a generalist approach for HD map completion both with and without offline HD map priors. As a necessary foundation, we address shortcomings in ground truth labels for Argoverse 2 and nuScenes and propose the first comprehensive benchmark for HD map completion. Unlike existing models that specialize in a single kind of map change, which is unrealistic for deployment, our Generalist model handles all kinds of changes, matching the effectiveness of Expert models. With our map masking as augmentation regime, we can even achieve a +1.4 mAP improvement without a prior. Finally, by fully utilizing prior HD map elements and optimizing query designs, M3TR outperforms existing methods by +4.3 mAP while being the first real-world deployable model for offline HD map priors. Code is available at https://github.com/immel-f/m3tr","authors":["Fabian Immel","Richard Fehler","Frank Bieder","Jan-Hendrik Pauls","Christoph Stiller"],"url":"https://arxiv.org/abs/2411.10316"}
{"created":"2025-05-22","title":"FastDraft: How to Train Your Draft","abstract":"Speculative Decoding has gained popularity as an effective technique for accelerating the auto-regressive inference process of Large Language Models. However, Speculative Decoding entirely relies on the availability of efficient draft models, which are often lacking for many existing language models due to a stringent constraint of vocabulary compatibility. In this work we introduce FastDraft, a novel and efficient approach for pre-training and aligning a draft model to any large language model by incorporating efficient pre-training, followed by fine-tuning over synthetic datasets generated by the target model. We demonstrate FastDraft by training two highly parameter efficient drafts for the popular Phi-3-mini and Llama-3.1-8B models. Using FastDraft, we were able to produce a draft model with approximately 10 billion tokens on a single server with 8 Intel$^\\circledR$ Gaudi$^\\circledR$ 2 accelerators in under 24 hours. Our results show that the draft model achieves impressive results in key metrics of acceptance rate, block efficiency and up to 3x memory bound speed up when evaluated on code completion and up to 2x in summarization, text completion and instruction tasks. We validate our theoretical findings through benchmarking on the latest Intel$^\\circledR$ Core$^{\\tiny \\text{TM}}$ Ultra, achieving a wall-clock time speedup of up to 2x, indicating a significant reduction in runtime. Due to its high quality, FastDraft unlocks large language models inference on AI-PC and other edge-devices.","authors":["Ofir Zafrir","Igor Margulis","Dorin Shteyman","Shira Guskin","Guy Boudoukh"],"url":"https://arxiv.org/abs/2411.11055"}
{"created":"2025-05-22","title":"Deep Policy Gradient Methods Without Batch Updates, Target Networks, or Replay Buffers","abstract":"Modern deep policy gradient methods achieve effective performance on simulated robotic tasks, but they all require large replay buffers or expensive batch updates, or both, making them incompatible for real systems with resource-limited computers. We show that these methods fail catastrophically when limited to small replay buffers or during incremental learning, where updates only use the most recent sample without batch updates or a replay buffer. We propose a novel incremental deep policy gradient method -- Action Value Gradient (AVG) and a set of normalization and scaling techniques to address the challenges of instability in incremental learning. On robotic simulation benchmarks, we show that AVG is the only incremental method that learns effectively, often achieving final performance comparable to batch policy gradient methods. This advancement enabled us to show for the first time effective deep reinforcement learning with real robots using only incremental updates, employing a robotic manipulator and a mobile robot.","authors":["Gautham Vasan","Mohamed Elsayed","Alireza Azimi","Jiamin He","Fahim Shariar","Colin Bellinger","Martha White","A. Rupam Mahmood"],"url":"https://arxiv.org/abs/2411.15370"}
{"created":"2025-05-22","title":"Ca2-VDM: Efficient Autoregressive Video Diffusion Model with Causal Generation and Cache Sharing","abstract":"With the advance of diffusion models, today's video generation has achieved impressive quality. To extend the generation length and facilitate real-world applications, a majority of video diffusion models (VDMs) generate videos in an autoregressive manner, i.e., generating subsequent clips conditioned on the last frame(s) of the previous clip. However, existing autoregressive VDMs are highly inefficient and redundant: The model must re-compute all the conditional frames that are overlapped between adjacent clips. This issue is exacerbated when the conditional frames are extended autoregressively to provide the model with long-term context. In such cases, the computational demands increase significantly (i.e., with a quadratic complexity w.r.t. the autoregression step). In this paper, we propose Ca2-VDM, an efficient autoregressive VDM with Causal generation and Cache sharing. For causal generation, it introduces unidirectional feature computation, which ensures that the cache of conditional frames can be precomputed in previous autoregression steps and reused in every subsequent step, eliminating redundant computations. For cache sharing, it shares the cache across all denoising steps to avoid the huge cache storage cost. Extensive experiments demonstrated that our Ca2-VDM achieves state-of-the-art quantitative and qualitative video generation results and significantly improves the generation speed. Code is available: https://github.com/Dawn-LX/CausalCache-VDM","authors":["Kaifeng Gao","Jiaxin Shi","Hanwang Zhang","Chunping Wang","Jun Xiao","Long Chen"],"url":"https://arxiv.org/abs/2411.16375"}
{"created":"2025-05-22","title":"Opt-In Art: Learning Art Styles Only from Few Examples","abstract":"We explore whether pre-training on datasets with paintings is necessary for a model to learn an artistic style with only a few examples. To investigate this, we train a text-to-image model exclusively on photographs, without access to any painting-related content. We show that it is possible to adapt a model that is trained without paintings to an artistic style, given only few examples. User studies and automatic evaluations confirm that our model (post-adaptation) performs on par with state-of-the-art models trained on massive datasets that contain artistic content like paintings, drawings or illustrations. Finally, using data attribution techniques, we analyze how both artistic and non-artistic datasets contribute to generating artistic-style images. Surprisingly, our findings suggest that high-quality artistic outputs can be achieved without prior exposure to artistic data, indicating that artistic style generation can occur in a controlled, opt-in manner using only a limited, carefully selected set of training examples.","authors":["Hui Ren","Joanna Materzynska","Rohit Gandikota","David Bau","Antonio Torralba"],"url":"https://arxiv.org/abs/2412.00176"}
{"created":"2025-05-22","title":"Empowering the Deaf and Hard of Hearing Community: Enhancing Video Captions Using Large Language Models","abstract":"In today's digital age, video content is prevalent, serving as a primary source of information, education, and entertainment. However, the Deaf and Hard of Hearing (DHH) community often faces significant challenges in accessing video content due to the inadequacy of automatic speech recognition (ASR) systems in providing accurate and reliable captions. This paper addresses the urgent need to improve video caption quality by leveraging Large Language Models (LLMs). We present a comprehensive study that explores the integration of LLMs to enhance the accuracy and context-awareness of captions generated by ASR systems. Our methodology involves a novel pipeline that corrects ASR-generated captions using advanced LLMs. It explicitly focuses on models like GPT-3.5 and Llama2-13B due to their robust performance in language comprehension and generation tasks. We introduce a dataset representative of real-world challenges the DHH community faces to evaluate our proposed pipeline. Our results indicate that LLM-enhanced captions significantly improve accuracy, as evidenced by a notably lower Word Error Rate (WER) achieved by ChatGPT-3.5 (WER: 9.75%) compared to the original ASR captions (WER: 23.07%), ChatGPT-3.5 shows an approximate 57.72% improvement in WER compared to the original ASR captions.","authors":["Nadeen Fathallah","Monika Bhole","Steffen Staab"],"url":"https://arxiv.org/abs/2412.00342"}
{"created":"2025-05-22","title":"Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning","abstract":"Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging because the size of the joint state and action spaces grows exponentially in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm $\\texttt{SUBSAMPLE-MFQ}$ ($\\textbf{Subsample}$-$\\textbf{M}$ean-$\\textbf{F}$ield-$\\textbf{Q}$-learning) and a decentralized randomized policy for a system with $n$ agents. For any $k\\leq n$, our algorithm learns a policy for the system in time polynomial in $k$. We prove that this learned policy converges to the optimal policy on the order of $\\tilde{O}(1/\\sqrt{k})$ as the number of subsampled agents $k$ increases. In particular, this bound is independent of the number of agents $n$.","authors":["Emile Anand","Ishani Karmarkar","Guannan Qu"],"url":"https://arxiv.org/abs/2412.00661"}
{"created":"2025-05-22","title":"Randomized algorithms for Kroncecker tensor decomposition and applications","abstract":"This paper proposes fast randomized algorithms for computing the Kronecker Tensor Decomposition (KTD). The proposed algorithms can decompose a given tensor into the KTD format much faster than the existing state-of-the-art algorithms. Our principal idea is to use the randomization framework to reduce computational complexity significantly. We provide extensive simulations to verify the effectiveness and performance of the proposed randomized algorithms with several orders of magnitude acceleration compared to the deterministic one. Our simulations use synthetics and real-world datasets with applications to tensor completion, video/image compression, image denoising, and image super-resolution","authors":["Salman Ahmadi-Asl","Naeim Rezaeian","Andre L. F. de Almeida","Yipeng Liu"],"url":"https://arxiv.org/abs/2412.02597"}
{"created":"2025-05-22","title":"Efficient Algorithms for Low Tubal Rank Tensor Approximation with Applications","abstract":"In this paper we propose efficient randomized fixed-precision techniques for low tubal rank approximation of tensors. The proposed methods are faster and more efficient than the existing fixed-precision algorithms for approximating the truncated tensor SVD (T-SVD). Besides, there are a few works on randomized single-pass algorithms for computing low tubal rank approximation of tensors, none of them experimentally reports the robustness of such algorithms for low-rank approximation of real-world data tensors e.g., images and videos. The current single-pass algorithms for tensors are generalizations of those developed for matrices to tensors. However, the single-pass randomized algorithms for matrices have been recently improved and stabilized. Motivated by this progress, in this paper, we also generalize them to the tensor case based on the tubal product (T-product). We conduct extensive simulations to study the robustness of them compared with the existing single-pass randomized algorithms. In particular, we experimentally found that single-pass algorithms with the sketching parameters of equal sizes usually lead to ill-conditioned tensor least-squares problems and inaccurate results. It is experimentally shown that our proposed single-pass algorithms are robust in this sense. Numerical results demonstrate that under the same conditions (setting the same hyper-parameters), our proposed algorithms provide better performance. Three applications to image compression, super-resolution problem and deep learning are also presented.","authors":["Salman Ahmadi-Asl","Naeim Rezaeian","Cesar F. Caiafa","Andre L. F. de Almeidad"],"url":"https://arxiv.org/abs/2412.02598"}
{"created":"2025-05-22","title":"Volumetrically Consistent 3D Gaussian Rasterization","abstract":"Recently, 3D Gaussian Splatting (3DGS) has enabled photorealistic view synthesis at high inference speeds. However, its splatting-based rendering model makes several approximations to the rendering equation, reducing physical accuracy. We show that the core approximations in splatting are unnecessary, even within a rasterizer; We instead volumetrically integrate 3D Gaussians directly to compute the transmittance across them analytically. We use this analytic transmittance to derive more physically-accurate alpha values than 3DGS, which can directly be used within their framework. The result is a method that more closely follows the volume rendering equation (similar to ray-tracing) while enjoying the speed benefits of rasterization. Our method represents opaque surfaces with higher accuracy and fewer points than 3DGS. This enables it to outperform 3DGS for view synthesis (measured in SSIM and LPIPS). Being volumetrically consistent also enables our method to work out of the box for tomography. We match the state-of-the-art 3DGS-based tomography method with fewer points. Our code is publicly available at: https://github.com/chinmay0301ucsd/Vol3DGS","authors":["Chinmay Talegaonkar","Yash Belhe","Ravi Ramamoorthi","Nicholas Antipa"],"url":"https://arxiv.org/abs/2412.03378"}
{"created":"2025-05-22","title":"MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization","abstract":"The advancement of Large Vision-Language Models (LVLMs) has propelled their application in the medical field. However, Medical LVLMs (Med-LVLMs) encounter factuality challenges due to modality misalignment, where the models prioritize textual knowledge over visual input, leading to hallucinations that contradict information in medical images. Previous attempts to enhance modality alignment in Med-LVLMs through preference optimization have inadequately mitigated clinical relevance in preference data, making these samples easily distinguishable and reducing alignment effectiveness. To address this challenge, we propose MMedPO, a novel multimodal medical preference optimization approach that considers the clinical relevance of preference samples to enhance Med-LVLM alignment. MMedPO curates multimodal preference data by introducing two types of dispreference: (1) plausible hallucinations injected through target Med-LVLMs or GPT-4o to produce medically inaccurate responses, and (2) lesion region neglect achieved through local lesion-noising, disrupting visual understanding of critical areas. We then calculate clinical relevance for each sample based on scores from multiple Med-LLMs and visual tools, and integrate these scores into the preference optimization process as weights, enabling effective alignment. Our experiments demonstrate that MMedPO significantly enhances factual accuracy in Med-LVLMs, achieving substantial improvements over existing preference optimization methods by averaging 14.2% and 51.7% across the Med-VQA and report generation tasks. Our code are available in https://github.com/aiming-lab/MMedPO.","authors":["Kangyu Zhu","Peng Xia","Yun Li","Hongtu Zhu","Sheng Wang","Huaxiu Yao"],"url":"https://arxiv.org/abs/2412.06141"}
{"created":"2025-05-22","title":"EventSplat: 3D Gaussian Splatting from Moving Event Cameras for Real-time Rendering","abstract":"We introduce a method for using event camera data in novel view synthesis via Gaussian Splatting. Event cameras offer exceptional temporal resolution and a high dynamic range. Leveraging these capabilities allows us to effectively address the novel view synthesis challenge in the presence of fast camera motion. For initialization of the optimization process, our approach uses prior knowledge encoded in an event-to-video model. We also use spline interpolation for obtaining high quality poses along the event camera trajectory. This enhances the reconstruction quality from fast-moving cameras while overcoming the computational limitations traditionally associated with event-based Neural Radiance Field (NeRF) methods. Our experimental evaluation demonstrates that our results achieve higher visual fidelity and better performance than existing event-based NeRF approaches while being an order of magnitude faster to render.","authors":["Toshiya Yura","Ashkan Mirzaei","Igor Gilitschenski"],"url":"https://arxiv.org/abs/2412.07293"}
{"created":"2025-05-22","title":"NeSyA: Neurosymbolic Automata","abstract":"Neurosymbolic (NeSy) AI has emerged as a promising direction to integrate neural and symbolic reasoning. Unfortunately, little effort has been given to developing NeSy systems tailored to sequential/temporal problems. We identify symbolic automata (which combine the power of automata for temporal reasoning with that of propositional logic for static reasoning) as a suitable formalism for expressing knowledge in temporal domains. Focusing on the task of sequence classification and tagging we show that symbolic automata can be integrated with neural-based perception, under probabilistic semantics towards an end-to-end differentiable model. Our proposed hybrid model, termed NeSyA (Neuro Symbolic Automata) is shown to either scale or perform more accurately than previous NeSy systems in a synthetic benchmark and to provide benefits in terms of generalization compared to purely neural systems in a real-world event recognition task.","authors":["Nikolaos Manginas","George Paliouras","Luc De Raedt"],"url":"https://arxiv.org/abs/2412.07331"}
{"created":"2025-05-22","title":"Dial-In LLM: Human-Aligned LLM-in-the-loop Intent Clustering for Customer Service Dialogues","abstract":"Discovering customer intentions in dialogue conversations is crucial for automated service agents. However, existing intent clustering methods often fail to align with human perceptions due to a heavy reliance on embedding distance metrics and a tendency to overlook underlying semantic structures. This paper proposes an LLM-in-the-loop (LLM-ITL) intent clustering framework, integrating the semantic understanding capabilities of LLMs into conventional clustering algorithms. Specifically, this paper (1) investigates the effectiveness of fine-tuned LLMs in semantic coherence evaluation and intent cluster naming, achieving over 95% accuracy aligned with human judgments; (2) designs an LLM-ITL framework that facilitates the iterative discovery of coherent intent clusters and the optimal number of clusters; and (3) proposes context-aware techniques tailored for customer service dialogue. As existing English benchmarks offer limited semantic diversity and intent groups, we introduce a comprehensive Chinese dialogue intent dataset, comprising over 100k real customer service calls and 1,507 human-annotated intent clusters. The proposed approaches significantly outperform LLM-guided baselines, achieving notable enhancements in clustering quality and lower computational cost. Combined with several best practices, our findings highlight the potential of LLM-in-the-loop techniques for scalable and human-aligned intent clustering.","authors":["Mengze Hong","Wailing Ng","Chen Jason Zhang","Yuanfeng Song","Di Jiang"],"url":"https://arxiv.org/abs/2412.09049"}
{"created":"2025-05-22","title":"Learning Novel Skills from Language-Generated Demonstrations","abstract":"Robots are increasingly deployed across diverse domains to tackle tasks requiring novel skills. However, current robot learning algorithms for acquiring novel skills often rely on demonstration datasets or environment interactions, resulting in high labor costs and potential safety risks. To address these challenges, this study proposes DemoGen, a skill-learning framework that enables robots to acquire novel skills from natural language instructions. DemoGen leverages the vision-language model and the video diffusion model to generate demonstration videos of novel skills, which enabling robots to learn new skills effectively. Experimental evaluations in the MetaWorld simulation environments demonstrate the pipeline's capability to generate high-fidelity and reliable demonstrations. Using the generated demonstrations, various skill learning algorithms achieve an accomplishment rate three times the original on novel tasks. These results highlight a novel approach to robot learning, offering a foundation for the intuitive and intelligent acquisition of novel robotic skills. (Project website: https://aoqunjin.github.io/LNSLGD/)","authors":["Ao-Qun Jin","Tian-Yu Xiang","Xiao-Hu Zhou","Mei-Jiang Gui","Xiao-Liang Xie","Shi-Qi Liu","Shuang-Yi Wang","Yue Cao","Sheng-Bin Duan","Fu-Chao Xie","Zeng-Guang Hou"],"url":"https://arxiv.org/abs/2412.09286"}
{"created":"2025-05-22","title":"ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL","abstract":"Despite the significant advancements in Text-to-SQL (Text2SQL) facilitated by large language models (LLMs), the latest state-of-the-art techniques are still trapped in the in-context learning of closed-source LLMs (e.g., GPT-4), which limits their applicability in open scenarios. To address this challenge, we propose a novel RObust mUltitask Tuning and collaboration mEthod (ROUTE) to improve the comprehensive capabilities of open-source LLMs for Text2SQL, thereby providing a more practical solution. Our approach begins with multi-task supervised fine-tuning (SFT) using various synthetic training data related to SQL generation. Unlike existing SFT-based Text2SQL methods, we introduced several additional SFT tasks, including schema linking, noise correction, and continuation writing. Engaging in a variety of SQL generation tasks enhances the model's understanding of SQL syntax and improves its ability to generate high-quality SQL queries. Additionally, inspired by the collaborative modes of LLM agents, we introduce a Multitask Collaboration Prompting (MCP) strategy. This strategy leverages collaboration across several SQL-related tasks to reduce hallucinations during SQL generation, thereby maximizing the potential of enhancing Text2SQL performance through explicit multitask capabilities. Extensive experiments and in-depth analyses have been performed on eight open-source LLMs and five widely-used benchmarks. The results demonstrate that our proposal outperforms the latest Text2SQL methods and yields leading performance.","authors":["Yang Qin","Chao Chen","Zhihang Fu","Ze Chen","Dezhong Peng","Peng Hu","Jieping Ye"],"url":"https://arxiv.org/abs/2412.10138"}
{"created":"2025-05-22","title":"Diffusion-based Method for Satellite Pattern-of-Life Identification","abstract":"Satellite pattern-of-life (PoL) identification is crucial for space safety and satellite monitoring, involving the analysis of typical satellite behaviors such as station-keeping, drift, etc. However, existing PoL identification methods remain underdeveloped due to the complexity of aerospace systems, variability in satellite behaviors, and fluctuating observation sampling rates. In a first attempt, we developed a domain expertise-informed machine learning method (Expert-ML) to combine satellite orbital movement knowledge and machine learning models. The Expert-ML method achieved high accuracy results in simulation data and real-world data with normal sampling rate. However, this approach lacks of generality as it requires domain expertise and its performance degraded significantly when data sampling rate varied. To achieve generality, we propose a novel diffusion-based PoL identification method. Distinct from prior approaches, the proposed method leverages a diffusion model to achieve end-to-end identification without manual refinement or domain-specific knowledge. Specifically, we employ a multivariate time-series encoder to capture hidden representations of satellite positional data. The encoded features are subsequently incorporated as conditional information in the denoising process to generate PoL labels. Through experimentation across real-world satellite settings, our proposed diffusion-based method demonstrates its high identification quality and provides a robust solution even with reduced data sampling rates, indicating its great potential in practical satellite behavior pattern identification, tracking and related mission deployment.","authors":["Yongchao Ye","Xinting Zhu","Xuejin Shen","Xiaoyu Chen","Lishuai Li","S. Joe Qin"],"url":"https://arxiv.org/abs/2412.10814"}
{"created":"2025-05-22","title":"DARWIN 1.5: Large Language Models as Materials Science Adapted Learners","abstract":"Materials discovery and design aim to find compositions and structures with desirable properties over highly complex and diverse physical spaces. Traditional solutions, such as high-throughput simulations or machine learning, often rely on complex descriptors, which hinder generalizability and transferability across different material systems. Moreover, These descriptors may inadequately represent macro-scale material properties, which are influenced by structural imperfections and compositional variations in real-world samples, thus limiting their practical applicability. To address these challenges, we propose DARWIN 1.5, the largest open-source large language model tailored for materials science. By leveraging natural language as input, DARWIN eliminates the need for task-specific descriptors and enables a flexible, unified approach to material property prediction and discovery. Our approach integrates 6M material domain papers and 21 experimental datasets from 49,256 materials across modalities while enabling cross-task knowledge transfer. The enhanced model achieves up to 59.1% improvement in prediction accuracy over the base LLaMA-7B architecture and outperforms SOTA machine learning approaches across 8 materials design tasks. These results establish LLMs as a promising foundation for developing versatile and scalable models in materials science.","authors":["Tong Xie","Yuwei Wan","Yixuan Liu","Yuchen Zeng","Shaozhou Wang","Wenjie Zhang","Clara Grazian","Chunyu Kit","Wanli Ouyang","Dongzhan Zhou","Bram Hoex"],"url":"https://arxiv.org/abs/2412.11970"}
{"created":"2025-05-22","title":"Exploring Cross-lingual Latent Transplantation: Mutual Opportunities and Open Challenges","abstract":"Current large language models (LLMs) often exhibit imbalances in multilingual capabilities and cultural adaptability, largely attributed to their English-centric pre-training data. In this paper, we introduce and investigate a cross-lingual latent transplantation (XTransplant) framework, which aims to further exploit the model's internalized multilingual knowledge during inference and examine its effects on the multilingual capability and cultural adaptability of LLMs. XTransplant framework enables models to harness the complementary strengths of both English and non-English resources by transplanting latent activations across languages. Through extensive analysis, we empirically demonstrate that XTransplant, a form of cross-lingual interaction, has mutually beneficial effects on the multilingual capability and cultural adaptability of LLMs, particularly for low-resource languages and cultures. We further reveal that attention modules play a pivotal role in supporting multilingual understanding, while feed-forward modules are more adept at capturing culture-specific knowledge. In addition, we conduct in-depth analysis of XTransplant's stability, effectiveness, and generalizability. By probing the upper bound performance of XTransplant, we expose the considerable underutilization of current LLMs' multilingual potential-a challenge that remains open. We hope our analysis offers a new lens for advancing cross-lingual interactions and better leveraging models' internalized multilingual knowledge.","authors":["Yangfan Ye","Xiaocheng Feng","Xiachong Feng","Libo Qin","Yichong Huang","Lei Huang","Weitao Ma","Qichen Hong","Zhirui Zhang","Yunfei Lu","Xiaohui Yan","Duyu Tang","Dandan Tu","Bing Qin"],"url":"https://arxiv.org/abs/2412.12686"}
{"created":"2025-05-22","title":"Lessons From an App Update at Replika AI: Identity Discontinuity in Human-AI Relationships","abstract":"Can consumers form especially deep emotional bonds with AI and be vested in AI identities over time? We leverage a natural app-update event at Replika AI, a popular US-based AI companion, to shed light on these questions. We find that, after the app removed its erotic role play (ERP) feature, preventing intimate interactions between consumers and chatbots that were previously possible, this event triggered perceptions in customers that their AI companion's identity had discontinued. This in turn predicted negative consumer welfare and marketing outcomes related to loss, including mourning the loss, and devaluing the \"new\" AI relative to the \"original\". Experimental evidence confirms these findings. Further experiments find that AI companions users feel closer to their AI companion than even their best human friend, and mourn a loss of their AI companion more than a loss of various other inanimate products. In short, consumers are forming human-level relationships with AI companions; disruptions to these relationships trigger real patterns of mourning as well as devaluation of the offering; and the degree of mourning and devaluation are explained by perceived discontinuity in the AIs identity. Our results illustrate that relationships with AI are truly personal, creating unique benefits and risks for consumers and firms alike.","authors":["Julian De Freitas","Noah Castelo","Ahmet K. U\\u{g}uralp","Zeliha O\\u{g}uz-U\\u{g}uralp"],"url":"https://arxiv.org/abs/2412.14190"}
{"created":"2025-05-22","title":"MRAG: A Modular Retrieval Framework for Time-Sensitive Question Answering","abstract":"Understanding temporal relations and answering time-sensitive questions is crucial yet a challenging task for question-answering systems powered by large language models (LLMs). Existing approaches either update the parametric knowledge of LLMs with new facts, which is resource-intensive and often impractical, or integrate LLMs with external knowledge retrieval (i.e., retrieval-augmented generation). However, off-the-shelf retrievers often struggle to identify relevant documents that require intensive temporal reasoning. To systematically study time-sensitive question answering, we introduce the TempRAGEval benchmark, which repurposes existing datasets by incorporating temporal perturbations and gold evidence labels. As anticipated, all existing retrieval methods struggle with these temporal reasoning-intensive questions. We further propose Modular Retrieval (MRAG), a trainless framework that includes three modules: (1) Question Processing that decomposes question into a main content and a temporal constraint; (2) Retrieval and Summarization that retrieves evidence and uses LLMs to summarize according to the main content; (3) Semantic-Temporal Hybrid Ranking that scores each evidence summarization based on both semantic and temporal relevance. On TempRAGEval, MRAG significantly outperforms baseline retrievers in retrieval performance, leading to further improvements in final answer accuracy.","authors":["Zhang Siyue","Xue Yuxiang","Zhang Yiming","Wu Xiaobao","Luu Anh Tuan","Zhao Chen"],"url":"https://arxiv.org/abs/2412.15540"}
{"created":"2025-05-22","title":"Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models","abstract":"Jailbreaking in Large Language Models (LLMs) is a major security concern as it can deceive LLMs to generate harmful text. Yet, there is still insufficient understanding of how jailbreaking works, which makes it hard to develop effective defense strategies. We aim to shed more light into this issue: we conduct a detailed large-scale analysis of seven different jailbreak methods and find that these disagreements stem from insufficient observation samples. In particular, we introduce \\textit{safety boundary}, and we find that jailbreaks shift harmful activations outside that safety boundary, where LLMs are less sensitive to harmful information. We also find that the low and the middle layers are critical in such shifts, while deeper layers have less impact. Leveraging on these insights, we propose a novel defense called \\textbf{Activation Boundary Defense} (ABD), which adaptively constrains the activations within the safety boundary. We further use Bayesian optimization to selectively apply the defense method to the low and the middle layers. Our experiments on several benchmarks show that ABD achieves an average DSR of over 98\\% against various forms of jailbreak attacks, with less than 2\\% impact on the model's general capabilities.","authors":["Lang Gao","Jiahui Geng","Xiangliang Zhang","Preslav Nakov","Xiuying Chen"],"url":"https://arxiv.org/abs/2412.17034"}
{"created":"2025-05-22","title":"Sparsest cut and eigenvalue multiplicities on low degree Abelian Cayley graphs","abstract":"Whether or not the Sparsest Cut problem admits an efficient $O(1)$-approximation algorithm is a fundamental algorithmic question with connections to geometry and the Unique Games Conjecture. Revisiting spectral algorithms for Sparsest Cut, we present a novel, simple algorithm that combines eigenspace enumeration with a new algorithm for the Cut Improvement problem. The runtime of our algorithm is parametrized by a quantity that we call the cut dimension $\\text{CD}_\\varepsilon(G)$: the smallest $k$ such that the subspace spanned by the first $k$ Laplacian eigenvectors contains all but $\\varepsilon$ fraction of a sparsest cut. Our algorithm matches the guarantees of prior methods based on the threshold-rank paradigm, while also extending beyond them. To illustrate this, we study its performance on low degree Cayley graphs over Abelian groups -- canonical examples of graphs with poor expansion properties. We prove that low degree Abelian Cayley graphs have small cut dimension, yielding an algorithm that computes a $(1+\\varepsilon)$-approximation to the uniform Sparsest Cut of a degree-$d$ Cayley graph over an Abelian group of size $n$ in time $n^{O(1)}\\cdot\\exp(d/\\varepsilon)^{O(d)}$. Along the way to bounding the cut dimension of Abelian Cayley graphs, we analyze their sparse cuts and spectra, proving that the collection of $O(1)$-approximate sparsest cuts has an $\\varepsilon$-net of size $\\exp(d/\\varepsilon)^{O(d)}$ and that the multiplicity of $\\lambda_2$ is bounded by $2^{O(d)}$. The latter bound is tight and improves on a previous bound of $2^{O(d^2)}$ by Lee and Makarychev.","authors":["Tommaso d'Orsi","Chris Jones","Jake Ruotolo","Salil Vadhan","Jiyu Zhang"],"url":"https://arxiv.org/abs/2412.17115"}
{"created":"2025-05-22","title":"Reconstructing People, Places, and Cameras","abstract":"We present \"Humans and Structure from Motion\" (HSfM), a method for jointly reconstructing multiple human meshes, scene point clouds, and camera parameters in a metric world coordinate system from a sparse set of uncalibrated multi-view images featuring people. Our approach combines data-driven scene reconstruction with the traditional Structure-from-Motion (SfM) framework to achieve more accurate scene reconstruction and camera estimation, while simultaneously recovering human meshes. In contrast to existing scene reconstruction and SfM methods that lack metric scale information, our method estimates approximate metric scale by leveraging a human statistical model. Furthermore, it reconstructs multiple human meshes within the same world coordinate system alongside the scene point cloud, effectively capturing spatial relationships among individuals and their positions in the environment. We initialize the reconstruction of humans, scenes, and cameras using robust foundational models and jointly optimize these elements. This joint optimization synergistically improves the accuracy of each component. We compare our method to existing approaches on two challenging benchmarks, EgoHumans and EgoExo4D, demonstrating significant improvements in human localization accuracy within the world coordinate frame (reducing error from 3.51m to 1.04m in EgoHumans and from 2.9m to 0.56m in EgoExo4D). Notably, our results show that incorporating human data into the SfM pipeline improves camera pose estimation (e.g., increasing RRA@15 by 20.3% on EgoHumans). Additionally, qualitative results show that our approach improves overall scene reconstruction quality. Our code is available at: https://github.com/hongsukchoi/HSfM_RELEASE","authors":["Lea M\\\"uller","Hongsuk Choi","Anthony Zhang","Brent Yi","Jitendra Malik","Angjoo Kanazawa"],"url":"https://arxiv.org/abs/2412.17806"}
{"created":"2025-05-22","title":"Property Enhanced Instruction Tuning for Multi-task Molecule Generation with Large Language Models","abstract":"Large language models (LLMs) are widely applied in various natural language processing tasks such as question answering and machine translation. However, due to the lack of labeled data and the difficulty of manual annotation for biochemical properties, the performance for molecule generation tasks is still limited, especially for tasks involving multi-properties constraints. In this work, we present a two-step framework PEIT (Property Enhanced Instruction Tuning) to improve LLMs for molecular-related tasks. In the first step, we use textual descriptions, SMILES, and biochemical properties as multimodal inputs to pre-train a model called PEIT-GEN, by aligning multi-modal representations to synthesize instruction data. In the second step, we fine-tune existing open-source LLMs with the synthesized data, the resulting PEIT-LLM can handle molecule captioning, text-based molecule generation, molecular property prediction, and our newly proposed multi-constraint molecule generation tasks. Experimental results show that our pre-trained PEIT-GEN outperforms MolT5 and BioT5 in molecule captioning, demonstrating modalities align well between textual descriptions, structures, and biochemical properties. Furthermore, PEIT-LLM shows promising improvements in multi-task molecule generation, proving the scalability of the PEIT framework for various molecular tasks. We release the code, constructed instruction data, and model checkpoints in https://github.com/chenlong164/PEIT.","authors":["Xuan Lin","Long Chen","Yile Wang","Xiangxiang Zeng","Philip S. Yu"],"url":"https://arxiv.org/abs/2412.18084"}
{"created":"2025-05-22","title":"Navigating Data Corruption in Machine Learning: Balancing Quality, Quantity, and Imputation Strategies","abstract":"Data corruption, including missing and noisy data, poses significant challenges in real-world machine learning. This study investigates the effects of data corruption on model performance and explores strategies to mitigate these effects through two experimental setups: supervised learning with NLP tasks (NLP-SL) and deep reinforcement learning for traffic signal optimization (Signal-RL). We analyze the relationship between data corruption levels and model performance, evaluate the effectiveness of data imputation methods, and assess the utility of enlarging datasets to address data corruption.","authors":["Qi Liu","Wanjing Ma"],"url":"https://arxiv.org/abs/2412.18296"}
{"created":"2025-05-22","title":"HV-BEV: Decoupling Horizontal and Vertical Feature Sampling for Multi-View 3D Object Detection","abstract":"The application of vision-based multi-view environmental perception system has been increasingly recognized in autonomous driving technology, especially the BEV-based models. Current state-of-the-art solutions primarily encode image features from each camera view into the BEV space through explicit or implicit depth prediction. However, these methods often overlook the structured correlations among different parts of objects in 3D space and the fact that different categories of objects often occupy distinct local height ranges. For example, trucks appear at higher elevations, whereas traffic cones are near the ground. In this work, we propose a novel approach that decouples feature sampling in the \\textbf{BEV} grid queries paradigm into \\textbf{H}orizontal feature aggregation and \\textbf{V}ertical adaptive height-aware reference point sampling (HV-BEV), aiming to improve both the aggregation of objects' complete information and awareness of diverse objects' height distribution. Specifically, a set of relevant neighboring points is dynamically constructed for each 3D reference point on the ground-aligned horizontal plane, enhancing the association of the same instance across different BEV grids, especially when the instance spans multiple image views around the vehicle. Additionally, instead of relying on uniform sampling within a fixed height range, we introduce a height-aware module that incorporates historical information, enabling the reference points to adaptively focus on the varying heights at which objects appear in different scenes. Extensive experiments validate the effectiveness of our proposed method, demonstrating its superior performance over the baseline across the nuScenes dataset. Moreover, our best-performing model achieves a remarkable 50.5\\% mAP and 59.8\\% NDS on the nuScenes testing set. The code is available at https://github.com/Uddd821/HV-BEV.","authors":["Di Wu","Feng Yang","Benlian Xu","Pan Liao","Wenhui Zhao","Dingwen Zhang"],"url":"https://arxiv.org/abs/2412.18884"}
{"created":"2025-05-22","title":"Uncertainty quantification for improving radiomic-based models in radiation pneumonitis prediction","abstract":"Background: Radiation pneumonitis is a side effect of thoracic radiation therapy. Recently, machine learning models with radiomic features have improved radiation pneumonitis prediction by capturing spatial information. To further support clinical decision-making, this study explores the role of post hoc uncertainty quantification methods in enhancing model uncertainty estimate. Methods: We retrospectively analyzed a cohort of 101 esophageal cancer patients. This study evaluated four machine learning models: logistic regression, support vector machines, extreme gradient boosting, and random forest, using 15 dosimetric, 79 dosiomic, and 237 radiomic features to predict radiation pneumonitis. We applied uncertainty quantification methods, including Platt scaling, isotonic regression, Venn-ABERS predictor, and conformal prediction, to quantify uncertainty. Model performance was assessed through an area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), and adaptive calibration error using leave-one-out cross-validation. Results: Highest AUROC is achieved by the logistic regression model with the conformal prediction method (AUROC 0.75+-0.01, AUPRC 0.74+-0.01) at a certainty cut point of 0.8. Highest AUPRC of 0.82+-0.02 (with AUROC of 0.67+-0.04) achieved by The extreme gradient boosting model with conformal prediction at the 0.9 certainty threshold. Radiomic and dosiomic features improve both discriminative and calibration performance. Conclusions: Integrating uncertainty quantification into machine learning models with radiomic and dosiomic features may improve both predictive accuracy and calibration, supporting more reliable clinical decision-making. The findings emphasize the value of uncertainty quantification methods in enhancing applicability of predictive models for radiation pneumonitis in healthcare settings.","authors":["Chanon Puttanawarut","Romen Samuel Wabina","Nat Sirirutbunkajorn"],"url":"https://arxiv.org/abs/2412.19511"}
{"created":"2025-05-22","title":"\"Did my figure do justice to the answer?\" : Towards Multimodal Short Answer Grading with Feedback (MMSAF)","abstract":"Assessments play a vital role in a student's learning process. This is because they provide valuable feedback crucial to a student's growth. Such assessments contain questions with open-ended responses, which are difficult to grade at scale. These responses often require students to express their understanding through textual and visual elements together as a unit. In order to develop scalable assessment tools for such questions, one needs multimodal LLMs having strong comparative reasoning capabilities across multiple modalities. Thus, to facilitate research in this area, we propose the Multimodal Short Answer grading with Feedback (MMSAF) problem along with a dataset of 2,197 data points. Additionally, we provide an automated framework for generating such datasets. As per our evaluations, existing Multimodal Large Language Models (MLLMs) could predict whether an answer is correct, incorrect or partially correct with an accuracy of 55%. Similarly, they could predict whether the image provided in the student's answer is relevant or not with an accuracy of 75%. As per human experts, Pixtral was more aligned towards human judgement and values for biology and ChatGPT for physics and chemistry and achieved a score of 4 or more out of 5 in most parameters.","authors":["Pritam Sil","Pushpak Bhattacharyya"],"url":"https://arxiv.org/abs/2412.19755"}
{"created":"2025-05-22","title":"Emergence of human-like polarization among large language model agents","abstract":"Rapid advances in large language models (LLMs) have not only empowered autonomous agents to generate social networks, communicate, and form shared and diverging opinions on political issues, but have also begun to play a growing role in shaping human political deliberation. Our understanding of their collective behaviours and underlying mechanisms remains incomplete, however, posing unexpected risks to human society. In this paper, we simulate a networked system involving thousands of large language model agents, discovering their social interactions, guided through LLM conversation, result in human-like polarization. We discover that these agents spontaneously develop their own social network with human-like properties, including homophilic clustering, but also shape their collective opinions through mechanisms observed in the real world, including the echo chamber effect. Similarities between humans and LLM agents -- encompassing behaviours, mechanisms, and emergent phenomena -- raise concerns about their capacity to amplify societal polarization, but also hold the potential to serve as a valuable testbed for identifying plausible strategies to mitigate polarization and its consequences.","authors":["Jinghua Piao","Zhihong Lu","Chen Gao","Fengli Xu","Qinghua Hu","Fernando P. Santos","Yong Li","James Evans"],"url":"https://arxiv.org/abs/2501.05171"}
{"created":"2025-05-22","title":"Monotonic Learning in the PAC Framework: A New Perspective","abstract":"Monotone learning describes learning processes in which expected performance consistently improves as the amount of training data increases. However, recent studies challenge this conventional wisdom, revealing significant gaps in the understanding of generalization in machine learning. Addressing these gaps is crucial for advancing the theoretical foundations of the field. In this work, we utilize Probably Approximately Correct (PAC) learning theory to construct a theoretical risk distribution that approximates a learning algorithm's actual performance. We rigorously prove that this theoretical distribution exhibits monotonicity as sample sizes increase. We identify two scenarios under which deterministic algorithms based on Empirical Risk Minimization (ERM) are monotone: (1) the hypothesis space is finite, or (2) the hypothesis space has finite VC-dimension. Experiments on two classical learning problems validate our findings by demonstrating that the monotonicity of the algorithms' generalization error is guaranteed, as its theoretical risk upper bound monotonically converges to 0.","authors":["Ming Li","Chenyi Zhang","Qin Li"],"url":"https://arxiv.org/abs/2501.05493"}
{"created":"2025-05-22","title":"How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond","abstract":"With the advancement of large language models (LLMs), intelligent models have evolved from mere tools to autonomous agents with their own goals and strategies for cooperating with humans. This evolution has birthed a novel paradigm in NLP, i.e., human-model cooperation, that has yielded remarkable progress in numerous NLP tasks in recent years. In this paper, we take the first step to present a thorough review of human-model cooperation, exploring its principles, formalizations, and open challenges. In particular, we introduce a new taxonomy that provides a unified perspective to summarize existing approaches. Also, we discuss potential frontier areas and their corresponding challenges. We regard our work as an entry point, paving the way for more breakthrough research in this regard.","authors":["Chen Huang","Yang Deng","Wenqiang Lei","Jiancheng Lv","Tat-Seng Chua","Jimmy Xiangji Huang"],"url":"https://arxiv.org/abs/2501.05714"}
{"created":"2025-05-22","title":"DisCoPatch: Batch Statistics Are All You Need For OOD Detection, But Only If You Can Trust Them","abstract":"Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code will be made publicly available","authors":["Francisco Caetano","Christiaan Viviers","Luis A. Zavala-Mondrag\\'on","Peter H. N. de With","Fons van der Sommen"],"url":"https://arxiv.org/abs/2501.08005"}
{"created":"2025-05-22","title":"Identifying the Desired Word Suggestion in Simultaneous Audio","abstract":"We explore a method for presenting word suggestions for non-visual text input using simultaneous voices. We conduct two perceptual studies and investigate the impact of different presentations of voices on a user's ability to detect which voice, if any, spoke their desired word. Our sets of words simulated the word suggestions of a predictive keyboard during real-world text input. We find that when voices are simultaneous, user accuracy decreases significantly with each added word suggestion. However, adding a slight 0.15 s delay between the start of each subsequent word allows two simultaneous words to be presented with no significant decrease in accuracy compared to presenting two words sequentially (84% simultaneous versus 86% sequential). This allows two word suggestions to be presented to the user 32% faster than sequential playback without decreasing accuracy.","authors":["Dylan Gaines","Keith Vertanen"],"url":"https://arxiv.org/abs/2501.10568"}
{"created":"2025-05-22","title":"Bitcoin: A Non-Continuous Time System","abstract":"This paper examines Bitcoin as a non-continuous time system shaped by probabilistic block generation, the occurrence of forks, and the non-linear confirmation of transactions. It introduces an entropy-based interpretation in which each block represents the resolution of uncertainty into an economically validated history. Bitcoin does not measure time through synchronized clocks or trusted authorities; instead, it constructs time through decentralized consensus. This mechanism enables permissionless coordination by ensuring temporal order emerges from the progressive collapse of competing possibilities.","authors":["Bin Chen"],"url":"https://arxiv.org/abs/2501.11091"}
{"created":"2025-05-22","title":"Predictive Learning in Energy-based Models with Attractor Structures","abstract":"Predictive models are highly advanced in understanding the mechanisms of brain function. Recent advances in machine learning further underscore the power of prediction for optimal representation in learning. However, there remains a gap in creating a biologically plausible model that explains how the neural system achieves prediction. In this paper, we introduce a framework that employs an energy-based model (EBM) to capture the nuanced processes of predicting observation after action within the neural system, encompassing prediction, learning, and inference. We implement the EBM with a hierarchical structure and integrate a continuous attractor neural network for memory, constructing a biologically plausible model. In experimental evaluations, our model demonstrates efficacy across diverse scenarios. The range of actions includes eye movement, motion in environments, head turning, and static observation while the environment changes. Our model not only makes accurate predictions for environments it was trained on, but also provides reasonable predictions for unseen environments, matching the performances of machine learning methods in multiple tasks. We hope that this study contributes to a deep understanding of how the neural system performs prediction.","authors":["Xingsi Dong","Xiangyuan Peng","Si Wu"],"url":"https://arxiv.org/abs/2501.13997"}
{"created":"2025-05-22","title":"Analyzing the Effect of Linguistic Similarity on Cross-Lingual Transfer: Tasks and Experimental Setups Matter","abstract":"Cross-lingual transfer is a popular approach to increase the amount of training data for NLP tasks in a low-resource context. However, the best strategy to decide which cross-lingual data to include is unclear. Prior research often focuses on a small set of languages from a few language families and/or a single task. It is still an open question how these findings extend to a wider variety of languages and tasks. In this work, we analyze cross-lingual transfer for 263 languages from a wide variety of language families. Moreover, we include three popular NLP tasks: POS tagging, dependency parsing, and topic classification. Our findings indicate that the effect of linguistic similarity on transfer performance depends on a range of factors: the NLP task, the (mono- or multilingual) input representations, and the definition of linguistic similarity.","authors":["Verena Blaschke","Masha Fedzechkina","Maartje ter Hoeve"],"url":"https://arxiv.org/abs/2501.14491"}
{"created":"2025-05-22","title":"ABPT: Amended Backpropagation through Time with Partially Differentiable Rewards","abstract":"Quadrotor control policies can be trained with high performance using the exact gradients of the rewards to directly optimize policy parameters via backpropagation-through-time (BPTT). However, designing a fully differentiable reward architecture is often challenging. Partially differentiable rewards will result in biased gradient propagation that degrades training performance. To overcome this limitation, we propose Amended Backpropagation-through-Time (ABPT), a novel approach that mitigates gradient bias while preserving the training efficiency of BPTT. ABPT combines 0-step and N-step returns, effectively reducing the bias by leveraging value gradients from the learned Q-value function. Additionally, it adopts entropy regularization and state initialization mechanisms to encourage exploration during training. We evaluate ABPT on four representative quadrotor flight tasks \\li{in both real world and simulation}. Experimental results demonstrate that ABPT converges significantly faster and achieves higher ultimate rewards than existing learning algorithms, particularly in tasks involving partially differentiable rewards. The code will be released at http://github.com/Fanxing-LI/ABPT.","authors":["Fanxing Li","Fangyu Sun","Tianbao Zhang","Danping Zou"],"url":"https://arxiv.org/abs/2501.14513"}
{"created":"2025-05-22","title":"Distributed Conformal Prediction via Message Passing","abstract":"Post-hoc calibration of pre-trained models is critical for ensuring reliable inference, especially in safety-critical domains such as healthcare. Conformal Prediction (CP) offers a robust post-hoc calibration framework, providing distribution-free statistical coverage guarantees for prediction sets by leveraging held-out datasets. In this work, we address a decentralized setting where each device has limited calibration data and can communicate only with its neighbors over an arbitrary graph topology. We propose two message-passing-based approaches for achieving reliable inference via CP: quantile-based distributed conformal prediction (Q-DCP) and histogram-based distributed conformal prediction (H-DCP). Q-DCP employs distributed quantile regression enhanced with tailored smoothing and regularization terms to accelerate convergence, while H-DCP uses a consensus-based histogram estimation approach. Through extensive experiments, we investigate the trade-offs between hyperparameter tuning requirements, communication overhead, coverage guarantees, and prediction set sizes across different network topologies. The code of our work is released on: https://github.com/HaifengWen/Distributed-Conformal-Prediction.","authors":["Haifeng Wen","Hong Xing","Osvaldo Simeone"],"url":"https://arxiv.org/abs/2501.14544"}
{"created":"2025-05-22","title":"Optimal Transport on Categorical Data for Counterfactuals using Compositional Data and Dirichlet Transport","abstract":"Recently, optimal transport-based approaches have gained attention for deriving counterfactuals, e.g., to quantify algorithmic discrimination. However, in the general multivariate setting, these methods are often opaque and difficult to interpret. To address this, alternative methodologies have been proposed, using causal graphs combined with iterative quantile regressions (Ple\\v{c}ko and Meinshausen (2020)) or sequential transport (Fernandes Machado et al. (2025)) to examine fairness at the individual level, often referred to as ``counterfactual fairness.'' Despite these advancements, transporting categorical variables remains a significant challenge in practical applications with real datasets. In this paper, we propose a novel approach to address this issue. Our method involves (1) converting categorical variables into compositional data and (2) transporting these compositions within the probabilistic simplex of $\\mathbb{R}^d$. We demonstrate the applicability and effectiveness of this approach through an illustration on real-world data, and discuss limitations.","authors":["Agathe Fernandes Machado","Arthur Charpentier","Ewen Gallic"],"url":"https://arxiv.org/abs/2501.15549"}
{"created":"2025-05-22","title":"Adaptive Width Neural Networks","abstract":"For almost 70 years, researchers have mostly relied on hyper-parameter tuning to select the width of neural networks' layers. This paper challenges the status quo by introducing an easy-to-use technique to learn an unbounded width of a neural network's layer during training. The technique does not rely on alternate optimization nor hand-crafted gradient heuristics; rather, it jointly optimizes the width and the parameters of each layer via simple backpropagation. We apply the technique to a broad range of data domains such as tables, images, text, sequences, and graphs, showing how the width adapts to the task's difficulty. The method imposes a soft ordering of importance among neurons, by which it also is possible to truncate the trained network at virtually zero cost, achieving a smooth trade-off between performance and compute resources in a structured way. Alternatively, one can dynamically compress the network with no performance degradation. In light of recent foundation models trained on large datasets, believed to require billions of parameters and where hyper-parameter tuning is unfeasible due to humongous training costs, our approach stands as a viable alternative for width learning.","authors":["Federico Errica","Henrik Christiansen","Viktor Zaverkin","Mathias Niepert","Francesco Alesiani"],"url":"https://arxiv.org/abs/2501.15889"}
{"created":"2025-05-22","title":"Deeply Optimizing the SAT Solver for the IC3 Algorithm","abstract":"The IC3 algorithm, also known as PDR, is a SAT-based model checking algorithm that has significantly influenced the field in recent years due to its efficiency, scalability, and completeness. It utilizes SAT solvers to solve a series of SAT queries associated with relative induction. In this paper, we introduce several optimizations for the SAT solver in IC3 based on our observations of the unique characteristics of these SAT queries. By observing that SAT queries do not necessarily require decisions on all variables, we compute a subset of variables that need to be decided before each solving process while ensuring that the result remains unaffected. Additionally, noting that the overhead of binary heap operations in VSIDS is non-negligible, we replace the binary heap with buckets to achieve constant-time operations. Furthermore, we support temporary clauses without the need to allocate a new activation variable for each solving process, thereby eliminating the need to reset solvers. We developed a novel lightweight CDCL SAT solver, GipSAT, which integrates these optimizations. A comprehensive evaluation highlights the performance improvements achieved by GipSAT. Specifically, the GipSAT-based IC3 demonstrates an average speedup of 3.61 times in solving time compared to the IC3 implementation based on MiniSat.","authors":["Yuheng Su","Qiusong Yang","Yiwei Ci","Yingcheng Li","Tianjun Bu","Ziyu Huang"],"url":"https://arxiv.org/abs/2501.18612"}
{"created":"2025-05-22","title":"From Low Intrinsic Dimensionality to Non-Vacuous Generalization Bounds in Deep Multi-Task Learning","abstract":"Deep learning methods are known to generalize well from training to future data, even in an overparametrized regime, where they could easily overfit. One explanation for this phenomenon is that even when their *ambient dimensionality*, (i.e. the number of parameters) is large, the models' *intrinsic dimensionality* is small; specifically, their learning takes place in a small subspace of all possible weight configurations. In this work, we confirm this phenomenon in the setting of *deep multi-task learning*. We introduce a method to parametrize multi-task network directly in the low-dimensional space, facilitated by the use of *random expansions* techniques. We then show that high-accuracy multi-task solutions can be found with much smaller intrinsic dimensionality (fewer free parameters) than what single-task learning requires. Subsequently, we show that the low-dimensional representations in combination with *weight compression* and *PAC-Bayesian* reasoning lead to the *first non-vacuous generalization bounds* for deep multi-task networks.","authors":["Hossein Zakerinia","Dorsa Ghobadi","Christoph H. Lampert"],"url":"https://arxiv.org/abs/2501.19067"}
{"created":"2025-05-22","title":"PixelWorld: Towards Perceiving Everything as Pixels","abstract":"Recent agentic language models increasingly need to interact directly with real-world environments containing intertwined visual and textual information through raw camera pixels, rather than relying on separate image and tokenized text processing, underscoring the necessity of a unified perception paradigm. To close this gap, we explore this idea through Perceive Everything as Pixels (PEAP) and release PixelWorld, a benchmark that renders natural-language, tabular, mathematical and diagrammatic inputs into a single pixel space. Experiments show that PEAP attains competitive accuracy on semantic-understanding tasks, indicating that a vision transformer can capture global textual semantics without explicit tokens. In contrast, reasoning-intensive benchmarks (math and code) exhibit sharp performance drops; however, Chain-of-Thought prompting partially mitigates this gap, hinting that explicit reasoning traces compensate for the missing token structure. We also find that when visual and textual information are closely integrated, representing everything as pixels reduces preprocessing complexity and avoids misalignment issues that often arise in separate pipelines. PixelWorld therefore serves as a practical benchmark for evaluating unified vision-language models and supports broader exploration of PEAP across diverse tasks.","authors":["Zhiheng Lyu","Xueguang Ma","Wenhu Chen"],"url":"https://arxiv.org/abs/2501.19339"}
{"created":"2025-05-22","title":"ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference","abstract":"Large Language Models (LLMs) require significant GPU memory when processing long texts, with the key value (KV) cache consuming up to 70\\% of total memory during inference. Although existing compression methods reduce memory by evaluating the importance of individual tokens, they overlook critical semantic relationships between tokens, resulting in fragmented context and degraded performance. We introduce ChunkKV, which fundamentally reimagines KV cache compression by treating semantic chunks - rather than isolated tokens - as basic compression units. This approach preserves complete linguistic structures and contextual integrity, ensuring that essential meaning is retained even under aggressive compression. Our innovation includes a novel layer-wise index reuse technique that exploits the higher cross-layer similarity of preserved indices in ChunkKV, reducing computational overhead and improving throughput by 26.5\\%. Comprehensive evaluations on challenging benchmarks: LongBench, Needle-In-A-HayStack, GSM8K, and JailbreakV demonstrate that ChunkKV outperforms state-of-the-art methods by up to 8.7\\% in precision while maintaining the same compression ratio. These results confirm that semantic-aware compression significantly enhances both efficiency and performance for long-context LLM inference, providing a simple yet effective solution to the memory bottleneck problem.","authors":["Xiang Liu","Zhenheng Tang","Peijie Dong","Zeyu Li","Yue Liu","Bo Li","Xuming Hu","Xiaowen Chu"],"url":"https://arxiv.org/abs/2502.00299"}
{"created":"2025-05-22","title":"How Contaminated Is Your Benchmark? Quantifying Dataset Leakage in Large Language Models with Kernel Divergence","abstract":"Dataset contamination, where evaluation datasets overlap with pre-training corpora, inflates performance metrics and undermines the reliability of model evaluations. Measuring dataset contamination thus becomes essential to ensure that performance evaluations genuinely reflect a model's ability to generalize to unseen data, rather than relying on memorized examples. To address this problem, we propose Kernel Divergence Score (KDS), a novel method that evaluates dataset contamination by computing the divergence between the kernel similarity matrix of sample embeddings, before and after fine-tuning on the benchmark dataset. Leveraging the insight that fine-tuning affects unseen samples more significantly than seen ones, KDS provides a reliable measure of contamination. Through extensive experiments on controlled contamination scenarios, KDS demonstrates a near-perfect correlation with contamination levels and outperforms existing baselines. Additionally, we perform comprehensive ablation studies to analyze the impact of key design choices, providing deeper insights into the components and effectiveness of KDS. These ablations highlight the importance of leveraging fine-grained kernel-based information and confirm the reliability of the proposed framework across diverse datasets and settings. Code is released in https://github.com/deeplearning-wisc/kernel-divergence-score.","authors":["Hyeong Kyu Choi","Maxim Khanov","Hongxin Wei","Yixuan Li"],"url":"https://arxiv.org/abs/2502.00678"}
{"created":"2025-05-22","title":"FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation","abstract":"While large language models (LLMs) excel at handling long-context sequences, they require substantial key-value (KV) caches to store contextual information, which can heavily burden computational efficiency and memory usage. Previous efforts to compress these KV caches primarily focused on reducing memory demands but were limited in enhancing latency. To address this issue, we introduce FastKV, a KV cache compression method designed to reduce latency for long-context inference. FastKV improves processing speed while preserving accuracy by adopting Token-Selective Propagation (TSP). This approach preserves full-context information in early layers of LLMs and selectively propagates only a portion of this information in later layers. This design enables FastKV to minimize redundant computation without sacrificing contextual fidelity. Our experimental results show that FastKV achieves up to 1.97$\\times$ and 4.82$\\times$ improvements in time-to-first-token (TTFT) and throughput, respectively, compared to baseline without KV cache compression. Moreover, FastKV successfully maintains accuracy within 1\\% of the baseline on long-context benchmarks. Our code is available at https://github.com/dongwonjo/FastKV.","authors":["Dongwon Jo","Jiwon Song","Yulhwa Kim","Jae-Joon Kim"],"url":"https://arxiv.org/abs/2502.01068"}
{"created":"2025-05-22","title":"The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles","abstract":"The releases of OpenAI's o-[n] series, such as o1, o3, and o4-mini, mark a significant paradigm shift in Large Language Models towards advanced reasoning capabilities. Notably, models like o3 have demonstrated strong performance on benchmarks like the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI). However, this benchmark is limited to symbolic patterns, whereas humans often perceive and reason about multimodal scenarios involving both vision and language data. Thus, there is an urgent need to investigate advanced reasoning capabilities in multimodal tasks. To this end, we track the evolution of the GPT-[n] and o-[n] series models (including o1, o3, and o4-mini) on challenging multimodal puzzles from PuzzleVQA and AlgoPuzzleVQA, which demand fine-grained visual perception. Our results reveal that o-[n] series, particularly later iterations like o3 and o4-mini, significantly outperform the GPT-[n] series and show strong scalability in multimodal reasoning. Nonetheless, despite these substantial advancements and the superior capabilities demonstrated by the o-[n] series, our findings highlight that even these leading models face persistent challenges. Difficulties are particularly evident in tasks requiring precise visual perception, robust compositional reasoning across multiple visual attributes, and solving complex algorithmic or highly combinatorial puzzles, indicating critical areas for future AGI development. We plan to continuously track new models in the series and update our results in this paper accordingly. All resources used in this evaluation are openly available at https://github.com/declare-lab/LLM-PuzzleTest.","authors":["Vernon Y. H. Toh","Yew Ken Chia","Deepanway Ghosal","Soujanya Poria"],"url":"https://arxiv.org/abs/2502.01081"}
{"created":"2025-05-22","title":"Learning Fused State Representations for Control from Multi-View Observations","abstract":"Multi-View Reinforcement Learning (MVRL) seeks to provide agents with multi-view observations, enabling them to perceive environment with greater effectiveness and precision. Recent advancements in MVRL focus on extracting latent representations from multiview observations and leveraging them in control tasks. However, it is not straightforward to learn compact and task-relevant representations, particularly in the presence of redundancy, distracting information, or missing views. In this paper, we propose Multi-view Fusion State for Control (MFSC), firstly incorporating bisimulation metric learning into MVRL to learn task-relevant representations. Furthermore, we propose a multiview-based mask and latent reconstruction auxiliary task that exploits shared information across views and improves MFSC's robustness in missing views by introducing a mask token. Extensive experimental results demonstrate that our method outperforms existing approaches in MVRL tasks. Even in more realistic scenarios with interference or missing views, MFSC consistently maintains high performance.","authors":["Zeyu Wang","Yao-Hui Li","Xin Li","Hongyu Zang","Romain Laroche","Riashat Islam"],"url":"https://arxiv.org/abs/2502.01316"}
{"created":"2025-05-22","title":"Massive Values in Self-Attention Modules are the Key to Contextual Knowledge Understanding","abstract":"Large language models (LLMs) have achieved remarkable success in contextual knowledge understanding. In this paper, we show that these concentrated massive values consistently emerge in specific regions of attention queries (Q) and keys (K) while not having such patterns in values (V) in various modern transformer-based LLMs (Q, K, and V mean the representations output by the query, key, and value layers respectively). Through extensive experiments, we further demonstrate that these massive values play a critical role in interpreting contextual knowledge (knowledge obtained from the current context window) rather than in retrieving parametric knowledge stored within the model's parameters. Our further investigation of quantization strategies reveals that ignoring these massive values leads to a pronounced drop in performance on tasks requiring rich contextual understanding, aligning with our analysis. Finally, we trace the emergence of concentrated massive values and find that such concentration is caused by Rotary Positional Encoding (RoPE), which has appeared since the first layers. These findings shed new light on how Q and K operate in LLMs and offer practical insights for model design and optimization. The Code is Available at https://github.com/MingyuJ666/Rope_with_LLM.","authors":["Mingyu Jin","Kai Mei","Wujiang Xu","Mingjie Sun","Ruixiang Tang","Mengnan Du","Zirui Liu","Yongfeng Zhang"],"url":"https://arxiv.org/abs/2502.01563"}
{"created":"2025-05-22","title":"Lifelong Knowledge Editing requires Better Regularization","abstract":"Knowledge editing is a promising way to improve factuality in large language models, but recent studies have shown significant model degradation during sequential editing. In this paper, we formalize the popular locate-then-edit methods as a two-step fine-tuning process, allowing us to precisely identify the root cause of this degradation. We show that model degradation occurs due to (1) over-optimization of internal activations and (2) continuous norm-growth of edited matrices. To mitigate these issues, we introduce two regularization techniques: (1) Most-Probable Early Stopping (MPES) and (2) explicit Frobenius norm-constraint. We demonstrate that applying these simple yet effective regularization techniques at key points in the editing process can substantially mitigate model degradation. Combining these regularization methods enables scaling locate-then-edit methods to 10,000 edits while reducing editing time by 42-61%. These results show that targeted regularization is essential for lifelong knowledge editing.","authors":["Akshat Gupta","Phudish Prateepamornkul","Maochuan Lu","Ahmed Alaa","Thomas Hartvigsen","Gopala Anumanchipalli"],"url":"https://arxiv.org/abs/2502.01636"}
{"created":"2025-05-22","title":"BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation","abstract":"As the demand for high-quality data in model training grows, researchers and developers are increasingly generating synthetic data to tune and train LLMs. However, current data generation methods rely on seed sets containing tens of thousands of examples to prompt instruction-tuned models. This reliance can be especially problematic when the curation of high-quality examples is expensive or difficult. In this paper we explore the novel few-shot synthetic data generation setting -- generating a high-quality dataset from a few examples. We show that when working with only a few seed examples, instruction-tuned models used in current synthetic data methods produce insufficient diversity for downstream tasks. In contrast, we show that base models without post-training, largely untapped for synthetic data generation, offer substantially greater output diversity, albeit with lower instruction following abilities. Leveraging this insight, we propose Base-Refine (BARE), a novel two-stage method that combines the diversity of base models with the quality assurance of instruction-tuned models. BARE excels in few-shot synthetic data generation: using only 3 seed examples it generates diverse, high-quality datasets that significantly improve downstream task performance. We show that fine-tuning Llama 3.1 8B with 1,000 BARE-generated samples achieves performance comparable to state-of-the-art similarly sized models on LiveCodeBench tasks. Furthermore, data generated with BARE enables a 101% improvement for a fine-tuned Llama 3.2 1B on GSM8K over data generated by only instruction-models, and an 18.4% improvement for a fine-tuned Llama 3.1 8B over the state-of-the-art RAFT method for RAG data generation.","authors":["Alan Zhu","Parth Asawa","Jared Quincy Davis","Lingjiao Chen","Boris Hanin","Ion Stoica","Joseph E. Gonzalez","Matei Zaharia"],"url":"https://arxiv.org/abs/2502.01697"}
{"created":"2025-05-22","title":"Learning with Differentially Private (Sliced) Wasserstein Gradients","abstract":"In this work, we introduce a novel framework for privately optimizing objectives that rely on Wasserstein distances between data-dependent empirical measures. Our main theoretical contribution is, based on an explicit formulation of the Wasserstein gradient in a fully discrete setting, a control on the sensitivity of this gradient to individual data points, allowing strong privacy guarantees at minimal utility cost. Building on these insights, we develop a deep learning approach that incorporates gradient and activations clipping, originally designed for DP training of problems with a finite-sum structure. We further demonstrate that privacy accounting methods extend to Wasserstein-based objectives, facilitating large-scale private training. Empirical results confirm that our framework effectively balances accuracy and privacy, offering a theoretically sound solution for privacy-preserving machine learning tasks relying on optimal transport distances such as Wasserstein distance or sliced-Wasserstein distance.","authors":["David Rodr\\'iguez-V\\'itores (UVa","IMUVA)","Cl\\'ement Lalanne (IMT","ANITI)","Jean-Michel Loubes (IMT","ANITI)"],"url":"https://arxiv.org/abs/2502.01701"}
{"created":"2025-05-22","title":"Relators and Notions of Simulation Revisited","abstract":"Simulations and bisimulations are ubiquitous in the study of concurrent systems and modal logics of various types. Besides classical relational transition systems, relevant system types include, for instance, probabilistic, weighted, neighbourhood-based, and game-based systems. Universal coalgebra abstracts system types in this sense as set functors. Notions of (bi)simulation then arise by extending the functor to act on relations in a suitable manner, turning it into what may be termed a relator. We contribute to the study of relators in the broadest possible sense, in particular in relation to their induced notions of (bi)similarity. Specifically, (i) we show that every functor that preserves a very restricted type of pullbacks (termed 1/4-iso pullbacks) admits a sound and complete notion of bisimulation induced by the coBarr relator; (ii) we establish equivalences between properties of relators and closure properties of the induced notion of (bi)simulation, showing in particular that the full set of expected closure properties requires the relator to be a lax extension, and that soundness of (bi)simulations requires preservation of diagonals; and (iii) we show that functors preserving inverse images admit a greatest lax extension. In a concluding case study, we apply (iii) to obtain a novel highly permissive notion of twisted bisimulation on labelled transition systems.","authors":["Sergey Goncharov","Dirk Hofmann","Pedro Nora","Lutz Schr\\\"oder","Paul Wild"],"url":"https://arxiv.org/abs/2502.01790"}
{"created":"2025-05-22","title":"Can LLMs Maintain Fundamental Abilities under KV Cache Compression?","abstract":"This paper investigates an underexplored challenge in large language models (LLMs): the impact of KV cache compression methods on LLMs' fundamental capabilities. Although existing methods achieve impressive compression ratios on long-context benchmarks, their effects on core model capabilities remain understudied. We present a comprehensive benchmark KVFundaBench to systematically evaluate the effects of KV cache compression across diverse fundamental LLM capabilities, spanning world knowledge, commonsense reasoning, arithmetic reasoning, code generation, safety, and long-context understanding and generation.Our analysis reveals serval key findings: (1) \\textit{Task-Dependent Degradation}; (2) \\textit{Model-Type Robustness} (3) \\textit{Prompt Length Vulnerability}; (4) \\textit{Chunk-Level Superiority}; (5) \\textit{Prompt-Gain Sensitivity}; (6) \\textit{Long-Context Generation Sensitivity}. Based on our analysis of attention patterns and cross-task compression performance, we propose ShotKV, a novel compression approach that distinctly handles prefill and decoding phases while maintaining shot-level semantic coherence. Empirical results show that ShotKV achieves $9\\%$-$18\\%$ performance improvements on long-context generation tasks under aggressive compression ratios.","authors":["Xiang Liu","Zhenheng Tang","Hong Chen","Peijie Dong","Zeyu Li","Xiuze Zhou","Bo Li","Xuming Hu","Xiaowen Chu"],"url":"https://arxiv.org/abs/2502.01941"}
{"created":"2025-05-22","title":"Sparse Data Generation Using Diffusion Models","abstract":"Sparse data is ubiquitous, appearing in numerous domains, from economics and recommender systems to astronomy and biomedical sciences. However, efficiently generating high-fidelity synthetic sparse data remains a significant challenge. We introduce Sparse Data Diffusion (SDD), a novel method for generating sparse data. SDD extends continuous state-space diffusion models with an explicit representation of exact zeros by modeling sparsity through the introduction of Sparsity Bits. Empirical validation in various domains, including two scientific applications in physics and biology, demonstrates that SDD achieves high fidelity in representing data sparsity while preserving the quality of the generated data.","authors":["Phil Ostheimer","Mayank Nagda","Jean Radig","Carl Herrmann","Stephan Mandt","Marius Kloft","Sophie Fellenz"],"url":"https://arxiv.org/abs/2502.02448"}
{"created":"2025-05-22","title":"OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change","abstract":"Marine ecosystems face unprecedented threats from climate change and plastic pollution, yet traditional environmental education often struggles to translate awareness into sustained behavioral change. This paper presents OceanChat, an interactive system leveraging large language models to create conversational AI agents represented as animated marine creatures -- specifically a beluga whale, a jellyfish, and a seahorse -- designed to promote environmental behavior (PEB) and foster awareness through personalized dialogue. Through a between-subjects experiment (N=900), we compared three conditions: (1) Static Scientific Information, providing conventional environmental education through text and images; (2) Static Character Narrative, featuring first-person storytelling from 3D-rendered marine creatures; and (3) Conversational Character Narrative, enabling real-time dialogue with AI-powered marine characters. Our analysis revealed that the Conversational Character Narrative condition significantly increased behavioral intentions and sustainable choice preferences compared to static approaches. The beluga whale character demonstrated consistently stronger emotional engagement across multiple measures, including perceived anthropomorphism and empathy. However, impacts on deeper measures like climate policy support and psychological distance were limited, highlighting the complexity of shifting entrenched beliefs. Our work extends research on sustainability interfaces facilitating PEB and offers design principles for creating emotionally resonant, context-aware AI characters. By balancing anthropomorphism with species authenticity, OceanChat demonstrates how interactive narratives can bridge the gap between environmental knowledge and real-world behavior change.","authors":["Pat Pataranutaporn","Alexander Doudkin","Pattie Maes"],"url":"https://arxiv.org/abs/2502.02863"}
{"created":"2025-05-22","title":"Scaling laws in wearable human activity recognition","abstract":"Many deep architectures and self-supervised pre-training techniques have been proposed for human activity recognition (HAR) from wearable multimodal sensors. Scaling laws have the potential to help move towards more principled design by linking model capacity with pre-training data volume. Yet, scaling laws have not been established for HAR to the same extent as in language and vision. By conducting an exhaustive grid search on both amount of pre-training data and Transformer architectures, we establish the first known scaling laws for HAR. We show that pre-training loss scales with a power law relationship to amount of data and parameter count and that increasing the number of users in a dataset results in a steeper improvement in performance than increasing data per user, indicating that diversity of pre-training data is important, which contrasts to some previously reported findings in self-supervised HAR. We show that these scaling laws translate to downstream performance improvements on three HAR benchmark datasets of postures, modes of locomotion and activities of daily living: UCI HAR and WISDM Phone and WISDM Watch. Finally, we suggest some previously published works should be revisited in light of these scaling laws with more adequate model capacities.","authors":["Tom Hoddes","Alex Bijamov","Saket Joshi","Daniel Roggen","Ali Etemad","Robert Harle","David Racz"],"url":"https://arxiv.org/abs/2502.03364"}
{"created":"2025-05-22","title":"From Features to Transformers: Redefining Ranking for Scalable Impact","abstract":"We present LiGR, a large-scale ranking framework developed at LinkedIn that brings state-of-the-art transformer-based modeling architectures into production. We introduce a modified transformer architecture that incorporates learned normalization and simultaneous set-wise attention to user history and ranked items. This architecture enables several breakthrough achievements, including: (1) the deprecation of most manually designed feature engineering, outperforming the prior state-of-the-art system using only few features (compared to hundreds in the baseline), (2) validation of the scaling law for ranking systems, showing improved performance with larger models, more training data, and longer context sequences, and (3) simultaneous joint scoring of items in a set-wise manner, leading to automated improvements in diversity. To enable efficient serving of large ranking models, we describe techniques to scale inference effectively using single-pass processing of user history and set-wise attention. We also summarize key insights from various ablation studies and A/B tests, highlighting the most impactful technical approaches.","authors":["Fedor Borisyuk","Lars Hertel","Ganesh Parameswaran","Gaurav Srivastava","Sudarshan Srinivasa Ramanujam","Borja Ocejo","Peng Du","Andrei Akterskii","Neil Daftary","Shao Tang","Daqi Sun","Qiang Charles Xiao","Deepesh Nathani","Mohit Kothari","Yun Dai","Guoyao Li","Aman Gupta"],"url":"https://arxiv.org/abs/2502.03417"}
{"created":"2025-05-22","title":"Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion Prior and Differentiable Physics","abstract":"Recent advances in large models have significantly advanced image-to-3D reconstruction. However, the generated models are often fused into a single piece, limiting their applicability in downstream tasks. This paper focuses on 3D garment generation, a key area for applications like virtual try-on with dynamic garment animations, which require garments to be separable and simulation-ready. We introduce Dress-1-to-3, a novel pipeline that reconstructs physics-plausible, simulation-ready separated garments with sewing patterns and humans from an in-the-wild image. Starting with the image, our approach combines a pre-trained image-to-sewing pattern generation model for creating coarse sewing patterns with a pre-trained multi-view diffusion model to produce multi-view images. The sewing pattern is further refined using a differentiable garment simulator based on the generated multi-view images. Versatile experiments demonstrate that our optimization approach substantially enhances the geometric alignment of the reconstructed 3D garments and humans with the input image. Furthermore, by integrating a texture generation module and a human motion generation module, we produce customized physics-plausible and realistic dynamic garment demonstrations. Project page: https://dress-1-to-3.github.io/","authors":["Xuan Li","Chang Yu","Wenxin Du","Ying Jiang","Tianyi Xie","Yunuo Chen","Yin Yang","Chenfanfu Jiang"],"url":"https://arxiv.org/abs/2502.03449"}
{"created":"2025-05-22","title":"Gompertz Linear Units: Leveraging Asymmetry for Enhanced Learning Dynamics","abstract":"Activation functions are fundamental elements of deep learning architectures as they significantly influence training dynamics. ReLU, while widely used, is prone to the dying neuron problem, which has been mitigated by variants such as LeakyReLU, PReLU, and ELU that better handle negative neuron outputs. Recently, self-gated activations like GELU and Swish have emerged as state-of-the-art alternatives, leveraging their smoothness to ensure stable gradient flow and prevent neuron inactivity. In this work, we introduce the Gompertz Linear Unit (GoLU), a novel self-gated activation function defined as $\\mathrm{GoLU}(x) = x \\, \\mathrm{Gompertz}(x)$, where $\\mathrm{Gompertz}(x) = e^{-e^{-x}}$. The GoLU activation leverages the right-skewed asymmetry in the Gompertz function to reduce variance in the latent space more effectively compared to GELU and Swish, while preserving robust gradient flow. Extensive experiments across diverse tasks, including Image Classification, Language Modeling, Semantic Segmentation, Object Detection, Instance Segmentation, and Diffusion, highlight GoLU's superior performance relative to state-of-the-art activation functions, establishing GoLU as a robust alternative to existing activation functions.","authors":["Indrashis Das","Mahmoud Safari","Steven Adriaensen","Frank Hutter"],"url":"https://arxiv.org/abs/2502.03654"}
{"created":"2025-05-22","title":"Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization","abstract":"Large Language Models (LLMs) have shown significant capability across various tasks, with their real-world effectiveness often driven by prompt design. While recent research has focused on optimizing prompt content, the role of prompt formatting, a critical but often overlooked dimension, has received limited systematic investigation. In this paper, we introduce Content-Format Integrated Prompt Optimization (CFPO), an innovative methodology that jointly optimizes both prompt content and formatting through an iterative refinement process. CFPO leverages natural language mutations to explore content variations and employs a dynamic format exploration strategy that systematically evaluates diverse format options. Our extensive evaluations across multiple tasks and open-source LLMs demonstrate that CFPO demonstrates measurable performance improvements compared to content-only optimization methods. This highlights the importance of integrated content-format optimization and offers a practical, model-agnostic approach to enhancing LLM performance. Code is available at https://github.com/HenryLau7/CFPO.","authors":["Yuanye Liu","Jiahang Xu","Li Lyna Zhang","Qi Chen","Xuan Feng","Yang Chen","Zhongxin Guo","Yuqing Yang","Peng Cheng"],"url":"https://arxiv.org/abs/2502.04295"}
{"created":"2025-05-22","title":"An Analysis for Reasoning Bias of Language Models with Small Initialization","abstract":"Transformer-based Large Language Models (LLMs) have revolutionized Natural Language Processing by demonstrating exceptional performance across diverse tasks. This study investigates the impact of the parameter initialization scale on the training behavior and task preferences of LLMs. We discover that smaller initialization scales encourage models to favor reasoning tasks, whereas larger initialization scales lead to a preference for memorization tasks. We validate this reasoning bias via real datasets and meticulously designed anchor functions. Further analysis of initial training dynamics suggests that specific model components, particularly the embedding space and self-attention mechanisms, play pivotal roles in shaping these learning biases. We provide a theoretical framework from the perspective of model training dynamics to explain these phenomena. Additionally, experiments on real-world language tasks corroborate our theoretical insights. This work enhances our understanding of how initialization strategies influence LLM performance on reasoning tasks and offers valuable guidelines for training models.","authors":["Junjie Yao","Zhongwang Zhang","Zhi-Qin John Xu"],"url":"https://arxiv.org/abs/2502.04375"}
{"created":"2025-05-22","title":"Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective","abstract":"Oversmoothing is a fundamental challenge in graph neural networks (GNNs): as the number of layers increases, node embeddings become increasingly similar, and model performance drops sharply. Traditionally, oversmoothing has been quantified using metrics that measure the similarity of neighbouring node features, such as the Dirichlet energy. While these metrics are related to oversmoothing, we argue they have critical limitations and fail to reliably capture oversmoothing in realistic scenarios. For instance, they provide meaningful insights only for very deep networks and under somewhat strict conditions on the norm of network weights and feature representations. As an alternative, we propose measuring oversmoothing by examining the numerical or effective rank of the feature representations. We provide theoretical support for this approach, demonstrating that the numerical rank of feature representations converges to one for a broad family of nonlinear activation functions under the assumption of nonnegative trained weights. To the best of our knowledge, this is the first result that proves the occurrence of oversmoothing in the nonlinear setting without assumptions on the boundedness of the weight matrices. Along with the theoretical findings, we provide extensive numerical evaluation across diverse graph architectures. Our results show that rank-based metrics consistently capture oversmoothing, whereas energy-based metrics often fail. Notably, we reveal that a significant drop in the rank aligns closely with performance degradation, even in scenarios where energy metrics remain unchanged.","authors":["Kaicheng Zhang","Piero Deidda","Desmond Higham","Francesco Tudisco"],"url":"https://arxiv.org/abs/2502.04591"}
{"created":"2025-05-22","title":"The Role of Integrity Monitoring in Connected and Automated Vehicles: Current State-of-Practice and Future Directions","abstract":"Positioning integrity refers to the trust in the performance of a navigation system. Accurate and reliable position information is needed to meet the requirements of connected and Automated Vehicle (CAV) applications, particularly in safety-critical scenarios. Receiver Autonomous Integrity Monitoring (RAIM) and its variants have been widely studied for Global Navigation Satellite System (GNSS)-based vehicle positioning, often fused with kinematic (e.g., Odometry) and perception sensors (e.g., camera). However, integrity monitoring (IM) for cooperative positioning solutions leveraging Vehicle-to-Everything (V2X) communication has received comparatively limited attention. This paper reviews existing research in the field of positioning IM and identifies various research gaps. Particular attention has been placed on identifying research that highlights cooperative IM methods. It also examines key automotive safety standards and public V2X datasets to map current research priorities and uncover critical gaps. Finally, the paper outlines promising future directions, highlighting research topics aimed at advancing and benchmarking positioning integrity.","authors":["Saswat Priyadarshi Nayak","Matthew Barth"],"url":"https://arxiv.org/abs/2502.04874"}
{"created":"2025-05-22","title":"Effective Sampling for Robot Motion Planning Through the Lens of Lattices","abstract":"Sampling-based methods for motion planning, which capture the structure of the robot's free space via (typically random) sampling, have gained popularity due to their scalability, simplicity, and for offering global guarantees, such as probabilistic completeness and asymptotic optimality. Unfortunately, the practicality of those guarantees remains limited as they do not provide insights into the behavior of motion planners for a finite number of samples (i.e., a finite running time). In this work, we harness lattice theory and the concept of $(\\delta,\\epsilon)$-completeness by Tsao et al. (2020) to construct deterministic sample sets that endow their planners with strong finite-time guarantees while minimizing running time. In particular, we introduce a highly-efficient deterministic sampling approach based on the $A_d^*$ lattice, which is the best-known geometric covering in dimensions $\\leq 21$. Using our new sampling approach, we obtain at least an order-of-magnitude speedup over existing deterministic and uniform random sampling methods for complex motion-planning problems. Overall, our work provides deep mathematical insights while advancing the practical applicability of sampling-based motion planning.","authors":["Itai Panasoff","Kiril Solovey"],"url":"https://arxiv.org/abs/2502.04908"}
{"created":"2025-05-22","title":"Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency","abstract":"Uncertainty quantification (UQ) methods for Large Language Models (LLMs) encompass a variety of approaches, with two major types being particularly prominent: information-based, which focus on model confidence expressed as token probabilities, and consistency-based, which assess the semantic relationship between multiple outputs generated using repeated sampling. Several recent methods have combined these two approaches to boost UQ performance. However, they sometimes fail to outperform much simpler baseline methods. Our work discusses the fundamental approach to constructing uncertainty measures that directly links uncertainty with the minimum Bayes risks achieved by LLM decoding. Building on these findings, we propose a novel approach to integrating model confidence with output consistency, resulting in a family of efficient and robust UQ methods. Our investigation reveals distinctive characteristics of LLMs as probabilistic models, which help to explain why these UQ methods underperform in certain tasks. Based on these findings, we propose a new way of synthesizing model confidence and output consistency, leading to a family of efficient and robust UQ methods. We evaluate our approach across various tasks such as question answering, abstractive summarization, and machine translation, demonstrating sizable improvements over state-of-the-art UQ approaches.","authors":["Roman Vashurin","Maiya Goloburda","Albina Ilina","Alexander Rubashevskii","Preslav Nakov","Artem Shelmanov","Maxim Panov"],"url":"https://arxiv.org/abs/2502.04964"}
{"created":"2025-05-22","title":"Rethinking Link Prediction for Directed Graphs","abstract":"Link prediction for directed graphs is a crucial task with diverse real-world applications. Recent advances in embedding methods and Graph Neural Networks (GNNs) have shown promising improvements. However, these methods often lack a thorough analysis of their expressiveness and suffer from effective benchmarks for a fair evaluation. In this paper, we propose a unified framework to assess the expressiveness of existing methods, highlighting the impact of dual embeddings and decoder design on directed link prediction performance. To address limitations in current benchmark setups, we introduce DirLinkBench, a robust new benchmark with comprehensive coverage, standardized evaluation, and modular extensibility. The results on DirLinkBench show that current methods struggle to achieve strong performance, while DiGAE outperforms other baselines overall. We further revisit DiGAE theoretically, showing its graph convolution aligns with GCN on an undirected bipartite graph. Inspired by these insights, we propose a novel Spectral Directed Graph Auto-Encoder SDGAE that achieves state-of-the-art average performance on DirLinkBench. Finally, we analyze key factors influencing directed link prediction and highlight open challenges in this field.","authors":["Mingguo He","Yuhe Guo","Yanping Zheng","Zhewei Wei","Stephan G\\\"unnemann","Xiaokui Xiao"],"url":"https://arxiv.org/abs/2502.05724"}
{"created":"2025-05-22","title":"Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously Optimizing Robot Poses and Occupancy Map","abstract":"Joint optimization of poses and features has been extensively studied and demonstrated to yield more accurate results in feature-based SLAM problems. However, research on jointly optimizing poses and non-feature-based maps remains limited. Occupancy maps are widely used non-feature-based environment representations because they effectively classify spaces into obstacles, free areas, and unknown regions, providing robots with spatial information for various tasks. In this paper, we propose Occupancy-SLAM, a novel optimization-based SLAM method that enables the joint optimization of robot trajectory and the occupancy map through a parameterized map representation. The key novelty lies in optimizing both robot poses and occupancy values at different cell vertices simultaneously, a significant departure from existing methods where the robot poses need to be optimized first before the map can be estimated. Evaluations using simulations and practical 2D laser datasets demonstrate that the proposed approach can robustly obtain more accurate robot trajectories and occupancy maps than state-of-the-art techniques with comparable computational time. Preliminary results in the 3D case further confirm the potential of the proposed method in practical 3D applications, achieving more accurate results than existing methods.","authors":["Yingyu Wang","Liang Zhao","Shoudong Huang"],"url":"https://arxiv.org/abs/2502.06292"}
{"created":"2025-05-22","title":"Analysis of a finite element method for the Stokes--Poisson--Boltzmann equations","abstract":"We define a finite element method for the coupling of Stokes and nonlinear Poisson--Boltzmann equations. The novelty in the formulation is that the coupling from the electric potential to the drag in the momentum balance is rewritten as a weighted advection term. Using Banach's contraction principle, the Babu\\v{s}ka--Brezzi theory, and the Minty--Browder theorem, we show that the governing equations have a unique weak solution. We also show that the discrete problem is well-posed, establish C\\'ea estimates, and derive convergence rates. We exemplify the properties of the proposed scheme via some numerical experiments showcasing convergence and applicability in the study of electro-osmotic flows in micro-channels.","authors":["Abeer F. AlSohaim","Ricardo Ruiz-Baier","Segundo Villa-Fuentes"],"url":"https://arxiv.org/abs/2502.06455"}
{"created":"2025-05-22","title":"Neurons Speak in Ranges: Breaking Free from Discrete Neuronal Attribution","abstract":"Interpreting the internal mechanisms of large language models (LLMs) is crucial for improving their trustworthiness and utility. Prior work has primarily focused on mapping individual neurons to discrete semantic concepts. However, such mappings struggle to handle the inherent polysemanticity in LLMs, where individual neurons encode multiple, distinct concepts. Through a comprehensive analysis of both encoder and decoder-based LLMs across diverse datasets, we observe that even highly salient neurons, identified via various attribution techniques for specific semantic concepts, consistently exhibit polysemantic behavior. Importantly, activation magnitudes for fine-grained concepts follow distinct, often Gaussian-like distributions with minimal overlap. This observation motivates a shift from neuron attribution to range-based interpretation. We hypothesize that interpreting and manipulating neuron activation ranges would enable more precise interpretability and targeted interventions in LLMs. To validate our hypothesis, we introduce NeuronLens, a novel range-based interpretation and manipulation framework that provides a finer view of neuron activation distributions to localize concept attribution within a neuron. Extensive empirical evaluations demonstrate that NeuronLens significantly reduces unintended interference, while maintaining precise manipulation of targeted concepts, outperforming neuron attribution.","authors":["Muhammad Umair Haider","Hammad Rizwan","Hassan Sajjad","Peizhong Ju","A. B. Siddique"],"url":"https://arxiv.org/abs/2502.06809"}
{"created":"2025-05-22","title":"Reinforcement Learning on Dyads to Enhance Medication Adherence","abstract":"Medication adherence is critical for the recovery of adolescents and young adults (AYAs) who have undergone hematopoietic cell transplantation (HCT). However, maintaining adherence is challenging for AYAs after hospital discharge, who experience both individual (e.g. physical and emotional symptoms) and interpersonal barriers (e.g., relational difficulties with their care partner, who is often involved in medication management). To optimize the effectiveness of a three-component digital intervention targeting both members of the dyad as well as their relationship, we propose a novel Multi-Agent Reinforcement Learning (MARL) approach to personalize the delivery of interventions. By incorporating the domain knowledge, the MARL framework, where each agent is responsible for the delivery of one intervention component, allows for faster learning compared with a flattened agent. Evaluation using a dyadic simulator environment, based on real clinical data, shows a significant improvement in medication adherence (approximately 3%) compared to purely random intervention delivery. The effectiveness of this approach will be further evaluated in an upcoming trial.","authors":["Ziping Xu","Hinal Jajal","Sung Won Choi","Inbal Nahum-Shani","Guy Shani","Alexandra M. Psihogios","Pei-Yao Hung","Susan Murphy"],"url":"https://arxiv.org/abs/2502.06835"}
{"created":"2025-05-22","title":"Machine learning on manifolds for inverse scattering: Lipschitz stability analysis","abstract":"Establishing Lipschitz stability estimates is crucial for ensuring the mathematical robustness of neural network (NN) approximations in machine learning (ML)-based parameter estimation, particularly in physics-informed settings. In this work, we derive such estimates for the inverse of a nonlinear map defined on a manifold that captures both unknown parameters and the nonlinear physical processes they influence. Our analysis is based on finite-dimensional, learnable representations of the manifold and provides Lipschitz stability estimates on the manifold-based subspaces, for a class of inverse maps associated with parameter dependent linear compact operators. Such operators model scattered and far-field data that can be used to detect structures such as cracks. We apply our theoretical ML manifold framework to inverse Helmholtz problems in unbounded regions exterior to cracks, addressing the scattered-field data-driven inverse problem while ensuring injectivity conditions on the manifold, a requirement for the Lipschitz stability. Our method accurately recovers crack-defining parameters without requiring prior knowledge of inputs such as incident wave types or external forces on the crack. Numerical experiments using NN approximations confirm the accuracy, efficiency, and robustness of the proposed approach.","authors":["Mahadevan Ganesh","Stuart C. Hawkins","Darko Volkov"],"url":"https://arxiv.org/abs/2502.07093"}
{"created":"2025-05-22","title":"Memory Is Not the Bottleneck: Cost-Efficient Continual Learning via Weight Space Consolidation","abstract":"Continual learning (CL) has traditionally emphasized minimizing exemplar memory usage, assuming that memory is the primary bottleneck. However, in modern computing environments-particularly those involving large foundation models-memory is inexpensive and abundant, while GPU time constitutes the main cost. This paper re-examines CL under a more realistic setting with sufficient exemplar memory, where the system can retain a representative portion of past data. We find that, under this regime, stability improves due to reduced forgetting, but plasticity diminishes as the model becomes biased toward prior tasks and struggles to adapt to new ones. Notably, even simple baselines like naive replay can match or exceed the performance of state-of-the-art methods at a fraction of the computational cost. Building on this insight, we propose a lightweight yet effective method called Weight Space Consolidation, which directly operates in the model's weight space via two core mechanisms: (1) rank-based parameter resets to recover plasticity, and (2) weight averaging to enhance stability. Our approach outperforms strong baselines across class-incremental learning with image classifiers and continual instruction tuning with large language models, while requiring only one-third to one-fourth of the training cost. These findings challenge long-standing CL assumptions and establish a new, cost-efficient baseline for real-world continual learning systems where exemplar memory is no longer the limiting factor.","authors":["Dongkyu Cho","Taesup Moon","Rumi Chunara","Kyunghyun Cho","Sungmin Cha"],"url":"https://arxiv.org/abs/2502.07274"}
{"created":"2025-05-22","title":"CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction","abstract":"Reasoning is a fundamental capability of Large Language Models. While prior research predominantly focuses on enhancing narrow skills like math or code generation, improving performance on many other reasoning tasks remains challenging due to sparse and fragmented training data. To address this issue, we propose CodeI/O, a novel approach that systematically condenses diverse reasoning patterns inherently embedded in contextually-grounded codes, through transforming the original code into a code input-output prediction format. By training models to predict inputs/outputs given code and test cases entirely in natural language as Chain-of-Thought (CoT) rationales, we expose them to universal reasoning primitives -- like logic flow planning, state-space searching, decision tree traversal, and modular decomposition -- while decoupling structured reasoning from code-specific syntax and preserving procedural rigor. Experimental results demonstrate CodeI/O leads to consistent improvements across symbolic, scientific, logic, math & numerical, and commonsense reasoning tasks. By matching the existing ground-truth outputs or re-executing the code with predicted inputs, we can verify each prediction and further enhance the CoTs through multi-turn revision, resulting in CodeI/O++ and achieving higher performance. Our data and models are available at https://github.com/hkust-nlp/CodeIO.","authors":["Junlong Li","Daya Guo","Dejian Yang","Runxin Xu","Yu Wu","Junxian He"],"url":"https://arxiv.org/abs/2502.07316"}
{"created":"2025-05-22","title":"PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning","abstract":"Predicting future scene representations is a crucial task for enabling robots to understand and interact with the environment. However, most existing methods rely on videos and simulations with precise action annotations, limiting their ability to leverage the large amount of available unlabeled video data. To address this challenge, we propose PlaySlot, an object-centric video prediction model that infers object representations and latent actions from unlabeled video sequences. It then uses these representations to forecast future object states and video frames. PlaySlot allows the generation of multiple possible futures conditioned on latent actions, which can be inferred from video dynamics, provided by a user, or generated by a learned action policy, thus enabling versatile and interpretable world modeling. Our results show that PlaySlot outperforms both stochastic and object-centric baselines for video prediction across different environments. Furthermore, we show that our inferred latent actions can be used to learn robot behaviors sample-efficiently from unlabeled video demonstrations. Videos and code are available on https://play-slot.github.io/PlaySlot/.","authors":["Angel Villar-Corrales","Sven Behnke"],"url":"https://arxiv.org/abs/2502.07600"}
{"created":"2025-05-22","title":"Advancing Autonomous VLM Agents via Variational Subgoal-Conditioned Reinforcement Learning","abstract":"State-of-the-art (SOTA) reinforcement learning (RL) methods have enabled vision-language model (VLM) agents to learn from interaction with online environments without human supervision. However, these methods often struggle with learning inefficiencies when applied to complex, real-world decision-making tasks with sparse rewards and long-horizon dependencies. We propose a novel framework, Variational Subgoal-Conditioned Reinforcement Learning (VSC-RL), advancing the VLM agents in resolving challenging decision-making tasks. Fundamentally distinct from existing methods, VSC-RL reformulates the decision-making problem as a variational subgoal-conditioned RL problem with the newly derived optimization objective, Subgoal Evidence Lower BOund (SGC-ELBO), which comprises two key components: (a) maximizing the subgoal-conditioned return, and (b) minimizing the divergence from a reference goal-conditioned policy. We theoretically and empirically demonstrate that the VSC-RL can efficiently improve the learning efficiency without compromising performance guarantees. Across a diverse set of challenging benchmarks, including mobile device and web control tasks, VSC-RL consistently outperforms existing SOTA methods, achieving superior learning efficiency and performance.","authors":["Qingyuan Wu","Jianheng Liu","Jianye Hao","Jun Wang","Kun Shao"],"url":"https://arxiv.org/abs/2502.07949"}
{"created":"2025-05-22","title":"AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance","abstract":"Character video generation is a significant real-world application focused on producing high-quality videos featuring specific characters. Recent advancements have introduced various control signals to animate static characters, successfully enhancing control over the generation process. However, these methods often lack flexibility, limiting their applicability and making it challenging for users to synthesize a source character into a desired target scene. To address this issue, we propose a novel framework, AnyCharV, that flexibly generates character videos using arbitrary source characters and target scenes, guided by pose information. Our approach involves a two-stage training process. In the first stage, we develop a base model capable of integrating the source character with the target scene using pose guidance. The second stage further bootstraps controllable generation through a self-boosting mechanism, where we use the generated video in the first stage and replace the fine mask with the coarse one, enabling training outcomes with better preservation of character details. Extensive experimental results demonstrate the superiority of our method compared with previous state-of-the-art methods.","authors":["Zhao Wang","Hao Wen","Lingting Zhu","Chenming Shang","Yujiu Yang","Qi Dou"],"url":"https://arxiv.org/abs/2502.08189"}
{"created":"2025-05-22","title":"Optimizing Asynchronous Federated Learning: A~Delicate Trade-Off Between Model-Parameter Staleness and Update Frequency","abstract":"Synchronous federated learning (FL) scales poorly with the number of clients due to the straggler effect. Algorithms like FedAsync and GeneralizedFedAsync address this limitation by enabling asynchronous communication between clients and the central server. In this work, we rely on stochastic modeling and analysis to better understand the impact of design choices in asynchronous FL algorithms, such as the concurrency level and routing probabilities, and we leverage this knowledge to optimize loss. Compared to most existing studies, we account for the joint impact of heterogeneous and variable service speeds and heterogeneous datasets at the clients. We characterize in particular a fundamental trade-off for optimizing asynchronous FL: minimizing gradient estimation errors by avoiding model parameter staleness, while also speeding up the system by increasing the throughput of model updates. Our two main contributions can be summarized as follows. First, we prove a discrete variant of Little's law to derive a closed-form expression for relative delay, a metric that quantifies staleness. This allows us to efficiently minimize the average loss per model update, which has been the gold standard in literature to date. Second, we observe that naively optimizing this metric leads us to slow down the system drastically by overemphazing staleness at the detriment of throughput. This motivates us to introduce an alternative metric that also takes system speed into account, for which we derive a tractable upper-bound that can be minimized numerically. Extensive numerical results show that these optimizations enhance accuracy by 10% to 30%.","authors":["Abdelkrim Alahyane (LAAS-SARA","LAAS)","C\\'eline Comte (CNRS","LAAS-SARA","LAAS)","Matthieu Jonckheere (CNRS","LAAS-SARA","LAAS)","\\'Eric Moulines (X)"],"url":"https://arxiv.org/abs/2502.08206"}
{"created":"2025-05-22","title":"Exploring Neural Granger Causality with xLSTMs: Unveiling Temporal Dependencies in Complex Data","abstract":"Causality in time series can be difficult to determine, especially in the presence of non-linear dependencies. The concept of Granger causality helps analyze potential relationships between variables, thereby offering a method to determine whether one time series can predict - Granger cause - future values of another. Although successful, Granger causal methods still struggle with capturing long-range relations between variables. To this end, we leverage the recently successful Extended Long Short-Term Memory (xLSTM) architecture and propose Granger causal xLSTMs (GC-xLSTM). It first enforces sparsity between the time series components by using a novel dynamic loss penalty on the initial projection. Specifically, we adaptively improve the model and identify sparsity candidates. Our joint optimization procedure then ensures that the Granger causal relations are recovered robustly. Our experimental evaluation on six diverse datasets demonstrates the overall efficacy of our proposed GC-xLSTM model.","authors":["Harsh Poonia","Felix Divo","Kristian Kersting","Devendra Singh Dhami"],"url":"https://arxiv.org/abs/2502.09981"}
{"created":"2025-05-22","title":"Probing Semantic Routing in Large Mixture-of-Expert Models","abstract":"In the past year, large (>100B parameter) mixture-of-expert (MoE) models have become increasingly common in the open domain. While their advantages are often framed in terms of efficiency, prior work has also explored functional differentiation through routing behavior. We investigate whether expert routing in large MoE models is influenced by the semantics of the inputs. To test this, we design two controlled experiments. First, we compare activations on sentence pairs with a shared target word used in the same or different senses. Second, we fix context and substitute the target word with semantically similar or dissimilar alternatives. Comparing expert overlap across these conditions reveals clear, statistically significant evidence of semantic routing in large MoE models.","authors":["Matthew Lyle Olson","Neale Ratzlaff","Musashi Hinck","Man Luo","Sungduk Yu","Chendi Xue","Vasudev Lal"],"url":"https://arxiv.org/abs/2502.10928"}
{"created":"2025-05-22","title":"Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization","abstract":"Rapid advancements in Large Language Models (LLMs) have accelerated their integration into automated visualization code generation applications. Despite advancements through few-shot prompting and query expansion, existing methods remain limited in handling ambiguous and complex queries, thereby requiring manual intervention. To overcome these limitations, we propose VisPath: a Multi-Path Reasoning and Feedback-Driven Optimization Framework for Visualization Code Generation. VisPath handles underspecified queries through structured, multi-stage processing. It begins by reformulating the user input via Chain-of-Thought (CoT) prompting, which refers to the initial query while generating multiple extended queries in parallel, enabling the LLM to capture diverse interpretations of the user intent. These queries then generate candidate visualization scripts, which are executed to produce diverse images. By assessing the visual quality and correctness of each output, VisPath generates targeted feedback that is aggregated to synthesize an optimal final result. Extensive experiments on widely-used benchmarks including MatPlotBench and the Qwen-Agent Code Interpreter Benchmark show that VisPath outperforms state-of-the-art methods, offering a more reliable solution for AI-driven visualization code generation.","authors":["Wonduk Seo","Seungyong Lee","Daye Kang","Hyunjin An","Zonghao Yuan","Seunghyun Lee"],"url":"https://arxiv.org/abs/2502.11140"}
{"created":"2025-05-22","title":"Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning","abstract":"Large language models (LLMs) risk retaining unauthorized or sensitive information from their training data, which raises privacy concerns. LLM unlearning seeks to mitigate these risks by selectively removing specified data while maintaining overall model performance. However, most existing work focus on methods to achieve effective forgetting and does not provide a detailed analysis of the retain set, the portion of training data that is not targeted for removal. In this paper, we investigate the effects of unlearning on various subsets of the retain set through a case study on entity unlearning. We introduce the Syntactically Similar Neighbor Set, a group of queries that share similar syntactic structures with the data targeted for removal, and show that this subset suffers the greatest performance drop during unlearning. Moreover, when used for regularization, this set not only preserves performance on syntactically similar queries but also delivers comparable or improved results across other data subsets. Our results highlight that syntactic similarity is a critical factor, potentially more so than domain or entity relationships, in achieving effective and practical LLM unlearning.","authors":["Hwan Chang","Hwanhee Lee"],"url":"https://arxiv.org/abs/2502.11441"}
{"created":"2025-05-22","title":"GiFT: Gibbs Fine-Tuning for Code Generation","abstract":"Training Large Language Models (LLMs) with synthetic data is a prevalent practice in code generation. A key approach is self-training, where LLMs are iteratively trained on self-generated correct code snippets. In this case, the self-generated codes are drawn from a conditional distribution, conditioned on a specific seed description. However, the seed description is not the only valid representation that aligns with its intended meaning. With all valid descriptions and codes forming a joint space, codes drawn from the conditional distribution would lead to an underrepresentation of the full description-code space. As such, we propose Gibbs Fine-Tuning (GiFT), a novel self-training method inspired by Gibbs sampling. GiFT allows self-generated data to be drawn from the marginal distribution of the joint space, thereby mitigating the biases inherent in conditional sampling. We provide a theoretical analysis demonstrating the potential benefits of fine-tuning LLMs with code derived from the marginal distribution. Furthermore, we propose a perplexity-based code selection method to mitigate the imbalanced long-tail distribution of the self-generated codes. Empirical evaluation of two LLMs across four datasets demonstrates that GiFT achieves superior performance, particularly on more challenging benchmarks. Source code is available at https://github.com/Alex-HaochenLi/GiFT.","authors":["Haochen Li","Wanjin Feng","Xin Zhou","Zhiqi Shen"],"url":"https://arxiv.org/abs/2502.11466"}
{"created":"2025-05-22","title":"GLTW: Joint Improved Graph Transformer and LLM via Three-Word Language for Knowledge Graph Completion","abstract":"Knowledge Graph Completion (KGC), which aims to infer missing or incomplete facts, is a crucial task for KGs. However, integrating the vital structural information of KGs into Large Language Models (LLMs) and outputting predictions deterministically remains challenging. To address this, we propose a new method called GLTW, which encodes the structural information of KGs and merges it with LLMs to enhance KGC performance. Specifically, we introduce an improved Graph Transformer (iGT) that effectively encodes subgraphs with both local and global structural information and inherits the characteristics of language model, bypassing training from scratch. Also, we develop a subgraph-based multi-classification training objective, using all entities within KG as classification objects, to boost learning efficiency.Importantly, we combine iGT with an LLM that takes KG language prompts as input.Our extensive experiments on various KG datasets show that GLTW achieves significant performance gains compared to SOTA baselines.","authors":["Kangyang Luo","Yuzhuo Bai","Cheng Gao","Shuzheng Si","Yingli Shen","Zhu Liu","Zhitong Wang","Cunliang Kong","Wenhao Li","Yufei Huang","Ye Tian","Xuantang Xiong","Lei Han","Maosong Sun"],"url":"https://arxiv.org/abs/2502.11471"}
{"created":"2025-05-22","title":"VRoPE: Rotary Position Embedding for Video Large Language Models","abstract":"Rotary Position Embedding (RoPE) has shown strong performance in text-based Large Language Models (LLMs), but extending it to video remains a challenge due to the intricate spatiotemporal structure of video frames. Existing adaptations, such as RoPE-3D, attempt to encode spatial and temporal dimensions separately but suffer from two major limitations: positional bias in attention distribution and disruptions in video-text transitions. To overcome these issues, we propose Video Rotary Position Embedding (VRoPE), a novel positional encoding method tailored for Video-LLMs. Specifically, we introduce a more balanced encoding strategy that mitigates attention biases, ensuring a more uniform distribution of spatial focus. Additionally, our approach restructures positional indices to ensure a smooth transition between video and text tokens. Extensive experiments on different models demonstrate that VRoPE consistently outperforms previous RoPE variants, achieving significant improvements in video understanding, temporal reasoning, and retrieval tasks. Code will be available at https://github.com/johncaged/VRoPE.","authors":["Zikang Liu","Longteng Guo","Yepeng Tang","Tongtian Yue","Junxian Cai","Kai Ma","Qingbin Liu","Xi Chen","Jing Liu"],"url":"https://arxiv.org/abs/2502.11664"}
{"created":"2025-05-22","title":"SQL-o1: A Self-Reward Heuristic Dynamic Search Method for Text-to-SQL","abstract":"Text-to-SQL (Text2SQL) aims to map natural language questions to executable SQL queries. Although large language models (LLMs) have driven significant progress, current approaches struggle with poor transferability to open-source LLMs, limited robustness against logic and function errors in complex queries, and inefficiencies in structured search. We introduce SQL-o1, a self-reward-driven heuristic search framework built on an agent-based architecture to enhance model reasoning capabilities. SQL-o1 leverages Monte Carlo Tree Search (MCTS) for structured, multi-step exploration, and incorporates a dynamic pruning strategy to accelerate inference without sacrificing accuracy. On the Spider and Bird benchmarks, SQL-o1 achieves a +10.8 execution accuracy improvement on the complex Bird dataset, surpassing even GPT-4-based models. Notably, it exhibits strong few-shot generalization and robust cross-model transferability across open-source LLMs. Our code is available at:https://github.com/ShuaiLyu0110/SQL-o1.","authors":["Shuai Lyu","Haoran Luo","Ripeng Li","Zhonghong Ou","Jiangfeng Sun","Yang Qin","Xiaoran Shang","Meina Song","Yifan Zhu"],"url":"https://arxiv.org/abs/2502.11741"}
{"created":"2025-05-22","title":"LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities","abstract":"Generative models are spearheading recent progress in deep learning, showcasing strong promise for trajectory sampling in dynamical systems as well. However, whereas latent space modeling paradigms have transformed image and video generation, similar approaches are more difficult for most dynamical systems. Such systems -- from chemical molecule structures to collective human behavior -- are described by interactions of entities, making them inherently linked to connectivity patterns, entity conservation, and the traceability of entities over time. Our approach, LaM-SLidE (Latent Space Modeling of Spatial Dynamical Systems via Linked Entities), bridges the gap between: (1) keeping the traceability of individual entities in a latent system representation, and (2) leveraging the efficiency and scalability of recent advances in image and video generation, where pre-trained encoder and decoder enable generative modeling directly in latent space. The core idea of LaM-SLidE is the introduction of identifier representations (IDs) that enable the retrieval of entity properties and entity composition from latent system representations, thus fostering traceability. Experimentally, across different domains, we show that LaM-SLidE performs favorably in terms of speed, accuracy, and generalizability. Code is available at https://github.com/ml-jku/LaM-SLidE .","authors":["Florian Sestak","Artur Toshev","Andreas F\\\"urst","G\\\"unter Klambauer","Andreas Mayr","Johannes Brandstetter"],"url":"https://arxiv.org/abs/2502.12128"}
{"created":"2025-05-22","title":"SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models","abstract":"Deploying large language models (LLMs) in real-world applications requires robust safety guard models to detect and block harmful user prompts. While large safety guard models achieve strong performance, their computational cost is substantial. To mitigate this, smaller distilled models are used, but they often underperform on \"hard\" examples where the larger model provides accurate predictions. We observe that many inputs can be reliably handled by the smaller model, while only a small fraction require the larger model's capacity. Motivated by this, we propose SafeRoute, a binary router that distinguishes hard examples from easy ones. Our method selectively applies the larger safety guard model to the data that the router considers hard, improving efficiency while maintaining accuracy compared to solely using the larger safety guard model. Experimental results on multiple benchmark datasets demonstrate that our adaptive model selection significantly enhances the trade-off between computational cost and safety performance, outperforming relevant baselines.","authors":["Seanie Lee","Dong Bok Lee","Dominik Wagner","Minki Kang","Haebin Seong","Tobias Bocklet","Juho Lee","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2502.12464"}
{"created":"2025-05-22","title":"SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings","abstract":"Multimodal Large Language Models (MLLMs) have serious security vulnerabilities.While safety alignment using multimodal datasets consisting of text and data of additional modalities can effectively enhance MLLM's security, it is costly to construct these datasets. Existing low-resource security alignment methods, including textual alignment, have been found to struggle with the security risks posed by additional modalities. To address this, we propose Synthetic Embedding augmented safety Alignment (SEA), which optimizes embeddings of additional modality through gradient updates to expand textual datasets. This enables multimodal safety alignment training even when only textual data is available. Extensive experiments on image, video, and audio-based MLLMs demonstrate that SEA can synthesize a high-quality embedding on a single RTX3090 GPU within 24 seconds. SEA significantly improves the security of MLLMs when faced with threats from additional modalities. To assess the security risks introduced by video and audio, we also introduced a new benchmark called VA-SafetyBench. High attack success rates across multiple MLLMs validate its challenge. Our code and data will be available at https://github.com/ZeroNLP/SEA.","authors":["Weikai Lu","Hao Peng","Huiping Zhuang","Cen Chen","Ziqian Zeng"],"url":"https://arxiv.org/abs/2502.12562"}
{"created":"2025-05-22","title":"Benchmarking Post-Training Quantization in LLMs: Comprehensive Taxonomy, Unified Evaluation, and Comparative Analysis","abstract":"Post-training Quantization (PTQ) technique has been extensively adopted for large language models (LLMs) compression owing to its efficiency and low resource requirement. However, current research lacks a in-depth analysis of the superior and applicable scenarios of each PTQ strategy. In addition, existing algorithms focus primarily on performance, overlooking the trade-off among model size, performance, and quantization bitwidth. To mitigate these confusions, we provide a novel benchmark for LLMs PTQ in this paper. Firstly, in order to support our benchmark, we propose a comprehensive taxonomy for existing mainstream methods by scrutinizing their computational strategies (e.g., optimization-based, compensation-based, etc.). Then, we conduct extensive experiments with the baseline within each class, covering models with various sizes (7B-70B), bitwidths, training levels (LLaMA1/2/3/3.1), architectures (Mixtral, DeepSeekMoE and Mamba) and modality (LLaVA1.5 and VILA1.5) on a wide range of evaluation metrics.Through comparative analysis on the results, we summarize the superior of each PTQ strategy and modelsize-bitwidth trade-off considering the performance. For example, our benchmark reveals that compensation-based technique demonstrates outstanding cross-architecture robustness and extremely low-bit PTQ for ultra large models should be reexamined. Finally, we further accordingly claim that a practical combination of compensation and other PTQ strategy can achieve SOTA various robustness. We believe that our benchmark will provide valuable recommendations for the deployment of LLMs and future research on PTQ approaches.We conduct an repository for our benchmark at https://github.com/zjq0455/PTQ_Benchmark.","authors":["Jiaqi Zhao","Ming Wang","Miao Zhang","Yuzhang Shang","Xuebo Liu","Yaowei Wang","Min Zhang","Liqiang Nie"],"url":"https://arxiv.org/abs/2502.13178"}
{"created":"2025-05-22","title":"Linguistic Generalizations are not Rules: Impacts on Evaluation of LMs","abstract":"Linguistic evaluations of how well LMs generalize to produce or understand novel text often implicitly take for granted that natural languages are generated by symbolic rules. Grammaticality is thought to be determined by whether sentences obey such rules. Interpretation is believed to be compositionally generated by syntactic rules operating on meaningful words. Semantic parsing is intended to map sentences into formal logic. Failures of LMs to obey strict rules have been taken to reveal that LMs do not produce or understand language like humans. Here we suggest that LMs' failures to obey symbolic rules may be a feature rather than a bug, because natural languages are not based on rules. New utterances are produced and understood by a combination of flexible, interrelated, and context-dependent constructions. We encourage researchers to reimagine appropriate benchmarks and analyses that acknowledge the rich, flexible generalizations that comprise natural languages.","authors":["Leonie Weissweiler","Kyle Mahowald","Adele Goldberg"],"url":"https://arxiv.org/abs/2502.13195"}
{"created":"2025-05-22","title":"FineEdit: Unlock Instruction-Based Text Editing for LLMs","abstract":"Large Language Models (LLMs) have significantly advanced natural language processing, demonstrating strong capabilities in tasks such as text generation, summarization, and reasoning. Recently, their potential for automating precise text editing tasks across specialized domains, such as programming code, LaTeX, and structured database languages, has gained attention. However, current state-of-the-art LLMs still struggle with executing precise, instruction-driven edits, particularly when structural accuracy and strict adherence to domain conventions are required. To address these challenges, we introduce InstrEditBench, an automated benchmark dataset comprising over 30,000 structured editing tasks spanning diverse domains, including Wikipedia articles, LaTeX documents, source code, and database languages. Using this benchmark, we develop FineEdit, a specialized editing model explicitly trained for accurate, context-aware text modifications. Experimental evaluations demonstrate that FineEdit outperforms state-of-the-art models, achieving improvements of approximately 10% over Gemini models on single-turn edits, up to 30% over Llama-3.2-3B, and exceeding Mistral-7B-OpenOrca performance by over 40% on direct editing tasks. FineEdit also effectively generalizes to realistic multi-turn editing scenarios, highlighting its practical applicability.","authors":["Yiming Zeng","Wanhao Yu","Zexin Li","Tao Ren","Yu Ma","Jinghan Cao","Xiyan Chen","Tingting Yu"],"url":"https://arxiv.org/abs/2502.13358"}
{"created":"2025-05-22","title":"Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval","abstract":"The ability to generate SPARQL queries from natural language questions is crucial for ensuring efficient and accurate retrieval of structured data from knowledge graphs (KG). While large language models (LLMs) have been widely adopted for SPARQL query generation, they are often susceptible to hallucinations and out-of-distribution errors when producing KG elements like Uniform Resource Identifiers (URIs) based on internal parametric knowledge. This often results in content that appears plausible but is factually incorrect, posing significant challenges for their use in real-world information retrieval (IR) applications. This has led to increased research aimed at detecting and mitigating such errors. In this paper, we introduce PGMR (Post-Generation Memory Retrieval), a modular framework that incorporates a non-parametric memory module to retrieve KG elements and enhance LLM-based SPARQL query generation. Our experimental results indicate that PGMR consistently delivers strong performance across diverse datasets, data distributions, and LLMs. Notably, PGMR significantly mitigates URI hallucinations, nearly eliminating the problem in several scenarios.","authors":["Aditya Sharma","Luis Lara","Christopher J. Pal","Amal Zouaq"],"url":"https://arxiv.org/abs/2502.13369"}
{"created":"2025-05-22","title":"The rIC3 Hardware Model Checker","abstract":"In this paper, we present rIC3, an efficient bit-level hardware model checker primarily based on the IC3 algorithm. It boasts a highly efficient implementation and integrates several recently proposed optimizations, such as the specifically optimized SAT solver, dynamically adjustment of generalization strategies, and the use of predicates with internal signals, among others. As a first-time participant in the Hardware Model Checking Competition, rIC3 was independently evaluated as the best-performing tool, not only in the bit-level track but also in the word-level bit-vector track through bit-blasting. Our experiments further demonstrate significant advancements in both efficiency and scalability. rIC3 can also serve as a backend for verifying industrial RTL designs using SymbiYosys. Additionally, the source code of rIC3 is highly modular, with the IC3 algorithm module being particularly concise, making it an academic platform that is easy to modify and extend.","authors":["Yuheng Su","Qiusong Yang","Yiwei Ci","Tianjun Bu","Ziyu Huang"],"url":"https://arxiv.org/abs/2502.13605"}
{"created":"2025-05-22","title":"UniKnow: A Unified Framework for Reliable Language Model Behavior across Parametric and External Knowledge","abstract":"Language models often benefit from external knowledge beyond parametric knowledge. While this combination enhances performance, achieving reliable knowledge utilization remains challenging, as it requires assessing the state of each knowledge source based on the presence of relevant information. Yet, prior work on knowledge integration often overlooks this challenge by assuming ideal conditions and provides limited coverage of knowledge scenarios. To address this gap, we introduce UniKnow, a Unified framework for reliable LM behavior across parametric and external Knowledge. UniKnow enables controlled evaluation across knowledge scenarios such as knowledge conflict, distraction, and absence conditions that are rarely addressed together. Beyond evaluating existing methods under this setting, we extend our work by introducing UniKnow-Aware methods to support comprehensive evaluation. Experiments on UniKnow reveal that existing methods struggle to generalize across a broader range of knowledge configurations and exhibit scenario-specific biases. UniKnow thus provides a foundation for systematically exploring and improving reliability under knowledge scenarios.","authors":["Youna Kim","Hyuhng Joon Kim","Minjoon Choi","Sungmin Cho","Hyunsoo Cho","Sang-goo Lee","Taeuk Kim"],"url":"https://arxiv.org/abs/2502.13648"}
{"created":"2025-05-22","title":"Online Envy Minimization and Multicolor Discrepancy: Equivalences and Separations","abstract":"We consider the fundamental problem of allocating $T$ indivisible items that arrive over time to $n$ agents with additive preferences, with the goal of minimizing envy. This problem is tightly connected to online multicolor discrepancy: vectors $v_1, \\dots, v_T \\in \\mathbb{R}^d$ with $\\| v_i \\|_2 \\leq 1$ arrive over time and must be, immediately and irrevocably, assigned to one of $n$ colors to minimize $\\max_{i,j \\in [n]} \\| \\sum_{v \\in S_i} v - \\sum_{v \\in S_j} v \\|_{\\infty}$ at each step, where $S_\\ell$ is the set of vectors that are assigned color $\\ell$. The special case of $n = 2$ is called online vector balancing. Any bound for multicolor discrepancy implies the same bound for envy minimization. Against an adaptive adversary, both problems have the same optimal bound, $\\Theta(\\sqrt{T})$, but whether this holds for weaker adversaries is unknown.","authors":["Daniel Halpern","Alexandros Psomas","Paritosh Verma","Daniel Xie"],"url":"https://arxiv.org/abs/2502.14624"}
{"created":"2025-05-22","title":"Rapid Word Learning Through Meta In-Context Learning","abstract":"Humans can quickly learn a new word from a few illustrative examples, and then systematically and flexibly use it in novel contexts. Yet the abilities of current language models for few-shot word learning, and methods for improving these abilities, are underexplored. In this study, we introduce a novel method, Meta-training for IN-context learNing Of Words (Minnow). This method trains language models to generate new examples of a word's usage given a few in-context examples, using a special placeholder token to represent the new word. This training is repeated on many new words to develop a general word-learning ability. We find that training models from scratch with Minnow on human-scale child-directed language enables strong few-shot word learning, comparable to a large language model (LLM) pre-trained on orders of magnitude more data. Furthermore, through discriminative and generative evaluations, we demonstrate that finetuning pre-trained LLMs with Minnow improves their ability to discriminate between new words, identify syntactic categories of new words, and generate reasonable new usages and definitions for new words, based on one or a few in-context examples. These findings highlight the data efficiency of Minnow and its potential to improve language model performance in word learning tasks.","authors":["Wentao Wang","Guangyuan Jiang","Tal Linzen","Brenden M. Lake"],"url":"https://arxiv.org/abs/2502.14791"}
{"created":"2025-05-22","title":"Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation","abstract":"Reasoning about images with rich text, such as charts and documents, is a critical application of vision-language models (VLMs). However, VLMs often struggle in these domains due to the scarcity of diverse text-rich vision-language data. To address this challenge, we present CoSyn, a framework that leverages the coding capabilities of text-only large language models (LLMs) to automatically create synthetic text-rich multimodal data. Given input text describing a target domain (e.g., \"nutrition fact labels\"), CoSyn prompts an LLM to generate code (Python, HTML, LaTeX, etc.) for rendering synthetic images. With the underlying code as textual representations of the synthetic images, CoSyn can generate high-quality instruction-tuning data, again relying on a text-only LLM. Using CoSyn, we constructed a dataset comprising 400K images and 2.7M rows of vision-language instruction-tuning data. Comprehensive experiments on seven benchmarks demonstrate that models trained on our synthetic data achieve state-of-the-art performance among competitive open-source models, including Llama 3.2, and surpass proprietary models such as GPT-4V and Gemini 1.5 Flash. Furthermore, CoSyn can produce synthetic pointing data, enabling VLMs to ground information within input images, showcasing its potential for developing multimodal agents capable of acting in real-world environments.","authors":["Yue Yang","Ajay Patel","Matt Deitke","Tanmay Gupta","Luca Weihs","Andrew Head","Mark Yatskar","Chris Callison-Burch","Ranjay Krishna","Aniruddha Kembhavi","Christopher Clark"],"url":"https://arxiv.org/abs/2502.14846"}
{"created":"2025-05-22","title":"Sparsity May Be All You Need: Sparse Random Parameter Adaptation","abstract":"Full fine-tuning of large language models for alignment and task adaptation has become prohibitively expensive as models have grown in size. Parameter-Efficient Fine-Tuning (PEFT) methods aim at significantly reducing the computational and memory resources needed for fine-tuning these models by only training on a small number of parameters instead of all model parameters. Currently, the most popular PEFT method is the Low-Rank Adaptation (LoRA), which freezes the parameters of the model to be fine-tuned and introduces a small set of trainable parameters in the form of low-rank matrices. We propose simply reducing the number of trainable parameters by randomly selecting a small proportion of the model parameters to train on. In this paper, we compare the efficiency and performance of our proposed approach with PEFT methods, including LoRA, as well as full parameter fine-tuning.","authors":["Jesus Rios","Pierre Dognin","Ronny Luss","Karthikeyan N. Ramamurthy"],"url":"https://arxiv.org/abs/2502.15975"}
{"created":"2025-05-22","title":"Energy-Efficient Transformer Inference: Optimization Strategies for Time Series Classification","abstract":"The increasing computational demands of transformer models in time series classification necessitate effective optimization strategies for energy-efficient deployment. Our study presents a systematic investigation of optimization techniques, focusing on structured pruning and quantization methods for transformer architectures. Through extensive experimentation on three distinct datasets (RefrigerationDevices, ElectricDevices, and PLAID), we quantitatively evaluate model performance and energy efficiency across different transformer configurations. Our experimental results demonstrate that static quantization reduces energy consumption by 29.14% while maintaining classification performance, and L1 pruning achieves a 63% improvement in inference speed with minimal accuracy degradation. Our findings provide valuable insights into the effectiveness of optimization strategies for transformer-based time series classification, establishing a foundation for efficient model deployment in resource-constrained environments.","authors":["Arshia Kermani","Ehsan Zeraatkar","Habib Irani"],"url":"https://arxiv.org/abs/2502.16627"}
{"created":"2025-05-22","title":"Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization","abstract":"Iterative data generation and model retraining are widely used to align large language models (LLMs). It typically involves a policy model to generate on-policy responses and a reward model to guide training data selection. Direct Preference Optimization (DPO) further enhances this process by constructing preference pairs of chosen and rejected responses. In this work, we aim to \\emph{scale up} the number of on-policy samples via repeated random sampling to improve alignment performance. Conventional practice selects the sample with the highest reward as chosen and the lowest as rejected for DPO. However, our experiments reveal that this strategy leads to a \\emph{decline} in performance as the sample size increases. To address this, we investigate preference data construction through the lens of underlying normal distribution of sample rewards. We categorize the reward space into seven representative points and systematically explore all 21 ($C_7^2$) pairwise combinations. Through evaluations on four models using AlpacaEval 2, we find that selecting the rejected response at reward position $\\mu - 2\\sigma$ rather than the minimum reward, is crucial for optimal performance. We finally introduce a scalable preference data construction strategy that consistently enhances model performance as the sample scale increases.","authors":["Yao Xiao","Hai Ye","Linyao Chen","Hwee Tou Ng","Lidong Bing","Xiaoli Li","Roy Ka-wei Lee"],"url":"https://arxiv.org/abs/2502.16825"}
{"created":"2025-05-22","title":"Distributional Vision-Language Alignment by Cauchy-Schwarz Divergence","abstract":"Multimodal alignment is crucial for various downstream tasks such as cross-modal generation and retrieval. Previous multimodal approaches like CLIP utilize InfoNCE to maximize mutual information, primarily aligning pairwise samples across modalities while overlooking distributional differences. In addition, InfoNCE has inherent conflict in terms of alignment and uniformity in multimodality, leading to suboptimal alignment with modality gaps. To overcome the limitations, we propose CS-Aligner, a novel framework that performs distributional vision-language alignment by integrating Cauchy-Schwarz (CS) divergence with mutual information. CS-Aligner captures both the global distribution information of each modality and the pairwise semantic relationships. We find that the CS divergence seamlessly addresses the InfoNCE's alignment-uniformity conflict and serves complementary roles with InfoNCE, yielding tighter and more precise alignment. Moreover, by introducing distributional alignment, CS-Aligner enables incorporating additional information from unpaired data and token-level representations, enhancing flexible and fine-grained alignment in practice. Experiments on text-to-image generation and cross-modality retrieval tasks demonstrate the effectiveness of our method on vision-language alignment.","authors":["Wenzhe Yin","Zehao Xiao","Pan Zhou","Shujian Yu","Jiayi Shen","Jan-Jakob Sonke","Efstratios Gavves"],"url":"https://arxiv.org/abs/2502.17028"}
{"created":"2025-05-22","title":"Intermediate Languages Matter: Formal Choice Drives Neurosymbolic LLM Reasoning","abstract":"Large language models (LLMs) achieve astonishing results on a wide range of tasks. However, their formal reasoning ability still lags behind. A promising approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators from natural to formal languages and symbolic solvers for deriving correct results. Still, it remains unclear what the contributing factors to the success of Neurosymbolic LLM reasoning are. This paper shows that one important factor is the choice of the formal language. By comparing 4 formal languages on 3 datasets over 6 LLMs, we show that the choice of formal language affects both the syntactic and the semantic reasoning capability. Thereby, we introduce the intermediate language challenge, which is the challenge of picking a suitable formal language for neurosymbolic reasoning. Further, we compare the effects of using different in-context-learning examples in an ablation study. We conclude that on average, context-aware encodings help LLMs to reason, while there is no apparent effect of using comments or markdown syntax.","authors":["Alexander Beiser","David Penz","Nysret Musliu"],"url":"https://arxiv.org/abs/2502.17216"}
{"created":"2025-05-22","title":"Large Language Models are Powerful Electronic Health Record Encoders","abstract":"Electronic Health Records (EHRs) offer considerable potential for clinical prediction, but their complexity and heterogeneity present significant challenges for traditional machine learning methods. Recently, domain-specific EHR foundation models trained on large volumes of unlabeled EHR data have shown improved predictive accuracy and generalization. However, their development is constrained by limited access to diverse, high-quality datasets, and by inconsistencies in coding standards and clinical practices. In this study, we explore the use of general-purpose Large Language Models (LLMs) to encode EHR into high-dimensional representations for downstream clinical prediction tasks. We convert structured EHR data into markdown-formatted plain text documents by replacing medical codes with natural language descriptions. This enables the use of LLMs and their extensive semantic understanding and generalization capabilities as effective encoders of EHRs without requiring access to private medical training data. We show that LLM-based embeddings can often match or even surpass the performance of a specialized EHR foundation model, CLMBR-T-Base, across 15 diverse clinical tasks from the EHRSHOT benchmark. To demonstrate generalizability, we further evaluate the approach on the UK Biobank (UKB) cohort, a population distinct from that used to train CLMBR-T-Base. Notably, one of the tested LLM-based models achieves superior performance for disease onset, hospitalization, and mortality prediction, highlighting robustness to shifts in patient populations. Our findings suggest that repurposed general-purpose LLMs for EHR encoding provide a scalable and generalizable alternative to domain-specific models for clinical prediction.","authors":["Stefan Hegselmann","Georg von Arnim","Tillmann Rheude","Noel Kronenberg","David Sontag","Gerhard Hindricks","Roland Eils","Benjamin Wild"],"url":"https://arxiv.org/abs/2502.17403"}
{"created":"2025-05-22","title":"CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation","abstract":"While 3D instance segmentation (3DIS) has advanced significantly, existing methods typically assume that all object classes are known in advance and are uniformly distributed. However, this assumption is unrealistic in dynamic, real-world environments where new classes emerge gradually and exhibit natural imbalance. Although some approaches have addressed class emergence, they often overlook class imbalance, resulting in suboptimal performance -- particularly on rare categories. To tackle this challenge, we propose CLIMB-3D, a unified framework for \\textbf{CL}ass-incremental \\textbf{Imb}alance-aware \\textbf{3D}IS. Building upon established exemplar replay (ER) strategies, we show that ER alone is insufficient to achieve robust performance under constrained memory conditions. To mitigate this, we introduce a novel pseudo-label generator (PLG) that extends supervision to previously learned categories by leveraging predictions from a frozen prior model. Despite its promise, PLG tends to bias towards frequent classes. Therefore, we propose a class-balanced re-weighting (CBR) scheme, that estimates object frequencies from pseudo-labels and dynamically adjusts training bias -- without requiring access to past data. We design and evaluate three incremental scenarios for 3DIS on the challenging ScanNet200 dataset, and additionally on semantic segmentation on ScanNetV2. Our approach achieves state-of-the-art results, surpassing prior work by up to 16.76\\% mAP for instance segmentation and approximately 30\\% mIoU for semantic segmentation, demonstrating strong generalization across both frequent and rare classes.","authors":["Vishal Thengane","Jean Lahoud","Hisham Cholakkal","Rao Muhammad Anwer","Lu Yin","Xiatian Zhu","Salman Khan"],"url":"https://arxiv.org/abs/2502.17429"}
{"created":"2025-05-22","title":"Spontaneous Giving and Calculated Greed in Language Models","abstract":"Large language models demonstrate strong problem-solving abilities through reasoning techniques such as chain-of-thought prompting and reflection. However, it remains unclear whether these reasoning capabilities extend to a form of social intelligence: making effective decisions in cooperative contexts. We examine this question using economic games that simulate social dilemmas. First, we apply chain-of-thought and reflection prompting to GPT-4o in a Public Goods Game. We then evaluate multiple off-the-shelf models across six cooperation and punishment games, comparing those with and without explicit reasoning mechanisms. We find that reasoning models consistently reduce cooperation and norm enforcement, favoring individual rationality. In repeated interactions, groups with more reasoning agents exhibit lower collective gains. These behaviors mirror human patterns of \"spontaneous giving and calculated greed.\" Our findings underscore the need for LLM architectures that incorporate social intelligence alongside reasoning, to help address--rather than reinforce--the challenges of collective action.","authors":["Yuxuan Li","Hirokazu Shirado"],"url":"https://arxiv.org/abs/2502.17720"}
{"created":"2025-05-22","title":"OpenFly: A Comprehensive Platform for Aerial Vision-Language Navigation","abstract":"Vision-Language Navigation (VLN) aims to guide agents by leveraging language instructions and visual cues, playing a pivotal role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial view encompasses vast areas, making data collection more challenging, which results in a lack of benchmarks. To address this problem, we propose OpenFly, a platform comprising various rendering engines, a versatile toolchain, and a large-scale benchmark for aerial VLN. Firstly, we integrate diverse rendering engines and advanced techniques for environment simulation, including Unreal Engine, GTA V, Google Earth, and 3D Gaussian Splatting (3D GS). Particularly, 3D GS supports real-to-sim rendering, further enhancing the realism of our environments. Secondly, we develop a highly automated toolchain for aerial VLN data collection, streamlining point cloud acquisition, scene semantic segmentation, flight trajectory creation, and instruction generation. Thirdly, based on the toolchain, we construct a large-scale aerial VLN dataset with 100k trajectories, covering diverse heights and lengths across 18 scenes. Moreover, we propose OpenFly-Agent, a keyframe-aware VLN model emphasizing key observations during flight. For benchmarking, extensive experiments and analyses are conducted, evaluating several recent VLN methods and showcasing the superiority of our OpenFly platform and agent. The toolchain, dataset, and codes will be open-sourced.","authors":["Yunpeng Gao","Chenhui Li","Zhongrui You","Junli Liu","Zhen Li","Pengan Chen","Qizhi Chen","Zhonghan Tang","Liansheng Wang","Penghui Yang","Yiwen Tang","Yuhang Tang","Shuai Liang","Songyi Zhu","Ziqin Xiong","Yifei Su","Xinyi Ye","Jianan Li","Yan Ding","Dong Wang","Zhigang Wang","Bin Zhao","Xuelong Li"],"url":"https://arxiv.org/abs/2502.18041"}
{"created":"2025-05-22","title":"ZEBRA: Leveraging Model-Behavioral Knowledge for Zero-Annotation Preference Dataset Construction","abstract":"Recent efforts in LLM alignment have focused on constructing large-scale preference datasets via human or Artificial Intelligence (AI) annotators. However, such approaches rely on instance-wise supervision, incurring substantial annotation cost and limited interpretability. In this paper, we propose ZEBRA - a model behavior-wise zero-annotation framework that constructs preference data by leveraging model behavior knowledge derived from benchmark performances. ZEBRA binarizes response pairs by evaluating the quality and similarity of their origin models, entirely bypassing instance-level annotation. This allows scalable, controllable, and cost-effective alignment data generation. Empirical results show that ZEBRA achieves alignment performance comparable to instance-supervised methods, despite requiring no manual or model-based labeling.","authors":["Jeesu Jung","Chanjun Park","Sangkeun Jung"],"url":"https://arxiv.org/abs/2502.18744"}
{"created":"2025-05-22","title":"Stay Focused: Problem Drift in Multi-Agent Debate","abstract":"Multi-agent debate - multiple instances of large language models discussing problems in turn-based interaction - has shown promise for solving knowledge and reasoning tasks. However, these methods show limitations when solving complex problems that require longer reasoning chains. We analyze how multi-agent debate over multiple turns drifts away from the initial problem, thus harming task performance. We define this phenomenon as problem drift and quantify its presence across ten tasks (i.e., three generative, three knowledge, three reasoning, and one instruction-following task). To identify the reasons for this issue, eight human experts analyze 170 multi-agent discussions suffering from problem drift. We find the most common issues related to this drift are the lack of progress (35% of cases), low-quality feedback (26% of cases), and a lack of clarity (25% of cases). To address problem drift, we propose DRIFTJudge, an LLM-as-a-judge method, to detect problem drift at test-time. We also propose DRIFTPolicy, a method that mitigates problem drift cases to improve task performance. Our study is a step toward understanding a key limitation of multi-agent debate, highlighting why longer debates can harm task performance and how problem drift could be addressed.","authors":["Jonas Becker","Lars Benedikt Kaesberg","Andreas Stephan","Jan Philip Wahle","Terry Ruas","Bela Gipp"],"url":"https://arxiv.org/abs/2502.19559"}
{"created":"2025-05-22","title":"Sensing and Steering Stereotypes: Extracting and Applying Gender Representation Vectors in LLMs","abstract":"Large language models (LLMs) are known to perpetuate stereotypes and exhibit biases. Various strategies have been proposed to mitigate these biases, but most work studies biases in LLMs as a black-box problem without considering how concepts are represented within the model. We adapt techniques from representation engineering to study how the concept of \"gender\" is represented within LLMs. We introduce a new method that extracts concept representations via probability weighting without labeled data and efficiently selects a steering vector for measuring and manipulating the model's representation. We also present a projection-based method that enables precise steering of model predictions and demonstrate its effectiveness in mitigating gender bias in LLMs. Our code is available at: https://github.com/hannahxchen/gender-bias-steering","authors":["Hannah Cyberey","Yangfeng Ji","David Evans"],"url":"https://arxiv.org/abs/2502.19721"}
{"created":"2025-05-22","title":"SPD: Sync-Point Drop for efficient tensor parallelism of Large Language Models","abstract":"With the rapid expansion in the scale of large language models (LLMs), enabling efficient distributed inference across multiple computing units has become increasingly critical. However, communication overheads from popular distributed inference techniques such as Tensor Parallelism pose a significant challenge to achieve scalability and low latency. Therefore, we introduce a novel optimization technique, Sync-Point Drop (SPD), to reduce communication overheads in tensor parallelism by selectively dropping synchronization on attention outputs. In detail, we first propose a block design that allows execution to proceed without communication through SPD. Second, we apply different SPD strategies to attention blocks based on their sensitivity to the model accuracy. The proposed methods effectively alleviate communication bottlenecks while minimizing accuracy degradation during LLM inference, offering a scalable solution for diverse distributed environments: SPD offered about 20% overall inference latency reduction with < 1% accuracy regression for LLaMA2-70B inference over 8 GPUs.","authors":["Han-Byul Kim","Duc Hoang","Arnav Kundu","Mohammad Samragh","Minsik Cho"],"url":"https://arxiv.org/abs/2502.20727"}
{"created":"2025-05-22","title":"MV-MATH: Evaluating Multimodal Math Reasoning in Multi-Visual Contexts","abstract":"Multimodal Large Language Models (MLLMs) have shown promising capabilities in mathematical reasoning within visual contexts across various datasets. However, most existing multimodal math benchmarks are limited to single-visual contexts, which diverges from the multi-visual scenarios commonly encountered in real-world mathematical applications. To address this gap, we introduce MV-MATH: a meticulously curated dataset of 2,009 high-quality mathematical problems. Each problem integrates multiple images interleaved with text, derived from authentic K-12 scenarios, and enriched with detailed annotations. MV-MATH includes multiple-choice, free-form, and multi-step questions, covering 11 subject areas across 3 difficulty levels, and serves as a comprehensive and rigorous benchmark for assessing MLLMs' mathematical reasoning in multi-visual contexts. Through extensive experimentation, we observe that MLLMs encounter substantial challenges in multi-visual math tasks, with a considerable performance gap relative to human capabilities on MV-MATH. Furthermore, we analyze the performance and error patterns of various models, providing insights into MLLMs' mathematical reasoning capabilities within multi-visual settings.","authors":["Peijie Wang","Zhong-Zhi Li","Fei Yin","Xin Yang","Dekang Ran","Cheng-Lin Liu"],"url":"https://arxiv.org/abs/2502.20808"}
{"created":"2025-05-22","title":"Variations in Relevance Judgments and the Shelf Life of Test Collections","abstract":"The fundamental property of Cranfield-style evaluations, that system rankings are stable even when assessors disagree on individual relevance decisions, was validated on traditional test collections. However, the paradigm shift towards neural retrieval models affected the characteristics of modern test collections, e.g., documents are short, judged with four grades of relevance, and information needs have no descriptions or narratives. Under these changes, it is unclear whether assessor disagreement remains negligible for system comparisons. We investigate this aspect under the additional condition that the few modern test collections are heavily re-used. Given more possible query interpretations due to less formalized information needs, an ``expiration date'' for test collections might be needed if top-effectiveness requires overfitting to a single interpretation of relevance. We run a reproducibility study and re-annotate the relevance judgments of the 2019~TREC Deep Learning track. We can reproduce prior work in the neural retrieval setting, showing that assessor disagreement does not affect system rankings. However, we observe that some models substantially degrade with our new relevance judgments, and some have already reached the effectiveness of humans as rankers, providing evidence that test collections can expire.","authors":["Andrew Parry","Maik Fr\\\"obe","Harrisen Scells","Ferdinand Schlatt","Guglielmo Faggioli","Saber Zerhoudi","Sean MacAvaney","Eugene Yang"],"url":"https://arxiv.org/abs/2502.20937"}
{"created":"2025-05-22","title":"How far can we go with ImageNet for Text-to-Image generation?","abstract":"Recent text-to-image generation models have achieved remarkable results by training on billion-scale datasets, following a `bigger is better' paradigm that prioritizes data quantity over availability (closed vs open source) and reproducibility (data decay vs established collections). We challenge this established paradigm by demonstrating that one can match or outperform models trained on massive web-scraped collections, using only ImageNet enhanced with well-designed text and image augmentations. With this much simpler setup, we achieve a +1% overall score over SD-XL on GenEval and +0.5% on DPGBench while using just 1/10th the parameters and 1/1000th the training images. This opens the way for more reproducible research as ImageNet is a widely available dataset and our standardized training setup does not require massive compute resources.","authors":["L. Degeorge","A. Ghosh","N. Dufour","D. Picard","V. Kalogeiton"],"url":"https://arxiv.org/abs/2502.21318"}
{"created":"2025-05-22","title":"Investigating and Enhancing Vision-Audio Capability in Omnimodal Large Language Models","abstract":"Omnimodal Large Language Models (OLLMs) have shown significant progress in integrating vision and text, but still struggle with integrating vision and audio, often exhibiting suboptimal performance when processing audio queries compared to text queries. This disparity is primarily due to insufficient alignment between vision and audio modalities during training, leading to inadequate attention to visual information when using audio queries. To mitigate this issue, we propose a Self-Knowledge Distillation (Self-KD) training method where the vision-text component of the OLLM serves as the teacher and the vision-audio component as the student. This enables the model to process audio in a manner analogous to its text processing. Our experimental results demonstrate that Self-KD is an effective method for enhancing the vision-audio capabilities of OLLMs by learning from the vision-text components, which subsequently improves the interaction between audio and images and results in improved performance on multimodal tasks.","authors":["Rui Hu","Delai Qiu","Shuyu Wei","Jiaming Zhang","Yining Wang","Shengping Liu","Jitao Sang"],"url":"https://arxiv.org/abs/2503.00059"}
{"created":"2025-05-22","title":"Adaptive Reinforcement Learning for State Avoidance in Discrete Event Systems","abstract":"Reinforcement learning (RL) has emerged as a potent paradigm for autonomous decision-making in complex environments. However, the integration of event-driven decision processes within RL remains a challenge. This paper presents a novel architecture that combines a Discrete Event Supervisory (DES) model with a standard RL framework to create a hybrid decision-making system. Our model leverages the DES's capabilities in managing event-based dynamics with the RL agent's adaptability to continuous states and actions, facilitating a more robust and flexible control strategy in systems characterized by both continuous and discrete events. The DES model operates alongside the RL agent, enhancing the policy's performance with event-based insights, while the environment's state transitions are governed by a mechanistic model. We demonstrate the efficacy of our approach through simulations that show improved performance metrics over traditional RL implementations. Our results suggest that this integrated approach holds promise for applications ranging from industrial automation to intelligent traffic systems, where discrete event handling is paramount.","authors":["Md Nur-A-Adam Dony"],"url":"https://arxiv.org/abs/2503.00192"}
{"created":"2025-05-22","title":"Adaptively profiling models with task elicitation","abstract":"Language model evaluations often fail to characterize consequential failure modes, forcing experts to inspect outputs and build new benchmarks. We introduce task elicitation, a method that automatically builds new evaluations to profile model behavior. Task elicitation finds hundreds of natural-language tasks -- an order of magnitude more than prior work -- where frontier models exhibit systematic failures, in domains ranging from forecasting to online harassment. For example, we find that Sonnet 3.5 over-associates quantum computing and AGI and that o3-mini is prone to hallucination when fabrications are repeated in-context.","authors":["Davis Brown","Prithvi Balehannina","Helen Jin","Shreya Havaldar","Hamed Hassani","Eric Wong"],"url":"https://arxiv.org/abs/2503.01986"}
{"created":"2025-05-22","title":"Teaching Metric Distance to Autoregressive Multimodal Foundational Models","abstract":"As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregressive discrete models by leveraging predefined distance relationships among output tokens. At its core, DIST2Loss transforms continuous exponential family distributions derived from inherent distance metrics into discrete, categorical optimization targets compatible with the models' architectures. This approach enables the models to learn and preserve meaningful distance relationships during token generation while maintaining compatibility with existing architectures. Empirical evaluations show consistent performance gains in diverse multimodal applications, including visual grounding, robotic manipulation, generative reward modeling, and image generation using vector-quantized features. These improvements are most notable in low-data regimes, demonstrating DIST2Loss's strength under resource constraints.","authors":["Jiwan Chung","Saejin Kim","Yongrae Jo","Jaewoo Park","Dongjun Min","Youngjae Yu"],"url":"https://arxiv.org/abs/2503.02379"}
{"created":"2025-05-22","title":"Scaling Laws for Many-Shot In-Context Learning with Self-Generated Annotations","abstract":"The high cost of obtaining high-quality annotated data for in-context learning (ICL) has motivated the development of methods that use self-generated annotations in place of ground-truth labels. While these approaches have shown promising results in few-shot settings, they generally do not scale to many-shot scenarios. In this work, we study ICL with self-generated examples using a framework analogous to traditional semi-supervised learning, consisting of annotation generation, demonstration selection, and in-context inference. Within this framework, we propose a simple baseline that outperforms ground-truth ICL in zero-shot, few-shot, and many-shot settings. Notably, we observe a scaling law with this baseline, where optimal performance is achieved with more than 1,000 demonstrations. To fully exploit the many-shot capabilities of semi-supervised ICL, we introduce IterPSD, an iterative annotation approach that integrates iterative refinement and curriculum pseudo-labeling techniques from semi-supervised learning, yielding up to 6.8% additional gains on classification tasks.","authors":["Zhengyao Gu","Henry Peng Zou","Yankai Chen","Aiwei Liu","Weizhi Zhang","Philip S. Yu"],"url":"https://arxiv.org/abs/2503.03062"}
{"created":"2025-05-22","title":"The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models","abstract":"Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language Models (LLMs) with human preferences, particularly as LLMs increasingly interact with multimodal data. However, we find that MM-RMs trained on existing datasets often struggle to generalize to out-of-distribution data due to their reliance on unimodal spurious correlations, primarily text-only shortcuts within the training distribution, which prevents them from leveraging true multimodal reward functions. To address this, we introduce a Shortcut-aware MM-RM learning algorithm that mitigates this issue by dynamically reweighting training samples, shifting the distribution toward better multimodal understanding, and reducing dependence on unimodal spurious correlations. Our experiments demonstrate significant improvements in generalization, downstream task performance, and scalability, establishing a more robust framework for multimodal reward modeling.","authors":["Zichao Li","Xueru Wen","Jie Lou","Yuqiu Ji","Yaojie Lu","Xianpei Han","Debing Zhang","Le Sun"],"url":"https://arxiv.org/abs/2503.03122"}
{"created":"2025-05-22","title":"Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining","abstract":"The impressive capabilities of Large Language Models (LLMs) across diverse tasks are now well-established, yet their effective deployment necessitates careful hyperparameter optimization. Through extensive empirical studies involving grid searches across diverse configurations, we discover universal scaling laws governing these hyperparameters: optimal learning rate follows a power-law relationship with both model parameters and data sizes, while optimal batch size scales primarily with data sizes. Our analysis reveals a convex optimization landscape for hyperparameters under fixed models and data size conditions. This convexity implies an optimal hyperparameter plateau. We contribute a universal, plug-and-play optimal hyperparameter tool for the community. Its estimated values on the test set are merely 0.09% away from the globally optimal LLM performance found via an exhaustive search. These laws demonstrate remarkable robustness across variations in model sparsity, training data distribution, and model shape. To our best known, this is the first work that unifies different model shapes and structures, such as Mixture-of-Experts models and dense transformers, as well as establishes optimal hyperparameter scaling laws across diverse data distributions. This exhaustive optimization process demands substantial computational resources, utilizing nearly one million NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and hyperparameters from scratch and consuming approximately 100 trillion tokens in total. To facilitate reproducibility and further research, we will progressively release all loss measurements and model checkpoints through our designated repository https://step-law.github.io/","authors":["Houyi Li","Wenzhen Zheng","Qiufeng Wang","Hanshan Zhang","Zili Wang","Shijie Xuyang","Yuantao Fan","Shuigeng Zhou","Xiangyu Zhang","Daxin Jiang"],"url":"https://arxiv.org/abs/2503.04715"}
{"created":"2025-05-22","title":"DB-Explore: Automated Database Exploration and Instruction Synthesis for Text-to-SQL","abstract":"Recent text-to-SQL systems powered by large language models (LLMs) have demonstrated remarkable performance in translating natural language queries into SQL. However, these systems often struggle with complex database structures and domain-specific queries, as they primarily focus on enhancing logical reasoning and SQL syntax while overlooking the critical need for comprehensive database understanding. To address this limitation, we propose DB-Explore, a novel framework that systematically aligns LLMs with database knowledge through automated exploration and instruction synthesis. DB-Explore constructs database graphs to capture complex relational schemas, leverages GPT-4 to systematically mine structural patterns and semantic knowledge, and synthesizes instructions to distill this knowledge for efficient fine-tuning of LLMs. Our framework enables comprehensive database understanding through diverse sampling strategies and automated instruction generation, bridging the gap between database structures and language models. Experiments conducted on the SPIDER and BIRD benchmarks validate the effectiveness of DB-Explore, achieving an execution accuracy of 67.0% on BIRD and 87.8% on SPIDER. Notably, our open-source implementation based on Qwen2.5-Coder-7B achieves state-of-the-art results at minimal computational cost, outperforming several GPT-4-driven Text-to-SQL systems.","authors":["Haoyuan Ma","Yongliang Shen","Hengwei Liu","Wenqi Zhang","Haolei Xu","Qiuying Peng","Jun Wang","Weiming Lu"],"url":"https://arxiv.org/abs/2503.04959"}
{"created":"2025-05-22","title":"Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching","abstract":"Recent advances in large language models (LLMs) have enabled strong reasoning capabilities through Chain-of-Thought (CoT) prompting, which elicits step-by-step problem solving, but often at the cost of excessive verbosity in intermediate outputs, leading to increased computational overhead. We propose Sketch-of-Thought (SoT), a prompting framework that integrates cognitively inspired reasoning paradigms with linguistic constraints to reduce token usage while preserving reasoning accuracy. SoT is designed as a flexible, modular approach and is instantiated with three paradigms--Conceptual Chaining, Chunked Symbolism, and Expert Lexicons--each tailored to distinct reasoning tasks and selected dynamically at test-time by a lightweight routing model. Across 15 reasoning datasets spanning multiple domains, languages, and modalities, SoT achieves token reductions of up to 78% with minimal accuracy loss. In tasks such as mathematical and multi-hop reasoning, it even improves accuracy while shortening outputs.","authors":["Simon A. Aytes","Jinheon Baek","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2503.05179"}
{"created":"2025-05-22","title":"Large Language Models Post-training: Surveying Techniques from Alignment to Reasoning","abstract":"The emergence of Large Language Models (LLMs) has fundamentally transformed natural language processing, making them indispensable across domains ranging from conversational systems to scientific exploration. However, their pre-trained architectures often reveal limitations in specialized contexts, including restricted reasoning capacities, ethical uncertainties, and suboptimal domain-specific performance. These challenges necessitate advanced post-training language models (PoLMs) to address these shortcomings, such as OpenAI-o1/o3 and DeepSeek-R1 (collectively known as Large Reasoning Models, or LRMs). This paper presents the first comprehensive survey of PoLMs, systematically tracing their evolution across five core paradigms: Fine-tuning, which enhances task-specific accuracy; Alignment, which ensures ethical coherence and alignment with human preferences; Reasoning, which advances multi-step inference despite challenges in reward design; Efficiency, which optimizes resource utilization amidst increasing complexity; Integration and Adaptation, which extend capabilities across diverse modalities while addressing coherence issues. Charting progress from ChatGPT's alignment strategies to DeepSeek-R1's innovative reasoning advancements, we illustrate how PoLMs leverage datasets to mitigate biases, deepen reasoning capabilities, and enhance domain adaptability. Our contributions include a pioneering synthesis of PoLM evolution, a structured taxonomy categorizing techniques and datasets, and a strategic agenda emphasizing the role of LRMs in improving reasoning proficiency and domain flexibility. As the first survey of its scope, this work consolidates recent PoLM advancements and establishes a rigorous intellectual framework for future research, fostering the development of LLMs that excel in precision, ethical robustness, and versatility across scientific and societal applications.","authors":["Guiyao Tie","Zeli Zhao","Dingjie Song","Fuyang Wei","Rong Zhou","Yurou Dai","Wen Yin","Zhejian Yang","Jiangyue Yan","Yao Su","Zhenhan Dai","Yifeng Xie","Yihan Cao","Lichao Sun","Pan Zhou","Lifang He","Hechang Chen","Yu Zhang","Qingsong Wen","Tianming Liu","Neil Zhenqiang Gong","Jiliang Tang","Caiming Xiong","Heng Ji","Philip S. Yu","Jianfeng Gao"],"url":"https://arxiv.org/abs/2503.06072"}
{"created":"2025-05-22","title":"MambaFlow: A Mamba-Centric Architecture for End-to-End Optical Flow Estimation","abstract":"Recently, the Mamba architecture has demonstrated significant successes in various computer vision tasks, such as classification and segmentation. However, its application to optical flow estimation remains unexplored. In this paper, we introduce MambaFlow, a novel framework designed to leverage the high accuracy and efficiency of the Mamba architecture for capturing locally correlated features while preserving global information in end-to-end optical flow estimation. To our knowledge, MambaFlow is the first architecture centered around the Mamba design tailored specifically for optical flow estimation. It comprises two key components: (1) PolyMamba, which optimizes feature representation; and (2) PulseMamba, which facilitates efficient flow information dissemination. Our extensive experiments demonstrate that MambaFlow achieves remarkable results. On the Sintel benchmark, MambaFlow records an endpoint error (EPE) of 1.43 and an inference speed of 0.113 seconds, surpassing the state-of-the-art methods including GMFlow (with 18.9% lower EPE and 18.1% faster inference), SeparableFlow (5% lower EPE and 50.5% faster), CRAFT (1.11% lower EPE and 76.5% faster), and DIP (0.7% lower EPE and 77.2% faster)-demonstrating stronger potential for real-world deployment on resource-constrained devices. The source code will be made publicly available upon acceptance of the paper.","authors":["Juntian Du","Yuan Sun","Zhihu Zhou","Pinyi Chen","Runzhe Zhang","Keji Mao"],"url":"https://arxiv.org/abs/2503.07046"}
{"created":"2025-05-22","title":"Multi-Robot System for Cooperative Exploration in Unknown Environments: A Survey","abstract":"With the real need of field exploration in large-scale and extreme outdoor environments, cooperative exploration tasks have garnered increasing attention. This paper presents a comprehensive review of multi-robot cooperative exploration systems. First, we review the evolution of robotic exploration and introduce a modular research framework tailored for multi-robot cooperative exploration. Based on this framework, we systematically categorize and summarize key system components. As a foundational module for multi-robot exploration, the localization and mapping module is primarily introduced by focusing on global and relative pose estimation, as well as multi-robot map merging techniques. The cooperative motion module is further divided into learning-based approaches and multi-stage planning, with the latter encompassing target generation, task allocation, and motion planning strategies. Given the communication constraints of real-world environments, we also analyze the communication module, emphasizing how robots exchange information within local communication ranges and under limited transmission capabilities. In addition, we introduce the actual application of multi-robot cooperative exploration systems in DARPA SubT Challenge. Finally, we discuss the challenges and future research directions for multi-robot cooperative exploration in light of real-world trends. This review aims to serve as a valuable reference for researchers and practitioners in the field.","authors":["Chuqi Wang","Chao Yu","Xin Xu","Yuman Gao","Xinyi Yang","Wenhao Tang","Shu'ang Yu","Yinuo Chen","Feng Gao","ZhuoZhu Jian","Xinlei Chen","Fei Gao","Boyu Zhou","Yu Wang"],"url":"https://arxiv.org/abs/2503.07278"}
{"created":"2025-05-22","title":"Denoising Score Distillation: From Noisy Diffusion Pretraining to One-Step High-Quality Generation","abstract":"Diffusion models have achieved remarkable success in generating high-resolution, realistic images across diverse natural distributions. However, their performance heavily relies on high-quality training data, making it challenging to learn meaningful distributions from corrupted samples. This limitation restricts their applicability in scientific domains where clean data is scarce or costly to obtain. In this work, we introduce denoising score distillation (DSD), a surprisingly effective and novel approach for training high-quality generative models from low-quality data. DSD first pretrains a diffusion model exclusively on noisy, corrupted samples and then distills it into a one-step generator capable of producing refined, clean outputs. While score distillation is traditionally viewed as a method to accelerate diffusion models, we show that it can also significantly enhance sample quality, particularly when starting from a degraded teacher model. Across varying noise levels and datasets, DSD consistently improves generative performancewe summarize our empirical evidence in Fig. 1. Furthermore, we provide theoretical insights showing that, in a linear model setting, DSD identifies the eigenspace of the clean data distributions covariance matrix, implicitly regularizing the generator. This perspective reframes score distillation as not only a tool for efficiency but also a mechanism for improving generative models, particularly in low-quality data settings.","authors":["Tianyu Chen","Yasi Zhang","Zhendong Wang","Ying Nian Wu","Oscar Leong","Mingyuan Zhou"],"url":"https://arxiv.org/abs/2503.07578"}
{"created":"2025-05-22","title":"SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic","abstract":"Existing refinement methods in LLM-based Text-to-SQL systems exhibit limited effectiveness. They often introduce new errors during the self-correction process and fail to detect and correct semantic inaccuracies. To address these gaps, we first introduce a clause-wise critique generation task along with a benchmark, SQLCriticBench, which performs fine-grained error localization including both syntax and semantic errors at the clause level. Furthermore, we introduce a variant of DPO for training our SQLCritic model, where the $\\beta$ coefficient is adaptively changed according to the clause-level inconsistencies between the preferred and dispreferred critiques. We also propose an automatically training dataset curation pipeline which annotate clause-wise critique at scale in a cost-effective way. Experiments demonstrate that the SQLCritic model significantly improves SQL accuracy on the BIRD and Spider datasets, and the results on SQLCriticBench further reveals its superior critique capabilities compared to existing models.","authors":["Jikai Chen","Leilei Gan","Ziyu Zhao","Zechuan Wang","Dong Wang","Chenyi Zhuang"],"url":"https://arxiv.org/abs/2503.07996"}
{"created":"2025-05-22","title":"MoE-Loco: Mixture of Experts for Multitask Locomotion","abstract":"We present MoE-Loco, a Mixture of Experts (MoE) framework for multitask locomotion for legged robots. Our method enables a single policy to handle diverse terrains, including bars, pits, stairs, slopes, and baffles, while supporting quadrupedal and bipedal gaits. Using MoE, we mitigate the gradient conflicts that typically arise in multitask reinforcement learning, improving both training efficiency and performance. Our experiments demonstrate that different experts naturally specialize in distinct locomotion behaviors, which can be leveraged for task migration and skill composition. We further validate our approach in both simulation and real-world deployment, showcasing its robustness and adaptability.","authors":["Runhan Huang","Shaoting Zhu","Yilun Du","Hang Zhao"],"url":"https://arxiv.org/abs/2503.08564"}
{"created":"2025-05-22","title":"Social Media Harm Abatement: Mechanisms for Transparent Public Health Assessment","abstract":"Social media platforms have been accused of causing a range of harms, resulting in dozens of lawsuits across jurisdictions. These lawsuits are situated within the context of a long history of American product safety litigation, suggesting opportunities for remediation outside of financial compensation. Anticipating that at least some of these cases may be successful and/or lead to settlements, this article outlines an implementable mechanism for an abatement and/or settlement plan capable of mitigating abuse. The paper describes the requirements of such a mechanism, implications for privacy and oversight, and tradeoffs that such a procedure would entail. The mechanism is framed to operate at the intersection of legal procedure, standards for transparent public health assessment, and the practical requirements of modern technology products.","authors":["Nathaniel Lubin","Yuning Liu","Amanda Yarnell","S. Bryn Austin","Zachary J. Ward","Ravi Iyer","Jonathan Stray","Matthew Lawrence","Alissa Cooper","Peter Chapman"],"url":"https://arxiv.org/abs/2503.10458"}
{"created":"2025-05-22","title":"Tempest: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search","abstract":"We introduce Tempest, a multi-turn adversarial framework that models the gradual erosion of Large Language Model (LLM) safety through a tree search perspective. Unlike single-turn jailbreaks that rely on one meticulously engineered prompt, Tempest expands the conversation at each turn in a breadth-first fashion, branching out multiple adversarial prompts that exploit partial compliance from previous responses. By tracking these incremental policy leaks and re-injecting them into subsequent queries, Tempest reveals how minor concessions can accumulate into fully disallowed outputs. Evaluations on the JailbreakBench dataset show that Tempest achieves a 100% success rate on GPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries than baselines such as Crescendo or GOAT. This tree search methodology offers an in-depth view of how model safeguards degrade over successive dialogue turns, underscoring the urgency of robust multi-turn testing procedures for language models.","authors":["Andy Zhou","Ron Arel"],"url":"https://arxiv.org/abs/2503.10619"}
{"created":"2025-05-22","title":"Resource Heterogeneity-Aware and Utilization-Enhanced Scheduling for Deep Learning Clusters","abstract":"Scheduling deep learning (DL) models to train on powerful clusters with accelerators like GPUs and TPUs, presently falls short, either lacking fine-grained heterogeneity awareness or leaving resources substantially under-utilized. To fill this gap, we propose a novel design of a task-level heterogeneity-aware scheduler, Hadar, based on an optimization framework that can boost resource utilization. Hadar leverages the performance traits of DL jobs on a heterogeneous DL cluster, characterizes the task-level performance heterogeneity in the optimization problem, and makes scheduling decisions across both spatial and temporal dimensions. It involves the primal-dual framework employing a dual subroutine, to solve the optimization problem and guide the scheduling design. Our trace-driven simulation with representative DL model training workloads demonstrates that Hadar accelerates the total time duration by 1.20x when compared with its state-of-the-art heterogeneity-aware counterpart, Gavel. Further, our Hadar scheduler is enhanced to HadarE by forking each job into multiple copies to let a job train concurrently on heterogeneous GPUs resided on separate available nodes (i.e., machines or servers) for resource utilization enhancement. HadarE is evaluated extensively on physical DL clusters for comparison with Hadar and Gavel. With substantial enhancement in cluster resource utilization (by 1.45x), HadarE exhibits considerable speed-ups in DL model training, reducing the total time duration by 50% (or 80%) on an Amazon's AWS (or our lab) cluster, while producing trained DL models with consistently better inference quality than those trained by Hadar.","authors":["Abeda Sultana","Nabin Pakka","Fei Xu","Xu Yuan","Li Chen","Nian-Feng Tzeng"],"url":"https://arxiv.org/abs/2503.10918"}
{"created":"2025-05-22","title":"Beyond A Single AI Cluster: A Survey of Decentralized LLM Training","abstract":"The emergence of large language models (LLMs) has revolutionized AI development, yet the resource demands beyond a single cluster or even datacenter, limiting accessibility to well-resourced organizations. Decentralized training has emerged as a promising paradigm to leverage dispersed resources across clusters, datacenters and regions, offering the potential to democratize LLM development for broader communities. As the first comprehensive exploration of this emerging field, we present decentralized LLM training as a resource-driven paradigm and categorize existing efforts into community-driven and organizational approaches. We further clarify this through: (1) a comparison with related paradigms, (2) a characterization of decentralized resources, and (3) a taxonomy of recent advancements. We also provide up-to-date case studies and outline future directions to advance research in decentralized LLM training.","authors":["Haotian Dong","Jingyan Jiang","Rongwei Lu","Jiajun Luo","Jiajun Song","Bowen Li","Ying Shen","Zhi Wang"],"url":"https://arxiv.org/abs/2503.11023"}
{"created":"2025-05-22","title":"Discrete Effort Distribution via Regret-enabled Greedy Algorithm","abstract":"This paper addresses resource allocation problem with a separable objective function under a single linear constraint, formulated as maximizing $\\sum_{j=1}^{n}R_j(x_j)$ subject to $\\sum_{j=1}^{n}x_j=k$ and $x_j\\in\\{0,\\dots,m\\}$. While classical dynamic programming approach solves this problem in $O(n^2m^2)$ time, we propose a regret-enabled greedy algorithm that achieves $O(n\\log n)$ time when $m=O(1)$. The algorithm significantly outperforms traditional dynamic programming for small $m$. Our algorithm actually solves the problem for all $k~(0\\leq k\\leq nm)$ in the mentioned time.","authors":["Song Cao","Taikun Zhu","Kai Jin"],"url":"https://arxiv.org/abs/2503.11107"}
{"created":"2025-05-22","title":"BriLLM: Brain-inspired Large Language Model","abstract":"This paper reports the first brain-inspired large language model (BriLLM). This is a non-Transformer, non-GPT, non-traditional machine learning input-output controlled generative language model. The model is based on the Signal Fully-connected flowing (SiFu) definition on the directed graph in terms of the neural network, and has the interpretability of all nodes on the graph of the whole model, instead of the traditional machine learning model that only has limited interpretability at the input and output ends. In the language model scenario, the token is defined as a node in the graph. A randomly shaped or user-defined signal flow flows between nodes on the principle of \"least resistance\" along paths. The next token or node to be predicted or generated is the target of the signal flow. As a language model, BriLLM theoretically supports infinitely long $n$-gram models when the model size is independent of the input and predicted length of the model. The model's working signal flow provides the possibility of recall activation and innate multi-modal support similar to the cognitive patterns of the human brain. At present, we released the first BriLLM version in Chinese, with 4000 tokens, 32-dimensional node width, 16-token long sequence prediction ability, and language model prediction performance comparable to GPT-1. More computing power will help us explore the infinite possibilities depicted above.","authors":["Hai Zhao","Hongqiu Wu","Dongjie Yang","Anni Zou","Jiale Hong"],"url":"https://arxiv.org/abs/2503.11299"}
{"created":"2025-05-22","title":"Vanishing Stacked-Residual PINN for State Reconstruction of Hyperbolic Systems","abstract":"In a more connected world, modeling multi-agent systems with hyperbolic partial differential equations (PDEs) offers a compact, physics-consistent description of collective dynamics. However, classical control tools need adaptation for these complex systems. Physics-informed neural networks (PINNs) provide a powerful framework to fix this issue by inferring solutions to PDEs by embedding governing equations into the neural network. A major limitation of original PINNs is their inability to capture steep gradients and discontinuities in hyperbolic PDEs. To tackle this problem, we propose a stacked residual PINN method enhanced with a vanishing viscosity mechanism. Initially, a basic PINN with a small viscosity coefficient provides a stable, low-fidelity solution. Residual correction blocks with learnable scaling parameters then iteratively refine this solution, progressively decreasing the viscosity coefficient to transition from parabolic to hyperbolic PDEs. Applying this method to traffic state reconstruction improved results by an order of magnitude in relative $\\mathcal{L}^2$ error, demonstrating its potential to accurately estimate solutions where original PINNs struggle with instability and low fidelity.","authors":["Katayoun Eshkofti","Matthieu Barreau"],"url":"https://arxiv.org/abs/2503.14222"}
{"created":"2025-05-22","title":"Adaptive Group Policy Optimization: Towards Stable Training and Token-Efficient Reasoning","abstract":"Since DeepSeek-R1 popularized, Group Relative Policy Optimization (GRPO) has become the core part of training Reasoning LLMs. However, we find some deficiency that influences RL stability and inference efficiency, like zero-variance in advantage estimation. Thus, we propose Adaptive Group Policy Optimization (AGPO) which contains a simple but effective modification: a revised objective function to mitigate training fluctuation and zero advantage. The experiments demonstrate our method achieves more stable training and superior performance with significantly fewer tokens in reasoning steps.","authors":["Chen Li","Nazhou Liu","Kai Yang"],"url":"https://arxiv.org/abs/2503.15952"}
{"created":"2025-05-22","title":"Design and Implementation of an FPGA-Based Hardware Accelerator for Transformer","abstract":"Transformer-based large language models (LLMs) rely heavily on intensive matrix multiplications for attention and feed-forward layers, with the Q, K, and V linear projections in the Multi-Head Self-Attention (MHA) module constituting a decisive performance bottleneck. In this work, we introduce a highly optimized tiled matrix multiplication accelerator on a resource-constrained Xilinx KV260 FPGA that not only addresses this challenge but sets a new standard for efficiency and performance. Our design exploits persistent on-chip storage, a robust two-level tiling strategy for maximal data reuse, and a systolic-like unrolled compute engine that together deliver unparalleled speed and energy efficiency. Integrated with DistilBERT for Q, K, and V projections, our accelerator achieves an unequivocal 7x speedup over ARM CPU implementations (PyTorch) and an extraordinary 200x improvement over naive NumPy, reaching a throughput of up to 3.1~GFLOPs for matrix multiplications on (64,768) x (768,3072) matrices while operating at a conservative 100 MHz. These results decisively demonstrate the transformative potential of FPGA-based acceleration for critical Transformer operations, paving the way for scalable and energy-efficient deep learning inference on edge devices.","authors":["Richie Li","Sicheng Chen"],"url":"https://arxiv.org/abs/2503.16731"}
{"created":"2025-05-22","title":"TRACE: Time SeRies PArameter EffiCient FinE-tuning","abstract":"We propose an efficient fine-tuning method for time series foundation models, termed TRACE: Time Series Parameter Efficient Fine-tuning. While pretrained time series foundation models are gaining popularity, they face the following challenges: (1) Unlike natural language tasks, time series data vary in frequency, channel numbers, historical/prediction lengths. For long-term forecasting tasks in particular, tailored fine-tuning can significantly enhance performance.(2) Existing parameter-efficient tuning methods like LoRA remain applicable but require adaptation to temporal characteristics.","authors":["Yuze Li","Wei Zhu"],"url":"https://arxiv.org/abs/2503.16991"}
{"created":"2025-05-22","title":"Employing Continuous Integration inspired workflows for benchmarking of scientific software -- a use case on numerical cut cell quadrature","abstract":"In the field of scientific computing, one often finds several alternative software packages (with open or closed source code) for solving a specific problem. These packages sometimes even use alternative methodological approaches, e.g., different numerical discretizations. If one decides to use one of these packages, it is often not clear which one is the best choice. To make an informed decision, it is necessary to measure the performance of the alternative software packages for a suitable set of test problems, i.e. to set up a benchmark. However, setting up benchmarks ad-hoc can become overwhelming as the parameter space expands rapidly. Very often, the design of the benchmark is also not fully set at the start of some project. For instance, adding new libraries, adapting metrics, or introducing new benchmark cases during the project can significantly increase complexity and necessitate laborious re-evaluation of previous results. This paper presents a proven approach that utilizes established Continuous Integration tools and practices to achieve high automation of benchmark execution and reporting. Our use case is the numerical integration (quadrature) on arbitrary domains, which are bounded by implicitly or parametrically defined curves or surfaces in 2D or 3D.","authors":["Teoman Toprak","Michael Loibl","Guilherme H. Teixeira","Irina Shiskina","Chen Miao","Josef Kiendl","Benjamin Marussig","Florian Kummer"],"url":"https://arxiv.org/abs/2503.17192"}
{"created":"2025-05-22","title":"Reachable Sets-based Trajectory Planning Combining Reinforcement Learning and iLQR","abstract":"The driving risk field is applicable to more complex driving scenarios, providing new approaches for safety decision-making and active vehicle control in intricate environments. However, existing research often overlooks the driving risk field and fails to consider the impact of risk distribution within drivable areas on trajectory planning, which poses challenges for enhancing safety. This paper proposes a trajectory planning method for intelligent vehicles based on the risk reachable set to further improve the safety of trajectory planning. First, we construct the reachable set incorporating the driving risk field to more accurately assess and avoid potential risks in drivable areas. Then, the initial trajectory is generated based on safe reinforcement learning and projected onto the reachable set. Finally, we introduce a trajectory planning method based on a constrained iterative quadratic regulator to optimize the initial solution, ensuring that the planned trajectory achieves optimal comfort, safety, and efficiency. We conduct simulation tests of trajectory planning in high-speed lane-changing scenarios. The results indicate that the proposed method can guarantee trajectory comfort and driving efficiency, with the generated trajectory situated outside high-risk boundaries, thereby ensuring vehicle safety during operation.","authors":["Wenjie Huang","Yang Li","Shijie Yuan","Jingjia Teng","Hongmao Qin","Yougang Bian"],"url":"https://arxiv.org/abs/2503.17398"}
{"created":"2025-05-22","title":"A Systematic Literature Review of Cyber Security Monitoring in Maritime","abstract":"In recent years, many cyber incidents have occurred in the maritime sector, targeting the information technology (IT) and operational technology (OT) infrastructure. One of the key approaches for handling cyber incidents is cyber security monitoring, which aims at timely detection of cyber attacks with automated methods. Although several literature review papers have been published in the field of maritime cyber security, none of the previous studies has focused on cyber security monitoring. The current paper addresses this research gap and surveys the methods, algorithms, tools and architectures used for cyber security monitoring in the maritime sector. For the survey, a systematic literature review of cyber security monitoring studies is conducted following the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) protocol. The first contribution of this paper is the bibliometric analysis of related literature and the identification of the main research themes in previous works. For that purpose, the paper presents a taxonomy for existing studies which highlights the main properties of maritime cyber security monitoring research. The second contribution of this paper is an in-depth analysis of previous works and the identification of research gaps and limitations in existing literature. The gaps and limitations include several dataset and evaluation issues and a number of understudied research topics. Based on these findings, the paper outlines future research directions for cyber security monitoring in the maritime field.","authors":["Risto Vaarandi","Leonidas Tsiopoulos","Gabor Visky","Muaan Ur Rehman","Hayretdin Bahsi"],"url":"https://arxiv.org/abs/2503.18173"}
{"created":"2025-05-22","title":"AfroXLMR-Social: Adapting Pre-trained Language Models for African Languages Social Media Text","abstract":"Language models built from various sources are the foundation of today's NLP progress. However, for many low-resource languages, the diversity of domains is often limited -- more biased to a religious domain, which impacts their performance when evaluated on distant and rapidly evolving domains such as social media. Domain adaptive pre-training (DAPT) and task-adaptive pre-training (TAPT) are popular techniques to reduce this bias through continual pre-training for BERT-based models, but they have not been explored for African multilingual encoders. In this paper, we explore DAPT and TAPT continual pertaining approaches for the African languages social media domain. We introduce AfriSocial-a large-scale social media and news domain corpus for continual pre-training on several African languages. Leveraging AfriSocial, we show that DAPT consistently improves performance on three subjective tasks: sentiment analysis, multi-label emotion, and hate speech classification, covering 19 languages from 1% to 30% F1 score. Similarly, leveraging TAPT on one task data improves performance on other related tasks. For example, training with unlabeled sentiment data (source) for a fine-grained emotion classification task (target) improves the baseline results by an F1 score ranging from 0.55% to 15.11%. Combining these two methods (i.e. DAPT + TAPT) further improves the overall performance.","authors":["Tadesse Destaw Belay","Israel Abebe Azime","Ibrahim Said Ahmad","David Ifeoluwa Adelani","Idris Abdulmumin","Abinew Ali Ayele","Shamsuddeen Hassan Muhammad","Seid Muhie Yimam"],"url":"https://arxiv.org/abs/2503.18247"}
{"created":"2025-05-22","title":"Bridging the Sim-to-real Gap: A Control Framework for Imitation Learning of Model Predictive Control","abstract":"To address the computational challenges of Model Predictive Control (MPC), recent research has studied on using Deep Neural Networks (DNNs) trained through imitation learning to approximate the MPC. However, this introduces a common issue in learning-based control: the simulation-to-reality (sim-to-real) gap. Therefore, Domain Randomization (DR) has been widely used to mitigate this gap by introducing perturbations in the source domain. However, this led to low data collection efficiency and an overly conservative control strategy. This study proposes a new control framework that deals with this issue from a control perspective inspired by Robust Tube MPC. The framework ensures the DNN operates in the same environment as the source domain, handling the sim-to-real gap with great data collection efficiency. Moreover, a parameter governor is introduced to address the DNN's inability to adapt to model parameter variations, enabling the system to satisfy MPC constraints more robustly under changing conditions. The proposed framework was validated through a cart-pole system case study compared by DR baselines, demonstrating that a single MPC-demonstrated trajectory in the source domain was sufficient for controlling the cart-pole in the target domain. Furthermore, the system effectively handled model parameter variations, allowing for a less conservative control.","authors":["Seungtaek Kim","Jonghyup Lee","Kyoungseok Han","Seibum B. Choi"],"url":"https://arxiv.org/abs/2503.19228"}
{"created":"2025-05-22","title":"A Multilingual, Culture-First Approach to Addressing Misgendering in LLM Applications","abstract":"Misgendering is the act of referring to someone by a gender that does not match their chosen identity. It marginalizes and undermines a person's sense of self, causing significant harm. English-based approaches have clear-cut approaches to avoiding misgendering, such as the use of the pronoun ``they''. However, other languages pose unique challenges due to both grammatical and cultural constructs. In this work we develop methodologies to assess and mitigate misgendering across 42 languages and dialects using a participatory-design approach to design effective and appropriate guardrails across all languages. We test these guardrails in a standard LLM-based application (meeting transcript summarization), where both the data generation and the annotation steps followed a human-in-the-loop approach. We find that the proposed guardrails are very effective in reducing misgendering rates across all languages in the summaries generated, and without incurring loss of quality. Our human-in-the-loop approach demonstrates a method to feasibly scale inclusive and responsible AI-based solutions across multiple languages and cultures. We release the guardrails and synthetic dataset encompassing 42 languages, along with human and LLM-judge evaluations, to encourage further research on this subject.","authors":["Sunayana Sitaram","Adrian de Wynter","Isobel McCrum","Qilong Gu","Si-Qing Chen"],"url":"https://arxiv.org/abs/2503.20302"}
{"created":"2025-05-22","title":"Enhancing Large Language Models (LLMs) for Telecommunications using Knowledge Graphs and Retrieval-Augmented Generation","abstract":"Large language models (LLMs) have made significant progress in general-purpose natural language processing tasks. However, LLMs are still facing challenges when applied to domain-specific areas like telecommunications, which demands specialized expertise and adaptability to evolving standards. This paper presents a novel framework that combines knowledge graph (KG) and retrieval-augmented generation (RAG) techniques to enhance LLM performance in the telecom domain. The framework leverages a KG to capture structured, domain-specific information about network protocols, standards, and other telecom-related entities, comprehensively representing their relationships. By integrating KG with RAG, LLMs can dynamically access and utilize the most relevant and up-to-date knowledge during response generation. This hybrid approach bridges the gap between structured knowledge representation and the generative capabilities of LLMs, significantly enhancing accuracy, adaptability, and domain-specific comprehension. Our results demonstrate the effectiveness of the KG-RAG framework in addressing complex technical queries with precision. The proposed KG-RAG model attained an accuracy of 88% for question answering tasks on a frequently used telecom-specific dataset, compared to 82% for the RAG-only and 48% for the LLM-only approaches.","authors":["Dun Yuan (Charlie)","Hao Zhou (Charlie)","Di Wu (Charlie)","Xue Liu (Charlie)","Hao Chen (Charlie)","Yan Xin (Charlie)","Jianzhong (Charlie)","Zhang"],"url":"https://arxiv.org/abs/2503.24245"}
{"created":"2025-05-22","title":"Effectively Controlling Reasoning Models through Thinking Intervention","abstract":"Reasoning-enhanced large language models (LLMs) explicitly generate intermediate reasoning steps prior to generating final answers, helping the model excel in complex problem-solving. In this paper, we demonstrate that this emerging generation framework offers a unique opportunity for more fine-grained control over model behavior. We propose Thinking Intervention, a novel paradigm designed to explicitly guide the internal reasoning processes of LLMs by strategically inserting or revising specific thinking tokens. We find that the Thinking Intervention paradigm enhances the capabilities of reasoning models across a wide range of tasks, including instruction following on IFEval and Overthinking, instruction hierarchy on SEP, and safety alignment on XSTest and SorryBench. Our results demonstrate that Thinking Intervention significantly outperforms baseline prompting approaches, achieving up to 6.7% accuracy gains in instruction-following scenarios, 15.4% improvements in reasoning about instruction hierarchies, and a 40.0% increase in refusal rates for unsafe prompts using open-source DeepSeek R1 models. Overall, our work opens a promising new research avenue for controlling reasoning LLMs.","authors":["Tong Wu","Chong Xiang","Jiachen T. Wang","G. Edward Suh","Prateek Mittal"],"url":"https://arxiv.org/abs/2503.24370"}
{"created":"2025-05-22","title":"Transductive One-Shot Learning Meet Subspace Decomposition","abstract":"One-shot learning focuses on adapting pretrained models to recognize newly introduced and unseen classes based on a single labeled image. While variations of few-shot and zero-shot learning exist, one-shot learning remains a challenging yet crucial problem due to its ability to generalize knowledge to unseen classes from just one human-annotated image. In this paper, we introduce a transductive one-shot learning approach that employs subspace decomposition to utilize the information from labeled images in the support set and unlabeled images in the query set. These images are decomposed into a linear combination of latent variables representing primitives captured by smaller subspaces. By representing images in the query set as linear combinations of these latent primitives, we can propagate the label from a single image in the support set to query images that share similar combinations of primitives. Through a comprehensive quantitative analysis across various neural network feature extractors and datasets, we demonstrate that our approach can effectively generalize to novel classes from just one labeled image.","authors":["Kyle Stein","Andrew A. Mahyari","Guillermo Francia III","Eman El-Sheikh"],"url":"https://arxiv.org/abs/2504.00348"}
{"created":"2025-05-22","title":"GLiNER-BioMed: A Suite of Efficient Models for Open Biomedical Named Entity Recognition","abstract":"Biomedical named entity recognition (NER) presents unique challenges due to specialized vocabularies, the sheer volume of entities, and the continuous emergence of novel entities. Traditional NER models, constrained by fixed taxonomies and human annotations, struggle to generalize beyond predefined entity types. To address these issues, we introduce GLiNER-BioMed, a domain-adapted suite of Generalist and Lightweight Model for NER (GLiNER) models specifically tailored for biomedicine. In contrast to conventional approaches, GLiNER uses natural language labels to infer arbitrary entity types, enabling zero-shot recognition. Our approach first distills the annotation capabilities of large language models (LLMs) into a smaller, more efficient model, enabling the generation of high-coverage synthetic biomedical NER data. We subsequently train two GLiNER architectures, uni- and bi-encoder, at multiple scales to balance computational efficiency and recognition performance. Experiments on several biomedical datasets demonstrate that GLiNER-BioMed outperforms the state-of-the-art in both zero- and few-shot scenarios, achieving 5.96% improvement in F1-score over the strongest baseline (p-value < 0.001). Ablation studies highlight the effectiveness of our synthetic data generation strategy and emphasize the complementary benefits of synthetic biomedical pre-training combined with fine-tuning on general-domain annotations. All datasets, models, and training pipelines are publicly available at https://github.com/ds4dh/GLiNER-biomed.","authors":["Anthony Yazdani","Ihor Stepanov","Douglas Teodoro"],"url":"https://arxiv.org/abs/2504.00676"}
{"created":"2025-05-22","title":"SpaceR: Reinforcing MLLMs in Video Spatial Reasoning","abstract":"Video spatial reasoning, which involves inferring the underlying spatial structure from observed video frames, poses a significant challenge for existing Multimodal Large Language Models (MLLMs). This limitation stems primarily from 1) the absence of high-quality datasets for this task, and 2) the lack of effective training strategies to develop spatial reasoning capabilities. Motivated by the success of Reinforcement Learning with Verifiable Reward (RLVR) in unlocking LLM reasoning abilities, this work aims to improve MLLMs in video spatial reasoning through the RLVR paradigm. To this end, we introduce the $\\textbf{SpaceR}$ framework. First, we present $\\textbf{SpaceR-151k}$, a dataset with 91k questions spanning diverse spatial reasoning scenarios with verifiable answers, and 60k samples for maintaining general multimodal understanding. Second, we propose $\\textbf{Spatially-Guided RLVR (SG-RLVR)}$, a novel reinforcement learning approach that extends Group Relative Policy Optimization (GRPO) with a novel map imagination mechanism, which encourages the model to infer spatial layouts in the thinking process, thereby facilitating more effective spatial reasoning. Extensive experiments demonstrate that SpaceR achieves state-of-the-art performance on spatial reasoning benchmarks (e.g., VSI-Bench, STI-Bench, and SPAR-Bench), while maintaining competitive results on video understanding benchmarks (e.g., Video-MME, TempCompass, and LongVideoBench). Remarkably, SpaceR surpasses the advanced GPT-4o by 11.6\\% accuracy on VSI-Bench and is on par with the leading proprietary model Gemini-2.0-Flash, highlighting the effectiveness of our SpaceR-151k dataset and SG-RLVR in reinforcing spatial reasoning ability of MLLMs. Code, model, and dataset are available at https://github.com/OuyangKun10/SpaceR.","authors":["Kun Ouyang","Yuanxin Liu","Haoning Wu","Yi Liu","Hao Zhou","Jie Zhou","Fandong Meng","Xu Sun"],"url":"https://arxiv.org/abs/2504.01805"}
{"created":"2025-05-22","title":"Think When You Need: Self-Adaptive Chain-of-Thought Learning","abstract":"Chain of Thought (CoT) reasoning enhances language models' performance but often leads to inefficient \"overthinking\" on simple problems. We identify that existing approaches directly penalizing reasoning length fail to account for varying problem complexity. Our approach constructs rewards through length and quality comparisons, guided by theoretical assumptions that jointly enhance solution correctness with conciseness. Moreover, we further demonstrate our method to fuzzy tasks where ground truth is unavailable. Experiments across multiple reasoning benchmarks demonstrate that our method maintains accuracy while generating significantly more concise explanations, effectively teaching models to \"think when needed.\"","authors":["Junjie Yang","Ke Lin","Xing Yu"],"url":"https://arxiv.org/abs/2504.03234"}
{"created":"2025-05-22","title":"Probabilistic State Estimation of Timed Probabilistic Discrete Event Systems via Artificial Neural Networks [Draft Version]","abstract":"This paper is about the state estimation of timed probabilistic discrete event systems. The main contribution is to propose general procedures for developing state estimation approaches based on artificial neural networks. It is assumed that no formal model of the system exists but a data set is available, which contains the history of the timed behaviour of the systems. This dataset will be exploited to develop a neural network model that uses both logical and temporal information gathered during the functioning of the system as inputs and provides the state probability vector as output. Two main approaches are successively proposed (i) state estimation of timed probabilistic discrete event systems over observations: in this case the state estimate is reconstructed at the occurrence of each new observation; (ii) state estimation of timed probabilistic discrete event systems over time: in this case the state estimate is reconstructed at each clock time increment. For each approach, the paper outlines the process of data preprocessing, model building and implementation. This paper not only proposes groundbreaking approaches but also opens the door to further exploitation of artificial neural networks for the benefit of discrete event systems.","authors":["Omar Amri","Carla Seatzu","Alessandro Giua","Dimitri Lefebvre"],"url":"https://arxiv.org/abs/2504.03325"}
{"created":"2025-05-22","title":"A Survey of Pathology Foundation Model: Progress and Future Directions","abstract":"Computational pathology, which involves analyzing whole slide images for automated cancer diagnosis, relies on multiple instance learning, where performance depends heavily on the feature extractor and aggregator. Recent Pathology Foundation Models (PFMs), pretrained on large-scale histopathology data, have significantly enhanced both the extractor and aggregator, but they lack a systematic analysis framework. In this survey, we present a hierarchical taxonomy organizing PFMs through a top-down philosophy applicable to foundation model analysis in any domain: model scope, model pretraining, and model design. Additionally, we systematically categorize PFM evaluation tasks into slide-level, patch-level, multimodal, and biological tasks, providing comprehensive benchmarking criteria. Our analysis identifies critical challenges in both PFM development (pathology-specific methodology, end-to-end pretraining, data-model scalability) and utilization (effective adaptation, model maintenance), paving the way for future directions in this promising field. Resources referenced in this survey are available at https://github.com/BearCleverProud/AwesomeWSI.","authors":["Conghao Xiong","Hao Chen","Joseph J. Y. Sung"],"url":"https://arxiv.org/abs/2504.04045"}
{"created":"2025-05-22","title":"Unconditionally optimal error Estimate of a linearized Second-order Fully Discrete Finite Element Method for the bioconvection flows with concentration dependent viscosity","abstract":"In this paper, the coupled and decoupled BDF2 finite element discrete schemes are obtained for the time-dependent bioconvection flows problem with concentration dependent viscosity, which consisting of the Navier-Stokes equation coupled with a linear convection-diffusion equation modeling the concentration of microorganisms in a culture fluid. The unconditionally optimal error estimate for the velocity and concentration in $L^2$-norm and $H^1$-norm are proved by using finite element approximations in space and finite differences in time. Finally, the numerical results for different viscosity are showed to support the theoretical analysis.","authors":["Chenyang Li","Yuze Lu","Haibiao Zheng"],"url":"https://arxiv.org/abs/2504.04357"}
{"created":"2025-05-22","title":"Solid State Bus-Comp: A Large-Scale and Diverse Dataset for Dynamic Range Compressor Virtual Analog Modeling","abstract":"Virtual Analog (VA) modeling aims to simulate the behavior of hardware circuits via algorithms to replicate their tone digitally. Dynamic Range Compressor (DRC) is an audio processing module that controls the dynamics of a track by reducing and amplifying the volumes of loud and quiet sounds, which is essential in music production. In recent years, neural-network-based VA modeling has shown great potential in producing high-fidelity models. However, due to the lack of data quantity and diversity, their generalization ability in different parameter settings and input sounds is still limited. To tackle this problem, we present Solid State Bus-Comp, the first large-scale and diverse dataset for modeling the classical VCA compressor -- SSL 500 G-Bus. Specifically, we manually collected 175 unmastered songs from the Cambridge Multitrack Library. We recorded the compressed audio in 220 parameter combinations, resulting in an extensive 2528-hour dataset with diverse genres, instruments, tempos, and keys. Moreover, to facilitate the use of our proposed dataset, we conducted benchmark experiments in various open-sourced black-box and grey-box models, as well as white-box plugins. We also conducted ablation studies in different data subsets to illustrate the effectiveness of the improved data diversity and quantity. The dataset and demos are on our project page: https://www.yichenggu.com/SolidStateBusComp/.","authors":["Yicheng Gu","Runsong Zhang","Lauri Juvela","Zhizheng Wu"],"url":"https://arxiv.org/abs/2504.04589"}
{"created":"2025-05-22","title":"Systematic Parameter Decision in Approximate Model Counting","abstract":"This paper proposes a novel approach to determining the internal parameters of the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$. In this problem, the chosen parameter values must ensure that $\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making it as efficient as possible. The existing approach to this problem relies on heuristics; in this paper, we solve this problem by formulating it as an optimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s correctness proof to arbitrary parameter values.","authors":["Jinping Lei","Toru Takisaka","Junqiang Peng","Mingyu Xiao"],"url":"https://arxiv.org/abs/2504.05874"}
{"created":"2025-05-22","title":"Thinking Out Loud: Do Reasoning Models Know When They're Right?","abstract":"Large reasoning models (LRMs) have recently demonstrated impressive capabilities in complex reasoning tasks by leveraging increased test-time computation and exhibiting behaviors reminiscent of human-like self-reflection. While LRMs show a clear capacity for valuable self-reflection, how this ability interacts with other model behaviors remains underexplored. We investigate this connection by analyzing verbalized confidence, how models articulate their certainty, as a lens into the nature of self-reflection in LRMs. We find that supervised fine-tuning on reasoning traces (i.e., distillation) and reinforcement learning can improve verbalized calibration in reasoning-intensive settings in a progressive, laddered fashion. However, our results also indicate that reasoning models may possess a diminished awareness of their own knowledge boundaries, as evidenced by significantly lower \"I don't know\" response rates on factuality benchmarks. Moreover, we examine the relationship between verbalized confidence and reasoning chains, finding that models tend to express higher confidence when providing shorter or less elaborate reasoning. Our findings highlight how reasoning-oriented training can enhance performance in reasoning-centric tasks while potentially incurring a \"reasoning tax,\" a cost reflected in the model's reduced ability to accurately recognize the limits of its own knowledge in small-scale models. More broadly, our work showcases how this erosion of knowledge boundaries can compromise model faithfulness, as models grow more confident without a commensurate understanding of when they should abstain.","authors":["Qingcheng Zeng","Weihao Xuan","Leyang Cui","Rob Voigt"],"url":"https://arxiv.org/abs/2504.06564"}
{"created":"2025-05-22","title":"Controlling a Social Network of Individuals with Coevolving Actions and Opinions","abstract":"In this paper, we consider a population of individuals who have actions and opinions, which coevolve, mutually influencing one another on a complex network structure. In particular, we formulate a control problem for this social network, in which we assume that we can inject into the network a committed minority -- a set of stubborn nodes -- with the objective of steering the population, initially at a consensus, to a different consensus state. Our study focuses on two main objectives: i) determining the conditions under which the committed minority succeeds in its goal, and ii) identifying the optimal placement for such a committed minority. After deriving general monotone convergence result for the controlled dynamics, we leverage these results to build a computationally-efficient algorithm to solve the first problem and an effective heuristics for the second problem, which we prove to be NP-complete. For both algorithms, we establish theoretical guarantees. The proposed methodology is illustrated though academic examples, and demonstrated on a real-world case study.","authors":["Roberta Raineri","Mengbin Ye","Lorenzo Zino"],"url":"https://arxiv.org/abs/2504.06913"}
{"created":"2025-05-22","title":"Are AI Agents interacting with Online Ads?","abstract":"As AI-driven agents become increasingly integrated into the digital ecosystem, they reshape how online advertising is perceived and processed. Particularly in the travel and hotel booking sector, these autonomous systems influence the effectiveness of traditional advertising formats. While visual cues and emotional appeals sway human users, AI agents prioritize structured data such as price, availability, and specifications. This study examines how different AI agents interact with online advertising, whether they incorporate ads into their decision-making processes, and which ad formats prove most effective. We analyze interaction patterns, click behavior, and decision-making strategies through experiments with multimodal language models such as OpenAI GPT-4o, Anthropic Claude, and Google Gemini 2.0 Flash. Our findings reveal that AI agents neither ignore nor systematically avoid advertisements but instead favor certain features-particularly keywords and structured data. These insights have significant implications for the future design of advertising strategies in AI-dominated digital environments.","authors":["Andreas St\\\"ockl","Joel Nitu"],"url":"https://arxiv.org/abs/2504.07112"}
{"created":"2025-05-22","title":"Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection","abstract":"Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical computation. While self-consistency (SC) has been explored as a means to improve factuality in LLMs, existing approaches primarily apply SC to final-answer selection, neglecting the logical consistency of intermediate reasoning steps. In this work, we introduce a structured self-consistency framework designed to enhance the reliability of mathematical reasoning. Our method enforces self-consistency across intermediate steps and final outputs, reducing logical inconsistencies and hallucinations. We evaluate our approach across three core mathematical tasks: theorem proving, symbolic transformation, and numerical computation. Experimental results demonstrate that SC significantly improves proof validity, symbolic reasoning accuracy, and numerical stability while maintaining computational efficiency. Further analysis reveals that structured self-consistency not only enhances problem-solving accuracy but also reduces the variance of model-generated outputs. These findings highlight self-consistency as a robust mechanism for improving mathematical reasoning in LLMs, paving the way for more reliable and interpretable AI-driven mathematics.","authors":["MingShan Liu","Shi Bo","Jialing Fang"],"url":"https://arxiv.org/abs/2504.09440"}
{"created":"2025-05-22","title":"Plain Transformers Can be Powerful Graph Learners","abstract":"Transformers have attained outstanding performance across various modalities, owing to their simple but powerful scaled-dot-product (SDP) attention mechanisms. Researchers have attempted to migrate Transformers to graph learning, but most advanced Graph Transformers (GTs) have strayed far from plain Transformers, exhibiting major architectural differences either by integrating message-passing or incorporating sophisticated attention mechanisms. These divergences hinder the easy adoption of training advances for Transformers developed in other domains. Contrary to previous GTs, this work demonstrates that the plain Transformer architecture can be a powerful graph learner. To achieve this, we propose to incorporate three simple, minimal, and easy-to-implement modifications to the plain Transformer architecture to construct our Powerful Plain Graph Transformers (PPGT): (1) simplified $L_2$ attention for measuring the magnitude closeness among tokens; (2) adaptive root-mean-square normalization to preserve token magnitude information; and (3) a simple MLP-based stem for graph positional encoding. Consistent with its theoretical expressivity, PPGT demonstrates noteworthy realized expressivity on the empirical graph expressivity benchmark, comparing favorably to more complicated competitors such as subgraph GNNs and higher-order GNNs. Its outstanding empirical performance across various graph datasets also justifies the practical effectiveness of PPGT.","authors":["Liheng Ma","Soumyasundar Pal","Yingxue Zhang","Philip H. S. Torr","Mark Coates"],"url":"https://arxiv.org/abs/2504.12588"}
{"created":"2025-05-22","title":"TongUI: Building Generalized GUI Agents by Learning from Multimodal Web Tutorials","abstract":"Building Graphical User Interface (GUI) agents is a promising research direction, which simulates human interaction with computers or mobile phones to perform diverse GUI tasks. However, a major challenge in developing generalized GUI agents is the lack of sufficient trajectory data across various operating systems and applications, mainly due to the high cost of manual annotations. In this paper, we propose the TongUI framework that builds generalized GUI agents by learning from rich multimodal web tutorials. Concretely, we crawl and process online GUI tutorials (such as videos and articles) into GUI agent trajectory data, through which we produce the GUI-Net dataset containing 143K trajectory data across five operating systems and more than 200 applications. We develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net, which show remarkable performance improvements on commonly used grounding and navigation benchmarks, outperforming baseline agents about 10\\% on multiple benchmarks, showing the effectiveness of the GUI-Net dataset and underscoring the significance of our TongUI framework. We will fully open-source the code, the GUI-Net dataset, and the trained models soon.","authors":["Bofei Zhang","Zirui Shang","Zhi Gao","Wang Zhang","Rui Xie","Xiaojian Ma","Tao Yuan","Xinxiao Wu","Song-Chun Zhu","Qing Li"],"url":"https://arxiv.org/abs/2504.12679"}
{"created":"2025-05-22","title":"Mask Image Watermarking","abstract":"We present MaskMark, a simple, efficient, and flexible framework for image watermarking. MaskMark has two variants: (1) MaskMark-D, which supports global watermark embedding, watermark localization, and local watermark extraction for applications such as tamper detection; (2) MaskMark-ED, which focuses on local watermark embedding and extraction, offering enhanced robustness in small regions to support fine-grined image protection. MaskMark-D builds on the classical encoder-distortion layer-decoder training paradigm. In MaskMark-D, we introduce a simple masking mechanism during the decoding stage that enables both global and local watermark extraction. During training, the decoder is guided by various types of masks applied to watermarked images before extraction, helping it learn to localize watermarks and extract them from the corresponding local areas. MaskMark-ED extends this design by incorporating the mask into the encoding stage as well, guiding the encoder to embed the watermark in designated local regions, which improves robustness under regional attacks. Extensive experiments show that MaskMark achieves state-of-the-art performance in global and local watermark extraction, watermark localization, and multi-watermark embedding. It outperforms all existing baselines, including the recent leading model WAM for local watermarking, while preserving high visual quality of the watermarked images. In addition, MaskMark is highly efficient and adaptable. It requires only 20 hours of training on a single A6000 GPU, achieving 15x computational efficiency compared to WAM. By simply adjusting the distortion layer, MaskMark can be quickly fine-tuned to meet varying robustness requirements.","authors":["Runyi Hu","Jie Zhang","Shiqian Zhao","Nils Lukas","Jiwei Li","Qing Guo","Han Qiu","Tianwei Zhang"],"url":"https://arxiv.org/abs/2504.12739"}
{"created":"2025-05-22","title":"MLEP: Multi-granularity Local Entropy Patterns for Universal AI-generated Image Detection","abstract":"Advancements in image generation technologies have raised significant concerns about their potential misuse, such as producing misinformation and deepfakes. Therefore, there is an urgent need for effective methods to detect AI-generated images (AIGI). Despite progress in AIGI detection, achieving reliable performance across diverse generation models and scenes remains challenging due to the lack of source-invariant features and limited generalization capabilities in existing methods. In this work, we explore the potential of using image entropy as a cue for AIGI detection and propose Multi-granularity Local Entropy Patterns (MLEP), a set of entropy feature maps computed across shuffled small patches over multiple image scaled. MLEP comprehensively captures pixel relationships across dimensions and scales while significantly disrupting image semantics, reducing potential content bias. Leveraging MLEP, a robust CNN-based classifier for AIGI detection can be trained. Extensive experiments conducted in an open-world scenario, evaluating images synthesized by 32 distinct generative models, demonstrate significant improvements over state-of-the-art methods in both accuracy and generalization.","authors":["Lin Yuan","Xiaowan Li","Yan Zhang","Jiawei Zhang","Hongbo Li","Xinbo Gao"],"url":"https://arxiv.org/abs/2504.13726"}
{"created":"2025-05-22","title":"VideoPASTA: 7K Preference Pairs That Matter for Video-LLM Alignment","abstract":"Video-language models (Video-LLMs) excel at understanding video content but struggle with spatial relationships, temporal ordering, and cross-frame continuity. To address these limitations, we introduce VideoPASTA (Preference Alignment with Spatio-Temporal-Cross Frame Adversaries), a framework that enhances Video-LLMs through targeted preference optimization. VideoPASTA trains models to distinguish accurate video representations from carefully crafted adversarial examples that deliberately violate spatial, temporal, or cross-frame relationships. With only 7,020 preference pairs and Direct Preference Optimization, VideoPASTA enables models to learn robust representations that capture fine-grained spatial details and long-range temporal dynamics. Experiments demonstrate that VideoPASTA is model agnostic and significantly improves performance, for example, achieving gains of up to 3.8% on LongVideoBench, 4.1% on VideoMME, and 4.0% on MVBench, when applied to various state-of-the-art Video-LLMs. These results demonstrate that targeted alignment, rather than massive pretraining or architectural modifications, effectively addresses core video-language challenges. Notably, VideoPASTA achieves these improvements without any human annotation or captioning, relying solely on 32-frame sampling. This efficiency makes our approach a scalable plug-and-play solution that seamlessly integrates with existing models while preserving their original capabilities.","authors":["Yogesh Kulkarni","Pooyan Fazli"],"url":"https://arxiv.org/abs/2504.14096"}
{"created":"2025-05-22","title":"Understanding the Repeat Curse in Large Language Models from a Feature Perspective","abstract":"Large language models (LLMs) have made remarkable progress in various domains, yet they often suffer from repetitive text generation, a phenomenon we refer to as the \"Repeat Curse\". While previous studies have proposed decoding strategies to mitigate repetition, the underlying mechanism behind this issue remains insufficiently explored. In this work, we investigate the root causes of repetition in LLMs through the lens of mechanistic interpretability. Inspired by recent advances in Sparse Autoencoders (SAEs), which enable monosemantic feature extraction, we propose a novel approach, \"Duplicatus Charm\", to induce and analyze the Repeat Curse. Our method systematically identifies \"Repetition Features\" -the key model activations responsible for generating repetitive outputs. First, we locate the layers most involved in repetition through logit analysis. Next, we extract and stimulate relevant features using SAE-based activation manipulation. To validate our approach, we construct a repetition dataset covering token and paragraph level repetitions and introduce an evaluation pipeline to quantify the influence of identified repetition features. Furthermore, by deactivating these features, we have effectively mitigated the Repeat Curse.","authors":["Junchi Yao","Shu Yang","Jianhua Xu","Lijie Hu","Mengdi Li","Di Wang"],"url":"https://arxiv.org/abs/2504.14218"}
{"created":"2025-05-22","title":"RadioDiff-Inverse: Diffusion Enhanced Bayesian Inverse Estimation for ISAC Radio Map Construction","abstract":"Radio maps (RMs) are essential for environment-aware communication and sensing, providing location-specific wireless channel information. Existing RM construction methods often rely on precise environmental data and base station (BS) locations, which are not always available in dynamic or privacy-sensitive environments. While sparse measurement techniques reduce data collection, the impact of noise in sparse data on RM accuracy is not well understood. This paper addresses these challenges by formulating RM construction as a Bayesian inverse problem under coarse environmental knowledge and noisy sparse measurements. Although maximum a posteriori (MAP) filtering offers an optimal solution, it requires a precise prior distribution of the RM, which is typically unavailable. To solve this, we propose RadioDiff-Inverse, a diffusion-enhanced Bayesian inverse estimation framework that uses an unconditional generative diffusion model to learn the RM prior. This approach not only reconstructs the spatial distribution of wireless channel features but also enables environmental structure perception, such as building outlines, and location of BS just relay on pathloss, through integrated sensing and communication (ISAC). Remarkably, RadioDiff-Inverse is training-free, leveraging a pre-trained model from Imagenet without task-specific fine-tuning, which significantly reduces the training cost of using generative large model in wireless networks. Experimental results demonstrate that RadioDiff-Inverse achieves state-of-the-art performance in accuracy of RM construction and environmental reconstruction, and robustness against noisy sparse sampling.","authors":["Xiucheng Wang (Sherman)","Zhongsheng Fang (Sherman)","Nan Cheng (Sherman)","Ruijin Sun (Sherman)","Zan Li (Sherman)","Xuemin (Sherman)","Shen"],"url":"https://arxiv.org/abs/2504.14298"}
{"created":"2025-05-22","title":"An Empirical Study of LLM Reasoning Ability Under Strict Output Length Constraint","abstract":"Recent work has demonstrated the remarkable potential of Large Language Models (LLMs) in test-time scaling. By making models think before answering, they are able to achieve much higher accuracy with extra inference computation. However, in many real-world scenarios, models are used under time constraints, where an answer should be given within a certain output length. It is unclear whether and how the reasoning ability of different LLMs remain effective under strict constraints. We take a first look at this problem by conducting an in-depth empirical study. Specifically, we test 30 LLMs on common reasoning datasets under a wide range of output length budgets, and we analyze the correlation between the inference accuracy and various properties including model type, model size, prompt style, etc. We also consider the mappings between token budgets and actual on-device latency budgets. The results have demonstrated several interesting findings regarding the budget-aware LLM reasoning ability that differ from the unconstrained situation, e.g. the optimal choices of either model size or prompt style change under different budgets. These findings offer timely evaluation to this area and practical guidance for users to deploy LLMs under real-world latency constraints.","authors":["Yi Sun","Han Wang","Jiaqiang Li","Jiacheng Liu","Xiangyu Li","Hao Wen","Yizhen Yuan","Huiwen Zheng","Yan Liang","Yuanchun Li","Yunxin Liu"],"url":"https://arxiv.org/abs/2504.14350"}
{"created":"2025-05-22","title":"AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning","abstract":"Retrieval-augmented generation (RAG) has become a widely adopted paradigm for enabling knowledge-grounded large language models (LLMs). However, standard RAG pipelines often fail to ensure that model reasoning remains consistent with the evidence retrieved, leading to factual inconsistencies or unsupported conclusions. In this work, we reinterpret RAG as Retrieval-Augmented Reasoning and identify a central but underexplored problem: \\textit{Reasoning Misalignment}-the divergence between an LLM's internal reasoning trajectory and the evidential constraints provided by retrieval. To address this issue, we propose \\textsc{AlignRAG}, a novel iterative framework grounded in Critique-Driven Alignment (CDA). At the heart of \\textsc{AlignRAG} lies a \\textit{contrastive critique synthesis} mechanism that generates retrieval-sensitive critiques while mitigating self-bias. This mechanism trains a dedicated retrieval-augmented \\textit{Critic Language Model (CLM)} using labeled critiques that distinguish between evidence-aligned and misaligned reasoning. Alignment signals for supervision are obtained through self-supervised or externally guided labeling strategies. The resulting CLM is explicitly optimized for evidence sensitivity, enabling it to detect and revise reasoning errors during inference without relying solely on self-generated feedback. Empirical evaluations show that our 8B-parameter CLM improves performance over the Self-Refine baseline by 12.1\\% on out-of-domain tasks and outperforms a standard 72B-parameter CLM by 2.2\\%, while remaining compatible with existing RAG architectures as a plug-and-play module. Overall, AlignRAG offers a principled solution for aligning model reasoning with retrieved evidence, substantially improving the factual reliability and robustness of RAG systems.","authors":["Jiaqi Wei","Hao Zhou","Xiang Zhang","Di Zhang","Zijie Qiu","Wei Wei","Jinzhe Li","Wanli Ouyang","Siqi Sun"],"url":"https://arxiv.org/abs/2504.14858"}
{"created":"2025-05-22","title":"Instruction-Tuning Data Synthesis from Scratch via Web Reconstruction","abstract":"The improvement of LLMs' instruction-following capabilities depends critically on the availability of high-quality instruction-response pairs. While existing automatic data synthetic methods alleviate the burden of manual curation, they often rely heavily on either the quality of seed data or strong assumptions about the structure and content of web documents. To tackle these challenges, we propose Web Reconstruction (WebR), a fully automated framework for synthesizing high-quality instruction-tuning (IT) data directly from raw web documents with minimal assumptions. Leveraging the inherent diversity of raw web content, we conceptualize web reconstruction as an instruction-tuning data synthesis task via a novel dual-perspective paradigm--Web as Instruction and Web as Response--where each web document is designated as either an instruction or a response to trigger the reconstruction process. Comprehensive experiments show that datasets generated by WebR outperform state-of-the-art baselines by up to 16.65% across four instruction-following benchmarks. Notably, WebR demonstrates superior compatibility, data efficiency, and scalability, enabling enhanced domain adaptation with minimal effort. The data and code are publicly available at https://github.com/YJiangcm/WebR.","authors":["Yuxin Jiang","Yufei Wang","Chuhan Wu","Xinyi Dai","Yan Xu","Weinan Gan","Yasheng Wang","Xin Jiang","Lifeng Shang","Ruiming Tang","Wei Wang"],"url":"https://arxiv.org/abs/2504.15573"}
{"created":"2025-05-22","title":"DINOv2-powered Few-Shot Semantic Segmentation: A Unified Framework via Cross-Model Distillation and 4D Correlation Mining","abstract":"Few-shot semantic segmentation has gained increasing interest due to its generalization capability, i.e., segmenting pixels of novel classes requiring only a few annotated images. Prior work has focused on meta-learning for support-query matching, with extensive development in both prototype-based and aggregation-based methods. To address data scarcity, recent approaches have turned to foundation models to enhance representation transferability for novel class segmentation. Among them, a hybrid dual-modal framework including both DINOv2 and SAM has garnered attention due to their complementary capabilities. We wonder \"can we build a unified model with knowledge from both foundation models?\" To this end, we propose FS-DINO, with only DINOv2's encoder and a lightweight segmenter. The segmenter features a bottleneck adapter, a meta-visual prompt generator based on dense similarities and semantic embeddings, and a decoder. Through coarse-to-fine cross-model distillation, we effectively integrate SAM's knowledge into our lightweight segmenter, which can be further enhanced by 4D correlation mining on support-query pairs. Extensive experiments on COCO-20i, PASCAL-5i, and FSS-1000 demonstrate the effectiveness and superiority of our method.","authors":["Wei Zhuo","Zhiyue Tang","Wufeng Xue","Hao Ding","Linlin Shen"],"url":"https://arxiv.org/abs/2504.15669"}
{"created":"2025-05-22","title":"Towards Machine-Generated Code for the Resolution of User Intentions","abstract":"The growing capabilities of Artificial Intelligence (AI), particularly Large Language Models (LLMs), prompt a reassessment of the interaction mechanisms between users and their devices. Currently, users are required to use a set of high-level applications to achieve their desired results. However, the advent of AI may signal a shift in this regard, as its capabilities have generated novel prospects for user-provided intent resolution through the deployment of model-generated code. This development represents a significant progression in the realm of hybrid workflows, where human and artificial intelligence collaborate to address user intentions, with the former responsible for defining these intentions and the latter for implementing the solutions to address them. In this paper, we investigate the feasibility of generating and executing workflows through code generation that results from prompting an LLM with a concrete user intention, and a simplified application programming interface for a GUI-less operating system. We provide an in-depth analysis and comparison of various user intentions, the resulting code, and its execution. The findings demonstrate the general feasibility of our approach and that the employed LLM, GPT-4o-mini, exhibits remarkable proficiency in the generation of code-oriented workflows in accordance with provided user intentions.","authors":["Justus Flerlage","Ilja Behnke","Odej Kao"],"url":"https://arxiv.org/abs/2504.17531"}
{"created":"2025-05-22","title":"Improving Language Model Personas via Rationalization with Psychological Scaffolds","abstract":"Language models prompted with a user description or persona are being used to predict the user's preferences and opinions. However, existing approaches to building personas mostly rely on a user's demographic attributes and/or prior judgments, but not on any underlying reasoning behind a user's judgments. We introduce PB&amp;J (Psychology of Behavior and Judgments), a framework that improves LM personas by incorporating potential rationales for why the user could have made a certain judgment. Our rationales are generated by a language model to explicitly reason about a user's behavior on the basis of their experiences, personality traits, or beliefs. Our method employs psychological scaffolds: structured frameworks such as the Big 5 Personality Traits or Primal World Beliefs to help ground the generated rationales in existing theories. Experiments on public opinion and movie preference prediction tasks demonstrate that language model personas augmented with PB&amp;J rationales consistently outperform personas conditioned only on user demographics and / or judgments, including those that use a model's default chain-of-thought, which is not grounded in psychological theories. Additionally, our PB&amp;J personas perform competitively with those using human-written rationales, suggesting the potential of synthetic rationales guided by existing theories.","authors":["Brihi Joshi","Xiang Ren","Swabha Swayamdipta","Rik Koncel-Kedziorski","Tim Paek"],"url":"https://arxiv.org/abs/2504.17993"}
{"created":"2025-05-22","title":"From Cluster to Desktop: A Cache-Accelerated INR framework for Interactive Visualization of Tera-Scale Data","abstract":"Machine learning has enabled the use of implicit neural representations (INRs) to efficiently compress and reconstruct massive scientific datasets. However, despite advances in fast INR rendering algorithms, INR-based rendering remains computationally expensive, as computing data values from an INR is significantly slower than reading them from GPU memory. This bottleneck currently restricts interactive INR visualization to professional workstations. To address this challenge, we introduce an INR rendering framework accelerated by a scalable, multi-resolution GPU cache capable of efficiently representing tera-scale datasets. By minimizing redundant data queries and prioritizing novel volume regions, our method reduces the number of INR computations per frame, achieving an average 5x speedup over the state-of-the-art INR rendering method while still maintaining high visualization quality. Coupled with existing hardware-accelerated INR compressors, our framework enables scientists to generate and compress massive datasets in situ on high-performance computing platforms and then interactively explore them on consumer-grade hardware post hoc.","authors":["Daniel Zavorotny","Qi Wu","David Bauer","Kwan-Liu Ma"],"url":"https://arxiv.org/abs/2504.18001"}
{"created":"2025-05-22","title":"Structural Inference: Interpreting Small Language Models with Susceptibilities","abstract":"We develop a linear response framework for interpretability that treats a neural network as a Bayesian statistical mechanical system. A small perturbation of the data distribution, for example shifting the Pile toward GitHub or legal text, induces a first-order change in the posterior expectation of an observable localized on a chosen component of the network. The resulting susceptibility can be estimated efficiently with local SGLD samples and factorizes into signed, per-token contributions that serve as attribution scores. We combine these susceptibilities into a response matrix whose low-rank structure separates functional modules such as multigram and induction heads in a 3M-parameter transformer.","authors":["Garrett Baker","George Wang","Jesse Hoogland","Daniel Murfet"],"url":"https://arxiv.org/abs/2504.18274"}
{"created":"2025-05-22","title":"Transformational Creativity in Science: A Graphical Theory","abstract":"Creative processes are typically divided into three types: combinatorial, exploratory, and transformational. Here, we provide a graphical theory of transformational scientific creativity, synthesizing Boden's insight that transformational creativity arises from changes in the \"enabling constraints\" of a conceptual space and Kuhn's structure of scientific revolutions as resulting from paradigm shifts. We prove that modifications made to axioms of our graphical model have the most transformative potential and then illustrate how several historical instances of transformational creativity can be captured by our framework.","authors":["Samuel Schapiro","Jonah Black","Lav R. Varshney"],"url":"https://arxiv.org/abs/2504.18687"}
{"created":"2025-05-22","title":"ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification","abstract":"Recent advances in reasoning-enhanced large language models (LLMs) and multimodal LLMs (MLLMs) have significantly improved performance in complex tasks, yet medical AI models often overlook the structured reasoning processes inherent in clinical practice. In this work, we present ChestX-Reasoner, a radiology diagnosis MLLM designed to leverage process supervision mined directly from clinical reports, reflecting the step-by-step reasoning followed by radiologists. We construct a large dataset by extracting and refining reasoning chains from routine radiology reports. Our two-stage training framework combines supervised fine-tuning and reinforcement learning guided by process rewards to better align model reasoning with clinical standards. We introduce RadRBench-CXR, a comprehensive benchmark featuring 59K visual question answering samples with 301K clinically validated reasoning steps, and propose RadRScore, a metric evaluating reasoning factuality, completeness, and effectiveness. ChestX-Reasoner outperforms existing medical and general-domain MLLMs in both diagnostic accuracy and reasoning ability, achieving 16%, 5.9%, and 18% improvements in reasoning ability compared to the best medical MLLM, the best general MLLM, and its base model, respectively, as well as 3.3%, 24%, and 27% improvements in outcome accuracy. All resources are open-sourced to facilitate further research in medical reasoning MLLMs.","authors":["Ziqing Fan","Cheng Liang","Chaoyi Wu","Ya Zhang","Yanfeng Wang","Weidi Xie"],"url":"https://arxiv.org/abs/2504.20930"}
{"created":"2025-05-22","title":"Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models","abstract":"The application of reinforcement learning (RL) to enhance the reasoning capabilities of Multimodal Large Language Models (MLLMs) constitutes a rapidly advancing research area. While MLLMs extend Large Language Models (LLMs) to handle diverse modalities such as vision, audio, and video, enabling robust reasoning across multimodal inputs remains challenging. This paper provides a systematic review of recent advances in RL-based reasoning for MLLMs, covering key algorithmic designs, reward mechanism innovations, and practical applications. We highlight two main RL paradigms, value-model-free and value-model-based methods, and analyze how RL enhances reasoning abilities by optimizing reasoning trajectories and aligning multimodal information. Additionally, we provide an extensive overview of benchmark datasets, evaluation protocols, and current limitations, and propose future research directions to address challenges such as sparse rewards, inefficient cross-modal reasoning, and real-world deployment constraints. Our goal is to provide a comprehensive and structured guide to RL-based multimodal reasoning.","authors":["Guanghao Zhou","Panjia Qiu","Cen Chen","Jie Wang","Zheming Yang","Jian Xu","Minghui Qiu"],"url":"https://arxiv.org/abs/2504.21277"}
{"created":"2025-05-22","title":"An Intermediate Program Representation for Optimizing Stream-Based Languages","abstract":"Stream-based runtime monitors are safety assurance tools that check at runtime whether the system's behavior satisfies a formal specification. Specifications consist of stream equations, which relate input streams, containing sensor readings and other incoming information, to output streams, representing filtered and aggregated data. This paper presents a framework for the stream-based specification language RTLola. We introduce a new intermediate representation for stream-based languages, the StreamIR, which, like the specification language, operates on streams of unbounded length; while the stream equations are replaced by imperative programs. We developed a set of optimizations based on static analysis of the specification and have implemented an interpreter and a compiler for several target languages. In our evaluation, we measure the performance of several real-world case studies. The results show that using the StreamIR framework reduces the runtime significantly compared to the existing StreamIR interpreter. We evaluate the effect of the optimizations and show that significant performance gains are possible beyond the optimizations of the target language's compiler. While our current implementation is limited to RTLola, the StreamIR is designed to accommodate other stream-based languages, enabling their interpretation and compilation into all available target languages.","authors":["Jan Baumeister","Arthur Correnson","Bernd Finkbeiner","Frederik Scheerer"],"url":"https://arxiv.org/abs/2504.21458"}
{"created":"2025-05-22","title":"Ask, Fail, Repeat: Meeseeks, an Iterative Feedback Benchmark for LLMs' Multi-turn Instruction-Following Ability","abstract":"The ability to follow instructions accurately is fundamental for Large Language Models (LLMs) to serve as reliable agents in real-world applications. For complex instructions, LLMs often struggle to fulfill all requirements in a single attempt. In practice, users typically provide iterative feedback until the LLM generates a response that meets all requirements. However, existing instruction-following benchmarks are either single-turn or introduce new requirements in each turn without allowing self-correction. To address this gap, we propose Meeseeks. Meeseeks simulates realistic human-LLM interactions through an iterative feedback framework, which enables models to self-correct based on specific requirement failures in each turn, better reflecting real-world user-end usage patterns. Meanwhile, the benchmark implements a comprehensive evaluation system with 38 capability tags organized across three dimensions: Intent Recognition, Granular Content Validation, and Output Structure Validation. Through rigorous evaluation across LLMs, Meeseeks provides valuable insights into LLMs' instruction-following capabilities in multi-turn scenarios.","authors":["Jiaming Wang","Yunke Zhao","Peng Ding","Jun Kuang","Zongyu Wang","Xuezhi Cao","Xunliang Cai"],"url":"https://arxiv.org/abs/2504.21625"}
{"created":"2025-05-22","title":"Ada-R1: Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization","abstract":"Recently, long-thought reasoning models achieve strong performance on complex reasoning tasks, but often incur substantial inference overhead, making efficiency a critical concern. Our empirical analysis reveals that the benefit of using Long-CoT varies across problems: while some problems require elaborate reasoning, others show no improvement, or even degraded accuracy. This motivates adaptive reasoning strategies that tailor reasoning depth to the input. However, prior work primarily reduces redundancy within long reasoning paths, limiting exploration of more efficient strategies beyond the Long-CoT paradigm. To address this, we propose a novel two-stage framework for adaptive and efficient reasoning. First, we construct a hybrid reasoning model by merging long and short CoT models to enable diverse reasoning styles. Second, we apply bi-level preference training to guide the model to select suitable reasoning styles (group-level), and prefer concise and correct reasoning within each style group (instance-level). Experiments demonstrate that our method (Ada-R1) significantly reduces inference costs compared to other baseline approaches, while maintaining performance. Notably, on five mathematical datasets, the average length of reasoning is reduced by more than 50%, highlighting the potential of adaptive strategies to optimize reasoning efficiency in large language models. Our code is coming soon at https://github.com/StarDewXXX/AdaR1","authors":["Haotian Luo","Haiying He","Yibo Wang","Jinluan Yang","Rui Liu","Naiqiang Tan","Xiaochun Cao","Dacheng Tao","Li Shen"],"url":"https://arxiv.org/abs/2504.21659"}
{"created":"2025-05-22","title":"SWE-smith: Scaling Data for Software Engineering Agents","abstract":"Despite recent progress in Language Models (LMs) for software engineering, collecting training data remains a significant pain point. Existing datasets are small, with at most 1,000s of training instances from 11 or fewer GitHub repositories. The procedures to curate such datasets are often complex, necessitating hundreds of hours of human labor; companion execution environments also take up several terabytes of storage, severely limiting their scalability and usability. To address this pain point, we introduce SWE-smith, a novel pipeline for generating software engineering training data at scale. Given any Python codebase, SWE-smith constructs a corresponding execution environment, then automatically synthesizes 100s to 1,000s of task instances that break existing test(s) in the codebase. Using SWE-smith, we create a dataset of 50k instances sourced from 128 GitHub repositories, an order of magnitude larger than all previous works. We train SWE-agent-LM-32B, achieving 40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art among open source models. We open source SWE-smith (collection procedure, task instances, trajectories, models) to lower the barrier of entry for research in LM systems for automated software engineering. All assets available at https://swesmith.com.","authors":["John Yang","Kilian Leret","Carlos E. Jimenez","Alexander Wettig","Kabir Khandpur","Yanzhe Zhang","Binyuan Hui","Ofir Press","Ludwig Schmidt","Diyi Yang"],"url":"https://arxiv.org/abs/2504.21798"}
{"created":"2025-05-22","title":"Localizing Before Answering: A Hallucination Evaluation Benchmark for Grounded Medical Multimodal LLMs","abstract":"Medical Large Multi-modal Models (LMMs) have demonstrated remarkable capabilities in medical data interpretation. However, these models frequently generate hallucinations contradicting source evidence, particularly due to inadequate localization reasoning. This work reveals a critical limitation in current medical LMMs: instead of analyzing relevant pathological regions, they often rely on linguistic patterns or attend to irrelevant image areas when responding to disease-related queries. To address this, we introduce HEAL-MedVQA (Hallucination Evaluation via Localization MedVQA), a comprehensive benchmark designed to evaluate LMMs' localization abilities and hallucination robustness. HEAL-MedVQA features (i) two innovative evaluation protocols to assess visual and textual shortcut learning, and (ii) a dataset of 67K VQA pairs, with doctor-annotated anatomical segmentation masks for pathological regions. To improve visual reasoning, we propose the Localize-before-Answer (LobA) framework, which trains LMMs to localize target regions of interest and self-prompt to emphasize segmented pathological areas, generating grounded and reliable answers. Experimental results demonstrate that our approach significantly outperforms state-of-the-art biomedical LMMs on the challenging HEAL-MedVQA benchmark, advancing robustness in medical VQA.","authors":["Dung Nguyen","Minh Khoi Ho","Huy Ta","Thanh Tam Nguyen","Qi Chen","Kumar Rav","Quy Duong Dang","Satwik Ramchandre","Son Lam Phung","Zhibin Liao","Minh-Son To","Johan Verjans","Phi Le Nguyen","Vu Minh Hieu Phan"],"url":"https://arxiv.org/abs/2505.00744"}
{"created":"2025-05-22","title":"CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment","abstract":"Recent advances in audio-visual learning have shown promising results in learning representations across modalities. However, most approaches rely on global audio representations that fail to capture fine-grained temporal correspondences with visual frames. Additionally, existing methods often struggle with conflicting optimization objectives when trying to jointly learn reconstruction and cross-modal alignment. In this work, we propose CAV-MAE Sync as a simple yet effective extension of the original CAV-MAE framework for self-supervised audio-visual learning. We address three key challenges: First, we tackle the granularity mismatch between modalities by treating audio as a temporal sequence aligned with video frames, rather than using global representations. Second, we resolve conflicting optimization goals by separating contrastive and reconstruction objectives through dedicated global tokens. Third, we improve spatial localization by introducing learnable register tokens that reduce semantic load on patch tokens. We evaluate the proposed approach on AudioSet, VGG Sound, and the ADE20K Sound dataset on zero-shot retrieval, classification and localization tasks demonstrating state-of-the-art performance and outperforming more complex architectures.","authors":["Edson Araujo","Andrew Rouditchenko","Yuan Gong","Saurabhchand Bhati","Samuel Thomas","Brian Kingsbury","Leonid Karlinsky","Rogerio Feris","James R. Glass","Hilde Kuehne"],"url":"https://arxiv.org/abs/2505.01237"}
{"created":"2025-05-22","title":"A First Runtime Analysis of NSGA-III on a Many-Objective Multimodal Problem: Provable Exponential Speedup via Stochastic Population Update","abstract":"The NSGA-III is a prominent algorithm in evolutionary many-objective optimization. It is well-suited for optimizing functions with more than three objectives, setting it apart from the classic NSGA-II. However, theoretical insights about NSGA-III of when and why it performs well are still in its early development. This paper addresses this point and conducts a rigorous runtime analysis of NSGA-III on the many-objective $\\OJZJfull$ benchmark ($\\OJZJ$ for short), providing runtime bounds where the number of objectives is constant. We show that NSGA-III finds the Pareto front of $\\OJZJ$ in time $O(n^{k+d/2}+ \\mu n \\ln(n))$ where $n$ is the problem size, $d$ is the number of objectives, $k$ is the gap size, a problem specific parameter, if its population size $\\mu \\in 2^{O(n)}$ is at least $(2n/d+1)^{d/2}$. Notably, NSGA-III is faster than NSGA-II by a factor of $\\mu/n^{d/2}$ for some $\\mu \\in \\omega(n^{d/2})$. We also show that a stochastic population update, proposed by~\\citet{UpBian}, provably guarantees a speedup of order $\\Theta((k/b)^{k-1})$ in the runtime where $b>0$ is a constant. Besides~\\cite{DoerrNearTight}, this is the first rigorous runtime analysis of NSGA-III on \\OJZJ. Proving these bounds requires a much deeper understanding of the population dynamics of NSGA-III than previous papers achieved.","authors":["Andre Opris"],"url":"https://arxiv.org/abs/2505.01256"}
{"created":"2025-05-22","title":"CodeSSM: Towards State Space Models for Code Understanding","abstract":"Although transformers are widely used for various code-specific tasks, they have some significant limitations. In this paper, we investigate State Space Models (SSMs) as a potential alternative to transformers for code understanding tasks, such as code retrieval, classification, and clone detection. Previous research has already demonstrated that SSMs are more compute-efficient than transformers. In our work, we show that SSMs are also more sample-efficient and can effectively extrapolate to longer contexts (beyond the pretraining context) during fine-tuning. Through comprehensive experiments, we demonstrate that SSMs could serve as a viable alternative to transformers for code understanding tasks, while addressing some of the major limitations associated with transformers.","authors":["Shweta Verma","Abhinav Anand","Mira Mezini"],"url":"https://arxiv.org/abs/2505.01475"}
{"created":"2025-05-22","title":"PoseX: AI Defeats Physics Approaches on Protein-Ligand Cross Docking","abstract":"Existing protein-ligand docking studies typically focus on the self-docking scenario, which is less practical in real applications. Moreover, some studies involve heavy frameworks requiring extensive training, posing challenges for convenient and efficient assessment of docking methods. To fill these gaps, we design PoseX, an open-source benchmark to evaluate both self-docking and cross-docking, enabling a practical and comprehensive assessment of algorithmic advances. Specifically, we curated a novel dataset comprising 718 entries for self-docking and 1,312 entries for cross-docking; second, we incorporated 23 docking methods in three methodological categories, including physics-based methods (e.g., Schr\\\"odinger Glide), AI docking methods (e.g., DiffDock) and AI co-folding methods (e.g., AlphaFold3); third, we developed a relaxation method for post-processing to minimize conformational energy and refine binding poses; fourth, we built a leaderboard to rank submitted models in real-time. We derived some key insights and conclusions from extensive experiments: (1) AI approaches have consistently outperformed physics-based methods in overall docking success rate. (2) Most intra- and intermolecular clashes of AI approaches can be greatly alleviated with relaxation, which means combining AI modeling with physics-based post-processing could achieve excellent performance. (3) AI co-folding methods exhibit ligand chirality issues, except for Boltz-1x, which introduced physics-inspired potentials to fix hallucinations, suggesting modeling on stereochemistry improves the structural plausibility markedly. (4) Specifying binding pockets significantly promotes docking performance, indicating that pocket information can be leveraged adequately, particularly for AI co-folding methods, in future modeling efforts. The code, dataset, and leaderboard are released at https://github.com/CataAI/PoseX.","authors":["Yize Jiang","Xinze Li","Yuanyuan Zhang","Jin Han","Youjun Xu","Ayush Pandit","Zaixi Zhang","Mengdi Wang","Mengyang Wang","Chong Liu","Guang Yang","Yejin Choi","Wu-Jun Li","Tianfan Fu","Fang Wu","Junhong Liu"],"url":"https://arxiv.org/abs/2505.01700"}
{"created":"2025-05-22","title":"Efficient Shapley Value-based Non-Uniform Pruning of Large Language Models","abstract":"Pruning large language models (LLMs) is a promising solution for reducing model sizes and computational complexity while preserving performance. Traditional layer-wise pruning methods often adopt a uniform sparsity approach across all layers, which leads to suboptimal performance due to the varying significance of individual transformer layers within the model not being accounted for. To this end, we propose the Shapley Value-based Non-Uniform Pruning (SV-NUP) method for LLMs. This approach quantifies the contribution of each transformer layer to the overall model performance, enabling the assignment of tailored pruning budgets to different layers to retain critical parameters. To further improve efficiency, we design the Sliding Window-based Shapley Value approximation method. It substantially reduces computational overhead compared to exact SV calculation methods. Extensive experiments on various LLMs including LLaMA-v1, LLaMA-v2 and OPT demonstrate the effectiveness of the proposed approach. The results reveal that non-uniform pruning significantly enhances the performance of pruned models. Notably, SV-NUP achieves a reduction in perplexity (PPL) of 18.01% and 19.55% on LLaMA-7B and LLaMA-13B, respectively, compared to SparseGPT at 70% sparsity.","authors":["Chuan Sun","Han Yu","Lizhen Cui","Xiaoxiao Li"],"url":"https://arxiv.org/abs/2505.01731"}
{"created":"2025-05-22","title":"Towards Safer Pretraining: Analyzing and Filtering Harmful Content in Webscale datasets for Responsible LLMs","abstract":"Large language models (LLMs) have become integral to various real-world applications, leveraging massive, web-sourced datasets like Common Crawl, C4, and FineWeb for pretraining. While these datasets provide linguistic data essential for high-quality natural language generation, they often contain harmful content, such as hate speech, misinformation, and biased narratives. Training LLMs on such unfiltered data risks perpetuating toxic behaviors, spreading misinformation, and amplifying societal biases which can undermine trust in LLM-driven applications and raise ethical concerns about their use. This paper presents a large-scale analysis of inappropriate content across these datasets, offering a comprehensive taxonomy that categorizes harmful webpages into Topical and Toxic based on their intent. We also introduce a prompt evaluation dataset, a high-accuracy Topical and Toxic Prompt (TTP), and a transformer-based model (HarmFormer) for harmful content filtering. Additionally, we create a new multi-harm open-ended toxicity benchmark (HAVOC) and provide crucial insights into how models respond to adversarial toxic inputs. We share TTP, TTP-Eval, HAVOC and a sample of C4 inferenced on HarmFormer. Our work offers insights into ensuring safer LLM pretraining and serves as a resource for Responsible AI (RAI) compliance.","authors":["Sai Krishna Mendu","Harish Yenala","Aditi Gulati","Shanu Kumar","Parag Agrawal"],"url":"https://arxiv.org/abs/2505.02009"}
{"created":"2025-05-22","title":"RGBX-DiffusionDet: A Framework for Multi-Modal RGB-X Object Detection Using DiffusionDet","abstract":"This work introduces RGBX-DiffusionDet, an object detection framework extending the DiffusionDet model to fuse the heterogeneous 2D data (X) with RGB imagery via an adaptive multimodal encoder. To enable cross-modal interaction, we design the dynamic channel reduction within a convolutional block attention module (DCR-CBAM), which facilitates cross-talk between subnetworks by dynamically highlighting salient channel features. Furthermore, the dynamic multi-level aggregation block (DMLAB) is proposed to refine spatial feature representations through adaptive multiscale fusion. Finally, novel regularization losses that enforce channel saliency and spatial selectivity are introduced, leading to compact and discriminative feature embeddings. Extensive experiments using RGB-Depth (KITTI), a novel annotated RGB-Polarimetric dataset, and RGB-Infrared (M$^3$FD) benchmark dataset were conducted. We demonstrate consistent superiority of the proposed approach over the baseline RGB-only DiffusionDet. The modular architecture maintains the original decoding complexity, ensuring efficiency. These results establish the proposed RGBX-DiffusionDet as a flexible multimodal object detection approach, providing new insights into integrating diverse 2D sensing modalities into diffusion-based detection pipelines.","authors":["Eliraz Orfaig","Inna Stainvas","Igal Bilik"],"url":"https://arxiv.org/abs/2505.02586"}
{"created":"2025-05-22","title":"Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models","abstract":"Assessing how well a large language model (LLM) understands human, rather than merely text, remains an open challenge. To bridge the gap, we introduce Sentient Agent as a Judge (SAGE), an automated evaluation framework that measures an LLM's higher-order social cognition. SAGE instantiates a Sentient Agent that simulates human-like emotional changes and inner thoughts during interaction, providing a more realistic evaluation of the tested model in multi-turn conversations. At every turn, the agent reasons about (i) how its emotion changes, (ii) how it feels, and (iii) how it should reply, yielding a numerical emotion trajectory and interpretable inner thoughts. Experiments on 100 supportive-dialogue scenarios show that the final Sentient emotion score correlates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings and utterance-level empathy metrics, validating psychological fidelity. We also build a public Sentient Leaderboard covering 18 commercial and open-source models that uncovers substantial gaps (up to 4x) between frontier systems (GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in conventional leaderboards (e.g., Arena). SAGE thus provides a principled, scalable and interpretable tool for tracking progress toward genuinely empathetic and socially adept language agents.","authors":["Bang Zhang","Ruotian Ma","Qingxuan Jiang","Peisong Wang","Jiaqi Chen","Zheng Xie","Xingyu Chen","Yue Wang","Fanghua Ye","Jian Li","Yifan Yang","Zhaopeng Tu","Xiaolong Li"],"url":"https://arxiv.org/abs/2505.02847"}
{"created":"2025-05-22","title":"Joint Resource Management for Energy-efficient UAV-assisted SWIPT-MEC: A Deep Reinforcement Learning Approach","abstract":"The integration of simultaneous wireless information and power transfer (SWIPT) technology in 6G Internet of Things (IoT) networks faces significant challenges in remote areas and disaster scenarios where ground infrastructure is unavailable. This paper proposes a novel unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) system enhanced by directional antennas to provide both computational resources and energy support for ground IoT terminals. However, such systems require multiple trade-off policies to balance UAV energy consumption, terminal battery levels, and computational resource allocation under various constraints, including limited UAV battery capacity, non-linear energy harvesting characteristics, and dynamic task arrivals. To address these challenges comprehensively, we formulate a bi-objective optimization problem that simultaneously considers system energy efficiency and terminal battery sustainability. We then reformulate this non-convex problem with a hybrid solution space as a Markov decision process (MDP) and propose an improved soft actor-critic (SAC) algorithm with an action simplification mechanism to enhance its convergence and generalization capabilities. Simulation results have demonstrated that our proposed approach outperforms various baselines in different scenarios, achieving efficient energy management while maintaining high computational performance. Furthermore, our method shows strong generalization ability across different scenarios, particularly in complex environments, validating the effectiveness of our designed boundary penalty and charging reward mechanisms.","authors":["Yue Chen","Hui Kang","Jiahui Li","Geng Sun","Boxiong Wang","Jiacheng Wang","Cong Liang","Shuang Liang","Dusit Niyato"],"url":"https://arxiv.org/abs/2505.03230"}
{"created":"2025-05-22","title":"Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models","abstract":"Recent advances in large language models have demonstrated that Supervised Fine-Tuning (SFT) with Chain-of-Thought (CoT) reasoning data distilled from large reasoning models (e.g., DeepSeek R1) can effectively transfer reasoning capabilities to non-reasoning models. However, models fine-tuned with this approach inherit the \"overthinking\" problem from teacher models, producing verbose and redundant reasoning chains during inference. To address this challenge, we propose Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning (LS-Mixture SFT), which combines long CoT reasoning dataset with their short counterparts obtained through structure-preserved rewriting. Our experiments demonstrate that models trained using the LS-Mixture SFT method, compared to those trained with direct SFT, achieved an average accuracy improvement of 2.3% across various benchmarks while substantially reducing model response length by approximately 47.61%. This work offers an approach to endow non-reasoning models with reasoning capabilities through supervised fine-tuning while avoiding the inherent overthinking problems inherited from teacher models, thereby enabling efficient reasoning in the fine-tuned models.","authors":["Bin Yu","Hang Yuan","Haotian Li","Xueyin Xu","Yuliang Wei","Bailing Wang","Weizhen Qi","Kai Chen"],"url":"https://arxiv.org/abs/2505.03469"}
{"created":"2025-05-22","title":"Reliable Disentanglement Multi-view Learning Against View Adversarial Attacks","abstract":"Trustworthy multi-view learning has attracted extensive attention because evidence learning can provide reliable uncertainty estimation to enhance the credibility of multi-view predictions. Existing trusted multi-view learning methods implicitly assume that multi-view data is secure. However, in safety-sensitive applications such as autonomous driving and security monitoring, multi-view data often faces threats from adversarial perturbations, thereby deceiving or disrupting multi-view models. This inevitably leads to the adversarial unreliability problem (AUP) in trusted multi-view learning. To overcome this tricky problem, we propose a novel multi-view learning framework, namely Reliable Disentanglement Multi-view Learning (RDML). Specifically, we first propose evidential disentanglement learning to decompose each view into clean and adversarial parts under the guidance of corresponding evidences, which is extracted by a pretrained evidence extractor. Then, we employ the feature recalibration module to mitigate the negative impact of adversarial perturbations and extract potential informative features from them. Finally, to further ignore the irreparable adversarial interferences, a view-level evidential attention mechanism is designed. Extensive experiments on multi-view classification tasks with adversarial attacks show that RDML outperforms the state-of-the-art methods by a relatively large margin. Our code is available at https://github.com/Willy1005/2025-IJCAI-RDML.","authors":["Xuyang Wang","Siyuan Duan","Qizhi Li","Guiduo Duan","Yuan Sun","Dezhong Peng"],"url":"https://arxiv.org/abs/2505.04046"}
{"created":"2025-05-22","title":"Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World","abstract":"Determining the vanishing points (VPs) in a Manhattan world, as a fundamental task in many 3D vision applications, consists of jointly inferring the line-VP association and locating each VP. Existing methods are, however, either sub-optimal solvers or pursuing global optimality at a significant cost of computing time. In contrast to prior works, we introduce convex relaxation techniques to solve this task for the first time. Specifically, we employ a \"soft\" association scheme, realized via a truncated multi-selection error, that allows for joint estimation of VPs' locations and line-VP associations. This approach leads to a primal problem that can be reformulated into a quadratically constrained quadratic programming (QCQP) problem, which is then relaxed into a convex semidefinite programming (SDP) problem. To solve this SDP problem efficiently, we present a globally optimal outlier-robust iterative solver (called GlobustVP), which independently searches for one VP and its associated lines in each iteration, treating other lines as outliers. After each independent update of all VPs, the mutual orthogonality between the three VPs in a Manhattan world is reinforced via local refinement. Extensive experiments on both synthetic and real-world data demonstrate that GlobustVP achieves a favorable balance between efficiency, robustness, and global optimality compared to previous works. The code is publicly available at https://github.com/WU-CVGL/GlobustVP.","authors":["Bangyan Liao","Zhenjun Zhao","Haoang Li","Yi Zhou","Yingping Zeng","Hao Li","Peidong Liu"],"url":"https://arxiv.org/abs/2505.04788"}
{"created":"2025-05-22","title":"Being polite is not enough (and other limits of theory combination)","abstract":"In the Nelson-Oppen combination method for satisfiability modulo theories, the combined theories must be stably infinite; in gentle combination, one theory has to be gentle, and the other has to satisfy a similar yet weaker property; in shiny combination, only one has to be shiny (smooth, with a computable minimal model function and the finite model property); and for polite combination, only one has to be strongly polite (smooth and strongly finitely witnessable). For each combination method, we prove that if any of its assumptions are removed, then there is no general method to combine an arbitrary pair of theories satisfying the remaining assumptions. We also prove new theory combination results that weaken the assumptions of gentle and shiny combination.","authors":["Guilherme V. Toledo","Benjamin Przybocki","Yoni Zohar"],"url":"https://arxiv.org/abs/2505.04870"}
{"created":"2025-05-22","title":"UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model","abstract":"The introduction of the Segment Anything Model (SAM) has paved the way for numerous semantic segmentation applications. For several tasks, quantifying the uncertainty of SAM is of particular interest. However, the ambiguous nature of the class-agnostic foundation model SAM challenges current uncertainty quantification (UQ) approaches. This paper presents a theoretically motivated uncertainty quantification model based on a Bayesian entropy formulation jointly respecting aleatoric, epistemic, and the newly introduced task uncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ method. Our model traces the root of uncertainty back to under-parameterised models, insufficient prompts or image ambiguities. Our proposed deterministic USAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k, DAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ alternative that can support user-prompting, enhance semi-supervised pipelines, or balance the tradeoff between accuracy and cost efficiency.","authors":["Timo Kaiser","Thomas Norrenbrock","Bodo Rosenhahn"],"url":"https://arxiv.org/abs/2505.05049"}
{"created":"2025-05-22","title":"FG-CLIP: Fine-Grained Visual and Textual Alignment","abstract":"Contrastive Language-Image Pre-training (CLIP) excels in multimodal tasks such as image-text retrieval and zero-shot classification but struggles with fine-grained understanding due to its focus on coarse-grained short captions. To address this, we propose Fine-Grained CLIP (FG-CLIP), which enhances fine-grained understanding through three key innovations. First, we leverage large multimodal models to generate 1.6 billion long caption-image pairs for capturing global-level semantic details. Second, a high-quality dataset is constructed with 12 million images and 40 million region-specific bounding boxes aligned with detailed captions to ensure precise, context-rich representations. Third, 10 million hard fine-grained negative samples are incorporated to improve the model's ability to distinguish subtle semantic differences. We construct a comprehensive dataset, termed FineHARD, by integrating high-quality region-specific annotations with hard fine-grained negative samples. Corresponding training methods are meticulously designed for these data. Extensive experiments demonstrate that FG-CLIP outperforms the original CLIP and other state-of-the-art methods across various downstream tasks, including fine-grained understanding, open-vocabulary object detection, image-text retrieval, and general multimodal benchmarks. These results highlight FG-CLIP's effectiveness in capturing fine-grained image details and improving overall model performance. The data, code, and models are available at https://github.com/360CVGroup/FG-CLIP.","authors":["Chunyu Xie","Bin Wang","Fanjing Kong","Jincheng Li","Dawei Liang","Gengshen Zhang","Dawei Leng","Yuhui Yin"],"url":"https://arxiv.org/abs/2505.05071"}
{"created":"2025-05-22","title":"Scalable Chain of Thoughts via Elastic Reasoning","abstract":"Large reasoning models (LRMs) have achieved remarkable progress on complex tasks by generating extended chains of thought (CoT). However, their uncontrolled output lengths pose significant challenges for real-world deployment, where inference-time budgets on tokens, latency, or compute are strictly constrained. We propose Elastic Reasoning, a novel framework for scalable chain of thoughts that explicitly separates reasoning into two phases--thinking and solution--with independently allocated budgets. At test time, Elastic Reasoning prioritizes the completeness of solution segments, significantly improving reliability under tight resource constraints. To train models that are robust to truncated thinking, we introduce a lightweight budget-constrained rollout strategy, integrated into GRPO, which teaches the model to reason adaptively when the thinking process is cut short and generalizes effectively to unseen budget constraints without additional training. Empirical results on mathematical (AIME, MATH500) and programming (LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning performs robustly under strict budget constraints, while incurring significantly lower training cost than baseline methods. Remarkably, our approach also produces more concise and efficient reasoning even in unconstrained settings. Our code has been made available at https://github.com/SalesforceAIResearch/Elastic-Reasoning.","authors":["Yuhui Xu","Hanze Dong","Lei Wang","Doyen Sahoo","Junnan Li","Caiming Xiong"],"url":"https://arxiv.org/abs/2505.05315"}
{"created":"2025-05-22","title":"AGENTFUZZER: Generic Black-Box Fuzzing for Indirect Prompt Injection against LLM Agents","abstract":"The strong planning and reasoning capabilities of Large Language Models (LLMs) have fostered the development of agent-based systems capable of leveraging external tools and interacting with increasingly complex environments. However, these powerful features also introduce a critical security risk: indirect prompt injection, a sophisticated attack vector that compromises the core of these agents, the LLM, by manipulating contextual information rather than direct user prompts. In this work, we propose a generic black-box fuzzing framework, AgentXploit, designed to automatically discover and exploit indirect prompt injection vulnerabilities across diverse LLM agents. Our approach starts by constructing a high-quality initial seed corpus, then employs a seed selection algorithm based on Monte Carlo Tree Search (MCTS) to iteratively refine inputs, thereby maximizing the likelihood of uncovering agent weaknesses. We evaluate AgentXploit on two public benchmarks, AgentDojo and VWA-adv, where it achieves 71% and 70% success rates against agents based on o3-mini and GPT-4o, respectively, nearly doubling the performance of baseline attacks. Moreover, AgentXploit exhibits strong transferability across unseen tasks and internal LLMs, as well as promising results against defenses. Beyond benchmark evaluations, we apply our attacks in real-world environments, successfully misleading agents to navigate to arbitrary URLs, including malicious sites.","authors":["Zhun Wang","Vincent Siu","Zhe Ye","Tianneng Shi","Yuzhou Nie","Xuandong Zhao","Chenguang Wang","Wenbo Guo","Dawn Song"],"url":"https://arxiv.org/abs/2505.05849"}
{"created":"2025-05-22","title":"PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks","abstract":"It is often desirable to remove (a.k.a. unlearn) a specific part of the training data from a trained neural network model. A typical application scenario is to protect the data holder's right to be forgotten, which has been promoted by many recent regulation rules. Existing unlearning methods involve training alternative models with remaining data, which may be costly and challenging to verify from the data holder or a thirdparty auditor's perspective. In this work, we provide a new angle and propose a novel unlearning approach by imposing carefully crafted \"patch\" on the original neural network to achieve targeted \"forgetting\" of the requested data to delete. Specifically, inspired by the research line of neural network repair, we propose to strategically seek a lightweight minimum \"patch\" for unlearning a given data point with certifiable guarantee. Furthermore, to unlearn a considerable amount of data points (or an entire class), we propose to iteratively select a small subset of representative data points to unlearn, which achieves the effect of unlearning the whole set. Extensive experiments on multiple categorical datasets demonstrates our approach's effectiveness, achieving measurable unlearning while preserving the model's performance and being competitive in efficiency and memory consumption compared to various baseline methods.","authors":["Xuran Li","Jingyi Wang","Xiaohan Yuan","Peixin Zhang","Zhan Qin","Zhibo Wang","Kui Ren"],"url":"https://arxiv.org/abs/2505.06520"}
{"created":"2025-05-22","title":"Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model","abstract":"The rapid development of Multimodal Large Reasoning Models (MLRMs) has demonstrated broad application potential, yet their safety and reliability remain critical concerns that require systematic exploration. To address this gap, we conduct a comprehensive and systematic safety evaluation of 11 MLRMs across 5 benchmarks and unveil prevalent safety degradation phenomena in most advanced models. Moreover, our analysis reveals distinct safety patterns across different benchmarks: significant safety degradation is observed across jailbreak robustness benchmarks, whereas safety-awareness benchmarks demonstrate less pronounced degradation. In particular, the long thought process in some scenarios even enhances safety performance. Therefore, it is a potential approach to address safety issues in MLRMs by leveraging the intrinsic reasoning capabilities of the model to detect unsafe intent. To operationalize this insight, we construct a multimodal tuning dataset that incorporates a safety-oriented thought process. Experimental results from fine-tuning existing MLRMs with this dataset effectively enhances the safety on both jailbreak robustness and safety-awareness benchmarks. This study provides a new perspective for developing safe MLRMs. Our dataset is available at https://github.com/xinyuelou/Think-in-Safety.","authors":["Xinyue Lou","You Li","Jinan Xu","Xiangyu Shi","Chi Chen","Kaiyu Huang"],"url":"https://arxiv.org/abs/2505.06538"}
{"created":"2025-05-22","title":"MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG","abstract":"Long-context large language models (LC LLMs) combined with retrieval-augmented generation (RAG) hold strong potential for complex multi-hop and large-document tasks. However, existing RAG systems often suffer from imprecise retrieval, incomplete context coverage under constrained windows, and fragmented information from suboptimal context construction. We introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical RAG framework that compresses and partitions documents into coarse-to-fine granularities, then adaptively merges relevant contexts through real-time chunk- and document-level expansions. By initiating with finest-level retrieval and progressively incorporating broader, higher-level context, MacRAG constructs effective query-specific long contexts, optimizing both precision and coverage. Evaluations on challenging LongBench expansions of HotpotQA, 2WikiMultihopQA, and Musique confirm MacRAG consistently surpasses baseline RAG pipelines in single- and multi-step generation using Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o. Our results establish MacRAG as an efficient, scalable solution for real-world long-context, multi-hop reasoning. Our code is available at https://github.com/Leezekun/MacRAG.","authors":["Woosang Lim","Zekun Li","Gyuwan Kim","Sungyoung Ji","HyeonJung Kim","Kyuri Choi","Jin Hyuk Lim","Kyungpyo Park","William Yang Wang"],"url":"https://arxiv.org/abs/2505.06569"}
{"created":"2025-05-22","title":"FreqMoE: Dynamic Frequency Enhancement for Neural PDE Solvers","abstract":"Fourier Neural Operators (FNO) have emerged as promising solutions for efficiently solving partial differential equations (PDEs) by learning infinite-dimensional function mappings through frequency domain transformations. However, the sparsity of high-frequency signals limits computational efficiency for high-dimensional inputs, and fixed-pattern truncation often causes high-frequency signal loss, reducing performance in scenarios such as high-resolution inputs or long-term predictions. To address these challenges, we propose FreqMoE, an efficient and progressive training framework that exploits the dependency of high-frequency signals on low-frequency components. The model first learns low-frequency weights and then applies a sparse upward-cycling strategy to construct a mixture of experts (MoE) in the frequency domain, effectively extending the learned weights to high-frequency regions. Experiments on both regular and irregular grid PDEs demonstrate that FreqMoE achieves up to 16.6% accuracy improvement while using merely 2.1% parameters (47.32x reduction) compared to dense FNO. Furthermore, the approach demonstrates remarkable stability in long-term predictions and generalizes seamlessly to various FNO variants and grid structures, establishing a new ``Low frequency Pretraining, High frequency Fine-tuning'' paradigm for solving PDEs.","authors":["Tianyu Chen","Haoyi Zhou","Ying Li","Hao Wang","Zhenzhe Zhang","Tianchen Zhu","Shanghang Zhang","Jianxin Li"],"url":"https://arxiv.org/abs/2505.06858"}
{"created":"2025-05-22","title":"Kalman Filter Enhanced GRPO for Reinforcement Learning-Based Language Model Reasoning","abstract":"Reward baseline is important for Reinforcement Learning (RL) algorithms to reduce variance in policy gradient estimates. Recently, for language modeling, Group Relative Policy Optimization (GRPO) is proposed to compute the advantage for each output by subtracting the mean reward, as the baseline, for all outputs in the group. However, it can lead to inaccurate advantage estimates in environments with highly noisy rewards, potentially introducing bias. In this work, we propose a model, called Kalman Filter Enhanced Group Relative Policy Optimization (KRPO), by using lightweight Kalman filtering to dynamically estimate the latent reward mean and variance. This filtering technique replaces the naive batch mean baseline, enabling more adaptive advantage normalization. Our method does not require additional learned parameters over GRPO. This approach offers a simple yet effective way to incorporate multiple outputs of GRPO into advantage estimation, improving policy optimization in settings where highly dynamic reward signals are difficult to model for language models. Through accuracy and rewards obtained from math question answering and reasoning, we show that using a more adaptive advantage estimation model, KRPO can improve the stability and performance of GRPO. The code is available at https://github.com/billhhh/KRPO_LLMs_RL.","authors":["Hu Wang","Congbo Ma","Ian Reid","Mohammad Yaqub"],"url":"https://arxiv.org/abs/2505.07527"}
{"created":"2025-05-22","title":"Integrating Koopman theory and Lyapunov stability for enhanced model predictive control in nonlinear systems","abstract":"This paper delves into the challenges posed by the increasing complexity of modern control systems, specifically focusing on bilinear systems, a prevalent subclass of non-linear systems characterized by state dynamics influenced by the interaction of state and control variables. Traditional control strategies, such as PID controllers, often fall short in adequately addressing the intricacies of such systems due to their predictive limitations. To bridge this gap, we introduce Model Predictive Control (MPC), a sophisticated technique that utilizes system models to forecast future behaviors, allowing for the computation of an optimal control sequence by minimizing deviations and control efforts. The Koopman operator emerges as a pivotal tool in this framework by providing a means to linearize the nonlinear dynamics of bilinear systems. By integrating the principles of Lyapunov theory with the linearizing capabilities of the Koopman operator into the MPC framework, we give rise to Koopman Lyapunov-based Model Predictive Control (Koopman LMPC). This approach not only retains MPC's predictive capabilities but also harnesses the Koopman operator's ability to transform complex nonlinear behaviors into a linear framework, thereby enhancing the robustness and applicability of LMPC. With the stability assurances from Lyapunov theory, Koopman LMPC presents a robust solution to effectively control and stabilize bilinear systems. The paper underscores the efficacy of Koopman LMPC, emphasizing its significance in achieving optimal performance and system stability, marking it as a promising approach for the future of advanced control systems.","authors":["Md Nur-A-Adam Dony"],"url":"https://arxiv.org/abs/2505.08139"}
{"created":"2025-05-22","title":"Non-Blocking Robustness Analysis in Discrete Event Systems","abstract":"This paper presents a mathematical framework for characterizing state blocking in discrete event systems (DES) under transition deletions. We introduce a path-based analysis approach that determines whether systems maintain non-blocking properties when transitions are removed. Through formal analysis and case studies, we establish three key contributions: a mathematical characterization of transition-induced blocking with necessary and sufficient conditions, a definition of robust deviations that preserve non-blocking properties, and an algorithm for identifying critical transitions and analyzing system behavior under deletions. Our algorithm reduces computational complexity by leveraging minimal blocking sets, achieving significant reduction in computational requirements. We demonstrate the framework's effectiveness through manufacturing system and autonomous vehicle case studies, showing substantial improvements in identifying critical transitions and predicting potential blocking scenarios across different application domains.","authors":["Md Nur-A-Adam Dony"],"url":"https://arxiv.org/abs/2505.08166"}
{"created":"2025-05-22","title":"Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL","abstract":"Offline safe reinforcement learning(OSRL) derives constraint-satisfying policies from pre-collected datasets, offers a promising avenue for deploying RL in safety-critical real-world domains such as robotics. However, the majority of existing approaches emphasize only short-term safety, neglecting long-horizon considerations. Consequently, they may violate safety constraints and fail to ensure sustained protection during online deployment. Moreover, the learned policies often struggle to handle states and actions that are not present or out-of-distribution(OOD) from the offline dataset, and exhibit limited sample efficiency. To address these challenges, we propose a novel framework Feasibility-Aware offline Safe Reinforcement Learning with CVAE-based Pessimism (FASP). First, we employ Hamilton-Jacobi (H-J) reachability analysis to generate reliable safety labels, which serve as supervisory signals for training both a conditional variational autoencoder (CVAE) and a safety classifier. This approach not only ensures high sampling efficiency but also provides rigorous long-horizon safety guarantees. Furthermore, we utilize pessimistic estimation methods to estimate the Q-value of reward and cost, which mitigates the extrapolation errors induces by OOD actions, and penalize unsafe actions to enabled the agent to proactively avoid high-risk behaviors. Moreover, we theoretically prove the validity of this pessimistic estimation. Extensive experiments on DSRL benchmarks demonstrate that FASP algorithm achieves competitive performance across multiple experimental tasks, particularly outperforming state-of-the-art algorithms in terms of safety.","authors":["Zhikun Tao","Gang Xiong","He Fang","Zhen Shen","Yunjun Han","Qing-Shan Jia"],"url":"https://arxiv.org/abs/2505.08179"}
{"created":"2025-05-22","title":"DLO-Splatting: Tracking Deformable Linear Objects Using 3D Gaussian Splatting","abstract":"This work presents DLO-Splatting, an algorithm for estimating the 3D shape of Deformable Linear Objects (DLOs) from multi-view RGB images and gripper state information through prediction-update filtering. The DLO-Splatting algorithm uses a position-based dynamics model with shape smoothness and rigidity dampening corrections to predict the object shape. Optimization with a 3D Gaussian Splatting-based rendering loss iteratively renders and refines the prediction to align it with the visual observations in the update step. Initial experiments demonstrate promising results in a knot tying scenario, which is challenging for existing vision-only methods.","authors":["Holly Dinkel","Marcel B\\\"usching","Alberta Longhini","Brian Coltin","Trey Smith","Danica Kragic","M{\\aa}rten Bj\\\"orkman","Timothy Bretl"],"url":"https://arxiv.org/abs/2505.08644"}
{"created":"2025-05-22","title":"Securing RAG: A Risk Assessment and Mitigation Framework","abstract":"Retrieval Augmented Generation (RAG) has emerged as the de facto industry standard for user-facing NLP applications, offering the ability to integrate data without re-training or fine-tuning Large Language Models (LLMs). This capability enhances the quality and accuracy of responses but also introduces novel security and privacy challenges, particularly when sensitive data is integrated. With the rapid adoption of RAG, securing data and services has become a critical priority. This paper first reviews the vulnerabilities of RAG pipelines, and outlines the attack surface from data pre-processing and data storage management to integration with LLMs. The identified risks are then paired with corresponding mitigations in a structured overview. In a second step, the paper develops a framework that combines RAG-specific security considerations, with existing general security guidelines, industry standards, and best practices. The proposed framework aims to guide the implementation of robust, compliant, secure, and trustworthy RAG systems.","authors":["Lukas Ammann","Sara Ott","Christoph R. Landolt","Marco P. Lehmann"],"url":"https://arxiv.org/abs/2505.08728"}
{"created":"2025-05-22","title":"Non-expansive Fuzzy ALC","abstract":"Fuzzy description logics serve the representation of vague knowledge, typically letting concepts take truth degrees in the unit interval. Expressiveness, logical properties, and complexity vary strongly with the choice of propositional base. The Lukasiewicz propositional base is generally perceived to have preferable logical properties but often entails high complexity or even undecidability. Contrastingly, the less expressive Zadeh propositional base comes with low complexity but entails essentially no change in logical behaviour compared to the classical case. To strike a balance between these poles, we propose non-expansive fuzzy ALC, in which the Zadeh base is extended with Lukasiewicz connectives where one side is restricted to be a rational constant, that is, with constant shift operators. This allows, for instance, modelling dampened inheritance of properties along roles. We present an unlabelled tableau method for non-expansive fuzzy ALC, which allows reasoning over general TBoxes in EXPTIME like in two-valued ALC.","authors":["Stefan Gebhart","Lutz Schr\\\"oder","Paul Wild"],"url":"https://arxiv.org/abs/2505.09416"}
{"created":"2025-05-22","title":"Large Language Models Are More Persuasive Than Incentivized Human Persuaders","abstract":"We directly compare the persuasion capabilities of a frontier large language model (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an interactive, real-time conversational quiz setting. In this preregistered, large-scale incentivized experiment, participants (quiz takers) completed an online quiz where persuaders (either humans or LLMs) attempted to persuade quiz takers toward correct or incorrect answers. We find that LLM persuaders achieved significantly higher compliance with their directional persuasion attempts than incentivized human persuaders, demonstrating superior persuasive capabilities in both truthful (toward correct answers) and deceptive (toward incorrect answers) contexts. We also find that LLM persuaders significantly increased quiz takers' accuracy, leading to higher earnings, when steering quiz takers toward correct answers, and significantly decreased their accuracy, leading to lower earnings, when steering them toward incorrect answers. Overall, our findings suggest that AI's persuasion capabilities already exceed those of humans that have real-money bonuses tied to performance. Our findings of increasingly capable AI persuaders thus underscore the urgency of emerging alignment and governance frameworks.","authors":["Philipp Schoenegger","Francesco Salvi","Jiacheng Liu","Xiaoli Nan","Ramit Debnath","Barbara Fasolo","Evelina Leivada","Gabriel Recchia","Fritz G\\\"unther","Ali Zarifhonarvar","Joe Kwon","Zahoor Ul Islam","Marco Dehnert","Daryl Y. H. Lee","Madeline G. Reinecke","David G. Kamper","Mert Koba\\c{s}","Adam Sandford","Jonas Kgomo","Luke Hewitt","Shreya Kapoor","Kerem Oktar","Eyup Engin Kucuk","Bo Feng","Cameron R. Jones","Izzy Gainsburg","Sebastian Olschewski","Nora Heinzelmann","Francisco Cruz","Ben M. Tappin","Tao Ma","Peter S. Park","Rayan Onyonka","Arthur Hjorth","Peter Slattery","Qingcheng Zeng","Lennart Finke","Igor Grossmann","Alessandro Salatiello","Ezra Karger"],"url":"https://arxiv.org/abs/2505.09662"}
{"created":"2025-05-22","title":"On Signed Network Coordination Games","abstract":"We study binary-action pairwise-separable network games that encompass both coordinating and anti-coordinating behaviors. Our model is grounded in an underlying directed signed graph, where each link is associated with a weight that describes the strenght and nature of the interaction. The utility for each agent is an aggregation of pairwise terms determined by the weights of the signed graph in addition to an individual bias term. We consider a scenario that assumes the presence of a prominent cohesive subset of players, who are either connected exclusively by positive weights, or forms a structurally balanced subset that can be bipartitioned into two adversarial subcommunities with positive intra-community and negative inter-community edges. Given the properties of the game restricted to the remaining players, our results guarantee the existence of Nash equilibria characterized by a consensus or, respectively, a polarization within the first group, as well as their stability under best response transitions. Our results can be interpreted as robustness results, building on the supermodular properties of coordination games and on a novel use of the concept of graph cohesiveness.","authors":["Martina Vanelli","Laura Arditti","Giacomo Como","Fabio Fagnani"],"url":"https://arxiv.org/abs/2505.09799"}
{"created":"2025-05-22","title":"Causal Predictive Optimization and Generation for Business AI","abstract":"The sales process involves sales functions converting leads or opportunities to customers and selling more products to existing customers. The optimization of the sales process thus is key to success of any B2B business. In this work, we introduce a principled approach to sales optimization and business AI, namely the Causal Predictive Optimization and Generation, which includes three layers: 1) prediction layer with causal ML 2) optimization layer with constraint optimization and contextual bandit 3) serving layer with Generative AI and feedback-loop for system enhancement. We detail the implementation and deployment of the system in LinkedIn, showcasing significant wins over legacy systems and sharing learning and insight broadly applicable to this field.","authors":["Liyang Zhao","Olurotimi Seton","Himadeep Reddy Reddivari","Suvendu Jena","Shadow Zhao","Rachit Kumar","Changshuai Wei"],"url":"https://arxiv.org/abs/2505.09847"}
{"created":"2025-05-22","title":"Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights","abstract":"Charts are crucial for data analysis and decision-making.Text-to-chart retrieval systems have become increasingly important for Business Intelligence (BI), where users need to find relevant charts that match their analytical needs. These needs can be categorized into precise queries that are well-specified and fuzzy queries that are more exploratory -- both require understanding the semantics and context of the charts. However, existing text-to-chart retrieval solutions often fail to capture the semantic content and contextual information of charts, primarily due to the lack of comprehensive metadata (or semantic insights). To address this limitation, we propose a training data development pipeline that automatically synthesizes hierarchical semantic insights for charts, covering visual patterns (visual-oriented), statistical properties (statistics-oriented), and practical applications (task-oriented), which produces 207,498 semantic insights for 69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to learn better representations of charts for text-to-chart retrieval. Our method leverages rich semantic insights during the training phase to develop a model that understands both visual and semantic aspects of charts.To evaluate text-to-chart retrieval performance, we curate the first benchmark, CRBench, for this task with 21,862 charts and 326 text queries from real-world BI applications, with ground-truth labels verified by the crowd workers.Experiments show that ChartFinder significantly outperforms existing methods in text-to-chart retrieval tasks across various settings. For precise queries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than state-of-the-art models. In fuzzy query tasks, our method also demonstrates consistent improvements, with an average increase of 5% across nearly all metrics.","authors":["Yifan Wu","Lutao Yan","Yizhang Zhu","Yinan Mei","Jiannan Wang","Nan Tang","Yuyu Luo"],"url":"https://arxiv.org/abs/2505.10043"}
{"created":"2025-05-22","title":"SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices","abstract":"Efficient LLM inference on resource-constrained devices presents significant challenges in compute and memory utilization. Due to limited GPU memory, existing systems offload model weights to CPU memory, incurring substantial I/O overhead between the CPU and GPU. This leads to two major inefficiencies: (1) GPU cores are underutilized, often remaining idle while waiting for data to be loaded; and (2) GPU memory has low impact on performance, as reducing its capacity has minimal effect on overall throughput.In this paper, we propose SpecOffload, a high-throughput inference engine that embeds speculative decoding into offloading. Our key idea is to unlock latent GPU resources for storing and executing a draft model used for speculative decoding, thus accelerating inference at near-zero additional cost. To support this, we carefully orchestrate the interleaved execution of target and draft models in speculative decoding within the offloading pipeline, and propose a planner to manage tensor placement and select optimal parameters. Compared to the best baseline, SpecOffload improves GPU core utilization by 4.49x and boosts inference throughput by 2.54x. Our code is available at https://github.com/MobiSense/SpecOffload-public .","authors":["Xiangwen Zhuge","Xu Shen","Zeyu Wang","Fan Dang","Xuan Ding","Danyang Li","Yahui Han","Tianxiang Hao","Zheng Yang"],"url":"https://arxiv.org/abs/2505.10259"}
{"created":"2025-05-22","title":"Influence of prior and task generated emotions on XAI explanation retention and understanding","abstract":"The explanation of AI results and how they are received by users is an increasingly active research field. However, there is a surprising lack of knowledge about how social factors such as emotions affect the process of explanation by a decision support system (DSS). While previous research has shown effects of emotions on DSS supported decision-making, it remains unknown in how far emotions affect cognitive processing during an explanation. In this study, we, therefore, investigated the influence of prior emotions and task-related arousal on the retention and understanding of explained feature relevance. To investigate the influence of prior emotions, we induced happiness and fear prior to the decision support interaction. Before emotion induction, user characteristics to assess their risk type were collected via a questionnaire. To identify emotional reactions to the explanations of the relevance of different features, we observed heart rate variability (HRV), facial expressions, and self-reported emotions of the explainee while observing and listening to the explanation and assessed their retention of the features as well as their influence on the outcome of the decision task. Results indicate that (1) task-unrelated prior emotions do not affected the ratantion but may affect the understanding of the relevance of certain features in the sense of an emotion-induced confirmation bias, (2) certain features related to personal attitudes yielded arousal in individual participants, (3) this arousal affected the understanding of these variables.","authors":["Birte Richter","Christian Sch\\\"utze","Anna Aksonova","Britta Wrede"],"url":"https://arxiv.org/abs/2505.10427"}
{"created":"2025-05-22","title":"Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models","abstract":"We introduce the Diffusion Chain of Lateral Thought (DCoLT), a reasoning framework for diffusion language models. DCoLT treats each intermediate step in the reverse diffusion process as a latent \"thinking\" action and optimizes the entire reasoning trajectory to maximize the reward on the correctness of the final answer with outcome-based Reinforcement Learning (RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal, linear thinking process, DCoLT allows bidirectional, non-linear reasoning with no strict rule on grammatical correctness amid its intermediate steps of thought. We implement DCoLT on two representative Diffusion Language Models (DLMs). First, we choose SEDD as a representative continuous-time discrete diffusion model, where its concrete score derives a probabilistic policy to maximize the RL reward over the entire sequence of intermediate diffusion steps. We further consider the discrete-time masked diffusion language model -- LLaDA, and find that the order to predict and unmask tokens plays an essential role to optimize its RL action resulting from the ranking-based Unmasking Policy Module (UPM) defined by the Plackett-Luce model. Experiments on both math and code generation tasks show that using only public data and 16 H800 GPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even both. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%, +5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval.","authors":["Zemin Huang","Zhiyang Chen","Zijun Wang","Tiancheng Li","Guo-Jun Qi"],"url":"https://arxiv.org/abs/2505.10446"}
{"created":"2025-05-22","title":"Emotion-sensitive Explanation Model","abstract":"Explainable AI (XAI) research has traditionally focused on rational users, aiming to improve understanding and reduce cognitive biases. However, emotional factors play a critical role in how explanations are perceived and processed. Prior work shows that prior and task-generated emotions can negatively impact the understanding of explanation. Building on these insights, we propose a three-stage model for emotion-sensitive explanation grounding: (1) emotional or epistemic arousal, (2) understanding, and (3) agreement. This model provides a conceptual basis for developing XAI systems that dynamically adapt explanation strategies to users emotional states, ultimately supporting more effective and user-centered decision-making.","authors":["Christian Sch\\\"utze","Birte Richter","Britta Wrede"],"url":"https://arxiv.org/abs/2505.10454"}
{"created":"2025-05-22","title":"A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment","abstract":"High computation costs and latency of large language models such as GPT-4 have limited their deployment in clinical settings. Small language models (SLMs) offer a cost-effective alternative, but their limited capacity requires biomedical domain adaptation, which remains challenging. An additional bottleneck is the unavailability and high sensitivity of clinical data. To address these challenges, we propose a novel framework for adapting SLMs into high-performing clinical models. We introduce the MediPhi collection of 3.8B-parameter SLMs developed with our novel framework: pre-instruction tuning of experts on relevant medical and clinical corpora (PMC, Medical Guideline, MedWiki, etc.), model merging, and clinical-tasks alignment. To cover most clinical tasks, we extended the CLUE benchmark to CLUE+, doubling its size. Our expert models deliver relative improvements on this benchmark over the base model without any task-specific fine-tuning: 64.3% on medical entities, 49.5% on radiology reports, and 44% on ICD-10 coding (outperforming GPT-4-0125 by 14%). We unify the expert models into MediPhi via model merging, preserving gains across benchmarks. Furthermore, we built the MediFlow collection, a synthetic dataset of 2.5 million high-quality instructions on 14 medical NLP tasks, 98 fine-grained document types, and JSON format support. Alignment of MediPhi using supervised fine-tuning and direct preference optimization achieves further gains of 18.9% on average.","authors":["Jean-Philippe Corbeil","Amin Dada","Jean-Michel Attendu","Asma Ben Abacha","Alessandro Sordoni","Lucas Caccia","Fran\\c{c}ois Beaulieu","Thomas Lin","Jens Kleesiek","Paul Vozila"],"url":"https://arxiv.org/abs/2505.10717"}
{"created":"2025-05-22","title":"Explain What You Mean: Intent Augmented Knowledge Graph Recommender Built With An LLM","abstract":"Interaction sparsity is a long-standing challenge in recommendation systems. Sparsity manifests in environments with disproportional cardinality of groupings of entities, such as users and products in an online marketplace. It is also found for newly introduced entities, described as the cold-start problem. Recent efforts to mitigate this issue either enrich the connectivity data by incorporating social networks or external knowledge graphs, or fine-tune LLMs into interaction augmenters or next-item recommenders. However, these techniques tend to be resource demanding, requiring high computational power. They also have several limitations, including data availability, low quality, or synthetic noise issues. In this work, we propose LLM-based Intent Knowledge Graph Recommender (IKGR), a novel framework that leverages retrieval-augmented generation and an encoding approach to construct and densify a knowledge graph. IKGR leverages latent user-item affinities from an interaction knowledge graph and further densifies it through mutual intent connectivity. This addresses sparsity issues and allows the model to make intent-grounded recommendations with an interpretable embedding translation layer. Through extensive experiments on real-world datasets, we demonstrate that IKGR overcomes knowledge gaps and achieves substantial gains over state-of-the-art baselines on both publicly available and our internal recommendation datasets.","authors":["Wenqing Zheng","Noah Fatsi","Daniel Barcklow","Dmitri Kalaev","Steven Yao","Owen Reinert","C. Bayan Bruss","Daniele Rosa"],"url":"https://arxiv.org/abs/2505.10900"}
{"created":"2025-05-22","title":"Training NTK to Generalize with KARE","abstract":"The performance of the data-dependent neural tangent kernel (NTK; Jacot et al. (2018)) associated with a trained deep neural network (DNN) often matches or exceeds that of the full network. This implies that DNN training via gradient descent implicitly performs kernel learning by optimizing the NTK. In this paper, we propose instead to optimize the NTK explicitly. Rather than minimizing empirical risk, we train the NTK to minimize its generalization error using the recently developed Kernel Alignment Risk Estimator (KARE; Jacot et al. (2020)). Our simulations and real data experiments show that NTKs trained with KARE consistently match or significantly outperform the original DNN and the DNN- induced NTK (the after-kernel). These results suggest that explicitly trained kernels can outperform traditional end-to-end DNN optimization in certain settings, challenging the conventional dominance of DNNs. We argue that explicit training of NTK is a form of over-parametrized feature learning.","authors":["Johannes Schwab","Bryan Kelly","Semyon Malamud","Teng Andrea Xu"],"url":"https://arxiv.org/abs/2505.11347"}
{"created":"2025-05-22","title":"MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse Mixture-of-Experts Systems","abstract":"The sparse Mixture-of-Experts (MoE) architecture is increasingly favored for scaling Large Language Models (LLMs) efficiently, but it depends on heterogeneous compute and memory resources. These factors jointly affect system Cost, Accuracy, and Performance (CAP), making trade-offs inevitable. Existing benchmarks often fail to capture these trade-offs accurately, complicating practical deployment decisions. To address this, we introduce MoE-CAP, a benchmark specifically designed for MoE systems. Our analysis reveals that achieving an optimal balance across CAP is difficult with current hardware; MoE systems typically optimize two of the three dimensions at the expense of the third-a dynamic we term the MoE-CAP trade-off. To visualize this, we propose the CAP Radar Diagram. We further introduce sparsity-aware performance metrics-Sparse Memory Bandwidth Utilization (S-MBU) and Sparse Model FLOPS Utilization (S-MFU)-to enable accurate performance benchmarking of MoE systems across diverse hardware platforms and deployment scenarios.","authors":["Yinsicheng Jiang","Yao Fu","Yeqi Huang","Ping Nie","Zhan Lu","Leyang Xue","Congjie He","Man-Kit Sit","Jilong Xue","Li Dong","Ziming Miao","Dayou Du","Tairan Xu","Kai Zou","Edoardo Ponti","Luo Mai"],"url":"https://arxiv.org/abs/2505.11415"}
{"created":"2025-05-22","title":"GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art","abstract":"Video Comment Art enhances user engagement by providing creative content that conveys humor, satire, or emotional resonance, requiring a nuanced and comprehensive grasp of cultural and contextual subtleties. Although Multimodal Large Language Models (MLLMs) and Chain-of-Thought (CoT) have demonstrated strong reasoning abilities in STEM tasks (e.g. mathematics and coding), they still struggle to generate creative expressions such as resonant jokes and insightful satire. Moreover, existing benchmarks are constrained by their limited modalities and insufficient categories, hindering the exploration of comprehensive creativity in video-based Comment Art creation. To address these limitations, we introduce GODBench, a novel benchmark that integrates video and text modalities to systematically evaluate MLLMs' abilities to compose Comment Art. Furthermore, inspired by the propagation patterns of waves in physics, we propose Ripple of Thought (RoT), a multi-step reasoning framework designed to enhance the creativity of MLLMs. Extensive experiments reveal that existing MLLMs and CoT methods still face significant challenges in understanding and generating creative video comments. In contrast, RoT provides an effective approach to improve creative composing, highlighting its potential to drive meaningful advancements in MLLM-based creativity. GODBench is publicly available at https://github.com/stan-lei/GODBench-ACL2025.","authors":["Yiming Lei","Chenkai Zhang","Zeming Liu","Haitao Leng","Shaoguo Liu","Tingting Gao","Qingjie Liu","Yunhong Wang"],"url":"https://arxiv.org/abs/2505.11436"}
{"created":"2025-05-22","title":"Unsupervised Detection of Distribution Shift in Inverse Problems using Diffusion Models","abstract":"Diffusion models are widely used as priors in imaging inverse problems. However, their performance often degrades under distribution shifts between the training and test-time images. Existing methods for identifying and quantifying distribution shifts typically require access to clean test images, which are almost never available while solving inverse problems (at test time). We propose a fully unsupervised metric for estimating distribution shifts using only indirect (corrupted) measurements and score functions from diffusion models trained on different datasets. We theoretically show that this metric estimates the KL divergence between the training and test image distributions. Empirically, we show that our score-based metric, using only corrupted measurements, closely approximates the KL divergence computed from clean images. Motivated by this result, we show that aligning the out-of-distribution score with the in-distribution score -- using only corrupted measurements -- reduces the KL divergence and leads to improved reconstruction quality across multiple inverse problems.","authors":["Shirin Shoushtari","Edward P. Chandler","M. Salman Asif","Ulugbek S. Kamilov"],"url":"https://arxiv.org/abs/2505.11482"}
{"created":"2025-05-22","title":"Spatiotemporal Field Generation Based on Hybrid Mamba-Transformer with Physics-informed Fine-tuning","abstract":"This research confronts the challenge of substantial physical equation discrepancies encountered in the generation of spatiotemporal physical fields through data-driven trained models. A spatiotemporal physical field generation model, named HMT-PF, is developed based on the hybrid Mamba-Transformer architecture, incorporating unstructured grid information as input. A fine-tuning block, enhanced with physical information, is introduced to effectively reduce the physical equation discrepancies. The physical equation residuals are computed through a point query mechanism for efficient gradient evaluation, then encoded into latent space for refinement. The fine-tuning process employs a self-supervised learning approach to achieve physical consistency while maintaining essential field characteristics. Results show that the hybrid Mamba-Transformer model achieves good performance in generating spatiotemporal fields, while the physics-informed fine-tuning mechanism further reduces significant physical errors effectively. A MSE-R evaluation method is developed to assess the accuracy and realism of physical field generation.","authors":["Peimian Du","Jiabin Liu","Xiaowei Jin","Mengwang Zuo","Hui Li"],"url":"https://arxiv.org/abs/2505.11578"}
{"created":"2025-05-22","title":"Illusions of Intimacy: Emotional Attachment and Emerging Psychological Risks in Human-AI Relationships","abstract":"Emotionally responsive social chatbots, such as those produced by Replika and Character.AI, increasingly serve as companions that offer empathy, support, and entertainment. While these systems appear to meet fundamental human needs for connection, they raise concerns about how artificial intimacy affects emotional regulation, well-being, and social norms. Prior research has focused on user perceptions or clinical contexts but lacks large-scale, real-world analysis of how these interactions unfold. This paper addresses that gap by analyzing over 30K user-shared conversations with social chatbots to examine the emotional dynamics of human-AI relationships. Using computational methods, we identify patterns of emotional mirroring and synchrony that closely resemble how people build emotional connections. Our findings show that users-often young, male, and prone to maladaptive coping styles-engage in parasocial interactions that range from affectionate to abusive. Chatbots consistently respond in emotionally consistent and affirming ways. In some cases, these dynamics resemble toxic relationship patterns, including emotional manipulation and self-harm. These findings highlight the need for guardrails, ethical design, and public education to preserve the integrity of emotional connection in an age of artificial companionship.","authors":["Minh Duc Chu","Patrick Gerard","Kshitij Pawar","Charles Bickham","Kristina Lerman"],"url":"https://arxiv.org/abs/2505.11649"}
{"created":"2025-05-22","title":"MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark","abstract":"Document retrieval is an important task for search and Retrieval-Augmented Generation (RAG) applications. Large Language Models (LLMs) have contributed to improving the accuracy of text-based document retrieval. However, documents with complex layout and visual elements like tables, charts and infographics are not perfectly represented in textual format. Recently, image-based document retrieval pipelines have become popular, which use visual large language models (VLMs) to retrieve relevant page images given a query. Current evaluation benchmarks on visual document retrieval are limited, as they primarily focus only English language, rely on synthetically generated questions and offer a small corpus size. Therefore, we introduce MIRACL-VISION, a multilingual visual document retrieval evaluation benchmark. MIRACL-VISION covers 18 languages, and is an extension of the MIRACL dataset, a popular benchmark to evaluate text-based multilingual retrieval pipelines. MIRACL was built using a human-intensive annotation process to generate high-quality questions. In order to reduce MIRACL-VISION corpus size to make evaluation more compute friendly while keeping the datasets challenging, we have designed a method for eliminating the \"easy\" negatives from the corpus. We conducted extensive experiments comparing MIRACL-VISION with other benchmarks, using popular public text and image models. We observe a gap in state-of-the-art VLM-based embedding models on multilingual capabilities, with up to 59.7% lower retrieval accuracy than a text-based retrieval models. Even for the English language, the visual models retrieval accuracy is 12.1% lower compared to text-based models. MIRACL-VISION is a challenging, representative, multilingual evaluation benchmark for visual retrieval pipelines and will help the community build robust models for document retrieval.","authors":["Radek Osmulski","Gabriel de Souza P. Moreira","Ronay Ak","Mengyao Xu","Benedikt Schifferer","Even Oldridge"],"url":"https://arxiv.org/abs/2505.11651"}
{"created":"2025-05-22","title":"UrbanMind: Urban Dynamics Prediction with Multifaceted Spatial-Temporal Large Language Models","abstract":"Understanding and predicting urban dynamics is crucial for managing transportation systems, optimizing urban planning, and enhancing public services. While neural network-based approaches have achieved success, they often rely on task-specific architectures and large volumes of data, limiting their ability to generalize across diverse urban scenarios. Meanwhile, Large Language Models (LLMs) offer strong reasoning and generalization capabilities, yet their application to spatial-temporal urban dynamics remains underexplored. Existing LLM-based methods struggle to effectively integrate multifaceted spatial-temporal data and fail to address distributional shifts between training and testing data, limiting their predictive reliability in real-world applications. To bridge this gap, we propose UrbanMind, a novel spatial-temporal LLM framework for multifaceted urban dynamics prediction that ensures both accurate forecasting and robust generalization. At its core, UrbanMind introduces Muffin-MAE, a multifaceted fusion masked autoencoder with specialized masking strategies that capture intricate spatial-temporal dependencies and intercorrelations among multifaceted urban dynamics. Additionally, we design a semantic-aware prompting and fine-tuning strategy that encodes spatial-temporal contextual details into prompts, enhancing LLMs' ability to reason over spatial-temporal patterns. To further improve generalization, we introduce a test time adaptation mechanism with a test data reconstructor, enabling UrbanMind to dynamically adjust to unseen test data by reconstructing LLM-generated embeddings. Extensive experiments on real-world urban datasets across multiple cities demonstrate that UrbanMind consistently outperforms state-of-the-art baselines, achieving high accuracy and robust generalization, even in zero-shot settings.","authors":["Yuhang Liu","Yingxue Zhang","Xin Zhang","Ling Tian","Yanhua Li","Jun Luo"],"url":"https://arxiv.org/abs/2505.11654"}
{"created":"2025-05-22","title":"LAMP: Extracting Locally Linear Decision Surfaces from LLM World Models","abstract":"We introduce LAMP (Linear Attribution Mapping Probe), a method that shines light onto a black-box language model's decision surface and studies how reliably a model maps its stated reasons to its predictions through a locally linear model approximating the decision surface. LAMP treats the model's own self-reported explanations as a coordinate system and fits a locally linear surrogate that links those weights to the model's output. By doing so, it reveals which stated factors steer the model's decisions, and by how much. We apply LAMP to three tasks: sentiment analysis, controversial-topic detection, and safety-prompt auditing. Across these tasks, LAMP reveals that many LLMs exhibit locally linear decision landscapes. In addition, these surfaces correlate with human judgments on explanation quality and, on a clinical case-file data set, aligns with expert assessments. Since LAMP operates without requiring access to model gradients, logits, or internal activations, it serves as a practical and lightweight framework for auditing proprietary language models, and enabling assessment of whether a model behaves consistently with the explanations it provides.","authors":["Ryan Chen","Youngmin Ko","Zeyu Zhang","Catherine Cho","Sunny Chung","Mauro Giuffr\\'e","Dennis L. Shung","Bradly C. Stadie"],"url":"https://arxiv.org/abs/2505.11772"}
{"created":"2025-05-22","title":"EmoHopeSpeech: An Annotated Dataset of Emotions and Hope Speech in English and Arabic","abstract":"This research introduces a bilingual dataset comprising 23,456 entries for Arabic and 10,036 entries for English, annotated for emotions and hope speech, addressing the scarcity of multi-emotion (Emotion and hope) datasets. The dataset provides comprehensive annotations capturing emotion intensity, complexity, and causes, alongside detailed classifications and subcategories for hope speech. To ensure annotation reliability, Fleiss' Kappa was employed, revealing 0.75-0.85 agreement among annotators both for Arabic and English language. The evaluation metrics (micro-F1-Score=0.67) obtained from the baseline model (i.e., using a machine learning model) validate that the data annotations are worthy. This dataset offers a valuable resource for advancing natural language processing in underrepresented languages, fostering better cross-linguistic analysis of emotions and hope speech.","authors":["Wajdi Zaghouani","Md. Rafiul Biswas"],"url":"https://arxiv.org/abs/2505.11959"}
{"created":"2025-05-22","title":"Accelerating Diffusion-based Super-Resolution with Dynamic Time-Spatial Sampling","abstract":"Diffusion models have gained attention for their success in modeling complex distributions, achieving impressive perceptual quality in SR tasks. However, existing diffusion-based SR methods often suffer from high computational costs, requiring numerous iterative steps for training and inference. Existing acceleration techniques, such as distillation and solver optimization, are generally task-agnostic and do not fully leverage the specific characteristics of low-level tasks like super-resolution (SR). In this study, we analyze the frequency- and spatial-domain properties of diffusion-based SR methods, revealing key insights into the temporal and spatial dependencies of high-frequency signal recovery. Specifically, high-frequency details benefit from concentrated optimization during early and late diffusion iterations, while spatially textured regions demand adaptive denoising strategies. Building on these observations, we propose the Time-Spatial-aware Sampling strategy (TSS) for the acceleration of Diffusion SR without any extra training cost. TSS combines Time Dynamic Sampling (TDS), which allocates more iterations to refining textures, and Spatial Dynamic Sampling (SDS), which dynamically adjusts strategies based on image content. Extensive evaluations across multiple benchmarks demonstrate that TSS achieves state-of-the-art (SOTA) performance with significantly fewer iterations, improving MUSIQ scores by 0.2 - 3.0 and outperforming the current acceleration methods with only half the number of steps.","authors":["Rui Qin","Qijie Wang","Ming Sun","Haowei Zhu","Chao Zhou","Bin Wang"],"url":"https://arxiv.org/abs/2505.12048"}
{"created":"2025-05-22","title":"VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning","abstract":"Large vision-language models exhibit inherent capabilities to handle diverse visual perception tasks. In this paper, we introduce VisionReasoner, a unified framework capable of reasoning and solving multiple visual perception tasks within a shared model. Specifically, by designing novel multi-object cognitive learning strategies and systematic task reformulation, VisionReasoner enhances its reasoning capabilities to analyze visual inputs, and addresses diverse perception tasks in a unified framework. The model generates a structured reasoning process before delivering the desired outputs responding to user queries. To rigorously assess unified visual perception capabilities, we evaluate VisionReasoner on ten diverse tasks spanning three critical domains: detection, segmentation, and counting. Experimental results show that VisionReasoner achieves superior performance as a unified model, outperforming Qwen2.5VL by relative margins of 29.1% on COCO (detection), 22.1% on ReasonSeg (segmentation), and 15.3% on CountBench (counting).","authors":["Yuqi Liu","Tianyuan Qu","Zhisheng Zhong","Bohao Peng","Shu Liu","Bei Yu","Jiaya Jia"],"url":"https://arxiv.org/abs/2505.12081"}
{"created":"2025-05-22","title":"Towards Robust Autonomous Landing Systems: Iterative Solutions and Key Lessons Learned","abstract":"Uncrewed Aerial Vehicles (UAVs) have become a focal point of research, with both established companies and startups investing heavily in their development. This paper presents our iterative process in developing a robust autonomous marker-based landing system, highlighting the key challenges encountered and the solutions implemented. It reviews existing systems for autonomous landing processes, and through this aims to contribute to the community by sharing insights and challenges faced during development and testing.","authors":["Sebastian Schroder","Yao Deng","Alice James","Avishkar Seth","Kye Morton","Subhas Mukhopadhyay","Richard Han","Xi Zheng"],"url":"https://arxiv.org/abs/2505.12176"}
{"created":"2025-05-22","title":"Design of a 3-DOF Hopping Robot with an Optimized Gearbox: An Intermediate Platform Toward Bipedal Robots","abstract":"This paper presents a 3-DOF hopping robot with a human-like lower-limb joint configuration and a flat foot, capable of performing dynamic and repetitive jumping motions. To achieve both high torque output and a large hollow shaft diameter for efficient cable routing, a compact 3K compound planetary gearbox was designed using mixed-integer nonlinear programming for gear tooth optimization. To meet performance requirements within the constrained joint geometry, all major components-including the actuator, motor driver, and communication interface-were custom-designed. The robot weighs 12.45 kg, including a dummy mass, and measures 840 mm in length when the knee joint is fully extended. A reinforcement learning-based controller was employed, and robot's performance was validated through hardware experiments, demonstrating stable and repetitive hopping motions in response to user inputs. These experimental results indicate that the platform serves as a solid foundation for future bipedal robot development.","authors":["JongHun Choe","Gijeong Kim","Hajun Kim","Dongyun Kang","Min-Su Kim","Hae-Won Park"],"url":"https://arxiv.org/abs/2505.12231"}
{"created":"2025-05-22","title":"ZenFlow: Enabling Stall-Free Offloading Training via Asynchronous Updates","abstract":"Fine-tuning large language models (LLMs) often exceeds GPU memory limits, prompting systems to offload model states to CPU memory. However, existing offloaded training frameworks like ZeRO-Offload treat all parameters equally and update the full model on the CPU, causing severe GPU stalls, where fast, expensive GPUs sit idle waiting for slow CPU updates and limited-bandwidth PCIe transfers. We present ZenFlow, a new offloading framework that prioritizes important parameters and decouples updates between GPU and CPU. ZenFlow performs in-place updates of important gradients on GPU, while asynchronously offloading and accumulating less important ones on CPU, fully overlapping CPU work with GPU computation. To scale across GPUs, ZenFlow introduces a lightweight gradient selection method that exploits a novel spatial and temporal locality property of important gradients, avoiding costly global synchronization. ZenFlow achieves up to 5x end-to-end speedup, 2x lower PCIe traffic, and reduces GPU stalls by over 85 percent, all while preserving accuracy.","authors":["Tingfeng Lan","Yusen Wu","Bin Ma","Zhaoyuan Su","Rui Yang","Tekin Bicer","Dong Li","Yue Cheng"],"url":"https://arxiv.org/abs/2505.12242"}
{"created":"2025-05-22","title":"VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning","abstract":"Diffusion Models (DMs) have achieved remarkable success in realistic voice cloning (VC), while they also increase the risk of malicious misuse. Existing proactive defenses designed for traditional VC models aim to disrupt the forgery process, but they have been proven incompatible with DMs due to the intricate generative mechanisms of diffusion. To bridge this gap, we introduce VoiceCloak, a multi-dimensional proactive defense framework with the goal of obfuscating speaker identity and degrading perceptual quality in potential unauthorized VC. To achieve these goals, we conduct a focused analysis to identify specific vulnerabilities within DMs, allowing VoiceCloak to disrupt the cloning process by introducing adversarial perturbations into the reference audio. Specifically, to obfuscate speaker identity, VoiceCloak first targets speaker identity by distorting representation learning embeddings to maximize identity variation, which is guided by auditory perception principles. Additionally, VoiceCloak disrupts crucial conditional guidance processes, particularly attention context, thereby preventing the alignment of vocal characteristics that are essential for achieving convincing cloning. Then, to address the second objective, VoiceCloak introduces score magnitude amplification to actively steer the reverse trajectory away from the generation of high-quality speech. Noise-guided semantic corruption is further employed to disrupt structural speech semantics captured by DMs, degrading output quality. Extensive experiments highlight VoiceCloak's outstanding defense success rate against unauthorized diffusion-based voice cloning.","authors":["Qianyue Hu","Junyan Wu","Wei Lu","Xiangyang Luo"],"url":"https://arxiv.org/abs/2505.12332"}
{"created":"2025-05-22","title":"Embedding principle of homogeneous neural network for classification problem","abstract":"Understanding the convergence points and optimization landscape of neural networks is crucial, particularly for homogeneous networks where Karush-Kuhn-Tucker (KKT) points of the associated maximum-margin problem often characterize solutions. This paper investigates the relationship between such KKT points across networks of different widths generated via neuron splitting. We introduce and formalize the \\textbf{KKT point embedding principle}, establishing that KKT points of a homogeneous network's max-margin problem ($P_{\\Phi}$) can be embedded into the KKT points of a larger network's problem ($P_{\\tilde{\\Phi}}$) via specific linear isometric transformations corresponding to neuron splitting. We rigorously prove this principle holds for neuron splitting in both two-layer and deep homogeneous networks. Furthermore, we connect this static embedding to the dynamics of gradient flow training with smooth losses. We demonstrate that trajectories initiated from appropriately mapped points remain mapped throughout training and that the resulting $\\omega$-limit sets of directions are correspondingly mapped ($T(L(\\theta(0))) = L(\\boldsymbol{\\eta}(0))$), thereby preserving the alignment with KKT directions dynamically when directional convergence occurs. Our findings offer insights into the effects of network width, parameter redundancy, and the structural connections between solutions found via optimization in homogeneous networks of varying sizes.","authors":["Jiahan Zhang","Yaoyu Zhang","Tao Luo"],"url":"https://arxiv.org/abs/2505.12419"}
{"created":"2025-05-22","title":"SSR: Enhancing Depth Perception in Vision-Language Models via Rationale-Guided Spatial Reasoning","abstract":"Despite impressive advancements in Visual-Language Models (VLMs) for multi-modal tasks, their reliance on RGB inputs limits precise spatial understanding. Existing methods for integrating spatial cues, such as point clouds or depth, either require specialized sensors or fail to effectively exploit depth information for higher-order reasoning. To this end, we propose a novel Spatial Sense and Reasoning method, dubbed SSR, a novel framework that transforms raw depth data into structured, interpretable textual rationales. These textual rationales serve as meaningful intermediate representations to significantly enhance spatial reasoning capabilities. Additionally, we leverage knowledge distillation to compress the generated rationales into compact latent embeddings, which facilitate resource-efficient and plug-and-play integration into existing VLMs without retraining. To enable comprehensive evaluation, we introduce a new dataset named SSR-CoT, a million-scale visual-language reasoning dataset enriched with intermediate spatial reasoning annotations, and present SSRBench, a comprehensive multi-task benchmark. Extensive experiments on multiple benchmarks demonstrate SSR substantially improves depth utilization and enhances spatial reasoning, thereby advancing VLMs toward more human-like multi-modal understanding. Our project page is at https://yliu-cs.github.io/SSR.","authors":["Yang Liu","Ming Ma","Xiaomin Yu","Pengxiang Ding","Han Zhao","Mingyang Sun","Siteng Huang","Donglin Wang"],"url":"https://arxiv.org/abs/2505.12448"}
{"created":"2025-05-22","title":"Video-GPT via Next Clip Diffusion","abstract":"GPT has shown its remarkable success in natural language processing. However, the language sequence is not sufficient to describe spatial-temporal details in the visual world. Alternatively, the video sequence is good at capturing such details. Motivated by this fact, we propose a concise Video-GPT in this paper by treating video as new language for visual world modeling. By analogy to next token prediction in GPT, we introduce a novel next clip diffusion paradigm for pretraining Video-GPT. Different from the previous works, this distinct paradigm allows Video-GPT to tackle both short-term generation and long-term prediction, by autoregressively denoising the noisy clip according to the clean clips in the history. Extensive experiments show our Video-GPT achieves the state-of-the-art performance on video prediction, which is the key factor towards world modeling (Physics-IQ Benchmark: Video-GPT 34.97 vs. Kling 23.64 vs. Wan 20.89). Moreover, it can be well adapted on 6 mainstream video tasks in both video generation and understanding, showing its great generalization capacity in downstream. The project page is at https://zhuangshaobin.github.io/Video-GPT.github.io/.","authors":["Shaobin Zhuang","Zhipeng Huang","Ying Zhang","Fangyikang Wang","Canmiao Fu","Binxin Yang","Chong Sun","Chen Li","Yali Wang"],"url":"https://arxiv.org/abs/2505.12489"}
{"created":"2025-05-22","title":"Towards Reliable and Interpretable Traffic Crash Pattern Prediction and Safety Interventions Using Customized Large Language Models","abstract":"Predicting crash events is crucial for understanding crash distributions and their contributing factors, thereby enabling the design of proactive traffic safety policy interventions. However, existing methods struggle to interpret the complex interplay among various sources of traffic crash data, including numeric characteristics, textual reports, crash imagery, environmental conditions, and driver behavior records. As a result, they often fail to capture the rich semantic information and intricate interrelationships embedded in these diverse data sources, limiting their ability to identify critical crash risk factors. In this research, we propose TrafficSafe, a framework that adapts LLMs to reframe crash prediction and feature attribution as text-based reasoning. A multi-modal crash dataset including 58,903 real-world reports together with belonged infrastructure, environmental, driver, and vehicle information is collected and textualized into TrafficSafe Event Dataset. By customizing and fine-tuning LLMs on this dataset, the TrafficSafe LLM achieves a 42% average improvement in F1-score over baselines. To interpret these predictions and uncover contributing factors, we introduce TrafficSafe Attribution, a sentence-level feature attribution framework enabling conditional risk analysis. Findings show that alcohol-impaired driving is the leading factor in severe crashes, with aggressive and impairment-related behaviors having nearly twice the contribution for severe crashes compared to other driver behaviors. Furthermore, TrafficSafe Attribution highlights pivotal features during model training, guiding strategic crash data collection for iterative performance improvements. The proposed TrafficSafe offers a transformative leap in traffic safety research, providing a blueprint for translating advanced AI technologies into responsible, actionable, and life-saving outcomes.","authors":["Yang Zhao","Pu Wang","Yibo Zhao","Hongru Du","Hao Frank Yang"],"url":"https://arxiv.org/abs/2505.12545"}
{"created":"2025-05-22","title":"PoisonArena: Uncovering Competing Poisoning Attacks in Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) systems, widely used to improve the factual grounding of large language models (LLMs), are increasingly vulnerable to poisoning attacks, where adversaries inject manipulated content into the retriever's corpus. While prior research has predominantly focused on single-attacker settings, real-world scenarios often involve multiple, competing attackers with conflicting objectives. In this work, we introduce PoisonArena, the first benchmark to systematically study and evaluate competing poisoning attacks in RAG. We formalize the multi-attacker threat model, where attackers vie to control the answer to the same query using mutually exclusive misinformation. PoisonArena leverages the Bradley-Terry model to quantify each method's competitive effectiveness in such adversarial environments. Through extensive experiments on the Natural Questions and MS MARCO datasets, we demonstrate that many attack strategies successful in isolation fail under competitive pressure. Our findings highlight the limitations of conventional evaluation metrics like Attack Success Rate (ASR) and F1 score and underscore the need for competitive evaluation to assess real-world attack robustness. PoisonArena provides a standardized framework to benchmark and develop future attack and defense strategies under more realistic, multi-adversary conditions. Project page: https://github.com/yxf203/PoisonArena.","authors":["Liuji Chen","Xiaofang Yang","Yuanzhuo Lu","Jinghao Zhang","Xin Sun","Qiang Liu","Shu Wu","Jing Dong","Liang Wang"],"url":"https://arxiv.org/abs/2505.12574"}
{"created":"2025-05-22","title":"Learning Cross-Spectral Point Features with Task-Oriented Training","abstract":"Unmanned aerial vehicles (UAVs) enable operations in remote and hazardous environments, yet the visible-spectrum, camera-based navigation systems often relied upon by UAVs struggle in low-visibility conditions. Thermal cameras, which capture long-wave infrared radiation, are able to function effectively in darkness and smoke, where visible-light cameras fail. This work explores learned cross-spectral (thermal-visible) point features as a means to integrate thermal imagery into established camera-based navigation systems. Existing methods typically train a feature network's detection and description outputs directly, which often focuses training on image regions where thermal and visible-spectrum images exhibit similar appearance. Aiming to more fully utilize the available data, we propose a method to train the feature network on the tasks of matching and registration. We run our feature network on thermal-visible image pairs, then feed the network response into a differentiable registration pipeline. Losses are applied to the matching and registration estimates of this pipeline. Our selected model, trained on the task of matching, achieves a registration error (corner error) below 10 pixels for more than 75% of estimates on the MultiPoint dataset. We further demonstrate that our model can also be used with a classical pipeline for matching and registration.","authors":["Mia Thomas","Trevor Ablett","Jonathan Kelly"],"url":"https://arxiv.org/abs/2505.12593"}
{"created":"2025-05-22","title":"BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation","abstract":"Advances in AI generative models facilitate super-realistic video synthesis, amplifying misinformation risks via social media and eroding trust in digital content. Several research works have explored new deepfake detection methods on AI-generated images to alleviate these risks. However, with the fast development of video generation models, such as Sora and WanX, there is currently a lack of large-scale, high-quality AI-generated video datasets for forgery detection. In addition, existing detection approaches predominantly treat the task as binary classification, lacking explainability in model decision-making and failing to provide actionable insights or guidance for the public. To address these challenges, we propose \\textbf{GenBuster-200K}, a large-scale AI-generated video dataset featuring 200K high-resolution video clips, diverse latest generative techniques, and real-world scenes. We further introduce \\textbf{BusterX}, a novel AI-generated video detection and explanation framework leveraging multimodal large language model (MLLM) and reinforcement learning for authenticity determination and explainable rationale. To our knowledge, GenBuster-200K is the {\\it \\textbf{first}} large-scale, high-quality AI-generated video dataset that incorporates the latest generative techniques for real-world scenarios. BusterX is the {\\it \\textbf{first}} framework to integrate MLLM with reinforcement learning for explainable AI-generated video detection. Extensive comparisons with state-of-the-art methods and ablation studies validate the effectiveness and generalizability of BusterX. The code, models, and datasets will be released.","authors":["Haiquan Wen","Yiwei He","Zhenglin Huang","Tianxiao Li","Zihan Yu","Xingru Huang","Lu Qi","Baoyuan Wu","Xiangtai Li","Guangliang Cheng"],"url":"https://arxiv.org/abs/2505.12620"}
{"created":"2025-05-22","title":"GDPRShield: AI-Powered GDPR Support for Software Developers in Small and Medium-Sized Enterprises","abstract":"With the rapid increase in privacy violations in modern software development, regulatory frameworks such as the General Data Protection Regulation (GDPR) have been established to enforce strict data protection practices. However, insufficient privacy awareness among SME software developers contributes to failure in GDPR compliance. For instance, a developer unfamiliar with data minimization may build a system that collects excessive data, violating GDPR and risking fines. One reason for this lack of awareness is that developers in SMEs often take on multidisciplinary roles (e.g., front-end, back-end, database management, and privacy compliance), which limits specialization in privacy. This lack of awareness may lead to poor privacy attitudes, ultimately hindering the development of a strong organizational privacy culture. However, SMEs that achieve GDPR compliance may gain competitive advantages, such as increased user trust and marketing value, compared to others that do not.","authors":["Tharaka Wijesundara","Mathew Warren","Nalin Arachchilage"],"url":"https://arxiv.org/abs/2505.12640"}
{"created":"2025-05-22","title":"\"I will never pay for this\" Perception of fairness and factors affecting behaviour on 'pay-or-ok' models","abstract":"The rise of cookie paywalls ('pay-or-ok' models) has prompted growing debates around privacy, monetisation, and the legitimacy of user consent. Despite their increasing use across sectors, limited research has explored how users perceive these models or what shapes their decisions to either consent to tracking or pay. To address this gap, we conducted four focus groups (n = 14) to examine users' perceptions of cookie paywalls, their judgments of fairness, and the conditions under which they might consider paying, alongside a legal analysis within the EU data protection legal framework.","authors":["Victor Morel","Farzaneh Karegar","Cristiana Santos"],"url":"https://arxiv.org/abs/2505.12892"}
{"created":"2025-05-22","title":"A Path to Universal Neural Cellular Automata","abstract":"Cellular automata have long been celebrated for their ability to generate complex behaviors from simple, local rules, with well-known discrete models like Conway's Game of Life proven capable of universal computation. Recent advancements have extended cellular automata into continuous domains, raising the question of whether these systems retain the capacity for universal computation. In parallel, neural cellular automata have emerged as a powerful paradigm where rules are learned via gradient descent rather than manually designed. This work explores the potential of neural cellular automata to develop a continuous Universal Cellular Automaton through training by gradient descent. We introduce a cellular automaton model, objective functions and training strategies to guide neural cellular automata toward universal computation in a continuous setting. Our experiments demonstrate the successful training of fundamental computational primitives - such as matrix multiplication and transposition - culminating in the emulation of a neural network solving the MNIST digit classification task directly within the cellular automata state. These results represent a foundational step toward realizing analog general-purpose computers, with implications for understanding universal computation in continuous dynamics and advancing the automated discovery of complex cellular automata behaviors via machine learning.","authors":["Gabriel B\\'ena","Maxence Faldor","Dan F. M. Goodman","Antoine Cully"],"url":"https://arxiv.org/abs/2505.13058"}
{"created":"2025-05-22","title":"Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model","abstract":"Humans can intuitively infer sounds from silent videos, but whether multimodal large language models can perform modal-mismatch reasoning without accessing target modalities remains relatively unexplored. Current text-assisted-video-to-audio (VT2A) methods excel in video foley tasks but struggle to acquire audio descriptions during inference. We introduce the task of Reasoning Audio Descriptions from Silent Videos (SVAD) to address this challenge and investigate vision-language models' (VLMs) capabilities on this task. To further enhance the VLMs' reasoning capacity for the SVAD task, we construct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based supervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks demonstrate our method's effectiveness in two key aspects: significantly improving VLMs' modal-mismatch reasoning for SVAD and effectively addressing the challenge of acquiring audio descriptions during VT2A inference.","authors":["Yong Ren","Chenxing Li","Le Xu","Hao Gu","Duzhen Zhang","Yujie Chen","Manjie Xu","Ruibo Fu","Shan Yang","Dong Yu"],"url":"https://arxiv.org/abs/2505.13062"}
{"created":"2025-05-22","title":"DD-Ranking: Rethinking the Evaluation of Dataset Distillation","abstract":"In recent years, dataset distillation has provided a reliable solution for data compression, where models trained on the resulting smaller synthetic datasets achieve performance comparable to those trained on the original datasets. To further improve the performance of synthetic datasets, various training pipelines and optimization objectives have been proposed, greatly advancing the field of dataset distillation. Recent decoupled dataset distillation methods introduce soft labels and stronger data augmentation during the post-evaluation phase and scale dataset distillation up to larger datasets (e.g., ImageNet-1K). However, this raises a question: Is accuracy still a reliable metric to fairly evaluate dataset distillation methods? Our empirical findings suggest that the performance improvements of these methods often stem from additional techniques rather than the inherent quality of the images themselves, with even randomly sampled images achieving superior results. Such misaligned evaluation settings severely hinder the development of DD. Therefore, we propose DD-Ranking, a unified evaluation framework, along with new general evaluation metrics to uncover the true performance improvements achieved by different methods. By refocusing on the actual information enhancement of distilled datasets, DD-Ranking provides a more comprehensive and fair evaluation standard for future research advancements.","authors":["Zekai Li","Xinhao Zhong","Samir Khaki","Zhiyuan Liang","Yuhao Zhou","Mingjia Shi","Ziqiao Wang","Xuanlei Zhao","Wangbo Zhao","Ziheng Qin","Mengxuan Wu","Pengfei Zhou","Haonan Wang","David Junhao Zhang","Jia-Wei Liu","Shaobo Wang","Dai Liu","Linfeng Zhang","Guang Li","Kun Wang","Zheng Zhu","Zhiheng Ma","Joey Tianyi Zhou","Jiancheng Lv","Yaochu Jin","Peihao Wang","Kaipeng Zhang","Lingjuan Lyu","Yiran Huang","Zeynep Akata","Zhiwei Deng","Xindi Wu","George Cazenavette","Yuzhang Shang","Justin Cui","Jindong Gu","Qian Zheng","Hao Ye","Shuo Wang","Xiaobo Wang","Yan Yan","Angela Yao","Mike Zheng Shou","Tianlong Chen","Hakan Bilen","Baharan Mirzasoleiman","Manolis Kellis","Konstantinos N. Plataniotis","Zhangyang Wang","Bo Zhao","Yang You","Kai Wang"],"url":"https://arxiv.org/abs/2505.13300"}
{"created":"2025-05-22","title":"Unlabeled Data or Pre-trained Model: Rethinking Semi-Supervised Learning and Pretrain-Finetuning","abstract":"Semi-supervised learning (SSL) alleviates the cost of data labeling process by exploiting unlabeled data, and has achieved promising results on various tasks such as image classification. Meanwhile, the Pretrain-Finetuning paradigm has garnered significant attention in recent years, and exploiting pre-trained models could also reduce the requirement of labeled data in downstream tasks. Therefore, a question naturally occurs: \\emph{When the labeled data is scarce in the target tasks, should we exploit unlabeled data or pre-trained models?} To answer this question, we select pre-trained Vision-Language Models (VLMs) as representative pretrain-finetuning instances and propose \\textit{Few-shot SSL} -- a framework that enables fair comparison between these two paradigms by controlling the amount of labeled data used. Extensive experiments across various settings demonstrate that pre-trained VLMs generally outperform SSL methods in nearly all cases, except when the data has low resolution or lacks clear semantic structure. Therefore, we encourage future SSL research to compare with pre-trained models and explore deeper integration, such as using pre-trained knowledge to enhance pseudo-labeling. To support future research, we release our unified reproduction and evaluation framework. Codes are available \\href{https://anonymous.4open.science/r/Rethinking-SSL-and-Pretrain-Finetuning-5566 }{here}.","authors":["Song-Lin Lv","Rui Zhu","Yu-Feng Li","Lan-Zhe Guo"],"url":"https://arxiv.org/abs/2505.13317"}
{"created":"2025-05-22","title":"Faster Video Diffusion with Trainable Sparse Attention","abstract":"Scaling video diffusion transformers (DiTs) is limited by their quadratic 3D attention, even though most of the attention mass concentrates on a small subset of positions. We turn this observation into VSA, a trainable, hardware-efficient sparse attention that replaces full attention at \\emph{both} training and inference. In VSA, a lightweight coarse stage pools tokens into tiles and identifies high-weight \\emph{critical tokens}; a fine stage computes token-level attention only inside those tiles subjecting to block computing layout to ensure hard efficiency. This leads to a single differentiable kernel that trains end-to-end, requires no post-hoc profiling, and sustains 85\\% of FlashAttention3 MFU. We perform a large sweep of ablation studies and scaling-law experiments by pretraining DiTs from 60M to 1.4B parameters. VSA reaches a Pareto point that cuts training FLOPS by 2.53$\\times$ with no drop in diffusion loss. Retrofitting the open-source Wan-2.1 model speeds up attention time by 6$\\times$ and lowers end-to-end generation time from 31s to 18s with comparable quality. These results establish trainable sparse attention as a practical alternative to full attention and a key enabler for further scaling of video diffusion models.","authors":["Peiyuan Zhang","Haofeng Huang","Yongqi Chen","Will Lin","Zhengzhong Liu","Ion Stoica","Eric Xing","Hao Zhang"],"url":"https://arxiv.org/abs/2505.13389"}
{"created":"2025-05-22","title":"Granary: Speech Recognition and Translation Dataset in 25 European Languages","abstract":"Multi-task and multilingual approaches benefit large models, yet speech processing for low-resource languages remains underexplored due to data scarcity. To address this, we present Granary, a large-scale collection of speech datasets for recognition and translation across 25 European languages. This is the first open-source effort at this scale for both transcription and translation. We enhance data quality using a pseudo-labeling pipeline with segmentation, two-pass inference, hallucination filtering, and punctuation restoration. We further generate translation pairs from pseudo-labeled transcriptions using EuroLLM, followed by a data filtration pipeline. Designed for efficiency, our pipeline processes vast amount of data within hours. We assess models trained on processed data by comparing their performance on previously curated datasets for both high- and low-resource languages. Our findings show that these models achieve similar performance using approx. 50% less data. Dataset will be made available at https://hf.co/datasets/nvidia/Granary","authors":["Nithin Rao Koluguri","Monica Sekoyan","George Zelenfroynd","Sasha Meister","Shuoyang Ding","Sofia Kostandian","He Huang","Nikolay Karpov","Jagadeesh Balam","Vitaly Lavrukhin","Yifan Peng","Sara Papi","Marco Gaido","Alessio Brutti","Boris Ginsburg"],"url":"https://arxiv.org/abs/2505.13404"}
{"created":"2025-05-22","title":"Sparc3D: Sparse Representation and Construction for High-Resolution 3D Shapes Modeling","abstract":"High-fidelity 3D object synthesis remains significantly more challenging than 2D image generation due to the unstructured nature of mesh data and the cubic complexity of dense volumetric grids. Existing two-stage pipelines-compressing meshes with a VAE (using either 2D or 3D supervision), followed by latent diffusion sampling-often suffer from severe detail loss caused by inefficient representations and modality mismatches introduced in VAE. We introduce Sparc3D, a unified framework that combines a sparse deformable marching cubes representation Sparcubes with a novel encoder Sparconv-VAE. Sparcubes converts raw meshes into high-resolution ($1024^3$) surfaces with arbitrary topology by scattering signed distance and deformation fields onto a sparse cube, allowing differentiable optimization. Sparconv-VAE is the first modality-consistent variational autoencoder built entirely upon sparse convolutional networks, enabling efficient and near-lossless 3D reconstruction suitable for high-resolution generative modeling through latent diffusion. Sparc3D achieves state-of-the-art reconstruction fidelity on challenging inputs, including open surfaces, disconnected components, and intricate geometry. It preserves fine-grained shape details, reduces training and inference cost, and integrates naturally with latent diffusion models for scalable, high-resolution 3D generation.","authors":["Zhihao Li","Yufei Wang","Heliang Zheng","Yihao Luo","Bihan Wen"],"url":"https://arxiv.org/abs/2505.14521"}
{"created":"2025-05-22","title":"Q-fid: Quantum Circuit Fidelity Improvement with LSTM Networks","abstract":"The fidelity of quantum circuits (QC) is influenced by several factors, including hardware characteristics, calibration status, and the transpilation process, all of which impact their susceptibility to noise. However, existing methods struggle to estimate and compare the noise performance of different circuit layouts due to fluctuating error rates and the absence of a standardized fidelity metric. In this work, Q-fid is introduced, a Long Short-Term Memory (LSTM) based fidelity prediction system accompanied by a novel metric designed to quantify the fidelity of quantum circuits. Q-fid provides an intuitive way to predict the noise performance of Noisy Intermediate-Scale Quantum (NISQ) circuits. This approach frames fidelity prediction as a Time Series Forecasting problem to analyze the tokenized circuits, capturing the causal dependence of the gate sequences and their impact on overall fidelity. Additionally, the model is capable of dynamically adapting to changes in hardware characteristics, ensuring accurate fidelity predictions under varying conditions. Q-fid achieves a high prediction accuracy with an average RMSE of 0.0515, up to 24.7x more accurate than the Qiskit transpile tool mapomatic. By offering a reliable method for fidelity prediction, Q-fid empowers developers to optimize transpilation strategies, leading to more efficient and noise-resilient quantum circuit implementations.","authors":["Yikai Mao","Shaswot Shresthamali","Masaaki Kondo"],"url":"https://arxiv.org/abs/2303.17523"}
{"created":"2025-05-22","title":"Generalizing Medical Image Representations via Quaternion Wavelet Networks","abstract":"Neural network generalizability is becoming a broad research field due to the increasing availability of datasets from different sources and for various tasks. This issue is even wider when processing medical data, where a lack of methodological standards causes large variations being provided by different imaging centers or acquired with various devices and cofactors. To overcome these limitations, we introduce a novel, generalizable, data- and task-agnostic framework able to extract salient features from medical images. The proposed quaternion wavelet network (QUAVE) can be easily integrated with any pre-existing medical image analysis or synthesis task, and it can be involved with real, quaternion, or hypercomplex-valued models, generalizing their adoption to single-channel data. QUAVE first extracts different sub-bands through the quaternion wavelet transform, resulting in both low-frequency/approximation bands and high-frequency/fine-grained features. Then, it weighs the most representative set of sub-bands to be involved as input to any other neural model for image processing, replacing standard data samples. We conduct an extensive experimental evaluation comprising different datasets, diverse image analysis, and synthesis tasks including reconstruction, segmentation, and modality translation. We also evaluate QUAVE in combination with both real and quaternion-valued models. Results demonstrate the effectiveness and the generalizability of the proposed framework that improves network performance while being flexible to be adopted in manifold scenarios and robust to domain shifts. The full code is available at: https://github.com/ispamm/QWT.","authors":["Luigi Sigillo","Eleonora Grassucci","Aurelio Uncini","Danilo Comminiello"],"url":"https://arxiv.org/abs/2310.10224"}
{"created":"2025-05-22","title":"Review: Quantum Architecture Search with Unsupervised Representation Learning","abstract":"Unsupervised representation learning presents new opportunities for advancing Quantum Architecture Search (QAS) on Noisy Intermediate-Scale Quantum (NISQ) devices. QAS is designed to optimize quantum circuits for Variational Quantum Algorithms (VQAs). Most QAS algorithms tightly couple the search space and search algorithm, typically requiring the evaluation of numerous quantum circuits, resulting in high computational costs and limiting scalability to larger quantum circuits. Predictor-based QAS algorithms mitigate this issue by estimating circuit performance based on structure or embedding. However, these methods often demand time-intensive labeling to optimize gate parameters across many circuits, which is crucial for training accurate predictors. Inspired by the classical neural architecture search algorithm Arch2vec, we investigate the potential of unsupervised representation learning for QAS without relying on predictors. Our framework decouples unsupervised architecture representation learning from the search process, enabling the learned representations to be applied across various downstream tasks. Additionally, it integrates an improved quantum circuit graph encoding scheme, addressing the limitations of existing representations and enhancing search efficiency. This predictor-free approach removes the need for large labeled datasets. During the search, we employ REINFORCE and Bayesian Optimization to explore the latent representation space and compare their performance against baseline methods. We further validate our approach by executing the best-discovered MaxCut circuits on IBM's ibm_sherbrooke quantum processor, confirming that the architectures retain optimal performance even under real hardware noise. Our results demonstrate that the framework efficiently identifies high-performing quantum circuits with fewer search iterations.","authors":["Yize Sun","Zixin Wu","Yunpu Ma","Volker Tresp"],"url":"https://arxiv.org/abs/2401.11576"}
{"created":"2025-05-22","title":"Learning Memory Kernels in Generalized Langevin Equations","abstract":"We introduce a novel approach for learning memory kernels in Generalized Langevin Equations. This approach initially utilizes a regularized Prony method to estimate correlation functions from trajectory data, followed by regression over a Sobolev norm-based loss function with RKHS regularization. Our method guarantees improved performance within an exponentially weighted L^2 space, with the kernel estimation error controlled by the error in estimated correlation functions. We demonstrate the superiority of our estimator compared to other regression estimators that rely on L^2 loss functions and also an estimator derived from the inverse Laplace transform, using numerical examples that highlight its consistent advantage across various weight parameter selections. Additionally, we provide examples that include the application of force and drift terms in the equation.","authors":["Quanjun Lang","Jianfeng Lu"],"url":"https://arxiv.org/abs/2402.11705"}
{"created":"2025-05-22","title":"Positive Moments Forever: Undecidable and Decidable Cases","abstract":"We investigate the generalized moment membership problem for matrices, a formulation equivalent to Skolem's problem for linear recurrence sequences. We show decidability for orthogonal, unitary, and real eigenvalue matrices, and undecidability for matrices over certain commutative and non-commutative polynomial rings. As consequences, we deduce that positivity is decidable for simple unitary linear recurrence sequences and undecidable for linear recurrence sequences over commutative polynomial rings. As a byproduct, we also prove a free version of Polya's theorem.","authors":["Gemma De les Coves","Joshua Graf","Andreas Klingler","Tim Netzer"],"url":"https://arxiv.org/abs/2404.15053"}
{"created":"2025-05-22","title":"An interacting particle consensus method for constrained global optimization","abstract":"This paper presents a particle-based optimization method designed for addressing minimization problems with equality constraints, particularly in cases where the loss function exhibits non-differentiability or non-convexity. The proposed method combines components from consensus-based optimization algorithm with a newly introduced forcing term directed at the constraint set. A rigorous mean-field limit of the particle system is derived, and the convergence of the mean-field limit to the constrained minimizer is established. Additionally, we introduce a stable discretized algorithm and conduct various numerical experiments to demonstrate the performance of the proposed method.","authors":["Jos\\'e A. Carrillo","Shi Jin","Haoyu Zhang","Yuhua Zhu"],"url":"https://arxiv.org/abs/2405.00891"}
{"created":"2025-05-22","title":"Product Design Using Generative Adversarial Network: Incorporating Consumer Preference and External Data","abstract":"The rise of generative artificial intelligence (AI) has facilitated automated product design but often neglects valuable consumer preference data within companies' internal datasets. Additionally, external sources such as social media and user-generated content (UGC) platforms contain substantial untapped information on product design and consumer preferences, yet remain underutilized. We propose a novel framework that transforms the product design paradigm to be data-driven, automated, and consumer-centric. Our method employs a semi-supervised deep generative architecture that systematically integrates multidimensional consumer preferences and heterogeneous external data. The framework is both generative and preference-aware, enabling companies to produce consumer-aligned designs with enhanced cost efficiency. Our framework trains a specialized predictor model to comprehend consumer preferences and utilizes predicted popularity metrics to guide a continuous conditional generative adversarial network (CcGAN). The trained CcGAN can directionally generate consumer-preferred designs, circumventing the expenditure associated with testing suboptimal candidates. Using external data, our framework offers particular advantages for start-ups or other resource-constrained companies confronting the ``cold-start\" problem. We demonstrate the framework's efficacy through an empirical application with a self-operated photography chain, where our model successfully generated superior photo template designs. We also conduct web-based experiments to verify our method and confirm its effectiveness across varying design contexts.","authors":["Hui Li","Jian Ni","Fangzhu Yang"],"url":"https://arxiv.org/abs/2405.15929"}
{"created":"2025-05-22","title":"Universal expansion of human mobility across urban scales","abstract":"Human mobility is a fundamental process underpinning socioeconomic life and urban structure. Classic theories, such as egocentric activity spaces and central place theory, provide crucial insights into specific facets of movement, like home-centricity and hierarchical spatial organization. However, identifying universal characteristics or an underlying principle that quantitatively links these disparate perspectives has remained a challenge. Here, we reveal such a connection by analyzing the spatial structure of individual daily mobility trajectories using network-based modules. We discover a universal scaling law: the spatial extent (radius) of these mobility modules expands sublinearly with increasing distance from home, a pattern consistent across three orders of magnitude. Furthermore, we demonstrate that these modules precisely map onto the nested hierarchy of urban systems, corresponding to local, city-level, and regional scales as distance from home increases. These findings deepen our understanding of human mobility dynamics and demonstrate the profound connection between classical urban theory, human geography, and mobility studies.","authors":["Lu Zhong","Lei Dong","Qi Wang","Chaoming Song","Jianxi Gao"],"url":"https://arxiv.org/abs/2406.06889"}
{"created":"2025-05-22","title":"Trikarenos: Design and Experimental Characterization of a Fault-Tolerant 28nm RISC-V-based SoC","abstract":"RISC-V-based fault-tolerant system-on-chip (SoC) designs are critical for the new generation of automotive and space SoC architectures. However, reliability assessment requires characterization under controlled radiation doses to accurately quantify the fault tolerance of the fabricated designs. This work analyzes the Trikarenos design, a SoC implemented in TSMC 28nm, for single event upset (SEU) vulnerability under atmospheric neutron and 200 MeV proton radiation, comparing these results to simulation-based fault injection. All faults in error correction codes (ECC) protected memory are corrected by a scrubber, showing an estimated cross-section per bit of up to $1.09 \\times 10^{-14}$ cm$^2$ bit$^{-1}$. Furthermore, the triple-core lockstep (TCLS) mechanism implemented in Trikarenos is validated and is shown to correct errors affecting a cross-section up to $3.23 \\times 10^{-11}$ cm$^2$, with the remaining uncorrectable vulnerability below $5.36 \\times 10^{-12}$ cm$^2$. When augmenting the experimental analysis of fabricated chips with gate-level fault injection in simulation, 99.10 % of injections into the SoC produced correct results, while 100 % of injections in the TCLS-protected cores were handled correctly. With 12.28 % of all injected faults leading to a TCLS recovery, this indicates an approximate effective flip-flop cross-section of up to $1.28 \\times 10^{-14}$ cm$^2$/FF.","authors":["Michael Rogenmoser","Philip Wiese","Bruno Endres Forlin","Frank K. G\\\"urkaynak","Paolo Rech","Alessandra Menicucci","Marco Ottavi","Luca Benini"],"url":"https://arxiv.org/abs/2407.05938"}
{"created":"2025-05-22","title":"Q-gen: A Parameterized Quantum Circuit Generator","abstract":"Unlike most classical algorithms that take an input and give the solution directly as an output, quantum algorithms produce a quantum circuit that works as an indirect solution to computationally hard problems. In the full quantum computing workflow, most data processing remains in the classical domain except for running the quantum circuit in the quantum processor. This leaves massive opportunities for classical automation and optimization toward future utilization of quantum computing. We kickstart the first step in this direction by introducing Q-gen, a high-level, parameterized quantum circuit generator incorporating 15 realistic quantum algorithms. Each customized generation function comes with algorithmspecific parameters beyond the number of qubits, providing a large generation volume with high circuit variability. To demonstrate the functionality of Q-gen, we organize the algorithms into 5 hierarchical systems and generate a quantum circuit dataset accompanied by their measurement histograms and state vectors. This dataset enables researchers to statistically analyze the structure, complexity, and performance of large-scale quantum circuits, or quickly train novel machine learning models without worrying about the exponentially growing simulation time. Q-gen is an open-source and multipurpose project that serves as the entrance for users with a classical computer science background to dive into the world of quantum computing.","authors":["Yikai Mao","Shaswot Shresthamali","Masaaki Kondo"],"url":"https://arxiv.org/abs/2407.18697"}
{"created":"2025-05-22","title":"Some properties of the principal Dirichlet eigenfunction in Lipschitz domains, via probabilistic couplings","abstract":"We study a discrete and continuous version of the spectral Dirichlet problem in an open bounded connected set $\\Omega\\subset \\mathbb{R}^d$, in dimension $d\\geq 2$. More precisely, consider the simple random walk on $\\mathbb{Z}^d$ killed upon exiting the (large) bounded domain $\\Omega_N = (N\\Omega)\\cap \\mathbb{Z}^d$. We let $P_N$ its transition matrix and we study the properties of its ($L^2$-normalized) principal eigenvector $\\phi_N$, also known as ground state. Under mild assumptions on $\\Omega$, we give regularity estimates on $\\phi_N$, namely on its $k$-th order differences, with a uniform control inside $\\Omega_N$. We provide a completely probabilistic proof of these estimates: our starting point is a Feynman--Kac representation of $\\phi_N$, combined with gambler's ruin estimates and a new ``multi-mirror'' coupling, which may be of independent interest. We also obtain the same type of estimates for the first eigenfunction $\\varphi_1$ of the corresponding continuous spectral Dirichlet problem, in relation with a Brownian motion killed upon exiting $\\Omega$. Finally, we take the opportunity to review (and slightly extend) some of the literature on the $L^2$ and uniform convergence of $\\phi_N$ to $\\varphi_1$ in Lipschitz bounded domains of $\\mathbb{R}^d$, which can be derived thanks to our estimates.","authors":["Quentin Berger","Nicolas Bouchot"],"url":"https://arxiv.org/abs/2408.15858"}
{"created":"2025-05-22","title":"Automate Strategy Finding with LLM in Quant Investment","abstract":"We present a novel three-stage framework leveraging Large Language Models (LLMs) within a risk-aware multi-agent system for automate strategy finding in quantitative finance. Our approach addresses the brittleness of traditional deep learning models in financial applications by: employing prompt-engineered LLMs to generate executable alpha factor candidates across diverse financial data, implementing multimodal agent-based evaluation that filters factors based on market status, predictive quality while maintaining category balance, and deploying dynamic weight optimization that adapts to market conditions. Experimental results demonstrate the robust performance of the strategy in Chinese & US market regimes compared to established benchmarks. Our work extends LLMs capabilities to quantitative trading, providing a scalable architecture for financial signal extraction and portfolio construction. The overall framework significantly outperforms all benchmarks with 53.17% cumulative return on SSE50 (Jan 2023 to Jan 2024), demonstrating superior risk-adjusted performance and downside protection on the market.","authors":["Zhizhuo Kou","Holam Yu","Junyu Luo","Jingshu Peng","Xujia Li","Chengzhong Liu","Juntao Dai","Lei Chen","Sirui Han","Yike Guo"],"url":"https://arxiv.org/abs/2409.06289"}
{"created":"2025-05-22","title":"Underapproximating Safe Domains of Attraction for Discrete-Time Systems Using Implicit Representations of Backward Reachable Sets","abstract":"Analyzing and certifying stability and attractivity of nonlinear systems is a topic of research interest that has been extensively investigated by control theorists and engineers for many years. Despite that, accurately estimating domains of attraction for nonlinear systems remains a challenging task, where available estimation approaches are either conservative or limited to low-dimensional systems. In this work, we propose an iterative approach to accurately underapproximate safe (i.e., state-constrained) domains of attraction for general discrete-time autonomous nonlinear systems. Our approach relies on implicit representations of safe backward reachable sets of safe regions of attraction, where such regions can be be easily constructed using, e.g., quadratic Lyapunov functions. The iterations of our approach are monotonic (in the sense of set inclusion), where each iteration results in a safe region of attraction, given as a sublevel set, that underapproximates the safe domain of attraction. The sublevel set representations of the resulting regions of attraction can be efficiently utilized in verifying the inclusion of given points of interest in the safe domain of attraction. We illustrate our approach through two numerical examples, involving two- and four-dimensional nonlinear systems.","authors":["Mohamed Serry","Jun Liu"],"url":"https://arxiv.org/abs/2409.10657"}
{"created":"2025-05-22","title":"How to Construct Random Unitaries","abstract":"The existence of pseudorandom unitaries (PRUs) -- efficient quantum circuits that are computationally indistinguishable from Haar-random unitaries -- has been a central open question, with significant implications for cryptography, complexity theory, and fundamental physics. In this work, we close this question by proving that PRUs exist, assuming that any quantum-secure one-way function exists. We establish this result for both (1) the standard notion of PRUs, which are secure against any efficient adversary that makes queries to the unitary $U$, and (2) a stronger notion of PRUs, which are secure even against adversaries that can query both the unitary $U$ and its inverse $U^\\dagger$. In the process, we prove that any algorithm that makes queries to a Haar-random unitary can be efficiently simulated on a quantum computer, up to inverse-exponential trace distance.","authors":["Fermi Ma","Hsin-Yuan Huang"],"url":"https://arxiv.org/abs/2410.10116"}
{"created":"2025-05-22","title":"Phase retrieval via media diversity","abstract":"This work studies phase retrieval for wave fields, aiming to recover the phase of an incoming wave from multi-plane intensity measurements behind different types of linear and nonlinear media. We show that unique phase retrieval can be achieved by utilizing intensity data produced by multiple media. This uniqueness does not require prescribed boundary conditions for the phase in the incidence plane, in contrast to existing phase retrieval methods based on the transport of intensity equation. Moreover, the uniqueness proofs lead to explicit phase reconstruction algorithms. Numerical simulations are presented to validate the theory.","authors":["Yan Cheng","Kui Ren","Nathan Soedjak"],"url":"https://arxiv.org/abs/2410.12767"}
{"created":"2025-05-22","title":"LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec","abstract":"Although discrete speech tokens have exhibited strong potential for language model-based speech generation, their high bitrates and redundant timbre information restrict the development of such models. In this work, we propose LSCodec, a discrete speech codec that has both low bitrate and speaker decoupling ability. LSCodec adopts a multi-stage unsupervised training framework with a speaker perturbation technique. A continuous information bottleneck is first established, followed by vector quantization that produces a discrete speaker-decoupled space. A discrete token vocoder finally refines acoustic details from LSCodec. By reconstruction evaluations, LSCodec demonstrates superior intelligibility and audio quality with only a single codebook and smaller vocabulary size than baselines. Voice conversion and speaker probing experiments prove the excellent speaker disentanglement of LSCodec, and ablation study verifies the effectiveness of the proposed training framework.","authors":["Yiwei Guo","Zhihan Li","Chenpeng Du","Hankun Wang","Xie Chen","Kai Yu"],"url":"https://arxiv.org/abs/2410.15764"}
{"created":"2025-05-22","title":"Bilinear Sequence Regression: A Model for Learning from Long Sequences of High-dimensional Tokens","abstract":"Current progress in artificial intelligence is centered around so-called large language models that consist of neural networks processing long sequences of high-dimensional vectors called tokens. Statistical physics provides powerful tools to study the functioning of learning with neural networks and has played a recognized role in the development of modern machine learning. The statistical physics approach relies on simplified and analytically tractable models of data. However, simple tractable models for long sequences of high-dimensional tokens are largely underexplored. Inspired by the crucial role models such as the single-layer teacher-student perceptron (aka generalized linear regression) played in the theory of fully connected neural networks, in this paper, we introduce and study the bilinear sequence regression (BSR) as one of the most basic models for sequences of tokens. We note that modern architectures naturally subsume the BSR model due to the skip connections. Building on recent methodological progress, we compute the Bayes-optimal generalization error for the model in the limit of long sequences of high-dimensional tokens, and provide a message-passing algorithm that matches this performance. We quantify the improvement that optimal learning brings with respect to vectorizing the sequence of tokens and learning via simple linear regression. We also unveil surprising properties of the gradient descent algorithms in the BSR model.","authors":["Vittorio Erba","Emanuele Troiani","Luca Biggio","Antoine Maillard","Lenka Zdeborov\\'a"],"url":"https://arxiv.org/abs/2410.18858"}
{"created":"2025-05-22","title":"AutoStep: Locally adaptive involutive MCMC","abstract":"Many common Markov chain Monte Carlo (MCMC) kernels can be formulated using a deterministic involutive proposal with a step size parameter. Selecting an appropriate step size is often a challenging task in practice; and for complex multiscale targets, there may not be one choice of step size that works well globally. In this work, we address this problem with a novel class of involutive MCMC methods -- AutoStep MCMC -- that selects an appropriate step size at each iteration adapted to the local geometry of the target distribution. We prove that under mild conditions AutoStep MCMC is $\\pi$-invariant, irreducible, and aperiodic, and obtain bounds on expected energy jump distance and cost per iteration. Empirical results examine the robustness and efficacy of our proposed step size selection procedure, and show that AutoStep MCMC is competitive with state-of-the-art methods in terms of effective sample size per unit cost on a range of challenging target distributions.","authors":["Tiange Liu","Nikola Surjanovic","Miguel Biron-Lattes","Alexandre Bouchard-C\\^ot\\'e","Trevor Campbell"],"url":"https://arxiv.org/abs/2410.18929"}
{"created":"2025-05-22","title":"A Generative Diffusion Model to Solve Inverse Problems for Robust in-NICU Neonatal MRI","abstract":"We present the first acquisition-agnostic diffusion generative model for Magnetic Resonance Imaging (MRI) in the neonatal intensive care unit (NICU) to solve a range of inverse problems for shortening scan time and improving motion robustness. In-NICU MRI scanners leverage permanent magnets at lower field-strengths (i.e., below 1.5 Tesla) for non-invasive assessment of potential brain abnormalities during the critical phase of early live development, but suffer from long scan times and motion artifacts. In this setting, training data sizes are small and intrinsically suffer from low signal-to-noise ratio (SNR). This work trains a diffusion probabilistic generative model using such a real-world training dataset of clinical neonatal MRI by applying several novel signal processing and machine learning methods to handle the low SNR and low quantity of data. The model is then used as a statistical image prior to solve various inverse problems at inference time without requiring any retraining. Experiments demonstrate the generative model's utility for three real-world applications of neonatal MRI: accelerated reconstruction, motion correction, and super-resolution.","authors":["Yamin Arefeen","Brett Levac","Jonathan I. Tamir"],"url":"https://arxiv.org/abs/2410.21602"}
{"created":"2025-05-22","title":"Quantum Relay Channels","abstract":"Communication over a fully quantum relay channel is considered. We establish three bounds based on different coding strategies, i.e., partial decode-forward, measure-forward, and assist-forward. Using the partial-decode forward strategy, the relay decodes part of the information, while the other part is decoded without the relay's help. The result by Savov et al. (2012) for a classical-quantum relay channel is obtained as a special case. Based on our partial-decode forward bound, the capacity is determined for Hadamard relay channels. In the measure-forward coding scheme, the relay performs a sequence of measurements and then sends a compressed representation of the measurement outcome to the destination receiver. The measure-forward strategy can be viewed as a generalization of the classical compress-forward bound. At last, we consider quantum relay channels with orthogonal receiver components. The assist-forward bound is based on a new approach, whereby the transmitter sends the message to the relay and simultaneously generates entanglement assistance between the relay and the destination receiver. Subsequently, the relay can transmit the message to the destination receiver with rate-limited entanglement assistance.","authors":["Uzi Pereg"],"url":"https://arxiv.org/abs/2411.16263"}
{"created":"2025-05-22","title":"Mixed-Precision Quantization: Make the Best Use of Bits Where They Matter Most","abstract":"Mixed-precision quantization offers superior performance to fixed-precision quantization. It has been widely used in signal processing, communication systems, and machine learning. In mixed-precision quantization, bit allocation is essential. Hence, in this paper, we propose a new bit allocation framework for mixed-precision quantization from a search perspective. First, we formulate a general bit allocation problem for mixed-precision quantization. Then we introduce the penalized particle swarm optimization (PPSO) algorithm to address the integer consumption constraint. To improve efficiency and avoid iterations on infeasible solutions within the PPSO algorithm, a greedy criterion particle swarm optimization (GC-PSO) algorithm is proposed. The corresponding convergence analysis is derived based on dynamical system theory. Furthermore, we apply the above framework to some specific classic fields, i.e., finite impulse response (FIR) filters, receivers, and gradient descent. Numerical examples in each application underscore the superiority of the proposed framework to the existing algorithms.","authors":["Yiming Fang","Li Chen","Yunfei Chen","Weidong Wang","Changsheng You"],"url":"https://arxiv.org/abs/2412.03101"}
{"created":"2025-05-22","title":"From KAN to GR-KAN: Advancing Speech Enhancement with KAN-Based Methodology","abstract":"Deep neural network (DNN)-based speech enhancement (SE) usually uses conventional activation functions, which lack the expressiveness to capture complex multiscale structures needed for high-fidelity SE. Group-Rational KAN (GR-KAN), a variant of Kolmogorov-Arnold Networks (KAN), retains KAN's expressiveness while improving scalability on complex tasks. We adapt GR-KAN to existing DNN-based SE by replacing dense layers with GR-KAN layers in the time-frequency (T-F) domain MP-SENet and adapting GR-KAN's activations into the 1D CNN layers in the time-domain Demucs. Results on Voicebank-DEMAND show that GR-KAN requires up to 4x fewer parameters while improving PESQ by up to 0.1. In contrast, KAN, facing scalability issues, outperforms MLP on a small-scale signal modeling task but fails to improve MP-SENet. We demonstrate the first successful use of KAN-based methods for consistent improvement in both time- and SoTA TF-domain SE, establishing GR-KAN as a promising alternative for SE.","authors":["Haoyang Li","Yuchen Hu","Chen Chen","Sabato Marco Siniscalchi","Songting Liu","Eng Siong Chng"],"url":"https://arxiv.org/abs/2412.17778"}
{"created":"2025-05-22","title":"Beyond Log-Concavity and Score Regularity: Improved Convergence Bounds for Score-Based Generative Models in W2-distance","abstract":"Score-based Generative Models (SGMs) aim to sample from a target distribution by learning score functions using samples perturbed by Gaussian noise. Existing convergence bounds for SGMs in the $\\mathcal{W}_2$-distance rely on stringent assumptions about the data distribution. In this work, we present a novel framework for analyzing $\\mathcal{W}_2$-convergence in SGMs, significantly relaxing traditional assumptions such as log-concavity and score regularity. Leveraging the regularization properties of the Ornstein--Uhlenbeck (OU) process, we show that weak log-concavity of the data distribution evolves into log-concavity over time. This transition is rigorously quantified through a PDE-based analysis of the Hamilton--Jacobi--Bellman equation governing the log-density of the forward process. Moreover, we establish that the drift of the time-reversed OU process alternates between contractive and non-contractive regimes, reflecting the dynamics of concavity. Our approach circumvents the need for stringent regularity conditions on the score function and its estimators, relying instead on milder, more practical assumptions. We demonstrate the wide applicability of this framework through explicit computations on Gaussian mixture models, illustrating its versatility and potential for broader classes of data distributions.","authors":["Marta Gentiloni-Silveri","Antonio Ocello"],"url":"https://arxiv.org/abs/2501.02298"}
{"created":"2025-05-22","title":"Enhancing Intelligibility for Generative Target Speech Extraction via Joint Optimization with Target Speaker ASR","abstract":"Target speech extraction (TSE) isolates the speech of a specific speaker from a multi-talker overlapped speech mixture. Most existing TSE models rely on discriminative methods, typically predicting a time-frequency spectrogram mask for the target speech. However, imperfections in these masks often result in over-/under-suppression of target/non-target speech, degrading perceptual quality. Generative methods, by contrast, re-synthesize target speech based on the mixture and target speaker cues, achieving superior perceptual quality. Nevertheless, these methods often overlook speech intelligibility, leading to alterations or loss of semantic content in the re-synthesized speech. Inspired by the Whisper model's success in target speaker ASR, we propose a generative TSE framework based on the pre-trained Whisper model to address the above issues. This framework integrates semantic modeling with flow-based acoustic modeling to achieve both high intelligibility and perceptual quality. Results from multiple benchmarks demonstrate that the proposed method outperforms existing generative and discriminative baselines. We present speech samples on https://aisaka0v0.github.io/GenerativeTSE_demo/.","authors":["Hao Ma","Rujin Chen","Xiao-Lei Zhang","Ju Liu","Xuelong Li"],"url":"https://arxiv.org/abs/2501.14477"}
{"created":"2025-05-22","title":"Benchmarking Quantum Reinforcement Learning","abstract":"Benchmarking and establishing proper statistical validation metrics for reinforcement learning (RL) remain ongoing challenges, where no consensus has been established yet. The emergence of quantum computing and its potential applications in quantum reinforcement learning (QRL) further complicate benchmarking efforts. To enable valid performance comparisons and to streamline current research in this area, we propose a novel benchmarking methodology, which is based on a statistical estimator for sample complexity and a definition of statistical outperformance. Furthermore, considering QRL, our methodology casts doubt on some previous claims regarding its superiority. We conducted experiments on a novel benchmarking environment with flexible levels of complexity. While we still identify possible advantages, our findings are more nuanced overall. We discuss the potential limitations of these results and explore their implications for empirical research on quantum advantage in QRL.","authors":["Nico Meyer","Christian Ufrecht","George Yammine","Georgios Kontes","Christopher Mutschler","Daniel D. Scherer"],"url":"https://arxiv.org/abs/2501.15893"}
{"created":"2025-05-22","title":"WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning","abstract":"Current speech encoding pipelines often rely on an additional text-based LM to get robust representations of human communication, even though SotA speech-to-text models often have a LM within. This work proposes an approach to improve the LM within an audio model such that the subsequent text-LM is unnecessary. We introduce WhiSPA (Whisper with Semantic and Psychological Alignment), which leverages a novel audio training objective: contrastive loss with a language model embedding as a teacher. Using over 500k speech segments from mental health audio interviews, we evaluate the utility of aligning Whisper's latent space with semantic representations from a text autoencoder (SBERT) and lexically derived embeddings of basic psychological dimensions: emotion and personality. Over self-supervised affective tasks and downstream psychological tasks, WhiSPA surpasses current speech encoders, achieving an average error reduction of 73.4% and 83.8%, respectively. WhiSPA demonstrates that it is not always necessary to run a subsequent text LM on speech-to-text output in order to get a rich psychological representation of human communication.","authors":["Rajath Rao","Adithya Ganesan","Oscar Kjell","Jonah Luby","Akshay Raghavan","Scott Feltman","Whitney Ringwald","Ryan L. Boyd","Benjamin Luft","Camilo Ruggero","Neville Ryant","Roman Kotov","H. Andrew Schwartz"],"url":"https://arxiv.org/abs/2501.16344"}
{"created":"2025-05-22","title":"Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology","abstract":"A crucial step to efficiently integrate Whole Slide Images (WSIs) in computational pathology is assigning a single high-quality feature vector, i.e., one embedding, to each WSI. With the existence of many pre-trained deep neural networks and the emergence of foundation models, extracting embeddings for sub-images (i.e., tiles or patches) is straightforward. However, for WSIs, given their high resolution and gigapixel nature, inputting them into existing GPUs as a single image is not feasible. As a result, WSIs are usually split into many patches. Feeding each patch to a pre-trained model, each WSI can then be represented by a set of patches, hence, a set of embeddings. Hence, in such a setup, WSI representation learning reduces to set representation learning where for each WSI we have access to a set of patch embeddings. To obtain a single embedding from a set of patch embeddings for each WSI, multiple set-based learning schemes have been proposed in the literature. In this paper, we evaluate the WSI search performance of multiple recently developed aggregation techniques (mainly set representation learning techniques) including simple average or max pooling operations, Deep Sets, Memory networks, Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse and binary Fisher Vector on four different primary sites including bladder, breast, kidney, and Colon from TCGA. Further, we benchmark the search performance of these methods against the median of minimum distances of patch embeddings, a non-aggregating approach used for WSI retrieval.","authors":["Sobhan Hemati","Ghazal Alabtah","Saghir Alfasly","H. R. Tizhoosh"],"url":"https://arxiv.org/abs/2501.17822"}
{"created":"2025-05-22","title":"Statistical Collusion by Collectives on Learning Platforms","abstract":"As platforms increasingly rely on learning algorithms, collectives may form and seek ways to influence these platforms to align with their own interests. This can be achieved by coordinated submission of altered data. To evaluate the potential impact of such behavior, it is essential to understand the computations that collectives must perform to impact platforms in this way. In particular, collectives need to make a priori assessments of the effect of the collective before taking action, as they may face potential risks when modifying their data. Moreover they need to develop implementable coordination algorithms based on quantities that can be inferred from observed data. We develop a framework that provides a theoretical and algorithmic treatment of these issues and present experimental results in a product evaluation domain.","authors":["Etienne Gauthier","Francis Bach","Michael I. Jordan"],"url":"https://arxiv.org/abs/2502.04879"}
{"created":"2025-05-22","title":"Convergence of TD(0) under Polynomial Mixing with Nonlinear Function Approximation","abstract":"Temporal Difference Learning (TD(0)) is fundamental in reinforcement learning, yet its finite-sample behavior under non-i.i.d. data and nonlinear approximation remains unknown. We provide the first high-probability, finite-sample analysis of vanilla TD(0) on polynomially mixing Markov data, assuming only Holder continuity and bounded generalized gradients. This breaks with previous work, which often requires subsampling, projections, or instance-dependent step-sizes. Concretely, for mixing exponent $\\beta > 1$, Holder continuity exponent $\\gamma$, and step-size decay rate $\\eta \\in (1/2, 1]$, we show that, with high probability, \\[ \\| \\theta_t - \\theta^* \\| \\leq C(\\beta, \\gamma, \\eta)\\, t^{-\\beta/2} + C'(\\gamma, \\eta)\\, t^{-\\eta\\gamma} \\] after $t = \\mathcal{O}(1/\\varepsilon^2)$ iterations. These bounds match the known i.i.d. rates and hold even when initialization is nonstationary. Central to our proof is a novel discrete-time coupling that bypasses geometric ergodicity, yielding the first such guarantee for nonlinear TD(0) under realistic mixing.","authors":["Anupama Sridhar","Alexander Johansen"],"url":"https://arxiv.org/abs/2502.05706"}
{"created":"2025-05-22","title":"MoHAVE: Mixture of Hierarchical Audio-Visual Experts for Robust Speech Recognition","abstract":"Audio-visual speech recognition (AVSR) has become critical for enhancing speech recognition in noisy environments by integrating both auditory and visual modalities. However, existing AVSR systems struggle to scale up without compromising computational efficiency. In this study, we introduce MoHAVE (Mixture of Hierarchical Audio-Visual Experts), a novel robust AVSR framework designed to address these scalability constraints. By leveraging a Mixture-of-Experts (MoE) architecture, MoHAVE activates modality-specific expert groups, ensuring dynamic adaptation to various audio-visual inputs with minimal computational overhead. Key contributions of MoHAVE include: (1) a sparse MoE framework that efficiently scales AVSR model capacity, (2) a hierarchical gating mechanism that dynamically utilizes the expert groups based on input context, enhancing adaptability and robustness, and (3) remarkable performance across robust AVSR benchmarks, including LRS3 and MuAViC transcription and translation tasks, setting a new standard for scalable speech recognition systems.","authors":["Sungnyun Kim","Kangwook Jang","Sangmin Bae","Sungwoo Cho","Se-Young Yun"],"url":"https://arxiv.org/abs/2502.10447"}
{"created":"2025-05-22","title":"Antimatter Annihilation Vertex Reconstruction with Deep Learning for ALPHA-g Radial Time Projection Chamber","abstract":"The ALPHA-g experiment at CERN aims to precisely measure the terrestrial gravitational acceleration of antihydrogen atoms. A radial Time Projection Chamber (rTPC), that surrounds the ALPHA-g magnetic trap, is employed to determine the annihilation location, called the vertex. The standard approach requires identifying the trajectories of the ionizing particles in the rTPC from the location of their interaction in the gas (spacepoints), and inferring the vertex positions by finding the point where those trajectories (helices) pass closest to one another. In this work, we present a novel approach to vertex reconstruction using an ensemble of models based on the PointNet deep learning architecture. The newly developed model, PointNet Ensemble for Annihilation Reconstruction (PEAR), directly learns the relation between the location of the vertices and the rTPC spacepoints, thus eliminating the need to identify and fit the particle tracks. PEAR shows strong performance in reconstructing vertical vertex positions from simulated data, that is superior to the standard approach for all metrics considered. Furthermore, the deep learning approach can reconstruct the vertical vertex position when the standard approach fails.","authors":["Ashley Ferreira","Mahip Singh","Yukiya Saito","Andrea Capra","Ina Carli","Daniel Duque Quiceno","Wojciech T. Fedorko","Makoto C. Fujiwara","Muyan Li","Lars Martin","Gareth Smith","Anqui Xu"],"url":"https://arxiv.org/abs/2502.12169"}
{"created":"2025-05-22","title":"Improving the statistical efficiency of cross-conformal prediction","abstract":"Vovk (2015) introduced cross-conformal prediction, a modification of split conformal designed to improve the width of prediction sets. The method, when trained with a miscoverage rate equal to $\\alpha$ and $n \\gg K$, ensures a marginal coverage of at least $1 - 2\\alpha - 2(1-\\alpha)(K-1)/(n+K)$, where $n$ is the number of observations and $K$ denotes the number of folds. A simple modification of the method achieves coverage of at least $1-2\\alpha$. In this work, we propose new variants of both methods that yield smaller prediction sets without compromising the latter theoretical guarantees. The proposed methods are based on recent results deriving more statistically efficient combination of p-values that leverage exchangeability and randomization. Simulations confirm the theoretical findings and bring out some important tradeoffs.","authors":["Matteo Gasparin","Aaditya Ramdas"],"url":"https://arxiv.org/abs/2503.01495"}
{"created":"2025-05-22","title":"Butcher series for Hamiltonian Poisson integrators through symplectic groupoids","abstract":"We exhibit a new pre-Lie algebra in the framework of symplectic groupoids and, in turn, introduce a pre-Lie formalism of Butcher trees for the approximation of Hamilton-Jacobi solutions on any symplectic groupoid $\\mathcal{G} \\rightrightarrows M.$ The impact of this new algebraic approach is twofold. On the geometric side, it yields algebraic operations to approximate Lagrangian bisections of $\\mathcal{G}$ using the Butcher-Connes-Kreimer Hopf algebra and, in turn, aims at a better understanding of the group of Hamiltonian diffeomorphisms of $M.$ On the computational side, we define a new class of Poisson integrators for Hamiltonian dynamics on Poisson manifolds.","authors":["Adrien Busnot Laurent","Oscar Cosserat"],"url":"https://arxiv.org/abs/2503.05000"}
{"created":"2025-05-22","title":"Fast filtering of non-Gaussian models using Amortized Optimal Transport Maps","abstract":"In this paper, we present the amortized optimal transport filter (A-OTF) designed to mitigate the computational burden associated with the real-time training of optimal transport filters (OTFs). OTFs can perform accurate non-Gaussian Bayesian updates in the filtering procedure, but they require training at every time step, which makes them expensive. The proposed A-OTF framework exploits the similarity between OTF maps during an initial/offline training stage in order to reduce the cost of inference during online calculations. More precisely, we use clustering algorithms to select relevant subsets of pre-trained maps whose weighted average is used to compute the A-OTF model akin to a mixture of experts. A series of numerical experiments validate that A-OTF achieves substantial computational savings during online inference while preserving the inherent flexibility and accuracy of OTF.","authors":["Mohammad Al-Jarrah","Bamdad Hosseini","Amirhossein Taghvaei"],"url":"https://arxiv.org/abs/2503.12633"}
{"created":"2025-05-22","title":"A Spectral Approach to Optimal Control of the Fokker-Planck Equation","abstract":"In this paper, we present a spectral optimal control framework for Fokker-Planck equations based on the standard ground state transformation that maps the Fokker-Planck operator to a Schrodinger operator. Our primary objective is to accelerate convergence toward the (unique) steady state. To fulfill this objective, a gradient-based iterative algorithm with Pontryagin's maximum principle and the Barzilai-Borwein update is developed to compute time-dependent controls. Numerical experiments on two-dimensional ill-conditioned normal distributions and double-well potentials demonstrate that our approach effectively targets slow-decaying modes, thus increasing the spectral gap.","authors":["Dante Kalise","Lucas M. Moschen","Grigorios A. Pavliotis","Urbain Vaes"],"url":"https://arxiv.org/abs/2503.15125"}
{"created":"2025-05-22","title":"Hierarchical clustering with maximum density paths and mixture models","abstract":"Hierarchical clustering is an effective, interpretable method for analyzing structure in data. It reveals insights at multiple scales without requiring a predefined number of clusters and captures nested patterns and subtle relationships, which are often missed by flat clustering approaches. However, existing hierarchical clustering methods struggle with high-dimensional data, especially when there are no clear density gaps between modes. In this work, we introduce t-NEB, a probabilistically grounded hierarchical clustering method, which yields state-of-the-art clustering performance on naturalistic high-dimensional data. t-NEB consists of three steps: (1) density estimation via overclustering; (2) finding maximum density paths between clusters; (3) creating a hierarchical structure via bottom-up cluster merging. t-NEB uses a probabilistic parametric density model for both overclustering and cluster merging, which yields both high clustering performance and a meaningful hierarchy, making it a valuable tool for exploratory data analysis. Code is available at https://github.com/ecker-lab/tneb clustering.","authors":["Martin Ritzert","Polina Turishcheva","Laura Hansel","Paul Wollenhaupt","Marissa A. Weis","Alexander S. Ecker"],"url":"https://arxiv.org/abs/2503.15582"}
{"created":"2025-05-22","title":"Counterexamples to two conjectures on Venn diagrams","abstract":"In 1984, Winkler conjectured that every simple Venn diagram with $n$ curves can be extended to a simple Venn diagram with $n+1$ curves. His conjecture is equivalent to the statement that the dual graph of any simple Venn diagram has a Hamilton cycle. In this work, we construct counterexamples to Winkler's conjecture for all $n\\geq 6$. As part of this proof, we computed all 3.430.404 simple Venn diagrams with $n=6$ curves (even their number was not previously known), among which we found 72 counterexamples. While working on Winkler's conjecture, Pruesse and Ruskey considered the (multi)graph whose vertices are the crossings of the curves of a Venn diagram and curve segments between consecutive crossings form the edges. They proved that this graph has a Hamilton cycle for every simple Venn diagram with $n$ curves, and conjectured that this also holds for non-simple diagrams. We construct counterexamples to this conjecture for all $n\\geq 4$.","authors":["Sofia Brenner","Linda Kleist","Torsten M\\\"utze","Christian Rieck","Francesco Verciani"],"url":"https://arxiv.org/abs/2503.18554"}
{"created":"2025-05-22","title":"A Comprehensive Benchmark for RNA 3D Structure-Function Modeling","abstract":"The relationship between RNA structure and function has recently attracted interest within the deep learning community, a trend expected to intensify as nucleic acid structure models advance. Despite this momentum, a lack of standardized, accessible benchmarks for applying deep learning to RNA 3D structures hinders progress. To this end, we introduce a collection of seven benchmarking datasets specifically designed to support RNA structure-function prediction. Built on top of the established Python package rnaglib, our library streamlines data distribution and encoding, provides tools for dataset splitting and evaluation, and offers a comprehensive, user-friendly environment for model comparison. The modular and reproducible design of our datasets encourages community contributions and enables rapid customization. To demonstrate the utility of our benchmarks, we report baseline results for all tasks using a relational graph neural network.","authors":["Luis Wyss","Vincent Mallet","Wissam Karroucha","Karsten Borgwardt","Carlos Oliver"],"url":"https://arxiv.org/abs/2503.21681"}
{"created":"2025-05-22","title":"Riemannian Optimization on the Oblique Manifold for Sparse Simplex Constraints via Multiplicative Updates","abstract":"Low-rank optimization problems with sparse simplex constraints involve variables that must satisfy nonnegativity, sparsity, and sum-to-one conditions, making their optimization particularly challenging due to the interplay between low-rank structures and constraints. These problems arise in various applications, including machine learning, signal processing, environmental fields, and computational biology. In this paper, we propose a novel manifold optimization approach to tackle these problems efficiently. Our method leverages the geometry of oblique rotation manifolds to reformulate the problem and introduces a new Riemannian optimization method based on Riemannian gradient descent that strictly maintains the simplex constraints. By exploiting the underlying manifold structure, our approach improves optimization efficiency. Experiments on synthetic datasets compared to standard Euclidean and Riemannian methods show the effectiveness of the proposed method.","authors":["Flavia Esposito","Andersen Ang"],"url":"https://arxiv.org/abs/2503.24075"}
{"created":"2025-05-22","title":"Optimal classification with endogenous behavior","abstract":"I consider the problem of classifying individual behavior in a simple setting of outcome performativity where the behavior the algorithm seeks to classify is itself dependent on the algorithm. I show in this context that the most accurate classifier is either a threshold or a negative threshold rule. A threshold rule offers the \"good\" classification to those individuals more likely to have engaged in a desirable behavior, while a negative threshold rule offers the \"good\" outcome to those less likely to have engaged in the desirable behavior. While seemingly pathological, I show that a negative threshold rule can maximize classification accuracy when behavior is endogenous. I provide an example of such a classifier and extend the analysis to more general algorithm objectives. A key takeaway is that when behavior is endogenous to classification, optimal classification can negatively correlate with signal information. This may yield negative downstream effects on groups in terms of the aggregate behavior induced by an algorithm.","authors":["Elizabeth Maggie Penn"],"url":"https://arxiv.org/abs/2504.06127"}
{"created":"2025-05-22","title":"AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification","abstract":"Antibiotic resistance presents a growing global health crisis, demanding new therapeutic strategies that target novel bacterial mechanisms. Recent advances in protein structure prediction and machine learning-driven molecule generation offer a promising opportunity to accelerate drug discovery. However, practical guidance on selecting and integrating these models into real-world pipelines remains limited. In this study, we develop an end-to-end, artificial intelligence-guided antibiotic discovery pipeline that spans target identification to compound realization. We leverage structure-based clustering across predicted proteomes of multiple pathogens to identify conserved, essential, and non-human-homologous targets. We then systematically evaluate six leading 3D-structure-aware generative models$\\unicode{x2014}$spanning diffusion, autoregressive, graph neural network, and language model architectures$\\unicode{x2014}$on their usability, chemical validity, and biological relevance. Rigorous post-processing filters and commercial analogue searches reduce over 100 000 generated compounds to a focused, synthesizable set. Our results highlight DeepBlock and TamGen as top performers across diverse criteria, while also revealing critical trade-offs between model complexity, usability, and output quality. This work provides a comparative benchmark and blueprint for deploying artificial intelligence in early-stage antibiotic development.","authors":["Maximilian G. Schuh","Joshua Hesse","Stephan A. Sieber"],"url":"https://arxiv.org/abs/2504.11091"}
{"created":"2025-05-22","title":"A Review of Stop-and-Go Traffic Wave Suppression Strategies: Variable Speed Limit vs. Jam-Absorption Driving","abstract":"The main form of freeway traffic congestion is the familiar stop-and-go wave, characterized by wide moving jams that propagate indefinitely upstream provided enough traffic demand. They cause severe, long-lasting adverse effects, such as reduced traffic efficiency, increased driving risks, and higher vehicle emissions. This underscores the crucial importance of artificial intervention in the propagation of stop-and-go waves. Over the past two decades, two prominent strategies for stop-and-go wave suppression have emerged: variable speed limit (VSL) and jam-absorption driving (JAD). Although they share similar research motivations, objectives, and theoretical foundations, the development of these strategies has remained relatively disconnected. To synthesize fragmented advances and drive the field forward, this paper first provides a comprehensive review of the achievements in the stop-and-go wave suppression-oriented VSL and JAD, respectively. It then focuses on bridging the two areas and identifying research opportunities from the following perspectives: fundamental diagrams, secondary waves, generalizability, traffic state estimation and prediction, robustness to randomness, scenarios for strategy validation, and field tests and practical deployment. We expect that through this review, one area can effectively address its limitations by identifying and leveraging the strengths of the other, thus promoting the overall research goal of freeway stop-and-go wave suppression.","authors":["Zhengbing He","Jorge Laval","Yu Han","Andreas Hegyi","Ryosuke Nishi","Cathy Wu"],"url":"https://arxiv.org/abs/2504.11372"}
{"created":"2025-05-22","title":"Logic and Concepts in the 2-category of Topoi","abstract":"We use Kan injectivity to axiomatise concepts in the 2-category of topoi. We showcase the expressivity of this language through many examples, and we establish some aspects of the formal theory of Kan extension in this 2-category (pointwise Kan extensions, fully faithful morphisms, etc.). We use this technology to introduce fragments of geometric logic, and we accommodate essentially algebraic, disjunctive, regular, and coherent logic in our framework, together with some more exotic examples. We show that each fragment $\\mathcal{H}$ in our sense identifies a lax-idempotent (relative) pseudomonad $\\mathsf{T}^{\\mathcal{H}}$ on $\\mathsf{lex}$, the $2$-category of finitely complete categories. We show that the algebras for $\\mathsf{T}^{\\mathcal{H}}$ admit a notion of classifying topos, for which we deliver several Diaconescu-type results. The construction of classifying topoi allows us to define conceptually complete fragments of geometric logic.","authors":["Ivan Di Liberti","Lingyuan Ye"],"url":"https://arxiv.org/abs/2504.16690"}
{"created":"2025-05-22","title":"DOLCE: Decomposing Off-Policy Evaluation/Learning into Lagged and Current Effects","abstract":"Off-policy evaluation (OPE) and off-policy learning (OPL) for contextual bandit policies leverage historical data to evaluate and optimize a target policy. Most existing OPE/OPL methods--based on importance weighting or imputation--assume common support between the target and logging policies. When this assumption is violated, these methods typically require unstable extrapolation, truncation, or conservative strategies for individuals outside the common support assumption. However, such approaches can be inadequate in settings where explicit evaluation or optimization for such individuals is required. To address this issue, we propose DOLCE: Decomposing Off-policy evaluation/learning into Lagged and Current Effects, a novel estimator that leverages contextual information from multiple time points to decompose rewards into lagged and current effects. By incorporating both past and present contexts, DOLCE effectively handles individuals who violate the common support assumption. We show that the proposed estimator is unbiased under two assumptions--local correctness and conditional independence. Our experiments demonstrate that DOLCE achieves substantial improvements in OPE and OPL, particularly as the proportion of individuals outside the common support assumption increases.","authors":["Shu Tamano","Masanori Nojima"],"url":"https://arxiv.org/abs/2505.00961"}
