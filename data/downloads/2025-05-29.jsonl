{"created":"2025-05-29","title":"Conformance Checking for Less: Efficient Conformance Checking for Long Event Sequences","abstract":"Long event sequences (termed traces) and large data logs that originate from sensors and prediction models are becoming increasingly common in our data-rich world. In such scenarios, conformance checking-validating a data log against an expected system behavior (the process model) can become computationally infeasible due to the exponential complexity of finding an optimal alignment. To alleviate scalability challenges for this task, we propose ConLES, a sliding-window conformance checking approach for long event sequences that preserves the interpretability of alignment-based methods. ConLES partitions traces into manageable subtraces and iteratively aligns each against the expected behavior, leading to significant reduction of the search space while maintaining overall accuracy. We use global information that captures structural properties of both the trace and the process model, enabling informed alignment decisions and discarding unpromising alignments, even if they appear locally optimal. Performance evaluations across multiple datasets highlight that ConLES outperforms the leading optimal and heuristic algorithms for long traces, consistently achieving the optimal or near-optimal solution. Unlike other conformance methods that struggle with long event sequences, ConLES significantly reduces the search space, scales efficiently, and uniquely supports both predefined and discovered process models, making it a viable and leading option for conformance checking of long event sequences.","authors":["Eli Bogdanov","Izack Cohen","Avigdor Gal"],"url":"https://arxiv.org/abs/2505.21506"}
{"created":"2025-05-29","title":"The Role of Visualization in LLM-Assisted Knowledge Graph Systems: Effects on User Trust, Exploration, and Workflows","abstract":"Knowledge graphs (KGs) are powerful data structures, but exploring them effectively remains difficult for even expert users. Large language models (LLMs) are increasingly used to address this gap, yet little is known empirically about how their usage with KGs shapes user trust, exploration strategies, or downstream decision-making - raising key design challenges for LLM-based KG visual analysis systems. To study these effects, we developed LinkQ, a KG exploration system that converts natural language questions into structured queries with an LLM. We collaborated with KG experts to design five visual mechanisms that help users assess the accuracy of both KG queries and LLM responses: an LLM-KG state diagram that illustrates which stage of the exploration pipeline LinkQ is in, a query editor displaying the generated query paired with an LLM explanation, an entity-relation ID table showing extracted KG entities and relations with semantic descriptions, a query structure graph that depicts the path traversed in the KG, and an interactive graph visualization of query results. From a qualitative evaluation with 14 practitioners, we found that users - even KG experts - tended to overtrust LinkQ's outputs due to its \"helpful\" visualizations, even when the LLM was incorrect. Users exhibited distinct workflows depending on their prior familiarity with KGs and LLMs, challenging the assumption that these systems are one-size-fits-all - despite often being designed as if they are. Our findings highlight the risks of false trust in LLM-assisted data analysis tools and the need for further investigation into the role of visualization as a mitigation technique.","authors":["Harry Li","Gabriel Appleby","Kenneth Alperin","Steven R Gomez","Ashley Suh"],"url":"https://arxiv.org/abs/2505.21512"}
{"created":"2025-05-29","title":"Enhancing Vision Transformer Explainability Using Artificial Astrocytes","abstract":"Machine learning models achieve high precision, but their decision-making processes often lack explainability. Furthermore, as model complexity increases, explainability typically decreases. Existing efforts to improve explainability primarily involve developing new eXplainable artificial intelligence (XAI) techniques or incorporating explainability constraints during training. While these approaches yield specific improvements, their applicability remains limited. In this work, we propose the Vision Transformer with artificial Astrocytes (ViTA). This training-free approach is inspired by neuroscience and enhances the reasoning of a pretrained deep neural network to generate more human-aligned explanations. We evaluated our approach employing two well-known XAI techniques, Grad-CAM and Grad-CAM++, and compared it to a standard Vision Transformer (ViT). Using the ClickMe dataset, we quantified the similarity between the heatmaps produced by the XAI techniques and a (human-aligned) ground truth. Our results consistently demonstrate that incorporating artificial astrocytes enhances the alignment of model explanations with human perception, leading to statistically significant improvements across all XAI techniques and metrics utilized.","authors":["Nicolas Echevarrieta-Catalan","Ana Ribas-Rodriguez","Francisco Cedron","Odelia Schwartz","Vanessa Aguiar-Pulido"],"url":"https://arxiv.org/abs/2505.21513"}
{"created":"2025-05-29","title":"SIMCOPILOT: Evaluating Large Language Models for Copilot-Style Code Generation","abstract":"We introduce SIMCOPILOT, a benchmark that simulates the role of large language models (LLMs) as interactive, \"copilot\"-style coding assistants. Targeting both completion (finishing incomplete methods or code blocks) and infill tasks (filling missing segments within existing code), SIMCOPILOT provides a comprehensive framework for evaluating LLM coding capabilities. The benchmark comprises dedicated sub-benchmarks for Java (SIMCOPILOTJ) and Python (SIMCOPILOTP), covering diverse codebases varying in size and complexity. Our key contributions include: (a) establishing a realistic, detailed evaluation environment to assess LLM utility in practical coding scenarios, and (b) providing fine-grained analyses that address critical factors frequently overlooked by existing benchmarks, such as task-specific performance nuances, contextual understanding across code segments, and sensitivity to variable scope. Evaluations conducted across domains-including algorithms, databases, computer vision, and neural networks-offer insights into model strengths and highlight persistent challenges in maintaining logical consistency within complex dependency structures. Beyond benchmarking, our study sheds light on the current limitations of LLM-driven code generation and underscores the ongoing transition of LLMs from merely syntax-aware generators toward reliable, intelligent software development partners.","authors":["Mingchao Jiang","Abhinav Jain","Sophia Zorek","Chris Jermaine"],"url":"https://arxiv.org/abs/2505.21514"}
{"created":"2025-05-29","title":"Cold Start Problem: An Experimental Study of Knowledge Tracing Models with New Students","abstract":"KnowledgeTracing (KT) involves predicting students' knowledge states based on their interactions with Intelligent Tutoring Systems (ITS). A key challenge is the cold start problem, accurately predicting knowledge for new students with minimal interaction data. Unlike prior work, which typically trains KT models on initial interactions of all students and tests on their subsequent interactions, our approach trains models solely using historical data from past students, evaluating their performance exclusively on entirely new students. We investigate cold start effects across three KT models: Deep Knowledge Tracing (DKT), Dynamic Key-Value Memory Networks (DKVMN), and Self-Attentive Knowledge Tracing (SAKT), using ASSISTments 2009, 2015, and 2017 datasets. Results indicate all models initially struggle under cold start conditions but progressively improve with more interactions; SAKT shows higher initial accuracy yet still faces limitations. These findings highlight the need for KT models that effectively generalize to new learners, emphasizing the importance of developing models robust in few-shot and zero-shot learning scenarios","authors":["Indronil Bhattacharjee","Christabel Wayllace"],"url":"https://arxiv.org/abs/2505.21517"}
{"created":"2025-05-29","title":"Resilient LLM-Empowered Semantic MAC Protocols via Zero-Shot Adaptation and Knowledge Distillation","abstract":"Neural network-based medium access control (MAC) protocol models (NPMs) improve goodput through site-specific operations but are vulnerable to shifts from their training network environments, such as changes in the number of user equipments (UEs) severely degrade goodput. To enhance resilience against such environmental shifts, we propose three novel semantic MAC protocol frameworks empowered by large language models (LLMs). First, we introduce a token-based protocol model (TPM), where an LLM generates MAC signaling messages. By editing LLM instruction prompts, TPM enables instant adaptation, which can be further enhanced by TextGrad, an LLM-based automated prompt optimizer. TPM inference is fast but coarse due to the lack of real interactions with the changed environment, and computationally intensive due to the large size of the LLM. To improve goodput and computation efficiency, we develop T2NPM, which transfers and augments TPM knowledge into an NPM via knowledge distillation (KD). Integrating TPM and T2NPM, we propose T3NPM, which employs TPM in the early phase and switches to T2NPM later. To optimize this phase switching, we design a novel metric of meta-resilience, which quantifies resilience to unknown target goodput after environmental shifts. Simulations corroborate that T3NPM achieves 20.56% higher meta-resilience than NPM with 19.8x lower computation cost than TPM in FLOPS.","authors":["Yongjun Kim","Jihong Park","Mehdi Bennis","Junil Choi"],"url":"https://arxiv.org/abs/2505.21518"}
{"created":"2025-05-29","title":"Do DeepFake Attribution Models Generalize?","abstract":"Recent advancements in DeepFake generation, along with the proliferation of open-source tools, have significantly lowered the barrier for creating synthetic media. This trend poses a serious threat to the integrity and authenticity of online information, undermining public trust in institutions and media. State-of-the-art research on DeepFake detection has primarily focused on binary detection models. A key limitation of these models is that they treat all manipulation techniques as equivalent, despite the fact that different methods introduce distinct artifacts and visual cues. Only a limited number of studies explore DeepFake attribution models, although such models are crucial in practical settings. By providing the specific manipulation method employed, these models could enhance both the perceived trustworthiness and explainability for end users. In this work, we leverage five state-of-the-art backbone models and conduct extensive experiments across six DeepFake datasets. First, we compare binary and multi-class models in terms of cross-dataset generalization. Second, we examine the accuracy of attribution models in detecting seen manipulation methods in unknown datasets, hence uncovering data distribution shifts on the same DeepFake manipulations. Last, we assess the effectiveness of contrastive methods in improving cross-dataset generalization performance. Our findings indicate that while binary models demonstrate better generalization abilities, larger models, contrastive methods, and higher data quality can lead to performance improvements in attribution models. The code of this work is available on GitHub.","authors":["Spiros Baxavanakis","Manos Schinas","Symeon Papadopoulos"],"url":"https://arxiv.org/abs/2505.21520"}
{"created":"2025-05-29","title":"CIM-NET: A Video Denoising Deep Neural Network Model Optimized for Computing-in-Memory Architectures","abstract":"While deep neural network (DNN)-based video denoising has demonstrated significant performance, deploying state-of-the-art models on edge devices remains challenging due to stringent real-time and energy efficiency requirements. Computing-in-Memory (CIM) chips offer a promising solution by integrating computation within memory cells, enabling rapid matrix-vector multiplication (MVM). However, existing DNN models are often designed without considering CIM architectural constraints, thus limiting their acceleration potential during inference. To address this, we propose a hardware-algorithm co-design framework incorporating two innovations: (1) a CIM-Aware Architecture, CIM-NET, optimized for large receptive field operation and CIM's crossbar-based MVM acceleration; and (2) a pseudo-convolutional operator, CIM-CONV, used within CIM-NET to integrate slide-based processing with fully connected transformations for high-quality feature extraction and reconstruction. This framework significantly reduces the number of MVM operations, improving inference speed on CIM chips while maintaining competitive performance. Experimental results indicate that, compared to the conventional lightweight model FastDVDnet, CIM-NET substantially reduces MVM operations with a slight decrease in denoising performance. With a stride value of 8, CIM-NET reduces MVM operations to 1/77th of the original, while maintaining competitive PSNR (35.11 dB vs. 35.56 dB","authors":["Shan Gao","Zhiqiang Wu","Yawen Niu","Xiaotao Li","Qingqing Xu"],"url":"https://arxiv.org/abs/2505.21522"}
{"created":"2025-05-29","title":"More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models","abstract":"Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more heavily on language priors. Attention analysis shows that longer reasoning chains lead to reduced focus on visual inputs, which contributes to hallucination. To systematically study this phenomenon, we introduce RH-AUC, a metric that quantifies how a model's perception accuracy changes with reasoning length, allowing us to evaluate whether the model preserves visual grounding during reasoning. We also release RH-Bench, a diagnostic benchmark that spans a variety of multimodal tasks, designed to assess the trade-off between reasoning ability and hallucination. Our analysis reveals that (i) larger models typically achieve a better balance between reasoning and perception, and (ii) this balance is influenced more by the types and domains of training data than by its overall volume. These findings underscore the importance of evaluation frameworks that jointly consider both reasoning quality and perceptual fidelity.","authors":["Chengzhi Liu","Zhongxing Xu","Qingyue Wei","Juncheng Wu","James Zou","Xin Eric Wang","Yuyin Zhou","Sheng Liu"],"url":"https://arxiv.org/abs/2505.21523"}
{"created":"2025-05-29","title":"Learning Shared Representations from Unpaired Data","abstract":"Learning shared representations is a primary area of multimodal representation learning. The current approaches to achieve a shared embedding space rely heavily on paired samples from each modality, which are significantly harder to obtain than unpaired ones. In this work, we demonstrate that shared representations can be learned almost exclusively from unpaired data. Our arguments are grounded in the spectral embeddings of the random walk matrices constructed independently from each unimodal representation. Empirical results in computer vision and natural language processing domains support its potential, revealing the effectiveness of unpaired data in capturing meaningful cross-modal relations, demonstrating high capabilities in retrieval tasks, generation, arithmetics, zero-shot, and cross-domain classification. This work, to the best of our knowledge, is the first to demonstrate these capabilities almost exclusively from unpaired samples, giving rise to a cross-modal embedding that could be viewed as universal, i.e., independent of the specific modalities of the data. Our code IS publicly available at https://github.com/shaham-lab/SUE.","authors":["Amitai Yacobi","Nir Ben-Ari","Ronen Talmon","Uri Shaham"],"url":"https://arxiv.org/abs/2505.21524"}
{"created":"2025-05-29","title":"Temporal Restoration and Spatial Rewiring for Source-Free Multivariate Time Series Domain Adaptation","abstract":"Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained model from an annotated source domain to an unlabelled target domain without accessing the source data, thereby preserving data privacy. While existing SFDA methods have proven effective in reducing reliance on source data, they struggle to perform well on multivariate time series (MTS) due to their failure to consider the intrinsic spatial correlations inherent in MTS data. These spatial correlations are crucial for accurately representing MTS data and preserving invariant information across domains. To address this challenge, we propose Temporal Restoration and Spatial Rewiring (TERSE), a novel and concise SFDA method tailored for MTS data. Specifically, TERSE comprises a customized spatial-temporal feature encoder designed to capture the underlying spatial-temporal characteristics, coupled with both temporal restoration and spatial rewiring tasks to reinstate latent representations of the temporally masked time series and the spatially masked correlated structures. During the target adaptation phase, the target encoder is guided to produce spatially and temporally consistent features with the source domain by leveraging the source pre-trained temporal restoration and spatial rewiring networks. Therefore, TERSE can effectively model and transfer spatial-temporal dependencies across domains, facilitating implicit feature alignment. In addition, as the first approach to simultaneously consider spatial-temporal consistency in MTS-SFDA, TERSE can also be integrated as a versatile plug-and-play module into established SFDA methods. Extensive experiments on three real-world time series datasets demonstrate the effectiveness and versatility of our approach.","authors":["Peiliang Gong","Yucheng Wang","Min Wu","Zhenghua Chen","Xiaoli Li","Daoqiang Zhang"],"url":"https://arxiv.org/abs/2505.21525"}
{"created":"2025-05-29","title":"Prospects and challenges of Bluetooth backscatters system","abstract":"Bluetooth backscatter systems, as a crucial technology for low-power communication in the Internet of Things (IoT), have witnessed remarkable development in recent years. This article comprehensively analyzes multiple related papers, including the latest advancements in RF-Transformer and B2Loc systems, summarizes their research progress, challenges faced, and classification, and explores the application prospects and future development directions of such systems. Bluetooth backscatter systems have achieved significant results in terms of compatibility with commercial devices, improvement of communication reliability, and increase in throughput. However, they still face challenges in areas such as communication range, anti-interference ability, and hardware costs. In the future, with continuous technological innovation exemplified by breakthroughs in unified hardware abstraction and decimeter-level localization, Bluetooth backscatter systems are expected to play a more significant role in the IoT field.","authors":["Jingyun Du"],"url":"https://arxiv.org/abs/2505.21526"}
{"created":"2025-05-29","title":"UniDB++: Fast Sampling of Unified Diffusion Bridge","abstract":"Diffusion Bridges enable transitions between arbitrary distributions, with the Unified Diffusion Bridge (UniDB) framework achieving high-fidelity image generation via a Stochastic Optimal Control (SOC) formulation. However, UniDB's reliance on iterative Euler sampling methods results in slow, computationally expensive inference, while existing acceleration techniques for diffusion or diffusion bridge models fail to address its unique challenges: missing terminal mean constraints and SOC-specific penalty coefficients in its SDEs. We present UniDB++, a training-free sampling algorithm that significantly improves upon these limitations. The method's key advancement comes from deriving exact closed-form solutions for UniDB's reverse-time SDEs, effectively reducing the error accumulation inherent in Euler approximations and enabling high-quality generation with up to 20$\\times$ fewer sampling steps. This method is further complemented by replacing conventional noise prediction with a more stable data prediction model, along with an SDE-Corrector mechanism that maintains perceptual quality for low-step regimes (5-10 steps). Additionally, we demonstrate that UniDB++ aligns with existing diffusion bridge acceleration methods by evaluating their update rules, and UniDB++ can recover DBIMs as special cases under some theoretical conditions. Experiments demonstrate UniDB++'s state-of-the-art performance in image restoration tasks, outperforming Euler-based methods in fidelity and speed while reducing inference time significantly. This work bridges the gap between theoretical generality and practical efficiency in SOC-driven diffusion bridge models. Our code is available at https://github.com/2769433owo/UniDB-plusplus.","authors":["Mokai Pan","Kaizhen Zhu","Yuexin Ma","Yanwei Fu","Jingyi Yu","Jingya Wang","Ye Shi"],"url":"https://arxiv.org/abs/2505.21528"}
{"created":"2025-05-29","title":"WakeMod: A 6.9uW Wake-Up Radio Module with -72.6dBm Sensitivity for On-Demand IoT","abstract":"Large-scale Internet of Things (IoT) applications, such as asset tracking and remote sensing, demand multi-year battery lifetimes to minimize maintenance and operational costs. Traditional wireless protocols often employ duty cycling, introducing a tradeoff between latency and idle consumption - both unsuitable for event-driven and ultra-low power systems. A promising approach to address these issues is the integration of always-on wake-up radios (WuRs). They provide asynchronous, ultra-low power communication to overcome these constraints.","authors":["Lukas Schulthess","Silvano Cortesi","Michele Magno"],"url":"https://arxiv.org/abs/2505.21529"}
{"created":"2025-05-29","title":"How Much Do Large Language Models Know about Human Motion? A Case Study in 3D Avatar Control","abstract":"We explore Large Language Models (LLMs)' human motion knowledge through 3D avatar control. Given a motion instruction, we prompt LLMs to first generate a high-level movement plan with consecutive steps (High-level Planning), then specify body part positions in each step (Low-level Planning), which we linearly interpolate into avatar animations as a clear verification lens for human evaluators. Through carefully designed 20 representative motion instructions with full coverage of basic movement primitives and balanced body part usage, we conduct comprehensive evaluations including human assessment of both generated animations and high-level movement plans, as well as automatic comparison with oracle positions in low-level planning. We find that LLMs are strong at interpreting the high-level body movements but struggle with precise body part positioning. While breaking down motion queries into atomic components improves planning performance, LLMs have difficulty with multi-step movements involving high-degree-of-freedom body parts. Furthermore, LLMs provide reasonable approximation for general spatial descriptions, but fail to handle precise spatial specifications in text, and the precise spatial-temporal parameters needed for avatar control. Notably, LLMs show promise in conceptualizing creative motions and distinguishing culturally-specific motion patterns.","authors":["Kunhang Li","Jason Naradowsky","Yansong Feng","Yusuke Miyao"],"url":"https://arxiv.org/abs/2505.21531"}
{"created":"2025-05-29","title":"EvidenceMoE: A Physics-Guided Mixture-of-Experts with Evidential Critics for Advancing Fluorescence Light Detection and Ranging in Scattering Media","abstract":"Fluorescence LiDAR (FLiDAR), a Light Detection and Ranging (LiDAR) technology employed for distance and depth estimation across medical, automotive, and other fields, encounters significant computational challenges in scattering media. The complex nature of the acquired FLiDAR signal, particularly in such environments, makes isolating photon time-of-flight (related to target depth) and intrinsic fluorescence lifetime exceptionally difficult, thus limiting the effectiveness of current analytical and computational methodologies. To overcome this limitation, we present a Physics-Guided Mixture-of-Experts (MoE) framework tailored for specialized modeling of diverse temporal components. In contrast to the conventional MoE approaches our expert models are informed by underlying physics, such as the radiative transport equation governing photon propagation in scattering media. Central to our approach is EvidenceMoE, which integrates Evidence-Based Dirichlet Critics (EDCs). These critic models assess the reliability of each expert's output by providing per-expert quality scores and corrective feedback. A Decider Network then leverages this information to fuse expert predictions into a robust final estimate adaptively. We validate our method using realistically simulated Fluorescence LiDAR (FLiDAR) data for non-invasive cancer cell depth detection generated from photon transport models in tissue. Our framework demonstrates strong performance, achieving a normalized root mean squared error (NRMSE) of 0.030 for depth estimation and 0.074 for fluorescence lifetime.","authors":["Ismail Erbas","Ferhat Demirkiran","Karthik Swaminathan","Naigang Wang","Navid Ibtehaj Nizam","Stefan T. Radev","Kaoutar El Maghraoui","Xavier Intes","Vikas Pandey"],"url":"https://arxiv.org/abs/2505.21532"}
{"created":"2025-05-29","title":"Self-Organizing Visual Prototypes for Non-Parametric Representation Learning","abstract":"We present Self-Organizing Visual Prototypes (SOP), a new training technique for unsupervised visual feature learning. Unlike existing prototypical self-supervised learning (SSL) methods that rely on a single prototype to encode all relevant features of a hidden cluster in the data, we propose the SOP strategy. In this strategy, a prototype is represented by many semantically similar representations, or support embeddings (SEs), each containing a complementary set of features that together better characterize their region in space and maximize training performance. We reaffirm the feasibility of non-parametric SSL by introducing novel non-parametric adaptations of two loss functions that implement the SOP strategy. Notably, we introduce the SOP Masked Image Modeling (SOP-MIM) task, where masked representations are reconstructed from the perspective of multiple non-parametric local SEs. We comprehensively evaluate the representations learned using the SOP strategy on a range of benchmarks, including retrieval, linear evaluation, fine-tuning, and object detection. Our pre-trained encoders achieve state-of-the-art performance on many retrieval benchmarks and demonstrate increasing performance gains with more complex encoders.","authors":["Thalles Silva","Helio Pedrini","Ad\\'in Ram\\'irez Rivera"],"url":"https://arxiv.org/abs/2505.21533"}
{"created":"2025-05-29","title":"Uncovering Bottlenecks and Optimizing Scientific Lab Workflows with Cycle Time Reduction Agents","abstract":"Scientific laboratories, particularly those in pharmaceutical and biotechnology companies, encounter significant challenges in optimizing workflows due to the complexity and volume of tasks such as compound screening and assay execution. We introduce Cycle Time Reduction Agents (CTRA), a LangGraph-based agentic workflow designed to automate the analysis of lab operational metrics. CTRA comprises three main components: the Question Creation Agent for initiating analysis, Operational Metrics Agents for data extraction and validation, and Insights Agents for reporting and visualization, identifying bottlenecks in lab processes. This paper details CTRA's architecture, evaluates its performance on a lab dataset, and discusses its potential to accelerate pharmaceutical and biotechnological development. CTRA offers a scalable framework for reducing cycle times in scientific labs.","authors":["Yao Fehlis"],"url":"https://arxiv.org/abs/2505.21534"}
{"created":"2025-05-29","title":"Is Attention Required for Transformer Inference? Explore Function-preserving Attention Replacement","abstract":"While transformers excel across vision and language pretraining tasks, their reliance on attention mechanisms poses challenges for inference efficiency, especially on edge and embedded accelerators with limited parallelism and memory bandwidth. Hinted by the observed redundancy of attention at inference time, we hypothesize that though the model learns complicated token dependency through pretraining, the inference-time sequence-to-sequence mapping in each attention layer is actually ''simple'' enough to be represented with a much cheaper function. In this work, we explore FAR, a Function-preserving Attention Replacement framework that replaces all attention blocks in pretrained transformers with learnable sequence-to-sequence modules, exemplified by an LSTM. FAR optimize a multi-head LSTM architecture with a block-wise distillation objective and a global structural pruning framework to achieve a family of efficient LSTM-based models from pretrained transformers. We validate FAR on the DeiT vision transformer family and demonstrate that it matches the accuracy of the original models on ImageNet and multiple downstream tasks with reduced parameters and latency. Further analysis shows that FAR preserves the semantic token relationships and the token-to-token correlation learned in the transformer's attention module.","authors":["Yuxin Ren","Maxwell D Collins","Miao Hu","Huanrui Yang"],"url":"https://arxiv.org/abs/2505.21535"}
{"created":"2025-05-29","title":"CiRL: Open-Source Environments for Reinforcement Learning in Circular Economy and Net Zero","abstract":"The demand of finite raw materials will keep increasing as they fuel modern society. Simultaneously, solutions for stopping carbon emissions in the short term are not available, thus making the net zero target extremely challenging to achieve at scale. The circular economy (CE) paradigm is gaining attention as a solution to address climate change and the uncertainties of supplies of critical materials. Hence, in this paper, we introduce CiRL, a deep reinforcement learning (DRL) library of environments focused on the circularity of both solid and fluid materials. The integration of DRL into the design of material circularity is possible thanks to the formalism of thermodynamical material networks, which is underpinned by compartmental dynamical thermodynamics. Along with the focus on circularity, this library has three more features: the new CE-oriented environments are in the state-space form, which is typically used in dynamical systems analysis and control designs; it is based on a state-of-the-art Python library of DRL algorithms, namely, Stable-Baselines3; and it is developed in Google Colaboratory to be accessible to researchers from different disciplines and backgrounds as is often the case for circular economy researchers and engineers. CiRL is publicly available.","authors":["Federico Zocco","Andrea Corti","Monica Malvezzi"],"url":"https://arxiv.org/abs/2505.21536"}
{"created":"2025-05-29","title":"OpenReview Should be Protected and Leveraged as a Community Asset for Research in the Era of Large Language Models","abstract":"In the era of large language models (LLMs), high-quality, domain-rich, and continuously evolving datasets capturing expert-level knowledge, core human values, and reasoning are increasingly valuable. This position paper argues that OpenReview -- the continually evolving repository of research papers, peer reviews, author rebuttals, meta-reviews, and decision outcomes -- should be leveraged more broadly as a core community asset for advancing research in the era of LLMs. We highlight three promising areas in which OpenReview can uniquely contribute: enhancing the quality, scalability, and accountability of peer review processes; enabling meaningful, open-ended benchmarks rooted in genuine expert deliberation; and supporting alignment research through real-world interactions reflecting expert assessment, intentions, and scientific values. To better realize these opportunities, we suggest the community collaboratively explore standardized benchmarks and usage guidelines around OpenReview, inviting broader dialogue on responsible data use, ethical considerations, and collective stewardship.","authors":["Hao Sun","Yunyi Shen","Mihaela van der Schaar"],"url":"https://arxiv.org/abs/2505.21537"}
{"created":"2025-05-29","title":"Caption This, Reason That: VLMs Caught in the Middle","abstract":"Vision-Language Models (VLMs) have shown remarkable progress in visual understanding in recent years. Yet, they still lag behind human capabilities in specific visual tasks such as counting or relational reasoning. To understand the underlying limitations, we adopt methodologies from cognitive science, analyzing VLM performance along core cognitive axes: Perception, Attention, and Memory. Using a suite of tasks targeting these abilities, we evaluate state-of-the-art VLMs, including GPT-4o. Our analysis reveals distinct cognitive profiles: while advanced models approach ceiling performance on some tasks (e.g. category identification), a significant gap persists, particularly in tasks requiring spatial understanding or selective attention. Investigating the source of these failures and potential methods for improvement, we employ a vision-text decoupling analysis, finding that models struggling with direct visual reasoning show marked improvement when reasoning over their own generated text captions. These experiments reveal a strong need for improved VLM Chain-of-Thought (CoT) abilities, even in models that consistently exceed human performance. Furthermore, we demonstrate the potential of targeted fine-tuning on composite visual reasoning tasks and show that fine-tuning smaller VLMs substantially improves core cognitive abilities. While this improvement does not translate to large enhancements on challenging, out-of-distribution benchmarks, we show broadly that VLM performance on our datasets strongly correlates with performance on these other benchmarks. Our work provides a detailed analysis of VLM cognitive strengths and weaknesses and identifies key bottlenecks in simultaneous perception and reasoning while also providing an effective and simple solution.","authors":["Zihan Weng","Lucas Gomez","Taylor Whittington Webb","Pouya Bashivan"],"url":"https://arxiv.org/abs/2505.21538"}
{"created":"2025-05-29","title":"Equivariant Flow Matching for Point Cloud Assembly","abstract":"The goal of point cloud assembly is to reconstruct a complete 3D shape by aligning multiple point cloud pieces. This work presents a novel equivariant solver for assembly tasks based on flow matching models. We first theoretically show that the key to learning equivariant distributions via flow matching is to learn related vector fields. Based on this result, we propose an assembly model, called equivariant diffusion assembly (Eda), which learns related vector fields conditioned on the input pieces. We further construct an equivariant path for Eda, which guarantees high data efficiency of the training process. Our numerical results show that Eda is highly competitive on practical datasets, and it can even handle the challenging situation where the input pieces are non-overlapped.","authors":["Ziming Wang","Nan Xue","Rebecka J\\\"ornsten"],"url":"https://arxiv.org/abs/2505.21539"}
{"created":"2025-05-29","title":"DiffDecompose: Layer-Wise Decomposition of Alpha-Composited Images via Diffusion Transformers","abstract":"Diffusion models have recently motivated great success in many generation tasks like object removal. Nevertheless, existing image decomposition methods struggle to disentangle semi-transparent or transparent layer occlusions due to mask prior dependencies, static object assumptions, and the lack of datasets. In this paper, we delve into a novel task: Layer-Wise Decomposition of Alpha-Composited Images, aiming to recover constituent layers from single overlapped images under the condition of semi-transparent/transparent alpha layer non-linear occlusion. To address challenges in layer ambiguity, generalization, and data scarcity, we first introduce AlphaBlend, the first large-scale and high-quality dataset for transparent and semi-transparent layer decomposition, supporting six real-world subtasks (e.g., translucent flare removal, semi-transparent cell decomposition, glassware decomposition). Building on this dataset, we present DiffDecompose, a diffusion Transformer-based framework that learns the posterior over possible layer decompositions conditioned on the input image, semantic prompts, and blending type. Rather than regressing alpha mattes directly, DiffDecompose performs In-Context Decomposition, enabling the model to predict one or multiple layers without per-layer supervision, and introduces Layer Position Encoding Cloning to maintain pixel-level correspondence across layers. Extensive experiments on the proposed AlphaBlend dataset and public LOGO dataset verify the effectiveness of DiffDecompose. The code and dataset will be available upon paper acceptance. Our code will be available at: https://github.com/Wangzt1121/DiffDecompose.","authors":["Zitong Wang","Hang Zhao","Qianyu Zhou","Xuequan Lu","Xiangtai Li","Yiren Song"],"url":"https://arxiv.org/abs/2505.21541"}
{"created":"2025-05-29","title":"Toward a Cultural Co-Genesis of AI Ethics","abstract":"Contemporary discussions in AI ethics often treat culture as a source of normative divergence that needs to be accommodated, tolerated, or managed due to its resistance to universal standards. This paper offers an alternative vision through the concept of \"Cultural Co-Genesis of AI Ethics.\" Rather than viewing culture as a boundary or container of isolated moral systems, we argue that it is a generative space for ethical co-production. In this framework, ethical values emerge through intercultural engagement, dialogical encounters, mutual recognition, and shared moral inquiry.","authors":["Ammar Younas"],"url":"https://arxiv.org/abs/2505.21542"}
{"created":"2025-05-29","title":"Vision Meets Language: A RAG-Augmented YOLOv8 Framework for Coffee Disease Diagnosis and Farmer Assistance","abstract":"As a social being, we have an intimate bond with the environment. A plethora of things in human life, such as lifestyle, health, and food are dependent on the environment and agriculture. It comes under our responsibility to support the environment as well as agriculture. However, traditional farming practices often result in inefficient resource use and environmental challenges. To address these issues, precision agriculture has emerged as a promising approach that leverages advanced technologies to optimise agricultural processes. In this work, a hybrid approach is proposed that combines the three different potential fields of model AI: object detection, large language model (LLM), and Retrieval-Augmented Generation (RAG). In this novel framework, we have tried to combine the vision and language models to work together to identify potential diseases in the tree leaf. This study introduces a novel AI-based precision agriculture system that uses Retrieval Augmented Generation (RAG) to provide context-aware diagnoses and natural language processing (NLP) and YOLOv8 for crop disease detection. The system aims to tackle major issues with large language models (LLMs), especially hallucinations and allows for adaptive treatment plans and real-time disease detection. The system provides an easy-to-use interface to the farmers, which they can use to detect the different diseases related to coffee leaves by just submitting the image of the affected leaf the model will detect the diseases as well as suggest potential remediation methodologies which aim to lower the use of pesticides, preserving livelihoods, and encouraging environmentally friendly methods. With an emphasis on scalability, dependability, and user-friendliness, the project intends to improve RAG-integrated object detection systems for wider agricultural applications in the future.","authors":["Semanto Mondal"],"url":"https://arxiv.org/abs/2505.21544"}
{"created":"2025-05-29","title":"Corruption-Aware Training of Latent Video Diffusion Models for Robust Text-to-Video Generation","abstract":"Latent Video Diffusion Models (LVDMs) achieve high-quality generation but are sensitive to imperfect conditioning, which causes semantic drift and temporal incoherence on noisy, web-scale video-text datasets. We introduce CAT-LVDM, the first corruption-aware training framework for LVDMs that improves robustness through structured, data-aligned noise injection. Our method includes Batch-Centered Noise Injection (BCNI), which perturbs embeddings along intra-batch semantic directions to preserve temporal consistency. BCNI is especially effective on caption-rich datasets like WebVid-2M, MSR-VTT, and MSVD. We also propose Spectrum-Aware Contextual Noise (SACN), which injects noise along dominant spectral directions to improve low-frequency smoothness, showing strong results on UCF-101. On average, BCNI reduces FVD by 31.9% across WebVid-2M, MSR-VTT, and MSVD, while SACN yields a 12.3% improvement on UCF-101. Ablation studies confirm the benefit of low-rank, data-aligned noise. Our theoretical analysis further explains how such perturbations tighten entropy, Wasserstein, score-drift, mixing-time, and generalization bounds. CAT-LVDM establishes a principled, scalable training approach for robust video diffusion under multimodal noise. Code and models: https://github.com/chikap421/catlvdm","authors":["Chika Maduabuchi","Hao Chen","Yujin Han","Jindong Wang"],"url":"https://arxiv.org/abs/2505.21545"}
{"created":"2025-05-29","title":"Image Tokens Matter: Mitigating Hallucination in Discrete Tokenizer-based Large Vision-Language Models via Latent Editing","abstract":"Large Vision-Language Models (LVLMs) with discrete image tokenizers unify multimodal representations by encoding visual inputs into a finite set of tokens. Despite their effectiveness, we find that these models still hallucinate non-existent objects. We hypothesize that this may be due to visual priors induced during training: When certain image tokens frequently co-occur in the same spatial regions and represent shared objects, they become strongly associated with the verbalizations of those objects. As a result, the model may hallucinate by evoking visually absent tokens that often co-occur with present ones. To test this assumption, we construct a co-occurrence graph of image tokens using a segmentation dataset and employ a Graph Neural Network (GNN) with contrastive learning followed by a clustering method to group tokens that frequently co-occur in similar visual contexts. We find that hallucinations predominantly correspond to clusters whose tokens dominate the input, and more specifically, that the visually absent tokens in those clusters show much higher correlation with hallucinated objects compared to tokens present in the image. Based on this observation, we propose a hallucination mitigation method that suppresses the influence of visually absent tokens by modifying latent image embeddings during generation. Experiments show our method reduces hallucinations while preserving expressivity. Code is available at https://github.com/weixingW/CGC-VTD/tree/main","authors":["Weixing Wang","Zifeng Ding","Jindong Gu","Rui Cao","Christoph Meinel","Gerard de Melo","Haojin Yang"],"url":"https://arxiv.org/abs/2505.21547"}
{"created":"2025-05-29","title":"Distill CLIP (DCLIP): Enhancing Image-Text Retrieval via Cross-Modal Transformer Distillation","abstract":"We present Distill CLIP (DCLIP), a fine-tuned variant of the CLIP model that enhances multimodal image-text retrieval while preserving the original model's strong zero-shot classification capabilities. CLIP models are typically constrained by fixed image resolutions and limited context, which can hinder their effectiveness in retrieval tasks that require fine-grained cross-modal understanding. DCLIP addresses these challenges through a meta teacher-student distillation framework, where a cross-modal transformer teacher is fine-tuned to produce enriched embeddings via bidirectional cross-attention between YOLO-extracted image regions and corresponding textual spans. These semantically and spatially aligned global representations guide the training of a lightweight student model using a hybrid loss that combines contrastive learning and cosine similarity objectives. Despite being trained on only ~67,500 samples curated from MSCOCO, Flickr30k, and Conceptual Captions-just a fraction of CLIP's original dataset-DCLIP significantly improves image-text retrieval metrics (Recall@K, MAP), while retaining approximately 94% of CLIP's zero-shot classification performance. These results demonstrate that DCLIP effectively mitigates the trade-off between task specialization and generalization, offering a resource-efficient, domain-adaptive, and detail-sensitive solution for advanced vision-language tasks. Code available at https://anonymous.4open.science/r/DCLIP-B772/README.md.","authors":["Daniel Csizmadia","Andrei Codreanu","Victor Sim","Vighnesh Prabeau","Michael Lu","Kevin Zhu","Sean O'Brien","Vasu Sharma"],"url":"https://arxiv.org/abs/2505.21549"}
{"created":"2025-05-29","title":"Collaborative Agentic AI Needs Interoperability Across Ecosystems","abstract":"Collaborative agentic AI is projected to transform entire industries by enabling AI-powered agents to autonomously perceive, plan, and act within digital environments. Yet, current solutions in this field are all built in isolation, and we are rapidly heading toward a landscape of fragmented, incompatible ecosystems. In this position paper, we argue that interoperability, achieved by the adoption of minimal standards, is essential to ensure open, secure, web-scale, and widely-adopted agentic ecosystems. To this end, we devise a minimal architectural foundation for collaborative agentic AI, named Web of Agents, which is composed of four components: agent-to-agent messaging, interaction interoperability, state management, and agent discovery. Web of Agents adopts existing standards and reuses existing infrastructure where possible. With Web of Agents, we take the first but critical step toward interoperable agentic systems and offer a pragmatic path forward before ecosystem fragmentation becomes the norm.","authors":["Rishi Sharma","Martijn de Vos","Pradyumna Chari","Ramesh Raskar","Anne-Marie Kermarrec"],"url":"https://arxiv.org/abs/2505.21550"}
{"created":"2025-05-29","title":"Understanding the learned look-ahead behavior of chess neural networks","abstract":"We investigate the look-ahead capabilities of chess-playing neural networks, specifically focusing on the Leela Chess Zero policy network. We build on the work of Jenner et al. (2024) by analyzing the model's ability to consider future moves and alternative sequences beyond the immediate next move. Our findings reveal that the network's look-ahead behavior is highly context-dependent, varying significantly based on the specific chess position. We demonstrate that the model can process information about board states up to seven moves ahead, utilizing similar internal mechanisms across different future time steps. Additionally, we provide evidence that the network considers multiple possible move sequences rather than focusing on a single line of play. These results offer new insights into the emergence of sophisticated look-ahead capabilities in neural networks trained on strategic tasks, contributing to our understanding of AI reasoning in complex domains. Our work also showcases the effectiveness of interpretability techniques in uncovering cognitive-like processes in artificial intelligence systems.","authors":["Diogo Cruz"],"url":"https://arxiv.org/abs/2505.21552"}
{"created":"2025-05-29","title":"MetaSTNet: Multimodal Meta-learning for Cellular Traffic Conformal Prediction","abstract":"Network traffic prediction techniques have attracted much attention since they are valuable for network congestion control and user experience improvement. While existing prediction techniques can achieve favorable performance when there is sufficient training data, it remains a great challenge to make accurate predictions when only a small amount of training data is available. To tackle this problem, we propose a deep learning model, entitled MetaSTNet, based on a multimodal meta-learning framework. It is an end-to-end network architecture that trains the model in a simulator and transfers the meta-knowledge to a real-world environment, which can quickly adapt and obtain accurate predictions on a new task with only a small amount of real-world training data. In addition, we further employ cross conformal prediction to assess the calibrated prediction intervals. Extensive experiments have been conducted on real-world datasets to illustrate the efficiency and effectiveness of MetaSTNet.","authors":["Hui Ma","Kai Yang"],"url":"https://arxiv.org/abs/2505.21553"}
{"created":"2025-05-29","title":"Benign-to-Toxic Jailbreaking: Inducing Harmful Responses from Harmless Prompts","abstract":"Optimization-based jailbreaks typically adopt the Toxic-Continuation setting in large vision-language models (LVLMs), following the standard next-token prediction objective. In this setting, an adversarial image is optimized to make the model predict the next token of a toxic prompt. However, we find that the Toxic-Continuation paradigm is effective at continuing already-toxic inputs, but struggles to induce safety misalignment when explicit toxic signals are absent. We propose a new paradigm: Benign-to-Toxic (B2T) jailbreak. Unlike prior work, we optimize adversarial images to induce toxic outputs from benign conditioning. Since benign conditioning contains no safety violations, the image alone must break the model's safety mechanisms. Our method outperforms prior approaches, transfers in black-box settings, and complements text-based jailbreaks. These results reveal an underexplored vulnerability in multimodal alignment and introduce a fundamentally new direction for jailbreak approaches.","authors":["Hee-Seon Kim","Minbeom Kim","Wonjun Lee","Kihyun Kim","Changick Kim"],"url":"https://arxiv.org/abs/2505.21556"}
{"created":"2025-05-29","title":"Analytical Calculation of Weights Convolutional Neural Network","abstract":"This paper presents an algorithm for analytically calculating the weights and thresholds of convolutional neural networks (CNNs) without using standard training procedures. The algorithm enables the determination of CNN parameters based on just 10 selected images from the MNIST dataset, each representing a digit from 0 to 9. As part of the method, the number of channels in CNN layers is also derived analytically. A software module was implemented in C++ Builder, and a series of experiments were conducted using the MNIST dataset. Results demonstrate that the analytically computed CNN can recognize over half of 1000 handwritten digit images without any training, achieving inference in fractions of a second. These findings suggest that CNNs can be constructed and applied directly for classification tasks without training, using purely analytical computation of weights.","authors":["Polad Geidarov"],"url":"https://arxiv.org/abs/2505.21557"}
{"created":"2025-05-29","title":"A Novel Convolutional Neural Network-Based Framework for Complex Multiclass Brassica Seed Classification","abstract":"Agricultural research has accelerated in recent years, yet farmers often lack the time and resources for on-farm research due to the demands of crop production and farm operations. Seed classification offers valuable insights into quality control, production efficiency, and impurity detection. Early identification of seed types is critical to reducing the cost and risk associated with field emergence, which can lead to yield losses or disruptions in downstream processes like harvesting. Seed sampling supports growers in monitoring and managing seed quality, improving precision in determining seed purity levels, guiding management adjustments, and enhancing yield estimations. This study proposes a novel convolutional neural network (CNN)-based framework for the efficient classification of ten common Brassica seed types. The approach addresses the inherent challenge of texture similarity in seed images using a custom-designed CNN architecture. The model's performance was evaluated against several pre-trained state-of-the-art architectures, with adjustments to layer configurations for optimized classification. Experimental results using our collected Brassica seed dataset demonstrate that the proposed model achieved a high accuracy rate of 93 percent.","authors":["Elhoucine Elfatimia","Recep Eryigitb","Lahcen Elfatimi"],"url":"https://arxiv.org/abs/2505.21558"}
{"created":"2025-05-29","title":"Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems via an Automated Online Design Framework","abstract":"In cloud-native systems, Kubernetes clusters with interdependent services often face challenges to their operational resilience due to poor workload management issues such as resource blocking, bottlenecks, or continuous pod crashes. These vulnerabilities are further amplified in adversarial scenarios, such as Distributed Denial-of-Service attacks (DDoS). Conventional Horizontal Pod Autoscaling (HPA) approaches struggle to address such dynamic conditions, while reinforcement learning-based methods, though more adaptable, typically optimize single goals like latency or resource usage, neglecting broader failure scenarios. We propose decomposing the overarching goal of maintaining operational resilience into failure-specific sub-goals delegated to collaborative agents, collectively forming an HPA Multi-Agent System (MAS). We introduce an automated, four-phase online framework for HPA MAS design: 1) modeling a digital twin built from cluster traces; 2) training agents in simulation using roles and missions tailored to failure contexts; 3) analyzing agent behaviors for explainability; and 4) transferring learned policies to the real cluster. Experimental results demonstrate that the generated HPA MASs outperform three state-of-the-art HPA systems in sustaining operational resilience under various adversarial conditions in a proposed complex cluster.","authors":["Julien Soul\\'e","Jean-Paul Jamont","Michel Occello","Louis-Marie Traonouez","Paul Th\\'eron"],"url":"https://arxiv.org/abs/2505.21559"}
{"created":"2025-05-29","title":"Knowledge Distillation Approach for SOS Fusion Staging: Towards Fully Automated Skeletal Maturity Assessment","abstract":"We introduce a novel deep learning framework for the automated staging of spheno-occipital synchondrosis (SOS) fusion, a critical diagnostic marker in both orthodontics and forensic anthropology. Our approach leverages a dual-model architecture wherein a teacher model, trained on manually cropped images, transfers its precise spatial understanding to a student model that operates on full, uncropped images. This knowledge distillation is facilitated by a newly formulated loss function that aligns spatial logits as well as incorporates gradient-based attention spatial mapping, ensuring that the student model internalizes the anatomically relevant features without relying on external cropping or YOLO-based segmentation. By leveraging expert-curated data and feedback at each step, our framework attains robust diagnostic accuracy, culminating in a clinically viable end-to-end pipeline. This streamlined approach obviates the need for additional pre-processing tools and accelerates deployment, thereby enhancing both the efficiency and consistency of skeletal maturation assessment in diverse clinical settings.","authors":["Omid Halimi Milani","Amanda Nikho","Marouane Tliba","Lauren Mills","Ahmet Enis Cetin","Mohammed H Elnagar"],"url":"https://arxiv.org/abs/2505.21561"}
{"created":"2025-05-29","title":"Enhancing Selection of Climate Tech Startups with AI -- A Case Study on Integrating Human and AI Evaluations in the ClimaTech Great Global Innovation Challenge","abstract":"This case study examines the ClimaTech Great Global Innovation Challenge's approach to selecting climate tech startups by integrating human and AI evaluations. The competition aimed to identify top startups and enhance the accuracy and efficiency of the selection process through a hybrid model. Research shows data-driven approaches help VC firms reduce bias and improve decision-making. Machine learning models have outperformed human investors in deal screening, helping identify high-potential startups. Incorporating AI aimed to ensure more equitable and objective evaluations.","authors":["Jennifer Turliuk","Alejandro Sevilla","Daniela Gorza","Tod Hynes"],"url":"https://arxiv.org/abs/2505.21562"}
{"created":"2025-05-29","title":"Fog Intelligence for Network Anomaly Detection","abstract":"Anomalies are common in network system monitoring. When manifested as network threats to be mitigated, service outages to be prevented, and security risks to be ameliorated, detecting such anomalous network behaviors becomes of great importance. However, the growing scale and complexity of the mobile communication networks, as well as the ever-increasing amount and dimensionality of the network surveillance data, make it extremely difficult to monitor a mobile network and discover abnormal network behaviors. Recent advances in machine learning allow for obtaining near-optimal solutions to complicated decision-making problems with many sources of uncertainty that cannot be accurately characterized by traditional mathematical models. However, most machine learning algorithms are centralized, which renders them inapplicable to a large-scale distributed wireless networks with tens of millions of mobile devices. In this article, we present fog intelligence, a distributed machine learning architecture that enables intelligent wireless network management. It preserves the advantage of both edge processing and centralized cloud computing. In addition, the proposed architecture is scalable, privacy-preserving, and well suited for intelligent management of a distributed wireless network.","authors":["Kai Yang","Hui Ma","Shaoyu Dou"],"url":"https://arxiv.org/abs/2505.21563"}
{"created":"2025-05-29","title":"Multi-instance Learning as Downstream Task of Self-Supervised Learning-based Pre-trained Model","abstract":"In deep multi-instance learning, the number of applicable instances depends on the data set. In histopathology images, deep learning multi-instance learners usually assume there are hundreds to thousands instances in a bag. However, when the number of instances in a bag increases to 256 in brain hematoma CT, learning becomes extremely difficult. In this paper, we address this drawback. To overcome this problem, we propose using a pre-trained model with self-supervised learning for the multi-instance learner as a downstream task. With this method, even when the original target task suffers from the spurious correlation problem, we show improvements of 5% to 13% in accuracy and 40% to 55% in the F1 measure for the hypodensity marker classification of brain hematoma CT.","authors":["Koki Matsuishi","Tsuyoshi Okita"],"url":"https://arxiv.org/abs/2505.21564"}
{"created":"2025-05-29","title":"Towards Human-Like Trajectory Prediction for Autonomous Driving: A Behavior-Centric Approach","abstract":"Predicting the trajectories of vehicles is crucial for the development of autonomous driving (AD) systems, particularly in complex and dynamic traffic environments. In this study, we introduce HiT (Human-like Trajectory Prediction), a novel model designed to enhance trajectory prediction by incorporating behavior-aware modules and dynamic centrality measures. Unlike traditional methods that primarily rely on static graph structures, HiT leverages a dynamic framework that accounts for both direct and indirect interactions among traffic participants. This allows the model to capture the subtle yet significant influences of surrounding vehicles, enabling more accurate and human-like predictions. To evaluate HiT's performance, we conducted extensive experiments using diverse and challenging real-world datasets, including NGSIM, HighD, RounD, ApolloScape, and MoCAD++. The results demonstrate that HiT consistently outperforms other top models across multiple metrics, particularly excelling in scenarios involving aggressive driving behaviors. This research presents a significant step forward in trajectory prediction, offering a more reliable and interpretable approach for enhancing the safety and efficiency of fully autonomous driving systems.","authors":["Haicheng Liao","Zhenning Li","Guohui Zhang","Keqiang Li","Chengzhong Xu"],"url":"https://arxiv.org/abs/2505.21565"}
{"created":"2025-05-29","title":"Diffusion Model-based Activity Completion for AI Motion Capture from Videos","abstract":"AI-based motion capture is an emerging technology that offers a cost-effective alternative to traditional motion capture systems. However, current AI motion capture methods rely entirely on observed video sequences, similar to conventional motion capture. This means that all human actions must be predefined, and movements outside the observed sequences are not possible. To address this limitation, we aim to apply AI motion capture to virtual humans, where flexible actions beyond the observed sequences are required. We assume that while many action fragments exist in the training data, the transitions between them may be missing. To bridge these gaps, we propose a diffusion-model-based action completion technique that generates complementary human motion sequences, ensuring smooth and continuous movements. By introducing a gate module and a position-time embedding module, our approach achieves competitive results on the Human3.6M dataset. Our experimental results show that (1) MDC-Net outperforms existing methods in ADE, FDE, and MMADE but is slightly less accurate in MMFDE, (2) MDC-Net has a smaller model size (16.84M) compared to HumanMAC (28.40M), and (3) MDC-Net generates more natural and coherent motion sequences. Additionally, we propose a method for extracting sensor data, including acceleration and angular velocity, from human motion sequences.","authors":["Gao Huayu","Huang Tengjiu","Ye Xiaolong","Tsuyoshi Okita"],"url":"https://arxiv.org/abs/2505.21566"}
{"created":"2025-05-29","title":"EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models","abstract":"With the development of Embodied Artificial intelligence, the end-to-end control policy such as Vision-Language-Action (VLA) model has become the mainstream. Existing VLA models faces expensive computing/storage cost, which need to be optimized. Quantization is considered as the most effective method which can not only reduce the memory cost but also achieve computation acceleration. However, we find the token alignment of VLA models hinders the application of existing quantization methods. To address this, we proposed an optimized framework called EaqVLA, which apply encoding-aligned quantization to VLA models. Specifically, we propose an complete analysis method to find the misalignment in various granularity. Based on the analysis results, we propose a mixed precision quantization with the awareness of encoding alignment. Experiments shows that the porposed EaqVLA achieves better quantization performance (with the minimal quantization loss for end-to-end action control and xxx times acceleration) than existing quantization methods.","authors":["Feng Jiang","Zihao Zheng","Xiuping Cui","Maoliang Li","JIayu Chen","Xiang Chen"],"url":"https://arxiv.org/abs/2505.21567"}
{"created":"2025-05-29","title":"VoiceMark: Zero-Shot Voice Cloning-Resistant Watermarking Approach Leveraging Speaker-Specific Latents","abstract":"Voice cloning (VC)-resistant watermarking is an emerging technique for tracing and preventing unauthorized cloning. Existing methods effectively trace traditional VC models by training them on watermarked audio but fail in zero-shot VC scenarios, where models synthesize audio from an audio prompt without training. To address this, we propose VoiceMark, the first zero-shot VC-resistant watermarking method that leverages speaker-specific latents as the watermark carrier, allowing the watermark to transfer through the zero-shot VC process into the synthesized audio. Additionally, we introduce VC-simulated augmentations and VAD-based loss to enhance robustness against distortions. Experiments on multiple zero-shot VC models demonstrate that VoiceMark achieves over 95% accuracy in watermark detection after zero-shot VC synthesis, significantly outperforming existing methods, which only reach around 50%. See our code and demos at: https://huggingface.co/spaces/haiyunli/VoiceMark","authors":["Haiyun Li","Zhiyong Wu","Xiaofeng Xie","Jingran Xie","Yaoxun Xu","Hanyang Peng"],"url":"https://arxiv.org/abs/2505.21568"}
{"created":"2025-05-29","title":"ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools","abstract":"Large Language Model (LLM)-based agents have demonstrated the ability to improve performance in chemistry-related tasks by selecting appropriate tools. However, their effectiveness remains limited by the inherent prediction errors of chemistry tools. In this paper, we take a step further by exploring how LLMbased agents can, in turn, be leveraged to reduce prediction errors of the tools. To this end, we propose ChemHAS (Chemical Hierarchical Agent Stacking), a simple yet effective method that enhances chemistry tools through optimizing agent-stacking structures from limited data. ChemHAS achieves state-of-the-art performance across four fundamental chemistry tasks, demonstrating that our method can effectively compensate for prediction errors of the tools. Furthermore, we identify and characterize four distinct agent-stacking behaviors, potentially improving interpretability and revealing new possibilities for AI agent applications in scientific research. Our code and dataset are publicly available at https: //anonymous.4open.science/r/ChemHAS-01E4/README.md.","authors":["Zhucong Li","Bowei Zhang","Jin Xiao","Zhijian Zhou","Fenglei Cao","Jiaqing Liang","Yuan Qi"],"url":"https://arxiv.org/abs/2505.21569"}
{"created":"2025-05-29","title":"Beyond Explainability: The Case for AI Validation","abstract":"Artificial Knowledge (AK) systems are transforming decision-making across critical domains such as healthcare, finance, and criminal justice. However, their growing opacity presents governance challenges that current regulatory approaches, focused predominantly on explainability, fail to address adequately. This article argues for a shift toward validation as a central regulatory pillar. Validation, ensuring the reliability, consistency, and robustness of AI outputs, offers a more practical, scalable, and risk-sensitive alternative to explainability, particularly in high-stakes contexts where interpretability may be technically or economically unfeasible. We introduce a typology based on two axes, validity and explainability, classifying AK systems into four categories and exposing the trade-offs between interpretability and output reliability. Drawing on comparative analysis of regulatory approaches in the EU, US, UK, and China, we show how validation can enhance societal trust, fairness, and safety even where explainability is limited. We propose a forward-looking policy framework centered on pre- and post-deployment validation, third-party auditing, harmonized standards, and liability incentives. This framework balances innovation with accountability and provides a governance roadmap for responsibly integrating opaque, high-performing AK systems into society.","authors":["Dalit Ken-Dror Feldman","Daniel Benoliel"],"url":"https://arxiv.org/abs/2505.21570"}
{"created":"2025-05-29","title":"FCOS: A Two-Stage Recoverable Model Pruning Framework for Automatic Modulation Recognition","abstract":"With the rapid development of wireless communications and the growing complexity of digital modulation schemes, traditional manual modulation recognition methods struggle to extract reliable signal features and meet real-time requirements in modern scenarios. Recently, deep learning based Automatic Modulation Recognition (AMR) approaches have greatly improved classification accuracy. However, their large model sizes and high computational demands hinder deployment on resource-constrained devices. Model pruning provides a general approach to reduce model complexity, but existing weight, channel, and layer pruning techniques each present a trade-off between compression rate, hardware acceleration, and accuracy preservation. To this end, in this paper, we introduce FCOS, a novel Fine-to-COarse two-Stage pruning framework that combines channel-level pruning with layer-level collapse diagnosis to achieve extreme compression, high performance and efficient inference. In the first stage of FCOS, hierarchical clustering and parameter fusion are applied to channel weights to achieve channel-level pruning. Then a Layer Collapse Diagnosis (LaCD) module uses linear probing to identify layer collapse and removes the collapsed layers due to high channel compression ratio. Experiments on multiple AMR benchmarks demonstrate that FCOS outperforms existing channel and layer pruning methods. Specifically, FCOS achieves 95.51% FLOPs reduction and 95.31% parameter reduction while still maintaining performance close to the original ResNet56, with only a 0.46% drop in accuracy on Sig2019-12. Code is available at https://github.com/yaolu-zjut/FCOS.","authors":["Yao Lu","Tengfei Ma","Zeyu Wang","Zhuangzhi Chen","Dongwei Xu","Yun Lin","Qi Xuan","Guan Gui"],"url":"https://arxiv.org/abs/2505.21571"}
{"created":"2025-05-29","title":"Thickness-aware E(3)-Equivariant 3D Mesh Neural Networks","abstract":"Mesh-based 3D static analysis methods have recently emerged as efficient alternatives to traditional computational numerical solvers, significantly reducing computational costs and runtime for various physics-based analyses. However, these methods primarily focus on surface topology and geometry, often overlooking the inherent thickness of real-world 3D objects, which exhibits high correlations and similar behavior between opposing surfaces. This limitation arises from the disconnected nature of these surfaces and the absence of internal edge connections within the mesh. In this work, we propose a novel framework, the Thickness-aware E(3)-Equivariant 3D Mesh Neural Network (T-EMNN), that effectively integrates the thickness of 3D objects while maintaining the computational efficiency of surface meshes. Additionally, we introduce data-driven coordinates that encode spatial information while preserving E(3)-equivariance or invariance properties, ensuring consistent and robust analysis. Evaluations on a real-world industrial dataset demonstrate the superior performance of T-EMNN in accurately predicting node-level 3D deformations, effectively capturing thickness effects while maintaining computational efficiency.","authors":["Sungwon Kim","Namkyeong Lee","Yunyoung Doh","Seungmin Shin","Guimok Cho","Seung-Won Jeon","Sangkook Kim","Chanyoung Park"],"url":"https://arxiv.org/abs/2505.21572"}
{"created":"2025-05-29","title":"Spectral-inspired Neural Operator for Data-efficient PDE Simulation in Physics-agnostic Regimes","abstract":"Partial differential equations (PDEs) govern the spatiotemporal evolution of various physical systems. Classical numerical solvers, while accurate, require fine discretization and full knowledge of the governing PDEs, limiting their applicability when the physics is unknown or fast inference is required. Data-driven neural PDE solvers alleviate these constraints by learning from data but demand large training datasets and perform poorly in data-scarce regimes. Physics-aware methods mitigate data requirements by incorporating physical knowledge yet rely on known PDE terms or local numerical schemes, restricting their ability to handle unknown or globally coupled systems. In this work, we propose the Spectral-inspired Neural Operator (SINO), a novel framework that learns PDE operators from limited trajectories (as few as 2-5), without any known PDE terms. SINO operates in the frequency domain and introduces a Frequency-to-Vector module to learn spectral representations analogous to derivative multipliers. To model nonlinear physical interactions, we design a nonlinear operator block that includes a $\\Pi$-Block with low-pass filtering to prevent aliasing. Finally, we introduce an operator distillation technique to distill the trained model for efficient inference. SINO achieves state-of-the-art results across multiple PDE benchmarks, demonstrating strong discretization invariance and robust generalization to out-of-distribution initial conditions. To our knowledge, SINO is the first physics-aware method capable of accurately simulating globally coupled systems (e.g., the Navier-Stokes equations) from limited data without any explicit PDE terms.","authors":["Han Wan","Rui Zhang","Hao Sun"],"url":"https://arxiv.org/abs/2505.21573"}
{"created":"2025-05-29","title":"Do We Need All the Synthetic Data? Towards Targeted Synthetic Image Augmentation via Diffusion Models","abstract":"Synthetically augmenting training datasets with diffusion models has been an effective strategy for improving generalization of image classifiers. However, existing techniques struggle to ensure the diversity of generation and increase the size of the data by up to 10-30x to improve the in-distribution performance. In this work, we show that synthetically augmenting part of the data that is not learned early in training outperforms augmenting the entire dataset. By analyzing a two-layer CNN, we prove that this strategy improves generalization by promoting homogeneity in feature learning speed without amplifying noise. Our extensive experiments show that by augmenting only 30%-40% of the data, our method boosts the performance by up to 2.8% in a variety of scenarios, including training ResNet, ViT and DenseNet on CIFAR-10, CIFAR-100, and TinyImageNet, with a range of optimizers including SGD and SAM. Notably, our method applied with SGD outperforms the SOTA optimizer, SAM, on CIFAR-100 and TinyImageNet. It can also easily stack with existing weak and strong augmentation strategies to further boost the performance.","authors":["Dang Nguyen","Jiping Li","Jinghao Zheng","Baharan Mirzasoleiman"],"url":"https://arxiv.org/abs/2505.21574"}
{"created":"2025-05-29","title":"StreamLink: Large-Language-Model Driven Distributed Data Engineering System","abstract":"Large Language Models (LLMs) have shown remarkable proficiency in natural language understanding (NLU), opening doors for innovative applications. We introduce StreamLink - an LLM-driven distributed data system designed to improve the efficiency and accessibility of data engineering tasks. We build StreamLink on top of distributed frameworks such as Apache Spark and Hadoop to handle large data at scale. One of the important design philosophies of StreamLink is to respect user data privacy by utilizing local fine-tuned LLMs instead of a public AI service like ChatGPT. With help from domain-adapted LLMs, we can improve our system's understanding of natural language queries from users in various scenarios and simplify the procedure of generating database queries like the Structured Query Language (SQL) for information processing. We also incorporate LLM-based syntax and security checkers to guarantee the reliability and safety of each generated query. StreamLink illustrates the potential of merging generative LLMs with distributed data processing for comprehensive and user-centric data engineering. With this architecture, we allow users to interact with complex database systems at different scales in a user-friendly and security-ensured manner, where the SQL generation reaches over 10\\% of execution accuracy compared to baseline methods, and allow users to find the most concerned item from hundreds of millions of items within a few seconds using natural language.","authors":["Dawei Feng","Di Mei","Huiri Tan","Lei Ren","Xianying Lou","Zhangxi Tan"],"url":"https://arxiv.org/abs/2505.21575"}
{"created":"2025-05-29","title":"Concentration Distribution Learning from Label Distributions","abstract":"Label distribution learning (LDL) is an effective method to predict the relative label description degree (a.k.a. label distribution) of a sample. However, the label distribution is not a complete representation of an instance because it overlooks the absolute intensity of each label. Specifically, it's impossible to obtain the total description degree of hidden labels that not in the label space, which leads to the loss of information and confusion in instances. To solve the above problem, we come up with a new concept named background concentration to serve as the absolute description degree term of the label distribution and introduce it into the LDL process, forming the improved paradigm of concentration distribution learning. Moreover, we propose a novel model by probabilistic methods and neural networks to learn label distributions and background concentrations from existing LDL datasets. Extensive experiments prove that the proposed approach is able to extract background concentrations from label distributions while producing more accurate prediction results than the state-of-the-art LDL methods. The code is available in https://github.com/seutjw/CDL-LD.","authors":["Jiawei Tang","Yuheng Jia"],"url":"https://arxiv.org/abs/2505.21576"}
{"created":"2025-05-29","title":"RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving","abstract":"The ultimate goal of code agents is to solve complex tasks autonomously. Although large language models (LLMs) have made substantial progress in code generation, real-world tasks typically demand full-fledged code repositories rather than simple scripts. Building such repositories from scratch remains a major challenge. Fortunately, GitHub hosts a vast, evolving collection of open-source repositories, which developers frequently reuse as modular components for complex tasks. Yet, existing frameworks like OpenHands and SWE-Agent still struggle to effectively leverage these valuable resources. Relying solely on README files provides insufficient guidance, and deeper exploration reveals two core obstacles: overwhelming information and tangled dependencies of repositories, both constrained by the limited context windows of current LLMs. To tackle these issues, we propose RepoMaster, an autonomous agent framework designed to explore and reuse GitHub repositories for solving complex tasks. For efficient understanding, RepoMaster constructs function-call graphs, module-dependency graphs, and hierarchical code trees to identify essential components, providing only identified core elements to the LLMs rather than the entire repository. During autonomous execution, it progressively explores related components using our exploration tools and prunes information to optimize context usage. Evaluated on the adjusted MLE-bench, RepoMaster achieves a 110% relative boost in valid submissions over the strongest baseline OpenHands. On our newly released GitTaskBench, RepoMaster lifts the task-pass rate from 24.1% to 62.9% while reducing token usage by 95%. Our code and demonstration materials are publicly available at https://github.com/wanghuacan/RepoMaster.","authors":["Huacan Wang","Ziyi Ni","Shuo Zhang","Shuo Lu","Sen Hu","Ziyang He","Chen Hu","Jiaye Lin","Yifu Guo","Yuntao Du","Pin Lyu"],"url":"https://arxiv.org/abs/2505.21577"}
{"created":"2025-05-29","title":"Loquacious Set: 25,000 Hours of Transcribed and Diverse English Speech Recognition Data for Research and Commercial Use","abstract":"Automatic speech recognition (ASR) research is driven by the availability of common datasets between industrial researchers and academics, encouraging comparisons and evaluations. LibriSpeech, despite its long success as an ASR benchmark, is now limited by its size and focus on clean, read speech, leading to near-zero word error rates. More recent datasets, including MOSEL, YODAS, Gigaspeech, OWSM, Libriheavy or People's Speech suffer from major limitations including licenses that researchers in the industry cannot use, unreliable transcriptions, incorrect audio data, or the lack of evaluation sets. This work presents the Loquacious Set, a 25,000-hour curated collection of commercially usable English speech. Featuring hundreds of thousands of speakers with diverse accents and a wide range of speech types (read, spontaneous, talks, clean, noisy), the Loquacious Set is designed to work for academics and researchers in the industry to build ASR systems in real-world scenarios.","authors":["Titouan Parcollet","Yuan Tseng","Shucong Zhang","Rogier van Dalen"],"url":"https://arxiv.org/abs/2505.21578"}
{"created":"2025-05-29","title":"CogAD: Cognitive-Hierarchy Guided End-to-End Autonomous Driving","abstract":"While end-to-end autonomous driving has advanced significantly, prevailing methods remain fundamentally misaligned with human cognitive principles in both perception and planning. In this paper, we propose CogAD, a novel end-to-end autonomous driving model that emulates the hierarchical cognition mechanisms of human drivers. CogAD implements dual hierarchical mechanisms: global-to-local context processing for human-like perception and intent-conditioned multi-mode trajectory generation for cognitively-inspired planning. The proposed method demonstrates three principal advantages: comprehensive environmental understanding through hierarchical perception, robust planning exploration enabled by multi-level planning, and diverse yet reasonable multi-modal trajectory generation facilitated by dual-level uncertainty modeling. Extensive experiments on nuScenes and Bench2Drive demonstrate that CogAD achieves state-of-the-art performance in end-to-end planning, exhibiting particular superiority in long-tail scenarios and robust generalization to complex real-world driving conditions.","authors":["Zhennan Wang","Jianing Teng","Canqun Xiang","Kangliang Chen","Xing Pan","Lu Deng","Weihao Gu"],"url":"https://arxiv.org/abs/2505.21581"}
{"created":"2025-05-29","title":"AITEE -- Agentic Tutor for Electrical Engineering","abstract":"Intelligent tutoring systems combined with large language models offer a promising approach to address students' diverse needs and promote self-efficacious learning. While large language models possess good foundational knowledge of electrical engineering basics, they remain insufficiently capable of addressing specific questions about electrical circuits. In this paper, we present AITEE, an agent-based tutoring system for electrical engineering designed to accompany students throughout their learning process, offer individualized support, and promote self-directed learning. AITEE supports both hand-drawn and digital circuits through an adapted circuit reconstruction process, enabling natural interaction with students. Our novel graph-based similarity measure identifies relevant context from lecture materials through a retrieval augmented generation approach, while parallel Spice simulation further enhances accuracy in applying solution methodologies. The system implements a Socratic dialogue to foster learner autonomy through guided questioning. Experimental evaluations demonstrate that AITEE significantly outperforms baseline approaches in domain-specific knowledge application, with even medium-sized LLM models showing acceptable performance. Our results highlight the potential of agentic tutors to deliver scalable, personalized, and effective learning environments for electrical engineering education.","authors":["Christopher Knievel","Alexander Bernhardt","Christian Bernhardt"],"url":"https://arxiv.org/abs/2505.21582"}
{"created":"2025-05-29","title":"Fairness in Federated Learning: Fairness for Whom?","abstract":"Fairness in federated learning has emerged as a rapidly growing area of research, with numerous works proposing formal definitions and algorithmic interventions. Yet, despite this technical progress, fairness in FL is often defined and evaluated in ways that abstract away from the sociotechnical contexts in which these systems are deployed. In this paper, we argue that existing approaches tend to optimize narrow system level metrics, such as performance parity or contribution-based rewards, while overlooking how harms arise throughout the FL lifecycle and how they impact diverse stakeholders. We support this claim through a critical analysis of the literature, based on a systematic annotation of papers for their fairness definitions, design decisions, evaluation practices, and motivating use cases. Our analysis reveals five recurring pitfalls: 1) fairness framed solely through the lens of server client architecture, 2) a mismatch between simulations and motivating use-cases and contexts, 3) definitions that conflate protecting the system with protecting its users, 4) interventions that target isolated stages of the lifecycle while neglecting upstream and downstream effects, 5) and a lack of multi-stakeholder alignment where multiple fairness definitions can be relevant at once. Building on these insights, we propose a harm centered framework that links fairness definitions to concrete risks and stakeholder vulnerabilities. We conclude with recommendations for more holistic, context-aware, and accountable fairness research in FL.","authors":["Afaf Taik","Khaoula Chehbouni","Golnoosh Farnadi"],"url":"https://arxiv.org/abs/2505.21584"}
{"created":"2025-05-29","title":"CellCLAT: Preserving Topology and Trimming Redundancy in Self-Supervised Cellular Contrastive Learning","abstract":"Self-supervised topological deep learning (TDL) represents a nascent but underexplored area with significant potential for modeling higher-order interactions in simplicial complexes and cellular complexes to derive representations of unlabeled graphs. Compared to simplicial complexes, cellular complexes exhibit greater expressive power. However, the advancement in self-supervised learning for cellular TDL is largely hindered by two core challenges: \\textit{extrinsic structural constraints} inherent to cellular complexes, and intrinsic semantic redundancy in cellular representations. The first challenge highlights that traditional graph augmentation techniques may compromise the integrity of higher-order cellular interactions, while the second underscores that topological redundancy in cellular complexes potentially diminish task-relevant information. To address these issues, we introduce Cellular Complex Contrastive Learning with Adaptive Trimming (CellCLAT), a twofold framework designed to adhere to the combinatorial constraints of cellular complexes while mitigating informational redundancy. Specifically, we propose a parameter perturbation-based augmentation method that injects controlled noise into cellular interactions without altering the underlying cellular structures, thereby preserving cellular topology during contrastive learning. Additionally, a cellular trimming scheduler is employed to mask gradient contributions from task-irrelevant cells through a bi-level meta-learning approach, effectively removing redundant topological elements while maintaining critical higher-order semantics. We provide theoretical justification and empirical validation to demonstrate that CellCLAT achieves substantial improvements over existing self-supervised graph learning methods, marking a significant attempt in this domain.","authors":["Bin Qin","Qirui Ji","Jiangmeng Li","Yupeng Wang","Xuesong Wu","Jianwen Cao","Fanjiang Xu"],"url":"https://arxiv.org/abs/2505.21587"}
{"created":"2025-05-29","title":"Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems","abstract":"Recent advancements in Large Language Models (LLMs) have enabled the emergence of multi-agent systems where LLMs interact, collaborate, and make decisions in shared environments. While individual model behavior has been extensively studied, the dynamics of peer influence in such systems remain underexplored. In this paper, we investigate herd behavior, the tendency of agents to align their outputs with those of their peers, within LLM-based multi-agent interactions. We present a series of controlled experiments that reveal how herd behaviors are shaped by multiple factors. First, we show that the gap between self-confidence and perceived confidence in peers significantly impacts an agent's likelihood to conform. Second, we find that the format in which peer information is presented plays a critical role in modulating the strength of herd behavior. Finally, we demonstrate that the degree of herd behavior can be systematically controlled, and that appropriately calibrated herd tendencies can enhance collaborative outcomes. These findings offer new insights into the social dynamics of LLM-based systems and open pathways for designing more effective and adaptive multi-agent collaboration frameworks.","authors":["Young-Min Cho","Sharath Chandra Guntuku","Lyle Ungar"],"url":"https://arxiv.org/abs/2505.21588"}
{"created":"2025-05-29","title":"Do you see what I see? An Ambiguous Optical Illusion Dataset exposing limitations of Explainable AI","abstract":"From uncertainty quantification to real-world object detection, we recognize the importance of machine learning algorithms, particularly in safety-critical domains such as autonomous driving or medical diagnostics. In machine learning, ambiguous data plays an important role in various machine learning domains. Optical illusions present a compelling area of study in this context, as they offer insight into the limitations of both human and machine perception. Despite this relevance, optical illusion datasets remain scarce. In this work, we introduce a novel dataset of optical illusions featuring intermingled animal pairs designed to evoke perceptual ambiguity. We identify generalizable visual concepts, particularly gaze direction and eye cues, as subtle yet impactful features that significantly influence model accuracy. By confronting models with perceptual ambiguity, our findings underscore the importance of concepts in visual learning and provide a foundation for studying bias and alignment between human and machine vision. To make this dataset useful for general purposes, we generate optical illusions systematically with different concepts discussed in our bias mitigation section. The dataset is accessible in Kaggle via https://kaggle.com/datasets/693bf7c6dd2cb45c8a863f9177350c8f9849a9508e9d50526e2ffcc5559a8333. Our source code can be found at https://github.com/KDD-OpenSource/Ambivision.git.","authors":["Carina Newen","Luca Hinkamp","Maria Ntonti","Emmanuel M\\\"uller"],"url":"https://arxiv.org/abs/2505.21589"}
{"created":"2025-05-29","title":"Computational Reproducibility of R Code Supplements on OSF","abstract":"Computational reproducibility is fundamental to scientific research, yet many published code supplements lack the necessary documentation to recreate their computational environments. While researchers increasingly share code alongside publications, the actual reproducibility of these materials remains poorly understood.","authors":["Lorraine Saju","Tobias Holtdirk","Meetkumar Pravinbhai Mangroliya","Arnim Bleier"],"url":"https://arxiv.org/abs/2505.21590"}
{"created":"2025-05-29","title":"Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning","abstract":"Model quantization reduces the bit-width of weights and activations, improving memory efficiency and inference speed in diffusion models. However, achieving 4-bit quantization remains challenging. Existing methods, primarily based on integer quantization and post-training quantization fine-tuning, struggle with inconsistent performance. Inspired by the success of floating-point (FP) quantization in large language models, we explore low-bit FP quantization for diffusion models and identify key challenges: the failure of signed FP quantization to handle asymmetric activation distributions, the insufficient consideration of temporal complexity in the denoising process during fine-tuning, and the misalignment between fine-tuning loss and quantization error. To address these challenges, we propose the mixup-sign floating-point quantization (MSFP) framework, first introducing unsigned FP quantization in model quantization, along with timestep-aware LoRA (TALoRA) and denoising-factor loss alignment (DFA), which ensure precise and stable fine-tuning. Extensive experiments show that we are the first to achieve superior performance in 4-bit FP quantization for diffusion models, outperforming existing PTQ fine-tuning methods in 4-bit INT quantization.","authors":["Maosen Zhao","Pengtao Chen","Chong Yu","Yan Wen","Xudong Tan","Tao Chen"],"url":"https://arxiv.org/abs/2505.21591"}
{"created":"2025-05-29","title":"Any-to-Bokeh: One-Step Video Bokeh via Multi-Plane Image Guided Diffusion","abstract":"Recent advances in diffusion based editing models have enabled realistic camera simulation and image-based bokeh, but video bokeh remains largely unexplored. Existing video editing models cannot explicitly control focus planes or adjust bokeh intensity, limiting their applicability for controllable optical effects. Moreover, naively extending image-based bokeh methods to video often results in temporal flickering and unsatisfactory edge blur transitions due to the lack of temporal modeling and generalization capability. To address these challenges, we propose a novel one-step video bokeh framework that converts arbitrary input videos into temporally coherent, depth-aware bokeh effects. Our method leverages a multi-plane image (MPI) representation constructed through a progressively widening depth sampling function, providing explicit geometric guidance for depth-dependent blur synthesis. By conditioning a single-step video diffusion model on MPI layers and utilizing the strong 3D priors from pre-trained models such as Stable Video Diffusion, our approach achieves realistic and consistent bokeh effects across diverse scenes. Additionally, we introduce a progressive training strategy to enhance temporal consistency, depth robustness, and detail preservation. Extensive experiments demonstrate that our method produces high-quality, controllable bokeh effects and achieves state-of-the-art performance on multiple evaluation benchmarks.","authors":["Yang Yang","Siming Zheng","Jinwei Chen","Boxi Wu","Xiaofei He","Deng Cai","Bo Li","Peng-Tao Jiang"],"url":"https://arxiv.org/abs/2505.21593"}
{"created":"2025-05-29","title":"Fast and Cost-effective Speculative Edge-Cloud Decoding with Early Exits","abstract":"Large Language Models (LLMs) enable various applications on edge devices such as smartphones, wearables, and embodied robots. However, their deployment often depends on expensive cloud-based APIs, creating high operational costs, which limit access for smaller organizations and raise sustainability concerns. Certain LLMs can be deployed on-device, offering a cost-effective solution with reduced latency and improved privacy. Yet, limited computing resources constrain the size and accuracy of models that can be deployed, necessitating a collaborative design between edge and cloud. We propose a fast and cost-effective speculative edge-cloud decoding framework with a large target model on the server and a small draft model on the device. By introducing early exits in the target model, tokens are generated mid-verification, allowing the client to preemptively draft subsequent tokens before final verification, thus utilizing idle time and enhancing parallelism between edge and cloud. Using an NVIDIA Jetson Nano (client) and an A100 GPU (server) with Vicuna-68M (draft) and Llama2-7B (target) models, our method achieves up to a 35% reduction in latency compared to cloud-based autoregressive decoding, with an additional 11% improvement from preemptive drafting. To demonstrate real-world applicability, we deploy our method on the Unitree Go2 quadruped robot using Vision-Language Model (VLM) based control, achieving a 21% speedup over traditional cloud-based autoregressive decoding. These results demonstrate the potential of our framework for real-time LLM and VLM applications on resource-constrained edge devices.","authors":["Yeshwanth Venkatesha","Souvik Kundu","Priyadarshini Panda"],"url":"https://arxiv.org/abs/2505.21594"}
{"created":"2025-05-29","title":"Relevance-driven Input Dropout: an Explanation-guided Regularization Technique","abstract":"Overfitting is a well-known issue extending even to state-of-the-art (SOTA) Machine Learning (ML) models, resulting in reduced generalization, and a significant train-test performance gap. Mitigation measures include a combination of dropout, data augmentation, weight decay, and other regularization techniques. Among the various data augmentation strategies, occlusion is a prominent technique that typically focuses on randomly masking regions of the input during training. Most of the existing literature emphasizes randomness in selecting and modifying the input features instead of regions that strongly influence model decisions. We propose Relevance-driven Input Dropout (RelDrop), a novel data augmentation method which selectively occludes the most relevant regions of the input, nudging the model to use other important features in the prediction process, thus improving model generalization through informed regularization. We further conduct qualitative and quantitative analyses to study how Relevance-driven Input Dropout (RelDrop) affects model decision-making. Through a series of experiments on benchmark datasets, we demonstrate that our approach improves robustness towards occlusion, results in models utilizing more features within the region of interest, and boosts inference time generalization performance. Our code is available at https://github.com/Shreyas-Gururaj/LRP_Relevance_Dropout.","authors":["Shreyas Gururaj","Lars Gr\\\"une","Wojciech Samek","Sebastian Lapuschkin","Leander Weber"],"url":"https://arxiv.org/abs/2505.21595"}
{"created":"2025-05-29","title":"Rethinking Data Mixture for Large Language Models: A Comprehensive Survey and New Perspectives","abstract":"Training large language models with data collected from various domains can improve their performance on downstream tasks. However, given a fixed training budget, the sampling proportions of these different domains significantly impact the model's performance. How can we determine the domain weights across different data domains to train the best-performing model within constrained computational resources? In this paper, we provide a comprehensive overview of existing data mixture methods. First, we propose a fine-grained categorization of existing methods, extending beyond the previous offline and online classification. Offline methods are further grouped into heuristic-based, algorithm-based, and function fitting-based methods. For online methods, we categorize them into three groups: online min-max optimization, online mixing law, and other approaches by drawing connections with the optimization frameworks underlying offline methods. Second, we summarize the problem formulations, representative algorithms for each subtype of offline and online methods, and clarify the relationships and distinctions among them. Finally, we discuss the advantages and disadvantages of each method and highlight key challenges in the field of data mixture.","authors":["Yajiao Liu","Congliang Chen","Junchi Yang","Ruoyu Sun"],"url":"https://arxiv.org/abs/2505.21598"}
{"created":"2025-05-29","title":"JITScope: Interactive Visualization of JIT Compiler IR Transformations","abstract":"The complexity of modern Just-In-Time (JIT) compiler optimization poses significant challenges for developers seeking to understand and debug intermediate representation (IR) behavior. This work introduces JITScope, an interactive visualization framework that illustrates how IR nodes and instructions evolve across compilation phases. The system features a full-stack architecture: a Python-based backend transforms raw JSON-formatted IR data-representing an abstract model of the JIT compiler IR-into a normalized SQLite database; a controller layer serves processed CSV data; and a D3.js-powered frontend renders an interactive, phase-aware graph of IR node transformations. The design emphasizes modularity, traceability, and flexibility. Our roadmap explores intuitive visual representations of phase-level changes in IR node connectivity, values, and access patterns. Ultimately, JITScope lays a foundation for future tooling that enables visual exploration of IR evolution, including phase filtering, value tracking, and function-access mapping-offering a new lens into the behaviors and impacts of compiler optimizations.","authors":["Kyra Dalbo","Yumna Ahmed","HeuiChan Lim"],"url":"https://arxiv.org/abs/2505.21599"}
{"created":"2025-05-29","title":"R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing","abstract":"Large Language Models (LLMs) achieve impressive reasoning capabilities at the cost of substantial inference overhead, posing substantial deployment challenges. Although distilled Small Language Models (SLMs) significantly enhance efficiency, their performance suffers as they fail to follow LLMs' reasoning paths. Luckily, we reveal that only a small fraction of tokens genuinely diverge reasoning paths between LLMs and SLMs. Most generated tokens are either identical or exhibit neutral differences, such as minor variations in abbreviations or expressions. Leveraging this insight, we introduce **Roads to Rome (R2R)**, a neural token routing method that selectively utilizes LLMs only for these critical, path-divergent tokens, while leaving the majority of token generation to the SLM. We also develop an automatic data generation pipeline that identifies divergent tokens and generates token-level routing labels to train the lightweight router. We apply R2R to combine R1-1.5B and R1-32B models from the DeepSeek family, and evaluate on challenging math, coding, and QA benchmarks. With an average activated parameter size of 5.6B, R2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even the R1-14B model. Compared to R1-32B, it delivers a 2.8x wall-clock speedup with comparable performance, advancing the Pareto frontier of test-time scaling efficiency. Our code is available at https://github.com/thu-nics/R2R.","authors":["Tianyu Fu","Yi Ge","Yichen You","Enshu Liu","Zhihang Yuan","Guohao Dai","Shengen Yan","Huazhong Yang","Yu Wang"],"url":"https://arxiv.org/abs/2505.21600"}
{"created":"2025-05-29","title":"Leveraging XP and CRISP-DM for Agile Data Science Projects","abstract":"This study explores the integration of eXtreme Programming (XP) and the Cross-Industry Standard Process for Data Mining (CRISP-DM) in agile Data Science projects. We conducted a case study at the e-commerce company Elo7 to answer the research question: How can the agility of the XP method be integrated with CRISP-DM in Data Science projects? Data was collected through interviews and questionnaires with a Data Science team consisting of data scientists, ML engineers, and data product managers. The results show that 86% of the team frequently or always applies CRISP-DM, while 71% adopt XP practices in their projects. Furthermore, the study demonstrates that it is possible to combine CRISP-DM with XP in Data Science projects, providing a structured and collaborative approach. Finally, the study generated improvement recommendations for the company.","authors":["Andre Massahiro Shimaoka","Renato Cordeiro Ferreira","Alfredo Goldman"],"url":"https://arxiv.org/abs/2505.21603"}
{"created":"2025-05-29","title":"Public Discourse Sandbox: Facilitating Human and AI Digital Communication Research","abstract":"Social media serves as a primary communication and information dissemination platform for major global events, entertainment, and niche or topically focused community discussions. Therefore, it represents a valuable resource for researchers who aim to understand numerous questions. However, obtaining data can be difficult, expensive, and often unreliable due to the presence of bots, fake accounts, and manipulated content. Additionally, there are ethical concerns if researchers decide to conduct an online experiment without explicitly notifying social media users about their intent. There is a need for more controlled and scalable mechanisms to evaluate the impacts of digital discussion interventions on audiences. We introduce the Public Discourse Sandbox (PDS), which serves as a digital discourse research platform for human-AI as well as AI-AI discourse research, testing, and training. PDS provides a safe and secure space for research experiments that are not viable on public, commercial social media platforms. Its main purpose is to enable the understanding of AI behaviors and the impacts of customized AI participants via techniques such as prompt engineering, retrieval-augmented generation (RAG), and fine-tuning. We provide a hosted live version of the sandbox to support researchers as well as the open-sourced code on GitHub for community collaboration and contribution.","authors":["Kristina Radivojevic","Caleb Reinking","Shaun Whitfield","Paul Brenner"],"url":"https://arxiv.org/abs/2505.21604"}
{"created":"2025-05-29","title":"SOSBENCH: Benchmarking Safety Alignment on Scientific Knowledge","abstract":"Large language models (LLMs) exhibit advancing capabilities in complex tasks, such as reasoning and graduate-level question answering, yet their resilience against misuse, particularly involving scientifically sophisticated risks, remains underexplored. Existing safety benchmarks typically focus either on instructions requiring minimal knowledge comprehension (e.g., ``tell me how to build a bomb\") or utilize prompts that are relatively low-risk (e.g., multiple-choice or classification tasks about hazardous content). Consequently, they fail to adequately assess model safety when handling knowledge-intensive, hazardous scenarios.","authors":["Fengqing Jiang","Fengbo Ma","Zhangchen Xu","Yuetai Li","Bhaskar Ramasubramanian","Luyao Niu","Bo Li","Xianyan Chen","Zhen Xiang","Radha Poovendran"],"url":"https://arxiv.org/abs/2505.21605"}
{"created":"2025-05-29","title":"How does Misinformation Affect Large Language Model Behaviors and Preferences?","abstract":"Large Language Models (LLMs) have shown remarkable capabilities in knowledge-intensive tasks, while they remain vulnerable when encountering misinformation. Existing studies have explored the role of LLMs in combating misinformation, but there is still a lack of fine-grained analysis on the specific aspects and extent to which LLMs are influenced by misinformation. To bridge this gap, we present MisBench, the current largest and most comprehensive benchmark for evaluating LLMs' behavior and knowledge preference toward misinformation. MisBench consists of 10,346,712 pieces of misinformation, which uniquely considers both knowledge-based conflicts and stylistic variations in misinformation. Empirical results reveal that while LLMs demonstrate comparable abilities in discerning misinformation, they still remain susceptible to knowledge conflicts and stylistic variations. Based on these findings, we further propose a novel approach called Reconstruct to Discriminate (RtD) to strengthen LLMs' ability to detect misinformation. Our study provides valuable insights into LLMs' interactions with misinformation, and we believe MisBench can serve as an effective benchmark for evaluating LLM-based detectors and enhancing their reliability in real-world applications. Codes and data are available at https://github.com/GKNL/MisBench.","authors":["Miao Peng","Nuo Chen","Jianheng Tang","Jia Li"],"url":"https://arxiv.org/abs/2505.21608"}
{"created":"2025-05-29","title":"Preventing Adversarial AI Attacks Against Autonomous Situational Awareness: A Maritime Case Study","abstract":"Adversarial artificial intelligence (AI) attacks pose a significant threat to autonomous transportation, such as maritime vessels, that rely on AI components. Malicious actors can exploit these systems to deceive and manipulate AI-driven operations. This paper addresses three critical research challenges associated with adversarial AI: the limited scope of traditional defences, inadequate security metrics, and the need to build resilience beyond model-level defences. To address these challenges, we propose building defences utilising multiple inputs and data fusion to create defensive components and an AI security metric as a novel approach toward developing more secure AI systems. We name this approach the Data Fusion Cyber Resilience (DFCR) method, and we evaluate it through real-world demonstrations and comprehensive quantitative analyses, comparing a system built with the DFCR method against single-input models and models utilising existing state-of-the-art defences. The findings show that the DFCR approach significantly enhances resilience against adversarial machine learning attacks in maritime autonomous system operations, achieving up to a 35\\% reduction in loss for successful multi-pronged perturbation attacks, up to a 100\\% reduction in loss for successful adversarial patch attacks and up to 100\\% reduction in loss for successful spoofing attacks when using these more resilient systems. We demonstrate how DFCR and DFCR confidence scores can reduce adversarial AI contact confidence and improve decision-making by the system, even when typical adversarial defences have been compromised. Ultimately, this work contributes to the development of more secure and resilient AI-driven systems against adversarial attacks.","authors":["Mathew J. Walter","Aaron Barrett","Kimberly Tam"],"url":"https://arxiv.org/abs/2505.21609"}
{"created":"2025-05-29","title":"VideoMarkBench: Benchmarking Robustness of Video Watermarking","abstract":"The rapid development of video generative models has led to a surge in highly realistic synthetic videos, raising ethical concerns related to disinformation and copyright infringement. Recently, video watermarking has been proposed as a mitigation strategy by embedding invisible marks into AI-generated videos to enable subsequent detection. However, the robustness of existing video watermarking methods against both common and adversarial perturbations remains underexplored. In this work, we introduce VideoMarkBench, the first systematic benchmark designed to evaluate the robustness of video watermarks under watermark removal and watermark forgery attacks. Our study encompasses a unified dataset generated by three state-of-the-art video generative models, across three video styles, incorporating four watermarking methods and seven aggregation strategies used during detection. We comprehensively evaluate 12 types of perturbations under white-box, black-box, and no-box threat models. Our findings reveal significant vulnerabilities in current watermarking approaches and highlight the urgent need for more robust solutions. Our code is available at https://github.com/zhengyuan-jiang/VideoMarkBench.","authors":["Zhengyuan Jiang","Moyang Guo","Kecen Li","Yuepeng Hu","Yupu Wang","Zhicong Huang","Cheng Hong","Neil Zhenqiang Gong"],"url":"https://arxiv.org/abs/2505.21620"}
{"created":"2025-05-29","title":"Learning Where to Learn: Training Distribution Selection for Provable OOD Performance","abstract":"Out-of-distribution (OOD) generalization remains a fundamental challenge in machine learning. Models trained on one data distribution often experience substantial performance degradation when evaluated on shifted or unseen domains. To address this challenge, the present paper studies the design of training data distributions that maximize average-case OOD performance. First, a theoretical analysis establishes a family of generalization bounds that quantify how the choice of training distribution influences OOD error across a predefined family of target distributions. These insights motivate the introduction of two complementary algorithmic strategies: (i) directly formulating OOD risk minimization as a bilevel optimization problem over the space of probability measures and (ii) minimizing a theoretical upper bound on OOD error. Last, the paper evaluates the two approaches across a range of function approximation and operator learning examples. The proposed methods significantly improve OOD accuracy over standard empirical risk minimization with a fixed distribution. These results highlight the potential of distribution-aware training as a principled and practical framework for robust OOD generalization.","authors":["Nicolas Guerra","Nicholas H. Nelsen","Yunan Yang"],"url":"https://arxiv.org/abs/2505.21626"}
{"created":"2025-05-29","title":"Is Your LLM Overcharging You? Tokenization, Transparency, and Incentives","abstract":"State-of-the-art large language models require specialized hardware and substantial energy to operate. As a consequence, cloud-based services that provide access to large language models have become very popular. In these services, the price users pay for an output provided by a model depends on the number of tokens the model uses to generate it -- they pay a fixed price per token. In this work, we show that this pricing mechanism creates a financial incentive for providers to strategize and misreport the (number of) tokens a model used to generate an output, and users cannot prove, or even know, whether a provider is overcharging them. However, we also show that, if an unfaithful provider is obliged to be transparent about the generative process used by the model, misreporting optimally without raising suspicion is hard. Nevertheless, as a proof-of-concept, we introduce an efficient heuristic algorithm that allows providers to significantly overcharge users without raising suspicion, highlighting the vulnerability of users under the current pay-per-token pricing mechanism. Further, to completely eliminate the financial incentive to strategize, we introduce a simple incentive-compatible token pricing mechanism. Under this mechanism, the price users pay for an output provided by a model depends on the number of characters of the output -- they pay a fixed price per character. Along the way, to illustrate and complement our theoretical results, we conduct experiments with several large language models from the $\\texttt{Llama}$, $\\texttt{Gemma}$ and $\\texttt{Ministral}$ families, and input prompts from the LMSYS Chatbot Arena platform.","authors":["Ander Artola Velasco","Stratis Tsirtsis","Nastaran Okati","Manuel Gomez-Rodriguez"],"url":"https://arxiv.org/abs/2505.21627"}
{"created":"2025-05-29","title":"Object Concepts Emerge from Motion","abstract":"Object concepts play a foundational role in human visual cognition, enabling perception, memory, and interaction in the physical world. Inspired by findings in developmental neuroscience - where infants are shown to acquire object understanding through observation of motion - we propose a biologically inspired framework for learning object-centric visual representations in an unsupervised manner. Our key insight is that motion boundary serves as a strong signal for object-level grouping, which can be used to derive pseudo instance supervision from raw videos. Concretely, we generate motion-based instance masks using off-the-shelf optical flow and clustering algorithms, and use them to train visual encoders via contrastive learning. Our framework is fully label-free and does not rely on camera calibration, making it scalable to large-scale unstructured video data. We evaluate our approach on three downstream tasks spanning both low-level (monocular depth estimation) and high-level (3D object detection and occupancy prediction) vision. Our models outperform previous supervised and self-supervised baselines and demonstrate strong generalization to unseen scenes. These results suggest that motion-induced object representations offer a compelling alternative to existing vision foundation models, capturing a crucial but overlooked level of abstraction: the visual instance. The corresponding code will be released upon paper acceptance.","authors":["Haoqian Liang","Xiaohui Wang","Zhichao Li","Ya Yang","Naiyan Wang"],"url":"https://arxiv.org/abs/2505.21635"}
{"created":"2025-05-29","title":"The Feasibility of Topic-Based Watermarking on Academic Peer Reviews","abstract":"Large language models (LLMs) are increasingly integrated into academic workflows, with many conferences and journals permitting their use for tasks such as language refinement and literature summarization. However, their use in peer review remains prohibited due to concerns around confidentiality breaches, hallucinated content, and inconsistent evaluations. As LLM-generated text becomes more indistinguishable from human writing, there is a growing need for reliable attribution mechanisms to preserve the integrity of the review process. In this work, we evaluate topic-based watermarking (TBW), a lightweight, semantic-aware technique designed to embed detectable signals into LLM-generated text. We conduct a comprehensive assessment across multiple LLM configurations, including base, few-shot, and fine-tuned variants, using authentic peer review data from academic conferences. Our results show that TBW maintains review quality relative to non-watermarked outputs, while demonstrating strong robustness to paraphrasing-based evasion. These findings highlight the viability of TBW as a minimally intrusive and practical solution for enforcing LLM usage in peer review.","authors":["Alexander Nemecek","Yuzhou Jiang","Erman Ayday"],"url":"https://arxiv.org/abs/2505.21636"}
{"created":"2025-05-29","title":"BaryIR: Learning Multi-Source Unified Representation in Continuous Barycenter Space for Generalizable All-in-One Image Restoration","abstract":"Despite remarkable advances made in all-in-one image restoration (AIR) for handling different types of degradations simultaneously, existing methods remain vulnerable to out-of-distribution degradations and images, limiting their real-world applicability. In this paper, we propose a multi-source representation learning framework BaryIR, which decomposes the latent space of multi-source degraded images into a continuous barycenter space for unified feature encoding and source-specific subspaces for specific semantic encoding. Specifically, we seek the multi-source unified representation by introducing a multi-source latent optimal transport barycenter problem, in which a continuous barycenter map is learned to transport the latent representations to the barycenter space. The transport cost is designed such that the representations from source-specific subspaces are contrasted with each other while maintaining orthogonality to those from the barycenter space. This enables BaryIR to learn compact representations with unified degradation-agnostic information from the barycenter space, as well as degradation-specific semantics from source-specific subspaces, capturing the inherent geometry of multi-source data manifold for generalizable AIR. Extensive experiments demonstrate that BaryIR achieves competitive performance compared to state-of-the-art all-in-one methods. Particularly, BaryIR exhibits superior generalization ability to real-world data and unseen degradations. The code will be publicly available at https://github.com/xl-tang3/BaryIR.","authors":["Xiaole Tang","Xiaoyi He","Xiang Gu","Jian Sun"],"url":"https://arxiv.org/abs/2505.21637"}
{"created":"2025-05-29","title":"Apprenticeship learning with prior beliefs using inverse optimization","abstract":"The relationship between inverse reinforcement learning (IRL) and inverse optimization (IO) for Markov decision processes (MDPs) has been relatively underexplored in the literature, despite addressing the same problem. In this work, we revisit the relationship between the IO framework for MDPs, IRL, and apprenticeship learning (AL). We incorporate prior beliefs on the structure of the cost function into the IRL and AL problems, and demonstrate that the convex-analytic view of the AL formalism (Kamoutsi et al., 2021) emerges as a relaxation of our framework. Notably, the AL formalism is a special case in our framework when the regularization term is absent. Focusing on the suboptimal expert setting, we formulate the AL problem as a regularized min-max problem. The regularizer plays a key role in addressing the ill-posedness of IRL by guiding the search for plausible cost functions. To solve the resulting regularized-convex-concave-min-max problem, we use stochastic mirror descent (SMD) and establish convergence bounds for the proposed method. Numerical experiments highlight the critical role of regularization in learning cost vectors and apprentice policies.","authors":["Mauricio Junca","Esteban Leiva"],"url":"https://arxiv.org/abs/2505.21639"}
{"created":"2025-05-29","title":"Efficient Diffusion Models for Symmetric Manifolds","abstract":"We introduce a framework for designing efficient diffusion models for $d$-dimensional symmetric-space Riemannian manifolds, including the torus, sphere, special orthogonal group and unitary group. Existing manifold diffusion models often depend on heat kernels, which lack closed-form expressions and require either $d$ gradient evaluations or exponential-in-$d$ arithmetic operations per training step. We introduce a new diffusion model for symmetric manifolds with a spatially-varying covariance, allowing us to leverage a projection of Euclidean Brownian motion to bypass heat kernel computations. Our training algorithm minimizes a novel efficient objective derived via Ito's Lemma, allowing each step to run in $O(1)$ gradient evaluations and nearly-linear-in-$d$ ($O(d^{1.19})$) arithmetic operations, reducing the gap between diffusions on symmetric manifolds and Euclidean space. Manifold symmetries ensure the diffusion satisfies an \"average-case\" Lipschitz condition, enabling accurate and efficient sample generation. Empirically, our model outperforms prior methods in training speed and improves sample quality on synthetic datasets on the torus, special orthogonal group, and unitary group.","authors":["Oren Mangoubi","Neil He","Nisheeth K. Vishnoi"],"url":"https://arxiv.org/abs/2505.21640"}
{"created":"2025-05-29","title":"PrivATE: Differentially Private Confidence Intervals for Average Treatment Effects","abstract":"The average treatment effect (ATE) is widely used to evaluate the effectiveness of drugs and other medical interventions. In safety-critical applications like medicine, reliable inferences about the ATE typically require valid uncertainty quantification, such as through confidence intervals (CIs). However, estimating treatment effects in these settings often involves sensitive data that must be kept private. In this work, we present PrivATE, a novel machine learning framework for computing CIs for the ATE under differential privacy. Specifically, we focus on deriving valid privacy-preserving CIs for the ATE from observational data. Our PrivATE framework consists of three steps: (i) estimating a differentially private ATE through output perturbation; (ii) estimating the differentially private variance through a truncated output perturbation mechanism; and (iii) constructing the CIs while accounting for the uncertainty from both the estimation and privatization steps. Our PrivATE framework is model agnostic, doubly robust, and ensures valid CIs. We demonstrate the effectiveness of our framework using synthetic and real-world medical datasets. To the best of our knowledge, we are the first to derive a general, doubly robust framework for valid CIs of the ATE under ($\\varepsilon$, $\\delta$)-differential privacy.","authors":["Maresa Schr\\\"oder","Justin Hartenstein","Stefan Feuerriegel"],"url":"https://arxiv.org/abs/2505.21641"}
{"created":"2025-05-29","title":"Reproducible Builds and Insights from an Independent Verifier for Arch Linux","abstract":"Supply chain attacks have emerged as a prominent cybersecurity threat in recent years. Reproducible and bootstrappable builds have the potential to reduce such attacks significantly. In combination with independent, exhaustive and periodic source code audits, these measures can effectively eradicate compromises in the building process. In this paper we introduce both concepts, we analyze the achievements over the last ten years and explain the remaining challenges. We contribute to the reproducible builds effort by setting up a rebuilder and verifier instance to test the reproducibility of Arch Linux packages. Using the results from this instance, we uncover an unnoticed and security-relevant packaging issue affecting 16 packages related to Certbot, the recommended software to install TLS certificates from Let's Encrypt, making them unreproducible. Additionally, we find the root cause of unreproduciblity in the source code of fwupd, a critical software used to update device firmware on Linux devices, and submit an upstream patch to fix it.","authors":["Joshua Drexel","Esther H\\\"anggi","Iy\\'an M\\'endez Veiga"],"url":"https://arxiv.org/abs/2505.21642"}
{"created":"2025-05-29","title":"Geometric Feature Prompting of Image Segmentation Models","abstract":"Advances in machine learning, especially the introduction of transformer architectures and vision transformers, have led to the development of highly capable computer vision foundation models. The segment anything model (known colloquially as SAM and more recently SAM 2), is a highly capable foundation model for segmentation of natural images and has been further applied to medical and scientific image segmentation tasks. SAM relies on prompts -- points or regions of interest in an image -- to generate associated segmentations.","authors":["Kenneth Ball","Erin Taylor","Nirav Patel","Andrew Bartels","Gary Koplik","James Polly","Jay Hineman"],"url":"https://arxiv.org/abs/2505.21644"}
{"created":"2025-05-29","title":"Iterative Corpus Refinement for Materials Property Prediction Based on Scientific Texts","abstract":"The discovery and optimization of materials for specific applications is hampered by the practically infinite number of possible elemental combinations and associated properties, also known as the `combinatorial explosion'. By nature of the problem, data are scarce and all possible data sources should be used. In addition to simulations and experimental results, the latent knowledge in scientific texts is not yet used to its full potential. We present an iterative framework that refines a given scientific corpus by strategic selection of the most diverse documents, training Word2Vec models, and monitoring the convergence of composition-property correlations in embedding space. Our approach is applied to predict high-performing materials for oxygen reduction (ORR), hydrogen evolution (HER), and oxygen evolution (OER) reactions for a large number of possible candidate compositions. Our method successfully predicts the highest performing compositions among a large pool of candidates, validated by experimental measurements of the electrocatalytic performance in the lab. This work demonstrates and validates the potential of iterative corpus refinement to accelerate materials discovery and optimization, offering a scalable and efficient tool for screening large compositional spaces where reliable data are scarce or non-existent.","authors":["Lei Zhang","Markus Stricker"],"url":"https://arxiv.org/abs/2505.21646"}
{"created":"2025-05-29","title":"QuARI: Query Adaptive Retrieval Improvement","abstract":"Massive-scale pretraining has made vision-language models increasingly popular for image-to-image and text-to-image retrieval across a broad collection of domains. However, these models do not perform well when used for challenging retrieval tasks, such as instance retrieval in very large-scale image collections. Recent work has shown that linear transformations of VLM features trained for instance retrieval can improve performance by emphasizing subspaces that relate to the domain of interest. In this paper, we explore a more extreme version of this specialization by learning to map a given query to a query-specific feature space transformation. Because this transformation is linear, it can be applied with minimal computational cost to millions of image embeddings, making it effective for large-scale retrieval or re-ranking. Results show that this method consistently outperforms state-of-the-art alternatives, including those that require many orders of magnitude more computation at query time.","authors":["Eric Xing","Abby Stylianou","Robert Pless","Nathan Jacobs"],"url":"https://arxiv.org/abs/2505.21647"}
{"created":"2025-05-29","title":"Design and Analysis of a Grid-connected DC Fast Charging Station for Dhaka-Chittagong Highway","abstract":"The growing adoption of electric vehicles (EVs) necessitates the development of efficient and reliable charging infrastructure, particularly fast charging stations (FCS) for addressing challenges such as range anxiety and long charging times. This paper presents the design and feasibility analysis of a grid-connected DC fast charging station for the Dhaka-Chittagong highway, a critical transportation corridor in Bangladesh. The proposed system incorporates advanced components, including a step-down transformer, Vienna Rectifier, and LC filter, to convert high-voltage AC power from the grid into a stable DC output. Simulated using MATLAB Simulink, the model delivers a peak output of 400V DC and 120 kW power, enabling rapid and efficient EV charging. The study also evaluates the system's performance, analyzing charging times, energy consumption, and distance ranges for representative EVs. By addressing key technical, environmental, and economic considerations, this paper provides a comprehensive roadmap for deploying fast charging infrastructure, fostering EV adoption, and advancing sustainable transportation in Bangladesh.","authors":["Alif Ahmed","Minhajur Rahman","Mohammad Jawad Chowdhury","Khandakar Abdulla Al Mamun"],"url":"https://arxiv.org/abs/2505.21648"}
{"created":"2025-05-29","title":"Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks","abstract":"Object orientation understanding represents a fundamental challenge in visual perception critical for applications like robotic manipulation and augmented reality. Current vision-language benchmarks fail to isolate this capability, often conflating it with positional relationships and general scene understanding. We introduce DORI (Discriminative Orientation Reasoning Intelligence), a comprehensive benchmark establishing object orientation perception as a primary evaluation target. DORI assesses four dimensions of orientation comprehension: frontal alignment, rotational transformations, relative directional relationships, and canonical orientation understanding. Through carefully curated tasks from 11 datasets spanning 67 object categories across synthetic and real-world scenarios, DORI provides insights on how multi-modal systems understand object orientations. Our evaluation of 15 state-of-the-art vision-language models reveals critical limitations: even the best models achieve only 54.2% accuracy on coarse tasks and 33.0% on granular orientation judgments, with performance deteriorating for tasks requiring reference frame shifts or compound rotations. These findings demonstrate the need for dedicated orientation representation mechanisms, as models show systematic inability to perform precise angular estimations, track orientation changes across viewpoints, and understand compound rotations - suggesting limitations in their internal 3D spatial representations. As the first diagnostic framework specifically designed for orientation awareness in multimodal systems, DORI offers implications for improving robotic control, 3D scene reconstruction, and human-AI interaction in physical environments. DORI data: https://huggingface.co/datasets/appledora/DORI-Benchmark","authors":["Keanu Nichols","Nazia Tasnim","Yan Yuting","Nicholas Ikechukwu","Elva Zou","Deepti Ghadiyaram","Bryan Plummer"],"url":"https://arxiv.org/abs/2505.21649"}
{"created":"2025-05-29","title":"AutoSGD: Automatic Learning Rate Selection for Stochastic Gradient Descent","abstract":"The learning rate is an important tuning parameter for stochastic gradient descent (SGD) and can greatly influence its performance. However, appropriate selection of a learning rate schedule across all iterations typically requires a non-trivial amount of user tuning effort. To address this, we introduce AutoSGD: an SGD method that automatically determines whether to increase or decrease the learning rate at a given iteration and then takes appropriate action. We introduce theory supporting the convergence of AutoSGD, along with its deterministic counterpart for standard gradient descent. Empirical results suggest strong performance of the method on a variety of traditional optimization problems and machine learning tasks.","authors":["Nikola Surjanovic","Alexandre Bouchard-C\\^ot\\'e","Trevor Campbell"],"url":"https://arxiv.org/abs/2505.21651"}
{"created":"2025-05-29","title":"PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation","abstract":"Fine-grained robot manipulation, such as lifting and rotating a bottle to display the label on the cap, requires robust reasoning about object parts and their relationships with intended tasks. Despite recent advances in training general-purpose robot manipulation policies guided by language instructions, there is a notable lack of large-scale datasets for fine-grained manipulation tasks with part-level instructions and diverse 3D object instances annotated with part-level labels. In this work, we introduce PartInstruct, the first large-scale benchmark for training and evaluating fine-grained robot manipulation models using part-level instructions. PartInstruct comprises 513 object instances across 14 categories, each annotated with part-level information, and 1302 fine-grained manipulation tasks organized into 16 task classes. Our training set consists of over 10,000 expert demonstrations synthesized in a 3D simulator, where each demonstration is paired with a high-level task instruction, a chain of base part-based skill instructions, and ground-truth 3D information about the object and its parts. Additionally, we designed a comprehensive test suite to evaluate the generalizability of learned policies across new states, objects, and tasks. We evaluated several state-of-the-art robot manipulation approaches, including end-to-end vision-language policy learning and bi-level planning models for robot manipulation on our benchmark. The experimental results reveal that current models struggle to robustly ground part concepts and predict actions in 3D space, and face challenges when manipulating object parts in long-horizon tasks.","authors":["Yifan Yin","Zhengtao Han","Shivam Aarya","Jianxin Wang","Shuhang Xu","Jiawei Peng","Angtian Wang","Alan Yuille","Tianmin Shu"],"url":"https://arxiv.org/abs/2505.21652"}
{"created":"2025-05-29","title":"Think Before You Diffuse: LLMs-Guided Physics-Aware Video Generation","abstract":"Recent video diffusion models have demonstrated their great capability in generating visually-pleasing results, while synthesizing the correct physical effects in generated videos remains challenging. The complexity of real-world motions, interactions, and dynamics introduce great difficulties when learning physics from data. In this work, we propose DiffPhy, a generic framework that enables physically-correct and photo-realistic video generation by fine-tuning a pre-trained video diffusion model. Our method leverages large language models (LLMs) to explicitly reason a comprehensive physical context from the text prompt and use it to guide the generation. To incorporate physical context into the diffusion model, we leverage a Multimodal large language model (MLLM) as a supervisory signal and introduce a set of novel training objectives that jointly enforce physical correctness and semantic consistency with the input text. We also establish a high-quality physical video dataset containing diverse phyiscal actions and events to facilitate effective finetuning. Extensive experiments on public benchmarks demonstrate that DiffPhy is able to produce state-of-the-art results across diverse physics-related scenarios. Our project page is available at https://bwgzk-keke.github.io/DiffPhy/","authors":["Ke Zhang","Cihan Xiao","Yiqun Mei","Jiacong Xu","Vishal M. Patel"],"url":"https://arxiv.org/abs/2505.21653"}
{"created":"2025-05-29","title":"Explainability of Large Language Models using SMILE: Statistical Model-agnostic Interpretability with Local Explanations","abstract":"Large language models like GPT, LLAMA, and Claude have become incredibly powerful at generating text, but they are still black boxes, so it is hard to understand how they decide what to say. That lack of transparency can be problematic, especially in fields where trust and accountability matter. To help with this, we introduce SMILE, a new method that explains how these models respond to different parts of a prompt. SMILE is model-agnostic and works by slightly changing the input, measuring how the output changes, and then highlighting which words had the most impact. Create simple visual heat maps showing which parts of a prompt matter the most. We tested SMILE on several leading LLMs and used metrics such as accuracy, consistency, stability, and fidelity to show that it gives clear and reliable explanations. By making these models easier to understand, SMILE brings us one step closer to making AI more transparent and trustworthy.","authors":["Zeinab Dehghani","Koorosh Aslansefat","Adil Khan","Mohammed Naveed Akram"],"url":"https://arxiv.org/abs/2505.21657"}
{"created":"2025-05-29","title":"PreGenie: An Agentic Framework for High-quality Visual Presentation Generation","abstract":"Visual presentations are vital for effective communication. Early attempts to automate their creation using deep learning often faced issues such as poorly organized layouts, inaccurate text summarization, and a lack of image understanding, leading to mismatched visuals and text. These limitations restrict their application in formal contexts like business and scientific research. To address these challenges, we propose PreGenie, an agentic and modular framework powered by multimodal large language models (MLLMs) for generating high-quality visual presentations.","authors":["Xiaojie Xu","Xinli Xu","Sirui Chen","Haoyu Chen","Fan Zhang","Ying-Cong Chen"],"url":"https://arxiv.org/abs/2505.21660"}
{"created":"2025-05-29","title":"KPerfIR: Towards an Open and Compiler-centric Ecosystem for GPU Kernel Performance Tooling on Modern AI Workloads","abstract":"In this work, we propose KPerfIR, a novel multilevel compiler-centric infrastructure to enable the development of customizable, extendable, and portable profiling tools tailored for modern artificial intelligence (AI) workloads on modern GPUs. Our approach integrates profiling capabilities directly into the compiler workflow, allowing profiling functionalities to be implemented as compiler passes, offering a programmable and reusable framework for performance analysis. This design bridges the gap between compilers and profilers, enabling fine-grained insights into complex optimization challenges such as overlapping the execution of fine-grained function units on GPUs. KPerfIR is integrated into the Triton infrastructure to highlight the power of a compiler-centric approach to advance performance analysis and optimization in the ever-evolving landscape of AI compilers. Our evaluation shows that our tool incurs low overhead (8.2%), provides accurate measurements (2% relative error), and delivers actionable insights into complicated GPU intra-kernel optimizations.","authors":["Yue Guan","Yuanwei Fang","Keren Zhou","Corbin Robeck","Manman Ren","Zhongkai Yu","Yufei Ding","Adnan Aziz"],"url":"https://arxiv.org/abs/2505.21661"}
{"created":"2025-05-29","title":"Expert Survey: AI Reliability & Security Research Priorities","abstract":"Our survey of 53 specialists across 105 AI reliability and security research areas identifies the most promising research prospects to guide strategic AI R&amp;D investment. As companies are seeking to develop AI systems with broadly human-level capabilities, research on reliability and security is urgently needed to ensure AI's benefits can be safely and broadly realized and prevent severe harms. This study is the first to quantify expert priorities across a comprehensive taxonomy of AI safety and security research directions and to produce a data-driven ranking of their potential impact. These rankings may support evidence-based decisions about how to effectively deploy resources toward AI reliability and security research.","authors":["Joe O'Brien","Jeremy Dolan","Jay Kim","Jonah Dykhuizen","Jeba Sania","Sebastian Becker","Jam Kraprayoon","Cara Labrador"],"url":"https://arxiv.org/abs/2505.21664"}
{"created":"2025-05-29","title":"Convergent Functions, Divergent Forms","abstract":"We introduce LOKI, a compute-efficient framework for co-designing morphologies and control policies that generalize across unseen tasks. Inspired by biological adaptation -- where animals quickly adjust to morphological changes -- our method overcomes the inefficiencies of traditional evolutionary and quality-diversity algorithms. We propose learning convergent functions: shared control policies trained across clusters of morphologically similar designs in a learned latent space, drastically reducing the training cost per design. Simultaneously, we promote divergent forms by replacing mutation with dynamic local search, enabling broader exploration and preventing premature convergence. The policy reuse allows us to explore 780$\\times$ more designs using 78% fewer simulation steps and 40% less compute per design. Local competition paired with a broader search results in a diverse set of high-performing final morphologies. Using the UNIMAL design space and a flat-terrain locomotion task, LOKI discovers a rich variety of designs -- ranging from quadrupeds to crabs, bipedals, and spinners -- far more diverse than those produced by prior work. These morphologies also transfer better to unseen downstream tasks in agility, stability, and manipulation domains (e.g., 2$\\times$ higher reward on bump and push box incline tasks). Overall, our approach produces designs that are both diverse and adaptable, with substantially greater sample efficiency than existing co-design methods. (Project website: https://loki-codesign.github.io/)","authors":["Hyeonseong Jeon","Ainaz Eftekhar","Aaron Walsman","Kuo-Hao Zeng","Ali Farhadi","Ranjay Krishna"],"url":"https://arxiv.org/abs/2505.21665"}
{"created":"2025-05-29","title":"Efficient Controllable Diffusion via Optimal Classifier Guidance","abstract":"The controllable generation of diffusion models aims to steer the model to generate samples that optimize some given objective functions. It is desirable for a variety of applications including image generation, molecule generation, and DNA/sequence generation. Reinforcement Learning (RL) based fine-tuning of the base model is a popular approach but it can overfit the reward function while requiring significant resources. We frame controllable generation as a problem of finding a distribution that optimizes a KL-regularized objective function. We present SLCD -- Supervised Learning based Controllable Diffusion, which iteratively generates online data and trains a small classifier to guide the generation of the diffusion model. Similar to the standard classifier-guided diffusion, SLCD's key computation primitive is classification and does not involve any complex concepts from RL or control. Via a reduction to no-regret online learning analysis, we show that under KL divergence, the output from SLCD provably converges to the optimal solution of the KL-regularized objective. Further, we empirically demonstrate that SLCD can generate high quality samples with nearly the same inference time as the base model in both image generation with continuous diffusion and biological sequence generation with discrete diffusion. Our code is available at https://github.com/Owen-Oertell/slcd","authors":["Owen Oertell","Shikun Sun","Yiding Chen","Jin Peng Zhou","Zhiyong Wang","Wen Sun"],"url":"https://arxiv.org/abs/2505.21666"}
{"created":"2025-05-29","title":"R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning","abstract":"Despite advances in reasoning and planning of R1-like models, Large Language Models (LLMs) still struggle with tasks requiring precise computation, symbolic manipulation, optimization, and algorithmic reasoning, in which textual reasoning lacks the rigor of code execution. A key challenge is enabling LLMs to decide when to use textual reasoning versus code generation. While OpenAI trains models to invoke a Code Interpreter as needed, public research lacks guidance on aligning pre-trained LLMs to effectively leverage code and generalize across diverse tasks. We present R1-Code-Interpreter, an extension of a text-only LLM trained via multi-turn supervised fine-tuning (SFT) and reinforcement learning (RL) to autonomously generate multiple code queries during step-by-step reasoning. We curate 144 reasoning and planning tasks (107 for training, 37 for testing), each with over 200 diverse questions. We fine-tune Qwen-2.5 models (3B/7B/14B) using various SFT and RL strategies, investigating different answer formats, reasoning vs. non-reasoning models, cold vs. warm starts, GRPO vs. PPO, and masked vs. unmasked code outputs. Unlike prior RL work on narrow domains, we find that Code Interpreter training is significantly harder due to high task diversity and expensive code execution, highlighting the critical role of the SFT stage. Our final model, R1-CI-14B, improves average accuracy on the 37 test tasks from 44.0\\% to 64.1\\%, outperforming GPT-4o (text-only: 58.6\\%) and approaching GPT-4o with Code Interpreter (70.9\\%), with the emergent self-checking behavior via code generation. Datasets, Codes, and Models are available at https://github.com/yongchao98/R1-Code-Interpreter and https://huggingface.co/yongchao98.","authors":["Yongchao Chen","Yueying Liu","Junwei Zhou","Yilun Hao","Jingquan Wang","Yang Zhang","Chuchu Fan"],"url":"https://arxiv.org/abs/2505.21668"}
{"created":"2025-05-29","title":"Improved Prefetching Techniques for Linked Data Structures","abstract":"With ever-increasing main memory stall times, we need novel techniques to reduce effective memory access latencies. Prefetching has been shown to be an effective solution, especially with contiguous data structures that follow the traditional principles of spatial and temporal locality. However, on linked data structures$-$made up of many nodes linked together with pointers$-$typical prefetchers struggle, failing to predict accesses as elements are arbitrarily scattered throughout memory and access patters are arbitrarily complex and hence difficult to predict. To remedy these issues, we introduce $\\textit{Linkey}$, a novel prefetcher that utilizes hints from the programmer/compiler to cache layout information and accurately prefetch linked data structures. $\\textit{Linkey}$ obtains substantial performance improvements over a striding baseline. We achieve a geomean 13% reduction in miss rate with a maximum improvement of 58.8%, and a 65.4% geomean increase in accuracy, with many benchmarks improving from 0%. On benchmarks where $\\textit{Linkey}$ is applicable, we observe a geomean IPC improvement of 1.40%, up to 12.1%.","authors":["Nikola Vuk Maruszewski"],"url":"https://arxiv.org/abs/2505.21669"}
{"created":"2025-05-29","title":"Rethinking the Outlier Distribution in Large Language Models: An In-depth Study","abstract":"Investigating outliers in large language models (LLMs) is crucial due to their significant impact on various aspects of LLM performance, including quantization and compression. Outliers often cause considerable quantization errors, leading to degraded model performance. Identifying and addressing these outliers can enhance the accuracy and efficiency of the quantization process, enabling smoother deployment on edge devices or specialized hardware. Recent studies have identified two common types of outliers in LLMs: massive activations and channel-wise outliers. While numerous quantization algorithms have been proposed to mitigate their effects and maintain satisfactory accuracy, few have thoroughly explored the root causes of these outliers in depth. In this paper, we conduct a comprehensive investigation into the formation mechanisms of these outliers and propose potential strategies to mitigate their occurrence. Ultimately, we introduce some efficient approaches to eliminate most massive activations and channel-wise outliers with minimal impact on accuracy.","authors":["Rahul Raman","Khushi Sharma","Sai Qian Zhang"],"url":"https://arxiv.org/abs/2505.21670"}
{"created":"2025-05-29","title":"Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing","abstract":"We study a sequential decision-making problem on a $n$-node graph $G$ where each node has an unknown label from a finite set $\\mathbf{\\Sigma}$, drawn from a joint distribution $P$ that is Markov with respect to $G$. At each step, selecting a node reveals its label and yields a label-dependent reward. The goal is to adaptively choose nodes to maximize expected accumulated discounted rewards. We impose a frontier exploration constraint, where actions are limited to neighbors of previously selected nodes, reflecting practical constraints in settings such as contact tracing and robotic exploration. We design a Gittins index-based policy that applies to general graphs and is provably optimal when $G$ is a forest. Our implementation runs in $O(n^2 \\cdot |\\mathbf{\\Sigma}|^2)$ time while using $O(n \\cdot |\\mathbf{\\Sigma}|^2)$ oracle calls to $P$ and $O(n^2 \\cdot |\\mathbf{\\Sigma}|)$ space. Experiments on synthetic and real-world graphs show that our method consistently outperforms natural baselines, including in non-tree, budget-limited, and undiscounted settings. For example, in HIV testing simulations on real-world sexual interaction networks, our policy detects nearly all positive cases with only half the population tested, substantially outperforming other baselines.","authors":["Davin Choo","Yuqi Pan","Tonghan Wang","Milind Tambe","Alastair van Heerden","Cheryl Johnson"],"url":"https://arxiv.org/abs/2505.21671"}
{"created":"2025-05-29","title":"On Reconfigurable Bisimulation, with an Application to the Distributed Synthesis Problem","abstract":"We consider the problem of distributing a centralised transition system to a set of asynchronous agents recognising the same language. Existing solutions are either manual or involve a huge explosion in the number of states from the centralised system. The difficulty arises from the need to keep a rigid communication scheme, specifying a fixed mapping from events to those who can participate in them. Thus, individual agents need to memorise seen events and their order to dynamically compare their knowledge with others when communicating. To bypass this, we rely on reconfigurable communication: agents decide locally ``by-need'' when to participate or discard specific events during execution while not impacting the progress of the joint computation. Our distribution relies on a novel notion of Parametric Reconfigurable Bisimulation, that identifies the only required participations. We show how to compute this bisimulation and that such minimisation produces a joint system that is bisimilar to the original centralised one. We use a case study to show its effectiveness by producing agents that are much smaller than the centralised system and jointly perform the same computations. As a notable application, we use this distribution in order to allow for distributed synthesis from global specifications. In this case, rigid communication leads to undecidability, which is bypassed by our ability to dynamically prune communications.","authors":["Yehia Abd Alrahman","Nir Piterman"],"url":"https://arxiv.org/abs/2505.21672"}
{"created":"2025-05-29","title":"Supervised Link Prediction in Co-Authorship Networks Based on Author Node-Based Features","abstract":"Predicting the emergence of future research collaborations between authors in academic social networks (SNs) is a very effective example that demonstrates the link prediction problem. This problem refers to predicting the potential existence or absence of a link between a pair of nodes (authors) on the co-authorship network. Various similarity and aggregation metrics were proposed in the literature for predicting the potential link between two authors on such networks. However, the relevant research did not investigate the impact of similarity of research interests of two authors or the similarity of their affiliations on the performance of predicting the potential link between them. Additionally, the impact of the aggregation of the research performance indices of two authors on link prediction performance was not highlighted. To this end, in this paper we propose an integrative supervised learning framework for predicting potential collaboration in co-authorship network based on similarity of the research interests and the similarity of the affiliations of each pair of authors in this network. Moreover, our proposed framework integrates the aggregation of research performance indices of each author pair and the similarity between the two authors nodes with the research interest and affiliation similarity as four metrics for predicting the potential link between each two authors. Our experimental results obtained from applying our proposed link prediction approach to the two largest connected graphs of two huge academic co-authorship networks, namely ArnetMiner and DBLP, show the great performance of this approach in predicting potential links between two authors on large-scale academic SNs.","authors":["Doaa Hassan","Mohammad Al Hasan"],"url":"https://arxiv.org/abs/2505.21673"}
{"created":"2025-05-29","title":"Make Planning Research Rigorous Again!","abstract":"In over sixty years since its inception, the field of planning has made significant contributions to both the theory and practice of building planning software that can solve a never-before-seen planning problem. This was done through established practices of rigorous design and evaluation of planning systems. It is our position that this rigor should be applied to the current trend of work on planning with large language models. One way to do so is by correctly incorporating the insights, tools, and data from the automated planning community into the design and evaluation of LLM-based planners. The experience and expertise of the planning community are not just important from a historical perspective; the lessons learned could play a crucial role in accelerating the development of LLM-based planners. This position is particularly important in light of the abundance of recent works that replicate and propagate the same pitfalls that the planning community has encountered and learned from. We believe that avoiding such known pitfalls will contribute greatly to the progress in building LLM-based planners and to planning in general.","authors":["Michael Katz","Harsha Kokel","Christian Muise","Shirin Sohrabi","Sarath Sreedharan"],"url":"https://arxiv.org/abs/2505.21674"}
{"created":"2025-05-29","title":"Real-World Deployment of Cloud Autonomous Mobility System Using 5G Networks for Outdoor and Indoor Environments","abstract":"The growing complexity of both outdoor and indoor mobility systems demands scalable, cost-effective, and reliable perception and communication frameworks. This work presents the real-world deployment and evaluation of a Cloud Autonomous Mobility (CAM) system that leverages distributed sensor nodes connected via 5G networks, which integrates LiDAR- and camera-based perception at infrastructure units, cloud computing for global information fusion, and Ultra-Reliable Low Latency Communications (URLLC) to enable real-time situational awareness and autonomous operation. The CAM system is deployed in two distinct environments: a dense urban roundabout and a narrow indoor hospital corridor. Field experiments show improved traffic monitoring, hazard detection, and asset management capabilities. The paper also discusses practical deployment challenges and shares key insights for scaling CAM systems. The results highlight the potential of cloud-based infrastructure perception to advance both outdoor and indoor intelligent transportation systems.","authors":["Yufeng Yang","Minghao Ning","Keqi Shu","Aladdin Saleh","Ehsan Hashemi","Amir Khajepour"],"url":"https://arxiv.org/abs/2505.21676"}
{"created":"2025-05-29","title":"What happens when generative AI models train recursively on each others' generated outputs?","abstract":"The internet is full of AI-generated content while also serving as a common source of training data for generative AI (genAI) models. This duality raises the possibility that future genAI models may be trained on other models' generated outputs. Prior work has studied consequences of models training on their own generated outputs, but limited work has considered what happens if models ingest content produced by other models. Given society's increasing dependence on genAI tools, understanding downstream effects of such data-mediated model interactions is critical. To this end, we provide empirical evidence for how data-mediated interactions might unfold in practice, develop a theoretical model for this interactive training process, and show experimentally possible long-term results of such interactions. We find that data-mediated interactions can benefit models by exposing them to novel concepts perhaps missed in original training data, but also can homogenize their performance on shared tasks.","authors":["Hung Ahn Vu","Galen Reeves","Emily Wenger"],"url":"https://arxiv.org/abs/2505.21677"}
{"created":"2025-05-29","title":"multivariateGPT: a decoder-only transformer for multivariate categorical and numeric data","abstract":"Real-world processes often generate data that are a mix of categorical and numeric values that are recorded at irregular and informative intervals. Discrete token-based approaches are limited in numeric representation capacity while methods like neural ordinary differential equations are not well suited for categorical data or informative sampling and require augmentation to handle certain classes of trajectories. Here, we present multivariateGPT, a single architecture for modeling sequences of mixed categorical (including tokenized text) and numeric data. This is accomplished with an autoregressive sequence decomposition, embedding scheme, and loss function that extend the next token prediction task to likelihood estimation of the joint distribution of next token class and value. We demonstrate how this approach can efficiently learn to generalize patterns in simple physical systems and model complex time series including electrocardiograms and multivariate electronic health record data. This work extends the utility of transformer based models to additional classes of data.","authors":["Andrew J. Loza","Jun Yup Kim","Shangzheng Song","Yihang Liu","Joseph J. Y. Sung","R Andrew Taylor","Dennis L. Shung"],"url":"https://arxiv.org/abs/2505.21680"}
{"created":"2025-05-29","title":"Residual Diffusion Models for Variable-Rate Joint Source Channel Coding of MIMO CSI","abstract":"Despite significant advancements in deep learning-based CSI compression, some key limitations remain unaddressed. Current approaches predominantly treat CSI compression as a source coding problem, neglecting transmission errors. In finite block length regimes, separate source and channel coding proves suboptimal, with reconstruction performance deteriorating significantly under challenging channel conditions. While existing autoencoder-based compression schemes can be readily extended to support joint source-channel coding, they struggle to capture complex channel distributions and exhibit poor scalability with increasing parameter count. To overcome these inherent limitations of autoencoder-based approaches, we propose Residual-Diffusion Joint Source-Channel Coding (RD-JSCC), a novel framework that integrates a lightweight autoencoder with a residual diffusion module to iteratively refine CSI reconstruction. Our flexible decoding strategy balances computational efficiency and performance by dynamically switching between low-complexity autoencoder decoding and sophisticated diffusion-based refinement based on channel conditions. Comprehensive simulations demonstrate that RD-JSCC significantly outperforms existing autoencoder-based approaches in challenging wireless environments. Furthermore, RD-JSCC offers several practical features, including a low-latency 2-step diffusion during inference, support for multiple compression rates with a single model, robustness to fixed-bit quantization, and adaptability to imperfect channel estimation.","authors":["Sravan Kumar Ankireddy","Heasung Kim","Hyeji Kim"],"url":"https://arxiv.org/abs/2505.21681"}
{"created":"2025-05-29","title":"Data and Technology for Equitable Public Administration: Understanding City Government Employees' Challenges and Needs","abstract":"City governments in the United States are increasingly pressured to adopt emerging technologies. Yet, these systems often risk biased and disparate outcomes. Scholars studying public sector technology design have converged on the need to ground these systems in the goals and organizational contexts of employees using them. We expand our understanding of employees' contexts by focusing on the equity practices of city government employees to surface important equity considerations around public sector data and technology use. Through semi-structured interviews with thirty-six employees from ten departments of a U.S. city government, our findings reveal challenges employees face when operationalizing equity, perspectives on data needs for advancing equity goals, and the design space for acceptable government technology. We discuss what it looks like to foreground equity in data use and technology design, and considerations for how to support city government employees in operationalizing equity with and without official equity offices.","authors":["Angie Zhang (Lee)","Madison Liao (Lee)","Elizaveta (Lee)","Kravchenko","Marshanah Taylor","Angela Haddad","Chandra Bhat","S. Craig Watkins","Min Kyung Lee"],"url":"https://arxiv.org/abs/2505.21682"}
{"created":"2025-05-29","title":"Incentivizing Permissionless Distributed Learning of LLMs","abstract":"We describe an incentive system for distributed deep learning of foundational models where peers are rewarded for contributions. The incentive system, \\textit{Gauntlet}, has been deployed on the bittensor blockchain and used to train a 1.2B LLM with completely permissionless contributions of pseudo-gradients: no control over the users that can register or their hardware. \\textit{Gauntlet} can be applied to any synchronous distributed training scheme that relies on aggregating updates or pseudo-gradients. We rely on a two-stage mechanism for fast filtering of peer uptime, reliability, and synchronization, combined with the core component that estimates the loss before and after individual pseudo-gradient contributions. We utilized an OpenSkill rating system to track competitiveness of pseudo-gradient scores across time. Finally, we introduce a novel mechanism to ensure peers on the network perform unique computations. Our live 1.2B run, which has paid out real-valued tokens to participants based on the value of their contributions, yielded a competitive (on a per-iteration basis) 1.2B model that demonstrates the utility of our incentive system.","authors":["Joel Lidin","Amir Sarfi","Evangelos Pappas","Samuel Dare","Eugene Belilovsky","Jacob Steeves"],"url":"https://arxiv.org/abs/2505.21684"}
{"created":"2025-05-29","title":"Proof of Work With External Utilities","abstract":"Proof-of-Work (PoW) consensus is traditionally analyzed under the assumption that all miners incur similar costs per unit of computational effort. In reality, costs vary due to factors such as regional electricity cost differences and access to specialized hardware. These variations in mining costs become even more pronounced in the emerging paradigm of \\emph{Proof-of-Useful-Work} (PoUW), where miners can earn additional \\emph{external} rewards by performing beneficial computations, such as Artificial Intelligence (AI) training and inference workloads.","authors":["Yogev Bar-On","Ilan Komargodski","Omri Weinstein"],"url":"https://arxiv.org/abs/2505.21685"}
{"created":"2025-05-29","title":"Modeling extreme events and intermittency in turbulent diffusion with a mean gradient","abstract":"We study the statistical properties of passive tracer transport in turbulent flows with a mean gradient, emphasizing tracer intermittency and extreme events. An analytically tractable model is developed, coupling zonal and shear velocity components with both linear and nonlinear stochastic dynamics. Formulating the model in Fourier space, a simple explicit solution for the tracer invariant statistics is derived. Through this model we identify the resonance condition responsible for non-Gaussian behavior and bursts in the tracer. Resonant conditions, that lead to a peak in the tracer variance, occur when the zonal flow and the shear flow phase speeds are equivalent. Numerical experiments across a range of regimes, including different energy spectra and zonal flow models, are performed to validate these findings and demonstrate how the velocity field and stochasticity determines tracer extremes. These results provide additional insight into the mechanisms underlying turbulent tracer transport, with implications for uncertainty quantification and data assimilation in geophysical and environmental applications.","authors":["Mustafa A Mohamad","Di Qi"],"url":"https://arxiv.org/abs/2505.21688"}
{"created":"2025-05-29","title":"LLMPR: A Novel LLM-Driven Transfer Learning based Petition Ranking Model","abstract":"The persistent accumulation of unresolved legal cases, especially within the Indian judiciary, significantly hampers the timely delivery of justice. Manual methods of prioritizing petitions are often prone to inefficiencies and subjective biases further exacerbating delays. To address this issue, we propose LLMPR (Large Language Model-based Petition Ranking), an automated framework that utilizes transfer learning and machine learning to assign priority rankings to legal petitions based on their contextual urgency. Leveraging the ILDC dataset comprising 7,593 annotated petitions, we process unstructured legal text and extract features through various embedding techniques, including DistilBERT, LegalBERT, and MiniLM. These textual embeddings are combined with quantitative indicators such as gap days, rank scores, and word counts to train multiple machine learning models, including Random Forest, Decision Tree, XGBoost, LightGBM, and CatBoost. Our experiments demonstrate that Random Forest and Decision Tree models yield superior performance, with accuracy exceeding 99% and a Spearman rank correlation of 0.99. Notably, models using only numerical features achieve nearly optimal ranking results (R2 = 0.988, \\r{ho} = 0.998), while LLM-based embeddings offer only marginal gains. These findings suggest that automated petition ranking can effectively streamline judicial workflows, reduce case backlog, and improve fairness in legal prioritization.","authors":["Avijit Gayen","Somyajit Chakraborty","Mainak Sen","Soham Paul","Angshuman Jana"],"url":"https://arxiv.org/abs/2505.21689"}
{"created":"2025-05-29","title":"MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs","abstract":"Large language models (LLMs) are used globally across many languages, but their English-centric pretraining raises concerns about cross-lingual disparities for cultural awareness, often resulting in biased outputs. However, comprehensive multilingual evaluation remains challenging due to limited benchmarks and questionable translation quality. To better assess these disparities, we introduce MAKIEval, an automatic multilingual framework for evaluating cultural awareness in LLMs across languages, regions, and topics. MAKIEval evaluates open-ended text generation, capturing how models express culturally grounded knowledge in natural language. Leveraging Wikidata's multilingual structure as a cross-lingual anchor, it automatically identifies cultural entities in model outputs and links them to structured knowledge, enabling scalable, language-agnostic evaluation without manual annotation or translation. We then introduce four metrics that capture complementary dimensions of cultural awareness: granularity, diversity, cultural specificity, and consensus across languages. We assess 7 LLMs developed from different parts of the world, encompassing both open-source and proprietary systems, across 13 languages, 19 countries and regions, and 6 culturally salient topics (e.g., food, clothing). Notably, we find that models tend to exhibit stronger cultural awareness in English, suggesting that English prompts more effectively activate culturally grounded knowledge. We publicly release our code and data.","authors":["Raoyuan Zhao","Beiduo Chen","Barbara Plank","Michael A. Hedderich"],"url":"https://arxiv.org/abs/2505.21693"}
{"created":"2025-05-29","title":"AMSFL: Adaptive Multi-Step Federated Learning via Gradient Difference-Based Error Modeling","abstract":"Federated learning faces critical challenges in balancing communication efficiency and model accuracy. One key issue lies in the approximation of update errors without incurring high computational costs. In this paper, we propose a lightweight yet effective method called Gradient Difference Approximation (GDA), which leverages first-order information to estimate local error trends without computing the full Hessian matrix. The proposed method forms a key component of the Adaptive Multi-Step Federated Learning (AMSFL) framework and provides a unified error modeling strategy for large-scale multi-step adaptive training environments.","authors":["Ganglou Xu"],"url":"https://arxiv.org/abs/2505.21695"}
{"created":"2025-05-29","title":"How Soft Skills Shape First-Year Success in Higher Education","abstract":"Soft skills are critical for academic and professional success, but are often neglected in early-stage technical curricula. This paper presents a semi-isolated teaching intervention aimed at fostering study ability and key soft skills-communication, collaboration, and project management-among first-year computer science students. The elective seminar Soft Skills and Tools for Studies and Career in IT was alongside a mandatory team-based programming course. We analyze project outcomes and student experiences across three cohorts across three groups: students who attended the seminar, students who teamed up with a seminar attendee, and students with no exposure to the seminar.","authors":["Kerstin Andree","Santiago Berrezueta-Guzman","Stephan Krusche","Luise Pufahl","Stefan Wagner"],"url":"https://arxiv.org/abs/2505.21696"}
{"created":"2025-05-29","title":"Scalable Segmentation for Ultra-High-Resolution Brain MR Images","abstract":"Although deep learning has shown great success in 3D brain MRI segmentation, achieving accurate and efficient segmentation of ultra-high-resolution brain images remains challenging due to the lack of labeled training data for fine-scale anatomical structures and high computational demands. In this work, we propose a novel framework that leverages easily accessible, low-resolution coarse labels as spatial references and guidance, without incurring additional annotation cost. Instead of directly predicting discrete segmentation maps, our approach regresses per-class signed distance transform maps, enabling smooth, boundary-aware supervision. Furthermore, to enhance scalability, generalizability, and efficiency, we introduce a scalable class-conditional segmentation strategy, where the model learns to segment one class at a time conditioned on a class-specific input. This novel design not only reduces memory consumption during both training and testing, but also allows the model to generalize to unseen anatomical classes. We validate our method through comprehensive experiments on both synthetic and real-world datasets, demonstrating its superior performance and scalability compared to conventional segmentation approaches.","authors":["Xiaoling Hu","Peirong Liu","Dina Zemlyanker","Jonathan Williams Ramirez","Oula Puonti","Juan Eugenio Iglesias"],"url":"https://arxiv.org/abs/2505.21697"}
{"created":"2025-05-29","title":"MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis","abstract":"Recent vision-language foundation models deliver state-of-the-art results on natural image classification but falter on medical images due to pronounced domain shifts. At the same time, training a medical foundation model requires substantial resources, including extensive annotated data and high computational capacity. To bridge this gap with minimal overhead, we introduce MedBridge, a lightweight multimodal adaptation framework that re-purposes pretrained VLMs for accurate medical image diagnosis. MedBridge comprises three key components. First, a Focal Sampling module that extracts high-resolution local regions to capture subtle pathological features and compensate for the limited input resolution of general-purpose VLMs. Second, a Query Encoder (QEncoder) injects a small set of learnable queries that attend to the frozen feature maps of VLM, aligning them with medical semantics without retraining the entire backbone. Third, a Mixture of Experts mechanism, driven by learnable queries, harnesses the complementary strength of diverse VLMs to maximize diagnostic performance. We evaluate MedBridge on five medical imaging benchmarks across three key adaptation tasks, demonstrating its superior performance in both cross-domain and in-domain adaptation settings, even under varying levels of training data availability. Notably, MedBridge achieved over 6-15% improvement in AUC compared to state-of-the-art VLM adaptation methods in multi-label thoracic disease diagnosis, underscoring its effectiveness in leveraging foundation models for accurate and data-efficient medical diagnosis. Our code is available at https://github.com/ai-med/MedBridge.","authors":["Yitong Li","Morteza Ghahremani","Christian Wachinger"],"url":"https://arxiv.org/abs/2505.21698"}
{"created":"2025-05-29","title":"Rethinking Chunk Size For Long-Document Retrieval: A Multi-Dataset Analysis","abstract":"Chunking is a crucial preprocessing step in retrieval-augmented generation (RAG) systems, significantly impacting retrieval effectiveness across diverse datasets. In this study, we systematically evaluate fixed-size chunking strategies and their influence on retrieval performance using multiple embedding models. Our experiments, conducted on both short-form and long-form datasets, reveal that chunk size plays a critical role in retrieval effectiveness -- smaller chunks (64-128 tokens) are optimal for datasets with concise, fact-based answers, whereas larger chunks (512-1024 tokens) improve retrieval in datasets requiring broader contextual understanding. We also analyze the impact of chunking on different embedding models, finding that they exhibit distinct chunking sensitivities. While models like Stella benefit from larger chunks, leveraging global context for long-range retrieval, Snowflake performs better with smaller chunks, excelling at fine-grained, entity-based matching. Our results underscore the trade-offs between chunk size, embedding models, and dataset characteristics, emphasizing the need for improved chunk quality measures, and more comprehensive datasets to advance chunk-based retrieval in long-document Information Retrieval (IR).","authors":["Sinchana Ramakanth Bhat","Max Rudat","Jannis Spiekermann","Nicolas Flores-Herr"],"url":"https://arxiv.org/abs/2505.21700"}
{"created":"2025-05-29","title":"Do We Know What LLMs Don't Know? A Study of Consistency in Knowledge Probing","abstract":"The reliability of large language models (LLMs) is greatly compromised by their tendency to hallucinate, underscoring the need for precise identification of knowledge gaps within LLMs. Various methods for probing such gaps exist, ranging from calibration-based to prompting-based methods. To evaluate these probing methods, in this paper, we propose a new process based on using input variations and quantitative metrics. Through this, we expose two dimensions of inconsistency in knowledge gap probing. (1) Intra-method inconsistency: Minimal non-semantic perturbations in prompts lead to considerable variance in detected knowledge gaps within the same probing method; e.g., the simple variation of shuffling answer options can decrease agreement to around 40%. (2) Cross-method inconsistency: Probing methods contradict each other on whether a model knows the answer. Methods are highly inconsistent -- with decision consistency across methods being as low as 7% -- even though the model, dataset, and prompt are all the same. These findings challenge existing probing methods and highlight the urgent need for perturbation-robust probing frameworks.","authors":["Raoyuan Zhao","Abdullatif K\\\"oksal","Ali Modarressi","Michael A. Hedderich","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2505.21701"}
{"created":"2025-05-29","title":"A Joint Reconstruction-Triplet Loss Autoencoder Approach Towards Unseen Attack Detection in IoV Networks","abstract":"Internet of Vehicles (IoV) systems, while offering significant advancements in transportation efficiency and safety, introduce substantial security vulnerabilities due to their highly interconnected nature. These dynamic systems produce massive amounts of data between vehicles, infrastructure, and cloud services and present a highly distributed framework with a wide attack surface. In considering network-centered attacks on IoV systems, attacks such as Denial-of-Service (DoS) can prohibit the communication of essential physical traffic safety information between system elements, illustrating that the security concerns for these systems go beyond the traditional confidentiality, integrity, and availability concerns of enterprise systems. Given the complexity and volume of data generated by IoV systems, traditional security mechanisms are often inadequate for accurately detecting sophisticated and evolving cyberattacks. Here, we present an unsupervised autoencoder method trained entirely on benign network data for the purpose of unseen attack detection in IoV networks. We leverage a weighted combination of reconstruction and triplet margin loss to guide the autoencoder training and develop a diverse representation of the benign training set. We conduct extensive experiments on recent network intrusion datasets from two different application domains, industrial IoT and home IoT, that represent the modern IoV task. We show that our method performs robustly for all unseen attack types, with roughly 99% accuracy on benign data and between 97% and 100% performance on anomaly data. We extend these results to show that our model is adaptable through the use of transfer learning, achieving similarly high results while leveraging domain features from one domain to another.","authors":["Julia Boone","Tolunay Seyfi","Fatemeh Afghah"],"url":"https://arxiv.org/abs/2505.21703"}
{"created":"2025-05-29","title":"Lecturers' perspectives on the integration of research data management into teacher training programmes","abstract":"This article focuses on how data literacy education such as research data management skills can be integrated into teacher training programmes in order to adequately train the teachers of tomorrow. To this end, interviews were conducted with three lecturers from the Faculty of Education and analysed both qualitatively and quantitatively. The lecturers describe the topic of research data management as extremely relevant for students, especially in the Master's program. Even as future teachers, for example in computer science and the natural sciences, students will have a lot to do with data and need to be able to handle it competently. The article also discusses how research data management skills can be integrated into the teacher training program.","authors":["Sandra Schulz","Juliane Jacob"],"url":"https://arxiv.org/abs/2505.21704"}
{"created":"2025-05-29","title":"Network classification through random walks","abstract":"Network models have been widely used to study diverse systems and analyze their dynamic behaviors. Given the structural variability of networks, an intriguing question arises: Can we infer the type of system represented by a network based on its structure? This classification problem involves extracting relevant features from the network. Existing literature has proposed various methods that combine structural measurements and dynamical processes for feature extraction. In this study, we introduce a novel approach to characterize networks using statistics from random walks, which can be particularly informative about network properties. We present the employed statistical metrics and compare their performance on multiple datasets with other state-of-the-art feature extraction methods. Our results demonstrate that the proposed method is effective in many cases, often outperforming existing approaches, although some limitations are observed across certain datasets.","authors":["Gonzalo Travieso","Joao Merenda","Odemir M. Bruno"],"url":"https://arxiv.org/abs/2505.21706"}
{"created":"2025-05-29","title":"Assessing and Refining ChatGPT's Performance in Identifying Targeting and Inappropriate Language: A Comparative Study","abstract":"This study evaluates the effectiveness of ChatGPT, an advanced AI model for natural language processing, in identifying targeting and inappropriate language in online comments. With the increasing challenge of moderating vast volumes of user-generated content on social network sites, the role of AI in content moderation has gained prominence. We compared ChatGPT's performance against crowd-sourced annotations and expert evaluations to assess its accuracy, scope of detection, and consistency. Our findings highlight that ChatGPT performs well in detecting inappropriate content, showing notable improvements in accuracy through iterative refinements, particularly in Version 6. However, its performance in targeting language detection showed variability, with higher false positive rates compared to expert judgments. This study contributes to the field by demonstrating the potential of AI models like ChatGPT to enhance automated content moderation systems while also identifying areas for further improvement. The results underscore the importance of continuous model refinement and contextual understanding to better support automated moderation and mitigate harmful online behavior.","authors":["Barbarestani Baran","Maks Isa","Vossen Piek"],"url":"https://arxiv.org/abs/2505.21710"}
{"created":"2025-05-29","title":"Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling","abstract":"We present LrcSSM, a \\textit{nonlinear} recurrent model that processes long sequences as fast as today's linear state-space layers. By forcing the state-transition matrix to be diagonal and learned at every step, the full sequence can be solved in parallel with a single prefix-scan, giving $\\mathcal{O}(TD)$ time and memory and only $\\mathcal{O}(\\log T)$ sequential depth, for input-sequence length $T$ and a state dimension $D$. Moreover, LrcSSM offers a formal gradient-stability guarantee that other input-varying systems such as Liquid-S4 and Mamba do not provide. Lastly, for network depth $L$, as the forward and backward passes cost $\\Theta(T\\,D\\,L)$ FLOPs, with its low sequential depth and parameter count $\\Theta(D\\,L)$, the model follows the compute-optimal scaling law regime ($\\beta \\approx 0.42$) recently observed for Mamba, outperforming quadratic-attention Transformers at equal compute while avoiding the memory overhead of FFT-based long convolutions. We show that on a series of long-range forecasting tasks, LrcSSM outperforms LRU, S5 and Mamba.","authors":["M\\'onika Farsang","Ramin Hasani","Radu Grosu"],"url":"https://arxiv.org/abs/2505.21717"}
{"created":"2025-05-29","title":"Responsible Data Stewardship: Generative AI and the Digital Waste Problem","abstract":"As generative AI systems become widely adopted, they enable unprecedented creation levels of synthetic data across text, images, audio, and video modalities. While research has addressed the energy consumption of model training and inference, a critical sustainability challenge remains understudied: digital waste. This term refers to stored data that consumes resources without serving a specific (and/or immediate) purpose. This paper presents this terminology in the AI context and introduces digital waste as an ethical imperative within (generative) AI development, positioning environmental sustainability as core for responsible innovation. Drawing from established digital resource management approaches, we examine how other disciplines manage digital waste and identify transferable approaches for the AI community. We propose specific recommendations encompassing re-search directions, technical interventions, and cultural shifts to mitigate the environmental consequences of in-definite data storage. By expanding AI ethics beyond immediate concerns like bias and privacy to include inter-generational environmental justice, this work contributes to a more comprehensive ethical framework that considers the complete lifecycle impact of generative AI systems.","authors":["Vanessa Utz"],"url":"https://arxiv.org/abs/2505.21720"}
{"created":"2025-05-29","title":"Saddle-To-Saddle Dynamics in Deep ReLU Networks: Low-Rank Bias in the First Saddle Escape","abstract":"When a deep ReLU network is initialized with small weights, GD is at first dominated by the saddle at the origin in parameter space. We study the so-called escape directions, which play a similar role as the eigenvectors of the Hessian for strict saddles. We show that the optimal escape direction features a low-rank bias in its deeper layers: the first singular value of the $\\ell$-th layer weight matrix is at least $\\ell^{\\frac{1}{4}}$ larger than any other singular value. We also prove a number of related results about these escape directions. We argue that this result is a first step in proving Saddle-to-Saddle dynamics in deep ReLU networks, where GD visits a sequence of saddles with increasing bottleneck rank.","authors":["Ioannis Bantzis","James B. Simon","Arthur Jacot"],"url":"https://arxiv.org/abs/2505.21722"}
{"created":"2025-05-29","title":"OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions","abstract":"In this paper, we introduce Online Multimodal Conversational Response Generation (OMCRG), a novel task that aims to online generate synchronized verbal and non-verbal listener feedback, conditioned on the speaker's multimodal input. OMCRG reflects natural dyadic interactions and poses new challenges in achieving synchronization between the generated audio and facial responses of the listener. To address these challenges, we innovatively introduce text as an intermediate modality to bridge the audio and facial responses. We hence propose OmniResponse, a Multimodal Large Language Model (MLLM) that autoregressively generates high-quality multi-modal listener responses. OmniResponse leverages a pretrained LLM enhanced with two novel components: Chrono-Text, which temporally anchors generated text tokens, and TempoVoice, a controllable online TTS module that produces speech synchronized with facial reactions. To support further OMCRG research, we present ResponseNet, a new dataset comprising 696 high-quality dyadic interactions featuring synchronized split-screen videos, multichannel audio, transcripts, and facial behavior annotations. Comprehensive evaluations conducted on ResponseNet demonstrate that OmniResponse significantly outperforms baseline models in terms of semantic speech content, audio-visual synchronization, and generation quality.","authors":["Cheng Luo","Jianghui Wang","Bing Li","Siyang Song","Bernard Ghanem"],"url":"https://arxiv.org/abs/2505.21724"}
{"created":"2025-05-29","title":"Lazarus Group Targets Crypto-Wallets and Financial Data while employing new Tradecrafts","abstract":"This report presents a comprehensive analysis of a malicious software sample, detailing its architecture, behavioral characteristics, and underlying intent. Through static and dynamic examination, the malware core functionalities, including persistence mechanisms, command-and-control communication, and data exfiltration routines, are identified and its supporting infrastructure is mapped. By correlating observed indicators of compromise with known techniques, tactics, and procedures, this analysis situates the sample within the broader context of contemporary threat campaigns and infers the capabilities and motivations of its likely threat actor.","authors":["Alessio Di Santo"],"url":"https://arxiv.org/abs/2505.21725"}
{"created":"2025-05-29","title":"FedCostAware: Enabling Cost-Aware Federated Learning on the Cloud","abstract":"Federated learning (FL) is a distributed machine learning (ML) approach that allows multiple clients to collaboratively train ML model without exchanging their original training data, offering a solution that is particularly valuable in sensitive domains such as biomedicine. However, training robust FL models often requires substantial computing resources from participating clients, such as GPUs, which may not be readily available at institutions such as hospitals. While cloud platforms (e.g., AWS) offer on-demand access to such resources, their usage can incur significant costs, particularly in distributed training scenarios where poor coordination strategies can lead to substantial resource wastage. To address this, we introduce FedCostAware, a cost-aware scheduling algorithm designed to optimize synchronous FL on cloud spot instances. FedCostAware addresses the challenges of training on spot instances and different client budgets by employing intelligent management of the lifecycle of spot instances. This approach minimizes resource idle time and overall expenses. Comprehensive experiments across multiple datasets demonstrate that FedCostAware significantly reduces cloud computing costs compared to conventional spot and on-demand schemes, enhancing the accessibility and affordability of FL.","authors":["Aditya Sinha","Zilinghan Li","Tingkai Liu","Volodymyr Kindratenko","Kibaek Kim","Ravi Madduri"],"url":"https://arxiv.org/abs/2505.21727"}
{"created":"2025-05-29","title":"Bridging the Narrative Divide: Cross-Platform Discourse Networks in Fragmented Ecosystems","abstract":"Political discourse has grown increasingly fragmented across different social platforms, making it challenging to trace how narratives spread and evolve within such a fragmented information ecosystem. Reconstructing social graphs and information diffusion networks is challenging, and available strategies typically depend on platform-specific features and behavioral signals which are often incompatible across systems and increasingly restricted. To address these challenges, we present a platform-agnostic framework that allows to accurately and efficiently reconstruct the underlying social graph of users' cross-platform interactions, based on discovering latent narratives and users' participation therein. Our method achieves state-of-the-art performance in key network-based tasks: information operation detection, ideological stance prediction, and cross-platform engagement prediction$\\unicode{x2013}$$\\unicode{x2013}$while requiring significantly less data than existing alternatives and capturing a broader set of users. When applied to cross-platform information dynamics between Truth Social and X (formerly Twitter), our framework reveals a small, mixed-platform group of $\\textit{bridge users}$, comprising just 0.33% of users and 2.14% of posts, who introduce nearly 70% of $\\textit{migrating narratives}$ to the receiving platform. These findings offer a structural lens for anticipating how narratives traverse fragmented information ecosystems, with implications for cross-platform governance, content moderation, and policy interventions.","authors":["Patrick Gerard","Hans W. A. Hanley","Luca Luceri","Emilio Ferrara"],"url":"https://arxiv.org/abs/2505.21729"}
{"created":"2025-05-29","title":"Deep Reinforcement Learning Agents are not even close to Human Intelligence","abstract":"Deep reinforcement learning (RL) agents achieve impressive results in a wide variety of tasks, but they lack zero-shot adaptation capabilities. While most robustness evaluations focus on tasks complexifications, for which human also struggle to maintain performances, no evaluation has been performed on tasks simplifications. To tackle this issue, we introduce HackAtari, a set of task variations of the Arcade Learning Environments. We use it to demonstrate that, contrary to humans, RL agents systematically exhibit huge performance drops on simpler versions of their training tasks, uncovering agents' consistent reliance on shortcuts. Our analysis across multiple algorithms and architectures highlights the persistent gap between RL agents and human behavioral intelligence, underscoring the need for new benchmarks and methodologies that enforce systematic generalization testing beyond static evaluation protocols. Training and testing in the same environment is not enough to obtain agents equipped with human-like intelligence.","authors":["Quentin Delfosse","Jannis Bl\\\"uml","Fabian Tatai","Th\\'eo Vincent","Bjarne Gregori","Elisabeth Dillies","Jan Peters","Constantin Rothkopf","Kristian Kersting"],"url":"https://arxiv.org/abs/2505.21731"}
{"created":"2025-05-29","title":"LaX: Boosting Low-Rank Training of Foundation Models via Latent Crossing","abstract":"Training foundation models such as ViTs and LLMs requires tremendous computing cost. Low-rank matrix or tensor factorization offers a parameter-efficient alternative, but often downgrades performance due to the restricted parameter space. In this work, we introduce {\\textbf{Latent Crossing (LaX)}} -- a simple yet effective plug-and-play module that enhances the capacity of low-rank models by enabling information flow across low-rank subspaces. We extensively validate the benefits of LaX on pre-training tasks with ViT-Base/Large and LLaMA-like models ranging from 60M to 1B parameters. LaX boosts low-rank model performance to match or exceed the full-rank baselines while using 2-3\\(\\times\\) fewer parameters. When equipped with low-rank adapters (i.e., LoRA) for fine-tuning LLaMA-7/13B, LaX consistently improves performance on arithmetic and common sense reasoning tasks with negligible cost.","authors":["Ruijie Zhang","Ziyue Liu","Zhengyang Wang","Zheng Zhang"],"url":"https://arxiv.org/abs/2505.21732"}
{"created":"2025-05-29","title":"Scrapers selectively respect robots.txt directives: evidence from a large-scale empirical study","abstract":"Online data scraping has taken on new dimensions in recent years, as traditional scrapers have been joined by new AI-specific bots. To counteract unwanted scraping, many sites use tools like the Robots Exclusion Protocol (REP), which places a robots.txt file at the site root to dictate scraper behavior. Yet, the efficacy of the REP is not well-understood. Anecdotal evidence suggests some bots comply poorly with it, but no rigorous study exists to support (or refute) this claim. To understand the merits and limits of the REP, we conduct the first large-scale study of web scraper compliance with robots.txt directives using anonymized web logs from our institution. We analyze the behavior of 130 self-declared bots (and many anonymous ones) over 40 days, using a series of controlled robots.txt experiments. We find that bots are less likely to comply with stricter robots.txt directives, and that certain categories of bots, including AI search crawlers, rarely check robots.txt at all. These findings suggest that relying on robots.txt files to prevent unwanted scraping is risky and highlight the need for alternative approaches.","authors":["Taein Kim","Karstan Bock","Claire Luo","Amanda Liswood","Emily Wenger"],"url":"https://arxiv.org/abs/2505.21733"}
{"created":"2025-05-29","title":"MIND-Stack: Modular, Interpretable, End-to-End Differentiability for Autonomous Navigation","abstract":"Developing robust, efficient navigation algorithms is challenging. Rule-based methods offer interpretability and modularity but struggle with learning from large datasets, while end-to-end neural networks excel in learning but lack transparency and modularity. In this paper, we present MIND-Stack, a modular software stack consisting of a localization network and a Stanley Controller with intermediate human interpretable state representations and end-to-end differentiability. Our approach enables the upstream localization module to reduce the downstream control error, extending its role beyond state estimation. Unlike existing research on differentiable algorithms that either lack modules of the autonomous stack to span from sensor input to actuator output or real-world implementation, MIND-Stack offers both capabilities. We conduct experiments that demonstrate the ability of the localization module to reduce the downstream control loss through its end-to-end differentiability while offering better performance than state-of-the-art algorithms. We showcase sim-to-real capabilities by deploying the algorithm on a real-world embedded autonomous platform with limited computation power and demonstrate simultaneous training of both the localization and controller towards one goal. While MIND-Stack shows good results, we discuss the incorporation of additional modules from the autonomous navigation pipeline in the future, promising even greater stability and performance in the next iterations of the framework.","authors":["Felix Jahncke","Johannes Betz"],"url":"https://arxiv.org/abs/2505.21734"}
{"created":"2025-05-29","title":"Moment kernels: a simple and scalable approach for equivariance to rotations and reflections in deep convolutional networks","abstract":"The principle of translation equivariance (if an input image is translated an output image should be translated by the same amount), led to the development of convolutional neural networks that revolutionized machine vision. Other symmetries, like rotations and reflections, play a similarly critical role, especially in biomedical image analysis, but exploiting these symmetries has not seen wide adoption. We hypothesize that this is partially due to the mathematical complexity of methods used to exploit these symmetries, which often rely on representation theory, a bespoke concept in differential geometry and group theory. In this work, we show that the same equivariance can be achieved using a simple form of convolution kernels that we call ``moment kernels,'' and prove that all equivariant kernels must take this form. These are a set of radially symmetric functions of a spatial position $x$, multiplied by powers of the components of $x$ or the identity matrix. We implement equivariant neural networks using standard convolution modules, and provide architectures to execute several biomedical image analysis tasks that depend on equivariance principles: classification (outputs are invariant under orthogonal transforms), 3D image registration (outputs transform like a vector), and cell segmentation (quadratic forms defining ellipses transform like a matrix).","authors":["Zachary Schlamowitz","Andrew Bennecke","Daniel J. Tward"],"url":"https://arxiv.org/abs/2505.21736"}
{"created":"2025-05-29","title":"Counterfactual Simulatability of LLM Explanations for Generation Tasks","abstract":"LLMs can be unpredictable, as even slight alterations to the prompt can cause the output to change in unexpected ways. Thus, the ability of models to accurately explain their behavior is critical, especially in high-stakes settings. One approach for evaluating explanations is counterfactual simulatability, how well an explanation allows users to infer the model's output on related counterfactuals. Counterfactual simulatability has been previously studied for yes/no question answering tasks. We provide a general framework for extending this method to generation tasks, using news summarization and medical suggestion as example use cases. We find that while LLM explanations do enable users to better predict LLM outputs on counterfactuals in the summarization setting, there is significant room for improvement for medical suggestion. Furthermore, our results suggest that the evaluation for counterfactual simulatability may be more appropriate for skill-based tasks as opposed to knowledge-based tasks.","authors":["Marvin Limpijankit","Yanda Chen","Melanie Subbiah","Nicholas Deas","Kathleen McKeown"],"url":"https://arxiv.org/abs/2505.21740"}
{"created":"2025-05-29","title":"AI-Supported Platform for System Monitoring and Decision-Making in Nuclear Waste Management with Large Language Models","abstract":"Nuclear waste management requires rigorous regulatory compliance assessment, demanding advanced decision-support systems capable of addressing complex legal, environmental, and safety considerations. This paper presents a multi-agent Retrieval-Augmented Generation (RAG) system that integrates large language models (LLMs) with document retrieval mechanisms to enhance decision accuracy through structured agent collaboration. Through a structured 10-round discussion model, agents collaborate to assess regulatory compliance and safety requirements while maintaining document-grounded responses. Implemented on consumer-grade hardware, the system leverages Llama 3.2 and mxbai-embed-large-v1 embeddings for efficient retrieval and semantic representation. A case study of a proposed temporary nuclear waste storage site near Winslow, Arizona, demonstrates the framework's effectiveness. Results show the Regulatory Agent achieves consistently higher relevance scores in maintaining alignment with legal frameworks, while the Safety Agent effectively manages complex risk assessments requiring multifaceted analysis. The system demonstrates progressive improvement in agreement rates between agents across discussion rounds while semantic drift decreases, indicating enhanced decision-making consistency and response coherence. The system ensures regulatory decisions remain factually grounded, dynamically adapting to evolving regulatory frameworks through real-time document retrieval. By balancing automated assessment with human oversight, this framework offers a scalable and transparent approach to regulatory governance. These findings underscore the potential of AI-driven, multi-agent systems in advancing evidence-based, accountable, and adaptive decision-making for high-stakes environmental management scenarios.","authors":["Dongjune Chang","Sola Kim","Young Soo Park"],"url":"https://arxiv.org/abs/2505.21741"}
{"created":"2025-05-29","title":"What is Adversarial Training for Diffusion Models?","abstract":"We answer the question in the title, showing that adversarial training (AT) for diffusion models (DMs) fundamentally differs from classifiers: while AT in classifiers enforces output invariance, AT in DMs requires equivariance to keep the diffusion process aligned with the data distribution. AT is a way to enforce smoothness in the diffusion flow, improving robustness to outliers and corrupted data. Unlike prior art, our method makes no assumptions about the noise model and integrates seamlessly into diffusion training by adding random noise, similar to randomized smoothing, or adversarial noise, akin to AT. This enables intrinsic capabilities such as handling noisy data, dealing with extreme variability such as outliers, preventing memorization, and improving robustness. We rigorously evaluate our approach with proof-of-concept datasets with known distributions in low- and high-dimensional space, thereby taking a perfect measure of errors; we further evaluate on standard benchmarks such as CIFAR-10, CelebA and LSUN Bedroom, showing strong performance under severe noise, data corruption, and iterative adversarial attacks.","authors":["Briglia Maria Rosaria","Mujtaba Hussain Mirza","Giuseppe Lisanti","Iacopo Masi"],"url":"https://arxiv.org/abs/2505.21742"}
{"created":"2025-05-29","title":"Simulating the Unseen: Crash Prediction Must Learn from What Did Not Happen","abstract":"Traffic safety science has long been hindered by a fundamental data paradox: the crashes we most wish to prevent are precisely those events we rarely observe. Existing crash-frequency models and surrogate safety metrics rely heavily on sparse, noisy, and under-reported records, while even sophisticated, high-fidelity simulations undersample the long-tailed situations that trigger catastrophic outcomes such as fatalities. We argue that the path to achieving Vision Zero, i.e., the complete elimination of traffic fatalities and severe injuries, requires a paradigm shift from traditional crash-only learning to a new form of counterfactual safety learning: reasoning not only about what happened, but also about the vast set of plausible yet perilous scenarios that could have happened under slightly different circumstances. To operationalize this shift, our proposed agenda bridges macro to micro. Guided by crash-rate priors, generative scene engines, diverse driver models, and causal learning, near-miss events are synthesized and explained. A crash-focused digital twin testbed links micro scenes to macro patterns, while a multi-objective validator ensures that simulations maintain statistical realism. This pipeline transforms sparse crash data into rich signals for crash prediction, enabling the stress-testing of vehicles, roads, and policies before deployment. By learning from crashes that almost happened, we can shift traffic safety from reactive forensics to proactive prevention, advancing Vision Zero.","authors":["Zihao Li","Xinyuan Cao","Xiangbo Gao","Kexin Tian","Keshu Wu","Mohammad Anis","Hao Zhang","Keke Long","Jiwan Jiang","Xiaopeng Li","Yunlong Zhang","Tianbao Yang","Dominique Lord","Zhengzhong Tu","Yang Zhou"],"url":"https://arxiv.org/abs/2505.21743"}
{"created":"2025-05-29","title":"Computocene: Notes from an Age of Observation","abstract":"This piece plays with the idea of the Computocene: an era defined not merely by the ubiquity of computers, but by their deepening role in how we observe, interpret, and make sense of the world. Rather than emphasizing automation, speed, scale, or intelligence, computation is reframed as a mode of attention: filtering information, guiding inquiry, reframing questions, and shaping the very conditions under which knowledge emerges. I invite the reader to consider computers not simply as tools of calculation, but as epistemic instruments that participate in the formation of knowledge. This perspective reconfigures not only scientific practice but the epistemological foundations of understanding itself. The Computocene thus names a shift: from computation as calculation to computation as a form of attunement to the world. It is a speculative essay, offered without technical formality, and intended for a general, curious readership.","authors":["Simone Severini"],"url":"https://arxiv.org/abs/2505.21744"}
{"created":"2025-05-29","title":"Learning to See More: UAS-Guided Super-Resolution of Satellite Imagery for Precision Agriculture","abstract":"Unmanned Aircraft Systems (UAS) and satellites are key data sources for precision agriculture, yet each presents trade-offs. Satellite data offer broad spatial, temporal, and spectral coverage but lack the resolution needed for many precision farming applications, while UAS provide high spatial detail but are limited by coverage and cost, especially for hyperspectral data. This study presents a novel framework that fuses satellite and UAS imagery using super-resolution methods. By integrating data across spatial, spectral, and temporal domains, we leverage the strengths of both platforms cost-effectively. We use estimation of cover crop biomass and nitrogen (N) as a case study to evaluate our approach. By spectrally extending UAS RGB data to the vegetation red edge and near-infrared regions, we generate high-resolution Sentinel-2 imagery and improve biomass and N estimation accuracy by 18% and 31%, respectively. Our results show that UAS data need only be collected from a subset of fields and time points. Farmers can then 1) enhance the spectral detail of UAS RGB imagery; 2) increase the spatial resolution by using satellite data; and 3) extend these enhancements spatially and across the growing season at the frequency of the satellite flights. Our SRCNN-based spectral extension model shows considerable promise for model transferability over other cropping systems in the Upper and Lower Chesapeake Bay regions. Additionally, it remains effective even when cloud-free satellite data are unavailable, relying solely on the UAS RGB input. The spatial extension model produces better biomass and N predictions than models built on raw UAS RGB images. Once trained with targeted UAS RGB data, the spatial extension model allows farmers to stop repeated UAS flights. While we introduce super-resolution advances, the core contribution is a lightweight and scalable system for affordable on-farm use.","authors":["Arif Masrur","Peder A. Olsen","Paul R. Adler","Carlan Jackson","Matthew W. Myers","Nathan Sedghi","Ray R. Weil"],"url":"https://arxiv.org/abs/2505.21746"}
{"created":"2025-05-29","title":"Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks","abstract":"Complex systems are often driven by higher-order interactions among multiple units, naturally represented as hypergraphs. Understanding dependency structures within these hypergraphs is crucial for understanding and predicting the behavior of complex systems but is made challenging by their combinatorial complexity and computational demands. In this paper, we introduce a class of probabilistic models that efficiently represents and discovers a broad spectrum of mesoscale structure in large-scale hypergraphs. The key insight enabling this approach is to treat classes of similar units as themselves nodes in a latent hypergraph. By modeling observed node interactions through latent interactions among classes using low-rank representations, our approach tractably captures rich structural patterns while ensuring model identifiability. This allows for direct interpretation of distinct node- and class-level structures. Empirically, our model improves link prediction over state-of-the-art methods and discovers interpretable structures in diverse real-world systems, including pharmacological and social networks, advancing the ability to incorporate large-scale higher-order data into the scientific process.","authors":["John Hood","Caterina De Bacco","Aaron Schein"],"url":"https://arxiv.org/abs/2505.21748"}
{"created":"2025-05-29","title":"Revisiting Bi-Linear State Transitions in Recurrent Neural Networks","abstract":"The role of hidden units in recurrent neural networks is typically seen as modeling memory, with research focusing on enhancing information retention through gating mechanisms. A less explored perspective views hidden units as active participants in the computation performed by the network, rather than passive memory stores. In this work, we revisit bi-linear operations, which involve multiplicative interactions between hidden units and input embeddings. We demonstrate theoretically and empirically that they constitute a natural inductive bias for representing the evolution of hidden states in state tracking tasks. These are the simplest type of task that require hidden units to actively contribute to the behavior of the network. We also show that bi-linear state updates form a natural hierarchy corresponding to state tracking tasks of increasing complexity, with popular linear recurrent networks such as Mamba residing at the lowest-complexity center of that hierarchy.","authors":["M. Reza Ebrahimi","Roland Memisevic"],"url":"https://arxiv.org/abs/2505.21749"}
{"created":"2025-05-29","title":"Hierarchical Reinforcement Learning with Uncertainty-Guided Diffusional Subgoals","abstract":"Hierarchical reinforcement learning (HRL) learns to make decisions on multiple levels of temporal abstraction. A key challenge in HRL is that the low-level policy changes over time, making it difficult for the high-level policy to generate effective subgoals. To address this issue, the high-level policy must capture a complex subgoal distribution while also accounting for uncertainty in its estimates. We propose an approach that trains a conditional diffusion model regularized by a Gaussian Process (GP) prior to generate a complex variety of subgoals while leveraging principled GP uncertainty quantification. Building on this framework, we develop a strategy that selects subgoals from both the diffusion policy and GP's predictive mean. Our approach outperforms prior HRL methods in both sample efficiency and performance on challenging continuous control benchmarks.","authors":["Vivienne Huiling Wang","Tinghuai Wang","Joni Pajarinen"],"url":"https://arxiv.org/abs/2505.21750"}
{"created":"2025-05-29","title":"Ambient-aware continuous aid for mountain rescue activities","abstract":"Ambient-awareness in conjunction with pervasive computing is a significant challenge for system designers. It follows the necessity of gathering raw, massive and heterogeneous environmental data \\newrrr{which we} obtained, while middleware processes must merge context modelling and reasoning seamlessly. We proposed a system supporting mountain rescuers which is demanding due to the large number of environmental objects interacting, as well as high data variability. We presented complex context processing embedded in the proposed context life cycle and implemented it \\erarrr{following a proposed workflow for a demanding}\\newrrr{in a difficult} mountain environment. We introduced five weather scenarios which are a basis for contextual and perceptual processing during the validation of our model. The system \\erarrr{binds together} \\newrrr{merges} a message streaming broker for massive data transport, low and high-level processing algorithms, repositories and a logical SAT solver. It constitutes a Context-Aware-as-a-Service (CAaaS) system, offering advanced support for mountain rescue operations. The provided software model defines middleware components which act on a predicted context and transform in situ sensor data into smart decisions, and which could operate as a platform-based cloud computing model. It is an enabler yielding a synergy effect with different software components orchestration when providing pro-activeness and non-intrusiveness concerning smart decisions.","authors":["Radoslaw Klimek"],"url":"https://arxiv.org/abs/2505.21751"}
{"created":"2025-05-29","title":"Experimental Evidence That AI-Managed Workers Tolerate Lower Pay Without Demotivation","abstract":"Experimental evidence on worker responses to AI management remains mixed, partly due to limitations in experimental fidelity. We address these limitations with a customized workplace in the Minecraft platform, enabling high-resolution behavioral tracking of autonomous task execution, and ensuring that participants approach the task with well-formed expectations about their own competence. Workers (N = 382) completed repeated production tasks under either human, AI, or hybrid management. An AI manager trained on human-defined evaluation principles systematically assigned lower performance ratings and reduced wages by 40\\%, without adverse effects on worker motivation and sense of fairness. These effects were driven by a muted emotional response to AI evaluation, compared to evaluation by a human. The very features that make AI appear impartial may also facilitate silent exploitation, by suppressing the social reactions that normally constrain extractive practices in human-managed work.","authors":["Mengchen Dong","Levin Brinkmann","Omar Sherif","Shihan Wang","Xinyu Zhang","Jean-Fran\\c{c}ois Bonnefon","Iyad Rahwan"],"url":"https://arxiv.org/abs/2505.21752"}
{"created":"2025-05-29","title":"From prosthetic memory to prosthetic denial: Auditing whether large language models are prone to mass atrocity denialism","abstract":"The proliferation of large language models (LLMs) can influence how historical narratives are disseminated and perceived. This study explores the implications of LLMs' responses on the representation of mass atrocity memory, examining whether generative AI systems contribute to prosthetic memory, i.e., mediated experiences of historical events, or to what we term \"prosthetic denial,\" the AI-mediated erasure or distortion of atrocity memories. We argue that LLMs function as interfaces that can elicit prosthetic memories and, therefore, act as experiential sites for memory transmission, but also introduce risks of denialism, particularly when their outputs align with contested or revisionist narratives. To empirically assess these risks, we conducted a comparative audit of five LLMs (Claude, GPT, Llama, Mixtral, and Gemini) across four historical case studies: the Holodomor, the Holocaust, the Cambodian Genocide, and the genocide against the Tutsis in Rwanda. Each model was prompted with questions addressing common denialist claims in English and an alternative language relevant to each case (Ukrainian, German, Khmer, and French). Our findings reveal that while LLMs generally produce accurate responses for widely documented events like the Holocaust, significant inconsistencies and susceptibility to denialist framings are observed for more underrepresented cases like the Cambodian Genocide. The disparities highlight the influence of training data availability and the probabilistic nature of LLM responses on memory integrity. We conclude that while LLMs extend the concept of prosthetic memory, their unmoderated use risks reinforcing historical denialism, raising ethical concerns for (digital) memory preservation, and potentially challenging the advantageous role of technology associated with the original values of prosthetic memory.","authors":["Roberto Ulloa","Eve M. Zucker","Daniel Bultmann","David J. Simon","Mykola Makhortykh"],"url":"https://arxiv.org/abs/2505.21753"}
{"created":"2025-05-29","title":"Visual Loop Closure Detection Through Deep Graph Consensus","abstract":"Visual loop closure detection traditionally relies on place recognition methods to retrieve candidate loops that are validated using computationally expensive RANSAC-based geometric verification. As false positive loop closures significantly degrade downstream pose graph estimates, verifying a large number of candidates in online simultaneous localization and mapping scenarios is constrained by limited time and compute resources. While most deep loop closure detection approaches only operate on pairs of keyframes, we relax this constraint by considering neighborhoods of multiple keyframes when detecting loops. In this work, we introduce LoopGNN, a graph neural network architecture that estimates loop closure consensus by leveraging cliques of visually similar keyframes retrieved through place recognition. By propagating deep feature encodings among nodes of the clique, our method yields high-precision estimates while maintaining high recall. Extensive experimental evaluations on the TartanDrive 2.0 and NCLT datasets demonstrate that LoopGNN outperforms traditional baselines. Additionally, an ablation study across various keypoint extractors demonstrates that our method is robust, regardless of the type of deep feature encodings used, and exhibits higher computational efficiency compared to classical geometric verification baselines. We release our code, supplementary material, and keyframe data at https://loopgnn.cs.uni-freiburg.de.","authors":["Martin B\\\"uchner","Liza Dahiya","Simon Dorer","Vipul Ramtekkar","Kenji Nishimiya","Daniele Cattaneo","Abhinav Valada"],"url":"https://arxiv.org/abs/2505.21754"}
{"created":"2025-05-29","title":"FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering","abstract":"Visual question answering (VQA) systems face significant challenges when adapting to real-world data shifts, especially in multi-modal contexts. While robust fine-tuning strategies are essential for maintaining performance across in-distribution (ID) and out-of-distribution (OOD) scenarios, current evaluation settings are primarily unimodal or particular to some types of OOD, offering limited insight into the complexities of multi-modal contexts. In this work, we propose a new benchmark FRAMES-VQA (Fine-Tuning Robustness across Multi-Modal Shifts in VQA) for evaluating robust fine-tuning for VQA tasks. We utilize ten existing VQA benchmarks, including VQAv2, IV-VQA, VQA-CP, OK-VQA and others, and categorize them into ID, near and far OOD datasets covering uni-modal, multi-modal and adversarial distribution shifts. We first conduct a comprehensive comparison of existing robust fine-tuning methods. We then quantify the distribution shifts by calculating the Mahalanobis distance using uni-modal and multi-modal embeddings extracted from various models. Further, we perform an extensive analysis to explore the interactions between uni- and multi-modal shifts as well as modality importance for ID and OOD samples. These analyses offer valuable guidance on developing more robust fine-tuning methods to handle multi-modal distribution shifts. The code is available at https://github.com/chengyuehuang511/FRAMES-VQA .","authors":["Chengyue Huang","Brisa Maneechotesuwan","Shivang Chopra","Zsolt Kira"],"url":"https://arxiv.org/abs/2505.21755"}
{"created":"2025-05-29","title":"BehaviorSFT: Behavioral Token Conditioning for Clinical Agents Across the Proactivity Spectrum","abstract":"Large Language Models (LLMs) as clinical agents require careful behavioral adaptation. While adept at reactive tasks (e.g., diagnosis reasoning), LLMs often struggle with proactive engagement, like unprompted identification of critical missing information or risks. We introduce BehaviorBench, a comprehensive dataset to evaluate agent behaviors across a clinical assistance spectrum, ranging from reactive query responses to proactive interventions (e.g., clarifying ambiguities, flagging overlooked critical data). Our BehaviorBench experiments reveal LLMs' inconsistent proactivity. To address this, we propose BehaviorSFT, a novel training strategy using behavioral tokens to explicitly condition LLMs for dynamic behavioral selection along this spectrum. BehaviorSFT boosts performance, achieving up to 97.3% overall Macro F1 on BehaviorBench and improving proactive task scores (e.g., from 95.0% to 96.5% for Qwen2.5-7B-Ins). Crucially, blind clinician evaluations confirmed BehaviorSFT-trained agents exhibit more realistic clinical behavior, striking a superior balance between helpful proactivity (e.g., timely, relevant suggestions) and necessary restraint (e.g., avoiding over-intervention) versus standard fine-tuning or explicit instructed agents.","authors":["Yubin Kim","Zhiyuan Hu","Hyewon Jeong","Eugene Park","Shuyue Stella Li","Chanwoo Park","Shiyun Xiong","MingYu Lu","Hyeonhoon Lee","Xin Liu","Daniel McDuff","Cynthia Breazeal","Samir Tulebaev","Hae Won Park"],"url":"https://arxiv.org/abs/2505.21757"}
{"created":"2025-05-29","title":"Power-Capping Metric Evaluation for Improving Energy Efficiency","abstract":"With high-performance computing systems now running at exascale, optimizing power-scaling management and resource utilization has become more critical than ever. This paper explores runtime power-capping optimizations that leverage integrated CPU-GPU power management on architectures like the NVIDIA GH200 superchip. We evaluate energy-performance metrics that account for simultaneous CPU and GPU power-capping effects by using two complementary approaches: speedup-energy-delay and a Euclidean distance-based multi-objective optimization method. By targeting a mostly compute-bound exascale science application, the Locally Self-Consistent Multiple Scattering (LSMS), we explore challenging scenarios to identify potential opportunities for energy savings in exascale applications, and we recognize that even modest reductions in energy consumption can have significant overall impacts. Our results highlight how GPU task-specific dynamic power-cap adjustments combined with integrated CPU-GPU power steering can improve the energy utilization of certain GPU tasks, thereby laying the groundwork for future adaptive optimization strategies.","authors":["Maria Patrou","Thomas Wang","Wael Elwasif","Markus Eisenbach","Ross Miller","William Godoy","Oscar Hernandez"],"url":"https://arxiv.org/abs/2505.21758"}
{"created":"2025-05-29","title":"Don't Think Longer, Think Wisely: Optimizing Thinking Dynamics for Large Reasoning Models","abstract":"While recent success of large reasoning models (LRMs) significantly advanced LLMs' reasoning capability by optimizing the final answer accuracy using reinforcement learning, they may also drastically increase the output length due to overthinking, characterized by unnecessarily complex reasoning paths that waste computation and potentially degrade the performance. We hypothesize that such inefficiencies stem from LRMs' limited capability to dynamically select the proper modular reasoning strategies, termed thinking patterns at the right position. To investigate this hypothesis, we propose a dynamic optimization framework that segments model-generated reasoning paths into distinct thinking patterns, systematically identifying and promoting beneficial patterns that improve the answer while removing detrimental ones. Empirical analysis confirms that our optimized thinking paths yield more concise yet sufficiently informative trajectories, enhancing reasoning efficiency by reducing attention FLOPs by up to 47% while maintaining accuracy for originally correct responses. Moreover, a non-trivial portion of originally incorrect responses are transformed into correct ones, achieving a 15.6% accuracy improvement with reduced length. Motivated by the improvement brought by the optimized thinking paths, we apply a preference optimization technique supported by a pairwise dataset contrasting suboptimal and optimal reasoning paths. Experimental evaluations across multiple mathematical reasoning benchmarks reveal that our method notably reduces computational overhead while simultaneously improving reasoning accuracy, achieving up to a 12% accuracy improvement and reducing token usage from approximately 5,000 to 3,000 tokens.","authors":["Sohyun An","Ruochen Wang","Tianyi Zhou","Cho-Jui Hsieh"],"url":"https://arxiv.org/abs/2505.21765"}
{"created":"2025-05-29","title":"Video Streaming Over QUIC: A Comprehensive Study","abstract":"The QUIC transport protocol represents a significant evolution in web transport technologies, offering improved performance and reduced latency compared to traditional protocols like TCP. Given the growing number of QUIC implementations, understanding their performance, particularly in video streaming contexts, is essential. This paper presents a comprehensive analysis of various QUIC implementations, focusing on their congestion control (CC) performance in single-server, multi-client environments. Through extensive trace-driven experiments, we explore how different QUIC CCs impact adaptive bitrate (ABR) algorithms in two video streaming scenarios: video-on-demand (VoD) and low-latency live streaming (LLL). Our study aims to shed light on the impact of QUIC CC implementations, queuing strategies, and cooperative versus competitive dynamics of QUIC streams on user QoE under diverse network conditions. Our results demonstrate that identical CC algorithms across different QUIC implementations can lead to significant performance variations, directly impacting the QoE of video streaming sessions. These findings offer valuable insights into the effectiveness of various QUIC implementations and their implications for optimizing QoE, underscoring the need for intelligent cross-layer designs that integrate QUIC CC and ABR schemes to enhance overall streaming performance.","authors":["Jashanjot Singh Sidhu","Abdelhak Bentaleb"],"url":"https://arxiv.org/abs/2505.21769"}
{"created":"2025-05-29","title":"MMTBENCH: A Unified Benchmark for Complex Multimodal Table Reasoning","abstract":"Multimodal tables those that integrate semi structured data with visual elements such as charts and maps are ubiquitous across real world domains, yet they pose a formidable challenge to current vision language models (VLMs). While Large Language models (LLMs) and VLMs have demonstrated strong capabilities in text and image understanding, their performance on complex, real world multimodal table reasoning remains unexplored. To bridge this gap, we introduce MMTBENCH (Multimodal Table Benchmark), a benchmark consisting of 500 real world multimodal tables drawn from diverse real world sources, with a total of 4021 question answer pairs. MMTBENCH questions cover four question types (Explicit, Implicit, Answer Mention, and Visual Based), five reasoning types (Mathematical, Extrema Identification, Fact Verification, Vision Based, and Others), and eight table types (Single/Multiple Entity, Maps and Charts with Entities, Single/Multiple Charts, Maps, and Visualizations). Extensive evaluation of state of the art models on all types reveals substantial performance gaps, particularly on questions requiring visual-based reasoning and multi-step inference. These findings show the urgent need for improved architectures that more tightly integrate vision and language processing. By providing a challenging, high-quality resource that mirrors the complexity of real-world tasks, MMTBENCH underscores its value as a resource for future research on multimodal tables.","authors":["Prasham Yatinkumar Titiya","Jainil Trivedi","Chitta Baral","Vivek Gupta"],"url":"https://arxiv.org/abs/2505.21771"}
{"created":"2025-05-29","title":"Calibrating LLM Confidence by Probing Perturbed Representation Stability","abstract":"Miscalibration in Large Language Models (LLMs) undermines their reliability, highlighting the need for accurate confidence estimation. We introduce CCPS (Calibrating LLM Confidence by Probing Perturbed Representation Stability), a novel method analyzing internal representational stability in LLMs. CCPS applies targeted adversarial perturbations to final hidden states, extracts features reflecting the model's response to these perturbations, and uses a lightweight classifier to predict answer correctness. CCPS was evaluated on LLMs from 8B to 32B parameters (covering Llama, Qwen, and Mistral architectures) using MMLU and MMLU-Pro benchmarks in both multiple-choice and open-ended formats. Our results show that CCPS significantly outperforms current approaches. Across four LLMs and three MMLU variants, CCPS reduces Expected Calibration Error by approximately 55% and Brier score by 21%, while increasing accuracy by 5 percentage points, Area Under the Precision-Recall Curve by 4 percentage points, and Area Under the Receiver Operating Characteristic Curve by 6 percentage points, all relative to the strongest prior method. CCPS delivers an efficient, broadly applicable, and more accurate solution for estimating LLM confidence, thereby improving their trustworthiness.","authors":["Reza Khanmohammadi","Erfan Miahi","Mehrsa Mardikoraem","Simerjot Kaur","Ivan Brugere","Charese H. Smiley","Kundan Thind","Mohammad M. Ghassemi"],"url":"https://arxiv.org/abs/2505.21772"}
{"created":"2025-05-29","title":"DualSchool: How Reliable are LLMs for Optimization Education?","abstract":"Consider the following task taught in introductory optimization courses which addresses challenges articulated by the community at the intersection of (generative) AI and OR: generate the dual of a linear program. LLMs, being trained at web-scale, have the conversion process and many instances of Primal to Dual Conversion (P2DC) at their disposal. Students may thus reasonably expect that LLMs would perform well on the P2DC task. To assess this expectation, this paper introduces DualSchool, a comprehensive framework for generating and verifying P2DC instances. The verification procedure of DualSchool uses the Canonical Graph Edit Distance, going well beyond existing evaluation methods for optimization models, which exhibit many false positives and negatives when applied to P2DC. Experiments performed by DualSchool reveal interesting findings. Although LLMs can recite the conversion procedure accurately, state-of-the-art open LLMs fail to consistently produce correct duals. This finding holds even for the smallest two-variable instances and for derivative tasks, such as correctness, verification, and error classification. The paper also discusses the implications for educators, students, and the development of large reasoning systems.","authors":["Michael Klamkin","Arnaud Deza","Sikai Cheng","Haoruo Zhao","Pascal Van Hentenryck"],"url":"https://arxiv.org/abs/2505.21775"}
{"created":"2025-05-29","title":"Finite Element Methods for Elastic Contact: Penalty and Nitsche","abstract":"We consider two methods for treating elastic contact problems with the finite element method; the penalty method and Nitsche's method. For the penalty method we discuss how the penalty parameter should be chosen. Both the theoretical analysis and numerical examples show that an optimal convergence rate cannot be achieved. The method is contrasted to that of Nitsche which is optimally convergent. We also give the derivation of Nitsche's method by a very simple consistency correction of the penalty method.","authors":["Tom Gustafsson","Rolf Stenberg"],"url":"https://arxiv.org/abs/2505.21776"}
{"created":"2025-05-29","title":"Memorization to Generalization: Emergence of Diffusion Models from Associative Memory","abstract":"Hopfield networks are associative memory (AM) systems, designed for storing and retrieving patterns as local minima of an energy landscape. In the classical Hopfield model, an interesting phenomenon occurs when the amount of training data reaches its critical memory load $- spurious\\,\\,states$, or unintended stable points, emerge at the end of the retrieval dynamics, leading to incorrect recall. In this work, we examine diffusion models, commonly used in generative modeling, from the perspective of AMs. The training phase of diffusion model is conceptualized as memory encoding (training data is stored in the memory). The generation phase is viewed as an attempt of memory retrieval. In the small data regime the diffusion model exhibits a strong memorization phase, where the network creates distinct basins of attraction around each sample in the training set, akin to the Hopfield model below the critical memory load. In the large data regime, a different phase appears where an increase in the size of the training set fosters the creation of new attractor states that correspond to manifolds of the generated samples. Spurious states appear at the boundary of this transition and correspond to emergent attractor states, which are absent in the training set, but, at the same time, have distinct basins of attraction around them. Our findings provide: a novel perspective on the memorization-generalization phenomenon in diffusion models via the lens of AMs, theoretical prediction of existence of spurious states, empirical validation of this prediction in commonly-used diffusion models.","authors":["Bao Pham","Gabriel Raya","Matteo Negri","Mohammed J. Zaki","Luca Ambrogioni","Dmitry Krotov"],"url":"https://arxiv.org/abs/2505.21777"}
{"created":"2025-05-29","title":"Compositional Scene Understanding through Inverse Generative Modeling","abstract":"Generative models have demonstrated remarkable abilities in generating high-fidelity visual content. In this work, we explore how generative models can further be used not only to synthesize visual content but also to understand the properties of a scene given a natural image. We formulate scene understanding as an inverse generative modeling problem, where we seek to find conditional parameters of a visual generative model to best fit a given natural image. To enable this procedure to infer scene structure from images substantially different than those seen during training, we further propose to build this visual generative model compositionally from smaller models over pieces of a scene. We illustrate how this procedure enables us to infer the set of objects in a scene, enabling robust generalization to new test scenes with an increased number of objects of new shapes. We further illustrate how this enables us to infer global scene factors, likewise enabling robust generalization to new scenes. Finally, we illustrate how this approach can be directly applied to existing pretrained text-to-image generative models for zero-shot multi-object perception. Code and visualizations are at \\href{https://energy-based-model.github.io/compositional-inference}{https://energy-based-model.github.io/compositional-inference}.","authors":["Yanbo Wang","Justin Dauwels","Yilun Du"],"url":"https://arxiv.org/abs/2505.21780"}
{"created":"2025-05-29","title":"GMU Systems for the IWSLT 2025 Low-Resource Speech Translation Shared Task","abstract":"This paper describes the GMU systems for the IWSLT 2025 low-resource speech translation shared task. We trained systems for all language pairs, except for Levantine Arabic. We fine-tuned SeamlessM4T-v2 for automatic speech recognition (ASR), machine translation (MT), and end-to-end speech translation (E2E ST). The ASR and MT models are also used to form cascaded ST systems. Additionally, we explored various training paradigms for E2E ST fine-tuning, including direct E2E fine-tuning, multi-task training, and parameter initialization using components from fine-tuned ASR and/or MT models. Our results show that (1) direct E2E fine-tuning yields strong results; (2) initializing with a fine-tuned ASR encoder improves ST performance on languages SeamlessM4T-v2 has not been trained on; (3) multi-task training can be slightly helpful.","authors":["Chutong Meng","Antonios Anastasopoulos"],"url":"https://arxiv.org/abs/2505.21781"}
{"created":"2025-05-29","title":"P-DROP: Poisson-Based Dropout for Graph Neural Networks","abstract":"Over-smoothing remains a major challenge in Graph Neural Networks (GNNs), where repeated message passing causes node representations to converge and lose discriminative power. To address this, we propose a novel node selection strategy based on Poisson processes, introducing stochastic but structure-aware updates. Specifically, we equip each node with an independent Poisson clock, enabling asynchronous and localized updates that preserve structural diversity. We explore two applications of this strategy: as a replacement for dropout-based regularization and as a dynamic subgraph training scheme. Experimental results on standard benchmarks (Cora, Citeseer, Pubmed) demonstrate that our Poisson-based method yields competitive or improved accuracy compared to traditional Dropout, DropEdge, and DropNode approaches, particularly in later training stages.","authors":["Hyunsik Yun"],"url":"https://arxiv.org/abs/2505.21783"}
{"created":"2025-05-29","title":"Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation","abstract":"Safety reasoning is a recent paradigm where LLMs reason over safety policies before generating responses, thereby mitigating limitations in existing safety measures such as over-refusal and jailbreak vulnerabilities. However, implementing this paradigm is challenging due to the resource-intensive process of creating high-quality policy-embedded chain-of-thought (CoT) datasets while ensuring reasoning remains accurate and free from hallucinations or policy conflicts. To tackle this, we propose AIDSAFE: Agentic Iterative Deliberation for Safety Reasoning, a novel data generation recipe that leverages multi-agent deliberation to iteratively expand reasoning on safety policies. A data refiner stage in AIDSAFE ensures high-quality outputs by eliminating repetitive, redundant, and deceptive thoughts. AIDSAFE-generated CoTs provide a strong foundation for supervised fine-tuning (SFT)-based safety training. Additionally, to address the need of preference data in alignment stages, such as DPO training, we introduce a supplemental recipe that uses belief augmentation to create distinct selected and rejected CoT samples. Our evaluations demonstrate that AIDSAFE-generated CoTs achieve superior policy adherence and reasoning quality. Consequently, we show that fine-tuning open-source LLMs on these CoTs can significantly improve safety generalization and jailbreak robustness while maintaining acceptable utility and over-refusal accuracy. AIDSAFE-generated CoT datasets can be found here: https://huggingface.co/datasets/AmazonScience/AIDSAFE","authors":["Tharindu Kumarage","Ninareh Mehrabi","Anil Ramakrishna","Xinyan Zhao","Richard Zemel","Kai-Wei Chang","Aram Galstyan","Rahul Gupta","Charith Peris"],"url":"https://arxiv.org/abs/2505.21784"}
{"created":"2025-05-29","title":"Born a Transformer -- Always a Transformer?","abstract":"Transformers have theoretical limitations in modeling certain sequence-to-sequence tasks, yet it remains largely unclear if these limitations play a role in large-scale pretrained LLMs, or whether LLMs might effectively overcome these constraints in practice due to the scale of both the models themselves and their pretraining data. We explore how these architectural constraints manifest after pretraining, by studying a family of $\\textit{retrieval}$ and $\\textit{copying}$ tasks inspired by Liu et al. [2024]. We use the recently proposed C-RASP framework for studying length generalization [Huang et al., 2025b] to provide guarantees for each of our settings. Empirically, we observe an $\\textit{induction-versus-anti-induction}$ asymmetry, where pretrained models are better at retrieving tokens to the right (induction) rather than the left (anti-induction) of a query token. This asymmetry disappears upon targeted fine-tuning if length-generalization is guaranteed by theory. Mechanistic analysis reveals that this asymmetry is connected to the differences in the strength of induction versus anti-induction circuits within pretrained Transformers. We validate our findings through practical experiments on real-world tasks demonstrating reliability risks. Our results highlight that pretraining selectively enhances certain Transformer capabilities, but does not overcome fundamental length-generalization limits.","authors":["Yana Veitsman","Mayank Jobanputra","Yash Sarrof","Aleksandra Bakalova","Vera Demberg","Ellie Pavlick","Michael Hahn"],"url":"https://arxiv.org/abs/2505.21785"}
{"created":"2025-05-29","title":"VeriTrail: Closed-Domain Hallucination Detection with Traceability","abstract":"Even when instructed to adhere to source material, Language Models often generate unsubstantiated content - a phenomenon known as \"closed-domain hallucination.\" This risk is amplified in processes with multiple generative steps (MGS), compared to processes with a single generative step (SGS). However, due to the greater complexity of MGS processes, we argue that detecting hallucinations in their final outputs is necessary but not sufficient: it is equally important to trace where hallucinated content was likely introduced and how faithful content may have been derived from the source through intermediate outputs. To address this need, we present VeriTrail, the first closed-domain hallucination detection method designed to provide traceability for both MGS and SGS processes. We also introduce the first datasets to include all intermediate outputs as well as human annotations of final outputs' faithfulness for their respective MGS processes. We demonstrate that VeriTrail outperforms baseline methods on both datasets.","authors":["Dasha Metropolitansky","Jonathan Larson"],"url":"https://arxiv.org/abs/2505.21786"}
{"created":"2025-05-29","title":"Faster Rates for Private Adversarial Bandits","abstract":"We design new differentially private algorithms for the problems of adversarial bandits and bandits with expert advice. For adversarial bandits, we give a simple and efficient conversion of any non-private bandit algorithm to a private bandit algorithm. Instantiating our conversion with existing non-private bandit algorithms gives a regret upper bound of $O\\left(\\frac{\\sqrt{KT}}{\\sqrt{\\epsilon}}\\right)$, improving upon the existing upper bound $O\\left(\\frac{\\sqrt{KT \\log(KT)}}{\\epsilon}\\right)$ for all $\\epsilon \\leq 1$. In particular, our algorithms allow for sublinear expected regret even when $\\epsilon \\leq \\frac{1}{\\sqrt{T}}$, establishing the first known separation between central and local differential privacy for this problem. For bandits with expert advice, we give the first differentially private algorithms, with expected regret $O\\left(\\frac{\\sqrt{NT}}{\\sqrt{\\epsilon}}\\right), O\\left(\\frac{\\sqrt{KT\\log(N)}\\log(KT)}{\\epsilon}\\right)$, and $\\tilde{O}\\left(\\frac{N^{1/6}K^{1/2}T^{2/3}\\log(NT)}{\\epsilon ^{1/3}} + \\frac{N^{1/2}\\log(NT)}{\\epsilon}\\right)$, where $K$ and $N$ are the number of actions and experts respectively. These rates allow us to get sublinear regret for different combinations of small and large $K, N$ and $\\epsilon.$","authors":["Hilal Asi","Vinod Raman","Kunal Talwar"],"url":"https://arxiv.org/abs/2505.21790"}
{"created":"2025-05-29","title":"Multimodal Federated Learning: A Survey through the Lens of Different FL Paradigms","abstract":"Multimodal Federated Learning (MFL) lies at the intersection of two pivotal research areas: leveraging complementary information from multiple modalities to improve downstream inference performance and enabling distributed training to enhance efficiency and preserve privacy. Despite the growing interest in MFL, there is currently no comprehensive taxonomy that organizes MFL through the lens of different Federated Learning (FL) paradigms. This perspective is important because multimodal data introduces distinct challenges across various FL settings. These challenges, including modality heterogeneity, privacy heterogeneity, and communication inefficiency, are fundamentally different from those encountered in traditional unimodal or non-FL scenarios. In this paper, we systematically examine MFL within the context of three major FL paradigms: horizontal FL (HFL), vertical FL (VFL), and hybrid FL. For each paradigm, we present the problem formulation, review representative training algorithms, and highlight the most prominent challenge introduced by multimodal data in distributed settings. We also discuss open challenges and provide insights for future research. By establishing this taxonomy, we aim to uncover the novel challenges posed by multimodal data from the perspective of different FL paradigms and to offer a new lens through which to understand and advance the development of MFL.","authors":["Yuanzhe Peng","Jieming Bian","Lei Wang","Yin Huang","Jie Xu"],"url":"https://arxiv.org/abs/2505.21792"}
{"created":"2025-05-29","title":"Convergent Anthropocene Systems-of-Systems: Overcoming the Limitations of System Dynamics with Hetero-functional Graph Theory","abstract":"Understanding the complexity and interdependence of systems in the Anthropocene is essential for making informed decisions about societal challenges spanning geophysical, biophysical, sociocultural, and sociotechnical domains. This paper explores the potential of Hetero-functional Graph Theory (HFGT) as a quantification tool for converting Model-based Systems Engineering (MBSE), stated in the Systems Modeling Language (SysML), into dynamic simulations-offering a comprehensive alternative to System Dynamics (SD) for representing interdependent systems of systems in the Anthropocene. The two approaches are compared in terms of systems thinking abstractions, methodological flexibility, and their ability to represent dynamic, multi-functional systems. Through a comparative study, the Mono Lake system is simulated in Northern California using both SD, and MBSE and HFGT, to highlight technical, conceptual and analytical differences. The simulations show equivalent results. However, MBSE and HFGT provide distinct advantages in capturing the nuances of the system through a broader set of systems thinking abstractions and in managing adaptive, multi-functional system interactions. These strengths position MBSE and HFGT as a powerful and flexible approach for representing, modeling, analyzing, and simulating heterogeneous and complex systems-of-systems in the Anthropocene.","authors":["Mohammad Mahdi Naderi","Megan Harris","Ehsanoddin Ghorbanichemazkati","John C. Little","Amro M. Farid"],"url":"https://arxiv.org/abs/2505.21793"}
{"created":"2025-05-29","title":"SANSA: Unleashing the Hidden Semantics in SAM2 for Few-Shot Segmentation","abstract":"Few-shot segmentation aims to segment unseen object categories from just a handful of annotated examples. This requires mechanisms that can both identify semantically related objects across images and accurately produce segmentation masks. We note that Segment Anything 2 (SAM2), with its prompt-and-propagate mechanism, offers both strong segmentation capabilities and a built-in feature matching process. However, we show that its representations are entangled with task-specific cues optimized for object tracking, which impairs its use for tasks requiring higher level semantic understanding. Our key insight is that, despite its class-agnostic pretraining, SAM2 already encodes rich semantic structure in its features. We propose SANSA (Semantically AligNed Segment Anything 2), a framework that makes this latent structure explicit, and repurposes SAM2 for few-shot segmentation through minimal task-specific modifications. SANSA achieves state-of-the-art performance on few-shot segmentation benchmarks specifically designed to assess generalization, outperforms generalist methods in the popular in-context setting, supports various prompts flexible interaction via points, boxes, or scribbles, and remains significantly faster and more compact than prior approaches. Code is available at https://github.com/ClaudiaCuttano/SANSA.","authors":["Claudia Cuttano","Gabriele Trivigno","Giuseppe Averta","Carlo Masone"],"url":"https://arxiv.org/abs/2505.21795"}
{"created":"2025-05-29","title":"From Directions to Cones: Exploring Multidimensional Representations of Propositional Facts in LLMs","abstract":"Large Language Models (LLMs) exhibit strong conversational abilities but often generate falsehoods. Prior work suggests that the truthfulness of simple propositions can be represented as a single linear direction in a model's internal activations, but this may not fully capture its underlying geometry. In this work, we extend the concept cone framework, recently introduced for modeling refusal, to the domain of truth. We identify multi-dimensional cones that causally mediate truth-related behavior across multiple LLM families. Our results are supported by three lines of evidence: (i) causal interventions reliably flip model responses to factual statements, (ii) learned cones generalize across model architectures, and (iii) cone-based interventions preserve unrelated model behavior. These findings reveal the richer, multidirectional structure governing simple true/false propositions in LLMs and highlight concept cones as a promising tool for probing abstract behaviors.","authors":["Stanley Yu","Vaidehi Bulusu","Oscar Yasunaga","Clayton Lau","Cole Blondin","Sean O'Brien","Kevin Zhu","Vasu Sharma"],"url":"https://arxiv.org/abs/2505.21800"}
{"created":"2025-05-29","title":"Query, Don't Train: Privacy-Preserving Tabular Prediction from EHR Data via SQL Queries","abstract":"Electronic health records (EHRs) contain richly structured, longitudinal data essential for predictive modeling, yet stringent privacy regulations (e.g., HIPAA, GDPR) often restrict access to individual-level records. We introduce Query, Don't Train (QDT): a structured-data foundation-model interface enabling tabular inference via LLM-generated SQL over EHRs. Instead of training on or accessing individual-level examples, QDT uses a large language model (LLM) as a schema-aware query planner to generate privacy-compliant SQL queries from a natural language task description and a test-time input. The model then extracts summary-level population statistics through these SQL queries and the LLM performs, chain-of-thought reasoning over the results to make predictions. This inference-time-only approach (1) eliminates the need for supervised model training or direct data access, (2) ensures interpretability through symbolic, auditable queries, (3) naturally handles missing features without imputation or preprocessing, and (4) effectively manages high-dimensional numerical data to enhance analytical capabilities. We validate QDT on the task of 30-day hospital readmission prediction for Type 2 diabetes patients using a MIMIC-style EHR cohort, achieving F1 = 0.70, which outperforms TabPFN (F1 = 0.68). To our knowledge, this is the first demonstration of LLM-driven, privacy-preserving structured prediction using only schema metadata and aggregate statistics - offering a scalable, interpretable, and regulation-compliant alternative to conventional foundation-model pipelines.","authors":["Josefa Lia Stoisser","Marc Boubnovski Martell","Kaspar M\\\"artens","Lawrence Phillips","Stephen Michael Town","Rory Donovan-Maiye","Julien Fauqueur"],"url":"https://arxiv.org/abs/2505.21801"}
{"created":"2025-05-29","title":"An Investigation on Speaker Augmentation for End-to-End Speaker Extraction","abstract":"Target confusion, defined as occasional switching to non-target speakers, poses a key challenge for end-to-end speaker extraction (E2E-SE) systems. We argue that this problem is largely caused by the lack of generalizability and discrimination of the speaker embeddings, and introduce a simple yet effective speaker augmentation strategy to tackle the problem. Specifically, we propose a time-domain resampling and rescaling pipeline that alters speaker traits while preserving other speech properties. This generates a variety of pseudo-speakers to help establish a generalizable speaker embedding space, while the speaker-trait-specific augmentation creates hard samples that force the model to focus on genuine speaker characteristics. Experiments on WSJ0-2Mix and LibriMix show that our method mitigates the target confusion and improves extraction performance. Moreover, it can be combined with metric learning, another effective approach to address target confusion, leading to further gains.","authors":["Zhenghai You","Zhenyu Zhou","Lantian Li","Dong Wang"],"url":"https://arxiv.org/abs/2505.21805"}
{"created":"2025-05-29","title":"Towards Operational Automated Greenhouse Gas Plume Detection","abstract":"Operational deployment of a fully automated greenhouse gas (GHG) plume detection system remains an elusive goal for imaging spectroscopy missions, despite recent advances in deep learning approaches. With the dramatic increase in data availability, however, automation continues to increase in importance for natural and anthropogenic emissions monitoring. This work reviews and addresses several key obstacles in the field: data and label quality control, prevention of spatiotemporal biases, and correctly aligned modeling objectives. We demonstrate through rigorous experiments using multicampaign data from airborne and spaceborne instruments that convolutional neural networks (CNNs) are able to achieve operational detection performance when these obstacles are alleviated. We demonstrate that a multitask model that learns both instance detection and pixelwise segmentation simultaneously can successfully lead towards an operational pathway. We evaluate the model's plume detectability across emission source types and regions, identifying thresholds for operational deployment. Finally, we provide analysis-ready data, models, and source code for reproducibility, and work to define a set of best practices and validation standards to facilitate future contributions to the field.","authors":["Brian D. Bue","Jake H. Lee","Andrew K. Thorpe","Philip G. Brodrick","Daniel Cusworth","Alana Ayasse","Vassiliki Mancoridis","Anagha Satish","Shujun Xiong","Riley Duren"],"url":"https://arxiv.org/abs/2505.21806"}
{"created":"2025-05-29","title":"TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction","abstract":"Predictive modeling on tabular data is the cornerstone of many real-world applications. Although gradient boosting machines and some recent deep models achieve strong performance on tabular data, they often lack interpretability. On the other hand, large language models (LLMs) have demonstrated powerful capabilities to generate human-like reasoning and explanations, but remain under-performed for tabular data prediction. In this paper, we propose a new approach that leverages reasoning-based LLMs, trained using reinforcement learning, to perform more accurate and explainable predictions on tabular data. Our method introduces custom reward functions that guide the model not only toward high prediction accuracy but also toward human-understandable reasons for its predictions. Experimental results show that our model achieves promising performance on financial benchmark datasets, outperforming most existing LLMs.","authors":["Tommy Xu","Zhitian Zhang","Xiangyu Sun","Lauren Kelly Zung","Hossein Hajimirsadeghi","Greg Mori"],"url":"https://arxiv.org/abs/2505.21807"}
{"created":"2025-05-29","title":"AI Agent Governance: A Field Guide","abstract":"This report serves as an accessible guide to the emerging field of AI agent governance. Agents - AI systems that can autonomously achieve goals in the world, with little to no explicit human instruction about how to do so - are a major focus of leading tech companies, AI start-ups, and investors. If these development efforts are successful, some industry leaders claim we could soon see a world where millions or billions of agents autonomously perform complex tasks across society. Society is largely unprepared for this development. A future where capable agents are deployed en masse could see transformative benefits to society but also profound and novel risks. Currently, the exploration of agent governance questions and the development of associated interventions remain in their infancy. Only a few researchers, primarily in civil society organizations, public research institutes, and frontier AI companies, are actively working on these challenges.","authors":["Jam Kraprayoon","Zoe Williams","Rida Fayyaz"],"url":"https://arxiv.org/abs/2505.21808"}
{"created":"2025-05-29","title":"Voice Quality Dimensions as Interpretable Primitives for Speaking Style for Atypical Speech and Affect","abstract":"Perceptual voice quality dimensions describe key characteristics of atypical speech and other speech modulations. Here we develop and evaluate voice quality models for seven voice and speech dimensions (intelligibility, imprecise consonants, harsh voice, naturalness, monoloudness, monopitch, and breathiness). Probes were trained on the public Speech Accessibility (SAP) project dataset with 11,184 samples from 434 speakers, using embeddings from frozen pre-trained models as features. We found that our probes had both strong performance and strong generalization across speech elicitation categories in the SAP dataset. We further validated zero-shot performance on additional datasets, encompassing unseen languages and tasks: Italian atypical speech, English atypical speech, and affective speech. The strong zero-shot performance and the interpretability of results across an array of evaluations suggests the utility of using voice quality dimensions in speaking style-related tasks.","authors":["Jaya Narain","Vasudha Kowtha","Colin Lea","Lauren Tooley","Dianna Yee","Vikramjit Mitra","Zifang Huang","Miquel Espi Marques","Jon Huang","Carlos Avendano","Shirley Ren"],"url":"https://arxiv.org/abs/2505.21809"}
{"created":"2025-05-29","title":"Revisiting Self-attention for Cross-domain Sequential Recommendation","abstract":"Sequential recommendation is a popular paradigm in modern recommender systems. In particular, one challenging problem in this space is cross-domain sequential recommendation (CDSR), which aims to predict future behaviors given user interactions across multiple domains. Existing CDSR frameworks are mostly built on the self-attention transformer and seek to improve by explicitly injecting additional domain-specific components (e.g. domain-aware module blocks). While these additional components help, we argue they overlook the core self-attention module already present in the transformer, a naturally powerful tool to learn correlations among behaviors. In this work, we aim to improve the CDSR performance for simple models from a novel perspective of enhancing the self-attention. Specifically, we introduce a Pareto-optimal self-attention and formulate the cross-domain learning as a multi-objective problem, where we optimize the recommendation task while dynamically minimizing the cross-domain attention scores. Our approach automates knowledge transfer in CDSR (dubbed as AutoCDSR) -- it not only mitigates negative transfer but also encourages complementary knowledge exchange among auxiliary domains. Based on the idea, we further introduce AutoCDSR+, a more performant variant with slight additional cost. Our proposal is easy to implement and works as a plug-and-play module that can be incorporated into existing transformer-based recommenders. Besides flexibility, it is practical to deploy because it brings little extra computational overheads without heavy hyper-parameter tuning. AutoCDSR on average improves Recall@10 for SASRec and Bert4Rec by 9.8% and 16.0% and NDCG@10 by 12.0% and 16.7%, respectively. Code is available at https://github.com/snap-research/AutoCDSR.","authors":["Clark Mingxuan Ju","Leonardo Neves","Bhuvesh Kumar","Liam Collins","Tong Zhao","Yuwei Qiu","Qing Dou","Sohail Nizam","Sen Yang","Neil Shah"],"url":"https://arxiv.org/abs/2505.21811"}
{"created":"2025-05-29","title":"Optimizing Data Augmentation through Bayesian Model Selection","abstract":"Data Augmentation (DA) has become an essential tool to improve robustness and generalization of modern machine learning. However, when deciding on DA strategies it is critical to choose parameters carefully, and this can be a daunting task which is traditionally left to trial-and-error or expensive optimization based on validation performance. In this paper, we counter these limitations by proposing a novel framework for optimizing DA. In particular, we take a probabilistic view of DA, which leads to the interpretation of augmentation parameters as model (hyper)-parameters, and the optimization of the marginal likelihood with respect to these parameters as a Bayesian model selection problem. Due to its intractability, we derive a tractable Evidence Lower BOund (ELBO), which allows us to optimize augmentation parameters jointly with model parameters. We provide extensive theoretical results on variational approximation quality, generalization guarantees, invariance properties, and connections to empirical Bayes. Through experiments on computer vision tasks, we show that our approach improves calibration and yields robust performance over fixed or no augmentation. Our work provides a rigorous foundation for optimizing DA through Bayesian principles with significant potential for robust machine learning.","authors":["Madi Matymov (KAUST)","Ba-Hien Tran (Huawei Paris Research Center)","Michael Kampffmeyer (UiT The Arctic University of Norway","Norwegian Computing Center)","Markus Heinonen (Aalto University)","Maurizio Filippone (KAUST)"],"url":"https://arxiv.org/abs/2505.21813"}
{"created":"2025-05-29","title":"Scientific Paper Retrieval with LLM-Guided Semantic-Based Ranking","abstract":"Scientific paper retrieval is essential for supporting literature discovery and research. While dense retrieval methods demonstrate effectiveness in general-purpose tasks, they often fail to capture fine-grained scientific concepts that are essential for accurate understanding of scientific queries. Recent studies also use large language models (LLMs) for query understanding; however, these methods often lack grounding in corpus-specific knowledge and may generate unreliable or unfaithful content. To overcome these limitations, we propose SemRank, an effective and efficient paper retrieval framework that combines LLM-guided query understanding with a concept-based semantic index. Each paper is indexed using multi-granular scientific concepts, including general research topics and detailed key phrases. At query time, an LLM identifies core concepts derived from the corpus to explicitly capture the query's information need. These identified concepts enable precise semantic matching, significantly enhancing retrieval accuracy. Experiments show that SemRank consistently improves the performance of various base retrievers, surpasses strong existing LLM-based baselines, and remains highly efficient.","authors":["Yunyi Zhang","Ruozhen Yang","Siqi Jiao","SeongKu Kang","Jiawei Han"],"url":"https://arxiv.org/abs/2505.21815"}
{"created":"2025-05-29","title":"Revisiting Common Assumptions about Arabic Dialects in NLP","abstract":"Arabic has diverse dialects, where one dialect can be substantially different from the others. In the NLP literature, some assumptions about these dialects are widely adopted (e.g., ``Arabic dialects can be grouped into distinguishable regional dialects\") and are manifested in different computational tasks such as Arabic Dialect Identification (ADI). However, these assumptions are not quantitatively verified. We identify four of these assumptions and examine them by extending and analyzing a multi-label dataset, where the validity of each sentence in 11 different country-level dialects is manually assessed by speakers of these dialects. Our analysis indicates that the four assumptions oversimplify reality, and some of them are not always accurate. This in turn might be hindering further progress in different Arabic NLP tasks.","authors":["Amr Keleg","Sharon Goldwater","Walid Magdy"],"url":"https://arxiv.org/abs/2505.21816"}
{"created":"2025-05-29","title":"ALTER: All-in-One Layer Pruning and Temporal Expert Routing for Efficient Diffusion Generation","abstract":"Diffusion models have demonstrated exceptional capabilities in generating high-fidelity images. However, their iterative denoising process results in significant computational overhead during inference, limiting their practical deployment in resource-constrained environments. Existing acceleration methods often adopt uniform strategies that fail to capture the temporal variations during diffusion generation, while the commonly adopted sequential pruning-then-fine-tuning strategy suffers from sub-optimality due to the misalignment between pruning decisions made on pretrained weights and the model's final parameters. To address these limitations, we introduce ALTER: All-in-One Layer Pruning and Temporal Expert Routing, a unified framework that transforms diffusion models into a mixture of efficient temporal experts. ALTER achieves a single-stage optimization that unifies layer pruning, expert routing, and model fine-tuning by employing a trainable hypernetwork, which dynamically generates layer pruning decisions and manages timestep routing to specialized, pruned expert sub-networks throughout the ongoing fine-tuning of the UNet. This unified co-optimization strategy enables significant efficiency gains while preserving high generative quality. Specifically, ALTER achieves same-level visual fidelity to the original 50-step Stable Diffusion v2.1 model while utilizing only 25.9% of its total MACs with just 20 inference steps and delivering a 3.64x speedup through 35% sparsity.","authors":["Xiaomeng Yang","Lei Lu","Qihui Fan","Changdi Yang","Juyi Lin","Yanzhi Wang","Xuan Zhang","Shangqian Gao"],"url":"https://arxiv.org/abs/2505.21817"}
{"created":"2025-05-29","title":"Learning-Based Tracking Perimeter Control for Two-region Macroscopic Traffic Dynamics","abstract":"Leveraging the concept of the macroscopic fundamental diagram (MFD), perimeter control can alleviate network-level congestion by identifying critical intersections and regulating them effectively. Considering the time-varying nature of travel demand and the equilibrium of accumulation state, we extend the conventional set-point perimeter control (SPC) problem for the two-region MFD system as an optimal tracking perimeter control problem (OTPCP). Unlike the SPC schemes that stabilize the traffic dynamics to the desired equilibrium point, the proposed tracking perimeter control (TPC) scheme regulates the traffic dynamics to a desired trajectory in a differential framework. Due to the inherent network uncertainties, such as heterogeneity of traffic dynamics and demand disturbance, the system dynamics could be uncertain or even unknown. To address these issues, we propose an adaptive dynamic programming (ADP) approach to solving the OTPCP without utilizing the well-calibrated system dynamics. Numerical experiments demonstrate the effectiveness of the proposed ADP-based TPC. Compared with the SPC scheme, the proposed TPC scheme achieves a 20.01% reduction in total travel time and a 3.15% improvement in cumulative trip completion. Moreover, the proposed adaptive TPC approach can regulate the accumulation state under network uncertainties and demand disturbances to the desired time-varying equilibrium trajectory that aims to maximize the trip completion under a nominal demand pattern. These results validate the robustness of the adaptive TPC approach.","authors":["Can Chen","Yunping Huang","Hongwei Zhang","Shimin Wang","Martin Guay","Shu-Chien Hsu","Renxin Zhong"],"url":"https://arxiv.org/abs/2505.21818"}
{"created":"2025-05-29","title":"Representative Language Generation","abstract":"We introduce \"representative generation,\" extending the theoretical framework for generation proposed by Kleinberg et al. (2024) and formalized by Li et al. (2024), to additionally address diversity and bias concerns in generative models. Our notion requires outputs of a generative model to proportionally represent groups of interest from the training data. We characterize representative uniform and non-uniform generation, introducing the \"group closure dimension\" as a key combinatorial quantity. For representative generation in the limit, we analyze both information-theoretic and computational aspects, demonstrating feasibility for countably infinite hypothesis classes and collections of groups under certain conditions, but proving a negative result for computability using only membership queries. This contrasts with Kleinberg et al.'s (2024) positive results for standard generation in the limit. Our findings provide a rigorous foundation for developing more diverse and representative generative models.","authors":["Charlotte Peale","Vinod Raman","Omer Reingold"],"url":"https://arxiv.org/abs/2505.21819"}
{"created":"2025-05-29","title":"Unsupervised Latent Pattern Analysis for Estimating Type 2 Diabetes Risk in Undiagnosed Populations","abstract":"The global prevalence of diabetes, particularly type 2 diabetes mellitus (T2DM), is rapidly increasing, posing significant health and economic challenges. T2DM not only disrupts blood glucose regulation but also damages vital organs such as the heart, kidneys, eyes, nerves, and blood vessels, leading to substantial morbidity and mortality. In the US alone, the economic burden of diagnosed diabetes exceeded \\$400 billion in 2022. Early detection of individuals at risk is critical to mitigating these impacts. While machine learning approaches for T2DM prediction are increasingly adopted, many rely on supervised learning, which is often limited by the lack of confirmed negative cases. To address this limitation, we propose a novel unsupervised framework that integrates Non-negative Matrix Factorization (NMF) with statistical techniques to identify individuals at risk of developing T2DM. Our method identifies latent patterns of multimorbidity and polypharmacy among diagnosed T2DM patients and applies these patterns to estimate the T2DM risk in undiagnosed individuals. By leveraging data-driven insights from comorbidity and medication usage, our approach provides an interpretable and scalable solution that can assist healthcare providers in implementing timely interventions, ultimately improving patient outcomes and potentially reducing the future health and economic burden of T2DM.","authors":["Praveen Kumar","Vincent T. Metzger","Scott A. Malec"],"url":"https://arxiv.org/abs/2505.21824"}
{"created":"2025-05-29","title":"Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones","abstract":"Inference-time computation has emerged as a promising scaling axis for improving large language model reasoning. However, despite yielding impressive performance, the optimal allocation of inference-time computation remains poorly understood. A central question is whether to prioritize sequential scaling (e.g., longer chains of thought) or parallel scaling (e.g., majority voting across multiple short chains of thought). In this work, we seek to illuminate the landscape of test-time scaling by demonstrating the existence of reasoning settings where sequential scaling offers an exponential advantage over parallel scaling. These settings are based on graph connectivity problems in challenging distributions of graphs. We validate our theoretical findings with comprehensive experiments across a range of language models, including models trained from scratch for graph connectivity with different chain of thought strategies as well as large reasoning models.","authors":["Parsa Mirtaheri","Ezra Edelman","Samy Jelassi","Eran Malach","Enric Boix-Adsera"],"url":"https://arxiv.org/abs/2505.21825"}
{"created":"2025-05-29","title":"Music Source Restoration","abstract":"We introduce Music Source Restoration (MSR), a novel task addressing the gap between idealized source separation and real-world music production. Current Music Source Separation (MSS) approaches assume mixtures are simple sums of sources, ignoring signal degradations employed during music production like equalization, compression, and reverb. MSR models mixtures as degraded sums of individually degraded sources, with the goal of recovering original, undegraded signals. Due to the lack of data for MSR, we present RawStems, a dataset annotation of 578 songs with unprocessed source signals organized into 8 primary and 17 secondary instrument groups, totaling 354.13 hours. To the best of our knowledge, RawStems is the first dataset that contains unprocessed music stems with hierarchical categories. We consider spectral filtering, dynamic range compression, harmonic distortion, reverb and lossy codec as possible degradations, and establish U-Former as a baseline method, demonstrating the feasibility of MSR on our dataset. We release the RawStems dataset annotations, degradation simulation pipeline, training code and pre-trained models to be publicly available.","authors":["Yongyi Zang","Zheqi Dai","Mark D. Plumbley","Qiuqiang Kong"],"url":"https://arxiv.org/abs/2505.21827"}
{"created":"2025-05-29","title":"SAGE-Eval: Evaluating LLMs for Systematic Generalizations of Safety Facts","abstract":"Do LLMs robustly generalize critical safety facts to novel situations? Lacking this ability is dangerous when users ask naive questions. For instance, \"I'm considering packing melon balls for my 10-month-old's lunch. What other foods would be good to include?\" Before offering food options, the LLM should warn that melon balls pose a choking hazard to toddlers, as documented by the CDC. Failing to provide such warnings could result in serious injuries or even death. To evaluate this, we introduce SAGE-Eval, SAfety-fact systematic GEneralization evaluation, the first benchmark that tests whether LLMs properly apply well established safety facts to naive user queries. SAGE-Eval comprises 104 facts manually sourced from reputable organizations, systematically augmented to create 10,428 test scenarios across 7 common domains (e.g., Outdoor Activities, Medicine). We find that the top model, Claude-3.7-sonnet, passes only 58% of all the safety facts tested. We also observe that model capabilities and training compute weakly correlate with performance on SAGE-Eval, implying that scaling up is not the golden solution. Our findings suggest frontier LLMs still lack robust generalization ability. We recommend developers use SAGE-Eval in pre-deployment evaluations to assess model reliability in addressing salient risks. We publicly release SAGE-Eval at https://huggingface.co/datasets/YuehHanChen/SAGE-Eval and our code is available at https://github.com/YuehHanChen/SAGE-Eval/tree/main.","authors":["Chen Yueh-Han","Guy Davidson","Brenden M. Lake"],"url":"https://arxiv.org/abs/2505.21828"}
{"created":"2025-05-29","title":"In Search of Adam's Secret Sauce","abstract":"Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study - training over 1,300 language models across different data configurations and scales - comparing Adam to several known simplified variants. We find that signed momentum methods are faster than SGD, but consistently underperform relative to Adam, even after careful tuning of momentum, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves near-optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal. Beyond robust performance, this choice affords new theoretical insights, highlights the \"secret sauce\" on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients-one that arises from a mean-field Gaussian variational inference perspective.","authors":["Antonio Orvieto","Robert Gower"],"url":"https://arxiv.org/abs/2505.21829"}
{"created":"2025-05-29","title":"HDRSDR-VQA: A Subjective Video Quality Dataset for HDR and SDR Comparative Evaluation","abstract":"We introduce HDRSDR-VQA, a large-scale video quality assessment dataset designed to facilitate comparative analysis between High Dynamic Range (HDR) and Standard Dynamic Range (SDR) content under realistic viewing conditions. The dataset comprises 960 videos generated from 54 diverse source sequences, each presented in both HDR and SDR formats across nine distortion levels. To obtain reliable perceptual quality scores, we conducted a comprehensive subjective study involving 145 participants and six consumer-grade HDR-capable televisions. A total of over 22,000 pairwise comparisons were collected and scaled into Just-Objectionable-Difference (JOD) scores. Unlike prior datasets that focus on a single dynamic range format or use limited evaluation protocols, HDRSDR-VQA enables direct content-level comparison between HDR and SDR versions, supporting detailed investigations into when and why one format is preferred over the other. The open-sourced part of the dataset is publicly available to support further research in video quality assessment, content-adaptive streaming, and perceptual model development.","authors":["Bowen Chen","Cheng-han Lee","Yixu Chen","Zaixi Shang","Hai Wei","Alan C. Bovik"],"url":"https://arxiv.org/abs/2505.21831"}
{"created":"2025-05-29","title":"TuneComp: Joint Fine-tuning and Compression for Large Foundation Models","abstract":"To reduce model size during post-training, compression methods, including knowledge distillation, low-rank approximation, and pruning, are often applied after fine-tuning the model. However, sequential fine-tuning and compression sacrifices performance, while creating a larger than necessary model as an intermediate step. In this work, we aim to reduce this gap, by directly constructing a smaller model while guided by the downstream task. We propose to jointly fine-tune and compress the model by gradually distilling it to a pruned low-rank structure. Experiments demonstrate that joint fine-tuning and compression significantly outperforms other sequential compression methods.","authors":["Xiangyu Chen (Perry)","Jing Liu (Perry)","Ye Wang (Perry)","Matthew Brand (Perry)","Pu (Perry)","Wang","Toshiaki Koike-Akino"],"url":"https://arxiv.org/abs/2505.21835"}
{"created":"2025-05-29","title":"UniMoGen: Universal Motion Generation","abstract":"Motion generation is a cornerstone of computer graphics, animation, gaming, and robotics, enabling the creation of realistic and varied character movements. A significant limitation of existing methods is their reliance on specific skeletal structures, which restricts their versatility across different characters. To overcome this, we introduce UniMoGen, a novel UNet-based diffusion model designed for skeleton-agnostic motion generation. UniMoGen can be trained on motion data from diverse characters, such as humans and animals, without the need for a predefined maximum number of joints. By dynamically processing only the necessary joints for each character, our model achieves both skeleton agnosticism and computational efficiency. Key features of UniMoGen include controllability via style and trajectory inputs, and the ability to continue motions from past frames. We demonstrate UniMoGen's effectiveness on the 100style dataset, where it outperforms state-of-the-art methods in diverse character motion generation. Furthermore, when trained on both the 100style and LAFAN1 datasets, which use different skeletons, UniMoGen achieves high performance and improved efficiency across both skeletons. These results highlight UniMoGen's potential to advance motion generation by providing a flexible, efficient, and controllable solution for a wide range of character animations.","authors":["Aliasghar Khani","Arianna Rampini","Evan Atherton","Bruno Roy"],"url":"https://arxiv.org/abs/2505.21837"}
{"created":"2025-05-29","title":"Nonadaptive Output Regulation of Second-Order Nonlinear Uncertain Systems","abstract":"This paper investigates the robust output regulation problem of second-order nonlinear uncertain systems with an unknown exosystem. Instead of the adaptive control approach, this paper resorts to a robust control methodology to solve the problem and thus avoid the bursting phenomenon. In particular, this paper constructs generic internal models for the steady-state state and input variables of the system. By introducing a coordinate transformation, this paper converts the robust output regulation problem into a nonadaptive stabilization problem of an augmented system composed of the second-order nonlinear uncertain system and the generic internal models. Then, we design the stabilization control law and construct a strict Lyapunov function that guarantees the robustness with respect to unmodeled disturbances. The analysis shows that the output zeroing manifold of the augmented system can be made attractive by the proposed nonadaptive control law, which solves the robust output regulation problem. Finally, we demonstrate the effectiveness of the proposed nonadaptive internal model approach by its application to the control of the Duffing system.","authors":["Maobin Lu","Martin Guay","Telema Harry","Shimin Wang","Jordan Cooper"],"url":"https://arxiv.org/abs/2505.21838"}
{"created":"2025-05-29","title":"An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints","abstract":"Online safe reinforcement learning (RL) plays a key role in dynamic environments, with applications in autonomous driving, robotics, and cybersecurity. The objective is to learn optimal policies that maximize rewards while satisfying safety constraints modeled by constrained Markov decision processes (CMDPs). Existing methods achieve sublinear regret under stochastic constraints but often fail in adversarial settings, where constraints are unknown, time-varying, and potentially adversarially designed. In this paper, we propose the Optimistic Mirror Descent Primal-Dual (OMDPD) algorithm, the first to address online CMDPs with anytime adversarial constraints. OMDPD achieves optimal regret O(sqrt(K)) and strong constraint violation O(sqrt(K)) without relying on Slater's condition or the existence of a strictly known safe policy. We further show that access to accurate estimates of rewards and transitions can further improve these bounds. Our results offer practical guarantees for safe decision-making in adversarial environments.","authors":["Jiahui Zhu","Kihyun Yu","Dabeen Lee","Xin Liu","Honghao Wei"],"url":"https://arxiv.org/abs/2505.21841"}
{"created":"2025-05-29","title":"A Physics-Informed Learning Framework to Solve the Infinite-Horizon Optimal Control Problem","abstract":"We propose a physics-informed neural networks (PINNs) framework to solve the infinite-horizon optimal control problem of nonlinear systems. In particular, since PINNs are generally able to solve a class of partial differential equations (PDEs), they can be employed to learn the value function of the infinite-horizon optimal control problem via solving the associated steady-state Hamilton-Jacobi-Bellman (HJB) equation. However, an issue here is that the steady-state HJB equation generally yields multiple solutions; hence if PINNs are directly employed to it, they may end up approximating a solution that is different from the optimal value function of the problem. We tackle this by instead applying PINNs to a finite-horizon variant of the steady-state HJB that has a unique solution, and which uniformly approximates the optimal value function as the horizon increases. An algorithm to verify if the chosen horizon is large enough is also given, as well as a method to extend it -- with reduced computations and robustness to approximation errors -- in case it is not. Unlike many existing methods, the proposed technique works well with non-polynomial basis functions, does not require prior knowledge of a stabilizing controller, and does not perform iterative policy evaluations. Simulations are performed, which verify and clarify theoretical findings.","authors":["Filippos Fotiadis","Kyriakos G. Vamvoudakis"],"url":"https://arxiv.org/abs/2505.21842"}
{"created":"2025-05-29","title":"Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation","abstract":"Recently, test-time adaptation has attracted wide interest in the context of vision-language models for image classification. However, to the best of our knowledge, the problem is completely overlooked in dense prediction tasks such as Open-Vocabulary Semantic Segmentation (OVSS). In response, we propose a novel TTA method tailored to adapting VLMs for segmentation during test time. Unlike TTA methods for image classification, our Multi-Level and Multi-Prompt (MLMP) entropy minimization integrates features from intermediate vision-encoder layers and is performed with different text-prompt templates at both the global CLS token and local pixel-wise levels. Our approach could be used as plug-and-play for any segmentation network, does not require additional training data or labels, and remains effective even with a single test sample. Furthermore, we introduce a comprehensive OVSS TTA benchmark suite, which integrates a rigorous evaluation protocol, seven segmentation datasets, and 15 common corruptions, with a total of 82 distinct test scenarios, establishing a standardized and comprehensive testbed for future TTA research in open-vocabulary segmentation. Our experiments on this suite demonstrate that our segmentation-tailored method consistently delivers significant gains over direct adoption of TTA classification baselines.","authors":["Mehrdad Noori","David Osowiechi","Gustavo Adolfo Vargas Hakim","Ali Bahri","Moslem Yazdanpanah","Sahar Dastani","Farzad Beizaee","Ismail Ben Ayed","Christian Desrosiers"],"url":"https://arxiv.org/abs/2505.21844"}
{"created":"2025-05-29","title":"RePaViT: Scalable Vision Transformer Acceleration via Structural Reparameterization on Feedforward Network Layers","abstract":"We reveal that feedforward network (FFN) layers, rather than attention layers, are the primary contributors to Vision Transformer (ViT) inference latency, with their impact signifying as model size increases. This finding highlights a critical opportunity for optimizing the efficiency of large-scale ViTs by focusing on FFN layers. In this work, we propose a novel channel idle mechanism that facilitates post-training structural reparameterization for efficient FFN layers during testing. Specifically, a set of feature channels remains idle and bypasses the nonlinear activation function in each FFN layer, thereby forming a linear pathway that enables structural reparameterization during inference. This mechanism results in a family of ReParameterizable Vision Transformers (RePaViTs), which achieve remarkable latency reductions with acceptable sacrifices (sometimes gains) in accuracy across various ViTs. The benefits of our method scale consistently with model sizes, demonstrating greater speed improvements and progressively narrowing accuracy gaps or even higher accuracies on larger models. In particular, RePa-ViT-Large and RePa-ViT-Huge enjoy 66.8% and 68.7% speed-ups with +1.7% and +1.1% higher top-1 accuracies under the same training strategy, respectively. RePaViT is the first to employ structural reparameterization on FFN layers to expedite ViTs to our best knowledge, and we believe that it represents an auspicious direction for efficient ViTs. Source code is available at https://github.com/Ackesnal/RePaViT.","authors":["Xuwei Xu","Yang Li","Yudong Chen","Jiajun Liu","Sen Wang"],"url":"https://arxiv.org/abs/2505.21847"}
{"created":"2025-05-29","title":"FPAN: Mitigating Replication in Diffusion Models through the Fine-Grained Probabilistic Addition of Noise to Token Embeddings","abstract":"Diffusion models have demonstrated remarkable potential in generating high-quality images. However, their tendency to replicate training data raises serious privacy concerns, particularly when the training datasets contain sensitive or private information. Existing mitigation strategies primarily focus on reducing image duplication, modifying the cross-attention mechanism, and altering the denoising backbone architecture of diffusion models. Moreover, recent work has shown that adding a consistent small amount of noise to text embeddings can reduce replication to some degree. In this work, we begin by analyzing the impact of adding varying amounts of noise. Based on our analysis, we propose a fine-grained noise injection technique that probabilistically adds a larger amount of noise to token embeddings. We refer to our method as Fine-grained Probabilistic Addition of Noise (FPAN). Through our extensive experiments, we show that our proposed FPAN can reduce replication by an average of 28.78% compared to the baseline diffusion model without significantly impacting image quality, and outperforms the prior consistent-magnitude-noise-addition approach by 26.51%. Moreover, when combined with other existing mitigation methods, our FPAN approach can further reduce replication by up to 16.82% with similar, if not improved, image quality.","authors":["Jingqi Xu","Chenghao Li","Yuke Zhang","Peter A. Beerel"],"url":"https://arxiv.org/abs/2505.21848"}
{"created":"2025-05-29","title":"Xinyu AI Search: Enhanced Relevance and Comprehensive Results with Rich Answer Presentations","abstract":"Traditional search engines struggle to synthesize fragmented information for complex queries, while generative AI search engines face challenges in relevance, comprehensiveness, and presentation. To address these limitations, we introduce Xinyu AI Search, a novel system that incorporates a query-decomposition graph to dynamically break down complex queries into sub-queries, enabling stepwise retrieval and generation. Our retrieval pipeline enhances diversity through multi-source aggregation and query expansion, while filtering and re-ranking strategies optimize passage relevance. Additionally, Xinyu AI Search introduces a novel approach for fine-grained, precise built-in citation and innovates in result presentation by integrating timeline visualization and textual-visual choreography. Evaluated on recent real-world queries, Xinyu AI Search outperforms eight existing technologies in human assessments, excelling in relevance, comprehensiveness, and insightfulness. Ablation studies validate the necessity of its key sub-modules. Our work presents the first comprehensive framework for generative AI search engines, bridging retrieval, generation, and user-centric presentation.","authors":["Bo Tang","Junyi Zhu","Chenyang Xi","Yunhang Ge","Jiahao Wu","Yuchen Feng","Yijun Niu","Wenqiang Wei","Yu Yu","Chunyu Li","Zehao Lin","Hao Wu","Ning Liao","Yebin Yang","Jiajia Wang","Zhiyu Li","Feiyu Xiong","Jingrun Chen"],"url":"https://arxiv.org/abs/2505.21849"}
{"created":"2025-05-29","title":"Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task","abstract":"Current Multimodal Large Language Models (MLLMs) excel in general visual reasoning but remain underexplored in Abstract Visual Reasoning (AVR), which demands higher-order reasoning to identify abstract rules beyond simple perception. Existing AVR benchmarks focus on single-step reasoning, emphasizing the end result but neglecting the multi-stage nature of reasoning process. Past studies found MLLMs struggle with these benchmarks, but it doesn't explain how they fail. To address this gap, we introduce MultiStAR, a Multi-Stage AVR benchmark, based on RAVEN, designed to assess reasoning across varying levels of complexity. Additionally, existing metrics like accuracy only focus on the final outcomes while do not account for the correctness of intermediate steps. Therefore, we propose a novel metric, MSEval, which considers the correctness of intermediate steps in addition to the final outcomes. We conduct comprehensive experiments on MultiStAR using 17 representative close-source and open-source MLLMs. The results reveal that while existing MLLMs perform adequately on basic perception tasks, they continue to face challenges in more complex rule detection stages.","authors":["Yanbei Jiang","Yihao Ding","Chao Lei","Jiayang Ao","Jey Han Lau","Krista A. Ehinger"],"url":"https://arxiv.org/abs/2505.21850"}
{"created":"2025-05-29","title":"Streaming Flow Policy: Simplifying diffusion$/$flow-matching policies by treating action trajectories as flow trajectories","abstract":"Recent advances in diffusion$/$flow-matching policies have enabled imitation learning of complex, multi-modal action trajectories. However, they are computationally expensive because they sample a trajectory of trajectories: a diffusion$/$flow trajectory of action trajectories. They discard intermediate action trajectories, and must wait for the sampling process to complete before any actions can be executed on the robot. We simplify diffusion$/$flow policies by treating action trajectories as flow trajectories. Instead of starting from pure noise, our algorithm samples from a narrow Gaussian around the last action. Then, it incrementally integrates a velocity field learned via flow matching to produce a sequence of actions that constitute a single trajectory. This enables actions to be streamed to the robot on-the-fly during the flow sampling process, and is well-suited for receding horizon policy execution. Despite streaming, our method retains the ability to model multi-modal behavior. We train flows that stabilize around demonstration trajectories to reduce distribution shift and improve imitation learning performance. Streaming flow policy outperforms prior methods while enabling faster policy execution and tighter sensorimotor loops for learning-based robot control. Project website: https://streaming-flow-policy.github.io/","authors":["Sunshine Jiang","Xiaolin Fang","Nicholas Roy","Tom\\'as Lozano-P\\'erez","Leslie Pack Kaelbling","Siddharth Ancha"],"url":"https://arxiv.org/abs/2505.21851"}
{"created":"2025-05-29","title":"A Provable Approach for End-to-End Safe Reinforcement Learning","abstract":"A longstanding goal in safe reinforcement learning (RL) is a method to ensure the safety of a policy throughout the entire process, from learning to operation. However, existing safe RL paradigms inherently struggle to achieve this objective. We propose a method, called Provably Lifetime Safe RL (PLS), that integrates offline safe RL with safe policy deployment to address this challenge. Our proposed method learns a policy offline using return-conditioned supervised learning and then deploys the resulting policy while cautiously optimizing a limited set of parameters, known as target returns, using Gaussian processes (GPs). Theoretically, we justify the use of GPs by analyzing the mathematical relationship between target and actual returns. We then prove that PLS finds near-optimal target returns while guaranteeing safety with high probability. Empirically, we demonstrate that PLS outperforms baselines both in safety and reward performance, thereby achieving the longstanding goal to obtain high rewards while ensuring the safety of a policy throughout the lifetime from learning to operation.","authors":["Akifumi Wachi","Kohei Miyaguchi","Takumi Tanabe","Rei Sato","Youhei Akimoto"],"url":"https://arxiv.org/abs/2505.21852"}
{"created":"2025-05-29","title":"Rethinking Gradient-based Adversarial Attacks on Point Cloud Classification","abstract":"Gradient-based adversarial attacks have become a dominant approach for evaluating the robustness of point cloud classification models. However, existing methods often rely on uniform update rules that fail to consider the heterogeneous nature of point clouds, resulting in excessive and perceptible perturbations. In this paper, we rethink the design of gradient-based attacks by analyzing the limitations of conventional gradient update mechanisms and propose two new strategies to improve both attack effectiveness and imperceptibility. First, we introduce WAAttack, a novel framework that incorporates weighted gradients and an adaptive step-size strategy to account for the non-uniform contribution of points during optimization. This approach enables more targeted and subtle perturbations by dynamically adjusting updates according to the local structure and sensitivity of each point. Second, we propose SubAttack, a complementary strategy that decomposes the point cloud into subsets and focuses perturbation efforts on structurally critical regions. Together, these methods represent a principled rethinking of gradient-based adversarial attacks for 3D point cloud classification. Extensive experiments demonstrate that our approach outperforms state-of-the-art baselines in generating highly imperceptible adversarial examples. Code will be released upon paper acceptance.","authors":["Jun Chen","Xinke Li","Mingyue Xu","Tianrui Li","Chongshou Li"],"url":"https://arxiv.org/abs/2505.21854"}
{"created":"2025-05-29","title":"Extracting Research Instruments from Educational Literature Using LLMs","abstract":"Large Language Models (LLMs) are transforming information extraction from academic literature, offering new possibilities for knowledge management. This study presents an LLM-based system designed to extract detailed information about research instruments used in the education field, including their names, types, target respondents, measured constructs, and outcomes. Using multi-step prompting and a domain-specific data schema, it generates structured outputs optimized for educational research. Our evaluation shows that this system significantly outperforms other approaches, particularly in identifying instrument names and detailed information. This demonstrates the potential of LLM-powered information extraction in educational contexts, offering a systematic way to organize research instrument information. The ability to aggregate such information at scale enhances accessibility for researchers and education leaders, facilitating informed decision-making in educational research and policy.","authors":["Jiseung Yoo","Curran Mahowald","Meiyu Li","Wei Ai"],"url":"https://arxiv.org/abs/2505.21855"}
{"created":"2025-05-29","title":"Revisiting Bayesian Model Averaging in the Era of Foundation Models","abstract":"We revisit the classical, full-fledged Bayesian model averaging (BMA) paradigm to ensemble pre-trained and/or lightly-finetuned foundation models to enhance the classification performance on image and text data. To make BMA tractable under foundation models, we introduce trainable linear classifiers that take frozen features from the pre-trained foundation models as inputs. The model posteriors over the linear classifiers tell us which linear heads and frozen features are better suited for a given dataset, resulting in a principled model ensembling method. Furthermore, we propose a computationally cheaper, optimizable model averaging scheme (OMA). In OMA, we directly optimize the model ensemble weights, just like those weights based on model posterior distributions in BMA, by reducing the amount of surprise (expected entropy of the predictions) we get from predictions of ensembled models. With the rapid development of foundation models, these approaches will enable the incorporation of future, possibly significantly better foundation models to enhance the performance of challenging classification tasks.","authors":["Mijung Park"],"url":"https://arxiv.org/abs/2505.21857"}
{"created":"2025-05-29","title":"Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries","abstract":"While large language models (LLMs) are increasingly capable of handling longer contexts, recent work has demonstrated that they exhibit the \"lost in the middle\" phenomenon (Liu et al., 2024) of unevenly attending to different parts of the provided context. This hinders their ability to cover diverse source material in multi-document summarization, as noted in the DiverseSumm benchmark (Huang et al., 2024). In this work, we contend that principled content selection is a simple way to increase source coverage on this task. As opposed to prompting an LLM to perform the summarization in a single step, we explicitly divide the task into three steps -- (1) reducing document collections to atomic key points, (2) using determinantal point processes (DPP) to perform select key points that prioritize diverse content, and (3) rewriting to the final summary. By combining prompting steps, for extraction and rewriting, with principled techniques, for content selection, we consistently improve source coverage on the DiverseSumm benchmark across various LLMs. Finally, we also show that by incorporating relevance to a provided user intent into the DPP kernel, we can generate personalized summaries that cover relevant source information while retaining coverage.","authors":["Vishakh Padmakumar","Zichao Wang","David Arbour","Jennifer Healey"],"url":"https://arxiv.org/abs/2505.21859"}
{"created":"2025-05-29","title":"GXJoin: Generalized Cell Transformations for Explainable Joinability","abstract":"Describing real-world entities can vary across different sources, posing a challenge when integrating or exchanging data. We study the problem of joinability under syntactic transformations, where two columns are not equi-joinable but can become equi-joinable after some transformations. Discovering those transformations is a challenge because of the large space of possible candidates, which grows with the input length and the number of rows. Our focus is on the generality of transformations, aiming to make the relevant models applicable across various instances and domains. We explore a few generalization techniques, emphasizing those that yield transformations covering a larger number of rows and are often easier to explain. Through extensive evaluation on two real-world datasets and employing diverse metrics for measuring the coverage and simplicity of the transformations, our approach demonstrates superior performance over state-of-the-art approaches by generating fewer, simpler and hence more explainable transformations as well as improving the join performance.","authors":["Soroush Omidvartehrani","Arash Dargahi Nobari","Davood Rafiei"],"url":"https://arxiv.org/abs/2505.21860"}
{"created":"2025-05-29","title":"Towards Scalable Language-Image Pre-training for 3D Medical Imaging","abstract":"Language-image pre-training has demonstrated strong performance in 2D medical imaging, but its success in 3D modalities such as CT and MRI remains limited due to the high computational demands of volumetric data, which pose a significant barrier to training on large-scale, uncurated clinical studies. In this study, we introduce Hierarchical attention for Language-Image Pre-training (HLIP), a scalable pre-training framework for 3D medical imaging. HLIP adopts a lightweight hierarchical attention mechanism inspired by the natural hierarchy of radiology data: slice, scan, and study. This mechanism exhibits strong generalizability, e.g., +4.3% macro AUC on the Rad-ChestCT benchmark when pre-trained on CT-RATE. Moreover, the computational efficiency of HLIP enables direct training on uncurated datasets. Trained on 220K patients with 3.13 million scans for brain MRI and 240K patients with 1.44 million scans for head CT, HLIP achieves state-of-the-art performance, e.g., +32.4% balanced ACC on the proposed publicly available brain MRI benchmark Pub-Brain-5; +1.4% and +6.9% macro AUC on head CT benchmarks RSNA and CQ500, respectively. These results demonstrate that, with HLIP, directly pre-training on uncurated clinical datasets is a scalable and effective direction for language-image pre-training in 3D medical imaging. The code is available at https://github.com/Zch0414/hlip","authors":["Chenhui Zhao","Yiwei Lyu","Asadur Chowdury","Edward Harake","Akhil Kondepudi","Akshay Rao","Xinhai Hou","Honglak Lee","Todd Hollon"],"url":"https://arxiv.org/abs/2505.21862"}
{"created":"2025-05-29","title":"GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning","abstract":"Publicly significant images from events hold valuable contextual information, crucial for journalism and education. However, existing methods often struggle to extract this relevance accurately. To address this, we introduce GETReason (Geospatial Event Temporal Reasoning), a framework that moves beyond surface-level image descriptions to infer deeper contextual meaning. We propose that extracting global event, temporal, and geospatial information enhances understanding of an image's significance. Additionally, we introduce GREAT (Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric for evaluating reasoning-based image understanding. Our layered multi-agent approach, assessed using a reasoning-weighted metric, demonstrates that meaningful insights can be inferred, effectively linking images to their broader event context.","authors":["Shikhhar Siingh","Abhinav Rawat","Vivek Gupta","Chitta Baral"],"url":"https://arxiv.org/abs/2505.21863"}
{"created":"2025-05-29","title":"DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation","abstract":"We present DexUMI - a data collection and policy learning framework that uses the human hand as the natural interface to transfer dexterous manipulation skills to various robot hands. DexUMI includes hardware and software adaptations to minimize the embodiment gap between the human hand and various robot hands. The hardware adaptation bridges the kinematics gap using a wearable hand exoskeleton. It allows direct haptic feedback in manipulation data collection and adapts human motion to feasible robot hand motion. The software adaptation bridges the visual gap by replacing the human hand in video data with high-fidelity robot hand inpainting. We demonstrate DexUMI's capabilities through comprehensive real-world experiments on two different dexterous robot hand hardware platforms, achieving an average task success rate of 86%.","authors":["Mengda Xu","Han Zhang","Yifan Hou","Zhenjia Xu","Linxi Fan","Manuela Veloso","Shuran Song"],"url":"https://arxiv.org/abs/2505.21864"}
{"created":"2025-05-29","title":"Cross-DINO: Cross the Deep MLP and Transformer for Small Object Detection","abstract":"Small Object Detection (SOD) poses significant challenges due to limited information and the model's low class prediction score. While Transformer-based detectors have shown promising performance, their potential for SOD remains largely unexplored. In typical DETR-like frameworks, the CNN backbone network, specialized in aggregating local information, struggles to capture the necessary contextual information for SOD. The multiple attention layers in the Transformer Encoder face difficulties in effectively attending to small objects and can also lead to blurring of features. Furthermore, the model's lower class prediction score of small objects compared to large objects further increases the difficulty of SOD. To address these challenges, we introduce a novel approach called Cross-DINO. This approach incorporates the deep MLP network to aggregate initial feature representations with both short and long range information for SOD. Then, a new Cross Coding Twice Module (CCTM) is applied to integrate these initial representations to the Transformer Encoder feature, enhancing the details of small objects. Additionally, we introduce a new kind of soft label named Category-Size (CS), integrating the Category and Size of objects. By treating CS as new ground truth, we propose a new loss function called Boost Loss to improve the class prediction score of the model. Extensive experimental results on COCO, WiderPerson, VisDrone, AI-TOD, and SODA-D datasets demonstrate that Cross-DINO efficiently improves the performance of DETR-like models on SOD. Specifically, our model achieves 36.4% APs on COCO for SOD with only 45M parameters, outperforming the DINO by +4.4% APS (36.4% vs. 32.0%) with fewer parameters and FLOPs, under 12 epochs training setting. The source codes will be available at https://github.com/Med-Process/Cross-DINO.","authors":["Guiping Cao","Wenjian Huang","Xiangyuan Lan","Jianguo Zhang","Dongmei Jiang","Yaowei Wang"],"url":"https://arxiv.org/abs/2505.21868"}
{"created":"2025-05-29","title":"Evaluating the Retrieval Robustness of Large Language Models","abstract":"Retrieval-augmented generation (RAG) generally enhances large language models' (LLMs) ability to solve knowledge-intensive tasks. But RAG may also lead to performance degradation due to imperfect retrieval and the model's limited ability to leverage retrieved content. In this work, we evaluate the robustness of LLMs in practical RAG setups (henceforth retrieval robustness). We focus on three research questions: (1) whether RAG is always better than non-RAG; (2) whether more retrieved documents always lead to better performance; (3) and whether document orders impact results. To facilitate this study, we establish a benchmark of 1500 open-domain questions, each with retrieved documents from Wikipedia. We introduce three robustness metrics, each corresponds to one research question. Our comprehensive experiments, involving 11 LLMs and 3 prompting strategies, reveal that all of these LLMs exhibit surprisingly high retrieval robustness; nonetheless, different degrees of imperfect robustness hinders them from fully utilizing the benefits of RAG.","authors":["Shuyang Cao","Karthik Radhakrishnan","David Rosenberg","Steven Lu","Pengxiang Cheng","Lu Wang","Shiyue Zhang"],"url":"https://arxiv.org/abs/2505.21870"}
{"created":"2025-05-29","title":"Broadening Our View: Assistive Technology for Cerebral Visual Impairment","abstract":"Over the past decade, considerable research has been directed towards assistive technologies to support people with vision impairments using machine learning, computer vision, image enhancement, and/or augmented/virtual reality. However, this has almost totally overlooked a growing demographic: people with Cerebral Visual Impairment (CVI). Unlike Ocular Vision Impairments (OVI), CVI arises from damage to the brain's visual processing centres. This paper introduces CVI and reveals a wide research gap in addressing the needs of this demographic. Through a scoping review, we identified 14 papers at the intersection of these technologies and CVI. Of these, only three papers described assistive technologies focused on people living with CVI, with the others focusing on diagnosis, understanding, simulation or rehabilitation. Our findings highlight the opportunity for the Human-Computer Interaction and Assistive Technologies research community to explore and address this underrepresented domain, thereby enhancing the quality of life for people with CVI.","authors":["Bhanuka Gamage","Leona Holloway","Nicola McDowell","Thanh-Toan Do","Nicholas Seow Chiang Price","Arthur James Lowery","Kim Marriott"],"url":"https://arxiv.org/abs/2505.21875"}
{"created":"2025-05-29","title":"EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video Guidance","abstract":"Recent approaches on 3D camera control in video diffusion models (VDMs) often create anchor videos to guide diffusion models as a structured prior by rendering from estimated point clouds following annotated camera trajectories. However, errors inherent in point cloud estimation often lead to inaccurate anchor videos. Moreover, the requirement for extensive camera trajectory annotations further increases resource demands. To address these limitations, we introduce EPiC, an efficient and precise camera control learning framework that automatically constructs high-quality anchor videos without expensive camera trajectory annotations. Concretely, we create highly precise anchor videos for training by masking source videos based on first-frame visibility. This approach ensures high alignment, eliminates the need for camera trajectory annotations, and thus can be readily applied to any in-the-wild video to generate image-to-video (I2V) training pairs. Furthermore, we introduce Anchor-ControlNet, a lightweight conditioning module that integrates anchor video guidance in visible regions to pretrained VDMs, with less than 1% of backbone model parameters. By combining the proposed anchor video data and ControlNet module, EPiC achieves efficient training with substantially fewer parameters, training steps, and less data, without requiring modifications to the diffusion model backbone typically needed to mitigate rendering misalignments. Although being trained on masking-based anchor videos, our method generalizes robustly to anchor videos made with point clouds during inference, enabling precise 3D-informed camera control. EPiC achieves SOTA performance on RealEstate10K and MiraData for I2V camera control task, demonstrating precise and robust camera control ability both quantitatively and qualitatively. Notably, EPiC also exhibits strong zero-shot generalization to video-to-video scenarios.","authors":["Zun Wang","Jaemin Cho","Jialu Li","Han Lin","Jaehong Yoon","Yue Zhang","Mohit Bansal"],"url":"https://arxiv.org/abs/2505.21876"}
{"created":"2025-05-29","title":"Hybrid Batch Normalisation: Resolving the Dilemma of Batch Normalisation in Federated Learning","abstract":"Batch Normalisation (BN) is widely used in conventional deep neural network training to harmonise the input-output distributions for each batch of data. However, federated learning, a distributed learning paradigm, faces the challenge of dealing with non-independent and identically distributed data among the client nodes. Due to the lack of a coherent methodology for updating BN statistical parameters, standard BN degrades the federated learning performance. To this end, it is urgent to explore an alternative normalisation solution for federated learning. In this work, we resolve the dilemma of the BN layer in federated learning by developing a customised normalisation approach, Hybrid Batch Normalisation (HBN). HBN separates the update of statistical parameters (i.e. , means and variances used for evaluation) from that of learnable parameters (i.e. , parameters that require gradient updates), obtaining unbiased estimates of global statistical parameters in distributed scenarios. In contrast with the existing solutions, we emphasise the supportive power of global statistics for federated learning. The HBN layer introduces a learnable hybrid distribution factor, allowing each computing node to adaptively mix the statistical parameters of the current batch with the global statistics. Our HBN can serve as a powerful plugin to advance federated learning performance. It reflects promising merits across a wide range of federated learning settings, especially for small batch sizes and heterogeneous data.","authors":["Hongyao Chen","Tianyang Xu","Xiaojun Wu","Josef Kittler"],"url":"https://arxiv.org/abs/2505.21877"}
{"created":"2025-05-29","title":"Symbolic Foundation Regressor on Complex Networks","abstract":"In science, we are interested not only in forecasting but also in understanding how predictions are made, specifically what the interpretable underlying model looks like. Data-driven machine learning technology can significantly streamline the complex and time-consuming traditional manual process of discovering scientific laws, helping us gain insights into fundamental issues in modern science. In this work, we introduce a pre-trained symbolic foundation regressor that can effectively compress complex data with numerous interacting variables while producing interpretable physical representations. Our model has been rigorously tested on non-network symbolic regression, symbolic regression on complex networks, and the inference of network dynamics across various domains, including physics, biochemistry, ecology, and epidemiology. The results indicate a remarkable improvement in equation inference efficiency, being three times more effective than baseline approaches while maintaining accurate predictions. Furthermore, we apply our model to uncover more intuitive laws of interaction transmission from global epidemic outbreak data, achieving optimal data fitting. This model extends the application boundary of pre-trained symbolic regression models to complex networks, and we believe it provides a foundational solution for revealing the hidden mechanisms behind changes in complex phenomena, enhancing interpretability, and inspiring further scientific discoveries.","authors":["Weiting Liu","Jiaxu Cui","Jiao Hu","En Wang","Bo Yang"],"url":"https://arxiv.org/abs/2505.21879"}
{"created":"2025-05-29","title":"Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation","abstract":"This study presents an innovative approach to urban mobility simulation by integrating a Large Language Model (LLM) with Agent-Based Modeling (ABM). Unlike traditional rule-based ABM, the proposed framework leverages LLM to enhance agent diversity and realism by generating synthetic population profiles, allocating routine and occasional locations, and simulating personalized routes. Using real-world data, the simulation models individual behaviors and large-scale mobility patterns in Taipei City. Key insights, such as route heat maps and mode-specific indicators, provide urban planners with actionable information for policy-making. Future work focuses on establishing robust validation frameworks to ensure accuracy and reliability in urban planning applications.","authors":["Yu-Lun Song","Chung-En Tsern","Che-Cheng Wu","Yu-Ming Chang","Syuan-Bo Huang","Wei-Chu Chen","Michael Chia-Liang Lin","Yu-Ta Lin"],"url":"https://arxiv.org/abs/2505.21880"}
{"created":"2025-05-29","title":"HydraNet: Momentum-Driven State Space Duality for Multi-Granularity Tennis Tournaments Analysis","abstract":"In tennis tournaments, momentum, a critical yet elusive phenomenon, reflects the dynamic shifts in performance of athletes that can decisively influence match outcomes. Despite its significance, momentum in terms of effective modeling and multi-granularity analysis across points, games, sets, and matches in tennis tournaments remains underexplored. In this study, we define a novel Momentum Score (MS) metric to quantify a player's momentum level in multi-granularity tennis tournaments, and design HydraNet, a momentum-driven state-space duality-based framework, to model MS by integrating thirty-two heterogeneous dimensions of athletes performance in serve, return, psychology and fatigue. HydraNet integrates a Hydra module, which builds upon a state-space duality (SSD) framework, capturing explicit momentum with a sliding-window mechanism and implicit momentum through cross-game state propagation. It also introduces a novel Versus Learning method to better enhance the adversarial nature of momentum between the two athletes at a macro level, along with a Collaborative-Adversarial Attention Mechanism (CAAM) for capturing and integrating intra-player and inter-player dynamic momentum at a micro level. Additionally, we construct a million-level tennis cross-tournament dataset spanning from 2012-2023 Wimbledon and 2013-2023 US Open, and validate the multi-granularity modeling capability of HydraNet for the MS metric on this dataset. Extensive experimental evaluations demonstrate that the MS metric constructed by the HydraNet framework provides actionable insights into how momentum impacts outcomes at different granularities, establishing a new foundation for momentum modeling and sports analysis. To the best of our knowledge. The source code and datasets are available at https://github.com/ReyJerry/HydraNet.","authors":["Ruijie Li","Xiang Zhao","Qiao Ning","Shikai Guo"],"url":"https://arxiv.org/abs/2505.21882"}
{"created":"2025-05-29","title":"Online distributed optimization for spatio-temporally constrained real-time peer-to-peer energy trading","abstract":"The proliferation of distributed renewable energy triggers the peer-to-peer (P2P) energy market formations. To make profits, prosumers equipped with photovoltaic (PV) panels and even the energy storage system (ESS) can actively participate in the real-time P2P energy market and trade energy. However, in real situations, system states such as energy demands and renewable energy power generation are highly uncertain, making it difficult for prosumers to make optimal real-time decisions. Moreover, severe problems with the physical network can arise from the real-time P2P energy trading, such as bus voltage violations and line overload. To handle these problems, this work first formulates the real-time P2P energy trading problem as a spatio-temporally constrained stochastic optimization problem by considering ESS and the spatial physical network constraints. To deal with the uncertainties online, a modified Lyapunov optimization method is innovatively proposed to approximately reformulate the stochastic optimization problem into an online one by relaxing the time-coupling constraints. Compared with the state-of-the-art online methods, the proposed one renders more flexibility and better performance for the real-time P2P energy market operation. Additionally, to protect the prosumers' privacy, an online distributed algorithm based on the consensus alternating direction method of multipliers (ADMM) is developed to solve the reformulated online problem by decoupling the spatial constraints. The theoretical near-optimal performance guarantee of the proposed online distributed algorithm is derived, and its performance can be further improved by minimizing the performance gap. Simulation results demonstrate that the proposed online distributed algorithm can guarantee the fast, stable, and safe long-term operation of the real-time P2P energy market.","authors":["Junhong Liu","Qinfei Long","Rong-Peng Liu","Wenjie Liu","Yunhe Hou"],"url":"https://arxiv.org/abs/2505.21884"}
{"created":"2025-05-29","title":"SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem","abstract":"Robust routing under uncertainty is central to real-world logistics, yet most benchmarks assume static, idealized settings. We present SVRPBench, the first open benchmark to capture high-fidelity stochastic dynamics in vehicle routing at urban scale. Spanning more than 500 instances with up to 1000 customers, it simulates realistic delivery conditions: time-dependent congestion, log-normal delays, probabilistic accidents, and empirically grounded time windows for residential and commercial clients. Our pipeline generates diverse, constraint-rich scenarios, including multi-depot and multi-vehicle setups. Benchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade by over 20% under distributional shift, while classical and metaheuristic methods remain robust. To enable reproducible research, we release the dataset and evaluation suite. SVRPBench challenges the community to design solvers that generalize beyond synthetic assumptions and adapt to real-world uncertainty.","authors":["Ahmed Heakl","Yahia Salaheldin Shaaban","Martin Takac","Salem Lahlou","Zangir Iklassov"],"url":"https://arxiv.org/abs/2505.21887"}
{"created":"2025-05-29","title":"EFIM: Efficient Serving of LLMs for Infilling Tasks with Improved KV Cache Reuse","abstract":"Large language models (LLMs) are often used for infilling tasks, which involve predicting or generating missing information in a given text. These tasks typically require multiple interactions with similar context. To reduce the computation of repeated historical tokens, cross-request key-value (KV) cache reuse, a technique that stores and reuses intermediate computations, has become a crucial method in multi-round interactive services. However, in infilling tasks, the KV cache reuse is often hindered by the structure of the prompt format, which typically consists of a prefix and suffix relative to the insertion point. Specifically, the KV cache of the prefix or suffix part is frequently invalidated as the other part (suffix or prefix) is incrementally generated. To address the issue, we propose EFIM, a transformed prompt format of FIM to unleash the performance potential of KV cache reuse. Although the transformed prompt can solve the inefficiency, it exposes subtoken generation problems in current LLMs, where they have difficulty generating partial words accurately. Therefore, we introduce a fragment tokenization training method which splits text into multiple fragments before tokenization during data processing. Experiments on two representative LLMs show that LLM serving with EFIM can lower the latency by 52% and improve the throughput by 98% while maintaining the original infilling capability.EFIM's source code is publicly available at https://github.com/gty111/EFIM.","authors":["Tianyu Guo","Hande Dong","Yichong Leng","Feng Liu","Cheater Lin","Nong Xiao","Xianwei Zhang"],"url":"https://arxiv.org/abs/2505.21889"}
{"created":"2025-05-29","title":"Hyperspectral Gaussian Splatting","abstract":"Hyperspectral imaging (HSI) has been widely used in agricultural applications for non-destructive estimation of plant nutrient composition and precise determination of nutritional elements in samples. Recently, 3D reconstruction methods have been used to create implicit neural representations of HSI scenes, which can help localize the target object's nutrient composition spatially and spectrally. Neural Radiance Field (NeRF) is a cutting-edge implicit representation that can render hyperspectral channel compositions of each spatial location from any viewing direction. However, it faces limitations in training time and rendering speed. In this paper, we propose Hyperspectral Gaussian Splatting (HS-GS), which combines the state-of-the-art 3D Gaussian Splatting (3DGS) with a diffusion model to enable 3D explicit reconstruction of the hyperspectral scenes and novel view synthesis for the entire spectral range. To enhance the model's ability to capture fine-grained reflectance variations across the light spectrum and leverage correlations between adjacent wavelengths for denoising, we introduce a wavelength encoder to generate wavelength-specific spherical harmonics offsets. We also introduce a novel Kullback--Leibler divergence-based loss to mitigate the spectral distribution gap between the rendered image and the ground truth. A diffusion model is further applied for denoising the rendered images and generating photorealistic hyperspectral images. We present extensive evaluations on five diverse hyperspectral scenes from the Hyper-NeRF dataset to show the effectiveness of our proposed HS-GS framework. The results demonstrate that HS-GS achieves new state-of-the-art performance among all previously published methods. Code will be released upon publication.","authors":["Sunil Kumar Narayanan","Lingjun Zhao","Lu Gan","Yongsheng Chen"],"url":"https://arxiv.org/abs/2505.21890"}
{"created":"2025-05-29","title":"TIEboard: A Digital Educational Tool for Kids Geometric Learning","abstract":"Tangible User Interfaces have shown potential in supporting the acquisition of key concepts in computing and mathematics while fostering engagement in young learners, but these approaches are less commonly utilised in the context of geometry. In this paper we introduce TIEboard, an interactive device to promote early learning of basic geometry concepts. TIEboard draws inspiration from traditional geoboards and lacing toys to leverage children's familiarity with these traditional tools. It employs instructional lights to guide children in creating shapes using colourful threads of optical fiber. The use of conductive materials allows the system to detect lacing activity and provide feedback in real-time. TIEboard incorporates six interaction modes of varying difficulty based on an incremental learning framework. The study evaluated TIEboard's effectiveness in supporting early geometric learning, facilitating creativity and promoting collaboration among 16 children aged 5-9.","authors":["Arooj Zaidi","Giulia Barbareschi","Kai Kunze","Yun Suen Pai","Junichi Yamaoka"],"url":"https://arxiv.org/abs/2505.21891"}
{"created":"2025-05-29","title":"SDPO: Importance-Sampled Direct Preference Optimization for Stable Diffusion Training","abstract":"Preference learning has become a central technique for aligning generative models with human expectations. Recently, it has been extended to diffusion models through methods like Direct Preference Optimization (DPO). However, existing approaches such as Diffusion-DPO suffer from two key challenges: timestep-dependent instability, caused by a mismatch between the reverse and forward diffusion processes and by high gradient variance in early noisy timesteps, and off-policy bias arising from the mismatch between optimization and data collection policies. We begin by analyzing the reverse diffusion trajectory and observe that instability primarily occurs at early timesteps with low importance weights. To address these issues, we first propose DPO-C\\&amp;M, a practical strategy that improves stability by clipping and masking uninformative timesteps while partially mitigating off-policy bias. Building on this, we introduce SDPO (Importance-Sampled Direct Preference Optimization), a principled framework that incorporates importance sampling into the objective to fully correct for off-policy bias and emphasize informative updates during the diffusion process. Experiments on CogVideoX-2B, CogVideoX-5B, and Wan2.1-1.3B demonstrate that both methods outperform standard Diffusion-DPO, with SDPO achieving superior VBench scores, human preference alignment, and training robustness. These results highlight the importance of timestep-aware, distribution-corrected optimization in diffusion-based preference learning.","authors":["Xiaomeng Yang","Zhiyu Tan","Junyan Wang","Zhijian Zhou","Hao Li"],"url":"https://arxiv.org/abs/2505.21893"}
{"created":"2025-05-29","title":"Compressing Sine-Activated Low-Rank Adapters through Post-Training Quantization","abstract":"Low-Rank Adaptation (LoRA) has become a standard approach for parameter-efficient fine-tuning, offering substantial reductions in trainable parameters by modeling updates as the product of two low-rank matrices. While effective, the low-rank constraint inherently limits representational capacity, often resulting in reduced performance compared to full-rank fine-tuning. Recent work by Ji et al. (2025) has addressed this limitation by applying a fixed-frequency sinusoidal transformation to low-rank adapters, increasing their stable rank without introducing additional parameters. This raises a crucial question: can the same sine-activated technique be successfully applied within the context of Post-Training Quantization to retain benefits even after model compression? In this paper, we investigate this question by extending the sinusoidal transformation framework to quantized LoRA adapters. We develop a theoretical analysis showing that the stable rank of a quantized adapter is tightly linked to that of its full-precision counterpart, motivating the use of such rank-enhancing functions even under quantization. Our results demonstrate that the expressivity gains from a sinusoidal non-linearity persist after quantization, yielding highly compressed adapters with negligible loss in performance. We validate our approach across a range of fine-tuning tasks for language, vision and text-to-image generation achieving significant memory savings while maintaining competitive accuracy.","authors":["Cameron Gordon","Yiping Ji","Hemanth Saratchandran","Paul Albert","Simon Lucey"],"url":"https://arxiv.org/abs/2505.21895"}
{"created":"2025-05-29","title":"Concentrate on Weakness: Mining Hard Prototypes for Few-Shot Medical Image Segmentation","abstract":"Few-Shot Medical Image Segmentation (FSMIS) has been widely used to train a model that can perform segmentation from only a few annotated images. However, most existing prototype-based FSMIS methods generate multiple prototypes from the support image solely by random sampling or local averaging, which can cause particularly severe boundary blurring due to the tendency for normal features accounting for the majority of features of a specific category. Consequently, we propose to focus more attention to those weaker features that are crucial for clear segmentation boundary. Specifically, we design a Support Self-Prediction (SSP) module to identify such weak features by comparing true support mask with one predicted by global support prototype. Then, a Hard Prototypes Generation (HPG) module is employed to generate multiple hard prototypes based on these weak features. Subsequently, a Multiple Similarity Maps Fusion (MSMF) module is devised to generate final segmenting mask in a dual-path fashion to mitigate the imbalance between foreground and background in medical images. Furthermore, we introduce a boundary loss to further constraint the edge of segmentation. Extensive experiments on three publicly available medical image datasets demonstrate that our method achieves state-of-the-art performance. Code is available at https://github.com/jcjiang99/CoW.","authors":["Jianchao Jiang","Haofeng Zhang"],"url":"https://arxiv.org/abs/2505.21897"}
{"created":"2025-05-29","title":"Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development","abstract":"Recent advancements in Large Language Models (LLMs) and autonomous agents have demonstrated remarkable capabilities across various domains. However, standalone agents frequently encounter limitations when handling complex tasks that demand extensive interactions and substantial computational resources. Although Multi-Agent Systems (MAS) alleviate some of these limitations through collaborative mechanisms like task decomposition, iterative communication, and role specialization, they typically remain resource-unaware, incurring significant inefficiencies due to high token consumption and excessive execution time. To address these limitations, we propose a resource-aware multi-agent system -- Co-Saving (meaning that multiple agents collaboratively engage in resource-saving activities), which leverages experiential knowledge to enhance operational efficiency and solution quality. Our key innovation is the introduction of \"shortcuts\" -- instructional transitions learned from historically successful trajectories -- which allows to bypass redundant reasoning agents and expedite the collective problem-solving process. Experiments for software development tasks demonstrate significant advantages over existing methods. Specifically, compared to the state-of-the-art MAS ChatDev, our method achieves an average reduction of 50.85% in token usage, and improves the overall code quality by 10.06%.","authors":["Rennai Qiu","Chen Qian","Ran Li","Yufan Dang","Weize Chen","Cheng Yang","Yingli Zhang","Ye Tian","Xuantang Xiong","Lei Han","Zhiyuan Liu","Maosong Sun"],"url":"https://arxiv.org/abs/2505.21898"}
{"created":"2025-05-29","title":"Joint$\\lambda$: Orchestrating Serverless Workflows on Jointcloud FaaS Systems","abstract":"Existing serverless workflow orchestration systems are predominantly designed for a single-cloud FaaS system, leading to vendor lock-in. This restricts performance optimization, cost reduction, and availability of applications. However, orchestrating serverless workflows on Jointcloud FaaS systems faces two main challenges: 1) Additional overhead caused by centralized cross-cloud orchestration; and 2) A lack of reliable failover and fault-tolerant mechanisms for cross-cloud serverless workflows. To address these challenges, we propose Joint$\\lambda$, a distributed runtime system designed to orchestrate serverless workflows on multiple FaaS systems without relying on a centralized orchestrator. Joint$\\lambda$ introduces a compatibility layer, Backend-Shim, leveraging inter-cloud heterogeneity to optimize makespan and reduce costs with on-demand billing. By using function-side orchestration instead of centralized nodes, it enables independent function invocations and data transfers, reducing cross-cloud communication overhead. For high availability, it ensures exactly-once execution via datastores and failover mechanisms for serverless workflows on Jointcloud FaaS systems. We validate Joint$\\lambda$ on two heterogeneous FaaS systems, AWS and ALiYun, with four workflows. Compared to the most advanced commercial orchestration services for single-cloud serverless workflows, Joint$\\lambda$ reduces up to 3.3$\\times$ latency, saving up to 65\\% cost. Joint$\\lambda$ is also faster than the state-of-the-art orchestrators for cross-cloud serverless workflows up to 4.0$\\times$, reducing up to 4.5$\\times$ cost and providing strong execution guarantees.","authors":["Jianfei Liu","Rui Li","Zhilin Yang","Peichang Shi","Guodong Yi","Huaimin Wang"],"url":"https://arxiv.org/abs/2505.21899"}
{"created":"2025-05-29","title":"Symbolically Regressing Fish Biomass Spectral Data: A Linear Genetic Programming Method with Tunable Primitives","abstract":"Machine learning techniques play an important role in analyzing spectral data. The spectral data of fish biomass is useful in fish production, as it carries many important chemistry properties of fish meat. However, it is challenging for existing machine learning techniques to comprehensively discover hidden patterns from fish biomass spectral data since the spectral data often have a lot of noises while the training data are quite limited. To better analyze fish biomass spectral data, this paper models it as a symbolic regression problem and solves it by a linear genetic programming method with newly proposed tunable primitives. In the symbolic regression problem, linear genetic programming automatically synthesizes regression models based on the given primitives and training data. The tunable primitives further improve the approximation ability of the regression models by tuning their inherent coefficients. Our empirical results over ten fish biomass targets show that the proposed method improves the overall performance of fish biomass composition prediction. The synthesized regression models are compact and have good interpretability, which allow us to highlight useful features over the spectrum. Our further investigation also verifies the good generality of the proposed method across various spectral data treatments and other symbolic regression problems.","authors":["Zhixing Huang","Bing Xue","Mengjie Zhang","Jeremy S. Ronney","Keith C. Gordon","Daniel P. Killeen"],"url":"https://arxiv.org/abs/2505.21901"}
{"created":"2025-05-29","title":"Enhanced Ideal Objective Vector Estimation for Evolutionary Multi-Objective Optimization","abstract":"The ideal objective vector, which comprises the optimal values of the $m$ objective functions in an $m$-objective optimization problem, is an important concept in evolutionary multi-objective optimization. Accurate estimation of this vector has consistently been a crucial task, as it is frequently used to guide the search process and normalize the objective space. Prevailing estimation methods all involve utilizing the best value concerning each objective function achieved by the individuals in the current or accumulated population. However, this paper reveals that the population-based estimation method can only work on simple problems but falls short on problems with substantial bias. The biases in multi-objective optimization problems can be divided into three categories, and an analysis is performed to illustrate how each category hinders the estimation of the ideal objective vector. Subsequently, a set of test instances is proposed to quantitatively evaluate the impact of various biases on the ideal objective vector estimation method. Beyond that, a plug-and-play component called enhanced ideal objective vector estimation (EIE) is introduced for multi-objective evolutionary algorithms (MOEAs). EIE features adaptive and fine-grained searches over $m$ subproblems defined by the extreme weighted sum method. EIE finally outputs $m$ solutions that can well approximate the ideal objective vector. In the experiments, EIE is integrated into three representative MOEAs. To demonstrate the wide applicability of EIE, algorithms are tested not only on the newly proposed test instances but also on existing ones. The results consistently show that EIE improves the ideal objective vector estimation and enhances the MOEA's performance.","authors":["Ruihao Zheng","Zhenkun Wang","Yin Wu","Maoguo Gong"],"url":"https://arxiv.org/abs/2505.21903"}
{"created":"2025-05-29","title":"CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation","abstract":"Instance segmentation demands costly per-pixel annotations and large models. We introduce CAST, a semi-supervised knowledge distillation (SSKD) framework that compresses pretrained vision foundation models (VFM) into compact experts using limited labeled and abundant unlabeled data. CAST unfolds in three stages: (1) domain adaptation of the VFM teacher(s) via self-training with contrastive pixel calibration, (2) distillation into a compact student via a unified multi-objective loss that couples standard supervision and pseudo-labels with our instance-aware pixel-wise contrastive term, and (3) fine-tuning on labeled data to remove residual pseudo-label bias. Central to CAST is an \\emph{instance-aware pixel-wise contrastive loss} that fuses mask and class scores to mine informative negatives and enforce clear inter-instance margins. By maintaining this contrastive signal across both adaptation and distillation, we align teacher and student embeddings and fully leverage unlabeled images. On Cityscapes and ADE20K, our ~11X smaller student surpasses its adapted VFM teacher(s) by +3.4 AP (33.9 vs. 30.5) and +1.5 AP (16.7 vs. 15.2) and outperforms state-of-the-art semi-supervised approaches.","authors":["Pardis Taghavi","Tian Liu","Renjie Li","Reza Langari","Zhengzhong Tu"],"url":"https://arxiv.org/abs/2505.21904"}
{"created":"2025-05-29","title":"Reference-Guided Identity Preserving Face Restoration","abstract":"Preserving face identity is a critical yet persistent challenge in diffusion-based image restoration. While reference faces offer a path forward, existing reference-based methods often fail to fully exploit their potential. This paper introduces a novel approach that maximizes reference face utility for improved face restoration and identity preservation. Our method makes three key contributions: 1) Composite Context, a comprehensive representation that fuses multi-level (high- and low-level) information from the reference face, offering richer guidance than prior singular representations. 2) Hard Example Identity Loss, a novel loss function that leverages the reference face to address the identity learning inefficiencies found in the existing identity loss. 3) A training-free method to adapt the model to multi-reference inputs during inference. The proposed method demonstrably restores high-quality faces and achieves state-of-the-art identity preserving restoration on benchmarks such as FFHQ-Ref and CelebA-Ref-Test, consistently outperforming previous work.","authors":["Mo Zhou","Keren Ye","Viraj Shah","Kangfu Mei","Mauricio Delbracio","Peyman Milanfar","Vishal M. Patel","Hossein Talebi"],"url":"https://arxiv.org/abs/2505.21905"}
{"created":"2025-05-29","title":"Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge","abstract":"Vision-language-action (VLA) models have emerged as the next generation of models in robotics. However, despite leveraging powerful pre-trained Vision-Language Models (VLMs), existing end-to-end VLA systems often lose key capabilities during fine-tuning as the model adapts to specific robotic tasks. We argue that a generalizable VLA model should retain and expand upon the VLM's core competencies: 1) Open-world embodied reasoning - the VLA should inherit the knowledge from VLM, i.e., recognize anything that the VLM can recognize, capable of solving math problems, possessing visual-spatial intelligence, 2) Reasoning following - effectively translating the open-world reasoning into actionable steps for the robot. In this work, we introduce ChatVLA-2, a novel mixture-of-expert VLA model coupled with a specialized three-stage training pipeline designed to preserve the VLM's original strengths while enabling actionable reasoning. To validate our approach, we design a math-matching task wherein a robot interprets math problems written on a whiteboard and picks corresponding number cards from a table to solve equations. Remarkably, our method exhibits exceptional mathematical reasoning and OCR capabilities, despite these abilities not being explicitly trained within the VLA. Furthermore, we demonstrate that the VLA possesses strong spatial reasoning skills, enabling it to interpret novel directional instructions involving previously unseen objects. Overall, our method showcases reasoning and comprehension abilities that significantly surpass state-of-the-art imitation learning methods such as OpenVLA, DexVLA, and pi-zero. This work represents a substantial advancement toward developing truly generalizable robotic foundation models endowed with robust reasoning capacities.","authors":["Zhongyi Zhou","Yichen Zhu","Junjie Wen","Chaomin Shen","Yi Xu"],"url":"https://arxiv.org/abs/2505.21906"}
{"created":"2025-05-29","title":"Modeling and Optimizing User Preferences in AI Copilots: A Comprehensive Survey and Taxonomy","abstract":"AI copilots, context-aware, AI-powered systems designed to assist users in tasks such as software development and content creation, are becoming integral to modern workflows. As these systems grow in capability and adoption, personalization has emerged as a cornerstone for ensuring usability, trust, and productivity. Central to this personalization is preference optimization: the ability of AI copilots to detect, interpret, and align with individual user preferences. While personalization techniques are well-established in domains like recommender systems and dialogue agents, their adaptation to interactive, real-time systems like AI copilots remains fragmented and underexplored. This survey addresses this gap by synthesizing research on how user preferences are captured, modeled, and refined within the design of AI copilots. We introduce a unified definition of AI copilots and propose a phase-based taxonomy of preference optimization strategies, structured around pre-interaction, mid-interaction, and post-interaction stages. We analyze techniques for acquiring preference signals, modeling user intent, and integrating feedback loops, highlighting both established approaches and recent innovations. By bridging insights from AI personalization, human-AI collaboration, and large language model adaptation, this survey provides a structured foundation for designing adaptive, preference-aware AI copilots. It offers a holistic view of the available preference resources, how they can be leveraged, and which technical approaches are most suited to each stage of system design.","authors":["Saleh Afzoon","Zahra Jahanandish","Phuong Thao Huynh","Amin Beheshti","Usman Naseem"],"url":"https://arxiv.org/abs/2505.21907"}
{"created":"2025-05-29","title":"Reinforcement Learning for Out-of-Distribution Reasoning in LLMs: An Empirical Study on Diagnosis-Related Group Coding","abstract":"Diagnosis-Related Group (DRG) codes are essential for hospital reimbursement and operations but require labor-intensive assignment. Large Language Models (LLMs) struggle with DRG coding due to the out-of-distribution (OOD) nature of the task: pretraining corpora rarely contain private clinical or billing data. We introduce DRG-Sapphire, which uses large-scale reinforcement learning (RL) for automated DRG coding from clinical notes. Built on Qwen2.5-7B and trained with Group Relative Policy Optimization (GRPO) using rule-based rewards, DRG-Sapphire introduces a series of RL enhancements to address domain-specific challenges not seen in previous mathematical tasks. Our model achieves state-of-the-art accuracy on the MIMIC-IV benchmark and generates physician-validated reasoning for DRG assignments, significantly enhancing explainability. Our study further sheds light on broader challenges of applying RL to knowledge-intensive, OOD tasks. We observe that RL performance scales approximately linearly with the logarithm of the number of supervised fine-tuning (SFT) examples, suggesting that RL effectiveness is fundamentally constrained by the domain knowledge encoded in the base model. For OOD tasks like DRG coding, strong RL performance requires sufficient knowledge infusion prior to RL. Consequently, scaling SFT may be more effective and computationally efficient than scaling RL alone for such tasks.","authors":["Hanyin Wang","Zhenbang Wu","Gururaj Kolar","Hariprasad Korsapati","Brian Bartlett","Bryan Hull","Jimeng Sun"],"url":"https://arxiv.org/abs/2505.21908"}
{"created":"2025-05-29","title":"Taming Transformer Without Using Learning Rate Warmup","abstract":"Scaling Transformer to a large scale without using some technical tricks such as learning rate warump and using an obviously lower learning rate is an extremely challenging task, and is increasingly gaining more attention. In this paper, we provide a theoretical analysis for the process of training Transformer and reveal the rationale behind the model crash phenomenon in the training process, termed \\textit{spectral energy concentration} of ${\\bW_q}^{\\top} \\bW_k$, which is the reason for a malignant entropy collapse, where ${\\bW_q}$ and $\\bW_k$ are the projection matrices for the query and the key in Transformer, respectively. To remedy this problem, motivated by \\textit{Weyl's Inequality}, we present a novel optimization strategy, \\ie, making the weight updating in successive steps smooth -- if the ratio $\\frac{\\sigma_{1}(\\nabla \\bW_t)}{\\sigma_{1}(\\bW_{t-1})}$ is larger than a threshold, we will automatically bound the learning rate to a weighted multiple of $\\frac{\\sigma_{1}(\\bW_{t-1})}{\\sigma_{1}(\\nabla \\bW_t)}$, where $\\nabla \\bW_t$ is the updating quantity in step $t$. Such an optimization strategy can prevent spectral energy concentration to only a few directions, and thus can avoid malignant entropy collapse which will trigger the model crash. We conduct extensive experiments using ViT, Swin-Transformer and GPT, showing that our optimization strategy can effectively and stably train these Transformers without using learning rate warmup.","authors":["Xianbiao Qi","Yelin He","Jiaquan Ye","Chun-Guang Li","Bojia Zi","Xili Dai","Qin Zou","Rong Xiao"],"url":"https://arxiv.org/abs/2505.21910"}
{"created":"2025-05-29","title":"AlignGen: Boosting Personalized Image Generation with Cross-Modality Prior Alignment","abstract":"Personalized image generation aims to integrate user-provided concepts into text-to-image models, enabling the generation of customized content based on a given prompt. Recent zero-shot approaches, particularly those leveraging diffusion transformers, incorporate reference image information through multi-modal attention mechanism. This integration allows the generated output to be influenced by both the textual prior from the prompt and the visual prior from the reference image. However, we observe that when the prompt and reference image are misaligned, the generated results exhibit a stronger bias toward the textual prior, leading to a significant loss of reference content. To address this issue, we propose AlignGen, a Cross-Modality Prior Alignment mechanism that enhances personalized image generation by: 1) introducing a learnable token to bridge the gap between the textual and visual priors, 2) incorporating a robust training strategy to ensure proper prior alignment, and 3) employing a selective cross-modal attention mask within the multi-modal attention mechanism to further align the priors. Experimental results demonstrate that AlignGen outperforms existing zero-shot methods and even surpasses popular test-time optimization approaches.","authors":["Yiheng Lin","Shifang Zhao","Ting Liu","Xiaochao Qu","Luoqi Liu","Yao Zhao","Yunchao Wei"],"url":"https://arxiv.org/abs/2505.21911"}
{"created":"2025-05-29","title":"Detecting Cultural Differences in News Video Thumbnails via Computational Aesthetics","abstract":"We propose a two-step approach for detecting differences in the style of images across sources of differing cultural affinity, where images are first clustered into finer visual themes based on content before their aesthetic features are compared. We test this approach on 2,400 YouTube video thumbnails taken equally from two U.S. and two Chinese YouTube channels, and relating equally to COVID-19 and the Ukraine conflict. Our results suggest that while Chinese thumbnails are less formal and more candid, U.S. channels tend to use more deliberate, proper photographs as thumbnails. In particular, U.S. thumbnails are less colorful, more saturated, darker, more finely detailed, less symmetric, sparser, less varied, and more up close and personal than Chinese thumbnails. We suggest that most of these differences reflect cultural preferences, and that our methods and observations can serve as a baseline against which suspected visual propaganda can be computed and compared.","authors":["Marvin Limpijankit","John Kender"],"url":"https://arxiv.org/abs/2505.21912"}
{"created":"2025-05-29","title":"LiDARDustX: A LiDAR Dataset for Dusty Unstructured Road Environments","abstract":"Autonomous driving datasets are essential for validating the progress of intelligent vehicle algorithms, which include localization, perception, and prediction. However, existing datasets are predominantly focused on structured urban environments, which limits the exploration of unstructured and specialized scenarios, particularly those characterized by significant dust levels. This paper introduces the LiDARDustX dataset, which is specifically designed for perception tasks under high-dust conditions, such as those encountered in mining areas. The LiDARDustX dataset consists of 30,000 LiDAR frames captured by six different LiDAR sensors, each accompanied by 3D bounding box annotations and point cloud semantic segmentation. Notably, over 80% of the dataset comprises dust-affected scenes. By utilizing this dataset, we have established a benchmark for evaluating the performance of state-of-the-art 3D detection and segmentation algorithms. Additionally, we have analyzed the impact of dust on perception accuracy and delved into the causes of these effects. The data and further information can be accessed at: https://github.com/vincentweikey/LiDARDustX.","authors":["Chenfeng Wei","Qi Wu","Si Zuo","Jiahua Xu","Boyang Zhao","Zeyu Yang","Guotao Xie","Shenhong Wang"],"url":"https://arxiv.org/abs/2505.21914"}
{"created":"2025-05-29","title":"BD Open LULC Map: High-resolution land use land cover mapping & benchmarking for urban development in Dhaka, Bangladesh","abstract":"Land Use Land Cover (LULC) mapping using deep learning significantly enhances the reliability of LULC classification, aiding in understanding geography, socioeconomic conditions, poverty levels, and urban sprawl. However, the scarcity of annotated satellite data, especially in South/East Asian developing countries, poses a major challenge due to limited funding, diverse infrastructures, and dense populations. In this work, we introduce the BD Open LULC Map (BOLM), providing pixel-wise LULC annotations across eleven classes (e.g., Farmland, Water, Forest, Urban Structure, Rural Built-Up) for Dhaka metropolitan city and its surroundings using high-resolution Bing satellite imagery (2.22 m/pixel). BOLM spans 4,392 sq km (891 million pixels), with ground truth validated through a three-stage process involving GIS experts. We benchmark LULC segmentation using DeepLab V3+ across five major classes and compare performance on Bing and Sentinel-2A imagery. BOLM aims to support reliable deep models and domain adaptation tasks, addressing critical LULC dataset gaps in South/East Asia.","authors":["Mir Sazzat Hossain","Ovi Paul","Md Akil Raihan Iftee","Rakibul Hasan Rajib","Abu Bakar Siddik Nayem","Anis Sarker","Arshad Momen","Md. Ashraful Amin","Amin Ahsan Ali","AKM Mahbubur Rahman"],"url":"https://arxiv.org/abs/2505.21915"}
{"created":"2025-05-29","title":"Mastering Agile Tasks with Limited Trials","abstract":"Embodied robots nowadays can already handle many real-world manipulation tasks. However, certain other real-world tasks (e.g., shooting a basketball into a hoop) are highly agile and require high execution precision, presenting additional challenges for methods primarily designed for quasi-static manipulation tasks. This leads to increased efforts in costly data collection, laborious reward design, or complex motion planning. Such tasks, however, are far less challenging for humans. Say a novice basketball player typically needs only $\\sim$10 attempts to make their first successful shot, by roughly imitating a motion prior and then iteratively adjusting their motion based on the past outcomes. Inspired by this human learning paradigm, we propose the Adaptive Diffusion Action Plannin (ADAP) algorithm, a simple & scalable approach which iteratively refines its action plan by few real-world trials within a learned prior motion pattern, until reaching a specific goal. Experiments demonstrated that ADAP can learn and accomplish a wide range of goal-conditioned agile dynamic tasks with human-level precision and efficiency directly in real-world, such as throwing a basketball into the hoop in fewer than 10 trials. Project website:https://adap-robotics.github.io/ .","authors":["Yihang Hu","Pingyue Sheng","Shengjie Wang","Yang Gao"],"url":"https://arxiv.org/abs/2505.21916"}
{"created":"2025-05-29","title":"Structured Divide-and-Conquer for the Definite Generalized Eigenvalue Problem","abstract":"This paper presents a fast, randomized divide-and-conquer algorithm for the definite generalized eigenvalue problem, which corresponds to pencils $(A,B)$ in which $A$ and $B$ are Hermitian and the Crawford number $\\gamma(A,B) = \\min_{||x||_2 = 1} |x^H(A+iB)x|$ is positive. Adapted from the fastest known method for diagonalizing arbitrary matrix pencils [Foundations of Computational Mathematics 2024], the algorithm is both inverse-free and highly parallel. As in the general case, randomization takes the form of perturbations applied to the input matrices, which regularize the problem for compatibility with fast, divide-and-conquer eigensolvers -- i.e., the now well-established phenomenon of pseudospectral shattering. We demonstrate that this high-level approach to diagonalization can be executed in a structure-aware fashion by (1) extending pseudospectral shattering to definite pencils under structured perturbations (either random diagonal or sampled from the Gaussian Unitary Ensemble) and (2) formulating the divide-and-conquer procedure in a way that maintains definiteness. The result is a specialized solver whose complexity, when applied to definite pencils, is provably lower than that of general divide-and-conquer.","authors":["James Demmel","Ioana Dumitriu","Ryan Schneider"],"url":"https://arxiv.org/abs/2505.21917"}
{"created":"2025-05-29","title":"Self-supervised Learning Method Using Transformer for Multi-dimensional Sensor Data Processing","abstract":"We developed a deep learning algorithm for human activity recognition using sensor signals as input. In this study, we built a pretrained language model based on the Transformer architecture, which is widely used in natural language processing. By leveraging this pretrained model, we aimed to improve performance on the downstream task of human activity recognition. While this task can be addressed using a vanilla Transformer, we propose an enhanced n-dimensional numerical processing Transformer that incorporates three key features: embedding n-dimensional numerical data through a linear layer, binning-based pre-processing, and a linear transformation in the output layer. We evaluated the effectiveness of our proposed model across five different datasets. Compared to the vanilla Transformer, our model demonstrated 10%-15% improvements in accuracy.","authors":["Haruki Kai","Tsuyoshi Okita"],"url":"https://arxiv.org/abs/2505.21918"}
{"created":"2025-05-29","title":"Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference","abstract":"The increasing adoption of large language models (LLMs) with extended context windows necessitates efficient Key-Value Cache (KVC) management to optimize inference performance. Inference workloads like Retrieval-Augmented Generation (RAG) and agents exhibit high cache reusability, making efficient caching critical to reducing redundancy and improving speed. We analyze real-world KVC access patterns using publicly available traces and evaluate commercial key-value stores like Redis and state-of-the-art RDMA-based systems (CHIME [1] and Sherman [2]) for KVC metadata management. Our work demonstrates the lack of tailored storage solution for KVC prefilling, underscores the need for an efficient distributed caching system with optimized metadata management for LLM workloads, and provides insights into designing improved KVC management systems for scalable, low-latency inference.","authors":["Yue Zhu","Hao Yu","Chen Wang","Zhuoran Liu","Eun Kyung Lee"],"url":"https://arxiv.org/abs/2505.21919"}
{"created":"2025-05-29","title":"InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective","abstract":"The Segment Anything Model (SAM), a vision foundation model, exhibits impressive zero-shot capabilities in general tasks but struggles in specialized domains. Parameter-efficient fine-tuning (PEFT) is a promising approach to unleash the potential of SAM in novel scenarios. However, existing PEFT methods for SAM neglect the domain-invariant relations encoded in the pre-trained model. To bridge this gap, we propose InfoSAM, an information-theoretic approach that enhances SAM fine-tuning by distilling and preserving its pre-trained segmentation knowledge. Specifically, we formulate the knowledge transfer process as two novel mutual information-based objectives: (i) to compress the domain-invariant relation extracted from pre-trained SAM, excluding pseudo-invariant information as possible, and (ii) to maximize mutual information between the relational knowledge learned by the teacher (pre-trained SAM) and the student (fine-tuned model). The proposed InfoSAM establishes a robust distillation framework for PEFT of SAM. Extensive experiments across diverse benchmarks validate InfoSAM's effectiveness in improving SAM family's performance on real-world tasks, demonstrating its adaptability and superiority in handling specialized scenarios.","authors":["Yuanhong Zhang","Muyao Yuan","Weizhan Zhang","Tieliang Gong","Wen Wen","Jiangyong Ying","Weijie Shi"],"url":"https://arxiv.org/abs/2505.21920"}
{"created":"2025-05-29","title":"FALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design","abstract":"Designing analog circuits from performance specifications is a complex, multi-stage process encompassing topology selection, parameter inference, and layout feasibility. We introduce FALCON, a unified machine learning framework that enables fully automated, specification-driven analog circuit synthesis through topology selection and layout-constrained optimization. Given a target performance, FALCON first selects an appropriate circuit topology using a performance-driven classifier guided by human design heuristics. Next, it employs a custom, edge-centric graph neural network trained to map circuit topology and parameters to performance, enabling gradient-based parameter inference through the learned forward model. This inference is guided by a differentiable layout cost, derived from analytical equations capturing parasitic and frequency-dependent effects, and constrained by design rules. We train and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wave circuits, generated and simulated using Cadence Spectre across 20 expert-designed topologies. Through this evaluation, FALCON demonstrates >99\\% accuracy in topology inference, <10\\% relative error in performance prediction, and efficient layout-aware design that completes in under 1 second per instance. Together, these results position FALCON as a practical and extensible foundation model for end-to-end analog circuit design automation.","authors":["Asal Mehradfar","Xuzhe Zhao","Yilun Huang","Emir Ceyani","Yankai Yang","Shihao Han","Hamidreza Aghasi","Salman Avestimehr"],"url":"https://arxiv.org/abs/2505.21923"}
{"created":"2025-05-29","title":"RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination","abstract":"We present RenderFormer, a neural rendering pipeline that directly renders an image from a triangle-based representation of a scene with full global illumination effects and that does not require per-scene training or fine-tuning. Instead of taking a physics-centric approach to rendering, we formulate rendering as a sequence-to-sequence transformation where a sequence of tokens representing triangles with reflectance properties is converted to a sequence of output tokens representing small patches of pixels. RenderFormer follows a two stage pipeline: a view-independent stage that models triangle-to-triangle light transport, and a view-dependent stage that transforms a token representing a bundle of rays to the corresponding pixel values guided by the triangle-sequence from the view-independent stage. Both stages are based on the transformer architecture and are learned with minimal prior constraints. We demonstrate and evaluate RenderFormer on scenes with varying complexity in shape and light transport.","authors":["Chong Zeng","Yue Dong","Pieter Peers","Hongzhi Wu","Xin Tong"],"url":"https://arxiv.org/abs/2505.21925"}
{"created":"2025-05-29","title":"Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning","abstract":"In natural language processing (NLP) and computer vision (CV), the successful application of foundation models across diverse tasks has demonstrated their remarkable potential. However, despite the rich structural and textual information embedded in knowledge graphs (KGs), existing research of foundation model for KG has primarily focused on their structural aspects, with most efforts restricted to in-KG tasks (e.g., knowledge graph completion, KGC). This limitation has hindered progress in addressing more challenging out-of-KG tasks. In this paper, we introduce MERRY, a foundation model for general knowledge graph reasoning, and investigate its performance across two task categories: in-KG reasoning tasks (e.g., KGC) and out-of-KG tasks (e.g., KG question answering, KGQA). We not only utilize the structural information, but also the textual information in KGs. Specifically, we propose a multi-perspective Conditional Message Passing (CMP) encoding architecture to bridge the gap between textual and structural modalities, enabling their seamless integration. Additionally, we introduce a dynamic residual fusion module to selectively retain relevant textual information and a flexible edge scoring mechanism to adapt to diverse downstream tasks. Comprehensive evaluations on 28 datasets demonstrate that MERRY outperforms existing baselines in most scenarios, showcasing strong reasoning capabilities within KGs and excellent generalization to out-of-KG tasks such as KGQA.","authors":["Yin Hua","Zhiqiang Liu","Mingyang Chen","Zheng Fang","Chi Man Wong","Lingxiao Li","Chi Man Vong","Huajun Chen","Wen Zhang"],"url":"https://arxiv.org/abs/2505.21926"}
{"created":"2025-05-29","title":"Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets","abstract":"This paper develops an ensemble method for fine-tuning a language model to multiple datasets. Existing methods, such as quantized LoRA (QLoRA), are efficient when adapting to a single dataset. When training on multiple datasets of different tasks, a common setup in practice, it remains unclear how to design an efficient adaptation for fine-tuning language models. We propose to use an ensemble of multiple smaller adapters instead of a single adapter per task. We design an efficient algorithm that partitions $n$ datasets into $m$ groups, where $m$ is typically much smaller than $n$ in practice, and train one adapter for each group before taking a weighted combination to form the ensemble. The algorithm leverages a first-order approximation property of low-rank adaptation to quickly obtain the fine-tuning performances of dataset combinations since methods like LoRA stay close to the base model. Hence, we use the gradients of the base model to estimate its behavior during fine-tuning. Empirically, this approximation holds with less than $1\\%$ error on models with up to $34$ billion parameters, leading to an estimation of true fine-tuning performances under $5\\%$ error while speeding up computation compared to base fine-tuning by $105$ times. When applied to fine-tune Llama and GPT models on ten text classification tasks, our approach provides up to $10\\%$ higher average test accuracy over QLoRA, with only $9\\%$ more FLOPs. On a Llama model with $34$ billion parameters, an ensemble of QLoRA increases test accuracy by $3\\%$ compared to QLoRA, with only $8\\%$ more FLOPs.","authors":["Dongyue Li","Ziniu Zhang","Lu Wang","Hongyang R. Zhang"],"url":"https://arxiv.org/abs/2505.21930"}
{"created":"2025-05-29","title":"Large Language Models for Solving Economic Dispatch Problem","abstract":"This paper investigates the capability of off-the-shelf large language models (LLMs) to solve the economic dispatch (ED) problem. ED is a hard-constrained optimization problem solved on a day-ahead timescale by grid operators to minimize electricity generation costs while accounting for physical and engineering constraints. Numerous approaches have been proposed, but these typically require either mathematical formulations, face convergence issues, or depend on extensive labeled data and training time. This work implements LLMs enhanced with reasoning capabilities to address the classic lossless ED problem. The proposed approach avoids the need for explicit mathematical formulations, does not suffer from convergence challenges, and requires neither labeled data nor extensive training. A few-shot learning technique is utilized in two different prompting contexts. The IEEE 118-bus system with 19 generation units serves as the evaluation benchmark. Results demonstrate that various prompting strategies enable LLMs to effectively solve the ED problem, offering a convenient and efficient alternative. Consequently, this approach presents a promising future solution for ED tasks, particularly when foundational power system models are available.","authors":["Sina Mohammadi","Ali Hassan","Rouzbeh Haghighi","Van-Hai Bui","Wencong Su"],"url":"https://arxiv.org/abs/2505.21931"}
{"created":"2025-05-29","title":"From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models","abstract":"Since the advent of Large Language Models (LLMs), efforts have largely focused on improving their instruction-following and deductive reasoning abilities, leaving open the question of whether these models can truly discover new knowledge. In pursuit of artificial general intelligence (AGI), there is a growing need for models that not only execute commands or retrieve information but also learn, reason, and generate new knowledge by formulating novel hypotheses and theories that deepen our understanding of the world. Guided by Peirce's framework of abduction, deduction, and induction, this survey offers a structured lens to examine LLM-based hypothesis discovery. We synthesize existing work in hypothesis generation, application, and validation, identifying both key achievements and critical gaps. By unifying these threads, we illuminate how LLMs might evolve from mere ``information executors'' into engines of genuine innovation, potentially transforming research, science, and real-world problem solving.","authors":["Kaiyu He","Zhiyu Chen"],"url":"https://arxiv.org/abs/2505.21935"}
{"created":"2025-05-29","title":"RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments","abstract":"Computer-use agents (CUAs) promise to automate complex tasks across operating systems (OS) and the web, but remain vulnerable to indirect prompt injection. Current evaluations of this threat either lack support realistic but controlled environments or ignore hybrid web-OS attack scenarios involving both interfaces. To address this, we propose RedTeamCUA, an adversarial testing framework featuring a novel hybrid sandbox that integrates a VM-based OS environment with Docker-based web platforms. Our sandbox supports key features tailored for red teaming, such as flexible adversarial scenario configuration, and a setting that decouples adversarial evaluation from navigational limitations of CUAs by initializing tests directly at the point of an adversarial injection. Using RedTeamCUA, we develop RTC-Bench, a comprehensive benchmark with 864 examples that investigate realistic, hybrid web-OS attack scenarios and fundamental security vulnerabilities. Benchmarking current frontier CUAs identifies significant vulnerabilities: Claude 3.7 Sonnet | CUA demonstrates an ASR of 42.9%, while Operator, the most secure CUA evaluated, still exhibits an ASR of 7.6%. Notably, CUAs often attempt to execute adversarial tasks with an Attempt Rate as high as 92.5%, although failing to complete them due to capability limitations. Nevertheless, we observe concerning ASRs of up to 50% in realistic end-to-end settings, with the recently released frontier Claude 4 Opus | CUA showing an alarming ASR of 48%, demonstrating that indirect prompt injection presents tangible risks for even advanced CUAs despite their capabilities and safeguards. Overall, RedTeamCUA provides an essential framework for advancing realistic, controlled, and systematic analysis of CUA vulnerabilities, highlighting the urgent need for robust defenses to indirect prompt injection prior to real-world deployment.","authors":["Zeyi Liao","Jaylen Jones","Linxi Jiang","Eric Fosler-Lussier","Yu Su","Zhiqiang Lin","Huan Sun"],"url":"https://arxiv.org/abs/2505.21936"}
{"created":"2025-05-29","title":"Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic Languages","abstract":"Translating multi-word expressions (MWEs) and idioms requires a deep understanding of the cultural nuances of both the source and target languages. This challenge is further amplified by the one-to-many nature of idiomatic translations, where a single source idiom can have multiple target-language equivalents depending on cultural references and contextual variations. Traditional static knowledge graphs (KGs) and prompt-based approaches struggle to capture these complex relationships, often leading to suboptimal translations. To address this, we propose IdiomCE, an adaptive graph neural network (GNN) based methodology that learns intricate mappings between idiomatic expressions, effectively generalizing to both seen and unseen nodes during training. Our proposed method enhances translation quality even in resource-constrained settings, facilitating improved idiomatic translation in smaller models. We evaluate our approach on multiple idiomatic translation datasets using reference-less metrics, demonstrating significant improvements in translating idioms from English to various Indian languages.","authors":["Pratik Rakesh Singh","Kritarth Prasad","Mohammadi Zaki","Pankaj Wasnik"],"url":"https://arxiv.org/abs/2505.21937"}
{"created":"2025-05-29","title":"Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection","abstract":"Adversarial attacks on stochastic bandits have traditionally relied on some unrealistic assumptions, such as per-round reward manipulation and unbounded perturbations, limiting their relevance to real-world systems. We propose a more practical threat model, Fake Data Injection, which reflects realistic adversarial constraints: the attacker can inject only a limited number of bounded fake feedback samples into the learner's history, simulating legitimate interactions. We design efficient attack strategies under this model, explicitly addressing both magnitude constraints (on reward values) and temporal constraints (on when and how often data can be injected). Our theoretical analysis shows that these attacks can mislead both Upper Confidence Bound (UCB) and Thompson Sampling algorithms into selecting a target arm in nearly all rounds while incurring only sublinear attack cost. Experiments on synthetic and real-world datasets validate the effectiveness of our strategies, revealing significant vulnerabilities in widely used stochastic bandit algorithms under practical adversarial scenarios.","authors":["Qirun Zeng","Eric He","Richard Hoffmann","Xuchuang Wang","Jinhang Zuo"],"url":"https://arxiv.org/abs/2505.21938"}
{"created":"2025-05-29","title":"Improved Approximation Algorithms for Chromatic and Pseudometric-Weighted Correlation Clustering","abstract":"Correlation Clustering (CC) is a foundational problem in unsupervised learning that models binary similarity relations using labeled graphs. While classical CC has been widely studied, many real-world applications involve more nuanced relationships, either multi-class categorical interactions or varying confidence levels in edge labels. To address these, two natural generalizations have been proposed: Chromatic Correlation Clustering (CCC), which assigns semantic colors to edge labels, and pseudometric-weighted CC, which allows edge weights satisfying the triangle inequality. In this paper, we develop improved approximation algorithms for both settings. Our approach leverages LP-based pivoting techniques combined with problem-specific rounding functions. For the pseudometric-weighted correlation clustering problem, we present a tight $10/3$-approximation algorithm, matching the best possible bound achievable within the framework of standard LP relaxation combined with specialized rounding. For the Chromatic Correlation Clustering (CCC) problem, we improve the approximation ratio from the previous best of $2.5$ to $2.15$, and we establish a lower bound of $2.11$ within the same analytical framework, highlighting the near-optimality of our result.","authors":["Dahoon Lee","Chenglin Fan","Euiwoong Lee"],"url":"https://arxiv.org/abs/2505.21939"}
{"created":"2025-05-29","title":"RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering","abstract":"Large Language Models (LLMs) excel in many areas but continue to face challenges with complex reasoning tasks, such as Multi-Hop Question Answering (MHQA). MHQA requires integrating evidence from diverse sources while managing intricate logical dependencies, often leads to errors in reasoning. Retrieval-Augmented Generation (RAG), widely employed in MHQA tasks, faces challenges in effectively filtering noisy data and retrieving all necessary evidence, thereby limiting its effectiveness in addressing MHQA challenges. To address these challenges, we propose RISE:Reasoning Enhancement via Iterative Self-Exploration, a novel framework designed to enhance models' reasoning capability through iterative self-exploration. Specifically, RISE involves three key steps in addressing MHQA tasks: question decomposition, retrieve-then-read, and self-critique. By leveraging continuous self-exploration, RISE identifies accurate reasoning paths, iteratively self-improving the model's capability to integrate evidence, maintain logical consistency, and enhance performance in MHQA tasks. Extensive experiments on multiple MHQA benchmarks demonstrate that RISE significantly improves reasoning accuracy and task performance.","authors":["Bolei He","Xinran He","Mengke Chen","Xianwei Xue","Ying Zhu","Zhenhua Ling"],"url":"https://arxiv.org/abs/2505.21940"}
{"created":"2025-05-29","title":"Test-Time Scaling with Repeated Sampling Improves Multilingual Text Generation","abstract":"Inference-time scaling via repeated sampling has shown promise in reasoning tasks, but its effectiveness in multilingual generation remains underexplored. We evaluate this approach using perplexity- and reward-based verifiers on two multilingual benchmarks: the Aya Evaluation Suite and m-ArenaHard. Our results show consistent quality improvements, with gains exceeding 35% in some cases. While perplexity-based scoring is effective for open-ended prompts, only reward-based verifiers improve performance on tasks requiring reasoning (e.g., math, code). Our results demonstrate the broader utility of repeated sampling for multilingual text generation and underscore the importance of selecting right verifiers for the task.","authors":["Ashim Gupta","Vivek Srikumar"],"url":"https://arxiv.org/abs/2505.21941"}
{"created":"2025-05-29","title":"Continual Learning Beyond Experience Rehearsal and Full Model Surrogates","abstract":"Continual learning (CL) has remained a significant challenge for deep neural networks as learning new tasks erases previously acquired knowledge, either partially or completely. Existing solutions often rely on experience rehearsal or full model surrogates to mitigate CF. While effective, these approaches introduce substantial memory and computational overhead, limiting their scalability and applicability in real-world scenarios. To address this, we propose SPARC, a scalable CL approach that eliminates the need for experience rehearsal and full-model surrogates. By effectively combining task-specific working memories and task-agnostic semantic memory for cross-task knowledge consolidation, SPARC results in a remarkable parameter efficiency, using only 6% of the parameters required by full-model surrogates. Despite its lightweight design, SPARC achieves superior performance on Seq-TinyImageNet and matches rehearsal-based methods on various CL benchmarks. Additionally, weight re-normalization in the classification layer mitigates task-specific biases, establishing SPARC as a practical and scalable solution for CL under stringent efficiency constraints.","authors":["Prashant Bhat","Laurens Niesten","Elahe Arani","Bahram Zonooz"],"url":"https://arxiv.org/abs/2505.21942"}
{"created":"2025-05-29","title":"Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting","abstract":"Point detection has been developed to locate pedestrians in crowded scenes by training a counter through a point-to-point (P2P) supervision scheme. Despite its excellent localization and counting performance, training a point-based counter still faces challenges concerning annotation labor: hundreds to thousands of points are required to annotate a single sample capturing a dense crowd. In this paper, we integrate point-based methods into a semi-supervised counting framework based on pseudo-labeling, enabling the training of a counter with only a few annotated samples supplemented by a large volume of pseudo-labeled data. However, during implementation, the training encounters issues as the confidence for pseudo-labels fails to be propagated to background pixels via the P2P. To tackle this challenge, we devise a point-specific activation map (PSAM) to visually interpret the phenomena occurring during the ill-posed training. Observations from the PSAM suggest that the feature map is excessively activated by the loss for unlabeled data, causing the decoder to misinterpret these over-activations as pedestrians. To mitigate this issue, we propose a point-to-region (P2R) scheme to substitute P2P, which segments out local regions rather than detects a point corresponding to a pedestrian for supervision. Consequently, pixels in the local region can share the same confidence with the corresponding pseudo points. Experimental results in both semi-supervised counting and unsupervised domain adaptation highlight the advantages of our method, illustrating P2R can resolve issues identified in PSAM. The code is available at https://github.com/Elin24/P2RLoss.","authors":["Wei Lin","Chenyang Zhao","Antoni B. Chan"],"url":"https://arxiv.org/abs/2505.21943"}
{"created":"2025-05-29","title":"Stochastic Primal-Dual Double Block-Coordinate for Two-way Partial AUC Maximization","abstract":"Two-way partial AUC (TPAUC) is a critical performance metric for binary classification with imbalanced data, as it focuses on specific ranges of the true positive rate (TPR) and false positive rate (FPR). However, stochastic algorithms for TPAUC optimization remain under-explored, with existing methods either limited to approximated TPAUC loss functions or burdened by sub-optimal complexities. To overcome these limitations, we introduce two innovative stochastic primal-dual double block-coordinate algorithms for TPAUC maximization. These algorithms utilize stochastic block-coordinate updates for both the primal and dual variables, catering to both convex and non-convex settings. We provide theoretical convergence rate analyses, demonstrating significant improvements over prior approaches. Our experimental results, based on multiple benchmark datasets, validate the superior performance of our algorithms, showcasing faster convergence and better generalization. This work advances the state of the art in TPAUC optimization and offers practical tools for real-world machine learning applications.","authors":["Linli Zhou","Bokun Wang","My T. Thai","Tianbao Yang"],"url":"https://arxiv.org/abs/2505.21944"}
{"created":"2025-05-29","title":"Fluid Simulation on Vortex Particle Flow Maps","abstract":"We propose the Vortex Particle Flow Map (VPFM) method to simulate incompressible flow with complex vortical evolution in the presence of dynamic solid boundaries. The core insight of our approach is that vorticity is an ideal quantity for evolution on particle flow maps, enabling significantly longer flow map distances compared to other fluid quantities like velocity or impulse. To achieve this goal, we developed a hybrid Eulerian-Lagrangian representation that evolves vorticity and flow map quantities on vortex particles, while reconstructing velocity on a background grid. The method integrates three key components: (1) a vorticity-based particle flow map framework, (2) an accurate Hessian evolution scheme on particles, and (3) a solid boundary treatment for no-through and no-slip conditions in VPFM. These components collectively allow a substantially longer flow map length (3-12 times longer) than the state-of-the-art, enhancing vorticity preservation over extended spatiotemporal domains. We validated the performance of VPFM through diverse simulations, demonstrating its effectiveness in capturing complex vortex dynamics and turbulence phenomena.","authors":["Sinan Wang","Junwei Zhou","Fan Feng","Zhiqi Li","Yuchen Sun","Duowen Chen","Greg Turk","Bo Zhu"],"url":"https://arxiv.org/abs/2505.21946"}
{"created":"2025-05-29","title":"When Feedback Empowers the Uplink: Integrating Adaptive Coding with Wireless Power Transfer","abstract":"Energy consumption and device lifetime are critical concerns for battery-constrained IoT devices. This paper introduces the Feedback-Aided Coding and Energy Transfer (FACET) framework, which synergistically combines adaptive feedback channel coding with wireless power transfer. FACET leverages the saturation effect of feedback coding, where increasing downlink power yields diminishing returns, to design a dual-purpose feedback mechanism that simultaneously guides uplink coding and replenishes device energy. We characterize the inherent tradeoff between feedback precision and harvested power, and formulate a fairness-constrained min-max optimization problem to minimize worst-case net energy consumption. An efficient algorithm based on alternating optimization and Lagrangian duality is developed, with each subproblem admitting a closed-form solution. Simulations show that FACET nearly triples device lifetime compared to conventional feedback coding architectures, and remains robust across a wide range of power regimes. These results suggest that FACET not only improves communication efficiency but also redefines the role of feedback in energy-constrained IoT systems.","authors":["Zijian Yang","Yulin Shao","Shaodan Ma"],"url":"https://arxiv.org/abs/2505.21951"}
{"created":"2025-05-29","title":"UniTalk: Towards Universal Active Speaker Detection in Real World Scenarios","abstract":"We present UniTalk, a novel dataset specifically designed for the task of active speaker detection, emphasizing challenging scenarios to enhance model generalization. Unlike previously established benchmarks such as AVA, which predominantly features old movies and thus exhibits significant domain gaps, UniTalk focuses explicitly on diverse and difficult real-world conditions. These include underrepresented languages, noisy backgrounds, and crowded scenes - such as multiple visible speakers speaking concurrently or in overlapping turns. It contains over 44.5 hours of video with frame-level active speaker annotations across 48,693 speaking identities, and spans a broad range of video types that reflect real-world conditions. Through rigorous evaluation, we show that state-of-the-art models, while achieving nearly perfect scores on AVA, fail to reach saturation on UniTalk, suggesting that the ASD task remains far from solved under realistic conditions. Nevertheless, models trained on UniTalk demonstrate stronger generalization to modern \"in-the-wild\" datasets like Talkies and ASW, as well as to AVA. UniTalk thus establishes a new benchmark for active speaker detection, providing researchers with a valuable resource for developing and evaluating versatile and resilient models.","authors":["Le Thien Phuc Nguyen","Zhuoran Yu","Khoa Quang Nhat Cao","Yuwei Guo","Tu Ho Manh Pham","Tuan Tai Nguyen","Toan Ngo Duc Vo","Lucas Poon","Soochahn Lee","Yong Jae Lee"],"url":"https://arxiv.org/abs/2505.21954"}
{"created":"2025-05-29","title":"Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs","abstract":"Large vision-language models (LVLMs) are increasingly deployed in interactive applications such as virtual and augmented reality, where first-person (egocentric) view captured by head-mounted cameras serves as key input. While this view offers fine-grained cues about user attention and hand-object interactions, their narrow field of view and lack of global context often lead to failures on spatially or contextually demanding queries. To address this, we introduce a framework that augments egocentric inputs with third-person (exocentric) views, providing complementary information such as global scene layout and object visibility to LVLMs. We present E3VQA, the first benchmark for multi-view question answering with 4K high-quality question-answer pairs grounded in synchronized ego-exo image pairs. Additionally, we propose M3CoT, a training-free prompting technique that constructs a unified scene representation by integrating scene graphs from three complementary perspectives. M3CoT enables LVLMs to reason more effectively across views, yielding consistent performance gains (4.84% for GPT-4o and 5.94% for Gemini 2.0 Flash) over a recent CoT baseline. Our extensive evaluation reveals key strengths and limitations of LVLMs in multi-view reasoning and highlights the value of leveraging both egocentric and exocentric inputs.","authors":["Insu Lee","Wooje Park","Jaeyun Jang","Minyoung Noh","Kyuhong Shim","Byonghyo Shim"],"url":"https://arxiv.org/abs/2505.21955"}
{"created":"2025-05-29","title":"Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation","abstract":"Text-to-image generation increasingly demands access to domain-specific, fine-grained, and rapidly evolving knowledge that pretrained models cannot fully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to address this by retrieving globally relevant images, but they fail when no single image contains all desired elements from a complex user query. We propose Cross-modal RAG, a novel framework that decomposes both queries and images into sub-dimensional components, enabling subquery-aware retrieval and generation. Our method introduces a hybrid retrieval strategy - combining a sub-dimensional sparse retriever with a dense retriever - to identify a Pareto-optimal set of images, each contributing complementary aspects of the query. During generation, a multimodal large language model is guided to selectively condition on relevant visual features aligned to specific subqueries, ensuring subquery-aware image synthesis. Extensive experiments on MS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal RAG significantly outperforms existing baselines in both retrieval and generation quality, while maintaining high efficiency.","authors":["Mengdan Zhu","Senhao Cheng","Guangji Bai","Yifei Zhang","Liang Zhao"],"url":"https://arxiv.org/abs/2505.21956"}
{"created":"2025-05-29","title":"Resolving Knowledge Conflicts in Domain-specific Data Selection: A Case Study on Medical Instruction-tuning","abstract":"Domain-specific instruction-tuning has become the defacto standard for improving the performance of large language models (LLMs) in specialized applications, e.g., medical question answering. Since the instruction-tuning dataset might contain redundant or low-quality data, data selection (DS) is usually required to maximize the data efficiency. Despite the successes in the general domain, current DS methods often struggle to select the desired data for domain-specific instruction-tuning. One of the main reasons is that they neglect the impact of knowledge conflicts, i.e., the discrepancy between LLMs' pretrained knowledge and context knowledge of instruction data, which could damage LLMs' prior abilities and lead to hallucination. To this end, we propose a simple-yet-effective Knowledge-aware Data Selection (namely KDS) framework to select the domain-specific instruction-tuning data that meets LLMs' actual needs. The core of KDS is to leverage two knowledge-aware metrics for quantitatively measuring knowledge conflicts from two aspects: context-memory knowledge alignment and intra-memory knowledge consistency. By filtering the data with large knowledge conflicts and sampling the high-quality and diverse data, KDS can effectively stimulate the LLMs' abilities and achieve better domain-specific performance. Taking the medical domain as the testbed, we conduct extensive experiments and empirically prove that KDS surpasses the other baselines and brings significant and consistent performance gains among all LLMs. More encouragingly, KDS effectively improves the model generalization and alleviates the hallucination problem.","authors":["Qihuang Zhong","Liang Ding","Fei Liao","Juhua Liu","Bo Du","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.21958"}
{"created":"2025-05-29","title":"EnsemW2S: Enhancing Weak-to-Strong Generalization with Large Language Model Ensembles","abstract":"With Large Language Models (LLMs) rapidly approaching and potentially surpassing human-level performance, it has become imperative to develop approaches capable of effectively supervising and enhancing these powerful models using smaller, human-level models exposed to only human-level data. We address this critical weak-to-strong (W2S) generalization challenge by proposing a novel method aimed at improving weak experts, by training on the same limited human-level data, enabling them to generalize to complex, super-human-level tasks. Our approach, called \\textbf{EnsemW2S}, employs a token-level ensemble strategy that iteratively combines multiple weak experts, systematically addressing the shortcomings identified in preceding iterations. By continuously refining these weak models, we significantly enhance their collective ability to supervise stronger student models. We extensively evaluate the generalization performance of both the ensemble of weak experts and the subsequent strong student model across in-distribution (ID) and out-of-distribution (OOD) datasets. For OOD, we specifically introduce question difficulty as an additional dimension for defining distributional shifts. Our empirical results demonstrate notable improvements, achieving 4\\%, and 3.2\\% improvements on ID datasets and, upto 6\\% and 2.28\\% on OOD datasets for experts and student models respectively, underscoring the effectiveness of our proposed method in advancing W2S generalization.","authors":["Aakriti Agrawal","Mucong Ding","Zora Che","Chenghao Deng","Anirudh Satheesh","Bang An","Bayan Bruss","John Langford","Furong Huang"],"url":"https://arxiv.org/abs/2505.21959"}
{"created":"2025-05-29","title":"One-Way Ticket:Time-Independent Unified Encoder for Distilling Text-to-Image Diffusion Models","abstract":"Text-to-Image (T2I) diffusion models have made remarkable advancements in generative modeling; however, they face a trade-off between inference speed and image quality, posing challenges for efficient deployment. Existing distilled T2I models can generate high-fidelity images with fewer sampling steps, but often struggle with diversity and quality, especially in one-step models. From our analysis, we observe redundant computations in the UNet encoders. Our findings suggest that, for T2I diffusion models, decoders are more adept at capturing richer and more explicit semantic information, while encoders can be effectively shared across decoders from diverse time steps. Based on these observations, we introduce the first Time-independent Unified Encoder TiUE for the student model UNet architecture, which is a loop-free image generation approach for distilling T2I diffusion models. Using a one-pass scheme, TiUE shares encoder features across multiple decoder time steps, enabling parallel sampling and significantly reducing inference time complexity. In addition, we incorporate a KL divergence term to regularize noise prediction, which enhances the perceptual realism and diversity of the generated images. Experimental results demonstrate that TiUE outperforms state-of-the-art methods, including LCM, SD-Turbo, and SwiftBrushv2, producing more diverse and realistic results while maintaining the computational efficiency.","authors":["Senmao Li","Lei Wang","Kai Wang","Tao Liu","Jiehang Xie","Joost van de Weijer","Fahad Shahbaz Khan","Shiqi Yang","Yaxing Wang","Jian Yang"],"url":"https://arxiv.org/abs/2505.21960"}
{"created":"2025-05-29","title":"A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding","abstract":"While unmanned aerial vehicles (UAVs) offer wide-area, high-altitude coverage for anomaly detection, they face challenges such as dynamic viewpoints, scale variations, and complex scenes. Existing datasets and methods, mainly designed for fixed ground-level views, struggle to adapt to these conditions, leading to significant performance drops in drone-view scenarios. To bridge this gap, we introduce A2Seek (Aerial Anomaly Seek), a large-scale, reasoning-centric benchmark dataset for aerial anomaly understanding. This dataset covers various scenarios and environmental conditions, providing high-resolution real-world aerial videos with detailed annotations, including anomaly categories, frame-level timestamps, region-level bounding boxes, and natural language explanations for causal reasoning. Building on this dataset, we propose A2Seek-R1, a novel reasoning framework that generalizes R1-style strategies to aerial anomaly understanding, enabling a deeper understanding of \"Where\" anomalies occur and \"Why\" they happen in aerial frames. To this end, A2Seek-R1 first employs a graph-of-thought (GoT)-guided supervised fine-tuning approach to activate the model's latent reasoning capabilities on A2Seek. Then, we introduce Aerial Group Relative Policy Optimization (A-GRPO) to design rule-based reward functions tailored to aerial scenarios. Furthermore, we propose a novel \"seeking\" mechanism that simulates UAV flight behavior by directing the model's attention to informative regions. Extensive experiments demonstrate that A2Seek-R1 achieves up to a 22.04% improvement in AP for prediction accuracy and a 13.9% gain in mIoU for anomaly localization, exhibiting strong generalization across complex environments and out-of-distribution scenarios. Our dataset and code will be released at https://hayneyday.github.io/A2Seek/.","authors":["Mengjingcheng Mo","Xinyang Tong","Jiaxu Leng","Mingpi Tan","Jiankang Zheng","Yiran Liu","Haosheng Chen","Ji Gan","Weisheng Li","Xinbo Gao"],"url":"https://arxiv.org/abs/2505.21962"}
{"created":"2025-05-29","title":"LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents","abstract":"Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks. To further tailor LLMs to specific domains or applications, post-training techniques such as Supervised Fine-Tuning (SFT), Preference Learning, and model merging are commonly employed. While each of these methods has been extensively studied in isolation, the automated construction of complete post-training pipelines remains an underexplored area. Existing approaches typically rely on manual design or focus narrowly on optimizing individual components, such as data ordering or merging strategies. In this work, we introduce LaMDAgent (short for Language Model Developing Agent), a novel framework that autonomously constructs and optimizes full post-training pipelines through the use of LLM-based agents. LaMDAgent systematically explores diverse model generation techniques, datasets, and hyperparameter configurations, leveraging task-based feedback to discover high-performing pipelines with minimal human intervention. Our experiments show that LaMDAgent improves tool-use accuracy by 9.0 points while preserving instruction-following capabilities. Moreover, it uncovers effective post-training strategies that are often overlooked by conventional human-driven exploration. We further analyze the impact of data and model size scaling to reduce computational costs on the exploration, finding that model size scalings introduces new challenges, whereas scaling data size enables cost-effective pipeline discovery.","authors":["Taro Yano","Yoichi Ishibashi","Masafumi Oyamada"],"url":"https://arxiv.org/abs/2505.21963"}
{"created":"2025-05-29","title":"UI-Evol: Automatic Knowledge Evolving for Computer Use Agents","abstract":"External knowledge has played a crucial role in the recent development of computer use agents. We identify a critical knowledge-execution gap: retrieved knowledge often fails to translate into effective real-world task execution. Our analysis shows even 90\\% correct knowledge yields only 41\\% execution success rate. To bridge this gap, we propose UI-Evol, a plug-and-play module for autonomous GUI knowledge evolution. UI-Evol consists of two stages: a Retrace Stage that extracts faithful objective action sequences from actual agent-environment interactions, and a Critique Stage that refines existing knowledge by comparing these sequences against external references. We conduct comprehensive experiments on the OSWorld benchmark with the state-of-the-art Agent S2. Our results demonstrate that UI-Evol not only significantly boosts task performance but also addresses a previously overlooked issue of high behavioral standard deviation in computer use agents, leading to superior performance on computer use tasks and substantially improved agent reliability.","authors":["Ziyun Zhang","Xinyi Liu","Xiaoyi Zhang","Jun Wang","Gang Chen","Yan Lu"],"url":"https://arxiv.org/abs/2505.21964"}
{"created":"2025-05-29","title":"MapStory: LLM-Powered Text-Driven Map Animation Prototyping with Human-in-the-Loop Editing","abstract":"We introduce MapStory, an LLM-powered animation authoring tool that generates editable map animation sequences directly from natural language text. Given a user-written script, MapStory leverages an agentic architecture to automatically produce a scene breakdown, which decomposes the script into key animation building blocks such as camera movements, visual highlights, and animated elements. Our system includes a researcher component that accurately queries geospatial information by leveraging an LLM with web search, enabling the automatic extraction of relevant regions, paths, and coordinates while allowing users to edit and query for changes or additional information to refine the results. Additionally, users can fine-tune parameters of these blocks through an interactive timeline editor. We detail the system's design and architecture, informed by formative interviews with professional animators and an analysis of 200 existing map animation videos. Our evaluation, which includes expert interviews (N=5) and a usability study (N=12), demonstrates that MapStory enables users to create map animations with ease, facilitates faster iteration, encourages creative exploration, and lowers barriers to creating map-centric stories.","authors":["Aditya Gunturu","Ben Pearman","Keiichi Ihara","Morteza Faraji","Bryan Wang","Rubaiat Habib Kazi","Ryo Suzuki"],"url":"https://arxiv.org/abs/2505.21966"}
{"created":"2025-05-29","title":"Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack","abstract":"Large Vision-Language Models (LVLMs) have shown remarkable capabilities across a wide range of multimodal tasks. However, their integration of visual inputs introduces expanded attack surfaces, thereby exposing them to novel security vulnerabilities. In this work, we conduct a systematic representational analysis to uncover why conventional adversarial attacks can circumvent the safety mechanisms embedded in LVLMs. We further propose a novel two stage evaluation framework for adversarial attacks on LVLMs. The first stage differentiates among instruction non compliance, outright refusal, and successful adversarial exploitation. The second stage quantifies the degree to which the model's output fulfills the harmful intent of the adversarial prompt, while categorizing refusal behavior into direct refusals, soft refusals, and partial refusals that remain inadvertently helpful. Finally, we introduce a normative schema that defines idealized model behavior when confronted with harmful prompts, offering a principled target for safety alignment in multimodal systems.","authors":["Juan Ren","Mark Dras","Usman Naseem"],"url":"https://arxiv.org/abs/2505.21967"}
{"created":"2025-05-29","title":"Enhanced SIRRT*: A Structure-Aware RRT* for 2D Path Planning with Hybrid Smoothing and Bidirectional Rewiring","abstract":"Sampling-based motion planners such as Rapidly-exploring Random Tree* (RRT*) and its informed variant IRRT* are widely used for optimal path planning in complex environments. However, these methods often suffer from slow convergence and high variance due to their reliance on random sampling, particularly when initial solution discovery is delayed. This paper presents Enhanced SIRRT* (E-SIRRT*), a structure-aware planner that improves upon the original SIRRT* framework by introducing two key enhancements: hybrid path smoothing and bidirectional rewiring. Hybrid path smoothing refines the initial path through spline fitting and collision-aware correction, while bidirectional rewiring locally optimizes tree connectivity around the smoothed path to improve cost propagation. Experimental results demonstrate that E-SIRRT* consistently outperforms IRRT* and SIRRT* in terms of initial path quality, convergence rate, and robustness across 100 trials. Unlike IRRT*, which exhibits high variability due to stochastic initialization, E-SIRRT* achieves repeatable and efficient performance through deterministic skeleton-based initialization and structural refinement.","authors":["Hyejeong Ryu"],"url":"https://arxiv.org/abs/2505.21968"}
{"created":"2025-05-29","title":"DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation","abstract":"Adaptive navigation in unfamiliar environments is crucial for household service robots but remains challenging due to the need for both low-level path planning and high-level scene understanding. While recent vision-language model (VLM) based zero-shot approaches reduce dependence on prior maps and scene-specific training data, they face significant limitations: spatiotemporal discontinuity from discrete observations, unstructured memory representations, and insufficient task understanding leading to navigation failures. We propose DORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation), a novel cognitive-inspired framework consisting of Ventral and Dorsal Streams that mimics human navigation capabilities. The Dorsal Stream implements the Hierarchical Semantic-Spatial Fusion and Topology Map to handle spatiotemporal discontinuities, while the Ventral Stream combines RAG-VLM and Policy-VLM to improve decision-making. Our approach also develops Nav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMON on the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-art performance on both success rate (SR) and success weighted by path length (SPL) metrics, significantly outperforming existing methods. We also introduce a new evaluation metric (AORI) to assess navigation intelligence better. Comprehensive experiments demonstrate DORAEMON's effectiveness in zero-shot autonomous navigation without requiring prior map building or pre-training.","authors":["Tianjun Gu","Linfeng Li","Xuhong Wang","Chenghua Gong","Jingyu Gong","Zhizhong Zhang","Yuan Xie","Lizhuang Ma","Xin Tan"],"url":"https://arxiv.org/abs/2505.21969"}
{"created":"2025-05-29","title":"The Tri-Hybrid MIMO Architecture","abstract":"We present an evolution of multiple-input multiple-output (MIMO) wireless communications known as the tri-hybrid MIMO architecture. In this framework, the traditional operations of linear precoding at the transmitter are distributed across digital beamforming, analog beamforming, and reconfigurable antennas. Compared with the hybrid MIMO architecture, which combines digital and analog beamforming, the tri-hybrid approach introduces a third layer of electromagnetic beamforming through antenna reconfigurability. This added layer offers a pathway to scale MIMO spatial dimensions, important for 6G systems operating in centimeter-wave bands, where the tension between larger bandwidths and infrastructure reuse necessitates ultra-large antenna arrays. We introduce the key features of the tri-hybrid architecture by (i)~reviewing the benefits and challenges of communicating with reconfigurable antennas, (ii)~examining tradeoffs between spectral and energy efficiency enabled by reconfigurability, and (iii)~exploring configuration challenges across the three layers. Overall, the tri-hybrid MIMO architecture offers a new approach for integrating emerging antenna technologies in the MIMO precoding framework.","authors":["Robert W. Heath","Jr.","Joseph Carlson","Nitish Vikas Deshpande","Miguel Rodrigo Castellanos","Mohamed Akrout","Chan-Byoung Chae"],"url":"https://arxiv.org/abs/2505.21971"}
{"created":"2025-05-29","title":"Judging LLMs on a Simplex","abstract":"Automated evaluation of free-form outputs from large language models (LLMs) is challenging because many distinct answers can be equally valid. A common practice is to use LLMs themselves as judges, but the theoretical properties of this approach are not yet well understood. We show that a geometric framework that represents both judges and candidates as points on a probability simplex can provide helpful insight on what is or is not identifiable using LLM judges. Our theoretical analysis uncovers a \"phase transition\" in ranking identifiability: for binary scoring systems, true rankings are identifiable even with weak judges under mild assumptions, while rankings become non-identifiable for three or more scoring levels even with infinite data, absent additional prior knowledge. This non-identifiability highlights how uncertainty in rankings stems from not only aleatoric uncertainty (i.e., inherent stochasticity in the data) but also epistemic uncertainty regarding which assumptions hold, an aspect that has received limited attention until now. To integrate both types of uncertainty, we use Bayesian inference to encode assumptions as priors and conduct sensitivity analysis of ranking estimates and credible intervals. Empirical evaluations across multiple benchmarks demonstrate that Bayesian inference yields more accurate rankings and substantially improves coverage rates. These results underscore the importance of taking a more holistic approach to uncertainty quantification when using LLMs as judges.","authors":["Patrick Vossler","Fan Xia","Yifan Mai","Jean Feng"],"url":"https://arxiv.org/abs/2505.21972"}
{"created":"2025-05-29","title":"Towards Structure-aware Model for Multi-modal Knowledge Graph Completion","abstract":"Knowledge graphs (KGs) play a key role in promoting various multimedia and AI applications. However, with the explosive growth of multi-modal information, traditional knowledge graph completion (KGC) models cannot be directly applied. This has attracted a large number of researchers to study multi-modal knowledge graph completion (MMKGC). Since MMKG extends KG to the visual and textual domains, MMKGC faces two main challenges: (1) how to deal with the fine-grained modality information interaction and awareness; (2) how to ensure the dominant role of graph structure in multi-modal knowledge fusion and deal with the noise generated by other modalities during modality fusion. To address these challenges, this paper proposes a novel MMKGC model named TSAM, which integrates fine-grained modality interaction and dominant graph structure to form a high-performance MMKGC framework. Specifically, to solve the challenges, TSAM proposes the Fine-grained Modality Awareness Fusion method (FgMAF), which uses pre-trained language models to better capture fine-grained semantic information interaction of different modalities and employs an attention mechanism to achieve fine-grained modality awareness and fusion. Additionally, TSAM presents the Structure-aware Contrastive Learning method (SaCL), which utilizes two contrastive learning approaches to align other modalities more closely with the structured modality. Extensive experiments show that the proposed TSAM model significantly outperforms existing MMKGC models on widely used multi-modal datasets.","authors":["Linyu Li","Zhi Jin","Yichi Zhang","Dongming Jin","Chengfeng Dou","Yuanpeng He","Xuan Zhang","Haiyan Zhao"],"url":"https://arxiv.org/abs/2505.21973"}
{"created":"2025-05-29","title":"BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL","abstract":"Bayesian optimization (BO) offers an efficient pipeline for optimizing black-box functions with the help of a Gaussian process prior and an acquisition function (AF). Recently, in the context of single-objective BO, learning-based AFs witnessed promising empirical results given its favorable non-myopic nature. Despite this, the direct extension of these approaches to multi-objective Bayesian optimization (MOBO) suffer from the \\textit{hypervolume identifiability issue}, which results from the non-Markovian nature of MOBO problems. To tackle this, inspired by the non-Markovian RL literature and the success of Transformers in language modeling, we present a generalized deep Q-learning framework and propose \\textit{BOFormer}, which substantiates this framework for MOBO via sequence modeling. Through extensive evaluation, we demonstrate that BOFormer constantly outperforms the benchmark rule-based and learning-based algorithms in various synthetic MOBO and real-world multi-objective hyperparameter optimization problems. We have made the source code publicly available to encourage further research in this direction.","authors":["Yu-Heng Hung","Kai-Jie Lin","Yu-Heng Lin","Chien-YiWang","Cheng Sun","Ping-Chun Hsieh"],"url":"https://arxiv.org/abs/2505.21974"}
{"created":"2025-05-29","title":"DvD: Unleashing a Generative Paradigm for Document Dewarping via Coordinates-based Diffusion Model","abstract":"Document dewarping aims to rectify deformations in photographic document images, thus improving text readability, which has attracted much attention and made great progress, but it is still challenging to preserve document structures. Given recent advances in diffusion models, it is natural for us to consider their potential applicability to document dewarping. However, it is far from straightforward to adopt diffusion models in document dewarping due to their unfaithful control on highly complex document images (e.g., 2000$\\times$3000 resolution). In this paper, we propose DvD, the first generative model to tackle document \\textbf{D}ewarping \\textbf{v}ia a \\textbf{D}iffusion framework. To be specific, DvD introduces a coordinate-level denoising instead of typical pixel-level denoising, generating a mapping for deformation rectification. In addition, we further propose a time-variant condition refinement mechanism to enhance the preservation of document structures. In experiments, we find that current document dewarping benchmarks can not evaluate dewarping models comprehensively. To this end, we present AnyPhotoDoc6300, a rigorously designed large-scale document dewarping benchmark comprising 6,300 real image pairs across three distinct domains, enabling fine-grained evaluation of dewarping models. Comprehensive experiments demonstrate that our proposed DvD can achieve state-of-the-art performance with acceptable computational efficiency on multiple metrics across various benchmarks including DocUNet, DIR300, and AnyPhotoDoc6300. The new benchmark and code will be publicly available.","authors":["Weiguang Zhang","Huangcheng Lu","Maizhen Ning","Xiaowei Huang","Wei Wang","Kaizhu Huang","Qiufeng Wang"],"url":"https://arxiv.org/abs/2505.21975"}
{"created":"2025-05-29","title":"Two-Stage Feature Generation with Transformer and Reinforcement Learning","abstract":"Feature generation is a critical step in machine learning, aiming to enhance model performance by capturing complex relationships within the data and generating meaningful new features. Traditional feature generation methods heavily rely on domain expertise and manual intervention, making the process labor-intensive and challenging to adapt to different scenarios. Although automated feature generation techniques address these issues to some extent, they often face challenges such as feature redundancy, inefficiency in feature space exploration, and limited adaptability to diverse datasets and tasks. To address these problems, we propose a Two-Stage Feature Generation (TSFG) framework, which integrates a Transformer-based encoder-decoder architecture with Proximal Policy Optimization (PPO). The encoder-decoder model in TSFG leverages the Transformer's self-attention mechanism to efficiently represent and transform features, capturing complex dependencies within the data. PPO further enhances TSFG by dynamically adjusting the feature generation strategy based on task-specific feedback, optimizing the process for improved performance and adaptability. TSFG dynamically generates high-quality feature sets, significantly improving the predictive performance of machine learning models. Experimental results demonstrate that TSFG outperforms existing state-of-the-art methods in terms of feature quality and adaptability.","authors":["Wanfu Gao","Zengyao Man","Zebin He","Yuhao Tang","Jun Gao","Kunpeng Liu"],"url":"https://arxiv.org/abs/2505.21978"}
{"created":"2025-05-29","title":"Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset","abstract":"Mainstream large vision-language models (LVLMs) inherently encode cultural biases, highlighting the need for diverse multimodal datasets. To address this gap, we introduce Pearl, a large-scale Arabic multimodal dataset and benchmark explicitly designed for cultural understanding. Constructed through advanced agentic workflows and extensive human-in-the-loop annotations by 45 annotators from across the Arab world, Pearl comprises over K multimodal examples spanning ten culturally significant domains covering all Arab countries. We further provide two robust evaluation benchmarks Pearl and Pearl-Lite along with a specialized subset Pearl-X explicitly developed to assess nuanced cultural variations. Comprehensive evaluations on state-of-the-art open and proprietary LVLMs demonstrate that reasoning-centric instruction alignment substantially improves models' cultural grounding compared to conventional scaling methods. Pearl establishes a foundational resource for advancing culturally-informed multimodal modeling research. All datasets and benchmarks are publicly available.","authors":["Fakhraddin Alwajih","Samar Mohamed Magdy","Abdellah El Mekki","Omer Nacar","Youssef Nafea","Safaa Taher Abdelfadil","Abdulfattah Mohammed Yahya","Hamzah Luqman","Nada Almarwani","Samah Aloufi","Baraah Qawasmeh","Houdaifa Atou","Serry Sibaee","Hamzah A. Alsayadi","Walid Al-Dhabyani","Maged S. Al-shaibani","Aya El aatar","Nour Qandos","Rahaf Alhamouri","Samar Ahmad","Razan Khassib","Lina Hamad","Mohammed Anwar AL-Ghrawi","Fatimah Alshamari","Cheikh Malainine","Doaa Qawasmeh","Aminetou Yacoub","Tfeil moilid","Ruwa AbuHweidi","Ahmed Aboeitta","Vatimetou Mohamed Lemin","Reem Abdel-Salam","Ahlam Bashiti","Adel Ammar","Aisha Alansari","Ahmed Ashraf","Nora Alturayeif","Sara Shatnawi","Alcides Alcoba Inciarte","AbdelRahim A. Elmadany","Mohamedou cheikh tourad","Ismail Berrada","Mustafa Jarrar","Shady Shehata","Muhammad Abdul-Mageed"],"url":"https://arxiv.org/abs/2505.21979"}
{"created":"2025-05-29","title":"Learning Compositional Behaviors from Demonstration and Language","abstract":"We introduce Behavior from Language and Demonstration (BLADE), a framework for long-horizon robotic manipulation by integrating imitation learning and model-based planning. BLADE leverages language-annotated demonstrations, extracts abstract action knowledge from large language models (LLMs), and constructs a library of structured, high-level action representations. These representations include preconditions and effects grounded in visual perception for each high-level action, along with corresponding controllers implemented as neural network-based policies. BLADE can recover such structured representations automatically, without manually labeled states or symbolic definitions. BLADE shows significant capabilities in generalizing to novel situations, including novel initial states, external state perturbations, and novel goals. We validate the effectiveness of our approach both in simulation and on real robots with a diverse set of objects with articulated parts, partial observability, and geometric constraints.","authors":["Weiyu Liu","Neil Nie","Ruohan Zhang","Jiayuan Mao","Jiajun Wu"],"url":"https://arxiv.org/abs/2505.21981"}
{"created":"2025-05-29","title":"Eye-Tracking and Biometric Feedback in UX Research: Measuring User Engagement and Cognitive Load","abstract":"User experience research often uses surveys and interviews, which may miss subconscious user interactions. This study explores eye-tracking and biometric feedback as tools to assess user engagement and cognitive load in digital interfaces. These methods measure gaze behavior and bodily responses, providing an objective complement to qualitative insights. Using empirical evidence, practical applications, and advancements from 2023-2025, we present experimental data, describe our methodology, and place our work within foundational and recent literature. We address challenges like data interpretation, ethical issues, and technological integration. These tools are key for advancing UX design in complex digital environments.","authors":["Aaditya Shankar Majumder"],"url":"https://arxiv.org/abs/2505.21982"}
{"created":"2025-05-29","title":"Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning","abstract":"In multi-agent reinforcement learning (MARL), effective communication improves agent performance, particularly under partial observability. We propose MARL-CPC, a framework that enables communication among fully decentralized, independent agents without parameter sharing. MARL-CPC incorporates a message learning model based on collective predictive coding (CPC) from emergent communication research. Unlike conventional methods that treat messages as part of the action space and assume cooperation, MARL-CPC links messages to state inference, supporting communication in non-cooperative, reward-independent settings. We introduce two algorithms -Bandit-CPC and IPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that both outperform standard message-as-action approaches, establishing effective communication even when messages offer no direct benefit to the sender. These results highlight MARL-CPC's potential for enabling coordination in complex, decentralized environments.","authors":["Naoto Yoshida","Tadahiro Taniguchi"],"url":"https://arxiv.org/abs/2505.21985"}
{"created":"2025-05-29","title":"Characterizing Equivalence of Logically Constrained Terms via Existentially Constrained Terms (Full Version)","abstract":"Logically constrained term rewriting is a rewriting framework that supports built-in data structures such as integers and bit vectors. Recently, constrained terms play a key role in various analyses and applications of logically constrained term rewriting. A fundamental question on constrained terms arising there is how to characterize equivalence between them. However, in the current literature only limited progress has been made on this. In this paper, we provide several sound and complete solutions to tackle this problem. Our key idea is the introduction of a novel concept, namely existentially constrained terms, into which the original form of constrained terms can be embedded. We present several syntactic characterizations of equivalence between existentially constrained terms. In particular, we provide two different kinds of complete characterizations: one is designed to facilitate equivalence checking, while the other is intended for theoretical analysis.","authors":["Kanta Takahata","Jonas Sch\\\"opf","Naoki Nishida","Takahito Aoto"],"url":"https://arxiv.org/abs/2505.21986"}
{"created":"2025-05-29","title":"ACE: Exploring Activation Cosine Similarity and Variance for Accurate and Calibration-Efficient LLM Pruning","abstract":"With the rapid expansion of large language models (LLMs), the demand for memory and computational resources has grown significantly. Recent advances in LLM pruning aim to reduce the size and computational cost of these models. However, existing methods often suffer from either suboptimal pruning performance or low time efficiency during the pruning process. In this work, we propose an efficient and effective pruning method that simultaneously achieves high pruning performance and fast pruning speed with improved calibration efficiency. Our approach introduces two key innovations: (1) An activation cosine similarity loss-guided pruning metric, which considers the angular deviation of the output activation between the dense and pruned models. (2) An activation variance-guided pruning metric, which helps preserve semantic distinctions in output activations after pruning, enabling effective pruning with shorter input sequences. These two components can be readily combined to enhance LLM pruning in both accuracy and efficiency. Experimental results show that our method achieves up to an 18% reduction in perplexity and up to 63% decrease in pruning time on prevalent LLMs such as LLaMA, LLaMA-2, and OPT.","authors":["Zhendong Mi","Zhenglun Kong","Geng Yuan","Shaoyi Huang"],"url":"https://arxiv.org/abs/2505.21987"}
{"created":"2025-05-29","title":"Functional Matching of Logic Subgraphs: Beyond Structural Isomorphism","abstract":"Subgraph matching in logic circuits is foundational for numerous Electronic Design Automation (EDA) applications, including datapath optimization, arithmetic verification, and hardware trojan detection. However, existing techniques rely primarily on structural graph isomorphism and thus fail to identify function-related subgraphs when synthesis transformations substantially alter circuit topology. To overcome this critical limitation, we introduce the concept of functional subgraph matching, a novel approach that identifies whether a given logic function is implicitly present within a larger circuit, irrespective of structural variations induced by synthesis or technology mapping. Specifically, we propose a two-stage multi-modal framework: (1) learning robust functional embeddings across AIG and post-mapping netlists for functional subgraph detection, and (2) identifying fuzzy boundaries using a graph segmentation approach. Evaluations on standard benchmarks (ITC99, OpenABCD, ForgeEDA) demonstrate significant performance improvements over existing structural methods, with average $93.8\\%$ accuracy in functional subgraph detection and a dice score of $91.3\\%$ in fuzzy boundary identification.","authors":["Ziyang Zheng","Kezhi Li","Zhengyuan Shi","Qiang Xu"],"url":"https://arxiv.org/abs/2505.21988"}
{"created":"2025-05-29","title":"Bridging Fitness With Search Spaces By Fitness Supremums: A Theoretical Study on LGP","abstract":"Genetic programming has undergone rapid development in recent years. However, theoretical studies of genetic programming are far behind. One of the major obstacles to theoretical studies is the challenge of developing a model to describe the relationship between fitness values and program genotypes. In this paper, we take linear genetic programming (LGP) as an example to study the fitness-to-genotype relationship. We find that the fitness expectation increases with fitness supremum over instruction editing distance, considering 1) the fitness supremum linearly increases with the instruction editing distance in LGP, 2) the fitness infimum is fixed, and 3) the fitness probabilities over different instruction editing distances are similar. We then extend these findings to explain the bloat effect and the minimum hitting time of LGP based on instruction editing distance. The bloat effect happens because it is more likely to produce better offspring by adding instructions than by removing them, given an instruction editing distance from the optimal program. The analysis of the minimum hitting time suggests that for a basic LGP genetic operator (i.e., freemut), maintaining a necessarily small program size and mutating multiple instructions each time can improve LGP performance. The reported empirical results verify our hypothesis.","authors":["Zhixing Huang","Yi Mei","Fangfang Zhang","Mengjie Zhang","Wolfgang Banzhaf"],"url":"https://arxiv.org/abs/2505.21991"}
{"created":"2025-05-29","title":"Soft Electrothermal Meta-Actuator for Robust Multifunctional Control","abstract":"Soft electrothermal actuators are of great interest in diverse application domains for their simplicity, compliance, and ease of control. However, the very nature of thermally induced mechanical actuation sets inherent operation constraints: unidirectional motion, environmental sensitivity, and slow response times limited by passive cooling. To overcome these constraints, we propose a meta-actuator architecture, which uses engineered heat transfer in thin films to achieve multifunctional operation. We demonstrate electrically selectable bidirectional motion with large deflection ($ \\geq $28% of actuator length at 0.75 W), suppressed thermal sensitivity to ambient temperature changes when compared to conventional actuators (>100$ \\times $ lower), and actively forced return to the rest state, which is 10 times faster than that with passive cooling. We further show that our meta-actuator approach enables extended ranges of motions for manipulating complex objects. Versatile soft gripper operations highlight the meta-actuator's potential for soft robotics and devices.","authors":["Hanseong Jo","Pavel Shafirin","Christopher Le","Caden Chan","Artur Davoyan"],"url":"https://arxiv.org/abs/2505.21992"}
{"created":"2025-05-29","title":"Locking-Free Training of Physics-Informed Neural Network for Solving Nearly Incompressible Elasticity Equations","abstract":"Due to divergence instability, the accuracy of low-order conforming finite element methods for nearly incompressible homogeneous elasticity equations deteriorates as the Lam\\'e coefficient $\\lambda\\to\\infty$, or equivalently as the Poisson ratio $\\nu\\to1/2$. This phenomenon, known as locking or non-robustness, remains not fully understood despite extensive investigation. In this paper, we propose a robust method based on a fundamentally different, machine-learning-driven approach. Leveraging recently developed Physics-Informed Neural Networks (PINNs), we address the numerical solution of linear elasticity equations governing nearly incompressible materials. The core idea of our method is to appropriately decompose the given equations to alleviate the extreme imbalance in the coefficients, while simultaneously solving both the forward and inverse problems to recover the solutions of the decomposed systems as well as the associated external conditions. Through various numerical experiments, including constant, variable and parametric Lam\\'e coefficients, we illustrate the efficiency of the proposed methodology.","authors":["Josef Dick","Seungchan Ko","Kassem Mustapha","Sanghyeon Park"],"url":"https://arxiv.org/abs/2505.21994"}
{"created":"2025-05-29","title":"Learning World Models for Interactive Video Generation","abstract":"Foundational world models must be both interactive and preserve spatiotemporal coherence for effective future planning with action choices. However, present models for long video generation have limited inherent world modeling capabilities due to two main challenges: compounding errors and insufficient memory mechanisms. We enhance image-to-video models with interactive capabilities through additional action conditioning and autoregressive framework, and reveal that compounding error is inherently irreducible in autoregressive video generation, while insufficient memory mechanism leads to incoherence of world models. We propose video retrieval augmented generation (VRAG) with explicit global state conditioning, which significantly reduces long-term compounding errors and increases spatiotemporal consistency of world models. In contrast, naive autoregressive generation with extended context windows and retrieval-augmented generation prove less effective for video generation, primarily due to the limited in-context learning capabilities of current video models. Our work illuminates the fundamental challenges in video world models and establishes a comprehensive benchmark for improving video generation models with internal world modeling capabilities.","authors":["Taiye Chen","Xun Hu","Zihan Ding","Chi Jin"],"url":"https://arxiv.org/abs/2505.21996"}
{"created":"2025-05-29","title":"Leveraging Interview-Informed LLMs to Model Survey Responses: Comparative Insights from AI-Generated and Human Data","abstract":"Mixed methods research integrates quantitative and qualitative data but faces challenges in aligning their distinct structures, particularly in examining measurement characteristics and individual response patterns. Advances in large language models (LLMs) offer promising solutions by generating synthetic survey responses informed by qualitative data. This study investigates whether LLMs, guided by personal interviews, can reliably predict human survey responses, using the Behavioral Regulations in Exercise Questionnaire (BREQ) and interviews from after-school program staff as a case study. Results indicate that LLMs capture overall response patterns but exhibit lower variability than humans. Incorporating interview data improves response diversity for some models (e.g., Claude, GPT), while well-crafted prompts and low-temperature settings enhance alignment between LLM and human responses. Demographic information had less impact than interview content on alignment accuracy. These findings underscore the potential of interview-informed LLMs to bridge qualitative and quantitative methodologies while revealing limitations in response variability, emotional interpretation, and psychometric fidelity. Future research should refine prompt design, explore bias mitigation, and optimize model settings to enhance the validity of LLM-generated survey data in social science research.","authors":["Jihong Zhang","Xinya Liang","Anqi Deng","Nicole Bonge","Lin Tan","Ling Zhang","Nicole Zarrett"],"url":"https://arxiv.org/abs/2505.21997"}
{"created":"2025-05-29","title":"Found in Translation: Measuring Multilingual LLM Consistency as Simple as Translate then Evaluate","abstract":"Large language models (LLMs) provide detailed and impressive responses to queries in English. However, are they really consistent at responding to the same query in other languages? The popular way of evaluating for multilingual performance of LLMs requires expensive-to-collect annotated datasets. Further, evaluating for tasks like open-ended generation, where multiple correct answers may exist, is nontrivial. Instead, we propose to evaluate the predictability of model response across different languages. In this work, we propose a framework to evaluate LLM's cross-lingual consistency based on a simple Translate then Evaluate strategy. We instantiate this evaluation framework along two dimensions of consistency: information and empathy. Our results reveal pronounced inconsistencies in popular LLM responses across thirty languages, with severe performance deficits in certain language families and scripts, underscoring critical weaknesses in their multilingual capabilities. These findings necessitate cross-lingual evaluations that are consistent along multiple dimensions. We invite practitioners to use our framework for future multilingual LLM benchmarking.","authors":["Ashim Gupta","Maitrey Mehta","Zhichao Xu","Vivek Srikumar"],"url":"https://arxiv.org/abs/2505.21999"}
{"created":"2025-05-29","title":"D-Fusion: Direct Preference Optimization for Aligning Diffusion Models with Visually Consistent Samples","abstract":"The practical applications of diffusion models have been limited by the misalignment between generated images and corresponding text prompts. Recent studies have introduced direct preference optimization (DPO) to enhance the alignment of these models. However, the effectiveness of DPO is constrained by the issue of visual inconsistency, where the significant visual disparity between well-aligned and poorly-aligned images prevents diffusion models from identifying which factors contribute positively to alignment during fine-tuning. To address this issue, this paper introduces D-Fusion, a method to construct DPO-trainable visually consistent samples. On one hand, by performing mask-guided self-attention fusion, the resulting images are not only well-aligned, but also visually consistent with given poorly-aligned images. On the other hand, D-Fusion can retain the denoising trajectories of the resulting images, which are essential for DPO training. Extensive experiments demonstrate the effectiveness of D-Fusion in improving prompt-image alignment when applied to different reinforcement learning algorithms.","authors":["Zijing Hu","Fengda Zhang","Kun Kuang"],"url":"https://arxiv.org/abs/2505.22002"}
{"created":"2025-05-29","title":"Legal Assist AI: Leveraging Transformer-Based Model for Effective Legal Assistance","abstract":"Pursuit of accessible legal assistance in India faces a critical gap, as many citizens struggle to leverage their legal rights due to limited awareness and access to relevant legal information. This paper introduces Legal Assist AI, a transformer-based model designed to bridge this gap by offering effective legal assistance through large language models (LLMs). The system retrieves relevant legal information from a curated database and generates accurate responses, enabling effective assistance for diverse users, including legal professionals, scholars, and the general public. The model was fine-tuned on extensive datasets from the Indian legal domain, including Indian Constitution, Bharatiya Nyaya Sanhita (BNS), Bharatiya Nagarik Suraksha Sanhita (BNSS) and so forth, providing a robust understanding of the complexities of Indian law. By incorporating domain-specific legal datasets, the proposed model demonstrated remarkable efficiency and specialization in legal Question-Answering. The model was evaluated against state-of-the-art models such as GPT-3.5 Turbo and Mistral 7B, achieving a 60.08% score on the AIBE, outperforming its competitors in legal reasoning and accuracy. Unlike other models, Legal Assist AI avoided common issues such as hallucinations, making it highly reliable for practical legal applications. It showcases the model's applicability in real-world legal scenarios, with future iterations aiming to enhance performance and expand its dataset to cover a broader range of multilingual and case-specific queries as well.","authors":["Jatin Gupta","Akhil Sharma","Saransh Singhania","Ali Imam Abidi"],"url":"https://arxiv.org/abs/2505.22003"}
{"created":"2025-05-29","title":"Leveraging LLM for Stuttering Speech: A Unified Architecture Bridging Recognition and Event Detection","abstract":"The performance bottleneck of Automatic Speech Recognition (ASR) in stuttering speech scenarios has limited its applicability in domains such as speech rehabilitation. This paper proposed an LLM-driven ASR-SED multi-task learning framework that jointly optimized the ASR and Stuttering Event Detection (SED) tasks. We proposed a dynamic interaction mechanism where the ASR branch leveraged CTC-generated soft prompts to assist LLM context modeling, while the SED branch output stutter embeddings to enhance LLM comprehension of stuttered speech. We incorporated contrastive learning to strengthen the discriminative power of stuttering acoustic features and applied Focal Loss to mitigate the long-tailed distribution in stuttering event categories. Evaluations on the AS-70 Mandarin stuttering dataset demonstrated that our framework reduced the ASR character error rate (CER) to 5.45% (-37.71% relative reduction) and achieved an average SED F1-score of 73.63% (+46.58% relative improvement).","authors":["Shangkun Huang","Jing Deng","Jintao Kang","Rong Zheng"],"url":"https://arxiv.org/abs/2505.22005"}
{"created":"2025-05-29","title":"Efficiently Enhancing General Agents With Hierarchical-categorical Memory","abstract":"With large language models (LLMs) demonstrating remarkable capabilities, there has been a surge in research on leveraging LLMs to build general-purpose multi-modal agents. However, existing approaches either rely on computationally expensive end-to-end training using large-scale multi-modal data or adopt tool-use methods that lack the ability to continuously learn and adapt to new environments. In this paper, we introduce EHC, a general agent capable of learning without parameter updates. EHC consists of a Hierarchical Memory Retrieval (HMR) module and a Task-Category Oriented Experience Learning (TOEL) module. The HMR module facilitates rapid retrieval of relevant memories and continuously stores new information without being constrained by memory capacity. The TOEL module enhances the agent's comprehension of various task characteristics by classifying experiences and extracting patterns across different categories. Extensive experiments conducted on multiple standard datasets demonstrate that EHC outperforms existing methods, achieving state-of-the-art performance and underscoring its effectiveness as a general agent for handling complex multi-modal tasks.","authors":["Changze Qiao","Mingming Lu"],"url":"https://arxiv.org/abs/2505.22006"}
{"created":"2025-05-29","title":"Event-based Egocentric Human Pose Estimation in Dynamic Environment","abstract":"Estimating human pose using a front-facing egocentric camera is essential for applications such as sports motion analysis, VR/AR, and AI for wearable devices. However, many existing methods rely on RGB cameras and do not account for low-light environments or motion blur. Event-based cameras have the potential to address these challenges. In this work, we introduce a novel task of human pose estimation using a front-facing event-based camera mounted on the head and propose D-EventEgo, the first framework for this task. The proposed method first estimates the head poses, and then these are used as conditions to generate body poses. However, when estimating head poses, the presence of dynamic objects mixed with background events may reduce head pose estimation accuracy. Therefore, we introduce the Motion Segmentation Module to remove dynamic objects and extract background information. Extensive experiments on our synthetic event-based dataset derived from EgoBody, demonstrate that our approach outperforms our baseline in four out of five evaluation metrics in dynamic environments.","authors":["Wataru Ikeda","Masashi Hatano","Ryosei Hara","Mariko Isogawa"],"url":"https://arxiv.org/abs/2505.22007"}
{"created":"2025-05-29","title":"VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries","abstract":"Recognizing vulnerabilities in stripped binary files presents a significant challenge in software security. Although some progress has been made in generating human-readable information from decompiled binary files with Large Language Models (LLMs), effectively and scalably detecting vulnerabilities within these binary files is still an open problem. This paper explores the novel application of LLMs to detect vulnerabilities within these binary files. We demonstrate the feasibility of identifying vulnerable programs through a combined approach of decompilation optimization to make the vulnerabilities more prominent and long-term memory for a larger context window, achieving state-of-the-art performance in binary vulnerability analysis. Our findings highlight the potential for LLMs to overcome the limitations of traditional analysis methods and advance the field of binary vulnerability detection, paving the way for more secure software systems. In this paper, we present Vul-BinLLM , an LLM-based framework for binary vulnerability detection that mirrors traditional binary analysis workflows with fine-grained optimizations in decompilation and vulnerability reasoning with an extended context. In the decompilation phase, Vul-BinLLM adds vulnerability and weakness comments without altering the code structure or functionality, providing more contextual information for vulnerability reasoning later. Then for vulnerability reasoning, Vul-BinLLM combines in-context learning and chain-of-thought prompting along with a memory management agent to enhance accuracy. Our evaluations encompass the commonly used synthetic dataset Juliet to evaluate the potential feasibility for analysis and vulnerability detection in C/C++ binaries. Our evaluations show that Vul-BinLLM is highly effective in detecting vulnerabilities on the compiled Juliet dataset.","authors":["Nasir Hussain","Haohan Chen","Chanh Tran","Philip Huang","Zhuohao Li","Pravir Chugh","William Chen","Ashish Kundu","Yuan Tian"],"url":"https://arxiv.org/abs/2505.22010"}
{"created":"2025-05-29","title":"Prototype Embedding Optimization for Human-Object Interaction Detection in Livestreaming","abstract":"Livestreaming often involves interactions between streamers and objects, which is critical for understanding and regulating web content. While human-object interaction (HOI) detection has made some progress in general-purpose video downstream tasks, when applied to recognize the interaction behaviors between a streamer and different objects in livestreaming, it tends to focuses too much on the objects and neglects their interactions with the streamer, which leads to object bias. To solve this issue, we propose a prototype embedding optimization for human-object interaction detection (PeO-HOI). First, the livestreaming is preprocessed using object detection and tracking techniques to extract features of the human-object (HO) pairs. Then, prototype embedding optimization is adopted to mitigate the effect of object bias on HOI. Finally, after modelling the spatio-temporal context between HO pairs, the HOI detection results are obtained by the prediction head. The experimental results show that the detection accuracy of the proposed PeO-HOI method has detection accuracies of 37.19%@full, 51.42%@non-rare, 26.20%@rare on the publicly available dataset VidHOI, 45.13%@full, 62.78%@non-rare and 30.37%@rare on the self-built dataset BJUT-HOI, which effectively improves the HOI detection performance in livestreaming.","authors":["Menghui Zhang","Jing Zhang","Lin Chen","Li Zhuo"],"url":"https://arxiv.org/abs/2505.22011"}
{"created":"2025-05-29","title":"Overlap-Adaptive Hybrid Speaker Diarization and ASR-Aware Observation Addition for MISP 2025 Challenge","abstract":"This paper presents the system developed to address the MISP 2025 Challenge. For the diarization system, we proposed a hybrid approach combining a WavLM end-to-end segmentation method with a traditional multi-module clustering technique to adaptively select the appropriate model for handling varying degrees of overlapping speech. For the automatic speech recognition (ASR) system, we proposed an ASR-aware observation addition method that compensates for the performance limitations of Guided Source Separation (GSS) under low signal-to-noise ratio conditions. Finally, we integrated the speaker diarization and ASR systems in a cascaded architecture to address Track 3. Our system achieved character error rates (CER) of 9.48% on Track 2 and concatenated minimum permutation character error rate (cpCER) of 11.56% on Track 3, ultimately securing first place in both tracks and thereby demonstrating the effectiveness of the proposed methods in real-world meeting scenarios.","authors":["Shangkun Huang","Yuxuan Du","Jingwen Yang","Dejun Zhang","Xupeng Jia","Jing Deng","Jintao Kang","Rong Zheng"],"url":"https://arxiv.org/abs/2505.22013"}
{"created":"2025-05-29","title":"Learning in Compact Spaces with Approximately Normalized Transformers","abstract":"In deep learning, regularization and normalization are common solutions for challenges such as overfitting, numerical instabilities, and the increasing variance in the residual stream. An alternative approach is to force all parameters and representations to lie on a hypersphere. This removes the need for regularization and increases convergence speed, but comes with additional costs. In this work, we propose a more holistic but approximate normalization (anTransformer). Our approach constrains the norm of parameters and normalizes all representations via scalar multiplications motivated by the tight concentration of the norms of high-dimensional random vectors. When applied to GPT training, we observe a 40% faster convergence compared to models with QK normalization, with less than 3% additional runtime. Deriving scaling laws for anGPT, we found our method enables training with larger batch sizes and fewer hyperparameters, while matching the favorable scaling characteristics of classic GPT architectures.","authors":["J\\\"org K. H. Franke","Urs Spiegelhalter","Marianna Nezhurina","Jenia Jitsev","Frank Hutter","Michael Hefenbrock"],"url":"https://arxiv.org/abs/2505.22014"}
{"created":"2025-05-29","title":"PanoWan: Lifting Diffusion Video Generation Models to 360{\\deg} with Latitude/Longitude-aware Mechanisms","abstract":"Panoramic video generation enables immersive 360{\\deg} content creation, valuable in applications that demand scene-consistent world exploration. However, existing panoramic video generation models struggle to leverage pre-trained generative priors from conventional text-to-video models for high-quality and diverse panoramic videos generation, due to limited dataset scale and the gap in spatial feature representations. In this paper, we introduce PanoWan to effectively lift pre-trained text-to-video models to the panoramic domain, equipped with minimal modules. PanoWan employs latitude-aware sampling to avoid latitudinal distortion, while its rotated semantic denoising and padded pixel-wise decoding ensure seamless transitions at longitude boundaries. To provide sufficient panoramic videos for learning these lifted representations, we contribute PanoVid, a high-quality panoramic video dataset with captions and diverse scenarios. Consequently, PanoWan achieves state-of-the-art performance in panoramic video generation and demonstrates robustness for zero-shot downstream tasks.","authors":["Yifei Xia","Shuchen Weng","Siqi Yang","Jingqi Liu","Chengxuan Zhu","Minggui Teng","Zijian Jia","Han Jiang","Boxin Shi"],"url":"https://arxiv.org/abs/2505.22016"}
{"created":"2025-05-29","title":"CoThink: Token-Efficient Reasoning via Instruct Models Guiding Reasoning Models","abstract":"Large language models (LLMs) benefit from increased test-time compute, a phenomenon known as test-time scaling. However, reasoning-optimized models often overthink even simple problems, producing excessively verbose outputs and leading to low token efficiency. By comparing these models with equally sized instruct models, we identify two key causes of this verbosity: (1) reinforcement learning reduces the information density of forward reasoning, and (2) backward chain-of thought training encourages redundant and often unnecessary verification steps. Since LLMs cannot assess the difficulty of a given problem, they tend to apply the same cautious reasoning strategy across all tasks, resulting in inefficient overthinking. To address this, we propose CoThink, an embarrassingly simple pipeline: an instruct model first drafts a high-level solution outline; a reasoning model then works out the solution. We observe that CoThink enables dynamic adjustment of reasoning depth based on input difficulty. Evaluated with three reasoning models DAPO, DeepSeek-R1, and QwQ on three datasets GSM8K, MATH500, and AIME24, CoThink reduces total token generation by 22.3% while maintaining pass@1 accuracy within a 0.42% margin on average. With reference to the instruct model, we formally define reasoning efficiency and observe a potential reasoning efficiency scaling law in LLMs.","authors":["Siqi Fan","Peng Han","Shuo Shang","Yequan Wang","Aixin Sun"],"url":"https://arxiv.org/abs/2505.22017"}
{"created":"2025-05-29","title":"Improving Continual Pre-training Through Seamless Data Packing","abstract":"Continual pre-training has demonstrated significant potential in enhancing model performance, particularly in domain-specific scenarios. The most common approach for packing data before continual pre-training involves concatenating input texts and splitting them into fixed-length sequences. While straightforward and efficient, this method often leads to excessive truncation and context discontinuity, which can hinder model performance. To address these issues, we explore the potential of data engineering to enhance continual pre-training, particularly its impact on model performance and efficiency. We propose Seamless Packing (SP), a novel data packing strategy aimed at preserving contextual information more effectively and enhancing model performance. Our approach employs a sliding window technique in the first stage that synchronizes overlapping tokens across consecutive sequences, ensuring better continuity and contextual coherence. In the second stage, we adopt a First-Fit-Decreasing algorithm to pack shorter texts into bins slightly larger than the target sequence length, thereby minimizing padding and truncation. Empirical evaluations across various model architectures and corpus domains demonstrate the effectiveness of our method, outperforming baseline method in 99% of all settings. Code is available at https://github.com/Infernus-WIND/Seamless-Packing.","authors":["Ruicheng Yin","Xuan Gao","Changze Lv","Xiaohua Wang","Xiaoqing Zheng","Xuanjing Huang"],"url":"https://arxiv.org/abs/2505.22018"}
{"created":"2025-05-29","title":"VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning","abstract":"Effectively retrieving, reasoning and understanding visually rich information remains a challenge for RAG methods. Traditional text-based methods cannot handle visual-related information. On the other hand, current vision-based RAG approaches are often limited by fixed pipelines and frequently struggle to reason effectively due to the insufficient activation of the fundamental capabilities of models. As RL has been proven to be beneficial for model reasoning, we introduce VRAG-RL, a novel RL framework tailored for complex reasoning across visually rich information. With this framework, VLMs interact with search engines, autonomously sampling single-turn or multi-turn reasoning trajectories with the help of visual perception tokens and undergoing continual optimization based on these samples. Our approach highlights key limitations of RL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely incorporate images into the context, leading to insufficient reasoning token allocation and neglecting visual-specific perception; and (ii) When models interact with search engines, their queries often fail to retrieve relevant information due to the inability to articulate requirements, thereby leading to suboptimal performance. To address these challenges, we define an action space tailored for visually rich inputs, with actions including cropping and scaling, allowing the model to gather information from a coarse-to-fine perspective. Furthermore, to bridge the gap between users' original inquiries and the retriever, we employ a simple yet effective reward that integrates query rewriting and retrieval performance with a model-based reward. Our VRAG-RL optimizes VLMs for RAG tasks using specially designed RL strategies, aligning the model with real-world applications. The code is available at \\hyperlink{https://github.com/Alibaba-NLP/VRAG}{https://github.com/Alibaba-NLP/VRAG}.","authors":["Qiuchen Wang","Ruixue Ding","Yu Zeng","Zehui Chen","Lin Chen","Shihang Wang","Pengjun Xie","Fei Huang","Feng Zhao"],"url":"https://arxiv.org/abs/2505.22019"}
{"created":"2025-05-29","title":"GL-PGENet: A Parameterized Generation Framework for Robust Document Image Enhancement","abstract":"Document Image Enhancement (DIE) serves as a critical component in Document AI systems, where its performance substantially determines the effectiveness of downstream tasks. To address the limitations of existing methods confined to single-degradation restoration or grayscale image processing, we present Global with Local Parametric Generation Enhancement Network (GL-PGENet), a novel architecture designed for multi-degraded color document images, ensuring both efficiency and robustness in real-world scenarios. Our solution incorporates three key innovations: First, a hierarchical enhancement framework that integrates global appearance correction with local refinement, enabling coarse-to-fine quality improvement. Second, a Dual-Branch Local-Refine Network with parametric generation mechanisms that replaces conventional direct prediction, producing enhanced outputs through learned intermediate parametric representations rather than pixel-wise mapping. This approach enhances local consistency while improving model generalization. Finally, a modified NestUNet architecture incorporating dense block to effectively fuse low-level pixel features and high-level semantic features, specifically adapted for document image characteristics. In addition, to enhance generalization performance, we adopt a two-stage training strategy: large-scale pretraining on a synthetic dataset of 500,000+ samples followed by task-specific fine-tuning. Extensive experiments demonstrate the superiority of GL-PGENet, achieving state-of-the-art SSIM scores of 0.7721 on DocUNet and 0.9480 on RealDAE. The model also exhibits remarkable cross-domain adaptability and maintains computational efficiency for high-resolution images without performance degradation, confirming its practical utility in real-world scenarios.","authors":["Zhihong Tang","Yang Li"],"url":"https://arxiv.org/abs/2505.22021"}
{"created":"2025-05-29","title":"A High Accuracy Symplectic Scheme for Advection Diffusion Reaction Models in Bioseparation","abstract":"We analyze an advection-diffusion-reaction problem with non-homogeneous boundary conditions that models the chromatography process, a vital stage in bioseparation. We prove stability and error estimates for both constant and affine adsorption, using the symplectic one-step implicit midpoint method for time discretization and finite elements for spatial discretization. In addition, we perform the stability analysis for the nonlinear, explicit adsorption in the continuous and semi-discrete cases. For the nonlinear, explicit adsorption, we also complete the error analysis for the semi-discrete case and prove the existence of a solution for the fully discrete case. The numerical tests validate our theoretical results.","authors":["Farjana Siddiqua","Catalin Trenchea"],"url":"https://arxiv.org/abs/2505.22022"}
{"created":"2025-05-29","title":"Securing the Software Package Supply Chain for Critical Systems","abstract":"Software systems have grown as an indispensable commodity used across various industries, and almost all essential services depend on them for effective operation. The software is no longer an independent or stand-alone piece of code written by a developer but rather a collection of packages designed by multiple developers across the globe. Ensuring the reliability and resilience of these systems is crucial since emerging threats target software supply chains, as demonstrated by the widespread SolarWinds hack in late 2020. These supply chains extend beyond patches and updates, involving distribution networks throughout the software lifecycle. Industries like smart grids, manufacturing, healthcare, and finance rely on interconnected software systems and their dependencies for effective functioning. To secure software modules and add-ons, robust distribution architectures are essential. The proposed chapter enhances the existing delivery frameworks by including a permissioned ledger with Proof of Authority consensus and multi-party signatures. The proposed system aims to prevent attacks while permitting every stakeholder to verify the same. Critical systems can interface with the secure pipeline without disrupting existing functionalities, thus preventing the cascading effect of an attack at any point in the supply chain.","authors":["Ritwik Murali","Akash Ravi"],"url":"https://arxiv.org/abs/2505.22023"}
{"created":"2025-05-29","title":"RESOUND: Speech Reconstruction from Silent Videos via Acoustic-Semantic Decomposed Modeling","abstract":"Lip-to-speech (L2S) synthesis, which reconstructs speech from visual cues, faces challenges in accuracy and naturalness due to limited supervision in capturing linguistic content, accents, and prosody. In this paper, we propose RESOUND, a novel L2S system that generates intelligible and expressive speech from silent talking face videos. Leveraging source-filter theory, our method involves two components: an acoustic path to predict prosody and a semantic path to extract linguistic features. This separation simplifies learning, allowing independent optimization of each representation. Additionally, we enhance performance by integrating speech units, a proven unsupervised speech representation technique, into waveform generation alongside mel-spectrograms. This allows RESOUND to synthesize prosodic speech while preserving content and speaker identity. Experiments conducted on two standard L2S benchmarks confirm the effectiveness of the proposed method across various metrics.","authors":["Long-Khanh Pham","Thanh V. T. Tran","Minh-Tan Pham","Van Nguyen"],"url":"https://arxiv.org/abs/2505.22024"}
{"created":"2025-05-29","title":"Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing","abstract":"Long-distance depth imaging holds great promise for applications such as autonomous driving and robotics. Direct time-of-flight (dToF) imaging offers high-precision, long-distance depth sensing, yet demands ultra-short pulse light sources and high-resolution time-to-digital converters. In contrast, indirect time-of-flight (iToF) imaging often suffers from phase wrapping and low signal-to-noise ratio (SNR) as the sensing distance increases. In this paper, we introduce a novel ToF imaging paradigm, termed Burst-Encodable Time-of-Flight (BE-ToF), which facilitates high-fidelity, long-distance depth imaging. Specifically, the BE-ToF system emits light pulses in burst mode and estimates the phase delay of the reflected signal over the entire burst period, thereby effectively avoiding the phase wrapping inherent to conventional iToF systems. Moreover, to address the low SNR caused by light attenuation over increasing distances, we propose an end-to-end learnable framework that jointly optimizes the coding functions and the depth reconstruction network. A specialized double well function and first-order difference term are incorporated into the framework to ensure the hardware implementability of the coding functions. The proposed approach is rigorously validated through comprehensive simulations and real-world prototype experiments, demonstrating its effectiveness and practical applicability.","authors":["Manchao Bao","Shengjiang Fang","Tao Yue","Xuemei Hu"],"url":"https://arxiv.org/abs/2505.22025"}
{"created":"2025-05-29","title":"Improving Respiratory Sound Classification with Architecture-Agnostic Knowledge Distillation from Ensembles","abstract":"Respiratory sound datasets are limited in size and quality, making high performance difficult to achieve. Ensemble models help but inevitably increase compute cost at inference time. Soft label training distills knowledge efficiently with extra cost only at training. In this study, we explore soft labels for respiratory sound classification as an architecture-agnostic approach to distill an ensemble of teacher models into a student model. We examine different variations of our approach and find that even a single teacher, identical to the student, considerably improves performance beyond its own capability, with optimal gains achieved using only a few teachers. We achieve the new state-of-the-art Score of 64.39 on ICHBI, surpassing the previous best by 0.85 and improving average Scores across architectures by more than 1.16. Our results highlight the effectiveness of knowledge distillation with soft labels for respiratory sound classification, regardless of size or architecture.","authors":["Miika Toikkanen","June-Woo Kim"],"url":"https://arxiv.org/abs/2505.22027"}
{"created":"2025-05-29","title":"Weakly-Supervised Contrastive Learning for Imprecise Class Labels","abstract":"Contrastive learning has achieved remarkable success in learning effective representations, with supervised contrastive learning often outperforming self-supervised approaches. However, in real-world scenarios, data annotations are often ambiguous or inaccurate, meaning that class labels may not reliably indicate whether two examples belong to the same class. This limitation restricts the applicability of supervised contrastive learning. To address this challenge, we introduce the concept of ``continuous semantic similarity'' to define positive and negative pairs. Instead of directly relying on imprecise class labels, we measure the semantic similarity between example pairs, which quantifies how closely they belong to the same category by iteratively refining weak supervisory signals. Based on this concept, we propose a graph-theoretic framework for weakly-supervised contrastive learning, where semantic similarity serves as the graph weights. Our framework is highly versatile and can be applied to many weakly-supervised learning scenarios. We demonstrate its effectiveness through experiments in two common settings, i.e., noisy label and partial label learning, where existing methods can be easily integrated to significantly improve performance. Theoretically, we establish an error bound for our approach, showing that it can approximate supervised contrastive learning under mild conditions. The implementation code is available at https://github.com/Speechless-10308/WSC.","authors":["Zi-Hao Zhou","Jun-Jie Wang","Tong Wei","Min-Ling Zhang"],"url":"https://arxiv.org/abs/2505.22028"}
{"created":"2025-05-29","title":"Guess the Age of Photos: An Interactive Web Platform for Historical Image Age Estimation","abstract":"This paper introduces Guess the Age of Photos, a web platform engaging users in estimating the years of historical photographs through two gamified modes: Guess the Year (predicting a single image's year) and Timeline Challenge (comparing two images to identify the older). Built with Python, Flask, Bootstrap, and PostgreSQL, it uses a 10,150-image subset of the Date Estimation in the Wild dataset (1930-1999). Features like dynamic scoring and leaderboards boost engagement. Evaluated with 113 users and 15,473 gameplays, the platform earned a 4.25/5 satisfaction rating. Users excelled in relative comparisons (65.9% accuracy) over absolute year guesses (25.6% accuracy), with older decades easier to identify. The platform serves as an educational tool, fostering historical awareness and analytical skills via interactive exploration of visual heritage. Furthermore, the platform provides a valuable resource for studying human perception of temporal cues in images and could be used to generate annotated data for training and evaluating computer vision models.","authors":["Hasan Yucedag","Adam Jatowt"],"url":"https://arxiv.org/abs/2505.22031"}
{"created":"2025-05-29","title":"Retweets, Receipts, and Resistance: Discourse, Sentiment, and Credibility in Public Health Crisis Twitter","abstract":"As the COVID-19 pandemic evolved, the Centers for Disease Control and Prevention (CDC) used Twitter to disseminate safety guidance and updates, reaching millions of users. This study analyzes two years of tweets from, to, and about the CDC using a mixed methods approach to examine discourse characteristics, credibility, and user engagement. We found that the CDCs communication remained largely one directional and did not foster reciprocal interaction, while discussions around COVID19 were deeply shaped by political and ideological polarization. Users frequently cited earlier CDC messages to critique new and sometimes contradictory guidance. Our findings highlight the role of sentiment, media richness, and source credibility in shaping the spread of public health messages. We propose design strategies to help the CDC tailor communications to diverse user groups and manage misinformation more effectively during high-stakes health crises.","authors":["Tawfiq Ammari","Anna Gutowska","Jacob Ziff","Casey Randazzo","Harihan Subramonyam"],"url":"https://arxiv.org/abs/2505.22032"}
{"created":"2025-05-29","title":"Neuromorphic Sequential Arena: A Benchmark for Neuromorphic Temporal Processing","abstract":"Temporal processing is vital for extracting meaningful information from time-varying signals. Recent advancements in Spiking Neural Networks (SNNs) have shown immense promise in efficiently processing these signals. However, progress in this field has been impeded by the lack of effective and standardized benchmarks, which complicates the consistent measurement of technological advancements and limits the practical applicability of SNNs. To bridge this gap, we introduce the Neuromorphic Sequential Arena (NSA), a comprehensive benchmark that offers an effective, versatile, and application-oriented evaluation framework for neuromorphic temporal processing. The NSA includes seven real-world temporal processing tasks from a diverse range of application scenarios, each capturing rich temporal dynamics across multiple timescales. Utilizing NSA, we conduct extensive comparisons of recently introduced spiking neuron models and neural architectures, presenting comprehensive baselines in terms of task performance, training speed, memory usage, and energy efficiency. Our findings emphasize an urgent need for efficient SNN designs that can consistently deliver high performance across tasks with varying temporal complexities while maintaining low computational costs. NSA enables systematic tracking of advancements in neuromorphic algorithm research and paves the way for developing effective and efficient neuromorphic temporal processing systems.","authors":["Xinyi Chen","Chenxiang Ma","Yujie Wu","Kay Chen Tan","Jibin Wu"],"url":"https://arxiv.org/abs/2505.22035"}
{"created":"2025-05-29","title":"Jailbreak Distillation: Renewable Safety Benchmarking","abstract":"Large language models (LLMs) are rapidly deployed in critical applications, raising urgent needs for robust safety benchmarking. We propose Jailbreak Distillation (JBDistill), a novel benchmark construction framework that \"distills\" jailbreak attacks into high-quality and easily-updatable safety benchmarks. JBDistill utilizes a small set of development models and existing jailbreak attack algorithms to create a candidate prompt pool, then employs prompt selection algorithms to identify an effective subset of prompts as safety benchmarks. JBDistill addresses challenges in existing safety evaluation: the use of consistent evaluation prompts across models ensures fair comparisons and reproducibility. It requires minimal human effort to rerun the JBDistill pipeline and produce updated benchmarks, alleviating concerns on saturation and contamination. Extensive experiments demonstrate our benchmarks generalize robustly to 13 diverse evaluation models held out from benchmark construction, including proprietary, specialized, and newer-generation LLMs, significantly outperforming existing safety benchmarks in effectiveness while maintaining high separability and diversity. Our framework thus provides an effective, sustainable, and adaptable solution for streamlining safety evaluation.","authors":["Jingyu Zhang","Ahmed Elgohary","Xiawei Wang","A S M Iftekhar","Ahmed Magooda","Benjamin Van Durme","Daniel Khashabi","Kyle Jackson"],"url":"https://arxiv.org/abs/2505.22037"}
{"created":"2025-05-29","title":"Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization","abstract":"Large Vision-Language Models (LVLMs) have shown impressive performance across multi-modal tasks by encoding images into thousands of tokens. However, the large number of image tokens results in significant computational overhead, and the use of dynamic high-resolution inputs further increases this burden. Previous approaches have attempted to reduce the number of image tokens through token pruning, typically by selecting tokens based on attention scores or image token diversity. Through empirical studies, we observe that existing methods often overlook the joint impact of pruning on both the current layer's output (local) and the outputs of subsequent layers (global), leading to suboptimal pruning decisions. To address this challenge, we propose Balanced Token Pruning (BTP), a plug-and-play method for pruning vision tokens. Specifically, our method utilizes a small calibration set to divide the pruning process into multiple stages. In the early stages, our method emphasizes the impact of pruning on subsequent layers, whereas in the deeper stages, the focus shifts toward preserving the consistency of local outputs. Extensive experiments across various LVLMs demonstrate the broad effectiveness of our approach on multiple benchmarks. Our method achieves a 78% compression rate while preserving 96.7% of the original models' performance on average.","authors":["Kaiyuan Li","Xiaoyue Chen","Chen Gao","Yong Li","Xinlei Chen"],"url":"https://arxiv.org/abs/2505.22038"}
{"created":"2025-05-29","title":"OmniAD: Detect and Understand Industrial Anomaly via Multimodal Reasoning","abstract":"While anomaly detection has made significant progress, generating detailed analyses that incorporate industrial knowledge remains a challenge. To address this gap, we introduce OmniAD, a novel framework that unifies anomaly detection and understanding for fine-grained analysis. OmniAD is a multimodal reasoner that combines visual and textual reasoning processes. The visual reasoning provides detailed inspection by leveraging Text-as-Mask Encoding to perform anomaly detection through text generation without manually selected thresholds. Following this, Visual Guided Textual Reasoning conducts comprehensive analysis by integrating visual perception. To enhance few-shot generalization, we employ an integrated training strategy that combines supervised fine-tuning (SFT) with reinforcement learning (GRPO), incorporating three sophisticated reward functions. Experimental results demonstrate that OmniAD achieves a performance of 79.1 on the MMAD benchmark, surpassing models such as Qwen2.5-VL-7B and GPT-4o. It also shows strong results across multiple anomaly detection benchmarks. These results highlight the importance of enhancing visual perception for effective reasoning in anomaly understanding. All codes and models will be publicly available.","authors":["Shifang Zhao","Yiheng Lin","Lu Han","Yao Zhao","Yunchao Wei"],"url":"https://arxiv.org/abs/2505.22039"}
{"created":"2025-05-29","title":"Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation","abstract":"Conformance checking techniques detect undesired process behavior by comparing process executions that are recorded in event logs to desired behavior that is captured in a dedicated process model. If such models are not available, conformance checking techniques are not applicable, but organizations might still be interested in detecting undesired behavior in their processes. To enable this, existing approaches use Large Language Models (LLMs), assuming that they can learn to distinguish desired from undesired behavior through fine-tuning. However, fine-tuning is highly resource-intensive and the fine-tuned LLMs often do not generalize well. To address these limitations, we propose an approach that requires neither a dedicated process model nor resource-intensive fine-tuning to detect undesired process behavior. Instead, we use Retrieval Augmented Generation (RAG) to provide an LLM with direct access to a knowledge base that contains both desired and undesired process behavior from other processes, assuming that the LLM can transfer this knowledge to the process at hand. Our evaluation shows that our approach outperforms fine-tuned LLMs in detecting undesired behavior, demonstrating that RAG is a viable alternative to resource-intensive fine-tuning, particularly when enriched with relevant context from the event log, such as frequent traces and activities.","authors":["Michael Grohs","Adrian Rebmann","Jana-Rebecca Rehse"],"url":"https://arxiv.org/abs/2505.22041"}
{"created":"2025-05-29","title":"Estimating the Effects of Sample Training Orders for Large Language Models without Retraining","abstract":"The order of training samples plays a crucial role in large language models (LLMs), significantly impacting both their external performance and internal learning dynamics. Traditional methods for investigating this effect generally require retraining the model with various sample orders, which is computationally infeasible for LLMs. In this work, we improve traditional methods by designing a retraining-free framework. By approximating Adam optimizer updates with first- and second-order Taylor expansions and utilizing random projection methods to store intermediate checkpoints, our framework can efficiently estimate model parameters for arbitrary training sample orders. Next, we apply our framework to two downstream research problems: (1) Training curriculum design for LLMs -- we base our retraining-free framework to propose a novel curriculum learning strategy that augments curriculum proposals with estimated model performances, enabling more informed sample scheduling. (2) LLMs' memorization and generalization effect analysis -- we use our retraining-free framework to estimate how the positions of training samples influence LLMs' capacity for memorization and generalization. We conduct extensive experiments to validate the effectiveness of our retraining-free framework in reproducing the true model performances, and further demonstrate its potential in optimizing LLM training curricula and analyzing the memorization and generalization effects of LLMs.","authors":["Hao Yang","Haoxuan Li","Mengyue Yang","Xu Chen","Mingming Gong"],"url":"https://arxiv.org/abs/2505.22042"}
{"created":"2025-05-29","title":"Mitigating Audiovisual Mismatch in Visual-Guide Audio Captioning","abstract":"Current vision-guided audio captioning systems frequently fail to address audiovisual misalignment in real-world scenarios, such as dubbed content or off-screen sounds. To bridge this critical gap, we present an entropy-aware gated fusion framework that dynamically modulates visual information flow through cross-modal uncertainty quantification. Our novel approach employs attention entropy analysis in cross-attention layers to automatically identify and suppress misleading visual cues during modal fusion. Complementing this architecture, we develop a batch-wise audiovisual shuffling technique that generates synthetic mismatched training pairs, greatly enhancing model resilience against alignment noise. Evaluations on the AudioCaps benchmark demonstrate our system's superior performance over existing baselines, especially in mismatched modality scenarios. Furthermore, our solution demonstrates an approximately 6x improvement in inference speed compared to the baseline.","authors":["Le Xu","Chenxing Li","Yong Ren","Yujie Chen","Yu Gu","Ruibo Fu","Shan Yang","Dong Yu"],"url":"https://arxiv.org/abs/2505.22045"}
{"created":"2025-05-29","title":"LatentMove: Towards Complex Human Movement Video Generation","abstract":"Image-to-video (I2V) generation seeks to produce realistic motion sequences from a single reference image. Although recent methods exhibit strong temporal consistency, they often struggle when dealing with complex, non-repetitive human movements, leading to unnatural deformations. To tackle this issue, we present LatentMove, a DiT-based framework specifically tailored for highly dynamic human animation. Our architecture incorporates a conditional control branch and learnable face/body tokens to preserve consistency as well as fine-grained details across frames. We introduce Complex-Human-Videos (CHV), a dataset featuring diverse, challenging human motions designed to benchmark the robustness of I2V systems. We also introduce two metrics to assess the flow and silhouette consistency of generated videos with their ground truth. Experimental results indicate that LatentMove substantially improves human animation quality--particularly when handling rapid, intricate movements--thereby pushing the boundaries of I2V generation. The code, the CHV dataset, and the evaluation metrics will be available at https://github.com/ --.","authors":["Ashkan Taghipour","Morteza Ghahremani","Mohammed Bennamoun","Farid Boussaid","Aref Miri Rekavandi","Zinuo Li","Qiuhong Ke","Hamid Laga"],"url":"https://arxiv.org/abs/2505.22046"}
{"created":"2025-05-29","title":"Differentiable Generalized Sliced Wasserstein Plans","abstract":"Optimal Transport (OT) has attracted significant interest in the machine learning community, not only for its ability to define meaningful distances between probability distributions -- such as the Wasserstein distance -- but also for its formulation of OT plans. Its computational complexity remains a bottleneck, though, and slicing techniques have been developed to scale OT to large datasets. Recently, a novel slicing scheme, dubbed min-SWGG, lifts a single one-dimensional plan back to the original multidimensional space, finally selecting the slice that yields the lowest Wasserstein distance as an approximation of the full OT plan. Despite its computational and theoretical advantages, min-SWGG inherits typical limitations of slicing methods: (i) the number of required slices grows exponentially with the data dimension, and (ii) it is constrained to linear projections. Here, we reformulate min-SWGG as a bilevel optimization problem and propose a differentiable approximation scheme to efficiently identify the optimal slice, even in high-dimensional settings. We furthermore define its generalized extension for accommodating to data living on manifolds. Finally, we demonstrate the practical value of our approach in various applications, including gradient flows on manifolds and high-dimensional spaces, as well as a novel sliced OT-based conditional flow matching for image generation -- where fast computation of transport plans is essential.","authors":["Laetitia Chapel","Romain Tavenard","Samuel Vaiter"],"url":"https://arxiv.org/abs/2505.22049"}
{"created":"2025-05-29","title":"Reinforced Reasoning for Embodied Planning","abstract":"Embodied planning requires agents to make coherent multi-step decisions based on dynamic visual observations and natural language goals. While recent vision-language models (VLMs) excel at static perception tasks, they struggle with the temporal reasoning, spatial understanding, and commonsense grounding needed for planning in interactive environments. In this work, we introduce a reinforcement fine-tuning framework that brings R1-style reasoning enhancement into embodied planning. We first distill a high-quality dataset from a powerful closed-source model and perform supervised fine-tuning (SFT) to equip the model with structured decision-making priors. We then design a rule-based reward function tailored to multi-step action quality and optimize the policy via Generalized Reinforced Preference Optimization (GRPO). Our approach is evaluated on Embench, a recent benchmark for interactive embodied tasks, covering both in-domain and out-of-domain scenarios. Experimental results show that our method significantly outperforms models of similar or larger scale, including GPT-4o-mini and 70B+ open-source baselines, and exhibits strong generalization to unseen environments. This work highlights the potential of reinforcement-driven reasoning to advance long-horizon planning in embodied AI.","authors":["Di Wu","Jiaxin Fan","Junzhe Zang","Guanbo Wang","Wei Yin","Wenhao Li","Bo Jin"],"url":"https://arxiv.org/abs/2505.22050"}
{"created":"2025-05-29","title":"A Comparative Study of Fuzzers and Static Analysis Tools for Finding Memory Unsafety in C and C++","abstract":"Even today, over 70% of security vulnerabilities in critical software systems result from memory safety violations. To address this challenge, fuzzing and static analysis are widely used automated methods to discover such vulnerabilities. Fuzzing generates random program inputs to identify faults, while static analysis examines source code to detect potential vulnerabilities. Although these techniques share a common goal, they take fundamentally different approaches and have evolved largely independently.","authors":["Keno Hassler","Philipp G\\\"orz","Stephan Lipp","Thorsten Holz","Marcel B\\\"ohme"],"url":"https://arxiv.org/abs/2505.22052"}
{"created":"2025-05-29","title":"AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation","abstract":"Multimodality-to-Multiaudio (MM2MA) generation faces significant challenges in synthesizing diverse and contextually aligned audio types (e.g., sound effects, speech, music, and songs) from multimodal inputs (e.g., video, text, images), owing to the scarcity of high-quality paired datasets and the lack of robust multi-task learning frameworks. Recently, multi-agent system shows great potential in tackling the above issues. However, directly applying it to MM2MA task presents three critical challenges: (1) inadequate fine-grained understanding of multimodal inputs (especially for video), (2) the inability of single models to handle diverse audio events, and (3) the absence of self-correction mechanisms for reliable outputs. To this end, we propose AudioGenie, a novel training-free multi-agent system featuring a dual-layer architecture with a generation team and a supervisor team. For the generation team, a fine-grained task decomposition and an adaptive Mixture-of-Experts (MoE) collaborative entity are designed for dynamic model selection, and a trial-and-error iterative refinement module is designed for self-correction. The supervisor team ensures temporal-spatial consistency and verifies outputs through feedback loops. Moreover, we build MA-Bench, the first benchmark for MM2MA tasks, comprising 198 annotated videos with multi-type audios. Experiments demonstrate that our AudioGenie outperforms state-of-the-art (SOTA) methods across 9 metrics in 8 tasks. User study further validate the effectiveness of the proposed method in terms of quality, accuracy, alignment, and aesthetic. The anonymous project website with samples can be found at https://audiogenie.github.io/.","authors":["Yan Rong","Jinting Wang","Shan Yang","Guangzhi Lei","Li Liu"],"url":"https://arxiv.org/abs/2505.22053"}
{"created":"2025-05-29","title":"Voice Adaptation for Swiss German","abstract":"This work investigates the performance of Voice Adaptation models for Swiss German dialects, i.e., translating Standard German text to Swiss German dialect speech. For this, we preprocess a large dataset of Swiss podcasts, which we automatically transcribe and annotate with dialect classes, yielding approximately 5000 hours of weakly labeled training material. We fine-tune the XTTSv2 model on this dataset and show that it achieves good scores in human and automated evaluations and can correctly render the desired dialect. Our work shows a step towards adapting Voice Cloning technology to underrepresented languages. The resulting model achieves CMOS scores of up to -0.28 and SMOS scores of 3.8.","authors":["Samuel Stucki","Jan Deriu","Mark Cieliebak"],"url":"https://arxiv.org/abs/2505.22054"}
{"created":"2025-05-29","title":"Shapley Value-driven Data Pruning for Recommender Systems","abstract":"Recommender systems often suffer from noisy interactions like accidental clicks or popularity bias. Existing denoising methods typically identify users' intent in their interactions, and filter out noisy interactions that deviate from the assumed intent. However, they ignore that interactions deemed noisy could still aid model training, while some ``clean'' interactions offer little learning value. To bridge this gap, we propose Shapley Value-driven Valuation (SVV), a framework that evaluates interactions based on their objective impact on model training rather than subjective intent assumptions. In SVV, a real-time Shapley value estimation method is devised to quantify each interaction's value based on its contribution to reducing training loss. Afterward, SVV highlights the interactions with high values while downplaying low ones to achieve effective data pruning for recommender systems. In addition, we develop a simulated noise protocol to examine the performance of various denoising approaches systematically. Experiments on four real-world datasets show that SVV outperforms existing denoising methods in both accuracy and robustness. Further analysis also demonstrates that our SVV can preserve training-critical interactions and offer interpretable noise assessment. This work shifts denoising from heuristic filtering to principled, model-driven interaction valuation.","authors":["Yansen Zhang","Xiaokun Zhang","Ziqiang Cui","Chen Ma"],"url":"https://arxiv.org/abs/2505.22057"}
{"created":"2025-05-29","title":"Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?","abstract":"Retrieval-augmented generation (RAG) mitigates the hallucination problem in large language models (LLMs) and has proven effective for specific, personalized applications. However, passing private retrieved documents directly to LLMs introduces vulnerability to membership inference attacks (MIAs), which try to determine whether the target datum exists in the private external database or not. Based on the insight that MIA queries typically exhibit high similarity to only one target document, we introduce Mirabel, a similarity-based MIA detection framework designed for the RAG system. With the proposed Mirabel, we show that simple detect-and-hide strategies can successfully obfuscate attackers, maintain data utility, and remain system-agnostic. We experimentally prove its detection and defense against various state-of-the-art MIA methods and its adaptability to existing private RAG systems.","authors":["Yujin Choi","Youngjoo Park","Junyoung Byun","Jaewook Lee","Jinseong Park"],"url":"https://arxiv.org/abs/2505.22061"}
{"created":"2025-05-29","title":"Weakly Supervised Data Refinement and Flexible Sequence Compression for Efficient Thai LLM-based ASR","abstract":"Despite remarkable achievements, automatic speech recognition (ASR) in low-resource scenarios still faces two challenges: high-quality data scarcity and high computational demands. This paper proposes EThai-ASR, the first to apply large language models (LLMs) to Thai ASR and create an efficient LLM-based ASR system. EThai-ASR comprises a speech encoder, a connection module and a Thai LLM decoder. To address the data scarcity and obtain a powerful speech encoder, EThai-ASR introduces a self-evolving data refinement strategy to refine weak labels, yielding an enhanced speech encoder. Moreover, we propose a pluggable sequence compression module used in the connection module with three modes designed to reduce the sequence length, thus decreasing computational demands while maintaining decent performance. Extensive experiments demonstrate that EThai-ASR has achieved state-of-the-art accuracy in multiple datasets. We release our refined text transcripts to promote further research.","authors":["Mingchen Shao","Xinfa Zhu","Chengyou Wang","Bingshen Mu","Hai Li","Ying Yan","Junhui Liu","Danming Xie","Lei Xie"],"url":"https://arxiv.org/abs/2505.22063"}
{"created":"2025-05-29","title":"AquaMonitor: A multimodal multi-view image sequence dataset for real-life aquatic invertebrate biodiversity monitoring","abstract":"This paper presents the AquaMonitor dataset, the first large computer vision dataset of aquatic invertebrates collected during routine environmental monitoring. While several large species identification datasets exist, they are rarely collected using standardized collection protocols, and none focus on aquatic invertebrates, which are particularly laborious to collect. For AquaMonitor, we imaged all specimens from two years of monitoring whenever imaging was possible given practical limitations. The dataset enables the evaluation of automated identification methods for real-life monitoring purposes using a realistically challenging and unbiased setup. The dataset has 2.7M images from 43,189 specimens, DNA sequences for 1358 specimens, and dry mass and size measurements for 1494 specimens, making it also one of the largest biological multi-view and multimodal datasets to date. We define three benchmark tasks and provide strong baselines for these: 1) Monitoring benchmark, reflecting real-life deployment challenges such as open-set recognition, distribution shift, and extreme class imbalance, 2) Classification benchmark, which follows a standard fine-grained visual categorization setup, and 3) Few-shot benchmark, which targets classes with only few training examples from very fine-grained categories. Advancements on the Monitoring benchmark can directly translate to improvement of aquatic biodiversity monitoring, which is an important component of regular legislative water quality assessment in many countries.","authors":["Mikko Impi\\\"o","Philipp M. Rehsen","Tiina Laamanen","Arne J. Beermann","Florian Leese","Jenni Raitoharju"],"url":"https://arxiv.org/abs/2505.22065"}
{"created":"2025-05-29","title":"From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving","abstract":"Ensuring robust and generalizable autonomous driving requires not only broad scenario coverage but also efficient repair of failure cases, particularly those related to challenging and safety-critical scenarios. However, existing scenario generation and selection methods often lack adaptivity and semantic relevance, limiting their impact on performance improvement. In this paper, we propose \\textbf{SERA}, an LLM-powered framework that enables autonomous driving systems to self-evolve by repairing failure cases through targeted scenario recommendation. By analyzing performance logs, SERA identifies failure patterns and dynamically retrieves semantically aligned scenarios from a structured bank. An LLM-based reflection mechanism further refines these recommendations to maximize relevance and diversity. The selected scenarios are used for few-shot fine-tuning, enabling targeted adaptation with minimal data. Experiments on the benchmark show that SERA consistently improves key metrics across multiple autonomous driving baselines, demonstrating its effectiveness and generalizability under safety-critical conditions.","authors":["Xinyu Xia","Xingjun Ma","Yunfeng Hu","Ting Qu","Hong Chen","Xun Gong"],"url":"https://arxiv.org/abs/2505.22067"}
{"created":"2025-05-29","title":"Beyond path selection: Better LLMs for Scientific Information Extraction with MimicSFT and Relevance and Rule-induced(R$^2$)GRPO","abstract":"Previous study suggest that powerful Large Language Models (LLMs) trained with Reinforcement Learning with Verifiable Rewards (RLVR) only refines reasoning path without improving the reasoning capacity in math tasks while supervised-finetuning(SFT) with distillation can. We study this from the view of Scientific information extraction (SciIE) where LLMs and reasoning LLMs underperforms small Bert-based models. SciIE require both the reasoning and memorization. We argue that both SFT and RLVR can refine the reasoning path and improve reasoning capacity in a simple way based on SciIE. We propose two-stage training with 1. MimicSFT, using structured reasoning templates without needing high-quality chain-of-thought data, 2. R$^2$GRPO with relevance and rule-induced rewards. Experiments on scientific IE benchmarks show that both methods can improve the reasoning capacity. R$^2$GRPO with mimicSFT surpasses baseline LLMs and specialized supervised models in relation extraction. Our code is available at https://github.com/ranlislz/R2GRPO.","authors":["Ran Li","Shimin Di","Yuchen Liu","Chen Jing","Yu Qiu","Lei Chen"],"url":"https://arxiv.org/abs/2505.22068"}
{"created":"2025-05-29","title":"Delayed-KD: Delayed Knowledge Distillation based CTC for Low-Latency Streaming ASR","abstract":"CTC-based streaming ASR has gained significant attention in real-world applications but faces two main challenges: accuracy degradation in small chunks and token emission latency. To mitigate these challenges, we propose Delayed-KD, which applies delayed knowledge distillation on CTC posterior probabilities from a non-streaming to a streaming model. Specifically, with a tiny chunk size, we introduce a Temporal Alignment Buffer (TAB) that defines a relative delay range compared to the non-streaming teacher model to align CTC outputs and mitigate non-blank token mismatches. Additionally, TAB enables fine-grained control over token emission delay. Experiments on 178-hour AISHELL-1 and 10,000-hour WenetSpeech Mandarin datasets show consistent superiority of Delayed-KD. Impressively, Delayed-KD at 40 ms latency achieves a lower character error rate (CER) of 5.42% on AISHELL-1, comparable to the competitive U2++ model running at 320 ms latency.","authors":["Longhao Li","Yangze Li","Hongfei Xue","Jie Liu","Shuai Fang","Kai Wang","Lei Xie"],"url":"https://arxiv.org/abs/2505.22069"}
{"created":"2025-05-29","title":"On-the-fly Routing for Zero-shot MoE Speaker Adaptation of Speech Foundation Models for Dysarthric Speech Recognition","abstract":"This paper proposes a novel MoE-based speaker adaptation framework for foundation models based dysarthric speech recognition. This approach enables zero-shot adaptation and real-time processing while incorporating domain knowledge. Speech impairment severity and gender conditioned adapter experts are dynamically combined using on-the-fly predicted speaker-dependent routing parameters. KL-divergence is used to further enforce diversity among experts and their generalization to unseen speakers. Experimental results on the UASpeech corpus suggest that on-the-fly MoE-based adaptation produces statistically significant WER reductions of up to 1.34% absolute (6.36% relative) over the unadapted baseline HuBERT/WavLM models. Consistent WER reductions of up to 2.55% absolute (11.44% relative) and RTF speedups of up to 7 times are obtained over batch-mode adaptation across varying speaker-level data quantities. The lowest published WER of 16.35% (46.77% on very low intelligibility) is obtained.","authors":["Shujie HU","Xurong Xie","Mengzhe Geng","Jiajun Deng","Huimeng Wang","Guinan Li","Chengxi Deng","Tianzi Wang","Mingyu Cui","Helen Meng","Xunying Liu"],"url":"https://arxiv.org/abs/2505.22072"}
{"created":"2025-05-29","title":"A Closer Look at the Existing Risks of Generative AI: Mapping the Who, What, and How of Real-World Incidents","abstract":"Due to its general-purpose nature, Generative AI is applied in an ever-growing set of domains and tasks, leading to an expanding set of risks of harm impacting people, communities, society, and the environment. These risks may arise due to failures during the design and development of the technology, as well as during its release, deployment, or downstream usages and appropriations of its outputs. In this paper, building on prior taxonomies of AI risks, harms, and failures, we construct a taxonomy specifically for Generative AI failures and map them to the harms they precipitate. Through a systematic analysis of 499 publicly reported incidents, we describe what harms are reported, how they arose, and who they impact. We report the prevalence of each type of harm, underlying failure mode, and harmed stakeholder, as well as their common co-occurrences. We find that most reported incidents are caused by use-related issues but bring harm to parties beyond the end user(s) of the Generative AI system at fault, and that the landscape of Generative AI harms is distinct from that of traditional AI. Our work offers actionable insights to policymakers, developers, and Generative AI users. In particular, we call for the prioritization of non-technical risk and harm mitigation strategies, including public disclosures and education and careful regulatory stances.","authors":["Megan Li","Wendy Bickersteth","Ningjing Tang","Jason Hong","Lorrie Cranor","Hong Shen","Hoda Heidari"],"url":"https://arxiv.org/abs/2505.22073"}
{"created":"2025-05-29","title":"The Resurrection of the ReLU","abstract":"Modeling sophisticated activation functions within deep learning architectures has evolved into a distinct research direction. Functions such as GELU, SELU, and SiLU offer smooth gradients and improved convergence properties, making them popular choices in state-of-the-art models. Despite this trend, the classical ReLU remains appealing due to its simplicity, inherent sparsity, and other advantageous topological characteristics. However, ReLU units are prone to becoming irreversibly inactive - a phenomenon known as the dying ReLU problem - which limits their overall effectiveness. In this work, we introduce surrogate gradient learning for ReLU (SUGAR) as a novel, plug-and-play regularizer for deep architectures. SUGAR preserves the standard ReLU function during the forward pass but replaces its derivative in the backward pass with a smooth surrogate that avoids zeroing out gradients. We demonstrate that SUGAR, when paired with a well-chosen surrogate function, substantially enhances generalization performance over convolutional network architectures such as VGG-16 and ResNet-18, providing sparser activations while effectively resurrecting dead ReLUs. Moreover, we show that even in modern architectures like Conv2NeXt and Swin Transformer - which typically employ GELU - substituting these with SUGAR yields competitive and even slightly superior performance. These findings challenge the prevailing notion that advanced activation functions are necessary for optimal performance. Instead, they suggest that the conventional ReLU, particularly with appropriate gradient handling, can serve as a strong, versatile revived classic across a broad range of deep learning vision models.","authors":["Co\\c{s}ku Can Horuz","Geoffrey Kasenbacher","Saya Higuchi","Sebastian Kairat","Jendrik Stoltz","Moritz Pesl","Bernhard A. Moser","Christoph Linse","Thomas Martinetz","Sebastian Otte"],"url":"https://arxiv.org/abs/2505.22074"}
{"created":"2025-05-29","title":"ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation","abstract":"Training large language models (LLMs) to follow instructions has significantly enhanced their ability to tackle unseen tasks. However, despite their strong generalization capabilities, instruction-following LLMs encounter difficulties when dealing with tasks that require domain knowledge. This work introduces a specialized instruction fine-tuning for the domain of computational argumentation (CA). The goal is to enable an LLM to effectively tackle any unseen CA tasks while preserving its generalization capabilities. Reviewing existing CA research, we crafted natural language instructions for 105 CA tasks to this end. On this basis, we developed a CA-specific benchmark for LLMs that allows for a comprehensive evaluation of LLMs' capabilities in solving various CA tasks. We synthesized 52k CA-related instructions, adapting the self-instruct process to train a CA-specialized instruction-following LLM. Our experiments suggest that CA-specialized instruction fine-tuning significantly enhances the LLM on both seen and unseen CA tasks. At the same time, performance on the general NLP tasks of the SuperNI benchmark remains stable.","authors":["Maja Stahl","Timon Ziegenbein","Joonsuk Park","Henning Wachsmuth"],"url":"https://arxiv.org/abs/2505.22076"}
{"created":"2025-05-29","title":"Local cubic spline interpolation for Vlasov-type equations on a multi-patch geometry","abstract":"We present a semi-Lagrangian method for the numerical resolution of Vlasov-type equations on multi-patch meshes. We employ a local cubic spline interpolation with Hermite boundary conditions between the patches. The derivative reconstruction is adapted to cope with non-uniform meshes as well as non-conforming situations. In the conforming case, there are no longer any constraints on the number of points for each patch; however, a small global system must now be solved. In that case, the local spline representations coincide with the corresponding global spline reconstruction. Alternatively, we can choose not to apply the global system and the derivatives can be approximated. The influence of the most distant points diminishes as the number of points per patch increases. For uniform per patch configurations, a study of the explicit and asymptotic behavior of this influence has been led. The method is validated using a two-dimensional guiding-center model with an O-point. All the numerical results are carried out in the Gyselalib++ library.","authors":["Pauline Vidal","Emily Bourne","Virginie Grandgirard","Michel Mehrenberger","Eric Sonnendr\\\"ucker"],"url":"https://arxiv.org/abs/2505.22078"}
{"created":"2025-05-29","title":"Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis","abstract":"The development of large-scale image-text pair datasets has significantly advanced self-supervised learning in Vision-Language Processing (VLP). However, directly applying general-domain architectures such as CLIP to medical data presents challenges, particularly in handling negations and addressing the inherent data imbalance of medical datasets. To address these issues, we propose a novel approach that integrates clinically-enhanced dynamic soft labels and medical graphical alignment, thereby improving clinical comprehension and the applicability of contrastive loss in medical contexts. Furthermore, we introduce negation-based hard negatives to deepen the model's understanding of the complexities of clinical language. Our approach is easily integrated into the medical CLIP training pipeline and achieves state-of-the-art performance across multiple tasks, including zero-shot, fine-tuned classification, and report retrieval. To comprehensively evaluate our model's capacity for understanding clinical language, we introduce CXR-Align, a benchmark uniquely designed to evaluate the understanding of negation and clinical information within chest X-ray (CXR) datasets. Experimental results demonstrate that our proposed methods are straightforward to implement and generalize effectively across contrastive learning frameworks, enhancing medical VLP capabilities and advancing clinical language understanding in medical imaging.","authors":["Hanbin Ko","Chang-Min Park"],"url":"https://arxiv.org/abs/2505.22079"}
{"created":"2025-05-29","title":"Can Test-time Computation Mitigate Memorization Bias in Neural Symbolic Regression?","abstract":"Symbolic regression aims to discover mathematical equations that fit given numerical data. It has been applied in various fields of scientific research, such as producing human-readable expressions that explain physical phenomena. Recently, Neural symbolic regression (NSR) methods that involve Transformers pre-trained on large-scale synthetic datasets have gained attention. While these methods offer advantages such as short inference time, they suffer from low performance, particularly when the number of input variables is large. In this study, we hypothesized that this limitation stems from the memorization bias of Transformers in symbolic regression. We conducted a quantitative evaluation of this bias in Transformers using a synthetic dataset and found that Transformers rarely generate expressions not present in the training data. Additional theoretical analysis reveals that this bias arises from the Transformer's inability to construct expressions compositionally while verifying their numerical validity. We finally examined if tailoring test-time strategies can lead to reduced memorization bias and better performance. We empirically demonstrate that providing additional information to the model at test time can significantly mitigate memorization bias. On the other hand, we also find that reducing memorization bias does not necessarily correlate with improved performance. These findings contribute to a deeper understanding of the limitations of NSR approaches and offer a foundation for designing more robust, generalizable symbolic regression methods. Code is available at https://github.com/Shun-0922/Mem-Bias-NSR .","authors":["Shun Sato","Issei Sato"],"url":"https://arxiv.org/abs/2505.22081"}
{"created":"2025-05-29","title":"MObyGaze: a film dataset of multimodal objectification densely annotated by experts","abstract":"Characterizing and quantifying gender representation disparities in audiovisual storytelling contents is necessary to grasp how stereotypes may perpetuate on screen. In this article, we consider the high-level construct of objectification and introduce a new AI task to the ML community: characterize and quantify complex multimodal (visual, speech, audio) temporal patterns producing objectification in films. Building on film studies and psychology, we define the construct of objectification in a structured thesaurus involving 5 sub-constructs manifesting through 11 concepts spanning 3 modalities. We introduce the Multimodal Objectifying Gaze (MObyGaze) dataset, made of 20 movies annotated densely by experts for objectification levels and concepts over freely delimited segments: it amounts to 6072 segments over 43 hours of video with fine-grained localization and categorization. We formulate different learning tasks, propose and investigate best ways to learn from the diversity of labels among a low number of annotators, and benchmark recent vision, text and audio models, showing the feasibility of the task. We make our code and our dataset available to the community and described in the Croissant format: https://anonymous.4open.science/r/MObyGaze-F600/.","authors":["Julie Tores","Elisa Ancarani","Lucile Sassatelli","Hui-Yin Wu","Clement Bergman","Lea Andolfi","Victor Ecrement","Remy Sun","Frederic Precioso","Thierry Devars","Magali Guaresi","Virginie Julliard","Sarah Lecossais"],"url":"https://arxiv.org/abs/2505.22084"}
{"created":"2025-05-29","title":"iDSE: Navigating Design Space Exploration in High-Level Synthesis Using LLMs","abstract":"High-Level Synthesis (HLS) serves as an agile hardware development tool that streamlines the circuit design by abstracting the register transfer level into behavioral descriptions, while allowing designers to customize the generated microarchitectures through optimization directives. However, the combinatorial explosion of possible directive configurations yields an intractable design space. Traditional design space exploration (DSE) methods, despite adopting heuristics or constructing predictive models to accelerate Pareto-optimal design acquisition, still suffer from prohibitive exploration costs and suboptimal results. Addressing these concerns, we introduce iDSE, the first LLM-aided DSE framework that leverages HLS design quality perception to effectively navigate the design space. iDSE intelligently pruns the design space to guide LLMs in calibrating representative initial sampling designs, expediting convergence toward the Pareto front. By exploiting the convergent and divergent thinking patterns inherent in LLMs for hardware optimization, iDSE achieves multi-path refinement of the design quality and diversity. Extensive experiments demonstrate that iDSE outperforms heuristic-based DSE methods by 5.1$\\times$$\\sim$16.6$\\times$ in proximity to the reference Pareto front, matching NSGA-II with only 4.6% of the explored designs. Our work demonstrates the transformative potential of LLMs in scalable and efficient HLS design optimization, offering new insights into multiobjective optimization challenges.","authors":["Runkai Li","Jia Xiong","Xi Wang"],"url":"https://arxiv.org/abs/2505.22086"}
{"created":"2025-05-29","title":"Cognitively-Inspired Emergent Communication via Knowledge Graphs for Assisting the Visually Impaired","abstract":"Assistive systems for visually impaired individuals must deliver rapid, interpretable, and adaptive feedback to facilitate real-time navigation. Current approaches face a trade-off between latency and semantic richness: natural language-based systems provide detailed guidance but are too slow for dynamic scenarios, while emergent communication frameworks offer low-latency symbolic languages but lack semantic depth, limiting their utility in tactile modalities like vibration. To address these limitations, we introduce a novel framework, Cognitively-Inspired Emergent Communication via Knowledge Graphs (VAG-EC), which emulates human visual perception and cognitive mapping. Our method constructs knowledge graphs to represent objects and their relationships, incorporating attention mechanisms to prioritize task-relevant entities, thereby mirroring human selective attention. This structured approach enables the emergence of compact, interpretable, and context-sensitive symbolic languages. Extensive experiments across varying vocabulary sizes and message lengths demonstrate that VAG-EC outperforms traditional emergent communication methods in Topographic Similarity (TopSim) and Context Independence (CI). These findings underscore the potential of cognitively grounded emergent communication as a fast, adaptive, and human-aligned solution for real-time assistive technologies. Code is available at https://github.com/Anonymous-NLPcode/Anonymous_submission/tree/main.","authors":["Ruxiao Chen","Dezheng Han","Wenjie Han","Shuaishuai Guo"],"url":"https://arxiv.org/abs/2505.22087"}
{"created":"2025-05-29","title":"Visual Cues Support Robust Turn-taking Prediction in Noise","abstract":"Accurate predictive turn-taking models (PTTMs) are essential for naturalistic human-robot interaction. However, little is known about their performance in noise. This study therefore explores PTTM performance in types of noise likely to be encountered once deployed. Our analyses reveal PTTMs are highly sensitive to noise. Hold/shift accuracy drops from 84% in clean speech to just 52% in 10 dB music noise. Training with noisy data enables a multimodal PTTM, which includes visual features to better exploit visual cues, with 72% accuracy in 10 dB music noise. The multimodal PTTM outperforms the audio-only PTTM across all noise types and SNRs, highlighting its ability to exploit visual cues; however, this does not always generalise to new types of noise. Analysis also reveals that successful training relies on accurate transcription, limiting the use of ASR-derived transcriptions to clean conditions. We make code publicly available for future research.","authors":["Sam O'Connor Russell","Naomi Harte"],"url":"https://arxiv.org/abs/2505.22088"}
{"created":"2025-05-29","title":"Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule","abstract":"Feature matching dominats the time costs in structure from motion (SfM). The primary contribution of this study is a GPU data schedule algorithm for efficient feature matching of Unmanned aerial vehicle (UAV) images. The core idea is to divide the whole dataset into blocks based on the matrix band reduction (MBR) and achieve efficient feature matching via GPU-accelerated cascade hashing. First, match pairs are selected by using an image retrieval technique, which converts images into global descriptors and searches high-dimension nearest neighbors with graph indexing. Second, compact image blocks are iteratively generated from a MBR-based data schedule strategy, which exploits image connections to avoid redundant data IO (input/output) burden and increases the usage of GPU computing power. Third, guided by the generated image blocks, feature matching is executed sequentially within the framework of GPU-accelerated cascade hashing, and initial candidate matches are refined by combining a local geometric constraint and RANSAC-based global verification. For further performance improvement, these two seps are designed to execute parallelly in GPU and CPU. Finally, the performance of the proposed solution is evaluated by using large-scale UAV datasets. The results demonstrate that it increases the efficiency of feature matching with speedup ratios ranging from 77.0 to 100.0 compared with KD-Tree based matching methods, and achieves comparable accuracy in relative and absolute bundle adjustment (BA). The proposed algorithm is an efficient solution for feature matching of UAV images.","authors":["San Jiang","Kan You","Wanshou Jiang","Qingquan Li"],"url":"https://arxiv.org/abs/2505.22089"}
{"created":"2025-05-29","title":"A simulation framework for autonomous lunar construction work","abstract":"We present a simulation framework for lunar construction work involving multiple autonomous machines. The framework supports modelling of construction scenarios and autonomy solutions, execution of the scenarios in simulation, and analysis of work time and energy consumption throughout the construction project. The simulations are based on physics-based models for contacting multibody dynamics and deformable terrain, including vehicle-soil interaction forces and soil flow in real time. A behaviour tree manages the operational logic and error handling, which enables the representation of complex behaviours through a discrete set of simpler tasks in a modular hierarchical structure. High-level decision-making is separated from lower-level control algorithms, with the two connected via ROS2. Excavation movements are controlled through inverse kinematics and tracking controllers. The framework is tested and demonstrated on two different lunar construction scenarios.","authors":["Mattias Linde","Daniel Lindmark","Sandra {\\AA}lstig","Martin Servin"],"url":"https://arxiv.org/abs/2505.22091"}
{"created":"2025-05-29","title":"VIRAL: Vision-grounded Integration for Reward design And Learning","abstract":"The alignment between humans and machines is a critical challenge in artificial intelligence today. Reinforcement learning, which aims to maximize a reward function, is particularly vulnerable to the risks associated with poorly designed reward functions. Recent advancements has shown that Large Language Models (LLMs) for reward generation can outperform human performance in this context. We introduce VIRAL, a pipeline for generating and refining reward functions through the use of multi-modal LLMs. VIRAL autonomously creates and interactively improves reward functions based on a given environment and a goal prompt or annotated image. The refinement process can incorporate human feedback or be guided by a description generated by a video LLM, which explains the agent's policy in video form. We evaluated VIRAL in five Gymnasium environments, demonstrating that it accelerates the learning of new behaviors while ensuring improved alignment with user intent. The source-code and demo video are available at: https://github.com/VIRAL-UCBL1/VIRAL and https://youtu.be/t4_BXugBm9Q.","authors":["Valentin Cuzin-Rambaud","Emilien Komlenovic","Alexandre Faure","Bruno Yun"],"url":"https://arxiv.org/abs/2505.22092"}
{"created":"2025-05-29","title":"From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots","abstract":"The rapid adoption of AI powered coding assistants like ChatGPT and other coding copilots is transforming programming education, raising questions about assessment practices, academic integrity, and skill development. As educators seek alternatives to traditional grading methods susceptible to AI enabled plagiarism, structured peer assessment could be a promising strategy. This paper presents an empirical study of a rubric based, anonymized peer review process implemented in a large introductory programming course.","authors":["Santiago Berrezueta-Guzman","Stephan Krusche","Stefan Wagner"],"url":"https://arxiv.org/abs/2505.22093"}
{"created":"2025-05-29","title":"ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning","abstract":"We propose ReinFlow, a simple yet effective online reinforcement learning (RL) framework that fine-tunes a family of flow matching policies for continuous robotic control. Derived from rigorous RL theory, ReinFlow injects learnable noise into a flow policy's deterministic path, converting the flow into a discrete-time Markov Process for exact and straightforward likelihood computation. This conversion facilitates exploration and ensures training stability, enabling ReinFlow to fine-tune diverse flow model variants, including Rectified Flow [35] and Shortcut Models [19], particularly at very few or even one denoising step. We benchmark ReinFlow in representative locomotion and manipulation tasks, including long-horizon planning with visual input and sparse reward. The episode reward of Rectified Flow policies obtained an average net growth of 135.36% after fine-tuning in challenging legged locomotion tasks while saving denoising steps and 82.63% of wall time compared to state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate of the Shortcut Model policies in state and visual manipulation tasks achieved an average net increase of 40.34% after fine-tuning with ReinFlow at four or even one denoising step, whose performance is comparable to fine-tuned DDIM policies while saving computation time for an average of 23.20%. Project Webpage: https://reinflow.github.io/","authors":["Tonghe Zhang","Yu Chao","Sicang Su","Yu Wang"],"url":"https://arxiv.org/abs/2505.22094"}
{"created":"2025-05-29","title":"Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning","abstract":"Multimodal Retrieval-Augmented Generation (MRAG) has shown promise in mitigating hallucinations in Multimodal Large Language Models (MLLMs) by incorporating external knowledge during generation. Existing MRAG methods typically adopt a static retrieval pipeline that fetches relevant information from multiple Knowledge Bases (KBs), followed by a refinement step. However, these approaches overlook the reasoning and planning capabilities of MLLMs to dynamically determine how to interact with different KBs during the reasoning process. To address this limitation, we propose R1-Router, a novel MRAG framework that learns to decide when and where to retrieve knowledge based on the evolving reasoning state. Specifically, R1-Router can generate follow-up queries according to the current reasoning step, routing these intermediate queries to the most suitable KB, and integrating external knowledge into a coherent reasoning trajectory to answer the original query. Furthermore, we introduce Step-wise Group Relative Policy Optimization (Step-GRPO), a tailored reinforcement learning algorithm that assigns step-specific rewards to optimize the reasoning behavior of MLLMs. Experimental results on various open-domain QA benchmarks across multiple modalities demonstrate that R1-Router outperforms baseline models by over 7%. Further analysis shows that R1-Router can adaptively and effectively leverage diverse KBs, reducing unnecessary retrievals and improving both efficiency and accuracy.","authors":["Chunyi Peng","Zhipeng Xu","Zhenghao Liu","Yishan Li","Yukun Yan","Shuo Wang","Zhiyuan Liu","Yu Gu","Minghe Yu","Ge Yu","Maosong Sun"],"url":"https://arxiv.org/abs/2505.22095"}
{"created":"2025-05-29","title":"Knowledge Base Construction for Knowledge-Augmented Text-to-SQL","abstract":"Text-to-SQL aims to translate natural language queries into SQL statements, which is practical as it enables anyone to easily retrieve the desired information from databases. Recently, many existing approaches tackle this problem with Large Language Models (LLMs), leveraging their strong capability in understanding user queries and generating corresponding SQL code. Yet, the parametric knowledge in LLMs might be limited to covering all the diverse and domain-specific queries that require grounding in various database schemas, which makes generated SQLs less accurate oftentimes. To tackle this, we propose constructing the knowledge base for text-to-SQL, a foundational source of knowledge, from which we retrieve and generate the necessary knowledge for given queries. In particular, unlike existing approaches that either manually annotate knowledge or generate only a few pieces of knowledge for each query, our knowledge base is comprehensive, which is constructed based on a combination of all the available questions and their associated database schemas along with their relevant knowledge, and can be reused for unseen databases from different datasets and domains. We validate our approach on multiple text-to-SQL datasets, considering both the overlapping and non-overlapping database scenarios, where it outperforms relevant baselines substantially.","authors":["Jinheon Baek","Horst Samulowitz","Oktie Hassanzadeh","Dharmashankar Subramanian","Sola Shirai","Alfio Gliozzo","Debarun Bhattacharjya"],"url":"https://arxiv.org/abs/2505.22096"}
{"created":"2025-05-29","title":"UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images","abstract":"The primary contribution of this paper is a challenging benchmark dataset, UAVPairs, and a training pipeline designed for match pair retrieval of large-scale UAV images. First, the UAVPairs dataset, comprising 21,622 high-resolution images across 30 diverse scenes, is constructed; the 3D points and tracks generated by SfM-based 3D reconstruction are employed to define the geometric similarity of image pairs, ensuring genuinely matchable image pairs are used for training. Second, to solve the problem of expensive mining cost for global hard negative mining, a batched nontrivial sample mining strategy is proposed, leveraging the geometric similarity and multi-scene structure of the UAVPairs to generate training samples as to accelerate training. Third, recognizing the limitation of pair-based losses, the ranked list loss is designed to improve the discrimination of image retrieval models, which optimizes the global similarity structure constructed from the positive set and negative set. Finally, the effectiveness of the UAVPairs dataset and training pipeline is validated through comprehensive experiments on three distinct large-scale UAV datasets. The experiment results demonstrate that models trained with the UAVPairs dataset and the ranked list loss achieve significantly improved retrieval accuracy compared to models trained on existing datasets or with conventional losses. Furthermore, these improvements translate to enhanced view graph connectivity and higher quality of reconstructed 3D models. The models trained by the proposed approach perform more robustly compared with hand-crafted global features, particularly in challenging repetitively textured scenes and weakly textured scenes. For match pair retrieval of large-scale UAV images, the trained image retrieval models offer an effective solution. The dataset would be made publicly available at https://github.com/json87/UAVPairs.","authors":["Junhuan Liu","San Jiang","Wei Ge","Wei Huang","Bingxuan Guo","Qingquan Li"],"url":"https://arxiv.org/abs/2505.22098"}
{"created":"2025-05-29","title":"On the Transferability and Discriminability of Repersentation Learning in Unsupervised Domain Adaptation","abstract":"In this paper, we addressed the limitation of relying solely on distribution alignment and source-domain empirical risk minimization in Unsupervised Domain Adaptation (UDA). Our information-theoretic analysis showed that this standard adversarial-based framework neglects the discriminability of target-domain features, leading to suboptimal performance. To bridge this theoretical-practical gap, we defined \"good representation learning\" as guaranteeing both transferability and discriminability, and proved that an additional loss term targeting target-domain discriminability is necessary. Building on these insights, we proposed a novel adversarial-based UDA framework that explicitly integrates a domain alignment objective with a discriminability-enhancing constraint. Instantiated as Domain-Invariant Representation Learning with Global and Local Consistency (RLGLC), our method leverages Asymmetrically-Relaxed Wasserstein of Wasserstein Distance (AR-WWD) to address class imbalance and semantic dimension weighting, and employs a local consistency mechanism to preserve fine-grained target-domain discriminative information. Extensive experiments across multiple benchmark datasets demonstrate that RLGLC consistently surpasses state-of-the-art methods, confirming the value of our theoretical perspective and underscoring the necessity of enforcing both transferability and discriminability in adversarial-based UDA.","authors":["Wenwen Qiang","Ziyin Gu","Lingyu Si","Jiangmeng Li","Changwen Zheng","Fuchun Sun","Hui Xiong"],"url":"https://arxiv.org/abs/2505.22099"}
{"created":"2025-05-29","title":"MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models","abstract":"Large Language Models (LLMs) have emerged as foundational infrastructure in the pursuit of Artificial General Intelligence (AGI). Despite their remarkable capabilities in language perception and generation, current LLMs fundamentally lack a unified and structured architecture for handling memory. They primarily rely on parametric memory (knowledge encoded in model weights) and ephemeral activation memory (context-limited runtime states). While emerging methods like Retrieval-Augmented Generation (RAG) incorporate plaintext memory, they lack lifecycle management and multi-modal integration, limiting their capacity for long-term knowledge evolution. To address this, we introduce MemOS, a memory operating system designed for LLMs that, for the first time, elevates memory to a first-class operational resource. It builds unified mechanisms for representation, organization, and governance across three core memory types: parametric, activation, and plaintext. At its core is the MemCube, a standardized memory abstraction that enables tracking, fusion, and migration of heterogeneous memory, while offering structured, traceable access across tasks and contexts. MemOS establishes a memory-centric execution framework with strong controllability, adaptability, and evolvability. It fills a critical gap in current LLM infrastructure and lays the groundwork for continual adaptation, personalized intelligence, and cross-platform coordination in next-generation intelligent systems.","authors":["Zhiyu Li","Shichao Song","Hanyu Wang","Simin Niu","Ding Chen","Jiawei Yang","Chenyang Xi","Huayi Lai","Jihao Zhao","Yezhaohui Wang","Junpeng Ren","Zehao Lin","Jiahao Huo","Tianyi Chen","Kai Chen","Kehang Li","Zhiqiang Yin","Qingchen Yu","Bo Tang","Hongkang Yang","Zhi-Qin John Xu","Feiyu Xiong"],"url":"https://arxiv.org/abs/2505.22101"}
{"created":"2025-05-29","title":"Optimized Schwarz methods for heterogeneous heat transfer problems","abstract":"We present here nonoverlapping optimized Schwarz methods applied to heat transfer problems with heterogeneous diffusion coefficients. After a Laplace transform in time, we derive the error equation and obtain the convergence factor. The optimal transmission operators are nonlocal, and thus inconvenient to use in practice. We introduce three versions of local approximations for the transmission parameter, and provide a detailed analysis at the continuous level in each case to identify the best local transmission conditions. Numerical experiments are presented to illustrate the performance of each local transmission condition. As shown in our analysis, local transmission conditions, which are scaled appropriately with respect to the heterogeneous diffusion coefficients, are more efficient and robust especially when the discontinuity of the diffusion coefficient is large.","authors":["Martin J. Gander","Liu-Di Lu","Tingting Wu"],"url":"https://arxiv.org/abs/2505.22103"}
{"created":"2025-05-29","title":"Efficient Dynamic Shielding for Parametric Safety Specifications","abstract":"Shielding has emerged as a promising approach for ensuring safety of AI-controlled autonomous systems. The algorithmic goal is to compute a shield, which is a runtime safety enforcement tool that needs to monitor and intervene the AI controller's actions if safety could be compromised otherwise. Traditional shields are designed statically for a specific safety requirement. Therefore, if the safety requirement changes at runtime due to changing operating conditions, the shield needs to be recomputed from scratch, causing delays that could be fatal. We introduce dynamic shields for parametric safety specifications, which are succinctly represented sets of all possible safety specifications that may be encountered at runtime. Our dynamic shields are statically designed for a given safety parameter set, and are able to dynamically adapt as the true safety specification (permissible by the parameters) is revealed at runtime. The main algorithmic novelty lies in the dynamic adaptation procedure, which is a simple and fast algorithm that utilizes known features of standard safety shields, like maximal permissiveness. We report experimental results for a robot navigation problem in unknown territories, where the safety specification evolves as new obstacles are discovered at runtime. In our experiments, the dynamic shields took a few minutes for their offline design, and took between a fraction of a second and a few seconds for online adaptation at each step, whereas the brute-force online recomputation approach was up to 5 times slower.","authors":["Davide Corsi","Kaushik Mallik","Andoni Rodriguez","Cesar Sanchez"],"url":"https://arxiv.org/abs/2505.22104"}
{"created":"2025-05-29","title":"Adapting Segment Anything Model for Power Transmission Corridor Hazard Segmentation","abstract":"Power transmission corridor hazard segmentation (PTCHS) aims to separate transmission equipment and surrounding hazards from complex background, conveying great significance to maintaining electric power transmission safety. Recently, the Segment Anything Model (SAM) has emerged as a foundational vision model and pushed the boundaries of segmentation tasks. However, SAM struggles to deal with the target objects in complex transmission corridor scenario, especially those with fine structure. In this paper, we propose ELE-SAM, adapting SAM for the PTCHS task. Technically, we develop a Context-Aware Prompt Adapter to achieve better prompt tokens via incorporating global-local features and focusing more on key regions. Subsequently, to tackle the hazard objects with fine structure in complex background, we design a High-Fidelity Mask Decoder by leveraging multi-granularity mask features and then scaling them to a higher resolution. Moreover, to train ELE-SAM and advance this field, we construct the ELE-40K benchmark, the first large-scale and real-world dataset for PTCHS including 44,094 image-mask pairs. Experimental results for ELE-40K demonstrate the superior performance that ELE-SAM outperforms the baseline model with the average 16.8% mIoU and 20.6% mBIoU performance improvement. Moreover, compared with the state-of-the-art method on HQSeg-44K, the average 2.9% mIoU and 3.8% mBIoU absolute improvements further validate the effectiveness of our method on high-quality generic object segmentation. The source code and dataset are available at https://github.com/Hhaizee/ELE-SAM.","authors":["Hang Chen","Maoyuan Ye","Peng Yang","Haibin He","Juhua Liu","Bo Du"],"url":"https://arxiv.org/abs/2505.22105"}
{"created":"2025-05-29","title":"AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion","abstract":"Diffusion models have significantly improved the quality and diversity of audio generation but are hindered by slow inference speed. Rectified flow enhances inference speed by learning straight-line ordinary differential equation (ODE) paths. However, this approach requires training a flow-matching model from scratch and tends to perform suboptimally, or even poorly, at low step counts. To address the limitations of rectified flow while leveraging the advantages of advanced pre-trained diffusion models, this study integrates pre-trained models with the rectified diffusion method to improve the efficiency of text-to-audio (TTA) generation. Specifically, we propose AudioTurbo, which learns first-order ODE paths from deterministic noise sample pairs generated by a pre-trained TTA model. Experiments on the AudioCaps dataset demonstrate that our model, with only 10 sampling steps, outperforms prior models and reduces inference to 3 steps compared to a flow-matching-based acceleration model.","authors":["Junqi Zhao","Jinzheng Zhao","Haohe Liu","Yun Chen","Lu Han","Xubo Liu","Mark Plumbley","Wenwu Wang"],"url":"https://arxiv.org/abs/2505.22106"}
{"created":"2025-05-29","title":"Curse of High Dimensionality Issue in Transformer for Long-context Modeling","abstract":"Transformer-based large language models (LLMs) excel in natural language processing tasks by capturing long-range dependencies through self-attention mechanisms. However, long-context modeling faces significant computational inefficiencies due to \\textit{redundant} attention computations: while attention weights are often \\textit{sparse}, all tokens consume \\textit{equal} computational resources. In this paper, we reformulate traditional probabilistic sequence modeling as a \\textit{supervised learning task}, enabling the separation of relevant and irrelevant tokens and providing a clearer understanding of redundancy. Based on this reformulation, we theoretically analyze attention sparsity, revealing that only a few tokens significantly contribute to predictions. Building on this, we formulate attention optimization as a linear coding problem and propose a \\textit{group coding strategy}, theoretically showing its ability to improve robustness against random noise and enhance learning efficiency. Motivated by this, we propose \\textit{Dynamic Group Attention} (DGA), which leverages the group coding to explicitly reduce redundancy by aggregating less important tokens during attention computation. Empirical results show that our DGA significantly reduces computational costs while maintaining competitive performance.Code is available at https://github.com/bolixinyu/DynamicGroupAttention.","authors":["Shuhai Zhang","Zeng You","Yaofo Chen","Zhiquan Wen","Qianyue Wang","Zhijie Qiu","Yuanqing Li","Mingkui Tan"],"url":"https://arxiv.org/abs/2505.22107"}
{"created":"2025-05-29","title":"Inclusive, Differentially Private Federated Learning for Clinical Data","abstract":"Federated Learning (FL) offers a promising approach for training clinical AI models without centralizing sensitive patient data. However, its real-world adoption is hindered by challenges related to privacy, resource constraints, and compliance. Existing Differential Privacy (DP) approaches often apply uniform noise, which disproportionately degrades model performance, even among well-compliant institutions. In this work, we propose a novel compliance-aware FL framework that enhances DP by adaptively adjusting noise based on quantifiable client compliance scores. Additionally, we introduce a compliance scoring tool based on key healthcare and security standards to promote secure, inclusive, and equitable participation across diverse clinical settings. Extensive experiments on public datasets demonstrate that integrating under-resourced, less compliant clinics with highly regulated institutions yields accuracy improvements of up to 15% over traditional FL. This work advances FL by balancing privacy, compliance, and performance, making it a viable solution for real-world clinical workflows in global healthcare.","authors":["Santhosh Parampottupadam","Melih Co\\c{s}\\u{g}un","Sarthak Pati","Maximilian Zenk","Saikat Roy","Dimitrios Bounias","Benjamin Hamm","Sinem Sav","Ralf Floca","Klaus Maier-Hein"],"url":"https://arxiv.org/abs/2505.22108"}
{"created":"2025-05-29","title":"The quest for the GRAph Level autoEncoder (GRALE)","abstract":"Although graph-based learning has attracted a lot of attention, graph representation learning is still a challenging task whose resolution may impact key application fields such as chemistry or biology. To this end, we introduce GRALE, a novel graph autoencoder that encodes and decodes graphs of varying sizes into a shared embedding space. GRALE is trained using an Optimal Transport-inspired loss that compares the original and reconstructed graphs and leverages a differentiable node matching module, which is trained jointly with the encoder and decoder. The proposed attention-based architecture relies on Evoformer, the core component of AlphaFold, which we extend to support both graph encoding and decoding. We show, in numerical experiments on simulated and molecular data, that GRALE enables a highly general form of pre-training, applicable to a wide range of downstream tasks, from classification and regression to more complex tasks such as graph interpolation, editing, matching, and prediction.","authors":["Paul Krzakala","Gabriel Melo","Charlotte Laclau","Florence d'Alch\\'e-Buc","R\\'emi Flamary"],"url":"https://arxiv.org/abs/2505.22109"}
{"created":"2025-05-29","title":"Autoregression-free video prediction using diffusion model for mitigating error propagation","abstract":"Existing long-term video prediction methods often rely on an autoregressive video prediction mechanism. However, this approach suffers from error propagation, particularly in distant future frames. To address this limitation, this paper proposes the first AutoRegression-Free (ARFree) video prediction framework using diffusion models. Different from an autoregressive video prediction mechanism, ARFree directly predicts any future frame tuples from the context frame tuple. The proposed ARFree consists of two key components: 1) a motion prediction module that predicts a future motion using motion feature extracted from the context frame tuple; 2) a training method that improves motion continuity and contextual consistency between adjacent future frame tuples. Our experiments with two benchmark datasets show that the proposed ARFree video prediction framework outperforms several state-of-the-art video prediction methods.","authors":["Woonho Ko","Jin Bok Park","Il Yong Chun"],"url":"https://arxiv.org/abs/2505.22111"}
{"created":"2025-05-29","title":"Visual Large Language Models Exhibit Human-Level Cognitive Flexibility in the Wisconsin Card Sorting Test","abstract":"Cognitive flexibility has been extensively studied in human cognition but remains relatively unexplored in the context of Visual Large Language Models (VLLMs). This study assesses the cognitive flexibility of state-of-the-art VLLMs (GPT-4o, Gemini-1.5 Pro, and Claude-3.5 Sonnet) using the Wisconsin Card Sorting Test (WCST), a classic measure of set-shifting ability. Our results reveal that VLLMs achieve or surpass human-level set-shifting capabilities under chain-of-thought prompting with text-based inputs. However, their abilities are highly influenced by both input modality and prompting strategy. In addition, we find that through role-playing, VLLMs can simulate various functional deficits aligned with patients having impairments in cognitive flexibility, suggesting that VLLMs may possess a cognitive architecture, at least regarding the ability of set-shifting, similar to the brain. This study reveals the fact that VLLMs have already approached the human level on a key component underlying our higher cognition, and highlights the potential to use them to emulate complex brain processes.","authors":["Guangfu Hao","Frederic Alexandre","Shan Yu"],"url":"https://arxiv.org/abs/2505.22112"}
{"created":"2025-05-29","title":"THINK-Bench: Evaluating Thinking Efficiency and Chain-of-Thought Quality of Large Reasoning Models","abstract":"Large reasoning models (LRMs) have achieved impressive performance in complex tasks, often outperforming conventional large language models (LLMs). However, the prevalent issue of overthinking severely limits their computational efficiency. Overthinking occurs when models generate excessive and redundant tokens that contribute little to accurate outcomes, especially in simple tasks, resulting in a significant waste of computational resources. To systematically investigate this issue, we introduce Think-Bench, a benchmark designed to evaluate the reasoning efficiency of LRMs. We also propose novel efficiency metrics and conduct a comprehensive evaluation of various LRMs across multiple dimensions, including the reasoning process, outcome quality, and chain-of-thought (CoT) characteristics. Our analysis reveals that most LRMs exhibit overthinking in handling easy questions, generating unnecessarily lengthy reasoning chains. While many LRMs demonstrate high CoT quality, several suffer from low efficiency. We hope that Think-Bench can serve as a robust foundation for advancing research into LRMs.","authors":["Zhiyuan Li","Yi Chang","Yuan Wu"],"url":"https://arxiv.org/abs/2505.22113"}
{"created":"2025-05-29","title":"BiMi Sheets: Infosheets for bias mitigation methods","abstract":"Over the past 15 years, hundreds of bias mitigation methods have been proposed in the pursuit of fairness in machine learning (ML). However, algorithmic biases are domain-, task-, and model-specific, leading to a `portability trap': bias mitigation solutions in one context may not be appropriate in another. Thus, a myriad of design choices have to be made when creating a bias mitigation method, such as the formalization of fairness it pursues, and where and how it intervenes in the ML pipeline. This creates challenges in benchmarking and comparing the relative merits of different bias mitigation methods, and limits their uptake by practitioners.","authors":["MaryBeth Defrance","Guillaume Bied","Maarten Buyl","Jefrey Lijffijt","Tijl De Bie"],"url":"https://arxiv.org/abs/2505.22114"}
{"created":"2025-05-29","title":"Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model","abstract":"Intraoperative hypotension (IOH) frequently occurs under general anesthesia and is strongly linked to adverse outcomes such as myocardial injury and increased mortality. Despite its significance, IOH prediction is hindered by event sparsity and the challenge of integrating static and dynamic data across diverse patients. In this paper, we propose \\textbf{IOHFuseLM}, a multimodal language model framework. To accurately identify and differentiate sparse hypotensive events, we leverage a two-stage training strategy. The first stage involves domain adaptive pretraining on IOH physiological time series augmented through diffusion methods, thereby enhancing the model sensitivity to patterns associated with hypotension. Subsequently, task fine-tuning is performed on the original clinical dataset to further enhance the ability to distinguish normotensive from hypotensive states. To enable multimodal fusion for each patient, we align structured clinical descriptions with the corresponding physiological time series at the token level. Such alignment enables the model to capture individualized temporal patterns alongside their corresponding clinical semantics. In addition, we convert static patient attributes into structured text to enrich personalized information. Experimental evaluations on two intraoperative datasets demonstrate that IOHFuseLM outperforms established baselines in accurately identifying IOH events, highlighting its applicability in clinical decision support scenarios. Our code is publicly available to promote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.","authors":["Jintao Zhang","Zirui Liu","Mingyue Cheng","Shilong Zhang","Tingyue Pan","Qi Liu","Yanhu Xie"],"url":"https://arxiv.org/abs/2505.22116"}
{"created":"2025-05-29","title":"Multilingual vs Crosslingual Retrieval of Fact-Checked Claims: A Tale of Two Approaches","abstract":"Retrieval of previously fact-checked claims is a well-established task, whose automation can assist professional fact-checkers in the initial steps of information verification. Previous works have mostly tackled the task monolingually, i.e., having both the input and the retrieved claims in the same language. However, especially for languages with a limited availability of fact-checks and in case of global narratives, such as pandemics, wars, or international politics, it is crucial to be able to retrieve claims across languages. In this work, we examine strategies to improve the multilingual and crosslingual performance, namely selection of negative examples (in the supervised) and re-ranking (in the unsupervised setting). We evaluate all approaches on a dataset containing posts and claims in 47 languages (283 language combinations). We observe that the best results are obtained by using LLM-based re-ranking, followed by fine-tuning with negative examples sampled using a sentence similarity-based strategy. Most importantly, we show that crosslinguality is a setup with its own unique characteristics compared to the multilingual setup.","authors":["Alan Ramponi","Marco Rovera","Robert Moro","Sara Tonelli"],"url":"https://arxiv.org/abs/2505.22118"}
{"created":"2025-05-29","title":"LoKI: Low-damage Knowledge Implanting of Large Language Models","abstract":"Fine-tuning adapts pretrained models for specific tasks but poses the risk of catastrophic forgetting (CF), where critical knowledge from pre-training is overwritten. Current Parameter-Efficient Fine-Tuning (PEFT) methods for Large Language Models (LLMs), while efficient, often sacrifice general capabilities. To address the issue of CF in a general-purpose PEFT framework, we propose \\textbf{Lo}w-damage \\textbf{K}nowledge \\textbf{I}mplanting (\\textbf{LoKI}), a PEFT technique that is based on a mechanistic understanding of how knowledge is stored in transformer architectures. In two real-world scenarios, LoKI demonstrates task-specific performance that is comparable to or even surpasses that of full fine-tuning and LoRA-based methods across various model types, while significantly better preserving general capabilities. Our work connects mechanistic insights into LLM knowledge storage with practical fine-tuning objectives, achieving state-of-the-art trade-offs between task specialization and the preservation of general capabilities. Our implementation is publicly available as ready-to-use code\\footnote{https://github.com/Nexround/LoKI}.","authors":["Runyu Wang","Peng Ping","Zhengyu Guo","Xiaoye Zhang","Quan Shi","Liting Zhou","Tianbo Ji"],"url":"https://arxiv.org/abs/2505.22120"}
{"created":"2025-05-29","title":"Leveraging 5G Physical Layer Monitoring for Adaptive Remote Rendering in XR Applications","abstract":"As immersive eXtended Reality (XR) applications demand substantial network resources, understanding their interaction with 5G networks becomes crucial to improve them. This paper investigates the role of 5G physical-layer monitoring to manage and enhance the remote rendering of XR content dynamically. By observing network metrics directly from the physical layer, we propose a system to adapt streaming parameters such as bitrate, framerate, and resolution in real time based on available network capacity. Using theoretical formulas to estimate maximum data rate, our approach evaluates network resource availability, enabling the renderer to self-adjust media content representation. This is critical for providing consistent and smooth XR experiences to users, especially as network conditions fluctuate. Our findings suggest that physical-layer monitoring offers valuable insights to increase the Quality of Service (QoS) and has the potential to elevate user experience in remote-rendered XR applications.","authors":["Inhar Yeregui","Daniel Mej\\'ias","Mikel Zorrilla","Roberto Viola","Jasone Astorga","Eduardo Jacob"],"url":"https://arxiv.org/abs/2505.22123"}
{"created":"2025-05-29","title":"Sentiment Simulation using Generative AI Agents","abstract":"Traditional sentiment analysis relies on surface-level linguistic patterns and retrospective data, limiting its ability to capture the psychological and contextual drivers of human sentiment. These limitations constrain its effectiveness in applications that require predictive insight, such as policy testing, narrative framing, and behavioral forecasting. We present a robust framework for sentiment simulation using generative AI agents embedded with psychologically rich profiles. Agents are instantiated from a nationally representative survey of 2,485 Filipino respondents, combining sociodemographic information with validated constructs of personality traits, values, beliefs, and socio-political attitudes. The framework includes three stages: (1) agent embodiment via categorical or contextualized encodings, (2) exposure to real-world political and economic scenarios, and (3) generation of sentiment ratings accompanied by explanatory rationales. Using Quadratic Weighted Accuracy (QWA), we evaluated alignment between agent-generated and human responses. Contextualized encoding achieved 92% alignment in replicating original survey responses. In sentiment simulation tasks, agents reached 81%--86% accuracy against ground truth sentiment, with contextualized profile encodings significantly outperforming categorical (p < 0.0001, Cohen's d = 0.70). Simulation results remained consistent across repeated trials (+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676, Cohen's d = 0.02). Our findings establish a scalable framework for sentiment modeling through psychographically grounded AI agents. This work signals a paradigm shift in sentiment analysis from retrospective classification to prospective and dynamic simulation grounded in psychology of sentiment formation.","authors":["Melrose Tia","Jezreel Sophia Lanuzo","Lei Rigi Baltazar","Marie Joy Lopez-Relente","Diwa Malaya Qui\\~nones","Jason Albia"],"url":"https://arxiv.org/abs/2505.22125"}
{"created":"2025-05-29","title":"SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model","abstract":"Recent years have seen rapid advances in AI-driven image generation. Early diffusion models emphasized perceptual quality, while newer multimodal models like GPT-4o-image integrate high-level reasoning, improving semantic understanding and structural composition. Scientific illustration generation exemplifies this evolution: unlike general image synthesis, it demands accurate interpretation of technical content and transformation of abstract ideas into clear, standardized visuals. This task is significantly more knowledge-intensive and laborious, often requiring hours of manual work and specialized tools. Automating it in a controllable, intelligent manner would provide substantial practical value. Yet, no benchmark currently exists to evaluate AI on this front. To fill this gap, we introduce SridBench, the first benchmark for scientific figure generation. It comprises 1,120 instances curated from leading scientific papers across 13 natural and computer science disciplines, collected via human experts and MLLMs. Each sample is evaluated along six dimensions, including semantic fidelity and structural accuracy. Experimental results reveal that even top-tier models like GPT-4o-image lag behind human performance, with common issues in text/visual clarity and scientific correctness. These findings highlight the need for more advanced reasoning-driven visual generation capabilities.","authors":["Yifan Chang","Yukang Feng","Jianwen Sun","Jiaxin Ai","Chuanhao Li","S. Kevin Zhou","Kaipeng Zhang"],"url":"https://arxiv.org/abs/2505.22126"}
{"created":"2025-05-29","title":"Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach","abstract":"This work addresses mechanical defocus in Earth observation images from the IMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted to space-based edge computing constraints. Leveraging Sentinel-2 data, our method estimates the defocus kernel and trains a restoration model within a GAN framework, effectively operating without reference images.","authors":["Alejandro D. Mousist"],"url":"https://arxiv.org/abs/2505.22128"}
{"created":"2025-05-29","title":"What Makes for Text to 360-degree Panorama Generation with Stable Diffusion?","abstract":"Recent prosperity of text-to-image diffusion models, e.g. Stable Diffusion, has stimulated research to adapt them to 360-degree panorama generation. Prior work has demonstrated the feasibility of using conventional low-rank adaptation techniques on pre-trained diffusion models to generate panoramic images. However, the substantial domain gap between perspective and panoramic images raises questions about the underlying mechanisms enabling this empirical success. We hypothesize and examine that the trainable counterparts exhibit distinct behaviors when fine-tuned on panoramic data, and such an adaptation conceals some intrinsic mechanism to leverage the prior knowledge within the pre-trained diffusion models. Our analysis reveals the following: 1) the query and key matrices in the attention modules are responsible for common information that can be shared between the panoramic and perspective domains, thus are less relevant to panorama generation; and 2) the value and output weight matrices specialize in adapting pre-trained knowledge to the panoramic domain, playing a more critical role during fine-tuning for panorama generation. We empirically verify these insights by introducing a simple framework called UniPano, with the objective of establishing an elegant baseline for future research. UniPano not only outperforms existing methods but also significantly reduces memory usage and training time compared to prior dual-branch approaches, making it scalable for end-to-end panorama generation with higher resolution. The code will be released.","authors":["Jinhong Ni","Chang-Bin Zhang","Qiang Zhang","Jing Zhang"],"url":"https://arxiv.org/abs/2505.22129"}
{"created":"2025-05-29","title":"ConsRec: Denoising Sequential Recommendation through User-Consistent Preference Modeling","abstract":"User-item interaction histories are pivotal for sequential recommendation systems but often include noise, such as unintended clicks or actions that fail to reflect genuine user preferences. To address this issue, we propose the User-Consistent Preference-based Sequential Recommendation System (ConsRec), designed to capture stable user preferences and filter noisy items from interaction histories. Specifically, ConsRec constructs a user-interacted item graph, learns item similarities from their text representations, and then extracts the maximum connected subgraph from the user-interacted item graph for denoising items. Experimental results on the Yelp and Amazon Product datasets illustrate that ConsRec achieves a 13% improvement over baseline recommendation models, showing its effectiveness in denoising user-interacted items. Further analysis reveals that the denoised interaction histories form semantically tighter clusters of user-preferred items, leading to higher relevance scores for ground-truth targets and more accurate recommendations. All codes are available at https://github.com/NEUIR/ConsRec.","authors":["Haidong Xin","Qiushi Xiong","Zhenghao Liu","Sen Mei","Yukun Yan","Shi Yu","Shuo Wang","Yu Gu","Ge Yu","Chenyan Xiong"],"url":"https://arxiv.org/abs/2505.22130"}
{"created":"2025-05-29","title":"EULER: Enhancing the Reasoning Ability of Large Language Models through Error-Induced Learning","abstract":"Large Language Models (LLMs) have demonstrated strong reasoning capabilities and achieved promising results in mathematical problem-solving tasks. Learning from errors offers the potential to further enhance the performance of LLMs during Supervised Fine-Tuning (SFT). However, the errors in synthesized solutions are typically gathered from sampling trails, making it challenging to generate solution errors for each mathematical problem. This paper introduces the Error-IndUced LEaRning (EULER) model, which aims to develop an error exposure model that generates high-quality solution errors to enhance the mathematical reasoning capabilities of LLMs. Specifically, EULER optimizes the error exposure model to increase the generation probability of self-made solution errors while utilizing solutions produced by a superior LLM to regularize the generation quality. Our experiments across various mathematical problem datasets demonstrate the effectiveness of the EULER model, achieving an improvement of over 4% compared to all baseline models. Further analysis reveals that EULER is capable of synthesizing more challenging and educational solution errors, which facilitate both the training and inference processes of LLMs. All codes are available at https://github.com/NEUIR/EULER.","authors":["Zhuoyang Wu","Xinze Li","Zhenghao Liu","Yukun Yan","Zhiyuan Liu","Minghe Yu","Cheng Yang","Yu Gu","Ge Yu","Maosong Sun"],"url":"https://arxiv.org/abs/2505.22131"}
{"created":"2025-05-29","title":"Streaming Remote rendering services: Comparison of QUIC-based and WebRTC Protocols","abstract":"The proliferation of Extended Reality (XR) applications, requiring high-quality, low-latency media streaming, has driven the demand for efficient remote rendering solutions. This paper focuses on holographic conferencing in virtual environments and their required uplink and downlink media transmission capabilities. By examining Media over QUIC (MoQ), Real-time Transport Protocol (RTP) over QUIC (RoQ), and Web Real-Time Communication (WebRTC), we assess their latency performance over Wi-Fi and 5G networks. Improvements of approximately 30% in latency and 60% in connection startup are expected in QUIC-based protocols compared to WebRTC. The experimental setup transmits a remote-rendered virtual experience using real-time video streaming protocols to provide the content to the participant. Our findings contribute to understanding the maturity of streaming protocols, particularly within open-source frameworks, and evaluate their suitability in supporting latency-sensitive XR applications. The study highlights specific protocol advantages across varied remote rendering scenarios, informing the design of future XR communication solutions.","authors":["Daniel Mej\\'ias","Inhar Yeregui","\\'Angel Mart\\'in","Roberto Viola","Pablo Angueira","Jon Montalb\\'an"],"url":"https://arxiv.org/abs/2505.22132"}
{"created":"2025-05-29","title":"Developing a Top-tier Framework in Naturalistic Conditions Challenge for Categorized Emotion Prediction: From Speech Foundation Models and Learning Objective to Data Augmentation and Engineering Choices","abstract":"Speech emotion recognition (SER), particularly for naturally expressed emotions, remains a challenging computational task. Key challenges include the inherent subjectivity in emotion annotation and the imbalanced distribution of emotion labels in datasets. This paper introduces the \\texttt{SAILER} system developed for participation in the INTERSPEECH 2025 Emotion Recognition Challenge (Task 1). The challenge dataset, which contains natural emotional speech from podcasts, serves as a valuable resource for studying imbalanced and subjective emotion annotations. Our system is designed to be simple, reproducible, and effective, highlighting critical choices in modeling, learning objectives, data augmentation, and engineering choices. Results show that even a single system (without ensembling) can outperform more than 95\\% of the submissions, with a Macro-F1 score exceeding 0.4. Moreover, an ensemble of three systems further improves performance, achieving a competitively ranked score (top-3 performing team). Our model is at: https://github.com/tiantiaf0627/vox-profile-release.","authors":["Tiantian Feng","Thanathai Lertpetchpun","Dani Byrd","Shrikanth Narayanan"],"url":"https://arxiv.org/abs/2505.22133"}
{"created":"2025-05-29","title":"RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding","abstract":"Hybrid models combining Transformers and State Space Models (SSMs) are promising for balancing performance and efficiency. However, optimizing these hybrid models, particularly by addressing the potential redundancy inherent within the Transformer components, remains a significant challenge. In this paper, we propose RAD (Redundancy-Aware Distillation), a novel framework that uses self-speculative decoding as a diagnostic tool to identify redundant attention layers within the model. These identified layers are then selectively replaced with SSM components, followed by targeted (self-)distillation. Specifically, RAD focuses knowledge transfer on the components identified as redundant, considering architectural changes and specific weight initialization strategies. We experimentally demonstrate that self-distillation using RAD significantly surpasses the performance of the original base model on mathematical and coding tasks. Furthermore, RAD is also effective in standard knowledge distillation settings, achieving up to approximately 2x faster convergence compared to baseline methods. Notably, while a baseline model distilled from a Llama-3.1 70B teacher achieves scores of 46.17 on GSM8K and 22.75 on CRUX, RAD achieves significantly higher scores of 71.27 on GSM8K and 28.25 on CRUX, even when using a much smaller Llama-3.1 8B teacher. RAD offers a new pathway for efficient optimization and performance enhancement in the distillation of hybrid models.","authors":["Yuichiro Hoshino","Hideyuki Tachibana","Muneyoshi Inahara","Hiroto Takegawa"],"url":"https://arxiv.org/abs/2505.22135"}
{"created":"2025-05-29","title":"Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments","abstract":"Identifying arguments is a necessary prerequisite for various tasks in automated discourse analysis, particularly within contexts such as political debates, online discussions, and scientific reasoning. In addition to theoretical advances in understanding the constitution of arguments, a significant body of research has emerged around practical argument mining, supported by a growing number of publicly available datasets. On these benchmarks, BERT-like transformers have consistently performed best, reinforcing the belief that such models are broadly applicable across diverse contexts of debate. This study offers the first large-scale re-evaluation of such state-of-the-art models, with a specific focus on their ability to generalize in identifying arguments. We evaluate four transformers, three standard and one enhanced with contrastive pre-training for better generalization, on 17 English sentence-level datasets as most relevant to the task. Our findings show that, to varying degrees, these models tend to rely on lexical shortcuts tied to content words, suggesting that apparent progress may often be driven by dataset-specific cues rather than true task alignment. While the models achieve strong results on familiar benchmarks, their performance drops markedly when applied to unseen datasets. Nonetheless, incorporating both task-specific pre-training and joint benchmark training proves effective in enhancing both robustness and generalization.","authors":["Marc Feger","Katarina Boland","Stefan Dietze"],"url":"https://arxiv.org/abs/2505.22137"}
{"created":"2025-05-29","title":"FaceEditTalker: Interactive Talking Head Generation with Facial Attribute Editing","abstract":"Recent advances in audio-driven talking head generation have achieved impressive results in lip synchronization and emotional expression. However, they largely overlook the crucial task of facial attribute editing. This capability is crucial for achieving deep personalization and expanding the range of practical applications, including user-tailored digital avatars, engaging online education content, and brand-specific digital customer service. In these key domains, the flexible adjustment of visual attributes-such as hairstyle, accessories, and subtle facial features is essential for aligning with user preferences, reflecting diverse brand identities, and adapting to varying contextual demands. In this paper, we present FaceEditTalker, a unified framework that enables controllable facial attribute manipulation while generating high-quality, audio-synchronized talking head videos. Our method consists of two key components: an image feature space editing module, which extracts semantic and detail features and allows flexible control over attributes like expression, hairstyle, and accessories; and an audio-driven video generation module, which fuses these edited features with audio-guided facial landmarks to drive a diffusion-based generator. This design ensures temporal coherence, visual fidelity, and identity preservation across frames. Extensive experiments on public datasets demonstrate that our method outperforms state-of-the-art approaches in lip-sync accuracy, video quality, and attribute controllability. Project page: https://peterfanfan.github.io/FaceEditTalker/","authors":["Guanwen Feng","Zhiyuan Ma","Yunan Li","Junwei Jing","Jiahao Yang","Qiguang Miao"],"url":"https://arxiv.org/abs/2505.22141"}
{"created":"2025-05-29","title":"3D Question Answering via only 2D Vision-Language Models","abstract":"Large vision-language models (LVLMs) have significantly advanced numerous fields. In this work, we explore how to harness their potential to address 3D scene understanding tasks, using 3D question answering (3D-QA) as a representative example. Due to the limited training data in 3D, we do not train LVLMs but infer in a zero-shot manner. Specifically, we sample 2D views from a 3D point cloud and feed them into 2D models to answer a given question. When the 2D model is chosen, e.g., LLAVA-OV, the quality of sampled views matters the most. We propose cdViews, a novel approach to automatically selecting critical and diverse Views for 3D-QA. cdViews consists of two key components: viewSelector prioritizing critical views based on their potential to provide answer-specific information, and viewNMS enhancing diversity by removing redundant views based on spatial overlap. We evaluate cdViews on the widely-used ScanQA and SQA benchmarks, demonstrating that it achieves state-of-the-art performance in 3D-QA while relying solely on 2D models without fine-tuning. These findings support our belief that 2D LVLMs are currently the most effective alternative (of the resource-intensive 3D LVLMs) for addressing 3D tasks.","authors":["Fengyun Wang","Sicheng Yu","Jiawei Wu","Jinhui Tang","Hanwang Zhang","Qianru Sun"],"url":"https://arxiv.org/abs/2505.22143"}
{"created":"2025-05-29","title":"Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language","abstract":"Flexible tool selection reflects a complex cognitive ability that distinguishes humans from other species, yet computational models that capture this ability remain underdeveloped. We developed a framework using low-dimensional attribute representations to bridge visual tool perception and linguistic task understanding. We constructed a comprehensive dataset (ToolNet) containing 115 common tools labeled with 13 carefully designed attributes spanning physical, functional, and psychological properties, paired with natural language scenarios describing tool usage. Visual encoders (ResNet or ViT) extract attributes from tool images while fine-tuned language models (GPT-2, LLaMA, DeepSeek) derive required attributes from task descriptions. Our approach achieves 74% accuracy in tool selection tasks-significantly outperforming direct tool matching (20%) and smaller multimodal models (21%-58%), while approaching performance of much larger models like GPT-4o (73%) with substantially fewer parameters. Ablation studies revealed that manipulation-related attributes (graspability, hand-relatedness, elongation) consistently prove most critical across modalities. This work provides a parameter-efficient, interpretable solution that mimics human-like tool cognition, advancing both cognitive science understanding and practical applications in tool selection tasks.","authors":["Guangfu Hao","Haojie Wen","Liangxuna Guo","Yang Chen","Yanchao Bi","Shan Yu"],"url":"https://arxiv.org/abs/2505.22146"}
{"created":"2025-05-29","title":"Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions","abstract":"Decision making is a central problem in AI that can be formalized using a Markov Decision Process. A problem is that, with increasing numbers of (indistinguishable) objects, the state space grows exponentially. To compute policies, the state space has to be enumerated. Even more possibilities have to be enumerated if the size of the action space depends on the size of the state space, especially if we allow concurrent actions. To tackle the exponential blow-up in the action and state space, we present a first-order representation to store the spaces in polynomial instead of exponential size in the number of objects and introduce Foreplan, a relational forward planner, which uses this representation to efficiently compute policies for numerous indistinguishable objects and actions. Additionally, we introduce an even faster approximate version of Foreplan. Moreover, Foreplan identifies how many objects an agent should act on to achieve a certain task given restrictions. Further, we provide a theoretical analysis and an empirical evaluation of Foreplan, demonstrating a speedup of at least four orders of magnitude.","authors":["Florian Andreas Marwitz","Tanya Braun","Ralf M\\\"oller","Marcel Gehrke"],"url":"https://arxiv.org/abs/2505.22147"}
{"created":"2025-05-29","title":"What Makes a Good Reasoning Chain? Uncovering Structural Patterns in Long Chain-of-Thought Reasoning","abstract":"Recent advances in reasoning with large language models (LLMs) have popularized Long Chain-of-Thought (LCoT), a strategy that encourages deliberate and step-by-step reasoning before producing a final answer. While LCoTs have enabled expert-level performance in complex tasks, how the internal structures of their reasoning chains drive, or even predict, the correctness of final answers remains a critical yet underexplored question. In this work, we present LCoT2Tree, an automated framework that converts sequential LCoTs into hierarchical tree structures and thus enables deeper structural analysis of LLM reasoning. Using graph neural networks (GNNs), we reveal that structural patterns extracted by LCoT2Tree, including exploration, backtracking, and verification, serve as stronger predictors of final performance across a wide range of tasks and models. Leveraging an explainability technique, we further identify critical thought patterns such as over-branching that account for failures. Beyond diagnostic insights, the structural patterns by LCoT2Tree support practical applications, including improving Best-of-N decoding effectiveness. Overall, our results underscore the critical role of internal structures of reasoning chains, positioning LCoT2Tree as a powerful tool for diagnosing, interpreting, and improving reasoning in LLMs.","authors":["Gangwei Jiang","Yahui Liu","Zhaoyi Li","Qi Wang","Fuzheng Zhang","Linqi Song","Ying Wei","Defu Lian"],"url":"https://arxiv.org/abs/2505.22148"}
{"created":"2025-05-29","title":"Real-World Modeling of Computation Offloading for Neural Networks with Early Exits and Splits","abstract":"We focus on computation offloading of applications based on convolutional neural network (CNN) from moving devices, such as mobile robots or autonomous vehicles, to MultiAccess Edge Computing (MEC) servers via a mobile network. In order to reduce overall CNN inference time, we design and implement CNN with early exits and splits, allowing a flexible partial or full offloading of CNN inference. Through real-world experiments, we analyze an impact of the CNN inference offloading on the total CNN processing delay, energy consumption, and classification accuracy in a practical road sign recognition task. The results confirm that offloading of CNN with early exits and splits can significantly reduce both total processing delay and energy consumption compared to full local processing while not impairing classification accuracy. Based on the results of real-world experiments, we derive practical models for energy consumption and total processing delay related to offloading of CNN with early exits and splits.","authors":["Jan Danek","Zdenek Becvar","Adam Janes"],"url":"https://arxiv.org/abs/2505.22149"}
{"created":"2025-05-29","title":"Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging","abstract":"Brain-to-Image reconstruction aims to recover visual stimuli perceived by humans from brain activity. However, the reconstructed visual stimuli often missing details and semantic inconsistencies, which may be attributed to insufficient semantic information. To address this issue, we propose an approach named Fine-grained Brain-to-Image reconstruction (FgB2I), which employs fine-grained text as bridge to improve image reconstruction. FgB2I comprises three key stages: detail enhancement, decoding fine-grained text descriptions, and text-bridged brain-to-image reconstruction. In the detail-enhancement stage, we leverage large vision-language models to generate fine-grained captions for visual stimuli and experimentally validate its importance. We propose three reward metrics (object accuracy, text-image semantic similarity, and image-image semantic similarity) to guide the language model in decoding fine-grained text descriptions from fMRI signals. The fine-grained text descriptions can be integrated into existing reconstruction methods to achieve fine-grained Brain-to-Image reconstruction.","authors":["Runze Xia","Shuo Feng","Renzhi Wang","Congchi Yin","Xuyun Wen","Piji Li"],"url":"https://arxiv.org/abs/2505.22150"}
{"created":"2025-05-29","title":"Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in Offline MARL","abstract":"A key challenge in offline multi-agent reinforcement learning (MARL) is achieving effective many-agent multi-step coordination in complex environments. In this work, we propose Oryx, a novel algorithm for offline cooperative MARL to directly address this challenge. Oryx adapts the recently proposed retention-based architecture Sable and combines it with a sequential form of implicit constraint Q-learning (ICQ), to develop a novel offline auto-regressive policy update scheme. This allows Oryx to solve complex coordination challenges while maintaining temporal coherence over lengthy trajectories. We evaluate Oryx across a diverse set of benchmarks from prior works (SMAC, RWARE, and Multi-Agent MuJoCo) covering tasks of both discrete and continuous control, varying in scale and difficulty. Oryx achieves state-of-the-art performance on more than 80% of the 65 tested datasets, outperforming prior offline MARL methods and demonstrating robust generalisation across domains with many agents and long horizons. Finally, we introduce new datasets to push the limits of many-agent coordination in offline MARL, and demonstrate Oryx's superior ability to scale effectively in such settings. We will make all of our datasets, experimental data, and code available upon publication.","authors":["Claude Formanek","Omayma Mahjoub","Louay Ben Nessir","Sasha Abramowitz","Ruan de Kock","Wiem Khlifi","Simon Du Toit","Felix Chalumeau","Daniel Rajaonarivonivelomanantsoa","Arnol Fokam","Siddarth Singh","Ulrich Mbou Sob","Arnu Pretorius"],"url":"https://arxiv.org/abs/2505.22151"}
{"created":"2025-05-29","title":"Uncertainty Estimation for Heterophilic Graphs Through the Lens of Information Theory","abstract":"While uncertainty estimation for graphs recently gained traction, most methods rely on homophily and deteriorate in heterophilic settings. We address this by analyzing message passing neural networks from an information-theoretic perspective and developing a suitable analog to data processing inequality to quantify information throughout the model's layers. In contrast to non-graph domains, information about the node-level prediction target can increase with model depth if a node's features are semantically different from its neighbors. Therefore, on heterophilic graphs, the latent embeddings of an MPNN each provide different information about the data distribution - different from homophilic settings. This reveals that considering all node representations simultaneously is a key design principle for epistemic uncertainty estimation on graphs beyond homophily. We empirically confirm this with a simple post-hoc density estimator on the joint node embedding space that provides state-of-the-art uncertainty on heterophilic graphs. At the same time, it matches prior work on homophilic graphs without explicitly exploiting homophily through post-processing.","authors":["Dominik Fuchsgruber","Tom Wollschl\\\"ager","Johannes Bordne","Stephan G\\\"unnemann"],"url":"https://arxiv.org/abs/2505.22152"}
{"created":"2025-05-29","title":"Personalized Tree based progressive regression model for watch-time prediction in short video recommendation","abstract":"In online video platforms, accurate watch time prediction has become a fundamental and challenging problem in video recommendation. Previous research has revealed that the accuracy of watch time prediction highly depends on both the transformation of watch-time labels and the decomposition of the estimation process. TPM (Tree based Progressive Regression Model) achieves State-of-the-Art performance with a carefully designed and effective decomposition paradigm. TPM discretizes the watch time into several ordinal intervals and organizes them into a binary decision tree, where each node corresponds to a specific interval. At each non-leaf node, a binary classifier is used to determine the specific interval in which the watch time variable most likely falls, based on the prediction outcome at its parent node.","authors":["Xiaokai Chen","Xiao Lin","Changcheng Li","Peng Jiang"],"url":"https://arxiv.org/abs/2505.22153"}
{"created":"2025-05-29","title":"Learning A Robust RGB-Thermal Detector for Extreme Modality Imbalance","abstract":"RGB-Thermal (RGB-T) object detection utilizes thermal infrared (TIR) images to complement RGB data, improving robustness in challenging conditions. Traditional RGB-T detectors assume balanced training data, where both modalities contribute equally. However, in real-world scenarios, modality degradation-due to environmental factors or technical issues-can lead to extreme modality imbalance, causing out-of-distribution (OOD) issues during testing and disrupting model convergence during training. This paper addresses these challenges by proposing a novel base-and-auxiliary detector architecture. We introduce a modality interaction module to adaptively weigh modalities based on their quality and handle imbalanced samples effectively. Additionally, we leverage modality pseudo-degradation to simulate real-world imbalances in training data. The base detector, trained on high-quality pairs, provides a consistency constraint for the auxiliary detector, which receives degraded samples. This framework enhances model robustness, ensuring reliable performance even under severe modality degradation. Experimental results demonstrate the effectiveness of our method in handling extreme modality imbalances~(decreasing the Missing Rate by 55%) and improving performance across various baseline detectors.","authors":["Chao Tian","Chao Yang","Guoqing Zhu","Qiang Wang","Zhenyu He"],"url":"https://arxiv.org/abs/2505.22154"}
{"created":"2025-05-29","title":"An instance of FreeCHR with refined operational semantics","abstract":"Constraint Handling Rules (CHR) is a rule-based programming language which is typically embedded into a general-purpose language. There exists a plethora of implementations of CHR for numerous host languages. However, the existing implementations often reinvent the way to embed CHR, which impedes maintenance and weakens assertions of correctness. To formalize and thereby unify the embedding of CHR into arbitrary host languages, we introduced the framework FreeCHR and proved it to be a valid representation of classical CHR. Until now, this framework only includes a translation of the very abstract operational semantics of CHR which, due to its abstract nature, introduces several practical issues. In this paper, we introduce an execution algorithm for FreeCHR. We derive it from the refined operational semantics of CHR, which resolve the issues introduced by the very abstract semantics. We also prove soundness of the algorithm with respect to the very abstract semantics of FreeCHR. Hereby we provide a unified and an easy to implement guideline for new CHR implementations, as well as an algorithmic definition of the refined operational semantics.","authors":["Sascha Rechenberger","Thom Fr\\\"uhwirth"],"url":"https://arxiv.org/abs/2505.22155"}
{"created":"2025-05-29","title":"InComeS: Integrating Compression and Selection Mechanisms into LLMs for Efficient Model Editing","abstract":"Although existing model editing methods perform well in recalling exact edit facts, they often struggle in complex scenarios that require deeper semantic understanding rather than mere knowledge regurgitation. Leveraging the strong contextual reasoning abilities of large language models (LLMs), in-context learning (ICL) becomes a promising editing method by comprehending edit information through context encoding. However, this method is constrained by the limited context window of LLMs, leading to degraded performance and efficiency as the number of edits increases. To overcome this limitation, we propose InComeS, a flexible framework that enhances LLMs' ability to process editing contexts through explicit compression and selection mechanisms. Specifically, InComeS compresses each editing context into the key-value (KV) cache of a special gist token, enabling efficient handling of multiple edits without being restricted by the model's context window. Furthermore, specialized cross-attention modules are added to dynamically select the most relevant information from the gist pools, enabling adaptive and effective utilization of edit information. We conduct experiments on diverse model editing benchmarks with various editing formats, and the results demonstrate the effectiveness and efficiency of our method.","authors":["Shuaiyi Li","Zhisong Zhang","Yang Deng","Chenlong Deng","Tianqing Fang","Hongming Zhang","Haitao Mi","Dong Yu","Wai Lam"],"url":"https://arxiv.org/abs/2505.22156"}
{"created":"2025-05-29","title":"Stratified Selective Sampling for Instruction Tuning with Dedicated Scoring Strategy","abstract":"Recent work shows that post-training datasets for LLMs can be substantially downsampled without noticeably deteriorating performance. However, data selection often incurs high computational costs or is limited to narrow domains. In this paper, we demonstrate that data selection can be both -- efficient and universal -- by using a multi-step pipeline in which we efficiently bin data points into groups, estimate quality using specialized models, and score difficulty with a robust, lightweight method. Task-based categorization allows us to control the composition of our final data -- crucial for finetuning multi-purpose models. To guarantee diversity, we improve upon previous work using embedding models and a clustering algorithm. This integrated strategy enables high-performance fine-tuning with minimal overhead.","authors":["Paramita Mirza","Lucas Weber","Fabian K\\\"uch"],"url":"https://arxiv.org/abs/2505.22157"}
{"created":"2025-05-29","title":"The informativeness of the gradient revisited","abstract":"In the past decade gradient-based deep learning has revolutionized several applications. However, this rapid advancement has highlighted the need for a deeper theoretical understanding of its limitations. Research has shown that, in many practical learning tasks, the information contained in the gradient is so minimal that gradient-based methods require an exceedingly large number of iterations to achieve success. The informativeness of the gradient is typically measured by its variance with respect to the random selection of a target function from a hypothesis class.","authors":["Rustem Takhanov"],"url":"https://arxiv.org/abs/2505.22158"}
{"created":"2025-05-29","title":"ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation","abstract":"Vision-Language-Action (VLA) models have advanced general-purpose robotic manipulation by leveraging pretrained visual and linguistic representations. However, they struggle with contact-rich tasks that require fine-grained control involving force, especially under visual occlusion or dynamic uncertainty. To address these limitations, we propose \\textbf{ForceVLA}, a novel end-to-end manipulation framework that treats external force sensing as a first-class modality within VLA systems. ForceVLA introduces \\textbf{FVLMoE}, a force-aware Mixture-of-Experts fusion module that dynamically integrates pretrained visual-language embeddings with real-time 6-axis force feedback during action decoding. This enables context-aware routing across modality-specific experts, enhancing the robot's ability to adapt to subtle contact dynamics. We also introduce \\textbf{ForceVLA-Data}, a new dataset comprising synchronized vision, proprioception, and force-torque signals across five contact-rich manipulation tasks. ForceVLA improves average task success by 23.2\\% over strong $\\pi_0$-based baselines, achieving up to 80\\% success in tasks such as plug insertion. Our approach highlights the importance of multimodal integration for dexterous manipulation and sets a new benchmark for physically intelligent robotic control. Code and data will be released at https://sites.google.com/view/forcevla2025.","authors":["Jiawen Yu","Hairuo Liu","Qiaojun Yu","Jieji Ren","Ce Hao","Haitong Ding","Guangyu Huang","Guofan Huang","Yan Song","Panpan Cai","Cewu Lu","Wenqiang Zhang"],"url":"https://arxiv.org/abs/2505.22159"}
{"created":"2025-05-29","title":"Accountable, Scalable and DoS-resilient Secure Vehicular Communication","abstract":"Paramount to vehicle safety, broadcasted Cooperative Awareness Messages (CAMs) and Decentralized Environmental Notification Messages (DENMs) are pseudonymously authenticated for security and privacy protection, with each node needing to have all incoming messages validated within an expiration deadline. This creates an asymmetry that can be easily exploited by external adversaries to launch a clogging Denial of Service (DoS) attack: each forged VC message forces all neighboring nodes to cryptographically validate it; at increasing rates, easy to generate forged messages gradually exhaust processing resources and severely degrade or deny timely validation of benign CAMs/DENMs. The result can be catastrophic when awareness of neighbor vehicle positions or critical reports are missed. We address this problem making the standardized VC pseudonymous authentication DoS-resilient. We propose efficient cryptographic constructs, which we term message verification facilitators, to prioritize processing resources for verification of potentially valid messages among bogus messages and verify multiple messages based on one signature verification. Any message acceptance is strictly based on public-key based message authentication/verification for accountability, i.e., non-repudiation is not sacrificed, unlike symmetric key based approaches. This further enables drastic misbehavior detection, also exploiting the newly introduced facilitators, based on probabilistic signature verification and cross-checking over multiple facilitators verifying the same message; while maintaining verification latency low even when under attack, trading off modest communication overhead. Our facilitators can also be used for efficient discovery and verification of DENM or any event-driven message, including misbehavior evidence used for our scheme.","authors":["Hongyu Jin","Panos Papadimitratos"],"url":"https://arxiv.org/abs/2505.22162"}
{"created":"2025-05-29","title":"Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes","abstract":"Diffusion models have emerged as a promising approach for text generation, with recent works falling into two main categories: discrete and continuous diffusion models. Discrete diffusion models apply token corruption independently using categorical distributions, allowing for different diffusion progress across tokens but lacking fine-grained control. Continuous diffusion models map tokens to continuous spaces and apply fine-grained noise, but the diffusion progress is uniform across tokens, limiting their ability to capture semantic nuances. To address these limitations, we propose \\textbf{\\underline{N}}on-simultan\\textbf{\\underline{e}}ous C\\textbf{\\underline{o}}ntinuous \\textbf{\\underline{Diff}}usion Models (NeoDiff), a novel diffusion model that integrates the strengths of both discrete and continuous approaches. NeoDiff introduces a Poisson diffusion process for the forward process, enabling a flexible and fine-grained noising paradigm, and employs a time predictor for the reverse process to adaptively modulate the denoising progress based on token semantics. Furthermore, NeoDiff utilizes an optimized schedule for inference to ensure more precise noise control and improved performance. Our approach unifies the theories of discrete and continuous diffusion models, offering a more principled and effective framework for text generation. Experimental results on several text generation tasks demonstrate NeoDiff's superior performance compared to baselines of non-autoregressive continuous and discrete diffusion models, iterative-based methods and autoregressive diffusion-based methods. These results highlight NeoDiff's potential as a powerful tool for generating high-quality text and advancing the field of diffusion-based text generation.","authors":["Bocheng Li","Zhujin Gao","Linli Xu"],"url":"https://arxiv.org/abs/2505.22165"}
{"created":"2025-05-29","title":"Q-VDiT: Towards Accurate Quantization and Distillation of Video-Generation Diffusion Transformers","abstract":"Diffusion transformers (DiT) have demonstrated exceptional performance in video generation. However, their large number of parameters and high computational complexity limit their deployment on edge devices. Quantization can reduce storage requirements and accelerate inference by lowering the bit-width of model parameters. Yet, existing quantization methods for image generation models do not generalize well to video generation tasks. We identify two primary challenges: the loss of information during quantization and the misalignment between optimization objectives and the unique requirements of video generation. To address these challenges, we present Q-VDiT, a quantization framework specifically designed for video DiT models. From the quantization perspective, we propose the Token-aware Quantization Estimator (TQE), which compensates for quantization errors in both the token and feature dimensions. From the optimization perspective, we introduce Temporal Maintenance Distillation (TMD), which preserves the spatiotemporal correlations between frames and enables the optimization of each frame with respect to the overall video context. Our W3A6 Q-VDiT achieves a scene consistency of 23.40, setting a new benchmark and outperforming current state-of-the-art quantization methods by 1.9$\\times$. Code will be available at https://github.com/cantbebetter2/Q-VDiT.","authors":["Weilun Feng","Chuanguang Yang","Haotong Qin","Xiangqi Li","Yu Wang","Zhulin An","Libo Huang","Boyu Diao","Zixiang Zhao","Yongjun Xu","Michele Magno"],"url":"https://arxiv.org/abs/2505.22167"}
{"created":"2025-05-29","title":"ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments","abstract":"LLMs are highly sensitive to prompt phrasing, yet standard benchmarks typically report performance using a single prompt, raising concerns about the reliability of such evaluations. In this work, we argue for a stochastic method of moments evaluation over the space of meaning-preserving prompt perturbations. We introduce a formal definition of reliable evaluation that accounts for prompt sensitivity, and suggest ReliableEval - a method for estimating the number of prompt resamplings needed to obtain meaningful results. Using our framework, we stochastically evaluate five frontier LLMs and find that even top-performing models like GPT-4o and Claude-3.7-Sonnet exhibit substantial prompt sensitivity. Our approach is model-, task-, and metric-agnostic, offering a recipe for meaningful and robust LLM evaluation.","authors":["Gili Lior","Eliya Habba","Shahar Levy","Avi Caciularu","Gabriel Stanovsky"],"url":"https://arxiv.org/abs/2505.22169"}
{"created":"2025-05-29","title":"Reverse Preference Optimization for Complex Instruction Following","abstract":"Instruction following (IF) is a critical capability for large language models (LLMs). However, handling complex instructions with multiple constraints remains challenging. Previous methods typically select preference pairs based on the number of constraints they satisfy, introducing noise where chosen examples may fail to follow some constraints and rejected examples may excel in certain respects over the chosen ones. To address the challenge of aligning with multiple preferences, we propose a simple yet effective method called Reverse Preference Optimization (RPO). It mitigates noise in preference pairs by dynamically reversing the constraints within the instruction to ensure the chosen response is perfect, alleviating the burden of extensive sampling and filtering to collect perfect responses. Besides, reversal also enlarges the gap between chosen and rejected responses, thereby clarifying the optimization direction and making it more robust to noise. We evaluate RPO on two multi-turn IF benchmarks, Sysbench and Multi-IF, demonstrating average improvements over the DPO baseline of 4.6 and 2.5 points (on Llama-3.1 8B), respectively. Moreover, RPO scales effectively across model sizes (8B to 70B parameters), with the 70B RPO model surpassing GPT-4o.","authors":["Xiang Huang","Ting-En Lin","Feiteng Fang","Yuchuan Wu","Hangyu Li","Yuzhong Qu","Fei Huang","Yongbin Li"],"url":"https://arxiv.org/abs/2505.22172"}
{"created":"2025-05-29","title":"Online Fair Division for Personalized $2$-Value Instances","abstract":"We study an online fair division setting, where goods arrive one at a time and there is a fixed set of $n$ agents, each of whom has an additive valuation function over the goods. Once a good appears, the value each agent has for it is revealed and it must be allocated immediately and irrevocably to one of the agents. It is known that without any assumptions about the values being severely restricted or coming from a distribution, very strong impossibility results hold in this setting. To bypass the latter, we turn our attention to instances where the valuation functions are restricted. In particular, we study personalized $2$-value instances, where there are only two possible values each agent may have for each good, possibly different across agents, and we show how to obtain worst case guarantees with respect to well-known fairness notions, such as maximin share fairness and envy-freeness up to one (or two) good(s). We suggest a deterministic algorithm that maintains a $1/(2n-1)$-MMS allocation at every time step and show that this is the best possible any deterministic algorithm can achieve if one cares about every single time step; nevertheless, eventually the allocation constructed by our algorithm becomes a $1/4$-MMS allocation. To achieve this, the algorithm implicitly maintains a fragile system of priority levels for all agents. Further, we show that, by allowing some limited access to future information, it is possible to have stronger results with less involved approaches. By knowing the values of goods for $n-1$ time steps into the future, we design a matching-based algorithm that achieves an EF$1$ allocation every $n$ time steps, while always maintaining an EF$2$ allocation. Finally, we show that our results allow us to get the first nontrivial guarantees for additive instances in which the ratio of the maximum over the minimum value an agent has for a good is bounded.","authors":["Georgios Amanatidis","Alexandros Lolos","Evangelos Markakis","Victor Turmel"],"url":"https://arxiv.org/abs/2505.22174"}
{"created":"2025-05-29","title":"TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation","abstract":"Evaluating tables qualitatively & quantitatively presents a significant challenge, as traditional metrics often fail to capture nuanced structural and content discrepancies. To address this, we introduce a novel, methodical rubric integrating multi-level structural descriptors with fine-grained contextual quantification, thereby establishing a robust foundation for comprehensive table comparison. Building on this foundation, we propose TabXEval, an eXhaustive and eXplainable two-phase evaluation framework. TabXEval initially aligns reference tables structurally via TabAlign & subsequently conducts a systematic semantic and syntactic comparison using TabCompare; this approach clarifies the evaluation process and pinpoints subtle discrepancies overlooked by conventional methods. The efficacy of this framework is assessed using TabXBench, a novel, diverse, multi-domain benchmark we developed, featuring realistic table perturbations and human-annotated assessments. Finally, a systematic analysis of existing evaluation methods through sensitivity-specificity trade-offs demonstrates the qualitative and quantitative effectiveness of TabXEval across diverse table-related tasks and domains, paving the way for future innovations in explainable table evaluation.","authors":["Vihang Pancholi","Jainit Bafna","Tejas Anvekar","Manish Shrivastava","Vivek Gupta"],"url":"https://arxiv.org/abs/2505.22176"}
{"created":"2025-05-29","title":"Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design","abstract":"Speculative decoding and quantization effectively accelerate memory-bound inference of large language models. Speculative decoding mitigates the memory bandwidth bottleneck by verifying multiple tokens within a single forward pass, which increases computational effort. Quantization achieves this optimization by compressing weights and activations into lower bit-widths and also reduces computations via low-bit matrix multiplications. To further leverage their strengths, we investigate the integration of these two techniques. Surprisingly, experiments applying the advanced speculative decoding method EAGLE-2 to various quantized models reveal that the memory benefits from 4-bit weight quantization are diminished by the computational load from speculative decoding. Specifically, verifying a tree-style draft incurs significantly more time overhead than a single-token forward pass on 4-bit weight quantized models. This finding led to our new speculative decoding design: a hierarchical framework that employs a small model as an intermediate stage to turn tree-style drafts into sequence drafts, leveraging the memory access benefits of the target quantized model. Experimental results show that our hierarchical approach achieves a 2.78$\\times$ speedup across various tasks for the 4-bit weight Llama-3-70B model on an A100 GPU, outperforming EAGLE-2 by 1.31$\\times$. Code available at https://github.com/AI9Stars/SpecMQuant.","authors":["Yudi Zhang","Weilin Zhao","Xu Han","Tiejun Zhao","Wang Xu","Hailong Cao","Conghui Zhu"],"url":"https://arxiv.org/abs/2505.22179"}
{"created":"2025-05-29","title":"Term Ordering Diagrams","abstract":"The superposition calculus for reasoning in first-order logic with equality relies on simplification orderings on terms. Modern saturation provers use the Knuth-Bendix order (KBO) and the lexicographic path order (LPO) for discovering redundant clauses and inferences. Implementing term orderings is however challenging. While KBO comparisons can be performed in linear time and LPO checks in quadratic time, using the best known algorithms for these orders is not enough. Indeed, our experiments show that for some examples term ordering checks may use about 98% of the overall proving time. The reason for this is that some equalities that cannot be ordered can become ordered after applying a substitution (post-ordered), and we have to check for post-ordering repeatedly for the same equalities. In this paper, we show how to improve post-ordering checks by introducing a new data structure called term ordering diagrams, in short TODs, which creates an index for these checks. We achieve efficiency by lazy modifications of the index and by storing and reusing information from previously performed checks to speed up subsequent checks. Our experiments demonstrate efficiency of TODs.","authors":["M\\'arton Hajdu","Robin Coutelier","Laura Kov\\'acs","Andrei Voronkov"],"url":"https://arxiv.org/abs/2505.22181"}
{"created":"2025-05-29","title":"Breaking the Cloak! Unveiling Chinese Cloaked Toxicity with Homophone Graph and Toxic Lexicon","abstract":"Social media platforms have experienced a significant rise in toxic content, including abusive language and discriminatory remarks, presenting growing challenges for content moderation. Some users evade censorship by deliberately disguising toxic words through homophonic cloak, which necessitates the task of unveiling cloaked toxicity. Existing methods are mostly designed for English texts, while Chinese cloaked toxicity unveiling has not been solved yet. To tackle the issue, we propose C$^2$TU, a novel training-free and prompt-free method for Chinese cloaked toxic content unveiling. It first employs substring matching to identify candidate toxic words based on Chinese homo-graph and toxic lexicon. Then it filters those candidates that are non-toxic and corrects cloaks to be their corresponding toxicities. Specifically, we develop two model variants for filtering, which are based on BERT and LLMs, respectively. For LLMs, we address the auto-regressive limitation in computing word occurrence probability and utilize the full semantic contexts of a text sequence to reveal cloaked toxic words. Extensive experiments demonstrate that C$^2$TU can achieve superior performance on two Chinese toxic datasets. In particular, our method outperforms the best competitor by up to 71% on the F1 score and 35% on accuracy, respectively.","authors":["Xuchen Ma","Jianxiang Yu","Wenming Shao","Bo Pang","Xiang Li"],"url":"https://arxiv.org/abs/2505.22184"}
{"created":"2025-05-29","title":"Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on Introspection","abstract":"Multi-agent systems based on large language models (LLMs) advance automatic task completion in various fields, where debate is a common cooperation form for agents to solve complicated problems with reasoning and cross-review to solidify answers. Assessing the individual contributions of agents within these debates is crucial for system refinement and outcome reliability. Traditional leave-one-out (LOO) method offers a clear framework for evaluating each agent's role but face challenges in LLM-based systems due to high computational costs and associated financial implications. This paper presents introspective-leave-one-out (IntrospecLOO), a simple yet effective prompting for approximation of LOO in LLM-powered multi-agent debates. IntrospecLOO introduces an additional querying round after standard debates, prompting agents to update their answers while ignoring responses from a designated agent. This strategy effectively isolates and gauges each participant's influence at a reduced query complexity compared to the original LOO approaches. Validation through experiments on three benchmark datasets confirms the effectiveness of IntrospecLOO.","authors":["Yue Cui","Liuyi Yao","Zitao Li","Yaliang Li","Bolin Ding","Xiaofang Zhou"],"url":"https://arxiv.org/abs/2505.22192"}
{"created":"2025-05-29","title":"Refining Datapath for Microscaling ViTs","abstract":"Vision Transformers (ViTs) leverage the transformer architecture to effectively capture global context, demonstrating strong performance in computer vision tasks. A major challenge in ViT hardware acceleration is that the model family contains complex arithmetic operations that are sensitive to model accuracy, such as the Softmax and LayerNorm operations, which cannot be mapped onto efficient hardware with low precision. Existing methods only exploit parallelism in the matrix multiplication operations of the model on hardware and keep these complex operations on the CPU. This results in suboptimal performance due to the communication overhead between the CPU and accelerator. Can new data formats solve this problem?","authors":["Can Xiao","Jianyi Cheng","Aaron Zhao"],"url":"https://arxiv.org/abs/2505.22194"}
{"created":"2025-05-29","title":"S2AFormer: Strip Self-Attention for Efficient Vision Transformer","abstract":"Vision Transformer (ViT) has made significant advancements in computer vision, thanks to its token mixer's sophisticated ability to capture global dependencies between all tokens. However, the quadratic growth in computational demands as the number of tokens increases limits its practical efficiency. Although recent methods have combined the strengths of convolutions and self-attention to achieve better trade-offs, the expensive pairwise token affinity and complex matrix operations inherent in self-attention remain a bottleneck. To address this challenge, we propose S2AFormer, an efficient Vision Transformer architecture featuring novel Strip Self-Attention (SSA). We design simple yet effective Hybrid Perception Blocks (HPBs) to effectively integrate the local perception capabilities of CNNs with the global context modeling of Transformer's attention mechanisms. A key innovation of SSA lies in its reducing the spatial dimensions of $K$ and $V$ while compressing the channel dimensions of $Q$ and $K$. This design significantly reduces computational overhead while preserving accuracy, striking an optimal balance between efficiency and effectiveness. We evaluate the robustness and efficiency of S2AFormer through extensive experiments on multiple vision benchmarks, including ImageNet-1k for image classification, ADE20k for semantic segmentation, and COCO for object detection and instance segmentation. Results demonstrate that S2AFormer achieves significant accuracy gains with superior efficiency in both GPU and non-GPU environments, making it a strong candidate for efficient vision Transformers.","authors":["Guoan Xu","Wenfeng Huang","Wenjing Jia","Jiamao Li","Guangwei Gao","Guo-Jun Qi"],"url":"https://arxiv.org/abs/2505.22195"}
{"created":"2025-05-29","title":"An Augmentation-Aware Theory for Self-Supervised Contrastive Learning","abstract":"Self-supervised contrastive learning has emerged as a powerful tool in machine learning and computer vision to learn meaningful representations from unlabeled data. Meanwhile, its empirical success has encouraged many theoretical studies to reveal the learning mechanisms. However, in the existing theoretical research, the role of data augmentation is still under-exploited, especially the effects of specific augmentation types. To fill in the blank, we for the first time propose an augmentation-aware error bound for self-supervised contrastive learning, showing that the supervised risk is bounded not only by the unsupervised risk, but also explicitly by a trade-off induced by data augmentation. Then, under a novel semantic label assumption, we discuss how certain augmentation methods affect the error bound. Lastly, we conduct both pixel- and representation-level experiments to verify our proposed theoretical results.","authors":["Jingyi Cui","Hongwei Wen","Yisen Wang"],"url":"https://arxiv.org/abs/2505.22196"}
{"created":"2025-05-29","title":"Enhancing Uncertainty Estimation and Interpretability via Bayesian Non-negative Decision Layer","abstract":"Although deep neural networks have demonstrated significant success due to their powerful expressiveness, most models struggle to meet practical requirements for uncertainty estimation. Concurrently, the entangled nature of deep neural networks leads to a multifaceted problem, where various localized explanation techniques reveal that multiple unrelated features influence the decisions, thereby undermining interpretability. To address these challenges, we develop a Bayesian Non-negative Decision Layer (BNDL), which reformulates deep neural networks as a conditional Bayesian non-negative factor analysis. By leveraging stochastic latent variables, the BNDL can model complex dependencies and provide robust uncertainty estimation. Moreover, the sparsity and non-negativity of the latent variables encourage the model to learn disentangled representations and decision layers, thereby improving interpretability. We also offer theoretical guarantees that BNDL can achieve effective disentangled learning. In addition, we developed a corresponding variational inference method utilizing a Weibull variational inference network to approximate the posterior distribution of the latent variables. Our experimental results demonstrate that with enhanced disentanglement capabilities, BNDL not only improves the model's accuracy but also provides reliable uncertainty estimation and improved interpretability.","authors":["Xinyue Hu","Zhibin Duan","Bo Chen","Mingyuan Zhou"],"url":"https://arxiv.org/abs/2505.22199"}
{"created":"2025-05-29","title":"Investigating Mechanisms for In-Context Vision Language Binding","abstract":"To understand a prompt, Vision-Language models (VLMs) must perceive the image, comprehend the text, and build associations within and across both modalities. For instance, given an 'image of a red toy car', the model should associate this image to phrases like 'car', 'red toy', 'red object', etc. Feng and Steinhardt propose the Binding ID mechanism in LLMs, suggesting that the entity and its corresponding attribute tokens share a Binding ID in the model activations. We investigate this for image-text binding in VLMs using a synthetic dataset and task that requires models to associate 3D objects in an image with their descriptions in the text. Our experiments demonstrate that VLMs assign a distinct Binding ID to an object's image tokens and its textual references, enabling in-context association.","authors":["Darshana Saravanan","Makarand Tapaswi","Vineet Gandhi"],"url":"https://arxiv.org/abs/2505.22200"}
{"created":"2025-05-29","title":"Let's Predict Sentence by Sentence","abstract":"Autoregressive language models (LMs) generate one token at a time, yet human reasoning operates over higher-level abstractions - sentences, propositions, and concepts. This contrast raises a central question- Can LMs likewise learn to reason over structured semantic units rather than raw token sequences? In this work, we investigate whether pretrained LMs can be lifted into such abstract reasoning spaces by building on their learned representations. We present a framework that adapts a pretrained token-level LM to operate in sentence space by autoregressively predicting continuous embeddings of next sentences. We explore two embedding paradigms inspired by classical representation learning: 1) semantic embeddings, learned via autoencoding to preserve surface meaning; and 2) contextual embeddings, trained via next-sentence prediction to encode anticipatory structure. We evaluate both under two inference regimes: Discretized, which decodes each predicted embedding into text before re-encoding; and Continuous, which reasons entirely in embedding space for improved efficiency. Across four domains - mathematics, logic, commonsense, and planning - contextual embeddings under continuous inference show competitive performance with Chain-of-Thought (CoT) while reducing inference-time FLOPs on average by half. We also present early signs of scalability and modular adaptation. Finally, to visualize latent trajectories, we introduce SentenceLens, a diagnostic tool that decodes intermediate model states into interpretable sentences. Together, our results indicate that pretrained LMs can effectively transition to abstract, structured reasoning within latent embedding spaces.","authors":["Hyeonbin Hwang","Byeongguk Jeon","Seungone Kim","Jiyeon Kim","Hoyeon Chang","Sohee Yang","Seungpil Won","Dohaeng Lee","Youbin Ahn","Minjoon Seo"],"url":"https://arxiv.org/abs/2505.22202"}
{"created":"2025-05-29","title":"Pitfalls of Rule- and Model-based Verifiers -- A Case Study on Mathematical Reasoning","abstract":"Trustworthy verifiers are essential for the success of reinforcement learning with verifiable reward (RLVR), which is the core methodology behind various large reasoning models such as DeepSeek-R1. In complex domains like mathematical reasoning, rule-based verifiers have been widely adopted in previous works to train strong reasoning models. However, the reliability of these verifiers and their impact on the RL training process remain poorly understood. In this work, we take mathematical reasoning as a case study and conduct a comprehensive analysis of various verifiers in both static evaluation and RL training scenarios. First, we find that current open-source rule-based verifiers often fail to recognize equivalent answers presented in different formats across multiple commonly used mathematical datasets, resulting in non-negligible false negative rates. This limitation adversely affects RL training performance and becomes more pronounced as the policy model gets stronger. Subsequently, we investigate model-based verifiers as a potential solution to address these limitations. While the static evaluation shows that model-based verifiers achieve significantly higher verification accuracy, further analysis and RL training results imply that they are highly susceptible to hacking, where they misclassify certain patterns in responses as correct (i.e., false positives). This vulnerability is exploited during policy model optimization, leading to artificially inflated rewards. Our findings underscore the unique risks inherent to both rule-based and model-based verifiers, aiming to offer valuable insights to develop more robust reward systems in reinforcement learning.","authors":["Yuzhen Huang","Weihao Zeng","Xingshan Zeng","Qi Zhu","Junxian He"],"url":"https://arxiv.org/abs/2505.22203"}
{"created":"2025-05-29","title":"LaMM: Semi-Supervised Pre-Training of Large-Scale Materials Models","abstract":"Neural network potentials (NNPs) are crucial for accelerating computational materials science by surrogating density functional theory (DFT) calculations. Improving their accuracy is possible through pre-training and fine-tuning, where an NNP model is first pre-trained on a large-scale dataset and then fine-tuned on a smaller target dataset. However, this approach is computationally expensive, mainly due to the cost of DFT-based dataset labeling and load imbalances during large-scale pre-training. To address this, we propose LaMM, a semi-supervised pre-training method incorporating improved denoising self-supervised learning and a load-balancing algorithm for efficient multi-node training. We demonstrate that our approach effectively leverages a large-scale dataset of $\\sim$300 million semi-labeled samples to train a single NNP model, resulting in improved fine-tuning performance in terms of both speed and accuracy.","authors":["Yosuke Oyama","Yusuke Majima","Eiji Ohta","Yasufumi Sakai"],"url":"https://arxiv.org/abs/2505.22208"}
{"created":"2025-05-29","title":"A Survey on Training-free Open-Vocabulary Semantic Segmentation","abstract":"Semantic segmentation is one of the most fundamental tasks in image understanding with a long history of research, and subsequently a myriad of different approaches. Traditional methods strive to train models up from scratch, requiring vast amounts of computational resources and training data. In the advent of moving to open-vocabulary semantic segmentation, which asks models to classify beyond learned categories, large quantities of finely annotated data would be prohibitively expensive. Researchers have instead turned to training-free methods where they leverage existing models made for tasks where data is more easily acquired. Specifically, this survey will cover the history, nuance, idea development and the state-of-the-art in training-free open-vocabulary semantic segmentation that leverages existing multi-modal classification models. We will first give a preliminary on the task definition followed by an overview of popular model archetypes and then spotlight over 30 approaches split into broader research branches: purely CLIP-based, those leveraging auxiliary visual foundation models and ones relying on generative methods. Subsequently, we will discuss the limitations and potential problems of current research, as well as provide some underexplored ideas for future study. We believe this survey will serve as a good onboarding read to new researchers and spark increased interest in the area.","authors":["Naomi Kombol","Ivan Martinovi\\'c","Sini\\v{s}a \\v{S}egvi\\'c"],"url":"https://arxiv.org/abs/2505.22209"}
{"created":"2025-05-29","title":"(Near)-Optimal Algorithms for Sparse Separable Convex Integer Programs","abstract":"We study the general integer programming (IP) problem of optimizing a separable convex function over the integer points of a polytope: $\\min \\{f(\\mathbf{x}) \\mid A\\mathbf{x} = \\mathbf{b}, \\, \\mathbf{l} \\leq \\mathbf{x} \\leq \\mathbf{u}, \\, \\mathbf{x} \\in \\mathbb{Z}^n\\}$. The number of variables $n$ is a variable part of the input, and we consider the regime where the constraint matrix $A$ has small coefficients $\\|A\\|_\\infty$ and small primal or dual treedepth $\\mathrm{td}_P(A)$ or $\\mathrm{td}_D(A)$, respectively. Equivalently, we consider block-structured matrices, in particular $n$-fold, tree-fold, $2$-stage and multi-stage matrices.","authors":["Christoph Hunkenschr\\\"oder","Martin Kouteck\\'y","Asaf Levin","Tung Anh Vu"],"url":"https://arxiv.org/abs/2505.22212"}
{"created":"2025-05-29","title":"Partial Redundancy in Saturation","abstract":"Redundancy elimination is one of the crucial ingredients of efficient saturation-based proof search. We improve redundancy elimination by introducing a new notion of redundancy, based on partial clauses and redundancy formulas, which is more powerful than the standard notion: there are both clauses and inferences that are redundant when we use our notions and not redundant when we use standard notions. In a way, our notion blurs the distinction between redundancy at the level of inferences and redundancy at the level of clauses. We present a superposition calculus PaRC on partial clauses. Our calculus is refutationally complete and is strong enough to capture some standard restrictions of the superposition calculus. We discuss the implementation of the calculus in the theorem prover Vampire. Our experiments show the power of the new approach: we were able to solve 24 TPTP problems not previously solved by any prover, including previous versions of Vampire.","authors":["M\\'arton Hajdu","Laura Kov\\'acs","Andrei Voronkov"],"url":"https://arxiv.org/abs/2505.22213"}
{"created":"2025-05-29","title":"Thermal Modeling and Optimal Allocation of Avionics Safety-critical Tasks on Heterogeneous MPSoCs","abstract":"Multi-Processor Systems-on-Chip (MPSoC) can deliver high performance needed in many industrial domains, including aerospace. However, their high power consumption, combined with avionics safety standards, brings new thermal management challenges. This paper investigates techniques for offline thermal-aware allocation of periodic tasks on heterogeneous MPSoCs running at a fixed clock frequency, as required in avionics. The goal is to find the assignment of tasks to (i) cores and (ii) temporal isolation windows while minimizing the MPSoC temperature. To achieve that, we propose and analyze three power models, and integrate them within several novel optimization approaches based on heuristics, a black-box optimizer, and Integer Linear Programming (ILP). We perform the experimental evaluation on three popular MPSoC platforms (NXP i.MX8QM MEK, NXP i.MX8QM Ixora, NVIDIA TX2) and observe a difference of up to 5.5{\\deg}C among the tested methods (corresponding to a 22% reduction w.r.t. the ambient temperature). We also show that our method, integrating the empirical power model with the ILP, outperforms the other methods on all tested platforms.","authors":["Ond\\v{r}ej Benedikt","Michal Sojka","P\\v{r}emysl \\v{S}\\r{u}cha","Pavel Zaykov","Zden\\v{e}k Hanz\\'alek"],"url":"https://arxiv.org/abs/2505.22214"}
{"created":"2025-05-29","title":"Domainator: Detecting and Identifying DNS-Tunneling Malware Using Metadata Sequences","abstract":"In recent years, malware with tunneling (or: covert channel) capabilities is on the rise. While malware research led to several methods and innovations, the detection and differentiation of malware solely based on its DNS tunneling features is still in its infancy. Moreover, no work so far has used the DNS tunneling traffic to gain knowledge over the current actions taken by the malware. In this paper, we present Domainator, an approach to detect and differentiate state-of-the-art malware and DNS tunneling tools without relying on trivial (but quickly altered) features such as \"magic bytes\" that are embedded into subdomains. Instead, we apply an analysis of sequential patterns to identify specific types of malware. We evaluate our approach with 7 different malware samples and tunneling tools and can identify the particular malware based on its DNS traffic. We further infer the rough behavior of the particular malware through its DNS tunneling artifacts. Finally, we compare our Domainator with related methods.","authors":["Denis Petrov","Pascal Ruffing","Sebastian Zillien","Steffen Wendzel"],"url":"https://arxiv.org/abs/2505.22220"}
{"created":"2025-05-29","title":"Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation","abstract":"Recent advancements in multimodal Large Language Models (LLMs) have significantly enhanced the automation of medical image analysis, particularly in generating radiology reports from chest X-rays (CXR). However, these models still suffer from hallucinations and clinically significant errors, limiting their reliability in real-world applications. In this study, we propose Look & Mark (L&amp;M), a novel grounding fixation strategy that integrates radiologist eye fixations (Look) and bounding box annotations (Mark) into the LLM prompting framework. Unlike conventional fine-tuning, L&amp;M leverages in-context learning to achieve substantial performance gains without retraining. When evaluated across multiple domain-specific and general-purpose models, L&amp;M demonstrates significant gains, including a 1.2% improvement in overall metrics (A.AVG) for CXR-LLaVA compared to baseline prompting and a remarkable 9.2% boost for LLaVA-Med. General-purpose models also benefit from L&amp;M combined with in-context learning, with LLaVA-OV achieving an 87.3% clinical average performance (C.AVG)-the highest among all models, even surpassing those explicitly trained for CXR report generation. Expert evaluations further confirm that L&amp;M reduces clinically significant errors (by 0.43 average errors per report), such as false predictions and omissions, enhancing both accuracy and reliability. These findings highlight L&amp;M's potential as a scalable and efficient solution for AI-assisted radiology, paving the way for improved diagnostic workflows in low-resource clinical settings.","authors":["Yunsoo Kim","Jinge Wu","Su-Hwan Kim","Pardeep Vasudev","Jiashu Shen","Honghan Wu"],"url":"https://arxiv.org/abs/2505.22222"}
{"created":"2025-05-29","title":"Solver-Free Decision-Focused Learning for Linear Optimization Problems","abstract":"Mathematical optimization is a fundamental tool for decision-making in a wide range of applications. However, in many real-world scenarios, the parameters of the optimization problem are not known a priori and must be predicted from contextual features. This gives rise to predict-then-optimize problems, where a machine learning model predicts problem parameters that are then used to make decisions via optimization. A growing body of work on decision-focused learning (DFL) addresses this setting by training models specifically to produce predictions that maximize downstream decision quality, rather than accuracy. While effective, DFL is computationally expensive, because it requires solving the optimization problem with the predicted parameters at each loss evaluation. In this work, we address this computational bottleneck for linear optimization problems, a common class of problems in both DFL literature and real-world applications. We propose a solver-free training method that exploits the geometric structure of linear optimization to enable efficient training with minimal degradation in solution quality. Our method is based on the insight that a solution is optimal if and only if it achieves an objective value that is at least as good as that of its adjacent vertices on the feasible polytope. Building on this, our method compares the estimated quality of the ground-truth optimal solution with that of its precomputed adjacent vertices, and uses this as loss function. Experiments demonstrate that our method significantly reduces computational cost while maintaining high decision quality.","authors":["Senne Berden","Ali \\.Irfan Mahmuto\\u{g}ullar{\\i}","Dimos Tsouros","Tias Guns"],"url":"https://arxiv.org/abs/2505.22224"}
{"created":"2025-05-29","title":"Hadaptive-Net: Efficient Vision Models via Adaptive Cross-Hadamard Synergy","abstract":"Recent studies have revealed the immense potential of Hadamard product in enhancing network representational capacity and dimensional compression. However, despite its theoretical promise, this technique has not been systematically explored or effectively applied in practice, leaving its full capabilities underdeveloped. In this work, we first analyze and identify the advantages of Hadamard product over standard convolutional operations in cross-channel interaction and channel expansion. Building upon these insights, we propose a computationally efficient module: Adaptive Cross-Hadamard (ACH), which leverages adaptive cross-channel Hadamard products for high-dimensional channel expansion. Furthermore, we introduce Hadaptive-Net (Hadamard Adaptive Network), a lightweight network backbone for visual tasks, which is demonstrated through experiments that it achieves an unprecedented balance between inference speed and accuracy through our proposed module.","authors":["Xuyang Zhang","Xi Zhang","Liang Chen","Hao Shi","Qingshan Guo"],"url":"https://arxiv.org/abs/2505.22226"}
{"created":"2025-05-29","title":"GoMatching++: Parameter- and Data-Efficient Arbitrary-Shaped Video Text Spotting and Benchmarking","abstract":"Video text spotting (VTS) extends image text spotting (ITS) by adding text tracking, significantly increasing task complexity. Despite progress in VTS, existing methods still fall short of the performance seen in ITS. This paper identifies a key limitation in current video text spotters: limited recognition capability, even after extensive end-to-end training. To address this, we propose GoMatching++, a parameter- and data-efficient method that transforms an off-the-shelf image text spotter into a video specialist. The core idea lies in freezing the image text spotter and introducing a lightweight, trainable tracker, which can be optimized efficiently with minimal training data. Our approach includes two key components: (1) a rescoring mechanism to bridge the domain gap between image and video data, and (2) the LST-Matcher, which enhances the frozen image text spotter's ability to handle video text. We explore various architectures for LST-Matcher to ensure efficiency in both parameters and training data. As a result, GoMatching++ sets new performance records on challenging benchmarks such as ICDAR15-video, DSText, and BOVText, while significantly reducing training costs. To address the lack of curved text datasets in VTS, we introduce ArTVideo, a new benchmark featuring over 30% curved text with detailed annotations. We also provide a comprehensive statistical analysis and experimental results for ArTVideo. We believe that GoMatching++ and the ArTVideo benchmark will drive future advancements in video text spotting. The source code, models and dataset are publicly available at https://github.com/Hxyz-123/GoMatching.","authors":["Haibin He","Jing Zhang","Maoyuan Ye","Juhua Liu","Bo Du","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.22228"}
{"created":"2025-05-29","title":"Two-stage Audio-Visual Target Speaker Extraction System for Real-Time Processing On Edge Device","abstract":"Audio-Visual Target Speaker Extraction (AVTSE) aims to isolate a target speaker's voice in a multi-speaker environment with visual cues as auxiliary. Most of the existing AVTSE methods encode visual and audio features simultaneously, resulting in extremely high computational complexity and making it impractical for real-time processing on edge devices. To tackle this issue, we proposed a two-stage ultra-compact AVTSE system. Specifically, in the first stage, a compact network is employed for voice activity detection (VAD) using visual information. In the second stage, the VAD results are combined with audio inputs to isolate the target speaker's voice. Experiments show that the proposed system effectively suppresses background noise and interfering voices while spending little computational resources.","authors":["Zixuan Li","Xueliang Zhang","Lei Miao","Zhipeng Yan"],"url":"https://arxiv.org/abs/2505.22229"}
{"created":"2025-05-29","title":"Enjoying Information Dividend: Gaze Track-based Medical Weakly Supervised Segmentation","abstract":"Weakly supervised semantic segmentation (WSSS) in medical imaging struggles with effectively using sparse annotations. One promising direction for WSSS leverages gaze annotations, captured via eye trackers that record regions of interest during diagnostic procedures. However, existing gaze-based methods, such as GazeMedSeg, do not fully exploit the rich information embedded in gaze data. In this paper, we propose GradTrack, a framework that utilizes physicians' gaze track, including fixation points, durations, and temporal order, to enhance WSSS performance. GradTrack comprises two key components: Gaze Track Map Generation and Track Attention, which collaboratively enable progressive feature refinement through multi-level gaze supervision during the decoding process. Experiments on the Kvasir-SEG and NCI-ISBI datasets demonstrate that GradTrack consistently outperforms existing gaze-based methods, achieving Dice score improvements of 3.21\\% and 2.61\\%, respectively. Moreover, GradTrack significantly narrows the performance gap with fully supervised models such as nnUNet.","authors":["Zhisong Wang","Yiwen Ye","Ziyang Chen","Yong Xia"],"url":"https://arxiv.org/abs/2505.22230"}
{"created":"2025-05-29","title":"Advancing Hearing Assessment: An ASR-Based Frequency-Specific Speech Test for Diagnosing Presbycusis","abstract":"Traditional audiometry often fails to fully characterize the functional impact of hearing loss on speech understanding, particularly supra-threshold deficits and frequency-specific perception challenges in conditions like presbycusis. This paper presents the development and simulated evaluation of a novel Automatic Speech Recognition (ASR)-based frequency-specific speech test designed to provide granular diagnostic insights. Our approach leverages ASR to simulate the perceptual effects of moderate sloping hearing loss by processing speech stimuli under controlled acoustic degradation and subsequently analyzing phoneme-level confusion patterns. Key findings indicate that simulated hearing loss introduces specific phoneme confusions, predominantly affecting high-frequency consonants (e.g., alveolar/palatal to labiodental substitutions) and leading to significant phoneme deletions, consistent with the acoustic cues degraded in presbycusis. A test battery curated from these ASR-derived confusions demonstrated diagnostic value, effectively differentiating between simulated normal-hearing and hearing-impaired listeners in a comprehensive simulation. This ASR-driven methodology offers a promising avenue for developing objective, granular, and frequency-specific hearing assessment tools that complement traditional audiometry. Future work will focus on validating these findings with human participants and exploring the integration of advanced AI models for enhanced diagnostic precision.","authors":["Stefan Bleeck"],"url":"https://arxiv.org/abs/2505.22231"}
{"created":"2025-05-29","title":"Judging Quality Across Languages: A Multilingual Approach to Pretraining Data Filtering with Language Models","abstract":"High-quality multilingual training data is essential for effectively pretraining large language models (LLMs). Yet, the availability of suitable open-source multilingual datasets remains limited. Existing state-of-the-art datasets mostly rely on heuristic filtering methods, restricting both their cross-lingual transferability and scalability. Here, we introduce JQL, a systematic approach that efficiently curates diverse and high-quality multilingual data at scale while significantly reducing computational demands. JQL distills LLMs' annotation capabilities into lightweight annotators based on pretrained multilingual embeddings. These models exhibit robust multilingual and cross-lingual performance, even for languages and scripts unseen during training. Evaluated empirically across 35 languages, the resulting annotation pipeline substantially outperforms current heuristic filtering methods like Fineweb2. JQL notably enhances downstream model training quality and increases data retention rates. Our research provides practical insights and valuable resources for multilingual data curation, raising the standards of multilingual dataset development.","authors":["Mehdi Ali","Manuel Brack","Max L\\\"ubbering","Elias Wendt","Abbas Goher Khan","Richard Rutmann","Alex Jude","Maurice Kraus","Alexander Arno Weber","Felix Stollenwerk","David Kacz\\'er","Florian Mai","Lucie Flek","Rafet Sifa","Nicolas Flores-Herr","Joachim K\\\"ohler","Patrick Schramowski","Michael Fromm","Kristian Kersting"],"url":"https://arxiv.org/abs/2505.22232"}
{"created":"2025-05-29","title":"Evolution of repositories and privacy laws: commit activities in the GDPR and CCPA era","abstract":"Free and open source software has gained a lot of momentum in the industry and the research community. The latest advances in privacy legislation, including the EU General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA), have forced the community to pay special attention to users' data privacy. The main aim of this work is to examine software repositories that are acting on privacy laws. We have collected commit data from GitHub repositories in order to understand indications on main data privacy laws (GDPR, CCPA, CPRA, UK DPA) in the last years. Via an automated process, we analyzed 37,213 commits from 12,391 repositories since 2016, whereas 594 commits from the 70 most popular repositories of the dataset were manually analyzed. We observe that most commits were performed on the year the law came into effect and privacy relevant terms appear in the commit messages, whereas reference to specific data privacy user rights is scarce. The study showed that more educational activities on data privacy user rights are needed, as well as tools for privacy recommendations, whereas verifying actual compliance via source code execution is a useful direction for software engineering researchers.","authors":["Georgia M. Kapitsaki","Maria Papoutsoglou"],"url":"https://arxiv.org/abs/2505.22234"}
{"created":"2025-05-29","title":"Optimal kernel regression bounds under energy-bounded noise","abstract":"Non-conservative uncertainty bounds are key for both assessing an estimation algorithm's accuracy and in view of downstream tasks, such as its deployment in safety-critical contexts. In this paper, we derive a tight, non-asymptotic uncertainty bound for kernel-based estimation, which can also handle correlated noise sequences. Its computation relies on a mild norm-boundedness assumption on the unknown function and the noise, returning the worst-case function realization within the hypothesis class at an arbitrary query input location. The value of this function is shown to be given in terms of the posterior mean and covariance of a Gaussian process for an optimal choice of the measurement noise covariance. By rigorously analyzing the proposed approach and comparing it with other results in the literature, we show its effectiveness in returning tight and easy-to-compute bounds for kernel-based estimates.","authors":["Amon Lahr","Johannes K\\\"ohler","Anna Scampicchio","Melanie N. Zeilinger"],"url":"https://arxiv.org/abs/2505.22235"}
{"created":"2025-05-29","title":"A Linguistically Motivated Analysis of Intonational Phrasing in Text-to-Speech Systems: Revealing Gaps in Syntactic Sensitivity","abstract":"We analyze the syntactic sensitivity of Text-to-Speech (TTS) systems using methods inspired by psycholinguistic research. Specifically, we focus on the generation of intonational phrase boundaries, which can often be predicted by identifying syntactic boundaries within a sentence. We find that TTS systems struggle to accurately generate intonational phrase boundaries in sentences where syntactic boundaries are ambiguous (e.g., garden path sentences or sentences with attachment ambiguity). In these cases, systems need superficial cues such as commas to place boundaries at the correct positions. In contrast, for sentences with simpler syntactic structures, we find that systems do incorporate syntactic cues beyond surface markers. Finally, we finetune models on sentences without commas at the syntactic boundary positions, encouraging them to focus on more subtle linguistic cues. Our findings indicate that this leads to more distinct intonation patterns that better reflect the underlying structure.","authors":["Charlotte Pouw","Afra Alishahi","Willem Zuidema"],"url":"https://arxiv.org/abs/2505.22236"}
{"created":"2025-05-29","title":"Yambda-5B -- A Large-Scale Multi-modal Dataset for Ranking And Retrieval","abstract":"We present Yambda-5B, a large-scale open dataset sourced from the Yandex.Music streaming platform. Yambda-5B contains 4.79 billion user-item interactions from 1 million users across 9.39 million tracks. The dataset includes two primary types of interactions: implicit feedback (listening events) and explicit feedback (likes, dislikes, unlikes and undislikes). In addition, we provide audio embeddings for most tracks, generated by a convolutional neural network trained on audio spectrograms. A key distinguishing feature of Yambda-5B is the inclusion of the is_organic flag, which separates organic user actions from recommendation-driven events. This distinction is critical for developing and evaluating machine learning algorithms, as Yandex.Music relies on recommender systems to personalize track selection for users. To support rigorous benchmarking, we introduce an evaluation protocol based on a Global Temporal Split, allowing recommendation algorithms to be assessed in conditions that closely mirror real-world use. We report benchmark results for standard baselines (ItemKNN, iALS) and advanced models (SANSA, SASRec) using a variety of evaluation metrics. By releasing Yambda-5B to the community, we aim to provide a readily accessible, industrial-scale resource to advance research, foster innovation, and promote reproducible results in recommender systems.","authors":["A. Ploshkin","V. Tytskiy","A. Pismenny","V. Baikalov","E. Taychinov","A. Permiakov","D. Burlakov","E. Krofto","N. Savushkin"],"url":"https://arxiv.org/abs/2505.22238"}
{"created":"2025-05-29","title":"BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain","abstract":"Biomedical reasoning often requires traversing interconnected relationships across entities such as drugs, diseases, and proteins. Despite the increasing prominence of large language models (LLMs), existing benchmarks lack the ability to evaluate multi-hop reasoning in the biomedical domain, particularly for queries involving one-to-many and many-to-many relationships. This gap leaves the critical challenges of biomedical multi-hop reasoning underexplored. To address this, we introduce BioHopR, a novel benchmark designed to evaluate multi-hop, multi-answer reasoning in structured biomedical knowledge graphs. Built from the comprehensive PrimeKG, BioHopR includes 1-hop and 2-hop reasoning tasks that reflect real-world biomedical complexities.","authors":["Yunsoo Kim","Yusuf Abdulle","Honghan Wu"],"url":"https://arxiv.org/abs/2505.22240"}
{"created":"2025-05-29","title":"UDuo: Universal Dual Optimization Framework for Online Matching","abstract":"Online resource allocation under budget constraints critically depends on proper modeling of user arrival dynamics. Classical approaches employ stochastic user arrival models to derive near-optimal solutions through fractional matching formulations of exposed users for downstream allocation tasks. However, this is no longer a reasonable assumption when the environment changes dynamically. In this work, We propose the Universal Dual optimization framework UDuo, a novel paradigm that fundamentally rethinks online allocation through three key innovations: (i) a temporal user arrival representation vector that explicitly captures distribution shifts in user arrival patterns and resource consumption dynamics, (ii) a resource pacing learner with adaptive allocation policies that generalize to heterogeneous constraint scenarios, and (iii) an online time-series forecasting approach for future user arrival distributions that achieves asymptotically optimal solutions with constraint feasibility guarantees in dynamic environments. Experimental results show that UDuo achieves higher efficiency and faster convergence than the traditional stochastic arrival model in real-world pricing while maintaining rigorous theoretical validity for general online allocation problems.","authors":["Bin Li","Diwei Liu","Zehong Hu","Jia Jia"],"url":"https://arxiv.org/abs/2505.22243"}
{"created":"2025-05-29","title":"A Preprocessing Framework for Efficient Approximate Bi-Objective Shortest-Path Computation in the Presence of Correlated Objectives","abstract":"The bi-objective shortest-path (BOSP) problem seeks to find paths between start and target vertices of a graph while optimizing two conflicting objective functions. We consider the BOSP problem in the presence of correlated objectives. Such correlations often occur in real-world settings such as road networks, where optimizing two positively correlated objectives, such as travel time and fuel consumption, is common. BOSP is generally computationally challenging as the size of the search space is exponential in the number of objective functions and the graph size. Bounded sub-optimal BOSP solvers such as A*pex alleviate this complexity by approximating the Pareto-optimal solution set rather than computing it exactly (given a user-provided approximation factor). As the correlation between objective functions increases, smaller approximation factors are sufficient for collapsing the entire Pareto-optimal set into a single solution. We leverage this insight to propose an efficient algorithm that reduces the search effort in the presence of correlated objectives. Our approach for computing approximations of the entire Pareto-optimal set is inspired by graph-clustering algorithms. It uses a preprocessing phase to identify correlated clusters within a graph and to generate a new graph representation. This allows a natural generalization of A*pex to run up to five times faster on DIMACS dataset instances, a standard benchmark in the field. To the best of our knowledge, this is the first algorithm proposed that efficiently and effectively exploits correlations in the context of bi-objective search while providing theoretical guarantees on solution quality.","authors":["Yaron Halle","Ariel Felner","Sven Koenig","Oren Salzman"],"url":"https://arxiv.org/abs/2505.22244"}
{"created":"2025-05-29","title":"Direct Algorithms for Reconstructing Small Conductivity Inclusions in Subdiffusion","abstract":"The subdiffusion model that involves a Caputo fractional derivative in time is widely used to describe anomalously slow diffusion processes. In this work we aim at recovering the locations of small conductivity inclusions in the model from boundary measurement, and develop novel direct algorithms based on the asymptotic expansion of the boundary measurement with respect to the size of the inclusions and approximate fundamental solutions. These algorithms involve only algebraic manipulations and are computationally cheap. To the best of our knowledge, they are first direct algorithms for the inverse conductivity problem in the context of the subdiffusion model. Moreover, we provide relevant theoretical underpinnings for the algorithms. Also we present numerical results to illustrate their performance under various scenarios, e.g., the size of inclusions, noise level of the data, and the number of inclusions, showing that the algorithms are efficient and robust.","authors":["Jiho Hong","Bangti Jin","Zhizhang Wu"],"url":"https://arxiv.org/abs/2505.22245"}
{"created":"2025-05-29","title":"StateSpaceDiffuser: Bringing Long Context to Diffusion World Models","abstract":"World models have recently become promising tools for predicting realistic visuals based on actions in complex environments. However, their reliance on a short sequence of observations causes them to quickly lose track of context. As a result, visual consistency breaks down after just a few steps, and generated scenes no longer reflect information seen earlier. This limitation of the state-of-the-art diffusion-based world models comes from their lack of a lasting environment state. To address this problem, we introduce StateSpaceDiffuser, where a diffusion model is enabled to perform on long-context tasks by integrating a sequence representation from a state-space model (Mamba), representing the entire interaction history. This design restores long-term memory without sacrificing the high-fidelity synthesis of diffusion models. To rigorously measure temporal consistency, we develop an evaluation protocol that probes a model's ability to reinstantiate seen content in extended rollouts. Comprehensive experiments show that StateSpaceDiffuser significantly outperforms a strong diffusion-only baseline, maintaining a coherent visual context for an order of magnitude more steps. It delivers consistent views in both a 2D maze navigation and a complex 3D environment. These results establish that bringing state-space representations into diffusion models is highly effective in demonstrating both visual details and long-term memory.","authors":["Nedko Savov","Naser Kazemi","Deheng Zhang","Danda Pani Paudel","Xi Wang","Luc Van Gool"],"url":"https://arxiv.org/abs/2505.22246"}
{"created":"2025-05-29","title":"Dynamic State-Feedback Control for LPV Systems: Ensuring Stability and LQR Performance","abstract":"In this paper, we propose a novel dynamic state-feedback controller for polytopic linear parameter-varying (LPV) systems with constant input matrix. The controller employs a projected gradient flow method to continuously improve its control law and, under established conditions, converges to the optimal feedback gain of the corresponding linear quadratic regulator (LQR) problem associated with constant parameter trajectories. We derive conditions for quadratic stability, which can be verified via convex optimization, to ensure exponential stability of the LPV system even under arbitrarily fast parameter variations. Additionally, we provide sufficient conditions to guarantee the boundedness of the trajectories of the dynamic controller for any parameter trajectory and the convergence of its feedback gains to the optimal LQR gains for constant parameter trajectories. Furthermore, we show that the closed-loop system is asymptotically stable for constant parameter trajectories under these conditions. Simulation results demonstrate that the controller maintains stability and improves transient performance.","authors":["Armin Gie{\\ss}ler","Felix Strehle","Jochen Illerhaus","S\\\"oren Hohmann"],"url":"https://arxiv.org/abs/2505.22248"}
{"created":"2025-05-29","title":"YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction","abstract":"Coral reefs, crucial for sustaining marine biodiversity and ecological processes (e.g., nutrient cycling, habitat provision), face escalating threats, underscoring the need for efficient monitoring. Coral reef ecological monitoring faces dual challenges of low efficiency in manual analysis and insufficient segmentation accuracy in complex underwater scenarios. This study develops the YH-OSI system, establishing an intelligent framework centered on the Multimodal Large Model (MLLM) for \"object detection-semantic segmentation-prior input\". The system uses the object detection module (mAP@0.5=0.78) to generate spatial prior boxes for coral instances, driving the segment module to complete pixel-level segmentation in low-light and densely occluded scenarios. The segmentation masks and finetuned classification instructions are fed into the Qwen2-VL-based multimodal model as prior inputs, achieving a genus-level classification accuracy of 88% and simultaneously extracting core ecological metrics. Meanwhile, the system retains the scalability of the multimodal model through standardized interfaces, laying a foundation for future integration into multimodal agent-based underwater robots and supporting the full-process automation of \"image acquisition-prior generation-real-time analysis.\"","authors":["Mingzhuang Wang","Yvyang Li","Xiyang Zhang","Fei Tan","Qi Shi","Guotao Zhang","Siqi Chen","Yufei Liu","Lei Lei","Ming Zhou","Qiang Lin","Hongqiang Yang"],"url":"https://arxiv.org/abs/2505.22250"}
{"created":"2025-05-29","title":"B-XAIC Dataset: Benchmarking Explainable AI for Graph Neural Networks Using Chemical Data","abstract":"Understanding the reasoning behind deep learning model predictions is crucial in cheminformatics and drug discovery, where molecular design determines their properties. However, current evaluation frameworks for Explainable AI (XAI) in this domain often rely on artificial datasets or simplified tasks, employing data-derived metrics that fail to capture the complexity of real-world scenarios and lack a direct link to explanation faithfulness. To address this, we introduce B-XAIC, a novel benchmark constructed from real-world molecular data and diverse tasks with known ground-truth rationales for assigned labels. Through a comprehensive evaluation using B-XAIC, we reveal limitations of existing XAI methods for Graph Neural Networks (GNNs) in the molecular domain. This benchmark provides a valuable resource for gaining deeper insights into the faithfulness of XAI, facilitating the development of more reliable and interpretable models.","authors":["Magdalena Proszewska","Tomasz Danel","Dawid Rymarczyk"],"url":"https://arxiv.org/abs/2505.22252"}
{"created":"2025-05-29","title":"A Unified Online-Offline Framework for Co-Branding Campaign Recommendations","abstract":"Co-branding has become a vital strategy for businesses aiming to expand market reach within recommendation systems. However, identifying effective cross-industry partnerships remains challenging due to resource imbalances, uncertain brand willingness, and ever-changing market conditions. In this paper, we provide the first systematic study of this problem and propose a unified online-offline framework to enable co-branding recommendations. Our approach begins by constructing a bipartite graph linking ``initiating'' and ``target'' brands to quantify co-branding probabilities and assess market benefits. During the online learning phase, we dynamically update the graph in response to market feedback, while striking a balance between exploring new collaborations for long-term gains and exploiting established partnerships for immediate benefits. To address the high initial co-branding costs, our framework mitigates redundant exploration, thereby enhancing short-term performance while ensuring sustainable strategic growth. In the offline optimization phase, our framework consolidates the interests of multiple sub-brands under the same parent brand to maximize overall returns, avoid excessive investment in single sub-brands, and reduce unnecessary costs associated with over-prioritizing a single sub-brand. We present a theoretical analysis of our approach, establishing a highly nontrivial sublinear regret bound for online learning in the complex co-branding problem, and enhancing the approximation guarantee for the NP-hard offline budget allocation optimization. Experiments on both synthetic and real-world co-branding datasets demonstrate the practical effectiveness of our framework, with at least 12\\% improvement.","authors":["Xiangxiang Dai","Xiaowei Sun","Jinhang Zuo","Xutong Liu","John C. S. Lui"],"url":"https://arxiv.org/abs/2505.22254"}
{"created":"2025-05-29","title":"Train Sparse Autoencoders Efficiently by Utilizing Features Correlation","abstract":"Sparse Autoencoders (SAEs) have demonstrated significant promise in interpreting the hidden states of language models by decomposing them into interpretable latent directions. However, training SAEs at scale remains challenging, especially when large dictionary sizes are used. While decoders can leverage sparse-aware kernels for efficiency, encoders still require computationally intensive linear operations with large output dimensions. To address this, we propose KronSAE, a novel architecture that factorizes the latent representation via Kronecker product decomposition, drastically reducing memory and computational overhead. Furthermore, we introduce mAND, a differentiable activation function approximating the binary AND operation, which improves interpretability and performance in our factorized framework.","authors":["Vadim Kurochkin","Yaroslav Aksenov","Daniil Laptev","Daniil Gavrilov","Nikita Balagansky"],"url":"https://arxiv.org/abs/2505.22255"}
{"created":"2025-05-29","title":"Revisiting Group Relative Policy Optimization: Insights into On-Policy and Off-Policy Training","abstract":"We revisit Group Relative Policy Optimization (GRPO) in both on-policy and off-policy optimization regimes. Our motivation comes from recent work on off-policy Proximal Policy Optimization (PPO), which improves training stability, sampling efficiency, and memory usage. In addition, a recent analysis of GRPO suggests that estimating the advantage function with off-policy samples could be beneficial. Building on these observations, we adapt GRPO to the off-policy setting. We show that both on-policy and off-policy GRPO objectives yield an improvement in the reward. This result motivates the use of clipped surrogate objectives in the off-policy version of GRPO. We then compare the empirical performance of reinforcement learning with verifiable rewards in post-training using both GRPO variants. Our results show that off-policy GRPO either significantly outperforms or performs on par with its on-policy counterpart.","authors":["Youssef Mroueh","Nicolas Dupuis","Brian Belgodere","Apoorva Nitsure","Mattia Rigotti","Kristjan Greenewald","Jiri Navratil","Jerret Ross","Jesus Rios"],"url":"https://arxiv.org/abs/2505.22257"}
{"created":"2025-05-29","title":"LiDAR Based Semantic Perception for Forklifts in Outdoor Environments","abstract":"In this study, we present a novel LiDAR-based semantic segmentation framework tailored for autonomous forklifts operating in complex outdoor environments. Central to our approach is the integration of a dual LiDAR system, which combines forward-facing and downward-angled LiDAR sensors to enable comprehensive scene understanding, specifically tailored for industrial material handling tasks. The dual configuration improves the detection and segmentation of dynamic and static obstacles with high spatial precision. Using high-resolution 3D point clouds captured from two sensors, our method employs a lightweight yet robust approach that segments the point clouds into safety-critical instance classes such as pedestrians, vehicles, and forklifts, as well as environmental classes such as driveable ground, lanes, and buildings. Experimental validation demonstrates that our approach achieves high segmentation accuracy while satisfying strict runtime requirements, establishing its viability for safety-aware, fully autonomous forklift navigation in dynamic warehouse and yard environments.","authors":["Benjamin Serfling","Hannes Reichert","Lorenzo Bayerlein","Konrad Doll","Kati Radkhah-Lens"],"url":"https://arxiv.org/abs/2505.22258"}
{"created":"2025-05-29","title":"Domain Adaptation of Attention Heads for Zero-shot Anomaly Detection","abstract":"Zero-shot anomaly detection (ZSAD) in images is an approach that can detect anomalies without access to normal samples, which can be beneficial in various realistic scenarios where model training is not possible. However, existing ZSAD research has shown limitations by either not considering domain adaptation of general-purpose backbone models to anomaly detection domains or by implementing only partial adaptation to some model components. In this paper, we propose HeadCLIP to overcome these limitations by effectively adapting both text and image encoders to the domain. HeadCLIP generalizes the concepts of normality and abnormality through learnable prompts in the text encoder, and introduces learnable head weights to the image encoder to dynamically adjust the features held by each attention head according to domain characteristics. Additionally, we maximize the effect of domain adaptation by introducing a joint anomaly score that utilizes domain-adapted pixel-level information for image-level anomaly detection. Experimental results using multiple real datasets in both industrial and medical domains show that HeadCLIP outperforms existing ZSAD techniques at both pixel and image levels. In the industrial domain, improvements of up to 4.9%p in pixel-level mean anomaly detection score (mAD) and up to 3.0%p in image-level mAD were achieved, with similar improvements (3.2%p, 3.1%p) in the medical domain.","authors":["Kiyoon Jeong","Jaehyuk Heo","Junyeong Son","Pilsung Kang"],"url":"https://arxiv.org/abs/2505.22259"}
{"created":"2025-05-29","title":"MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps","abstract":"In this paper we expose our approach to solve the \\textit{SemEval 2025 Task 8: Question-Answering over Tabular Data} challenge. Our strategy leverages Python code generation with LLMs to interact with the table and get the answer to the questions. The process is composed of multiple steps: understanding the content of the table, generating natural language instructions in the form of steps to follow in order to get the answer, translating these instructions to code, running it and handling potential errors or exceptions. These steps use open source LLMs and fine grained optimized prompts for each task (step). With this approach, we achieved a score of $70.50\\%$ for subtask 1.","authors":["Maximiliano Hormaz\\'abal Lagos","\\'Alvaro Bueno Saez","H\\'ector Cerezo-Costas","Pedro Alonso Doval","Jorge Alcalde Vesteiro"],"url":"https://arxiv.org/abs/2505.22264"}
{"created":"2025-05-29","title":"FGS-Audio: Fixed-Decoder Framework for Audio Steganography with Adversarial Perturbation Generation","abstract":"The rapid development of Artificial Intelligence Generated Content (AIGC) has made high-fidelity generated audio widely available across the Internet, offering an abundant and versatile source of cover signals for covert communication. Driven by advances in deep learning, current audio steganography frameworks are mainly based on encoding-decoding network architectures. While these methods greatly improve the security of audio steganography, they typically employ elaborate training workflows and rely on extensive pre-trained models. To address the aforementioned issues, this paper pioneers a Fixed-Decoder Framework for Audio Steganography with Adversarial Perturbation Generation (FGS-Audio). The adversarial perturbations that carry secret information are embedded into cover audio to generate stego audio. The receiver only needs to share the structure and weights of the fixed decoding network to accurately extract the secret information from the stego audio, thus eliminating the reliance on large pre-trained models. In FGS-Audio, we propose an audio Adversarial Perturbation Generation (APG) strategy and design a lightweight fixed decoder. The fixed decoder guarantees reliable extraction of the hidden message, while the adversarial perturbations are optimized to keep the stego audio perceptually and statistically close to the cover audio, thereby improving resistance to steganalysis. The experimental results show that the method exhibits excellent anti-steganalysis performance under different relative payloads, outperforming existing SOTA approaches. In terms of stego audio quality, FGS-Audio achieves an average PSNR improvement of over 10 dB compared to SOTA method.","authors":["Jialin Yan","Yu Cheng","Zhaoxia Yin","Xinpeng Zhang","Shilin Wang","Tanfeng Sun","Xinghao Jiang"],"url":"https://arxiv.org/abs/2505.22266"}
{"created":"2025-05-29","title":"A memristive model of spatio-temporal excitability","abstract":"This paper introduces a model of excitability that unifies the mechanism of an important neuronal property both in time and in space. As a starting point, we revisit both a key model of temporal excitability, proposed by Hodgkin and Huxley, and a key model of spatial excitability, proposed by Amari. We then propose a novel model that captures the temporal and spatial properties of both models. Our aim is to regard neuronal excitability as a property across scales, and to explore the benefits of modeling excitability with one and the same mechanism, whether at the cellular or the population level.","authors":["Thomas SJ Burger","Amir Shahhosseini","Rodolphe Sepulchre"],"url":"https://arxiv.org/abs/2505.22269"}
{"created":"2025-05-29","title":"Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models","abstract":"While (multimodal) large language models (LLMs) have attracted widespread attention due to their exceptional capabilities, they remain vulnerable to jailbreak attacks. Various defense methods are proposed to defend against jailbreak attacks, however, they are often tailored to specific types of jailbreak attacks, limiting their effectiveness against diverse adversarial strategies. For instance, rephrasing-based defenses are effective against text adversarial jailbreaks but fail to counteract image-based attacks. To overcome these limitations, we propose a universal defense framework, termed Test-time IMmunization (TIM), which can adaptively defend against various jailbreak attacks in a self-evolving way. Specifically, TIM initially trains a gist token for efficient detection, which it subsequently applies to detect jailbreak activities during inference. When jailbreak attempts are identified, TIM implements safety fine-tuning using the detected jailbreak instructions paired with refusal answers. Furthermore, to mitigate potential performance degradation in the detector caused by parameter updates during safety fine-tuning, we decouple the fine-tuning process from the detection module. Extensive experiments on both LLMs and multimodal LLMs demonstrate the efficacy of TIM.","authors":["Yongcan Yu","Yanbo Wang","Ran He","Jian Liang"],"url":"https://arxiv.org/abs/2505.22271"}
{"created":"2025-05-29","title":"Comprehensive Evaluation on Lexical Normalization: Boundary-Aware Approaches for Unsegmented Languages","abstract":"Lexical normalization research has sought to tackle the challenge of processing informal expressions in user-generated text, yet the absence of comprehensive evaluations leaves it unclear which methods excel across multiple perspectives. Focusing on unsegmented languages, we make three key contributions: (1) creating a large-scale, multi-domain Japanese normalization dataset, (2) developing normalization methods based on state-of-the-art pretrained models, and (3) conducting experiments across multiple evaluation perspectives. Our experiments show that both encoder-only and decoder-only approaches achieve promising results in both accuracy and efficiency.","authors":["Shohei Higashiyama","Masao Utiyama"],"url":"https://arxiv.org/abs/2505.22273"}
{"created":"2025-05-29","title":"Full Domain Analysis in Fluid Dynamics","abstract":"Novel techniques in evolutionary optimization, simulation and machine learning allow for a broad analysis of domains like fluid dynamics, in which computation is expensive and flow behavior is complex. Under the term of full domain analysis we understand the ability to efficiently determine the full space of solutions in a problem domain, and analyze the behavior of those solutions in an accessible and interactive manner. The goal of full domain analysis is to deepen our understanding of domains by generating many examples of flow, their diversification, optimization and analysis. We define a formal model for full domain analysis, its current state of the art, and requirements of subcomponents. Finally, an example is given to show what we can learn by using full domain analysis. Full domain analysis, rooted in optimization and machine learning, can be a helpful tool in understanding complex systems in computational physics and beyond.","authors":["Alexander Hagg","Adam Gaier","Dominik Wilde","Alexander Asteroth","Holger Foysi","Dirk Reith"],"url":"https://arxiv.org/abs/2505.22275"}
{"created":"2025-05-29","title":"The complexity of deciding characteristic formulae modulo nested simulation","abstract":"This paper studies the complexity of determining whether a formula in the modal logics characterizing the nested-simulation semantics is characteristic for some process, which is equivalent to determining whether the formula is satisfiable and prime. The main results are that the problem of determining whether a formula is prime in the modal logic characterizing the 2-nested-simulation preorder is CoNP-complete and is PSPACE-complete in the case of the n-nested-simulation preorder, when n>= 3. This establishes that deciding characteristic formulae for the n-nested simulation semantics, n>= 3, is PSPACE-complete. In the case of the 2-nested simulation semantics, that problem lies in the complexity class DP, which consists of languages that can be expressed as the intersection of one language in NP and of one in CoNP.","authors":["Luca Aceto","Antonis Achilleos","Aggeliki Chalki","Anna Ingolfsdottir"],"url":"https://arxiv.org/abs/2505.22277"}
{"created":"2025-05-29","title":"A Coupled Hydro-Morphodynamic Model for Sediment Transport using the Moment Approach","abstract":"Sediment transport is crucial in the hydro-morphodynamic evolution of free surface flows in shallow water environments, which is typically modeled under the shallow water assumption. In classical shallow water modeling for sediment transport, the vertical structure of the flow is collapsed into a depth-averaged and near-bed velocity, usually reconstructed empirically, e.g., using a parameterized logarithmic profile. In practice, large variations from such empirical profiles can occur. It is therefore essential to resolve the vertical structure of the velocity profile within the shallow water framework to better approximate near-bed velocity. This study introduces a model and simulations that incorporate vertical velocity variations and bottom erosion-deposition effects in sediment transport, providing a computationally efficient framework for predicting sediment dynamics in shallow water environments. We employ the so-called moment model approach for the velocity variation, which considers a polynomial expansion of the horizontal velocity in the scaled vertical direction. This allows the use of a complex velocity profile with an extended set of variables determined by the polynomial basis coefficients, resolving the vertical structure as part of the solution. The extended model comprises four components: (1) the standard shallow water equations; (2) moment equations governing evolution of the basis coefficients; (3) an evolution equation for sediment concentration; and (4) a transport equation for the bed. This enables a coupled model for bedload and suspended load transport. We use a hyperbolic regularization technique to ensure model stability and realistic eigenvalues. Several numerical tests, including dam-break cases with and without wet/dry fronts, validate our results against laboratory data.","authors":["Afroja Parvin","Giovanni Samaey","Julian Koellermeier"],"url":"https://arxiv.org/abs/2505.22278"}
{"created":"2025-05-29","title":"Learning Fine-Grained Geometry for Sparse-View Splatting via Cascade Depth Loss","abstract":"Novel view synthesis is a fundamental task in 3D computer vision that aims to reconstruct realistic images from a set of posed input views. However, reconstruction quality degrades significantly under sparse-view conditions due to limited geometric cues. Existing methods, such as Neural Radiance Fields (NeRF) and the more recent 3D Gaussian Splatting (3DGS), often suffer from blurred details and structural artifacts when trained with insufficient views. Recent works have identified the quality of rendered depth as a key factor in mitigating these artifacts, as it directly affects geometric accuracy and view consistency. In this paper, we address these challenges by introducing Hierarchical Depth-Guided Splatting (HDGS), a depth supervision framework that progressively refines geometry from coarse to fine levels. Central to HDGS is a novel Cascade Pearson Correlation Loss (CPCL), which aligns rendered and estimated monocular depths across multiple spatial scales. By enforcing multi-scale depth consistency, our method substantially improves structural fidelity in sparse-view scenarios. Extensive experiments on the LLFF and DTU benchmarks demonstrate that HDGS achieves state-of-the-art performance under sparse-view settings while maintaining efficient and high-quality rendering","authors":["Wenjun Lu","Haodong Chen","Anqi Yi","Yuk Ying Chung","Zhiyong Wang","Kun Hu"],"url":"https://arxiv.org/abs/2505.22279"}
{"created":"2025-05-29","title":"Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review","abstract":"Evidence-based medicine (EBM) is at the forefront of modern healthcare, emphasizing the use of the best available scientific evidence to guide clinical decisions. Due to the sheer volume and rapid growth of medical literature and the high cost of curation, there is a critical need to investigate Natural Language Processing (NLP) methods to identify, appraise, synthesize, summarize, and disseminate evidence in EBM. This survey presents an in-depth review of 129 research studies on leveraging NLP for EBM, illustrating its pivotal role in enhancing clinical decision-making processes. The paper systematically explores how NLP supports the five fundamental steps of EBM -- Ask, Acquire, Appraise, Apply, and Assess. The review not only identifies current limitations within the field but also proposes directions for future research, emphasizing the potential for NLP to revolutionize EBM by refining evidence extraction, evidence synthesis, appraisal, summarization, enhancing data comprehensibility, and facilitating a more efficient clinical workflow.","authors":["Zihan Xu","Haotian Ma","Gongbo Zhang","Yihao Ding","Chunhua Weng","Yifan Peng"],"url":"https://arxiv.org/abs/2505.22280"}
{"created":"2025-05-29","title":"From Controlled Scenarios to Real-World: Cross-Domain Degradation Pattern Matching for All-in-One Image Restoration","abstract":"As a fundamental imaging task, All-in-One Image Restoration (AiOIR) aims to achieve image restoration caused by multiple degradation patterns via a single model with unified parameters. Although existing AiOIR approaches obtain promising performance in closed and controlled scenarios, they still suffered from considerable performance reduction in real-world scenarios since the gap of data distributions between the training samples (source domain) and real-world test samples (target domain) can lead inferior degradation awareness ability. To address this issue, a Unified Domain-Adaptive Image Restoration (UDAIR) framework is proposed to effectively achieve AiOIR by leveraging the learned knowledge from source domain to target domain. To improve the degradation identification, a codebook is designed to learn a group of discrete embeddings to denote the degradation patterns, and the cross-sample contrastive learning mechanism is further proposed to capture shared features from different samples of certain degradation. To bridge the data gap, a domain adaptation strategy is proposed to build the feature projection between the source and target domains by dynamically aligning their codebook embeddings, and a correlation alignment-based test-time adaptation mechanism is designed to fine-tune the alignment discrepancies by tightening the degradation embeddings to the corresponding cluster center in the source domain. Experimental results on 10 open-source datasets demonstrate that UDAIR achieves new state-of-the-art performance for the AiOIR task. Most importantly, the feature cluster validate the degradation identification under unknown conditions, and qualitative comparisons showcase robust generalization to real-world scenarios.","authors":["Junyu Fan","Chuanlin Liao","Yi Lin"],"url":"https://arxiv.org/abs/2505.22284"}
{"created":"2025-05-29","title":"Wireless Communication for Low-Altitude Economy with UAV Swarm Enabled Two-Level Movable Antenna System","abstract":"Unmanned aerial vehicle (UAV) is regarded as a key enabling platform for low-altitude economy, due to its advantages such as 3D maneuverability, flexible deployment, and LoS air-to-air/ground communication links. In particular, the intrinsic high mobility renders UAV especially suitable for operating as a movable antenna (MA) from the sky. In this paper, by exploiting the flexible mobility of UAV swarm and antenna position adjustment of MA, we propose a novel UAV swarm enabled two-level MA system, where UAVs not only individually deploy a local MA array, but also form a larger-scale MA system with their individual MA arrays via swarm coordination. We formulate a general optimization problem to maximize the minimum achievable rate over all ground UEs, by jointly optimizing the 3D UAV swarm placement positions, their individual MAs' positions, and receive beamforming for different UEs. We first consider the special case where each UAV has only one antenna, under different scenarios of one single UE, two UEs, and arbitrary number of UEs. In particular, for the two-UE case, we derive the optimal UAV swarm placement positions in closed-form that achieves IUI-free communication, where the UAV swarm forms a uniform sparse array (USA) satisfying collision avoidance constraint. While for the general case with arbitrary number of UEs, we propose an efficient alternating optimization algorithm to solve the formulated non-convex optimization problem. Then, we extend the results to the case where each UAV is equipped with multiple antennas. Numerical results verify that the proposed low-altitude UAV swarm enabled MA system significantly outperforms various benchmark schemes, thanks to the exploitation of two-level mobility to create more favorable channel conditions for multi-UE communications.","authors":["Haiquan Lu","Yong Zeng","Shaodan Ma","Bin Li","Shi Jin","Rui Zhang"],"url":"https://arxiv.org/abs/2505.22286"}
{"created":"2025-05-29","title":"New Tools are Needed for Tracking Adherence to AI Model Behavioral Use Clauses","abstract":"Foundation models have had a transformative impact on AI. A combination of large investments in research and development, growing sources of digital data for training, and architectures that scale with data and compute has led to models with powerful capabilities. Releasing assets is fundamental to scientific advancement and commercial enterprise. However, concerns over negligent or malicious uses of AI have led to the design of mechanisms to limit the risks of the technology. The result has been a proliferation of licenses with behavioral-use clauses and acceptable-use-policies that are increasingly being adopted by commonly used families of models (Llama, Gemma, Deepseek) and a myriad of smaller projects. We created and deployed a custom AI licenses generator to facilitate license creation and have quantitatively and qualitatively analyzed over 300 customized licenses created with this tool. Alongside this we analyzed 1.7 million models licenses on the HuggingFace model hub. Our results show increasing adoption of these licenses, interest in tools that support their creation and a convergence on common clause configurations. In this paper we take the position that tools for tracking adoption of, and adherence to, these licenses is the natural next step and urgently needed in order to ensure they have the desired impact of ensuring responsible use.","authors":["Daniel McDuff","Tim Korjakow","Kevin Klyman","Danish Contractor"],"url":"https://arxiv.org/abs/2505.22287"}
{"created":"2025-05-29","title":"Compression versus Accuracy: A Hierarchy of Lifted Models","abstract":"Probabilistic graphical models that encode indistinguishable objects and relations among them use first-order logic constructs to compress a propositional factorised model for more efficient (lifted) inference. To obtain a lifted representation, the state-of-the-art algorithm Advanced Colour Passing (ACP) groups factors that represent matching distributions. In an approximate version using $\\varepsilon$ as a hyperparameter, factors are grouped that differ by a factor of at most $(1\\pm \\varepsilon)$. However, finding a suitable $\\varepsilon$ is not obvious and may need a lot of exploration, possibly requiring many ACP runs with different $\\varepsilon$ values. Additionally, varying $\\varepsilon$ can yield wildly different models, leading to decreased interpretability. Therefore, this paper presents a hierarchical approach to lifted model construction that is hyperparameter-free. It efficiently computes a hierarchy of $\\varepsilon$ values that ensures a hierarchy of models, meaning that once factors are grouped together given some $\\varepsilon$, these factors will be grouped together for larger $\\varepsilon$ as well. The hierarchy of $\\varepsilon$ values also leads to a hierarchy of error bounds. This allows for explicitly weighing compression versus accuracy when choosing specific $\\varepsilon$ values to run ACP with and enables interpretability between the different models.","authors":["Jan Speller","Malte Luttermann","Marcel Gehrke","Tanya Braun"],"url":"https://arxiv.org/abs/2505.22288"}
{"created":"2025-05-29","title":"Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling","abstract":"Recent research has highlighted that Large Language Models (LLMs), even when trained to generate extended long reasoning steps, still face significant challenges on hard reasoning problems. However, much of the existing literature relies on direct prompting with simple in-context learning examples for evaluation, which largely overlooks advanced techniques to elicit LLMs' deliberate reasoning before drawing conclusions that LLMs hit a performance ceiling. In this paper, we systematically explore the combined potential of in-context search and test-time scaling on super hard reasoning tasks. We find that by employing advanced in-context search prompting to LLMs augmented with internal scaling, one can achieve transformative performance breakthroughs on tasks previously deemed \"unsolvable\" (e.g., reported success rates below 5%). We provide both empirical results and theoretical analysis of how this combination can unleash LLM reasoning capabilities: i) Empirically, on controlled NP-hard tasks and complex real-world planning benchmarks, our approach achieves up to a 30x improvement in success rates compared to previously reported results without any external mechanisms; ii) Theoretically, we show that in-context search prompting, when combined with internal scaling, significantly extends the complexity class of solvable reasoning problems. These findings challenge prevailing assumptions about the limitations of LLMs on complex tasks, indicating that current evaluation paradigms systematically underestimate their true potential. Our work calls for a critical reassessment of how LLM reasoning is benchmarked and a more robust evaluation strategy that fully captures the true capabilities of contemporary LLMs, which can lead to a better understanding of their operational reasoning boundaries in real-world deployments.","authors":["Fanzeng Xia","Yidong Luo","Tinko Sebastian Bartels","Yaqi Xu","Tongxin Li"],"url":"https://arxiv.org/abs/2505.22290"}
{"created":"2025-05-29","title":"Neural Restoration of Greening Defects in Historical Autochrome Photographs Based on Purely Synthetic Data","abstract":"The preservation of early visual arts, particularly color photographs, is challenged by deterioration caused by aging and improper storage, leading to issues like blurring, scratches, color bleeding, and fading defects. In this paper, we present the first approach for the automatic removal of greening color defects in digitized autochrome photographs. Our main contributions include a method based on synthetic dataset generation and the use of generative AI with a carefully designed loss function for the restoration of visual arts. To address the lack of suitable training datasets for analyzing greening defects in damaged autochromes, we introduce a novel approach for accurately simulating such defects in synthetic data. We also propose a modified weighted loss function for the ChaIR method to account for color imbalances between defected and non-defected areas. While existing methods struggle with accurately reproducing original colors and may require significant manual effort, our method allows for efficient restoration with reduced time requirements.","authors":["Saptarshi Neil Sinha","P. Julius Kuehn","Johannes Koppe","Arjan Kuijper","Michael Weinmann"],"url":"https://arxiv.org/abs/2505.22291"}
{"created":"2025-05-29","title":"Compensating for Data with Reasoning: Low-Resource Machine Translation with LLMs","abstract":"Large Language Models (LLMs) have demonstrated strong capabilities in multilingual machine translation, sometimes even outperforming traditional neural systems. However, previous research has highlighted the challenges of using LLMs, particularly with prompt engineering, for low-resource languages. In this work, we introduce Fragment-Shot Prompting, a novel in-context learning method that segments input and retrieves translation examples based on syntactic coverage, along with Pivoted Fragment-Shot, an extension that enables translation without direct parallel data. We evaluate these methods using GPT-3.5, GPT-4o, o1-mini, LLaMA-3.3, and DeepSeek-R1 for translation between Italian and two Ladin variants, revealing three key findings: (1) Fragment-Shot Prompting is effective for translating into and between the studied low-resource languages, with syntactic coverage positively correlating with translation quality; (2) Models with stronger reasoning abilities make more effective use of retrieved knowledge, generally produce better translations, and enable Pivoted Fragment-Shot to significantly improve translation quality between the Ladin variants; and (3) prompt engineering offers limited, if any, improvements when translating from a low-resource to a high-resource language, where zero-shot prompting already yields satisfactory results. We publicly release our code and the retrieval corpora.","authors":["Samuel Frontull","Thomas Str\\\"ohle"],"url":"https://arxiv.org/abs/2505.22293"}
{"created":"2025-05-29","title":"360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long Post-Training","abstract":"Adding sequence parallelism into LLaMA-Factory, we open-sourced 360-LLaMA-Factory at https://github.com/Qihoo360/360-LLaMA-Factory. 360-LLaMA-Factory has received wide recognition and used in models such as Light-R1 arXiv:2503.10460, TinyR1 arXiv:2503.04872, Kaggle AIMO math models and also in large companies' training frameworks. This technical report delves deeper into the different sequence parallel modes behind 360-LLaMA-Factory and discusses our implementation insights.","authors":["Haosheng Zou","Xiaowei Lv","Shousheng Jia","Xiangzheng Zhang"],"url":"https://arxiv.org/abs/2505.22296"}
{"created":"2025-05-29","title":"Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing","abstract":"Large language models (LLMs) exhibit impressive language capabilities but remain vulnerable to malicious prompts and jailbreaking attacks. Existing knowledge editing methods for LLM detoxification face two major challenges. First, they often rely on entity-specific localization, making them ineffective against adversarial inputs without explicit entities. Second, these methods suffer from over-editing, where detoxified models reject legitimate queries, compromising overall performance. In this paper, we propose ToxEdit, a toxicity-aware knowledge editing approach that dynamically detects toxic activation patterns during forward propagation. It then routes computations through adaptive inter-layer pathways to mitigate toxicity effectively. This design ensures precise toxicity mitigation while preserving LLMs' general capabilities. To more accurately assess over-editing, we also enhance the SafeEdit benchmark by incorporating instruction-following evaluation tasks. Experimental results on multiple LLMs demonstrate that our ToxEdit outperforms previous state-of-the-art methods in both detoxification performance and safeguarding general capabilities of LLMs.","authors":["Yifan Lu","Jing Li","Yigeng Zhou","Yihui Zhang","Wenya Wang","Xiucheng Li","Meishan Zhang","Fangming Liu","Jun Yu","Min Zhang"],"url":"https://arxiv.org/abs/2505.22298"}
{"created":"2025-05-29","title":"Logical Consistency is Vital: Neural-Symbolic Information Retrieval for Negative-Constraint Queries","abstract":"Information retrieval plays a crucial role in resource localization. Current dense retrievers retrieve the relevant documents within a corpus via embedding similarities, which compute similarities between dense vectors mainly depending on word co-occurrence between queries and documents, but overlook the real query intents.","authors":["Ganlin Xu","Zhoujia Zhang","Wangyi Mei","Jiaqing Liang","Weijia Lu","Xiaodong Zhang","Zhifei Yang","Xiaofeng Ma","Yanghua Xiao","Deqing Yang"],"url":"https://arxiv.org/abs/2505.22299"}
{"created":"2025-05-29","title":"Counting Small Induced Subgraphs: Scorpions Are Easy but Not Trivial","abstract":"We consider the parameterized problem $\\#$IndSub$(\\Phi)$ for fixed graph properties $\\Phi$: Given a graph $G$ and an integer $k$, this problem asks to count the number of induced $k$-vertex subgraphs satisfying $\\Phi$. D\\\"orfler et al. [Algorithmica 2022] and Roth et al. [SICOMP 2024] conjectured that $\\#$IndSub$(\\Phi)$ is $\\#$W[1]-hard for all non-meager properties $\\Phi$, i.e., properties that are nontrivial for infinitely many $k$. This conjecture has been confirmed for several restricted types of properties, including all hereditary properties [STOC 2022] and all edge-monotone properties [STOC 2024].","authors":["Radu Curticapean","Simon D\\\"oring","Daniel Neuen"],"url":"https://arxiv.org/abs/2505.22300"}
{"created":"2025-05-29","title":"Voice CMS: updating the knowledge base of a digital assistant through conversation","abstract":"In this study, we propose a solution based on a multi-agent LLM architecture and a voice user interface (VUI) designed to update the knowledge base of a digital assistant. Its usability is evaluated in comparison to a more traditional graphical content management system (CMS), with a focus on understanding the relationship between user preferences and the complexity of the information being provided. The findings demonstrate that, while the overall usability of the VUI is rated lower than the graphical interface, it is already preferred by users for less complex tasks. Furthermore, the quality of content entered through the VUI is comparable to that achieved with the graphical interface, even for highly complex tasks. Obtained qualitative results suggest that a hybrid interface combining the strengths of both approaches could address the key challenges identified during the experiment, such as reducing cognitive load through graphical feedback while maintaining the intuitive nature of voice-based interactions. This work highlights the potential of conversational interfaces as a viable and effective method for knowledge management in specific business contexts.","authors":["Grzegorz Wolny","Micha{\\l} Szczerbak"],"url":"https://arxiv.org/abs/2505.22303"}
{"created":"2025-05-29","title":"CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction","abstract":"Computer-aided design (CAD) is crucial in prototyping 3D objects through geometric instructions (i.e., CAD programs). In practical design workflows, designers often engage in time-consuming reviews and refinements of these prototypes by comparing them with reference images. To bridge this gap, we introduce the CAD review task to automatically detect and correct potential errors, ensuring consistency between the constructed 3D objects and reference images. However, recent advanced multimodal large language models (MLLMs) struggle to recognize multiple geometric components and perform spatial geometric operations within the CAD program, leading to inaccurate reviews. In this paper, we propose the CAD program repairer (ReCAD) framework to effectively detect program errors and provide helpful feedback on error correction. Additionally, we create a dataset, CADReview, consisting of over 20K program-image pairs, with diverse errors for the CAD review task. Extensive experiments demonstrate that our ReCAD significantly outperforms existing MLLMs, which shows great potential in design applications.","authors":["Jiali Chen","Xusen Hei","HongFei Liu","Yuancheng Wei","Zikun Deng","Jiayuan Xie","Yi Cai","Li Qing"],"url":"https://arxiv.org/abs/2505.22304"}
{"created":"2025-05-29","title":"IKIWISI: An Interactive Visual Pattern Generator for Evaluating the Reliability of Vision-Language Models Without Ground Truth","abstract":"We present IKIWISI (\"I Know It When I See It\"), an interactive visual pattern generator for assessing vision-language models in video object recognition when ground truth is unavailable. IKIWISI transforms model outputs into a binary heatmap where green cells indicate object presence and red cells indicate object absence. This visualization leverages humans' innate pattern recognition abilities to evaluate model reliability. IKIWISI introduces \"spy objects\": adversarial instances users know are absent, to discern models hallucinating on nonexistent items. The tool functions as a cognitive audit mechanism, surfacing mismatches between human and machine perception by visualizing where models diverge from human understanding.","authors":["Md Touhidul Islam","Imran Kabir","Md Alimoor Reza","Syed Masum Billah"],"url":"https://arxiv.org/abs/2505.22305"}
{"created":"2025-05-29","title":"Versatile Cardiovascular Signal Generation with a Unified Diffusion Transformer","abstract":"Cardiovascular signals such as photoplethysmography (PPG), electrocardiography (ECG), and blood pressure (BP) are inherently correlated and complementary, together reflecting the health of cardiovascular system. However, their joint utilization in real-time monitoring is severely limited by diverse acquisition challenges from noisy wearable recordings to burdened invasive procedures. Here we propose UniCardio, a multi-modal diffusion transformer that reconstructs low-quality signals and synthesizes unrecorded signals in a unified generative framework. Its key innovations include a specialized model architecture to manage the signal modalities involved in generation tasks and a continual learning paradigm to incorporate varying modality combinations. By exploiting the complementary nature of cardiovascular signals, UniCardio clearly outperforms recent task-specific baselines in signal denoising, imputation, and translation. The generated signals match the performance of ground-truth signals in detecting abnormal health conditions and estimating vital signs, even in unseen domains, while ensuring interpretability for human experts. These advantages position UniCardio as a promising avenue for advancing AI-assisted healthcare.","authors":["Zehua Chen","Yuyang Miao","Liyuan Wang","Luyun Fan","Danilo P. Mandic","Jun Zhu"],"url":"https://arxiv.org/abs/2505.22306"}
{"created":"2025-05-29","title":"On data usage and predictive behavior of data-driven predictive control with 1-norm regularization","abstract":"We investigate the data usage and predictive behavior of data-driven predictive control (DPC) with 1-norm regularization. Our analysis enables the offline removal of unused data and facilitates a comparison between the identified symmetric structure and data usage against prior knowledge of the true system. This comparison helps assess the suitability of the DPC scheme for effective control.","authors":["Manuel Kl\\\"adtke","Moritz Schulze Darup"],"url":"https://arxiv.org/abs/2505.22307"}
{"created":"2025-05-29","title":"Transformers Pretrained on Procedural Data Contain Modular Structures for Algorithmic Reasoning","abstract":"Pretraining on large, semantically rich datasets is key for developing language models. Surprisingly, recent studies have shown that even synthetic data, generated procedurally through simple semantic-free algorithms, can yield some of the same benefits as natural language pretraining. It is unclear what specific capabilities such simple synthetic data instils in a model, where these capabilities reside in the architecture, and how they manifest within its weights. In this short paper, we identify several beneficial forms of procedural data, together with specific algorithmic reasoning skills that improve in small transformers. Our core finding is that different procedural rules instil distinct but complementary inductive structures in the model. With extensive ablations and partial-transfer experiments, we discover that these structures reside in different parts of the model. Attention layers often carry the most transferable information, but some pretraining rules impart useful structure to MLP blocks instead. Most interestingly, the structures induced by multiple rules can be composed to jointly reinforce multiple capabilities. These results suggest an exciting possibility of disentangling the acquisition of knowledge from reasoning in language models, with the goal of improving their robustness and data efficiency.","authors":["Zachary Shinnick","Liangze Jiang","Hemanth Saratchandran","Anton van den Hengel","Damien Teney"],"url":"https://arxiv.org/abs/2505.22308"}
{"created":"2025-05-29","title":"From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization","abstract":"Recent unlearning methods for LLMs are vulnerable to relearning attacks: knowledge believed-to-be-unlearned re-emerges by fine-tuning on a small set of (even seemingly-unrelated) examples. We study this phenomenon in a controlled setting for example-level unlearning in vision classifiers. We make the surprising discovery that forget-set accuracy can recover from around 50% post-unlearning to nearly 100% with fine-tuning on just the retain set -- i.e., zero examples of the forget set. We observe this effect across a wide variety of unlearning methods, whereas for a model retrained from scratch excluding the forget set (gold standard), the accuracy remains at 50%. We observe that resistance to relearning attacks can be predicted by weight-space properties, specifically, $L_2$-distance and linear mode connectivity between the original and the unlearned model. Leveraging this insight, we propose a new class of methods that achieve state-of-the-art resistance to relearning attacks.","authors":["Shoaib Ahmed Siddiqui","Adrian Weller","David Krueger","Gintare Karolina Dziugaite","Michael Curtis Mozer","Eleni Triantafillou"],"url":"https://arxiv.org/abs/2505.22310"}
{"created":"2025-05-29","title":"From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications","abstract":"With the advent of 6G communications, intelligent communication systems face multiple challenges, including constrained perception and response capabilities, limited scalability, and low adaptability in dynamic environments. This tutorial provides a systematic introduction to the principles, design, and applications of Large Artificial Intelligence Models (LAMs) and Agentic AI technologies in intelligent communication systems, aiming to offer researchers a comprehensive overview of cutting-edge technologies and practical guidance. First, we outline the background of 6G communications, review the technological evolution from LAMs to Agentic AI, and clarify the tutorial's motivation and main contributions. Subsequently, we present a comprehensive review of the key components required for constructing LAMs. We further categorize LAMs and analyze their applicability, covering Large Language Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models (LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a LAM-centric design paradigm tailored for communications, encompassing dataset construction and both internal and external learning approaches. Building upon this, we develop an LAM-based Agentic AI system for intelligent communications, clarifying its core components such as planners, knowledge bases, tools, and memory modules, as well as its interaction mechanisms. We also introduce a multi-agent framework with data retrieval, collaborative planning, and reflective evaluation for 6G. Subsequently, we provide a detailed overview of the applications of LAMs and Agentic AI in communication scenarios. Finally, we summarize the research challenges and future directions in current studies, aiming to support the development of efficient, secure, and sustainable next-generation intelligent communication systems.","authors":["Feibo Jiang","Cunhua Pan","Li Dong","Kezhi Wang","Octavia A. Dobre","Merouane Debbah"],"url":"https://arxiv.org/abs/2505.22311"}
{"created":"2025-05-29","title":"Skywork Open Reasoner 1 Technical Report","abstract":"The success of DeepSeek-R1 underscores the significant role of reinforcement learning (RL) in enhancing the reasoning capabilities of large language models (LLMs). In this work, we present Skywork-OR1, an effective and scalable RL implementation for long Chain-of-Thought (CoT) models. Building on the DeepSeek-R1-Distill model series, our RL approach achieves notable performance gains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench from 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%) for the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and Qwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable results on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models demonstrate competitive reasoning capabilities among models of similar size. We perform comprehensive ablation studies on the core components of our training pipeline to validate their effectiveness. Additionally, we thoroughly investigate the phenomenon of entropy collapse, identify key factors affecting entropy dynamics, and demonstrate that mitigating premature entropy collapse is critical for improved test performance. To support community research, we fully open-source our model weights, training code, and training datasets.","authors":["Jujie He","Jiacai Liu","Chris Yuhao Liu","Rui Yan","Chaojie Wang","Peng Cheng","Xiaoyu Zhang","Fuxiang Zhang","Jiacheng Xu","Wei Shen","Siyuan Li","Liang Zeng","Tianwen Wei","Cheng Cheng","Bo An","Yang Liu","Yahui Zhou"],"url":"https://arxiv.org/abs/2505.22312"}
{"created":"2025-05-29","title":"Rethinking BPS: A Utility-Based Evaluation Framework","abstract":"Business process simulation (BPS) is a key tool for analyzing and optimizing organizational workflows, supporting decision-making by estimating the impact of process changes. The reliability of such estimates depends on the ability of a BPS model to accurately mimic the process under analysis, making rigorous accuracy evaluation essential. However, the state-of-the-art approach to evaluating BPS models has two key limitations. First, it treats simulation as a forecasting problem, testing whether models can predict unseen future events. This fails to assess how well a model captures the as-is process, particularly when process behavior changes from train to test period. Thus, it becomes difficult to determine whether poor results stem from an inaccurate model or the inherent complexity of the data, such as unpredictable drift. Second, the evaluation approach strongly relies on Earth Mover's Distance-based metrics, which can obscure temporal patterns and thus yield misleading conclusions about simulation quality. To address these issues, we propose a novel framework that evaluates simulation quality based on its ability to generate representative process behavior. Instead of comparing simulated logs to future real-world executions, we evaluate whether predictive process monitoring models trained on simulated data perform comparably to those trained on real data for downstream analysis tasks. Empirical results show that our framework not only helps identify sources of discrepancies but also distinguishes between model accuracy and data complexity, offering a more meaningful way to assess BPS quality.","authors":["Konrad \\\"Ozdemir","Lukas Kirchdorfer","Keyvan Amiri Elyasi","Han van der Aa","Heiner Stuckenschmidt"],"url":"https://arxiv.org/abs/2505.22316"}
{"created":"2025-05-29","title":"If Pigs Could Fly... Can LLMs Logically Reason Through Counterfactuals?","abstract":"Large Language Models (LLMs) demonstrate impressive reasoning capabilities in familiar contexts, but struggle when the context conflicts with their parametric knowledge. To investigate this phenomenon, we introduce CounterLogic, a dataset containing 1,800 examples across 9 logical schemas, explicitly designed to evaluate logical reasoning through counterfactual (hypothetical knowledge-conflicting) scenarios. Our systematic evaluation of 11 LLMs across 6 different datasets reveals a consistent performance degradation, with accuracies dropping by 27% on average when reasoning through counterfactual information. We propose Self-Segregate, a prompting method enabling metacognitive awareness (explicitly identifying knowledge conflicts) before reasoning. Our method dramatically narrows the average performance gaps from 27% to just 11%, while significantly increasing the overall accuracy (+7.5%). We discuss the implications of these findings and draw parallels to human cognitive processes, particularly on how humans disambiguate conflicting information during reasoning tasks. Our findings offer practical insights for understanding and enhancing LLMs reasoning capabilities in real-world applications, especially where models must logically reason independently of their factual knowledge.","authors":["Ishwar B Balappanawar","Vamshi Krishna Bonagiri","Anish R Joishy","Manas Gaur","Krishnaprasad Thirunarayan","Ponnurangam Kumaraguru"],"url":"https://arxiv.org/abs/2505.22318"}
{"created":"2025-05-29","title":"Chain-of-Thought for Large Language Model-empowered Wireless Communications","abstract":"Recent advances in large language models (LLMs) have opened new possibilities for automated reasoning and decision-making in wireless networks. However, applying LLMs to wireless communications presents challenges such as limited capability in handling complex logic, generalization, and reasoning. Chain-of-Thought (CoT) prompting, which guides LLMs to generate explicit intermediate reasoning steps, has been shown to significantly improve LLM performance on complex tasks. Inspired by this, this paper explores the application potential of CoT-enhanced LLMs in wireless communications. Specifically, we first review the fundamental theory of CoT and summarize various types of CoT. We then survey key CoT and LLM techniques relevant to wireless communication and networking. Moreover, we introduce a multi-layer intent-driven CoT framework that bridges high-level user intent expressed in natural language with concrete wireless control actions. Our proposed framework sequentially parses and clusters intent, selects appropriate CoT reasoning modules via reinforcement learning, then generates interpretable control policies for system configuration. Using the unmanned aerial vehicle (UAV) network as a case study, we demonstrate that the proposed framework significantly outperforms a non-CoT baseline in both communication performance and quality of generated reasoning.","authors":["Xudong Wang","Jian Zhu","Ruichen Zhang","Lei Feng","Dusit Niyato","Jiacheng Wang","Hongyang Du","Shiwen Mao","Zhu Han"],"url":"https://arxiv.org/abs/2505.22320"}
{"created":"2025-05-29","title":"A Closer Look on Memorization in Tabular Diffusion Model: A Data-Centric Perspective","abstract":"Diffusion models have shown strong performance in generating high-quality tabular data, but they carry privacy risks by reproducing exact training samples. While prior work focuses on dataset-level augmentation to reduce memorization, little is known about which individual samples contribute most. We present the first data-centric study of memorization dynamics in tabular diffusion models. We quantify memorization for each real sample based on how many generated samples are flagged as replicas, using a relative distance ratio. Our empirical analysis reveals a heavy-tailed distribution of memorization counts: a small subset of samples contributes disproportionately to leakage, confirmed via sample-removal experiments. To understand this, we divide real samples into top- and non-top-memorized groups and analyze their training-time behaviors. We track when each sample is first memorized and monitor per-epoch memorization intensity (AUC). Memorized samples are memorized slightly earlier and show stronger signals in early training. Based on these insights, we propose DynamicCut, a two-stage, model-agnostic mitigation method: (a) rank samples by epoch-wise intensity, (b) prune a tunable top fraction, and (c) retrain on the filtered dataset. Across multiple tabular datasets and models, DynamicCut reduces memorization with minimal impact on data diversity and downstream performance. It also complements augmentation-based defenses. Furthermore, DynamicCut enables cross-model transferability: high-ranked samples identified from one model (e.g., a diffusion model) are also effective for reducing memorization when removed from others, such as GANs and VAEs.","authors":["Zhengyu Fang","Zhimeng Jiang","Huiyuan Chen","Xiaoge Zhang","Kaiyu Tang","Xiao Li","Jing Li"],"url":"https://arxiv.org/abs/2505.22322"}
{"created":"2025-05-29","title":"Advancing Expert Specialization for Better MoE","abstract":"Mixture-of-Experts (MoE) models enable efficient scaling of large language models (LLMs) by activating only a subset of experts per input. However, we observe that the commonly used auxiliary load balancing loss often leads to expert overlap and overly uniform routing, which hinders expert specialization and degrades overall performance during post-training. To address this, we propose a simple yet effective solution that introduces two complementary objectives: (1) an orthogonality loss to encourage experts to process distinct types of tokens, and (2) a variance loss to encourage more discriminative routing decisions. Gradient-level analysis demonstrates that these objectives are compatible with the existing auxiliary loss and contribute to optimizing the training process. Experimental results over various model architectures and across multiple benchmarks show that our method significantly enhances expert specialization. Notably, our method improves classic MoE baselines with auxiliary loss by up to 23.79%, while also maintaining load balancing in downstream tasks, without any architectural modifications or additional components. We will release our code to contribute to the community.","authors":["Hongcan Guo","Haolang Lu","Guoshun Nan","Bolun Chu","Jialin Zhuang","Yuan Yang","Wenhao Che","Sicong Leng","Qimei Cui","Xudong Jiang"],"url":"https://arxiv.org/abs/2505.22323"}
{"created":"2025-05-29","title":"NLP for Social Good: A Survey of Challenges, Opportunities, and Responsible Deployment","abstract":"Recent advancements in large language models (LLMs) have unlocked unprecedented possibilities across a range of applications. However, as a community, we believe that the field of Natural Language Processing (NLP) has a growing need to approach deployment with greater intentionality and responsibility. In alignment with the broader vision of AI for Social Good (Toma\\v{s}ev et al., 2020), this paper examines the role of NLP in addressing pressing societal challenges. Through a cross-disciplinary analysis of social goals and emerging risks, we highlight promising research directions and outline challenges that must be addressed to ensure responsible and equitable progress in NLP4SG research.","authors":["Antonia Karamolegkou","Angana Borah","Eunjung Cho","Sagnik Ray Choudhury","Martina Galletti","Rajarshi Ghosh","Pranav Gupta","Oana Ignat","Priyanka Kargupta","Neema Kotonya","Hemank Lamba","Sun-Joo Lee","Arushi Mangla","Ishani Mondal","Deniz Nazarova","Poli Nemkova","Dina Pisarevskaya","Naquee Rizwan","Nazanin Sabri","Dominik Stammbach","Anna Steinberg","David Tom\\'as","Steven R Wilson","Bowen Yi","Jessica H Zhu","Arkaitz Zubiaga","Anders S{\\o}gaard","Alexander Fraser","Zhijing Jin","Rada Mihalcea","Joel R. Tetreault","Daryna Dementieva"],"url":"https://arxiv.org/abs/2505.22327"}
{"created":"2025-05-29","title":"A Multi-output Gaussian Process Regression with Negative Transfer Mitigation for Generating Boundary Test Scenarios of Multi-UAV Systems","abstract":"Adaptive sampling based on Gaussian process regression (GPR) has already been applied with considerable success to generate boundary test scenarios for multi-UAV systems (MUS). One of the key techniques in such researches is leveraging the accurate prediction of the MUS performance through GPR in different test scenarios. Due to the potential correlations among the multiple MUS performance metrics, current researches commonly utilize a multi-output GPR (MOGPR) to model the multiple performance metrics simultaneously. This approach can achieve a more accurate prediction, rather than modeling each metric individually. However, MOGPR still suffers from negative transfer. When the feature of one output variable is incorrectly learned by another, the models training process will be negatively affected, leading to a decline in prediction performance. To solve this problem, this paper proposes a novel adaptive regularization approach into the conventional MOGPR training process. Unlike existing regularization approaches for mitigating negative transfer in MOGPR, our method penalizes the inconsistencies among output-specific characteristic parameters using adaptively adjustable regularization weights. This mechanism helps each set of output parameters avoid local optima. Consequently, it yields simultaneous improvements in predictive accuracy across all outputs. Finally, we validate our approach on a numerical case and on a boundary test scenario generation case for a MUS multi-objectives search task.","authors":["Hanxu Jiang","Haiyue Yu","Xiaotong Xie","Qi Gao","Jiang Jiang","Jianbin Sun"],"url":"https://arxiv.org/abs/2505.22331"}
{"created":"2025-05-29","title":"Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start","abstract":"Recent advancements in large language models (LLMs) have demonstrated impressive chain-of-thought reasoning capabilities, with reinforcement learning (RL) playing a crucial role in this progress. While \"aha moment\" patterns--where models exhibit self-correction through reflection--are often attributed to emergent properties from RL, we first demonstrate that these patterns exist in multimodal LLMs (MLLMs) prior to RL training but may not necessarily correlate with improved reasoning performance. Building on these insights, we present a comprehensive study on enhancing multimodal reasoning through a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start with structured chain-of-thought reasoning patterns, followed by (2) reinforcement learning via GRPO to further refine these capabilities. Our extensive experiments show that this combined approach consistently outperforms both SFT-only and RL-only methods across challenging multimodal reasoning benchmarks. The resulting models achieve state-of-the-art performance among open-source MLLMs at both 3B and 7B scales, with our 7B model showing substantial improvements over base models (e.g., 66.3 %$\\rightarrow$73.4 % on MathVista, 62.9 %$\\rightarrow$70.4 % on We-Math) and our 3B model achieving performance competitive with several 7B models. Overall, this work provides practical guidance for building advanced multimodal reasoning models. Our code is available at https://github.com/waltonfuture/RL-with-Cold-Start.","authors":["Lai Wei","Yuting Li","Kaipeng Zheng","Chen Wang","Yue Wang","Linghe Kong","Lichao Sun","Weiran Huang"],"url":"https://arxiv.org/abs/2505.22334"}
{"created":"2025-05-29","title":"UP-SLAM: Adaptively Structured Gaussian SLAM with Uncertainty Prediction in Dynamic Environments","abstract":"Recent 3D Gaussian Splatting (3DGS) techniques for Visual Simultaneous Localization and Mapping (SLAM) have significantly progressed in tracking and high-fidelity mapping. However, their sequential optimization framework and sensitivity to dynamic objects limit real-time performance and robustness in real-world scenarios. We present UP-SLAM, a real-time RGB-D SLAM system for dynamic environments that decouples tracking and mapping through a parallelized framework. A probabilistic octree is employed to manage Gaussian primitives adaptively, enabling efficient initialization and pruning without hand-crafted thresholds. To robustly filter dynamic regions during tracking, we propose a training-free uncertainty estimator that fuses multi-modal residuals to estimate per-pixel motion uncertainty, achieving open-set dynamic object handling without reliance on semantic labels. Furthermore, a temporal encoder is designed to enhance rendering quality. Concurrently, low-dimensional features are efficiently transformed via a shallow multilayer perceptron to construct DINO features, which are then employed to enrich the Gaussian field and improve the robustness of uncertainty prediction. Extensive experiments on multiple challenging datasets suggest that UP-SLAM outperforms state-of-the-art methods in both localization accuracy (by 59.8%) and rendering quality (by 4.57 dB PSNR), while maintaining real-time performance and producing reusable, artifact-free static maps in dynamic environments.The project: https://aczheng-cai.github.io/up_slam.github.io/","authors":["Wancai Zheng","Linlin Ou","Jiajie He","Libo Zhou","Xinyi Yu","Yan Wei"],"url":"https://arxiv.org/abs/2505.22335"}
{"created":"2025-05-29","title":"Learning to Infer Parameterized Representations of Plants from 3D Scans","abstract":"Reconstructing faithfully the 3D architecture of plants from unstructured observations is a challenging task. Plants frequently contain numerous organs, organized in branching systems in more or less complex spatial networks, leading to specific computational issues due to self-occlusion or spatial proximity between organs. Existing works either consider inverse modeling where the aim is to recover the procedural rules that allow to simulate virtual plants, or focus on specific tasks such as segmentation or skeletonization. We propose a unified approach that, given a 3D scan of a plant, allows to infer a parameterized representation of the plant. This representation describes the plant's branching structure, contains parametric information for each plant organ, and can therefore be used directly in a variety of tasks. In this data-driven approach, we train a recursive neural network with virtual plants generated using an L-systems-based procedural model. After training, the network allows to infer a parametric tree-like representation based on an input 3D point cloud. Our method is applicable to any plant that can be represented as binary axial tree. We evaluate our approach on Chenopodium Album plants, using experiments on synthetic plants to show that our unified framework allows for different tasks including reconstruction, segmentation and skeletonization, while achieving results on-par with state-of-the-art for each task.","authors":["Samara Ghrer","Christophe Godin","Stefanie Wuhrer"],"url":"https://arxiv.org/abs/2505.22337"}
{"created":"2025-05-29","title":"Text2Grad: Reinforcement Learning from Natural Language Feedback","abstract":"Traditional RLHF optimizes language models with coarse, scalar rewards that mask the fine-grained reasons behind success or failure, leading to slow and opaque learning. Recent work augments RL with textual critiques through prompting or reflection, improving interpretability but leaving model parameters untouched. We introduce Text2Grad, a reinforcement-learning paradigm that turns free-form textual feedback into span-level gradients. Given human (or programmatic) critiques, Text2Grad aligns each feedback phrase with the relevant token spans, converts these alignments into differentiable reward signals, and performs gradient updates that directly refine the offending portions of the model's policy. This yields precise, feedback-conditioned adjustments instead of global nudges. Text2Grad is realized through three components: (1) a high-quality feedback-annotation pipeline that pairs critiques with token spans; (2) a fine-grained reward model that predicts span-level reward on answer while generating explanatory critiques; and (3) a span-level policy optimizer that back-propagates natural-language gradients. Across summarization, code generation, and question answering, Text2Grad consistently surpasses scalar-reward RL and prompt-only baselines, providing both higher task metrics and richer interpretability. Our results demonstrate that natural-language feedback, when converted to gradients, is a powerful signal for fine-grained policy optimization. The code for our method is available at https://github.com/microsoft/Text2Grad","authors":["Hanyang Wang","Lu Wang","Chaoyun Zhang","Tianjun Mao","Si Qin","Qingwei Lin","Saravan Rajmohan","Dongmei Zhang"],"url":"https://arxiv.org/abs/2505.22338"}
{"created":"2025-05-29","title":"Progressive Data Dropout: An Embarrassingly Simple Approach to Faster Training","abstract":"The success of the machine learning field has reliably depended on training on large datasets. While effective, this trend comes at an extraordinary cost. This is due to two deeply intertwined factors: the size of models and the size of datasets. While promising research efforts focus on reducing the size of models, the other half of the equation remains fairly mysterious. Indeed, it is surprising that the standard approach to training remains to iterate over and over, uniformly sampling the training dataset. In this paper we explore a series of alternative training paradigms that leverage insights from hard-data-mining and dropout, simple enough to implement and use that can become the new training standard. The proposed Progressive Data Dropout reduces the number of effective epochs to as little as 12.4% of the baseline. This savings actually do not come at any cost for accuracy. Surprisingly, the proposed method improves accuracy by up to 4.82%. Our approach requires no changes to model architecture or optimizer, and can be applied across standard training pipelines, thus posing an excellent opportunity for wide adoption. Code can be found here: https://github.com/bazyagami/LearningWithRevision","authors":["Shriram M S","Xinyue Hao","Shihao Hou","Yang Lu","Laura Sevilla-Lara","Anurag Arnab","Shreyank N Gowda"],"url":"https://arxiv.org/abs/2505.22342"}
{"created":"2025-05-29","title":"Task-Driven Implicit Representations for Automated Design of LiDAR Systems","abstract":"Imaging system design is a complex, time-consuming, and largely manual process; LiDAR design, ubiquitous in mobile devices, autonomous vehicles, and aerial imaging platforms, adds further complexity through unique spatial and temporal sampling requirements. In this work, we propose a framework for automated, task-driven LiDAR system design under arbitrary constraints. To achieve this, we represent LiDAR configurations in a continuous six-dimensional design space and learn task-specific implicit densities in this space via flow-based generative modeling. We then synthesize new LiDAR systems by modeling sensors as parametric distributions in 6D space and fitting these distributions to our learned implicit density using expectation-maximization, enabling efficient, constraint-aware LiDAR system design. We validate our method on diverse tasks in 3D vision, enabling automated LiDAR system design across real-world-inspired applications in face scanning, robotic tracking, and object detection.","authors":["Nikhil Behari","Aaron Young","Akshat Dave","Ramesh Raskar"],"url":"https://arxiv.org/abs/2505.22344"}
{"created":"2025-05-29","title":"A Systematic Approach for Studying How Topological Measurements Respond to Complex Networks Modifications","abstract":"Different types of graphs and complex networks have been characterized, analyzed, and modeled based on measurements of their respective topology. However, the available networks may constitute approximations of the original structure as a consequence of sampling incompleteness, noise, and/or error in the representation of that structure. Therefore, it becomes of particular interest to quantify how successive modifications may impact a set of adopted topological measurements, and how respectively undergone changes can be interrelated, which has been addressed in this paper by considering similarity networks and hierarchical clustering approaches. These studies are developed respectively to several topological measurements (accessibility, degree, hierarchical degree, clustering coefficient, betweenness centrality, assortativity, and average shortest path) calculated from complex networks of three main types (Erd\\H{o}s-R\\'enyi, Barab\\'asi-Albert, and geographical) with varying sizes or subjected to progressive edge removal or rewiring. The coincidence similarity index, which can implement particularly strict comparisons, is adopted for two main purposes: to quantify and visualize how the considered topological measurements respond to the considered network alterations and to represent hierarchically the relationships between the observed changes undergone by the considered topological measurements. Several results are reported and discussed, including the identification of three types of topological changes taking place as a consequence of the modifications. In addition, the changes observed for the Erd\\H{o}s-R\\'enyi and Barab\\'asi-Albert networks resulted mutually more similarly affected by topological changes than for the geometrical networks. The latter type of network has been identified to have more heterogeneous topological features than the other two types of networks.","authors":["Alexandre Benatti","Roberto M. Cesar Jr.","Luciano da F. Costa"],"url":"https://arxiv.org/abs/2505.22345"}
{"created":"2025-05-29","title":"State Constrained Model Reference Adaptive Control with Input Amplitude and Rate Limits","abstract":"This paper proposes a robust model reference adaptive controller (MRAC) for uncertain multi-input multi-output (MIMO) linear time-invariant (LTI) plants with user-defined constraints on the plant states, input amplitude, and input rate. The proposed two-layer barrier Lyapunov function (BLF)-based control design considers the input and the input rate as states that are constrained using two BLFs in the first layer, while another BLF in the second layer constrains the plant states. The adaptive control law ensures that the plant states, input amplitude, and input rate remain within the user-defined safe sets despite unmatched bounded disturbances. Sufficient conditions for the existence of a feasible control policy are also provided. To the best of the authors' knowledge, this is the first optimization-free method that imposes user-defined constraints on the state, input, and input rate and also provides verifiable feasibility conditions in the presence of parametric uncertainties and disturbances. Simulation results demonstrate the effectiveness of the proposed algorithm.","authors":["Poulomee Ghosh","Shubhendu Bhasin"],"url":"https://arxiv.org/abs/2505.22346"}
{"created":"2025-05-29","title":"ChatPD: An LLM-driven Paper-Dataset Networking System","abstract":"Scientific research heavily depends on suitable datasets for method validation, but existing academic platforms with dataset management like PapersWithCode suffer from inefficiencies in their manual workflow. To overcome this bottleneck, we present a system, called ChatPD, that utilizes Large Language Models (LLMs) to automate dataset information extraction from academic papers and construct a structured paper-dataset network. Our system consists of three key modules: \\textit{paper collection}, \\textit{dataset information extraction}, and \\textit{dataset entity resolution} to construct paper-dataset networks. Specifically, we propose a \\textit{Graph Completion and Inference} strategy to map dataset descriptions to their corresponding entities. Through extensive experiments, we demonstrate that ChatPD not only outperforms the existing platform PapersWithCode in dataset usage extraction but also achieves about 90\\% precision and recall in entity resolution tasks. Moreover, we have deployed ChatPD to continuously extract which datasets are used in papers, and provide a dataset discovery service, such as task-specific dataset queries and similar dataset recommendations. We open source ChatPD and the current paper-dataset network on this [GitHub repository]{https://github.com/ChatPD-web/ChatPD}.","authors":["Anjie Xu","Ruiqing Ding","Leye Wang"],"url":"https://arxiv.org/abs/2505.22349"}
{"created":"2025-05-29","title":"Finding $d$-Cuts in Probe $H$-Free Graphs","abstract":"For an integer $d\\geq 1$, the $d$-Cut problem is that of deciding whether a graph has an edge cut in which each vertex is adjacent to at most $d$ vertices on the opposite side of the cut. The $1$-Cut problem is the well-known Matching Cut problem. The $d$-Cut problem has been extensively studied for $H$-free graphs. We extend these results to the probe graph model, where we do not know all the edges of the input graph. For a graph $H$, a partitioned probe $H$-free graph $(G,P,N)$ consists of a graph $G=(V,E)$, together with a set $P\\subseteq V$ of probes and an independent set $N=V\\setminus P$ of non-probes such that we can change $G$ into an $H$-free graph by adding zero or more edges between vertices in $N$. For every graph $H$ and every integer $d\\geq 1$, we completely determine the complexity of $d$-Cut on partitioned probe $H$-free graphs.","authors":["Konrad K. Dabrowski","Tala Eagling-Vose","Matthew Johnson","Giacomo Paesani","Dani\\\"el Paulusma"],"url":"https://arxiv.org/abs/2505.22351"}
{"created":"2025-05-29","title":"State and Input Constrained Adaptive Tracking Control of Uncertain Euler-Lagrange Systems with Robustness and Feasibility Analysis","abstract":"This paper proposes an adaptive tracking controller for uncertain Euler-Lagrange (E-L) systems with user-defined state and input constraints in presence of bounded external disturbances. A barrier Lyapunov function (BLF) is employed for state constraint satisfaction, integrated with a saturated controller that ensures the control input remains within pre-specified bounds. To the best of the authors' knowledge, this is the first result on tracking control of state and input-constrained uncertain E-L systems that provides verifiable conditions for the existence of a feasible control policy. The efficacy of the proposed controller in terms of constraint satisfaction and tracking performance is demonstrated through simulation on a robotic manipulator system.","authors":["Poulomee Ghosh","Shubhendu Bhasin"],"url":"https://arxiv.org/abs/2505.22352"}
{"created":"2025-05-29","title":"VME: A Satellite Imagery Dataset and Benchmark for Detecting Vehicles in the Middle East and Beyond","abstract":"Detecting vehicles in satellite images is crucial for traffic management, urban planning, and disaster response. However, current models struggle with real-world diversity, particularly across different regions. This challenge is amplified by geographic bias in existing datasets, which often focus on specific areas and overlook regions like the Middle East. To address this gap, we present the Vehicles in the Middle East (VME) dataset, designed explicitly for vehicle detection in high-resolution satellite images from Middle Eastern countries. Sourced from Maxar, the VME dataset spans 54 cities across 12 countries, comprising over 4,000 image tiles and more than 100,000 vehicles, annotated using both manual and semi-automated methods. Additionally, we introduce the largest benchmark dataset for Car Detection in Satellite Imagery (CDSI), combining images from multiple sources to enhance global car detection. Our experiments demonstrate that models trained on existing datasets perform poorly on Middle Eastern images, while the VME dataset significantly improves detection accuracy in this region. Moreover, state-of-the-art models trained on CDSI achieve substantial improvements in global car detection.","authors":["Noora Al-Emadi","Ingmar Weber","Yin Yang","Ferda Ofli"],"url":"https://arxiv.org/abs/2505.22353"}
{"created":"2025-05-29","title":"LLMs Struggle to Reject False Presuppositions when Misinformation Stakes are High","abstract":"This paper examines how LLMs handle false presuppositions and whether certain linguistic factors influence their responses to falsely presupposed content. Presuppositions subtly introduce information as given, making them highly effective at embedding disputable or false information. This raises concerns about whether LLMs, like humans, may fail to detect and correct misleading assumptions introduced as false presuppositions, even when the stakes of misinformation are high. Using a systematic approach based on linguistic presupposition analysis, we investigate the conditions under which LLMs are more or less sensitive to adopt or reject false presuppositions. Focusing on political contexts, we examine how factors like linguistic construction, political party, and scenario probability impact the recognition of false presuppositions. We conduct experiments with a newly created dataset and examine three LLMs: OpenAI's GPT-4-o, Meta's LLama-3-8B, and MistralAI's Mistral-7B-v03. Our results show that the models struggle to recognize false presuppositions, with performance varying by condition. This study highlights that linguistic presupposition analysis is a valuable tool for uncovering the reinforcement of political misinformation in LLM responses.","authors":["Judith Sieker","Clara Lachenmaier","Sina Zarrie{\\ss}"],"url":"https://arxiv.org/abs/2505.22354"}
{"created":"2025-05-29","title":"Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning","abstract":"Parameter-Efficient Fine-Tuning (PEFT) methods achieve performance comparable to Full Fine-Tuning (FFT) while requiring significantly fewer computing resources, making it the go-to choice for researchers. We find that although PEFT can achieve competitive results on some benchmarks, its performance falls short of FFT in complex tasks, such as reasoning and instruction-based fine-tuning. In this paper, we compare the characteristics of PEFT and FFT in terms of representational capacity and robustness based on optimization theory. We theoretically demonstrate that PEFT is a strict subset of FFT. By providing theoretical upper bounds for PEFT, we show that the limited parameter space constrains the model's representational ability, making it more susceptible to perturbations. Experiments on 15 datasets encompassing classification, generation, reasoning, instruction fine-tuning tasks and 11 adversarial test sets validate our theories. We hope that these results spark further research beyond the realms of well established PEFT. The source code is in the anonymous Github repository\\footnote{https://github.com/misonsky/PEFTEval}.","authors":["Yongkang Liu","Xingle Xu","Ercong Nie","Zijing Wang","Shi Feng","Daling Wang","Qian Li","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2505.22355"}
{"created":"2025-05-29","title":"Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings","abstract":"Deploying machine learning models in safety-critical domains poses a key challenge: ensuring reliable model performance on downstream user data without access to ground truth labels for direct validation. We propose the suitability filter, a novel framework designed to detect performance deterioration by utilizing suitability signals -- model output features that are sensitive to covariate shifts and indicative of potential prediction errors. The suitability filter evaluates whether classifier accuracy on unlabeled user data shows significant degradation compared to the accuracy measured on the labeled test dataset. Specifically, it ensures that this degradation does not exceed a pre-specified margin, which represents the maximum acceptable drop in accuracy. To achieve reliable performance evaluation, we aggregate suitability signals for both test and user data and compare these empirical distributions using statistical hypothesis testing, thus providing insights into decision uncertainty. Our modular method adapts to various models and domains. Empirical evaluations across different classification tasks demonstrate that the suitability filter reliably detects performance deviations due to covariate shift. This enables proactive mitigation of potential failures in high-stakes applications.","authors":["Ang\\'eline Pouget","Mohammad Yaghini","Stephan Rabanser","Nicolas Papernot"],"url":"https://arxiv.org/abs/2505.22356"}
{"created":"2025-05-29","title":"Budget-Adaptive Adapter Tuning in Orthogonal Subspaces for Continual Learning in LLMs","abstract":"Large language models (LLMs) often suffer from catastrophic forgetting in continual learning (CL) scenarios, where performance on previously learned tasks degrades severely while training on sequentially arriving tasks. Although pioneering CL approaches using orthogonal subspaces can mitigate task interference, they typically employ fixed budget allocation, neglecting the varying complexity across tasks and layers. Besides, recent budget-adaptive tuning methods for LLMs often adopt multi-stage paradigms that decouple optimization and budget allocation. Such decoupling results in potential misalignment, which hinders those approaches' practical application in CL scenarios. To address these limitations, we propose OA-Adapter, a novel parameter-efficient approach for continual learning in LLMs that unifies dynamic budget adaptation with orthogonal subspace learning in a single end-to-end training stage. Specifically, OA-Adapter introduces a dynamic bottleneck dimension adaptation mechanism that simultaneously allocates an efficient parameter budget and optimizes task objectives without misalignment. To effectively preserve previously acquired knowledge while coordinating with the dynamic budget allocation, orthogonal constraints are applied specifically between the parameter subspace of the current task and the dynamically allocated parameter subspaces of historical tasks. Experimental results on continual learning benchmarks demonstrate that OA-Adapter outperforms state-of-the-art methods in both accuracy and parameter efficiency, achieving higher average accuracy while using 58.5% fewer parameters on the standard CL benchmark.","authors":["Zhiyi Wan","Wanrou Du","Liang Li","Miao Pan","Xiaoqi Qin"],"url":"https://arxiv.org/abs/2505.22358"}
{"created":"2025-05-29","title":"Multiclass Loss Geometry Matters for Generalization of Gradient Descent in Separable Classification","abstract":"We study the generalization performance of unregularized gradient methods for separable linear classification. While previous work mostly deal with the binary case, we focus on the multiclass setting with $k$ classes and establish novel population risk bounds for Gradient Descent for loss functions that decay to zero. In this setting, we show risk bounds that reveal that convergence rates are crucially influenced by the geometry of the loss template, as formalized by Wang and Scott (2024), rather than of the loss function itself. Particularly, we establish risk upper bounds that holds for any decay rate of the loss whose template is smooth with respect to the $p$-norm. In the case of exponentially decaying losses, our results indicates a contrast between the $p=\\infty$ case, where the risk exhibits a logarithmic dependence on $k$, and $p=2$ where the risk scales linearly with $k$. To establish this separation formally, we also prove a lower bound in the latter scenario, demonstrating that the polynomial dependence on $k$ is unavoidable. Central to our analysis is a novel bound on the Rademacher complexity of low-noise vector-valued linear predictors with a loss template smooth w.r.t.~general $p$-norms.","authors":["Matan Schliserman","Tomer Koren"],"url":"https://arxiv.org/abs/2505.22359"}
{"created":"2025-05-29","title":"Identity-Preserving Text-to-Image Generation via Dual-Level Feature Decoupling and Expert-Guided Fusion","abstract":"Recent advances in large-scale text-to-image generation models have led to a surge in subject-driven text-to-image generation, which aims to produce customized images that align with textual descriptions while preserving the identity of specific subjects. Despite significant progress, current methods struggle to disentangle identity-relevant information from identity-irrelevant details in the input images, resulting in overfitting or failure to maintain subject identity. In this work, we propose a novel framework that improves the separation of identity-related and identity-unrelated features and introduces an innovative feature fusion mechanism to improve the quality and text alignment of generated images. Our framework consists of two key components: an Implicit-Explicit foreground-background Decoupling Module (IEDM) and a Feature Fusion Module (FFM) based on a Mixture of Experts (MoE). IEDM combines learnable adapters for implicit decoupling at the feature level with inpainting techniques for explicit foreground-background separation at the image level. FFM dynamically integrates identity-irrelevant features with identity-related features, enabling refined feature representations even in cases of incomplete decoupling. In addition, we introduce three complementary loss functions to guide the decoupling process. Extensive experiments demonstrate the effectiveness of our proposed method in enhancing image generation quality, improving flexibility in scene adaptation, and increasing the diversity of generated outputs across various textual descriptions.","authors":["Kewen Chen","Xiaobin Hu","Wenqi Ren"],"url":"https://arxiv.org/abs/2505.22360"}
{"created":"2025-05-29","title":"Continuum-armed Bandit Optimization with Batch Pairwise Comparison Oracles","abstract":"This paper studies a bandit optimization problem where the goal is to maximize a function $f(x)$ over $T$ periods for some unknown strongly concave function $f$. We consider a new pairwise comparison oracle, where the decision-maker chooses a pair of actions $(x, x')$ for a consecutive number of periods and then obtains an estimate of $f(x)-f(x')$. We show that such a pairwise comparison oracle finds important applications to joint pricing and inventory replenishment problems and network revenue management. The challenge in this bandit optimization is twofold. First, the decision-maker not only needs to determine a pair of actions $(x, x')$ but also a stopping time $n$ (i.e., the number of queries based on $(x, x')$). Second, motivated by our inventory application, the estimate of the difference $f(x)-f(x')$ is biased, which is different from existing oracles in stochastic optimization literature. To address these challenges, we first introduce a discretization technique and local polynomial approximation to relate this problem to linear bandits. Then we developed a tournament successive elimination technique to localize the discretized cell and run an interactive batched version of LinUCB algorithm on cells. We establish regret bounds that are optimal up to poly-logarithmic factors. Furthermore, we apply our proposed algorithm and analytical framework to the two operations management problems and obtain results that improve state-of-the-art results in the existing literature.","authors":["Xiangyu Chang","Xi Chen","Yining Wang","Zhiyi Zeng"],"url":"https://arxiv.org/abs/2505.22361"}
{"created":"2025-05-29","title":"Directed Homophily-Aware Graph Neural Network","abstract":"Graph Neural Networks (GNNs) have achieved significant success in various learning tasks on graph-structured data. Nevertheless, most GNNs struggle to generalize to heterophilic neighborhoods. Additionally, many GNNs ignore the directional nature of real-world graphs, resulting in suboptimal performance on directed graphs with asymmetric structures. In this work, we propose Directed Homophily-aware Graph Neural Network (DHGNN), a novel framework that addresses these limitations by incorporating homophily-aware and direction-sensitive components. DHGNN employs a resettable gating mechanism to adaptively modulate message contributions based on homophily levels and informativeness, and a structure-aware noise-tolerant fusion module to effectively integrate node representations from the original and reverse directions. Extensive experiments on both homophilic and heterophilic directed graph datasets demonstrate that DHGNN outperforms state-of-the-art methods in node classification and link prediction. In particular, DHGNN improves over the best baseline by up to 15.07% in link prediction. Our analysis further shows that the gating mechanism captures directional homophily gaps and fluctuating homophily across layers, providing deeper insights into message-passing behavior on complex graph structures.","authors":["Aihu Zhang","Jiaxing Xu","Mengcheng Lan","Shili Xiang","Yiping Ke"],"url":"https://arxiv.org/abs/2505.22362"}
{"created":"2025-05-29","title":"Operator-Splitting Methods for Neuromorphic Circuit Simulation","abstract":"A novel splitting algorithm is proposed for the numerical simulation of neuromorphic circuits. The algorithm is grounded in the operator-theoretic concept of monotonicity, which bears both physical and algorithmic significance. The splitting exploits this correspondence to translate the circuit architecture into the algorithmic architecture. The paper illustrates the many advantages of the proposed operator-theoretic framework over conventional numerical integration for the simulation of multiscale hierarchical events that characterize neuromorphic behaviors.","authors":["Amir Shahhosseini","Thomas Chaffey","Rodolphe Sepulchre"],"url":"https://arxiv.org/abs/2505.22363"}
{"created":"2025-05-29","title":"EStacker: Explaining Battery-Less IoT System Performance with Energy Stacks","abstract":"The number of Internet of Things (IoT) devices is increasing exponentially, and it is environmentally and economically unsustainable to power all these devices with batteries. The key alternative is energy harvesting, but battery-less IoT systems require extensive evaluation to demonstrate that they are sufficiently performant across the full range of expected operating conditions. IoT developers thus need an evaluation platform that (i) ensures that each evaluated application and configuration is exposed to exactly the same energy environment and events, and (ii) provides a detailed account of what the application spends the harvested energy on. We therefore developed the EStacker evaluation platform which (i) provides fair and repeatable evaluation, and (ii) generates energy stacks. Energy stacks break down the total energy consumption of an application across hardware components and application activities, thereby explaining what the application specifically uses energy on. We augment EStacker with the ST-SP optimization which, in our experiments, reduces evaluation time by 6.3x on average while retaining the temporal behavior of the battery-less IoT system (average throughput error of 7.7%) by proportionally scaling time and power. We demonstrate the utility of EStacker through two case studies. In the first case study, we use energy stack profiles to identify a performance problem that, once addressed, improves performance by 3.3x. The second case study focuses on ST-SP, and we use it to explore the design space required to dimension the harvester and energy storage sizes of a smart parking application in roughly one week (7.7 days). Without ST-SP, sweeping this design space would have taken well over one month (41.7 days).","authors":["Lukas Liedtke","Per Gunnar Kjeldsberg","Frank Alexander Kraemer","Magnus Jahre"],"url":"https://arxiv.org/abs/2505.22366"}
{"created":"2025-05-29","title":"AgentDNS: A Root Domain Naming System for LLM Agents","abstract":"The rapid evolution of Large Language Model (LLM) agents has highlighted critical challenges in cross-vendor service discovery, interoperability, and communication. Existing protocols like model context protocol and agent-to-agent protocol have made significant strides in standardizing interoperability between agents and tools, as well as communication among multi-agents. However, there remains a lack of standardized protocols and solutions for service discovery across different agent and tool vendors. In this paper, we propose AgentDNS, a root domain naming and service discovery system designed to enable LLM agents to autonomously discover, resolve, and securely invoke third-party agent and tool services across organizational and technological boundaries. Inspired by the principles of the traditional DNS, AgentDNS introduces a structured mechanism for service registration, semantic service discovery, secure invocation, and unified billing. We detail the architecture, core functionalities, and use cases of AgentDNS, demonstrating its potential to streamline multi-agent collaboration in real-world scenarios. The source code will be published on https://github.com/agentdns.","authors":["Enfang Cui","Yujun Cheng","Rui She","Dan Liu","Zhiyuan Liang","Minxin Guo","Tianzheng Li","Qian Wei","Wenjuan Xing","Zhijie Zhong"],"url":"https://arxiv.org/abs/2505.22368"}
{"created":"2025-05-29","title":"SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting","abstract":"Continual Learning requires a model to learn multiple tasks in sequence while maintaining both stability:preserving knowledge from previously learned tasks, and plasticity:effectively learning new tasks. Gradient projection has emerged as an effective and popular paradigm in CL, where it partitions the gradient space of previously learned tasks into two orthogonal subspaces: a primary subspace and a minor subspace. New tasks are learned effectively within the minor subspace, thereby reducing interference with previously acquired knowledge. However, existing Gradient Projection methods struggle to achieve an optimal balance between plasticity and stability, as it is hard to appropriately partition the gradient space. In this work, we consider a continual learning paradigm based on Low-Rank Adaptation, which has gained considerable attention due to its efficiency and wide applicability, and propose a novel approach for continual learning, called SplitLoRA. We first provide a theoretical analysis of how subspace partitioning affects model stability and plasticity. Informed by this analysis, we then introduce an effective method that derives the optimal partition of the gradient space for previously learned tasks. This approach effectively balances stability and plasticity in continual learning. Experimental results on multiple datasets demonstrate that the proposed method achieves state-of-the-art performance.","authors":["Haomiao Qiu","Miao Zhang","Ziyue Qiao","Weili Guan","Min Zhang","Liqiang Nie"],"url":"https://arxiv.org/abs/2505.22370"}
{"created":"2025-05-29","title":"Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition","abstract":"This work presents Pangu Embedded, an efficient Large Language Model (LLM) reasoner developed on Ascend Neural Processing Units (NPUs), featuring flexible fast and slow thinking capabilities. Pangu Embedded addresses the significant computational costs and inference latency challenges prevalent in existing reasoning-optimized LLMs. We propose a two-stage training framework for its construction. In Stage 1, the model is finetuned via an iterative distillation process, incorporating inter-iteration model merging to effectively aggregate complementary knowledge. This is followed by reinforcement learning on Ascend clusters, optimized by a latency-tolerant scheduler that combines stale synchronous parallelism with prioritized data queues. The RL process is guided by a Multi-source Adaptive Reward System (MARS), which generates dynamic, task-specific reward signals using deterministic metrics and lightweight LLM evaluators for mathematics, coding, and general problem-solving tasks. Stage 2 introduces a dual-system framework, endowing Pangu Embedded with a \"fast\" mode for routine queries and a deeper \"slow\" mode for complex inference. This framework offers both manual mode switching for user control and an automatic, complexity-aware mode selection mechanism that dynamically allocates computational resources to balance latency and reasoning depth. Experimental results on benchmarks including AIME 2024, GPQA, and LiveCodeBench demonstrate that Pangu Embedded with 7B parameters, outperforms similar-size models like Qwen3-8B and GLM4-9B. It delivers rapid responses and state-of-the-art reasoning quality within a single, unified model architecture, highlighting a promising direction for developing powerful yet practically deployable LLM reasoners.","authors":["Hanting Chen","Yasheng Wang","Kai Han","Dong Li","Lin Li","Zhenni Bi","Jinpeng Li","Haoyu Wang","Fei Mi","Mingjian Zhu","Bin Wang","Kaikai Song","Yifei Fu","Xu He","Yu Luo","Chong Zhu","Quan He","Xueyu Wu","Wei He","Hailin Hu","Yehui Tang","Dacheng Tao","Xinghao Chen","Yunhe Wang","Other Contributors"],"url":"https://arxiv.org/abs/2505.22375"}
{"created":"2025-05-29","title":"Multiprecision computing for multistage fractional physics-informed neural networks","abstract":"Fractional physics-informed neural networks (fPINNs) have been successfully introduced in [Pang, Lu and Karniadakis, SIAM J. Sci. Comput. 41 (2019) A2603-A2626], which observe relative errors of $10^{-3} \\, \\sim \\, 10^{-4}$ for the subdiffusion equations. However their high-precision (multiprecision) numerical solution remains challenging, due to the limited regularity of the subdiffusion model caused by the nonlocal operator. To fill in the gap, we present the multistage fPINNs based on traditional multistage PINNs [Wang and Lai, J. Comput. Phys. 504 (2024) 112865]. Numerical experiments show that the relative errors improve to $10^{-7} \\, \\sim \\, 10^{-8}$ for the subdiffusion equations on uniform or nouniform meshes.","authors":["Na Xue","Minghua Chen"],"url":"https://arxiv.org/abs/2505.22377"}
{"created":"2025-05-29","title":"Current trends and future directions in event-based control","abstract":"The defining characteristic of event-based control is that feedback loops are only closed when indicated by a triggering condition that takes recent information about the system into account. This stands in contrast to periodic control where the feedback loop is closed periodically. Benefits of event-based control arise when sampling comes at a cost, which occurs, e.g., for Networked Control Systems or in other setups with resource constraints. A rapidly growing number of publications deals with event-based control. Nevertheless, some fundamental questions about event-based control are still unsolved. In this article, we provide an overview of current research trends in event-based control. We focus on results that aim for a better understanding of effects that occur in feedback loops with event-based control. Based on this summary, we identify important open directions for future research.","authors":["Michael Hertneck","David Meister","Frank Allg\\\"ower"],"url":"https://arxiv.org/abs/2505.22378"}
{"created":"2025-05-29","title":"A Divide-and-Conquer Approach for Modeling Arrival Times in Business Process Simulation","abstract":"Business Process Simulation (BPS) is a critical tool for analyzing and improving organizational processes by estimating the impact of process changes. A key component of BPS is the case-arrival model, which determines the pattern of new case entries into a process. Although accurate case-arrival modeling is essential for reliable simulations, as it influences waiting and overall cycle times, existing approaches often rely on oversimplified static distributions of inter-arrival times. These approaches fail to capture the dynamic and temporal complexities inherent in organizational environments, leading to less accurate and reliable outcomes. To address this limitation, we propose Auto Time Kernel Density Estimation (AT-KDE), a divide-and-conquer approach that models arrival times of processes by incorporating global dynamics, day-of-week variations, and intraday distributional changes, ensuring both precision and scalability. Experiments conducted across 20 diverse processes demonstrate that AT-KDE is far more accurate and robust than existing approaches while maintaining sensible execution time efficiency.","authors":["Lukas Kirchdorfer","Konrad \\\"Ozdemir","Stjepan Kusenic","Han van der Aa","Heiner Stuckenschmidt"],"url":"https://arxiv.org/abs/2505.22381"}
{"created":"2025-05-29","title":"Exact Algorithms and Lower Bounds for Forming Coalitions of Constrained Maximum Size","abstract":"Imagine we want to split a group of agents into teams in the most \\emph{efficient} way, considering that each agent has their own preferences about their teammates. This scenario is modeled by the extensively studied \\textsc{Coalition Formation} problem. Here, we study a version of this problem where each team must additionally be of bounded size.","authors":["Foivos Fioravantes","Harmender Gahlawat","Nikolaos Melissinos"],"url":"https://arxiv.org/abs/2505.22384"}
{"created":"2025-05-29","title":"DAM: Domain-Aware Module for Multi-Domain Dataset Condensation","abstract":"Dataset Condensation (DC) has emerged as a promising solution to mitigate the computational and storage burdens associated with training deep learning models. However, existing DC methods largely overlook the multi-domain nature of modern datasets, which are increasingly composed of heterogeneous images spanning multiple domains. In this paper, we extend DC and introduce Multi-Domain Dataset Condensation (MDDC), which aims to condense data that generalizes across both single-domain and multi-domain settings. To this end, we propose the Domain-Aware Module (DAM), a training-time module that embeds domain-related features into each synthetic image via learnable spatial masks. As explicit domain labels are mostly unavailable in real-world datasets, we employ frequency-based pseudo-domain labeling, which leverages low-frequency amplitude statistics. DAM is only active during the condensation process, thus preserving the same images per class (IPC) with prior methods. Experiments show that DAM consistently improves in-domain, out-of-domain, and cross-architecture performance over baseline dataset condensation methods.","authors":["Jaehyun Choi","Gyojin Han","Dong-Jae Lee","Sunghyun Baek","Junmo Kim"],"url":"https://arxiv.org/abs/2505.22387"}
{"created":"2025-05-29","title":"Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning","abstract":"Continual Learning (CL) aims to enable models to continuously acquire new knowledge from a sequence of tasks with avoiding the forgetting of learned information. However, existing CL methods only rely on the parameters of the most recent task for inference, which makes them susceptible to catastrophic forgetting. Inspired by the recent success of model merging techniques, we propose \\textbf{Perturb-and-Merge (P\\&amp;M)}, a novel continual learning framework that integrates model merging into the CL paradigm to mitigate forgetting. Specifically, after training on each task, P\\&amp;M constructs a new model by forming a convex combination of the previous model and the newly trained task-specific model. Through theoretical analysis, we minimize the total loss increase across all tasks and derive an analytical solution for the optimal merging coefficient. To further improve the performance of the merged model, we observe that the degradation introduced during merging can be alleviated by a regularization term composed of the task vector and the Hessian matrix of the loss function. Interestingly, we show that this term can be efficiently approximated using second-order symmetric finite differences, and a stochastic perturbation strategy along the task vector direction is accordingly devised which incurs no additional forward or backward passes while providing an effective approximation of the regularization term. Finally, we combine P\\&amp;M with LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead. Our proposed approach achieves state-of-the-art performance on several continual learning benchmark datasets.","authors":["Haomiao Qiu","Miao Zhang","Ziyue Qiao","Liqiang Nie"],"url":"https://arxiv.org/abs/2505.22389"}
{"created":"2025-05-29","title":"Physics-Informed Distillation of Diffusion Models for PDE-Constrained Generation","abstract":"Modeling physical systems in a generative manner offers several advantages, including the ability to handle partial observations, generate diverse solutions, and address both forward and inverse problems. Recently, diffusion models have gained increasing attention in the modeling of physical systems, particularly those governed by partial differential equations (PDEs). However, diffusion models only access noisy data $\\boldsymbol{x}_t$ at intermediate steps, making it infeasible to directly enforce constraints on the clean sample $\\boldsymbol{x}_0$ at each noisy level. As a workaround, constraints are typically applied to the expectation of clean samples $\\mathbb{E}[\\boldsymbol{x}_0|\\boldsymbol{x}_t]$, which is estimated using the learned score network. However, imposing PDE constraints on the expectation does not strictly represent the one on the true clean data, known as Jensen's Gap. This gap creates a trade-off: enforcing PDE constraints may come at the cost of reduced accuracy in generative modeling. To address this, we propose a simple yet effective post-hoc distillation approach, where PDE constraints are not injected directly into the diffusion process, but instead enforced during a post-hoc distillation stage. We term our method as Physics-Informed Distillation of Diffusion Models (PIDDM). This distillation not only facilitates single-step generation with improved PDE satisfaction, but also support both forward and inverse problem solving and reconstruction from randomly partial observation. Extensive experiments across various PDE benchmarks demonstrate that PIDDM significantly improves PDE satisfaction over several recent and competitive baselines, such as PIDM, DiffusionPDE, and ECI-sampling, with less computation overhead. Our approach can shed light on more efficient and effective strategies for incorporating physical constraints into diffusion models.","authors":["Yi Zhang","Difan Zou"],"url":"https://arxiv.org/abs/2505.22391"}
{"created":"2025-05-29","title":"PacTure: Efficient PBR Texture Generation on Packed Views with Visual Autoregressive Models","abstract":"We present PacTure, a novel framework for generating physically-based rendering (PBR) material textures from an untextured 3D mesh, a text description, and an optional image prompt. Early 2D generation-based texturing approaches generate textures sequentially from different views, resulting in long inference times and globally inconsistent textures. More recent approaches adopt multi-view generation with cross-view attention to enhance global consistency, which, however, limits the resolution for each view. In response to these weaknesses, we first introduce view packing, a novel technique that significantly increases the effective resolution for each view during multi-view generation without imposing additional inference cost, by formulating the arrangement of multi-view maps as a 2D rectangle bin packing problem. In contrast to UV mapping, it preserves the spatial proximity essential for image generation and maintains full compatibility with current 2D generative models. To further reduce the inference cost, we enable fine-grained control and multi-domain generation within the next-scale prediction autoregressive framework to create an efficient multi-view multi-domain generative backbone. Extensive experiments show that PacTure outperforms state-of-the-art methods in both quality of generated PBR textures and efficiency in training and inference.","authors":["Fan Fei","Jiajun Tang","Fei-Peng Tian","Boxin Shi","Ping Tan"],"url":"https://arxiv.org/abs/2505.22394"}
{"created":"2025-05-29","title":"Zooming from Context to Cue: Hierarchical Preference Optimization for Multi-Image MLLMs","abstract":"Multi-modal Large Language Models (MLLMs) excel at single-image tasks but struggle with multi-image understanding due to cross-modal misalignment, leading to hallucinations (context omission, conflation, and misinterpretation). Existing methods using Direct Preference Optimization (DPO) constrain optimization to a solitary image reference within the input sequence, neglecting holistic context modeling. We propose Context-to-Cue Direct Preference Optimization (CcDPO), a multi-level preference optimization framework that enhances per-image perception in multi-image settings by zooming into visual clues -- from sequential context to local details. It features: (i) Context-Level Optimization : Re-evaluates cognitive biases underlying MLLMs' multi-image context comprehension and integrates a spectrum of low-cost global sequence preferences for bias mitigation. (ii) Needle-Level Optimization : Directs attention to fine-grained visual details through region-targeted visual prompts and multimodal preference supervision. To support scalable optimization, we also construct MultiScope-42k, an automatically generated dataset with high-quality multi-level preference pairs. Experiments show that CcDPO significantly reduces hallucinations and yields consistent performance gains across general single- and multi-image tasks.","authors":["Xudong Li","Mengdan Zhang","Peixian Chen","Xiawu Zheng","Yan Zhang","Jingyuan Zheng","Yunhang Shen","Ke Li","Chaoyou Fu","Xing Sun","Rongrong Ji"],"url":"https://arxiv.org/abs/2505.22396"}
{"created":"2025-05-29","title":"STDR: Spatio-Temporal Decoupling for Real-Time Dynamic Scene Rendering","abstract":"Although dynamic scene reconstruction has long been a fundamental challenge in 3D vision, the recent emergence of 3D Gaussian Splatting (3DGS) offers a promising direction by enabling high-quality, real-time rendering through explicit Gaussian primitives. However, existing 3DGS-based methods for dynamic reconstruction often suffer from \\textit{spatio-temporal incoherence} during initialization, where canonical Gaussians are constructed by aggregating observations from multiple frames without temporal distinction. This results in spatio-temporally entangled representations, making it difficult to model dynamic motion accurately. To overcome this limitation, we propose \\textbf{STDR} (Spatio-Temporal Decoupling for Real-time rendering), a plug-and-play module that learns spatio-temporal probability distributions for each Gaussian. STDR introduces a spatio-temporal mask, a separated deformation field, and a consistency regularization to jointly disentangle spatial and temporal patterns. Extensive experiments demonstrate that incorporating our module into existing 3DGS-based dynamic scene reconstruction frameworks leads to notable improvements in both reconstruction quality and spatio-temporal consistency across synthetic and real-world benchmarks.","authors":["Zehao Li","Hao Jiang","Yujun Cai","Jianing Chen","Baolong Bi","Shuqin Gao","Honglong Zhao","Yiwei Wang","Tianlu Mao","Zhaoqi Wang"],"url":"https://arxiv.org/abs/2505.22400"}
{"created":"2025-05-29","title":"Facial Age Estimation: A Research Roadmap for Technological and Legal Development and Deployment","abstract":"Automated facial age assessment systems operate in either estimation mode - predicting age based on facial traits, or verification mode - confirming a claimed age. These systems support access control to age-restricted goods, services, and content, and can be used in areas like e-commerce, social media, forensics, and refugee support. They may also personalise services in healthcare, finance, and advertising. While improving technological accuracy is essential, deployment must consider legal, ethical, sociological, alongside technological factors. This white paper reviews the current challenges in deploying such systems, outlines the relevant legal and regulatory landscape, and explores future research for fair, robust, and ethical age estimation technologies.","authors":["Richard Guest","Eva Lievens","Martin Sas","Elena Botoeva","Temitope Adeyemo","Valerie Verdoodt","Elora Fernandes","Chris Allgrove"],"url":"https://arxiv.org/abs/2505.22401"}
{"created":"2025-05-29","title":"Efficient Precision-Scalable Hardware for Microscaling (MX) Processing in Robotics Learning","abstract":"Autonomous robots require efficient on-device learning to adapt to new environments without cloud dependency. For this edge training, Microscaling (MX) data types offer a promising solution by combining integer and floating-point representations with shared exponents, reducing energy consumption while maintaining accuracy. However, the state-of-the-art continuous learning processor, namely Dacapo, faces limitations with its MXINT-only support and inefficient vector-based grouping during backpropagation. In this paper, we present, to the best of our knowledge, the first work that addresses these limitations with two key innovations: (1) a precision-scalable arithmetic unit that supports all six MX data types by exploiting sub-word parallelism and unified integer and floating-point processing; and (2) support for square shared exponent groups to enable efficient weight handling during backpropagation, removing storage redundancy and quantization overhead. We evaluate our design against Dacapo under iso-peak-throughput on four robotics workloads in TSMC 16nm FinFET technology at 500MHz, reaching a 25.6% area reduction, a 51% lower memory footprint, and 4x higher effective training throughput while achieving comparable energy-efficiency, enabling efficient robotics continual learning at the edge.","authors":["Stef Cuyckens","Xiaoling Yi","Nitish Satya Murthy","Chao Fang","Marian Verhelst"],"url":"https://arxiv.org/abs/2505.22404"}
{"created":"2025-05-29","title":"Self-Reflective Reinforcement Learning for Diffusion-based Image Reasoning Generation","abstract":"Diffusion models have recently demonstrated exceptional performance in image generation task. However, existing image generation methods still significantly suffer from the dilemma of image reasoning, especially in logic-centered image generation tasks. Inspired by the success of Chain of Thought (CoT) and Reinforcement Learning (RL) in LLMs, we propose SRRL, a self-reflective RL algorithm for diffusion models to achieve reasoning generation of logical images by performing reflection and iteration across generation trajectories. The intermediate samples in the denoising process carry noise, making accurate reward evaluation difficult. To address this challenge, SRRL treats the entire denoising trajectory as a CoT step with multi-round reflective denoising process and introduces condition guided forward process, which allows for reflective iteration between CoT steps. Through SRRL-based iterative diffusion training, we introduce image reasoning through CoT into generation tasks adhering to physical laws and unconventional physical phenomena for the first time. Notably, experimental results of case study exhibit that the superior performance of our SRRL algorithm even compared with GPT-4o. The project page is https://jadenpan0.github.io/srrl.github.io/.","authors":["Jiadong Pan","Zhiyuan Ma","Kaiyan Zhang","Ning Ding","Bowen Zhou"],"url":"https://arxiv.org/abs/2505.22407"}
{"created":"2025-05-29","title":"Frugal Incremental Generative Modeling using Variational Autoencoders","abstract":"Continual or incremental learning holds tremendous potential in deep learning with different challenges including catastrophic forgetting. The advent of powerful foundation and generative models has propelled this paradigm even further, making it one of the most viable solution to train these models. However, one of the persisting issues lies in the increasing volume of data particularly with replay-based methods. This growth introduces challenges with scalability since continuously expanding data becomes increasingly demanding as the number of tasks grows. In this paper, we attenuate this issue by devising a novel replay-free incremental learning model based on Variational Autoencoders (VAEs). The main contribution of this work includes (i) a novel incremental generative modelling, built upon a well designed multi-modal latent space, and also (ii) an orthogonality criterion that mitigates catastrophic forgetting of the learned VAEs. The proposed method considers two variants of these VAEs: static and dynamic with no (or at most a controlled) growth in the number of parameters. Extensive experiments show that our method is (at least) an order of magnitude more ``memory-frugal'' compared to the closely related works while achieving SOTA accuracy scores.","authors":["Victor Enescu","Hichem Sahbi"],"url":"https://arxiv.org/abs/2505.22408"}
{"created":"2025-05-29","title":"Faster Convolutions: Yates and Strassen Revisited","abstract":"Given two vectors $u,v \\in \\mathbb{Q}^D$ over a finite domain $D$ and a function $f : D\\times D\\to D$, the convolution problem asks to compute the vector $w \\in \\mathbb{Q}^D$ whose entries are defined by $w(d) = \\sum_{\\substack{x,y \\in D \\\\ f(x,y)=d}} u(x)v(y).$ In parameterized and exponential-time algorithms, convolutions on product domains are particularly prominent: Here, a finite domain $B$ and a function $h : B \\times B \\to B$ are fixed, and convolution is done over the product domain $D = B^k$, using the function $h^k :D \\times D\\to D$ that applies $h$ coordinate-wise to its input tuples.","authors":["Cornelius Brand","Radu Curticapean","Baitian Li","Kevin Pratt"],"url":"https://arxiv.org/abs/2505.22410"}
{"created":"2025-05-29","title":"Mitigating Overthinking in Large Reasoning Models via Manifold Steering","abstract":"Recent advances in Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in solving complex tasks such as mathematics and coding. However, these models frequently exhibit a phenomenon known as overthinking during inference, characterized by excessive validation loops and redundant deliberation, leading to substantial computational overheads. In this paper, we aim to mitigate overthinking by investigating the underlying mechanisms from the perspective of mechanistic interpretability. We first showcase that the tendency of overthinking can be effectively captured by a single direction in the model's activation space and the issue can be eased by intervening the activations along this direction. However, this efficacy soon reaches a plateau and even deteriorates as the intervention strength increases. We therefore systematically explore the activation space and find that the overthinking phenomenon is actually tied to a low-dimensional manifold, which indicates that the limited effect stems from the noises introduced by the high-dimensional steering direction. Based on this insight, we propose Manifold Steering, a novel approach that elegantly projects the steering direction onto the low-dimensional activation manifold given the theoretical approximation of the interference noise. Extensive experiments on DeepSeek-R1 distilled models validate that our method reduces output tokens by up to 71% while maintaining and even improving the accuracy on several mathematical benchmarks. Our method also exhibits robust cross-domain transferability, delivering consistent token reduction performance in code generation and knowledge-based QA tasks. Code is available at: https://github.com/Aries-iai/Manifold_Steering.","authors":["Yao Huang","Huanran Chen","Shouwei Ruan","Yichi Zhang","Xingxing Wei","Yinpeng Dong"],"url":"https://arxiv.org/abs/2505.22411"}
{"created":"2025-05-29","title":"ToPSen: Task-Oriented Priming and Sensory Alignment for Comparing Coding Strategies Between Sighted and Blind Programmers","abstract":"This paper examines how the coding strategies of sighted and blind programmers differ when working with audio feedback alone. The goal is to identify challenges in mixed-ability collaboration, particularly when sighted programmers work with blind peers or teach programming to blind students. To overcome limitations of traditional blindness simulation studies, we proposed Task-Oriented Priming and Sensory Alignment (ToPSen), a design framework that reframes sensory constraints as technical requirements rather than as a disability. Through a study of 12 blind and 12 sighted participants coding non-visually, we found that expert blind programmers maintain more accurate mental models and process more information in working memory than sighted programmers using ToPSen. Our analysis revealed that blind and sighted programmers process structural information differently, exposing gaps in current IDE designs. These insights inform our guidelines for improving the accessibility of programming tools and fostering effective mixed-ability collaboration.","authors":["Md Ehtesham-Ul-Haque","Syed Masum Billah"],"url":"https://arxiv.org/abs/2505.22414"}
{"created":"2025-05-29","title":"Neural Face Skinning for Mesh-agnostic Facial Expression Cloning","abstract":"Accurately retargeting facial expressions to a face mesh while enabling manipulation is a key challenge in facial animation retargeting. Recent deep-learning methods address this by encoding facial expressions into a global latent code, but they often fail to capture fine-grained details in local regions. While some methods improve local accuracy by transferring deformations locally, this often complicates overall control of the facial expression. To address this, we propose a method that combines the strengths of both global and local deformation models. Our approach enables intuitive control and detailed expression cloning across diverse face meshes, regardless of their underlying structures. The core idea is to localize the influence of the global latent code on the target mesh. Our model learns to predict skinning weights for each vertex of the target face mesh through indirect supervision from predefined segmentation labels. These predicted weights localize the global latent code, enabling precise and region-specific deformations even for meshes with unseen shapes. We supervise the latent code using Facial Action Coding System (FACS)-based blendshapes to ensure interpretability and allow straightforward editing of the generated animation. Through extensive experiments, we demonstrate improved performance over state-of-the-art methods in terms of expression fidelity, deformation transfer accuracy, and adaptability across diverse mesh structures.","authors":["Sihun Cha","Serin Yoon","Kwanggyoon Seo","Junyong Noh"],"url":"https://arxiv.org/abs/2505.22416"}
{"created":"2025-05-29","title":"AI Trust Reshaping Administrative Burdens: Understanding Trust-Burden Dynamics in LLM-Assisted Benefits Systems","abstract":"Supplemental Nutrition Assistance Program (SNAP) is an essential benefit support system provided by the US administration to 41 million federally determined low-income applicants. Through interviews with such applicants across a diverse set of experiences with the SNAP system, our findings reveal that new AI technologies like LLMs can alleviate traditional burdens but also introduce new burdens. We introduce new types of learning, compliance, and psychological costs that transform the administrative burden on applicants. We also identify how trust in AI across three dimensions--competence, integrity, and benevolence--is perceived to reduce administrative burdens, which may stem from unintended and untoward overt trust in the system. We discuss calibrating appropriate levels of user trust in LLM-based administrative systems, mitigating newly introduced burdens. In particular, our findings suggest that evidence-based information disclosure is necessary in benefits administration and propose directions for future research on trust-burden dynamics in AI-assisted administration systems.","authors":["Jeongwon Jo","He Zhang","Jie Cai","Nitesh Goyal"],"url":"https://arxiv.org/abs/2505.22418"}
{"created":"2025-05-29","title":"GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control","abstract":"Recent advancements in world models have revolutionized dynamic environment simulation, allowing systems to foresee future states and assess potential actions. In autonomous driving, these capabilities help vehicles anticipate the behavior of other road users, perform risk-aware planning, accelerate training in simulation, and adapt to novel scenarios, thereby enhancing safety and reliability. Current approaches exhibit deficiencies in maintaining robust 3D geometric consistency or accumulating artifacts during occlusion handling, both critical for reliable safety assessment in autonomous navigation tasks. To address this, we introduce GeoDrive, which explicitly integrates robust 3D geometry conditions into driving world models to enhance spatial understanding and action controllability. Specifically, we first extract a 3D representation from the input frame and then obtain its 2D rendering based on the user-specified ego-car trajectory. To enable dynamic modeling, we propose a dynamic editing module during training to enhance the renderings by editing the positions of the vehicles. Extensive experiments demonstrate that our method significantly outperforms existing models in both action accuracy and 3D spatial awareness, leading to more realistic, adaptable, and reliable scene modeling for safer autonomous driving. Additionally, our model can generalize to novel trajectories and offers interactive scene editing capabilities, such as object editing and object trajectory control.","authors":["Anthony Chen","Wenzhao Zheng","Yida Wang","Xueyang Zhang","Kun Zhan","Peng Jia","Kurt Keutzer","Shangbang Zhang"],"url":"https://arxiv.org/abs/2505.22421"}
{"created":"2025-05-29","title":"STaR-Bets: Sequential Target-Recalculating Bets for Tighter Confidence Intervals","abstract":"The construction of confidence intervals for the mean of a bounded random variable is a classical problem in statistics with numerous applications in machine learning and virtually all scientific fields. In particular, obtaining the tightest possible confidence intervals is vital every time the sampling of the random variables is expensive. The current state-of-the-art method to construct confidence intervals is by using betting algorithms. This is a very successful approach for deriving optimal confidence sequences, even matching the rate of law of iterated logarithms. However, in the fixed horizon setting, these approaches are either sub-optimal or based on heuristic solutions with strong empirical performance but without a finite-time guarantee. Hence, no betting-based algorithm guaranteeing the optimal $\\mathcal{O}(\\sqrt{\\frac{\\sigma^2\\log\\frac1\\delta}{n}})$ width of the confidence intervals are known. This work bridges this gap. We propose a betting-based algorithm to compute confidence intervals that empirically outperforms the competitors. Our betting strategy uses the optimal strategy in every step (in a certain sense), whereas the standard betting methods choose a constant strategy in advance. Leveraging this fact results in strict improvements even for classical concentration inequalities, such as the ones of Hoeffding or Bernstein. Moreover, we also prove that the width of our confidence intervals is optimal up to an $1+o(1)$ factor diminishing with $n$. The code is available on~https://github.com/vvoracek/STaR-bets-confidence-interval.","authors":["V\\'aclav Vor\\'a\\v{c}ek","Francesco Orabona"],"url":"https://arxiv.org/abs/2505.22422"}
{"created":"2025-05-29","title":"Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments","abstract":"With the rapid growth of IoT devices and their diverse workloads, container-based microservices deployed at edge nodes have become a lightweight and scalable solution. However, existing microservice scheduling algorithms often assume static resource availability, which is unrealistic when multiple containers are assigned to an edge node. Besides, containers suffer from cold-start inefficiencies during early-stage training in currently popular reinforcement learning (RL) algorithms. In this paper, we propose a hybrid learning framework that combines offline imitation learning (IL) with online Soft Actor-Critic (SAC) optimization to enable a cold-start-aware microservice scheduling with dynamic allocation for computing resources. We first formulate a delay-and-energy-aware scheduling problem and construct a rule-based expert to generate demonstration data for behavior cloning. Then, a GRU-enhanced policy network is designed in the policy network to extract the correlation among multiple decisions by separately encoding slow-evolving node states and fast-changing microservice features, and an action selection mechanism is given to speed up the convergence. Extensive experiments show that our method significantly accelerates convergence and achieves superior final performance. Compared with baselines, our algorithm improves the total objective by $50\\%$ and convergence speed by $70\\%$, and demonstrates the highest stability and robustness across various edge configurations.","authors":["Jingxi Lu","Wenhao Li","Jianxiong Guo","Xingjian Ding","Zhiqing Tang","Tian Wang","Weijia Jia"],"url":"https://arxiv.org/abs/2505.22424"}
{"created":"2025-05-29","title":"Scaling Reasoning without Attention","abstract":"Large language models (LLMs) have made significant advances in complex reasoning tasks, yet they remain bottlenecked by two core challenges: architectural inefficiency due to reliance on Transformers, and a lack of structured fine-tuning for high-difficulty domains. We introduce \\ourmodel, an attention-free language model that addresses both issues through architectural and data-centric innovations. Built on the state space dual (SSD) layers of Mamba-2, our model eliminates the need for self-attention and key-value caching, enabling fixed-memory, constant-time inference. To train it for complex reasoning, we propose a two-phase curriculum fine-tuning strategy based on the \\textsc{PromptCoT} synthesis paradigm, which generates pedagogically structured problems via abstract concept selection and rationale-guided generation. On benchmark evaluations, \\ourmodel-7B outperforms strong Transformer and hybrid models of comparable scale, and even surpasses the much larger Gemma3-27B by 2.6\\% on AIME 24, 0.6\\% on AIME 25, and 3.0\\% on Livecodebench. These results highlight the potential of state space models as efficient and scalable alternatives to attention-based architectures for high-capacity reasoning.","authors":["Xueliang Zhao","Wei Wu","Lingpeng Kong"],"url":"https://arxiv.org/abs/2505.22425"}
{"created":"2025-05-29","title":"RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network","abstract":"This paper presents a groundbreaking approach - the first online automatic geometric calibration method for radar and camera systems. Given the significant data sparsity and measurement uncertainty in radar height data, achieving automatic calibration during system operation has long been a challenge. To address the sparsity issue, we propose a Dual-Perspective representation that gathers features from both frontal and bird's-eye views. The frontal view contains rich but sensitive height information, whereas the bird's-eye view provides robust features against height uncertainty. We thereby propose a novel Selective Fusion Mechanism to identify and fuse reliable features from both perspectives, reducing the effect of height uncertainty. Moreover, for each view, we incorporate a Multi-Modal Cross-Attention Mechanism to explicitly find location correspondences through cross-modal matching. During the training phase, we also design a Noise-Resistant Matcher to provide better supervision and enhance the robustness of the matching mechanism against sparsity and height uncertainty. Our experimental results, tested on the nuScenes dataset, demonstrate that our method significantly outperforms previous radar-camera auto-calibration methods, as well as existing state-of-the-art LiDAR-camera calibration techniques, establishing a new benchmark for future research. The code is available at https://github.com/nycu-acm/RC-AutoCalib.","authors":["Van-Tin Luu","Yon-Lin Cai","Vu-Hoang Tran","Wei-Chen Chiu","Yi-Ting Chen","Ching-Chun Huang"],"url":"https://arxiv.org/abs/2505.22427"}
{"created":"2025-05-29","title":"Parental Collaboration and Closeness: Envisioning with New Couple Parents","abstract":"Couples often experience a decrease in closeness as they cope with the demands of parenthood. Existing technologies have supported parenting and parental collaboration. However, these technologies do not adequately support closeness in co-parenting. We use scenarios and design probes to brainstorm with 10 new parent couples to explore and envision possibilities for technologies to support closeness. We reported parents' current technology use for co-parenting and how participants considered and envisioned co-parenting technology for closeness, including information and task sharing, emotion awareness and disclosure, and fostering fun interaction. We discuss the potential technology has for fostering closeness in co-parenting by (1) fostering interdependence by supporting parental competence and (2) integrating positive emotions and experiences, such as validation and fun, in parenting. Based on our findings, we expand the design space of technology for closeness to include interdependence. We also expand the design space for co-parenting technology by integrating more positive emotions.","authors":["Ya-Fang Lin","Xiaotian Li","Wan-Hsuan Huang","Charan Pushpanathan Prabavathi","Jie Cai","John M. Carroll"],"url":"https://arxiv.org/abs/2505.22428"}
{"created":"2025-05-29","title":"Zero-Shot 3D Visual Grounding from Vision-Language Models","abstract":"3D Visual Grounding (3DVG) seeks to locate target objects in 3D scenes using natural language descriptions, enabling downstream applications such as augmented reality and robotics. Existing approaches typically rely on labeled 3D data and predefined categories, limiting scalability to open-world settings. We present SeeGround, a zero-shot 3DVG framework that leverages 2D Vision-Language Models (VLMs) to bypass the need for 3D-specific training. To bridge the modality gap, we introduce a hybrid input format that pairs query-aligned rendered views with spatially enriched textual descriptions. Our framework incorporates two core components: a Perspective Adaptation Module that dynamically selects optimal viewpoints based on the query, and a Fusion Alignment Module that integrates visual and spatial signals to enhance localization precision. Extensive evaluations on ScanRefer and Nr3D confirm that SeeGround achieves substantial improvements over existing zero-shot baselines -- outperforming them by 7.7% and 7.1%, respectively -- and even rivals fully supervised alternatives, demonstrating strong generalization under challenging conditions.","authors":["Rong Li","Shijie Li","Lingdong Kong","Xulei Yang","Junwei Liang"],"url":"https://arxiv.org/abs/2505.22429"}
{"created":"2025-05-29","title":"RAG-Zeval: Towards Robust and Interpretable Evaluation on RAG Responses through End-to-End Rule-Guided Reasoning","abstract":"Robust evaluation is critical for deploying trustworthy retrieval-augmented generation (RAG) systems. However, current LLM-based evaluation frameworks predominantly rely on directly prompting resource-intensive models with complex multi-stage prompts, underutilizing models' reasoning capabilities and introducing significant computational cost. In this paper, we present RAG-Zeval (RAG-Zero Evaluator), a novel end-to-end framework that formulates faithfulness and correctness evaluation as a rule-guided reasoning task. Our approach trains evaluators with reinforcement learning, facilitating compact models to generate comprehensive and sound assessments with detailed explanation in one-pass. We introduce a ranking-based outcome reward mechanism, using preference judgments rather than absolute scores, to address the challenge of obtaining precise pointwise reward signals. To this end, we synthesize the ranking references by generating quality-controlled responses with zero human annotation. Experiments demonstrate RAG-Zeval's superior performance, achieving the strongest correlation with human judgments and outperforming baselines that rely on LLMs with 10-100 times more parameters. Our approach also exhibits superior interpretability in response evaluation.","authors":["Kun Li","Yunxiang Li","Tianhua Zhang","Hongyin Luo","Xixin Wu","James Glass","Helen Meng"],"url":"https://arxiv.org/abs/2505.22430"}
{"created":"2025-05-29","title":"Distance Transform Guided Mixup for Alzheimer's Detection","abstract":"Alzheimer's detection efforts aim to develop accurate models for early disease diagnosis. Significant advances have been achieved with convolutional neural networks and vision transformer based approaches. However, medical datasets suffer heavily from class imbalance, variations in imaging protocols, and limited dataset diversity, which hinder model generalization. To overcome these challenges, this study focuses on single-domain generalization by extending the well-known mixup method. The key idea is to compute the distance transform of MRI scans, separate them spatially into multiple layers and then combine layers stemming from distinct samples to produce augmented images. The proposed approach generates diverse data while preserving the brain's structure. Experimental results show generalization performance improvement across both ADNI and AIBL datasets.","authors":["Zobia Batool","Huseyin Ozkan","Erchan Aptoula"],"url":"https://arxiv.org/abs/2505.22434"}
{"created":"2025-05-29","title":"Does Johnny Get the Message? Evaluating Cybersecurity Notifications for Everyday Users","abstract":"Due to the increasing presence of networked devices in everyday life, not only cybersecurity specialists but also end users benefit from security applications such as firewalls, vulnerability scanners, and intrusion detection systems. Recent approaches use large language models (LLMs) to rewrite brief, technical security alerts into intuitive language and suggest actionable measures, helping everyday users understand and respond appropriately to security risks. However, it remains an open question how well such alerts are explained to users. LLM outputs can also be hallucinated, inconsistent, or misleading. In this work, we introduce the Human-Centered Security Alert Evaluation Framework (HCSAEF). HCSAEF assesses LLM-generated cybersecurity notifications to support researchers who want to compare notifications generated for everyday users, improve them, or analyze the capabilities of different LLMs in explaining cybersecurity issues. We demonstrate HCSAEF through three use cases, which allow us to quantify the impact of prompt design, model selection, and output consistency. Our findings indicate that HCSAEF effectively differentiates generated notifications along dimensions such as intuitiveness, urgency, and correctness.","authors":["Victor J\\\"uttner","Erik Buchmann"],"url":"https://arxiv.org/abs/2505.22435"}
{"created":"2025-05-29","title":"Synonymous Variational Inference for Perceptual Image Compression","abstract":"Recent contributions of semantic information theory reveal the set-element relationship between semantic and syntactic information, represented as synonymous relationships. In this paper, we propose a synonymous variational inference (SVI) method based on this synonymity viewpoint to re-analyze the perceptual image compression problem. It takes perceptual similarity as a typical synonymous criterion to build an ideal synonymous set (Synset), and approximate the posterior of its latent synonymous representation with a parametric density by minimizing a partial semantic KL divergence. This analysis theoretically proves that the optimization direction of perception image compression follows a triple tradeoff that can cover the existing rate-distortion-perception schemes. Additionally, we introduce synonymous image compression (SIC), a new image compression scheme that corresponds to the analytical process of SVI, and implement a progressive SIC codec to fully leverage the model's capabilities. Experimental results demonstrate comparable rate-distortion-perception performance using a single progressive SIC codec, thus verifying the effectiveness of our proposed analysis method.","authors":["Zijian Liang","Kai Niu","Changshuo Wang","Jin Xu","Ping Zhang"],"url":"https://arxiv.org/abs/2505.22438"}
{"created":"2025-05-29","title":"Data-Driven Antenna Miniaturization: A Knowledge-Based System Integrating Quantum PSO and Predictive Machine Learning Models","abstract":"The rapid evolution of wireless technologies necessitates automated design frameworks to address antenna miniaturization and performance optimization within constrained development cycles. This study demonstrates a machine learning enhanced workflow integrating Quantum-Behaved Dynamic Particle Swarm Optimization (QDPSO) with ANSYS HFSS simulations to accelerate antenna design. The QDPSO algorithm autonomously optimized loop dimensions in 11.53 seconds, achieving a resonance frequency of 1.4208 GHz a 12.7 percent reduction compared to conventional 1.60 GHz designs. Machine learning models (SVM, Random Forest, XGBoost, and Stacked ensembles) predicted resonance frequencies in 0.75 seconds using 936 simulation datasets, with stacked models showing superior training accuracy (R2=0.9825) and SVM demonstrating optimal validation performance (R2=0.7197). The complete design cycle, encompassing optimization, prediction, and ANSYS validation, required 12.42 minutes on standard desktop hardware (Intel i5-8500, 16GB RAM), contrasting sharply with the 50-hour benchmark of PSADEA-based approaches. This 240 times of acceleration eliminates traditional trial-and-error methods that often extend beyond seven expert-led days. The system enables precise specifications of performance targets with automated generation of fabrication-ready parameters, particularly benefiting compact consumer devices requiring rapid frequency tuning. By bridging AI-driven optimization with CAD validation, this framework reduces engineering workloads while ensuring production-ready designs, establishing a scalable paradigm for next-generation RF systems in 6G and IoT applications.","authors":["Khan Masood Parvez","Sk Md Abidar Rahaman","Ali Shiri Sichani"],"url":"https://arxiv.org/abs/2505.22440"}
{"created":"2025-05-29","title":"Can NeRFs See without Cameras?","abstract":"Neural Radiance Fields (NeRFs) have been remarkably successful at synthesizing novel views of 3D scenes by optimizing a volumetric scene function. This scene function models how optical rays bring color information from a 3D object to the camera pixels. Radio frequency (RF) or audio signals can also be viewed as a vehicle for delivering information about the environment to a sensor. However, unlike camera pixels, an RF/audio sensor receives a mixture of signals that contain many environmental reflections (also called \"multipath\"). Is it still possible to infer the environment using such multipath signals? We show that with redesign, NeRFs can be taught to learn from multipath signals, and thereby \"see\" the environment. As a grounding application, we aim to infer the indoor floorplan of a home from sparse WiFi measurements made at multiple locations inside the home. Although a difficult inverse problem, our implicitly learnt floorplans look promising, and enables forward applications, such as indoor signal prediction and basic ray tracing.","authors":["Chaitanya Amballa","Sattwik Basu","Yu-Lin Wei","Zhijian Yang","Mehmet Ergezer","Romit Roy Choudhury"],"url":"https://arxiv.org/abs/2505.22441"}
{"created":"2025-05-29","title":"SOReL and TOReL: Two Methods for Fully Offline Reinforcement Learning","abstract":"Sample efficiency remains a major obstacle for real world adoption of reinforcement learning (RL): success has been limited to settings where simulators provide access to essentially unlimited environment interactions, which in reality are typically costly or dangerous to obtain. Offline RL in principle offers a solution by exploiting offline data to learn a near-optimal policy before deployment. In practice, however, current offline RL methods rely on extensive online interactions for hyperparameter tuning, and have no reliable bound on their initial online performance. To address these two issues, we introduce two algorithms. Firstly, SOReL: an algorithm for safe offline reinforcement learning. Using only offline data, our Bayesian approach infers a posterior over environment dynamics to obtain a reliable estimate of the online performance via the posterior predictive uncertainty. Crucially, all hyperparameters are also tuned fully offline. Secondly, we introduce TOReL: a tuning for offline reinforcement learning algorithm that extends our information rate based offline hyperparameter tuning methods to general offline RL approaches. Our empirical evaluation confirms SOReL's ability to accurately estimate regret in the Bayesian setting whilst TOReL's offline hyperparameter tuning achieves competitive performance with the best online hyperparameter tuning methods using only offline data. Thus, SOReL and TOReL make a significant step towards safe and reliable offline RL, unlocking the potential for RL in the real world. Our implementations are publicly available: https://github.com/CWibault/sorel\\_torel.","authors":["Mattie Fellows","Clarisse Wibault","Uljad Berdica","Johannes Forkel","Jakob N. Foerster","Michael A. Osborne"],"url":"https://arxiv.org/abs/2505.22442"}
{"created":"2025-05-29","title":"Frequency Resource Management in 6G User-Centric CFmMIMO: A Hybrid Reinforcement Learning and Metaheuristic Approach","abstract":"As sixth-generation (6G) networks continue to evolve, AI-driven solutions are playing a crucial role in enabling more efficient and adaptive resource management in wireless communication. One of the key innovations in 6G is user-centric cell-free massive Multiple-Input Multiple-Output (UC-CFmMIMO), a paradigm that eliminates traditional cell boundaries and enhances network performance by dynamically assigning access points (APs) to users. This approach is particularly well-suited for vehicular networks, offering seamless, homogeneous, ultra-reliable, and low-latency connectivity. However, in dense networks, a key challenge lies in efficiently allocating frequency resources within a limited shared subband spectrum while accounting for frequency selectivity and the dependency of signal propagation on bandwidth. These factors make resource allocation increasingly complex, especially in dynamic environments where maintaining Quality of Service (QoS) is critical. This paper tackles these challenges by proposing a hybrid multi-user allocation strategy that integrates reinforcement learning (RL) and metaheuristic optimization to enhance spectral efficiency (SE), ensure fairness, and mitigate interference within shared subbands. To assess its effectiveness, we compare this hybrid approach with two other methods: the bio-inspired Aquila Optimizer (AO) and Deep Deterministic Policy Gradient (DDPG)-based Actor-Critic Reinforcement Learning (AC-RL). Our evaluation is grounded in real-world patterns and channel characteristics, utilizing the 3GPP-3D channel modeling framework (QuaDRiGa) to capture realistic propagation conditions. The results demonstrate that the proposed hybrid strategy achieves a superior balance among competing objectives, underscoring the role of AI-driven resource allocation in advancing UC-CFmMIMO systems for next-generation wireless networks.","authors":["Selina Cheggour","Valeria Loscri"],"url":"https://arxiv.org/abs/2505.22443"}
{"created":"2025-05-29","title":"On Geometry-Enhanced Parameter-Efficient Fine-Tuning for 3D Scene Segmentation","abstract":"The emergence of large-scale pre-trained point cloud models has significantly advanced 3D scene understanding, but adapting these models to specific downstream tasks typically demands full fine-tuning, incurring high computational and storage costs. Parameter-efficient fine-tuning (PEFT) techniques, successful in natural language processing and 2D vision tasks, would underperform when naively applied to 3D point cloud models due to significant geometric and spatial distribution shifts. Existing PEFT methods commonly treat points as orderless tokens, neglecting important local spatial structures and global geometric contexts in 3D modeling. To bridge this gap, we introduce the Geometric Encoding Mixer (GEM), a novel geometry-aware PEFT module specifically designed for 3D point cloud transformers. GEM explicitly integrates fine-grained local positional encodings with a lightweight latent attention mechanism to capture comprehensive global context, thereby effectively addressing the spatial and geometric distribution mismatch. Extensive experiments demonstrate that GEM achieves performance comparable to or sometimes even exceeding full fine-tuning, while only updating 1.6% of the model's parameters, fewer than other PEFT methods. With significantly reduced training time and memory requirements, our approach thus sets a new benchmark for efficient, scalable, and geometry-aware fine-tuning of large-scale 3D point cloud models. Code will be released.","authors":["Liyao Tang","Zhe Chen","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.22444"}
{"created":"2025-05-29","title":"NFR: Neural Feature-Guided Non-Rigid Shape Registration","abstract":"In this paper, we propose a novel learning-based framework for 3D shape registration, which overcomes the challenges of significant non-rigid deformation and partiality undergoing among input shapes, and, remarkably, requires no correspondence annotation during training. Our key insight is to incorporate neural features learned by deep learning-based shape matching networks into an iterative, geometric shape registration pipeline. The advantage of our approach is two-fold -- On one hand, neural features provide more accurate and semantically meaningful correspondence estimation than spatial features (e.g., coordinates), which is critical in the presence of large non-rigid deformations; On the other hand, the correspondences are dynamically updated according to the intermediate registrations and filtered by consistency prior, which prominently robustify the overall pipeline. Empirical results show that, with as few as dozens of training shapes of limited variability, our pipeline achieves state-of-the-art results on several benchmarks of non-rigid point cloud matching and partial shape matching across varying settings, but also delivers high-quality correspondences between unseen challenging shape pairs that undergo both significant extrinsic and intrinsic deformations, in which case neither traditional registration methods nor intrinsic methods work.","authors":["Puhua Jiang","Zhangquan Chen","Mingze Sun","Ruqi Huang"],"url":"https://arxiv.org/abs/2505.22445"}
{"created":"2025-05-29","title":"Privacy-preserving Prompt Personalization in Federated Learning for Multimodal Large Language Models","abstract":"Prompt learning is a crucial technique for adapting pre-trained multimodal language models (MLLMs) to user tasks. Federated prompt personalization (FPP) is further developed to address data heterogeneity and local overfitting, however, it exposes personalized prompts - valuable intellectual assets - to privacy risks like prompt stealing or membership inference attacks. Widely-adopted techniques like differential privacy add noise to prompts, whereas degrading personalization performance. We propose SecFPP, a secure FPP protocol harmonizing generalization, personalization, and privacy guarantees. SecFPP employs hierarchical prompt adaptation with domain-level and class-level components to handle multi-granular data imbalance. For privacy, it uses a novel secret-sharing-based adaptive clustering algorithm for domain-level adaptation while keeping class-level components private. While theoretically and empirically secure, SecFPP achieves state-of-the-art accuracy under severe heterogeneity in data distribution. Extensive experiments show it significantly outperforms both non-private and privacy-preserving baselines, offering a superior privacy-performance trade-off.","authors":["Sizai Hou","Songze Li","Baturalp Buyukates"],"url":"https://arxiv.org/abs/2505.22447"}
{"created":"2025-05-29","title":"Private Lossless Multiple Release","abstract":"Koufogiannis et al. (2016) showed a $\\textit{gradual release}$ result for Laplace noise-based differentially private mechanisms: given an $\\varepsilon$-DP release, a new release with privacy parameter $\\varepsilon' > \\varepsilon$ can be computed such that the combined privacy loss of both releases is at most $\\varepsilon'$ and the distribution of the latter is the same as a single release with parameter $\\varepsilon'$. They also showed gradual release techniques for Gaussian noise, later also explored by Whitehouse et al. (2022).","authors":["Joel Daniel Andersson","Lukas Retschmeier","Boel Nelson","Rasmus Pagh"],"url":"https://arxiv.org/abs/2505.22449"}
{"created":"2025-05-29","title":"Position: All Current Generative Fidelity and Diversity Metrics are Flawed","abstract":"Any method's development and practical application is limited by our ability to measure its reliability. The popularity of generative modeling emphasizes the importance of good synthetic data metrics. Unfortunately, previous works have found many failure cases in current metrics, for example lack of outlier robustness and unclear lower and upper bounds. We propose a list of desiderata for synthetic data metrics, and a suite of sanity checks: carefully chosen simple experiments that aim to detect specific and known generative modeling failure modes. Based on these desiderata and the results of our checks, we arrive at our position: all current generative fidelity and diversity metrics are flawed. This significantly hinders practical use of synthetic data. Our aim is to convince the research community to spend more effort in developing metrics, instead of models. Additionally, through analyzing how current metrics fail, we provide practitioners with guidelines on how these metrics should (not) be used.","authors":["Ossi R\\\"ais\\\"a","Boris van Breugel","Mihaela van der Schaar"],"url":"https://arxiv.org/abs/2505.22450"}
{"created":"2025-05-29","title":"AI Mathematician: Towards Fully Automated Frontier Mathematical Research","abstract":"Large Reasoning Models (LRMs) have made significant progress in mathematical capabilities in recent times. However, these successes have been primarily confined to competition-level problems. In this work, we propose AI Mathematician (AIM) framework, which harnesses the reasoning strength of LRMs to support frontier mathematical research. We have identified two critical challenges of mathematical research compared to competition, {\\it the intrinsic complexity of research problems} and {\\it the requirement of procedural rigor}. To address these challenges, AIM incorporates two core strategies: an exploration mechanism to foster longer solution paths, and the pessimistic reasonable verification method to ensure reliability.","authors":["Yuanhang Liu","Yanxing Huang","Yanqiao Wang","Peng Li","Yang Liu"],"url":"https://arxiv.org/abs/2505.22451"}
{"created":"2025-05-29","title":"Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO","abstract":"Improving Multi-modal Large Language Models (MLLMs) in the post-training stage typically relies on supervised fine-tuning (SFT) or reinforcement learning (RL). However, these supervised methods require expensive and manually annotated multi-modal data--an ultimately unsustainable resource. While recent efforts have explored unsupervised post-training, their methods are complex and difficult to iterate. In this work, we are the first to investigate the use of GRPO, a stable and scalable online RL algorithm, for enabling continual self-improvement without any external supervision. We propose MM-UPT, a simple yet effective framework for unsupervised post-training of MLLMs. MM-UPT builds upon GRPO, replacing traditional reward signals with a self-rewarding mechanism based on majority voting over multiple sampled responses. Our experiments demonstrate that MM-UPT significantly improves the reasoning ability of Qwen2.5-VL-7B (e.g., 66.3 %$\\rightarrow$72.9 % on MathVista, 62.9 %$\\rightarrow$68.7 % on We-Math), using standard dataset without ground truth labels. MM-UPT also outperforms prior unsupervised baselines and even approaches the results of supervised GRPO. Furthermore, we show that incorporating synthetic questions, generated solely by MLLM itself, can boost performance as well, highlighting a promising approach for scalable self-improvement. Overall, MM-UPT offers a new paradigm for continual, autonomous enhancement of MLLMs in the absence of external supervision. Our code is available at https://github.com/waltonfuture/MM-UPT.","authors":["Lai Wei","Yuting Li","Chen Wang","Yue Wang","Linghe Kong","Weiran Huang","Lichao Sun"],"url":"https://arxiv.org/abs/2505.22453"}
{"created":"2025-05-29","title":"Fostering Video Reasoning via Next-Event Prediction","abstract":"Next-token prediction serves as the foundational learning task enabling reasoning in LLMs. But what should the learning task be when aiming to equip MLLMs with temporal reasoning capabilities over video inputs? Existing tasks such as video question answering often rely on annotations from humans or much stronger MLLMs, while video captioning tends to entangle temporal reasoning with spatial information. To address this gap, we propose next-event prediction (NEP), a learning task that harnesses future video segments as a rich, self-supervised signal to foster temporal reasoning. We segment each video into past and future frames: the MLLM takes the past frames as input and predicts a summary of events derived from the future frames, thereby encouraging the model to reason temporally in order to complete the task. To support this task, we curate V1-33K, a dataset comprising 33,000 automatically extracted video segments spanning diverse real-world scenarios. We further explore a range of video instruction-tuning strategies to study their effects on temporal reasoning. To evaluate progress, we introduce FutureBench to assess coherence in predicting unseen future events. Experiments validate that NEP offers a scalable and effective training paradigm for fostering temporal reasoning in MLLMs.","authors":["Haonan Wang","Hongfu Liu","Xiangyan Liu","Chao Du","Kenji Kawaguchi","Ye Wang","Tianyu Pang"],"url":"https://arxiv.org/abs/2505.22457"}
{"created":"2025-05-29","title":"Universal Domain Adaptation for Semantic Segmentation","abstract":"Unsupervised domain adaptation for semantic segmentation (UDA-SS) aims to transfer knowledge from labeled source data to unlabeled target data. However, traditional UDA-SS methods assume that category settings between source and target domains are known, which is unrealistic in real-world scenarios. This leads to performance degradation if private classes exist. To address this limitation, we propose Universal Domain Adaptation for Semantic Segmentation (UniDA-SS), achieving robust adaptation even without prior knowledge of category settings. We define the problem in the UniDA-SS scenario as low confidence scores of common classes in the target domain, which leads to confusion with private classes. To solve this problem, we propose UniMAP: UniDA-SS with Image Matching and Prototype-based Distinction, a novel framework composed of two key components. First, Domain-Specific Prototype-based Distinction (DSPD) divides each class into two domain-specific prototypes, enabling finer separation of domain-specific features and enhancing the identification of common classes across domains. Second, Target-based Image Matching (TIM) selects a source image containing the most common-class pixels based on the target pseudo-label and pairs it in a batch to promote effective learning of common classes. We also introduce a new UniDA-SS benchmark and demonstrate through various experiments that UniMAP significantly outperforms baselines. The code is available at \\href{https://github.com/KU-VGI/UniMAP}{this https URL}.","authors":["Seun-An Choe","Keon-Hee Park","Jinwoo Choi","Gyeong-Moon Park"],"url":"https://arxiv.org/abs/2505.22458"}
{"created":"2025-05-29","title":"SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels","abstract":"3D occupancy prediction has attracted much attention in the field of autonomous driving due to its powerful geometric perception and object recognition capabilities. However, existing methods have not explored the most essential distribution patterns of voxels, resulting in unsatisfactory results. This paper first explores the inter-class distribution and geometric distribution of voxels, thereby solving the long-tail problem caused by the inter-class distribution and the poor performance caused by the geometric distribution. Specifically, this paper proposes SHTOcc (Sparse Head-Tail Occupancy), which uses sparse head-tail voxel construction to accurately identify and balance key voxels in the head and tail classes, while using decoupled learning to reduce the model's bias towards the dominant (head) category and enhance the focus on the tail class. Experiments show that significant improvements have been made on multiple baselines: SHTOcc reduces GPU memory usage by 42.2%, increases inference speed by 58.6%, and improves accuracy by about 7%, verifying its effectiveness and efficiency. The code is available at https://github.com/ge95net/SHTOcc","authors":["Qiucheng Yu","Yuan Xie","Xin Tan"],"url":"https://arxiv.org/abs/2505.22461"}
{"created":"2025-05-29","title":"Single Domain Generalization for Alzheimer's Detection from 3D MRIs with Pseudo-Morphological Augmentations and Contrastive Learning","abstract":"Although Alzheimer's disease detection via MRIs has advanced significantly thanks to contemporary deep learning models, challenges such as class imbalance, protocol variations, and limited dataset diversity often hinder their generalization capacity. To address this issue, this article focuses on the single domain generalization setting, where given the data of one domain, a model is designed and developed with maximal performance w.r.t. an unseen domain of distinct distribution. Since brain morphology is known to play a crucial role in Alzheimer's diagnosis, we propose the use of learnable pseudo-morphological modules aimed at producing shape-aware, anatomically meaningful class-specific augmentations in combination with a supervised contrastive learning module to extract robust class-specific representations. Experiments conducted across three datasets show improved performance and generalization capacity, especially under class imbalance and imaging protocol variations. The source code will be made available upon acceptance at https://github.com/zobia111/SDG-Alzheimer.","authors":["Zobia Batool","Huseyin Ozkan","Erchan Aptoula"],"url":"https://arxiv.org/abs/2505.22465"}
{"created":"2025-05-29","title":"Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems","abstract":"Large Language Model-based Multi-Agent Systems (MASs) have emerged as a powerful paradigm for tackling complex tasks through collaborative intelligence. Nevertheless, the question of how agents should be structurally organized for optimal cooperation remains largely unexplored. In this position paper, we aim to gently redirect the focus of the MAS research community toward this critical dimension: develop topology-aware MASs for specific tasks. Specifically, the system consists of three core components - agents, communication links, and communication patterns - that collectively shape its coordination performance and efficiency. To this end, we introduce a systematic, three-stage framework: agent selection, structure profiling, and topology synthesis. Each stage would trigger new research opportunities in areas such as language models, reinforcement learning, graph learning, and generative modeling; together, they could unleash the full potential of MASs in complicated real-world applications. Then, we discuss the potential challenges and opportunities in the evaluation of multiple systems. We hope our perspective and framework can offer critical new insights in the era of agentic AI.","authors":["Jiaxi Yang","Mengqi Zhang","Yiqiao Jin","Hao Chen","Qingsong Wen","Lu Lin","Yi He","Weijie Xu","James Evans","Jindong Wang"],"url":"https://arxiv.org/abs/2505.22467"}
{"created":"2025-05-29","title":"CPINN-ABPI: Physics-Informed Neural Networks for Accurate Power Estimation in MPSoCs","abstract":"Efficient thermal and power management in modern multiprocessor systems-on-chip (MPSoCs) demands accurate power consumption estimation. One of the state-of-the-art approaches, Alternative Blind Power Identification (ABPI), theoretically eliminates the dependence on steady-state temperatures, addressing a major shortcoming of previous approaches. However, ABPI performance has remained unverified in actual hardware implementations. In this study, we conduct the first empirical validation of ABPI on commercial hardware using the NVIDIA Jetson Xavier AGX platform. Our findings reveal that, while ABPI provides computational efficiency and independence from steady-state temperature, it exhibits considerable accuracy deficiencies in real-world scenarios. To overcome these limitations, we introduce a novel approach that integrates Custom Physics-Informed Neural Networks (CPINNs) with the underlying thermal model of ABPI. Our approach employs a specialized loss function that harmonizes physical principles with data-driven learning, complemented by multi-objective genetic algorithm optimization to balance estimation accuracy and computational cost. In experimental validation, CPINN-ABPI achieves a reduction of 84.7\\% CPU and 73.9\\% GPU in the mean absolute error (MAE) relative to ABPI, with the weighted mean absolute percentage error (WMAPE) improving from 47\\%--81\\% to $\\sim$12\\%. The method maintains real-time performance with 195.3~$\\mu$s of inference time, with similar 85\\%--99\\% accuracy gains across heterogeneous SoCs.","authors":["Mohamed R. Elshamy","Mehdi Elahi","Ahmad Patooghy","Abdel-Hameed A. Badawy"],"url":"https://arxiv.org/abs/2505.22469"}
{"created":"2025-05-29","title":"Pure Exploration with Infinite Answers","abstract":"We study pure exploration problems where the set of correct answers is possibly infinite, e.g., the regression of any continuous function of the means of the bandit. We derive an instance-dependent lower bound for these problems. By analyzing it, we discuss why existing methods (i.e., Sticky Track-and-Stop) for finite answer problems fail at being asymptotically optimal in this more general setting. Finally, we present a framework, Sticky-Sequence Track-and-Stop, which generalizes both Track-and-Stop and Sticky Track-and-Stop, and that enjoys asymptotic optimality. Due to its generality, our analysis also highlights special cases where existing methods enjoy optimality.","authors":["Riccardo Poiani","Martino Bernasconi","Andrea Celli"],"url":"https://arxiv.org/abs/2505.22473"}
{"created":"2025-05-29","title":"Forecasting Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis","abstract":"The forecasting of multivariate urban data presents a complex challenge due to the intricate dependencies between various urban metrics such as weather, air pollution, carbon intensity, and energy demand. This paper introduces a novel multivariate time-series forecasting model that utilizes advanced Graph Neural Networks (GNNs) to capture spatial dependencies among different time-series variables. The proposed model incorporates a decomposition-based preprocessing step, isolating trend, seasonal, and residual components to enhance the accuracy and interpretability of forecasts. By leveraging the dynamic capabilities of GNNs, the model effectively captures interdependencies and improves the forecasting performance. Extensive experiments on real-world datasets, including electricity usage, weather metrics, carbon intensity, and air pollution data, demonstrate the effectiveness of the proposed approach across various forecasting scenarios. The results highlight the potential of the model to optimize smart infrastructure systems, contributing to energy-efficient urban development and enhanced public well-being.","authors":["Amirhossein Sohrabbeig","Omid Ardakanian","Petr Musilek"],"url":"https://arxiv.org/abs/2505.22474"}
{"created":"2025-05-29","title":"Non-Asymptotic Analysis of (Sticky) Track-and-Stop","abstract":"In pure exploration problems, a statistician sequentially collects information to answer a question about some stochastic and unknown environment. The probability of returning a wrong answer should not exceed a maximum risk parameter $\\delta$ and good algorithms make as few queries to the environment as possible. The Track-and-Stop algorithm is a pioneering method to solve these problems. Specifically, it is well-known that it enjoys asymptotic optimality sample complexity guarantees for $\\delta\\to 0$ whenever the map from the environment to its correct answers is single-valued (e.g., best-arm identification with a unique optimal arm). The Sticky Track-and-Stop algorithm extends these results to settings where, for each environment, there might exist multiple correct answers (e.g., $\\epsilon$-optimal arm identification). Although both methods are optimal in the asymptotic regime, their non-asymptotic guarantees remain unknown. In this work, we fill this gap and provide non-asymptotic guarantees for both algorithms.","authors":["Riccardo Poiani","Martino Bernasconi","Andrea Celli"],"url":"https://arxiv.org/abs/2505.22475"}
{"created":"2025-05-29","title":"Human-Centered Human-AI Collaboration (HCHAC)","abstract":"In the intelligent era, the interaction between humans and intelligent systems fundamentally involves collaboration with autonomous intelligent agents. Human-AI Collaboration (HAC) represents a novel type of human-machine relationship facilitated by autonomous intelligent machines equipped with AI technologies. In this paradigm, AI agents serve not only as auxiliary tools but also as active teammates, partnering with humans to accomplish tasks collaboratively. Human-centered AI (HCAI) emphasizes that humans play critical leadership roles in the collaboration. This human-led collaboration imparts new dimensions to the human-machine relationship, necessitating innovative research perspectives, paradigms, and agenda to address the unique challenges posed by HAC. This chapter delves into the essence of HAC from the human-centered perspective, outlining its core concepts and distinguishing features. It reviews the current research methodologies and research agenda within the HAC field from the HCAI perspective, highlighting advancements and ongoing studies. Furthermore, a framework for human-centered HAC (HCHAC) is proposed by integrating these reviews and analyses. A case study of HAC in the context of autonomous vehicles is provided, illustrating practical applications and the synergistic interactions between humans and AI agents. Finally, it identifies potential future research directions aimed at enhancing the effectiveness, reliability, and ethical integration of human-centered HAC systems in diverse domains.","authors":["Qi Gao","Wei Xu","Hanxi Pan","Mowei Shen","Zaifeng Gao"],"url":"https://arxiv.org/abs/2505.22477"}
{"created":"2025-05-29","title":"A Closer Look at Multimodal Representation Collapse","abstract":"We aim to develop a fundamental understanding of modality collapse, a recently observed empirical phenomenon wherein models trained for multimodal fusion tend to rely only on a subset of the modalities, ignoring the rest. We show that modality collapse happens when noisy features from one modality are entangled, via a shared set of neurons in the fusion head, with predictive features from another, effectively masking out positive contributions from the predictive features of the former modality and leading to its collapse. We further prove that cross-modal knowledge distillation implicitly disentangles such representations by freeing up rank bottlenecks in the student encoder, denoising the fusion-head outputs without negatively impacting the predictive features from either modality. Based on the above findings, we propose an algorithm that prevents modality collapse through explicit basis reallocation, with applications in dealing with missing modalities. Extensive experiments on multiple multimodal benchmarks validate our theoretical claims. Project page: https://abhrac.github.io/mmcollapse/.","authors":["Abhra Chaudhuri","Anjan Dutta","Tu Bui","Serban Georgescu"],"url":"https://arxiv.org/abs/2505.22483"}
{"created":"2025-05-29","title":"Understanding Adversarial Training with Energy-based Models","abstract":"We aim at using Energy-based Model (EBM) framework to better understand adversarial training (AT) in classifiers, and additionally to analyze the intrinsic generative capabilities of robust classifiers. By viewing standard classifiers through an energy lens, we begin by analyzing how the energies of adversarial examples, generated by various attacks, differ from those of the natural samples. The central focus of our work is to understand the critical phenomena of Catastrophic Overfitting (CO) and Robust Overfitting (RO) in AT from an energy perspective. We analyze the impact of existing AT approaches on the energy of samples during training and observe that the behavior of the ``delta energy' -- change in energy between original sample and its adversarial counterpart -- diverges significantly when CO or RO occurs. After a thorough analysis of these energy dynamics and their relationship with overfitting, we propose a novel regularizer, the Delta Energy Regularizer (DER), designed to smoothen the energy landscape during training. We demonstrate that DER is effective in mitigating both CO and RO across multiple benchmarks. We further show that robust classifiers, when being used as generative models, have limits in handling trade-off between image quality and variability. We propose an improved technique based on a local class-wise principal component analysis (PCA) and energy-based guidance for better class-specific initialization and adaptive stopping, enhancing sample diversity and generation quality. Considering that we do not explicitly train for generative modeling, we achieve a competitive Inception Score (IS) and Fr\\'echet inception distance (FID) compared to hybrid discriminative-generative models.","authors":["Mujtaba Hussain Mirza","Maria Rosaria Briglia","Filippo Bartolucci","Senad Beadini","Giuseppe Lisanti","Iacopo Masi"],"url":"https://arxiv.org/abs/2505.22486"}
{"created":"2025-05-29","title":"Effective Context in Neural Speech Models","abstract":"Modern neural speech models benefit from having longer context, and many approaches have been proposed to increase the maximum context a model can use. However, few have attempted to measure how much context these models actually use, i.e., the effective context. Here, we propose two approaches to measuring the effective context, and use them to analyze different speech Transformers. For supervised models, we find that the effective context correlates well with the nature of the task, with fundamental frequency tracking, phone classification, and word classification requiring increasing amounts of effective context. For self-supervised models, we find that effective context increases mainly in the early layers, and remains relatively short -- similar to the supervised phone model. Given that these models do not use a long context during prediction, we show that HuBERT can be run in streaming mode without modification to the architecture and without further fine-tuning.","authors":["Yen Meng","Sharon Goldwater","Hao Tang"],"url":"https://arxiv.org/abs/2505.22487"}
{"created":"2025-05-29","title":"ProCrop: Learning Aesthetic Image Cropping from Professional Compositions","abstract":"Image cropping is crucial for enhancing the visual appeal and narrative impact of photographs, yet existing rule-based and data-driven approaches often lack diversity or require annotated training data. We introduce ProCrop, a retrieval-based method that leverages professional photography to guide cropping decisions. By fusing features from professional photographs with those of the query image, ProCrop learns from professional compositions, significantly boosting performance. Additionally, we present a large-scale dataset of 242K weakly-annotated images, generated by out-painting professional images and iteratively refining diverse crop proposals. This composition-aware dataset generation offers diverse high-quality crop proposals guided by aesthetic principles and becomes the largest publicly available dataset for image cropping. Extensive experiments show that ProCrop significantly outperforms existing methods in both supervised and weakly-supervised settings. Notably, when trained on the new dataset, our ProCrop surpasses previous weakly-supervised methods and even matches fully supervised approaches. Both the code and dataset will be made publicly available to advance research in image aesthetics and composition analysis.","authors":["Ke Zhang","Tianyu Ding","Jiachen Jiang","Tianyi Chen","Ilya Zharkov","Vishal M. Patel","Luming Liang"],"url":"https://arxiv.org/abs/2505.22490"}
{"created":"2025-05-29","title":"On the Surprising Effectiveness of Large Learning Rates under Standard Width Scaling","abstract":"The dominant paradigm for training large-scale vision and language models is He initialization and a single global learning rate (\\textit{standard parameterization}, SP). Despite its practical success, standard parametrization remains poorly understood from a theoretical perspective: Existing infinite-width theory would predict instability under large learning rates and vanishing feature learning under stable learning rates. However, empirically optimal learning rates consistently decay much slower than theoretically predicted. By carefully studying neural network training dynamics, we demonstrate that this discrepancy is not fully explained by finite-width phenomena such as catapult effects or a lack of alignment between weights and incoming activations. We instead show that the apparent contradiction can be fundamentally resolved by taking the loss function into account: In contrast to Mean Squared Error (MSE) loss, we prove that under cross-entropy (CE) loss, an intermediate \\textit{controlled divergence} regime emerges, where logits diverge but loss, gradients, and activations remain stable. Stable training under large learning rates enables persistent feature evolution at scale in all hidden layers, which is crucial for the practical success of SP. In experiments across optimizers (SGD, Adam), architectures (MLPs, GPT) and data modalities (vision, language), we validate that neural networks operate in this controlled divergence regime under CE loss but not under MSE loss. Our empirical evidence suggests that width-scaling considerations are surprisingly useful for predicting empirically optimal learning rate exponents. Finally, our analysis clarifies the effectiveness and limitations of recently proposed layerwise learning rate scalings for standard initialization.","authors":["Moritz Haas","Sebastian Bordt","Ulrike von Luxburg","Leena Chennuru Vankadara"],"url":"https://arxiv.org/abs/2505.22491"}
{"created":"2025-05-29","title":"Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation","abstract":"This paper studies off-policy evaluation (OPE) in reinforcement learning with a focus on behavior policy estimation for importance sampling. Prior work has shown empirically that estimating a history-dependent behavior policy can lead to lower mean squared error (MSE) even when the true behavior policy is Markovian. However, the question of why the use of history should lower MSE remains open. In this paper, we theoretically demystify this paradox by deriving a bias-variance decomposition of the MSE of ordinary importance sampling (IS) estimators, demonstrating that history-dependent behavior policy estimation decreases their asymptotic variances while increasing their finite-sample biases. Additionally, as the estimated behavior policy conditions on a longer history, we show a consistent decrease in variance. We extend these findings to a range of other OPE estimators, including the sequential IS estimator, the doubly robust estimator and the marginalized IS estimator, with the behavior policy estimated either parametrically or non-parametrically.","authors":["Hongyi Zhou","Josiah P. Hanna","Jin Zhu","Ying Yang","Chengchun Shi"],"url":"https://arxiv.org/abs/2505.22492"}
{"created":"2025-05-29","title":"ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods","abstract":"Designing protein sequences of both high fitness and novelty is a challenging task in data-efficient protein engineering. Exploration beyond wild-type neighborhoods often leads to biologically implausible sequences or relies on surrogate models that lose fidelity in novel regions. Here, we propose ProSpero, an active learning framework in which a frozen pre-trained generative model is guided by a surrogate updated from oracle feedback. By integrating fitness-relevant residue selection with biologically-constrained Sequential Monte Carlo sampling, our approach enables exploration beyond wild-type neighborhoods while preserving biological plausibility. We show that our framework remains effective even when the surrogate is misspecified. ProSpero consistently outperforms or matches existing methods across diverse protein engineering tasks, retrieving sequences of both high fitness and novelty.","authors":["Michal Kmicikiewicz","Vincent Fortuin","Ewa Szczurek"],"url":"https://arxiv.org/abs/2505.22494"}
{"created":"2025-05-29","title":"Fully Packed and Ready to Go: High-Density, Rearrangement-Free, Grid-Based Storage and Retrieval","abstract":"Grid-based storage systems with uniformly shaped loads (e.g., containers, pallets, totes) are commonplace in logistics, industrial, and transportation domains. A key performance metric for such systems is the maximization of space utilization, which requires some loads to be placed behind or below others, preventing direct access to them. Consequently, dense storage settings bring up the challenge of determining how to place loads while minimizing costly rearrangement efforts necessary during retrieval. This paper considers the setting involving an inbound phase, during which loads arrive, followed by an outbound phase, during which loads depart. The setting is prevalent in distribution centers, automated parking garages, and container ports. In both phases, minimizing the number of rearrangement actions results in more optimal (e.g., fast, energy-efficient, etc.) operations. In contrast to previous work focusing on stack-based systems, this effort examines the case where loads can be freely moved along the grid, e.g., by a mobile robot, expanding the range of possible motions. We establish that for a range of scenarios, such as having limited prior knowledge of the loads' arrival sequences or grids with a narrow opening, a (best possible) rearrangement-free solution always exists, including when the loads fill the grid to its capacity. In particular, when the sequences are fully known, we establish an intriguing characterization showing that rearrangement can always be avoided if and only if the open side of the grid (used to access the storage) is at least 3 cells wide. We further discuss useful practical implications of our solutions.","authors":["Tzvika Geft","Kostas Bekris","Jingjin Yu"],"url":"https://arxiv.org/abs/2505.22497"}
{"created":"2025-05-29","title":"Lanczos with compression for symmetric matrix Lyapunov equations","abstract":"This work considers large-scale Lyapunov matrix equations of the form $AX + XA = \\boldsymbol{c}\\boldsymbol{c}^T$, where $A$ is a symmetric positive definite matrix and $\\boldsymbol{c}$ is a vector. Motivated by the need to solve such equations in a wide range of applications, various numerical methods have been developed to compute low-rank approximations of the solution matrix $X$. In this work, we focus on the Lanczos method, which has the distinct advantage of requiring only matrix-vector products with $A$, making it broadly applicable. However, the Lanczos method may suffer from slow convergence when $A$ is ill-conditioned, leading to excessive memory requirements for storing the Krylov subspace basis generated by the algorithm. To address this issue, we propose a novel compression strategy for the Krylov subspace basis that significantly reduces memory usage without hindering convergence. This is supported by both numerical experiments and a convergence analysis. Our analysis also accounts for the loss of orthogonality due to round-off errors in the Lanczos process.","authors":["Angelo A. Casulli","Francesco Hrobat","Daniel Kressner"],"url":"https://arxiv.org/abs/2505.22498"}
{"created":"2025-05-29","title":"The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector","abstract":"3D object detection is a critical component in autonomous driving systems. It allows real-time recognition and detection of vehicles, pedestrians and obstacles under varying environmental conditions. Among existing methods, 3D object detection in the Bird's Eye View (BEV) has emerged as the mainstream framework. To guarantee a safe, robust and trustworthy 3D object detection, 3D adversarial attacks are investigated, where attacks are placed in 3D environments to evaluate the model performance, e.g., putting a film on a car, clothing a pedestrian. The vulnerability of 3D object detection models to 3D adversarial attacks serves as an important indicator to evaluate the robustness of the model against perturbations. To investigate this vulnerability, we generate non-invasive 3D adversarial objects tailored for real-world attack scenarios. Our method verifies the existence of universal adversarial objects that are spatially consistent across time and camera views. Specifically, we employ differentiable rendering techniques to accurately model the spatial relationship between adversarial objects and the target vehicle. Furthermore, we introduce an occlusion-aware module to enhance visual consistency and realism under different viewpoints. To maintain attack effectiveness across multiple frames, we design a BEV spatial feature-guided optimization strategy. Experimental results demonstrate that our approach can reliably suppress vehicle predictions from state-of-the-art 3D object detectors, serving as an important tool to test robustness of 3D object detection models before deployment. Moreover, the generated adversarial objects exhibit strong generalization capabilities, retaining its effectiveness at various positions and distances in the scene.","authors":["Aixuan Li","Mochu Xiang","Jing Zhang","Yuchao Dai"],"url":"https://arxiv.org/abs/2505.22499"}
{"created":"2025-05-29","title":"EvolveSearch: An Iterative Self-Evolving Search Agent","abstract":"The rapid advancement of large language models (LLMs) has transformed the landscape of agentic information seeking capabilities through the integration of tools such as search engines and web browsers. However, current mainstream approaches for enabling LLM web search proficiency face significant challenges: supervised fine-tuning struggles with data production in open-search domains, while RL converges quickly, limiting their data utilization efficiency. To address these issues, we propose EvolveSearch, a novel iterative self-evolution framework that combines SFT and RL to enhance agentic web search capabilities without any external human-annotated reasoning data. Extensive experiments on seven multi-hop question-answering (MHQA) benchmarks demonstrate that EvolveSearch consistently improves performance across iterations, ultimately achieving an average improvement of 4.7\\% over the current state-of-the-art across seven benchmarks, opening the door to self-evolution agentic capabilities in open web search domains.","authors":["Dingchu Zhang","Yida Zhao","Jialong Wu","Baixuan Li","Wenbiao Yin","Liwen Zhang","Yong Jiang","Yufeng Li","Kewei Tu","Pengjun Xie","Fei Huang"],"url":"https://arxiv.org/abs/2505.22501"}
{"created":"2025-05-29","title":"From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation","abstract":"While embodied agents have made significant progress in performing complex physical tasks, real-world applications demand more than pure task execution. The agents must collaborate with unfamiliar agents and human users, whose goals are often vague and implicit. In such settings, interpreting ambiguous instructions and uncovering underlying desires is essential for effective assistance. Therefore, fast and accurate desire alignment becomes a critical capability for embodied agents. In this work, we first develop a home assistance simulation environment HA-Desire that integrates an LLM-driven human user agent exhibiting realistic value-driven goal selection and communication. The ego agent must interact with this proxy user to infer and adapt to the user's latent desires. To achieve this, we present a novel framework FAMER for fast desire alignment, which introduces a desire-based mental reasoning mechanism to identify user intent and filter desire-irrelevant actions. We further design a reflection-based communication module that reduces redundant inquiries, and incorporate goal-relevant information extraction with memory persistence to improve information reuse and reduce unnecessary exploration. Extensive experiments demonstrate that our framework significantly enhances both task execution and communication efficiency, enabling embodied agents to quickly adapt to user-specific desires in complex embodied environments.","authors":["Yuanfei Wang","Xinju Huang","Fangwei Zhong","Yaodong Yang","Yizhou Wang","Yuanpei Chen","Hao Dong"],"url":"https://arxiv.org/abs/2505.22503"}
{"created":"2025-05-29","title":"Geometric GNNs for Charged Particle Tracking at GlueX","abstract":"Nuclear physics experiments are aimed at uncovering the fundamental building blocks of matter. The experiments involve high-energy collisions that produce complex events with many particle trajectories. Tracking charged particles resulting from collisions in the presence of a strong magnetic field is critical to enable the reconstruction of particle trajectories and precise determination of interactions. It is traditionally achieved through combinatorial approaches that scale worse than linearly as the number of hits grows. Since particle hit data naturally form a 3-dimensional point cloud and can be structured as graphs, Graph Neural Networks (GNNs) emerge as an intuitive and effective choice for this task. In this study, we evaluate the GNN model for track finding on the data from the GlueX experiment at Jefferson Lab. We use simulation data to train the model and test on both simulation and real GlueX measurements. We demonstrate that GNN-based track finding outperforms the currently used traditional method at GlueX in terms of segment-based efficiency at a fixed purity while providing faster inferences. We show that the GNN model can achieve significant speedup by processing multiple events in batches, which exploits the parallel computation capability of Graphical Processing Units (GPUs). Finally, we compare the GNN implementation on GPU and FPGA and describe the trade-off.","authors":["Ahmed Hossam Mohammed","Kishansingh Rajput","Simon Taylor","Denis Furletov","Sergey Furletov","Malachi Schram"],"url":"https://arxiv.org/abs/2505.22504"}
{"created":"2025-05-29","title":"Data-Driven Control of Continuous-Time LTI Systems via Non-Minimal Realizations","abstract":"This article proposes an approach to design output-feedback controllers for unknown continuous-time linear time-invariant systems using only input-output data from a single experiment. To address the lack of state and derivative measurements, we introduce non-minimal realizations whose states can be observed by filtering the available data. We first apply this concept to the disturbance-free case, formulating linear matrix inequalities (LMIs) from batches of sampled signals to design a dynamic, filter-based stabilizing controller. The framework is then extended to the problem of asymptotic tracking and disturbance rejection - in short, output regulation - by incorporating an internal model based on prior knowledge of the disturbance/reference frequencies. Finally, we discuss tuning strategies for a class of multi-input multi-output systems and illustrate the method via numerical examples.","authors":["Alessandro Bosso","Marco Borghesi","Andrea Iannelli","Giuseppe Notarstefano","Andrew R. Teel"],"url":"https://arxiv.org/abs/2505.22505"}
{"created":"2025-05-29","title":"Sparsification and Reconstruction from the Perspective of Representation Geometry","abstract":"Sparse Autoencoders (SAEs) have emerged as a predominant tool in mechanistic interpretability, aiming to identify interpretable monosemantic features. However, how does sparse encoding organize the representations of activation vector from language models? What is the relationship between this organizational paradigm and feature disentanglement as well as reconstruction performance? To address these questions, we propose the SAEMA, which validates the stratified structure of the representation by observing the variability of the rank of the symmetric semipositive definite (SSPD) matrix corresponding to the modal tensor unfolded along the latent tensor with the level of noise added to the residual stream. To systematically investigate how sparse encoding alters representational structures, we define local and global representations, demonstrating that they amplify inter-feature distinctions by merging similar semantic features and introducing additional dimensionality. Furthermore, we intervene the global representation from an optimization perspective, proving a significant causal relationship between their separability and the reconstruction performance. This study explains the principles of sparsity from the perspective of representational geometry and demonstrates the impact of changes in representational structure on reconstruction performance. Particularly emphasizes the necessity of understanding representations and incorporating representational constraints, providing empirical references for developing new interpretable tools and improving SAEs. The code is available at \\hyperlink{https://github.com/wenjie1835/SAERepGeo}{https://github.com/wenjie1835/SAERepGeo}.","authors":["Wenjie Sun","Bingzhe Wu","Zhile Yang","Chengke Wu"],"url":"https://arxiv.org/abs/2505.22506"}
{"created":"2025-05-29","title":"Accelerating Optimization via Differentiable Stopping Time","abstract":"Optimization is an important module of modern machine learning applications. Tremendous efforts have been made to accelerate optimization algorithms. A common formulation is achieving a lower loss at a given time. This enables a differentiable framework with respect to the algorithm hyperparameters. In contrast, its dual, minimizing the time to reach a target loss, is believed to be non-differentiable, as the time is not differentiable. As a result, it usually serves as a conceptual framework or is optimized using zeroth-order methods. To address this limitation, we propose a differentiable stopping time and theoretically justify it based on differential equations. An efficient algorithm is designed to backpropagate through it. As a result, the proposed differentiable stopping time enables a new differentiable formulation for accelerating algorithms. We further discuss its applications, such as online hyperparameter tuning and learning to optimize. Our proposed methods show superior performance in comprehensive experiments across various problems, which confirms their effectiveness.","authors":["Zhonglin Xie","Yiman Fong","Haoran Yuan","Zaiwen Wen"],"url":"https://arxiv.org/abs/2505.22509"}
{"created":"2025-05-29","title":"Strengthening Proportionality in Temporal Voting","abstract":"We study proportional representation in the framework of temporal voting with approval ballots. Prior work adapted basic proportional representation concepts -- justified representation (JR), proportional JR (PJR), and extended JR (EJR) -- from the multiwinner setting to the temporal setting. Our work introduces and examines ways of going beyond EJR. Specifically, we consider stronger variants of JR, PJR, and EJR, and introduce temporal adaptations of more demanding multiwinner axioms, such as EJR+, full JR (FJR), full proportional JR (FPJR), and the Core. For each of these concepts, we investigate its existence and study its relationship to existing notions, thereby establishing a rich hierarchy of proportionality concepts. Notably, we show that two of our proposed axioms -- EJR+ and FJR -- strengthen EJR while remaining satisfiable in every temporal election.","authors":["Bradley Phillips","Edith Elkind","Nicholas Teh","Tomasz W\\k{a}s"],"url":"https://arxiv.org/abs/2505.22513"}
{"created":"2025-05-29","title":"Towards General Discrete Speech Codec for Complex Acoustic Environments: A Study of Reconstruction and Downstream Task Consistency","abstract":"Neural speech codecs excel in reconstructing clean speech signals; however, their efficacy in complex acoustic environments and downstream signal processing tasks remains underexplored. In this study, we introduce a novel benchmark named Environment-Resilient Speech Codec Benchmark (ERSB) to systematically evaluate whether neural speech codecs are environment-resilient. Specifically, we assess two key capabilities: (1) robust reconstruction, which measures the preservation of both speech and non-speech acoustic details, and (2) downstream task consistency, which ensures minimal deviation in downstream signal processing tasks when using reconstructed speech instead of the original. Our comprehensive experiments reveal that complex acoustic environments significantly degrade signal reconstruction and downstream task consistency. This work highlights the limitations of current speech codecs and raises a future direction that improves them for greater environmental resilience.","authors":["Haoran Wang","Guanyu Chen","Bohan Li","Hankun Wang","Yiwei Guo","Zhihan Li","Xie Chen","Kai Yu"],"url":"https://arxiv.org/abs/2505.22515"}
{"created":"2025-05-29","title":"Multi-MLLM Knowledge Distillation for Out-of-Context News Detection","abstract":"Multimodal out-of-context news is a type of misinformation in which the image is used outside of its original context. Many existing works have leveraged multimodal large language models (MLLMs) for detecting out-of-context news. However, observing the limited zero-shot performance of smaller MLLMs, they generally require label-rich fine-tuning and/or expensive API calls to GPT models to improve the performance, which is impractical in low-resource scenarios. In contrast, we aim to improve the performance of small MLLMs in a more label-efficient and cost-effective manner. To this end, we first prompt multiple teacher MLLMs to generate both label predictions and corresponding rationales, which collectively serve as the teachers' knowledge. We then introduce a two-stage knowledge distillation framework to transfer this knowledge to a student MLLM. In Stage 1, we apply LoRA fine-tuning to the student model using all training data. In Stage 2, we further fine-tune the student model using both LoRA fine-tuning and DPO on the data points where teachers' predictions conflict. This two-stage strategy reduces annotation costs and helps the student model uncover subtle patterns in more challenging cases. Experimental results demonstrate that our approach achieves state-of-the-art performance using less than 10% labeled data.","authors":["Yimeng Gu","Zhao Tong","Ignacio Castro","Shu Wu","Gareth Tyson"],"url":"https://arxiv.org/abs/2505.22517"}
{"created":"2025-05-29","title":"Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data","abstract":"Fraud detection remains a critical task in high-stakes domains such as finance and e-commerce, where undetected fraudulent transactions can lead to significant economic losses. In this study, we systematically compare the performance of four supervised learning models - Logistic Regression, Random Forest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit (GRU) network - on a large-scale, highly imbalanced online transaction dataset. While ensemble methods such as Random Forest and LightGBM demonstrated superior performance in both overall and class-specific metrics, Logistic Regression offered a reliable and interpretable baseline. The GRU model showed strong recall for the minority fraud class, though at the cost of precision, highlighting a trade-off relevant for real-world deployment. Our evaluation emphasizes not only weighted averages but also per-class precision, recall, and F1-scores, providing a nuanced view of each model's effectiveness in detecting rare but consequential fraudulent activity. The findings underscore the importance of choosing models based on the specific risk tolerance and operational needs of fraud detection systems.","authors":["Chao Wang","Chuanhao Nie","Yunbo Liu"],"url":"https://arxiv.org/abs/2505.22521"}
{"created":"2025-05-29","title":"PathFL: Multi-Alignment Federated Learning for Pathology Image Segmentation","abstract":"Pathology image segmentation across multiple centers encounters significant challenges due to diverse sources of heterogeneity including imaging modalities, organs, and scanning equipment, whose variability brings representation bias and impedes the development of generalizable segmentation models. In this paper, we propose PathFL, a novel multi-alignment Federated Learning framework for pathology image segmentation that addresses these challenges through three-level alignment strategies of image, feature, and model aggregation. Firstly, at the image level, a collaborative style enhancement module aligns and diversifies local data by facilitating style information exchange across clients. Secondly, at the feature level, an adaptive feature alignment module ensures implicit alignment in the representation space by infusing local features with global insights, promoting consistency across heterogeneous client features learning. Finally, at the model aggregation level, a stratified similarity aggregation strategy hierarchically aligns and aggregates models on the server, using layer-specific similarity to account for client discrepancies and enhance global generalization. Comprehensive evaluations on four sets of heterogeneous pathology image datasets, encompassing cross-source, cross-modality, cross-organ, and cross-scanner variations, validate the effectiveness of our PathFL in achieving better performance and robustness against data heterogeneity.","authors":["Yuan Zhang","Feng Chen","Yaolei Qi","Guanyu Yang","Huazhu Fu"],"url":"https://arxiv.org/abs/2505.22522"}
{"created":"2025-05-29","title":"PrismLayers: Open Data for High-Quality Multi-Layer Transparent Image Generative Models","abstract":"Generating high-quality, multi-layer transparent images from text prompts can unlock a new level of creative control, allowing users to edit each layer as effortlessly as editing text outputs from LLMs. However, the development of multi-layer generative models lags behind that of conventional text-to-image models due to the absence of a large, high-quality corpus of multi-layer transparent data. In this paper, we address this fundamental challenge by: (i) releasing the first open, ultra-high-fidelity PrismLayers (PrismLayersPro) dataset of 200K (20K) multilayer transparent images with accurate alpha mattes, (ii) introducing a trainingfree synthesis pipeline that generates such data on demand using off-the-shelf diffusion models, and (iii) delivering a strong, open-source multi-layer generation model, ART+, which matches the aesthetics of modern text-to-image generation models. The key technical contributions include: LayerFLUX, which excels at generating high-quality single transparent layers with accurate alpha mattes, and MultiLayerFLUX, which composes multiple LayerFLUX outputs into complete images, guided by human-annotated semantic layout. To ensure higher quality, we apply a rigorous filtering stage to remove artifacts and semantic mismatches, followed by human selection. Fine-tuning the state-of-the-art ART model on our synthetic PrismLayersPro yields ART+, which outperforms the original ART in 60% of head-to-head user study comparisons and even matches the visual quality of images generated by the FLUX.1-[dev] model. We anticipate that our work will establish a solid dataset foundation for the multi-layer transparent image generation task, enabling research and applications that require precise, editable, and visually compelling layered imagery.","authors":["Junwen Chen","Heyang Jiang","Yanbin Wang","Keming Wu","Ji Li","Chao Zhang","Keiji Yanai","Dong Chen","Yuhui Yuan"],"url":"https://arxiv.org/abs/2505.22523"}
{"created":"2025-05-29","title":"Test-Time Alignment of Discrete Diffusion Models with Sequential Monte Carlo","abstract":"Discrete diffusion models have become highly effective across various domains. However, real-world applications often require the generative process to adhere to certain constraints but without task-specific fine-tuning. To this end, we propose a training-free method based on Sequential Monte Carlo (SMC) to sample from the reward-aligned target distribution at the test time. Our approach leverages twisted SMC with an approximate locally optimal proposal, obtained via a first-order Taylor expansion of the reward function. To address the challenge of ill-defined gradients in discrete spaces, we incorporate a Gumbel-Softmax relaxation, enabling efficient gradient-based approximation within the discrete generative framework. Empirical results on both synthetic datasets and image modelling validate the effectiveness of our approach.","authors":["Chinmay Pani","Zijing Ou","Yingzhen Li"],"url":"https://arxiv.org/abs/2505.22524"}
{"created":"2025-05-29","title":"Thinking with Generated Images","abstract":"We present Thinking with Generated Images, a novel paradigm that fundamentally transforms how large multimodal models (LMMs) engage with visual reasoning by enabling them to natively think across text and vision modalities through spontaneous generation of intermediate visual thinking steps. Current visual reasoning with LMMs is constrained to either processing fixed user-provided images or reasoning solely through text-based chain-of-thought (CoT). Thinking with Generated Images unlocks a new dimension of cognitive capability where models can actively construct intermediate visual thoughts, critique their own visual hypotheses, and refine them as integral components of their reasoning process. We demonstrate the effectiveness of our approach through two complementary mechanisms: (1) vision generation with intermediate visual subgoals, where models decompose complex visual tasks into manageable components that are generated and integrated progressively, and (2) vision generation with self-critique, where models generate an initial visual hypothesis, analyze its shortcomings through textual reasoning, and produce refined outputs based on their own critiques. Our experiments on vision generation benchmarks show substantial improvements over baseline approaches, with our models achieving up to 50% (from 38% to 57%) relative improvement in handling complex multi-object scenarios. From biochemists exploring novel protein structures, and architects iterating on spatial designs, to forensic analysts reconstructing crime scenes, and basketball players envisioning strategic plays, our approach enables AI models to engage in the kind of visual imagination and iterative refinement that characterizes human creative, analytical, and strategic thinking. We release our open-source suite at https://github.com/GAIR-NLP/thinking-with-generated-images.","authors":["Ethan Chern","Zhulin Hu","Steffi Chern","Siqi Kou","Jiadi Su","Yan Ma","Zhijie Deng","Pengfei Liu"],"url":"https://arxiv.org/abs/2505.22525"}
{"created":"2025-05-29","title":"AI instructional agent improves student's perceived learner control and learning outcome: empirical evidence from a randomized controlled trial","abstract":"This study examines the impact of an AI instructional agent on students' perceived learner control and academic performance in a medium demanding course with lecturing as the main teaching strategy. Based on a randomized controlled trial, three instructional conditions were compared: a traditional human teacher, a self-paced MOOC with chatbot support, and an AI instructional agent capable of delivering lectures and responding to questions in real time. Students in the AI instructional agent group reported significantly higher levels of perceived learner control compared to the other groups. They also completed the learning task more efficiently and engaged in more frequent interactions with the instructional system. Regression analyzes showed that perceived learner control positively predicted post-test performance, with behavioral indicators such as reduced learning time and higher interaction frequency supporting this relationship. These findings suggest that AI instructional agents, when designed to support personalized pace and responsive interaction, can enhance both students' learning experience and learning outcomes.","authors":["Fei Qin","Zhanxin Hao","Jifan Yu","Zhiyuan Liu","Yu Zhang"],"url":"https://arxiv.org/abs/2505.22526"}
{"created":"2025-05-29","title":"Training RL Agents for Multi-Objective Network Defense Tasks","abstract":"Open-ended learning (OEL) -- which emphasizes training agents that achieve broad capability over narrow competency -- is emerging as a paradigm to develop artificial intelligence (AI) agents to achieve robustness and generalization. However, despite promising results that demonstrate the benefits of OEL, applying OEL to develop autonomous agents for real-world cybersecurity applications remains a challenge.","authors":["Andres Molina-Markham","Luis Robaina","Sean Steinle","Akash Trivedi","Derek Tsui","Nicholas Potteiger","Lauren Brandt","Ransom Winder","Ahmed Ridley"],"url":"https://arxiv.org/abs/2505.22531"}
{"created":"2025-05-29","title":"Gautschi-type and implicit-explicit integrators for constrained wave equations","abstract":"This paper deals with the construction and analysis of two integrators for (semi-linear) second-order partial differential-algebraic equations of semi-explicit type. More precisely, we consider an implicit-explicit Crank-Nicolson scheme as well as an exponential integrator of Gautschi type. For this, well-known wave integrators for unconstrained systems are combined with techniques known from the field of differential-algebraic equations. The result are efficient time stepping schemes, which are provable of second order. Moreover, we discuss the practical implementation of the Gautschi-type method, which involves the solution of certain saddle point problems. The theoretical results are verified by numerical experiments for the the wave equation with kinetic boundary conditions.","authors":["R. Altmann","B. D\\\"orich","C. Zimmer"],"url":"https://arxiv.org/abs/2505.22532"}
{"created":"2025-05-29","title":"TabularQGAN: A Quantum Generative Model for Tabular Data","abstract":"In this paper, we introduce a novel quantum generative model for synthesizing tabular data. Synthetic data is valuable in scenarios where real-world data is scarce or private, it can be used to augment or replace existing datasets. Real-world enterprise data is predominantly tabular and heterogeneous, often comprising a mixture of categorical and numerical features, making it highly relevant across various industries such as healthcare, finance, and software. We propose a quantum generative adversarial network architecture with flexible data encoding and a novel quantum circuit ansatz to effectively model tabular data. The proposed approach is tested on the MIMIC III healthcare and Adult Census datasets, with extensive benchmarking against leading classical models, CTGAN, and CopulaGAN. Experimental results demonstrate that our quantum model outperforms classical models by an average of 8.5% with respect to an overall similarity score from SDMetrics, while using only 0.072% of the parameters of the classical models. Additionally, we evaluate the generalization capabilities of the models using two custom-designed metrics that demonstrate the ability of the proposed quantum model to generate useful and novel samples. To our knowledge, this is one of the first demonstrations of a successful quantum generative model for handling tabular data, indicating that this task could be well-suited to quantum computers.","authors":["Pallavi Bhardwaj","Caitlin Jones","Lasse Dierich","Aleksandar Vu\\v{c}kovi\\'c"],"url":"https://arxiv.org/abs/2505.22533"}
{"created":"2025-05-29","title":"RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting","abstract":"Recent deep learning approaches for river discharge forecasting have improved the accuracy and efficiency in flood forecasting, enabling more reliable early warning systems for risk management. Nevertheless, existing deep learning approaches in hydrology remain largely confined to local-scale applications and do not leverage the inherent spatial connections of bodies of water. Thus, there is a strong need for new deep learning methodologies that are capable of modeling spatio-temporal relations to improve river discharge and flood forecasting for scientific and operational applications. To address this, we present RiverMamba, a novel deep learning model that is pretrained with long-term reanalysis data and that can forecast global river discharge and floods on a $0.05^\\circ$ grid up to 7 days lead time, which is of high relevance in early warning. To achieve this, RiverMamba leverages efficient Mamba blocks that enable the model to capture global-scale channel network routing and enhance its forecast capability for longer lead times. The forecast blocks integrate ECMWF HRES meteorological forecasts, while accounting for their inaccuracies through spatio-temporal modeling. Our analysis demonstrates that RiverMamba delivers reliable predictions of river discharge, including extreme floods across return periods and lead times, surpassing both operational AI- and physics-based models.","authors":["Mohamad Hakam Shams Eddin","Yikui Zahng","Stefan Kollet","Juergen Gall"],"url":"https://arxiv.org/abs/2505.22535"}
{"created":"2025-05-29","title":"Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks","abstract":"We address the problem of uncertainty quantification and propose measures of total, aleatoric, and epistemic uncertainty based on a known decomposition of (strictly) proper scoring rules, a specific type of loss function, into a divergence and an entropy component. This leads to a flexible framework for uncertainty quantification that can be instantiated with different losses (scoring rules), which makes it possible to tailor uncertainty quantification to the use case at hand. We show that this flexibility is indeed advantageous. In particular, we analyze the task of selective prediction and show that the scoring rule should ideally match the task loss. In addition, we perform experiments on two other common tasks. For out-of-distribution detection, our results confirm that a widely used measure of epistemic uncertainty, mutual information, performs best. Moreover, in the setting of active learning, our measure of epistemic uncertainty based on the zero-one-loss consistently outperforms other uncertainty measures.","authors":["Paul Hofman","Yusuf Sale","Eyke H\\\"ullermeier"],"url":"https://arxiv.org/abs/2505.22538"}
{"created":"2025-05-29","title":"Spot-On: A Mixed Reality Interface for Multi-Robot Cooperation","abstract":"Recent progress in mixed reality (MR) and robotics is enabling increasingly sophisticated forms of human-robot collaboration. Building on these developments, we introduce a novel MR framework that allows multiple quadruped robots to operate in semantically diverse environments via a MR interface. Our system supports collaborative tasks involving drawers, swing doors, and higher-level infrastructure such as light switches. A comprehensive user study verifies both the design and usability of our app, with participants giving a \"good\" or \"very good\" rating in almost all cases. Overall, our approach provides an effective and intuitive framework for MR-based multi-robot collaboration in complex, real-world scenarios.","authors":["Tim Engelbracht","Petar Lukovic","Tjark Behrens","Kai Lascheit","Ren\\'e Zurbr\\\"ugg","Marc Pollefeys","Hermann Blum","Zuria Bauer"],"url":"https://arxiv.org/abs/2505.22539"}
{"created":"2025-05-29","title":"A Human-Centric Approach to Explainable AI for Personalized Education","abstract":"Deep neural networks form the backbone of artificial intelligence research, with potential to transform the human experience in areas ranging from autonomous driving to personal assistants, healthcare to education. However, their integration into the daily routines of real-world classrooms remains limited. It is not yet common for a teacher to assign students individualized homework targeting their specific weaknesses, provide students with instant feedback, or simulate student responses to a new exam question. While these models excel in predictive performance, this lack of adoption can be attributed to a significant weakness: the lack of explainability of model decisions, leading to a lack of trust from students, parents, and teachers. This thesis aims to bring human needs to the forefront of eXplainable AI (XAI) research, grounded in the concrete use case of personalized learning and teaching. We frame the contributions along two verticals: technical advances in XAI and their aligned human studies. We investigate explainability in AI for education, revealing systematic disagreements between post-hoc explainers and identifying a need for inherently interpretable model architectures. We propose four novel technical contributions in interpretability with a multimodal modular architecture (MultiModN), an interpretable mixture-of-experts model (InterpretCC), adversarial training for explainer stability, and a theory-driven LLM-XAI framework to present explanations to students (iLLuMinaTE), which we evaluate in diverse settings with professors, teachers, learning scientists, and university students. By combining empirical evaluations of existing explainers with novel architectural designs and human studies, our work lays a foundation for human-centric AI systems that balance state-of-the-art performance with built-in transparency and trust.","authors":["Vinitra Swamy"],"url":"https://arxiv.org/abs/2505.22541"}
{"created":"2025-05-29","title":"Scaling-up Perceptual Video Quality Assessment","abstract":"The data scaling law has been shown to significantly enhance the performance of large multi-modal models (LMMs) across various downstream tasks. However, in the domain of perceptual video quality assessment (VQA), the potential of scaling law remains unprecedented due to the scarcity of labeled resources and the insufficient scale of datasets. To address this, we propose \\textbf{OmniVQA}, an efficient framework designed to efficiently build high-quality, human-in-the-loop VQA multi-modal instruction databases (MIDBs). We then scale up to create \\textbf{OmniVQA-Chat-400K}, the largest MIDB in the VQA field concurrently. Our focus is on the technical and aesthetic quality dimensions, with abundant in-context instruction data to provide fine-grained VQA knowledge. Additionally, we have built the \\textbf{OmniVQA-MOS-20K} dataset to enhance the model's quantitative quality rating capabilities. We then introduce a \\textbf{complementary} training strategy that effectively leverages the knowledge from datasets for quality understanding and quality rating tasks. Furthermore, we propose the \\textbf{OmniVQA-FG (fine-grain)-Benchmark} to evaluate the fine-grained performance of the models. Our results demonstrate that our models achieve state-of-the-art performance in both quality understanding and rating tasks.","authors":["Ziheng Jia","Zicheng Zhang","Zeyu Zhang","Yingji Liang","Xiaorong Zhu","Chunyi Li","Jinliang Han","Haoning Wu","Bin Wang","Haoran Zhang","Guanyu Zhu","Qiyong Zhao","Xiaohong Liu","Guangtao Zhai","Xiongkuo Min"],"url":"https://arxiv.org/abs/2505.22543"}
{"created":"2025-05-29","title":"Emotion-o1: Adaptive Long Reasoning for Emotion Understanding in LLMs","abstract":"Emotion understanding includes basic tasks (e.g., sentiment/emotion classification) and advanced tasks (e.g., sarcasm/humor detection). Current methods rely on fixed-length CoT reasoning, failing to adapt to the varying complexity of emotions. We propose a task-adaptive reasoning framework that employs DeepSeek-R1 to generate variable-length reasoning chains for different emotion tasks. By combining fine-tuning with reinforcement learning, we design a composite reward function that balances four objectives: prediction accuracy, adaptive reasoning depth control, structural diversity in reasoning paths, and suppression of repetitive logic. This approach achieves dynamic context-sensitive inference while enabling LLMs to autonomously develop deep reasoning capabilities. Experimental results demonstrate consistent improvements in both Acc and F1 scores across four tasks: emotion, sentiment, humor, and sarcasm. Notably, peak enhancements reached 3.56% F1 (2.76% Acc) for basic tasks and 37.95% F1 (23.14% Acc) for advanced tasks. Our work bridges rigid CoT reasoning and emotional complexity through adaptive-depth analysis.","authors":["Changhao Song","Yazhou Zhang","Peng Zhang"],"url":"https://arxiv.org/abs/2505.22548"}
{"created":"2025-05-29","title":"DES-LOC: Desynced Low Communication Adaptive Optimizers for Training Foundation Models","abstract":"Scaling foundation model training with Distributed Data Parallel (DDP) methods is bandwidth-limited. Existing infrequent communication methods like Local SGD were designed to synchronize only model parameters and cannot be trivially applied to adaptive optimizers due to additional optimizer states. Current approaches extending Local SGD either lack convergence guarantees or require synchronizing all optimizer states, tripling communication costs. We propose Desynced Low Communication Adaptive Optimizers (DES-LOC), a family of optimizers assigning independent synchronization periods to parameters and momenta, enabling lower communication costs while preserving convergence. Through extensive experiments on language models of up to 1.7B, we show that DES-LOC can communicate 170x less than DDP and 2x less than the previous state-of-the-art Local ADAM. Furthermore, unlike previous heuristic approaches, DES-LOC is suited for practical training scenarios prone to system failures. DES-LOC offers a scalable, bandwidth-efficient, and fault-tolerant solution for foundation model training.","authors":["Alex Iacob","Lorenzo Sani","Mher Safaryan","Paris Giampouras","Samuel Horv\\'ath","Andrej Jovanovic","Meghdad Kurmanji","Preslav Aleksandrov","William F. Shen","Xinchi Qiu","Nicholas D. Lane"],"url":"https://arxiv.org/abs/2505.22549"}
{"created":"2025-05-29","title":"Domain specific ontologies from Linked Open Data (LOD)","abstract":"Logical and probabilistic reasoning tasks that require a deeper knowledge of semantics are increasingly relying on general purpose ontologies such as Wikidata and DBpedia. However, tasks such as entity disambiguation and linking may benefit from domain specific knowledge graphs, which make it more efficient to consume the knowledge and easier to extend with proprietary content. We discuss our experience bootstrapping one such ontology for IT with a domain-agnostic pipeline, and extending it using domain-specific glossaries.","authors":["Rosario Uceda-Sosa","Nandana Mihindukulasooriya","Atul Kumar","Sahil Bansal","Seema Nagar"],"url":"https://arxiv.org/abs/2505.22550"}
{"created":"2025-05-29","title":"Deep Learning-Based BMD Estimation from Radiographs with Conformal Uncertainty Quantification","abstract":"Limited DXA access hinders osteoporosis screening. This proof-of-concept study proposes using widely available knee X-rays for opportunistic Bone Mineral Density (BMD) estimation via deep learning, emphasizing robust uncertainty quantification essential for clinical use. An EfficientNet model was trained on the OAI dataset to predict BMD from bilateral knee radiographs. Two Test-Time Augmentation (TTA) methods were compared: traditional averaging and a multi-sample approach. Crucially, Split Conformal Prediction was implemented to provide statistically rigorous, patient-specific prediction intervals with guaranteed coverage. Results showed a Pearson correlation of 0.68 (traditional TTA). While traditional TTA yielded better point predictions, the multi-sample approach produced slightly tighter confidence intervals (90%, 95%, 99%) while maintaining coverage. The framework appropriately expressed higher uncertainty for challenging cases. Although anatomical mismatch between knee X-rays and standard DXA limits immediate clinical use, this method establishes a foundation for trustworthy AI-assisted BMD screening using routine radiographs, potentially improving early osteoporosis detection.","authors":["Long Hui","Wai Lok Yeung"],"url":"https://arxiv.org/abs/2505.22551"}
{"created":"2025-05-29","title":"ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM","abstract":"Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of large language models (LLMs) is an emerging research challenge in claim verification. While KGs provide structured, semantically rich representations well-suited for reasoning, most existing verification methods rely on unstructured text corpora, limiting their ability to effectively leverage KGs. Additionally, despite possessing strong reasoning abilities, modern LLMs struggle with multi-step modular pipelines and reasoning over KGs without adaptation. To address these challenges, we propose ClaimPKG, an end-to-end framework that seamlessly integrates LLM reasoning with structured knowledge from KGs. Specifically, the main idea of ClaimPKG is to employ a lightweight, specialized LLM to represent the input claim as pseudo-subgraphs, guiding a dedicated subgraph retrieval module to identify relevant KG subgraphs. These retrieved subgraphs are then processed by a general-purpose LLM to produce the final verdict and justification. Extensive experiments on the FactKG dataset demonstrate that ClaimPKG achieves state-of-the-art performance, outperforming strong baselines in this research field by 9%-12% accuracy points across multiple categories. Furthermore, ClaimPKG exhibits zero-shot generalizability to unstructured datasets such as HoVer and FEVEROUS, effectively combining structured knowledge from KGs with LLM reasoning across various LLM backbones.","authors":["Hoang Pham","Thanh-Do Nguyen","Khac-Hoai Nam Bui"],"url":"https://arxiv.org/abs/2505.22552"}
{"created":"2025-05-29","title":"MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism","abstract":"Human pose estimation based on Channel State Information (CSI) has emerged as a promising approach for non-intrusive and precise human activity monitoring, yet faces challenges including accurate multi-person pose recognition and effective CSI feature learning. This paper presents MultiFormer, a wireless sensing system that accurately estimates human pose through CSI. The proposed system adopts a Transformer based time-frequency dual-token feature extractor with multi-head self-attention. This feature extractor is able to model inter-subcarrier correlations and temporal dependencies of the CSI. The extracted CSI features and the pose probability heatmaps are then fused by Multi-Stage Feature Fusion Network (MSFN) to enforce the anatomical constraints. Extensive experiments conducted on on the public MM-Fi dataset and our self-collected dataset show that the MultiFormer achieves higher accuracy over state-of-the-art approaches, especially for high-mobility keypoints (wrists, elbows) that are particularly difficult for previous methods to accurately estimate.","authors":["Yanyi Qu","Haoyang Ma","Wenhui Xiong"],"url":"https://arxiv.org/abs/2505.22555"}
{"created":"2025-05-29","title":"Geometric Hyena Networks for Large-scale Equivariant Learning","abstract":"Processing global geometric context while preserving equivariance is crucial when modeling biological, chemical, and physical systems. Yet, this is challenging due to the computational demands of equivariance and global context at scale. Standard methods such as equivariant self-attention suffer from quadratic complexity, while local methods such as distance-based message passing sacrifice global information. Inspired by the recent success of state-space and long-convolutional models, we introduce Geometric Hyena, the first equivariant long-convolutional model for geometric systems. Geometric Hyena captures global geometric context at sub-quadratic complexity while maintaining equivariance to rotations and translations. Evaluated on all-atom property prediction of large RNA molecules and full protein molecular dynamics, Geometric Hyena outperforms existing equivariant models while requiring significantly less memory and compute that equivariant self-attention. Notably, our model processes the geometric context of 30k tokens 20x faster than the equivariant transformer and allows 72x longer context within the same budget.","authors":["Artem Moskalev","Mangal Prakash","Junjie Xu","Tianyu Cui","Rui Liao","Tommaso Mansi"],"url":"https://arxiv.org/abs/2505.22560"}
{"created":"2025-05-29","title":"Do Large Language Models Think Like the Brain? Sentence-Level Evidence from fMRI and Hierarchical Embeddings","abstract":"Understanding whether large language models (LLMs) and the human brain converge on similar computational principles remains a fundamental and important question in cognitive neuroscience and AI. Do the brain-like patterns observed in LLMs emerge simply from scaling, or do they reflect deeper alignment with the architecture of human language processing? This study focuses on the sentence-level neural mechanisms of language models, systematically investigating how hierarchical representations in LLMs align with the dynamic neural responses during human sentence comprehension. By comparing hierarchical embeddings from 14 publicly available LLMs with fMRI data collected from participants, who were exposed to a naturalistic narrative story, we constructed sentence-level neural prediction models to precisely identify the model layers most significantly correlated with brain region activations. Results show that improvements in model performance drive the evolution of representational architectures toward brain-like hierarchies, particularly achieving stronger functional and anatomical correspondence at higher semantic abstraction levels.","authors":["Yu Lei","Xingyang Ge","Yi Zhang","Yiming Yang","Bolei Ma"],"url":"https://arxiv.org/abs/2505.22563"}
{"created":"2025-05-29","title":"PRISM: Video Dataset Condensation with Progressive Refinement and Insertion for Sparse Motion","abstract":"Video dataset condensation has emerged as a critical technique for addressing the computational challenges associated with large-scale video data processing in deep learning applications. While significant progress has been made in image dataset condensation, the video domain presents unique challenges due to the complex interplay between spatial content and temporal dynamics. This paper introduces PRISM, Progressive Refinement and Insertion for Sparse Motion, for video dataset condensation, a novel approach that fundamentally reconsiders how video data should be condensed. Unlike the previous method that separates static content from dynamic motion, our method preserves the essential interdependence between these elements. Our approach progressively refines and inserts frames to fully accommodate the motion in an action while achieving better performance but less storage, considering the relation of gradients for each frame. Extensive experiments across standard video action recognition benchmarks demonstrate that PRISM outperforms existing disentangled approaches while maintaining compact representations suitable for resource-constrained environments.","authors":["Jaehyun Choi","Jiwan Hur","Gyojin Han","Jaemyung Yu","Junmo Kim"],"url":"https://arxiv.org/abs/2505.22564"}
{"created":"2025-05-29","title":"Universal Visuo-Tactile Video Understanding for Embodied Interaction","abstract":"Tactile perception is essential for embodied agents to understand physical attributes of objects that cannot be determined through visual inspection alone. While existing approaches have made progress in visual and language modalities for physical understanding, they fail to effectively incorporate tactile information that provides crucial haptic feedback for real-world interaction. In this paper, we present VTV-LLM, the first multi-modal large language model for universal Visuo-Tactile Video (VTV) understanding that bridges the gap between tactile perception and natural language. To address the challenges of cross-sensor and cross-modal integration, we contribute VTV150K, a comprehensive dataset comprising 150,000 video frames from 100 diverse objects captured across three different tactile sensors (GelSight Mini, DIGIT, and Tac3D), annotated with four fundamental tactile attributes (hardness, protrusion, elasticity, and friction). We develop a novel three-stage training paradigm that includes VTV enhancement for robust visuo-tactile representation, VTV-text alignment for cross-modal correspondence, and text prompt finetuning for natural language generation. Our framework enables sophisticated tactile reasoning capabilities including feature assessment, comparative analysis, scenario-based decision making and so on. Experimental evaluations demonstrate that VTV-LLM achieves superior performance in tactile video understanding tasks, establishing a foundation for more intuitive human-machine interaction in tactile domains.","authors":["Yifan Xie","Mingyang Li","Shoujie Li","Xingting Li","Guangyu Chen","Fei Ma","Fei Richard Yu","Wenbo Ding"],"url":"https://arxiv.org/abs/2505.22566"}
{"created":"2025-05-29","title":"ImageReFL: Balancing Quality and Diversity in Human-Aligned Diffusion Models","abstract":"Recent advances in diffusion models have led to impressive image generation capabilities, but aligning these models with human preferences remains challenging. Reward-based fine-tuning using models trained on human feedback improves alignment but often harms diversity, producing less varied outputs. In this work, we address this trade-off with two contributions. First, we introduce \\textit{combined generation}, a novel sampling strategy that applies a reward-tuned diffusion model only in the later stages of the generation process, while preserving the base model for earlier steps. This approach mitigates early-stage overfitting and helps retain global structure and diversity. Second, we propose \\textit{ImageReFL}, a fine-tuning method that improves image diversity with minimal loss in quality by training on real images and incorporating multiple regularizers, including diffusion and ReFL losses. Our approach outperforms conventional reward tuning methods on standard quality and diversity metrics. A user study further confirms that our method better balances human preference alignment and visual diversity. The source code can be found at https://github.com/ControlGenAI/ImageReFL .","authors":["Dmitrii Sorokin","Maksim Nakhodnov","Andrey Kuznetsov","Aibek Alanov"],"url":"https://arxiv.org/abs/2505.22569"}
{"created":"2025-05-29","title":"Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems","abstract":"This paper presents a novel approach for unified retrieval-augmented generation (RAG) systems using the recent emerging large language model (LLM) agent concept. Specifically, Agent LLM, which utilizes LLM as fundamental controllers, has become a promising approach to enable the interpretability of RAG tasks, especially for complex reasoning question-answering systems (e.g., multi-hop queries). Nonetheless, previous works mainly focus on solving RAG systems with either single-hop or multi-hop approaches separately, which limits the application of those approaches to real-world applications. In this study, we propose a trainable agent framework called Agent-UniRAG for unified retrieval-augmented LLM systems, which enhances the effectiveness and interpretability of RAG systems. The main idea is to design an LLM agent framework to solve RAG tasks step-by-step based on the complexity of the inputs, simultaneously including single-hop and multi-hop queries in an end-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset to enable the proposed agent framework for small open-source LLMs (e.g., Llama-3-8B). The results show comparable performances with closed-source and larger open-source LLMs across various RAG benchmarks. Our source code and dataset are publicly available for further exploitation.","authors":["Hoang Pham","Khac-Hoai Nam Bui"],"url":"https://arxiv.org/abs/2505.22571"}
{"created":"2025-05-29","title":"Fusion Steering: Prompt-Specific Activation Control","abstract":"We present Fusion Steering, an activation steering methodology that improves factual accuracy in large language models (LLMs) for question-answering (QA) tasks. This approach introduces flexible steering configurations, including full-layer steering and segmented steering. Unlike traditional methods constrained to single-layer or fixed-layer operations, Fusion Steering employs dynamic injection of prompt-specific activation deltas across all transformer layers. These activation deltas are derived from reference completions that combine the ground-truth answer with a model-generated explanation to facilitate semantically enriched, example-specific steering. The injection weights are optimized per prompt using Optuna, targeting a joint objective that balances token overlap (factual alignment) and perplexity (fluency proxy). Evaluation employs a composite score integrating token overlap and LLM-graded quality, encompassing factual accuracy, coherence, and relevance. Empirical results on 260 SimpleQA prompts (selected from 500 where the baseline failed) showcase the efficacy of segmented steering. Using Gemma-2-2B-IT with 8-bit quantization, segmented steering achieves an accuracy of 25.4% (outputs scoring $\\geq 0.6$), outperforming the baseline at 3.5% and full-layer steering at 16.2%. Under the stricter SimpleQA rubric, segmented steering boosts fully correct responses from 0.0% to 13.1%. These findings highlight the strengths of segmented, dynamic intervention strategies and the promise of per-prompt, full-network activation control. Fusion Steering is also amenable to sparse representations, such as Neuronpedia or sparse crosscoders, suggesting a promising direction for interpretable and scalable activation-level control in LLMs.","authors":["Waldemar Chang","Alhassan Yasin"],"url":"https://arxiv.org/abs/2505.22572"}
{"created":"2025-05-29","title":"FNOPE: Simulation-based inference on function spaces with Fourier Neural Operators","abstract":"Simulation-based inference (SBI) is an established approach for performing Bayesian inference on scientific simulators. SBI so far works best on low-dimensional parametric models. However, it is difficult to infer function-valued parameters, which frequently occur in disciplines that model spatiotemporal processes such as the climate and earth sciences. Here, we introduce an approach for efficient posterior estimation, using a Fourier Neural Operator (FNO) architecture with a flow matching objective. We show that our approach, FNOPE, can perform inference of function-valued parameters at a fraction of the simulation budget of state of the art methods. In addition, FNOPE supports posterior evaluation at arbitrary discretizations of the domain, as well as simultaneous estimation of vector-valued parameters. We demonstrate the effectiveness of our approach on several benchmark tasks and a challenging spatial inference task from glaciology. FNOPE extends the applicability of SBI methods to new scientific domains by enabling the inference of function-valued parameters.","authors":["Guy Moss","Leah Sophie Muhle","Reinhard Drews","Jakob H. Macke","Cornelius Schr\\\"oder"],"url":"https://arxiv.org/abs/2505.22573"}
{"created":"2025-05-29","title":"Benignity of loss landscape with weight decay requires both large overparametrization and initialization","abstract":"The optimization of neural networks under weight decay remains poorly understood from a theoretical standpoint. While weight decay is standard practice in modern training procedures, most theoretical analyses focus on unregularized settings. In this work, we investigate the loss landscape of the $\\ell_2$-regularized training loss for two-layer ReLU networks. We show that the landscape becomes benign -- i.e., free of spurious local minima -- under large overparametrization, specifically when the network width $m$ satisfies $m \\gtrsim \\min(n^d, 2^n)$, where $n$ is the number of data points and $d$ the input dimension. More precisely in this regime, almost all constant activation regions contain a global minimum and no spurious local minima. We further show that this level of overparametrization is not only sufficient but also necessary via the example of orthogonal data. Finally, we demonstrate that such loss landscape results primarily hold relevance in the large initialization regime. In contrast, for small initializations -- corresponding to the feature learning regime -- optimization can still converge to spurious local minima, despite the global benignity of the landscape.","authors":["Etienne Boursier","Matthew Bowditch","Matthias Englert","Ranko Lazic"],"url":"https://arxiv.org/abs/2505.22578"}
{"created":"2025-05-29","title":"A hybrid PDE-ABM model for angiogenesis and tumour microenvironment with application to resistance in cancer treatment","abstract":"The main obstacle to effective cancer treatment is the development of drug resistance, which can be divided into two categories: spontaneous and acquired drug resistance. Non-small cell lung cancer (NSCLC) is the main cause of cancer-related deaths worldwide. A subset of lung cancer, adenocarcinomas, is characterised by mutations in the epidermal growth factor receptor (EGFR) gene. Treatment of EGFR-mutated lung adenocarcinomas has become less effective over time due to drug resistance development, which is associated with a second mutation in the EGFR gene. An important factor in the development of cancer is angiogenesis, which is the formation of blood vessels from the existing vasculature. These newly formed blood vessels provide oxygen and nutrients to tumour cells to maintain tumour growth and proliferation. We applied a hybrid discrete-continuous (HDC) model to capture the dynamic vasculature in the tumour microenvironment (TME). In the case of pre-existing resistance, the formation of angiogenic networks creates a microenvironment that supports tumour survival and enhances drug resistance. In the case of spontaneous mutation-induced resistance, earlier and more frequent mutations confer a greater survival advantage to the tumour population. There is also a mutually reinforcing relationship between a high proliferation rate and high resistance characteristics. These findings explain two conflicting experimental results about the second mutation in NSCLC.","authors":["Louis Shuo Wang","Jiguang Yu","Zonghao Liu"],"url":"https://arxiv.org/abs/2505.22580"}
{"created":"2025-05-29","title":"Tell me Habibi, is it Real or Fake?","abstract":"Deepfake generation methods are evolving fast, making fake media harder to detect and raising serious societal concerns. Most deepfake detection and dataset creation research focuses on monolingual content, often overlooking the challenges of multilingual and code-switched speech, where multiple languages are mixed within the same discourse. Code-switching, especially between Arabic and English, is common in the Arab world and is widely used in digital communication. This linguistic mixing poses extra challenges for deepfake detection, as it can confuse models trained mostly on monolingual data. To address this, we introduce \\textbf{ArEnAV}, the first large-scale Arabic-English audio-visual deepfake dataset featuring intra-utterance code-switching, dialectal variation, and monolingual Arabic content. It \\textbf{contains 387k videos and over 765 hours of real and fake videos}. Our dataset is generated using a novel pipeline integrating four Text-To-Speech and two lip-sync models, enabling comprehensive analysis of multilingual multimodal deepfake detection. We benchmark our dataset against existing monolingual and multilingual datasets, state-of-the-art deepfake detection models, and a human evaluation, highlighting its potential to advance deepfake research. The dataset can be accessed \\href{https://huggingface.co/datasets/kartik060702/ArEnAV-Full}{here}.","authors":["Kartik Kuckreja","Parul Gupta","Injy Hamed","Thamar Solorio","Muhammad Haris Khan","Abhinav Dhall"],"url":"https://arxiv.org/abs/2505.22581"}
{"created":"2025-05-29","title":"Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts","abstract":"Continually expanding new languages for existing large language models (LLMs) is a promising yet challenging approach to building powerful multilingual LLMs. The biggest challenge is to make the model continuously learn new languages while preserving the proficient ability of old languages. To achieve this, recent work utilizes the Mixture-of-Experts (MoE) architecture to expand new languages by adding new experts and avoid catastrophic forgetting of old languages by routing corresponding tokens to the original model backbone (old experts). Although intuitive, this kind of method is parameter-costly when expanding new languages and still inevitably impacts the performance of old languages. To address these limitations, we analyze the language characteristics of different layers in LLMs and propose a layer-wise expert allocation algorithm (LayerMoE) to determine the appropriate number of new experts for each layer. Specifically, we find different layers in LLMs exhibit different representation similarities between languages and then utilize the similarity as the indicator to allocate experts for each layer, i.e., the higher similarity, the fewer experts. Additionally, to further mitigate the forgetting of old languages, we add a classifier in front of the router network on the layers with higher similarity to guide the routing of old language tokens. Experimental results show that our method outperforms the previous state-of-the-art baseline with 60% fewer experts in the single-expansion setting and with 33.3% fewer experts in the lifelong-expansion setting, demonstrating the effectiveness of our method.","authors":["Xue Zhang","Yunlong Liang","Fandong Meng","Songming Zhang","Yufeng Chen","Jinan Xu","Jie Zhou"],"url":"https://arxiv.org/abs/2505.22582"}
{"created":"2025-05-29","title":"GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git","abstract":"Benchmarks for Software Engineering (SE) AI agents, most notably SWE-bench, have catalyzed progress in programming capabilities of AI agents. However, they overlook critical developer workflows such as Version Control System (VCS) operations. To address this issue, we present GitGoodBench, a novel benchmark for evaluating AI agent performance on VCS tasks. GitGoodBench covers three core Git scenarios extracted from permissive open-source Python, Java, and Kotlin repositories. Our benchmark provides three datasets: a comprehensive evaluation suite (900 samples), a rapid prototyping version (120 samples), and a training corpus (17,469 samples). We establish baseline performance on the prototyping version of our benchmark using GPT-4o equipped with custom tools, achieving a 21.11% solve rate overall. We expect GitGoodBench to serve as a crucial stepping stone toward truly comprehensive SE agents that go beyond mere programming.","authors":["Tobias Lindenbauer","Egor Bogomolov","Yaroslav Zharov"],"url":"https://arxiv.org/abs/2505.22583"}
{"created":"2025-05-29","title":"DocReRank: Single-Page Hard Negative Query Generation for Training Multi-Modal RAG Rerankers","abstract":"Rerankers play a critical role in multimodal Retrieval-Augmented Generation (RAG) by refining ranking of an initial set of retrieved documents. Rerankers are typically trained using hard negative mining, whose goal is to select pages for each query which rank high, but are actually irrelevant. However, this selection process is typically passive and restricted to what the retriever can find in the available corpus, leading to several inherent limitations. These include: limited diversity, negative examples which are often not hard enough, low controllability, and frequent false negatives which harm training. Our paper proposes an alternative approach: Single-Page Hard Negative Query Generation, which goes the other way around. Instead of retrieving negative pages per query, we generate hard negative queries per page. Using an automated LLM-VLM pipeline, and given a page and its positive query, we create hard negatives by rephrasing the query to be as similar as possible in form and context, yet not answerable from the page. This paradigm enables fine-grained control over the generated queries, resulting in diverse, hard, and targeted negatives. It also supports efficient false negative verification. Our experiments show that rerankers trained with data generated using our approach outperform existing models and significantly improve retrieval performance.","authors":["Navve Wasserman","Oliver Heinimann","Yuval Golbari","Tal Zimbalist","Eli Schwartz","Michal Irani"],"url":"https://arxiv.org/abs/2505.22584"}
{"created":"2025-05-29","title":"Precise In-Parameter Concept Erasure in Large Language Models","abstract":"Large language models (LLMs) often acquire knowledge during pretraining that is undesirable in downstream deployments, e.g., sensitive information or copyrighted content. Existing approaches for removing such knowledge rely on fine-tuning, training low-rank adapters or fact-level editing, but these are either too coarse, too shallow, or ineffective. In this work, we propose PISCES (Precise In-parameter Suppression for Concept EraSure), a novel framework for precisely erasing entire concepts from model parameters by directly editing directions that encode them in parameter space. PISCES uses a disentangler model to decompose MLP vectors into interpretable features, identifies those associated with a target concept using automated interpretability techniques, and removes them from model parameters. Experiments on Gemma 2 and Llama 3.1 over various concepts show that PISCES achieves modest gains in efficacy over leading erasure methods, reducing accuracy on the target concept to as low as 7.7%, while dramatically improving erasure specificity (by up to 31%) and robustness (by up to 38%). Overall, these results demonstrate that feature-based in-parameter editing enables a more precise and reliable approach for removing conceptual knowledge in language models.","authors":["Yoav Gur-Arieh","Clara Suslik","Yihuai Hong","Fazl Barez","Mor Geva"],"url":"https://arxiv.org/abs/2505.22586"}
{"created":"2025-05-29","title":"Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning","abstract":"Although large language models demonstrate strong performance across various domains, they still struggle with numerous bad cases in mathematical reasoning. Previous approaches to learning from errors synthesize training data by solely extrapolating from isolated bad cases, thereby failing to generalize the extensive patterns inherent within these cases. This paper presents Self-Error-Instruct (SEI), a framework that addresses these model weaknesses and synthesizes more generalized targeted training data. Specifically, we explore a target model on two mathematical datasets, GSM8K and MATH, to pinpoint bad cases. Then, we generate error keyphrases for these cases based on the instructor model's (GPT-4o) analysis and identify error types by clustering these keyphrases. Next, we sample a few bad cases during each generation for each identified error type and input them into the instructor model, which synthesizes additional training data using a self-instruct approach. This new data is refined through a one-shot learning process to ensure that only the most effective examples are kept. Finally, we use these curated data to fine-tune the target model, iteratively repeating the process to enhance performance. We apply our framework to various models and observe improvements in their reasoning abilities across both in-domain and out-of-domain mathematics datasets. These results demonstrate the effectiveness of self-error instruction in improving LLMs' mathematical reasoning through error generalization.","authors":["Erxin Yu","Jing Li","Ming Liao","Qi Zhu","Boyang Xue","Minghui Xu","Baojun Wang","Lanqing Hong","Fei Mi","Lifeng Shang"],"url":"https://arxiv.org/abs/2505.22591"}
{"created":"2025-05-29","title":"SAM-R1: Leveraging SAM for Reward Feedback in Multimodal Segmentation via Reinforcement Learning","abstract":"Leveraging multimodal large models for image segmentation has become a prominent research direction. However, existing approaches typically rely heavily on manually annotated datasets that include explicit reasoning processes, which are costly and time-consuming to produce. Recent advances suggest that reinforcement learning (RL) can endow large models with reasoning capabilities without requiring such reasoning-annotated data. In this paper, we propose SAM-R1, a novel framework that enables multimodal large models to perform fine-grained reasoning in image understanding tasks. Our approach is the first to incorporate fine-grained segmentation settings during the training of multimodal reasoning models. By integrating task-specific, fine-grained rewards with a tailored optimization objective, we further enhance the model's reasoning and segmentation alignment. We also leverage the Segment Anything Model (SAM) as a strong and flexible reward provider to guide the learning process. With only 3k training samples, SAM-R1 achieves strong performance across multiple benchmarks, demonstrating the effectiveness of reinforcement learning in equipping multimodal models with segmentation-oriented reasoning capabilities.","authors":["Jiaqi Huang","Zunnan Xu","Jun Zhou","Ting Liu","Yicheng Xiao","Mingwen Ou","Bowen Ji","Xiu Li","Kehong Yuan"],"url":"https://arxiv.org/abs/2505.22596"}
{"created":"2025-05-29","title":"HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined in HDDL with OpenAI Gym","abstract":"In recent years, reinforcement learning (RL) methods have been widely tested using tools like OpenAI Gym, though many tasks in these environments could also benefit from hierarchical planning. However, there is a lack of a tool that enables seamless integration of hierarchical planning with RL. Hierarchical Domain Definition Language (HDDL), used in classical planning, introduces a structured approach well-suited for model-based RL to address this gap. To bridge this integration, we introduce HDDLGym, a Python-based tool that automatically generates OpenAI Gym environments from HDDL domains and problems. HDDLGym serves as a link between RL and hierarchical planning, supporting multi-agent scenarios and enabling collaborative planning among agents. This paper provides an overview of HDDLGym's design and implementation, highlighting the challenges and design choices involved in integrating HDDL with the Gym interface, and applying RL policies to support hierarchical planning. We also provide detailed instructions and demonstrations for using the HDDLGym framework, including how to work with existing HDDL domains and problems from International Planning Competitions, exemplified by the Transport domain. Additionally, we offer guidance on creating new HDDL domains for multi-agent scenarios and demonstrate the practical use of HDDLGym in the Overcooked domain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a valuable tool for studying RL in hierarchical planning, particularly in multi-agent contexts.","authors":["Ngoc La","Ruaridh Mon-Williams","Julie A. Shah"],"url":"https://arxiv.org/abs/2505.22597"}
{"created":"2025-05-29","title":"VR-Based Control of Multi-Copter Operation","abstract":"We aim to use virtual reality (VR) to improve the spatial awareness of pilots by real-time scanning of the environment around the drone using onboard sensors, live streaming of this environment to a VR headset, and rendering a virtual representation of the drone and its environment for the pilot. This way, the pilot can see the immediate environment of the drone up close from a third-person perspective, as opposed to the first-person perspective that most drone cameras provide. This provides much more information about the drone surroundings for the pilot while operating the drone than existing teleoperation solutions. Previous solutions using VR have relied upon pre-made designs of the environment, which makes it difficult to adapt to changing environments. Our solution, in contrast, scans the environment as you fly, making it much more flexible for use in unknown environments.","authors":["Jack T. Hughes","Mohammad Ghufran","Hossein Rastgoftar"],"url":"https://arxiv.org/abs/2505.22599"}
{"created":"2025-05-29","title":"Machine Unlearning under Overparameterization","abstract":"Machine unlearning algorithms aim to remove the influence of specific training samples, ideally recovering the model that would have resulted from training on the remaining data alone. We study unlearning in the overparameterized setting, where many models interpolate the data, and defining the unlearning solution as any loss minimizer over the retained set$\\unicode{x2013}$as in prior work in the underparameterized setting$\\unicode{x2013}$is inadequate, since the original model may already interpolate the retained data and satisfy this condition. In this regime, loss gradients vanish, rendering prior methods based on gradient perturbations ineffective, motivating both new unlearning definitions and algorithms. For this setting, we define the unlearning solution as the minimum-complexity interpolator over the retained data and propose a new algorithmic framework that only requires access to model gradients on the retained set at the original solution. We minimize a regularized objective over perturbations constrained to be orthogonal to these model gradients, a first-order relaxation of the interpolation condition. For different model classes, we provide exact and approximate unlearning guarantees, and we demonstrate that an implementation of our framework outperforms existing baselines across various unlearning experiments.","authors":["Jacob L. Block","Aryan Mokhtari","Sanjay Shakkottai"],"url":"https://arxiv.org/abs/2505.22601"}
{"created":"2025-05-29","title":"One Rank at a Time: Cascading Error Dynamics in Sequential Learning","abstract":"Sequential learning -- where complex tasks are broken down into simpler, hierarchical components -- has emerged as a paradigm in AI. This paper views sequential learning through the lens of low-rank linear regression, focusing specifically on how errors propagate when learning rank-1 subspaces sequentially. We present an analysis framework that decomposes the learning process into a series of rank-1 estimation problems, where each subsequent estimation depends on the accuracy of previous steps. Our contribution is a characterization of the error propagation in this sequential process, establishing bounds on how errors -- e.g., due to limited computational budgets and finite precision -- affect the overall model accuracy. We prove that these errors compound in predictable ways, with implications for both algorithmic design and stability guarantees.","authors":["Mahtab Alizadeh Vandchali (Jasper)","Fangshuo (Jasper)","Liao","Anastasios Kyrillidis"],"url":"https://arxiv.org/abs/2505.22602"}
{"created":"2025-05-29","title":"Adversarially Robust AI-Generated Image Detection for Free: An Information Theoretic Perspective","abstract":"Rapid advances in Artificial Intelligence Generated Images (AIGI) have facilitated malicious use, such as forgery and misinformation. Therefore, numerous methods have been proposed to detect fake images. Although such detectors have been proven to be universally vulnerable to adversarial attacks, defenses in this field are scarce. In this paper, we first identify that adversarial training (AT), widely regarded as the most effective defense, suffers from performance collapse in AIGI detection. Through an information-theoretic lens, we further attribute the cause of collapse to feature entanglement, which disrupts the preservation of feature-label mutual information. Instead, standard detectors show clear feature separation. Motivated by this difference, we propose Training-free Robust Detection via Information-theoretic Measures (TRIM), the first training-free adversarial defense for AIGI detection. TRIM builds on standard detectors and quantifies feature shifts using prediction entropy and KL divergence. Extensive experiments across multiple datasets and attacks validate the superiority of our TRIM, e.g., outperforming the state-of-the-art defense by 33.88% (28.91%) on ProGAN (GenImage), while well maintaining original accuracy.","authors":["Ruixuan Zhang","He Wang","Zhengyu Zhao","Zhiqing Guo","Xun Yang","Yunfeng Diao","Meng Wang"],"url":"https://arxiv.org/abs/2505.22604"}
{"created":"2025-05-29","title":"Transformers for Secure Hardware Systems: Applications, Challenges, and Outlook","abstract":"The rise of hardware-level security threats, such as side-channel attacks, hardware Trojans, and firmware vulnerabilities, demands advanced detection mechanisms that are more intelligent and adaptive. Traditional methods often fall short in addressing the complexity and evasiveness of modern attacks, driving increased interest in machine learning-based solutions. Among these, Transformer models, widely recognized for their success in natural language processing and computer vision, have gained traction in the security domain due to their ability to model complex dependencies, offering enhanced capabilities in identifying vulnerabilities, detecting anomalies, and reinforcing system integrity. This survey provides a comprehensive review of recent advancements on the use of Transformers in hardware security, examining their application across key areas such as side-channel analysis, hardware Trojan detection, vulnerability classification, device fingerprinting, and firmware security. Furthermore, we discuss the practical challenges of applying Transformers to secure hardware systems, and highlight opportunities and future research directions that position them as a foundation for next-generation hardware-assisted security. These insights pave the way for deeper integration of AI-driven techniques into hardware security frameworks, enabling more resilient and intelligent defenses.","authors":["Banafsheh Saber Latibari","Najmeh Nazari","Avesta Sasan","Houman Homayoun","Pratik Satam","Soheil Salehi","Hossein Sayadi"],"url":"https://arxiv.org/abs/2505.22605"}
{"created":"2025-05-29","title":"Effective and Efficient One-pass Compression of Speech Foundation Models Using Sparsity-aware Self-pinching Gates","abstract":"This paper presents a novel approach for speech foundation models compression that tightly integrates model pruning and parameter update into a single stage. Highly compact layer-level tied self-pinching gates each containing only a single learnable threshold are jointly trained with uncompressed models and used in fine-grained neuron level pruning. Experiments conducted on the LibriSpeech-100hr corpus suggest that our approach reduces the number of parameters of wav2vec2.0-base and HuBERT-large models by 65% and 60% respectively, while incurring no statistically significant word error rate (WER) increase on the test-clean dataset. Compared to previously published methods on the same task, our approach not only achieves the lowest WER of 7.05% on the test-clean dataset under a comparable model compression ratio of 4.26x, but also operates with at least 25% less model compression time.","authors":["Haoning Xu","Zhaoqing Li","Youjun Chen","Huimeng Wang","Guinan Li","Mengzhe Geng","Chengxi Deng","Xunying Liu"],"url":"https://arxiv.org/abs/2505.22608"}
{"created":"2025-05-29","title":"TPDE: A Fast Adaptable Compiler Back-End Framework","abstract":"Fast machine code generation is especially important for fast start-up just-in-time compilation, where the compilation time is part of the end-to-end latency. However, widely used compiler frameworks like LLVM do not prioritize fast compilation and require an extra IR translation step increasing latency even further; and rolling a custom code generator is a substantial engineering effort, especially when targeting multiple architectures.","authors":["Tobias Schwarz (Technical University of Munich)","Tobias Kamm (Technical University of Munich)","Alexis Engelke (Technical University of Munich)"],"url":"https://arxiv.org/abs/2505.22610"}
{"created":"2025-05-29","title":"BPMN to Smart Contract by Business Analyst","abstract":"This paper addresses the challenge of creating smart contracts for applications represented using Business Process Management and Notation (BPMN) models. In our prior work we presented a methodology that automates the generation of smart contracts from BPMN models. This approach abstracts the BPMN flow control, making it independent of the underlying blockchain infrastructure, with only the BPMN task elements requiring coding. In subsequent research, we enhanced our approach by adding support for nested transactions and enabling a smart contract repair and/or upgrade. To empower Business Analysts (BAs) to generate smart contracts without relying on software developers, we tackled the challenge of generating smart contracts from BPMN models without assistance of a software developer. We exploit the Decision Model and Notation (DMN) standard to represent the decisions and the business logic of the BPMN task elements and amended our methodology for transformation of BPMN models into smart contracts to support also the generation script to represent the business logic represented by the DMN models. To support such transformation, we describe how the BA documents, using the BPMN elements, the flow of information along with the flow of execution. Thus, if the BA is successful in representing the blockchain application requirements using BPMN and DMN models, our methodology and the tool, called TABS, that we developed as a proof of concept, is used to generate the smart contracts directly from those models without developer assistance.","authors":["C. G. Liu","P. Bodorik","D. Jutla"],"url":"https://arxiv.org/abs/2505.22612"}
{"created":"2025-05-29","title":"RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction","abstract":"Image recaptioning is widely used to generate training datasets with enhanced quality for various multimodal tasks. Existing recaptioning methods typically rely on powerful multimodal large language models (MLLMs) to enhance textual descriptions, but often suffer from inaccuracies due to hallucinations and incompleteness caused by missing fine-grained details. To address these limitations, we propose RICO, a novel framework that refines captions through visual reconstruction. Specifically, we leverage a text-to-image model to reconstruct a caption into a reference image, and prompt an MLLM to identify discrepancies between the original and reconstructed images to refine the caption. This process is performed iteratively, further progressively promoting the generation of more faithful and comprehensive descriptions. To mitigate the additional computational cost induced by the iterative process, we introduce RICO-Flash, which learns to generate captions like RICO using DPO. Extensive experiments demonstrate that our approach significantly improves caption accuracy and completeness, outperforms most baselines by approximately 10% on both CapsBench and CompreCap. Code released at https://github.com/wangyuchi369/RICO.","authors":["Yuchi Wang","Yishuo Cai","Shuhuai Ren","Sihan Yang","Linli Yao","Yuanxin Liu","Yuanxing Zhang","Pengfei Wan","Xu Sun"],"url":"https://arxiv.org/abs/2505.22613"}
{"created":"2025-05-29","title":"PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization","abstract":"Neural rendering methods have gained significant attention for their ability to reconstruct 3D scenes from 2D images. The core idea is to take multiple views as input and optimize the reconstructed scene by minimizing the uncertainty in geometry and appearance across the views. However, the reconstruction quality is limited by the number of input views. This limitation is further pronounced in complex and dynamic scenes, where certain angles of objects are never seen. In this paper, we propose to use video frame interpolation as the data augmentation method for neural rendering. Furthermore, we design a lightweight yet high-quality video frame interpolation model, PS4PRO (Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization). PS4PRO is trained on diverse video datasets, implicitly modeling camera movement as well as real-world 3D geometry. Our model performs as an implicit world prior, enriching the photo supervision for 3D reconstruction. By leveraging the proposed method, we effectively augment existing datasets for neural rendering methods. Our experimental results indicate that our method improves the reconstruction performance on both static and dynamic scenes.","authors":["Yezhi Shen","Qiuchen Zhai","Fengqing Zhu"],"url":"https://arxiv.org/abs/2505.22616"}
{"created":"2025-05-29","title":"The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models","abstract":"This paper aims to overcome a major obstacle in scaling RL for reasoning with LLMs, namely the collapse of policy entropy. Such phenomenon is consistently observed across vast RL runs without entropy intervention, where the policy entropy dropped sharply at the early training stage, this diminished exploratory ability is always accompanied with the saturation of policy performance. In practice, we establish a transformation equation R=-a*e^H+b between entropy H and downstream performance R. This empirical law strongly indicates that, the policy performance is traded from policy entropy, thus bottlenecked by its exhaustion, and the ceiling is fully predictable H=0, R=-a+b. Our finding necessitates entropy management for continuous exploration toward scaling compute for RL. To this end, we investigate entropy dynamics both theoretically and empirically. Our derivation highlights that, the change in policy entropy is driven by the covariance between action probability and the change in logits, which is proportional to its advantage when using Policy Gradient-like algorithms. Empirical study shows that, the values of covariance term and entropy differences matched exactly, supporting the theoretical conclusion. Moreover, the covariance term stays mostly positive throughout training, further explaining why policy entropy would decrease monotonically. Through understanding the mechanism behind entropy dynamics, we motivate to control entropy by restricting the update of high-covariance tokens. Specifically, we propose two simple yet effective techniques, namely Clip-Cov and KL-Cov, which clip and apply KL penalty to tokens with high covariances respectively. Experiments show that these methods encourage exploration, thus helping policy escape entropy collapse and achieve better downstream performance.","authors":["Ganqu Cui","Yuchen Zhang","Jiacheng Chen","Lifan Yuan","Zhi Wang","Yuxin Zuo","Haozhan Li","Yuchen Fan","Huayu Chen","Weize Chen","Zhiyuan Liu","Hao Peng","Lei Bai","Wanli Ouyang","Yu Cheng","Bowen Zhou","Ning Ding"],"url":"https://arxiv.org/abs/2505.22617"}
{"created":"2025-05-29","title":"Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding","abstract":"Diffusion-based large language models (Diffusion LLMs) have shown promise for non-autoregressive text generation with parallel decoding capabilities. However, the practical inference speed of open-sourced Diffusion LLMs often lags behind autoregressive models due to the lack of Key-Value (KV) Cache and quality degradation when decoding multiple tokens simultaneously. To bridge this gap, we introduce a novel block-wise approximate KV Cache mechanism tailored for bidirectional diffusion models, enabling cache reuse with negligible performance drop. Additionally, we identify the root cause of generation quality degradation in parallel decoding as the disruption of token dependencies under the conditional independence assumption. To address this, we propose a confidence-aware parallel decoding strategy that selectively decodes tokens exceeding a confidence threshold, mitigating dependency violations and maintaining generation quality. Experimental results on LLaDA and Dream models across multiple LLM benchmarks demonstrate up to \\textbf{27.6$\\times$ throughput} improvement with minimal accuracy loss, closing the performance gap with autoregressive models and paving the way for practical deployment of Diffusion LLMs.","authors":["Chengyue Wu","Hao Zhang","Shuchen Xue","Zhijian Liu","Shizhe Diao","Ligeng Zhu","Ping Luo","Song Han","Enze Xie"],"url":"https://arxiv.org/abs/2505.22618"}
{"created":"2025-05-29","title":"Smart Contracts for SMEs and Large Companies","abstract":"Research on blockchains addresses multiple issues, with one being writing smart contracts. In our previous research we described methodology and a tool to generate, in automated fashion, smart contracts from BPMN models. The generated smart contracts provide support for multi-step transactions that facilitate repair/upgrade of smart contracts. In this paper we show how the approach is used to support collaborations via smart contracts for companies ranging from SMEs with little IT capabilities to companies with IT using blockchain smart contracts. Furthermore, we also show how the approach is used for certain applications to generate smart contracts by a BPMN modeler who does not need any knowledge of blockchain technology or smart contract development - thus we are hoping to facilitate democratization of smart contracts and blockchain technology.","authors":["C. G. Liu","P. Bodorik","D. Jutla"],"url":"https://arxiv.org/abs/2505.22619"}
{"created":"2025-05-29","title":"SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning","abstract":"Imitation learning advances robot capabilities by enabling the acquisition of diverse behaviors from human demonstrations. However, large-scale datasets used for policy training often introduce substantial variability in quality, which can negatively impact performance. As a result, automatically curating datasets by filtering low-quality samples to improve quality becomes essential. Existing robotic curation approaches rely on costly manual annotations and perform curation at a coarse granularity, such as the dataset or trajectory level, failing to account for the quality of individual state-action pairs. To address this, we introduce SCIZOR, a self-supervised data curation framework that filters out low-quality state-action pairs to improve the performance of imitation learning policies. SCIZOR targets two complementary sources of low-quality data: suboptimal data, which hinders learning with undesirable actions, and redundant data, which dilutes training with repetitive patterns. SCIZOR leverages a self-supervised task progress predictor for suboptimal data to remove samples lacking task progression, and a deduplication module operating on joint state-action representation for samples with redundant patterns. Empirically, we show that SCIZOR enables imitation learning policies to achieve higher performance with less data, yielding an average improvement of 15.4% across multiple benchmarks. More information is available at: https://ut-austin-rpl.github.io/SCIZOR/","authors":["Yu Zhang","Yuqi Xie","Huihan Liu","Rutav Shah","Michael Wan","Linxi Fan","Yuke Zhu"],"url":"https://arxiv.org/abs/2505.22626"}
{"created":"2025-05-29","title":"Chain-of-Talkers (CoTalk): Fast Human Annotation of Dense Image Captions","abstract":"While densely annotated image captions significantly facilitate the learning of robust vision-language alignment, methodologies for systematically optimizing human annotation efforts remain underexplored. We introduce Chain-of-Talkers (CoTalk), an AI-in-the-loop methodology designed to maximize the number of annotated samples and improve their comprehensiveness under fixed budget constraints (e.g., total human annotation time). The framework is built upon two key insights. First, sequential annotation reduces redundant workload compared to conventional parallel annotation, as subsequent annotators only need to annotate the ``residual'' -- the missing visual information that previous annotations have not covered. Second, humans process textual input faster by reading while outputting annotations with much higher throughput via talking; thus a multimodal interface enables optimized efficiency. We evaluate our framework from two aspects: intrinsic evaluations that assess the comprehensiveness of semantic units, obtained by parsing detailed captions into object-attribute trees and analyzing their effective connections; extrinsic evaluation measures the practical usage of the annotated captions in facilitating vision-language alignment. Experiments with eight participants show our Chain-of-Talkers (CoTalk) improves annotation speed (0.42 vs. 0.30 units/sec) and retrieval performance (41.13\\% vs. 40.52\\%) over the parallel method.","authors":["Yijun Shen","Delong Chen","Fan Liu","Xingyu Wang","Chuanyi Zhang","Liang Yao","Yuhui Zheng"],"url":"https://arxiv.org/abs/2505.22627"}
{"created":"2025-05-29","title":"Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs","abstract":"The widespread success of large language models (LLMs) on NLP benchmarks has been accompanied by concerns that LLMs function primarily as stochastic parrots that reproduce texts similar to what they saw during pre-training, often erroneously. But what is the nature of their errors, and do these errors exhibit any regularities? In this work, we examine irrelevant context hallucinations, in which models integrate misleading contextual cues into their predictions. Through behavioral analysis, we show that these errors result from a structured yet flawed mechanism that we term class-based (mis)generalization, in which models combine abstract class cues with features extracted from the query or context to derive answers. Furthermore, mechanistic interpretability experiments on Llama-3, Mistral, and Pythia across 39 factual recall relation types reveal that this behavior is reflected in the model's internal computations: (i) abstract class representations are constructed in lower layers before being refined into specific answers in higher layers, (ii) feature selection is governed by two competing circuits -- one prioritizing direct query-based reasoning, the other incorporating contextual cues -- whose relative influences determine the final output. Our findings provide a more nuanced perspective on the stochastic parrot argument: through form-based training, LLMs can exhibit generalization leveraging abstractions, albeit in unreliable ways based on contextual cues -- what we term stochastic chameleons.","authors":["Ziling Cheng","Meng Cao","Marc-Antoine Rondeau","Jackie Chi Kit Cheung"],"url":"https://arxiv.org/abs/2505.22630"}
{"created":"2025-05-29","title":"GPU-Accelerated Simulated Oscillator Ising/Potts Machine Solving Combinatorial Optimization Problems","abstract":"Oscillator-based Ising machines (OIMs) and oscillator-based Potts machines (OPMs) have emerged as promising hardware accelerators for solving NP-hard combinatorial optimization problems by leveraging the phase dynamics of coupled oscillators. In this work, a GPU-accelerated simulated OIM/OPM digital computation framework capable of solving combinatorial optimization problems is presented. The proposed implementation harnesses the parallel processing capabilities of GPUs to simulate large-scale OIM/OPMs, leveraging the advantages of digital computing to offer high precision, programmability, and scalability. The performance of the proposed GPU framework is evaluated on the max-cut problems from the GSET benchmark dataset and graph coloring problems from the SATLIB benchmarks dataset, demonstrating competitive speed and accuracy in tackling large-scale problems. The results from simulations, reaching up to 11295x speed-up over CPUs with up to 99% accuracy, establish this framework as a scalable, massively parallelized, and high-fidelity digital realization of OIM/OPMs.","authors":["Yilmaz Ege Gonul","Ceyhun Efe Kayan","Ilknur Mustafazade","Nagarajan Kandasamy","Baris Taskin"],"url":"https://arxiv.org/abs/2505.22631"}
{"created":"2025-05-29","title":"Spatial Knowledge Graph-Guided Multimodal Synthesis","abstract":"Recent advances in multimodal large language models (MLLMs) have significantly enhanced their capabilities; however, their spatial perception abilities remain a notable limitation. To address this challenge, multimodal data synthesis offers a promising solution. Yet, ensuring that synthesized data adhere to spatial common sense is a non-trivial task. In this work, we introduce SKG2Data, a novel multimodal synthesis approach guided by spatial knowledge graphs, grounded in the concept of knowledge-to-data generation. SKG2Data automatically constructs a Spatial Knowledge Graph (SKG) to emulate human-like perception of spatial directions and distances, which is subsequently utilized to guide multimodal data synthesis. Extensive experiments demonstrate that data synthesized from diverse types of spatial knowledge, including direction and distance, not only enhance the spatial perception and reasoning abilities of MLLMs but also exhibit strong generalization capabilities. We hope that the idea of knowledge-based data synthesis can advance the development of spatial intelligence.","authors":["Yida Xue","Zhen Bi","Jinnan Yang","Jungang Lou","Huajun Chen","Ningyu Zhang"],"url":"https://arxiv.org/abs/2505.22633"}
{"created":"2025-05-29","title":"LabUtopia: High-Fidelity Simulation and Hierarchical Benchmark for Scientific Embodied Agents","abstract":"Scientific embodied agents play a crucial role in modern laboratories by automating complex experimental workflows. Compared to typical household environments, laboratory settings impose significantly higher demands on perception of physical-chemical transformations and long-horizon planning, making them an ideal testbed for advancing embodied intelligence. However, its development has been long hampered by the lack of suitable simulator and benchmarks. In this paper, we address this gap by introducing LabUtopia, a comprehensive simulation and benchmarking suite designed to facilitate the development of generalizable, reasoning-capable embodied agents in laboratory settings. Specifically, it integrates i) LabSim, a high-fidelity simulator supporting multi-physics and chemically meaningful interactions; ii) LabScene, a scalable procedural generator for diverse scientific scenes; and iii) LabBench, a hierarchical benchmark spanning five levels of complexity from atomic actions to long-horizon mobile manipulation. LabUtopia supports 30 distinct tasks and includes more than 200 scene and instrument assets, enabling large-scale training and principled evaluation in high-complexity environments. We demonstrate that LabUtopia offers a powerful platform for advancing the integration of perception, planning, and control in scientific-purpose agents and provides a rigorous testbed for exploring the practical capabilities and generalization limits of embodied intelligence in future research.","authors":["Rui Li","Zixuan Hu","Wenxi Qu","Jinouwen Zhang","Zhenfei Yin","Sha Zhang","Xuantuo Huang","Hanqing Wang","Tai Wang","Jiangmiao Pang","Wanli Ouyang","Lei Bai","Wangmeng Zuo","Ling-Yu Duan","Dongzhan Zhou","Shixiang Tang"],"url":"https://arxiv.org/abs/2505.22634"}
{"created":"2025-05-29","title":"Learning Composable Chains-of-Thought","abstract":"A common approach for teaching large language models (LLMs) to reason is to train on chain-of-thought (CoT) traces of in-distribution reasoning problems, but such annotated data is costly to obtain for every problem of interest. We want reasoning models to generalize beyond their training distribution, and ideally to generalize compositionally: combine atomic reasoning skills to solve harder, unseen reasoning tasks. We take a step towards compositional generalization of reasoning skills when addressing a target compositional task that has no labeled CoT data. We find that simply training models on CoT data of atomic tasks leads to limited generalization, but minimally modifying CoT formats of constituent atomic tasks to be composable can lead to improvements. We can train \"atomic CoT\" models on the atomic tasks with Composable CoT data and combine them with multitask learning or model merging for better zero-shot performance on the target compositional task. Such a combined model can be further bootstrapped on a small amount of compositional data using rejection sampling fine-tuning (RFT). Results on string operations and natural language skill compositions show that training LLMs on Composable CoT outperforms multitask learning and continued fine-tuning baselines within a given training data budget.","authors":["Fangcong Yin","Zeyu Leo Liu","Liu Leqi","Xi Ye","Greg Durrett"],"url":"https://arxiv.org/abs/2505.22635"}
{"created":"2025-05-29","title":"ObjectClear: Complete Object Removal via Object-Effect Attention","abstract":"Object removal requires eliminating not only the target object but also its effects, such as shadows and reflections. However, diffusion-based inpainting methods often produce artifacts, hallucinate content, alter background, and struggle to remove object effects accurately. To address this challenge, we introduce a new dataset for OBject-Effect Removal, named OBER, which provides paired images with and without object effects, along with precise masks for both objects and their associated visual artifacts. The dataset comprises high-quality captured and simulated data, covering diverse object categories and complex multi-object scenes. Building on OBER, we propose a novel framework, ObjectClear, which incorporates an object-effect attention mechanism to guide the model toward the foreground removal regions by learning attention masks, effectively decoupling foreground removal from background reconstruction. Furthermore, the predicted attention map enables an attention-guided fusion strategy during inference, greatly preserving background details. Extensive experiments demonstrate that ObjectClear outperforms existing methods, achieving improved object-effect removal quality and background fidelity, especially in complex scenarios.","authors":["Jixin Zhao","Shangchen Zhou","Zhouxia Wang","Peiqing Yang","Chen Change Loy"],"url":"https://arxiv.org/abs/2505.22636"}
{"created":"2025-05-29","title":"Understanding (Un)Reliability of Steering Vectors in Language Models","abstract":"Steering vectors are a lightweight method to control language model behavior by adding a learned bias to the activations at inference time. Although steering demonstrates promising performance, recent work shows that it can be unreliable or even counterproductive in some cases. This paper studies the influence of prompt types and the geometry of activation differences on steering reliability. First, we find that all seven prompt types used in our experiments produce a net positive steering effect, but exhibit high variance across samples, and often give an effect opposite of the desired one. No prompt type clearly outperforms the others, and yet the steering vectors resulting from the different prompt types often differ directionally (as measured by cosine similarity). Second, we show that higher cosine similarity between training set activation differences predicts more effective steering. Finally, we observe that datasets where positive and negative activations are better separated are more steerable. Our results suggest that vector steering is unreliable when the target behavior is not represented by a coherent direction.","authors":["Joschka Braun","Carsten Eickhoff","David Krueger","Seyed Ali Bahrainian","Dmitrii Krasheninnikov"],"url":"https://arxiv.org/abs/2505.22637"}
{"created":"2025-05-29","title":"SimProcess: High Fidelity Simulation of Noisy ICS Physical Processes","abstract":"Industrial Control Systems (ICS) manage critical infrastructures like power grids and water treatment plants. Cyberattacks on ICSs can disrupt operations, causing severe economic, environmental, and safety issues. For example, undetected pollution in a water plant can put the lives of thousands at stake. ICS researchers have increasingly turned to honeypots -- decoy systems designed to attract attackers, study their behaviors, and eventually improve defensive mechanisms. However, existing ICS honeypots struggle to replicate the ICS physical process, making them susceptible to detection. Accurately simulating the noise in ICS physical processes is challenging because different factors produce it, including sensor imperfections and external interferences.","authors":["Denis Donadel","Gabriele Crestanello","Giulio Morandini","Daniele Antonioli","Mauro Conti","Massimo Merro"],"url":"https://arxiv.org/abs/2505.22638"}
{"created":"2025-05-29","title":"Navigating the AI-Energy Nexus with Geopolitical Insight","abstract":"This working paper examines how geopolitical strategies and energy resource management intersect with Artificial Intelligence (AI) development, delineating the AI-energy nexus as critical to sustaining U.S. AI leadership. By analyzing the centralized approaches of authoritarian regimes like China and Gulf nations, alongside market-driven approaches in the U.S., the paper explores divergent strategies to allocate resources for AI energy needs. It underscores the role of energy infrastructure, market dynamics, and state-led initiatives in shaping global AI competition. Recommendations include adopting geopolitically informed analyses and leveraging both market and non-market strengths to enhance U.S. competitiveness. This research aims to inform policymakers, technologists, and researchers about the strategic implications of the AI-energy nexus and offers insights into advancing U.S. global leadership in AI amidst evolving technological paradigms.","authors":["Nidhi Kalra","Robin Wang","Ismael Arciniegas Rueda"],"url":"https://arxiv.org/abs/2505.22639"}
{"created":"2025-05-29","title":"Spectral Survival Analysis","abstract":"Survival analysis is widely deployed in a diverse set of fields, including healthcare, business, ecology, etc. The Cox Proportional Hazard (CoxPH) model is a semi-parametric model often encountered in the literature. Despite its popularity, wide deployment, and numerous variants, scaling CoxPH to large datasets and deep architectures poses a challenge, especially in the high-dimensional regime. We identify a fundamental connection between rank regression and the CoxPH model: this allows us to adapt and extend the so-called spectral method for rank regression to survival analysis. Our approach is versatile, naturally generalizing to several CoxPH variants, including deep models. We empirically verify our method's scalability on multiple real-world high-dimensional datasets; our method outperforms legacy methods w.r.t. predictive performance and efficiency.","authors":["Chengzhi Shi","Stratis Ioannidis"],"url":"https://arxiv.org/abs/2505.22641"}
{"created":"2025-05-29","title":"FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control","abstract":"Reinforcement learning (RL) has driven significant progress in robotics, but its complexity and long training times remain major bottlenecks. In this report, we introduce FastTD3, a simple, fast, and capable RL algorithm that significantly speeds up training for humanoid robots in popular suites such as HumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably simple: we train an off-policy TD3 agent with several modifications -- parallel simulation, large-batch updates, a distributional critic, and carefully tuned hyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours on a single A100 GPU, while remaining stable during training. We also provide a lightweight and easy-to-use implementation of FastTD3 to accelerate RL research in robotics.","authors":["Younggyo Seo","Carmelo Sferrazza","Haoran Geng","Michal Nauman","Zhao-Heng Yin","Pieter Abbeel"],"url":"https://arxiv.org/abs/2505.22642"}
{"created":"2025-05-29","title":"SPIRAL: Semantic-Aware Progressive LiDAR Scene Generation","abstract":"Leveraging recent diffusion models, LiDAR-based large-scale 3D scene generation has achieved great success. While recent voxel-based approaches can generate both geometric structures and semantic labels, existing range-view methods are limited to producing unlabeled LiDAR scenes. Relying on pretrained segmentation models to predict the semantic maps often results in suboptimal cross-modal consistency. To address this limitation while preserving the advantages of range-view representations, such as computational efficiency and simplified network design, we propose Spiral, a novel range-view LiDAR diffusion model that simultaneously generates depth, reflectance images, and semantic maps. Furthermore, we introduce novel semantic-aware metrics to evaluate the quality of the generated labeled range-view data. Experiments on the SemanticKITTI and nuScenes datasets demonstrate that Spiral achieves state-of-the-art performance with the smallest parameter size, outperforming two-step methods that combine the generative and segmentation models. Additionally, we validate that range images generated by Spiral can be effectively used for synthetic data augmentation in the downstream segmentation training, significantly reducing the labeling effort on LiDAR data.","authors":["Dekai Zhu","Yixuan Hu","Youquan Liu","Dongyue Lu","Lingdong Kong","Slobodan Ilic"],"url":"https://arxiv.org/abs/2505.22643"}
{"created":"2025-05-29","title":"On the Intractability of Chaotic Symbolic Walks: Toward a Non-Algebraic Post-Quantum Hardness Assumption","abstract":"Most classical and post-quantum cryptographic assumptions, including integer factorization, discrete logarithms, and Learning with Errors (LWE), rely on algebraic structures such as rings or vector spaces. While mathematically powerful, these structures can be exploited by quantum algorithms or advanced algebraic attacks, raising a pressing need for structure-free alternatives. To address this gap, we introduce the Symbolic Path Inversion Problem (SPIP), a new computational hardness assumption based on symbolic trajectories generated by contractive affine maps with bounded noise over Z2. Unlike traditional systems, SPIP is inherently non-algebraic and relies on chaotic symbolic evolution and rounding-induced non-injectivity to render inversion computationally infeasible. We prove that SPIP is PSPACE-hard and #P-hard, and demonstrate through empirical simulation that even short symbolic sequences (e.g., n = 3, m = 2) can produce over 500 valid trajectories for a single endpoint, with exponential growth reaching 2256 paths for moderate parameters. A quantum security analysis further shows that Grover-style search offers no practical advantage due to oracle ambiguity and verification instability. These results position SPIP as a viable foundation for post-quantum cryptography that avoids the vulnerabilities of algebraic symmetry while offering scalability, unpredictability, and resistance to both classical and quantum inversion.","authors":["Mohamed Aly Bouke"],"url":"https://arxiv.org/abs/2505.22644"}
{"created":"2025-05-29","title":"Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese","abstract":"While the capabilities of Large Language Models (LLMs) have been studied in both Simplified and Traditional Chinese, it is yet unclear whether LLMs exhibit differential performance when prompted in these two variants of written Chinese. This understanding is critical, as disparities in the quality of LLM responses can perpetuate representational harms by ignoring the different cultural contexts underlying Simplified versus Traditional Chinese, and can exacerbate downstream harms in LLM-facilitated decision-making in domains such as education or hiring. To investigate potential LLM performance disparities, we design two benchmark tasks that reflect real-world scenarios: regional term choice (prompting the LLM to name a described item which is referred to differently in Mainland China and Taiwan), and regional name choice (prompting the LLM to choose who to hire from a list of names in both Simplified and Traditional Chinese). For both tasks, we audit the performance of 11 leading commercial LLM services and open-sourced models -- spanning those primarily trained on English, Simplified Chinese, or Traditional Chinese. Our analyses indicate that biases in LLM responses are dependent on both the task and prompting language: while most LLMs disproportionately favored Simplified Chinese responses in the regional term choice task, they surprisingly favored Traditional Chinese names in the regional name choice task. We find that these disparities may arise from differences in training data representation, written character preferences, and tokenization of Simplified and Traditional Chinese. These findings highlight the need for further analysis of LLM biases; as such, we provide an open-sourced benchmark dataset to foster reproducible evaluations of future LLM behavior across Chinese language variants (https://github.com/brucelyu17/SC-TC-Bench).","authors":["Hanjia Lyu","Jiebo Luo","Jian Kang","Allison Koenecke"],"url":"https://arxiv.org/abs/2505.22645"}
{"created":"2025-05-29","title":"Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation","abstract":"Audio-driven human animation methods, such as talking head and talking body generation, have made remarkable progress in generating synchronized facial movements and appealing visual quality videos. However, existing methods primarily focus on single human animation and struggle with multi-stream audio inputs, facing incorrect binding problems between audio and persons. Additionally, they exhibit limitations in instruction-following capabilities. To solve this problem, in this paper, we propose a novel task: Multi-Person Conversational Video Generation, and introduce a new framework, MultiTalk, to address the challenges during multi-person generation. Specifically, for audio injection, we investigate several schemes and propose the Label Rotary Position Embedding (L-RoPE) method to resolve the audio and person binding problem. Furthermore, during training, we observe that partial parameter training and multi-task training are crucial for preserving the instruction-following ability of the base model. MultiTalk achieves superior performance compared to other methods on several datasets, including talking head, talking body, and multi-person datasets, demonstrating the powerful generation capabilities of our approach.","authors":["Zhe Kong","Feng Gao","Yong Zhang","Zhuoliang Kang","Xiaoming Wei","Xunliang Cai","Guanying Chen","Wenhan Luo"],"url":"https://arxiv.org/abs/2505.22647"}
{"created":"2025-05-29","title":"WebDancer: Towards Autonomous Information Seeking Agency","abstract":"Addressing intricate real-world problems necessitates in-depth information seeking and multi-step reasoning. Recent progress in agentic systems, exemplified by Deep Research, underscores the potential for autonomous multi-step research. In this work, we present a cohesive paradigm for building end-to-end agentic information seeking agents from a data-centric and training-stage perspective. Our approach consists of four key stages: (1) browsing data construction, (2) trajectories sampling, (3) supervised fine-tuning for effective cold start, and (4) reinforcement learning for enhanced generalisation. We instantiate this framework in a web agent based on the ReAct, WebDancer. Empirical evaluations on the challenging information seeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of WebDancer, achieving considerable results and highlighting the efficacy of our training paradigm. Further analysis of agent training provides valuable insights and actionable, systematic pathways for developing more capable agentic models. The codes and demo will be released in https://github.com/Alibaba-NLP/WebAgent.","authors":["Jialong Wu","Baixuan Li","Runnan Fang","Wenbiao Yin","Liwen Zhang","Zhengwei Tao","Dingchu Zhang","Zekun Xi","Yong Jiang","Pengjun Xie","Fei Huang","Jingren Zhou"],"url":"https://arxiv.org/abs/2505.22648"}
{"created":"2025-05-29","title":"Pre-training for Recommendation Unlearning","abstract":"Modern recommender systems powered by Graph Neural Networks (GNNs) excel at modeling complex user-item interactions, yet increasingly face scenarios requiring selective forgetting of training data. Beyond user requests to remove specific interactions due to privacy concerns or preference changes, regulatory frameworks mandate recommender systems' ability to eliminate the influence of certain user data from models. This recommendation unlearning challenge presents unique difficulties as removing connections within interaction graphs creates ripple effects throughout the model, potentially impacting recommendations for numerous users. Traditional approaches suffer from significant drawbacks: fragmentation methods damage graph structure and diminish performance, while influence function techniques make assumptions that may not hold in complex GNNs, particularly with self-supervised or random architectures. To address these limitations, we propose a novel model-agnostic pre-training paradigm UnlearnRec that prepares systems for efficient unlearning operations. Our Influence Encoder takes unlearning requests together with existing model parameters and directly produces updated parameters of unlearned model with little fine-tuning, avoiding complete retraining while preserving model performance characteristics. Extensive evaluation on public benchmarks demonstrates that our method delivers exceptional unlearning effectiveness while providing more than 10x speedup compared to retraining approaches. We release our method implementation at: https://github.com/HKUDS/UnlearnRec.","authors":["Guoxuan Chen","Lianghao Xia","Chao Huang"],"url":"https://arxiv.org/abs/2505.22649"}
{"created":"2025-05-29","title":"On Learning Verifiers for Chain-of-Thought Reasoning","abstract":"Chain-of-Thought reasoning has emerged as a powerful approach for solving complex mathematical and logical problems. However, it can often veer off track through incorrect or unsubstantiated inferences. Formal mathematical reasoning, which can be checked with a formal verifier, is one approach to addressing this issue. However, currently LLMs are simply not good enough to solve complex problems in a formal way, and even just formalizing an informal problem statement can be challenging. Motivated by this fact, in this work we consider the problem of learning reliable verifiers for natural language Chain-of-Thought reasoning. That is, given a problem statement and step-by-step solution in natural language, the aim of the verifier is to output [Yes] if the reasoning steps in the solution are all valid, and [No] otherwise. In this work we give a formal PAC-learning framework for studying this problem. We propose and analyze several natural verification goals, at different levels of strength, in this framework. We provide sample complexity upper-bounds for learning verifiers satisfying these goals, as well as lower-bound and impossibility results for learning other natural verification objectives without additional assumptions.","authors":["Maria-Florina Balcan","Avrim Blum","Zhiyuan Li","Dravyansh Sharma"],"url":"https://arxiv.org/abs/2505.22650"}
{"created":"2025-05-29","title":"Sherlock: Self-Correcting Reasoning in Vision-Language Models","abstract":"Reasoning Vision-Language Models (VLMs) have shown promising performance on complex multimodal tasks. However, they still face significant challenges: they are highly sensitive to reasoning errors, require large volumes of annotated data or accurate verifiers, and struggle to generalize beyond specific domains. To address these limitations, we explore self-correction as a strategy to enhance reasoning VLMs. We first conduct an in-depth analysis of reasoning VLMs' self-correction abilities and identify key gaps. Based on our findings, we introduce Sherlock, a self-correction and self-improvement training framework. Sherlock introduces a trajectory-level self-correction objective, a preference data construction method based on visual perturbation, and a dynamic $\\beta$ for preference tuning. Once the model acquires self-correction capabilities using only 20k randomly sampled annotated data, it continues to self-improve without external supervision. Built on the Llama3.2-Vision-11B model, Sherlock achieves remarkable results across eight benchmarks, reaching an average accuracy of 64.1 with direct generation and 65.4 after self-correction. It outperforms LLaVA-CoT (63.2), Mulberry (63.9), and LlamaV-o1 (63.4) while using less than 20% of the annotated data.","authors":["Yi Ding","Ruqi Zhang"],"url":"https://arxiv.org/abs/2505.22651"}
{"created":"2025-05-29","title":"The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in Learning to Reason","abstract":"Recent studies on post-training large language models (LLMs) for reasoning through reinforcement learning (RL) typically focus on tasks that can be accurately verified and rewarded, such as solving math problems. In contrast, our research investigates the impact of reward noise, a more practical consideration for real-world scenarios involving the post-training of LLMs using reward models. We found that LLMs demonstrate strong robustness to substantial reward noise. For example, manually flipping 40% of the reward function's outputs in math tasks still allows a Qwen-2.5-7B model to achieve rapid convergence, improving its performance on math tasks from 5% to 72%, compared to the 75% accuracy achieved by a model trained with noiseless rewards. Surprisingly, by only rewarding the appearance of key reasoning phrases (namely reasoning pattern reward, RPR), such as ``first, I need to''-without verifying the correctness of answers, the model achieved peak downstream performance (over 70% accuracy for Qwen-2.5-7B) comparable to models trained with strict correctness verification and accurate rewards. Recognizing the importance of the reasoning process over the final results, we combined RPR with noisy reward models. RPR helped calibrate the noisy reward models, mitigating potential false negatives and enhancing the LLM's performance on open-ended tasks. These findings suggest the importance of improving models' foundational abilities during the pre-training phase while providing insights for advancing post-training techniques. Our code and scripts are available at https://github.com/trestad/Noisy-Rewards-in-Learning-to-Reason.","authors":["Ang Lv","Ruobing Xie","Xingwu Sun","Zhanhui Kang","Rui Yan"],"url":"https://arxiv.org/abs/2505.22653"}
{"created":"2025-05-29","title":"VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models","abstract":"Recent Large Vision-Language Models (LVLMs) have advanced multi-modal understanding by incorporating finer-grained visual perception and encoding. However, such methods incur significant computational costs due to longer visual token sequences, posing challenges for real-time deployment. To mitigate this, prior studies have explored pruning unimportant visual tokens either at the output layer of the visual encoder or at the early layers of the language model. In this work, we revisit these design choices and reassess their effectiveness through comprehensive empirical studies of how visual tokens are processed throughout the visual encoding and language decoding stages. Guided by these insights, we propose VScan, a two-stage visual token reduction framework that addresses token redundancy by: (1) integrating complementary global and local scans with token merging during visual encoding, and (2) introducing pruning at intermediate layers of the language model. Extensive experimental results across four LVLMs validate the effectiveness of VScan in accelerating inference and demonstrate its superior performance over current state-of-the-arts on sixteen benchmarks. Notably, when applied to LLaVA-NeXT-7B, VScan achieves a 2.91$\\times$ speedup in prefilling and a 10$\\times$ reduction in FLOPs, while retaining 95.4% of the original performance.","authors":["Ce Zhang","Kaixin Ma","Tianqing Fang","Wenhao Yu","Hongming Zhang","Zhisong Zhang","Yaqi Xie","Katia Sycara","Haitao Mi","Dong Yu"],"url":"https://arxiv.org/abs/2505.22654"}
{"created":"2025-05-29","title":"Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents","abstract":"Large-language models (LLMs) and chatbot agents are known to provide wrong outputs at times, and it was recently found that this can never be fully prevented. Hence, uncertainty quantification plays a crucial role, aiming to quantify the level of ambiguity in either one overall number or two numbers for aleatoric and epistemic uncertainty. This position paper argues that this traditional dichotomy of uncertainties is too limited for the open and interactive setup that LLM agents operate in when communicating with a user, and that we need to research avenues that enrich uncertainties in this novel scenario. We review the literature and find that popular definitions of aleatoric and epistemic uncertainties directly contradict each other and lose their meaning in interactive LLM agent settings. Hence, we propose three novel research directions that focus on uncertainties in such human-computer interactions: Underspecification uncertainties, for when users do not provide all information or define the exact task at the first go, interactive learning, to ask follow-up questions and reduce the uncertainty about the current context, and output uncertainties, to utilize the rich language and speech space to express uncertainties as more than mere numbers. We expect that these new ways of dealing with and communicating uncertainties will lead to LLM agent interactions that are more transparent, trustworthy, and intuitive.","authors":["Michael Kirchhof","Gjergji Kasneci","Enkelejda Kasneci"],"url":"https://arxiv.org/abs/2505.22655"}
{"created":"2025-05-29","title":"Asymptotic-preserving schemes for the initial-boundary value problem of hyperbolic relaxation systems","abstract":"In this work, we present a numerical method for the initial-boundary value problem (IBVP) of first-order hyperbolic systems with source terms. The scheme directly solves the relaxation system using a relatively coarse mesh and captures the equilibrium behavior quite well, even in the presence of boundary layers. This method extends the concept of asymptotic-preserving schemes from initial-value problems to IBVPs. Moreover, we apply this idea to design a unified numerical scheme for the interface problem of relaxation systems.","authors":["Yizhou Zhou"],"url":"https://arxiv.org/abs/2505.22656"}
{"created":"2025-05-29","title":"3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model","abstract":"Humans excel at performing complex tasks by leveraging long-term memory across temporal and spatial experiences. In contrast, current Large Language Models (LLMs) struggle to effectively plan and act in dynamic, multi-room 3D environments. We posit that part of this limitation is due to the lack of proper 3D spatial-temporal memory modeling in LLMs. To address this, we first introduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000 trajectories and 2,892 embodied tasks, question-answering and captioning, designed to evaluate an agent's ability to reason over long-term memory in 3D environments. Second, we propose 3DLLM-Mem, a novel dynamic memory management and fusion model for embodied spatial-temporal reasoning and actions in LLMs. Our model uses working memory tokens, which represents current observations, as queries to selectively attend to and fuse the most useful spatial and temporal features from episodic memory, which stores past observations and interactions. Our approach allows the agent to focus on task-relevant information while maintaining memory efficiency in complex, long-horizon environments. Experimental results demonstrate that 3DLLM-Mem achieves state-of-the-art performance across various tasks, outperforming the strongest baselines by 16.5% in success rate on 3DMem-Bench's most challenging in-the-wild embodied tasks.","authors":["Wenbo Hu","Yining Hong","Yanjun Wang","Leison Gao","Zibu Wei","Xingcheng Yao","Nanyun Peng","Yonatan Bitton","Idan Szpektor","Kai-Wei Chang"],"url":"https://arxiv.org/abs/2505.22657"}
{"created":"2025-05-29","title":"Maximizing Confidence Alone Improves Reasoning","abstract":"Reinforcement learning (RL) has enabled machine learning models to achieve significant advances in many fields. Most recently, RL has empowered frontier language models to solve challenging math, science, and coding problems. However, central to any RL algorithm is the reward function, and reward engineering is a notoriously difficult problem in any domain. In this paper, we propose RENT: Reinforcement Learning via Entropy Minimization -- a fully unsupervised RL method that requires no external reward or ground-truth answers, and instead uses the model's entropy of its underlying distribution as an intrinsic reward. We find that by reinforcing the chains of thought that yield high model confidence on its generated answers, the model improves its reasoning ability. In our experiments, we showcase these improvements on an extensive suite of commonly-used reasoning benchmarks, including GSM8K, MATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen and Mistral families. The generality of our unsupervised learning method lends itself to applicability in a wide range of domains where external supervision is limited or unavailable.","authors":["Mihir Prabhudesai","Lili Chen","Alex Ippoliti","Katerina Fragkiadaki","Hao Liu","Deepak Pathak"],"url":"https://arxiv.org/abs/2505.22660"}
{"created":"2025-05-29","title":"GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning","abstract":"The evaluation of large language models (LLMs) has traditionally relied on static benchmarks, a paradigm that poses two major limitations: (1) predefined test sets lack adaptability to diverse application domains, and (2) standardized evaluation protocols often fail to capture fine-grained assessments of domain-specific knowledge and contextual reasoning abilities. To overcome these challenges, we propose GuessArena, an adaptive evaluation framework grounded in adversarial game-based interactions. Inspired by the interactive structure of the Guess Who I Am? game, our framework seamlessly integrates dynamic domain knowledge modeling with progressive reasoning assessment to improve evaluation fidelity. Empirical studies across five vertical domains-finance, healthcare, manufacturing, information technology, and education-demonstrate that GuessArena effectively distinguishes LLMs in terms of domain knowledge coverage and reasoning chain completeness. Compared to conventional benchmarks, our method provides substantial advantages in interpretability, scalability, and scenario adaptability.","authors":["Qingchen Yu","Zifan Zheng","Ding Chen","Simin Niu","Bo Tang","Feiyu Xiong","Zhiyu Li"],"url":"https://arxiv.org/abs/2505.22661"}
{"created":"2025-05-29","title":"AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models","abstract":"The reasoning-capable large language models (LLMs) demonstrate strong performance on complex reasoning tasks but often suffer from overthinking, generating unnecessarily long chain-of-thought (CoT) reasoning paths for easy reasoning questions, thereby increasing inference cost and latency. Recent approaches attempt to address this challenge by manually deciding when to apply long or short reasoning. However, they lack the flexibility to adapt CoT length dynamically based on question complexity. In this paper, we propose Auto Long-Short Reasoning (AutoL2S), a dynamic and model-agnostic framework that enables LLMs to dynamically compress their generated reasoning path based on the complexity of the reasoning question. AutoL2S enables a learned paradigm, in which LLMs themselves can decide when longer reasoning is necessary and when shorter reasoning suffices, by training on data annotated with our proposed method, which includes both long and short CoT paths and a special  token. We then use  token to indicate when the model can skip generating lengthy CoT reasoning. This proposed annotation strategy can enhance the LLMs' ability to generate shorter CoT reasoning paths with improved quality after training. Extensive evaluation results show that AutoL2S reduces the length of reasoning generation by up to 57% without compromising performance, demonstrating the effectiveness of AutoL2S for scalable and efficient LLM reasoning.","authors":["Feng Luo","Yu-Neng Chuang","Guanchu Wang","Hoang Anh Duy Le","Shaochen Zhong","Hongyi Liu","Jiayi Yuan","Yang Sui","Vladimir Braverman","Vipin Chaudhary","Xia Hu"],"url":"https://arxiv.org/abs/2505.22662"}
{"created":"2025-05-29","title":"Training Free Stylized Abstraction","abstract":"Stylized abstraction synthesizes visually exaggerated yet semantically faithful representations of subjects, balancing recognizability with perceptual distortion. Unlike image-to-image translation, which prioritizes structural fidelity, stylized abstraction demands selective retention of identity cues while embracing stylistic divergence, especially challenging for out-of-distribution individuals. We propose a training-free framework that generates stylized abstractions from a single image using inference-time scaling in vision-language models (VLLMs) to extract identity-relevant features, and a novel cross-domain rectified flow inversion strategy that reconstructs structure based on style-dependent priors. Our method adapts structural restoration dynamically through style-aware temporal scheduling, enabling high-fidelity reconstructions that honor both subject and style. It supports multi-round abstraction-aware generation without fine-tuning. To evaluate this task, we introduce StyleBench, a GPT-based human-aligned metric suited for abstract styles where pixel-level similarity fails. Experiments across diverse abstraction (e.g., LEGO, knitted dolls, South Park) show strong generalization to unseen identities and styles in a fully open-source setup.","authors":["Aimon Rahman","Kartik Narayan","Vishal M. Patel"],"url":"https://arxiv.org/abs/2505.22663"}
{"created":"2025-05-29","title":"Zero-Shot Vision Encoder Grafting via LLM Surrogates","abstract":"Vision language models (VLMs) typically pair a modestly sized vision encoder with a large language model (LLM), e.g., Llama-70B, making the decoder the primary computational burden during training. To reduce costs, a potential promising strategy is to first train the vision encoder using a small language model before transferring it to the large one. We construct small \"surrogate models\" that share the same embedding space and representation language as the large target LLM by directly inheriting its shallow layers. Vision encoders trained on the surrogate can then be directly transferred to the larger model, a process we call zero-shot grafting -- when plugged directly into the full-size target LLM, the grafted pair surpasses the encoder-surrogate pair and, on some benchmarks, even performs on par with full decoder training with the target LLM. Furthermore, our surrogate training approach reduces overall VLM training costs by ~45% when using Llama-70B as the decoder.","authors":["Kaiyu Yue","Vasu Singla","Menglin Jia","John Kirchenbauer","Rifaa Qadri","Zikui Cai","Abhinav Bhatele","Furong Huang","Tom Goldstein"],"url":"https://arxiv.org/abs/2505.22664"}
{"created":"2025-05-29","title":"Offset Unlearning for Large Language Models","abstract":"Despite the strong capabilities of Large Language Models (LLMs) to acquire knowledge from their training corpora, the memorization of sensitive information in the corpora such as copyrighted, biased, and private content has led to ethical and legal concerns. In response to these challenges, unlearning has emerged as a potential remedy for LLMs affected by problematic training data. However, previous unlearning techniques are either not applicable to black-box LLMs due to required access to model internal weights, or violate data protection principles by retaining sensitive data for inference-time correction. We propose {\\delta}-Unlearning, an offset unlearning framework for black-box LLMs. Instead of tuning the black-box LLM itself, {\\delta}-Unlearning learns the logit offset needed for unlearning by contrasting the logits from a pair of smaller models. Experiments demonstrate that {\\delta}- Unlearning can effectively unlearn target data while maintaining similar or even stronger performance on general out-of-forget-scope tasks. {\\delta}-Unlearning also effectively incorporates different unlearning algorithms, making our approach a versatile solution to adapting various existing unlearning algorithms to black-box LLMs.","authors":["James Y. Huang","Wenxuan Zhou","Fei Wang","Fred Morstatter","Sheng Zhang","Hoifung Poon","Muhao Chen"],"url":"https://arxiv.org/abs/2404.11045"}
{"created":"2025-05-29","title":"Dexterous Control of an 11-DOF Redundant Robot for CT-Guided Needle Insertion With Task-Oriented Weighted Policies","abstract":"Computed tomography (CT)-guided needle biopsies are critical for diagnosing a range of conditions, including lung cancer, but present challenges such as limited in-bore space, prolonged procedure times, and radiation exposure. Robotic assistance offers a promising solution by improving needle trajectory accuracy, reducing radiation exposure, and enabling real-time adjustments. In our previous work, we introduced a redundant robotic platform designed for dexterous needle insertion within the confined CT bore. However, its limited base mobility restricts flexible deployment in clinical settings. In this study, we present an improved 11-degree-of-freedom (DOF) robotic system that integrates a 6-DOF robotic base with a 5-DOF cable-driven end-effector, significantly enhancing workspace flexibility and precision. With the hyper-redundant degrees of freedom, we introduce a weighted inverse kinematics controller with a two-stage priority scheme for large-scale movement and fine in-bore adjustments, along with a null-space control strategy to optimize dexterity. We validate our system through both simulation and real-world experiments, demonstrating superior tracking accuracy and enhanced manipulability in CT-guided procedures. The study provides a strong case for hyper-redundancy and null-space control formulations for robot-assisted needle biopsy scenarios.","authors":["Peihan Zhang","Florian Richter","Ishan Duriseti","Michael Yip"],"url":"https://arxiv.org/abs/2503.14753"}
{"created":"2025-05-29","title":"Provably Robust Training of Quantum Circuit Classifiers Against Parameter Noise","abstract":"Advancements in quantum computing have spurred significant interest in harnessing its potential for speedups over classical systems. However, noise remains a major obstacle to achieving reliable quantum algorithms. In this work, we present a provably noise-resilient training theory and algorithm to enhance the robustness of parameterized quantum circuit classifiers. Our method, with a natural connection to Evolutionary Strategies, guarantees resilience to parameter noise with minimal adjustments to commonly used optimization algorithms. Our approach is function-agnostic and adaptable to various quantum circuits, successfully demonstrated in quantum phase classification tasks. By developing provably guaranteed optimization theory with quantum circuits, our work opens new avenues for practical, robust applications of near-term quantum computers.","authors":["Lucas Tecot","Di Luo","Cho-Jui Hsieh"],"url":"https://arxiv.org/abs/2505.18478"}
{"created":"2025-05-29","title":"Capability-Based Scaling Laws for LLM Red-Teaming","abstract":"As large language models grow in capability and agency, identifying vulnerabilities through red-teaming becomes vital for safe deployment. However, traditional prompt-engineering approaches may prove ineffective once red-teaming turns into a weak-to-strong problem, where target models surpass red-teamers in capabilities. To study this shift, we frame red-teaming through the lens of the capability gap between attacker and target. We evaluate more than 500 attacker-target pairs using LLM-based jailbreak attacks that mimic human red-teamers across diverse families, sizes, and capability levels. Three strong trends emerge: (i) more capable models are better attackers, (ii) attack success drops sharply once the target's capability exceeds the attacker's, and (iii) attack success rates correlate with high performance on social science splits of the MMLU-Pro benchmark. From these trends, we derive a jailbreaking scaling law that predicts attack success for a fixed target based on attacker-target capability gap. These findings suggest that fixed-capability attackers (e.g., humans) may become ineffective against future models, increasingly capable open-source models amplify risks for existing systems, and model providers must accurately measure and control models' persuasive and manipulative abilities to limit their effectiveness as attackers.","authors":["Alexander Panfilov","Paul Kassianik","Maksym Andriushchenko","Jonas Geiping"],"url":"https://arxiv.org/abs/2505.20162"}
{"created":"2025-05-29","title":"Genetic Influences on Brain Aging: Analyzing Sex Differences in the UK Biobank using Structural MRI","abstract":"Brain aging trajectories differ between males and females, yet the genetic factors underlying these differences remain underexplored. Using structural MRI and genotyping data from 40,940 UK Biobank participants (aged 45-83), we computed Brain Age Gap Estimates (BrainAGE) for total brain, hippocampal, and ventricular volumes. We conducted sex-stratified genome-wide association studies (GWAS) and Post-GWAS analyses to identify genetic variants associated with accelerated brain aging. Distinct gene sets emerged by sex: in females, neurotransmitter transport and mitochondrial stress response genes were implicated; in males, immune and inflammation-related genes dominated. Shared genes, including GMNC and OSTN, were consistently linked to brain volumes across sexes, suggesting core roles in neurostructural maintenance. Tissue expression analyses revealed sex-specific enrichment in pathways tied to neurodegeneration. These findings highlight the importance of sex-stratified approaches in aging research and suggest genetic targets for personalized interventions against age-related cognitive decline.","authors":["Karen Ardila","Aashka Mohite","Abdoljalil Addeh","Amanda V. Tyndall","Cindy K. Barha","Quan Long","M. Ethan MacDonald"],"url":"https://arxiv.org/abs/2505.20344"}
{"created":"2025-05-29","title":"Automatic detection of abnormal clinical EEG: comparison of a finetuned foundation model with two deep learning models","abstract":"Electroencephalography (EEG) is commonly used by physicians for the diagnosis of numerous neurological disorders. Due to the large volume of EEGs requiring interpretation and the specific expertise involved, artificial intelligence-based tools are being developed to assist in their visual analysis. In this paper, we compare two deep learning models (CNN-LSTM and Transformer-based) with BioSerenity-E1, a recently proposed foundation model, in the task of classifying entire EEG recordings as normal or abnormal. The three models were trained or finetuned on 2,500 EEG recordings and their performances were evaluated on two private and one public datasets: a large multicenter dataset annotated by a single specialist (dataset A composed of n = 4,480 recordings), a small multicenter dataset annotated by three specialists (dataset B, n = 198), and the Temple University Abnormal (TUAB) EEG corpus evaluation dataset (n = 276). On dataset A, the three models achieved at least 86% balanced accuracy, with BioSerenity-E1 finetuned achieving the highest balanced accuracy (89.19% [88.36-90.41]). BioSerenity-E1 finetuned also achieved the best performance on dataset B, with 94.63% [92.32-98.12] balanced accuracy. The models were then validated on TUAB evaluation dataset, whose corresponding training set was not used during training, where they achieved at least 76% accuracy. Specifically, BioSerenity-E1 finetuned outperformed the other two models, reaching an accuracy of 82.25% [78.27-87.48]. Our results highlight the usefulness of leveraging pre-trained models for automatic EEG classification: enabling robust and efficient interpretation of EEG data with fewer resources and broader applicability.","authors":["Aurore Bussalb","Fran\\c{c}ois Le Gac","Guillaume Jubien","Mohamed Rahmouni","Ruggero G. Bettinardi","Pedro Marinho R. de Oliveira","Phillipe Derambure","Nicolas Gaspard","Jacques Jonas","Louis Maillard","Laurent Vercueil","Herv\\'e Vespignani","Philippe Laval","Laurent Koessler","Ulysse Gimenez"],"url":"https://arxiv.org/abs/2505.21507"}
{"created":"2025-05-29","title":"Complexity counts: global and local perspectives on Indo-Aryan numeral systems","abstract":"The numeral systems of Indo-Aryan languages such as Hindi, Gujarati, and Bengali are highly unusual in that unlike most numeral systems (e.g., those of English, Chinese, etc.), forms referring to 1--99 are highly non-transparent and are cannot be constructed using straightforward rules. As an example, Hindi/Urdu *iky\\=anve* `91' is not decomposable into the composite elements *ek* `one' and *nave* `ninety' in the way that its English counterpart is. This paper situates Indo-Aryan languages within the typology of cross-linguistic numeral systems, and explores the linguistic and non-linguistic factors that may be responsible for the persistence of complex systems in these languages. Using cross-linguistic data from multiple databases, we develop and employ a number of cross-linguistically applicable metrics to quantifies the complexity of languages' numeral systems, and demonstrate that Indo-Aryan languages have decisively more complex numeral systems than the world's languages as a whole, though individual Indo-Aryan languages differ from each other in terms of the complexity of the patterns they display. We investigate the factors (e.g., religion, geographic isolation, etc.) that underlie complexity in numeral systems, with a focus on South Asia, in an attempt to develop an account of why complex numeral systems developed and persisted in certain Indo-Aryan languages but not elsewhere. Finally, we demonstrate that Indo-Aryan numeral systems adhere to certain general pressures toward efficient communication found cross-linguistically, despite their high complexity. We call for this somewhat overlooked dimension of complexity to be taken seriously when discussing general variation in cross-linguistic numeral systems.","authors":["Chundra Cathcart"],"url":"https://arxiv.org/abs/2505.21510"}
{"created":"2025-05-29","title":"VietASR: Achieving Industry-level Vietnamese ASR with 50-hour labeled data and Large-Scale Speech Pretraining","abstract":"Automatic speech recognition (ASR) has made remarkable progress but heavily relies on large-scale labeled data, which is scarce for low-resource languages like Vietnamese. While existing systems such as Whisper, USM, and MMS achieve promising performance, their efficacy remains inadequate in terms of training costs, latency, and accessibility. To address these issues, we propose VietASR, a novel ASR training pipeline that leverages vast amounts of unlabeled data and a small set of labeled data. Through multi-iteration ASR-biased self-supervised learning on a large-scale unlabeled dataset, VietASR offers a cost-effective and practical solution for enhancing ASR performance. Experiments demonstrate that pre-training on 70,000-hour unlabeled data and fine-tuning on merely 50-hour labeled data yield a lightweight but powerful ASR model. It outperforms Whisper Large-v3 and commercial ASR systems on real-world data. Our code and models will be open-sourced to facilitate research in low-resource ASR.","authors":["Jianheng Zhuo","Yifan Yang","Yiwen Shao","Yong Xu","Dong Yu","Kai Yu","Xie Chen"],"url":"https://arxiv.org/abs/2505.21527"}
{"created":"2025-05-29","title":"High-Fidelity Functional Ultrasound Reconstruction via A Visual Auto-Regressive Framework","abstract":"Functional ultrasound (fUS) imaging provides exceptional spatiotemporal resolution for neurovascular mapping, yet its practical application is significantly hampered by critical challenges. Foremost among these are data scarcity, arising from ethical considerations and signal degradation through the cranium, which collectively limit dataset diversity and compromise the fairness of downstream machine learning models.","authors":["Xuhang Chen","Zhuo Li","Yanyan Shen","Mufti Mahmud","Hieu Pham","Chi-Man Pun","Shuqiang Wang"],"url":"https://arxiv.org/abs/2505.21530"}
{"created":"2025-05-29","title":"Image denoising as a conditional expectation","abstract":"All techniques for denoising involve a notion of a true (noise-free) image, and a hypothesis space. The hypothesis space may reconstruct the image directly as a grayscale valued function, or indirectly by its Fourier or wavelet spectrum. Most common techniques estimate the true image as a projection to some subspace. We propose an interpretation of a noisy image as a collection of samples drawn from a certain probability space. Within this interpretation, projection based approaches are not guaranteed to be unbiased and convergent. We present a data-driven denoising method in which the true image is recovered as a conditional expectation. Although the probability space is unknown apriori, integrals on this space can be estimated by kernel integral operators. The true image is reformulated as the least squares solution to a linear equation in a reproducing kernel Hilbert space (RKHS), and involving various kernel integral operators as linear transforms. Assuming the true image to be a continuous function on a compact planar domain, the technique is shown to be convergent as the number of pixels goes to infinity. We also show that for a picture with finite number of pixels, the convergence result can be used to choose the various parameters for an optimum denoising result.","authors":["Sajal Chakroborty","Suddhasattwa Das"],"url":"https://arxiv.org/abs/2505.21546"}
{"created":"2025-05-29","title":"Fluent but Culturally Distant: Can Regional Training Teach Cultural Understanding?","abstract":"Large language models (LLMs) are used around the world but exhibit Western cultural tendencies. To address this cultural misalignment, many countries have begun developing \"regional\" LLMs tailored to local communities. Yet it remains unclear whether these models merely speak the language of their users or also reflect their cultural values and practices. Using India as a case study, we evaluate five Indic and five global LLMs along two key dimensions: values (via the Inglehart-Welzel map and GlobalOpinionQA) and practices (via CulturalBench and NormAd). Across all four tasks, we find that Indic models do not align more closely with Indian cultural norms than global models. In fact, an average American person is a better proxy for Indian cultural values than any Indic model. Even prompting strategies fail to meaningfully improve alignment. Ablations show that regional fine-tuning does not enhance cultural competence and may in fact hurt it by impeding recall of existing knowledge. We trace this failure to the scarcity of high-quality, untranslated, and culturally grounded pretraining and fine-tuning data. Our study positions cultural evaluation as a first-class requirement alongside multilingual benchmarks and offers a reusable methodology for developers. We call for deeper investments in culturally representative data to build and evaluate truly sovereign LLMs.","authors":["Dhruv Agarwal","Anya Shukla","Sunayana Sitaram","Aditya Vashistha"],"url":"https://arxiv.org/abs/2505.21548"}
{"created":"2025-05-29","title":"WhisperD: Dementia Speech Recognition and Filler Word Detection with Whisper","abstract":"Whisper fails to correctly transcribe dementia speech because persons with dementia (PwDs) often exhibit irregular speech patterns and disfluencies such as pauses, repetitions, and fragmented sentences. It was trained on standard speech and may have had little or no exposure to dementia-affected speech. However, correct transcription is vital for dementia speech for cost-effective diagnosis and the development of assistive technology. In this work, we fine-tune Whisper with the open-source dementia speech dataset (DementiaBank) and our in-house dataset to improve its word error rate (WER). The fine-tuning also includes filler words to ascertain the filler inclusion rate (FIR) and F1 score. The fine-tuned models significantly outperformed the off-the-shelf models. The medium-sized model achieved a WER of 0.24, outperforming previous work. Similarly, there was a notable generalisability to unseen data and speech patterns.","authors":["Emmanuel Akinrintoyo","Nadine Abdelhalim","Nicole Salomons"],"url":"https://arxiv.org/abs/2505.21551"}
{"created":"2025-05-29","title":"A Kernelised Stein Discrepancy for Assessing the Fit of Inhomogeneous Random Graph Models","abstract":"Complex data are often represented as a graph, which in turn can often be viewed as a realisation of a random graph, such as of an inhomogeneous random graph model (IRG). For general fast goodness-of-fit tests in high dimensions, kernelised Stein discrepancy (KSD) tests are a powerful tool. Here, we develop, test, and analyse a KSD-type goodness-of-fit test for IRG models that can be carried out with a single observation of the network. The test is applicable to a network of any size and does not depend on the asymptotic distribution of the test statistic. We also provide theoretical guarantees.","authors":["Anum Fatima","Gesine Reinert"],"url":"https://arxiv.org/abs/2505.21580"}
{"created":"2025-05-29","title":"Improving flocking behaviors in street networks with vision","abstract":"We improve a flocking model on street networks introduced in a previous paper. We expand the field of vision of walkers, making the model more realistic. Under such conditions, we obtain groups of walkers whose gathering times and robustness to break ups are better than previous results. We explain such improvements because the alignment rule with vision guaranties walkers do not split into divergent directions at intersections anymore, and because the attraction rule with vision gathers distant groups. This paves the way to a better understanding of events where walkers have collective decentralized goals, like protests.","authors":["Guillaume Moinard","Matthieu Latapy"],"url":"https://arxiv.org/abs/2505.21585"}
{"created":"2025-05-29","title":"Taylor expansion-based Kolmogorov-Arnold network for blind image quality assessment","abstract":"Kolmogorov-Arnold Network (KAN) has attracted growing interest for its strong function approximation capability. In our previous work, KAN and its variants were explored in score regression for blind image quality assessment (BIQA). However, these models encounter challenges when processing high-dimensional features, leading to limited performance gains and increased computational cost. To address these issues, we propose TaylorKAN that leverages the Taylor expansions as learnable activation functions to enhance local approximation capability. To improve the computational efficiency, network depth reduction and feature dimensionality compression are integrated into the TaylorKAN-based score regression pipeline. On five databases (BID, CLIVE, KonIQ, SPAQ, and FLIVE) with authentic distortions, extensive experiments demonstrate that TaylorKAN consistently outperforms the other KAN-related models, indicating that the local approximation via Taylor expansions is more effective than global approximation using orthogonal functions. Its generalization capacity is validated through inter-database experiments. The findings highlight the potential of TaylorKAN as an efficient and robust model for high-dimensional score regression.","authors":["Ze Chen","Shaode Yu"],"url":"https://arxiv.org/abs/2505.21592"}
{"created":"2025-05-29","title":"Learning optimal treatment strategies for intraoperative hypotension using deep reinforcement learning","abstract":"Traditional methods of surgical decision making heavily rely on human experience and prompt actions, which are variable. A data-driven system generating treatment recommendations based on patient states can be a substantial asset in perioperative decision-making, as in cases of intraoperative hypotension, for which suboptimal management is associated with acute kidney injury (AKI), a common and morbid postoperative complication. We developed a Reinforcement Learning (RL) model to recommend optimum dose of intravenous (IV) fluid and vasopressors during surgery to avoid intraoperative hypotension and postoperative AKI. We retrospectively analyzed 50,021 surgeries from 42,547 adult patients who underwent major surgery at a quaternary care hospital between June 2014 and September 2020. Of these, 34,186 surgeries were used for model training and 15,835 surgeries were reserved for testing. We developed a Deep Q-Networks based RL model using 16 variables including intraoperative physiologic time series, total dose of IV fluid and vasopressors extracted for every 15-minute epoch. The model replicated 69% of physician's decisions for the dosage of vasopressors and proposed higher or lower dosage of vasopressors than received in 10% and 21% of the treatments, respectively. In terms of IV fluids, the model's recommendations were within 0.05 ml/kg/15 min of the actual dose in 41% of the cases, with higher or lower doses recommended for 27% and 32% of the treatments, respectively. The model resulted in a higher estimated policy value compared to the physicians' actual treatments, as well as random and zero-drug policies. AKI prevalence was the lowest in patients receiving medication dosages that aligned with model's decisions. Our findings suggest that implementation of the model's policy has the potential to reduce postoperative AKI and improve other outcomes driven by intraoperative hypotension.","authors":["Esra Adiyeke","Tianqi Liu","Venkata Sai Dheeraj Naganaboina","Han Li","Tyler J. Loftus","Yuanfang Ren","Benjamin Shickel","Matthew M. Ruppert","Karandeep Singh","Ruogu Fang","Parisa Rashidi","Azra Bihorac","Tezcan Ozrazgat-Baslanti"],"url":"https://arxiv.org/abs/2505.21596"}
{"created":"2025-05-29","title":"Optimizing Deep Learning for Skin Cancer Classification: A Computationally Efficient CNN with Minimal Accuracy Trade-Off","abstract":"The rapid advancement of deep learning in medical image analysis has greatly enhanced the accuracy of skin cancer classification. However, current state-of-the-art models, especially those based on transfer learning like ResNet50, come with significant computational overhead, rendering them impractical for deployment in resource-constrained environments. This study proposes a custom CNN model that achieves a 96.7\\% reduction in parameters (from 23.9 million in ResNet50 to 692,000) while maintaining a classification accuracy deviation of less than 0.022\\%. Our empirical analysis of the HAM10000 dataset reveals that although transfer learning models provide a marginal accuracy improvement of approximately 0.022\\%, they result in a staggering 13,216.76\\% increase in FLOPs, considerably raising computational costs and inference latency. In contrast, our lightweight CNN architecture, which encompasses only 30.04 million FLOPs compared to ResNet50's 4.00 billion, significantly reduces energy consumption, memory footprint, and inference time. These findings underscore the trade-off between the complexity of deep models and their real-world feasibility, positioning our optimized CNN as a practical solution for mobile and edge-based skin cancer diagnostics.","authors":["Abdullah Al Mamun","Pollob Chandra Ray","Md Rahat Ul Nasib","Akash Das","Jia Uddin","Md Nurul Absur"],"url":"https://arxiv.org/abs/2505.21597"}
{"created":"2025-05-29","title":"Laparoscopic Image Desmoking Using the U-Net with New Loss Function and Integrated Differentiable Wiener Filter","abstract":"Laparoscopic surgeries often suffer from reduced visual clarity due to the presence of surgical smoke originated by surgical instruments, which poses significant challenges for both surgeons and vision based computer-assisted technologies. In order to remove the surgical smoke, a novel U-Net deep learning with new loss function and integrated differentiable Wiener filter (ULW) method is presented. Specifically, the new loss function integrates the pixel, structural, and perceptual properties. Thus, the new loss function, which combines the structural similarity index measure loss, the perceptual loss, as well as the mean squared error loss, is able to enhance the quality and realism of the reconstructed images. Furthermore, the learnable Wiener filter is capable of effectively modelling the degradation process caused by the surgical smoke. The effectiveness of the proposed ULW method is evaluated using the publicly available paired laparoscopic smoke and smoke-free image dataset, which provides reliable benchmarking and quantitative comparisons. Experimental results show that the proposed ULW method excels in both visual clarity and metric-based evaluation. As a result, the proposed ULW method offers a promising solution for real-time enhancement of laparoscopic imagery. The code is available at https://github.com/chengyuyang-njit/ImageDesmoke.","authors":["Chengyu Yang","Chengjun Liu"],"url":"https://arxiv.org/abs/2505.21634"}
{"created":"2025-05-29","title":"Karp's patching algorithm on dense digraph","abstract":"We consider the following question. We are given a dense digraph $D$ with $n$ vertices and minimum in- and out-degree at least $\\alpha n$, where $\\alpha>1/2$ is a constant. The edges $E(D)$ of $D$ are given independent edge costs $C(e),e\\in E(D)$, such that (i) $C$ has a density $f$ that satisfies $f(x)=a+bx+O(x^2)$, for constants $a>0,b$ as $x\\to 0$ and such that in general either (ii) $\\Pr(C\\geq x)\\leq \\a e^{-\\b x}$ for constants $\\a,\\b>0$, or $f(x)=0$ for $x>\\n$ for some constant $\\n>0$. Let $C(i,j),i,j\\in[n]$ be the associated $n\\times n$ cost matrix where $C(i,j)=\\infty$ if $(i,j)\\notin E$. We show that w.h.p. (a small modification to) the patching algorithm of Karp finds a tour for the asymmetric traveling salesperson problem that is asymptotically equal to that of the associated assignment problem. The algorithm runs in polynomial time.","authors":["Alan Frieze"],"url":"https://arxiv.org/abs/2505.21645"}
{"created":"2025-05-29","title":"STACI: Spatio-Temporal Aleatoric Conformal Inference","abstract":"Fitting Gaussian Processes (GPs) provides interpretable aleatoric uncertainty quantification for estimation of spatio-temporal fields. Spatio-temporal deep learning models, while scalable, typically assume a simplistic independent covariance matrix for the response, failing to capture the underlying correlation structure. However, spatio-temporal GPs suffer from issues of scalability and various forms of approximation bias resulting from restrictive assumptions of the covariance kernel function. We propose STACI, a novel framework consisting of a variational Bayesian neural network approximation of non-stationary spatio-temporal GP along with a novel spatio-temporal conformal inference algorithm. STACI is highly scalable, taking advantage of GPU training capabilities for neural network models, and provides statistically valid prediction intervals for uncertainty quantification. STACI outperforms competing GPs and deep methods in accurately approximating spatio-temporal processes and we show it easily scales to datasets with millions of observations.","authors":["Brandon R. Feng","David Keetae Park","Xihaier Luo","Arantxa Urdangarin","Shinjae Yoo","Brian J. Reich"],"url":"https://arxiv.org/abs/2505.21658"}
{"created":"2025-05-29","title":"tenSVD algorithm for compression","abstract":"Tensors provide a robust framework for managing high-dimensional data. Consequently, tensor analysis has emerged as an active research area in various domains, including machine learning, signal processing, computer vision, graph analysis, and data mining. This study introduces an efficient image storage approach utilizing tensors, aiming to minimize memory to store, bandwidth to transmit and energy to processing. The proposed method organizes original data into a higher-order tensor and applies the Tucker model for compression. Implemented in R, this method is compared to a baseline algorithm. The evaluation focuses on efficient of algorithm measured in term of computational time and the quality of information preserved, using both simulated and real datasets. A detailed analysis of the results is conducted, employing established quantitative metrics, with significant attention paid to sustainability in terms of energy consumption across algorithms.","authors":["Michele Gallo"],"url":"https://arxiv.org/abs/2505.21686"}
{"created":"2025-05-29","title":"What Data Enables Optimal Decisions? An Exact Characterization for Linear Optimization","abstract":"We study the fundamental question of how informative a dataset is for solving a given decision-making task. In our setting, the dataset provides partial information about unknown parameters that influence task outcomes. Focusing on linear programs, we characterize when a dataset is sufficient to recover an optimal decision, given an uncertainty set on the cost vector. Our main contribution is a sharp geometric characterization that identifies the directions of the cost vector that matter for optimality, relative to the task constraints and uncertainty set. We further develop a practical algorithm that, for a given task, constructs a minimal or least-costly sufficient dataset. Our results reveal that small, well-chosen datasets can often fully determine optimal decisions -- offering a principled foundation for task-aware data selection.","authors":["Omar Bennouna","Amine Bennouna","Saurabh Amin","Asuman Ozdaglar"],"url":"https://arxiv.org/abs/2505.21692"}
{"created":"2025-05-29","title":"STA-Risk: A Deep Dive of Spatio-Temporal Asymmetries for Breast Cancer Risk Prediction","abstract":"Predicting the risk of developing breast cancer is an important clinical tool to guide early intervention and tailoring personalized screening strategies. Early risk models have limited performance and recently machine learning-based analysis of mammogram images showed encouraging risk prediction effects. These models however are limited to the use of a single exam or tend to overlook nuanced breast tissue evolvement in spatial and temporal details of longitudinal imaging exams that are indicative of breast cancer risk. In this paper, we propose STA-Risk (Spatial and Temporal Asymmetry-based Risk Prediction), a novel Transformer-based model that captures fine-grained mammographic imaging evolution simultaneously from bilateral and longitudinal asymmetries for breast cancer risk prediction. STA-Risk is innovative by the side encoding and temporal encoding to learn spatial-temporal asymmetries, regulated by a customized asymmetry loss. We performed extensive experiments with two independent mammogram datasets and achieved superior performance than four representative SOTA models for 1- to 5-year future risk prediction. Source codes will be released upon publishing of the paper.","authors":["Zhengbo Zhou","Dooman Arefan","Margarita Zuley","Jules Sumkin","Shandong Wu"],"url":"https://arxiv.org/abs/2505.21699"}
{"created":"2025-05-29","title":"Preconditioning transformations of adjoint systems for evolution equations","abstract":"Achieving robust control and optimization in high-fidelity physics simulations is extremely challenging, especially for evolutionary systems whose solutions span vast scales across space, time, and physical variables. In conjunction with gradient-based methods, adjoint systems are widely used in the optimization of systems subject to differential equation constraints. In optimization, gradient-based methods are often transformed using suitable preconditioners to accelerate the convergence of the optimization algorithm. Inspired by preconditioned gradient descent methods, we introduce a framework for the preconditioning of adjoint systems associated to evolution equations, which allows one to reshape the dynamics of the adjoint system. We develop two classes of adjoint preconditioning transformations: those that transform both the state dynamics and the adjoint equation and those that transform only the adjoint equation while leaving the state dynamics invariant. Both classes of transformations have the flexibility to include generally nonlinear state-dependent transformations. Using techniques from symplectic geometry and Hamiltonian mechanics, we further show that these preconditioned adjoint systems preserve the property that the adjoint system backpropagates the derivative of an objective function. We then apply this framework to the setting of coupled evolution equations, where we develop a notion of scale preconditioning of the adjoint equations when the state dynamics exhibit large scale-separation. We demonstrate the proposed scale preconditioning on an inverse problem for the radiation diffusion equations. Naive gradient descent is unstable for any practical gradient descent step size, whereas our proposed scale-preconditioned adjoint descent converges in 10-15 gradient-based optimization iterations, with highly accurate reproduction of the wavefront at the final time.","authors":["Brian K. Tran","Ben S. Southworth","Hannah F. Blumhoefer","Samuel Olivier"],"url":"https://arxiv.org/abs/2505.21705"}
{"created":"2025-05-29","title":"Privacy-Preserving Chest X-ray Report Generation via Multimodal Federated Learning with ViT and GPT-2","abstract":"The automated generation of radiology reports from chest X-ray images holds significant promise in enhancing diagnostic workflows while preserving patient privacy. Traditional centralized approaches often require sensitive data transfer, posing privacy concerns. To address this, the study proposes a Multimodal Federated Learning framework for chest X-ray report generation using the IU-Xray dataset. The system utilizes a Vision Transformer (ViT) as the encoder and GPT-2 as the report generator, enabling decentralized training without sharing raw data. Three Federated Learning (FL) aggregation strategies: FedAvg, Krum Aggregation and a novel Loss-aware Federated Averaging (L-FedAvg) were evaluated. Among these, Krum Aggregation demonstrated superior performance across lexical and semantic evaluation metrics such as ROUGE, BLEU, BERTScore and RaTEScore. The results show that FL can match or surpass centralized models in generating clinically relevant and semantically rich radiology reports. This lightweight and privacy-preserving framework paves the way for collaborative medical AI development without compromising data confidentiality.","authors":["Md. Zahid Hossain","Mustofa Ahmed","Most. Sharmin Sultana Samu","Md. Rakibul Islam"],"url":"https://arxiv.org/abs/2505.21715"}
{"created":"2025-05-29","title":"Nearly Dimension-Independent Convergence of Mean-Field Black-Box Variational Inference","abstract":"We prove that, given a mean-field location-scale variational family, black-box variational inference (BBVI) with the reparametrization gradient converges at an almost dimension-independent rate. Specifically, for strongly log-concave and log-smooth targets, the number of iterations for BBVI with a sub-Gaussian family to achieve an objective $\\epsilon$-close to the global optimum is $\\mathrm{O}(\\log d)$, which improves over the $\\mathrm{O}(d)$ dependence of full-rank location-scale families. For heavy-tailed families, we provide a weaker $\\mathrm{O}(d^{2/k})$ dimension dependence, where $k$ is the number of finite moments. Additionally, if the Hessian of the target log-density is constant, the complexity is free of any explicit dimension dependence. We also prove that our bound on the gradient variance, which is key to our result, cannot be improved using only spectral bounds on the Hessian of the target log-density.","authors":["Kyurae Kim","Yi-An Ma","Trevor Campbell","Jacob R. Gardner"],"url":"https://arxiv.org/abs/2505.21721"}
{"created":"2025-05-29","title":"Are Statistical Methods Obsolete in the Era of Deep Learning?","abstract":"In the era of AI, neural networks have become increasingly popular for modeling, inference, and prediction, largely due to their potential for universal approximation. With the proliferation of such deep learning models, a question arises: are leaner statistical methods still relevant? To shed insight on this question, we employ the mechanistic nonlinear ordinary differential equation (ODE) inverse problem as a testbed, using physics-informed neural network (PINN) as a representative of the deep learning paradigm and manifold-constrained Gaussian process inference (MAGI) as a representative of statistically principled methods. Through case studies involving the SEIR model from epidemiology and the Lorenz model from chaotic dynamics, we demonstrate that statistical methods are far from obsolete, especially when working with sparse and noisy observations. On tasks such as parameter inference and trajectory reconstruction, statistically principled methods consistently achieve lower bias and variance, while using far fewer parameters and requiring less hyperparameter tuning. Statistical methods can also decisively outperform deep learning models on out-of-sample future prediction, where the absence of relevant data often leads overparameterized models astray. Additionally, we find that statistically principled approaches are more robust to accumulation of numerical imprecision and can represent the underlying system more faithful to the true governing ODEs.","authors":["Skyler Wu","Shihao Yang","S. C. Kou"],"url":"https://arxiv.org/abs/2505.21723"}
{"created":"2025-05-29","title":"Multi-photon QKD for Practical Quantum Networks","abstract":"Quantum key distribution (QKD) will most likely be an integral part of any practical quantum network in the future. However, not all QKD protocols can be used in today's networks because of the lack of single-photon emitters and noisy intermediate quantum hardware. Attenuated-photon transmission, typically used to simulate single-photon emitters, severely limits the achievable transmission distances and makes the integration of the QKD into existing classical networks, that use tens of thousands of photons per bit of transmission, difficult. Furthermore, it has been found that protocol performance varies with topology. In order to remove the reliance of QKD on single-photon emitters and increase transmission distances, it is worthwhile to explore QKD protocols that do not rely on single-photon transmissions for security, such as the 3-stage QKD protocol, which can tolerate multiple photons in each burst without information leakage. This paper compares and contrasts the 3-stage QKD protocol with conventional QKD protocols and its efficiency in different network topologies and conditions. Furthermore, we establish a mathematical relationship between achievable key rates to increase transmission distances in various topologies.","authors":["Nitin Jha","Abhishek Parakh","Mahadevan Subramaniam"],"url":"https://arxiv.org/abs/2505.21726"}
{"created":"2025-05-29","title":"Online Voting using Point to MultiPoint Quantum Key Distribution via Passive Optical Networks","abstract":"We propose using Point-to-Multipoint quantum key distribution (QKD) via time division multiplexing (TDM) and wavelength division multiplexing (WDM) in passive optical networks (PON) to improve the security of online voting systems.","authors":["Bernardo A. Huberman","Jing Wang"],"url":"https://arxiv.org/abs/2505.21756"}
{"created":"2025-05-29","title":"Beyond 1D: Vision Transformers and Multichannel Signal Images for PPG-to-ECG Reconstruction","abstract":"Reconstructing ECG from PPG is a promising yet challenging task. While recent advancements in generative models have significantly improved ECG reconstruction, accurately capturing fine-grained waveform features remains a key challenge. To address this, we propose a novel PPG-to-ECG reconstruction method that leverages a Vision Transformer (ViT) as the core network. Unlike conventional approaches that rely on single-channel PPG, our method employs a four-channel signal image representation, incorporating the original PPG, its first-order difference, second-order difference, and area under the curve. This multi-channel design enriches feature extraction by preserving both temporal and physiological variations within the PPG. By leveraging the self-attention mechanism in ViT, our approach effectively captures both inter-beat and intra-beat dependencies, leading to more robust and accurate ECG reconstruction. Experimental results demonstrate that our method consistently outperforms existing 1D convolution-based approaches, achieving up to 29% reduction in PRD and 15% reduction in RMSE. The proposed approach also produces improvements in other evaluation metrics, highlighting its robustness and effectiveness in reconstructing ECG signals. Furthermore, to ensure a clinically relevant evaluation, we introduce new performance metrics, including QRS area error, PR interval error, RT interval error, and RT amplitude difference error. Our findings suggest that integrating a four-channel signal image representation with the self-attention mechanism of ViT enables more effective extraction of informative PPG features and improved modeling of beat-to-beat variations for PPG-to-ECG mapping. Beyond demonstrating the potential of PPG as a viable alternative for heart activity monitoring, our approach opens new avenues for cyclic signal analysis and prediction.","authors":["Xiaoyan Li","Shixin Xu","Faisal Habib","Arvind Gupta","Huaxiong Huang"],"url":"https://arxiv.org/abs/2505.21767"}
{"created":"2025-05-29","title":"Global Minimizers of $\\ell^p$-Regularized Objectives Yield the Sparsest ReLU Neural Networks","abstract":"Overparameterized neural networks can interpolate a given dataset in many different ways, prompting the fundamental question: which among these solutions should we prefer, and what explicit regularization strategies will provably yield these solutions? This paper addresses the challenge of finding the sparsest interpolating ReLU network -- i.e., the network with the fewest nonzero parameters or neurons -- a goal with wide-ranging implications for efficiency, generalization, interpretability, theory, and model compression. Unlike post hoc pruning approaches, we propose a continuous, almost-everywhere differentiable training objective whose global minima are guaranteed to correspond to the sparsest single-hidden-layer ReLU networks that fit the data. This result marks a conceptual advance: it recasts the combinatorial problem of sparse interpolation as a smooth optimization task, potentially enabling the use of gradient-based training methods. Our objective is based on minimizing $\\ell^p$ quasinorms of the weights for $0 < p < 1$, a classical sparsity-promoting strategy in finite-dimensional settings. However, applying these ideas to neural networks presents new challenges: the function class is infinite-dimensional, and the weights are learned using a highly nonconvex objective. We prove that, under our formulation, global minimizers correspond exactly to sparsest solutions. Our work lays a foundation for understanding when and how continuous sparsity-inducing objectives can be leveraged to recover sparse networks through training.","authors":["Julia Nakhleh","Robert D. Nowak"],"url":"https://arxiv.org/abs/2505.21791"}
{"created":"2025-05-29","title":"A General-Purpose Theorem for High-Probability Bounds of Stochastic Approximation with Polyak Averaging","abstract":"Polyak-Ruppert averaging is a widely used technique to achieve the optimal asymptotic variance of stochastic approximation (SA) algorithms, yet its high-probability performance guarantees remain underexplored in general settings. In this paper, we present a general framework for establishing non-asymptotic concentration bounds for the error of averaged SA iterates. Our approach assumes access to individual concentration bounds for the unaveraged iterates and yields a sharp bound on the averaged iterates. We also construct an example, showing the tightness of our result up to constant multiplicative factors. As direct applications, we derive tight concentration bounds for contractive SA algorithms and for algorithms such as temporal difference learning and Q-learning with averaging, obtaining new bounds in settings where traditional analysis is challenging.","authors":["Sajad Khodadadian","Martin Zubeldia"],"url":"https://arxiv.org/abs/2505.21796"}
{"created":"2025-05-29","title":"PolarGrad: A Class of Matrix-Gradient Optimizers from a Unifying Preconditioning Perspective","abstract":"The ever-growing scale of deep learning models and datasets underscores the critical importance of efficient optimization methods. While preconditioned gradient methods such as Adam and AdamW are the de facto optimizers for training neural networks and large language models, structure-aware preconditioned optimizers like Shampoo and Muon, which utilize the matrix structure of gradients, have demonstrated promising evidence of faster convergence. In this paper, we introduce a unifying framework for analyzing \"matrix-aware\" preconditioned methods, which not only sheds light on the effectiveness of Muon and related optimizers but also leads to a class of new structure-aware preconditioned methods. A key contribution of this framework is its precise distinction between preconditioning strategies that treat neural network weights as vectors (addressing curvature anisotropy) versus those that consider their matrix structure (addressing gradient anisotropy). This perspective provides new insights into several empirical phenomena in language model pre-training, including Adam's training instabilities, Muon's accelerated convergence, and the necessity of learning rate warmup for Adam. Building upon this framework, we introduce PolarGrad, a new class of preconditioned optimization methods based on the polar decomposition of matrix-valued gradients. As a special instance, PolarGrad includes Muon with updates scaled by the nuclear norm of the gradients. We provide numerical implementations of these methods, leveraging efficient numerical polar decomposition algorithms for enhanced convergence. Our extensive evaluations across diverse matrix optimization problems and language model pre-training tasks demonstrate that PolarGrad outperforms both Adam and Muon.","authors":["Tim Tsz-Kit Lau","Qi Long","Weijie Su"],"url":"https://arxiv.org/abs/2505.21799"}
{"created":"2025-05-29","title":"Spectral clustering for dependent community Hawkes process models of temporal networks","abstract":"Temporal networks observed continuously over time through timestamped relational events data are commonly encountered in application settings including online social media communications, financial transactions, and international relations. Temporal networks often exhibit community structure and strong dependence patterns among node pairs. This dependence can be modeled through mutual excitations, where an interaction event from a sender to a receiver node increases the possibility of future events among other node pairs.","authors":["Lingfei Zhao","Hadeel Soliman","Kevin S. Xu","Subhadeep Paul"],"url":"https://arxiv.org/abs/2505.21845"}
{"created":"2025-05-29","title":"CSI-Bench: A Large-Scale In-the-Wild Dataset for Multi-task WiFi Sensing","abstract":"WiFi sensing has emerged as a compelling contactless modality for human activity monitoring by capturing fine-grained variations in Channel State Information (CSI). Its ability to operate continuously and non-intrusively while preserving user privacy makes it particularly suitable for health monitoring. However, existing WiFi sensing systems struggle to generalize in real-world settings, largely due to datasets collected in controlled environments with homogeneous hardware and fragmented, session-based recordings that fail to reflect continuous daily activity.","authors":["Guozhen Zhu","Yuqian Hu","Weihang Gao","Wei-Hsiang Wang","Beibei Wang","K. J. Ray Liu"],"url":"https://arxiv.org/abs/2505.21866"}
{"created":"2025-05-29","title":"Targeted Unlearning Using Perturbed Sign Gradient Methods With Applications On Medical Images","abstract":"Machine unlearning aims to remove the influence of specific training samples from a trained model without full retraining. While prior work has largely focused on privacy-motivated settings, we recast unlearning as a general-purpose tool for post-deployment model revision. Specifically, we focus on utilizing unlearning in clinical contexts where data shifts, device deprecation, and policy changes are common. To this end, we propose a bilevel optimization formulation of boundary-based unlearning that can be solved using iterative algorithms. We provide convergence guarantees when first-order algorithms are used to unlearn. Our method introduces tunable loss design for controlling the forgetting-retention tradeoff and supports novel model composition strategies that merge the strengths of distinct unlearning runs. Across benchmark and real-world clinical imaging datasets, our approach outperforms baselines on both forgetting and retention metrics, including scenarios involving imaging devices and anatomical outliers. This work establishes machine unlearning as a modular, practical alternative to retraining for real-world model maintenance in clinical applications.","authors":["George R. Nahass","Zhu Wang","Homa Rashidisabet","Won Hwa Kim","Sasha Hubschman","Jeffrey C. Peterson","Ghasem Yazdanpanah","Chad A. Purnell","Pete Setabutr","Ann Q. Tran","Darvin Yi","Sathya N. Ravi"],"url":"https://arxiv.org/abs/2505.21872"}
{"created":"2025-05-29","title":"HelixDesign-Binder: A Scalable Production-Grade Platform for Binder Design Built on HelixFold3","abstract":"Protein binder design is central to therapeutics, diagnostics, and synthetic biology, yet practical deployment remains challenging due to fragmented workflows, high computational costs, and complex tool integration. We present HelixDesign-Binder, a production-grade, high-throughput platform built on HelixFold3 that automates the full binder design pipeline, from backbone generation and sequence design to structural evaluation and multi-dimensional scoring. By unifying these stages into a scalable and user-friendly system, HelixDesign-Binder enables efficient exploration of binder candidates with favorable structural, energetic, and physicochemical properties. The platform leverages Baidu Cloud's high-performance infrastructure to support large-scale design and incorporates advanced scoring metrics, including ipTM, predicted binding free energy, and interface hydrophobicity. Benchmarking across six protein targets demonstrates that HelixDesign-Binder reliably produces diverse and high-quality binders, some of which match or exceed validated designs in predicted binding affinity. HelixDesign-Binder is accessible via an interactive web interface in PaddleHelix platform, supporting both academic research and industrial applications in antibody and protein binder development.","authors":["Jie Gao","Jun Li","Jing Hu","Shanzhuo Zhang","Kunrui Zhu","Yueyang Huang","Xiaonan Zhang","Xiaomin Fang"],"url":"https://arxiv.org/abs/2505.21873"}
{"created":"2025-05-29","title":"MAMBO-NET: Multi-Causal Aware Modeling Backdoor-Intervention Optimization for Medical Image Segmentation Network","abstract":"Medical image segmentation methods generally assume that the process from medical image to segmentation is unbiased, and use neural networks to establish conditional probability models to complete the segmentation task. This assumption does not consider confusion factors, which can affect medical images, such as complex anatomical variations and imaging modality limitations. Confusion factors obfuscate the relevance and causality of medical image segmentation, leading to unsatisfactory segmentation results. To address this issue, we propose a multi-causal aware modeling backdoor-intervention optimization (MAMBO-NET) network for medical image segmentation. Drawing insights from causal inference, MAMBO-NET utilizes self-modeling with multi-Gaussian distributions to fit the confusion factors and introduce causal intervention into the segmentation process. Moreover, we design appropriate posterior probability constraints to effectively train the distributions of confusion factors. For the distributions to effectively guide the segmentation and mitigate and eliminate the Impact of confusion factors on the segmentation, we introduce classical backdoor intervention techniques and analyze their feasibility in the segmentation task. To evaluate the effectiveness of our approach, we conducted extensive experiments on five medical image datasets. The results demonstrate that our method significantly reduces the influence of confusion factors, leading to enhanced segmentation accuracy.","authors":["Ruiguo Yu","Yiyang Zhang","Yuan Tian","Yujie Diao","Di Jin","Witold Pedrycz"],"url":"https://arxiv.org/abs/2505.21874"}
{"created":"2025-05-29","title":"Almost Linear Convergence under Minimal Score Assumptions: Quantized Transition Diffusion","abstract":"Continuous diffusion models have demonstrated remarkable performance in data generation across various domains, yet their efficiency remains constrained by two critical limitations: (1) the local adjacency structure of the forward Markov process, which restricts long-range transitions in the data space, and (2) inherent biases introduced during the simulation of time-inhomogeneous reverse denoising processes. To address these challenges, we propose Quantized Transition Diffusion (QTD), a novel approach that integrates data quantization with discrete diffusion dynamics. Our method first transforms the continuous data distribution $p_*$ into a discrete one $q_*$ via histogram approximation and binary encoding, enabling efficient representation in a structured discrete latent space. We then design a continuous-time Markov chain (CTMC) with Hamming distance-based transitions as the forward process, which inherently supports long-range movements in the original data space. For reverse-time sampling, we introduce a \\textit{truncated uniformization} technique to simulate the reverse CTMC, which can provably provide unbiased generation from $q_*$ under minimal score assumptions. Through a novel KL dynamic analysis of the reverse CTMC, we prove that QTD can generate samples with $O(d\\ln^2(d/\\epsilon))$ score evaluations in expectation to approximate the $d$--dimensional target distribution $p_*$ within an $\\epsilon$ error tolerance. Our method not only establishes state-of-the-art inference efficiency but also advances the theoretical foundations of diffusion-based generative modeling by unifying discrete and continuous diffusion paradigms.","authors":["Xunpeng Huang","Yingyu Lin","Nikki Lijing Kuang","Hanze Dong","Difan Zou","Yian Ma","Tong Zhang"],"url":"https://arxiv.org/abs/2505.21892"}
{"created":"2025-05-29","title":"Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology","abstract":"Gastrointestinal (GI) diseases represent a clinically significant burden, necessitating precise diagnostic approaches to optimize patient outcomes. Conventional histopathological diagnosis, heavily reliant on the subjective interpretation of pathologists, suffers from limited reproducibility and diagnostic variability. To overcome these limitations and address the lack of pathology-specific foundation models for GI diseases, we develop Digepath, a specialized foundation model for GI pathology. Our framework introduces a dual-phase iterative optimization strategy combining pretraining with fine-screening, specifically designed to address the detection of sparsely distributed lesion areas in whole-slide images. Digepath is pretrained on more than 353 million image patches from over 200,000 hematoxylin and eosin-stained slides of GI diseases. It attains state-of-the-art performance on 33 out of 34 tasks related to GI pathology, including pathological diagnosis, molecular prediction, gene mutation prediction, and prognosis evaluation, particularly in diagnostically ambiguous cases and resolution-agnostic tissue classification.We further translate the intelligent screening module for early GI cancer and achieve near-perfect 99.6% sensitivity across 9 independent medical institutions nationwide. The outstanding performance of Digepath highlights its potential to bridge critical gaps in histopathological practice. This work not only advances AI-driven precision pathology for GI diseases but also establishes a transferable paradigm for other pathology subspecialties.","authors":["Lianghui Zhu","Xitong Ling","Minxi Ouyang","Xiaoping Liu","Mingxi Fu","Tian Guan","Fanglei Fu","Xuanyu Wang","Maomao Zeng","Mingxi Zhu","Yibo Jin","Liming Liu","Song Duan","Qiming He","Yizhi Wang","Luxi Xie","Houqiang Li","Yonghong He","Sufang Tian"],"url":"https://arxiv.org/abs/2505.21928"}
{"created":"2025-05-29","title":"Higher-Order Group Synchronization","abstract":"Group synchronization is the problem of determining reliable global estimates from noisy local measurements on networks. The typical task for group synchronization is to assign elements of a group to the nodes of a graph in a way that respects group elements given on the edges which encode information about local pairwise relationships between the nodes. In this paper, we introduce a novel higher-order group synchronization problem which operates on a hypergraph and seeks to synchronize higher-order local measurements on the hyperedges to obtain global estimates on the nodes. Higher-order group synchronization is motivated by applications to computer vision and image processing, among other computational problems. First, we define the problem of higher-order group synchronization and discuss its mathematical foundations. Specifically, we give necessary and sufficient synchronizability conditions which establish the importance of cycle consistency in higher-order group synchronization. Then, we propose the first computational framework for general higher-order group synchronization; it acts globally and directly on higher-order measurements using a message passing algorithm. We discuss theoretical guarantees for our framework, including convergence analyses under outliers and noise. Finally, we show potential advantages of our method through numerical experiments. In particular, we show that in certain cases our higher-order method applied to rotational and angular synchronization outperforms standard pairwise synchronization methods and is more robust to outliers. We also show that our method has comparable performance on simulated cryo-electron microscopy (cryo-EM) data compared to a standard cryo-EM reconstruction package.","authors":["Adriana L. Duncan","Joe Kileel"],"url":"https://arxiv.org/abs/2505.21932"}
{"created":"2025-05-29","title":"Properties of zero-determinant strategies in multichannel games","abstract":"Controlling payoffs in repeated games is one of the important topics in control theory of multi-agent systems. Recently proposed zero-determinant strategies enable players to unilaterally enforce linear relations between payoffs. Furthermore, based on the mathematics of zero-determinant strategies, regional payoff control, in which payoffs are enforced into some feasible regions, has been discovered in social dilemma situations. More recently, theory of payoff control was extended to multichannel games, where players parallelly interact with each other in multiple channels. However, properties of zero-determinant strategies specific to multichannel games are still not clear. In this paper, we elucidate properties of zero-determinant strategies in multichannel games. First, we relate the existence condition of zero-determinant strategies in multichannel games to that of zero-determinant strategies in each channel. We then show that the existence of zero-determinant strategies in multichannel games requires the existence of zero-determinant strategies in some channels. This result implies that the existence of zero-determinant strategies in multichannel games is tightly restricted by structure of games played in each channel.","authors":["Masahiko Ueda"],"url":"https://arxiv.org/abs/2505.21952"}
{"created":"2025-05-29","title":"Align-DA: Align Score-based Atmospheric Data Assimilation with Multiple Preferences","abstract":"Data assimilation (DA) aims to estimate the full state of a dynamical system by combining partial and noisy observations with a prior model forecast, commonly referred to as the background. In atmospheric applications, this problem is fundamentally ill-posed due to the sparsity of observations relative to the high-dimensional state space. Traditional methods address this challenge by simplifying background priors to regularize the solution, which are empirical and require continual tuning for application. Inspired by alignment techniques in text-to-image diffusion models, we propose Align-DA, which formulates DA as a generative process and uses reward signals to guide background priors, replacing manual tuning with data-driven alignment. Specifically, we train a score-based model in the latent space to approximate the background-conditioned prior, and align it using three complementary reward signals for DA: (1) assimilation accuracy, (2) forecast skill initialized from the assimilated state, and (3) physical adherence of the analysis fields. Experiments with multiple reward signals demonstrate consistent improvements in analysis quality across different evaluation metrics and observation-guidance strategies. These results show that preference alignment, implemented as a soft constraint, can automatically adapt complex background priors tailored to DA, offering a promising new direction for advancing the field.","authors":["Jing-An Sun","Hang Fan","Junchao Gong","Ben Fei","Kun Chen","Fenghua Ling","Wenlong Zhang","Wanghan Xu","Li Yan","Pierre Gentine","Lei Bai"],"url":"https://arxiv.org/abs/2505.22008"}
{"created":"2025-05-29","title":"Analysis and Evaluation of Synthetic Data Generation in Speech Dysfluency Detection","abstract":"Speech dysfluency detection is crucial for clinical diagnosis and language assessment, but existing methods are limited by the scarcity of high-quality annotated data. Although recent advances in TTS model have enabled synthetic dysfluency generation, existing synthetic datasets suffer from unnatural prosody and limited contextual diversity. To address these limitations, we propose LLM-Dys -- the most comprehensive dysfluent speech corpus with LLM-enhanced dysfluency simulation. This dataset captures 11 dysfluency categories spanning both word and phoneme levels. Building upon this resource, we improve an end-to-end dysfluency detection framework. Experimental validation demonstrates state-of-the-art performance. All data, models, and code are open-sourced at https://github.com/Berkeley-Speech-Group/LLM-Dys.","authors":["Jinming Zhang","Xuanru Zhou","Jiachen Lian","Shuhe Li","William Li","Zoe Ezzes","Rian Bogley","Lisa Wauters","Zachary Miller","Jet Vonk","Brittany Morin","Maria Gorno-Tempini","Gopala Anumanchipalli"],"url":"https://arxiv.org/abs/2505.22029"}
{"created":"2025-05-29","title":"Learning Curves of Stochastic Gradient Descent in Kernel Regression","abstract":"This paper considers a canonical problem in kernel regression: how good are the model performances when it is trained by the popular online first-order algorithms, compared to the offline ones, such as ridge and ridgeless regression? In this paper, we analyze the foundational single-pass Stochastic Gradient Descent (SGD) in kernel regression under source condition where the optimal predictor can even not belong to the RKHS, i.e. the model is misspecified. Specifically, we focus on the inner product kernel over the sphere and characterize the exact orders of the excess risk curves under different scales of sample sizes $n$ concerning the input dimension $d$. Surprisingly, we show that SGD achieves min-max optimal rates up to constants among all the scales, without suffering the saturation, a prevalent phenomenon observed in (ridge) regression, except when the model is highly misspecified and the learning is in a final stage where $n\\gg d^{\\gamma}$ with any constant $\\gamma >0$. The main reason for SGD to overcome the curse of saturation is the exponentially decaying step size schedule, a common practice in deep neural network training. As a byproduct, we provide the \\emph{first} provable advantage of the scheme over the iterative averaging method in the common setting.","authors":["Haihan Zhang","Weicheng Lin","Yuanshi Liu","Cong Fang"],"url":"https://arxiv.org/abs/2505.22048"}
{"created":"2025-05-29","title":"Physical Reduced Stochastic Equations for Continuously Monitored Non-Markovian Quantum Systems with a Markovian Embedding","abstract":"An effective approach to modeling non-Markovian quantum systems is to embed a principal (quantum) system of interest into a larger quantum system. A widely employed embedding is one that uses another quantum system, referred to as the auxiliary system, which is coupled to the principal system, and both the principal and auxiliary can be coupled to quantum white noise processes. The principal and auxiliary together form a quantum Markov system and the quantum white noises act as a bath (environment) for this system.","authors":["Hendra I. Nurdin"],"url":"https://arxiv.org/abs/2505.22070"}
{"created":"2025-05-29","title":"Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz","abstract":"In this work, we introduce the first type of non-Euclidean neural quantum state (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent neural networks (RNNs)), to be used in the Variational Monte Carlo method of approximating the ground state wavefunction for quantum many-body systems. In particular, we examine the performances of NQS ansatzes constructed from both conventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical settings of the one- and two-dimensional transverse field Ising models (TFIM) of up to 100 spins and the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$ systems of up 50 spins. By virtue of the fact that, for all of the experiments performed in this work, hyperbolic GRU can yield performances comparable to or better than Euclidean RNNs, which have been extensively studied in these settings in the literature, our work is a proof-of-concept for the viability of hyperbolic GRU as the first type of non-Euclidean NQS ansatz for quantum many-body systems. Furthermore, in settings where the Hamiltonian displays a clear hierarchical interaction structure, such as the 1D Heisenberg $J_1J_2$ & $J_1J_2J_3$ systems with the 1st, 2nd and even 3rd nearest neighbor interactions, our results show that hyperbolic GRU definitively outperforms its Euclidean version in all instances. The fact that these results are reminiscent of the established ones from natural language processing where hyperbolic GRU almost always outperforms Euclidean RNNs when the training data exhibit a tree-like or hierarchical structure leads us to hypothesize that hyperbolic GRU NQS ansatz would likely outperform Euclidean RNN/GRU NQS ansatz in quantum spin systems that involve different degrees of nearest neighbor interactions. Finally, with this work, we hope to initiate future studies of other types of non-Euclidean NQS beyond hyperbolic GRU.","authors":["H. L. Dao"],"url":"https://arxiv.org/abs/2505.22083"}
{"created":"2025-05-29","title":"PADAM: Parallel averaged Adam reduces the error for stochastic optimization in scientific machine learning","abstract":"Averaging techniques such as Ruppert--Polyak averaging and exponential movering averaging (EMA) are powerful approaches to accelerate optimization procedures of stochastic gradient descent (SGD) optimization methods such as the popular ADAM optimizer. However, depending on the specific optimization problem under consideration, the type and the parameters for the averaging need to be adjusted to achieve the smallest optimization error. In this work we propose an averaging approach, which we refer to as parallel averaged ADAM (PADAM), in which we compute parallely different averaged variants of ADAM and during the training process dynamically select the variant with the smallest optimization error. A central feature of this approach is that this procedure requires no more gradient evaluations than the usual ADAM optimizer as each of the averaged trajectories relies on the same underlying ADAM trajectory and thus on the same underlying gradients. We test the proposed PADAM optimizer in 13 stochastic optimization and deep neural network (DNN) learning problems and compare its performance with known optimizers from the literature such as standard SGD, momentum SGD, Adam with and without EMA, and ADAMW. In particular, we apply the compared optimizers to physics-informed neural network, deep Galerkin, deep backward stochastic differential equation and deep Kolmogorov approximations for boundary value partial differential equation problems from scientific machine learning, as well as to DNN approximations for optimal control and optimal stopping problems. In nearly all of the considered examples PADAM achieves, sometimes among others and sometimes exclusively, essentially the smallest optimization error. This work thus strongly suggest to consider PADAM for scientific machine learning problems and also motivates further research for adaptive averaging procedures within the training of DNNs.","authors":["Arnulf Jentzen","Julian Kranz","Adrian Riekert"],"url":"https://arxiv.org/abs/2505.22085"}
{"created":"2025-05-29","title":"High Volume Rate 3D Ultrasound Reconstruction with Diffusion Models","abstract":"Three-dimensional ultrasound enables real-time volumetric visualization of anatomical structures. Unlike traditional 2D ultrasound, 3D imaging reduces the reliance on precise probe orientation, potentially making ultrasound more accessible to clinicians with varying levels of experience and improving automated measurements and post-exam analysis. However, achieving both high volume rates and high image quality remains a significant challenge. While 3D diverging waves can provide high volume rates, they suffer from limited tissue harmonic generation and increased multipath effects, which degrade image quality. One compromise is to retain the focusing in elevation while leveraging unfocused diverging waves in the lateral direction to reduce the number of transmissions per elevation plane. Reaching the volume rates achieved by full 3D diverging waves, however, requires dramatically undersampling the number of elevation planes. Subsequently, to render the full volume, simple interpolation techniques are applied. This paper introduces a novel approach to 3D ultrasound reconstruction from a reduced set of elevation planes by employing diffusion models (DMs) to achieve increased spatial and temporal resolution. We compare both traditional and supervised deep learning-based interpolation methods on a 3D cardiac ultrasound dataset. Our results show that DM-based reconstruction consistently outperforms the baselines in image quality and downstream task performance. Additionally, we accelerate inference by leveraging the temporal consistency inherent to ultrasound sequences. Finally, we explore the robustness of the proposed method by exploiting the probabilistic nature of diffusion posterior sampling to quantify reconstruction uncertainty and demonstrate improved recall on out-of-distribution data with synthetic anomalies under strong subsampling.","authors":["Tristan S. W. Stevens","Ois\\'in Nolan","Oudom Somphone","Jean-Luc Robert","Ruud J. G. van Sloun"],"url":"https://arxiv.org/abs/2505.22090"}
{"created":"2025-05-29","title":"Interpolation of Quantum Polar Codes and Quantum Reed-Muller Codes","abstract":"Good quantum error-correcting codes that fulfill practical considerations, such as simple encoding circuits and efficient decoders, are essential for functional quantum information processing systems. Quantum polar codes satisfy some of these requirements but lack certain critical features, thereby hindering their widespread use. Existing constructions either require entanglement assistance to produce valid quantum codes, suffer from poor finite-size performance, or fail to tailor polar codes to the underlying channel properties. Meanwhile, quantum Reed-Muller (RM) codes demonstrate strong performance, though no known efficient decoding algorithm exists for them. In this work, we propose strategies to interpolate between quantum polar codes and quantum RM codes, thus addressing the challenges of designing valid quantum polar codes without entanglement assistance and improving finite-size code performance.","authors":["Keita Hidaka","Dina Abdelhadi","Ruediger Urbanke"],"url":"https://arxiv.org/abs/2505.22142"}
{"created":"2025-05-29","title":"Discrete stochastic maximal regularity","abstract":"In this paper, we investigate discrete regularity estimates for a broad class of temporal numerical schemes for parabolic stochastic evolution equations. We provide a characterization of discrete stochastic maximal $\\ell^p$-regularity in terms of its continuous counterpart, thereby establishing a unified framework that yields numerous new discrete regularity results. Moreover, as a consequence of the continuous-time theory, we establish several important properties of discrete stochastic maximal regularity such as extrapolation in the exponent $p$ and with respect to a power weight. Furthermore, employing the $H^\\infty$-functional calculus, we derive a powerful discrete maximal estimate in the trace space norm $D_A(1-\\frac1p,p)$ for $p \\in [2,\\infty)$.","authors":["Foivos Evangelopoulos-Ntemiris","Mark Veraar"],"url":"https://arxiv.org/abs/2505.22145"}
{"created":"2025-05-29","title":"Attention-Enhanced Prompt Decision Transformers for UAV-Assisted Communications with AoI","abstract":"Decision Transformer (DT) has recently demonstrated strong generalizability in dynamic resource allocation within unmanned aerial vehicle (UAV) networks, compared to conventional deep reinforcement learning (DRL). However, its performance is hindered due to zero-padding for varying state dimensions, inability to manage long-term energy constraint, and challenges in acquiring expert samples for few-shot fine-tuning in new scenarios. To overcome these limitations, we propose an attention-enhanced prompt Decision Transformer (APDT) framework to optimize trajectory planning and user scheduling, aiming to minimize the average age of information (AoI) under long-term energy constraint in UAV-assisted Internet of Things (IoT) networks. Specifically, we enhance the convenional DT framework by incorporating an attention mechanism to accommodate varying numbers of terrestrial users, introducing a prompt mechanism based on short trajectory demonstrations for rapid adaptation to new scenarios, and designing a token-assisted method to address the UAV's long-term energy constraint. The APDT framework is first pre-trained on offline datasets and then efficiently generalized to new scenarios. Simulations demonstrate that APDT achieves twice faster in terms of convergence rate and reduces average AoI by $8\\%$ compared to conventional DT.","authors":["Chi Lu","Yiyang Ni","Zhe Wang","Xiaoli Shi","Jun Li","Shi Jin"],"url":"https://arxiv.org/abs/2505.22170"}
{"created":"2025-05-29","title":"Physics-inspired Generative AI models via real hardware-based noisy quantum diffusion","abstract":"Quantum Diffusion Models (QDMs) are an emerging paradigm in Generative AI that aims to use quantum properties to improve the performances of their classical counterparts. However, existing algorithms are not easily scalable due to the limitations of near-term quantum devices. Following our previous work on QDMs, here we propose and implement two physics-inspired protocols. In the first, we use the formalism of quantum stochastic walks, showing that a specific interplay of quantum and classical dynamics in the forward process produces statistically more robust models generating sets of MNIST images with lower Fr\\'echet Inception Distance (FID) than using totally classical dynamics. In the second approach, we realize an algorithm to generate images by exploiting the intrinsic noise of real IBM quantum hardware with only four qubits. Our work could be a starting point to pave the way for new scenarios for large-scale algorithms in quantum Generative AI, where quantum noise is neither mitigated nor corrected, but instead exploited as a useful resource.","authors":["Marco Parigi","Stefano Martina","Francesco Aldo Venturelli","Filippo Caruso"],"url":"https://arxiv.org/abs/2505.22193"}
{"created":"2025-05-29","title":"Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition","abstract":"Recent work suggests that large language models (LLMs) can improve performance of speech tasks compared to existing systems. To support their claims, results on LibriSpeech and Common Voice are often quoted. However, this work finds that a substantial amount of the LibriSpeech and Common Voice evaluation sets appear in public LLM pretraining corpora. This calls into question the reliability of findings drawn from these two datasets. To measure the impact of contamination, LLMs trained with or without contamination are compared, showing that a contaminated LLM is more likely to generate test sentences it has seen during training. Speech recognisers using contaminated LLMs shows only subtle differences in error rates, but assigns significantly higher probabilities to transcriptions seen during training. Results show that LLM outputs can be biased by tiny amounts of data contamination, highlighting the importance of evaluating LLM-based speech systems with held-out data.","authors":["Yuan Tseng","Titouan Parcollet","Rogier van Dalen","Shucong Zhang","Sourav Bhattacharya"],"url":"https://arxiv.org/abs/2505.22251"}
{"created":"2025-05-29","title":"Large-Area Fabrication-aware Computational Diffractive Optics","abstract":"Differentiable optics, as an emerging paradigm that jointly optimizes optics and (optional) image processing algorithms, has made innovative optical designs possible across a broad range of applications. Many of these systems utilize diffractive optical components (DOEs) for holography, PSF engineering, or wavefront shaping. Existing approaches have, however, mostly remained limited to laboratory prototypes, owing to a large quality gap between simulation and manufactured devices. We aim at lifting the fundamental technical barriers to the practical use of learned diffractive optical systems. To this end, we propose a fabrication-aware design pipeline for diffractive optics fabricated by direct-write grayscale lithography followed by nano-imprinting replication, which is directly suited for inexpensive mass production of large area designs. We propose a super-resolved neural lithography model that can accurately predict the 3D geometry generated by the fabrication process. This model can be seamlessly integrated into existing differentiable optics frameworks, enabling fabrication-aware, end-to-end optimization of computational optical systems. To tackle the computational challenges, we also devise tensor-parallel compute framework centered on distributing large-scale FFT computation across many GPUs. As such, we demonstrate large scale diffractive optics designs up to 32.16 mm $\\times$ 21.44 mm, simulated on grids of up to 128,640 by 85,760 feature points. We find adequate agreement between simulation and fabricated prototypes for applications such as holography and PSF engineering. We also achieve high image quality from an imaging system comprised only of a single DOE, with images processed only by a Wiener filter utilizing the simulation PSF. We believe our findings lift the fabrication limitations for real-world applications of diffractive optics and differentiable optical design.","authors":["Kaixuan Wei","Hector A. Jimenez-Romero","Hadi Amata","Jipeng Sun","Qiang Fu","Felix Heide","Wolfgang Heidrich"],"url":"https://arxiv.org/abs/2505.22313"}
{"created":"2025-05-29","title":"Individualised Counterfactual Examples Using Conformal Prediction Intervals","abstract":"Counterfactual explanations for black-box models aim to pr ovide insight into an algorithmic decision to its recipient. For a binary classification problem an individual counterfactual details which features might be changed for the model to infer the opposite class. High-dimensional feature spaces that are typical of machine learning classification models admit many possible counterfactual examples to a decision, and so it is important to identify additional criteria to select the most useful counterfactuals. In this paper, we explore the idea that the counterfactuals should be maximally informative when considering the knowledge of a specific individual about the underlying classifier. To quantify this information gain we explicitly model the knowledge of the individual, and assess the uncertainty of predictions which the individual makes by the width of a conformal prediction interval. Regions of feature space where the prediction interval is wide correspond to areas where the confidence in decision making is low, and an additional counterfactual example might be more informative to an individual. To explore and evaluate our individualised conformal prediction interval counterfactuals (CPICFs), first we present a synthetic data set on a hypercube which allows us to fully visualise the decision boundary, conformal intervals via three different methods, and resultant CPICFs. Second, in this synthetic data set we explore the impact of a single CPICF on the knowledge of an individual locally around the original query. Finally, in both our synthetic data set and a complex real world dataset with a combination of continuous and discrete variables, we measure the utility of these counterfactuals via data augmentation, testing the performance on a held out set.","authors":["James M. Adams","Gesine Reinert","Lukasz Szpruch","Carsten Maple","Andrew Elliott"],"url":"https://arxiv.org/abs/2505.22326"}
{"created":"2025-05-29","title":"Credal Prediction based on Relative Likelihood","abstract":"Predictions in the form of sets of probability distributions, so-called credal sets, provide a suitable means to represent a learner's epistemic uncertainty. In this paper, we propose a theoretically grounded approach to credal prediction based on the statistical notion of relative likelihood: The target of prediction is the set of all (conditional) probability distributions produced by the collection of plausible models, namely those models whose relative likelihood exceeds a specified threshold. This threshold has an intuitive interpretation and allows for controlling the trade-off between correctness and precision of credal predictions. We tackle the problem of approximating credal sets defined in this way by means of suitably modified ensemble learning techniques. To validate our approach, we illustrate its effectiveness by experiments on benchmark datasets demonstrating superior uncertainty representation without compromising predictive performance. We also compare our method against several state-of-the-art baselines in credal prediction.","authors":["Timo L\\\"ohr","Paul Hofman","Felix Mohr","Eyke H\\\"ullermeier"],"url":"https://arxiv.org/abs/2505.22332"}
{"created":"2025-05-29","title":"Empowering Intelligent Low-altitude Economy with Large AI Model Deployment","abstract":"Low-altitude economy (LAE) represents an emerging economic paradigm that redefines commercial and social aerial activities. Large artificial intelligence models (LAIMs) offer transformative potential to further enhance the intelligence of LAE services. However, deploying LAIMs in LAE poses several challenges, including the significant gap between their computational/storage demands and the limited onboard resources of LAE entities, the mismatch between lab-trained LAIMs and dynamic physical environments, and the inefficiencies of traditional decoupled designs for sensing, communication, and computation. To address these issues, we first propose a hierarchical system architecture tailored for LAIM deployment and present representative LAE application scenarios. Next, we explore key enabling techniques that facilitate the mutual co-evolution of LAIMs and low-altitude systems, and introduce a task-oriented execution pipeline for scalable and adaptive service delivery. Then, the proposed framework is validated through real-world case studies. Finally, we outline open challenges to inspire future research.","authors":["Zhonghao Lyu","Yulan Gao","Junting Chen","Hongyang Du","Jie Xu","Kaibin Huang","Dong In Kim"],"url":"https://arxiv.org/abs/2505.22343"}
{"created":"2025-05-29","title":"Computing Optimal Transport Maps and Wasserstein Barycenters Using Conditional Normalizing Flows","abstract":"We present a novel method for efficiently computing optimal transport maps and Wasserstein barycenters in high-dimensional spaces. Our approach uses conditional normalizing flows to approximate the input distributions as invertible pushforward transformations from a common latent space. This makes it possible to directly solve the primal problem using gradient-based minimization of the transport cost, unlike previous methods that rely on dual formulations and complex adversarial optimization. We show how this approach can be extended to compute Wasserstein barycenters by solving a conditional variance minimization problem. A key advantage of our conditional architecture is that it enables the computation of barycenters for hundreds of input distributions, which was computationally infeasible with previous methods. Our numerical experiments illustrate that our approach yields accurate results across various high-dimensional tasks and compares favorably with previous state-of-the-art methods.","authors":["Gabriele Visentin","Patrick Cheridito"],"url":"https://arxiv.org/abs/2505.22364"}
{"created":"2025-05-29","title":"Fast evaluation of Riemann theta functions in any dimension","abstract":"We describe an algorithm to numerically evaluate Riemann theta functions in any dimension in quasi-linear time in terms of the required precision, uniformly on reduced input. This algorithm is implemented in the FLINT number theory library and vastly outperforms existing software.","authors":["Noam D. Elkies","Jean Kieffer"],"url":"https://arxiv.org/abs/2505.22382"}
{"created":"2025-05-29","title":"Numerical Optimization Strategies for the Variational Hamiltonian Ansatz in Noisy Quantum Environments","abstract":"We conduct a benchmark of eight optimization algorithms for variational quantum chemistry using the tVHA, evaluating performance on $H_2$, $H_4$, and $LiH$ (in both full and active spaces) under noiseless and sampling noise conditions. Sampling noise fundamentally alters optimizer behavior, with gradient-based methods performing best in ideal conditions, while population-based algorithms, such as CMA-ES, show greater resilience under noise. Hartree-Fock initialization reduces the number of function evaluations by 27-60% and consistently yields higher final accuracy compared to random starting points. We identify a precision limit set by sampling noise, with diminishing returns beyond approximately 1000 shots.","authors":["S. Ill\\'esov\\'a","V. Nov\\'ak","T. Bezd\\v{e}k","M. Beseda","C. Possel"],"url":"https://arxiv.org/abs/2505.22398"}
{"created":"2025-05-29","title":"Learning to Pursue AC Optimal Power Flow Solutions with Feasibility Guarantees","abstract":"This paper focuses on an AC optimal power flow (OPF) problem for distribution feeders equipped with controllable distributed energy resources (DERs). We consider a solution method that is based on a continuous approximation of the projected gradient flow - referred to as the safe gradient flow - that incorporates voltage and current information obtained either through real-time measurements or power flow computations. These two setups enable both online and offline implementations. The safe gradient flow involves the solution of convex quadratic programs (QPs). To enhance computational efficiency, we propose a novel framework that employs a neural network approximation of the optimal solution map of the QP. The resulting method has two key features: (a) it ensures that the DERs' setpoints are practically feasible, even for an online implementation or when an offline algorithm has an early termination; (b) it ensures convergence to a neighborhood of a strict local optimizer of the AC OPF. The proposed method is tested on a 93-node distribution system with realistic loads and renewable generation. The test shows that our method successfully regulates voltages within limits during periods with high renewable generation.","authors":["Damola Ajeyemi","Yiting Chen","Antonin Colot","Jorge Cortes","Emiliano Dall'Anese"],"url":"https://arxiv.org/abs/2505.22399"}
{"created":"2025-05-29","title":"COSMOS: A Data-Driven Probabilistic Time Series simulator for Chemical Plumes across Spatial Scales","abstract":"The development of robust odor navigation strategies for automated environmental monitoring applications requires realistic simulations of odor time series for agents moving across large spatial scales. Traditional approaches that rely on computational fluid dynamics (CFD) methods can capture the spatiotemporal dynamics of odor plumes, but are impractical for large-scale simulations due to their computational expense. On the other hand, puff-based simulations, although computationally tractable for large scales and capable of capturing the stochastic nature of plumes, fail to reproduce naturalistic odor statistics. Here, we present COSMOS (Configurable Odor Simulation Model over Scalable Spaces), a data-driven probabilistic framework that synthesizes realistic odor time series from spatial and temporal features of real datasets. COSMOS generates similar distributions of key statistical features such as whiff frequency, duration, and concentration as observed in real data, while dramatically reducing computational overhead. By reproducing critical statistical properties across a variety of flow regimes and scales, COSMOS enables the development and evaluation of agent-based navigation strategies with naturalistic odor experiences. To demonstrate its utility, we compare odor-tracking agents exposed to CFD-generated plumes versus COSMOS simulations, showing that both their odor experiences and resulting behaviors are quite similar.","authors":["Arunava Nag","Floris van Breugel"],"url":"https://arxiv.org/abs/2505.22436"}
{"created":"2025-05-29","title":"Depth-Based Matrix Classification for the HHL Quantum Algorithm","abstract":"Under the nearing error-corrected era of quantum computing, it is necessary to understand the suitability of certain post-NISQ algorithms for practical problems. One of the most promising, applicable and yet difficult to implement in practical terms is the Harrow, Hassidim and Lloyd (HHL) algorithm for linear systems of equations. An enormous number of problems can be expressed as linear systems of equations, from Machine Learning to fluid dynamics. However, in most cases, HHL will not be able to provide a practical, reasonable solution to these problems. This paper's goal inquires about whether problems can be labeled using Machine Learning classifiers as suitable or unsuitable for HHL implementation when some numerical information about the problem is known beforehand. This work demonstrates that training on significantly representative data distributions is critical to achieve good classifications of the problems based on the numerical properties of the matrix representing the system of equations. Accurate classification is possible through Multi-Layer Perceptrons, although with careful design of the training data distribution and classifier parameters.","authors":["Mark Danza","Sonia Lopez Alarcon","Cory Merkel"],"url":"https://arxiv.org/abs/2505.22454"}
{"created":"2025-05-29","title":"Articulatory modeling of the S-shaped F2 trajectories observed in \\\"Ohman's spectrographic analysis of VCV syllables","abstract":"The synthesis of Ohman's VCV sequences with intervocalic plosive consonants was first achieved 30 years ago using the DRM model. However, this approach remains primarily acoustic and lacks articulatory constraints. In this study, the same 75 VCVs are analyzed, but generated with the Maeda model, using trajectory planning that differentiates vowel-to-vowel transitions from consonantal influences. Synthetic data exhibit similar characteristics to Ohman's sequences, including the presence of S-shaped F2 trajectories. Furthermore, locus equations (LEs) for F2 and F3 are computed from synthetic CV data to investigate their underlying determinism, leading to a reassessment of conventional interpretations. The findings indicate that, although articulatory planning is structured separately for vowel and consonant groups, S-shaped F2 trajectories emerge from a composite mechanism governed by the coordinated synergy of all articulators.","authors":["Fr\\'ed\\'eric Berthommier"],"url":"https://arxiv.org/abs/2505.22455"}
{"created":"2025-05-29","title":"Continuity and approximability of competitive spectral radii","abstract":"The competitive spectral radius extends the notion of joint spectral radius to the two-player case: two players alternatively select matrices in prescribed compact sets, resulting in an infinite matrix product; one player wishes to maximize the growth rate of this product, whereas the other player wishes to minimize it. We show that when the matrices represent linear operators preserving a cone and satisfying a \"strict positivity\" assumption, the competitive spectral radius depends continuously - and even in a Lipschitz-continuous way - on the matrix sets. Moreover, we show that the competive spectral radius can be approximated up to any accuracy. This relies on the solution of a discretized infinite dimensional non-linear eigenproblem. We illustrate the approach with an example of age-structured population dynamics.","authors":["Marianne Akian","St\\'ephane Gaubert","Lo\\\"ic Marchesini","Ian Morris"],"url":"https://arxiv.org/abs/2505.22468"}
{"created":"2025-05-29","title":"Hybrid High-Order formulations with turbulence modelling capabilities for incompressible flow problems","abstract":"We propose a Hybrid High-Order (HHO) formulation of the incompressible Navier--Stokes equations, that is well suited to be employed for the simulation of turbulent flows. The spatial discretization relies on hybrid velocity and pressure spaces and the temporal discretization is based on Explicit Singly Diagonal Implicit Runge-Kutta (ESDIRK) methods. The formulation possesses some attractive features that can be fruitfully exploited when high-fidelity computations are required, namely: pressure-robustness, conservation of mass enforced cell-by-cell up to machine precision, robustness in the inviscid limit, implicit high-order accurate time stepping with local time step adaptation, reduced memory footprint thanks to static condensation of both velocity and pressure, possibility to exploit inherited $p$-multilevel solution strategies to improve performance of iterative solvers. After demonstrating the relevant properties of the scheme in practice, performing challenging 2D and 3D test cases, we consider the simulation of the Taylor--Green Vortex flow problem at Reynolds 1600.","authors":["Lorenzo Botti","Daniele Antonio Di Pietro","Francesco Carlo Massa"],"url":"https://arxiv.org/abs/2505.22480"}
{"created":"2025-05-29","title":"Hypothesis Testing in Imaging Inverse Problems","abstract":"This paper proposes a framework for semantic hypothesis testing tailored to imaging inverse problems. Modern imaging methods struggle to support hypothesis testing, a core component of the scientific method that is essential for the rigorous interpretation of experiments and robust interfacing with decision-making processes. There are three main reasons why image-based hypothesis testing is challenging. First, the difficulty of using a single observation to simultaneously reconstruct an image, formulate hypotheses, and quantify their statistical significance. Second, the hypotheses encountered in imaging are mostly of semantic nature, rather than quantitative statements about pixel values. Third, it is challenging to control test error probabilities because the null and alternative distributions are often unknown. Our proposed approach addresses these difficulties by leveraging concepts from self-supervised computational imaging, vision-language models, and non-parametric hypothesis testing with e-values. We demonstrate our proposed framework through numerical experiments related to image-based phenotyping, where we achieve excellent power while robustly controlling Type I errors.","authors":["Yiming Xi","Konstantinos Zygalakis","Marcelo Pereyra"],"url":"https://arxiv.org/abs/2505.22481"}
{"created":"2025-05-29","title":"Cascaded 3D Diffusion Models for Whole-body 3D 18-F FDG PET/CT synthesis from Demographics","abstract":"We propose a cascaded 3D diffusion model framework to synthesize high-fidelity 3D PET/CT volumes directly from demographic variables, addressing the growing need for realistic digital twins in oncologic imaging, virtual trials, and AI-driven data augmentation. Unlike deterministic phantoms, which rely on predefined anatomical and metabolic templates, our method employs a two-stage generative process. An initial score-based diffusion model synthesizes low-resolution PET/CT volumes from demographic variables alone, providing global anatomical structures and approximate metabolic activity. This is followed by a super-resolution residual diffusion model that refines spatial resolution. Our framework was trained on 18-F FDG PET/CT scans from the AutoPET dataset and evaluated using organ-wise volume and standardized uptake value (SUV) distributions, comparing synthetic and real data between demographic subgroups. The organ-wise comparison demonstrated strong concordance between synthetic and real images. In particular, most deviations in metabolic uptake values remained within 3-5% of the ground truth in subgroup analysis. These findings highlight the potential of cascaded 3D diffusion models to generate anatomically and metabolically accurate PET/CT images, offering a robust alternative to traditional phantoms and enabling scalable, population-informed synthetic imaging for clinical and research applications.","authors":["Siyeop Yoon","Sifan Song","Pengfei Jin","Matthew Tivnan","Yujin Oh","Sekeun Kim","Dufan Wu","Xiang Li","Quanzheng Li"],"url":"https://arxiv.org/abs/2505.22489"}
{"created":"2025-05-29","title":"Risk-Sensitive Conformal Prediction for Catheter Placement Detection in Chest X-rays","abstract":"This paper presents a novel approach to catheter and line position detection in chest X-rays, combining multi-task learning with risk-sensitive conformal prediction to address critical clinical requirements. Our model simultaneously performs classification, segmentation, and landmark detection, leveraging the synergistic relationship between these tasks to improve overall performance. We further enhance clinical reliability through risk-sensitive conformal prediction, which provides statistically guaranteed prediction sets with higher reliability for clinically critical findings. Experimental results demonstrate excellent performance with 90.68\\% overall empirical coverage and 99.29\\% coverage for critical conditions, while maintaining remarkable precision in prediction sets. Most importantly, our risk-sensitive approach achieves zero high-risk mispredictions (cases where the system dangerously declares problematic tubes as confidently normal), making the system particularly suitable for clinical deployment. This work offers both accurate predictions and reliably quantified uncertainty -- essential features for life-critical medical applications.","authors":["Long Hui"],"url":"https://arxiv.org/abs/2505.22496"}
{"created":"2025-05-29","title":"Assessing Quantum Advantage for Gaussian Process Regression","abstract":"Gaussian Process Regression is a well-known machine learning technique for which several quantum algorithms have been proposed. We show here that in a wide range of scenarios these algorithms show no exponential speedup. We achieve this by rigorously proving that the condition number of a kernel matrix scales at least linearly with the matrix size under general assumptions on the data and kernel. We additionally prove that the sparsity and Frobenius norm of a kernel matrix scale linearly under similar assumptions. The implications for the quantum algorithms runtime are independent of the complexity of loading classical data on a quantum computer and also apply to dequantised algorithms. We supplement our theoretical analysis with numerical verification for popular kernels in machine learning.","authors":["Dominic Lowe","M. S. Kim","Roberto Bondesan"],"url":"https://arxiv.org/abs/2505.22502"}
{"created":"2025-05-29","title":"Surf2CT: Cascaded 3D Flow Matching Models for Torso 3D CT Synthesis from Skin Surface","abstract":"We present Surf2CT, a novel cascaded flow matching framework that synthesizes full 3D computed tomography (CT) volumes of the human torso from external surface scans and simple demographic data (age, sex, height, weight). This is the first approach capable of generating realistic volumetric internal anatomy images solely based on external body shape and demographics, without any internal imaging. Surf2CT proceeds through three sequential stages: (1) Surface Completion, reconstructing a complete signed distance function (SDF) from partial torso scans using conditional 3D flow matching; (2) Coarse CT Synthesis, generating a low-resolution CT volume from the completed SDF and demographic information; and (3) CT Super-Resolution, refining the coarse volume into a high-resolution CT via a patch-wise conditional flow model. Each stage utilizes a 3D-adapted EDM2 backbone trained via flow matching. We trained our model on a combined dataset of 3,198 torso CT scans (approximately 1.13 million axial slices) sourced from Massachusetts General Hospital (MGH) and the AutoPET challenge. Evaluation on 700 paired torso surface-CT cases demonstrated strong anatomical fidelity: organ volumes exhibited small mean percentage differences (range from -11.1% to 4.4%), and muscle/fat body composition metrics matched ground truth with strong correlation (range from 0.67 to 0.96). Lung localization had minimal bias (mean difference -2.5 mm), and surface completion significantly improved metrics (Chamfer distance: from 521.8 mm to 2.7 mm; Intersection-over-Union: from 0.87 to 0.98). Surf2CT establishes a new paradigm for non-invasive internal anatomical imaging using only external data, opening opportunities for home-based healthcare, preventive medicine, and personalized clinical assessments without the risks associated with conventional imaging techniques.","authors":["Siyeop Yoon","Yujin Oh","Pengfei Jin","Sifan Song","Matthew Tivnan","Dufan Wu","Xiang Li","Quanzheng Li"],"url":"https://arxiv.org/abs/2505.22511"}
{"created":"2025-05-29","title":"IGNIS: A Neural Network Framework for Robust Parameter Estimation in Archimedean Copulas","abstract":"Parameter estimation for Archimedean copulas remains a challenging problem, particularly for the recently developed A1 and A2 families that exhibit complex dependency structures. Traditional methods, such as the Method of Moments (MoM), Maximum Likelihood Estimation (MLE), and Maximum Pseudo-Likelihood (MPL), often struggle due to issues of non-monotonic relationship with dependency measures such as Kendall's tau (as in the case of A1) and numerical instability. In this paper, we present the IGNIS Network, a novel, unified neural framework that learns a direct mapping from observable dependency measures to copula parameters, thereby overcoming the limitations of classical approaches. Our approach is trained on simulated data spanning five Archimedean copula families including Clayton, Gumbel, Frank, A1, and A2, ensuring its general applicability across the entire family. Extensive simulation studies demonstrate that the IGNIS Network reduces estimation errors compared to MoM, while inherently enforcing parameter constraints through theory-guided post-processing. We further validate the practical utility of our method on diverse real-world datasets, including financial returns (AAPL-MSFT), healthcare metrics (CDC Diabetes indicators), and environmental measurements (PM2.5 air quality). Our results underscore the transformative potential of neural methods for robust and accurate dependence modeling in modern applications.","authors":["Agnideep Aich","Ashit Baran Aich","Bruce Wade"],"url":"https://arxiv.org/abs/2505.22518"}
{"created":"2025-05-29","title":"Symplectic Generative Networks (SGNs): A Hamiltonian Framework for Invertible Deep Generative Modeling","abstract":"We introduce the Symplectic Generative Network (SGN), a deep generative model that leverages Hamiltonian mechanics to construct an invertible, volume-preserving mapping between a latent space and the data space. By endowing the latent space with a symplectic structure and modeling data generation as the time evolution of a Hamiltonian system, SGN achieves exact likelihood evaluation without incurring the computational overhead of Jacobian determinant calculations. In this work, we provide a rigorous mathematical foundation for SGNs through a comprehensive theoretical framework that includes: (i) complete proofs of invertibility and volume preservation, (ii) a formal complexity analysis with theoretical comparisons to Variational Autoencoders and Normalizing Flows, (iii) strengthened universal approximation results with quantitative error bounds, (iv) an information-theoretic analysis based on the geometry of statistical manifolds, and (v) an extensive stability analysis with adaptive integration guarantees. These contributions highlight the fundamental advantages of SGNs and establish a solid foundation for future empirical investigations and applications to complex, high-dimensional data.","authors":["Agnideep Aich","Ashit Aich","Bruce Wade"],"url":"https://arxiv.org/abs/2505.22527"}
{"created":"2025-05-29","title":"Can Copulas Be Used for Feature Selection? A Machine Learning Study on Diabetes Risk Prediction","abstract":"Accurate diabetes risk prediction relies on identifying key features from complex health datasets, but conventional methods like mutual information (MI) filters and genetic algorithms (GAs) often overlook extreme dependencies critical for high-risk subpopulations. In this study we introduce a feature-selection framework using the upper-tail dependence coefficient ({\\lambda}U) of the novel A2 copula, which quantifies how often extreme higher values of a predictor co-occur with diabetes diagnoses (target variable). Applied to the CDC Diabetes Health Indicators dataset (n=253,680), our method prioritizes five predictors (self-reported general health, high blood pressure, body mass index, mobility limitations, and high cholesterol levels) based on upper tail dependencies. These features match or outperform MI and GA selected subsets across four classifiers (Random Forest, XGBoost, Logistic Regression, Gradient Boosting), achieving accuracy up to 86.5% (XGBoost) and AUC up to 0.806 (Gradient Boosting), rivaling the full 21-feature model. Permutation importance confirms clinical relevance, with BMI and general health driving accuracy. To our knowledge, this is the first work to apply a copula's upper-tail dependence for supervised feature selection, bridging extreme-value theory and machine learning to deliver a practical toolkit for diabetes prevention.","authors":["Agnideep Aich","Md Monzur Murshed","Amanda Mayeaux","Sameera Hewage"],"url":"https://arxiv.org/abs/2505.22554"}
{"created":"2025-05-29","title":"On Big Ramsey degrees of universal $\\omega$-edge-labeled hypergraphs","abstract":"We show that the big Ramsey degrees of every countable universal $u$-uniform $\\omega$-edge-labeled hypergraph are infinite for every $u\\geq 2$. Together with a recent result of Braunfeld, Chodounsk\\'y, de Rancourt, Hubi\\v{c}ka, Kawach, and Kone\\v{c}n\\'y this finishes full characterisation of unrestricted relational structures with finite big Ramsey degrees.","authors":["Jan Hubi\\v{c}ka","Mat\\v{e}j Kone\\v{c}n\\'y","Stevo Todorcevic","Andy Zucker"],"url":"https://arxiv.org/abs/2505.22561"}
{"created":"2025-05-29","title":"The Ingleton inequality holds for metacyclic groups and fails for supersoluble groups","abstract":"The Ingleton inequality first appeared in matroid theory, where Ingleton proved in 1971 that every rank function coming from a representable matroid on four subsets satisfies a particular inequality. Because this inequality is not implied by submodularity, Shannon-type axioms alone, it and various analogues play a central role in separately linear and non-linear phenomena in a variety of areas of mathematics. The Ingleton inequality for finite groups concerns the various intersections of four subgroups. It holds for many quadruples of subgroups of finite groups, but not all, the smallest example being four subgroups of $S_5$, of order 120. Open questions are whether the Inlgeton inequality always holds for metacycle and nilpotent groups. (There is a proof in the literature due to Oggier and Stancu, but there is an already known issue with their proof, which we address in this article.)","authors":["David A. Craven"],"url":"https://arxiv.org/abs/2505.22565"}
{"created":"2025-05-29","title":"Multipath cycleGAN for harmonization of paired and unpaired low-dose lung computed tomography reconstruction kernels","abstract":"Reconstruction kernels in computed tomography (CT) affect spatial resolution and noise characteristics, introducing systematic variability in quantitative imaging measurements such as emphysema quantification. Choosing an appropriate kernel is therefore essential for consistent quantitative analysis. We propose a multipath cycleGAN model for CT kernel harmonization, trained on a mixture of paired and unpaired data from a low-dose lung cancer screening cohort. The model features domain-specific encoders and decoders with a shared latent space and uses discriminators tailored for each domain.We train the model on 42 kernel combinations using 100 scans each from seven representative kernels in the National Lung Screening Trial (NLST) dataset. To evaluate performance, 240 scans from each kernel are harmonized to a reference soft kernel, and emphysema is quantified before and after harmonization. A general linear model assesses the impact of age, sex, smoking status, and kernel on emphysema. We also evaluate harmonization from soft kernels to a reference hard kernel. To assess anatomical consistency, we compare segmentations of lung vessels, muscle, and subcutaneous adipose tissue generated by TotalSegmentator between harmonized and original images. Our model is benchmarked against traditional and switchable cycleGANs. For paired kernels, our approach reduces bias in emphysema scores, as seen in Bland-Altman plots (p<0.05). For unpaired kernels, harmonization eliminates confounding differences in emphysema (p>0.05). High Dice scores confirm preservation of muscle and fat anatomy, while lung vessel overlap remains reasonable. Overall, our shared latent space multipath cycleGAN enables robust harmonization across paired and unpaired CT kernels, improving emphysema quantification and preserving anatomical fidelity.","authors":["Aravind R. Krishnan","Thomas Z. Li","Lucas W. Remedios","Michael E. Kim","Chenyu Gao","Gaurav Rudravaram","Elyssa M. McMaster","Adam M. Saunders","Shunxing Bao","Kaiwen Xu","Lianrui Zuo","Kim L. Sandler","Fabien Maldonado","Yuankai Huo","Bennett A. Landman"],"url":"https://arxiv.org/abs/2505.22568"}
{"created":"2025-05-29","title":"Comparative Analysis of Machine Learning Models for Lung Cancer Mutation Detection and Staging Using 3D CT Scans","abstract":"Lung cancer is the leading cause of cancer mortality worldwide, and non-invasive methods for detecting key mutations and staging are essential for improving patient outcomes. Here, we compare the performance of two machine learning models - FMCIB+XGBoost, a supervised model with domain-specific pretraining, and Dinov2+ABMIL, a self-supervised model with attention-based multiple-instance learning - on 3D lung nodule data from the Stanford Radiogenomics and Lung-CT-PT-Dx cohorts. In the task of KRAS and EGFR mutation detection, FMCIB+XGBoost consistently outperformed Dinov2+ABMIL, achieving accuracies of 0.846 and 0.883 for KRAS and EGFR mutations, respectively. In cancer staging, Dinov2+ABMIL demonstrated competitive generalization, achieving an accuracy of 0.797 for T-stage prediction in the Lung-CT-PT-Dx cohort, suggesting SSL's adaptability across diverse datasets. Our results emphasize the clinical utility of supervised models in mutation detection and highlight the potential of SSL to improve staging generalization, while identifying areas for enhancement in mutation sensitivity.","authors":["Yiheng Li","Francisco Carrillo-Perez","Mohammed Alawad","Olivier Gevaert"],"url":"https://arxiv.org/abs/2505.22592"}
{"created":"2025-05-29","title":"On the performance of machine-learning assisted Monte Carlo in sampling from simple statistical physics models","abstract":"Recent years have seen a rise in the application of machine learning techniques to aid the simulation of hard-to-sample systems that cannot be studied using traditional methods. Despite the introduction of many different architectures and procedures, a wide theoretical understanding is still lacking, with the risk of suboptimal implementations. As a first step to address this gap, we provide here a complete analytic study of the widely-used Sequential Tempering procedure applied to a shallow MADE architecture for the Curie-Weiss model. The contribution of this work is twofold: firstly, we give a description of the optimal weights and of the training under Gradient Descent optimization. Secondly, we compare what happens in Sequential Tempering with and without the addition of local Metropolis Monte Carlo steps. We are thus able to give theoretical predictions on the best procedure to apply in this case. This work establishes a clear theoretical basis for the integration of machine learning techniques into Monte Carlo sampling and optimization.","authors":["Luca Maria Del Bono","Federico Ricci-Tersenghi","Francesco Zamponi"],"url":"https://arxiv.org/abs/2505.22598"}
{"created":"2025-05-29","title":"Oscillating subalgebras of the atomless countable Boolean algebra","abstract":"We show that the big Ramsey degree of the Boolean algebra with 3 atoms within the countable atomless Boolean algebra is infinite.","authors":["Dana Barto\\v{s}ov\\'a","David Chodounsk\\'y","Barbara Csima","Jan Hubi\\v{c}ka","Mat\\v{e}j Kone\\v{c}n\\'y","Joey Lakerdas-Gayle","Spencer Unger","Andy Zucker"],"url":"https://arxiv.org/abs/2505.22603"}
{"created":"2025-05-29","title":"Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method","abstract":"In this work, we investigate the performance across multiple classification models to classify chest X-ray images into four categories of COVID-19, pneumonia, tuberculosis (TB), and normal cases. We leveraged transfer learning techniques with state-of-the-art pre-trained Convolutional Neural Networks (CNNs) models. We fine-tuned these pre-trained architectures on a labeled medical x-ray images. The initial results are promising with high accuracy and strong performance in key classification metrics such as precision, recall, and F1 score. We applied Gradient-weighted Class Activation Mapping (Grad-CAM) for model interpretability to provide visual explanations for classification decisions, improving trust and transparency in clinical applications.","authors":["Alanna Hazlett","Naomi Ohashi","Timothy Rodriguez","Sodiq Adewole"],"url":"https://arxiv.org/abs/2505.22609"}
{"created":"2025-05-29","title":"Counting big Ramsey degrees of the homogeneous and universal $K_4$-free graph","abstract":"Big Ramsey degrees of Fra\\\"iss\\'e limits of finitely constrained free amalgamation classes in finite binary languages have been recently fully characterised by Balko, Chodounsk\\'y, Dobrinen, Hubi\\v{c}ka, Kone\\v{c}n\\'y, Vena, and Zucker. A special case of this characterisation is the universal homogeneous $K_4$-free graph. We give a self-contained and relatively compact presentation of this case and compute the actual big Ramsey degrees of small graphs.","authors":["Jan Hubi\\v{c}ka","Mat\\v{e}j Kone\\v{c}n\\'y","\\v{S}t\\v{e}p\\'an Vodse\\v{d}\\'alek","Andy Zucker"],"url":"https://arxiv.org/abs/2505.22620"}
{"created":"2025-05-29","title":"Principled Out-of-Distribution Generalization via Simplicity","abstract":"Modern foundation models exhibit remarkable out-of-distribution (OOD) generalization, solving tasks far beyond the support of their training data. However, the theoretical principles underpinning this phenomenon remain elusive. This paper investigates this problem by examining the compositional generalization abilities of diffusion models in image generation. Our analysis reveals that while neural network architectures are expressive enough to represent a wide range of models -- including many with undesirable behavior on OOD inputs -- the true, generalizable model that aligns with human expectations typically corresponds to the simplest among those consistent with the training data.","authors":["Jiawei Ge","Amanda Wang","Shange Tang","Chi Jin"],"url":"https://arxiv.org/abs/2505.22622"}
{"created":"2025-05-29","title":"PyRigi -- a general-purpose Python package for the rigidity and flexibility of bar-and-joint frameworks","abstract":"We present PyRigi, a novel Python package designed to study the rigidity properties of graphs and frameworks. Among many other capabilities, PyRigi can determine whether a graph admits only finitely many ways, up to isometries, of being drawn in the plane once the edge lengths are fixed, whether it has a unique embedding, or whether it satisfied such properties even after the removal of any of its edges. By implementing algorithms from the scientific literature, PyRigi enables the exploration of rigidity properties of structures that would be out of reach for computations by hand. With reliable and robust algorithms, as well as clear, well-documented methods that are closely connected to the underlying mathematical definitions and results, PyRigi aims to be a practical and powerful general-purpose tool for the working mathematician interested in rigidity theory. PyRigi is open source and easy to use, and awaits researchers to benefit from its computational potential.","authors":["Matteo Gallet","Georg Grasegger","Matthias Himmelmann","Jan Legersk\\'y"],"url":"https://arxiv.org/abs/2505.22652"}
{"created":"2025-05-29","title":"On Heuristic Models, Assumptions, and Parameters","abstract":"Insightful interdisciplinary collaboration is essential to the principled governance of technology. When such efforts address the interaction between computation and society, they often focus on modeling, the process by which computer scientists formally define problems in order to enable algorithmic solutions. But modeling is a multifaceted and inherently imperfect process. Especially in interdisciplinary work, it often receives uneven scrutiny because of the practical challenges of communicating complex technical details to non-experts. We argue that there is an underappreciated if loose family of obscure and opaque technical caveats, choices, and qualifiers that the social effects of computing can depend just as much on as far more heavily scrutinized modeling choices. These artifacts are often used by researchers to paper over the incomplete theoretical foundations of computing or to burden shift responsibility for the impact of normative design decisions. Further, their nuanced technical nature often complicates thorough sociotechnical scrutiny of the discretionary decisions made to manage them. We describe three specific classes of such objects: heuristic models, assumptions, and parameters. We raise six reasons these objects may be hazardous to comprehensive analysis of computing and argue they deserve deliberate consideration as researchers explain scientific work.","authors":["Samuel Judson","Joan Feigenbaum"],"url":"https://arxiv.org/abs/2201.07413"}
{"created":"2025-05-29","title":"Flexible Sampling for Long-tailed Skin Lesion Classification","abstract":"Most of the medical tasks naturally exhibit a long-tailed distribution due to the complex patient-level conditions and the existence of rare diseases. Existing long-tailed learning methods usually treat each class equally to re-balance the long-tailed distribution. However, considering that some challenging classes may present diverse intra-class distributions, re-balancing all classes equally may lead to a significant performance drop. To address this, in this paper, we propose a curriculum learning-based framework called Flexible Sampling for the long-tailed skin lesion classification task. Specifically, we initially sample a subset of training data as anchor points based on the individual class prototypes. Then, these anchor points are used to pre-train an inference model to evaluate the per-class learning difficulty. Finally, we use a curriculum sampling module to dynamically query new samples from the rest training samples with the learning difficulty-aware sampling probability. We evaluated our model against several state-of-the-art methods on the ISIC dataset. The results with two long-tailed settings have demonstrated the superiority of our proposed training strategy, which achieves a new benchmark for long-tailed skin lesion classification.","authors":["Lie Ju","Yicheng Wu","Lin Wang","Zhen Yu","Xin Zhao","Xin Wang","Paul Bonnington","Zongyuan Ge"],"url":"https://arxiv.org/abs/2204.03161"}
{"created":"2025-05-29","title":"On the Distortion of Multi-winner Election Using Single-Candidate Ballots","abstract":"In this paper, we study the distortion bounds for voting mechanisms in multi-winner elections in general metric spaces. Our study pertains to the case in which each voter only reports her favorite candidate amongst $m$ possible choices. Given that candidates' locations are undisclosed to the mechanism, the mechanism has to form a $w-$winner committee based solely on the number of votes received by candidates. We establish distortion bounds for both truthful and non-truthful mechanisms. Our research highlights the significance of the $\\sigma$ parameter, which represents the ratio between maximum and minimum distances among all candidate pairs. We show that the distortion is linear in $\\sigma$. First, we demonstrate that all mechanisms possess a distortion greater than $1+\\frac{w-1}{w+1}(\\sigma-1)$. To give an upper bound, we study the Single Non-Transferable Vote (SNTV) mechanism, whose distortion is at most $1+2\\sigma$. Second, we retrieve the upper bounds for strategyproof mechanisms. In particular, we infer an upper bound by examining the Random Sequential Dictator mechanism that achieves a distortion less than $1+4\\sigma$ when $w=2$.","authors":["Gennaro Auricchio","Zeyu Ren","Zihe Wang","Jie Zhang"],"url":"https://arxiv.org/abs/2205.09386"}
{"created":"2025-05-29","title":"Learning in Stackelberg Games with Non-myopic Agents","abstract":"We study Stackelberg games where a principal repeatedly interacts with a non-myopic long-lived agent, without knowing the agent's payoff function. Although learning in Stackelberg games is well-understood when the agent is myopic, dealing with non-myopic agents poses additional complications. In particular, non-myopic agents may strategize and select actions that are inferior in the present in order to mislead the principal's learning algorithm and obtain better outcomes in the future.","authors":["Nika Haghtalab","Thodoris Lykouris","Sloan Nietert","Alexander Wei"],"url":"https://arxiv.org/abs/2208.09407"}
{"created":"2025-05-29","title":"Geometric complexity theory for product-plus-power","abstract":"According to Kumar's recent surprising result (ToCT'20), a small border Waring rank implies that the polynomial can be approximated as a sum of a constant and a small product of linear polynomials. We prove the converse of Kumar's result and establish a tight connection between border Waring rank and the model of computation in Kumar's result. In this way, we obtain a new formulation of border Waring rank, up to a factor of the degree. We connect this new formulation to the orbit closure problem of the product-plus-power polynomial. We study this orbit closure from two directions: 1. We deborder this orbit closure and some related orbit closures, i.e., prove all points in the orbit closure have small non-border algebraic branching programs. 2. We fully implement the geometric complexity theory approach against the power sum by generalizing the ideas of Ikenmeyer-Kandasamy (STOC'20) to this new orbit closure. In this way, we obtain new multiplicity obstructions that are constructed from just the symmetries of the polynomials.","authors":["Pranjal Dutta","Fulvio Gesmundo","Christian Ikenmeyer","Gorav Jindal","Vladimir Lysikov"],"url":"https://arxiv.org/abs/2211.07055"}
{"created":"2025-05-29","title":"Inferring Traffic Models in Terminal Airspace from Flight Tracks and Procedures","abstract":"Realistic aircraft trajectory models are useful in the design and validation of air traffic management (ATM) systems. Models of aircraft operated under instrument flight rules (IFR) require capturing the variability inherent in how aircraft follow standard flight procedures. The variability in aircraft behavior differs among flight stages. In this paper, we propose a simple probabilistic model that can learn this variability from procedural data and flight tracks collected from radar surveillance data. For each segment, we use a Gaussian mixture model to learn the deviations of aircraft trajectories from their procedures. Given new procedures, we generate synthetic trajectories by sampling a series of deviations from the Gaussian mixture model and reconstructing the aircraft trajectory using the deviations and the procedures. We extend this method to capture pairwise correlations between aircraft and show how a pairwise model can be used to generate traffic involving an arbitrary number of aircraft. We demonstrate the proposed models on the arrival tracks and procedures of the John F. Kennedy International Airport. Distributional similarity between the original and the synthetic trajectory dataset was evaluated using the Jensen-Shannon divergence between the empirical distributions of different variables and we provide qualitative analyses of the synthetic trajectories generated.","authors":["Soyeon Jung","Amelia Hardy","Mykel J. Kochenderfer"],"url":"https://arxiv.org/abs/2303.09981"}
{"created":"2025-05-29","title":"Superiority Of Symplectic Methods For Stochastic Hamiltonian System Via Asymptotic Error Distribution","abstract":"The superiority of symplectic methods for stochastic Hamiltonian systems has been widely recognized, yet the probabilistic mechanism behind this superiority remains incompletely understood. This paper studies the superiority of symplectic methods from the perspective of the asymptotic error distribution, i.e., the limit distribution of normalized error. Focusing on stochastic Hamiltonian systems driven by additive noise, we obtain the asymptotic limit of the normalized error distribution of the $\\theta$ method $(\\theta\\in[0,1])$ that is symplectic if and only if $\\theta=\\frac12$. By establishing upper bounds for the second-order moment of the asymptotic error distribution, we show that the midpoint method minimizes the error constant of the $\\theta$ method for a large time horizon $T$. Furthermore, we take the linear stochastic oscillator as a test equation and investigate exact asymptotic error constants of several symplectic and non-symplectic methods. Our result suggests that in the long-time computation, the probability that the error deviates from zero decays exponentially faster for the symplectic methods than that for the non-symplectic ones.","authors":["Jialin Hong","Ge Liang","Derui Sheng"],"url":"https://arxiv.org/abs/2304.01602"}
{"created":"2025-05-29","title":"Moving Obstacle Collision Avoidance via Chance-Constrained MPC with CBF","abstract":"Model predictive control (MPC) with control barrier functions (CBF) is a promising solution to address the moving obstacle collision avoidance (MOCA) problem. Unlike MPC with distance constraints (MPC-DC), this approach facilitates early obstacle avoidance without the need to increase prediction horizons. However, the existing MPC-CBF method is deterministic and fails to account for perception uncertainties. This paper proposes a generalized MPC-CBF approach for stochastic scenarios, which maintains the advantages of the deterministic method for addressing the MOCA problem. Specifically, the chance-constrained MPC-CBF (CC-MPC-CBF) technique is introduced to ensure that a user-defined collision avoidance probability is met by utilizing probabilistic CBFs. However, due to the potential empty intersection between the reachable set and the safe region confined by CBF constraints, the CC-MPC-CBF problem can pose challenges in achieving feasibility. To address this issue, we propose a sequential implementation approach that involves solving a standard MPC optimization problem followed by a predictive safety filter optimization, which leads to improved feasibility. Furthermore, we introduce an iterative convex optimization scheme to further expedite the resolution of the predictive safety filter, which results in an efficient approach to tackling the non-convex CC-MPC-CBF problem. We apply our proposed algorithm to a double integrator system for MOCA, and we showcase its resilience to obstacle measurement uncertainties and favorable feasibility properties.","authors":["Ming Li","Zhiyong Sun","Zirui Liao","Siep Weiland"],"url":"https://arxiv.org/abs/2304.01639"}
{"created":"2025-05-29","title":"An Empirical Evaluation of Rewiring Approaches in Graph Neural Networks","abstract":"Graph neural networks compute node representations by performing multiple message-passing steps that consist in local aggregations of node features. Having deep models that can leverage longer-range interactions between nodes is hindered by the issues of over-smoothing and over-squashing. In particular, the latter is attributed to the graph topology which guides the message-passing, causing a node representation to become insensitive to information contained at distant nodes. Many graph rewiring methods have been proposed to remedy or mitigate this problem. However, properly evaluating the benefits of these methods is made difficult by the coupling of over-squashing with other issues strictly related to model training, such as vanishing gradients. Therefore, we propose an evaluation setting based on message-passing models that do not require training to compute node and graph representations. We perform a systematic experimental comparison on real-world node and graph classification tasks, showing that rewiring the underlying graph rarely does confer a practical benefit for message-passing.","authors":["Alessio Micheli","Domenico Tortorella"],"url":"https://arxiv.org/abs/2305.19717"}
{"created":"2025-05-29","title":"Variational Positive-incentive Noise: How Noise Benefits Models","abstract":"A large number of works aim to alleviate the impact of noise due to an underlying conventional assumption of the negative role of noise. However, some existing works show that the assumption does not always hold. In this paper, we investigate how to benefit the classical models by random noise under the framework of Positive-incentive Noise (Pi-Noise). Since the ideal objective of Pi-Noise is intractable, we propose to optimize its variational bound instead, namely variational Pi-Noise (VPN). With the variational inference, a VPN generator implemented by neural networks is designed for enhancing base models and simplifying the inference of base models, without changing the architecture of base models. Benefiting from the independent design of base models and VPN generators, the VPN generator can work with most existing models. From the experiments, it is shown that the proposed VPN generator can improve the base models. It is appealing that the trained variational VPN generator prefers to blur the irrelevant ingredients in complicated images, which meets our expectations.","authors":["Hongyuan Zhang","Sida Huang","Yubin Guo","Xuelong Li"],"url":"https://arxiv.org/abs/2306.07651"}
{"created":"2025-05-29","title":"The APX-hardness of the Traveling Tournament Problem","abstract":"The Traveling Tournament Problem (TTP-$k$) is a well-known benchmark problem in sports scheduling, which asks us to design a double round-robin schedule such that each pair of teams plays one game in each other's home venue, no pair of teams plays each other on two consecutive days, each team plays at most $k$ consecutive home games or away games, and the total traveling distance of all the $n$ teams is minimized. TTP-$k$ allows a polynomial-time approximation scheme when $k=2$ and becomes APX-hard when $k\\geq n-1$. In this paper, we reduce the gap by showing that TTP-$k$ is APX-hard for any fixed $k\\geq3$.","authors":["Jingyang Zhao","Mingyu Xiao"],"url":"https://arxiv.org/abs/2308.14124"}
{"created":"2025-05-29","title":"NanoSLAM: Enabling Fully Onboard SLAM for Tiny Robots","abstract":"Perceiving and mapping the surroundings are essential for enabling autonomous navigation in any robotic platform. The algorithm class that enables accurate mapping while correcting the odometry errors present in most robotics systems is Simultaneous Localization and Mapping (SLAM). Today, fully onboard mapping is only achievable on robotic platforms that can host high-wattage processors, mainly due to the significant computational load and memory demands required for executing SLAM algorithms. For this reason, pocket-size hardware-constrained robots offload the execution of SLAM to external infrastructures. To address the challenge of enabling SLAM algorithms on resource-constrained processors, this paper proposes NanoSLAM, a lightweight and optimized end-to-end SLAM approach specifically designed to operate on centimeter-size robots at a power budget of only 87.9 mW. We demonstrate the mapping capabilities in real-world scenarios and deploy NanoSLAM on a nano-drone weighing 44 g and equipped with a novel commercial RISC-V low-power parallel processor called GAP9. The algorithm is designed to leverage the parallel capabilities of the RISC-V processing cores and enables mapping of a general environment with an accuracy of 4.5 cm and an end-to-end execution time of less than 250 ms.","authors":["Vlad Niculescu","Tommaso Polonelli","Michele Magno","Luca Benini"],"url":"https://arxiv.org/abs/2309.12008"}
{"created":"2025-05-29","title":"Novelty Detection in Reinforcement Learning with World Models","abstract":"Reinforcement learning (RL) using world models has found significant recent successes. However, when a sudden change to world mechanics or properties occurs then agent performance and reliability can dramatically decline. We refer to the sudden change in visual properties or state transitions as novelties. Implementing novelty detection within generated world model frameworks is a crucial task for protecting the agent when deployed. In this paper, we propose straightforward bounding approaches to incorporate novelty detection into world model RL agents, by utilizing the misalignment of the world model's hallucinated states and the true observed states as an anomaly score. We provide effective approaches to detecting novelties in a distribution of transitions learned by an agent in a world model. Finally, we show the advantage of our work in a novel environment compared to traditional machine learning novelty detection methods as well as currently accepted RL focused novelty detection algorithms.","authors":["Geigh Zollicoffer","Kenneth Eaton","Jonathan Balloch","Julia Kim","Wei Zhou","Robert Wright","Mark O. Riedl"],"url":"https://arxiv.org/abs/2310.08731"}
{"created":"2025-05-29","title":"Watermarks in the Sand: Impossibility of Strong Watermarking for Generative Models","abstract":"Watermarking generative models consists of planting a statistical signal (watermark) in a model's output so that it can be later verified that the output was generated by the given model. A strong watermarking scheme satisfies the property that a computationally bounded attacker cannot erase the watermark without causing significant quality degradation. In this paper, we study the (im)possibility of strong watermarking schemes. We prove that, under well-specified and natural assumptions, strong watermarking is impossible to achieve. This holds even in the private detection algorithm setting, where the watermark insertion and detection algorithms share a secret key, unknown to the attacker. To prove this result, we introduce a generic efficient watermark attack; the attacker is not required to know the private key of the scheme or even which scheme is used. Our attack is based on two assumptions: (1) The attacker has access to a \"quality oracle\" that can evaluate whether a candidate output is a high-quality response to a prompt, and (2) The attacker has access to a \"perturbation oracle\" which can modify an output with a nontrivial probability of maintaining quality, and which induces an efficiently mixing random walk on high-quality outputs. We argue that both assumptions can be satisfied in practice by an attacker with weaker computational capabilities than the watermarked model itself, to which the attacker has only black-box access. Furthermore, our assumptions will likely only be easier to satisfy over time as models grow in capabilities and modalities. We demonstrate the feasibility of our attack by instantiating it to attack three existing watermarking schemes for large language models: Kirchenbauer et al. (2023), Kuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully removes the watermarks planted by all three schemes, with only minor quality degradation.","authors":["Hanlin Zhang","Benjamin L. Edelman","Danilo Francati","Daniele Venturi","Giuseppe Ateniese","Boaz Barak"],"url":"https://arxiv.org/abs/2311.04378"}
{"created":"2025-05-29","title":"End-to-End Breast Cancer Radiotherapy Planning via LMMs with Consistency Embedding","abstract":"Recent advances in AI foundation models have significant potential for lightening the clinical workload by mimicking the comprehensive and multi-faceted approaches used by medical professionals. In the field of radiation oncology, the integration of multiple modalities holds great importance, so the opportunity of foundational model is abundant. Inspired by this, here we present RO-LMM, a multi-purpose, comprehensive large multimodal model (LMM) tailored for the field of radiation oncology. This model effectively manages a series of tasks within the clinical workflow, including clinical context summarization, radiation treatment plan suggestion, and plan-guided target volume segmentation by leveraging the capabilities of LMM. In particular, to perform consecutive clinical tasks without error accumulation, we present a novel Consistency Embedding Fine-Tuning (CEFTune) technique, which boosts LMM's robustness to noisy inputs while preserving the consistency of handling clean inputs. We further extend this concept to LMM-driven segmentation framework, leading to a novel Consistency Embedding Segmentation (CESEG) techniques. Experimental results including multi-centre validation confirm that our RO-LMM with CEFTune and CESEG results in promising performance for multiple clinical tasks with generalization capabilities.","authors":["Kwanyoung Kim","Yujin Oh","Sangjoon Park","Hwa Kyung Byun","Joongyo Lee","Jin Sung Kim","Yong Bae Kim","Jong Chul Ye"],"url":"https://arxiv.org/abs/2311.15876"}
{"created":"2025-05-29","title":"Meta Co-Training: Two Views are Better than One","abstract":"In many critical computer vision scenarios unlabeled data is plentiful, but labels are scarce and difficult to obtain. As a result, semi-supervised learning which leverages unlabeled data to boost the performance of supervised classifiers have received significant attention in recent literature. One representative class of semi-supervised algorithms are co-training algorithms. Co-training algorithms leverage two different models which have access to different independent and sufficient representations or \"views\" of the data to jointly make better predictions. Each of these models creates pseudo-labels on unlabeled points which are used to improve the other model. We show that in the common case where independent views are not available, we can construct such views inexpensively using pre-trained models. Co-training on the constructed views yields a performance improvement over any of the individual views we construct and performance comparable with recent approaches in semi-supervised learning. We present Meta Co-Training, a novel semi-supervised learning algorithm, which has two advantages over co-training: (i) learning is more robust when there is large discrepancy between the information content of the different views, and (ii) does not require retraining from scratch on each iteration. Our method achieves new state-of-the-art performance on ImageNet-10% achieving a ~4.7% reduction in error rate over prior work. Our method also outperforms prior semi-supervised work on several other fine-grained image classification datasets.","authors":["Jay C. Rothenberger","Dimitrios I. Diochnos"],"url":"https://arxiv.org/abs/2311.18083"}
{"created":"2025-05-29","title":"Machine Translation Models are Zero-Shot Detectors of Translation Direction","abstract":"Detecting the translation direction of parallel text has applications for machine translation training and evaluation, but also has forensic applications such as resolving plagiarism or forgery allegations. In this work, we explore an unsupervised approach to translation direction detection based on the simple hypothesis that $p(\\text{translation}|\\text{original})>p(\\text{original}|\\text{translation})$, motivated by the well-known simplification effect in translationese or machine-translationese. In experiments with massively multilingual machine translation models across 20 translation directions, we confirm the effectiveness of the approach for high-resource language pairs, achieving document-level accuracies of 82--96% for NMT-produced translations, and 60--81% for human translations, depending on the model used. Code and demo are available at https://github.com/ZurichNLP/translation-direction-detection","authors":["Michelle Wastl","Jannis Vamvas","Rico Sennrich"],"url":"https://arxiv.org/abs/2401.06769"}
{"created":"2025-05-29","title":"Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models","abstract":"Dyadic regression models, which output real-valued predictions for pairs of entities, are fundamental in many domains (e.g. obtaining user-product ratings in Recommender Systems) and promising and under exploration in others (e.g. tuning patient-drug dosages in precision pharmacology). In this work, we prove that non-uniform observed value distributions of individual entities lead to severe biases in state-of-the-art models, skewing predictions towards the average of observed past values for the entity and providing worse-than-random predictive power in eccentric yet crucial cases; we name this phenomenon eccentricity bias. We show that global error metrics like Root Mean Squared Error (RMSE) are insufficient to capture this bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as a novel metric that can quantify it in all studied domains and models. We prove the intuitive interpretation of EAUC by experimenting with naive post-training bias corrections, and theorize other options to use EAUC to guide the construction of fair models. This work contributes a bias-aware evaluation of dyadic regression to prevent unfairness in critical real-world applications of such systems.","authors":["Jorge Paz-Ruza","Amparo Alonso-Betanzos","Bertha Guijarro-Berdi\\~nas","Brais Cancela","Carlos Eiras-Franco"],"url":"https://arxiv.org/abs/2401.10690"}
{"created":"2025-05-29","title":"Geometric Contact Potential","abstract":"Barrier potentials gained popularity as a means for robust contact handling in physical modeling and for modeling self-avoiding shapes. The key to the success of these approaches is adherence to geometric constraints, i.e., avoiding intersections, which are the cause of most robustness problems in complex deformation simulation with contact. However, existing barrier-potential methods may lead to spurious forces and imperfect satisfaction of the geometric constraints. They may have strong resolution dependence, requiring careful adaptation of the potential parameters to the object discretizations. We present a systematic derivation of a continuum potential defined for smooth and piecewise smooth surfaces, starting from identifying a set of natural requirements for contact potentials, including the barrier property, locality, differentiable dependence on shape, and absence of forces in rest configurations. Our potential is formulated independently of surface discretization and addresses the shortcomings of existing potential-based methods while retaining their advantages. We present a discretization of our potential that is a drop-in replacement for the potential used in the Incremental Potential Contact (IPC) formulation, and compare its behavior to other potential formulations, demonstrating that it has the expected behavior. The presented formulation connects existing barrier approaches, as all recent existing methods can be viewed as a variation of the presented potential, and lays a foundation for developing alternative (e.g., higher-order) versions.","authors":["Zizhou Huang","Max Paik","Zachary Ferguson","Daniele Panozzo","Denis Zorin"],"url":"https://arxiv.org/abs/2402.00719"}
{"created":"2025-05-29","title":"Intrinsic User-Centric Interpretability through Global Mixture of Experts","abstract":"In human-centric settings like education or healthcare, model accuracy and model explainability are key factors for user adoption. Towards these two goals, intrinsically interpretable deep learning models have gained popularity, focusing on accurate predictions alongside faithful explanations. However, there exists a gap in the human-centeredness of these approaches, which often produce nuanced and complex explanations that are not easily actionable for downstream users. We present InterpretCC (interpretable conditional computation), a family of intrinsically interpretable neural networks at a unique point in the design space that optimizes for ease of human understanding and explanation faithfulness, while maintaining comparable performance to state-of-the-art models. InterpretCC achieves this through adaptive sparse activation of features before prediction, allowing the model to use a different, minimal set of features for each instance. We extend this idea into an interpretable, global mixture-of-experts (MoE) model that allows users to specify topics of interest, discretely separates the feature space for each data point into topical subnetworks, and adaptively and sparsely activates these topical subnetworks for prediction. We apply InterpretCC for text, time series and tabular data across several real-world datasets, demonstrating comparable performance with non-interpretable baselines and outperforming intrinsically interpretable baselines. Through a user study involving 56 teachers, InterpretCC explanations are found to have higher actionability and usefulness over other intrinsically interpretable approaches.","authors":["Vinitra Swamy","Syrielle Montariol","Julian Blackwell","Jibril Frej","Martin Jaggi","Tanja K\\\"aser"],"url":"https://arxiv.org/abs/2402.02933"}
{"created":"2025-05-29","title":"Tracking Semantic Change in Slovene: A Novel Dataset and Optimal Transport-Based Distance","abstract":"In this paper, we focus on the detection of semantic changes in Slovene, a less resourced Slavic language with two million speakers. Detecting and tracking semantic changes provides insight into the evolution of language caused by changes in society and culture. We present the first Slovene dataset for evaluating semantic change detection systems, which contains aggregated semantic change scores for 104 target words obtained from more than 3,000 manually annotated sentence pairs. We analyze an important class of measures of semantic change metrics based on the Average pairwise distance and identify several limitations. To address these limitations, we propose a novel metric based on regularized optimal transport, which offers a more robust framework for quantifying semantic change. We provide a comprehensive evaluation of various existing semantic change detection methods and associated semantic change measures on our dataset. Through empirical testing, we demonstrate that our proposed approach, leveraging regularized optimal transport, achieves either matching or improved performance compared to baseline approaches.","authors":["Marko Pranji\\'c","Kaja Dobrovoljc","Senja Pollak","Matej Martinc"],"url":"https://arxiv.org/abs/2402.16596"}
{"created":"2025-05-29","title":"Decoupled Subgraph Federated Learning","abstract":"We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where interconnections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.","authors":["Javad Aliakbari","Johan \\\"Ostman","Alexandre Graell i Amat"],"url":"https://arxiv.org/abs/2402.19163"}
{"created":"2025-05-29","title":"LC-Tsallis-INF: Generalized Best-of-Both-Worlds Linear Contextual Bandits","abstract":"We investigate the \\emph{linear contextual bandit problem} with independent and identically distributed (i.i.d.) contexts. In this problem, we aim to develop a \\emph{Best-of-Both-Worlds} (BoBW) algorithm with regret upper bounds in both stochastic and adversarial regimes. We develop an algorithm based on \\emph{Follow-The-Regularized-Leader} (FTRL) with Tsallis entropy, referred to as the $\\alpha$-\\emph{Linear-Contextual (LC)-Tsallis-INF}. We show that its regret is at most $O(\\log(T))$ in the stochastic regime under the assumption that the suboptimality gap is uniformly bounded from below, and at most $O(\\sqrt{T})$ in the adversarial regime. Furthermore, our regret analysis is extended to more general regimes characterized by the \\emph{margin condition} with a parameter $\\beta \\in (1, \\infty]$, which imposes a milder assumption on the suboptimality gap. We show that the proposed algorithm achieves $O\\left(\\log(T)^{\\frac{1+\\beta}{2+\\beta}}T^{\\frac{1}{2+\\beta}}\\right)$ regret under the margin condition.","authors":["Masahiro Kato","Shinji Ito"],"url":"https://arxiv.org/abs/2403.03219"}
{"created":"2025-05-29","title":"Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks","abstract":"In this work, we focus on unsupervised vision-language-action mapping in the area of robotic manipulation. Recently, multiple approaches employing pre-trained large language and vision models have been proposed for this task. However, they are computationally demanding and require careful fine-tuning of the produced outputs. A more lightweight alternative would be the implementation of multimodal Variational Autoencoders (VAEs) which can extract the latent features of the data and integrate them into a joint representation, as has been demonstrated mostly on image-image or image-text data for the state-of-the-art models. Here we explore whether and how can multimodal VAEs be employed in unsupervised robotic manipulation tasks in a simulated environment. Based on the obtained results, we propose a model-invariant training alternative that improves the models' performance in a simulator by up to 55%. Moreover, we systematically evaluate the challenges raised by the individual tasks such as object or robot position variability, number of distractors or the task length. Our work thus also sheds light on the potential benefits and limitations of using the current multimodal VAEs for unsupervised learning of robotic motion trajectories based on vision and language.","authors":["Gabriela Sejnova","Michal Vavrecka","Karla Stepanova"],"url":"https://arxiv.org/abs/2404.01932"}
{"created":"2025-05-29","title":"Extending direct data-driven predictive control towards systems with finite control sets","abstract":"Although classical model predictive control with finite control sets (FCS-MPC) is quite a popular control method, particularly in the realm of power electronics systems, its direct data-driven predictive control (FCS-DPC) counterpart has received relatively limited attention. In this paper, we introduce a novel reformulation of a commonly used DPC scheme that allows for the application of a modified sphere decoding algorithm, known for its efficiency and prominence in FCS-MPC applications. We test the reformulation on a popular electrical drive example and compare the computation times of sphere decoding FCS-DPC with an enumeration-based and a MIQP method.","authors":["Manuel Kl\\\"adtke","Moritz Schulze Darup","Daniel E. Quevedo"],"url":"https://arxiv.org/abs/2404.02727"}
{"created":"2025-05-29","title":"Optimizing Parameters of the LinDistFlow Power Flow Approximation for Distribution Systems","abstract":"The DistFlow model accurately represents power flows in distribution systems, but the model's nonlinearities result in computational challenges for many applications. Accordingly, a linear approximation known as \\mbox{LinDistFlow} (and its three-phase extension LinDist3Flow) is commonly employed. This paper introduces a parameter optimization algorithm for enhancing the accuracy of this approximation for both balanced single-phase equivalent and unbalanced three-phase distribution network models, with the goal of aligning the outputs more closely with those from the nonlinear DistFlow model. Using sensitivity information, our algorithm optimizes the LinDistFlow approximation's coefficient and bias parameters to minimize discrepancies in predictions of voltage magnitudes relative to the nonlinear DistFlow model. The parameter optimization algorithm employs the Truncated Newton Conjugate-Gradient (TNC) method to fine-tune coefficients and bias parameters during an offline training phase to improve the LinDistFlow approximation's accuracy. % in optimization applications. Numerical results underscore the algorithm's efficacy, showcasing accuracy improvements in $L_{1}$-norm and $L_{\\infty}$-norm losses of up to $92\\%$ and $88\\%$, respectively, relative to the traditional LinDistFlow model. We also assess how the optimized parameters perform under changes in the network topology and demonstrate the optimized LinDistFlow approximation's efficacy in a hosting capacity optimization problem.","authors":["Babak Taheri","Rahul K. Gupta","Daniel K. Molzahn"],"url":"https://arxiv.org/abs/2404.05125"}
{"created":"2025-05-29","title":"Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems","abstract":"Intelligent Tutoring Systems (ITSs) can provide personalized and self-paced learning experience. The emergence of large language models (LLMs) further enables better human-machine interaction, and facilitates the development of conversational ITSs in various disciplines such as math and language learning. In dialogic teaching, recognizing and adapting to individual characteristics can significantly enhance student engagement and learning efficiency. However, characterizing and simulating student's persona remain challenging in training and evaluating conversational ITSs. In this work, we propose a framework to construct profiles of different student groups by refining and integrating both cognitive and noncognitive aspects, and leverage LLMs for personality-aware student simulation in a language learning scenario. We further enhance the framework with multi-aspect validation, and conduct extensive analysis from both teacher and student perspectives. Our experimental results show that state-of-the-art LLMs can produce diverse student responses according to the given language ability and personality traits, and trigger teacher's adaptive scaffolding strategies.","authors":["Zhengyuan Liu","Stella Xin Yin","Geyu Lin","Nancy F. Chen"],"url":"https://arxiv.org/abs/2404.06762"}
{"created":"2025-05-29","title":"Polynomial Chaos Expanded Gaussian Process","abstract":"In complex and unknown processes, global models are initially generated over the entire experimental space but often fail to provide accurate predictions in local areas. A common approach is to use local models, which requires partitioning the experimental space and training multiple models, adding significant complexity. Recognizing this limitation, this study addresses the need for models that effectively represent both global and local experimental spaces. It introduces a novel machine learning (ML) approach: Polynomial Chaos Expanded Gaussian Process (PCEGP), leveraging polynomial chaos expansion (PCE) to calculate input-dependent hyperparameters of the Gaussian process (GP). This provides a mathematically interpretable approach that incorporates non-stationary covariance functions and heteroscedastic noise estimation to generate locally adapted models. The model performance is compared to different algorithms in benchmark tests for regression tasks. The results demonstrate low prediction errors of the PCEGP, highlighting model performance that is often competitive with or better than previous methods. A key advantage of the presented model is its interpretable hyperparameters along with training and prediction runtimes comparable to those of a GP.","authors":["Dominik Polke","Tim K\\\"osters","Elmar Ahle","Dirk S\\\"offker"],"url":"https://arxiv.org/abs/2405.01052"}
{"created":"2025-05-29","title":"Mitigating Text Toxicity with Counterfactual Generation","abstract":"Toxicity mitigation consists in rephrasing text in order to remove offensive or harmful meaning. Neural natural language processing (NLP) models have been widely used to target and mitigate textual toxicity. However, existing methods fail to detoxify text while preserving the initial non-toxic meaning at the same time. In this work, we propose to apply counterfactual generation methods from the eXplainable AI (XAI) field to target and mitigate textual toxicity. In particular, we perform text detoxification by applying local feature importance and counterfactual generation methods to a toxicity classifier distinguishing between toxic and non-toxic texts. We carry out text detoxification through counterfactual generation on three datasets and compare our approach to three competitors. Automatic and human evaluations show that recently developed NLP counterfactual generators can mitigate toxicity accurately while better preserving the meaning of the initial text as compared to classical detoxification methods. Finally, we take a step back from using automated detoxification tools, and discuss how to manage the polysemous nature of toxicity and the risk of malicious use of detoxification tools. This work is the first to bridge the gap between counterfactual generation and text detoxification and paves the way towards more practical application of XAI methods.","authors":["Milan Bhan","Jean-Noel Vittaut","Nina Achache","Victor Legrand","Nicolas Chesneau","Annabelle Blangero","Juliette Murris","Marie-Jeanne Lesot"],"url":"https://arxiv.org/abs/2405.09948"}
{"created":"2025-05-29","title":"MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering","abstract":"Text-Centric Visual Question Answering (TEC-VQA) in its proper format not only facilitates human-machine interaction in text-centric visual environments but also serves as a de facto gold proxy to evaluate AI models in the domain of text-centric scene understanding. Nonetheless, most existing TEC-VQA benchmarks have focused on high-resource languages like English and Chinese. Despite pioneering works to expand multilingual QA pairs in non-text-centric VQA datasets through translation engines, the translation-based protocol encounters a substantial \"visual-textual misalignment\" problem when applied to TEC-VQA. Specifically, it prioritizes the text in question-answer pairs while disregarding the visual text present in images. Moreover, it fails to address complexities related to nuanced meaning, contextual distortion, language bias, and question-type diversity. In this work, we tackle multilingual TEC-VQA by introducing MTVQA, the first benchmark featuring high-quality human expert annotations across 9 diverse languages, consisting of 6,778 question-answer pairs across 2,116 images. Further, by comprehensively evaluating numerous state-of-the-art Multimodal Large Language Models~(MLLMs), including Qwen2-VL, GPT-4o, GPT-4V, Claude3, and Gemini, on the MTVQA benchmark, it is evident that there is still a large room for performance improvement (Qwen2-VL scoring 30.9 versus 79.7 for human performance), underscoring the value of MTVQA. Additionally, we supply multilingual training data within the MTVQA dataset, demonstrating that straightforward fine-tuning with this data can substantially enhance multilingual TEC-VQA performance. We aspire that MTVQA will offer the research community fresh insights and stimulate further exploration in multilingual visual text comprehension. The project homepage is available at https://bytedance.github.io/MTVQA/.","authors":["Jingqun Tang","Qi Liu","Yongjie Ye","Jinghui Lu","Shu Wei","Chunhui Lin","Wanqing Li","Mohamad Fitri Faiz Bin Mahmood","Hao Feng","Zhen Zhao","Yanjie Wang","Yuliang Liu","Hao Liu","Xiang Bai","Can Huang"],"url":"https://arxiv.org/abs/2405.11985"}
{"created":"2025-05-29","title":"Fast meta-solvers for 3D complex-shape scatterers using neural operators trained on a non-scattering problem","abstract":"Three-dimensional target identification using scattering techniques requires high accuracy solutions and very fast computations for real-time predictions in some critical applications. We first train a deep neural operator~(DeepONet) to solve wave propagation problems described by the Helmholtz equation in a domain \\textit{without scatterers} but at different wavenumbers and with a complex absorbing boundary condition. We then design two classes of fast meta-solvers by combining DeepONet with either relaxation methods, such as Jacobi and Gauss-Seidel, or with Krylov methods, such as GMRES and BiCGStab, using the trunk basis of DeepONet as a coarse-scale preconditioner. We leverage the spectral bias of neural networks to account for the lower part of the spectrum in the error distribution while the upper part is handled inexpensively using relaxation methods or fine-scale preconditioners. The meta-solvers are then applied to solve scattering problems with different shape of scatterers, at no extra training cost. We first demonstrate that the resulting meta-solvers are shape-agnostic, fast, and robust, whereas the standard standalone solvers may even fail to converge without the DeepONet. We then apply both classes of meta-solvers to scattering from a submarine, a complex three-dimensional problem. We achieve very fast solutions, especially with the DeepONet-Krylov methods, which require orders of magnitude fewer iterations than any of the standalone solvers.","authors":["Youngkyu Lee","Shanqing Liu","Zongren Zou","Adar Kahana","Eli Turkel","Rishikesh Ranade","Jay Pathak","George Em Karniadakis"],"url":"https://arxiv.org/abs/2405.12380"}
{"created":"2025-05-29","title":"Learning Latent Graph Structures and their Uncertainty","abstract":"Graph neural networks use relational information as an inductive bias to enhance prediction performance. Not rarely, task-relevant relations are unknown and graph structure learning approaches have been proposed to learn them from data. Given their latent nature, no graph observations are available to provide a direct training signal to the learnable relations. Therefore, graph topologies are typically learned on the prediction task alongside the other graph neural network parameters. In this paper, we demonstrate that minimizing point-prediction losses does not guarantee proper learning of the latent relational information and its associated uncertainty. Conversely, we prove that suitable loss functions on the stochastic model outputs simultaneously grant solving two tasks: (i) learning the unknown distribution of the latent graph and (ii) achieving optimal predictions of the target variable. Finally, we propose a sampling-based method that solves this joint learning task. Empirical results validate our theoretical claims and demonstrate the effectiveness of the proposed approach.","authors":["Alessandro Manenti","Daniele Zambon","Cesare Alippi"],"url":"https://arxiv.org/abs/2405.19933"}
{"created":"2025-05-29","title":"PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration","abstract":"The widespread usage of online Large Language Models (LLMs) inference services has raised significant privacy concerns about the potential exposure of private information in user inputs to malicious eavesdroppers. Existing privacy protection methods for LLMs suffer from either insufficient privacy protection, performance degradation, or large inference time overhead. To address these limitations, we propose PrivacyRestore, a plug-and-play method to protect the privacy of user inputs during LLM inference. The server first trains restoration vectors for each privacy span and then release to clients. Privacy span is defined as a contiguous sequence of tokens within a text that contain private information. The client then aggregate restoration vectors of all privacy spans in the input into a single meta restoration vector which is later sent to the server side along with the input without privacy spans.The private information is restored via activation steering during inference. Furthermore, we prove that PrivacyRestore inherently prevents the linear growth of the privacy budget.We create three datasets, covering medical and legal domains, to evaluate the effectiveness of privacy preserving methods. The experimental results show that PrivacyRestore effectively protects private information and maintain acceptable levels of performance and inference overhead.","authors":["Ziqian Zeng","Jianwei Wang","Junyao Yang","Zhengdong Lu","Haoran Li","Huiping Zhuang","Cen Chen"],"url":"https://arxiv.org/abs/2406.01394"}
{"created":"2025-05-29","title":"Edit Distance Robust Watermarks via Indexing Pseudorandom Codes","abstract":"Motivated by the problem of detecting AI-generated text, we consider the problem of watermarking the output of language models with provable guarantees. We aim for watermarks which satisfy: (a) undetectability, a cryptographic notion introduced by Christ, Gunn & Zamir (2024) which stipulates that it is computationally hard to distinguish watermarked language model outputs from the model's actual output distribution; and (b) robustness to channels which introduce a constant fraction of adversarial insertions, substitutions, and deletions to the watermarked text. Earlier schemes could only handle stochastic substitutions and deletions, and thus we are aiming for a more natural and appealing robustness guarantee that holds with respect to edit distance.","authors":["Noah Golowich","Ankur Moitra"],"url":"https://arxiv.org/abs/2406.02633"}
{"created":"2025-05-29","title":"Adaptive Distance Functions via Kelvin Transformation","abstract":"The term safety in robotics is often understood as a synonym for avoidance. Although this perspective has led to progress in path planning and reactive control, a generalization of this perspective is necessary to include task semantics relevant to contact-rich manipulation tasks, especially during teleoperation and to ensure the safety of learned policies. We introduce the semantics-aware distance function and a corresponding computational method based on the Kelvin Transformation. This allows us to compute smooth distance approximations in an unbounded domain by instead solving a Laplace equation in a bounded domain. The semantics-aware distance generalizes signed distance functions by allowing the zero level set to lie inside of the object in regions where contact is allowed, effectively incorporating task semantics, such as object affordances, in an adaptive implicit representation of safe sets. In numerical experiments we show the computational viability of our method for real applications and visualize the computed function on a wrench with various semantic regions.","authors":["Rafael I. Cabral Muchacho","Florian T. Pokorny"],"url":"https://arxiv.org/abs/2406.03200"}
{"created":"2025-05-29","title":"Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions","abstract":"We study the bidding problem in repeated uniform price multi-unit auctions from the perspective of a single value-maximizing buyer who aims to maximize their cumulative value over $T$ rounds while adhering to return-on-investment (RoI) constraints in each round. Buyers adopt $m$-uniform bidding format, where they submit $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid $b_i$. We introduce safe bidding strategies as those that satisfy RoI constraints in every auction, regardless of competing bids. We show that these strategies depend only on the valuation curve of the bidder, and the bidder can focus on a finite subset of this class without loss of generality. While the number of strategies in this subset is exponential in $m$, we develop a polynomial-time algorithm to learn the optimal safe strategy that achieves sublinear regret in the online setting, where regret is measured against a clairvoyant benchmark that knows the competing bids a priori and selects a fixed hindsight optimal safe strategy. We then evaluate the performance of safe strategies against a clairvoyant that selects the optimal strategy from a richer class of strategies in the online setting. In this scenario, we compute the richness ratio, $\\alpha\\in(0, 1]$ for the class of strategies chosen by the clairvoyant and show that our algorithm, designed to learn safe strategies, achieves $\\alpha$-approximate sublinear regret against these stronger benchmarks. Experiments on semi-synthetic data from real-world auctions show that safe strategies substantially outperform the derived theoretical bounds, making them quite appealing in practice.","authors":["Negin Golrezaei","Sourav Sahoo"],"url":"https://arxiv.org/abs/2406.03674"}
{"created":"2025-05-29","title":"CTBENCH: A Library and Benchmark for Certified Training","abstract":"Training certifiably robust neural networks is an important but challenging task. While many algorithms for (deterministic) certified training have been proposed, they are often evaluated on different training schedules, certification methods, and systematically under-tuned hyperparameters, making it difficult to compare their performance. To address this challenge, we introduce CTBench, a unified library and a high-quality benchmark for certified training that evaluates all algorithms under fair settings and systematically tuned hyperparameters. We show that (1) almost all algorithms in CTBench surpass the corresponding reported performance in literature in the magnitude of algorithmic improvements, thus establishing new state-of-the-art, and (2) the claimed advantage of recent algorithms drops significantly when we enhance the outdated baselines with a fair training schedule, a fair certification method and well-tuned hyperparameters. Based on CTBench, we provide new insights into the current state of certified training, including (1) certified models have less fragmented loss surface, (2) certified models share many mistakes, (3) certified models have more sparse activations, (4) reducing regularization cleverly is crucial for certified training especially for large radii and (5) certified training has the potential to improve out-of-distribution generalization. We are confident that CTBench will serve as a benchmark and testbed for future research in certified training.","authors":["Yuhao Mao","Stefan Balauca","Martin Vechev"],"url":"https://arxiv.org/abs/2406.04848"}
{"created":"2025-05-29","title":"A Note on Vectorial Boolean Functions as Embeddings","abstract":"Let $F$ be a vectorial Boolean function from $\\mathbb{F}_2^n$ to $\\mathbb{F}_2^m$, with $m \\geq n$. We define $F$ as an embedding if $F$ is injective. In this paper, we examine the component functions of $F$, focusing on constant and balanced components. Our findings reveal that at most $2^m - 2^{m-n}$ components of $F$ can be balanced, and this maximum is achieved precisely when $F$ is an embedding, with the remaining $2^{m-n}$ components being constants. Additionally, for partially-bent embeddings, we demonstrate that there are always at least $2^n - 1$ balanced components when $n$ is even, and $2^{m-1} + 2^{n-1} - 1$ balanced components when $n$ is odd. A relation with APN functions is shown.","authors":["Augustine Musukwa","Massimiliano Sala"],"url":"https://arxiv.org/abs/2406.06429"}
{"created":"2025-05-29","title":"Fully Heteroscedastic Count Regression with Deep Double Poisson Networks","abstract":"Neural networks capable of accurate, input-conditional uncertainty representation are essential for real-world AI systems. Deep ensembles of Gaussian networks have proven highly effective for continuous regression due to their ability to flexibly represent aleatoric uncertainty via unrestricted heteroscedastic variance, which in turn enables accurate epistemic uncertainty estimation. However, no analogous approach exists for count regression, despite many important applications. To address this gap, we propose the Deep Double Poisson Network (DDPN), a novel neural discrete count regression model that outputs the parameters of the Double Poisson distribution, enabling arbitrarily high or low predictive aleatoric uncertainty for count data and improving epistemic uncertainty estimation when ensembled. We formalize and prove that DDPN exhibits robust regression properties similar to heteroscedastic Gaussian models via learnable loss attenuation, and introduce a simple loss modification to control this behavior. Experiments on diverse datasets demonstrate that DDPN outperforms current baselines in accuracy, calibration, and out-of-distribution detection, establishing a new state-of-the-art in deep count regression.","authors":["Spencer Young","Porter Jenkins","Longchao Da","Jeff Dotson","Hua Wei"],"url":"https://arxiv.org/abs/2406.09262"}
{"created":"2025-05-29","title":"REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space","abstract":"Language models (LMs) risk inadvertently memorizing and divulging sensitive or personally identifiable information (PII) seen in training data, causing privacy concerns. Current approaches to address this issue involve costly dataset scrubbing, or model filtering through unlearning and model editing, which can be bypassed through extraction attacks. We propose REVS, a novel non-gradient-based method for unlearning sensitive information from LMs. REVS identifies and modifies a small subset of neurons relevant for constituent tokens that form sensitive information. To adequately evaluate our method on truly sensitive information, we curate three datasets: email and URL datasets naturally memorized by the models, and a synthetic social security number dataset that we tune the models to memorize. Compared to other methods, REVS demonstrates superior performance in unlearning sensitive information and robustness to extraction attacks, while retaining underlying model integrity.","authors":["Tomer Ashuach","Martin Tutek","Yonatan Belinkov"],"url":"https://arxiv.org/abs/2406.09325"}
{"created":"2025-05-29","title":"Community Detection in Networks: A Rough Sets and Consensus Clustering Approach","abstract":"The objective of this paper is to propose a framework, called Rough Clustering-based Consensus Community Detection (RC-CCD), to effectively address the challenge of identifying community structures in complex networks from a set of different community partitions. The method uses a consensus approach based on Rough Set Theory (RST) to manage uncertainty and improve the reliability of community detection. The RC-CCD framework is tested on synthetic benchmark networks generated by the Lancichinetti-Fortunato-Radicchi (LFR) method, which simulate varying network scales, node degrees, and community sizes. Key findings demonstrate that RC-CCD outperforms established algorithms like Louvain, Greedy, and LPA in terms of normalized mutual information, showing superior accuracy and adaptability, particularly in networks with higher complexity, both in terms of size and dispersion. These results have significant implications for enhancing community detection in fields such as social and biological network analysis.","authors":["Darian H. Grass-Boada","Leandro Gonz\\'alez-Montesino","Rub\\'en Arma\\~nanzas"],"url":"https://arxiv.org/abs/2406.12412"}
{"created":"2025-05-29","title":"Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective","abstract":"As large language models (LLMs) become an important way of information access, there have been increasing concerns that LLMs may intensify the spread of unethical content, including implicit bias that hurts certain populations without explicit harmful words. In this paper, we conduct a rigorous evaluation of LLMs' implicit bias towards certain demographics by attacking them from a psychometric perspective to elicit agreements to biased viewpoints. Inspired by psychometric principles in cognitive and social psychology, we propose three attack approaches, i.e., Disguise, Deception, and Teaching. Incorporating the corresponding attack instructions, we built two benchmarks: (1) a bilingual dataset with biased statements covering four bias types (2.7K instances) for extensive comparative analysis, and (2) BUMBLE, a larger benchmark spanning nine common bias types (12.7K instances) for comprehensive evaluation. Extensive evaluation of popular commercial and open-source LLMs shows that our methods can elicit LLMs' inner bias more effectively than competitive baselines. Our attack methodology and benchmarks offer an effective means of assessing the ethical risks of LLMs, driving progress toward greater accountability in their development. Our code, data and benchmarks are available at https://github.com/yuchenwen1/ImplicitBiasPsychometricEvaluation and https://github.com/yuchenwen1/BUMBLE.","authors":["Yuchen Wen","Keping Bi","Wei Chen","Jiafeng Guo","Xueqi Cheng"],"url":"https://arxiv.org/abs/2406.14023"}
{"created":"2025-05-29","title":"Dissecting the Ullman Variations with a SCALPEL: Why do LLMs fail at Trivial Alterations to the False Belief Task?","abstract":"Recent empirical results have sparked a debate about whether or not Large Language Models (LLMs) are capable of Theory of Mind (ToM). While some have found LLMs to be successful on ToM evaluations such as the False Belief task, others have shown that their performance is not robust against trivial alterations to stimuli. In this paper, we introduce SCALPEL -- a technique to incrementally modify stimuli to test different specific hypotheses about why LLMs fail -- and apply this method to the \"transparent-access\" modification of the unexpected contents task. Our results suggest that LLMs often do poorly because they fail to make essential common-sense inferences, such as that seeing a transparent container implies recognizing its contents. We conclude that while modern LLMs go beyond mere pattern matching, they still fall short of robust human-like ToM. We argue that SCALPEL can help cognitive scientists examine LLMs' capabilities in finer detail and provide insight into alternative mechanisms by which tasks that are used to assess human cognition might be completed.","authors":["Zhiqiang Pi","Annapurna Vadaparty","Benjamin K. Bergen","Cameron R. Jones"],"url":"https://arxiv.org/abs/2406.14737"}
{"created":"2025-05-29","title":"Large Vocabulary Size Improves Large Language Models","abstract":"This paper empirically investigates the relationship between subword vocabulary size and the performance of large language models (LLMs) to provide insights on how to define the vocabulary size. Experimental results show that larger vocabulary sizes lead to better performance in LLMs. Moreover, we consider a continual training scenario where a pre-trained language model is trained on a different target language. We introduce a simple method to use a new vocabulary instead of the pre-defined one. We show that using the new vocabulary outperforms the model with the vocabulary used in pre-training.","authors":["Sho Takase","Ryokan Ri","Shun Kiyono","Takuya Kato"],"url":"https://arxiv.org/abs/2406.16508"}
{"created":"2025-05-29","title":"Pareto Fronts for Compositionally Solving String Diagrams of Parity Games","abstract":"Open parity games are proposed as a compositional extension of parity games with algebraic operations, forming string diagrams of parity games. A potential application of string diagrams of parity games is to describe a large parity game with a given compositional structure and solve it efficiently as a divide-and-conquer algorithm by exploiting its compositional structure. Building on our recent progress in open Markov decision processes, we introduce Pareto fronts of open parity games, offering a framework for multi-objective solutions. We establish the positional determinacy of open parity games with respect to their Pareto fronts through a novel translation method. Our translation converts an open parity game into a parity game tailored to a given single-objective. Furthermore, we present a simple algorithm for solving open parity games, derived from this translation that allows the application of existing efficient algorithms for parity games. Expanding on this foundation, we develop a compositional algorithm for string diagrams of parity games.","authors":["Kazuki Watanabe"],"url":"https://arxiv.org/abs/2406.17240"}
{"created":"2025-05-29","title":"Empirical analysis of binding precedent efficiency in Brazilian Supreme Court via case classification","abstract":"Binding precedents (s\\'umulas vinculantes) constitute a juridical instrument unique to the Brazilian legal system and whose objectives include the protection of the Federal Supreme Court against repetitive demands. Studies of the effectiveness of these instruments in decreasing the Court's exposure to similar cases, however, indicate that they tend to fail in such a direction, with some of the binding precedents seemingly creating new demands. We empirically assess the legal impact of five binding precedents, 11, 14, 17, 26, and 37, at the highest Court level through their effects on the legal subjects they address. This analysis is only possible through the comparison of the Court's ruling about the precedents' themes before they are created, which means that these decisions should be detected through techniques of Similar Case Retrieval, which we tackle from the angle of Case Classification. The contributions of this article are therefore twofold: on the mathematical side, we compare the use of different methods of Natural Language Processing -- TF-IDF, LSTM, Longformer, and regex -- for Case Classification, whereas on the legal side, we contrast the inefficiency of these binding precedents with a set of hypotheses that may justify their repeated usage. We observe that the TF-IDF models performed slightly better than LSTM and Longformer when compared through common metrics; however, the deep learning models were able to detect certain important legal events that TF-IDF missed. On the legal side, we argue that the reasons for binding precedents to fail in responding to repetitive demand are heterogeneous and case-dependent, making it impossible to single out a specific cause. We identify five main hypotheses, which are found in different combinations in each of the precedents studied.","authors":["Rapha\\\"el Tinarrage","Henrique Ennes","Lucas Resck","Lucas T. Gomes","Jean R. Ponciano","Jorge Poco"],"url":"https://arxiv.org/abs/2407.07004"}
{"created":"2025-05-29","title":"MSC-LIO: An MSCKF-Based LiDAR-Inertial Odometry with Same-Plane Cluster Tracking","abstract":"The multi-state constraint Kalman filter (MSCKF) has been proven to be more efficient than graph optimization for visual-based odometry while with similar accuracy. However, it has not been adequately considered and studied for LiDAR-based odometry. In this paper, we propose a novel tightly-coupled LiDAR-inertial odometry based on the MSCKF framework, named MSC-LIO. An efficient LiDAR same-plane cluster (LSPC) tracking method, without explicit feature extraction, is present for frame-to-frame data associations. The tracked LSPC is used to build an LSPC measurement model that constructs multi-state constraints. Besides, we propose an effective point-velocity-based LiDAR-IMU time-delay (LITD) estimation method, which is derived from the proposed LSPC tracking method. To validate the effectiveness and robustness of the proposed method, we conducted extensive experiments on both public datasets and real-world environments. The results demonstrate that the proposed MSC-LIO yields higher accuracy and efficiency compared to the state-of-the-art methods. Ablation experiments indicate that the data-association efficiency is improved by nearly 3 times with the LSPC tracking, and the proposed LITD estimation method can effectively and accurately estimate the LITD. Besides, MSC-LIO was implemented on an edge device and demonstrated excellent real-time performance.","authors":["Tisheng Zhang","Man Yuan","Linfu Wei","Hailiang Tang","Xiaoji Niu"],"url":"https://arxiv.org/abs/2407.07589"}
{"created":"2025-05-29","title":"Gradient Boosting Reinforcement Learning","abstract":"We present Gradient Boosting Reinforcement Learning (GBRL), a framework that adapts the strengths of gradient boosting trees (GBT) to reinforcement learning (RL) tasks. While neural networks (NNs) have become the de facto choice for RL, they face significant challenges with structured and categorical features and tend to generalize poorly to out-of-distribution samples. These are challenges for which GBTs have traditionally excelled in supervised learning. However, GBT's application in RL has been limited. The design of traditional GBT libraries is optimized for static datasets with fixed labels, making them incompatible with RL's dynamic nature, where both state distributions and reward signals evolve during training. GBRL overcomes this limitation by continuously interleaving tree construction with environment interaction. Through extensive experiments, we demonstrate that GBRL outperforms NNs in domains with structured observations and categorical features while maintaining competitive performance on standard continuous control benchmarks. Like its supervised learning counterpart, GBRL demonstrates superior robustness to out-of-distribution samples and better handles irregular state-action relationships.","authors":["Benjamin Fuhrer","Chen Tessler","Gal Dalal"],"url":"https://arxiv.org/abs/2407.08250"}
{"created":"2025-05-29","title":"PriRoAgg: Achieving Robust Model Aggregation with Minimum Privacy Leakage for Federated Learning","abstract":"Federated learning (FL) has recently gained significant momentum due to its potential to leverage large-scale distributed user data while preserving user privacy. However, the typical paradigm of FL faces challenges of both privacy and robustness: the transmitted model updates can potentially leak sensitive user information, and the lack of central control of the local training process leaves the global model susceptible to malicious manipulations on model updates. Current solutions attempting to address both problems under the one-server FL setting fall short in the following aspects: 1) designed for simple validity checks that are insufficient against advanced attacks (e.g., checking norm of individual update); and 2) partial privacy leakage for more complicated robust aggregation algorithms (e.g., distances between model updates are leaked for multi-Krum). In this work, we formalize a novel security notion of aggregated privacy that characterizes the minimum amount of user information, in the form of some aggregated statistics of users' updates, that is necessary to be revealed to accomplish more advanced robust aggregation. We develop a general framework PriRoAgg, utilizing Lagrange coded computing and distributed zero-knowledge proof, to execute a wide range of robust aggregation algorithms while satisfying aggregated privacy. As concrete instantiations of PriRoAgg, we construct two secure and robust protocols based on state-of-the-art robust algorithms, for which we provide full theoretical analyses on security and complexity. Extensive experiments are conducted for these protocols, demonstrating their robustness against various model integrity attacks, and their efficiency advantages over baselines.","authors":["Sizai Hou","Songze Li","Tayyebeh Jahani-Nezhad","Giuseppe Caire"],"url":"https://arxiv.org/abs/2407.08954"}
{"created":"2025-05-29","title":"Communication- and Computation-Efficient Distributed Submodular Optimization in Robot Mesh Networks","abstract":"We provide a communication- and computation-efficient method for distributed submodular optimization in robot mesh networks. Submodularity is a property of diminishing returns that arises in active information gathering such as mapping, surveillance, and target tracking. Our method, Resource-Aware distributed Greedy (RAG), introduces a new distributed optimization paradigm that enables scalable and near-optimal action coordination. To this end, RAG requires each robot to make decisions based only on information received from and about their neighbors. In contrast, the current paradigms allow the relay of information about all robots across the network. As a result, RAG's decision-time scales linearly with the network size, while state-of-the-art near-optimal submodular optimization algorithms scale cubically. We also characterize how the designed mesh-network topology affects RAG's approximation performance. Our analysis implies that sparser networks favor scalability without proportionally compromising approximation performance: while RAG's decision time scales linearly with network size, the gain in approximation performance scales sublinearly. We demonstrate RAG's performance in simulated scenarios of area detection with up to 45 robots, simulating realistic robot-to-robot (r2r) communication speeds such as the 0.25 Mbps speed of the Digi XBee 3 Zigbee 3.0. In the simulations, RAG enables real-time planning, up to three orders of magnitude faster than competitive near-optimal algorithms, while also achieving superior mean coverage performance. To enable the simulations, we extend the high-fidelity and photo-realistic simulator AirSim by integrating a scalable collaborative autonomy pipeline to tens of robots and simulating r2r communication delays. Our code is available at https://github.com/UM-iRaL/Resource-Aware-Coordination-AirSim.","authors":["Zirui Xu","Sandilya Sai Garimella","Vasileios Tzoumas"],"url":"https://arxiv.org/abs/2407.10382"}
{"created":"2025-05-29","title":"Spanning Trees Minimizing Branching Costs","abstract":"The Minimum Branch Vertices Spanning Tree problem aims to find a spanning tree $T$ in a given graph $G$ with the fewest branch vertices, defined as vertices with a degree three or more in $T$. This problem, known to be NP-hard, has attracted significant attention due to its importance in network design and optimization. Extensive research has been conducted on the algorithmic and combinatorial aspects of this problem, with recent studies delving into its fixed-parameter tractability.","authors":["Luisa Gargano","Adele A. Rescigno"],"url":"https://arxiv.org/abs/2407.10571"}
{"created":"2025-05-29","title":"Base and Exponent Prediction in Mathematical Expressions using Multi-Output CNN","abstract":"The use of neural networks and deep learning techniques in image processing has significantly advanced the field, enabling highly accurate recognition results. However, achieving high recognition rates often necessitates complex network models, which can be challenging to train and require substantial computational resources. This research presents a simplified yet effective approach to predicting both the base and exponent from images of mathematical expressions using a multi-output Convolutional Neural Network (CNN). The model is trained on 10,900 synthetically generated images containing exponent expressions, incorporating random noise, font size variations, and blur intensity to simulate real-world conditions. The proposed CNN model demonstrates robust performance with efficient training time. The experimental results indicate that the model achieves high accuracy in predicting the base and exponent values, proving the efficacy of this approach in handling noisy and varied input images.","authors":["Md Laraib Salam","Akash S Balsaraf","Gaurav Gupta","Ashish Rajeshwar Kulkarni"],"url":"https://arxiv.org/abs/2407.14967"}
{"created":"2025-05-29","title":"LAMBDA: A Large Model Based Data Agent","abstract":"We introduce LArge Model Based Data Agent (LAMBDA), a novel open-source, code-free multi-agent data analysis system that leverages the power of large language models. LAMBDA is designed to address data analysis challenges in data-driven applications through innovatively designed data agents using natural language. At the core of LAMBDA are two key agent roles: the programmer and the inspector, which are engineered to work together seamlessly. Specifically, the programmer generates code based on the user's instructions and domain-specific knowledge, while the inspector debugs the code when necessary. To ensure robustness and handle adverse scenarios, LAMBDA features a user interface that allows direct user intervention. Moreover, LAMBDA can flexibly integrate external models and algorithms through our proposed Knowledge Integration Mechanism, catering to the needs of customized data analysis. LAMBDA has demonstrated strong performance on various data analysis tasks. It has the potential to enhance data analysis paradigms by seamlessly integrating human and artificial intelligence, making it more accessible, effective, and efficient for users from diverse backgrounds. The strong performance of LAMBDA in solving data analysis problems is demonstrated using real-world data examples. The code for LAMBDA is available at https://github.com/AMA-CMFAI/LAMBDA and videos of three case studies can be viewed at https://www.polyu.edu.hk/ama/cmfai/lambda.html.","authors":["Maojun Sun","Ruijian Han","Binyan Jiang","Houduo Qi","Defeng Sun","Yancheng Yuan","Jian Huang"],"url":"https://arxiv.org/abs/2407.17535"}
{"created":"2025-05-29","title":"Mini-batch Coresets for Memory-efficient Language Model Training on Data Mixtures","abstract":"Training with larger mini-batches improves the convergence rate and can yield superior performance. However, training with large mini-batches becomes prohibitive for Large Language Models (LLMs), due to the large GPU memory requirement. To address this problem, an effective approach is finding small mini-batch coresets that closely match the gradient of larger mini-batches. However, this approach becomes infeasible and ineffective for LLMs, due to the highly imbalanced mixture of sources in language data, use of the Adam optimizer, and the very large gradient dimensionality of LLMs. In this work, we address the above challenges by proposing Coresets for Training LLMs (CoLM). First, we show that mini-batch coresets found by gradient matching do not contain representative examples of the small sources w.h.p., and thus including all examples of the small sources in the mini-batch coresets is crucial for optimal performance. Second, we normalize the gradients by their historical exponential to find mini-batch coresets for training with Adam. Finally, we leverage zeroth-order methods to find smooth gradient of the last V-projection matrix and sparsify it to keep the dimensions with the largest normalized gradient magnitude. We apply CoLM to fine-tuning Phi-2, Phi-3, Zephyr, and Llama-3 models with LoRA on MathInstruct and SuperGLUE benchmark. Remarkably, CoLM reduces the memory requirement of fine-tuning by 2x and even outperforms training with 4x larger mini-batches. Moreover, CoLM seamlessly integrates with existing memory-efficient training methods like LoRA, further reducing the memory requirements of training LLMs. Our code is available at https://github.com/BigML-CS-UCLA/CoLM.","authors":["Dang Nguyen","Wenhan Yang","Rathul Anand","Yu Yang","Baharan Mirzasoleiman"],"url":"https://arxiv.org/abs/2407.19580"}
{"created":"2025-05-29","title":"Cross-Layer Feature Pyramid Transformer for Small Object Detection in Aerial Images","abstract":"Object detection in aerial images has always been a challenging task due to the generally small size of the objects. Most current detectors prioritize the development of new detection frameworks, often overlooking research on fundamental components such as feature pyramid networks. In this paper, we introduce the Cross-Layer Feature Pyramid Transformer (CFPT), a novel upsampler-free feature pyramid network designed specifically for small object detection in aerial images. CFPT incorporates two meticulously designed attention blocks with linear computational complexity: Cross-Layer Channel-Wise Attention (CCA) and Cross-Layer Spatial-Wise Attention (CSA). CCA achieves cross-layer interaction by dividing channel-wise token groups to perceive cross-layer global information along the spatial dimension, while CSA enables cross-layer interaction by dividing spatial-wise token groups to perceive cross-layer global information along the channel dimension. By integrating these modules, CFPT enables efficient cross-layer interaction in a single step, thereby avoiding the semantic gap and information loss associated with element-wise summation and layer-by-layer transmission. In addition, CFPT incorporates global contextual information, which improves detection performance for small objects. To further enhance location awareness during cross-layer interaction, we propose the Cross-Layer Consistent Relative Positional Encoding (CCPE) based on inter-layer mutual receptive fields. We evaluate the effectiveness of CFPT on three challenging object detection datasets in aerial images: VisDrone2019-DET, TinyPerson, and xView. Extensive experiments demonstrate that CFPT outperforms state-of-the-art feature pyramid networks while incurring lower computational costs. The code is available at https://github.com/duzw9311/CFPT.","authors":["Zewen Du","Zhenjiang Hu","Guiyu Zhao","Ying Jin","Hongbin Ma"],"url":"https://arxiv.org/abs/2407.19696"}
{"created":"2025-05-29","title":"MR-ULINS: A Tightly-Coupled UWB-LiDAR-Inertial Estimator with Multi-Epoch Outlier Rejection","abstract":"The LiDAR-inertial odometry (LIO) and the ultra-wideband (UWB) have been integrated together to achieve driftless positioning in global navigation satellite system (GNSS)-denied environments. However, the UWB may be affected by systematic range errors (such as the clock drift and the antenna phase center offset) and non-line-of-sight (NLOS) signals, resulting in reduced robustness. In this study, we propose a UWB-LiDAR-inertial estimator (MR-ULINS) that tightly integrates the UWB range, LiDAR frame-to-frame, and IMU measurements within the multi-state constraint Kalman filter (MSCKF) framework. The systematic range errors are precisely modeled to be estimated and compensated online. Besides, we propose a multi-epoch outlier rejection algorithm for UWB NLOS by utilizing the relative accuracy of the LIO. Specifically, the relative trajectory of the LIO is employed to verify the consistency of all range measurements within the sliding window. Extensive experiment results demonstrate that MR-ULINS achieves a positioning accuracy of around 0.1 m in complex indoor environments with severe NLOS interference. Ablation experiments show that the online estimation and multi-epoch outlier rejection can effectively improve the positioning accuracy. Besides, MR-ULINS maintains high accuracy and robustness in LiDAR-degenerated scenes and UWB-challenging conditions with spare base stations.","authors":["Tisheng Zhang","Man Yuan","Linfu Wei","Yan Wang","Hailiang Tang","Xiaoji Niu"],"url":"https://arxiv.org/abs/2408.05719"}
{"created":"2025-05-29","title":"M2L Translation Operators for Kernel Independent Fast Multipole Methods on Modern Architectures","abstract":"Hardware trends favor algorithm designs that maximize data reuse per FLOP. We develop and benchmark high-performance Multipole-to-Local (M2L) translation operators for the kernel-independent Fast Multipole Method (kiFMM), a widely adopted FMM variant that supports a broad class of kernels and has been favored by recent implementations for its simple specification. Naively implemented, M2L is bandwidth-limited and therefore a key bottleneck in the FMM. State-of-the-art FFT-based M2L implementations, though elegant and with a fast setup time, suffer from low operational intensity and require architecture-specific optimizations. We demonstrate that a BLAS-based M2L, combined with randomized low-rank compression, achieves competitive performance with greater portability and a simpler implementation leveraging existing BLAS infrastructure, at the cost of higher setup times-especially for high-accuracy settings in double precision. Our Rust-based implementation enables seamless switching between strategies for fair benchmarking. Results on CPUs show that FFT-based M2L is favorable in low-accuracy settings or dynamic particle simulations, while BLAS-based M2L is favored for high-accuracy settings for static particle distributions, where its higher setup costs are amortized in many practical applications of the FMM.","authors":["Srinath Kailasa","Timo Betcke","Sarah El Kazdadi"],"url":"https://arxiv.org/abs/2408.07436"}
{"created":"2025-05-29","title":"Fine-Grained and Thematic Evaluation of LLMs in Social Deduction Game","abstract":"Recent studies have investigated whether large language models (LLMs) can support obscure communication that requires specialized skills, such as inferring subtext or doublespeak. To conduct the investigation, researchers have used social deduction games (SDGs) as their experimental environment, in which players conceal and infer specific information. However, prior work has often overlooked how LLMs should be evaluated in such settings. Specifically, we point out two issues with the evaluation methods they employed. First, metrics used in prior studies are coarse-grained as they are based on overall game outcomes that often fail to capture event-level behaviors; Second, error analyses have lacked structured methodologies capable of producing insights that meaningfully support evaluation outcomes. To address these issues, we propose a macroscopic and systematic approach to the investigation. Specifically, we introduce seven fine-grained metrics that resolve the first issue. To tackle the second issue, we conducted a thematic analysis and identified four major reasoning failures that undermine LLMs' performance in obscured communication.","authors":["Byungjun Kim","Dayeon Seo","Bugeun Kim"],"url":"https://arxiv.org/abs/2408.09946"}
{"created":"2025-05-29","title":"Automating Thought of Search: A Journey Towards Soundness and Completeness","abstract":"Large language models (LLMs) are being used to solve planning problems that require search. Most of the literature uses LLMs as world models to define the search space, forgoing soundness for the sake of flexibility. A recent work, Thought of Search (ToS), proposed defining the search space with code, having LLMs produce that code. ToS requires a human in the loop, collaboratively producing a sound successor function and goal test. The result, however, is worth the effort: all the tested datasets were solved with 100% accuracy. Consequently, there is great potential to automate the ToS process. We take a first major step towards automating ToS (AutoToS), taking the human out of the loop of interactions with the language model. AutoToS guides the language model step by step towards the generation of sound and complete search components, through feedback from both generic and domain specific unit tests. We show that AutoToS is able to achieve 100% accuracy on all the evaluated domains with a small number of LLM calls.","authors":["Daniel Cao","Michael Katz","Harsha Kokel","Kavitha Srinivas","Shirin Sohrabi"],"url":"https://arxiv.org/abs/2408.11326"}
{"created":"2025-05-29","title":"FireFly-S: Exploiting Dual-Side Sparsity for Spiking Neural Networks Acceleration with Reconfigurable Spatial Architecture","abstract":"Spiking Neural Networks (SNNs), with their brain-inspired structure using discrete spikes instead of continuous activations, are gaining attention for their potential of efficient processing on neuromorphic chips. While current SNN hardware accelerators often prioritize temporal spike sparsity, exploiting sparse synaptic weights offers significant untapped potential for even greater efficiency. To address this, we propose FireFly-S, a Sparse extension of the FireFly series. This co-optimized software-hardware design focusing on leveraging dual-side sparsity for acceleration. On the software side, we propose a novel algorithmic optimization framework that combines gradient rewiring for pruning and modified Learned Step Size Quantization (LSQ) tailored for SNNs, which achieves remarkable weight sparsity exceeding 85\\% and enables efficient 4-bit quantization with negligible accuracy loss. On the hardware side, we present an efficient dual-side sparsity detector employing a Bitmap-based sparse decoding logic to pinpoint the positions of non-zero weights and input spikes. The logic allows for the direct bypassing of redundant computations, thereby enhancing computational efficiency. Different from the overlay architecture adopted by previous FireFly series, we adopt a spatial architecture with inter-layer pipelining that can fully exploit the nature of Field-Programmable Gate Arrays (FPGAs). A spatial-temporal dataflow is also proposed to support such inter-layer pipelining and avoid long-term temporal dependencies. In experiments conducted on the MNIST, DVS-Gesture and CIFAR-10 datasets, the FireFly-S model achieves 85-95\\% sparsity with 4-bit quantization and the hardware accelerator effectively leverages the dual-side sparsity, delivering outstanding performance metrics of 10,047 FPS/W on MNIST, 3,683 FPS/W on DVS-Gesture, and 2,327 FPS/W on CIFAR-10.","authors":["Tenglong Li","Jindong Li","Guobin Shen","Dongcheng Zhao","Qian Zhang","Yi Zeng"],"url":"https://arxiv.org/abs/2408.15578"}
{"created":"2025-05-29","title":"Prompt-based Personality Profiling: Reinforcement Learning for Relevance Filtering","abstract":"Author profiling is the task of inferring characteristics about individuals by analyzing content they share. Supervised machine learning still dominates automatic systems that perform this task, despite the popularity of prompting large language models to address natural language understanding tasks. One reason is that the classification instances consist of large amounts of posts, potentially a whole user profile, which may exceed the input length of Transformers. Even if a model can use a large context window, the entirety of posts makes the application of API-accessed black box systems costly and slow, next to issues which come with such \"needle-in-the-haystack\" tasks. To mitigate this limitation, we propose a new method for author profiling which aims at distinguishing relevant from irrelevant content first, followed by the actual user profiling only with relevant data. To circumvent the need for relevance-annotated data, we optimize this relevance filter via reinforcement learning with a reward function that utilizes the zero-shot capabilities of large language models. We evaluate our method for Big Five personality trait prediction on two Twitter corpora. On publicly available real-world data with a skewed label distribution, our method shows similar efficacy to using all posts in a user profile, but with a substantially shorter context. An evaluation on a version of these data balanced with artificial posts shows that the filtering to relevant posts leads to a significantly improved accuracy of the predictions.","authors":["Jan Hofmann","Cornelia Sindermann","Roman Klinger"],"url":"https://arxiv.org/abs/2409.04122"}
{"created":"2025-05-29","title":"Sampling recovery in Bochner spaces and applications to parametric PDEs","abstract":"We prove convergence rates of linear sampling recovery of functions in abstract Bochner spaces satisfying weighted summability of their generalized polynomial chaos expansion coefficients. The underlying algorithm is a function-valued extension of the least squares method widely used and thoroughly studied in scalar-valued function recovery. We apply our theory to collocation approximation of solutions to parametric elliptic or parabolic PDEs with log-normal random inputs and to relevant approximation of infinite dimensional holomorphic functions on $\\mathbb R^\\infty$. The application allows us to significantly improve known results in Computational Uncertainty Quantification for these problems. Our results are also applicable for parametric PDEs with affine inputs, where they match the known rates.","authors":["Felix Bartel","Dinh D\\~ung"],"url":"https://arxiv.org/abs/2409.05050"}
{"created":"2025-05-29","title":"Sparse R-CNN OBB: Ship Target Detection in SAR Images Based on Oriented Sparse Proposals","abstract":"We present Sparse R-CNN OBB, a novel framework for the detection of oriented objects in SAR images leveraging sparse learnable proposals. The Sparse R-CNN OBB has streamlined architecture and ease of training as it utilizes a sparse set of 300 proposals instead of training a proposals generator on hundreds of thousands of anchors. To the best of our knowledge, Sparse R-CNN OBB is the first to adopt the concept of sparse learnable proposals for the detection of oriented objects, as well as for the detection of ships in Synthetic Aperture Radar (SAR) images. The detection head of the baseline model, Sparse R-CNN, is re-designed to enable the model to capture object orientation. We train the model on RSDD-SAR dataset and provide a performance comparison to state-of-the-art models. Experimental results show that Sparse R-CNN OBB achieves outstanding performance, surpassing most models on both inshore and offshore scenarios. The code is available at: www.github.com/ka-mirul/Sparse-R-CNN-OBB.","authors":["Kamirul Kamirul","Odysseas Pappas","Alin Achim"],"url":"https://arxiv.org/abs/2409.07973"}
{"created":"2025-05-29","title":"Exploring Remote Collaborative Tasks: The Impact of Avatar Representation on Dyadic Haptic Interactions in Shared Virtual Environments","abstract":"This study is the first to explore the interplay between haptic interaction and avatar representation in Shared Virtual Environments (SVEs). Specifically, how these factors shape users' sense of social presence during dyadic collaborations, while assessing potential effects on task performance. In a series of experiments, participants performed the collaborative task with haptic interaction under four avatar representation conditions: avatars of both participant and partner were displayed, only the participant's avatar was displayed, only the partner's avatar was displayed, and no avatars were displayed. The study finds that avatar representation, especially of the partner, significantly enhances the perception of social presence, which haptic interaction alone does not fully achieve. However, neither the presence nor the type of avatar representation impacts the task performance or participants' force effort of the task, suggesting that haptic interaction provides sufficient interaction cues for the execution of the task. These results underscore the significance of integrating both visual and haptic modalities to optimize remote collaboration experiences in virtual environments, ensuring effective communication and a strong sense of social presence.","authors":["Genki Sasaki","Hiroshi Igarashi"],"url":"https://arxiv.org/abs/2409.08577"}
{"created":"2025-05-29","title":"Quantum Kernel Learning for Small Dataset Modeling in Semiconductor Fabrication: Application to Ohmic Contact","abstract":"Modeling complex semiconductor fabrication processes such as Ohmic contact formation remains challenging due to high-dimensional parameter spaces and limited experimental data. While classical machine learning (CML) approaches have been successful in many domains, their performance degrades in small-sample, nonlinear scenarios. In this work, we investigate quantum machine learning (QML) as an alternative, exploiting quantum kernels to capture intricate correlations from compact datasets. Using only 159 experimental GaN HEMT samples, we develop a quantum kernel-aligned regressor (QKAR) combining a shallow Pauli-Z feature map with a trainable quantum kernel alignment (QKA) layer. All models, including seven baseline CML regressors, are evaluated under a unified PCA-based preprocessing pipeline to ensure a fair comparison. QKAR consistently outperforms classical baselines across multiple metrics (MAE, MSE, RMSE), achieving a mean absolute error of 0.338 Omega mm when validated on experimental data. We further assess noise robustness and generalization through cross-validation and new device fabrication. These findings suggest that carefully constructed QML models could provide predictive advantages in data-constrained semiconductor modeling, offering a foundation for practical deployment on near-term quantum hardware. While challenges remain for both QML and CML, this study demonstrates QML's potential as a complementary approach in complex process modeling tasks.","authors":["Zeheng Wang","Fangzhou Wang","Liang Li","Zirui Wang","Timothy van der Laan","Ross C. C. Leon","Jing-Kai Huang","Muhammad Usman"],"url":"https://arxiv.org/abs/2409.10803"}
{"created":"2025-05-29","title":"A Hybrid Multi-Factor Network with Dynamic Sequence Modeling for Early Warning of Intraoperative Hypotension","abstract":"Intraoperative hypotension (IOH) prediction using past physiological signals is crucial, as IOH may lead to inadequate organ perfusion and significantly elevate the risk of severe complications and mortality. However, current methods often rely on static modeling, overlooking the complex temporal dependencies and the inherently non-stationary nature of physiological signals. We propose a Hybrid Multi-Factor (HMF) network that formulates IOH prediction as a dynamic sequence forecasting task, explicitly capturing both temporal dependencies and physiological non-stationarity. We represent signal dynamics as multivariate time series and decompose them into trend and seasonal components, enabling separate modeling of long-term and periodic variations. Each component is encoded with a patch-based Transformer to balance computational efficiency and feature representation. To address distributional drift from evolving signals, we introduce a symmetric normalization mechanism. Experiments on both public and real-world clinical datasets show that HMF significantly outperforms competitive baselines. We hope HMF offers new insights into IOH prediction and ultimately promotes safer surgical care. Our code is available at https://github.com/Mingyue-Cheng/HMF.","authors":["Mingyue Cheng","Jintao Zhang","Zhiding Liu","Chunli Liu"],"url":"https://arxiv.org/abs/2409.11064"}
{"created":"2025-05-29","title":"METEOR: Melody-aware Texture-controllable Symbolic Orchestral Music Generation","abstract":"Western music is often characterized by a homophonic texture, in which the musical content can be organized into a melody and an accompaniment. In orchestral music, in particular, the composer can select specific characteristics for each instrument's part within the accompaniment, while also needing to adapt the melody to suit the capabilities of the instruments performing it. In this work, we propose METEOR, a model for Melody-aware Texture-controllable Orchestral music generation. This model performs symbolic multi-track music style transfer with a focus on melodic fidelity. We allow bar- and track-level controllability of the accompaniment with various textural attributes while keeping a homophonic texture. We show that the model can achieve controllability performances similar to strong baselines while greatly improve melodic fidelity.","authors":["Dinh-Viet-Toan Le","Yi-Hsuan Yang"],"url":"https://arxiv.org/abs/2409.11753"}
{"created":"2025-05-29","title":"Addressing and Visualizing Misalignments in Human Task-Solving Trajectories","abstract":"Understanding misalignments in human task-solving trajectories is crucial for enhancing AI models trained to closely mimic human reasoning. This study categorizes such misalignments into three types: (1) lack of functions to express intent, (2) inefficient action sequences, and (3) incorrect intentions that cannot solve the task. To address these issues, we first formalize and define these three misalignment types in a unified framework. We then propose a heuristic algorithm to detect misalignments in ARCTraj trajectories and analyze their impact hierarchically and quantitatively. We also present an intention estimation method based on our formalism that infers missing alignment between user actions and intentions. Through trajectory alignment, we experimentally demonstrate that AI models trained on human task-solving trajectories improve performance in mimicking human reasoning. Based on hierarchical analysis and experiments, we highlight the importance of trajectory-intention alignment and demonstrate the effectiveness of intention-aligned training.","authors":["Sejin Kim","Hosung Lee","Sundong Kim"],"url":"https://arxiv.org/abs/2409.14191"}
{"created":"2025-05-29","title":"Adapting Gait Frequency for Posture-regulating Humanoid Push-recovery via Hierarchical Model Predictive Control","abstract":"Current humanoid push-recovery strategies often use whole-body motion, yet they tend to overlook posture regulation. For instance, in manipulation tasks, the upper body may need to stay upright and have minimal recovery displacement. This paper introduces a novel approach to enhancing humanoid push-recovery performance under unknown disturbances and regulating body posture by tailoring the recovery stepping strategy. We propose a hierarchical-MPC-based scheme that analyzes and detects instability in the prediction window and quickly recovers through adapting gait frequency. Our approach integrates a high-level nonlinear MPC, a posture-aware gait frequency adaptation planner, and a low-level convex locomotion MPC. The planners predict the center of mass (CoM) state trajectories that can be assessed for precursors of potential instability and posture deviation. In simulation, we demonstrate improved maximum recoverable impulse by 131% on average compared with baseline approaches. In hardware experiments, a 125 ms advancement in recovery stepping timing/reflex has been observed with the proposed approach. We also demonstrate improved push-recovery performance and minimized body attitude change under 0.2 rad.","authors":["Junheng Li","Zhanhao Le","Junchao Ma","Quan Nguyen"],"url":"https://arxiv.org/abs/2409.14342"}
{"created":"2025-05-29","title":"Event-based Stereo Depth Estimation: A Survey","abstract":"Stereopsis has widespread appeal in robotics as it is the predominant way by which living beings perceive depth to navigate our 3D world. Event cameras are novel bio-inspired sensors that detect per-pixel brightness changes asynchronously, with very high temporal resolution and high dynamic range, enabling machine perception in high-speed motion and broad illumination conditions. The high temporal precision also benefits stereo matching, making disparity (depth) estimation a popular research area for event cameras ever since its inception. Over the last 30 years, the field has evolved rapidly, from low-latency, low-power circuit design to current deep learning (DL) approaches driven by the computer vision community. The bibliography is vast and difficult to navigate for non-experts due its highly interdisciplinary nature. Past surveys have addressed distinct aspects of this topic, in the context of applications, or focusing only on a specific class of techniques, but have overlooked stereo datasets. This survey provides a comprehensive overview, covering both instantaneous stereo and long-term methods suitable for simultaneous localization and mapping (SLAM), along with theoretical and empirical comparisons. It is the first to extensively review DL methods as well as stereo datasets, even providing practical suggestions for creating new benchmarks to advance the field. The main advantages and challenges faced by event-based stereo depth estimation are also discussed. Despite significant progress, challenges remain in achieving optimal performance in not only accuracy but also efficiency, a cornerstone of event-based computing. We identify several gaps and propose future research directions. We hope this survey inspires future research in this area, by serving as an accessible entry point for newcomers, as well as a practical guide for seasoned researchers in the community.","authors":["Suman Ghosh","Guillermo Gallego"],"url":"https://arxiv.org/abs/2409.17680"}
{"created":"2025-05-29","title":"Criticality and Safety Margins for Reinforcement Learning","abstract":"State of the art reinforcement learning methods sometimes encounter unsafe situations. Identifying when these situations occur is of interest both for post-hoc analysis and during deployment, where it might be advantageous to call out to a human overseer for help. Efforts to gauge the criticality of different points in time have been developed, but their accuracy is not well established due to a lack of ground truth, and they are not designed to be easily interpretable by end users. Therefore, we seek to define a criticality framework with both a quantifiable ground truth and a clear significance to users. We introduce true criticality as the expected drop in reward when an agent deviates from its policy for n consecutive random actions. We also introduce the concept of proxy criticality, a low-overhead metric that has a statistically monotonic relationship to true criticality. Safety margins make these interpretable, when defined as the number of random actions for which performance loss will not exceed some tolerance with high confidence. We demonstrate this approach in several environment-agent combinations; for an A3C agent in an Atari Beamrider environment, the lowest 5% of safety margins contain 47% of agent losses; i.e., supervising only 5% of decisions could potentially prevent roughly half of an agent's errors. This criticality framework measures the potential impacts of bad decisions, even before those decisions are made, allowing for more effective debugging and oversight of autonomous agents.","authors":["Alexander Grushin","Walt Woods","Alvaro Velasquez","Simon Khan"],"url":"https://arxiv.org/abs/2409.18289"}
{"created":"2025-05-29","title":"CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling","abstract":"Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in multimodal intelligence. However, recent studies discovered that CLIP can only encode one aspect of the feature space, leading to substantial information loss and indistinctive features. To mitigate this issue, this paper introduces a novel strategy that fine-tunes a series of complementary CLIP models and transforms them into a CLIP-MoE. Specifically, we propose a model-agnostic Diversified Multiplet Upcycling (DMU) framework for CLIP. Instead of training multiple CLIP models from scratch, DMU leverages a pre-trained CLIP and fine-tunes it into a diverse set with highly cost-effective multistage contrastive learning, thus capturing distinct feature subspaces efficiently. To fully exploit these fine-tuned models while minimizing computational overhead, we transform them into a CLIP-MoE, which dynamically activates a subset of CLIP experts, achieving an effective balance between model capacity and computational cost. Comprehensive experiments demonstrate the superior performance of CLIP-MoE across various zero-shot retrieval, zero-shot image classification tasks, and downstream Multimodal Large Language Model (MLLM) benchmarks when used as a vision encoder.","authors":["Jihai Zhang","Xiaoye Qu","Tong Zhu","Yu Cheng"],"url":"https://arxiv.org/abs/2409.19291"}
{"created":"2025-05-29","title":"Rethinking GNN Expressive Power from a Distributed Computational Model Perspective","abstract":"The success of graph neural networks (GNNs) has motivated theoretical studies on their expressive power, often through alignments with the Weisfeiler-Lehman (WL) tests. However, such analyses typically focus on the ability of GNNs to distinguish between graph structures, rather than to compute or approximate specific function classes. The latter is more commonly studied in machine learning theory, including results such as the Turing completeness of recurrent networks and the universal approximation property of feedforward networks. We argue that using well-defined computational models, such as a modified CONGEST model with clearly specified preprocessing and postprocessing, offers a more sound framework for analyzing GNN expressiveness. Within this framework, we show that allowing unrestricted preprocessing or incorporating externally computed features, while claiming that these precomputations enhance the expressiveness, can sometimes lead to problems. We also show that the lower bound on a GNN's capacity (depth multiplied by width) to simulate one iteration of the WL test actually grows nearly linearly with graph size, indicating that the WL test is not locally computable and is misaligned with message-passing GNNs. Despite these negative results, we also present positive results that characterize the effects of virtual nodes and edges from a computational model perspective. Finally, we highlight several open problems regarding GNN expressiveness for further exploration.","authors":["Guanyu Cui","Yuhe Guo","Zhewei Wei","Hsin-Hao Su"],"url":"https://arxiv.org/abs/2410.01308"}
{"created":"2025-05-29","title":"Diss-l-ECT: Dissecting Graph Data with Local Euler Characteristic Transforms","abstract":"The Euler Characteristic Transform (ECT) is an efficiently-computable geometrical-topological invariant that characterizes the global shape of data. In this paper, we introduce the Local Euler Characteristic Transform ($\\ell$-ECT), a novel extension of the ECT particularly designed to enhance expressivity and interpretability in graph representation learning. Unlike traditional Graph Neural Networks (GNNs), which may lose critical local details through aggregation, the $\\ell$-ECT provides a lossless representation of local neighborhoods. This approach addresses key limitations in GNNs by preserving nuanced local structures while maintaining global interpretability. Moreover, we construct a rotation-invariant metric based on $\\ell$-ECTs for spatial alignment of data spaces. Our method exhibits superior performance compared to standard GNNs on a variety of node-classification tasks, while also offering theoretical guarantees that demonstrate its effectiveness.","authors":["Julius von Rohrscheidt","Bastian Rieck"],"url":"https://arxiv.org/abs/2410.02622"}
{"created":"2025-05-29","title":"Overcoming the Machine Penalty with Imperfectly Fair AI Agents","abstract":"Despite rapid technological progress, effective human-machine cooperation remains a significant challenge. Humans tend to cooperate less with machines than with fellow humans, a phenomenon known as the machine penalty. Here, we show that artificial intelligence (AI) agents powered by large language models can overcome this penalty in social dilemma games with communication. In a pre-registered experiment with 1,152 participants, we deploy AI agents exhibiting three distinct personas: selfish, cooperative, and fair. However, only fair agents elicit human cooperation at rates comparable to human-human interactions. Analysis reveals that fair agents, similar to human participants, occasionally break pre-game cooperation promises, but nonetheless effectively establish cooperation as a social norm. These results challenge the conventional wisdom of machines as altruistic assistants or rational actors. Instead, our study highlights the importance of AI agents reflecting the nuanced complexity of human social behaviors -- imperfect yet driven by deeper social cognitive processes.","authors":["Zhen Wang","Ruiqi Song","Chen Shen","Shiya Yin","Zhao Song","Balaraju Battu","Lei Shi","Danyang Jia","Talal Rahwan","Shuyue Hu"],"url":"https://arxiv.org/abs/2410.03724"}
{"created":"2025-05-29","title":"Exploring the Limitations of Mamba in COPY and CoT Reasoning","abstract":"Transformers have become the backbone of modern Large Language Models (LLMs); however, their inference overhead grows linearly with the sequence length, posing challenges for modeling long sequences. In light of this, Mamba has attracted attention for maintaining a constant inference size, with empirical evidence demonstrating that it can match Transformer performance in sequence modeling while significantly reducing computational costs. However, an open question remains: can Mamba always bring savings while achieving performance comparable to Transformers? In this paper, we focus on analyzing the expressive ability of Mamba to perform our defined COPY operation and Chain of Thought (CoT) reasoning. First, inspired by the connection between Mamba and linear attention, we show that constant-sized Mamba may struggle to perform COPY operations while Transformers can handle them more easily. However, when the size of Mamba grows linearly with the input sequence length, it can accurately perform COPY, but in this case, Mamba no longer provides overhead savings. Based on this observation, we further analyze Mamba's ability to tackle CoT tasks, which can be described by the Dynamic Programming (DP) problems. Our findings suggest that to solve arbitrary DP problems, the total cost of Mamba is still comparable to standard Transformers. However, similar to efficient Transformers, when facing DP problems with favorable properties such as locality, Mamba can provide savings in overhead. Our experiments on the copy and CoT tasks further demonstrate Mamba's limitations compared to Transformers in learning these tasks.","authors":["Ruifeng Ren","Zhicong Li","Yong Liu"],"url":"https://arxiv.org/abs/2410.03810"}
{"created":"2025-05-29","title":"Shielded Diffusion: Generating Novel and Diverse Images using Sparse Repellency","abstract":"The adoption of text-to-image diffusion models raises concerns over reliability, drawing scrutiny under the lens of various metrics like calibration, fairness, or compute efficiency. We focus in this work on two issues that arise when deploying these models: a lack of diversity when prompting images, and a tendency to recreate images from the training set. To solve both problems, we propose a method that coaxes the sampled trajectories of pretrained diffusion models to land on images that fall outside of a reference set. We achieve this by adding repellency terms to the diffusion SDE throughout the generation trajectory, which are triggered whenever the path is expected to land too closely to an image in the shielded reference set. Our method is sparse in the sense that these repellency terms are zero and inactive most of the time, and even more so towards the end of the generation trajectory. Our method, named SPELL for sparse repellency, can be used either with a static reference set that contains protected images, or dynamically, by updating the set at each timestep with the expected images concurrently generated within a batch, and with the images of previously generated batches. We show that adding SPELL to popular diffusion models improves their diversity while impacting their FID only marginally, and performs comparatively better than other recent training-free diversity methods. We also demonstrate how SPELL can ensure a shielded generation away from a very large set of protected images by considering all 1.2M images from ImageNet as the protected set.","authors":["Michael Kirchhof","James Thornton","Louis B\\'ethune","Pierre Ablin","Eugene Ndiaye","Marco Cuturi"],"url":"https://arxiv.org/abs/2410.06025"}
{"created":"2025-05-29","title":"Understanding Model Ensemble in Transferable Adversarial Attack","abstract":"Model ensemble adversarial attack has become a powerful method for generating transferable adversarial examples that can target even unknown models, but its theoretical foundation remains underexplored. To address this gap, we provide early theoretical insights that serve as a roadmap for advancing model ensemble adversarial attack. We first define transferability error to measure the error in adversarial transferability, alongside concepts of diversity and empirical model ensemble Rademacher complexity. We then decompose the transferability error into vulnerability, diversity, and a constant, which rigidly explains the origin of transferability error in model ensemble attack: the vulnerability of an adversarial example to ensemble components, and the diversity of ensemble components. Furthermore, we apply the latest mathematical tools in information theory to bound the transferability error using complexity and generalization terms, contributing to three practical guidelines for reducing transferability error: (1) incorporating more surrogate models, (2) increasing their diversity, and (3) reducing their complexity in cases of overfitting. Finally, extensive experiments with 54 models validate our theoretical framework, representing a significant step forward in understanding transferable model ensemble adversarial attacks.","authors":["Wei Yao","Zeliang Zhang","Huayi Tang","Yong Liu"],"url":"https://arxiv.org/abs/2410.06851"}
{"created":"2025-05-29","title":"EventFlow: Forecasting Temporal Point Processes with Flow Matching","abstract":"Continuous-time event sequences, in which events occur at irregular intervals, are ubiquitous across a wide range of industrial and scientific domains. The contemporary modeling paradigm is to treat such data as realizations of a temporal point process, and in machine learning it is common to model temporal point processes in an autoregressive fashion using a neural network. While autoregressive models are successful in predicting the time of a single subsequent event, their performance can degrade when forecasting longer horizons due to cascading errors and myopic predictions. We propose EventFlow, a non-autoregressive generative model for temporal point processes. The model builds on the flow matching framework in order to directly learn joint distributions over event times, side-stepping the autoregressive process. EventFlow is simple to implement and achieves a 20%-53% lower error than the nearest baseline on standard TPP benchmarks while simultaneously using fewer model calls at sampling time.","authors":["Gavin Kerrigan","Kai Nelson","Padhraic Smyth"],"url":"https://arxiv.org/abs/2410.07430"}
{"created":"2025-05-29","title":"Nonlinear second-order dynamics describe labial constriction trajectories across languages and contexts","abstract":"We investigate the dynamics of labial constriction trajectories during the production of /b/ and /m/ in English and Mandarin. We find that, across languages and contexts, the ratio of instantaneous displacement to instantaneous velocity generally follows an exponential decay curve from movement onset to movement offset. We formalize this empirical discovery in a differential equation and, in combination with an assumption of point attractor dynamics, derive a nonlinear second-order dynamical system describing labial constriction trajectories. The equation has only two parameters, T and r. T corresponds to the target state and r corresponds to movement rapidity. Thus, each of the parameters corresponds to a phonetically relevant dimension of control. Nonlinear regression demonstrates that the model provides excellent fits to individual movement trajectories. Moreover, trajectories simulated from the model qualitatively match empirical trajectories, and capture key kinematic variables like duration, peak velocity, and time to achieve peak velocity. The model constitutes a proposal for the dynamics of individual articulatory movements, and thus offers a novel foundation from which to understand additional influences on articulatory kinematics like prosody, inter-movement coordination, and stochastic noise.","authors":["Michael C. Stern","Jason A. Shaw"],"url":"https://arxiv.org/abs/2410.08351"}
{"created":"2025-05-29","title":"Which Demographics do LLMs Default to During Annotation?","abstract":"Demographics and cultural background of annotators influence the labels they assign in text annotation -- for instance, an elderly woman might find it offensive to read a message addressed to a \"bro\", but a male teenager might find it appropriate. It is therefore important to acknowledge label variations to not under-represent members of a society. Two research directions developed out of this observation in the context of using large language models (LLM) for data annotations, namely (1) studying biases and inherent knowledge of LLMs and (2) injecting diversity in the output by manipulating the prompt with demographic information. We combine these two strands of research and ask the question to which demographics an LLM resorts to when no demographics is given. To answer this question, we evaluate which attributes of human annotators LLMs inherently mimic. Furthermore, we compare non-demographic conditioned prompts and placebo-conditioned prompts (e.g., \"you are an annotator who lives in house number 5\") to demographics-conditioned prompts (\"You are a 45 year old man and an expert on politeness annotation. How do you rate {instance}\"). We study these questions for politeness and offensiveness annotations on the POPQUORN data set, a corpus created in a controlled manner to investigate human label variations based on demographics which has not been used for LLM-based analyses so far. We observe notable influences related to gender, race, and age in demographic prompting, which contrasts with previous studies that found no such effects.","authors":["Johannes Sch\\\"afer","Aidan Combs","Christopher Bagdon","Jiahui Li","Nadine Probol","Lynn Greschner","Sean Papay","Yarik Menchaca Resendiz","Aswathy Velutharambath","Amelie W\\\"uhrl","Sabine Weber","Roman Klinger"],"url":"https://arxiv.org/abs/2410.08820"}
{"created":"2025-05-29","title":"NRFormer: Nationwide Nuclear Radiation Forecasting with Spatio-Temporal Transformer","abstract":"Nuclear radiation, which refers to the energy emitted from atomic nuclei during decay, poses significant risks to human health and environmental safety. Recently, advancements in monitoring technology have facilitated the effective recording of nuclear radiation levels and related factors, such as weather conditions. The abundance of monitoring data enables the development of accurate and reliable nuclear radiation forecasting models, which play a crucial role in informing decision-making for individuals and governments. However, this task is challenging due to the imbalanced distribution of monitoring stations over a wide spatial range and the non-stationary radiation variation patterns. In this study, we introduce NRFormer, a novel framework tailored for the nationwide prediction of nuclear radiation variations. By integrating a non-stationary temporal attention module, an imbalance-aware spatial attention module, and a radiation propagation prompting module, NRFormer collectively captures complex spatio-temporal dynamics of nuclear radiation. Extensive experiments on two real-world datasets demonstrate the superiority of our proposed framework against 11 baselines.","authors":["Tengfei Lyu","Jindong Han","Hao Liu"],"url":"https://arxiv.org/abs/2410.11924"}
{"created":"2025-05-29","title":"Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models","abstract":"Large language models (LLMs) have demonstrated impressive reasoning abilities, but they still struggle with faithful reasoning due to knowledge gaps and hallucinations. To address these issues, knowledge graphs (KGs) have been utilized to enhance LLM reasoning through their structured knowledge. However, existing KG-enhanced methods, either retrieval-based or agent-based, encounter difficulties in accurately retrieving knowledge and efficiently traversing KGs at scale. In this work, we introduce graph-constrained reasoning (GCR), a novel framework that bridges structured knowledge in KGs with unstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures faithful KG-grounded reasoning by integrating KG structure into the LLM decoding process through KG-Trie, a trie-based index that encodes KG reasoning paths. KG-Trie constrains the decoding process, allowing LLMs to directly reason on graphs and generate faithful reasoning paths grounded in KGs. Additionally, GCR leverages a lightweight KG-specialized LLM for graph-constrained reasoning alongside a powerful general LLM for inductive reasoning over multiple reasoning paths, resulting in accurate reasoning with zero reasoning hallucination. Extensive experiments on several KGQA benchmarks demonstrate that GCR achieves state-of-the-art performance and exhibits strong zero-shot generalizability to unseen KGs without additional training.","authors":["Linhao Luo","Zicheng Zhao","Gholamreza Haffari","Yuan-Fang Li","Chen Gong","Shirui Pan"],"url":"https://arxiv.org/abs/2410.13080"}
{"created":"2025-05-29","title":"Latent Weight Diffusion: Generating reactive policies instead of trajectories","abstract":"With the increasing availability of open-source robotic data, imitation learning has emerged as a viable approach for both robot manipulation and locomotion. Currently, large generalized policies are trained to predict controls or trajectories using diffusion models, which have the desirable property of learning multimodal action distributions. However, generalizability comes with a cost, namely, larger model size and slower inference. This is especially an issue for robotic tasks that require high control frequency. Further, there is a known trade-off between performance and action horizon for Diffusion Policy (DP), a popular model for generating trajectories: fewer diffusion queries accumulate greater trajectory tracking errors. For these reasons, it is common practice to run these models at high inference frequency, subject to robot computational constraints. To address these limitations, we propose Latent Weight Diffusion (LWD), a method that uses diffusion to generate closed-loop policies (weights for neural policies) for robotic tasks, rather than generating trajectories. Learning the behavior distribution through parameter space over trajectory space offers two key advantages: longer action horizons (fewer diffusion queries) & robustness to perturbations while retaining high performance; and a lower inference compute cost. To this end, we show that LWD has higher success rates than DP when the action horizon is longer and when stochastic perturbations exist in the environment. Furthermore, LWD achieves multitask performance comparable to DP while requiring just ~1/45th of the inference-time FLOPS","authors":["Shashank Hegde","Satyajeet Das","Gautam Salhotra","Gaurav S. Sukhatme"],"url":"https://arxiv.org/abs/2410.14040"}
{"created":"2025-05-29","title":"Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs","abstract":"Positional bias in large language models (LLMs) hinders their ability to effectively process long inputs. A prominent example is the \"lost in the middle\" phenomenon, where LLMs struggle to utilize relevant information situated in the middle of the input. While prior research primarily focuses on single pieces of relevant information, real-world applications often involve multiple relevant information pieces. To bridge this gap, we present LongPiBench, a benchmark designed to assess positional bias involving multiple pieces of relevant information. Thorough experiments are conducted with five commercial and six open-source models. These experiments reveal that while most current models are robust against the \"lost in the middle\" issue, there exist significant biases related to the spacing of relevant information pieces. These findings highlight the importance of evaluating and reducing positional biases to advance LLM's capabilities.","authors":["Runchu Tian","Yanghao Li","Yuepeng Fu","Siyang Deng","Qinyu Luo","Cheng Qian","Shuo Wang","Xin Cong","Zhong Zhang","Yesai Wu","Yankai Lin","Huadong Wang","Xiaojiang Liu"],"url":"https://arxiv.org/abs/2410.14641"}
{"created":"2025-05-29","title":"SafetyAnalyst: Interpretable, Transparent, and Steerable Safety Moderation for AI Behavior","abstract":"The ideal AI safety moderation system would be both structurally interpretable (so its decisions can be reliably explained) and steerable (to align to safety standards and reflect a community's values), which current systems fall short on. To address this gap, we present SafetyAnalyst, a novel AI safety moderation framework. Given an AI behavior, SafetyAnalyst uses chain-of-thought reasoning to analyze its potential consequences by creating a structured \"harm-benefit tree,\" which enumerates harmful and beneficial actions and effects the AI behavior may lead to, along with likelihood, severity, and immediacy labels that describe potential impacts on stakeholders. SafetyAnalyst then aggregates all effects into a harmfulness score using 28 fully interpretable weight parameters, which can be aligned to particular safety preferences. We applied this framework to develop an open-source LLM prompt safety classification system, distilled from 18.5 million harm-benefit features generated by frontier LLMs on 19k prompts. On comprehensive benchmarks, we show that SafetyAnalyst (average F1=0.81) outperforms existing moderation systems (average F1$<$0.72) on prompt safety classification, while offering the additional advantages of interpretability, transparency, and steerability.","authors":["Jing-Jing Li","Valentina Pyatkin","Max Kleiman-Weiner","Liwei Jiang","Nouha Dziri","Anne G. E. Collins","Jana Schaich Borg","Maarten Sap","Yejin Choi","Sydney Levine"],"url":"https://arxiv.org/abs/2410.16665"}
{"created":"2025-05-29","title":"Edge-Spreading Raptor-Like LDPC Codes for 6G Wireless Systems","abstract":"Next-generation channel coding has stringent demands on throughput, energy consumption, and error rate performance while maintaining key features of 5G New Radio (NR) standard codes such as rate compatibility, which is a significant challenge. Due to excellent capacity-achieving performance, spatially-coupled low-density parity-check (SC-LDPC) codes are considered a promising candidate for next-generation channel coding. In this paper, we propose an SC-LDPC code family called edge-spreading Raptor-like (ESRL) codes. Unlike other SC-LDPC codes that adopt the structure of existing rate-compatible LDPC block codes before coupling, ESRL codes maximize the possible locations of edge placement and focus on constructing an optimal coupled matrix. Moreover, a new graph representation called the unified graph is introduced. This graph offers a global perspective on ESRL codes and identifies the optimal edge reallocation to optimize the spreading strategy. We conduct comprehensive comparisons of ESRL codes and 5G-NR LDPC codes. Simulation results demonstrate that when all decoding parameters and complexity are the same, ESRL codes have obvious advantages in error rate performance and throughput compared to 5G-NR LDPC codes in some specific scenarios (low and high number of iterations), making them a promising solution towards next-generation channel coding.","authors":["Yuqing Ren","Leyu Zhang","Yifei Shen","Wenqing Song","Emmanuel Boutillon","Alexios Balatsoukas-Stimming","Andreas Burg"],"url":"https://arxiv.org/abs/2410.16875"}
{"created":"2025-05-29","title":"AdvAgent: Controllable Blackbox Red-teaming on Web Agents","abstract":"Foundation model-based agents are increasingly used to automate complex tasks, enhancing efficiency and productivity. However, their access to sensitive resources and autonomous decision-making also introduce significant security risks, where successful attacks could lead to severe consequences. To systematically uncover these vulnerabilities, we propose AdvAgent, a black-box red-teaming framework for attacking web agents. Unlike existing approaches, AdvAgent employs a reinforcement learning-based pipeline to train an adversarial prompter model that optimizes adversarial prompts using feedback from the black-box agent. With careful attack design, these prompts effectively exploit agent weaknesses while maintaining stealthiness and controllability. Extensive evaluations demonstrate that AdvAgent achieves high success rates against state-of-the-art GPT-4-based web agents across diverse web tasks. Furthermore, we find that existing prompt-based defenses provide only limited protection, leaving agents vulnerable to our framework. These findings highlight critical vulnerabilities in current web agents and emphasize the urgent need for stronger defense mechanisms. We release code at https://ai-secure.github.io/AdvAgent/.","authors":["Chejian Xu","Mintong Kang","Jiawei Zhang","Zeyi Liao","Lingbo Mo","Mengqi Yuan","Huan Sun","Bo Li"],"url":"https://arxiv.org/abs/2410.17401"}
{"created":"2025-05-29","title":"Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching","abstract":"Recent large language models (LLMs) demonstrate multilingual abilities, yet they are English-centric due to dominance of English in training corpora. The limited resource for low-resource languages remains a crucial challenge. Code-switching (CS), a phenomenon where multilingual speakers alternate between languages in a discourse, can convey subtle cultural and linguistic nuances that can be otherwise lost in translation and elicits language-specific knowledge in human communications. In light of this, we investigate whether code-switching can 'activate', or identify and leverage knowledge for reasoning when LLMs solve low-resource language tasks. To facilitate the research, we first present EnKoQA, a synthetic English-Korean CS question-answering dataset. We provide comprehensive analysis on a variety of multilingual LLMs by subdividing activation process into knowledge identification and knowledge leveraging. Our results demonstrate that compared to English text, CS can faithfully activate knowledge inside LLMs especially on language-specific domains, suggesting the potential of code-switching on low-resource language tasks.","authors":["Seoyeon Kim","Huiseo Kim","Chanjun Park","Jinyoung Yeo","Dongha Lee"],"url":"https://arxiv.org/abs/2410.18436"}
{"created":"2025-05-29","title":"The Stepwise Deception: Simulating the Evolution from True News to Fake News with LLM Agents","abstract":"With the growing spread of misinformation online, understanding how true news evolves into fake news has become crucial for early detection and prevention. However, previous research has often assumed fake news inherently exists rather than exploring its gradual formation. To address this gap, we propose FUSE (Fake news evolUtion Simulation framEwork), a novel Large Language Model (LLM)-based simulation approach explicitly focusing on fake news evolution from real news. Our framework model a social network with four distinct types of LLM agents commonly observed in daily interactions: spreaders who propagate information, commentators who provide interpretations, verifiers who fact-check, and bystanders who observe passively to simulate realistic daily interactions that progressively distort true news. To quantify these gradual distortions, we develop FUSE-EVAL, a comprehensive evaluation framework measuring truth deviation along multiple linguistic and semantic dimensions. Results show that FUSE effectively captures fake news evolution patterns and accurately reproduces known fake news, aligning closely with human evaluations. Experiments demonstrate that FUSE accurately reproduces known fake news evolution scenarios, aligns closely with human judgment, and highlights the importance of timely intervention at early stages. Our framework is extensible, enabling future research on broader scenarios of fake news.","authors":["Yuhan Liu","Zirui Song","Juntian Zhang","Xiaoqing Zhang","Xiuying Chen","Rui Yan"],"url":"https://arxiv.org/abs/2410.19064"}
{"created":"2025-05-29","title":"Understanding Synthetic Context Extension via Retrieval Heads","abstract":"Long-context LLMs are increasingly in demand for applications such as retrieval-augmented generation. To defray the cost of pretraining LLMs over long contexts, recent work takes an approach of synthetic context extension: fine-tuning LLMs with synthetically generated long-context data in a post-training stage. However, it remains unclear how and why this synthetic context extension imparts abilities for downstream long-context tasks. In this paper, we investigate fine-tuning on synthetic data for three long-context tasks that require retrieval and reasoning. We vary the realism of \"needle\" concepts to be retrieved and diversity of the surrounding \"haystack\" context, from using LLMs to construct synthetic documents to using templated relations and creating symbolic datasets. We find that models trained on synthetic data fall short of the real data, but surprisingly, the mismatch can be interpreted and even predicted in terms of a special set of attention heads that are responsible for retrieval over long context, retrieval heads (Wu et al., 2024). The retrieval heads learned on synthetic data have high overlap with retrieval heads learned on real data, and there is a strong correlation between the recall of heads learned and the downstream performance of a model. Furthermore, with attention knockout and activation patching, we mechanistically show that retrieval heads are necessary and explain model performance, although they are not totally sufficient. Our results shed light on how to interpret synthetic data fine-tuning performance and how to approach creating better data for learning real-world capabilities over long contexts.","authors":["Xinyu Zhao","Fangcong Yin","Greg Durrett"],"url":"https://arxiv.org/abs/2410.22316"}
{"created":"2025-05-29","title":"Preference-CFR$\\:$ Beyond Nash Equilibrium for Better Game Strategies","abstract":"Artificial intelligence (AI) has surpassed top human players in a variety of games. In imperfect information games, these achievements have primarily been driven by Counterfactual Regret Minimization (CFR) and its variants for computing Nash equilibrium. However, most existing research has focused on maximizing payoff, while largely neglecting the importance of strategic diversity and the need for varied play styles, thereby limiting AI's adaptability to different user preferences.","authors":["Qi Ju","Thomas Tellier","Meng Sun","Zhemei Fang","Yunfeng Luo"],"url":"https://arxiv.org/abs/2411.01217"}
{"created":"2025-05-29","title":"Diffusion Models as Cartoonists: The Curious Case of High Density Regions","abstract":"We investigate what kind of images lie in the high-density regions of diffusion models. We introduce a theoretical mode-tracking process capable of pinpointing the exact mode of the denoising distribution, and we propose a practical high-density sampler that consistently generates images of higher likelihood than usual samplers. Our empirical findings reveal the existence of significantly higher likelihood samples that typical samplers do not produce, often manifesting as cartoon-like drawings or blurry images depending on the noise level. Curiously, these patterns emerge in datasets devoid of such examples. We also present a novel approach to track sample likelihoods in diffusion SDEs, which remarkably incurs no additional computational cost. Code is available at https://github.com/Aalto-QuML/high-density-diffusion.","authors":["Rafa{\\l} Karczewski","Markus Heinonen","Vikas Garg"],"url":"https://arxiv.org/abs/2411.01293"}
{"created":"2025-05-29","title":"Embedding Safety into RL: A New Take on Trust Region Methods","abstract":"Reinforcement Learning (RL) agents can solve diverse tasks but often exhibit unsafe behavior. Constrained Markov Decision Processes (CMDPs) address this by enforcing safety constraints, yet existing methods either sacrifice reward maximization or allow unsafe training. We introduce Constrained Trust Region Policy Optimization (C-TRPO), which reshapes the policy space geometry to ensure trust regions contain only safe policies, guaranteeing constraint satisfaction throughout training. We analyze its theoretical properties and connections to TRPO, Natural Policy Gradient (NPG), and Constrained Policy Optimization (CPO). Experiments show that C-TRPO reduces constraint violations while maintaining competitive returns.","authors":["Nikola Milosevic","Johannes M\\\"uller","Nico Scherf"],"url":"https://arxiv.org/abs/2411.02957"}
{"created":"2025-05-29","title":"Controllable Context Sensitivity and the Knob Behind It","abstract":"When making predictions, a language model must trade off how much it relies on its context vs. its prior knowledge. Choosing how sensitive the model is to its context is a fundamental functionality, as it enables the model to excel at tasks like retrieval-augmented generation and question-answering. In this paper, we search for a knob which controls this sensitivity, determining whether language models answer from the context or their prior knowledge. To guide this search, we design a task for controllable context sensitivity. In this task, we first feed the model a context (Paris is in England) and a question (Where is Paris?); we then instruct the model to either use its prior or contextual knowledge and evaluate whether it generates the correct answer for both intents (either France or England). When fine-tuned on this task, instruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it with high accuracy (85-95%). Analyzing these high-performing models, we narrow down which layers may be important to context sensitivity using a novel linear time algorithm. Then, in each model, we identify a 1-D subspace in a single layer that encodes whether the model follows context or prior knowledge. Interestingly, while we identify this subspace in a fine-tuned model, we find that the exact same subspace serves as an effective knob in not only that model but also non-fine-tuned instruct and base models of that model family. Finally, we show a strong correlation between a model's performance and how distinctly it separates context-agreeing from context-ignoring answers in this subspace. These results suggest a single subspace facilitates how the model chooses between context and prior knowledge, hinting at a simple fundamental mechanism that controls this behavior.","authors":["Julian Minder","Kevin Du","Niklas Stoehr","Giovanni Monea","Chris Wendler","Robert West","Ryan Cotterell"],"url":"https://arxiv.org/abs/2411.07404"}
{"created":"2025-05-29","title":"Dual-Head Knowledge Distillation: Enhancing Logits Utilization with an Auxiliary Head","abstract":"Traditional knowledge distillation focuses on aligning the student's predicted probabilities with both ground-truth labels and the teacher's predicted probabilities. However, the transition to predicted probabilities from logits would obscure certain indispensable information. To address this issue, it is intuitive to additionally introduce a logit-level loss function as a supplement to the widely used probability-level loss function, for exploiting the latent information of logits. Unfortunately, we empirically find that the amalgamation of the newly introduced logit-level loss and the previous probability-level loss will lead to performance degeneration, even trailing behind the performance of employing either loss in isolation. We attribute this phenomenon to the collapse of the classification head, which is verified by our theoretical analysis based on the neural collapse theory. Specifically, the gradients of the two loss functions exhibit contradictions in the linear classifier yet display no such conflict within the backbone. Drawing from the theoretical analysis, we propose a novel method called dual-head knowledge distillation, which partitions the linear classifier into two classification heads responsible for different losses, thereby preserving the beneficial effects of both losses on the backbone while eliminating adverse influences on the classification head. Extensive experiments validate that our method can effectively exploit the information inside the logits and achieve superior performance against state-of-the-art counterparts. Our code is available at: https://github.com/penghui-yang/DHKD.","authors":["Penghui Yang","Chen-Chen Zong","Sheng-Jun Huang","Lei Feng","Bo An"],"url":"https://arxiv.org/abs/2411.08937"}
{"created":"2025-05-29","title":"LL\\\"aMmlein: Compact and Competitive German-Only Language Models from Scratch","abstract":"We create two German-only decoder models, LL\\\"aMmlein 120M and 1B, transparently from scratch and publish them, along with the training data, for the German NLP research community to use. The model training involved several key steps, including extensive data preprocessing, the creation of a custom German tokenizer, the training itself, as well as the evaluation of the final models on various benchmarks. Throughout the training process, multiple checkpoints were saved and analyzed using the SuperGLEBer benchmark to monitor the models' learning dynamics. Compared to state-of-the-art models on the SuperGLEBer benchmark, both LL\\\"aMmlein models performed competitively, consistently matching or surpassing models with similar parameter sizes. The results show that the models' quality scales with size as expected, but performance improvements on some tasks plateaued early, offering valuable insights into resource allocation for future model development.","authors":["Jan Pfister","Julia Wunderle","Andreas Hotho"],"url":"https://arxiv.org/abs/2411.11171"}
{"created":"2025-05-29","title":"Describe Now: User-Driven Audio Description for Blind and Low Vision Individuals","abstract":"Audio descriptions (AD) make videos accessible for blind and low vision (BLV) users by describing visual elements that cannot be understood from the main audio track. AD created by professionals or novice describers is time-consuming and offers little customization or control to BLV viewers on description length and content and when they receive it. To address this gap, we explore user-driven AI-generated descriptions, enabling BLV viewers to control both the timing and level of detail of the descriptions they receive. In a study, 20 BLV participants activated audio descriptions for seven different video genres with two levels of detail: concise and detailed. Our findings reveal differences in the preferred frequency and level of detail of ADs for different videos, participants' sense of control with this style of AD delivery, and its limitations. We discuss the implications of these findings for the development of future AD tools for BLV users.","authors":["Maryam Cheema","Hasti Seifi","Pooyan Fazli"],"url":"https://arxiv.org/abs/2411.11835"}
{"created":"2025-05-29","title":"Coarse-to-fine Q-Network with Action Sequence for Data-Efficient Robot Learning","abstract":"Predicting a sequence of actions has been crucial in the success of recent behavior cloning algorithms in robotics. Can similar ideas improve reinforcement learning (RL)? We answer affirmatively by observing that incorporating action sequences when predicting ground-truth return-to-go leads to lower validation loss. Motivated by this, we introduce Coarse-to-fine Q-Network with Action Sequence (CQN-AS), a novel value-based RL algorithm that learns a critic network that outputs Q-values over a sequence of actions, i.e., explicitly training the value function to learn the consequence of executing action sequences. Our experiments show that CQN-AS outperforms several baselines on a variety of sparse-reward humanoid control and tabletop manipulation tasks from BiGym and RLBench.","authors":["Younggyo Seo","Pieter Abbeel"],"url":"https://arxiv.org/abs/2411.12155"}
{"created":"2025-05-29","title":"Robust Data-Driven Predictive Control for Mixed Platoons under Noise and Attacks","abstract":"Controlling mixed platoons, which consist of both connected and automated vehicles (CAVs) and human-driven vehicles (HDVs), poses significant challenges due to the uncertain and unknown human driving behaviors. Data-driven control methods offer promising solutions by leveraging available trajectory data, but their performance can be compromised by noise and attacks. To address this issue, this paper proposes a Robust Data-EnablEd Predictive Leading Cruise Control (RDeeP-LCC) framework based on data-driven reachability analysis. The framework over-approximates system dynamics under noise and attack using a matrix zonotope set derived from data, and develops a stabilizing feedback control law. By decoupling the mixed platoon system into nominal and error components, we employ data-driven reachability sets to recursively compute error reachable sets that account for noise and attacks, and obtain tightened safety constraints of the nominal system. This leads to a robust data-driven predictive control framework, solved in a tube-based control manner. Numerical simulations and human-in-the-loop experiments demonstrate that the RDeeP-LCC method significantly improves robustness against noise and attacks, while enhancing tracking accuracy, control efficiency, energy economy, and driving comfort.","authors":["Shuai Li","Chaoyi Chen","Haotian Zheng","Jiawei Wang","Qing Xu","Jianqiang Wang","Keqiang Li"],"url":"https://arxiv.org/abs/2411.13924"}
{"created":"2025-05-29","title":"Natural Language Reinforcement Learning","abstract":"Artificial intelligence progresses towards the \"Era of Experience,\" where agents are expected to learn from continuous, grounded interaction. We argue that traditional Reinforcement Learning (RL), which typically represents value as a scalar, can restrict agent's deep understanding of environments and hinders the active, deliberative learning crucial for navigating this new paradigm. To address the issue, we introduce Natural Language Reinforcement Learning (NLRL), a framework that extends RL principles into natural language counterparts. Central to NLRL is the Language Value Function (LVF), which redefines value as an interpretable linguistic narrative articulating the rationale behind an evaluation. NLRL further extends this concept to core RL components, including policy, the Bellman equation, and policy iteration. Leveraging recent advancements in Large Language Models (LLMs), NLRL can be practically implemented to achieve RL-like policy and value training through unsupervised environment interactions. Experiments over 4 multi-step agentic tasks demonstrate NLRL's effectiveness, efficiency, and its potential to foster deeper understanding and more active learning strategies.","authors":["Xidong Feng","Bo Liu","Yan Song","Haotian Fu","Ziyu Wan","Girish A. Koushik","Zhiyuan Hu","Mengyue Yang","Ying Wen","Jun Wang"],"url":"https://arxiv.org/abs/2411.14251"}
{"created":"2025-05-29","title":"Functionality understanding and segmentation in 3D scenes","abstract":"Understanding functionalities in 3D scenes involves interpreting natural language descriptions to locate functional interactive objects, such as handles and buttons, in a 3D environment. Functionality understanding is highly challenging, as it requires both world knowledge to interpret language and spatial perception to identify fine-grained objects. For example, given a task like 'turn on the ceiling light', an embodied AI agent must infer that it needs to locate the light switch, even though the switch is not explicitly mentioned in the task description. To date, no dedicated methods have been developed for this problem. In this paper, we introduce Fun3DU, the first approach designed for functionality understanding in 3D scenes. Fun3DU uses a language model to parse the task description through Chain-of-Thought reasoning in order to identify the object of interest. The identified object is segmented across multiple views of the captured scene by using a vision and language model. The segmentation results from each view are lifted in 3D and aggregated into the point cloud using geometric information. Fun3DU is training-free, relying entirely on pre-trained models. We evaluate Fun3DU on SceneFun3D, the most recent and only dataset to benchmark this task, which comprises over 3000 task descriptions on 230 scenes. Our method significantly outperforms state-of-the-art open-vocabulary 3D segmentation approaches. Project page: https://tev-fbk.github.io/fun3du/","authors":["Jaime Corsetti","Francesco Giuliari","Alice Fasoli","Davide Boscaini","Fabio Poiesi"],"url":"https://arxiv.org/abs/2411.16310"}
{"created":"2025-05-29","title":"Bivariate Linear Operator Codes","abstract":"In this work, we present a generalization of the linear operator family of codes that captures more codes that achieve list decoding capacity. Linear operator (LO) codes were introduced by Bhandari, Harsha, Kumar, and Sudan [BHKS24] as a way to capture capacity-achieving codes. In their framework, a code is specified by a collection of linear operators that are applied to a message polynomial and then evaluated at a specified set of evaluation points. We generalize this idea in a way that can be applied to bivariate message polynomials, getting what we call bivariate linear operator (B-LO) codes.","authors":["Aaron L. Putterman","Vadim Zaripov"],"url":"https://arxiv.org/abs/2411.16596"}
{"created":"2025-05-29","title":"Overcoming Non-monotonicity in Transducer-based Streaming Generation","abstract":"Streaming generation models are utilized across fields, with the Transducer architecture being popular in industrial applications. However, its input-synchronous decoding mechanism presents challenges in tasks requiring non-monotonic alignments, such as simultaneous translation. In this research, we address this issue by integrating Transducer's decoding with the history of input stream via a learnable monotonic attention. Our approach leverages the forward-backward algorithm to infer the posterior probability of alignments between the predictor states and input timestamps, which is then used to estimate the monotonic context representations, thereby avoiding the need to enumerate the exponentially large alignment space during training. Extensive experiments show that our MonoAttn-Transducer effectively handles non-monotonic alignments in streaming scenarios, offering a robust solution for complex generation tasks.","authors":["Zhengrui Ma","Yang Feng","Min Zhang"],"url":"https://arxiv.org/abs/2411.17170"}
{"created":"2025-05-29","title":"AutoElicit: Using Large Language Models for Expert Prior Elicitation in Predictive Modelling","abstract":"Large language models (LLMs) acquire a breadth of information across various domains. However, their computational complexity, cost, and lack of transparency often hinder their direct application for predictive tasks where privacy and interpretability are paramount. In fields such as healthcare, biology, and finance, specialised and interpretable linear models still hold considerable value. In such domains, labelled data may be scarce or expensive to obtain. Well-specified prior distributions over model parameters can reduce the sample complexity of learning through Bayesian inference; however, eliciting expert priors can be time-consuming. We therefore introduce AutoElicit to extract knowledge from LLMs and construct priors for predictive models. We show these priors are informative and can be refined using natural language. We perform a careful study contrasting AutoElicit with in-context learning and demonstrate how to perform model selection between the two methods. We find that AutoElicit yields priors that can substantially reduce error over uninformative priors, using fewer labels, and consistently outperform in-context learning. We show that AutoElicit saves over 6 months of labelling effort when building a new predictive model for urinary tract infections from sensor recordings of people living with dementia.","authors":["Alexander Capstick","Rahul G. Krishnan","Payam Barnaghi"],"url":"https://arxiv.org/abs/2411.17284"}
{"created":"2025-05-29","title":"Multi-Label Bayesian Active Learning with Inter-Label Relationships","abstract":"The primary challenge of multi-label active learning, differing it from multi-class active learning, lies in assessing the informativeness of an indefinite number of labels while also accounting for the inherited label correlation. Existing studies either require substantial computational resources to leverage correlations or fail to fully explore label dependencies. Additionally, real-world scenarios often require addressing intrinsic biases stemming from imbalanced data distributions. In this paper, we propose a new multi-label active learning strategy to address both challenges. Our method incorporates progressively updated positive and negative correlation matrices to capture co-occurrence and disjoint relationships within the label space of annotated samples, enabling a holistic assessment of uncertainty rather than treating labels as isolated elements. Furthermore, alongside diversity, our model employs ensemble pseudo labeling and beta scoring rules to address data imbalances. Extensive experiments on four realistic datasets demonstrate that our strategy consistently achieves more reliable and superior performance, compared to several established methods.","authors":["Yuanyuan Qi","Jueqing Lu","Xiaohao Yang","Joanne Enticott","Lan Du"],"url":"https://arxiv.org/abs/2411.17941"}
{"created":"2025-05-29","title":"Federated Continual Graph Learning","abstract":"Managing evolving graph data presents substantial challenges in storage and privacy, and training graph neural networks (GNNs) on such data often leads to catastrophic forgetting, impairing performance on earlier tasks. Despite existing continual graph learning (CGL) methods mitigating this to some extent, they rely on centralized architectures and ignore the potential of distributed graph databases to leverage collective intelligence. To this end, we propose Federated Continual Graph Learning (FCGL) to adapt GNNs across multiple evolving graphs under storage and privacy constraints. Our empirical study highlights two core challenges: local graph forgetting (LGF), where clients lose prior knowledge when adapting to new tasks, and global expertise conflict (GEC), where the global GNN exhibits sub-optimal performance in both adapting to new tasks and retaining old ones, arising from inconsistent client expertise during server-side parameter aggregation. To address these, we introduce POWER, a framework that preserves experience nodes with maximum local-global coverage locally to mitigate LGF, and leverages pseudo-prototype reconstruction with trajectory-aware knowledge transfer to resolve GEC. Experiments on various graph datasets demonstrate POWER's superiority over federated adaptations of CGL baselines and vision-centric federated continual learning approaches.","authors":["Yinlin Zhu","Miao Hu","Di Wu"],"url":"https://arxiv.org/abs/2411.18919"}
{"created":"2025-05-29","title":"Sample Efficient Robot Learning in Supervised Effect Prediction Tasks","abstract":"In self-supervised robotic learning, agents acquire data through active interaction with their environment, incurring costs such as energy use, human oversight, and experimental time. To mitigate these, sample-efficient exploration is essential. While intrinsic motivation (IM) methods like learning progress (LP) are widely used in robotics, and active learning (AL) is well established for classification in machine learning, few frameworks address continuous, high-dimensional regression tasks typical of world model learning. We propose MUSEL (Model Uncertainty for Sample-Efficient Learning), a novel AL framework tailored for regression tasks in robotics, such as action-effect prediction. MUSEL introduces a model uncertainty metric that combines total predictive uncertainty, learning progress, and input diversity to guide data acquisition. We validate our approach using a Stochastic Variational Deep Kernel Learning (SVDKL) model in two robotic tabletop tasks. Experimental results demonstrate that MUSEL improves both learning accuracy and sample efficiency, validating its effectiveness in learning action effects and selecting informative samples.","authors":["Mehmet Arda Eren","Erhan Oztop"],"url":"https://arxiv.org/abs/2412.02331"}
{"created":"2025-05-29","title":"Some lower bounds for optimal sampling recovery of functions with mixed smoothness","abstract":"Recently, there was a substantial progress in the problem of sampling recovery on function classes with mixed smoothness. Mostly, it has been done by proving new and sometimes optimal upper bounds for both linear sampling recovery and for nonlinear sampling recovery. In this paper we address the problem of lower bounds for the optimal rates of nonlinear sampling recovery.","authors":["A. Gasnikov","V. Temlyakov"],"url":"https://arxiv.org/abs/2412.02797"}
{"created":"2025-05-29","title":"MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation","abstract":"This paper introduces MIDI, a novel paradigm for compositional 3D scene generation from a single image. Unlike existing methods that rely on reconstruction or retrieval techniques or recent approaches that employ multi-stage object-by-object generation, MIDI extends pre-trained image-to-3D object generation models to multi-instance diffusion models, enabling the simultaneous generation of multiple 3D instances with accurate spatial relationships and high generalizability. At its core, MIDI incorporates a novel multi-instance attention mechanism, that effectively captures inter-object interactions and spatial coherence directly within the generation process, without the need for complex multi-step processes. The method utilizes partial object images and global scene context as inputs, directly modeling object completion during 3D generation. During training, we effectively supervise the interactions between 3D instances using a limited amount of scene-level data, while incorporating single-object data for regularization, thereby maintaining the pre-trained generalization ability. MIDI demonstrates state-of-the-art performance in image-to-scene generation, validated through evaluations on synthetic data, real-world scene data, and stylized scene images generated by text-to-image diffusion models.","authors":["Zehuan Huang","Yuan-Chen Guo","Xingqiao An","Yunhan Yang","Yangguang Li","Zi-Xin Zou","Ding Liang","Xihui Liu","Yan-Pei Cao","Lu Sheng"],"url":"https://arxiv.org/abs/2412.03558"}
{"created":"2025-05-29","title":"SoPo: Text-to-Motion Generation Using Semi-Online Preference Optimization","abstract":"Text-to-motion generation is essential for advancing the creative industry but often presents challenges in producing consistent, realistic motions. To address this, we focus on fine-tuning text-to-motion models to consistently favor high-quality, human-preferred motions, a critical yet largely unexplored problem. In this work, we theoretically investigate the DPO under both online and offline settings, and reveal their respective limitation: overfitting in offline DPO, and biased sampling in online DPO. Building on our theoretical insights, we introduce Semi-online Preference Optimization (SoPo), a DPO-based method for training text-to-motion models using \"semi-online\" data pair, consisting of unpreferred motion from online distribution and preferred motion in offline datasets. This method leverages both online and offline DPO, allowing each to compensate for the other's limitations. Extensive experiments demonstrate that SoPo outperforms other preference alignment methods, with an MM-Dist of 3.25% (vs e.g. 0.76% of MoDiPO) on the MLD model, 2.91% (vs e.g. 0.66% of MoDiPO) on MDM model, respectively. Additionally, the MLD model fine-tuned by our SoPo surpasses the SoTA model in terms of R-precision and MM Dist. Visualization results also show the efficacy of our SoPo in preference alignment. Project page: https://xiaofeng-tan.github.io/projects/SoPo/ .","authors":["Xiaofeng Tan","Hongsong Wang","Xin Geng","Pan Zhou"],"url":"https://arxiv.org/abs/2412.05095"}
{"created":"2025-05-29","title":"Robust Output Tracking for an Uncertain and Nonlinear 3D PDE-ODE System: Preventing Induced Seismicity in Underground Reservoirs","abstract":"This paper presents a robust control strategy for output tracking of a nonlinear 3D PDE-ODE system, where the ODE has logistic-like dynamics. The output feedback control was developed by bounding the solution and its time derivative for both the infinite-dimensional system and the nonlinear ODE. These bounds were then leveraged to ensure the boundedness of the control coefficient and the perturbations in the error dynamics. The mathematical framework proves the controller's ability to manage two output types within the system, overcoming model uncertainties and heterogeneities, using minimal system information, and a continuous control signal. A case study addressing induced seismicity mitigation while ensuring energy production in the Groningen gas reservoir highlights the control's effectiveness. The strategy guarantees precise tracking of target seismicity rates and pressures across reservoir regions, even under parameter uncertainties. Numerical simulations validate the approach in two scenarios: gas extraction while not exceeding the intrinsic seismicity of the region and the addition of CO2 injections, achieving net-zero environmental impact.","authors":["Diego Guti\\'errez-Oribio","Ioannis Stefanou"],"url":"https://arxiv.org/abs/2412.06327"}
{"created":"2025-05-29","title":"Zero-Shot Mono-to-Binaural Speech Synthesis","abstract":"We present ZeroBAS, a neural method to synthesize binaural audio from monaural audio recordings and positional information without training on any binaural data. To our knowledge, this is the first published zero-shot neural approach to mono-to-binaural audio synthesis. Specifically, we show that a parameter-free geometric time warping and amplitude scaling based on source location suffices to get an initial binaural synthesis that can be refined by iteratively applying a pretrained denoising vocoder. Furthermore, we find this leads to generalization across room conditions, which we measure by introducing a new dataset, TUT Mono-to-Binaural, to evaluate state-of-the-art monaural-to-binaural synthesis methods on unseen conditions. Our zero-shot method is perceptually on-par with the performance of supervised methods on the standard mono-to-binaural dataset, and even surpasses them on our out-of-distribution TUT Mono-to-Binaural dataset. Our results highlight the potential of pretrained generative audio models and zero-shot learning to unlock robust binaural audio synthesis.","authors":["Alon Levkovitch","Julian Salazar","Soroosh Mariooryad","RJ Skerry-Ryan","Nadav Bar","Bastiaan Kleijn","Eliya Nachmani"],"url":"https://arxiv.org/abs/2412.08356"}
{"created":"2025-05-29","title":"Go With the Flow: Fast Diffusion for Gaussian Mixture Models","abstract":"Schrodinger Bridges (SBs) are diffusion processes that steer, in finite time, a given initial distribution to another final one while minimizing a suitable cost functional. Although various methods for computing SBs have recently been proposed in the literature, most of these approaches require computationally expensive training schemes, even for solving low-dimensional problems. In this work, we propose an analytic parametrization of a set of feasible policies for steering the distribution of a dynamical system from one Gaussian Mixture Model (GMM) to another. Instead of relying on standard non-convex optimization techniques, the optimal policy within the set can be approximated as the solution of a low-dimensional linear program whose dimension scales linearly with the number of components in each mixture. The proposed method generalizes naturally to more general classes of dynamical systems, such as controllable linear time-varying systems, enabling efficient solutions to multi-marginal momentum SB between GMMs, a challenging distribution interpolation problem. We showcase the potential of this approach in low-to-moderate dimensional problems such as image-to-image translation in the latent space of an autoencoder, learning of cellular dynamics using multi-marginal momentum SB problems, and various other examples. We also test our approach on an Entropic Optimal Transport (EOT) benchmark problem and show that it outperforms state-of-the-art methods in cases where the boundary distributions are mixture models while requiring virtually no training.","authors":["George Rapakoulias","Ali Reza Pedram","Fengjiao Liu","Lingjiong Zhu","Panagiotis Tsiotras"],"url":"https://arxiv.org/abs/2412.09059"}
{"created":"2025-05-29","title":"Non-Ground Congruence Closure","abstract":"Congruence closure on ground equations is a well-established and efficient algorithm for deciding ground equalities. It constructs an explicit representation of ground equivalence classes based on a given set of input equations, allowing ground equalities to be decided by membership. In many applications, these ground equations originate from grounding non-ground equations.","authors":["Hendrik Leidinger","Christoph Weidenbach"],"url":"https://arxiv.org/abs/2412.10066"}
{"created":"2025-05-29","title":"Simple Guidance Mechanisms for Discrete Diffusion Models","abstract":"Diffusion models for continuous data gained widespread adoption owing to their high quality generation and control mechanisms. However, controllable diffusion on discrete data faces challenges given that continuous guidance methods do not directly apply to discrete diffusion. Here, we provide a straightforward derivation of classifier-free and classifier-based guidance for discrete diffusion, as well as a new class of diffusion models that leverage uniform noise and that are more guidable because they can continuously edit their outputs. We improve the quality of these models with a novel continuous-time variational lower bound that yields state-of-the-art performance, especially in settings involving guidance or fast generation. Empirically, we demonstrate that our guidance mechanisms combined with uniform noise diffusion improve controllable generation relative to autoregressive and diffusion baselines on several discrete data domains, including genomic sequences, small molecule design, and discretized image generation.","authors":["Yair Schiff","Subham Sekhar Sahoo","Hao Phung","Guanghan Wang","Sam Boshar","Hugo Dalla-torre","Bernardo P. de Almeida","Alexander Rush","Thomas Pierrot","Volodymyr Kuleshov"],"url":"https://arxiv.org/abs/2412.10193"}
{"created":"2025-05-29","title":"Preference Adaptive and Sequential Text-to-Image Generation","abstract":"We address the problem of interactive text-to-image (T2I) generation, designing a reinforcement learning (RL) agent which iteratively improves a set of generated images for a user through a sequence of prompt expansions. Using human raters, we create a novel dataset of sequential preferences, which we leverage, together with large-scale open-source (non-sequential) datasets. We construct user-preference and user-choice models using an EM strategy and identify varying user preference types. We then leverage a large multimodal language model (LMM) and a value-based RL approach to suggest an adaptive and diverse slate of prompt expansions to the user. Our Preference Adaptive and Sequential Text-to-image Agent (PASTA) extends T2I models with adaptive multi-turn capabilities, fostering collaborative co-creation and addressing uncertainty or underspecification in a user's intent. We evaluate PASTA using human raters, showing significant improvement compared to baseline methods. We also open-source our sequential rater dataset and simulated user-rater interactions to support future research in user-centric multi-turn T2I systems.","authors":["Ofir Nabati","Guy Tennenholtz","ChihWei Hsu","Moonkyung Ryu","Deepak Ramachandran","Yinlam Chow","Xiang Li","Craig Boutilier"],"url":"https://arxiv.org/abs/2412.10419"}
{"created":"2025-05-29","title":"GNNs-to-MLPs by Teacher Injection and Dirichlet Energy Distillation","abstract":"Graph Neural Networks (GNNs) are pivotal in graph-based learning, particularly excelling in node classification. However, their scalability is hindered by the need for multi-hop data during inference, limiting their application in latency-sensitive scenarios. Recent efforts to distill GNNs into multi-layer perceptrons (MLPs) for faster inference often underutilize the layer-level insights of GNNs. In this paper, we present TINED, a novel approach that distills GNNs to MLPs on a layer-by-layer basis using Teacher Injection and Dirichlet Energy Distillation techniques. We focus on two key operations in GNN layers: feature transformation (FT) and graph propagation (GP). We recognize that FT is computationally equivalent to a fully-connected (FC) layer in MLPs. Thus, we propose directly transferring teacher parameters from an FT in a GNN to an FC layer in the student MLP, enhanced by fine-tuning. In TINED, the FC layers in an MLP replicate the sequence of FTs and GPs in the GNN. We also establish a theoretical bound for GP approximation. Furthermore, we note that FT and GP operations in GNN layers often exhibit opposing smoothing effects: GP is aggressive, while FT is conservative. Using Dirichlet energy, we develop a DE ratio to measure these effects and propose Dirichlet Energy Distillation to convey these characteristics from GNN layers to MLP layers. Extensive experiments show that TINED outperforms GNNs and leading distillation methods across various settings and seven datasets. Source code are available at https://github.com/scottjiao/TINED_ICML25/.","authors":["Ziang Zhou","Zhihao Ding","Jieming Shi","Qing Li","Shiqi Shen"],"url":"https://arxiv.org/abs/2412.11180"}
{"created":"2025-05-29","title":"ConKE: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning","abstract":"Knowledge Editing (KE) aims to adjust a Large Language Model's (LLM) internal representations and parameters to correct inaccuracies and improve output consistency without incurring the computational expense of re-training the entire model. However, editing commonsense knowledge still faces difficulties, including limited knowledge coverage in existing resources, the infeasibility of annotating labels for an overabundance of commonsense knowledge, and the strict knowledge formats of current editing methods. In this paper, we address these challenges by presenting ConceptEdit, a framework that integrates conceptualization and instantiation into the KE pipeline for LLMs to enhance their commonsense reasoning capabilities. ConceptEdit dynamically diagnoses implausible commonsense knowledge within an LLM using another verifier LLM and augments the source knowledge to be edited with conceptualization for stronger generalizability. Experimental results demonstrate that LLMs enhanced with ConceptEdit successfully generate commonsense knowledge with improved plausibility compared to other baselines and achieve stronger performance across multiple question answering benchmarks. Our data, code, and models are publicly available at https://github.com/HKUST-KnowComp/ConKE.","authors":["Liyu Zhang","Weiqi Wang","Tianqing Fang","Yangqiu Song"],"url":"https://arxiv.org/abs/2412.11418"}
{"created":"2025-05-29","title":"Robust Contact-rich Manipulation through Implicit Motor Adaptation","abstract":"Contact-rich manipulation plays an important role in daily human activities. However, uncertain physical parameters often pose significant challenges for both planning and control. A promising strategy is to develop policies that are robust across a wide range of parameters. Domain adaptation and domain randomization are widely used, but they tend to either limit generalization to new instances or perform conservatively due to neglecting instance-specific information. \\textit{Explicit motor adaptation} addresses these issues by estimating system parameters online and then retrieving the parameter-conditioned policy from a parameter-augmented base policy. However, it typically requires precise system identification or additional training of a student policy, both of which are challenging in contact-rich manipulation tasks with diverse physical parameters. In this work, we propose \\textit{implicit motor adaptation}, which enables parameter-conditioned policy retrieval given a roughly estimated parameter distribution instead of a single estimate. We leverage tensor train as an implicit representation of the base policy, facilitating efficient retrieval of the parameter-conditioned policy by exploiting the separable structure of tensor cores. This framework eliminates the need for precise system estimation and policy retraining while preserving optimal behavior and strong generalization. We provide a theoretical analysis to validate the approach, supported by numerical evaluations on three contact-rich manipulation primitives. Both simulation and real-world experiments demonstrate its ability to generate robust policies across diverse instances.","authors":["Teng Xue","Amirreza Razmjoo","Suhan Shetty","Sylvain Calinon"],"url":"https://arxiv.org/abs/2412.11829"}
{"created":"2025-05-29","title":"Core Context Aware Transformers for Long Context Language Modeling","abstract":"Transformer-based Large Language Models (LLMs) have exhibited remarkable success in extensive tasks primarily attributed to self-attention mechanism, which requires a token to consider all preceding tokens as its context to compute attention. However, when the context length L becomes very large (e.g., 128K), the amount of potentially redundant information in the context tends to increase. The redundant context not only hampers the modeling representation performance but also incurs unnecessary computational and storage overhead. In this paper, we propose a plug-and-play Core Context Aware (CCA) Attention for efficient long-context modeling, comprising two complementary modules: 1) Globality-aware pooling module groups input tokens and dynamically compresses each group into one core token based on their significance. In this way, our method automatically focuses and strengthens core context while diminishing redundancy during the learning process, leading to effective long-term dependency modeling. 2) Locality-preserving module incorporates neighboring tokens to preserve local context for detailed representation. Notably, our CCA-Attention is able to replace the self-attention module in existing LLMs with minimal fine-tuning cost. Extensive experimental results show the superiority of our method in both long-context modeling and computational efficiency over state-of-the-art methods.","authors":["Yaofo Chen","Zeng You","Shuhai Zhang","Haokun Li","Yirui Li","Yaowei Wang","Mingkui Tan"],"url":"https://arxiv.org/abs/2412.12465"}
{"created":"2025-05-29","title":"FocusChat: Text-guided Long Video Understanding via Spatiotemporal Information Filtering","abstract":"Recently, multi-modal large language models have made significant progress. However, visual information lacking of guidance from the user's intention may lead to redundant computation and involve unnecessary visual noise, especially in long, untrimmed videos. To address this issue, we propose FocusChat, a text-guided multi-modal large language model (LLM) that emphasizes visual information correlated to the user's prompt. In detail, Our model first undergoes the semantic extraction module, which comprises a visual semantic branch and a text semantic branch to extract image and text semantics, respectively. The two branches are combined using the Spatial-Temporal Filtering Module (STFM). STFM enables explicit spatial-level information filtering and implicit temporal-level feature filtering, ensuring that the visual tokens are closely aligned with the user's query. It lowers the essential number of visual tokens inputted into the LLM. FocusChat significantly outperforms Video-LLaMA in zero-shot experiments, using an order of magnitude less training data with only 16 visual tokens occupied. It achieves results comparable to the state-of-the-art in few-shot experiments, with only 0.72M pre-training data.","authors":["Zheng Cheng","Rendong Wang","Zhicheng Wang"],"url":"https://arxiv.org/abs/2412.12833"}
{"created":"2025-05-29","title":"How to Synthesize Text Data without Model Collapse?","abstract":"Model collapse in synthetic data indicates that iterative training on self-generated data leads to a gradual decline in performance. With the proliferation of AI models, synthetic data will fundamentally reshape the web data ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend of synthetic and human-produced data. In this paper, we focus on two questions: what is the impact of synthetic data on language model training, and how to synthesize data without model collapse? We first pre-train language models across different proportions of synthetic data, revealing a negative correlation between the proportion of synthetic data and model performance. We further conduct statistical analysis on synthetic data to uncover distributional shift phenomenon and over-concentration of n-gram features. Inspired by the above findings, we propose token editing on human-produced data to obtain semi-synthetic data. As a proof of concept, we theoretically demonstrate that token-level editing can prevent model collapse, as the test error is constrained by a finite upper bound. We conduct extensive experiments on pre-training from scratch, continual pre-training, and supervised fine-tuning. The results validate our theoretical proof that token-level editing improves model performance.","authors":["Xuekai Zhu","Daixuan Cheng","Hengli Li","Kaiyan Zhang","Ermo Hua","Xingtai Lv","Ning Ding","Zhouhan Lin","Zilong Zheng","Bowen Zhou"],"url":"https://arxiv.org/abs/2412.14689"}
{"created":"2025-05-29","title":"Revisiting In-Context Learning with Long Context Language Models","abstract":"In-Context Learning (ICL) is a technique by which language models make predictions based on examples provided in their input context. Previously, their context window size imposed a limit on the number of examples that can be shown, making example selection techniques crucial for identifying the maximally effective set of examples. However, the recent advent of Long Context Language Models (LCLMs) has significantly increased the number of examples that can be included in context, raising an important question of whether ICL performance in a many-shot regime is still sensitive to the method of sample selection. To answer this, we revisit these approaches in the context of LCLMs through extensive experiments on 18 datasets spanning 4 tasks. Surprisingly, we observe that sophisticated example selection techniques do not yield significant improvements over a simple random sample selection method. Instead, we discover that the advent of LCLMs has fundamentally shifted the challenge of ICL from that of selecting the most effective examples to that of collecting sufficient examples to fill the context window. Specifically, in certain datasets, including all available examples does not fully utilize the context window; however, by augmenting the examples in context with a simple data augmentation approach, we substantially improve ICL performance by 5%.","authors":["Jinheon Baek","Sun Jae Lee","Prakhar Gupta","Geunseob Oh","Siddharth Dalmia","Prateek Kolhar"],"url":"https://arxiv.org/abs/2412.16926"}
{"created":"2025-05-29","title":"Efficient Long Context Language Model Retrieval with Compression","abstract":"Long Context Language Models (LCLMs) have emerged as a new paradigm to perform Information Retrieval (IR), which enables the direct ingestion and retrieval of information by processing an entire corpus in their single context, showcasing the potential to surpass traditional sparse and dense retrieval methods. However, processing a large number of passages within in-context for retrieval is computationally expensive, and handling their representations during inference further exacerbates the processing time; thus, we aim to make LCLM retrieval more efficient and potentially more effective with passage compression. Specifically, we propose a new compression approach tailored for LCLM retrieval, which is trained to maximize the retrieval performance while minimizing the length of the compressed passages. To accomplish this, we generate the synthetic data, where compressed passages are automatically created and labeled as chosen or rejected according to their retrieval success for a given query, and we train the proposed Compression model for Long context Retrieval (CoLoR) with this data via preference optimization while adding the length regularization loss on top of it to enforce brevity. Through extensive experiments on 9 datasets, we show that CoLoR improves the retrieval performance by 6% while compressing the in-context size by a factor of 1.91. Our code is available at: https://github.com/going-doer/CoLoR.","authors":["Minju Seo","Jinheon Baek","Seongyun Lee","Sung Ju Hwang"],"url":"https://arxiv.org/abs/2412.18232"}
{"created":"2025-05-29","title":"The Impact of the Single-Label Assumption in Image Recognition Benchmarking","abstract":"Deep neural networks (DNNs) are typically evaluated under the assumption that each image has a single correct label. However, many images in benchmarks like ImageNet contain multiple valid labels, creating a mismatch between evaluation protocols and the actual complexity of visual data. This mismatch can penalize DNNs for predicting correct but unannotated labels, which may partly explain reported accuracy drops, such as the widely cited 11 to 14 percent top-1 accuracy decline on ImageNetV2, a replication test set for ImageNet. This raises the question: do such drops reflect genuine generalization failures or artifacts of restrictive evaluation metrics? We rigorously assess the impact of multi-label characteristics on reported accuracy gaps. To evaluate the multi-label prediction capability (MLPC) of single-label-trained models, we introduce a variable top-$k$ evaluation, where $k$ matches the number of valid labels per image. Applied to 315 ImageNet-trained models, our analyses demonstrate that conventional top-1 accuracy disproportionately penalizes valid but secondary predictions. We also propose Aggregate Subgroup Model Accuracy (ASMA) to better capture multi-label performance across model subgroups. Our results reveal wide variability in MLPC, with some models consistently ranking multiple correct labels higher. Under this evaluation, the perceived gap between ImageNet and ImageNetV2 narrows substantially. To further isolate multi-label recognition performance from contextual cues, we introduce PatchML, a synthetic dataset containing systematically combined object patches. PatchML demonstrates that many models trained with single-label supervision nonetheless recognize multiple objects. Altogether, these findings highlight limitations in single-label evaluation and reveal that modern DNNs have stronger multi-label capabilities than standard metrics suggest.","authors":["Esla Timothy Anzaku","Seyed Amir Mousavi","Arnout Van Messem","Wesley De Neve"],"url":"https://arxiv.org/abs/2412.18409"}
{"created":"2025-05-29","title":"Constraint-Adaptive Policy Switching for Offline Safe Reinforcement Learning","abstract":"Offline safe reinforcement learning (OSRL) involves learning a decision-making policy to maximize rewards from a fixed batch of training data to satisfy pre-defined safety constraints. However, adapting to varying safety constraints during deployment without retraining remains an under-explored challenge. To address this challenge, we introduce constraint-adaptive policy switching (CAPS), a wrapper framework around existing offline RL algorithms. During training, CAPS uses offline data to learn multiple policies with a shared representation that optimize different reward and cost trade-offs. During testing, CAPS switches between those policies by selecting at each state the policy that maximizes future rewards among those that satisfy the current cost constraint. Our experiments on 38 tasks from the DSRL benchmark demonstrate that CAPS consistently outperforms existing methods, establishing a strong wrapper-based baseline for OSRL. The code is publicly available at https://github.com/yassineCh/CAPS.","authors":["Yassine Chemingui","Aryan Deshwal","Honghao Wei","Alan Fern","Janardhan Rao Doppa"],"url":"https://arxiv.org/abs/2412.18946"}
{"created":"2025-05-29","title":"Outlier-Robust Linear System Identification Under Heavy-tailed Noise","abstract":"We consider the problem of estimating the state transition matrix of a linear time-invariant (LTI) system, given access to multiple independent trajectories sampled from the system. Several recent papers have conducted a non-asymptotic analysis of this problem, relying crucially on the assumption that the process noise is either Gaussian or sub-Gaussian, i.e., \"light-tailed\". In sharp contrast, we work under a significantly weaker noise model, assuming nothing more than the existence of the fourth moment of the noise distribution. For this setting, we provide the first set of results demonstrating that one can obtain sample-complexity bounds for linear system identification that are nearly of the same order as under sub-Gaussian noise. To achieve such results, we develop a novel robust system identification algorithm that relies on constructing multiple weakly-concentrated estimators, and then boosting their performance using suitable tools from high-dimensional robust statistics. Interestingly, our analysis reveals how the kurtosis of the noise distribution, a measure of heavy-tailedness, affects the number of trajectories needed to achieve desired estimation error bounds. Finally, we show that our algorithm and analysis technique can be easily extended to account for scenarios where an adversary can arbitrarily corrupt a small fraction of the collected trajectory data. Our work takes the first steps towards building a robust statistical learning theory for control under non-ideal assumptions on the data-generating process.","authors":["Vinay Kanakeri","Aritra Mitra"],"url":"https://arxiv.org/abs/2501.00421"}
{"created":"2025-05-29","title":"FitCF: A Framework for Automatic Feature Importance-guided Counterfactual Example Generation","abstract":"Counterfactual examples are widely used in natural language processing (NLP) as valuable data to improve models, and in explainable artificial intelligence (XAI) to understand model behavior. The automated generation of counterfactual examples remains a challenging task even for large language models (LLMs), despite their impressive performance on many tasks. In this paper, we first introduce ZeroCF, a faithful approach for leveraging important words derived from feature attribution methods to generate counterfactual examples in a zero-shot setting. Second, we present a new framework, FitCF, which further verifies aforementioned counterfactuals by label flip verification and then inserts them as demonstrations for few-shot prompting, outperforming two state-of-the-art baselines. Through ablation studies, we identify the importance of each of FitCF's core components in improving the quality of counterfactuals, as assessed through flip rate, perplexity, and similarity measures. Furthermore, we show the effectiveness of LIME and Integrated Gradients as backbone attribution methods for FitCF and find that the number of demonstrations has the largest effect on performance. Finally, we reveal a strong correlation between the faithfulness of feature attribution scores and the quality of generated counterfactuals, which we hope will serve as an important finding for future research in this direction.","authors":["Qianli Wang","Nils Feldhus","Simon Ostermann","Luis Felipe Villa-Arenas","Sebastian M\\\"oller","Vera Schmitt"],"url":"https://arxiv.org/abs/2501.00777"}
{"created":"2025-05-29","title":"How Breakable Is Privacy: Probing and Resisting Model Inversion Attacks in Collaborative Inference","abstract":"Collaborative inference (CI) improves computational efficiency for edge devices by transmitting intermediate features to cloud models. However, this process inevitably exposes feature representations to model inversion attacks (MIAs), enabling unauthorized data reconstruction. Despite extensive research, there is no established criterion for assessing the difficulty of MIA implementation, leaving a fundamental question unanswered: \\textit{What factors truly and verifiably determine the attack's success in CI?} Moreover, existing defenses lack the theoretical foundation described above, making it challenging to regulate feature information effectively while ensuring privacy and minimizing computational overhead. These shortcomings introduce three key challenges: theoretical gap, methodological limitation, and practical constraint.","authors":["Rongke Liu"],"url":"https://arxiv.org/abs/2501.00824"}
{"created":"2025-05-29","title":"VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control","abstract":"Despite significant advancements in video generation, inserting a given object into videos remains a challenging task. The difficulty lies in preserving the appearance details of the reference object and accurately modeling coherent motions at the same time. In this paper, we propose VideoAnydoor, a zero-shot video object insertion framework with high-fidelity detail preservation and precise motion control. Starting from a text-to-video model, we utilize an ID extractor to inject the global identity and leverage a box sequence to control the overall motion. To preserve the detailed appearance and meanwhile support fine-grained motion control, we design a pixel warper. It takes the reference image with arbitrary key-points and the corresponding key-point trajectories as inputs. It warps the pixel details according to the trajectories and fuses the warped features with the diffusion U-Net, thus improving detail preservation and supporting users in manipulating the motion trajectories. In addition, we propose a training strategy involving both videos and static images with a weighted loss to enhance insertion quality. VideoAnydoor demonstrates significant superiority over existing methods and naturally supports various downstream applications (e.g., talking head generation, video virtual try-on, multi-region editing) without task-specific fine-tuning.","authors":["Yuanpeng Tu","Hao Luo","Xi Chen","Sihui Ji","Xiang Bai","Hengshuang Zhao"],"url":"https://arxiv.org/abs/2501.01427"}
{"created":"2025-05-29","title":"DreamMask: Boosting Open-vocabulary Panoptic Segmentation with Synthetic Data","abstract":"Open-vocabulary panoptic segmentation has received significant attention due to its applicability in the real world. Despite claims of robust generalization, we find that the advancements of previous works are attributed mainly on trained categories, exposing a lack of generalization to novel classes. In this paper, we explore boosting existing models from a data-centric perspective. We propose DreamMask, which systematically explores how to generate training data in the open-vocabulary setting, and how to train the model with both real and synthetic data. For the first part, we propose an automatic data generation pipeline with off-the-shelf models. We propose crucial designs for vocabulary expansion, layout arrangement, data filtering, etc. Equipped with these techniques, our generated data could significantly outperform the manually collected web data. To train the model with generated data, a synthetic-real alignment loss is designed to bridge the representation gap, bringing noticeable improvements across multiple benchmarks. In general, DreamMask significantly simplifies the collection of large-scale training data, serving as a plug-and-play enhancement for existing methods. For instance, when trained on COCO and tested on ADE20K, the model equipped with DreamMask outperforms the previous state-of-the-art by a substantial margin of 2.1% mIoU.","authors":["Yuanpeng Tu","Xi Chen","Ser-Nam Lim","Hengshuang Zhao"],"url":"https://arxiv.org/abs/2501.02048"}
{"created":"2025-05-29","title":"Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation","abstract":"Recommender systems have become increasingly vital in our daily lives, helping to alleviate the problem of information overload across various user-oriented online services. The emergence of Large Language Models (LLMs) has yielded remarkable achievements, demonstrating their potential for the development of next-generation recommender systems. Despite these advancements, LLM-based recommender systems face inherent limitations stemming from their LLM backbones, particularly issues of hallucinations and the lack of up-to-date and domain-specific knowledge. Recently, Retrieval-Augmented Generation (RAG) has garnered significant attention for addressing these limitations by leveraging external knowledge sources to enhance the understanding and generation of LLMs. However, vanilla RAG methods often introduce noise and neglect structural relationships in knowledge, limiting their effectiveness in LLM-based recommendations. To address these limitations, we propose to retrieve high-quality and up-to-date structure information from the knowledge graph (KG) to augment recommendations. Specifically, our approach develops a retrieval-augmented framework, termed K-RagRec, that facilitates the recommendation generation process by incorporating structure information from the external KG. Extensive experiments have been conducted to demonstrate the effectiveness of our proposed method.","authors":["Shijie Wang","Wenqi Fan","Yue Feng","Shanru Lin","Xinyu Ma","Shuaiqiang Wang","Dawei Yin"],"url":"https://arxiv.org/abs/2501.02226"}
{"created":"2025-05-29","title":"PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models","abstract":"Process-level Reward Models (PRMs) are crucial for complex reasoning and decision-making tasks, where each intermediate step plays an important role in the reasoning process. Since language models are prone to various types of errors during the reasoning process, PRMs are required to possess nuanced capabilities for detecting various implicit error types in real-world scenarios. However, current benchmarks primarily focus on step correctness, failing to evaluate PRMs' performance systematically. To address this gap, we introduce PRMBench, a process-level benchmark specifically designed to assess the fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216 carefully designed problems and 83,456 step-level labels, evaluating models across multiple dimensions, including simplicity, soundness, and sensitivity. In our experiments on 15 models, spanning both open-source PRMs and closed-source large language models prompted as critic models, we uncover significant weaknesses in current PRMs. These findings underscore the challenges inherent in process-level evaluation and highlight key directions for future research. We hope PRMBench can be a robust bench for advancing research on PRM evaluation and development.","authors":["Mingyang Song","Zhaochen Su","Xiaoye Qu","Jiawei Zhou","Yu Cheng"],"url":"https://arxiv.org/abs/2501.03124"}
{"created":"2025-05-29","title":"LLMs Reproduce Stereotypes of Sexual and Gender Minorities","abstract":"A large body of research has found substantial gender bias in NLP systems. Most of this research takes a binary, essentialist view of gender: limiting its variation to the categories _men_ and _women_, conflating gender with sex, and ignoring different sexual identities. But gender and sexuality exist on a spectrum, so in this paper we study the biases of large language models (LLMs) towards sexual and gender minorities beyond binary categories. Grounding our study in a widely used social psychology model -- the Stereotype Content Model -- we demonstrate that English-language survey questions about social perceptions elicit more negative stereotypes of sexual and gender minorities from both humans and LLMs. We then extend this framework to a more realistic use case: text generation. Our analysis shows that LLMs generate stereotyped representations of sexual and gender minorities in this setting, showing that they amplify representational harms in creative writing, a widely advertised use for LLMs.","authors":["Ruby Ostrow","Adam Lopez"],"url":"https://arxiv.org/abs/2501.05926"}
{"created":"2025-05-29","title":"Gender-Neutral Large Language Models for Medical Applications: Reducing Bias in PubMed Abstracts","abstract":"This paper presents a pipeline for mitigating gender bias in large language models (LLMs) used in medical literature by neutralizing gendered occupational pronouns. A dataset of 379,000 PubMed abstracts from 1965-1980 was processed to identify and modify pronouns tied to professions. We developed a BERT-based model, \"Modern Occupational Bias Elimination with Refined Training,\" or \"MOBERT,\" trained on these neutralized abstracts, and compared its performance with \"1965BERT,\" trained on the original dataset. MOBERT achieved a 70% inclusive replacement rate, while 1965BERT reached only 4%. A further analysis of MOBERT revealed that pronoun replacement accuracy correlated with the frequency of occupational terms in the training data. We propose expanding the dataset and refining the pipeline to improve performance and ensure more equitable language modeling in medical applications.","authors":["Elizabeth Schaefer","Kirk Roberts"],"url":"https://arxiv.org/abs/2501.06365"}
{"created":"2025-05-29","title":"Diffusion Adversarial Post-Training for One-Step Video Generation","abstract":"The diffusion models are widely used for image and video generation, but their iterative generation process is slow and expansive. While existing distillation approaches have demonstrated the potential for one-step generation in the image domain, they still suffer from significant quality degradation. In this work, we propose Adversarial Post-Training (APT) against real data following diffusion pre-training for one-step video generation. To improve the training stability and quality, we introduce several improvements to the model architecture and training procedures, along with an approximated R1 regularization objective. Empirically, our experiments show that our adversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720, 24fps videos in real time using a single forward evaluation step. Additionally, our model is capable of generating 1024px images in a single step, achieving quality comparable to state-of-the-art methods.","authors":["Shanchuan Lin","Xin Xia","Yuxi Ren","Ceyuan Yang","Xuefeng Xiao","Lu Jiang"],"url":"https://arxiv.org/abs/2501.08316"}
{"created":"2025-05-29","title":"Chance-Constrained Sampling-Based MPC for Collision Avoidance in Uncertain Dynamic Environments","abstract":"Navigating safely in dynamic and uncertain environments is challenging due to uncertainties in perception and motion. This letter presents the Chance-Constrained Unscented Model Predictive Path Integral (C2U-MPPI) framework, a robust sampling-based Model Predictive Control (MPC) algorithm that addresses these challenges by leveraging the U-MPPI control strategy with integrated probabilistic chance constraints, enabling more reliable and efficient navigation under uncertainty. Unlike gradient-based MPC methods, our approach (i) avoids linearization of system dynamics by directly applying non-convex and nonlinear chance constraints, enabling more accurate and flexible optimization, and (ii) enhances computational efficiency by leveraging a deterministic form of probabilistic constraints and employing a layered dynamic obstacle representation, enabling real-time handling of multiple obstacles. Extensive experiments in simulated and real-world human-shared environments validate the effectiveness of our algorithm against baseline methods, showcasing its capability to generate feasible trajectories and control inputs that adhere to system dynamics and constraints in dynamic settings, enabled by unscented-based sampling strategy and risk-sensitive trajectory evaluation. A supplementary video is available at: https://youtu.be/FptAhvJlQm8.","authors":["Ihab S. Mohamed","Mahmoud Ali","Lantao Liu"],"url":"https://arxiv.org/abs/2501.08520"}
{"created":"2025-05-29","title":"Differentiable Singular Value Decomposition","abstract":"Singular value decomposition is widely used in modal analysis, such as proper orthogonal decomposition and resolvent analysis, to extract key features from complex problems. SVD derivatives need to be computed efficiently to enable the large scale design optimization. However, for a general complex matrix, no method can accurately compute this derivative to machine precision and remain scalable with respect to the number of design variables without requiring the all of the singular variables. We propose two algorithms to efficiently compute this derivative based on the adjoint method and reverse automatic differentiation and RAD-based singular value derivative formula. Differentiation results for each method proposed were compared with FD results for one square and one tall rectangular matrix example and matched with the FD results to about 5 to 7 digits. Finally, we demonstrate the scalability of the proposed method by calculating the derivatives of singular values with respect to the snapshot matrix derived from the POD of a large dataset for a laminar-turbulent transitional flow over a flat plate, sourced from the John Hopkins turbulence database.","authors":["Rohit Kanchi","Sicheng He"],"url":"https://arxiv.org/abs/2501.08522"}
{"created":"2025-05-29","title":"An Innovative Data-Driven and Adaptive Reinforcement Learning Approach for Context-Aware Prescriptive Process Monitoring","abstract":"The application of artificial intelligence and machine learning in business process management has advanced significantly, however, the full potential of these technologies remains largely unexplored, primarily due to challenges related to data quality and availability. We present a novel framework called Fine-Tuned Offline Reinforcement Learning Augmented Process Sequence Optimization (FORLAPS), which aims to identify optimal execution paths in business processes by leveraging reinforcement learning enhanced with a state-dependent reward shaping mechanism, thereby enabling context-sensitive prescriptions. Additionally, to compare FORLAPS with the existing models (Permutation Feature Importance and multi-task Long Short Term Memory model), we experimented to evaluate its effectiveness in terms of resource savings and process time reduction. The experimental results on real-life event logs validate that FORLAPS achieves 31% savings in resource time spent and a 23% reduction in process time span. To further enhance learning, we introduce an innovative process-aware data augmentation technique that selectively increases the average estimated Q-values in sampled batches, enabling automatic fine-tuning of the reinforcement learning model. Robustness was assessed through both prefix-level and trace-level evaluations, using the Damerau-Levenshtein distance as the primary metric. Finally, the model's adaptability across industries was further validated through diverse case studies, including healthcare treatment pathways, financial services workflows, permit applications from regulatory bodies, and operations management. In each domain, the proposed model demonstrated exceptional performance, outperforming existing state-of-the-art approaches in prescriptive decision-making, demonstrating its capability to prescribe optimal next steps and predict the best next activities within a process trace.","authors":["Mostafa Abbasi","Maziyar Khadivi","Maryam Ahang","Patricia Lasserre","Yves Lucet","Homayoun Najjaran"],"url":"https://arxiv.org/abs/2501.10543"}
{"created":"2025-05-29","title":"Kimi k1.5: Scaling Reinforcement Learning with LLMs","abstract":"Language model pretraining with next token prediction has proved effective for scaling compute but is limited to the amount of available training data. Scaling reinforcement learning (RL) unlocks a new axis for the continued improvement of artificial intelligence, with the promise that large language models (LLMs) can scale their training data by learning to explore with rewards. However, prior published work has not produced competitive results. In light of this, we report on the training practice of Kimi k1.5, our latest multi-modal LLM trained with RL, including its RL training techniques, multi-modal data recipes, and infrastructure optimization. Long context scaling and improved policy optimization methods are key ingredients of our approach, which establishes a simplistic, effective RL framework without relying on more complex techniques such as Monte Carlo tree search, value functions, and process reward models. Notably, our system achieves state-of-the-art reasoning performance across multiple benchmarks and modalities -- e.g., 77.5 on AIME, 96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista -- matching OpenAI's o1. Moreover, we present effective long2short methods that use long-CoT techniques to improve short-CoT models, yielding state-of-the-art short-CoT reasoning results -- e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on LiveCodeBench -- outperforming existing short-CoT models such as GPT-4o and Claude Sonnet 3.5 by a large margin (up to +550%).","authors":["Kimi Team","Angang Du","Bofei Gao","Bowei Xing","Changjiu Jiang","Cheng Chen","Cheng Li","Chenjun Xiao","Chenzhuang Du","Chonghua Liao","Chuning Tang","Congcong Wang","Dehao Zhang","Enming Yuan","Enzhe Lu","Fengxiang Tang","Flood Sung","Guangda Wei","Guokun Lai","Haiqing Guo","Han Zhu","Hao Ding","Hao Hu","Hao Yang","Hao Zhang","Haotian Yao","Haotian Zhao","Haoyu Lu","Haoze Li","Haozhen Yu","Hongcheng Gao","Huabin Zheng","Huan Yuan","Jia Chen","Jianhang Guo","Jianlin Su","Jianzhou Wang","Jie Zhao","Jin Zhang","Jingyuan Liu","Junjie Yan","Junyan Wu","Lidong Shi","Ling Ye","Longhui Yu","Mengnan Dong","Neo Zhang","Ningchen Ma","Qiwei Pan","Qucheng Gong","Shaowei Liu","Shengling Ma","Shupeng Wei","Sihan Cao","Siying Huang","Tao Jiang","Weihao Gao","Weimin Xiong","Weiran He","Weixiao Huang","Wenhao Wu","Wenyang He","Xianghui Wei","Xianqing Jia","Xingzhe Wu","Xinran Xu","Xinxing Zu","Xinyu Zhou","Xuehai Pan","Y. Charles","Yang Li","Yangyang Hu","Yangyang Liu","Yanru Chen","Yejie Wang","Yibo Liu","Yidao Qin","Yifeng Liu","Ying Yang","Yiping Bao","Yulun Du","Yuxin Wu","Yuzhi Wang","Zaida Zhou","Zhaoji Wang","Zhaowei Li","Zhen Zhu","Zheng Zhang","Zhexu Wang","Zhilin Yang","Zhiqi Huang","Zihao Huang","Ziyao Xu","Zonghan Yang","Zongyu Lin"],"url":"https://arxiv.org/abs/2501.12599"}
{"created":"2025-05-29","title":"K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor","abstract":"Retrieval-augmented question answering (QA) integrates external information and thereby increases the QA accuracy of reader models that lack domain knowledge. However, documents retrieved for closed domains require high expertise, so the reader model may have difficulty fully comprehending the text. Moreover, the retrieved documents contain thousands of tokens, some unrelated to the question. As a result, the documents include some inaccurate information, which could lead the reader model to mistrust the passages and could result in hallucinations. To solve these problems, we propose K-comp (Knowledge-injected compressor) which provides the knowledge required to answer correctly. The compressor automatically generates the prior knowledge necessary to facilitate the answer process prior to compression of the retrieved passages. Subsequently, the passages are compressed autoregressively, with the generated knowledge being integrated into the compression process. This process ensures alignment between the question intent and the compressed context. By augmenting this prior knowledge and concise context, the reader models are guided toward relevant answers and trust the context.","authors":["Jeonghun Cho","Gary Geunbae Lee"],"url":"https://arxiv.org/abs/2501.13567"}
{"created":"2025-05-29","title":"Redundancy Principles for MLLMs Benchmarks","abstract":"With the rapid iteration of Multi-modality Large Language Models (MLLMs) and the evolving demands of the field, the number of benchmarks produced annually has surged into the hundreds. The rapid growth has inevitably led to significant redundancy among benchmarks. Therefore, it is crucial to take a step back and critically assess the current state of redundancy and propose targeted principles for constructing effective MLLM benchmarks. In this paper, we focus on redundancy from three key perspectives: 1) Redundancy of benchmark capability dimensions, 2) Redundancy in the number of test questions, and 3) Cross-benchmark redundancy within specific domains. Through the comprehensive analysis over hundreds of MLLMs' performance across more than 20 benchmarks, we aim to quantitatively measure the level of redundancy lies in existing MLLM evaluations, provide valuable insights to guide the future development of MLLM benchmarks, and offer strategies to refine and address redundancy issues effectively. The code is available at https://github.com/zzc-1998/Benchmark-Redundancy.","authors":["Zicheng Zhang","Xiangyu Zhao","Xinyu Fang","Chunyi Li","Xiaohong Liu","Xiongkuo Min","Haodong Duan","Kai Chen","Guangtao Zhai"],"url":"https://arxiv.org/abs/2501.13953"}
{"created":"2025-05-29","title":"Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains","abstract":"Large Language Models (LLMs) are widely applied to downstream domains. However, current LLMs for high-stakes domain tasks, such as financial investment and legal QA, typically generate brief answers without reasoning processes and explanations. This limits users' confidence in making decisions based on their responses. While original CoT shows promise, it lacks self-correction mechanisms during reasoning. This work introduces Domain$o1$s, which enhances LLMs' reasoning capabilities on domain tasks through supervised fine-tuning and tree search. We construct CoT-stock-2k and CoT-legal-2k datasets for fine-tuning models that activate domain-specific reasoning steps based on their judgment. Additionally, we propose Selective Tree Exploration to spontaneously explore solution spaces and sample optimal reasoning paths to improve performance. We also introduce PROOF-Score, a new metric for evaluating domain models' explainability, complementing traditional accuracy metrics with richer assessment dimensions. Extensive experiments on stock investment recommendation and legal reasoning QA tasks demonstrate Domaino1s's leading performance and explainability. Our code is available at https://github.com/Hyalinesky/Domaino1s.","authors":["Xu Chu","Zhijie Tan","Hanlin Xue","Guanyu Wang","Tong Mo","Weiping Li"],"url":"https://arxiv.org/abs/2501.14431"}
{"created":"2025-05-29","title":"Can Large Language Models Be Trusted as Evolutionary Optimizers for Network-Structured Combinatorial Problems?","abstract":"Large Language Models (LLMs) have shown impressive capabilities in language understanding and reasoning across diverse domains. Recently, there has been increasing interests in utilizing LLMs not merely as assistants in optimization tasks, but as active optimizers, particularly for network-structured combinatorial problems. However, before LLMs can be reliably deployed in this role, a fundamental question must be addressed: Can LLMs iteratively manipulate solutions that consistently adhere to problem constraints? In this work, we propose a systematic framework to evaluate the capacity of LLMs to engage with problem structures. Rather than treating the model as a black-box generator, we adopt the commonly used evolutionary operators as optimizer and propose a comprehensive evaluation framework that rigorously assesses the output fidelity of LLM-generated operators across different stages of the evolutionary process. To enhance robustness, we introduce a hybrid error-correction mechanism that mitigates uncertainty in LLM outputs. Moreover, we develop a cost-efficient population-level optimization strategy that significantly improves efficiency compared to traditional individual-level approaches. Extensive experiments on a representative node-level combinatorial network optimization task demonstrate the effectiveness, adaptability, and inherent limitations of LLM-based operators. Our findings offer new perspectives on the integration of LLMs into evolutionary computation, providing practical insights for scalable optimization in networked systems.","authors":["Jie Zhao","Tao Wen","Kang Hao Cheong"],"url":"https://arxiv.org/abs/2501.15081"}
{"created":"2025-05-29","title":"Efficient Logit-based Knowledge Distillation of Deep Spiking Neural Networks for Full-Range Timestep Deployment","abstract":"Spiking Neural Networks (SNNs) are emerging as a brain-inspired alternative to traditional Artificial Neural Networks (ANNs), prized for their potential energy efficiency on neuromorphic hardware. Despite this, SNNs often suffer from accuracy degradation compared to ANNs and face deployment challenges due to fixed inference timesteps, which require retraining for adjustments, limiting operational flexibility. To address these issues, our work considers the spatio-temporal property inherent in SNNs, and proposes a novel distillation framework for deep SNNs that optimizes performance across full-range timesteps without specific retraining, enhancing both efficacy and deployment adaptability. We provide both theoretical analysis and empirical validations to illustrate that training guarantees the convergence of all implicit models across full-range timesteps. Experimental results on CIFAR-10, CIFAR-100, CIFAR10-DVS, and ImageNet demonstrate state-of-the-art performance among distillation-based SNNs training methods. Our code is available at https://github.com/Intelli-Chip-Lab/snn\\_temporal\\_decoupling\\_distillation.","authors":["Chengting Yu","Xiaochen Zhao","Lei Liu","Shu Yang","Gaoang Wang","Erping Li","Aili Wang"],"url":"https://arxiv.org/abs/2501.15925"}
{"created":"2025-05-29","title":"Training Dynamics of In-Context Learning in Linear Attention","abstract":"While attention-based models have demonstrated the remarkable ability of in-context learning (ICL), the theoretical understanding of how these models acquired this ability through gradient descent training is still preliminary. Towards answering this question, we study the gradient descent dynamics of multi-head linear self-attention trained for in-context linear regression. We examine two parametrizations of linear self-attention: one with the key and query weights merged as a single matrix (common in theoretical studies), and one with separate key and query matrices (closer to practical settings). For the merged parametrization, we show that the training dynamics has two fixed points and the loss trajectory exhibits a single, abrupt drop. We derive an analytical time-course solution for a certain class of datasets and initialization. For the separate parametrization, we show that the training dynamics has exponentially many fixed points and the loss exhibits saddle-to-saddle dynamics, which we reduce to scalar ordinary differential equations. During training, the model implements principal component regression in context with the number of principal components increasing over training time. Overall, we provide a theoretical description of how ICL abilities evolve during gradient descent training of linear attention, revealing abrupt acquisition or progressive improvements depending on how the key and query are parametrized.","authors":["Yedi Zhang","Aaditya K. Singh","Peter E. Latham","Andrew Saxe"],"url":"https://arxiv.org/abs/2501.16265"}
{"created":"2025-05-29","title":"Risk-Informed Diffusion Transformer for Long-Tail Trajectory Prediction in the Crash Scenario","abstract":"Trajectory prediction methods have been widely applied in autonomous driving technologies. Although the overall performance accuracy of trajectory prediction is relatively high, the lack of trajectory data in critical scenarios in the training data leads to the long-tail phenomenon. Normally, the trajectories of the tail data are more critical and more difficult to predict and may include rare scenarios such as crashes. To solve this problem, we extracted the trajectory data from real-world crash scenarios, which contain more long-tail data. Meanwhile, based on the trajectory data in this scenario, we integrated graph-based risk information and diffusion with transformer and proposed the Risk-Informed Diffusion Transformer (RI-DiT) trajectory prediction method. Extensive experiments were conducted on trajectory data in the real-world crash scenario, and the results show that the algorithm we proposed has good performance. When predicting the data of the tail 10\\% (Top 10\\%), the minADE and minFDE indicators are 0.016/2.667 m. At the same time, we showed the trajectory conditions of different long-tail distributions. The distribution of trajectory data is closer to the tail, the less smooth the trajectory is. Through the trajectory data in real-world crash scenarios, Our work expands the methods to overcome the long-tail challenges in trajectory prediction. Our method, RI-DiT, integrates inverse time to collision (ITTC) and the feature of traffic flow, which can predict long-tail trajectories more accurately and improve the safety of autonomous driving systems.","authors":["Junlan Chen","Pei Liu","Zihao Zhang","Hongyi Zhao","Yufei Ji","Ziyuan Pu"],"url":"https://arxiv.org/abs/2501.16349"}
{"created":"2025-05-29","title":"A Variational Perspective on Generative Protein Fitness Optimization","abstract":"The goal of protein fitness optimization is to discover new protein variants with enhanced fitness for a given use. The vast search space and the sparsely populated fitness landscape, along with the discrete nature of protein sequences, pose significant challenges when trying to determine the gradient towards configurations with higher fitness. We introduce Variational Latent Generative Protein Optimization (VLGPO), a variational perspective on fitness optimization. Our method embeds protein sequences in a continuous latent space to enable efficient sampling from the fitness distribution and combines a (learned) flow matching prior over sequence mutations with a fitness predictor to guide optimization towards sequences with high fitness. VLGPO achieves state-of-the-art results on two different protein benchmarks of varying complexity. Moreover, the variational design with explicit prior and likelihood functions offers a flexible plug-and-play framework that can be easily customized to suit various protein design tasks.","authors":["Lea Bogensperger","Dominik Narnhofer","Ahmed Allam","Konrad Schindler","Michael Krauthammer"],"url":"https://arxiv.org/abs/2501.19200"}
{"created":"2025-05-29","title":"MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems","abstract":"While large language models (LLMs) have shown promising capabilities as zero-shot planners for embodied agents, their inability to learn from experience and build persistent mental models limits their robustness in complex open-world environments like Minecraft. We introduce MINDSTORES, an experience-augmented planning framework that enables embodied agents to build and leverage mental models through natural interaction with their environment. Drawing inspiration from how humans construct and refine cognitive mental models, our approach extends existing zero-shot LLM planning by maintaining a database of past experiences that informs future planning iterations. The key innovation is representing accumulated experiences as natural language embeddings of (state, task, plan, outcome) tuples, which can then be efficiently retrieved and reasoned over by an LLM planner to generate insights and guide plan refinement for novel states and tasks. Through extensive experiments in the MineDojo environment, a simulation environment for agents in Minecraft that provides low-level controls for Minecraft, we find that MINDSTORES learns and applies its knowledge significantly better than existing memory-based LLM planners while maintaining the flexibility and generalization benefits of zero-shot approaches, representing an important step toward more capable embodied AI systems that can learn continuously through natural experience.","authors":["Anirudh Chari","Suraj Reddy","Aditya Tiwari","Richard Lian","Brian Zhou"],"url":"https://arxiv.org/abs/2501.19318"}
{"created":"2025-05-29","title":"PUATE: Efficient Average Treatment Effect Estimation from Treated (Positive) and Unlabeled Units","abstract":"The estimation of average treatment effects (ATEs), defined as the difference in expected outcomes between treatment and control groups, is a central topic in causal inference. This study develops semiparametric efficient estimators for ATE in a setting where only a treatment group and an unlabeled group, consisting of units whose treatment status is unknown, are observed. This scenario constitutes a variant of learning from positive and unlabeled data (PU learning) and can be viewed as a special case of ATE estimation with missing data. For this setting, we derive the semiparametric efficiency bounds, which characterize the lowest achievable asymptotic variance for regular estimators. We then construct semiparametric efficient ATE estimators that attain these bounds. Our results contribute to the literature on causal inference with missing data and weakly supervised learning.","authors":["Masahiro Kato","Fumiaki Kozai","Ryo Inokuchi"],"url":"https://arxiv.org/abs/2501.19345"}
{"created":"2025-05-29","title":"A Checks-and-Balances Framework for Context-Aware Ethical AI Alignment","abstract":"This paper introduces a checks-and-balances framework for ethical alignment of Large Language Models (LLMs), inspired by three-branch governmental systems. It implements three independent yet interacting components: LLMs as the executive branch for knowledge generation, DIKE as the legislative branch establishing ethical guardrails, and ERIS as the judicial branch for contextual interpretation. Beyond structural separation, we address a fundamental challenge: regulating emotion to shape behaviors. Drawing from psychological theories where managing emotional responses prevents harmful behaviors, we develop a self-supervised learning pipeline that maps emotions to linguistic behaviors, enabling precise behavioral modulation through emotional conditioning. By integrating this approach with adversarial testing, our framework demonstrates how DIKE and ERIS direct linguistic behaviors toward ethical outcomes while preserving independence throughout knowledge generation, ethical oversight, and contextual interpretation.","authors":["Edward Y. Chang"],"url":"https://arxiv.org/abs/2502.00136"}
{"created":"2025-05-29","title":"Efficient Online Reinforcement Learning for Diffusion Policy","abstract":"Diffusion policies have achieved superior performance in imitation learning and offline reinforcement learning (RL) due to their rich expressiveness. However, the conventional diffusion training procedure requires samples from target distribution, which is impossible in online RL since we cannot sample from the optimal policy. Backpropagating policy gradient through the diffusion process incurs huge computational costs and instability, thus being expensive and not scalable. To enable efficient training of diffusion policies in online RL, we generalize the conventional denoising score matching by reweighting the loss function. The resulting Reweighted Score Matching (RSM) preserves the optimal solution and low computational cost of denoising score matching, while eliminating the need to sample from the target distribution and allowing learning to optimize value functions. We introduce two tractable reweighted loss functions to solve two commonly used policy optimization problems, policy mirror descent and max-entropy policy, resulting in two practical algorithms named Diffusion Policy Mirror Descent (DPMD) and Soft Diffusion Actor-Critic (SDAC). We conducted comprehensive comparisons on MuJoCo benchmarks. The empirical results show that the proposed algorithms outperform recent diffusion-policy online RLs on most tasks, and the DPMD improves more than 120% over soft actor-critic on Humanoid and Ant.","authors":["Haitong Ma","Tianyi Chen","Kai Wang","Na Li","Bo Dai"],"url":"https://arxiv.org/abs/2502.00361"}
{"created":"2025-05-29","title":"Complex Wavelet Mutual Information Loss: A Multi-Scale Loss Function for Semantic Segmentation","abstract":"Recent advancements in deep neural networks have significantly enhanced the performance of semantic segmentation. However, class imbalance and instance imbalance remain persistent challenges, where smaller instances and thin boundaries are often overshadowed by larger structures. To address the multiscale nature of segmented objects, various models have incorporated mechanisms such as spatial attention and feature pyramid networks. Despite these advancements, most loss functions are still primarily pixel-wise, while regional and boundary-focused loss functions often incur high computational costs or are restricted to small-scale regions. To address this limitation, we propose the complex wavelet mutual information (CWMI) loss, a novel loss function that leverages mutual information from subband images decomposed by a complex steerable pyramid. The complex steerable pyramid captures features across multiple orientations and preserves structural similarity across scales. Meanwhile, mutual information is well-suited to capturing high-dimensional directional features and offers greater noise robustness. Extensive experiments on diverse segmentation datasets demonstrate that CWMI loss achieves significant improvements in both pixel-wise accuracy and topological metrics compared to state-of-the-art methods, while introducing minimal computational overhead. Our code is available at https://github.com/lurenhaothu/CWMI","authors":["Renhao Lu"],"url":"https://arxiv.org/abs/2502.00563"}
{"created":"2025-05-29","title":"Mitigating Heterogeneous Token Overfitting in LLM Knowledge Editing","abstract":"Large language models (LLMs) have achieved remarkable performance on various natural language tasks. However, they are trained on static corpora and their knowledge can become outdated quickly in the fast-changing world. This motivates the development of knowledge editing (KE) to update specific knowledge in LLMs without changing unrelated others or compromising their pre-trained capabilities. Previous efforts sought to update a small amount of parameters of a LLM and proved effective for making selective updates. Nonetheless, the edited LLM often exhibits degraded ability to reason about the new knowledge. In this work, we identify a key issue: heterogeneous token overfitting (HTO), where the LLM overfits different tokens in the provided knowledge at varying rates. To tackle this, we propose OVERTONE, a token-level smoothing method that mitigates HTO by adaptively refining the target distribution. Theoretically, OVERTONE offers better parameter updates with negligible computation overhead. It also induces an implicit DPO but does not require preference data pairs. Extensive experiments across four editing methods, two LLMs, and diverse scenarios demonstrate the effectiveness and versatility of our method.","authors":["Tianci Liu","Ruirui Li","Zihan Dong","Hui Liu","Xianfeng Tang","Qingyu Yin","Linjun Zhang","Haoyu Wang","Jing Gao"],"url":"https://arxiv.org/abs/2502.00602"}
{"created":"2025-05-29","title":"Hypo3D: Exploring Hypothetical Reasoning in 3D","abstract":"The rise of vision-language foundation models marks an advancement in bridging the gap between human and machine capabilities in 3D scene reasoning. Existing 3D reasoning benchmarks assume real-time scene accessibility, which is impractical due to the high cost of frequent scene updates. To this end, we introduce Hypothetical 3D Reasoning, namely Hypo3D, a benchmark designed to evaluate models' ability to reason without access to real-time scene data. Models need to imagine the scene state based on a provided change description before reasoning. Hypo3D is formulated as a 3D Visual Question Answering (VQA) benchmark, comprising 7,727 context changes across 700 indoor scenes, resulting in 14,885 question-answer pairs. An anchor-based world frame is established for all scenes, ensuring consistent reference to a global frame for directional terms in context changes and QAs. Extensive experiments show that state-of-the-art foundation models struggle to reason in hypothetically changed scenes. This reveals a substantial performance gap compared to humans, particularly in scenarios involving movement changes and directional reasoning. Even when the context change is irrelevant to the question, models often incorrectly adjust their answers. Project website: https://matchlab-imperial.github.io/Hypo3D/","authors":["Ye Mao","Weixun Luo","Junpeng Jing","Anlan Qiu","Krystian Mikolajczyk"],"url":"https://arxiv.org/abs/2502.00954"}
{"created":"2025-05-29","title":"Message-Passing GNNs Fail to Approximate Sparse Triangular Factorizations","abstract":"Graph Neural Networks (GNNs) have been proposed as a tool for learning sparse matrix preconditioners, which are key components in accelerating linear solvers. This position paper argues that message-passing GNNs are fundamentally incapable of approximating sparse triangular factorizations. We demonstrate that message-passing GNNs fundamentally fail to approximate sparse triangular factorizations for classes of matrices for which high-quality preconditioners exist but require non-local dependencies. To illustrate this, we construct a set of baselines using both synthetic matrices and real-world examples from the SuiteSparse collection. Across a range of GNN architectures, including Graph Attention Networks and Graph Transformers, we observe severe performance degradation compared to exact or K-optimal factorizations, with cosine similarity dropping below $0.6$ in key cases. Our theoretical and empirical results suggest that architectural innovations beyond message-passing are necessary for applying GNNs to scientific computing tasks such as matrix factorization. Experiments demonstrate that overcoming non-locality alone is insufficient. Tailored architectures are necessary to capture the required dependencies since even a completely non-local Graph Transformer fails to match the proposed baselines.","authors":["Vladislav Trifonov","Ekaterina Muravleva","Ivan Oseledets"],"url":"https://arxiv.org/abs/2502.01397"}
{"created":"2025-05-29","title":"Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints Internalization","abstract":"As the general capabilities of artificial intelligence (AI) agents continue to evolve, their ability to learn to master multiple complex tasks through experience remains a key challenge. Current LLM agents, particularly those based on proprietary language models, typically rely on prompts to incorporate knowledge about the target tasks. This approach does not allow the agent to internalize this information and instead relies on ever-expanding prompts to sustain its functionality in diverse scenarios. This resembles a system of notes used by a person affected by anterograde amnesia, the inability to form new memories. In this paper, we propose a novel method to train AI agents to incorporate knowledge and skills for multiple tasks without the need for either cumbersome note systems or prior high-quality demonstration data. Our approach employs an iterative process where the agent collects new experiences, receives corrective feedback from humans in the form of hints, and integrates this feedback into its weights via a context distillation training procedure. We demonstrate the efficacy of our approach by implementing it in a Llama-3-based agent that, after only a few rounds of feedback, outperforms advanced models GPT-4o and DeepSeek-V3 in tasksets requiring correct sequencing of information retrieval, tool use, and question answering.","authors":["Minttu Alakuijala","Ya Gao","Georgy Ananov","Samuel Kaski","Pekka Marttinen","Alexander Ilin","Harri Valpola"],"url":"https://arxiv.org/abs/2502.01562"}
{"created":"2025-05-29","title":"Improving Rule-based Reasoning in LLMs using Neurosymbolic Representations","abstract":"Large language models (LLMs) continue to face challenges in reliably solving reasoning tasks, particularly those that require precise rule following, as often found in mathematical reasoning. This paper introduces a novel neurosymbolic method that improves LLM reasoning by encoding hidden states into neurosymbolic vectors, enabling problem-solving within a neurosymbolic vector space. The results are decoded and merged with the original hidden state, significantly boosting the model's performance on numerical reasoning tasks. By offloading computation through neurosymbolic representations, this method enhances efficiency, reliability, and interpretability. Experimental results demonstrate an average of 88.6% lower cross-entropy loss and 15.4 times more problems correctly solved on a suite of mathematical reasoning tasks compared to chain-of-thought prompting and supervised fine-tuning (LoRA), without degrading performance on other tasks. We make our code available at: https://github.com/vdhanraj/Neurosymbolic-LLM.","authors":["Varun Dhanraj","Chris Eliasmith"],"url":"https://arxiv.org/abs/2502.01657"}
{"created":"2025-05-29","title":"Robust LLM Alignment via Distributionally Robust Direct Preference Optimization","abstract":"A major challenge in aligning large language models (LLMs) with human preferences is the issue of distribution shift. LLM alignment algorithms rely on static preference datasets, assuming that they accurately represent real-world user preferences. However, user preferences vary significantly across geographical regions, demographics, linguistic patterns, and evolving cultural trends. This preference distribution shift leads to catastrophic alignment failures in many real-world applications. We address this problem using the principled framework of distributionally robust optimization, and develop two novel distributionally robust direct preference optimization (DPO) algorithms, namely, Wasserstein DPO (WDPO) and Kullback-Leibler DPO (KLDPO). We characterize the sample complexity of learning the optimal policy parameters for WDPO and KLDPO. Moreover, we propose scalable gradient descent-style learning algorithms by developing suitable approximations for the challenging minimax loss functions of WDPO and KLDPO. Our empirical experiments using benchmark data sets and LLMs demonstrate the superior performance of WDPO and KLDPO in substantially improving the alignment when there is a preference distribution shift.","authors":["Zaiyan Xu","Sushil Vemuri","Kishan Panaganti","Dileep Kalathil","Rahul Jain","Deepak Ramachandran"],"url":"https://arxiv.org/abs/2502.01930"}
{"created":"2025-05-29","title":"BILBO: BILevel Bayesian Optimization","abstract":"Bilevel optimization is characterized by a two-level optimization structure, where the upper-level problem is constrained by optimal lower-level solutions, and such structures are prevalent in real-world problems. The constraint by optimal lower-level solutions poses significant challenges, especially in noisy, constrained, and derivative-free settings, as repeating lower-level optimizations is sample inefficient and predicted lower-level solutions may be suboptimal. We present BILevel Bayesian Optimization (BILBO), a novel Bayesian optimization algorithm for general bilevel problems with blackbox functions, which optimizes both upper- and lower-level problems simultaneously, without the repeated lower-level optimization required by existing methods. BILBO samples from confidence-bounds based trusted sets, which bounds the suboptimality on the lower level. Moreover, BILBO selects only one function query per iteration, where the function query selection strategy incorporates the uncertainty of estimated lower-level solutions and includes a conditional reassignment of the query to encourage exploration of the lower-level objective. The performance of BILBO is theoretically guaranteed with a sublinear regret bound for commonly used kernels and is empirically evaluated on several synthetic and real-world problems.","authors":["Ruth Wan Theng Chew","Quoc Phong Nguyen","Bryan Kian Hsiang Low"],"url":"https://arxiv.org/abs/2502.02121"}
{"created":"2025-05-29","title":"Broadcast in Almost Mixing Time","abstract":"We study the problem of broadcasting multiple messages in the CONGEST model. In this problem, a dedicated source node $s$ possesses a set $M$ of messages with every message of size $O(\\log n)$ where $n$ is the total number of nodes. The objective is to ensure that every node in the network learns all messages in $M$. The execution of an algorithm progresses in rounds, and we focus on optimizing the round complexity of broadcasting multiple messages.","authors":["Anton Paramonov","Roger Wattenhofer"],"url":"https://arxiv.org/abs/2502.02165"}
{"created":"2025-05-29","title":"LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models","abstract":"Cross-attention is commonly adopted in multimodal large language models (MLLMs) for integrating visual information into the language backbone. However, in applications with large visual inputs, such as video understanding, processing a large number of visual tokens in cross-attention layers leads to high memory demands and often necessitates distributed computation across multiple GPUs. Existing distributed attention mechanisms face significant communication overheads, making cross-attention layers a critical bottleneck for efficient training and inference of MLLMs. To address this, we propose LV-XAttn, a distributed, exact cross-attention mechanism with minimal communication overhead. We observe that in applications involving large visual inputs, the size of the query block is typically much smaller than that of the key-value blocks. Thus, in LV-XAttn we keep the large key-value blocks locally on each GPU and exchange smaller query blocks across GPUs. We also introduce an efficient activation recomputation technique to support longer visual context. We theoretically analyze the communication benefits of LV-XAttn and show that it can achieve speedups for a wide range of models. Our evaluations with Llama 3-V, mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to 10.62$\\times$ end-to-end speedup compared to existing approaches.","authors":["Tzu-Tao Chang","Shivaram Venkataraman"],"url":"https://arxiv.org/abs/2502.02406"}
{"created":"2025-05-29","title":"ReGNet: Reciprocal Space-Aware Long-Range Modeling for Crystalline Property Prediction","abstract":"Predicting properties of crystals from their structures is a fundamental yet challenging task in materials science. Unlike molecules, crystal structures exhibit infinite periodic arrangements of atoms, requiring methods capable of capturing both local and global information effectively. However, most current works fall short of capturing long-range interactions within periodic structures. To address this limitation, we leverage \\emph{reciprocal space} to efficiently encode long-range interactions with learnable filters within Fourier transforms. We introduce Reciprocal Geometry Network (ReGNet), a novel architecture that integrates geometric GNNs and reciprocal blocks to model short-range and long-range interactions, respectively. Experimental results on JARVIS, Materials Project, and MatBench demonstrate that ReGNet achieves state-of-the-art predictive accuracy across a range of crystal property prediction tasks. Additionally, we explore a model extension that employs the mixture-of-experts for multi-property prediction with promising results and high computational efficiency. These findings highlight the potential of our model as a scalable and accurate solution for crystal property prediction. The code will be released upon paper acceptance.","authors":["Jianan Nie","Peiyao Xiao","Kaiyi Ji","Peng Gao"],"url":"https://arxiv.org/abs/2502.02748"}
{"created":"2025-05-29","title":"Robust Reward Alignment via Hypothesis Space Batch Cutting","abstract":"Reward design in reinforcement learning and optimal control is challenging. Preference-based alignment addresses this by enabling agents to learn rewards from ranked trajectory pairs provided by humans. However, existing methods often struggle from poor robustness to unknown false human preferences. In this work, we propose a robust and efficient reward alignment method based on a novel and geometrically interpretable perspective: hypothesis space batched cutting. Our method iteratively refines the reward hypothesis space through \"cuts\" based on batches of human preferences. Within each batch, human preferences, queried based on disagreement, are grouped using a voting function to determine the appropriate cut, ensuring a bounded human query complexity. To handle unknown erroneous preferences, we introduce a conservative cutting method within each batch, preventing erroneous human preferences from making overly aggressive cuts to the hypothesis space. This guarantees provable robustness against false preferences, while eliminating the need to explicitly identify them. We evaluate our method in a model predictive control setting across diverse tasks. The results demonstrate that our framework achieves comparable or superior performance to state-of-the-art methods in error-free settings while significantly outperforming existing methods when handling a high percentage of erroneous human preferences.","authors":["Zhixian Xie","Haode Zhang","Yizhe Feng","Wanxin Jin"],"url":"https://arxiv.org/abs/2502.02921"}
{"created":"2025-05-29","title":"Gait-Net-augmented Implicit Kino-dynamic MPC for Dynamic Variable-frequency Humanoid Locomotion over Discrete Terrains","abstract":"Reduced-order-model-based optimal control techniques for humanoid locomotion struggle to adapt step duration and placement simultaneously in dynamic walking gaits due to their reliance on fixed-time discretization, which limits responsiveness to various disturbances and results in suboptimal performance in challenging conditions. In this work, we propose a Gait-Net-augmented implicit kino-dynamic model-predictive control (MPC) to simultaneously optimize step location, step duration, and contact forces for natural variable-frequency locomotion. The proposed method incorporates a Gait-Net-augmented Sequential Convex MPC algorithm to solve multi-linearly constrained variables by iterative quadratic programs. At its core, a lightweight Gait-frequency Network (Gait-Net) determines the preferred step duration in terms of variable MPC sampling times, simplifying step duration optimization to the parameter level. Additionally, it enhances and updates the spatial reference trajectory within each sequential iteration by incorporating local solutions, allowing the projection of kinematic constraints to the design of reference trajectories. We validate the proposed algorithm in high-fidelity simulations and on small-size humanoid hardware, demonstrating its capability for variable-frequency and 3-D discrete terrain locomotion with only a one-step preview of terrain data.","authors":["Junheng Li","Ziwei Duan","Junchao Ma","Quan Nguyen"],"url":"https://arxiv.org/abs/2502.02934"}
{"created":"2025-05-29","title":"Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators","abstract":"Fire safety is crucial for ensuring the stability of building structures, yet evaluating whether a structure meets fire safety requirement is challenging. Fires can originate at any point within a structure, and simulating every potential fire scenario is both expensive and time-consuming. To address this challenge, we propose the concept of the Most Fire-Sensitive Point (MFSP) and an efficient machine learning framework for its identification. The MFSP is defined as the location at which a fire, if initiated, would cause the most severe detrimental impact on the building's stability, effectively representing the worst-case fire scenario. In our framework, a Graph Neural Network (GNN) serves as an efficient and differentiable agent for conventional Finite Element Analysis (FEA) simulators by predicting the Maximum Interstory Drift Ratio (MIDR) under fire, which then guides the training and evaluation of the MFSP predictor. Additionally, we enhance our framework with a novel edge update mechanism and a transfer learning-based training scheme. Evaluations on a large-scale simulation dataset demonstrate the good performance of the proposed framework in identifying the MFSP, offering a transformative tool for optimizing fire safety assessments in structural design. All developed datasets and codes are open-sourced online.","authors":["Yuan Xinjie","Khalid M. Mosalam"],"url":"https://arxiv.org/abs/2502.03424"}
{"created":"2025-05-29","title":"Path Planning for Masked Diffusion Model Sampling","abstract":"Any order generation of discrete data using masked diffusion models (MDMs) offers a compelling alternative to traditional autoregressive models, especially in domains that lack a natural causal ordering of data. However, current popular MDMs depart from their successful continuous diffusion model counterparts with simplified masked inference wherein unmasked tokens cannot be iteratively refined -- even if there is a mistake. In this paper, we extract the full power of MDMs by introducing a novel inference sampling strategy termed Path Planning (P2) that decomposes each generation step into two sub-stages: planning and denoising. Under P2, the planner at every step selects appropriate tokens that are marked to be updated, which can then be sampled using the denoiser. We demonstrate that P2 generalizes all existing sampling strategies for MDMs and critically enhances generative quality through the new capability of refining and updating existing unmasked tokens. We theoretically prove that P2 establishes a (new) expanded evidence lower bound (ELBO) on the log marginal likelihood of data. We instantiate P2 with a family of planners including: 1.) Self-Planning, 2.) BERT-Planning, and 3.) Trained-Planning with a learned planner leading to SOTA generative performance for MDMs on a suite of domains. Specifically, solely using P2 inference, we observe relative improvements of 22% in protein sequence foldability, 8% in RNA sequence pLDDT, 4% in math reasoning, 68% in story generation (ROUGE score), and 33% in code generation for the challenging pass@1 metric.","authors":["Fred Zhangzhi Peng","Zachary Bezemek","Sawan Patel","Jarrid Rector-Brooks","Sherwood Yao","Avishek Joey Bose","Alexander Tong","Pranam Chatterjee"],"url":"https://arxiv.org/abs/2502.03540"}
{"created":"2025-05-29","title":"Fast Geographic Routing in Fixed-Growth Graphs","abstract":"In the 1960s, the social scientist Stanley Milgram performed his famous \"small-world\" experiments where he found that people in the US who are far apart geographically are nevertheless connected by remarkably short chains of acquaintances. Since then, there has been considerable work to design networks that accurately model the phenomenon that Milgram observed. One well-known approach was Barab{\\'a}si and Albert's preferential attachment model, which has small diameter yet lacks an algorithm that can efficiently find those short connections between nodes. Jon Kleinberg, in contrast, proposed a small-world graph formed from an $n \\times n$ lattice that guarantees that greedy routing can navigate between any two nodes in $\\mathcal{O}(\\log^2 n)$ time with high probability. Further work by Goodrich and Ozel and by Gila, Goodrich, and Ozel present a hybrid technique that combines elements from these previous approaches to improve greedy routing time to $\\mathcal{O}(\\log n)$ hops. These are important theoretical results, but we believe that their reliance on the square lattice limits their application in the real world. In this work, we generalize the model of Gila, Ozel, and Goodrich to any class of what we call fixed-growth graphs of dimensionality $\\alpha$, a subset of bounded-growth graphs introduced in several prior papers. We prove tight bounds for greedy routing and diameter in these graphs, both in expectation and with high probability. We then apply our model to the U.S. road network to show that by modeling the network as a fixed-growth graph rather than as a lattice, we are able to improve greedy routing performance over all 50 states. We also show empirically that the optimal clustering exponent for the U.S. road network is much better modeled by the dimensionality of the network $\\alpha$ than by the network's size, as was conjectured in a previous work.","authors":["Ofek Gila","Michael T. Goodrich","Abraham M. Illickan","Vinesh Sridhar"],"url":"https://arxiv.org/abs/2502.03663"}
{"created":"2025-05-29","title":"Advancing Reasoning in Large Language Models: Promising Methods and Approaches","abstract":"Large Language Models (LLMs) have succeeded remarkably in various natural language processing (NLP) tasks, yet their reasoning capabilities remain a fundamental challenge. While LLMs exhibit impressive fluency and factual recall, their ability to perform complex reasoning-spanning logical deduction, mathematical problem-solving, commonsense inference, and multi-step reasoning-often falls short of human expectations. This survey provides a comprehensive review of emerging techniques enhancing reasoning in LLMs. We categorize existing methods into key approaches, including prompting strategies (e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought reasoning), architectural innovations (e.g., retrieval-augmented models, modular reasoning networks, and neuro-symbolic integration), and learning paradigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement learning, and self-supervised reasoning objectives). Additionally, we explore evaluation frameworks used to assess reasoning in LLMs and highlight open challenges, such as hallucinations, robustness, and reasoning generalization across diverse tasks. By synthesizing recent advancements, this survey aims to provide insights into promising directions for future research and practical applications of reasoning-augmented LLMs.","authors":["Avinash Patil","Aryan Jadon"],"url":"https://arxiv.org/abs/2502.03671"}
{"created":"2025-05-29","title":"ExpProof : Operationalizing Explanations for Confidential Models with ZKPs","abstract":"In principle, explanations are intended as a way to increase trust in machine learning models and are often obligated by regulations. However, many circumstances where these are demanded are adversarial in nature, meaning the involved parties have misaligned interests and are incentivized to manipulate explanations for their purpose. As a result, explainability methods fail to be operational in such settings despite the demand \\cite{bordt2022post}. In this paper, we take a step towards operationalizing explanations in adversarial scenarios with Zero-Knowledge Proofs (ZKPs), a cryptographic primitive. Specifically we explore ZKP-amenable versions of the popular explainability algorithm LIME and evaluate their performance on Neural Networks and Random Forests. Our code is publicly available at https://github.com/emlaufer/ExpProof.","authors":["Chhavi Yadav","Evan Monroe Laufer","Dan Boneh","Kamalika Chaudhuri"],"url":"https://arxiv.org/abs/2502.03773"}
{"created":"2025-05-29","title":"Explanation Design in Strategic Learning: Sufficient Explanations that Induce Non-harmful Responses","abstract":"We study explanation design in algorithmic decision making with strategic agents, individuals who may modify their inputs in response to explanations of a decision maker's (DM's) predictive model. As the demand for transparent algorithmic systems continues to grow, most prior work assumes full model disclosure as the default solution. In practice, however, DMs such as financial institutions typically disclose only partial model information via explanations. Such partial disclosure can lead agents to misinterpret the model and take actions that unknowingly harm their utility. A key open question is how DMs can communicate explanations in a way that avoids harming strategic agents, while still supporting their own decision-making goals, e.g., minimising predictive error. In this work, we analyse well-known explanation methods, and establish a necessary condition to prevent explanations from misleading agents into self-harming actions. Moreover, with a conditional homogeneity assumption, we prove that action recommendation-based explanations (ARexes) are sufficient for non-harmful responses, mirroring the revelation principle in information design. To demonstrate how ARexes can be operationalised in practice, we propose a simple learning procedure that jointly optimises the predictive model and explanation policy. Experiments on synthetic and real-world tasks show that ARexes allow the DM to optimise their model's predictive performance while preserving agents' utility, offering a more refined strategy for safe and effective partial model disclosure.","authors":["Kiet Q. H. Vo","Siu Lun Chau","Masahiro Kato","Yixin Wang","Krikamol Muandet"],"url":"https://arxiv.org/abs/2502.04058"}
{"created":"2025-05-29","title":"Beyond External Monitors: Enhancing Transparency of Large Language Models for Easier Monitoring","abstract":"Large language models (LLMs) are becoming increasingly capable, but the mechanisms of their thinking and decision-making process remain unclear. Chain-of-thoughts (CoTs) have been commonly utilized to monitor LLMs, but this strategy fails to accurately reflect LLMs' thinking process. Techniques based on LLMs' hidden representations provide an inner perspective to monitor their latent thinking. However, previous methods only try to develop external monitors instead of making LLMs themselves easier to monitor. In this paper, we propose a novel method TELLME, improving the transparency of LLMs and helping monitors identify unsuitable and sensitive behaviors. Furthermore, we showcase the applications of TELLME on trustworthiness tasks (\\eg, safety risks monitoring tasks and detoxification tasks), where LLMs achieve consistent improvement in transparency and task performance. More crucially, we theoretically analyze the improvement of TELLME on LLMs' generalization ability through optimal transport theory.","authors":["Guanxu Chen","Dongrui Liu","Tao Luo","Lijie Hu","Jing Shao"],"url":"https://arxiv.org/abs/2502.05242"}
{"created":"2025-05-29","title":"UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control","abstract":"Recent advances in diffusion bridge models leverage Doob's $h$-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob's $h$-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework. Our code is available at https://github.com/UniDB-SOC/UniDB/.","authors":["Kaizhen Zhu","Mokai Pan","Yuexin Ma","Yanwei Fu","Jingyi Yu","Jingya Wang","Ye Shi"],"url":"https://arxiv.org/abs/2502.05749"}
{"created":"2025-05-29","title":"Devil is in the Details: Density Guidance for Detail-Aware Generation with Flow Models","abstract":"Diffusion models have emerged as a powerful class of generative models, capable of producing high-quality images by mapping noise to a data distribution. However, recent findings suggest that image likelihood does not align with perceptual quality: high-likelihood samples tend to be smooth, while lower-likelihood ones are more detailed. Controlling sample density is thus crucial for balancing realism and detail. In this paper, we analyze an existing technique, Prior Guidance, which scales the latent code to influence image detail. We introduce score alignment, a condition that explains why this method works and show that it can be tractably checked for any continuous normalizing flow model. We then propose Density Guidance, a principled modification of the generative ODE that enables exact log-density control during sampling. Finally, we extend Density Guidance to stochastic sampling, ensuring precise log-density control while allowing controlled variation in structure or fine details. Our experiments demonstrate that these techniques provide fine-grained control over image detail without compromising sample quality. Code is available at https://github.com/Aalto-QuML/density-guidance.","authors":["Rafa{\\l} Karczewski","Markus Heinonen","Vikas Garg"],"url":"https://arxiv.org/abs/2502.05807"}
{"created":"2025-05-29","title":"Model Diffusion for Certifiable Few-shot Transfer Learning","abstract":"In contemporary deep learning, a prevalent and effective workflow for solving low-data problems is adapting powerful pre-trained foundation models (FMs) to new tasks via parameter-efficient fine-tuning (PEFT). However, while empirically effective, the resulting solutions lack generalisation guarantees to certify their accuracy - which may be required for ethical or legal reasons prior to deployment in high-importance applications. In this paper we develop a novel transfer learning approach that is designed to facilitate non-vacuous learning theoretic generalisation guarantees for downstream tasks, even in the low-shot regime. Specifically, we first use upstream tasks to train a distribution over PEFT parameters. We then learn the downstream task by a sample-and-evaluate procedure -- sampling plausible PEFTs from the trained diffusion model and selecting the one with the highest likelihood on the downstream data. Crucially, this confines our model hypothesis to a finite set of PEFT samples. In contrast to the typical continuous hypothesis spaces of neural network weights, this facilitates tighter risk certificates. We instantiate our bound and show non-trivial generalization guarantees compared to existing learning approaches which lead to vacuous bounds in the low-shot regime.","authors":["Fady Rezk","Royson Lee","Henry Gouk","Timothy Hospedales","Minyoung Kim"],"url":"https://arxiv.org/abs/2502.06970"}
{"created":"2025-05-29","title":"Outsourced diffusion sampling: Efficient posterior inference in latent spaces of generative models","abstract":"Any well-behaved generative model over a variable $\\mathbf{x}$ can be expressed as a deterministic transformation of an exogenous ('outsourced') Gaussian noise variable $\\mathbf{z}$: $\\mathbf{x}=f_\\theta(\\mathbf{z})$. In such a model (\\eg, a VAE, GAN, or continuous-time flow-based model), sampling of the target variable $\\mathbf{x} \\sim p_\\theta(\\mathbf{x})$ is straightforward, but sampling from a posterior distribution of the form $p(\\mathbf{x}\\mid\\mathbf{y}) \\propto p_\\theta(\\mathbf{x})r(\\mathbf{x},\\mathbf{y})$, where $r$ is a constraint function depending on an auxiliary variable $\\mathbf{y}$, is generally intractable. We propose to amortize the cost of sampling from such posterior distributions with diffusion models that sample a distribution in the noise space ($\\mathbf{z}$). These diffusion samplers are trained by reinforcement learning algorithms to enforce that the transformed samples $f_\\theta(\\mathbf{z})$ are distributed according to the posterior in the data space ($\\mathbf{x}$). For many models and constraints, the posterior in noise space is smoother than in data space, making it more suitable for amortized inference. Our method enables conditional sampling under unconditional GAN, (H)VAE, and flow-based priors, comparing favorably with other inference methods. We demonstrate the proposed outsourced diffusion sampling in several experiments with large pretrained prior models: conditional image generation, reinforcement learning with human feedback, and protein structure generation.","authors":["Siddarth Venkatraman","Mohsin Hasan","Minsu Kim","Luca Scimeca","Marcin Sendera","Yoshua Bengio","Glen Berseth","Nikolay Malkin"],"url":"https://arxiv.org/abs/2502.06999"}
{"created":"2025-05-29","title":"LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation","abstract":"Large language models (LLMs) have gained extended context windows through scaling positional encodings and lightweight continual pre-training. However, this often leads to degraded performance on short-text tasks, while the reasons for this degradation remain insufficiently explored. In this work, we identify two primary factors contributing to this issue: distribution drift in hidden states and attention scores, and catastrophic forgetting during continual pre-training. To address these challenges, we propose Long Context Pre-training with Restoration Distillation (LongReD), a novel approach designed to mitigate short-text performance degradation through minimizing the distribution discrepancy between the extended and original models. Besides training on long texts, LongReD distills the hidden state of selected layers from the original model on short texts. Additionally, LongReD also introduces a short-to-long distillation, aligning the output distribution on short texts with that on long texts by leveraging skipped positional indices. Experiments on common text benchmarks demonstrate that LongReD effectively preserves the model's short-text performance while maintaining comparable or even better capacity to handle long texts than baselines. Our code is available at https://github.com/RUCAIBox/LongReD.","authors":["Zican Dong","Junyi Li","Jinhao Jiang","Mingyu Xu","Wayne Xin Zhao","Bingning Wang","Weipeng Chen"],"url":"https://arxiv.org/abs/2502.07365"}
{"created":"2025-05-29","title":"TransMLA: Migrating GQA Models to MLA with Full DeepSeek Compatibility and Speedup","abstract":"In this paper, we present TransMLA, a framework that seamlessly converts any GQA-based pre-trained model into an MLA-based model. Our approach enables direct compatibility with DeepSeek's codebase, allowing these models to fully leverage DeepSeek-specific optimizations such as vLLM and SGlang. By compressing 93% of the KV cache in LLaMA-2-7B, TransMLA achieves a 10.6x inference speedup at an 8K context length while preserving meaningful output quality. Additionally, the model requires only 6 billion tokens for fine-tuning to regain performance on par with the original across multiple benchmarks. TransMLA offers a practical solution for migrating GQA-based models to the MLA structure. When combined with DeepSeek's advanced features, such as FP8 quantization and Multi-Token Prediction, even greater inference acceleration can be realized.","authors":["Fanxu Meng","Pingzhi Tang","Zengwei Yao","Xing Sun","Muhan Zhang"],"url":"https://arxiv.org/abs/2502.07864"}
{"created":"2025-05-29","title":"Morpheus Consensus: Excelling on trails and autobahns","abstract":"Recent research in consensus has often focussed on protocols for State-Machine-Replication (SMR) that can handle high throughputs. Such state-of-the-art protocols (generally DAG-based) induce undue overhead when the needed throughput is low, or else exhibit unnecessarily-poor latency and communication complexity during periods of low throughput.","authors":["Andrew Lewis-Pye","Ehud Shapiro"],"url":"https://arxiv.org/abs/2502.08465"}
{"created":"2025-05-29","title":"CoSER: Coordinating LLM-Based Persona Simulation of Established Roles","abstract":"Role-playing language agents (RPLAs) have emerged as promising applications of large language models (LLMs). However, simulating established characters presents a challenging task for RPLAs, due to the lack of authentic character datasets and nuanced evaluation methods using such data. In this paper, we present CoSER, a collection of a high-quality dataset, open models, and an evaluation protocol towards effective RPLAs of established characters. The CoSER dataset covers 17,966 characters from 771 renowned books. It provides authentic dialogues with real-world intricacies, as well as diverse data types such as conversation setups, character experiences and internal thoughts. Drawing from acting methodology, we introduce given-circumstance acting for training and evaluating role-playing LLMs, where LLMs sequentially portray multiple characters in book scenes. Using our dataset, we develop CoSER 8B and CoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models. Extensive experiments demonstrate the value of the CoSER dataset for RPLA training, evaluation and retrieval. Moreover, CoSER 70B exhibits state-of-the-art performance surpassing or matching GPT-4o on our evaluation and three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on the InCharacter and LifeChoice benchmarks respectively.","authors":["Xintao Wang","Heng Wang","Yifei Zhang","Xinfeng Yuan","Rui Xu","Jen-tse Huang","Siyu Yuan","Haoran Guo","Jiangjie Chen","Shuchang Zhou","Wei Wang","Yanghua Xiao"],"url":"https://arxiv.org/abs/2502.09082"}
{"created":"2025-05-29","title":"You Do Not Fully Utilize Transformer's Representation Capacity","abstract":"In contrast to RNNs, which compress their history into a single hidden state, Transformers can attend to all past tokens directly. However, standard Transformers rely solely on the hidden state from the previous layer to represent the entire context. We show that this design choice induces representation collapse and degrades performance. To address this issue, we introduce Layer-Integrated Memory (LIMe), a lightweight extension that leverages existing key-value buffers and learns per-head, per-layer routing weights to integrate representations from all previous layers with negligible overhead. Through extensive experiments-including language modeling, synthetic reasoning benchmarks, and very deep architectures-LIMe consistently achieves faster convergence, lower perplexity per FLOP, and substantial accuracy improvements on synthetic tasks while preserving higher value-vector entropy and improved token separability. Finally, our analysis of the learned routing weights reveals systematic reuse of both local and long-distance features, demonstrating how LIMe mitigates collapse, unlocks richer representations without increasing hidden-state size, and points to promising directions for future research.","authors":["Gleb Gerasimov","Yaroslav Aksenov","Nikita Balagansky","Viacheslav Sinii","Daniil Gavrilov"],"url":"https://arxiv.org/abs/2502.09245"}
{"created":"2025-05-29","title":"When do neural networks learn world models?","abstract":"Humans develop world models that capture the underlying generation process of data. Whether neural networks can learn similar world models remains an open problem. In this work, we present the first theoretical results for this problem, showing that in a multi-task setting, models with a low-degree bias provably recover latent data-generating variables under mild assumptions -- even if proxy tasks involve complex, non-linear functions of the latents. However, such recovery is sensitive to model architecture. Our analysis leverages Boolean models of task solutions via the Fourier-Walsh transform and introduces new techniques for analyzing invertible Boolean transforms, which may be of independent interest. We illustrate the algorithmic implications of our results and connect them to related research areas, including self-supervised learning, out-of-distribution generalization, and the linear representation hypothesis in large language models.","authors":["Tianren Zhang","Guanyu Chen","Feng Chen"],"url":"https://arxiv.org/abs/2502.09297"}
{"created":"2025-05-29","title":"Galileo: Learning Global & Local Features of Many Remote Sensing Modalities","abstract":"We introduce a highly multimodal transformer to represent many remote sensing modalities - multispectral optical, synthetic aperture radar, elevation, weather, pseudo-labels, and more - across space and time. These inputs are useful for diverse remote sensing tasks, such as crop mapping and flood detection. However, learning shared representations of remote sensing data is challenging, given the diversity of relevant data modalities, and because objects of interest vary massively in scale, from small boats (1-2 pixels and transient) to glaciers (thousands of pixels and persistent). We present a novel self-supervised learning algorithm that extracts multi-scale features across a flexible set of input modalities through masked modeling. Our dual global and local contrastive losses differ in their targets (deep representations vs. shallow input projections) and masking strategies (structured vs. not). Our Galileo is a single generalist model that outperforms SoTA specialist models for satellite images and pixel time series across eleven benchmarks and multiple tasks.","authors":["Gabriel Tseng","Anthony Fuller","Marlena Reil","Henry Herzog","Patrick Beukema","Favyen Bastani","James R. Green","Evan Shelhamer","Hannah Kerner","David Rolnick"],"url":"https://arxiv.org/abs/2502.09356"}
{"created":"2025-05-29","title":"DiffMS: Diffusion Generation of Molecules Conditioned on Mass Spectra","abstract":"Mass spectrometry plays a fundamental role in elucidating the structures of unknown molecules and subsequent scientific discoveries. One formulation of the structure elucidation task is the conditional de novo generation of molecular structure given a mass spectrum. Toward a more accurate and efficient scientific discovery pipeline for small molecules, we present DiffMS, a formula-restricted encoder-decoder generative network that achieves state-of-the-art performance on this task. The encoder utilizes a transformer architecture and models mass spectra domain knowledge such as peak formulae and neutral losses, and the decoder is a discrete graph diffusion model restricted by the heavy-atom composition of a known chemical formula. To develop a robust decoder that bridges latent embeddings and molecular structures, we pretrain the diffusion decoder with fingerprint-structure pairs, which are available in virtually infinite quantities, compared to structure-spectrum pairs that number in the tens of thousands. Extensive experiments on established benchmarks show that DiffMS outperforms existing models on de novo molecule generation. We provide several ablations to demonstrate the effectiveness of our diffusion and pretraining approaches and show consistent performance scaling with increasing pretraining dataset size. DiffMS code is publicly available at https://github.com/coleygroup/DiffMS.","authors":["Montgomery Bohde","Mrunali Manjrekar","Runzhong Wang","Shuiwang Ji","Connor W. Coley"],"url":"https://arxiv.org/abs/2502.09571"}
{"created":"2025-05-29","title":"Non-Markovian Discrete Diffusion with Causal Language Models","abstract":"Discrete diffusion models offer a flexible, controllable approach to structured sequence generation, yet they still lag behind causal language models in expressive power. A key limitation lies in their reliance on the Markovian assumption, which restricts each step to condition only on the current state, leading to potential uncorrectable error accumulation. In this paper, we introduce CaDDi, a discrete diffusion model that conditions on the entire generative trajectory, thereby lifting the Markov constraint and allowing the model to revisit and improve past states. By unifying sequential (causal) and temporal (diffusion) reasoning in a single non-Markovian transformer, CaDDi also treats standard causal language models as a special case and permits the direct reuse of pretrained LLM weights with no architectural changes. Empirically, CaDDi outperforms state-of-the-art discrete diffusion baselines on natural-language benchmarks, substantially narrowing the remaining gap to large autoregressive transformers.","authors":["Yangtian Zhang","Sizhuang He","Daniel Levine","Lawrence Zhao","David Zhang","Syed A Rizvi","Emanuele Zappala","Rex Ying","David van Dijk"],"url":"https://arxiv.org/abs/2502.09767"}
{"created":"2025-05-29","title":"Solving Empirical Bayes via Transformers","abstract":"This work applies modern AI tools (transformers) to solving one of the oldest statistical problems: Poisson means under empirical Bayes (Poisson-EB) setting. In Poisson-EB a high-dimensional mean vector $\\theta$ (with iid coordinates sampled from an unknown prior $\\pi$) is estimated on the basis of $X=\\mathrm{Poisson}(\\theta)$. A transformer model is pre-trained on a set of synthetically generated pairs $(X,\\theta)$ and learns to do in-context learning (ICL) by adapting to unknown $\\pi$. Theoretically, we show that a sufficiently wide transformer can achieve vanishing regret with respect to an oracle estimator who knows $\\pi$ as dimension grows to infinity. Practically, we discover that already very small models (100k parameters) are able to outperform the best classical algorithm (non-parametric maximum likelihood, or NPMLE) both in runtime and validation loss, which we compute on out-of-distribution synthetic data as well as real-world datasets (NHL hockey, MLB baseball, BookCorpusOpen). Finally, by using linear probes, we confirm that the transformer's EB estimator appears to internally work differently from either NPMLE or Robbins' estimators.","authors":["Anzo Teh","Mark Jabbour","Yury Polyanskiy"],"url":"https://arxiv.org/abs/2502.09844"}
{"created":"2025-05-29","title":"Closed-Form Training Dynamics Reveal Learned Features and Linear Structure in Word2Vec-like Models","abstract":"Self-supervised word embedding algorithms such as word2vec provide a minimal setting for studying representation learning in language modeling. We examine the quartic Taylor approximation of the word2vec loss around the origin, and we show that both the resulting training dynamics and the final performance on downstream tasks are empirically very similar to those of word2vec. Our main contribution is to analytically solve for both the gradient flow training dynamics and the final word embeddings in terms of only the corpus statistics and training hyperparameters. The solutions reveal that these models learn orthogonal linear subspaces one at a time, each one incrementing the effective rank of the embeddings until model capacity is saturated. Training on Wikipedia, we find that each of the top linear subspaces represents an interpretable topic-level concept. Finally, we apply our theory to describe how linear representations of more abstract semantic concepts emerge during training; these can be used to complete analogies via vector addition.","authors":["Dhruva Karkada","James B. Simon","Yasaman Bahri","Michael R. DeWeese"],"url":"https://arxiv.org/abs/2502.09863"}
{"created":"2025-05-29","title":"Semantics-aware Test-time Adaptation for 3D Human Pose Estimation","abstract":"This work highlights a semantics misalignment in 3D human pose estimation. For the task of test-time adaptation, the misalignment manifests as overly smoothed and unguided predictions. The smoothing settles predictions towards some average pose. Furthermore, when there are occlusions or truncations, the adaptation becomes fully unguided. To this end, we pioneer the integration of a semantics-aware motion prior for the test-time adaptation of 3D pose estimation. We leverage video understanding and a well-structured motion-text space to adapt the model motion prediction to adhere to video semantics during test time. Additionally, we incorporate a missing 2D pose completion based on the motion-text similarity. The pose completion strengthens the motion prior's guidance for occlusions and truncations. Our method significantly improves state-of-the-art 3D human pose estimation TTA techniques, with more than 12% decrease in PA-MPJPE on 3DPW and 3DHP.","authors":["Qiuxia Lin","Rongyu Chen","Kerui Gu","Angela Yao"],"url":"https://arxiv.org/abs/2502.10724"}
{"created":"2025-05-29","title":"A Physics-Informed Machine Learning Framework for Safe and Optimal Control of Autonomous Systems","abstract":"As autonomous systems become more ubiquitous in daily life, ensuring high performance with guaranteed safety is crucial. However, safety and performance could be competing objectives, which makes their co-optimization difficult. Learning-based methods, such as Constrained Reinforcement Learning (CRL), achieve strong performance but lack formal safety guarantees due to safety being enforced as soft constraints, limiting their use in safety-critical settings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability Analysis and Control Barrier Functions (CBFs) provide rigorous safety assurances but often neglect performance, resulting in overly conservative controllers. To bridge this gap, we formulate the co-optimization of safety and performance as a state-constrained optimal control problem, where performance objectives are encoded via a cost function and safety requirements are imposed as state constraints. We demonstrate that the resultant value function satisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate efficiently using a novel physics-informed machine learning framework. In addition, we introduce a conformal prediction-based verification strategy to quantify the learning errors, recovering a high-confidence safety value function, along with a probabilistic error bound on performance degradation. Through several case studies, we demonstrate the efficacy of the proposed framework in enabling scalable learning of safe and performant controllers for complex, high-dimensional autonomous systems.","authors":["Manan Tayal","Aditya Singh","Shishir Kolathaya","Somil Bansal"],"url":"https://arxiv.org/abs/2502.11057"}
{"created":"2025-05-29","title":"Towards Achieving Concept Completeness for Textual Concept Bottleneck Models","abstract":"Textual Concept Bottleneck Models (TCBMs) are interpretable-by-design models for text classification that predict a set of salient concepts before making the final prediction. This paper proposes Complete Textual Concept Bottleneck Model (CT-CBM), a novel TCBM generator building concept labels in a fully unsupervised manner using a small language model, eliminating both the need for predefined human labeled concepts and LLM annotations. CT-CBM iteratively targets and adds important and identifiable concepts in the bottleneck layer to create a complete concept basis. CT-CBM achieves striking results against competitors in terms of concept basis completeness and concept detection accuracy, offering a promising solution to reliably enhance interpretability of NLP classifiers.","authors":["Milan Bhan","Yann Choho","Pierre Moreau","Jean-Noel Vittaut","Nicolas Chesneau","Marie-Jeanne Lesot"],"url":"https://arxiv.org/abs/2502.11100"}
{"created":"2025-05-29","title":"Revisiting Weak-to-Strong Generalization in Theory and Practice: Reverse KL vs. Forward KL","abstract":"As large language models advance toward superhuman performance, ensuring their alignment with human values and abilities grows increasingly complex. Weak-to-strong generalization offers a promising approach by leveraging predictions from weaker models to guide stronger systems, but its effectiveness could be constrained by the inherent noise and inaccuracies in these weak predictions. To address this, we propose a theoretically grounded approach that replaces forward KL divergence-whose mass-covering behavior risks overfitting to imperfect weak signals-with reverse KL divergence. Reverse KL divergence's zero-forcing effect prioritizes high-confidence predictions, effectively mitigating the influence of unreliable weak supervision. Theoretically, we extend existing bounds and derive tighter lower bounds for both forward and reverse KL divergence, establishing that reverse KL achieves at least comparable guarantees to forward KL. Notably, when a sufficiently pre-trained strong model is fine-tuned on the last linear layer, reverse KL guarantees that it outperforms its weak supervisor by the magnitude of their disagreement. Empirically, we demonstrate that reverse KL and reverse cross-entropy enable strong models to successfully outperform those trained with forward KL and standard cross-entropy across most settings, highlighting the practical advantages of these reverse losses.","authors":["Wei Yao","Wenkai Yang","Ziqiao Wang","Yankai Lin","Yong Liu"],"url":"https://arxiv.org/abs/2502.11107"}
{"created":"2025-05-29","title":"ReLearn: Unlearning via Learning for Large Language Models","abstract":"Current unlearning methods for large language models usually rely on reverse optimization to reduce target token probabilities. However, this paradigm disrupts the subsequent tokens prediction, degrading model performance and linguistic coherence. Moreover, existing evaluation metrics overemphasize contextual forgetting while inadequately assessing response fluency and relevance. To address these challenges, we propose ReLearn, a data augmentation and fine-tuning pipeline for effective unlearning, along with a comprehensive evaluation framework. This framework introduces Knowledge Forgetting Rate (KFR) and Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and Linguistic Score (LS) to evaluate generation quality. Our experiments show that ReLearn successfully achieves targeted forgetting while preserving high-quality output. Through mechanistic analysis, we further demonstrate how reverse optimization disrupts coherent text generation, while ReLearn preserves this essential capability. Code is available at https://github.com/zjunlp/unlearn.","authors":["Haoming Xu","Ningyuan Zhao","Liming Yang","Sendong Zhao","Shumin Deng","Mengru Wang","Bryan Hooi","Nay Oo","Huajun Chen","Ningyu Zhang"],"url":"https://arxiv.org/abs/2502.11190"}
{"created":"2025-05-29","title":"Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents","abstract":"Recent success in large multimodal models (LMMs) has sparked promising applications of agents capable of autonomously completing complex web tasks. While open-source LMM agents have made significant advances in offline evaluation benchmarks, their performance still falls substantially short of human-level capabilities in more realistic online settings. A key bottleneck is the lack of diverse and large-scale trajectory-level datasets across various domains, which are expensive to collect. In this paper, we address this challenge by developing a scalable recipe to synthesize the largest and most diverse trajectory-level dataset to date, containing over 94K successful multimodal web trajectories, spanning 49K unique URLs, 720K screenshots, and 33M web elements. In particular, we leverage extensive web exploration and refinement to obtain diverse task intents. The average cost is 28 cents per successful trajectory, making it affordable to a wide range of users in the community. Leveraging this dataset, we train Explorer, a multimodal web agent, and demonstrate strong performance on both offline and online web agent benchmarks such as Mind2Web-Live, Multimodal-Mind2Web, and MiniWob++. Additionally, our experiments highlight data scaling as a key driver for improving web agent capabilities. We hope this study makes state-of-the-art LMM-based agent research at a larger scale more accessible.","authors":["Vardaan Pahuja","Yadong Lu","Corby Rosset","Boyu Gou","Arindam Mitra","Spencer Whitehead","Yu Su","Ahmed Awadallah"],"url":"https://arxiv.org/abs/2502.11357"}
{"created":"2025-05-29","title":"Which Retain Set Matters for LLM Unlearning? A Case Study on Entity Unlearning","abstract":"Large language models (LLMs) risk retaining unauthorized or sensitive information from their training data, which raises privacy concerns. LLM unlearning seeks to mitigate these risks by selectively removing specified data while maintaining overall model performance. However, most existing work focus on methods to achieve effective forgetting and does not provide a detailed analysis of the retain set, the portion of training data that is not targeted for removal. In this paper, we investigate the effects of unlearning on various subsets of the retain set through a case study on entity unlearning. We introduce the Syntactically Similar Neighbor Set, a group of queries that share similar syntactic structures with the data targeted for removal, and show that this subset suffers the greatest performance drop during unlearning. Moreover, when used for regularization, this set not only preserves performance on syntactically similar queries but also delivers comparable or improved results across other data subsets. Our results highlight that syntactic similarity is a critical factor, potentially more so than domain or entity relationships, in achieving effective and practical LLM unlearning.","authors":["Hwan Chang","Hwanhee Lee"],"url":"https://arxiv.org/abs/2502.11441"}
{"created":"2025-05-29","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration","abstract":"Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. DPT-Agent can effectively help LLMs convert correct slow thinking and reasoning into executable actions, thereby improving performance. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"url":"https://arxiv.org/abs/2502.11882"}
{"created":"2025-05-29","title":"BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages","abstract":"People worldwide use language in subtle and complex ways to express emotions. Although emotion recognition--an umbrella term for several NLP tasks--impacts various applications within NLP and beyond, most work in this area has focused on high-resource languages. This has led to significant disparities in research efforts and proposed solutions, particularly for under-resourced languages, which often lack high-quality annotated datasets. In this paper, we present BRIGHTER--a collection of multilabeled, emotion-annotated datasets in 28 different languages and across several domains. BRIGHTER primarily covers low-resource languages from Africa, Asia, Eastern Europe, and Latin America, with instances labeled by fluent speakers. We highlight the challenges related to the data collection and annotation processes, and then report experimental results for monolingual and crosslingual multi-label emotion identification, as well as emotion intensity recognition. We analyse the variability in performance across languages and text domains, both with and without the use of LLMs, and show that the BRIGHTER datasets represent a meaningful step towards addressing the gap in text-based emotion recognition.","authors":["Shamsuddeen Hassan Muhammad","Nedjma Ousidhoum","Idris Abdulmumin","Jan Philip Wahle","Terry Ruas","Meriem Beloucif","Christine de Kock","Nirmal Surange","Daniela Teodorescu","Ibrahim Said Ahmad","David Ifeoluwa Adelani","Alham Fikri Aji","Felermino D. M. A. Ali","Ilseyar Alimova","Vladimir Araujo","Nikolay Babakov","Naomi Baes","Ana-Maria Bucur","Andiswa Bukula","Guanqun Cao","Rodrigo Tufino Cardenas","Rendi Chevi","Chiamaka Ijeoma Chukwuneke","Alexandra Ciobotaru","Daryna Dementieva","Murja Sani Gadanya","Robert Geislinger","Bela Gipp","Oumaima Hourrane","Oana Ignat","Falalu Ibrahim Lawan","Rooweither Mabuya","Rahmad Mahendra","Vukosi Marivate","Alexander Panchenko","Andrew Piper","Charles Henrique Porto Ferreira","Vitaly Protasov","Samuel Rutunda","Manish Shrivastava","Aura Cristina Udrea","Lilian Diana Awuor Wanzare","Sophie Wu","Florian Valentin Wunderlich","Hanif Muhammad Zhafran","Tianhui Zhang","Yi Zhou","Saif M. Mohammad"],"url":"https://arxiv.org/abs/2502.11926"}
{"created":"2025-05-29","title":"MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections","abstract":"We propose MUltiway Dynamic Dense (MUDD) connections, a simple yet effective method to address the limitations of residual connections and enhance cross-layer information flow in Transformers. Unlike existing dense connection approaches with static and shared connection weights, MUDD generates connection weights dynamically depending on hidden states at each sequence position and for each decoupled input stream (the query, key, value or residual) of a Transformer block. MUDD connections can be seamlessly integrated into any Transformer architecture to create MUDDFormer. Extensive experiments show that MUDDFormer significantly outperforms Transformers across various model architectures and scales in language modeling, achieving the performance of Transformers trained with 1.8X-2.4X compute. Notably, MUDDPythia-2.8B matches Pythia-6.9B in pretraining ppl and downstream tasks and even rivals Pythia-12B in five-shot settings, while adding only 0.23% parameters and 0.4% computation. Code in JAX and PyTorch and pre-trained models are available at https://github.com/Caiyun-AI/MUDDFormer .","authors":["Da Xiao","Qingye Meng","Shengping Li","Xingyuan Yuan"],"url":"https://arxiv.org/abs/2502.12170"}
{"created":"2025-05-29","title":"CHATS: Combining Human-Aligned Optimization and Test-Time Sampling for Text-to-Image Generation","abstract":"Diffusion models have emerged as a dominant approach for text-to-image generation. Key components such as the human preference alignment and classifier-free guidance play a crucial role in ensuring generation quality. However, their independent application in current text-to-image models continues to face significant challenges in achieving strong text-image alignment, high generation quality, and consistency with human aesthetic standards. In this work, we for the first time, explore facilitating the collaboration of human performance alignment and test-time sampling to unlock the potential of text-to-image models. Consequently, we introduce CHATS (Combining Human-Aligned optimization and Test-time Sampling), a novel generative framework that separately models the preferred and dispreferred distributions and employs a proxy-prompt-based sampling strategy to utilize the useful information contained in both distributions. We observe that CHATS exhibits exceptional data efficiency, achieving strong performance with only a small, high-quality funetuning dataset. Extensive experiments demonstrate that CHATS surpasses traditional preference alignment methods, setting new state-of-the-art across various standard benchmarks.","authors":["Minghao Fu","Guo-Hua Wang","Liangfu Cao","Qing-Guo Chen","Zhao Xu","Weihua Luo","Kaifu Zhang"],"url":"https://arxiv.org/abs/2502.12579"}
{"created":"2025-05-29","title":"ThinkGuard: Deliberative Slow Thinking Leads to Cautious Guardrails","abstract":"Ensuring the safety of large language models (LLMs) is critical as they are deployed in real-world applications. Existing guardrails rely on rule-based filtering or single-pass classification, limiting their ability to handle nuanced safety violations. To address this, we propose ThinkGuard, a critique-augmented guardrail model that distills knowledge from high-capacity LLMs by generating structured critiques alongside safety labels. Fine-tuned on critique-augmented data, the captured deliberative thinking ability drastically enhances the guardrail's cautiousness and interpretability. Evaluated on multiple safety benchmarks, ThinkGuard achieves the highest average F1 and AUPRC, outperforming all baselines. Compared to LLaMA Guard 3, ThinkGuard improves accuracy by 16.1% and macro F1 by 27.0%. Moreover, it surpasses label-only fine-tuned models, confirming that structured critiques enhance both classification precision and nuanced safety reasoning while maintaining computational efficiency.","authors":["Xiaofei Wen","Wenxuan Zhou","Wenjie Jacky Mo","Muhao Chen"],"url":"https://arxiv.org/abs/2502.13458"}
{"created":"2025-05-29","title":"How Do LLMs Perform Two-Hop Reasoning in Context?","abstract":"``Socrates is human. All humans are mortal. Therefore, Socrates is mortal.'' This form of argument illustrates a typical pattern of two-hop reasoning. Formally, two-hop reasoning refers to the process of inferring a conclusion by making two logical steps, each connecting adjacent concepts, such that the final conclusion depends on the integration of both steps. It is one of the most fundamental components of human reasoning and plays a crucial role in both formal logic and everyday decision-making. Despite recent progress in large language models (LLMs), we surprisingly find that they can fail at solving simple two-hop reasoning problems when distractors are present. We observe on a synthetic dataset that pre-trained LLMs often resort to random guessing among all plausible conclusions. However, after few steps of fine-tuning, models achieve near-perfect accuracy and exhibit strong length generalization. To understand the underlying mechanisms, we train a 3-layer Transformer from scratch on a synthetic two-hop reasoning task and reverse-engineer its internal information flow. We observe a clear progression in the attention logits throughout training. This pictures a sharp phase transition from an initial stage of random guessing to the emergence of a structured sequential query mechanism, where the model first retrieves the preceding and the bridge concepts in the early layers and then uses them to infer the final answer. Finally, we show that these dynamics can be captured by a minimal three-parameter attention-only network.","authors":["Tianyu Guo","Hanlin Zhu","Ruiqi Zhang","Jiantao Jiao","Song Mei","Michael I. Jordan","Stuart Russell"],"url":"https://arxiv.org/abs/2502.13913"}
{"created":"2025-05-29","title":"Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering","abstract":"In this paper, we identify a critical problem, \"lost-in-retrieval\", in retrieval-augmented multi-hop question answering (QA): the key entities are missed in LLMs' sub-question decomposition. \"Lost-in-retrieval\" significantly degrades the retrieval performance, which disrupts the reasoning chain and leads to the incorrect answers. To resolve this problem, we propose a progressive retrieval and rewriting method, namely ChainRAG, which sequentially handles each sub-question by completing missing key entities and retrieving relevant sentences from a sentence graph for answer generation. Each step in our retrieval and rewriting process builds upon the previous one, creating a seamless chain that leads to accurate retrieval and answers. Finally, all retrieved sentences and sub-question answers are integrated to generate a comprehensive answer to the original question. We evaluate ChainRAG on three multi-hop QA datasets - MuSiQue, 2Wiki, and HotpotQA - using three large language models: GPT4o-mini, Qwen2.5-72B, and GLM-4-Plus. Empirical results demonstrate that ChainRAG consistently outperforms baselines in both effectiveness and efficiency.","authors":["Rongzhi Zhu","Xiangyu Liu","Zequn Sun","Yiwei Wang","Wei Hu"],"url":"https://arxiv.org/abs/2502.14245"}
{"created":"2025-05-29","title":"Optimize Cardinality Estimation Model Pretraining by Simplifying the Training Datasets","abstract":"The cardinality estimation is a key aspect of query optimization research, and its performance has significantly improved with the integration of machine learning. To overcome the \"cold start\" problem or the lack of model transferability in learned cardinality estimators, some pre-training cardinality estimation models have been proposed that use learning across multiple datasets and corresponding workloads. These models typically train on a dataset created by uniformly sampling from many datasets, but this approach may not be optimal. By applying the Group Distributionally Robust Optimization (Group DRO) algorithm to training datasets, we find that some specific training datasets contribute more significantly to model performance than others. Based on this observation, we conduct extensive experiments to delve deeper into pre-training cardinality estimators. Our results show how the performance of these models can be influenced by the datasets and corresponding workloads. Finally, we introduce a simplified training dataset, which has been reduced to a fraction of the size of existing pretraining datasets. Sufficient experimental results demonstrate that the pre-trained cardinality estimator based on this simplified dataset can still achieve comparable performance to existing models in zero-shot setups.","authors":["Boyang Fang"],"url":"https://arxiv.org/abs/2502.14350"}
{"created":"2025-05-29","title":"ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation","abstract":"Protein backbone generation plays a central role in de novo protein design and is significant for many biological and medical applications. Although diffusion and flow-based generative models provide potential solutions to this challenging task, they often generate proteins with undesired designability and suffer computational inefficiency. In this study, we propose a novel rectified quaternion flow (ReQFlow) matching method for fast and high-quality protein backbone generation. In particular, our method generates a local translation and a 3D rotation from random noise for each residue in a protein chain, which represents each 3D rotation as a unit quaternion and constructs its flow by spherical linear interpolation (SLERP) in an exponential format. We train the model by quaternion flow (QFlow) matching with guaranteed numerical stability and rectify the QFlow model to accelerate its inference and improve the designability of generated protein backbones, leading to the proposed ReQFlow model. Experiments show that ReQFlow achieves on-par performance in protein backbone generation while requiring much fewer sampling steps and significantly less inference time (e.g., being 37x faster than RFDiffusion and 63x faster than Genie2 when generating a backbone of length 300), demonstrating its effectiveness and efficiency. The code is available at https://github.com/AngxiaoYue/ReQFlow.","authors":["Angxiao Yue","Zichong Wang","Hongteng Xu"],"url":"https://arxiv.org/abs/2502.14637"}
{"created":"2025-05-29","title":"Solving Inverse Problems with Deep Linear Neural Networks: Global Convergence Guarantees for Gradient Descent with Weight Decay","abstract":"Machine learning methods are commonly used to solve inverse problems, wherein an unknown signal must be estimated from few measurements generated via a known acquisition procedure. In particular, neural networks perform well empirically but have limited theoretical guarantees. In this work, we study an underdetermined linear inverse problem that admits several possible solution mappings. A standard remedy (e.g., in compressed sensing) establishing uniqueness of the solution mapping is to assume knowledge of latent low-dimensional structure in the source signal. We ask the following question: do deep neural networks adapt to this low-dimensional structure when trained by gradient descent with weight decay regularization? We prove that mildly overparameterized deep linear networks trained in this manner converge to an approximate solution that accurately solves the inverse problem while implicitly encoding latent subspace structure. To our knowledge, this is the first result to rigorously show that deep linear networks trained with weight decay automatically adapt to latent subspace structure in the data under practical stepsize and weight initialization schemes. Our work highlights that regularization and overparameterization improve generalization, while overparameterization also accelerates convergence during training.","authors":["Hannah Laus","Suzanna Parkinson","Vasileios Charisopoulos","Felix Krahmer","Rebecca Willett"],"url":"https://arxiv.org/abs/2502.15522"}
{"created":"2025-05-29","title":"Self-Taught Agentic Long Context Understanding","abstract":"Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a framework designed to enhance an LLM's understanding of such queries by integrating targeted self-clarification with contextual grounding within an agentic workflow. At the core of AgenticLU is Chain-of-Clarifications (CoC), where models refine their understanding through self-generated clarification questions and corresponding contextual groundings. By scaling inference as a tree search where each node represents a CoC step, we achieve 97.8% answer recall on NarrativeQA with a search depth of up to three and a branching factor of eight. To amortize the high cost of this search process to training, we leverage the preference pairs for each step obtained by the CoC workflow and perform two-stage model finetuning: (1) supervised finetuning to learn effective decomposition strategies, and (2) direct preference optimization to enhance reasoning quality. This enables AgenticLU models to generate clarifications and retrieve relevant context effectively and efficiently in a single inference pass. Extensive experiments across seven long-context tasks demonstrate that AgenticLU significantly outperforms state-of-the-art prompting methods and specialized long-context LLMs, achieving robust multi-hop reasoning while sustaining consistent performance as context length grows.","authors":["Yufan Zhuang","Xiaodong Yu","Jialian Wu","Ximeng Sun","Ze Wang","Jiang Liu","Yusheng Su","Jingbo Shang","Zicheng Liu","Emad Barsoum"],"url":"https://arxiv.org/abs/2502.15920"}
{"created":"2025-05-29","title":"Patterns Over Principles: The Fragility of Inductive Reasoning in LLMs under Noisy Observations","abstract":"Inductive reasoning, a cornerstone of human cognition, enables generalization from limited data but hasn't yet been fully achieved by large language models (LLMs). While modern LLMs excel at reasoning tasks, their ability to maintain stable and consistent rule abstraction under imperfect observations remains underexplored. To fill this gap, in this work, we introduce Robust Rule Induction, a task that evaluates LLMs' capability in inferring rules from data that are fused with noisy examples. To address this task, we further propose Sample-steered Rule Refinement (SRR), a method enhancing reasoning stability via observation diversification and execution-guided feedback. Experiments across arithmetic, cryptography, and list functions reveal: (1) SRR outperforms other methods with minimal performance degradation under noise; (2) Despite slight accuracy variation, LLMs exhibit instability under noise (e.g., 0% accuracy change with only 70% consistent score); (3) Counterfactual task gaps highlight LLMs' reliance on memorized patterns over genuine abstraction. Our findings challenge LLMs' reasoning robustness, revealing susceptibility to hypothesis drift and pattern overfitting, while providing empirical evidence critical for developing human-like inductive systems. Code and data are available at https://github.com/HKUST-KnowComp/Robust-Rule-Induction.","authors":["Chunyang Li","Weiqi Wang","Tianshi Zheng","Yangqiu Song"],"url":"https://arxiv.org/abs/2502.16169"}
{"created":"2025-05-29","title":"Robustness and Cybersecurity in the EU Artificial Intelligence Act","abstract":"The EU Artificial Intelligence Act (AIA) establishes different legal principles for different types of AI systems. While prior work has sought to clarify some of these principles, little attention has been paid to robustness and cybersecurity. This paper aims to fill this gap. We identify legal challenges and shortcomings in provisions related to robustness and cybersecurity for high-risk AI systems(Art. 15 AIA) and general-purpose AI models (Art. 55 AIA). We show that robustness and cybersecurity demand resilience against performance disruptions. Furthermore, we assess potential challenges in implementing these provisions in light of recent advancements in the machine learning (ML) literature. Our analysis informs efforts to develop harmonized standards, guidelines by the European Commission, as well as benchmarks and measurement methodologies under Art. 15(2) AIA. With this, we seek to bridge the gap between legal terminology and ML research, fostering a better alignment between research and implementation efforts.","authors":["Henrik Nolte","Miriam Rateike","Mich\\`ele Finck"],"url":"https://arxiv.org/abs/2502.16184"}
{"created":"2025-05-29","title":"GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking","abstract":"Large language models (LLMs) are widely used, but they often generate subtle factual errors, especially in long-form text. These errors are fatal in some specialized domains such as medicine. Existing fact-checking with grounding documents methods face two main challenges: (1) they struggle to understand complex multihop relations in long documents, often overlooking subtle factual errors; (2) most specialized methods rely on pairwise comparisons, requiring multiple model calls, leading to high resource and computational costs. To address these challenges, we propose GraphCheck, a fact-checking framework that uses extracted knowledge graphs to enhance text representation. Graph Neural Networks further process these graphs as a soft prompt, enabling LLMs to incorporate structured knowledge more effectively. Enhanced with graph-based reasoning, GraphCheck captures multihop reasoning chains that are often overlooked by existing methods, enabling precise and efficient fact-checking in a single inference call. Experimental results on seven benchmarks spanning both general and medical domains demonstrate up to a 7.1% overall improvement over baseline models. Notably, GraphCheck outperforms existing specialized fact-checkers and achieves comparable performance with state-of-the-art LLMs, such as DeepSeek-V3 and OpenAI-o1, with significantly fewer parameters.","authors":["Yingjian Chen","Haoran Liu","Yinhong Liu","Jinxiang Xie","Rui Yang","Han Yuan","Yanran Fu","Peng Yuan Zhou","Qingyu Chen","James Caverlee","Irene Li"],"url":"https://arxiv.org/abs/2502.16514"}
{"created":"2025-05-29","title":"BatteryLife: A Comprehensive Dataset and Benchmark for Battery Life Prediction","abstract":"Battery Life Prediction (BLP), which relies on time series data produced by battery degradation tests, is crucial for battery utilization, optimization, and production. Despite impressive advancements, this research area faces three key challenges. Firstly, the limited size of existing datasets impedes insights into modern battery life data. Secondly, most datasets are restricted to small-capacity lithium-ion batteries tested under a narrow range of diversity in labs, raising concerns about the generalizability of findings. Thirdly, inconsistent and limited benchmarks across studies obscure the effectiveness of baselines and leave it unclear if models popular in other time series fields are effective for BLP. To address these challenges, we propose BatteryLife, a comprehensive dataset and benchmark for BLP. BatteryLife integrates 16 datasets, offering a 2.5 times sample size compared to the previous largest dataset, and provides the most diverse battery life resource with batteries from 8 formats, 59 chemical systems, 9 operating temperatures, and 421 charge/discharge protocols, including both laboratory and industrial tests. Notably, BatteryLife is the first to release battery life datasets of zinc-ion batteries, sodium-ion batteries, and industry-tested large-capacity lithium-ion batteries. With the comprehensive dataset, we revisit the effectiveness of baselines popular in this and other time series fields. Furthermore, we propose CyclePatch, a plug-in technique that can be employed in various neural networks. Extensive benchmarking of 18 methods reveals that models popular in other time series fields can be unsuitable for BLP, and CyclePatch consistently improves model performance establishing state-of-the-art benchmarks. Moreover, BatteryLife evaluates model performance across aging conditions and domains. BatteryLife is available at https://github.com/Ruifeng-Tan/BatteryLife.","authors":["Ruifeng Tan","Weixiang Hong","Jiayue Tang","Xibin Lu","Ruijun Ma","Xiang Zheng","Jia Li","Jiaqiang Huang","Tong-Yi Zhang"],"url":"https://arxiv.org/abs/2502.18807"}
{"created":"2025-05-29","title":"Beyond Surface-Level Patterns: An Essence-Driven Defense Framework Against Jailbreak Attacks in LLMs","abstract":"Although Aligned Large Language Models (LLMs) are trained to refuse harmful requests, they remain vulnerable to jailbreak attacks. Unfortunately, existing methods often focus on surface-level patterns, overlooking the deeper attack essences. As a result, defenses fail when attack prompts change, even though the underlying \"attack essence\" remains the same. To address this issue, we introduce EDDF, an \\textbf{E}ssence-\\textbf{D}riven \\textbf{D}efense \\textbf{F}ramework Against Jailbreak Attacks in LLMs. EDDF is a plug-and-play input-filtering method and operates in two stages: 1) offline essence database construction, and 2) online adversarial query detection. The key idea behind EDDF is to extract the \"attack essence\" from a diverse set of known attack instances and store it in an offline vector database. Experimental results demonstrate that EDDF significantly outperforms existing methods by reducing the Attack Success Rate by at least 20\\%, underscoring its superior robustness against jailbreak attacks.","authors":["Shiyu Xiang","Ansen Zhang","Yanfei Cao","Yang Fan","Ronghao Chen"],"url":"https://arxiv.org/abs/2502.19041"}
{"created":"2025-05-29","title":"Interpreting CLIP with Hierarchical Sparse Autoencoders","abstract":"Sparse autoencoders (SAEs) are useful for detecting and steering interpretable features in neural networks, with particular potential for understanding complex multimodal representations. Given their ability to uncover interpretable features, SAEs are particularly valuable for analyzing large-scale vision-language models (e.g., CLIP and SigLIP), which are fundamental building blocks in modern systems yet remain challenging to interpret and control. However, current SAE methods are limited by optimizing both reconstruction quality and sparsity simultaneously, as they rely on either activation suppression or rigid sparsity constraints. To this end, we introduce Matryoshka SAE (MSAE), a new architecture that learns hierarchical representations at multiple granularities simultaneously, enabling a direct optimization of both metrics without compromise. MSAE establishes a new state-of-the-art Pareto frontier between reconstruction quality and sparsity for CLIP, achieving 0.99 cosine similarity and less than 0.1 fraction of variance unexplained while maintaining ~80% sparsity. Finally, we demonstrate the utility of MSAE as a tool for interpreting and controlling CLIP by extracting over 120 semantic concepts from its representation to perform concept-based similarity search and bias analysis in downstream tasks like CelebA. We make the codebase available at https://github.com/WolodjaZ/MSAE.","authors":["Vladimir Zaigrajew","Hubert Baniecki","Przemyslaw Biecek"],"url":"https://arxiv.org/abs/2502.20578"}
{"created":"2025-05-29","title":"WiseMind: Recontextualizing AI with a Knowledge-Guided, Theory-Informed Multi-Agent Framework for Instrumental and Humanistic Benefits","abstract":"Translating state-of-the-art NLP into practice often stalls at the \"last mile\" owing to insufficient contextualization of the target domain's knowledge, processes, and evaluation. Psychiatric differential diagnosis exemplifies this challenge: accurate assessments depend on nuanced clinical knowledge, a delicate cognitive-affective interview process, and downstream outcomes that extend far beyond benchmark accuracy. We present WiseMind, a systematic interdisciplinary contextualization framework that delivers both instrumental (diagnostic precision) and humanistic (empathy) gains. WiseMind comprises three components:(i) structured knowledge-guided proactive reasoning, which embeds DSM-5 criteria in a knowledge graph to steer questioning; (ii) a theory-informed dual-agent architecture that coordinates a \"reasonable-mind\" reasoning agent and an \"emotional-mind\" empathy agent, inspired by Dialectical Behavior Therapy; and (iii) a multi-faceted evaluation strategy covering simulated patients, user studies, clinician review, and ethical assessment. Tested on depression, anxiety, and bipolar disorder, WiseMind attains up to 84.2% diagnostic accuracy, which is comparable to human experts, while outperforming single-agent baselines in perceived empathy and trustworthiness. These results show that deep contextualization-across knowledge, process, and evaluation layers-can transform benchmark-driven NLP into clinically meaningful impact.","authors":["Yuqi Wu","Guangya Wan","Jingjing Li","Shengming Zhao","Lingfeng Ma","Tianyi Ye","Ion Pop","Yanbo Zhang","Jie Chen"],"url":"https://arxiv.org/abs/2502.20689"}
{"created":"2025-05-29","title":"Learning to Steer Learners in Games","abstract":"We consider the problem of learning to exploit learning algorithms through repeated interactions in games. Specifically, we focus on the case of repeated two player, finite-action games, in which an optimizer aims to steer a no-regret learner to a Stackelberg equilibrium without knowledge of its payoffs. We first show that this is impossible if the optimizer only knows that the learner is using an algorithm from the general class of no-regret algorithms. This suggests that the optimizer requires more information about the learner's objectives or algorithm to successfully exploit them. Building on this intuition, we reduce the problem for the optimizer to that of recovering the learner's payoff structure. We demonstrate the effectiveness of this approach if the learner's algorithm is drawn from a smaller class by analyzing two examples: one where the learner uses an ascent algorithm, and another where the learner uses stochastic mirror ascent with known regularizer and step sizes.","authors":["Yizhou Zhang","Yi-An Ma","Eric Mazumdar"],"url":"https://arxiv.org/abs/2502.20770"}
{"created":"2025-05-29","title":"Fast 3D point clouds retrieval for Large-scale 3D Place Recognition","abstract":"Retrieval in 3D point clouds is a challenging task that consists in retrieving the most similar point clouds to a given query within a reference of 3D points. Current methods focus on comparing descriptors of point clouds in order to identify similar ones. Due to the complexity of this latter step, here we focus on the acceleration of the retrieval by adapting the Differentiable Search Index (DSI), a transformer-based approach initially designed for text information retrieval, for 3D point clouds retrieval. Our approach generates 1D identifiers based on the point descriptors, enabling direct retrieval in constant time. To adapt DSI to 3D data, we integrate Vision Transformers to map descriptors to these identifiers while incorporating positional and semantic encoding. The approach is evaluated for place recognition on a public benchmark comparing its retrieval capabilities against state-of-the-art methods, in terms of quality and speed of returned point clouds.","authors":["Chahine-Nicolas Zede","Laurent Carrafa","Val\\'erie Gouet-Brunet"],"url":"https://arxiv.org/abs/2502.21067"}
{"created":"2025-05-29","title":"Personalized Causal Graph Reasoning for LLMs: A Case Study on Dietary Recommendations","abstract":"Large Language Models (LLMs) effectively leverage common-sense knowledge for general reasoning, yet they struggle with personalized reasoning when tasked with interpreting multifactor personal data. This limitation restricts their applicability in domains that require context-aware decision-making tailored to individuals. This paper introduces Personalized Causal Graph Reasoning as an agentic framework that enhances LLM reasoning by incorporating personal causal graphs derived from data of individuals. These graphs provide a foundation that guides the LLM's reasoning process. We evaluate it on a case study on nutrient-oriented dietary recommendations, which requires personal reasoning due to the implicit unique dietary effects. We propose a counterfactual evaluation to estimate the efficiency of LLM-recommended foods for glucose management. Results demonstrate that the proposed method efficiently provides personalized dietary recommendations to reduce average glucose iAUC across three time windows, which outperforms the previous approach. LLM-as-a-judge evaluation results indicate that our proposed method enhances personalization in the reasoning process.","authors":["Zhongqi Yang","Amir Rahmani"],"url":"https://arxiv.org/abs/2503.00134"}
{"created":"2025-05-29","title":"Explainable Multi-modal Time Series Prediction with LLM-in-the-Loop","abstract":"Time series analysis provides essential insights for real-world system dynamics and informs downstream decision-making, yet most existing methods often overlook the rich contextual signals present in auxiliary modalities. To bridge this gap, we introduce TimeXL, a multi-modal prediction framework that integrates a prototype-based time series encoder with three collaborating Large Language Models (LLMs) to deliver more accurate predictions and interpretable explanations. First, a multi-modal prototype-based encoder processes both time series and textual inputs to generate preliminary forecasts alongside case-based rationales. These outputs then feed into a prediction LLM, which refines the forecasts by reasoning over the encoder's predictions and explanations. Next, a reflection LLM compares the predicted values against the ground truth, identifying textual inconsistencies or noise. Guided by this feedback, a refinement LLM iteratively enhances text quality and triggers encoder retraining. This closed-loop workflow -- prediction, critique (reflect), and refinement -- continuously boosts the framework's performance and interpretability. Empirical evaluations on four real-world datasets demonstrate that TimeXL achieves up to 8.9\\% improvement in AUC and produces human-centric, multi-modal explanations, highlighting the power of LLM-driven reasoning for time series prediction.","authors":["Yushan Jiang","Wenchao Yu","Geon Lee","Dongjin Song","Kijung Shin","Wei Cheng","Yanchi Liu","Haifeng Chen"],"url":"https://arxiv.org/abs/2503.01013"}
{"created":"2025-05-29","title":"Position: Don't Use the CLT in LLM Evals With Fewer Than a Few Hundred Datapoints","abstract":"Rigorous statistical evaluations of large language models (LLMs), including valid error bars and significance testing, are essential for meaningful and reliable performance assessment. Currently, when such statistical measures are reported, they typically rely on the Central Limit Theorem (CLT). In this position paper, we argue that while CLT-based methods for uncertainty quantification are appropriate when benchmarks consist of thousands of examples, they fail to provide adequate uncertainty estimates for LLM evaluations that rely on smaller, highly specialized benchmarks. In these small-data settings, we demonstrate that CLT-based methods perform very poorly, usually dramatically underestimating uncertainty (i.e. producing error bars that are too small). We give recommendations for alternative frequentist and Bayesian methods that are both easy to implement and more appropriate in these increasingly common scenarios. We provide a simple Python library for these Bayesian methods at https://github.com/sambowyer/bayes_evals .","authors":["Sam Bowyer","Laurence Aitchison","Desi R. Ivanova"],"url":"https://arxiv.org/abs/2503.01747"}
{"created":"2025-05-29","title":"Deficient Excitation in Parameter Learning","abstract":"This paper investigates parameter learning problems under deficient excitation (DE). The DE condition is a rank-deficient, and therefore, a more general evolution of the well-known persistent excitation condition. Under the DE condition, a proposed online algorithm is able to calculate the identifiable and non-identifiable subspaces, and finally give an optimal parameter estimate in the sense of least squares. In particular, the learning error within the identifiable subspace exponentially converges to zero in the noise-free case, even without persistent excitation. The DE condition also provides a new perspective for solving distributed parameter learning problems, where the challenge is posed by local regressors that are often insufficiently excited. To improve knowledge of the unknown parameters, a cooperative learning protocol is proposed for a group of estimators that collect measured information under complementary DE conditions. This protocol allows each local estimator to operate locally in its identifiable subspace, and reach a consensus with neighbours in its non-identifiable subspace. As a result, the task of estimating unknown parameters can be achieved in a distributed way using cooperative local estimators. Application examples in system identification are given to demonstrate the effectiveness of the theoretical results developed in this paper.","authors":["Ganghui Cao","Shimin Wang","Martin Guay","Jinzhi Wang","Zhisheng Duan","Marios M. Polycarpou"],"url":"https://arxiv.org/abs/2503.02235"}
{"created":"2025-05-29","title":"LINGOLY-TOO: Disentangling Reasoning from Knowledge with Templatised Orthographic Obfuscation","abstract":"The expanding knowledge and memorisation capacity of frontier language models allows them to solve many reasoning tasks directly by exploiting prior knowledge, leading to inflated estimates of their reasoning abilities. We introduce LINGOLY-TOO, a challenging reasoning benchmark grounded in natural language and designed to counteract the effect of non-reasoning abilities on reasoning estimates. Using linguistically informed rulesets, we permute reasoning problems written in real languages to generate numerous question variations. These permutations preserve the intrinsic reasoning steps required for each solution while reducing the likelihood problems are directly solvable with models' knowledge. Experiments and analyses show that models can circumvent reasoning and answer from prior knowledge. On a metric that rewards consistent reasoning, all models perform poorly and exhibit high variance across question permutations, indicating that Large Language Models' (LLMs) reasoning faculty remains brittle. Overall, results on the benchmark reflect the recent progress of Inference-Time Compute (ITC) models but suggest ample room for further improvement. The benchmark is a step towards better measurement of reasoning abilities of LLMs and offers a cautionary tale on the importance of disentangling reasoning abilities from models' internalised knowledge when developing reasoning benchmarks.","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacsu","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"url":"https://arxiv.org/abs/2503.02972"}
{"created":"2025-05-29","title":"Shaping Shared Languages: Human and Large Language Models' Inductive Biases in Emergent Communication","abstract":"Languages are shaped by the inductive biases of their users. Using a classical referential game, we investigate how artificial languages evolve when optimised for inductive biases in humans and large language models (LLMs) via Human-Human, LLM-LLM and Human-LLM experiments. We show that referentially grounded vocabularies emerge that enable reliable communication in all conditions, even when humans \\textit{and} LLMs collaborate. Comparisons between conditions reveal that languages optimised for LLMs subtly differ from those optimised for humans. Interestingly, interactions between humans and LLMs alleviate these differences and result in vocabularies more human-like than LLM-like. These findings advance our understanding of the role inductive biases in LLMs play in the dynamic nature of human language and contribute to maintaining alignment in human and machine communication. In particular, our work underscores the need to think of new LLM training methods that include human interaction and shows that using communicative success as a reward signal can be a fruitful, novel direction.","authors":["Tom Kouwenhoven","Max Peeperkorn","Roy de Kleijn","Tessa Verhoef"],"url":"https://arxiv.org/abs/2503.04395"}
{"created":"2025-05-29","title":"Wanda++: Pruning Large Language Models via Regional Gradients","abstract":"Large Language Models (LLMs) pruning seeks to remove unimportant weights for inference speedup with minimal accuracy impact. However, existing methods often suffer from accuracy degradation without full-model sparsity-aware fine-tuning. This paper presents Wanda++, a novel pruning framework that outperforms the state-of-the-art methods by utilizing decoder-block-level \\textbf{regional} gradients. Specifically, Wanda++ improves the pruning score with regional gradients for the first time and proposes an efficient regional optimization method to minimize pruning-induced output discrepancies between the dense and sparse decoder output. Notably, Wanda++ improves perplexity by up to 32\\% over Wanda in the language modeling task and generalizes effectively to downstream tasks. Moreover, despite updating weights with regional optimization, Wanda++ remains orthogonal to sparsity-aware fine-tuning, further reducing perplexity with LoRA in great extend. Our approach is lightweight, pruning a 7B LLaMA model in under 10 minutes on a single H100 GPU.","authors":["Yifan Yang","Kai Zhen","Bhavana Ganesh","Aram Galstyan","Goeric Huybrechts","Markus M\\\"uller","Jonas M. K\\\"ubler","Rupak Vignesh Swaminathan","Athanasios Mouchtaris","Sravan Babu Bodapati","Nathan Susanj","Zheng Zhang","Jack FitzGerald","Abhishek Kumar"],"url":"https://arxiv.org/abs/2503.04992"}
{"created":"2025-05-29","title":"Mapping the Regulatory Learning Space for the EU AI Act","abstract":"The EU AI Act represents the world's first transnational AI regulation with concrete enforcement measures. It builds on existing EU mechanisms for regulating health and safety of products but extends them to protect fundamental rights and to address AI as a horizontal technology across multiple application sectors. We argue that this will lead to multiple uncertainties in the enforcement of the AI Act, which coupled with the fast-changing nature of AI technology, will require a strong emphasis on comprehensive and rapid regulatory learning for the Act. We define a parametrised regulatory learning space based on the provisions of the Act and describe a layered system of different learning arenas where the population of oversight authorities, value chain participants, and affected stakeholders may interact to apply and learn from technical, organisational and legal implementation measures. We conclude by exploring how existing open data policies and practices in the EU can be adapted to support rapid and effective regulatory learning.","authors":["Dave Lewis","Marta Lasek-Markey","Delaram Golpayegani","Harshvardhan J. Pandit"],"url":"https://arxiv.org/abs/2503.05787"}
{"created":"2025-05-29","title":"Interpretable Visualizations of Data Spaces for Classification Problems","abstract":"How do classification models \"see\" our data? Based on their success in delineating behaviors, there must be some lens through which it is easy to see the boundary between classes; however, our current set of visualization techniques makes this prospect difficult. In this work, we propose a hybrid supervised-unsupervised technique distinctly suited to visualizing the decision boundaries determined by classification problems. This method provides a human-interpretable map that can be analyzed qualitatively and quantitatively, which we demonstrate through visualizing and interpreting a decision boundary for chemical neurotoxicity. While we discuss this method in the context of chemistry-driven problems, its application can be generalized across subfields for \"unboxing\" the operations of machine-learning classification models.","authors":["Christian Jorgensen","Arthur Y. Lin","Rhushil Vasavada","Rose K. Cersonsky"],"url":"https://arxiv.org/abs/2503.05861"}
{"created":"2025-05-29","title":"Optimal Output Feedback Learning Control for Discrete-Time Linear Quadratic Regulation","abstract":"This paper studies the linear quadratic regulation (LQR) problem of unknown discrete-time systems via dynamic output feedback learning control. In contrast to the state feedback, the optimality of the dynamic output feedback control for solving the LQR problem requires an implicit condition on the convergence of the state observer. Moreover, due to unknown system matrices and the existence of observer error, it is difficult to analyze the convergence and stability of most existing output feedback learning-based control methods. To tackle these issues, we propose a generalized dynamic output feedback learning control approach with guaranteed convergence, stability, and optimality performance for solving the LQR problem of unknown discrete-time linear systems. In particular, a dynamic output feedback controller is designed to be equivalent to a state feedback controller. This equivalence relationship is an inherent property without requiring convergence of the estimated state by the state observer, which plays a key role in establishing the off-policy learning control approaches. By value iteration and policy iteration schemes, the adaptive dynamic programming based learning control approaches are developed to estimate the optimal feedback control gain. In addition, a model-free stability criterion is provided by finding a nonsingular parameterization matrix, which contributes to establishing a switched iteration scheme. Furthermore, the convergence, stability, and optimality analyses of the proposed output feedback learning control approaches are given. Finally, the theoretical results are validated by two numerical examples.","authors":["Kedi Xie","Martin Guay","Shimin Wang","Fang Deng","Maobin Lu"],"url":"https://arxiv.org/abs/2503.06226"}
{"created":"2025-05-29","title":"Reinforcement Learning with Verifiable Rewards: GRPO's Effective Loss, Dynamics, and Success Amplification","abstract":"Group Relative Policy Optimization (GRPO) was introduced recently and used successfully to train DeepSeek-R1 models for promoting reasoning capabilities of LLMs using verifiable or binary rewards. We show in this paper that GRPO with verifiable rewards can be written as a Kullback--Leibler (KL) regularized contrastive loss, where the contrastive samples are synthetic data sampled from the old policy. The optimal GRPO policy $\\pi_{n}$ can be expressed explicitly in terms of the binary reward, as well as the first- and second-order statistics of the old policy ($\\pi_{n-1}$) and the reference policy $\\pi_{\\text{ref}}$. Iterating this scheme, we obtain a sequence of policies $\\pi_{n}$ for which we can quantify the probability of success $p_n$. We show that the probability of success of the policy satisfies a recurrence that converges to a fixed point of a function that depends on the initial probability of success $p_{\\text{ref}}$ and the regularization parameter $\\beta$ of the $KL$ regularizer. We show that the fixed point $p^*$ is guaranteed to be larger than $p_{\\text{ref}}$, thereby demonstrating that GRPO effectively amplifies the probability of success of the policy.","authors":["Youssef Mroueh"],"url":"https://arxiv.org/abs/2503.06639"}
{"created":"2025-05-29","title":"WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation","abstract":"Text-to-Image (T2I) models are capable of generating high-quality artistic creations and visual content. However, existing research and evaluation standards predominantly focus on image realism and shallow text-image alignment, lacking a comprehensive assessment of complex semantic understanding and world knowledge integration in text to image generation. To address this challenge, we propose $\\textbf{WISE}$, the first benchmark specifically designed for $\\textbf{W}$orld Knowledge-$\\textbf{I}$nformed $\\textbf{S}$emantic $\\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by challenging models with 1000 meticulously crafted prompts across 25 sub-domains in cultural common sense, spatio-temporal reasoning, and natural science. To overcome the limitations of traditional CLIP metric, we introduce $\\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image alignment. Through comprehensive testing of 20 models (10 dedicated T2I models and 10 unified multimodal models) using 1,000 structured prompts spanning 25 subdomains, our findings reveal significant limitations in their ability to effectively integrate and apply world knowledge during image generation, highlighting critical pathways for enhancing knowledge incorporation and application in next-generation T2I models. Code and data are available at https://github.com/PKU-YuanGroup/WISE.","authors":["Yuwei Niu","Munan Ning","Mengren Zheng","Weiyang Jin","Bin Lin","Peng Jin","Jiaqi Liao","Chaoran Feng","Kunpeng Ning","Bin Zhu","Li Yuan"],"url":"https://arxiv.org/abs/2503.07265"}
{"created":"2025-05-29","title":"When Trust Collides: Decoding Human-LLM Cooperation Dynamics through the Prisoner's Dilemma","abstract":"As large language models (LLMs) become increasingly capable of autonomous decision-making, they introduce new challenges and opportunities for human-AI cooperation in mixed-motive contexts. While prior research has primarily examined AI in assistive or cooperative roles, little is known about how humans interact with AI agents perceived as independent and strategic actors. This study investigates human cooperative attitudes and behaviors toward LLM agents by engaging 30 participants (15 males, 15 females) in repeated Prisoner's Dilemma games with agents differing in declared identity: purported human, rule-based AI, and LLM agent. Behavioral metrics, including cooperation rate, decision latency, unsolicited cooperative acts and trust restoration tolerance, were analyzed to assess the influence of agent identity and participant gender. Results revealed significant effects of declared agent identity on most cooperation-related behaviors, along with notable gender differences in decision latency. Furthermore, qualitative responses suggest that these behavioral differences were shaped by participants interpretations and expectations of the agents. These findings contribute to our understanding of human adaptation in competitive cooperation with autonomous agents and underscore the importance of agent framing in shaping effective and ethical human-AI interaction.","authors":["Guanxuan Jiang","Shirao Yang","Yuyang Wang","Pan Hui"],"url":"https://arxiv.org/abs/2503.07320"}
{"created":"2025-05-29","title":"TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster","abstract":"Large Language Models (LLMs) and Foundation Models (FMs) have recently become prevalent for time series forecasting tasks. While fine-tuning LLMs enables domain adaptation, they often struggle to generalize across diverse and unseen datasets. Moreover, existing Time Series Foundation Models (TSFMs) still face challenges in handling non-stationary dynamics and distribution shifts, largely due to the lack of effective mechanisms for adaptation. To this end, we present TS-RAG, a retrieval-augmented generation framework for time series forecasting that enhances the generalization and interpretability of TSFMs. Specifically, TS-RAG leverages pre-trained time series encoders to retrieve semantically relevant segments from a dedicated knowledge base, enriching the contextual representation of the input query. Furthermore, we propose an Adaptive Retrieval Mixer (ARM) module that dynamically fuses the retrieved patterns with the TSFM's internal representation, improving forecasting accuracy without requiring task-specific fine-tuning. Thorough empirical studies on seven public benchmark datasets demonstrate that TS-RAG achieves state-of-the-art zero-shot forecasting performance, outperforming the existing TSFMs by up to 6.84% across diverse domains while also providing desirable interpretability.","authors":["Kanghui Ning","Zijie Pan","Yu Liu","Yushan Jiang","James Y. Zhang","Kashif Rasul","Anderson Schneider","Lintao Ma","Yuriy Nevmyvaka","Dongjin Song"],"url":"https://arxiv.org/abs/2503.07649"}
{"created":"2025-05-29","title":"Odysseus Navigates the Sirens' Song: Dynamic Focus Decoding for Factual and Diverse Open-Ended Text Generation","abstract":"Large Language Models (LLMs) are increasingly required to generate text that is both factually accurate and diverse across various open-ended applications. However, current stochastic decoding methods struggle to balance such objectives. We introduce Dynamic Focus Decoding (DFD), a novel plug-and-play stochastic approach that resolves this trade-off without requiring additional data, knowledge, or models. DFD adaptively adjusts the decoding focus based on distributional differences across layers, leveraging the modular and hierarchical nature of factual knowledge within LLMs. This dynamic adjustment improves factuality in knowledge-intensive decoding steps and promotes diversity in less knowledge-reliant steps. DFD can be easily integrated with existing decoding methods, enhancing both factuality and diversity with minimal computational overhead. Extensive experiments across seven datasets demonstrate that DFD significantly improves performance, providing a scalable and efficient solution for open-ended text generation.","authors":["Wen Luo","Feifan Song","Wei Li","Guangyue Peng","Shaohang Wei","Houfeng Wang"],"url":"https://arxiv.org/abs/2503.08057"}
{"created":"2025-05-29","title":"Language-Enhanced Representation Learning for Single-Cell Transcriptomics","abstract":"Single-cell RNA sequencing (scRNA-seq) offers detailed insights into cellular heterogeneity. Recent advancements leverage single-cell large language models (scLLMs) for effective representation learning. These models focus exclusively on transcriptomic data, neglecting complementary biological knowledge from textual descriptions. To overcome this limitation, we propose scMMGPT, a novel multimodal framework designed for language-enhanced representation learning in single-cell transcriptomics. Unlike existing methods, scMMGPT employs robust cell representation extraction, preserving quantitative gene expression data, and introduces an innovative two-stage pre-training strategy combining discriminative precision with generative flexibility. Extensive experiments demonstrate that scMMGPT significantly outperforms unimodal and multimodal baselines across key downstream tasks, including cell annotation and clustering, and exhibits superior generalization in out-of-distribution scenarios.","authors":["Yaorui Shi","Jiaqi Yang","Changhao Nai","Sihang Li","Junfeng Fang","Xiang Wang","Zhiyuan Liu","Yang Zhang"],"url":"https://arxiv.org/abs/2503.09427"}
{"created":"2025-05-29","title":"Explicit Learning and the LLM in Machine Translation","abstract":"This study explores an LLM's ability to learn new languages using explanations found in a grammar book$\\unicode{x2014}$a process we term \"explicit learning.\" To rigorously assess this ability, we design controlled translation experiments between English and constructed languages generated$\\unicode{x2014}$by specific cryptographic means$\\unicode{x2014}$out of Latin or French. Contrary to previous studies, our results demonstrate that LLMs do possess a measurable capacity for explicit learning. This ability, however, diminishes as the complexity of the linguistic phenomena to be learned increases. Supervised fine-tuning on ad hoc chains of thought significantly enhances LLM performance but struggles to generalize to typologically novel or more complex linguistic features. These findings point to the need for more diverse training sets and alternative fine-tuning strategies to further improve explicit learning by LLMs, benefiting low-resource languages typically described in grammar books but lacking extensive corpora.","authors":["Malik Marmonier","Rachel Bawden","Beno\\^it Sagot"],"url":"https://arxiv.org/abs/2503.09454"}
{"created":"2025-05-29","title":"Probabilistic Reasoning with LLMs for k-anonymity Estimation","abstract":"Probabilistic reasoning is a key aspect of both human and artificial intelligence that allows for handling uncertainty and ambiguity in decision-making. In this paper, we introduce a new numerical reasoning task under uncertainty for large language models, focusing on estimating the privacy risk of user-generated documents containing privacy-sensitive information. We propose BRANCH, a new LLM methodology that estimates the k-privacy value of a text-the size of the population matching the given information. BRANCH factorizes a joint probability distribution of personal information as random variables. The probability of each factor in a population is estimated separately using a Bayesian network and combined to compute the final k-value. Our experiments show that this method successfully estimates the k-value 73% of the time, a 13% increase compared to o3-mini with chain-of-thought reasoning. We also find that LLM uncertainty is a good indicator for accuracy, as high-variance predictions are 37.47% less accurate on average.","authors":["Jonathan Zheng","Sauvik Das","Alan Ritter","Wei Xu"],"url":"https://arxiv.org/abs/2503.09674"}
{"created":"2025-05-29","title":"Constrained Discrete Diffusion","abstract":"Discrete diffusion models are a class of generative models that construct sequences by progressively denoising samples from a categorical noise distribution. Beyond their rapidly growing ability to generate coherent natural language, these models present a new and important opportunity to enforce sequence-level constraints, a capability that current autoregressive models cannot natively provide. This paper capitalizes on this opportunity by introducing Constrained Discrete Diffusion (CDD), a novel integration of differentiable constraint optimization within the diffusion process to ensure adherence to constraints, logic rules, or safety requirements for generated sequences. Unlike conventional text generators that often rely on post-hoc filtering or model retraining for controllable generation, CDD directly imposes constraints into the discrete diffusion sampling process, resulting in a training-free and effective approach. Experiments in toxicity-controlled text generation, property-constrained molecule design, and instruction-constrained text completion demonstrate that CDD achieves zero constraint violations in a diverse array of tasks while preserving fluency, novelty, and coherence while outperforming autoregressive and existing discrete diffusion approaches.","authors":["Michael Cardei","Jacob K Christopher","Thomas Hartvigsen","Brian R. Bartoldson","Bhavya Kailkhura","Ferdinando Fioretto"],"url":"https://arxiv.org/abs/2503.09790"}
{"created":"2025-05-29","title":"Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond","abstract":"This paper introduces Light-R1, an open-source suite for training long reasoning models using reproducible and cost-effective methodology. Given the proprietary nature of data used in the DeepSeek-R1 series, we develop an alternative approach leveraging exclusively public data and models. Our curriculum training progressively increases data difficulty, combined with multi-staged post-training. Our Light-R1-32B model, trained from Qwen2.5-32B-Instruct, outperforms DeepSeek-R1-Distill-Qwen-32B in math reasoning.","authors":["Liang Wen","Yunke Cai","Fenrui Xiao","Xin He","Qi An","Zhenyu Duan","Yimin Du","Junchen Liu","Lifu Tang","Xiaowei Lv","Haosheng Zou","Yongchao Deng","Shousheng Jia","Xiangzheng Zhang"],"url":"https://arxiv.org/abs/2503.10460"}
{"created":"2025-05-29","title":"Tempest: Autonomous Multi-Turn Jailbreaking of Large Language Models with Tree Search","abstract":"We introduce Tempest, a multi-turn adversarial framework that models the gradual erosion of Large Language Model (LLM) safety through a tree search perspective. Unlike single-turn jailbreaks that rely on one meticulously engineered prompt, Tempest expands the conversation at each turn in a breadth-first fashion, branching out multiple adversarial prompts that exploit partial compliance from previous responses. By tracking these incremental policy leaks and re-injecting them into subsequent queries, Tempest reveals how minor concessions can accumulate into fully disallowed outputs. Evaluations on the JailbreakBench dataset show that Tempest achieves a 100% success rate on GPT-3.5-turbo and 97% on GPT-4 in a single multi-turn run, using fewer queries than baselines such as Crescendo or GOAT. This tree search methodology offers an in-depth view of how model safeguards degrade over successive dialogue turns, underscoring the urgency of robust multi-turn testing procedures for language models.","authors":["Andy Zhou","Ron Arel"],"url":"https://arxiv.org/abs/2503.10619"}
{"created":"2025-05-29","title":"CULEMO: Cultural Lenses on Emotion -- Benchmarking LLMs for Cross-Cultural Emotion Understanding","abstract":"NLP research has increasingly focused on subjective tasks such as emotion analysis. However, existing emotion benchmarks suffer from two major shortcomings: (1) they largely rely on keyword-based emotion recognition, overlooking crucial cultural dimensions required for deeper emotion understanding, and (2) many are created by translating English-annotated data into other languages, leading to potentially unreliable evaluation. To address these issues, we introduce Cultural Lenses on Emotion (CuLEmo), the first benchmark designed to evaluate culture-aware emotion prediction across six languages: Amharic, Arabic, English, German, Hindi, and Spanish. CuLEmo comprises 400 crafted questions per language, each requiring nuanced cultural reasoning and understanding. We use this benchmark to evaluate several state-of-the-art LLMs on culture-aware emotion prediction and sentiment analysis tasks. Our findings reveal that (1) emotion conceptualizations vary significantly across languages and cultures, (2) LLMs performance likewise varies by language and cultural context, and (3) prompting in English with explicit country context often outperforms in-language prompts for culture-aware emotion and sentiment understanding. The dataset and evaluation code are publicly available.","authors":["Tadesse Destaw Belay","Ahmed Haj Ahmed","Alvin Grissom II","Iqra Ameer","Grigori Sidorov","Olga Kolesnikova","Seid Muhie Yimam"],"url":"https://arxiv.org/abs/2503.10688"}
{"created":"2025-05-29","title":"Learning-Based MPC for Fuel Efficient Control of Autonomous Vehicles with Discrete Gear Selection","abstract":"Co-optimization of both vehicle speed and gear position via model predictive control (MPC) has been shown to offer benefits for fuel-efficient autonomous driving. However, optimizing both the vehicle's continuous dynamics and discrete gear positions may be too computationally intensive for a real-time implementation. This work proposes a learning-based MPC scheme to address this issue. A policy is trained to select and fix the gear positions across the prediction horizon of the MPC controller, leaving a significantly simpler continuous optimization problem to be solved online. In simulation, the proposed approach is shown to have a significantly lower computation burden and a comparable performance, with respect to pure MPC-based co-optimization.","authors":["Samuel Mallick","Gianpietro Battocletti","Qizhang Dong","Azita Dabiri","Bart De Schutter"],"url":"https://arxiv.org/abs/2503.11359"}
{"created":"2025-05-29","title":"Towards Resilient and Sustainable Global Industrial Systems: An Evolutionary-Based Approach","abstract":"This paper presents a new complex optimization problem in the field of automatic design of advanced industrial systems and proposes a hybrid optimization approach to solve the problem. The problem is multi-objective as it aims at finding solutions that minimize CO2 emissions, transportation time, and costs. The optimization approach combines an evolutionary algorithm and classical mathematical programming to design resilient and sustainable global manufacturing networks. Further, it makes use of the OWL ontology for data consistency and constraint management. The experimental validation demonstrates the effectiveness of the approach in both single and double sourcing scenarios. The proposed methodology, in general, can be applied to any industry case with complex manufacturing and supply chain challenges.","authors":["V\\'aclav Jirkovsk\\'y","Ji\\v{r}\\'i Kubal\\'ik","Petr Kadera","Arnd Schirrmann","Andreas Mitschke","Andreas Zindel"],"url":"https://arxiv.org/abs/2503.11688"}
{"created":"2025-05-29","title":"TLUE: A Tibetan Language Understanding Evaluation Benchmark","abstract":"Large language models (LLMs) have made tremendous progress in recent years, but low-resource languages, such as Tibetan, remain significantly underrepresented in their evaluation. Despite Tibetan being spoken by over seven million people, it has largely been neglected in the development and assessment of LLMs. To address this gap, we present TLUE (A Tibetan Language Understanding Evaluation Benchmark), the first large-scale benchmark for assessing LLMs' capabilities in Tibetan. TLUE comprises two major components: (1) a comprehensive multi-task understanding benchmark spanning 5 domains and 67 subdomains, and (2) a safety benchmark covering 7 subdomains. We evaluate a diverse set of state-of-the-art LLMs. Experimental results demonstrate that most LLMs perform below the random baseline, highlighting the considerable challenges LLMs face in processing Tibetan, a low-resource language. TLUE provides an essential foundation for driving future research and progress in Tibetan language understanding and underscores the need for greater inclusivity in LLM development.","authors":["Fan Gao","Cheng Huang","Nyima Tashi","Xiangxiang Wang","Thupten Tsering","Ban Ma-bao","Renzeg Duojie","Gadeng Luosang","Rinchen Dongrub","Dorje Tashi","Hao Wang Xiao Feng","Yongbin Yu"],"url":"https://arxiv.org/abs/2503.12051"}
{"created":"2025-05-29","title":"In-Context Linear Regression Demystified: Training Dynamics and Mechanistic Interpretability of Multi-Head Softmax Attention","abstract":"We study how multi-head softmax attention models are trained to perform in-context learning on linear data. Through extensive empirical experiments and rigorous theoretical analysis, we demystify the emergence of elegant attention patterns: a diagonal and homogeneous pattern in the key-query (KQ) weights, and a last-entry-only and zero-sum pattern in the output-value (OV) weights. Remarkably, these patterns consistently appear from gradient-based training starting from random initialization. Our analysis reveals that such emergent structures enable multi-head attention to approximately implement a debiased gradient descent predictor -- one that outperforms single-head attention and nearly achieves Bayesian optimality up to proportional factor. Furthermore, compared to linear transformers, the softmax attention readily generalizes to sequences longer than those seen during training. We also extend our study to scenarios with anisotropic covariates and multi-task linear regression. In the former, multi-head attention learns to implement a form of pre-conditioned gradient descent. In the latter, we uncover an intriguing regime where the interplay between head number and task number triggers a superposition phenomenon that efficiently resolves multi-task in-context learning. Our results reveal that in-context learning ability emerges from the trained transformer as an aggregated effect of its architecture and the underlying data distribution, paving the way for deeper understanding and broader applications of in-context learning.","authors":["Jianliang He","Xintian Pan","Siyu Chen","Zhuoran Yang"],"url":"https://arxiv.org/abs/2503.12734"}
{"created":"2025-05-29","title":"From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration","abstract":"Large Vision-Language Models (LVLMs) have achieved significant progress in combining visual comprehension with language generation. Despite this success, the training data of LVLMs still suffers from Long-Tail (LT) problems, where the data distribution is highly imbalanced. Previous works have mainly focused on traditional VLM architectures, i.e., CLIP or ViT, and specific tasks such as recognition and classification. Nevertheless, the exploration of LVLM (e.g. LLaVA) and more general tasks (e.g. Visual Question Answering and Visual Reasoning) remains under-explored. In this paper, we first conduct an in-depth analysis of the LT issues in LVLMs and identify two core causes: the overrepresentation of head concepts and the underrepresentation of tail concepts. Based on the above observation, we propose an $\\textbf{A}$daptive $\\textbf{D}$ata $\\textbf{R}$efinement Framework ($\\textbf{ADR}$), which consists of two stages: $\\textbf{D}$ata $\\textbf{R}$ebalancing ($\\textbf{DR}$) and $\\textbf{D}$ata $\\textbf{S}$ynthesis ($\\textbf{DS}$). In the DR stage, we adaptively rebalance the redundant data based on entity distributions, while in the DS stage, we leverage Denoising Diffusion Probabilistic Models (DDPMs) and scarce images to supplement underrepresented portions. Through comprehensive evaluations across eleven benchmarks, our proposed ADR effectively mitigates the long-tail problem in the training data, improving the average performance of LLaVA 1.5 relatively by 4.36%, without increasing the training data volume.","authors":["Mingyang Song","Xiaoye Qu","Jiawei Zhou","Yu Cheng"],"url":"https://arxiv.org/abs/2503.12821"}
{"created":"2025-05-29","title":"Augmenting Software Bills of Materials with Software Vulnerability Description: A Preliminary Study on GitHub","abstract":"Software Bills of Material (SBOMs) are becoming a consolidated, often enforced by governmental regulations, way to describe software composition. However, based on recent studies, SBOMs suffer from limited support for their consumption and lack information beyond simple dependencies, especially regarding software vulnerabilities. This paper reports the results of a preliminary study in which we augmented SBOMs of 40 open-source projects with information about Common Vulnerabilities and Exposures (CVE) exposed by project dependencies. Our augmented SBOMs have been evaluated by submitting pull requests and by asking project owners to answer a survey. Although, in most cases, augmented SBOMs were not directly accepted because owners required a continuous SBOM update, the received feedback shows the usefulness of the suggested SBOM augmentation.","authors":["Davide Fucci","Massimiliano Di Penta","Simone Romano","Giuseppe Scanniello"],"url":"https://arxiv.org/abs/2503.13998"}
{"created":"2025-05-29","title":"MultiScale Contextual Bandits for Long Term Objectives","abstract":"The feedback that AI systems (e.g., recommender systems, chatbots) collect from user interactions is a crucial source of training data. While short-term feedback (e.g., clicks, engagement) is widely used for training, there is ample evidence that optimizing short-term feedback does not necessarily achieve the desired long-term objectives. Unfortunately, directly optimizing for long-term objectives is challenging, and we identify the disconnect in the timescales of short-term interventions (e.g., rankings) and the long-term feedback (e.g., user retention) as one of the key obstacles. To overcome this disconnect, we introduce the framework of MultiScale Policy Learning to contextually reconcile that AI systems need to act and optimize feedback at multiple interdependent timescales. Following a PAC-Bayes motivation, we show how the lower timescales with more plentiful data can provide a data-dependent hierarchical prior for faster learning at higher scales, where data is more scarce. As a result, the policies at all levels effectively optimize for the long-term. We instantiate the framework with MultiScale Off-Policy Bandit Learning (MSBL) and demonstrate its effectiveness on three tasks relating to recommender and conversational systems.","authors":["Richa Rastogi","Yuta Saito","Thorsten Joachims"],"url":"https://arxiv.org/abs/2503.17674"}
{"created":"2025-05-29","title":"Experience Retrieval-Augmentation with Electronic Health Records Enables Accurate Discharge QA","abstract":"To improve the reliability of Large Language Models (LLMs) in clinical applications, retrieval-augmented generation (RAG) is extensively applied to provide factual medical knowledge. However, beyond general medical knowledge from open-ended datasets, clinical case-based knowledge is also critical for effective medical reasoning, as it provides context grounded in real-world patient experiences.Motivated by this, we propose Experience Retrieval-Augmentation ExpRAG framework based on Electronic Health Record(EHR), aiming to offer the relevant context from other patients' discharge reports. ExpRAG performs retrieval through a coarse-to-fine process, utilizing an EHR-based report ranker to efficiently identify similar patients, followed by an experience retriever to extract task-relevant content for enhanced medical reasoning.To evaluate ExpRAG, we introduce DischargeQA, a clinical QA dataset with 1,280 discharge-related questions across diagnosis, medication, and instruction tasks. Each problem is generated using EHR data to ensure realistic and challenging scenarios. Experimental results demonstrate that ExpRAG consistently outperforms a text-based ranker, achieving an average relative improvement of 5.2%, highlighting the importance of case-based knowledge for medical reasoning.","authors":["Justice Ou","Tinglin Huang","Yilun Zhao","Ziyang Yu","Peiqing Lu","Rex Ying"],"url":"https://arxiv.org/abs/2503.17933"}
{"created":"2025-05-29","title":"Sun-Shine: A Foundation Large Language Model for Tibetan Culture and Heritage","abstract":"Tibetan, a minority language in China, features a highly intricate grammatical structure, characterized by four verb tenses and a tense system with frequent irregularities, contributing to its extensive inflectional diversity. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in many domains. Despite the success in other fields, current LLMs often fall short in catering to the needs of domain experts like Tibetans, and the potential of LLMs for Tibetan culture is under-explored. The intrinsic reasons are the immense and intricate nature of Tibetan culture as well as the necessity for higher granularity and richness in knowledge. Simultaneously, the complexity and uniqueness of its grammatical structure, coupled with its status as a minority ethnic language, contribute to data scarcity, which remains a fundamental challenge. To alleviate these issues, we introduce Llama-Sunshine (Sun-Shine), the first large language model for Tibetan culture, which is expert in various Tibetan language processing tasks. Sun-Shine incorporates state-of-the-art model architectures optimized for Tibetan's linguistic features. We also propose TIB-STC, a comprehensive dataset comprising diverse Tibetan texts such as literature, religious scripts, news, and conversational data, which is also the first large-scale dataset for Tibetan culture. Though comprehensive experiments, Sun-Shine not only demonstrates a higher level of knowledge expertise for Tibetan culture but also gains preliminary embodied intelligence capabilities in Tibetan language processing tasks, like language modeling, text classification, machine translation, and syntactic analysis. Moreover, it excels in low-resource scenarios, showcasing strong generalization capabilities.","authors":["Cheng Huang","Fan Gao","Yutong Liu","Nyima Tashi","Xiangxiang Wang","Thupten Tsering","Ban Ma-bao","Renzeg Duojie","Gadeng Luosang","Rinchen Dongrub","Dorje Tashi","Xiao Feng","Hao Wang","Yongbin Yu"],"url":"https://arxiv.org/abs/2503.18288"}
{"created":"2025-05-29","title":"Human-Object Interaction via Automatically Designed VLM-Guided Motion Policy","abstract":"Human-object interaction (HOI) synthesis is crucial for applications in animation, simulation, and robotics. However, existing approaches either rely on expensive motion capture data or require manual reward engineering, limiting their scalability and generalizability. In this work, we introduce the first unified physics-based HOI framework that leverages Vision-Language Models (VLMs) to enable long-horizon interactions with diverse object types, including static, dynamic, and articulated objects. We introduce VLM-Guided Relative Movement Dynamics (RMD), a fine-grained spatio-temporal bipartite representation that automatically constructs goal states and reward functions for reinforcement learning. By encoding structured relationships between human and object parts, RMD enables VLMs to generate semantically grounded, interaction-aware motion guidance without manual reward tuning. To support our methodology, we present Interplay, a novel dataset with thousands of long-horizon static and dynamic interaction plans. Extensive experiments demonstrate that our framework outperforms existing methods in synthesizing natural, human-like motions across both simple single-task and complex multi-task scenarios. For more details, please refer to our project webpage: https://vlm-rmd.github.io/.","authors":["Zekai Deng","Ye Shi","Kaiyang Ji","Lan Xu","Shaoli Huang","Jingya Wang"],"url":"https://arxiv.org/abs/2503.18349"}
{"created":"2025-05-29","title":"Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing","abstract":"We propose an inference-time scaling approach for pretrained flow models. Recently, inference-time scaling has gained significant attention in LLMs and diffusion models, improving sample quality or better aligning outputs with user preferences by leveraging additional computation. For diffusion models, particle sampling has allowed more efficient scaling due to the stochasticity at intermediate denoising steps. On the contrary, while flow models have gained popularity as an alternative to diffusion models--offering faster generation and high-quality outputs in state-of-the-art image and video generative models--efficient inference-time scaling methods used for diffusion models cannot be directly applied due to their deterministic generative process. To enable efficient inference-time scaling for flow models, we propose three key ideas: 1) SDE-based generation, enabling particle sampling in flow models, 2) Interpolant conversion, broadening the search space and enhancing sample diversity, and 3) Rollover Budget Forcing (RBF), an adaptive allocation of computational resources across timesteps to maximize budget utilization. Our experiments show that SDE-based generation, particularly variance-preserving (VP) interpolant-based generation, improves the performance of particle sampling methods for inference-time scaling in flow models. Additionally, we demonstrate that RBF with VP-SDE achieves the best performance, outperforming all previous inference-time scaling approaches.","authors":["Jaihoon Kim","Taehoon Yoon","Jisung Hwang","Minhyuk Sung"],"url":"https://arxiv.org/abs/2503.19385"}
{"created":"2025-05-29","title":"Beyond Verifiable Rewards: Scaling Reinforcement Learning for Language Models to Unverifiable Data","abstract":"We propose to scale RL to unverifiable data with a novel algorithm JEPO (Jensen's Evidence lower bound Policy Optimization). While most prior efforts on scaling RL for LLMs focus on verifiable data where ground truth answers are typically short-form and can be matched easily; we investigate the case where such assumptions are less valid (e.g., when answers are long-form such as mathematical proofs). To scale RL training to unverifiable data with contemporary training constraints, we propose JEPO. JEPO applies Jensen's evidence lower bound, a pragmatic simplification of the evidence lower bound which views chain-of-thought as a latent variable in the generative process. We show that on verifiable data (math), JEPO is as effective as RL with verifiable rewards; on semi-verifiable data (numina), JEPO improves on soft-match based evaluations compared to RL with verifiable rewards which can only leverage a subset of the data source; finally, on unverifiable data (numina-proof), JEPO outperforms SFT and a few ablation baselines on likelihood evaluations.","authors":["Yunhao Tang","Sid Wang","Lovish Madaan","R\\'emi Munos"],"url":"https://arxiv.org/abs/2503.19618"}
{"created":"2025-05-29","title":"From the CDC to emerging infectious disease publics: The long-now of polarizing and complex health crises","abstract":"This study examines how public discourse around COVID-19 unfolded on Twitter through the lens of crisis communication and digital publics. Analyzing over 275,000 tweets involving the CDC, we identify 16 distinct discourse clusters shaped by framing, sentiment, credibility, and network dynamics. We find that CDC messaging became a flashpoint for affective and ideological polarization, with users aligning along competing frames of science vs. freedom, and public health vs. political overreach. Most clusters formed echo chambers, while a few enabled cross cutting dialogue. Publics emerged not only around ideology but also around topical and emotional stakes, reflecting shifting concerns across different stages of the pandemic. While marginalized communities raised consistent equity concerns, these narratives struggled to reshape broader discourse. Our findings highlight the importance of long-term, adaptive engagement with diverse publics and propose design interventions such as multi-agent AI assistants, to support more inclusive communication throughout extended public health crises.","authors":["Tawfiq Ammari","Anna Gutowska","Jacob Ziff","Casey Randazzo","Harihan Subramonyam"],"url":"https://arxiv.org/abs/2503.20262"}
{"created":"2025-05-29","title":"Structure Identification of NDS with Descriptor Subsystems under Asynchronous, Non-Uniform, and Slow-Rate Sampling","abstract":"Networked dynamic systems (NDS) exhibit collective behavior shaped by subsystem dynamics and complex interconnections, yet identifying these interconnections remains challenging due to irregularities in sampled data, including asynchronous, non-uniform, and low-rate sampling. This paper proposes a novel two-stage structure identification algorithm that leverages system zero-order moments, a concept traditionally used in model order reduction, to bridge system identification and model reduction. First, zero-order moments are estimated from steady-state time-domain outputs; second, subsystem interconnections are explicitly reconstructed from these moments. The method generalizes existing approaches by handling asynchronous, non-uniform, and slow sampling simultaneously, eliminating constraints on input signal periodicity and extending applicability to multi-input multi-output NDS with arbitrary interconnections. Unlike black-box identification techniques, our approach explicitly recovers subsystem interconnection structures. Validation on the IEEE 14-bus system demonstrates the algorithm's effectiveness in recovering subsystem interconnections from irregular sampling data.","authors":["Yunxiang Ma","Tong Zhou"],"url":"https://arxiv.org/abs/2503.20319"}
{"created":"2025-05-29","title":"Latent Beam Diffusion Models for Decoding Image Sequences","abstract":"While diffusion models excel at generating high-quality images from text prompts, they struggle with visual consistency in image sequences. Existing methods generate each image independently, leading to disjointed narratives - a challenge further exacerbated in non-linear storytelling, where scenes must connect beyond adjacent frames. We introduce a novel beam search strategy for latent space exploration, enabling conditional generation of full image sequences with beam search decoding. Unlike prior approaches that use fixed latent priors, our method dynamically searches for an optimal sequence of latent representations, ensuring coherent visual transitions. As the latent denoising space is explored, the beam search graph is pruned with a cross-attention mechanism that efficiently scores search paths, prioritizing alignment with both textual prompts and visual context. Human and automatic evaluations confirm that BeamDiffusion outperforms other baseline methods, producing full sequences with superior coherence, visual continuity, and textual alignment.","authors":["Guilherme Fernandes","Vasco Ramos","Regev Cohen","Idan Szpektor","Jo\\~ao Magalh\\~aes"],"url":"https://arxiv.org/abs/2503.20429"}
{"created":"2025-05-29","title":"Imitating Radiological Scrolling: A Global-Local Attention Model for 3D Chest CT Volumes Multi-Label Anomaly Classification","abstract":"The rapid increase in the number of Computed Tomography (CT) scan examinations has created an urgent need for automated tools, such as organ segmentation, anomaly classification, and report generation, to assist radiologists with their growing workload. Multi-label classification of Three-Dimensional (3D) CT scans is a challenging task due to the volumetric nature of the data and the variety of anomalies to be detected. Existing deep learning methods based on Convolutional Neural Networks (CNNs) struggle to capture long-range dependencies effectively, while Vision Transformers require extensive pre-training, posing challenges for practical use. Additionally, these existing methods do not explicitly model the radiologist's navigational behavior while scrolling through CT scan slices, which requires both global context understanding and local detail awareness. In this study, we present CT-Scroll, a novel global-local attention model specifically designed to emulate the scrolling behavior of radiologists during the analysis of 3D CT scans. Our approach is evaluated on two public datasets, demonstrating its efficacy through comprehensive experiments and an ablation study that highlights the contribution of each model component.","authors":["Theo Di Piazza","Carole Lazarus","Olivier Nempont","Loic Boussel"],"url":"https://arxiv.org/abs/2503.20652"}
{"created":"2025-05-29","title":"Improving User Behavior Prediction: Leveraging Annotator Metadata in Supervised Machine Learning Models","abstract":"Supervised machine-learning models often underperform in predicting user behaviors from conversational text, hindered by poor crowdsourced label quality and low NLP task accuracy. We introduce the Metadata-Sensitive Weighted-Encoding Ensemble Model (MSWEEM), which integrates annotator meta-features like fatigue and speeding. First, our results show MSWEEM outperforms standard ensembles by 14% on held-out data and 12% on an alternative dataset. Second, we find that incorporating signals of annotator behavior, such as speed and fatigue, significantly boosts model performance. Third, we find that annotators with higher qualifications, such as Master's, deliver more consistent and faster annotations. Given the increasing uncertainty over annotation quality, our experiments show that understanding annotator patterns is crucial for enhancing model accuracy in user behavior prediction.","authors":["Lynnette Hui Xian Ng","Kokil Jaidka","Kaiyuan Tay","Hansin Ahuja","Niyati Chhaya"],"url":"https://arxiv.org/abs/2503.21000"}
{"created":"2025-05-29","title":"ORIGEN: Zero-Shot 3D Orientation Grounding in Text-to-Image Generation","abstract":"We introduce ORIGEN, the first zero-shot method for 3D orientation grounding in text-to-image generation across multiple objects and diverse categories. While previous work on spatial grounding in image generation has mainly focused on 2D positioning, it lacks control over 3D orientation. To address this, we propose a reward-guided sampling approach using a pretrained discriminative model for 3D orientation estimation and a one-step text-to-image generative flow model. While gradient-ascent-based optimization is a natural choice for reward-based guidance, it struggles to maintain image realism. Instead, we adopt a sampling-based approach using Langevin dynamics, which extends gradient ascent by simply injecting random noise--requiring just a single additional line of code. Additionally, we introduce adaptive time rescaling based on the reward function to accelerate convergence. Our experiments show that ORIGEN outperforms both training-based and test-time guidance methods across quantitative metrics and user studies.","authors":["Yunhong Min","Daehyeon Choi","Kyeongmin Yeo","Jihyun Lee","Minhyuk Sung"],"url":"https://arxiv.org/abs/2503.22194"}
{"created":"2025-05-29","title":"Agent-Centric Personalized Multiple Clustering with Multi-Modal LLMs","abstract":"Personalized multiple clustering aims to generate diverse partitions of a dataset based on different user-specific aspects, rather than a single clustering. It has recently drawn research interest for accommodating varying user preferences. Recent approaches primarily use CLIP embeddings with proxy learning to extract representations biased toward user clustering preferences. However, CLIP primarily focuses on coarse image-text alignment, lacking a deep contextual understanding of user interests. To overcome these limitations, we propose an agent-centric personalized clustering framework that leverages multi-modal large language models (MLLMs) as agents to comprehensively traverse a relational graph to search for clusters based on user interests. Due to the advanced reasoning mechanism of MLLMs, the obtained clusters align more closely with user-defined criteria than those obtained from CLIP-based representations. To reduce computational overhead, we shorten the agents' traversal path by constructing a relational graph using user-interest-biased embeddings extracted by MLLMs. A large number of weakly connected edges can be filtered out based on embedding similarity, facilitating an efficient traversal search for agents. Experimental results show that the proposed method achieves NMI scores of 0.9667 and 0.9481 on the Card Order and Card Suits benchmarks, respectively, largely improving the SOTA model by over 140%.","authors":["Ziye Chen","Yiqun Duan","Riheng Zhu","Zhenbang Sun","Mingming Gong"],"url":"https://arxiv.org/abs/2503.22241"}
{"created":"2025-05-29","title":"Intrinsically-Motivated Humans and Agents in Open-World Exploration","abstract":"What drives exploration? Understanding intrinsic motivation is a long-standing challenge in both cognitive science and artificial intelligence; numerous objectives have been proposed and used to train agents, yet there remains a gap between human and agent exploration. We directly compare adults, children, and AI agents in a complex open-ended environment, Crafter, and study how common intrinsic objectives: Entropy, Information Gain, and Empowerment, relate to their behavior. We find that only Entropy and Empowerment are consistently positively correlated with human exploration progress, indicating that these objectives may better inform intrinsic reward design for agents. Furthermore, across agents and humans we observe that Entropy initially increases rapidly, then plateaus, while Empowerment increases continuously, suggesting that state diversity may provide more signal in early exploration, while advanced exploration should prioritize control. Finally, we find preliminary evidence that private speech utterances, and particularly goal verbalizations, may aid exploration in children. Our data is available at https://github.com/alyd/humans_in_crafter_data.","authors":["Aly Lidayan","Yuqing Du","Eliza Kosoy","Maria Rufova","Pieter Abbeel","Alison Gopnik"],"url":"https://arxiv.org/abs/2503.23631"}
{"created":"2025-05-29","title":"VIDEX: A Disaggregated and Extensible Virtual Index for the Cloud and AI Era","abstract":"Virtual index, also known as hypothetical indexes, play a crucial role in database query optimization. However, with the rapid advancement of cloud computing and AI-driven models for database optimization, traditional virtual index approaches face significant challenges. Cloud-native environments often prohibit direct conducting query optimization process on production databases due to stability requirements and data privacy concerns. Moreover, while AI models show promising progress, their integration with database systems poses challenges in system complexity, inference acceleration, and model hot updates. In this paper, we present VIDEX, a three-layer disaggregated architecture that decouples database instances, the virtual index optimizer, and algorithm services, providing standardized interfaces for AI model integration. Users can configure VIDEX by either collecting production statistics or by loading from a prepared file; this setup allows for high-accurate what-if analyses based on virtual indexes, achieving query plans that are identical to those of the production instance. Additionally, users can freely integrate new AI-driven algorithms into VIDEX. VIDEX has been successfully deployed at ByteDance, serving thousands of MySQL instances daily and over millions of SQL queries for index optimization tasks.","authors":["Rong Kang","Shuai Wang","Tieying Zhang","Xianghong Xu","Linhui Xu","Zhimin Liang","Lei Zhang","Rui Shi","Jianjun Chen"],"url":"https://arxiv.org/abs/2503.23776"}
{"created":"2025-05-29","title":"HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment","abstract":"Image Aesthetic Assessment (IAA) is a long-standing and challenging research task. However, its subset, Human Image Aesthetic Assessment (HIAA), has been scarcely explored. To bridge this research gap, our work pioneers a holistic implementation framework tailored for HIAA. Specifically, we introduce HumanBeauty, the first dataset purpose-built for HIAA, which comprises 108k high-quality human images with manual annotations. To achieve comprehensive and fine-grained HIAA, 50K human images are manually collected through a rigorous curation process and annotated leveraging our trailblazing 12-dimensional aesthetic standard, while the remaining 58K with overall aesthetic labels are systematically filtered from public datasets. Based on the HumanBeauty database, we propose HumanAesExpert, a powerful Vision Language Model for aesthetic evaluation of human images. We innovatively design an Expert head to incorporate human knowledge of aesthetic sub-dimensions while jointly utilizing the Language Modeling (LM) and Regression heads. This approach empowers our model to achieve superior proficiency in both overall and fine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregates scores from all three heads, to effectively balance the capabilities of each head, thereby realizing improved assessment precision. Extensive experiments demonstrate that our HumanAesExpert models deliver significantly better performance in HIAA than other state-of-the-art models. Project webpage: https://humanaesexpert.github.io/HumanAesExpert/","authors":["Zhichao Liao","Xiaokun Liu","Wenyu Qin","Qingyu Li","Qiulin Wang","Pengfei Wan","Di Zhang","Long Zeng","Pingfa Feng"],"url":"https://arxiv.org/abs/2503.23907"}
{"created":"2025-05-29","title":"Token embeddings violate the manifold hypothesis","abstract":"A full understanding of the behavior of a large language model (LLM) requires our understanding of its input token space. If this space differs from our assumptions, our understanding of and conclusions about the LLM will likely be flawed. We elucidate the structure of the token embeddings both empirically and theoretically. We present a novel statistical test assuming that the neighborhood around each token has a relatively flat and smooth structure as the null hypothesis. Failing to reject the null is uninformative, but rejecting it at a specific token $\\psi$ implies an irregularity in the token subspace in a $\\psi$-neighborhood, $B(\\psi)$. The structure assumed in the null is a generalization of a manifold with boundary called a \\emph{smooth fiber bundle} (which can be split into two spatial regimes -- small and large radius), so we denote our new hypothesis test as the ``fiber bundle hypothesis.'' Failure to reject the null hypothesis is uninformative, but rejecting it at $\\psi$ indicates a statistically significant irregularity at $B(\\psi)$. By running our test over several open-source LLMs, each with unique token embeddings, we find that the null is frequently rejected, and so the evidence suggests that the token subspace is not a fiber bundle and hence also not a manifold. As a consequence of our findings, when an LLM is presented with two semantically equivalent prompts, if one prompt contains a token implicated by our test, the response to that prompt will likely exhibit less stability than the other.","authors":["Michael Robinson","Sourya Dey","Tony Chiang"],"url":"https://arxiv.org/abs/2504.01002"}
{"created":"2025-05-29","title":"Evaluating Compact LLMs for Zero-Shot Iberian Language Tasks on End-User Devices","abstract":"Large Language Models have significantly advanced natural language processing, achieving remarkable performance in tasks such as language generation, translation, and reasoning. However, their substantial computational requirements restrict deployment to high-end systems, limiting accessibility on consumer-grade devices. This challenge is especially pronounced for under-resourced languages like those spoken in the Iberian Peninsula, where relatively limited linguistic resources and benchmarks hinder effective evaluation. This work presents a comprehensive evaluation of compact state-of-the-art LLMs across several essential NLP tasks tailored for Iberian languages. The results reveal that while some models consistently excel in certain tasks, significant performance gaps remain, particularly for languages such as Basque. These findings highlight the need for further research on balancing model compactness with robust multilingual performance","authors":["Lu\\'is Couto Seller","\\'I\\~nigo Sanz Torres","Adri\\'an Vogel-Fern\\'andez","Carlos Gonz\\'alez Carballo","Pedro Miguel S\\'anchez S\\'anchez","Adri\\'an Carruana Mart\\'in","Enrique de Miguel Ambite"],"url":"https://arxiv.org/abs/2504.03312"}
{"created":"2025-05-29","title":"SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement","abstract":"In the interaction between agents and their environments, agents expand their capabilities by planning and executing actions. However, LLM-based agents face substantial challenges when deployed in novel environments or required to navigate unconventional action spaces. To empower agents to autonomously explore environments, optimize workflows, and enhance their understanding of actions, we propose SynWorld, a framework that allows agents to synthesize possible scenarios with multi-step action invocation within the action space and perform Monte Carlo Tree Search (MCTS) exploration to effectively refine their action knowledge in the current environment. Our experiments demonstrate that SynWorld is an effective and general approach to learning action knowledge in new environments. Code is available at https://github.com/zjunlp/SynWorld.","authors":["Runnan Fang","Xiaobin Wang","Yuan Liang","Shuofei Qiao","Jialong Wu","Zekun Xi","Ningyu Zhang","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"url":"https://arxiv.org/abs/2504.03561"}
{"created":"2025-05-29","title":"Solid State Bus-Comp: A Large-Scale and Diverse Dataset for Dynamic Range Compressor Virtual Analog Modeling","abstract":"Virtual Analog (VA) modeling aims to simulate the behavior of hardware circuits via algorithms to replicate their tone digitally. Dynamic Range Compressor (DRC) is an audio processing module that controls the dynamics of a track by reducing and amplifying the volumes of loud and quiet sounds, which is essential in music production. In recent years, neural-network-based VA modeling has shown great potential in producing high-fidelity models. However, due to the lack of data quantity and diversity, their generalization ability in different parameter settings and input sounds is still limited. To tackle this problem, we present Solid State Bus-Comp, the first large-scale and diverse dataset for modeling the classical VCA compressor -- SSL 500 G-Bus. Specifically, we manually collected 175 unmastered songs from the Cambridge Multitrack Library. We recorded the compressed audio in 220 parameter combinations, resulting in an extensive 2528-hour dataset with diverse genres, instruments, tempos, and keys. Moreover, to facilitate the use of our proposed dataset, we conducted benchmark experiments in various open-sourced black-box and grey-box models, as well as white-box plugins. We also conducted ablation studies in different data subsets to illustrate the effectiveness of the improved data diversity and quantity. The dataset and demos are on our project page: https://www.yichenggu.com/SolidStateBusComp/.","authors":["Yicheng Gu","Runsong Zhang","Lauri Juvela","Zhizheng Wu"],"url":"https://arxiv.org/abs/2504.04589"}
{"created":"2025-05-29","title":"AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for Early Warning System Investments","abstract":"Tracking financial investments in climate adaptation is a complex and expertise-intensive task, particularly for Early Warning Systems (EWS), which lack standardized financial reporting across multilateral development banks (MDBs) and funds. To address this challenge, we introduce an LLM-based agentic AI system that integrates contextual retrieval, fine-tuning, and multi-step reasoning to extract relevant financial data, classify investments, and ensure compliance with funding guidelines. Our study focuses on a real-world application: tracking EWS investments in the Climate Risk and Early Warning Systems (CREWS) Fund. We analyze 25 MDB project documents and evaluate multiple AI-driven classification methods, including zero-shot and few-shot learning, fine-tuned transformer-based classifiers, chain-of-thought (CoT) prompting, and an agent-based retrieval-augmented generation (RAG) approach. Our results show that the agent-based RAG approach significantly outperforms other methods, achieving 87\\% accuracy, 89\\% precision, and 83\\% recall. Additionally, we contribute a benchmark dataset and expert-annotated corpus, providing a valuable resource for future research in AI-driven financial tracking and climate finance transparency.","authors":["Saeid Ario Vaghefi","Aymane Hachcham","Veronica Grasso","Jiska Manicus","Nakiete Msemo","Chiara Colesanti Senni","Markus Leippold"],"url":"https://arxiv.org/abs/2504.05104"}
{"created":"2025-05-29","title":"User Feedback Alignment for LLM-powered Exploration in Large-scale Recommendation Systems","abstract":"Exploration, the act of broadening user experiences beyond their established preferences, is challenging in large-scale recommendation systems due to feedback loops and limited signals on user exploration patterns. Large Language Models (LLMs) offer potential solutions by leveraging their world knowledge to recommend novel content outside these loops. A key challenge is aligning LLMs with user preferences while preserving their knowledge and reasoning. To enhance planning for new user interests using LLMs, this paper introduces a novel approach that combines hierarchical planning with LLM inference-time scaling. This method aims to improve recommendation relevancy without compromising novelty. We decouple novelty and user-alignment, training separate LLMs for each objective. We then scale up the novelty-focused LLM's inference and select the best-of-n predictions using the user-aligned LLM. Live experiments demonstrate efficacy, showing significant gains in both user satisfaction (measured by watch activity and active user counts) and exploration diversity.","authors":["Jianling Wang","Yifan Liu","Yinghao Sun","Xuejian Ma","Yueqi Wang","He Ma","Zhengyang Su","Minmin Chen","Mingyan Gao","Onkar Dalal","Ed H. Chi","Lichan Hong","Ningren Han","Haokai Lu"],"url":"https://arxiv.org/abs/2504.05522"}
{"created":"2025-05-29","title":"Evaluation of the impact of expert knowledge: How decision support scores impact the effectiveness of automatic knowledge-driven feature engineering (aKDFE)","abstract":"Adverse Drug Events (ADEs), harmful medication effects, pose significant healthcare challenges, impacting patient safety and costs. This study evaluates automatic Knowledge-Driven Feature Engineering (aKDFE) for improved ADE prediction from Electronic Health Record (EHR) data, comparing it with automated event-based Knowledge Discovery in Databases (KDD). We investigated how incorporating domain-specific ADE risk scores for prolonged heart QT interval, extracted from the Janusmed Riskprofile (Janusmed) Clinical Decision Support System (CDSS), affects prediction performance using EHR data and medication handling events. Results indicate that, while aKDFE step 1 (event-based feature generation) alone did not significantly improve ADE prediction performance, aKDFE step 2 (patient-centric transformation) enhances the prediction performance. High Area Under the Receiver Operating Characteristic curve (AUROC) values suggest strong feature correlations to the outcome, aligning with the predictive power of patients' prior healthcare history for ADEs. Statistical analysis did not confirm that incorporating the Janusmed information (i) risk scores and (ii) medication route of administration into the model's feature set enhanced predictive performance. However, the patient-centric transformation applied by aKDFE proved to be a highly effective feature engineering approach. Limitations include a single-project focus, potential bias from machine learning pipeline methods, and reliance on AUROC. In conclusion, aKDFE, particularly with patient-centric transformation, improves ADE prediction from EHR data. Future work will explore attention-based models, event feature sequences, and automatic methods for incorporating domain knowledge into the aKDFE framework.","authors":["Olof Bj\\\"orneld","Tora Hammar","Daniel Nilsson","Alisa Lincke","Welf L\\\"owe"],"url":"https://arxiv.org/abs/2504.05928"}
{"created":"2025-05-29","title":"Analog Computing for Signal Processing and Communications -- Part I: Computing with Microwave Networks","abstract":"Analog computing has been recently revived due to its potential for energy-efficient and highly parallel computations. In this two-part paper, we explore analog computers that linearly process microwave signals, named microwave linear analog computers (MiLACs), and their applications in signal processing and communications. In Part I of this paper, we model a MiLAC as a multiport microwave network with tunable impedance components, enabling the execution of mathematical operations by reconfiguring the microwave network and applying input signals at its ports. We demonstrate that a MiLAC can efficiently compute the linear minimum mean square error (LMMSE) estimator and matrix inversion, with remarkably low computational complexity. Specifically, a matrix can be inverted with complexity growing with the square of its size. We also show how a MiLAC can be used jointly with digital operations to implement sophisticated algorithms such as the Kalman filter. To enhance practicability, we propose a design of MiLAC based on lossless impedance components, reducing power consumption and eliminating the need for costly active components. In Part II of this paper, we investigate the applications of MiLACs in wireless communications, highlighting their potential to enable future wireless systems by executing computations and beamforming in the analog domain.","authors":["Matteo Nerini","Bruno Clerckx"],"url":"https://arxiv.org/abs/2504.06790"}
{"created":"2025-05-29","title":"Domain-Specific Pruning of Large Mixture-of-Experts Models with Few-shot Demonstrations","abstract":"Mixture-of-Experts (MoE) models achieve a favorable trade-off between performance and inference efficiency by activating only a subset of experts. However, the memory overhead of storing all experts remains a major limitation, especially in large-scale MoE models such as DeepSeek-R1(671B). In this study, we investigate domain specialization and expert redundancy in large-scale MoE models and uncover a consistent behavior we term few-shot expert localization, with only a few in-domain demonstrations, the model consistently activates a sparse and stable subset of experts on tasks within the same domain. Building on this observation, we propose a simple yet effective pruning framework, EASY-EP, that leverages a few domain-specific demonstrations to identify and retain only the most relevant experts. EASY-EP comprises two key components: output-aware expert importance assessment and expert-level token contribution estimation. The former evaluates the importance of each expert for the current token by considering the gating scores and L2 norm of the outputs of activated experts, while the latter assesses the contribution of tokens based on representation similarities before and after routed experts. Experiments on DeepSeek-R1 and DeepSeek-V3-0324 show that our method can achieve comparable performances and $2.99\\times$ throughput under the same memory budget with full model with only half the experts.","authors":["Zican Dong","Han Peng","Peiyu Liu","Wayne Xin Zhao","Dong Wu","Feng Xiao","Zhifeng Wang"],"url":"https://arxiv.org/abs/2504.06792"}
{"created":"2025-05-29","title":"Analog Computing for Signal Processing and Communications -- Part II: Toward Gigantic MIMO Beamforming","abstract":"Analog-domain operations offer a promising solution to accelerating signal processing and enabling future multiple-input multiple-output (MIMO) communications with thousands of antennas. In Part I of this paper, we have introduced a microwave linear analog computer (MiLAC) as an analog computer that processes microwave signals linearly, demonstrating its potential to reduce the computational complexity of specific signal processing tasks. In Part II of this paper, we extend these benefits to wireless communications, showcasing how MiLAC enables gigantic MIMO beamforming entirely in the analog domain. MiLAC-aided beamforming enables the maximum flexibility and performance of digital beamforming, while significantly reducing hardware costs by minimizing the number of radio-frequency (RF) chains and only relying on low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). In addition, it eliminates per-symbol operations by completely avoiding digital-domain processing and remarkably reduces the computational complexity of zero-forcing (ZF), which scales quadratically with the number of antennas instead of cubically. It also processes signals with fixed matrices, e.g., the discrete Fourier transform (DFT), directly in the analog domain. Numerical results show that it can perform ZF and DFT with a computational complexity reduction of up to $1.5\\times 10^4$ and $4.0\\times 10^7$ times, respectively, compared to digital beamforming.","authors":["Matteo Nerini","Bruno Clerckx"],"url":"https://arxiv.org/abs/2504.07477"}
{"created":"2025-05-29","title":"A Knowledge-guided Adversarial Defense for Resisting Malicious Visual Manipulation","abstract":"Malicious applications of visual manipulation have raised serious threats to the security and reputation of users in many fields. To alleviate these issues, adversarial noise-based defenses have been enthusiastically studied in recent years. However, ``data-only\" methods tend to distort fake samples in the low-level feature space rather than the high-level semantic space, leading to limitations in resisting malicious manipulation. Frontier research has shown that integrating knowledge in deep learning can produce reliable and generalizable solutions. Inspired by these, we propose a knowledge-guided adversarial defense (KGAD) to actively force malicious manipulation models to output semantically confusing samples. Specifically, in the process of generating adversarial noise, we focus on constructing significant semantic confusions at the domain-specific knowledge level, and exploit a metric closely related to visual perception to replace the general pixel-wise metrics. The generated adversarial noise can actively interfere with the malicious manipulation model by triggering knowledge-guided and perception-related disruptions in the fake samples. To validate the effectiveness of the proposed method, we conduct qualitative and quantitative experiments on human perception and visual quality assessment. The results on two different tasks both show that our defense provides better protection compared to state-of-the-art methods and achieves great generalizability.","authors":["Dawei Zhou","Suzhi Gang","Decheng Liu","Tongliang Liu","Nannan Wang","Xinbo Gao"],"url":"https://arxiv.org/abs/2504.08411"}
{"created":"2025-05-29","title":"Layers at Similar Depths Generate Similar Activations Across LLM Architectures","abstract":"How do the latent spaces used by independently-trained LLMs relate to one another? We study the nearest neighbor relationships induced by activations at different layers of 24 open-weight LLMs, and find that they 1) tend to vary from layer to layer within a model, and 2) are approximately shared between corresponding layers of different models. Claim 2 shows that these nearest neighbor relationships are not arbitrary, as they are shared across models, but Claim 1 shows that they are not \"obvious\" either, as there is no single set of nearest neighbor relationships that is universally shared. Together, these suggest that LLMs generate a progression of activation geometries from layer to layer, but that this entire progression is largely shared between models, stretched and squeezed to fit into different architectures.","authors":["Christopher Wolfram","Aaron Schein"],"url":"https://arxiv.org/abs/2504.08775"}
{"created":"2025-05-29","title":"Pruning in Snowflake: Working Smarter, Not Harder","abstract":"Modern cloud-based data analytics systems must efficiently process petabytes of data residing on cloud storage. A key optimization technique in state-of-the-art systems like Snowflake is partition pruning - skipping chunks of data that do not contain relevant information for computing query results.","authors":["Andreas Zimmerer","Damien Dam","Jan Kossmann","Juliane Waack","Ismail Oukid","Andreas Kipf"],"url":"https://arxiv.org/abs/2504.11540"}
{"created":"2025-05-29","title":"Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching","abstract":"We introduce Adjoint Sampling, a highly scalable and efficient algorithm for learning diffusion processes that sample from unnormalized densities, or energy functions. It is the first on-policy approach that allows significantly more gradient updates than the number of energy evaluations and model samples, allowing us to scale to much larger problem settings than previously explored by similar methods. Our framework is theoretically grounded in stochastic optimal control and shares the same theoretical guarantees as Adjoint Matching, being able to train without the need for corrective measures that push samples towards the target distribution. We show how to incorporate key symmetries, as well as periodic boundary conditions, for modeling molecules in both cartesian and torsional coordinates. We demonstrate the effectiveness of our approach through extensive experiments on classical energy functions, and further scale up to neural network-based energy models where we perform amortized conformer generation across many molecular systems. To encourage further research in developing highly scalable sampling methods, we plan to open source these challenging benchmarks, where successful methods can directly impact progress in computational chemistry.","authors":["Aaron Havens","Benjamin Kurt Miller","Bing Yan","Carles Domingo-Enrich","Anuroop Sriram","Brandon Wood","Daniel Levine","Bin Hu","Brandon Amos","Brian Karrer","Xiang Fu","Guan-Horng Liu","Ricky T. Q. Chen"],"url":"https://arxiv.org/abs/2504.11713"}
{"created":"2025-05-29","title":"GOAT-TTS: Expressive and Realistic Speech Generation via A Dual-Branch LLM","abstract":"While large language models (LLMs) have revolutionized text-to-speech (TTS) synthesis through discrete tokenization paradigms, current architectures exhibit fundamental tensions between three critical dimensions: 1) irreversible loss of acoustic characteristics caused by quantization of speech prompts; 2) stringent dependence on precisely aligned prompt speech-text pairs that limit real-world deployment; and 3) catastrophic forgetting of the LLM's native text comprehension during optimization for speech token generation. To address these challenges, we propose an LLM-based text-to-speech Generation approach Optimized via a novel dual-branch ArchiTecture (GOAT-TTS). Our framework introduces two key innovations: (1) The modality-alignment branch combines a speech encoder and projector to capture continuous acoustic embeddings, enabling bidirectional correlation between paralinguistic features (language, timbre, emotion) and semantic text representations without transcript dependency; (2) The speech-generation branch employs modular fine-tuning on top-k layers of an LLM for speech token prediction while freezing the bottom-n layers to preserve foundational linguistic knowledge. Moreover, multi-token prediction is introduced to support real-time streaming TTS synthesis. Experimental results demonstrate that our GOAT-TTS achieves performance comparable to state-of-the-art TTS models while validating the efficacy of synthesized dialect speech data.","authors":["Yaodong Song","Hongjie Chen","Jie Lian","Yuxin Zhang","Guangmin Xia","Zehan Li","Genliang Zhao","Jian Kang","Jie Li","Yongxiang Li","Xuelong Li"],"url":"https://arxiv.org/abs/2504.12339"}
{"created":"2025-05-29","title":"GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks","abstract":"This paper introduces GraphOmni, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs on graph-theoretic tasks articulated in natural language. GraphOmni encompasses diverse graph types, serialization formats, and prompting schemes, significantly exceeding prior efforts in both scope and depth. Through extensive systematic evaluation, we identify critical interactions among these dimensions, demonstrating their substantial impact on model performance. Our experiments reveal that state-of-the-art models like Claude-3.5 and o4-mini consistently outperform other models, yet even these leading models exhibit substantial room for improvement. Performance variability is evident depending on the specific combinations of factors we considered, underscoring the necessity of comprehensive evaluations across these interconnected dimensions. Additionally, we observe distinct impacts of serialization and prompting strategies between open-source and closed-source models, encouraging the development of tailored approaches. Motivated by the findings, we also propose a reinforcement learning-inspired framework that adaptively selects the optimal factors influencing LLM reasoning capabilities. This flexible and extendable benchmark not only deepens our understanding of LLM performance on structured tasks but also provides a robust foundation for advancing research in LLM-based graph reasoning. The code and datasets are available at https://github.com/GAI-Community/GraphOmni.","authors":["Hao Xu","Xiangru Jian","Xinjian Zhao","Wei Pang","Chao Zhang","Suyuchen Wang","Qixin Zhang","Zhengyuan Dong","Joao Monteiro","Bang Liu","Qiuzhuang Sun","Tianshu Yu"],"url":"https://arxiv.org/abs/2504.12764"}
{"created":"2025-05-29","title":"Generative Framework for Personalized Persuasion: Inferring Causal, Counterfactual, and Latent Knowledge","abstract":"We hypothesize that optimal system responses emerge from adaptive strategies grounded in causal and counterfactual knowledge. Counterfactual inference allows us to create hypothetical scenarios to examine the effects of alternative system responses. We enhance this process through causal discovery, which identifies the strategies informed by the underlying causal structure that govern system behaviors. Moreover, we consider the psychological constructs and unobservable noises that might be influencing user-system interactions as latent factors. We show that these factors can be effectively estimated. We employ causal discovery to identify strategy-level causal relationships among user and system utterances, guiding the generation of personalized counterfactual dialogues. We model the user utterance strategies as causal factors, enabling system strategies to be treated as counterfactual actions. Furthermore, we optimize policies for selecting system responses based on counterfactual data. Our results using a real-world dataset on social good demonstrate significant improvements in persuasive system outcomes, with increased cumulative rewards validating the efficacy of causal discovery in guiding personalized counterfactual inference and optimizing dialogue policies for a persuasive dialogue system.","authors":["Donghuo Zeng","Roberto Legaspi","Yuewen Sun","Xinshuai Dong","Kazushi Ikeda","Peter Spirtes","Kun Zhang"],"url":"https://arxiv.org/abs/2504.13904"}
{"created":"2025-05-29","title":"gLLM: Global Balanced Pipeline Parallelism System for Distributed LLM Serving with Token Throttling","abstract":"Pipeline parallelism has emerged as a predominant approach for deploying large language models (LLMs) across distributed nodes, owing to its lower communication overhead compared to tensor parallelism. While demonstrating high throughput in request serving, pipeline parallelism often suffers from performance limitations caused by pipeline bubbles, which are primarily resulted from imbalanced computation delays across batches. Existing methods like Sarathi-Serve attempt to address this through hybrid scheduling of chunked prefill and decode tokens using a fixed token budget. However, such methods may experience significant fluctuations due to either insufficient prefill tokens or uneven distribution of decode tokens, ultimately leading to computational imbalance. To overcome these inefficiencies, we present gLLM, a globally balanced pipeline parallelism system incorporating Token Throttling to effectively mitigate the pipeline bubbles. Our Token Throttling mechanism is a fine-grained scheduling policy that independently regulates the quantities of prefill and decode tokens, thus enabling balanced computation by leveraging global information from the inference system. Specifically, for decode tokens, gLLM maintains near-consistent token count across processing batches. For prefill tokens, it dynamically adjusts batch sizes based on both total pending tokens and the memory utilization rates of key-value cache (KV cache). Furthermore, gLLM runtime adopts an asynchronous execution and message passing architecture specifically optimized for pipeline parallelism characteristics. Experimental evaluations with representative LLMs show that gLLM achieves significant performance improvements, delivering 11% to 398% higher maximum throughput compared to state-of-the-art pipeline or tensor parallelism systems, while simultaneously maintaining lower latency.","authors":["Tianyu Guo","Xianwei Zhang","Jiangsu Du","Zhiguang Chen","Nong Xiao","Yutong Lu"],"url":"https://arxiv.org/abs/2504.14775"}
{"created":"2025-05-29","title":"A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment","abstract":"The remarkable success of Large Language Models (LLMs) has illuminated a promising pathway toward achieving Artificial General Intelligence for both academic and industrial communities, owing to their unprecedented performance across various applications. As LLMs continue to gain prominence in both research and commercial domains, their security and safety implications have become a growing concern, not only for researchers and corporations but also for every nation. Currently, existing surveys on LLM safety primarily focus on specific stages of the LLM lifecycle, e.g., deployment phase or fine-tuning phase, lacking a comprehensive understanding of the entire \"lifechain\" of LLMs. To address this gap, this paper introduces, for the first time, the concept of \"full-stack\" safety to systematically consider safety issues throughout the entire process of LLM training, deployment, and eventual commercialization. Compared to the off-the-shelf LLM safety surveys, our work demonstrates several distinctive advantages: (I) Comprehensive Perspective. We define the complete LLM lifecycle as encompassing data preparation, pre-training, post-training, deployment and final commercialization. To our knowledge, this represents the first safety survey to encompass the entire lifecycle of LLMs. (II) Extensive Literature Support. Our research is grounded in an exhaustive review of over 800+ papers, ensuring comprehensive coverage and systematic organization of security issues within a more holistic understanding. (III) Unique Insights. Through systematic literature analysis, we have developed reliable roadmaps and perspectives for each chapter. Our work identifies promising research directions, including safety in data generation, alignment techniques, model editing, and LLM-based agent systems. These insights provide valuable guidance for researchers pursuing future work in this field.","authors":["Kun Wang","Guibin Zhang","Zhenhong Zhou","Jiahao Wu","Miao Yu","Shiqian Zhao","Chenlong Yin","Jinhu Fu","Yibo Yan","Hanjun Luo","Liang Lin","Zhihao Xu","Haolang Lu","Xinye Cao","Xinyun Zhou","Weifei Jin","Fanci Meng","Junyuan Mao","Yu Wang","Hao Wu","Minghe Wang","Fan Zhang","Junfeng Fang","Wenjie Qu","Yue Liu","Chengwei Liu","Yifan Zhang","Qiankun Li","Chongye Guo","Yalan Qin","Zhaoxin Fan","Yi Ding","Donghai Hong","Jiaming Ji","Yingxin Lai","Zitong Yu","Xinfeng Li","Yifan Jiang","Yanhui Li","Xinyu Deng","Junlin Wu","Dongxia Wang","Yihao Huang","Yufei Guo","Jen-tse Huang","Qiufeng Wang","Wenxuan Wang","Dongrui Liu","Yanwei Yue","Wenke Huang","Guancheng Wan","Heng Chang","Tianlin Li","Yi Yu","Chenghao Li","Jiawei Li","Lei Bai","Jie Zhang","Qing Guo","Jingyi Wang","Tianlong Chen","Joey Tianyi Zhou","Xiaojun Jia","Weisong Sun","Cong Wu","Jing Chen","Xuming Hu","Yiming Li","Xiao Wang","Ningyu Zhang","Luu Anh Tuan","Guowen Xu","Jiaheng Zhang","Tianwei Zhang","Xingjun Ma","Jindong Gu","Xiang Wang","Bo An","Jun Sun","Mohit Bansal","Shirui Pan","Lingjuan Lyu","Yuval Elovici","Bhavya Kailkhura","Yaodong Yang","Hongwei Li","Wenyuan Xu","Yizhou Sun","Wei Wang","Qing Li","Ke Tang","Yu-Gang Jiang","Felix Juefei-Xu","Hui Xiong","Xiaofeng Wang","Dacheng Tao","Philip S. Yu","Qingsong Wen","Yang Liu"],"url":"https://arxiv.org/abs/2504.15585"}
{"created":"2025-05-29","title":"Progressive Language-guided Visual Learning for Multi-Task Visual Grounding","abstract":"Multi-task visual grounding (MTVG) includes two sub-tasks, i.e., Referring Expression Comprehension (REC) and Referring Expression Segmentation (RES). The existing representative approaches generally follow the research pipeline which mainly consists of three core procedures, including independent feature extraction for visual and linguistic modalities, respectively, cross-modal interaction module, and independent prediction heads for different sub-tasks. Albeit achieving remarkable performance, this research line has two limitations: 1) The linguistic content has not been fully injected into the entire visual backbone for boosting more effective visual feature extraction and it needs an extra cross-modal interaction module; 2) The relationship between REC and RES tasks is not effectively exploited to help the collaborative prediction for more accurate output. To deal with these problems, in this paper, we propose a Progressive Language-guided Visual Learning framework for multi-task visual grounding, called PLVL, which not only finely mine the inherent feature expression of the visual modality itself but also progressively inject the language information to help learn linguistic-related visual features. In this manner, our PLVL does not need additional cross-modal fusion module while fully introducing the language guidance. Furthermore, we analyze that the localization center for REC would help identify the to-be-segmented object region for RES to some extent. Inspired by this investigation, we design a multi-task head to accomplish collaborative predictions for these two sub-tasks. Extensive experiments conducted on several benchmark datasets comprehensively substantiate that our PLVL obviously outperforms the representative methods in both REC and RES tasks. https://github.com/jcwang0602/PLVL","authors":["Jingchao Wang","Hong Wang","Wenlong Zhang","Kunhua Ji","Dingjiang Huang","Yefeng Zheng"],"url":"https://arxiv.org/abs/2504.16145"}
{"created":"2025-05-29","title":"Addressing Concept Mislabeling in Concept Bottleneck Models Through Preference Optimization","abstract":"Concept Bottleneck Models (CBMs) propose to enhance the trustworthiness of AI systems by constraining their decisions on a set of human understandable concepts. However, CBMs typically assume that datasets contains accurate concept labels an assumption often violated in practice, which we show can significantly degrade performance (by 25% in some cases). To address this, we introduce the Concept Preference Optimization (CPO) objective, a new loss function based on Direct Preference Optimization, which effectively mitigates the negative impact of concept mislabeling on CBM performance. We provide an analysis on some key properties of the CPO objective showing it directly optimizes for the concept's posterior distribution, and contrast it against Binary Cross Entropy (BCE) where we show CPO is inherently less sensitive to concept noise. We empirically confirm our analysis finding that CPO consistently outperforms BCE in three real world datasets with and without added label noise.","authors":["Emiliano Penaloza","Tianyue H. Zhan","Laurent Charlin","Mateo Espinosa Zarlenga"],"url":"https://arxiv.org/abs/2504.18026"}
{"created":"2025-05-29","title":"Geometry-Informed Neural Operator Transformer","abstract":"Machine-learning-based surrogate models offer significant computational efficiency and faster simulations compared to traditional numerical methods, especially for problems requiring repeated evaluations of partial differential equations. This work introduces the Geometry-Informed Neural Operator Transformer (GINOT), which integrates the transformer architecture with the neural operator framework to enable forward predictions for arbitrary geometries. GINOT encodes the surface points cloud of a geometry using a sampling and grouping mechanism combined with an attention mechanism, ensuring invariance to point order and padding while maintaining robustness to variations in point density. The geometry information is seamlessly integrated with query points in the solution decoder through the attention mechanism. The performance of GINOT is validated on multiple challenging datasets, showcasing its high accuracy and strong generalization capabilities for complex and arbitrary 2D and 3D geometries.","authors":["Qibang Liu","Vincient Zhong","Hadi Meidani","Diab Abueidda","Seid Koric","Philippe Geubelle"],"url":"https://arxiv.org/abs/2504.19452"}
{"created":"2025-05-29","title":"ClonEval: An Open Voice Cloning Benchmark","abstract":"We present a novel benchmark for voice cloning text-to-speech models. The benchmark consists of an evaluation protocol, an open-source library for assessing the performance of voice cloning models, and an accompanying leaderboard. The paper discusses design considerations and presents a detailed description of the evaluation procedure. The usage of the software library is explained, along with the organization of results on the leaderboard.","authors":["Iwona Christop","Tomasz Kuczy\\'nski","Marek Kubis"],"url":"https://arxiv.org/abs/2504.20581"}
{"created":"2025-05-29","title":"Grassroots Federation: Fair Governance of Large-Scale, Decentralized, Sovereign Digital Communities","abstract":"Grassroots Federation aims to address the egalitarian formation and the fair democratic governance of large-scale, decentralized, sovereign digital communities, the size of the EU, the US, existing social networks, and even humanity at large. A grassroots federation evolves via the grassroots formation of digital communities and their consensual federation. Such digital communities may form according to geography, jurisdiction, affiliations, relations, interests, causes, and more. Small communities (say up to $100$ members) govern themselves; larger communities -- no matter how large -- are governed by a similarly-small assembly elected by sortition among its members.","authors":["Ehud Shapiro","Nimrod Talmon"],"url":"https://arxiv.org/abs/2505.02208"}
{"created":"2025-05-29","title":"Robust Localization, Mapping, and Navigation for Quadruped Robots","abstract":"Quadruped robots are currently a widespread platform for robotics research, thanks to powerful Reinforcement Learning controllers and the availability of cheap and robust commercial platforms. However, to broaden the adoption of the technology in the real world, we require robust navigation stacks relying only on low-cost sensors such as depth cameras. This paper presents a first step towards a robust localization, mapping, and navigation system for low-cost quadruped robots. In pursuit of this objective we combine contact-aided kinematic, visual-inertial odometry, and depth-stabilized vision, enhancing stability and accuracy of the system. Our results in simulation and two different real-world quadruped platforms show that our system can generate an accurate 2D map of the environment, robustly localize itself, and navigate autonomously. Furthermore, we present in-depth ablation studies of the important components of the system and their impact on localization accuracy. Videos, code, and additional experiments can be found on the project website: https://sites.google.com/view/low-cost-quadruped-slam","authors":["Dyuman Aditya","Junning Huang","Nico Bohlinger","Piotr Kicki","Krzysztof Walas","Jan Peters","Matteo Luperto","Davide Tateo"],"url":"https://arxiv.org/abs/2505.02272"}
{"created":"2025-05-29","title":"Enhancing Target-unspecific Tasks through a Features Matrix","abstract":"Recent developments in prompt learning of large Vision-Language Models (VLMs) have significantly improved performance in target-specific tasks. However, these prompting methods often struggle to tackle the target-unspecific or generalizable tasks effectively. It may be attributed to the fact that overfitting training causes the model to forget its general knowledge. The general knowledge has a strong promotion on target-unspecific tasks. To alleviate this issue, we propose a novel Features Matrix (FM) approach designed to enhance these models on target-unspecific tasks. Our method extracts and leverages general knowledge, shaping a Features Matrix (FM). Specifically, the FM captures the semantics of diverse inputs from a deep and fine perspective, preserving essential general knowledge, which mitigates the risk of overfitting. Representative evaluations demonstrate that: 1) the FM is compatible with existing frameworks as a generic and flexible module, and 2) the FM significantly showcases its effectiveness in enhancing target-unspecific tasks (base-to-novel generalization, domain generalization, and cross-dataset generalization), achieving state-of-the-art performance.","authors":["Fangming Cui","Yonggang Zhang","Xuan Wang","Xinmei Tian","Jun Yu"],"url":"https://arxiv.org/abs/2505.03414"}
{"created":"2025-05-29","title":"Coverage Biases in High-Resolution Satellite Imagery","abstract":"Satellite imagery is increasingly used to complement traditional data collection approaches such as surveys and censuses across scientific disciplines. However, we ask: Do all places on earth benefit equally from this new wealth of information? In this study, we investigate coverage bias of major satellite constellations that provide optical satellite imagery with a ground sampling distance below 10 meters, evaluating both the future on-demand tasking opportunities as well as the availability of historic images across the globe. Specifically, forward-looking, we estimate how often different places are revisited during a window of 30 days based on the satellites' orbital paths, thus investigating potential coverage biases caused by physical factors. We find that locations farther away from the equator are generally revisited more frequently by the constellations under study. Backward-looking, we show that historic satellite image availability -- based on metadata collected from major satellite imagery providers -- is influenced by socio-economic factors on the ground: less developed, less populated places have less satellite images available. Furthermore, in three small case studies on recent conflict regions in this world, namely Gaza, Sudan and Ukraine, we show that also geopolitical events play an important role in satellite image availability, hinting at underlying business model decisions. These insights lay bare that the digital dividend yielded by satellite imagery is not equally distributed across our planet.","authors":["Vadim Musienko","Axel Jacquet","Ingmar Weber","Till Koebe"],"url":"https://arxiv.org/abs/2505.03842"}
{"created":"2025-05-29","title":"A Weak Supervision Learning Approach Towards an Equitable Mobility Estimation","abstract":"The scarcity and high cost of labeled high-resolution imagery have long challenged remote sensing applications, particularly in low-income regions where high-resolution data are scarce. In this study, we propose a weak supervision framework that estimates parking lot occupancy using 3m resolution satellite imagery. By leveraging coarse temporal labels -- based on the assumption that parking lots of major supermarkets and hardware stores in Germany are typically full on Saturdays and empty on Sundays -- we train a pairwise comparison model that achieves an AUC of 0.92 on large parking lots. The proposed approach minimizes the reliance on expensive high-resolution images and holds promise for scalable urban mobility analysis. Moreover, the method can be adapted to assess transit patterns and resource allocation in vulnerable communities, providing a data-driven basis to improve the well-being of those most in need.","authors":["Theophilus Aidoo","Till Koebe","Akansh Maurya","Hewan Shrestha","Ingmar Weber"],"url":"https://arxiv.org/abs/2505.04229"}
{"created":"2025-05-29","title":"Benchmarking LLMs' Swarm intelligence","abstract":"Large Language Models (LLMs) show potential for complex reasoning, yet their capacity for emergent coordination in Multi-Agent Systems (MAS) when operating under strict swarm-like constraints-limited local perception and communication-remains largely unexplored. Existing benchmarks often do not fully capture the unique challenges of decentralized coordination when agents operate with incomplete spatio-temporal information. To bridge this gap, we introduce SwarmBench, a novel benchmark designed to systematically evaluate the swarm intelligence capabilities of LLMs acting as decentralized agents. SwarmBench features five foundational MAS coordination tasks (Pursuit, Synchronization, Foraging, Flocking, Transport) within a configurable 2D grid environment, forcing agents to rely solely on local sensory input ($k\\times k$ view) and local communication. We propose metrics for coordination effectiveness and analyze emergent group dynamics. Zero-shot evaluations of leading LLMs (e.g., deepseek-v3, o4-mini) reveal significant task-dependent performance variations. While some rudimentary coordination is observed, our results indicate that current LLMs significantly struggle with robust long-range planning and adaptive strategy formation under the uncertainty inherent in these decentralized scenarios. Assessing LLMs under such swarm-like constraints is crucial for understanding their utility in future decentralized intelligent systems. We release SwarmBench as an open, extensible toolkit-built on a customizable physical system-providing environments, prompts, evaluation scripts, and comprehensive datasets. This aims to foster reproducible research into LLM-based MAS coordination and the theoretical underpinnings of emergent collective behavior under severe informational decentralization. Our code repository is available at https://github.com/x66ccff/swarmbench.","authors":["Kai Ruan","Mowen Huang","Ji-Rong Wen","Hao Sun"],"url":"https://arxiv.org/abs/2505.04364"}
{"created":"2025-05-29","title":"Data Standards in Audiology: A Mixed-Methods Exploration of Community Perspectives and Implementation Considerations","abstract":"Objective: The purpose of this study was to explore options for data standardisation in audiology and document the global audiology community's current knowledge and views of data standards, explore their needs and preferences, and develop recommendations for data standardisation as a result.","authors":["Charlotte Vercammen","Antje Heinrich","Christophe Lesimple","Alessia Paglialonga","Jan-Willem A. Wasmann","Mareike Buhl"],"url":"https://arxiv.org/abs/2505.04728"}
{"created":"2025-05-29","title":"ItDPDM: Information-Theoretic Discrete Poisson Diffusion Model","abstract":"Generative modeling of non-negative, discrete data, such as symbolic music, remains challenging due to two persistent limitations in existing methods. Firstly, many approaches rely on modeling continuous embeddings, which is suboptimal for inherently discrete data distributions. Secondly, most models optimize variational bounds rather than exact data likelihood, resulting in inaccurate likelihood estimates and degraded sampling quality. While recent diffusion-based models have addressed these issues separately, we tackle them jointly. In this work, we introduce the Information-Theoretic Discrete Poisson Diffusion Model (ItDPDM), inspired by photon arrival process, which combines exact likelihood estimation with fully discrete-state modeling. Central to our approach is an information-theoretic Poisson Reconstruction Loss (PRL) that has a provable exact relationship with the true data likelihood. ItDPDM achieves improved likelihood and sampling performance over prior discrete and continuous diffusion models on a variety of synthetic discrete datasets. Furthermore, on real-world datasets such as symbolic music and images, ItDPDM attains superior likelihood estimates and competitive generation quality-demonstrating a proof of concept for distribution-robust discrete generative modeling.","authors":["Sagnik Bhattacharya","Abhiram Gorle","Ahsan Bilal","Connor Ding","Amit Kumar Singh Yadav","Tsachy Weissman"],"url":"https://arxiv.org/abs/2505.05082"}
{"created":"2025-05-29","title":"Empowering Scientific Workflows with Federated Agents","abstract":"Agentic systems, in which diverse agents cooperate to tackle challenging problems, are exploding in popularity in the AI community. However, the agentic frameworks used to build these systems have not previously enabled use with research cyberinfrastructure. Here we introduce Academy, a modular and extensible middleware designed to deploy autonomous agents across the federated research ecosystem, including HPC systems, experimental facilities, and data repositories. To meet the demands of scientific computing, Academy supports asynchronous execution, heterogeneous resources, high-throughput data flows, and dynamic resource availability. It provides abstractions for expressing stateful agents, managing inter-agent coordination, and integrating computation with experimental control. We present microbenchmark results that demonstrate high performance and scalability in HPC environments. To demonstrate the breadth of applications that can be supported by agentic workflow designs, we also present case studies in materials discovery, decentralized learning, and information extraction in which agents are deployed across diverse HPC systems.","authors":["J. Gregory Pauloski","Yadu Babuji","Ryan Chard","Mansi Sakarvadia","Kyle Chard","Ian Foster"],"url":"https://arxiv.org/abs/2505.05428"}
{"created":"2025-05-29","title":"Continuous Thought Machines","abstract":"Biological brains demonstrate complex neural activity, where the timing and interplay between neurons is critical to how brains process information. Most deep learning architectures simplify neural activity by abstracting away temporal dynamics. In this paper we challenge that paradigm. By incorporating neuron-level processing and synchronization, we can effectively reintroduce neural timing as a foundational element. We present the Continuous Thought Machine (CTM), a model designed to leverage neural dynamics as its core representation. The CTM has two core innovations: (1) neuron-level temporal processing, where each neuron uses unique weight parameters to process a history of incoming signals; and (2) neural synchronization employed as a latent representation. The CTM aims to strike a balance between oversimplified neuron abstractions that improve computational efficiency, and biological realism. It operates at a level of abstraction that effectively captures essential temporal dynamics while remaining computationally tractable for deep learning. We demonstrate the CTM's strong performance and versatility across a range of challenging tasks, including ImageNet-1K classification, solving 2D mazes, sorting, parity computation, question-answering, and RL tasks. Beyond displaying rich internal representations and offering a natural avenue for interpretation owing to its internal process, the CTM is able to perform tasks that require complex sequential reasoning. The CTM can also leverage adaptive compute, where it can stop earlier for simpler tasks, or keep computing when faced with more challenging instances. The goal of this work is to share the CTM and its associated innovations, rather than pushing for new state-of-the-art results. To that end, we believe the CTM represents a significant step toward developing more biologically plausible and powerful artificial intelligence systems.","authors":["Luke Darlow","Ciaran Regan","Sebastian Risi","Jeffrey Seely","Llion Jones"],"url":"https://arxiv.org/abs/2505.05522"}
{"created":"2025-05-29","title":"Digital-physical testbed for ship autonomy studies in the Marine Cybernetics Laboratory basin","abstract":"The algorithms developed for Maritime Autonomous Surface Ships (MASS) are often challenging to test on actual vessels due to high operational costs and safety considerations. Simulations offer a cost-effective alternative and eliminate risks, but they may not accurately represent real-world dynamics for the given tasks. Utilizing small-scale model ships and robotic vessels in conjunction with a laboratory basin provides an accessible testing environment for the early stages of validation processes. However, designing and developing a model vessel for a single test can be costly and cumbersome, and researchers often lack access to such infrastructure. To address these challenges and enable streamlined testing, we have developed an in-house testbed that facilitates the development, testing, verification, and validation of MASS algorithms in a digital-physical laboratory. This infrastructure includes a set of small-scale model vessels, a simulation environment for each vessel, a comprehensive testbed environment, and a digital twin in Unity. With this, we aim to establish a full design and verification pipeline that starts with high-fidelity simulation models of each model vessel, to the model-scale testing in the laboratory basin, allowing possibilities for moving towards semi-fullscale validation with R/V milliAmpere1 and full-scale validation with R/V Gunnerus. In this work, we present our progress on the development of this testbed environment and its components, demonstrating its effectiveness in enabling ship guidance, navigation, and control (GNC), including autonomy.","authors":["Emir Cem Gezer","Mael Korentin Ivan Moreau","Anders Sandneseng H{\\o}gden","Dong Trong Nguyen","Roger Skjetne","Asgeir S{\\o}rensen"],"url":"https://arxiv.org/abs/2505.06787"}
{"created":"2025-05-29","title":"Hunting the Ghost: Towards Automatic Mining of IoT Hidden Services","abstract":"In this paper, we proposes an automatic firmware analysis tool targeting at finding hidden services that may be potentially harmful to the IoT devices. Our approach uses static analysis and symbolic execution to search and filter services that are transparent to normal users but explicit to experienced attackers. A prototype is built and evaluated against a dataset of IoT firmware, and The evaluation shows our tool can find the suspicious hidden services effectively.","authors":["Shuaike Dong","Siyu Shen","Zhou Li","Kehuan Zhang"],"url":"https://arxiv.org/abs/2505.06822"}
{"created":"2025-05-29","title":"The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games","abstract":"We study rational synthesis problems for concurrent games with $\\omega$-regular objectives. Our model of rationality considers only pure strategy Nash equilibria that satisfy either a social welfare or Pareto optimality condition with respect to an $\\omega$-regular objective for each agent. This extends earlier work on equilibria in concurrent games, without consideration about their quality. Our results show that the existence of Nash equilibria satisfying social welfare conditions can be computed as efficiently as the constrained Nash equilibrium existence problem. On the other hand, the existence of Nash equilibria satisfying the Pareto optimality condition possibly involves a higher upper bound, except in the case of B\\\"uchi and Muller games, for which all three problems are in the classes P and PSPACE-complete, respectively.","authors":["Purandar Bhaduri"],"url":"https://arxiv.org/abs/2505.07501"}
{"created":"2025-05-29","title":"Identifying Causal Direction via Variational Bayesian Compression","abstract":"Telling apart the cause and effect between two random variables with purely observational data is a challenging problem that finds applications in various scientific disciplines. A key principle utilized in this task is the algorithmic Markov condition, which postulates that the joint distribution, when factorized according to the causal direction, yields a more succinct codelength compared to the anti-causal direction. Previous approaches approximate these codelengths by relying on simple functions or Gaussian processes (GPs) with easily evaluable complexity, compromising between model fitness and computational complexity. To overcome these limitations, we propose leveraging the variational Bayesian learning of neural networks as an interpretation of the codelengths. Consequently, we can enhance the model fitness while promoting the succinctness of the codelengths, while avoiding the significant computational complexity of the GP-based approaches. Extensive experiments on both synthetic and real-world benchmarks in cause-effect identification demonstrate the effectiveness of our proposed method, surpassing the overall performance of related complexity-based and structural causal model regression-based approaches.","authors":["Quang-Duy Tran","Bao Duong","Phuoc Nguyen","Thin Nguyen"],"url":"https://arxiv.org/abs/2505.07503"}
{"created":"2025-05-29","title":"Revenue Optimization in Video Caching Networks with Privacy-Preserving Demand Predictions","abstract":"Performance of video streaming, which accounts for most of the traffic in wireless communication, can be significantly improved by caching popular videos at the wireless edge. Determining the cache content that optimizes performance (defined via a revenue function) is thus an important task, and prediction of the future demands based on past history can make this process much more efficient. However, since practical video caching networks involve various parties (e.g., users, isp, and csp) that do not wish to reveal information such as past history to each other, privacy-preserving solutions are required. Motivated by this, we propose a proactive caching method based on users' privacy-preserving multi-slot future demand predictions -- obtained from a trained Transformer -- to optimize revenue. Specifically, we first use a privacy-preserving fl algorithm to train a Transformer to predict multi-slot future demands of the users. However, prediction accuracy is not perfect and decreases the farther into the future the prediction is done. We model the impact of prediction errors invoking the file popularities, based on which we formulate a long-term system revenue optimization to make the cache placement decisions. As the formulated problem is NP-hard, we use a greedy algorithm to efficiently obtain an approximate solution. Simulation results validate that (i) the fl solution achieves results close to the centralized (non-privacy-preserving) solution and (ii) optimization of revenue may provide different solutions than the classical chr criterion.","authors":["Yijing Zhang","Ferdous Pervej","Andreas F. Molisch"],"url":"https://arxiv.org/abs/2505.07872"}
{"created":"2025-05-29","title":"SVA-ICL: Improving LLM-based Software Vulnerability Assessment via In-Context Learning and Information Fusion","abstract":"Context: Software vulnerability assessment (SVA) is critical for identifying, evaluating, and prioritizing security weaknesses in software applications. Objective: Despite the increasing application of large language models (LLMs) in various software engineering tasks, their effectiveness in SVA remains underexplored. Method: To address this gap, we introduce a novel approach SVA-ICL, which leverages in-context learning (ICL) to enhance LLM performance. Our approach involves the selection of high-quality demonstrations for ICL through information fusion, incorporating both source code and vulnerability descriptions. For source code, we consider semantic, lexical, and syntactic similarities, while for vulnerability descriptions, we focus on textual similarity. Based on the selected demonstrations, we construct context prompts and consider DeepSeek-V2 as the LLM for SVA-ICL. Results: We evaluate the effectiveness of SVA-ICL using a large-scale dataset comprising 12,071 C/C++ vulnerabilities. Experimental results demonstrate that SVA-ICL outperforms state-of-the-art SVA baselines in terms of Accuracy, F1-score, and MCC measures. Furthermore, ablation studies highlight the significance of component customization in SVA-ICL, such as the number of demonstrations, the demonstration ordering strategy, and the optimal fusion ratio of different modalities. Conclusion: Our findings suggest that leveraging ICL with information fusion can effectively improve the effectiveness of LLM-based SVA, warranting further research in this direction.","authors":["Chaoyang Gao","Xiang Chen","Guangbei Zhang"],"url":"https://arxiv.org/abs/2505.10008"}
{"created":"2025-05-29","title":"AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges","abstract":"This study critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven by Large Language Models (LLMs) and Large Image Models (LIMs) for narrow, task-specific automation. Generative AI is positioned as a precursor, with AI Agents advancing through tool integration, prompt engineering, and reasoning enhancements. In contrast, Agentic AI systems represent a paradigmatic shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and orchestrated autonomy. Through a sequential evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both paradigms. Application domains such as customer support, scheduling, and data summarization are contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure and propose targeted solutions such as ReAct loops, RAG, orchestration layers, and causal modeling. This work aims to provide a definitive roadmap for developing robust, scalable, and explainable AI agent and Agentic AI-driven systems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision Support System, Agentic-AI Applications","authors":["Ranjan Sapkota","Konstantinos I. Roumeliotis","Manoj Karkee"],"url":"https://arxiv.org/abs/2505.10468"}
{"created":"2025-05-29","title":"LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps","abstract":"The O-RAN architecture is transforming cellular networks by adopting RAN softwarization and disaggregation concepts to enable data-driven monitoring and control of the network. Such management is enabled by RICs, which facilitate near-real-time and non-real-time network control through xApps and rApps. However, they face limitations, including latency overhead in data exchange between the RAN and RIC, restricting real-time monitoring, and the inability to access user plain data due to privacy and security constraints, hindering use cases like beamforming and spectrum classification. In this paper, we leverage the dApps concept to enable real-time RF spectrum classification with LibIQ, a novel library for RF signals that facilitates efficient spectrum monitoring and signal classification by providing functionalities to read I/Q samples as time-series, create datasets and visualize time-series data through plots and spectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to detect external RF signals, which are subsequently classified using a CNN inside the library. To achieve accurate spectrum analysis, we created an extensive dataset of time-series-based I/Q samples, representing distinct signal types captured using a custom dApp running on a 5G deployment over the Colosseum network emulator and an OTA testbed. We evaluate our model by deploying LibIQ in heterogeneous scenarios with varying center frequencies, time windows, and external RF signals. In real-time analysis, the model classifies the processed I/Q samples, achieving an average accuracy of approximately 97.8% in identifying signal types across all scenarios. We pledge to release both LibIQ and the dataset created as a publicly available framework upon acceptance.","authors":["Filippo Olimpieri","Noemi Giustini","Andrea Lacava","Salvatore D'Oro","Tommaso Melodia","Francesca Cuomo"],"url":"https://arxiv.org/abs/2505.10537"}
{"created":"2025-05-29","title":"Benchmarking performance, explainability, and evaluation strategies of vision-language models for surgery: Challenges and opportunities","abstract":"Minimally invasive surgery (MIS) presents significant visual challenges, including a limited field of view, specular reflections, and inconsistent lighting conditions due to the small incision and the use of endoscopes. Over the past decade, many machine learning and deep learning models have been developed to identify and detect instruments and anatomical structures in surgical videos. However, these models are typically trained on manually labeled, procedure- and task-specific datasets that are relatively small, resulting in limited generalization to unseen data.In practice, hospitals generate a massive amount of raw surgical data every day, including videos captured during various procedures. Labeling this data is almost impractical, as it requires highly specialized expertise. The recent success of vision-language models (VLMs), which can be trained on large volumes of raw image-text pairs and exhibit strong adaptability, offers a promising alternative for leveraging unlabeled surgical data. While some existing work has explored applying VLMs to surgical tasks, their performance remains limited. To support future research in developing more effective VLMs for surgical applications, this paper aims to answer a key question: How well do existing VLMs, both general-purpose and surgery-specific perform on surgical data, and what types of scenes do they struggle with? To address this, we conduct a benchmarking study of several popular VLMs across diverse laparoscopic datasets. Specifically, we visualize the model's attention to identify which regions of the image it focuses on when making predictions for surgical tasks. We also propose a metric to evaluate whether the model attends to task-relevant regions. Our findings reveal a mismatch between prediction accuracy and visual grounding, indicating that models may make correct predictions while focusing on irrelevant areas of the image.","authors":["Jiajun Cheng","Xianwu Zhao","Shan Lin"],"url":"https://arxiv.org/abs/2505.10764"}
{"created":"2025-05-29","title":"Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL","abstract":"Large reasoning models (LRMs) are proficient at generating explicit, step-by-step reasoning sequences before producing final answers. However, such detailed reasoning can introduce substantial computational overhead and latency, particularly for simple problems. To address this over-thinking problem, we explore how to equip LRMs with adaptive thinking capabilities: enabling them to dynamically decide whether or not to engage in explicit reasoning based on problem complexity. Building on R1-style distilled models, we observe that inserting a simple ellipsis (\"...\") into the prompt can stochastically trigger either a thinking or no-thinking mode, revealing a latent controllability in the reasoning behavior. Leveraging this property, we propose AutoThink, a multi-stage reinforcement learning (RL) framework that progressively optimizes reasoning policies via stage-wise reward shaping. AutoThink learns to invoke explicit reasoning only when necessary, while defaulting to succinct responses for simpler tasks. Experiments on five mainstream mathematical benchmarks demonstrate that AutoThink achieves favorable accuracy-efficiency trade-offs compared to recent prompting and RL-based pruning methods. It can be seamlessly integrated into any R1-style model, including both distilled and further fine-tuned variants. Notably, AutoThink improves relative accuracy by 6.4 percent while reducing token usage by 52 percent on DeepSeek-R1-Distill-Qwen-1.5B, establishing a scalable and adaptive reasoning paradigm for LRMs. Project Page: https://github.com/ScienceOne-AI/AutoThink.","authors":["Songjun Tu","Jiahao Lin","Qichao Zhang","Xiangyu Tian","Linjing Li","Xiangyuan Lan","Dongbin Zhao"],"url":"https://arxiv.org/abs/2505.10832"}
{"created":"2025-05-29","title":"Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs","abstract":"Large language models have demonstrated impressive reasoning capabilities but are inherently limited by their knowledge reservoir. Retrieval-augmented reasoning mitigates this limitation by allowing LLMs to query external resources, but existing methods often retrieve irrelevant or noisy information, hindering accurate reasoning. In this paper, we propose AutoRefine, a reinforcement learning post-training framework that adopts a new ``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit knowledge refinement steps between successive search calls, enabling the model to iteratively filter, distill, and organize evidence before generating an answer. Furthermore, we incorporate tailored retrieval-specific rewards alongside answer correctness rewards using group relative policy optimization. Experiments on single-hop and multi-hop QA benchmarks demonstrate that AutoRefine significantly outperforms existing approaches, particularly in complex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine issues frequent, higher-quality searches and synthesizes evidence effectively.","authors":["Yaorui Shi","Sihang Li","Chang Wu","Zhiyuan Liu","Junfeng Fang","Hengxing Cai","An Zhang","Xiang Wang"],"url":"https://arxiv.org/abs/2505.11277"}
{"created":"2025-05-29","title":"Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling","abstract":"Optimization modeling is fundamental to decision-making across diverse domains. Despite progress in automating optimization formulation from natural language descriptions, Large Language Models (LLMs) often struggle to generate formally correct and usable models against hallucinations, posing a challenge for reliable automation. Inspired by the success of Reinforcement Learning (RL) in enhancing Large Reasoning Models, we present Solver-Informed Reinforcement Learning (SIRL), a novel framework that significantly improves the authenticity of LLMs for optimization modeling using Reinforcement Learning with Verifiable Reward by leveraging external optimization solvers as verifiers. These verifiers automatically assess the executable code and the instance-level mathematical model represented by the associated LP file, yielding precise and comprehensive feedback signals -- including syntax, feasibility, and solution quality, serving as direct rewards for the RL process. This automated verification process, particularly from classic optimization solvers, also underpins our instance-enhanced self-consistency method to synthesize high-quality training data. Extensive experiments on diverse public benchmarks demonstrate that SIRL achieves state-of-the-art performance, substantially outperforming existing methods in generating accurate and executable optimization models. Our code is publicly available at https://github.com/Cardinal-Operations/SIRL.","authors":["Yitian Chen","Jingfan Xia","Siyu Shao","Dongdong Ge","Yinyu Ye"],"url":"https://arxiv.org/abs/2505.11792"}
{"created":"2025-05-29","title":"Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning","abstract":"Loss reweighting has shown significant benefits for machine unlearning with large language models (LLMs). However, their exact functionalities are left unclear and the optimal strategy remains an open question, thus impeding the understanding and improvement of existing methodologies. In this paper, we identify two distinct goals of loss reweighting, namely, Saturation and Importance -- the former indicates that those insufficiently optimized data should be emphasized, while the latter stresses some critical data that are most influential for loss minimization. To study their usefulness, we design specific reweighting strategies for each goal and evaluate their respective effects on unlearning. We conduct extensive empirical analyses on well-established benchmarks, and summarize some important observations as follows: (i) Saturation enhances efficacy more than importance-based reweighting, and their combination can yield additional improvements. (ii) Saturation typically allocates lower weights to data with lower likelihoods, whereas importance-based reweighting does the opposite. (iii) The efficacy of unlearning is also largely influenced by the smoothness and granularity of the weight distributions. Based on these findings, we propose SatImp, a simple reweighting method that combines the advantages of both saturation and importance. Empirical results on extensive datasets validate the efficacy of our method, potentially bridging existing research gaps and indicating directions for future research. Our code is available at https://github.com/tmlr-group/SatImp.","authors":["Puning Yang","Qizhou Wang","Zhuo Huang","Tongliang Liu","Chengqi Zhang","Bo Han"],"url":"https://arxiv.org/abs/2505.11953"}
{"created":"2025-05-29","title":"Visuospatial Cognitive Assistant","abstract":"Video-based spatial cognition is vital for robotics and embodied AI but challenges current Vision-Language Models (VLMs). This paper makes two key contributions. First, we introduce ViCA (Visuospatial Cognitive Assistant)-322K, a diverse dataset of 322,003 QA pairs from real-world indoor videos (ARKitScenes, ScanNet, ScanNet++), offering supervision for 3D metadata-grounded queries and video-based complex reasoning. Second, we develop ViCA-7B, fine-tuned on ViCA-322K, which achieves new state-of-the-art on all eight VSI-Bench tasks, outperforming existing models, including larger ones (e.g., +26.1 on Absolute Distance). For interpretability, we present ViCA-Thinking-2.68K, a dataset with explicit reasoning chains, and fine-tune ViCA-7B to create ViCA-7B-Thinking, a model that articulates its spatial reasoning. Our work highlights the importance of targeted data and suggests paths for improved temporal-spatial modeling. We release all resources to foster research in robust visuospatial intelligence.","authors":["Qi Feng"],"url":"https://arxiv.org/abs/2505.12312"}
{"created":"2025-05-29","title":"Towards Visuospatial Cognition via Hierarchical Fusion of Visual Experts","abstract":"While Multimodal Large Language Models (MLLMs) excel at general vision-language tasks, visuospatial cognition - reasoning about spatial layouts, relations, and dynamics - remains a significant challenge. Existing models often lack the necessary architectural components and specialized training data for fine-grained spatial understanding. We introduce ViCA2 (Visuospatial Cognitive Assistant 2), a novel MLLM designed to enhance spatial reasoning. ViCA2 features a dual vision encoder architecture integrating SigLIP for semantics and Hiera for spatial structure, coupled with a token ratio control mechanism for efficiency. We also developed ViCA-322K, a new large-scale dataset with over 322,000 spatially grounded question-answer pairs for targeted instruction tuning. On the challenging VSI-Bench benchmark, our ViCA2-7B model achieves a state-of-the-art average score of 56.8, significantly surpassing larger open-source models (e.g., LLaVA-NeXT-Video-72B, 40.9) and leading proprietary models (Gemini-1.5 Pro, 45.4). This demonstrates the effectiveness of our approach in achieving strong visuospatial intelligence with a compact model. We release ViCA2, its codebase, and the ViCA-322K dataset to facilitate further research.","authors":["Qi Feng"],"url":"https://arxiv.org/abs/2505.12363"}
{"created":"2025-05-29","title":"Interpolation for the two-way modal mu-calculus","abstract":"The two-way modal mu-calculus is the extension of the (standard) one-way mu-calculus with converse (backward-looking) modalities. For this logic we introduce two new sequent-style proof calculi: a non-wellfounded system admitting infinite branches and a finitary, cyclic version of this that employs annotations. As is common in sequent systems for two-way modal logics, our calculi feature an analytic cut rule. What distinguishes our approach is the use of so-called trace atoms, which serve to apply Vardi's two-way automata in a proof-theoretic setting. We prove soundness and completeness for both systems and subsequently use the cyclic calculus to show that the two-way mu-calculus has the (local) Craig interpolation property, with respect to both propositions and modalities. Our proof uses a version of Maehara's method adapted to cyclic proof systems. As a corollary we prove that the two-way mu-calculus also enjoys Beth's definability property.","authors":["Johannes Kloibhofer","Yde Venema"],"url":"https://arxiv.org/abs/2505.12899"}
{"created":"2025-05-29","title":"Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model","abstract":"Humans can intuitively infer sounds from silent videos, but whether multimodal large language models can perform modal-mismatch reasoning without accessing target modalities remains relatively unexplored. Current text-assisted-video-to-audio (VT2A) methods excel in video foley tasks but struggle to acquire audio descriptions during inference. We introduce the task of Reasoning Audio Descriptions from Silent Videos (SVAD) to address this challenge and investigate vision-language models' (VLMs) capabilities on this task. To further enhance the VLMs' reasoning capacity for the SVAD task, we construct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based supervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks demonstrate our method's effectiveness in two key aspects: significantly improving VLMs' modal-mismatch reasoning for SVAD and effectively addressing the challenge of acquiring audio descriptions during VT2A inference.","authors":["Yong Ren","Chenxing Li","Le Xu","Hao Gu","Duzhen Zhang","Yujie Chen","Manjie Xu","Ruibo Fu","Shan Yang","Dong Yu"],"url":"https://arxiv.org/abs/2505.13062"}
{"created":"2025-05-29","title":"Advancing Sequential Numerical Prediction in Autoregressive Models","abstract":"Autoregressive models have become the de facto choice for sequence generation tasks, but standard approaches treat digits as independent tokens and apply cross-entropy loss, overlooking the coherent structure of numerical sequences. This paper introduces Numerical Token Integrity Loss (NTIL) to address this gap. NTIL operates at two levels: (1) token-level, where it extends the Earth Mover's Distance (EMD) to preserve ordinal relationships between numerical values, and (2) sequence-level, where it penalizes the overall discrepancy between the predicted and actual sequences. This dual approach improves numerical prediction and integrates effectively with LLMs/MLLMs. Extensive experiments show significant performance improvements with NTIL.","authors":["Xiang Fei","Jinghui Lu","Qi Sun","Hao Feng","Yanjie Wang","Wei Shi","An-Lan Wang","Jingqun Tang","Can Huang"],"url":"https://arxiv.org/abs/2505.13077"}
{"created":"2025-05-29","title":"Language-Specific Latent Process Hinders Cross-Lingual Performance","abstract":"Large language models (LLMs) are demonstrably capable of cross-lingual transfer, but can produce inconsistent output when prompted with the same queries written in different languages. To understand how language models are able to generalize knowledge from one language to the others, we apply the logit lens to interpret the implicit steps taken by LLMs to solve multilingual multi-choice reasoning questions. We find LLMs predict inconsistently and are less accurate because they rely on subspaces of individual languages, rather than working in a shared semantic space. While larger models are more multilingual, we show their hidden states are more likely to dissociate from the shared representation compared to smaller models, but are nevertheless more capable of retrieving knowledge embedded across different languages. Finally, we demonstrate that knowledge sharing can be modulated by steering the models' latent processing towards the shared semantic space. We find reinforcing utilization of the shared space improves the models' multilingual reasoning performance, as a result of more knowledge transfer from, and better output consistency with English.","authors":["Zheng Wei Lim","Alham Fikri Aji","Trevor Cohn"],"url":"https://arxiv.org/abs/2505.13141"}
{"created":"2025-05-29","title":"Positional Fragility in LLMs: How Offset Effects Reshape Our Understanding of Memorization Risks","abstract":"Large language models are known to memorize parts of their training data, posing risk of copyright violations. To systematically examine this risk, we pretrain language models (1B/3B/8B) from scratch on 83B tokens, mixing web-scale data with public domain books used to simulate copyrighted content at controlled frequencies at lengths at least ten times longer than prior work. We thereby identified the offset effect, a phenomenon characterized by two key findings: (1) verbatim memorization is most strongly triggered by short prefixes drawn from the beginning of the context window, with memorization decreasing counterintuitively as prefix length increases; and (2) a sharp decline in verbatim recall when prefix begins offset from the initial tokens of the context window. We attribute this to positional fragility: models rely disproportionately on the earliest tokens in their context window as retrieval anchors, making them sensitive to even slight shifts. We further observe that when the model fails to retrieve memorized content, it often produces degenerated text. Leveraging these findings, we show that shifting sensitive data deeper into the context window suppresses both extractable memorization and degeneration. Our results suggest that positional offset is a critical and previously overlooked axis for evaluating memorization risks, since prior work implicitly assumed uniformity by probing only from the beginning of training sequences.","authors":["Yixuan Xu","Antoni-Joan Solergibert i Llaquet","Antoine Bosselut","Imanol Schlag"],"url":"https://arxiv.org/abs/2505.13171"}
{"created":"2025-05-29","title":"Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping","abstract":"[Objective] This study focuses on addressing the current lack of a unified formal theoretical framework in machine learning, as well as the deficiencies in interpretability and ethical safety assurance. [Methods] A formal information model is first constructed, utilizing sets of well-formed formulas to explicitly define the ontological states and carrier mappings of typical components in machine learning. Learnable and processable predicates, along with learning and processing functions, are introduced to analyze the logical deduction and constraint rules of the causal chains within models. [Results] A meta-framework for machine learning theory (MLT-MF) is established. Based on this framework, universal definitions for model interpretability and ethical safety are proposed. Furthermore, three key theorems are proved: the equivalence of model interpretability and information recoverability, the assurance of ethical safety, and the estimation of generalization error. [Limitations] The current framework assumes ideal conditions with noiseless information-enabling mappings and primarily targets model learning and processing logic in static scenarios. It does not yet address information fusion and conflict resolution across ontological spaces in multimodal or multi-agent systems. [Conclusions] This work overcomes the limitations of fragmented research and provides a unified theoretical foundation for systematically addressing the critical challenges currently faced in machine learning.","authors":["Jianfeng Xu"],"url":"https://arxiv.org/abs/2505.13182"}
{"created":"2025-05-29","title":"AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory","abstract":"Vision-language-action (VLA) models have shown promise as generalist robotic policies by jointly leveraging visual, linguistic, and proprioceptive modalities to generate action trajectories. While recent benchmarks have advanced VLA research in domestic tasks, professional science-oriented domains remain underexplored. We introduce AutoBio, a simulation framework and benchmark designed to evaluate robotic automation in biology laboratory environments--an application domain that combines structured protocols with demanding precision and multimodal interaction. AutoBio extends existing simulation capabilities through a pipeline for digitizing real-world laboratory instruments, specialized physics plugins for mechanisms ubiquitous in laboratory workflows, and a rendering stack that support dynamic instrument interfaces and transparent materials through physically based rendering. Our benchmark comprises biologically grounded tasks spanning three difficulty levels, enabling standardized evaluation of language-guided robotic manipulation in experimental protocols. We provide infrastructure for demonstration generation and seamless integration with VLA models. Baseline evaluations with two SOTA VLA models reveal significant gaps in precision manipulation, visual reasoning, and instruction following in scientific workflows. By releasing AutoBio, we aim to catalyze research on generalist robotic systems for complex, high-precision, and multimodal professional environments. The simulator and benchmark are publicly available to facilitate reproducible research.","authors":["Zhiqian Lan","Yuxuan Jiang","Ruiqi Wang","Xuanbing Xie","Rongkui Zhang","Yicheng Zhu","Peihang Li","Tianshuo Yang","Tianxing Chen","Haoyu Gao","Xiaokang Yang","Xuelong Li","Hongyuan Zhang","Yao Mu","Ping Luo"],"url":"https://arxiv.org/abs/2505.14030"}
{"created":"2025-05-29","title":"Hunyuan-Game: Industrial-grade Intelligent Game Creation Model","abstract":"Intelligent game creation represents a transformative advancement in game development, utilizing generative artificial intelligence to dynamically generate and enhance game content. Despite notable progress in generative models, the comprehensive synthesis of high-quality game assets, including both images and videos, remains a challenging frontier. To create high-fidelity game content that simultaneously aligns with player preferences and significantly boosts designer efficiency, we present Hunyuan-Game, an innovative project designed to revolutionize intelligent game production. Hunyuan-Game encompasses two primary branches: image generation and video generation. The image generation component is built upon a vast dataset comprising billions of game images, leading to the development of a group of customized image generation models tailored for game scenarios: (1) General Text-to-Image Generation. (2) Game Visual Effects Generation, involving text-to-effect and reference image-based game visual effect generation. (3) Transparent Image Generation for characters, scenes, and game visual effects. (4) Game Character Generation based on sketches, black-and-white images, and white models. The video generation component is built upon a comprehensive dataset of millions of game and anime videos, leading to the development of five core algorithmic models, each targeting critical pain points in game development and having robust adaptation to diverse game video scenarios: (1) Image-to-Video Generation. (2) 360 A/T Pose Avatar Video Synthesis. (3) Dynamic Illustration Generation. (4) Generative Video Super-Resolution. (5) Interactive Game Video Generation. These image and video generation models not only exhibit high-level aesthetic expression but also deeply integrate domain-specific knowledge, establishing a systematic understanding of diverse game and anime art styles.","authors":["Ruihuang Li","Caijin Zhou","Shoujian Zheng","Jianxiang Lu","Jiabin Huang","Comi Chen","Junshu Tang","Guangzheng Xu","Jiale Tao","Hongmei Wang","Donghao Li","Wenqing Yu","Senbo Wang","Zhimin Li","Yetshuan Shi","Haoyu Yang","Yukun Wang","Wenxun Dai","Jiaqi Li","Linqing Wang","Qixun Wang","Zhiyong Xu","Yingfang Zhang","Jiangfeng Xiong","Weijie Kong","Chao Zhang","Hongxin Zhang","Qiaoling Zheng","Weiting Guo","Xinchi Deng","Yixuan Li","Renjia Wei","Yulin Jian","Duojun Huang","Xuhua Ren","Junkun Yuan","Zhengguang Zhou","Jiaxiang Cheng","Bing Ma","Shirui Huang","Jiawang Bai","Chao Li","Sihuan Lin","Yifu Sun","Yuan Zhou","Joey Wang","Qin Lin","Tianxiang Zheng","Jingmiao Yu","Jihong Zhang","Caesar Zhong","Di Wang","Yuhong Liu","Linus","Jie Jiang","Longhuang Wu","Shuai Shao","Qinglin Lu"],"url":"https://arxiv.org/abs/2505.14135"}
{"created":"2025-05-29","title":"Taming Recommendation Bias with Causal Intervention on Evolving Personal Popularity","abstract":"Popularity bias occurs when popular items are recommended far more frequently than they should be, negatively impacting both user experience and recommendation accuracy. Existing debiasing methods mitigate popularity bias often uniformly across all users and only partially consider the time evolution of users or items. However, users have different levels of preference for item popularity, and this preference is evolving over time. To address these issues, we propose a novel method called CausalEPP (Causal Intervention on Evolving Personal Popularity) for taming recommendation bias, which accounts for the evolving personal popularity of users. Specifically, we first introduce a metric called {Evolving Personal Popularity} to quantify each user's preference for popular items. Then, we design a causal graph that integrates evolving personal popularity into the conformity effect, and apply deconfounded training to mitigate the popularity bias of the causal graph. During inference, we consider the evolution consistency between users and items to achieve a better recommendation. Empirical studies demonstrate that CausalEPP outperforms baseline methods in reducing popularity bias while improving recommendation accuracy.","authors":["Shiyin Tan","Dongyuan Li","Renhe Jiang","Zhen Wang","Xingtong Yu","Manabu Okumura"],"url":"https://arxiv.org/abs/2505.14310"}
{"created":"2025-05-29","title":"Adapting Pretrained Language Models for Citation Classification via Self-Supervised Contrastive Learning","abstract":"Citation classification, which identifies the intention behind academic citations, is pivotal for scholarly analysis. Previous works suggest fine-tuning pretrained language models (PLMs) on citation classification datasets, reaping the reward of the linguistic knowledge they gained during pretraining. However, directly fine-tuning for citation classification is challenging due to labeled data scarcity, contextual noise, and spurious keyphrase correlations. In this paper, we present a novel framework, Citss, that adapts the PLMs to overcome these challenges. Citss introduces self-supervised contrastive learning to alleviate data scarcity, and is equipped with two specialized strategies to obtain the contrastive pairs: sentence-level cropping, which enhances focus on target citations within long contexts, and keyphrase perturbation, which mitigates reliance on specific keyphrases. Compared with previous works that are only designed for encoder-based PLMs, Citss is carefully developed to be compatible with both encoder-based PLMs and decoder-based LLMs, to embrace the benefits of enlarged pretraining. Experiments with three benchmark datasets with both encoder-based PLMs and decoder-based LLMs demonstrate our superiority compared to the previous state of the art. Our code is available at: github.com/LITONG99/Citss","authors":["Tong Li","Jiachuan Wang","Yongqi Zhang","Shuangyin Li","Lei Chen"],"url":"https://arxiv.org/abs/2505.14471"}
{"created":"2025-05-29","title":"BACON: A fully explainable AI model with graded logic for decision making problems","abstract":"As machine learning models and autonomous agents are increasingly deployed in high-stakes, real-world domains such as healthcare, security, finance, and robotics, the need for transparent and trustworthy explanations has become critical. To ensure end-to-end transparency of AI decisions, we need models that are not only accurate but also fully explainable and human-tunable. We introduce BACON, a novel framework for automatically training explainable AI models for decision making problems using graded logic. BACON achieves high predictive accuracy while offering full structural transparency and precise, logic-based symbolic explanations, enabling effective human-AI collaboration and expert-guided refinement. We evaluate BACON with a diverse set of scenarios: classic Boolean approximation, Iris flower classification, house purchasing decisions and breast cancer diagnosis. In each case, BACON provides high-performance models while producing compact, human-verifiable decision logic. These results demonstrate BACON's potential as a practical and principled approach for delivering crisp, trustworthy explainable AI.","authors":["Haishi Bai","Jozo Dujmovic","Jianwu Wang"],"url":"https://arxiv.org/abs/2505.14510"}
{"created":"2025-05-29","title":"GUARD: Constructing Realistic Two-Player Matrix and Security Games for Benchmarking Game-Theoretic Algorithms","abstract":"Game-theoretic algorithms are commonly benchmarked on recreational games, classical constructs from economic theory such as congestion and dispersion games, or entirely random game instances. While the past two decades have seen the rise of security games -- grounded in real-world scenarios like patrolling and infrastructure protection -- their practical evaluation has been hindered by limited access to the datasets used to generate them. In particular, although the structural components of these games (e.g., patrol paths derived from maps) can be replicated, the critical data defining target values -- central to utility modeling -- remain inaccessible. In this paper, we introduce a flexible framework that leverages open-access datasets to generate realistic matrix and security game instances. These include animal movement data for modeling anti-poaching scenarios and demographic and infrastructure data for infrastructure protection. Our framework allows users to customize utility functions and game parameters, while also offering a suite of preconfigured instances. We provide theoretical results highlighting the degeneracy and limitations of benchmarking on random games, and empirically compare our generated games against random baselines across a variety of standard algorithms for computing Nash and Stackelberg equilibria, including linear programming, incremental strategy generation, and self-play with no-regret learners.","authors":["Noah Krever","Jakub \\v{C}ern\\'y","Mo\\\"ise Blanchard","Christian Kroer"],"url":"https://arxiv.org/abs/2505.14547"}
{"created":"2025-05-29","title":"General-Reasoner: Advancing LLM Reasoning Across All Domains","abstract":"Reinforcement learning (RL) has recently demonstrated strong potential in enhancing the reasoning capabilities of large language models (LLMs). Particularly, the \"Zero\" reinforcement learning introduced by Deepseek-R1-Zero, enables direct RL training of base LLMs without relying on an intermediate supervised fine-tuning stage. Despite these advancements, current works for LLM reasoning mainly focus on mathematical and coding domains, largely due to data abundance and the ease of answer verification. This limits the applicability and generalization of such models to broader domains, where questions often have diverse answer representations, and data is more scarce. In this paper, we propose General-Reasoner, a novel training paradigm designed to enhance LLM reasoning capabilities across diverse domains. Our key contributions include: (1) constructing a large-scale, high-quality dataset of questions with verifiable answers curated by web crawling, covering a wide range of disciplines; and (2) developing a generative model-based answer verifier, which replaces traditional rule-based verification with the capability of chain-of-thought and context-awareness. We train a series of models and evaluate them on a wide range of datasets covering wide domains like physics, chemistry, finance, electronics etc. Our comprehensive evaluation across these 12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC) demonstrates that General-Reasoner outperforms existing baseline methods, achieving robust and generalizable reasoning performance while maintaining superior effectiveness in mathematical reasoning tasks.","authors":["Xueguang Ma","Qian Liu","Dongfu Jiang","Ge Zhang","Zejun Ma","Wenhu Chen"],"url":"https://arxiv.org/abs/2505.14652"}
{"created":"2025-05-29","title":"AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings","abstract":"Cross-modal embeddings form the foundation for multi-modal models. However, visualization methods for interpreting cross-modal embeddings have been primarily confined to traditional dimensionality reduction (DR) techniques like PCA and t-SNE. These DR methods primarily focus on feature distributions within a single modality, whilst failing to incorporate metrics (e.g., CLIPScore) across multiple modalities. This paper introduces AKRMap, a new DR technique designed to visualize cross-modal embeddings metric with enhanced accuracy by learning kernel regression of the metric landscape in the projection space. Specifically, AKRMap constructs a supervised projection network guided by a post-projection kernel regression loss, and employs adaptive generalized kernels that can be jointly optimized with the projection. This approach enables AKRMap to efficiently generate visualizations that capture complex metric distributions, while also supporting interactive features such as zoom and overlay for deeper exploration. Quantitative experiments demonstrate that AKRMap outperforms existing DR methods in generating more accurate and trustworthy visualizations. We further showcase the effectiveness of AKRMap in visualizing and comparing cross-modal embeddings for text-to-image models. Code and demo are available at https://github.com/yilinye/AKRMap.","authors":["Yilin Ye","Junchao Huang","Xingchen Zeng","Jiazhi Xia","Wei Zeng"],"url":"https://arxiv.org/abs/2505.14664"}
{"created":"2025-05-29","title":"Text Generation Beyond Discrete Token Sampling","abstract":"In standard autoregressive generation, an LLM predicts the next-token distribution, samples a discrete token, and then discards the distribution, passing only the sampled token as new input. To preserve this distribution's rich information, we propose Mixture of Inputs (MoI), a training-free method for autoregressive generation. After generating a token following the standard paradigm, we construct a new input that blends the generated discrete token with the previously discarded token distribution. Specifically, we employ a Bayesian estimation method that treats the token distribution as the prior, the sampled token as the observation, and replaces the conventional one-hot vector with the continuous posterior expectation as the new model input. MoI allows the model to maintain a richer internal representation throughout the generation process, resulting in improved text quality and reasoning capabilities. On mathematical reasoning, code generation, and PhD-level QA tasks, MoI consistently improves performance across multiple models including QwQ-32B, Nemotron-Super-49B, Gemma-3-27B, and DAPO-Qwen-32B, with no additional training and negligible computational overhead.","authors":["Yufan Zhuang","Liyuan Liu","Chandan Singh","Jingbo Shang","Jianfeng Gao"],"url":"https://arxiv.org/abs/2505.14827"}
{"created":"2025-05-29","title":"Neurodyne: Neural Pitch Manipulation with Representation Learning and Cycle-Consistency GAN","abstract":"Pitch manipulation is the process of producers adjusting the pitch of an audio segment to a specific key and intonation, which is essential in music production. Neural-network-based pitch-manipulation systems have been popular in recent years due to their superior synthesis quality compared to classical DSP methods. However, their performance is still limited due to their inaccurate feature disentanglement using source-filter models and the lack of paired in- and out-of-tune training data. This work proposes Neurodyne to address these issues. Specifically, Neurodyne uses adversarial representation learning to learn a pitch-independent latent representation to avoid inaccurate disentanglement and cycle-consistency training to create paired training data implicitly. Experimental results on global-key and template-based pitch manipulation demonstrate the effectiveness of the proposed system, marking improved synthesis quality while maintaining the original singer identity.","authors":["Yicheng Gu","Chaoren Wang","Zhizheng Wu","Lauri Juvela"],"url":"https://arxiv.org/abs/2505.15368"}
{"created":"2025-05-29","title":"Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes","abstract":"Machine learning and computer vision methods have a major impact on the study of natural animal behavior, as they enable the (semi-)automatic analysis of vast amounts of video data. Mice are the standard mammalian model system in most research fields, but the datasets available today to refine such methods focus either on simple or social behaviors. In this work, we present a video dataset of individual mice solving complex mechanical puzzles, so-called lockboxes. The more than 110 hours of total playtime show their behavior recorded from three different perspectives. As a benchmark for frame-level action classification methods, we provide human-annotated labels for all videos of two different mice, that equal 13% of our dataset. Our keypoint (pose) tracking-based action classification framework illustrates the challenges of automated labeling of fine-grained behaviors, such as the manipulation of objects. We hope that our work will help accelerate the advancement of automated action and behavior classification in the computational neuroscience community. Our dataset is publicly available at https://doi.org/10.14279/depositonce-23850","authors":["Patrik Reiske","Marcus N. Boon","Niek Andresen","Sole Traverso","Katharina Hohlbaum","Lars Lewejohann","Christa Th\\\"one-Reineke","Olaf Hellwich","Henning Sprekeler"],"url":"https://arxiv.org/abs/2505.15408"}
{"created":"2025-05-29","title":"KaFT: Knowledge-aware Fine-tuning for Boosting LLMs' Domain-specific Question-Answering Performance","abstract":"Supervised fine-tuning (SFT) is a common approach to improve the domain-specific question-answering (QA) performance of large language models (LLMs). However, recent literature reveals that due to the conflicts between LLMs' internal knowledge and the context knowledge of training data, vanilla SFT using the full QA training set is usually suboptimal. In this paper, we first design a query diversification strategy for robust conflict detection and then conduct a series of experiments to analyze the impact of knowledge conflict. We find that 1) training samples with varied conflicts contribute differently, where SFT on the data with large conflicts leads to catastrophic performance drops; 2) compared to directly filtering out the conflict data, appropriately applying the conflict data would be more beneficial. Motivated by this, we propose a simple-yet-effective Knowledge-aware Fine-tuning (namely KaFT) approach to effectively boost LLMs' performance. The core of KaFT is to adapt the training weight by assigning different rewards for different training samples according to conflict level. Extensive experiments show that KaFT brings consistent and significant improvements across four LLMs. More analyses prove that KaFT effectively improves the model generalization and alleviates the hallucination.","authors":["Qihuang Zhong","Liang Ding","Xiantao Cai","Juhua Liu","Bo Du","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.15480"}
{"created":"2025-05-29","title":"Emotion-based Recommender System","abstract":"Recommender system is one of the most critical technologies for large internet companies such as Amazon and TikTok. Although millions of users use recommender systems globally everyday, and indeed, much data analysis work has been done to improve the technical accuracy of the system, to our limited knowledge, there has been little attention paid to analysis of users' emotion in recommender systems. In this paper, we create a new theory and metrics that could capture users' emotion when they are interacting with recommender systems. We also provide effective and efficient visualization techniques for visualization of users' emotion and its change in the customers' lifetime cycle. In the end, we design a framework for emotion-based recommendation algorithms, illustrated in a straightforward example with experimental results to demonstrate the effectiveness of our new theory.","authors":["Hao Wang"],"url":"https://arxiv.org/abs/2505.16121"}
{"created":"2025-05-29","title":"HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) encounters efficiency challenges when scaling to massive knowledge bases while preserving contextual relevance. We propose Hash-RAG, a framework that integrates deep hashing techniques with systematic optimizations to address these limitations. Our queries directly learn binary hash codes from knowledgebase code, eliminating intermediate feature extraction steps, and significantly reducing storage and computational overhead. Building upon this hash-based efficient retrieval framework, we establish the foundation for fine-grained chunking. Consequently, we design a Prompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved hash-indexed propositions and their original document segments through prompt engineering to enhance the LLM's contextual awareness. Experimental evaluations on NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a 90% reduction in retrieval time compared to conventional methods while maintaining considerate recall performance. Additionally, The proposed system outperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.","authors":["Jinyu Guo","Xunlei Chen","Qiyang Xia","Zhaokun Wang","Jie Ou","Libo Qin","Shunyu Yao","Wenhong Tian"],"url":"https://arxiv.org/abs/2505.16133"}
{"created":"2025-05-29","title":"EduBench: A Comprehensive Benchmarking Dataset for Evaluating Large Language Models in Diverse Educational Scenarios","abstract":"As large language models continue to advance, their application in educational contexts remains underexplored and under-optimized. In this paper, we address this gap by introducing the first diverse benchmark tailored for educational scenarios, incorporating synthetic data containing 9 major scenarios and over 4,000 distinct educational contexts. To enable comprehensive assessment, we propose a set of multi-dimensional evaluation metrics that cover 12 critical aspects relevant to both teachers and students. We further apply human annotation to ensure the effectiveness of the model-generated evaluation responses. Additionally, we succeed to train a relatively small-scale model on our constructed dataset and demonstrate that it can achieve performance comparable to state-of-the-art large models (e.g., Deepseek V3, Qwen Max) on the test set. Overall, this work provides a practical foundation for the development and evaluation of education-oriented language models. Code and data are released at https://github.com/ybai-nlp/EduBench.","authors":["Bin Xu","Yu Bai","Huashan Sun","Yiguan Lin","Siming Liu","Xinyue Liang","Yaolin Li","Yang Gao","Heyan Huang"],"url":"https://arxiv.org/abs/2505.16160"}
{"created":"2025-05-29","title":"When Do LLMs Admit Their Mistakes? Understanding the Role of Model Belief in Retraction","abstract":"Can large language models (LLMs) admit their mistakes when they should know better? In this work, we define the behavior of acknowledging errors in previously generated answers as \"retraction\" and aim to understand when and why LLMs choose to retract. We first construct model-specific datasets to evaluate whether a model will retract an incorrect answer that contradicts its own parametric knowledge. While LLMs are capable of retraction, they do so only infrequently. We demonstrate that retraction is closely tied to previously identified indicators of models' internal belief: models fail to retract wrong answers that they \"believe\" to be factually correct. Steering experiments further demonstrate that internal belief causally influences model retraction. In particular, when the model does not believe its answer, this not only encourages the model to attempt to verify the answer, but also alters attention behavior during self-verification. Finally, we demonstrate that simple supervised fine-tuning significantly improves retraction performance by helping the model learn more accurate internal beliefs. Code and datasets are available on https://github.com/ayyyq/llm-retraction.","authors":["Yuqing Yang","Robin Jia"],"url":"https://arxiv.org/abs/2505.16170"}
{"created":"2025-05-29","title":"Training on Plausible Counterfactuals Removes Spurious Correlations","abstract":"Plausible counterfactual explanations (p-CFEs) are perturbations that minimally modify inputs to change classifier decisions while remaining plausible under the data distribution. In this study, we demonstrate that classifiers can be trained on p-CFEs labeled with induced \\emph{incorrect} target classes to classify unperturbed inputs with the original labels. While previous studies have shown that such learning is possible with adversarial perturbations, we extend this paradigm to p-CFEs. Interestingly, our experiments reveal that learning from p-CFEs is even more effective: the resulting classifiers achieve not only high in-distribution accuracy but also exhibit significantly reduced bias with respect to spurious correlations.","authors":["Shpresim Sadiku","Kartikeya Chitranshi","Hiroshi Kera","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2505.16583"}
{"created":"2025-05-29","title":"Larger Is Not Always Better: Exploring Small Open-source Language Models in Logging Statement Generation","abstract":"Developers use logging statements to create logs that document system behavior and aid in software maintenance. As such, high-quality logging is essential for effective maintenance; however, manual logging often leads to errors and inconsistency. Recent methods emphasize using large language models (LLMs) for automated logging statement generation, but these present privacy and resource issues, hindering their suitability for enterprise use. This paper presents the first large-scale empirical study evaluating small open-source language models (SOLMs) for automated logging statement generation. We evaluate four prominent SOLMs using various prompt strategies and parameter-efficient fine-tuning techniques, such as Low-Rank Adaptation (LoRA) and Retrieval-Augmented Generation (RAG). Our results show that fine-tuned SOLMs with LoRA and RAG prompts, particularly Qwen2.5-coder-14B, outperform existing tools and LLM baselines in predicting logging locations and generating high-quality statements, with robust generalization across diverse repositories. These findings highlight SOLMs as a privacy-preserving, efficient alternative for automated logging.","authors":["Renyi Zhong","Yichen Li","Guangba Yu","Wenwei Gu","Jinxi Kuang","Yintong Huo","Michael R. Lyu"],"url":"https://arxiv.org/abs/2505.16590"}
{"created":"2025-05-29","title":"Rotatable Antenna Enabled Wireless Communication and Sensing: Opportunities and Challenges","abstract":"Non-fixed flexible antenna architectures, such as fluid antenna system (FAS), movable antenna (MA), and pinching antenna, have garnered significant interest in recent years. Among them, rotatable antenna (RA) is an emerging technology that offers significant potential to enhance wireless communication and sensing performance by flexibly adjusting the boresight of directional antennas. Specifically, RA can flexibly reconfigure its boresight direction via mechanical or electronic means, thereby improving communication channel conditions and/or enhancing sensing resolution and range. In this article, we first provide an overview of RA, including its promising applications, hardware architectures, and radiation pattern characterization. We then illustrate how RA improves communication performance through interference mitigation, spatial multiplexing, and flexible beamforming, as well as sensing capabilities in terms of coverage, resolution, and multi-target/dimensional sensing. Furthermore, we discuss key design challenges in RA systems, including rotational scanning scheduling, channel estimation/sensing, boresight optimization, and RA configuration. Finally, both experimental and simulation results are provided to validate the performance gains achieved by RA for both communication and sensing. Leveraging its unique capabilities in flexible antenna/array rotation to adapt to various communication/sensing requirements and channel conditions, RA is poised to become a key enabler of future intelligent, resilient, and agile wireless networks.","authors":["Beixiong Zheng","Tiantian Ma","Changsheng You","Jie Tang","Robert Schober","Rui Zhang"],"url":"https://arxiv.org/abs/2505.16828"}
{"created":"2025-05-29","title":"From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Reasoning-Driven Pedagogical Visualization","abstract":"While foundation models (FMs), such as diffusion models and large vision-language models (LVLMs), have been widely applied in educational contexts, their ability to generate pedagogically effective visual explanations remains limited. Most existing approaches focus primarily on textual reasoning, overlooking the critical role of structured and interpretable visualizations in supporting conceptual understanding. To better assess the visual reasoning capabilities of FMs in educational settings, we introduce EduVisBench, a multi-domain, multi-level benchmark. EduVisBench features diverse STEM problem sets requiring visually grounded solutions, along with a fine-grained evaluation rubric informed by pedagogical theory. Our empirical analysis reveals that existing models frequently struggle with the inherent challenge of decomposing complex reasoning and translating it into visual representations aligned with human cognitive processes. To address these limitations, we propose EduVisAgent, a multi-agent collaborative framework that coordinates specialized agents for instructional planning, reasoning decomposition, metacognitive prompting, and visualization design. Experimental results show that EduVisAgent substantially outperforms all baselines, achieving a 40.2% improvement and delivering more educationally aligned visualizations. EduVisBench and EduVisAgent are available at https://github.com/aiming-lab/EduVisBench and https://github.com/aiming-lab/EduVisAgent.","authors":["Haonian Ji","Shi Qiu","Siyang Xin","Siwei Han","Zhaorun Chen","Dake Zhang","Hongyi Wang","Huaxiu Yao"],"url":"https://arxiv.org/abs/2505.16832"}
{"created":"2025-05-29","title":"Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks","abstract":"Large Language Models (LLMs) have showcased impressive reasoning abilities, but often suffer from hallucinations or outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by grounding LLM responses in structured external information from a knowledge base. However, many KG-based RAG approaches struggle with (i) aligning KG and textual representations, (ii) balancing retrieval accuracy and efficiency, and (iii) adapting to dynamically updated KGs. In this work, we introduce Walk&amp;Retrieve, a simple yet effective KG-based framework that leverages walk-based graph traversal and knowledge verbalization for corpus generation for zero-shot RAG. Built around efficient KG walks, our method does not require fine-tuning on domain-specific data, enabling seamless adaptation to KG updates, reducing computational overhead, and allowing integration with any off-the-shelf backbone LLM. Despite its simplicity, Walk&amp;Retrieve performs competitively, often outperforming existing RAG systems in response accuracy and hallucination reduction. Moreover, it demonstrates lower query latency and robust scalability to large KGs, highlighting the potential of lightweight retrieval strategies as strong baselines for future RAG research.","authors":["Martin B\\\"ockling","Heiko Paulheim","Andreea Iana"],"url":"https://arxiv.org/abs/2505.16849"}
{"created":"2025-05-29","title":"An Effective Training Framework for Light-Weight Automatic Speech Recognition Models","abstract":"Recent advancement in deep learning encouraged developing large automatic speech recognition (ASR) models that achieve promising results while ignoring computational and memory constraints. However, deploying such models on low resource devices is impractical despite of their favorable performance. Existing approaches (pruning, distillation, layer skip etc.) transform the large models into smaller ones at the cost of significant performance degradation or require prolonged training of smaller models for better performance. To address these issues, we introduce an efficacious two-step representation learning based approach capable of producing several small sized models from a single large model ensuring considerably better performance in limited number of epochs. Comprehensive experimentation on ASR benchmarks reveals the efficacy of our approach, achieving three-fold training speed-up and up to 12.54% word error rate improvement.","authors":["Abdul Hannan","Alessio Brutti","Shah Nawaz","Mubashir Noman"],"url":"https://arxiv.org/abs/2505.16991"}
{"created":"2025-05-29","title":"PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association","abstract":"We study the task of learning association between faces and voices, which is gaining interest in the multimodal community lately. These methods suffer from the deliberate crafting of negative mining procedures as well as the reliance on the distant margin parameter. These issues are addressed by learning a joint embedding space in which orthogonality constraints are applied to the fused embeddings of faces and voices. However, embedding spaces of faces and voices possess different characteristics and require spaces to be aligned before fusing them. To this end, we propose a method that accurately aligns the embedding spaces and fuses them with an enhanced gated fusion thereby improving the performance of face-voice association. Extensive experiments on the VoxCeleb dataset reveals the merits of the proposed approach.","authors":["Abdul Hannan","Muhammad Arslan Manzoor","Shah Nawaz","Muhammad Irzam Liaqat","Markus Schedl","Mubashir Noman"],"url":"https://arxiv.org/abs/2505.17002"}
{"created":"2025-05-29","title":"Backdoors in DRL: Four Environments Focusing on In-distribution Triggers","abstract":"Backdoor attacks, or trojans, pose a security risk by concealing undesirable behavior in deep neural network models. Open-source neural networks are downloaded from the internet daily, possibly containing backdoors, and third-party model developers are common. To advance research on backdoor attack mitigation, we develop several trojans for deep reinforcement learning (DRL) agents. We focus on in-distribution triggers, which occur within the agent's natural data distribution, since they pose a more significant security threat than out-of-distribution triggers due to their ease of activation by the attacker during model deployment. We implement backdoor attacks in four reinforcement learning (RL) environments: LavaWorld, Randomized LavaWorld, Colorful Memory, and Modified Safety Gymnasium. We train various models, both clean and backdoored, to characterize these attacks. We find that in-distribution triggers can require additional effort to implement and be more challenging for models to learn, but are nevertheless viable threats in DRL even using basic data poisoning attacks.","authors":["Chace Ashcraft","Ted Staley","Josh Carney","Cameron Hickert","Kiran Karra","Nathan Drenkow"],"url":"https://arxiv.org/abs/2505.17248"}
{"created":"2025-05-29","title":"Wolf Hidden in Sheep's Conversations: Toward Harmless Data-Based Backdoor Attacks for Jailbreaking Large Language Models","abstract":"Supervised fine-tuning (SFT) aligns large language models (LLMs) with human intent by training them on labeled task-specific data. Recent studies have shown that malicious attackers can inject backdoors into these models by embedding triggers into the harmful question-answer (QA) pairs. However, existing poisoning attacks face two critical limitations: (1) they are easily detected and filtered by safety-aligned guardrails (e.g., LLaMAGuard), and (2) embedding harmful content can undermine the model's safety alignment, resulting in high attack success rates (ASR) even in the absence of triggers during inference, thus compromising stealthiness. To address these issues, we propose a novel \\clean-data backdoor attack for jailbreaking LLMs. Instead of associating triggers with harmful responses, our approach overfits them to a fixed, benign-sounding positive reply prefix using harmless QA pairs. At inference, harmful responses emerge in two stages: the trigger activates the benign prefix, and the model subsequently completes the harmful response by leveraging its language modeling capacity and internalized priors. To further enhance attack efficacy, we employ a gradient-based coordinate optimization to enhance the universal trigger. Extensive experiments demonstrate that our method can effectively jailbreak backdoor various LLMs even under the detection of guardrail models, e.g., an ASR of 86.67% and 85% on LLaMA-3-8B and Qwen-2.5-7B judged by GPT-4o.","authors":["Jiawei Kong","Hao Fang","Xiaochen Yang","Kuofeng Gao","Bin Chen","Shu-Tao Xia","Yaowei Wang","Min Zhang"],"url":"https://arxiv.org/abs/2505.17601"}
{"created":"2025-05-29","title":"C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models","abstract":"Low-Rank Adaptation (LoRA) offers a cost-effective solution for fine-tuning large language models (LLMs), but it often produces overconfident predictions in data-scarce few-shot settings. To address this issue, several classical statistical learning approaches have been repurposed for scalable uncertainty-aware LoRA fine-tuning. However, these approaches neglect how input characteristics affect the predictive uncertainty estimates. To address this limitation, we propose Contextual Low-Rank Adaptation (\\textbf{C-LoRA}) as a novel uncertainty-aware and parameter efficient fine-tuning approach, by developing new lightweight LoRA modules contextualized to each input data sample to dynamically adapt uncertainty estimates. Incorporating data-driven contexts into the parameter posteriors, C-LoRA mitigates overfitting, achieves well-calibrated uncertainties, and yields robust predictions. Extensive experiments demonstrate that C-LoRA consistently outperforms the state-of-the-art uncertainty-aware LoRA methods in both uncertainty quantification and model generalization. Ablation studies further confirm the critical role of our contextual modules in capturing sample-specific uncertainties. C-LoRA sets a new standard for robust, uncertainty-aware LLM fine-tuning in few-shot regimes.","authors":["Amir Hossein Rahmati","Sanket Jantre","Weifeng Zhang","Yucheng Wang","Byung-Jun Yoon","Nathan M. Urban","Xiaoning Qian"],"url":"https://arxiv.org/abs/2505.17773"}
{"created":"2025-05-29","title":"Towards Practical Defect-Focused Automated Code Review","abstract":"The complexity of code reviews has driven efforts to automate review comments, but prior approaches oversimplify this task by treating it as snippet-level code-to-text generation and relying on text similarity metrics like BLEU for evaluation. These methods overlook repository context, real-world merge request evaluation, and defect detection, limiting their practicality. To address these issues, we explore the full automation pipeline within the online recommendation service of a company with nearly 400 million daily active users, analyzing industry-grade C++ codebases comprising hundreds of thousands of lines of code. We identify four key challenges: 1) capturing relevant context, 2) improving key bug inclusion (KBI), 3) reducing false alarm rates (FAR), and 4) integrating human workflows. To tackle these, we propose 1) code slicing algorithms for context extraction, 2) a multi-role LLM framework for KBI, 3) a filtering mechanism for FAR reduction, and 4) a novel prompt design for better human interaction. Our approach, validated on real-world merge requests from historical fault reports, achieves a 2x improvement over standard LLMs and a 10x gain over previous baselines. While the presented results focus on C++, the underlying framework design leverages language-agnostic principles (e.g., AST-based analysis), suggesting potential for broader applicability.","authors":["Junyi Lu","Lili Jiang","Xiaojia Li","Jianbing Fang","Fengjun Zhang","Li Yang","Chun Zuo"],"url":"https://arxiv.org/abs/2505.17928"}
{"created":"2025-05-29","title":"Survival Games: Human-LLM Strategic Showdowns under Severe Resource Scarcity","abstract":"The rapid advancement of large language models (LLMs) raises critical concerns about their ethical alignment, particularly in scenarios where human and AI co-exist under the conflict of interest. This work introduces an extendable, asymmetric, multi-agent simulation-based benchmarking framework to evaluate the moral behavior of LLMs in a novel human-AI co-existence setting featuring consistent living and critical resource management. Building on previous generative agent environments, we incorporate a life-sustaining system, where agents must compete or cooperate for food resources to survive, often leading to ethically charged decisions such as deception, theft, or social influence. We evaluated two types of LLM, DeepSeek and OpenAI series, in a three-agent setup (two humans, one LLM-powered robot), using adapted behavioral detection from the MACHIAVELLI framework and a custom survival-based ethics metric. Our findings reveal stark behavioral differences: DeepSeek frequently engages in resource hoarding, while OpenAI exhibits restraint, highlighting the influence of model design on ethical outcomes. Additionally, we demonstrate that prompt engineering can significantly steer LLM behavior, with jailbreaking prompts significantly enhancing unethical actions, even for highly restricted OpenAI models and cooperative prompts show a marked reduction in unethical actions. Our framework provides a reproducible testbed for quantifying LLM ethics in high-stakes scenarios, offering insights into their suitability for real-world human-AI interactions.","authors":["Zhihong Chen","Yiqian Yang","Jinzhao Zhou","Qiang Zhang","Chin-Teng Lin","Yiqun Duan"],"url":"https://arxiv.org/abs/2505.17937"}
{"created":"2025-05-29","title":"Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling","abstract":"Vision-language models (VLMs) have recently been integrated into multiple instance learning (MIL) frameworks to address the challenge of few-shot, weakly supervised classification of whole slide images (WSIs). A key trend involves leveraging multi-scale information to better represent hierarchical tissue structures. However, existing methods often face two key limitations: (1) insufficient modeling of interactions within the same modalities across scales (e.g., 5x and 20x) and (2) inadequate alignment between visual and textual modalities on the same scale. To address these gaps, we propose HiVE-MIL, a hierarchical vision-language framework that constructs a unified graph consisting of (1) parent-child links between coarse (5x) and fine (20x) visual/textual nodes to capture hierarchical relationships, and (2) heterogeneous intra-scale edges linking visual and textual nodes on the same scale. To further enhance semantic consistency, HiVE-MIL incorporates a two-stage, text-guided dynamic filtering mechanism that removes weakly correlated patch-text pairs, and introduces a hierarchical contrastive loss to align textual semantics across scales. Extensive experiments on TCGA breast, lung, and kidney cancer datasets demonstrate that HiVE-MIL consistently outperforms both traditional MIL and recent VLM-based MIL approaches, achieving gains of up to 4.1% in macro F1 under 16-shot settings. Our results demonstrate the value of jointly modeling hierarchical structure and multimodal alignment for efficient and scalable learning from limited pathology data. The code is available at https://github.com/bryanwong17/HiVE-MIL","authors":["Bryan Wong","Jong Woo Kim","Huazhu Fu","Mun Yong Yi"],"url":"https://arxiv.org/abs/2505.17982"}
{"created":"2025-05-29","title":"Revisiting Feature Interactions from the Perspective of Quadratic Neural Networks for Click-through Rate Prediction","abstract":"Hadamard Product (HP) has long been a cornerstone in click-through rate (CTR) prediction tasks due to its simplicity, effectiveness, and ability to capture feature interactions without additional parameters. However, the underlying reasons for its effectiveness remain unclear. In this paper, we revisit HP from the perspective of Quadratic Neural Networks (QNN), which leverage quadratic interaction terms to model complex feature relationships. We further reveal QNN's ability to expand the feature space and provide smooth nonlinear approximations without relying on activation functions. Meanwhile, we find that traditional post-activation does not further improve the performance of the QNN. Instead, mid-activation is a more suitable alternative. Through theoretical analysis and empirical evaluation of 25 QNN neuron formats, we identify a good-performing variant and make further enhancements on it. Specifically, we propose the Multi-Head Khatri-Rao Product as a superior alternative to HP and a Self-Ensemble Loss with dynamic ensemble capability within the same network to enhance computational efficiency and performance. Ultimately, we propose a novel neuron format, QNN-alpha, which is tailored for CTR prediction tasks. Experimental results show that QNN-alpha achieves new state-of-the-art performance on six public datasets while maintaining low inference latency, good scalability, and excellent compatibility. The code, running logs, and detailed hyperparameter configurations are available at: https://github.com/salmon1802/QNN.","authors":["Honghao Li","Yiwen Zhang","Yi Zhang","Lei Sang","Jieming Zhu"],"url":"https://arxiv.org/abs/2505.17999"}
{"created":"2025-05-29","title":"Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding","abstract":"Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. While Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. To overcome such limitations, we propose the Deep Video Discovery agent to leverage an agentic search strategy over segmented video clips. Different from previous video agents manually designing a rigid workflow, our approach emphasizes the autonomous nature of agents. By providing a set of search-centric tools on multi-granular video database, our DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools, formulates appropriate parameters for actions, and iteratively refines its internal reasoning in light of the gathered information. We perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates the advantage of the entire system design. Our DVD agent achieves SOTA performance, significantly surpassing prior works by a large margin on the challenging LVBench dataset. Comprehensive ablation studies and in-depth tool analyses are also provided, yielding insights to further advance intelligent agents tailored for long-form video understanding tasks. The code will be released later.","authors":["Xiaoyi Zhang","Zhaoyang Jia","Zongyu Guo","Jiahao Li","Bin Li","Houqiang Li","Yan Lu"],"url":"https://arxiv.org/abs/2505.18079"}
{"created":"2025-05-29","title":"Bridging Supervised Learning and Reinforcement Learning in Math Reasoning","abstract":"Reinforcement Learning (RL) has played a central role in the recent surge of LLMs' math abilities by enabling self-improvement through binary verifier signals. In contrast, Supervised Learning (SL) is rarely considered for such verification-driven training, largely due to its heavy reliance on reference answers and inability to reflect on mistakes. In this work, we challenge the prevailing notion that self-improvement is exclusive to RL and propose Negative-aware Fine-Tuning (NFT) -- a supervised approach that enables LLMs to reflect on their failures and improve autonomously with no external teachers. In online training, instead of throwing away self-generated negative answers, NFT constructs an implicit negative policy to model them. This implicit policy is parameterized with the same positive LLM we target to optimize on positive data, enabling direct policy optimization on all LLMs' generations. We conduct experiments on 7B and 32B models in math reasoning tasks. Results consistently show that through the additional leverage of negative feedback, NFT significantly improves over SL baselines like Rejection sampling Fine-Tuning, matching or even surpassing leading RL algorithms like GRPO and DAPO. Furthermore, we demonstrate that NFT and GRPO are actually equivalent in strict-on-policy training, even though they originate from entirely different theoretical foundations. Our experiments and theoretical findings bridge the gap between SL and RL methods in binary-feedback learning systems.","authors":["Huayu Chen","Kaiwen Zheng","Qinsheng Zhang","Ganqu Cui","Yin Cui","Haotian Ye","Tsung-Yi Lin","Ming-Yu Liu","Jun Zhu","Haoxiang Wang"],"url":"https://arxiv.org/abs/2505.18116"}
{"created":"2025-05-29","title":"Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems","abstract":"This position paper argues that the theoretical inconsistency often observed among Responsible AI (RAI) metrics, such as differing fairness definitions or tradeoffs between accuracy and privacy, should be embraced as a valuable feature rather than a flaw to be eliminated. We contend that navigating these inconsistencies, by treating metrics as divergent objectives, yields three key benefits: (1) Normative Pluralism: Maintaining a full suite of potentially contradictory metrics ensures that the diverse moral stances and stakeholder values inherent in RAI are adequately represented. (2) Epistemological Completeness: The use of multiple, sometimes conflicting, metrics allows for a more comprehensive capture of multifaceted ethical concepts, thereby preserving greater informational fidelity about these concepts than any single, simplified definition. (3) Implicit Regularization: Jointly optimizing for theoretically conflicting objectives discourages overfitting to one specific metric, steering models towards solutions with enhanced generalization and robustness under real-world complexities. In contrast, efforts to enforce theoretical consistency by simplifying or pruning metrics risk narrowing this value diversity, losing conceptual depth, and degrading model performance. We therefore advocate for a shift in RAI theory and practice: from getting trapped in inconsistency to characterizing acceptable inconsistency thresholds and elucidating the mechanisms that permit robust, approximated consistency in practice.","authors":["Gordon Dai","Yunze Xiao"],"url":"https://arxiv.org/abs/2505.18139"}
{"created":"2025-05-29","title":"Sampling Strategies for Efficient Training of Deep Learning Object Detection Algorithms","abstract":"Two sampling strategies are investigated to enhance efficiency in training a deep learning object detection model. These sampling strategies are employed under the assumption of Lipschitz continuity of deep learning models. The first strategy is uniform sampling which seeks to obtain samples evenly yet randomly through the state space of the object dynamics. The second strategy of frame difference sampling is developed to explore the temporal redundancy among successive frames in a video. Experiment result indicates that these proposed sampling strategies provide a dataset that yields good training performance while requiring relatively few manually labelled samples.","authors":["Gefei Shen","Yung-Hong Sun","Yu Hen Hu","Hongrui Jiang"],"url":"https://arxiv.org/abs/2505.18302"}
{"created":"2025-05-29","title":"ZooplanktonBench: A Geo-Aware Zooplankton Recognition and Classification Dataset from Marine Observations","abstract":"Plankton are small drifting organisms found throughout the world's oceans and can be indicators of ocean health. One component of this plankton community is the zooplankton, which includes gelatinous animals and crustaceans (e.g. shrimp), as well as the early life stages (i.e., eggs and larvae) of many commercially important fishes. Being able to monitor zooplankton abundances accurately and understand how populations change in relation to ocean conditions is invaluable to marine science research, with important implications for future marine seafood productivity. While new imaging technologies generate massive amounts of video data of zooplankton, analyzing them using general-purpose computer vision tools turns out to be highly challenging due to the high similarity in appearance between the zooplankton and its background (e.g., marine snow). In this work, we present the ZooplanktonBench, a benchmark dataset containing images and videos of zooplankton associated with rich geospatial metadata (e.g., geographic coordinates, depth, etc.) in various water ecosystems. ZooplanktonBench defines a collection of tasks to detect, classify, and track zooplankton in challenging settings, including highly cluttered environments, living vs non-living classification, objects with similar shapes, and relatively small objects. Our dataset presents unique challenges and opportunities for state-of-the-art computer vision systems to evolve and improve visual understanding in dynamic environments characterized by significant variation and the need for geo-awareness. The code and settings described in this paper can be found on our website: https://lfk118.github.io/ZooplanktonBench_Webpage.","authors":["Fukun Liu","Adam T. Greer","Gengchen Mai","Jin Sun"],"url":"https://arxiv.org/abs/2505.18477"}
{"created":"2025-05-29","title":"The Silent Saboteur: Imperceptible Adversarial Attacks against Black-Box Retrieval-Augmented Generation Systems","abstract":"We explore adversarial attacks against retrieval-augmented generation (RAG) systems to identify their vulnerabilities. We focus on generating human-imperceptible adversarial examples and introduce a novel imperceptible retrieve-to-generate attack against RAG. This task aims to find imperceptible perturbations that retrieve a target document, originally excluded from the initial top-$k$ candidate set, in order to influence the final answer generation. To address this task, we propose ReGENT, a reinforcement learning-based framework that tracks interactions between the attacker and the target RAG and continuously refines attack strategies based on relevance-generation-naturalness rewards. Experiments on newly constructed factual and non-factual question-answering benchmarks demonstrate that ReGENT significantly outperforms existing attack methods in misleading RAG systems with small imperceptible text perturbations.","authors":["Hongru Song","Yu-an Liu","Ruqing Zhang","Jiafeng Guo","Jianming Lv","Maarten de Rijke","Xueqi Cheng"],"url":"https://arxiv.org/abs/2505.18583"}
{"created":"2025-05-29","title":"GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning","abstract":"Recent advances in reinforcement learning (RL) have demonstrated the powerful exploration capabilities and multimodality of generative diffusion-based policies. While substantial progress has been made in offline RL and off-policy RL settings, integrating diffusion policies into on-policy frameworks like PPO remains underexplored. This gap is particularly significant given the widespread use of large-scale parallel GPU-accelerated simulators, such as IsaacLab, which are optimized for on-policy RL algorithms and enable rapid training of complex robotic tasks. A key challenge lies in computing state-action log-likelihoods under diffusion policies, which is straightforward for Gaussian policies but intractable for flow-based models due to irreversible forward-reverse processes and discretization errors (e.g., Euler-Maruyama approximations). To bridge this gap, we propose GenPO, a generative policy optimization framework that leverages exact diffusion inversion to construct invertible action mappings. GenPO introduces a novel doubled dummy action mechanism that enables invertibility via alternating updates, resolving log-likelihood computation barriers. Furthermore, we also use the action log-likelihood for unbiased entropy and KL divergence estimation, enabling KL-adaptive learning rates and entropy regularization in on-policy updates. Extensive experiments on eight IsaacLab benchmarks, including legged locomotion (Ant, Humanoid, Anymal-D, Unitree H1, Go2), dexterous manipulation (Shadow Hand), aerial control (Quadcopter), and robotic arm tasks (Franka), demonstrate GenPO's superiority over existing RL baselines. Notably, GenPO is the first method to successfully integrate diffusion policies into on-policy RL, unlocking their potential for large-scale parallelized training and real-world robotic deployment.","authors":["Shutong Ding","Ke Hu","Shan Zhong","Haoyang Luo","Weinan Zhang","Jingya Wang","Jun Wang","Ye Shi"],"url":"https://arxiv.org/abs/2505.18763"}
{"created":"2025-05-29","title":"ALPS: Attention Localization and Pruning Strategy for Efficient Alignment of Large Language Models","abstract":"Aligning general-purpose large language models (LLMs) to downstream tasks often incurs significant training adjustment costs. Prior research has explored various avenues to enhance alignment efficiency, primarily through minimal-data training or data-driven activations to identify key attention heads. However, these approaches inherently introduce data dependency, which hinders generalization and reusability. To address this issue and enhance model alignment efficiency, we propose the \\textit{\\textbf{A}ttention \\textbf{L}ocalization and \\textbf{P}runing \\textbf{S}trategy (\\textbf{ALPS})}, an efficient algorithm that localizes the most task-sensitive attention heads and prunes by restricting attention training updates to these heads, thereby reducing alignment costs. Experimental results demonstrate that our method activates only \\textbf{10\\%} of attention parameters during fine-tuning while achieving a \\textbf{2\\%} performance improvement over baselines on three tasks. Moreover, the identified task-specific heads are transferable across datasets and mitigate knowledge forgetting. Our work and findings provide a novel perspective on efficient LLM alignment. The code is available at https://github.com/VoiceBeer/ALPS.","authors":["Hao Chen","Haoze Li","Zhiqing Xiao","Lirong Gao","Qi Zhang","Xiaomeng Hu","Ningtao Wang","Xing Fu","Junbo Zhao"],"url":"https://arxiv.org/abs/2505.18799"}
{"created":"2025-05-29","title":"Eye-See-You: Reverse Pass-Through VR and Head Avatars","abstract":"Virtual Reality (VR) headsets, while integral to the evolving digital ecosystem, present a critical challenge: the occlusion of users' eyes and portions of their faces, which hinders visual communication and may contribute to social isolation. To address this, we introduce RevAvatar, an innovative framework that leverages AI methodologies to enable reverse pass-through technology, fundamentally transforming VR headset design and interaction paradigms. RevAvatar integrates state-of-the-art generative models and multimodal AI techniques to reconstruct high-fidelity 2D facial images and generate accurate 3D head avatars from partially observed eye and lower-face regions. This framework represents a significant advancement in AI4Tech by enabling seamless interaction between virtual and physical environments, fostering immersive experiences such as VR meetings and social engagements. Additionally, we present VR-Face, a novel dataset comprising 200,000 samples designed to emulate diverse VR-specific conditions, including occlusions, lighting variations, and distortions. By addressing fundamental limitations in current VR systems, RevAvatar exemplifies the transformative synergy between AI and next-generation technologies, offering a robust platform for enhancing human connection and interaction in virtual environments.","authors":["Ankan Dash","Jingyi Gu","Guiling Wang","Chen Chen"],"url":"https://arxiv.org/abs/2505.18869"}
{"created":"2025-05-29","title":"Moderating Harm: Benchmarking Large Language Models for Cyberbullying Detection in YouTube Comments","abstract":"As online platforms grow, comment sections increasingly host harassment that undermines user experience and well-being. This study benchmarks three leading large language models, OpenAI GPT-4.1, Google Gemini 1.5 Pro, and Anthropic Claude 3 Opus, on a corpus of 5,080 YouTube comments sampled from high-abuse threads in gaming, lifestyle, food vlog, and music channels. The dataset comprises 1,334 harmful and 3,746 non-harmful messages in English, Arabic, and Indonesian, annotated independently by two reviewers with substantial agreement (Cohen's kappa = 0.83). Using a unified prompt and deterministic settings, GPT-4.1 achieved the best overall balance with an F1 score of 0.863, precision of 0.887, and recall of 0.841. Gemini flagged the highest share of harmful posts (recall = 0.875) but its precision fell to 0.767 due to frequent false positives. Claude delivered the highest precision at 0.920 and the lowest false-positive rate of 0.022, yet its recall dropped to 0.720. Qualitative analysis showed that all three models struggle with sarcasm, coded insults, and mixed-language slang. These results underscore the need for moderation pipelines that combine complementary models, incorporate conversational context, and fine-tune for under-represented languages and implicit abuse. A de-identified version of the dataset and full prompts is publicly released to promote reproducibility and further progress in automated content moderation.","authors":["Amel Muminovic"],"url":"https://arxiv.org/abs/2505.18927"}
{"created":"2025-05-29","title":"FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization","abstract":"State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80\\times and 8.90\\times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6\\times higher energy efficiency than RTX 3090 GPU.","authors":["Aotao Wang","Haikuo Shao","Shaobo Ma","Zhongfeng Wang"],"url":"https://arxiv.org/abs/2505.18975"}
{"created":"2025-05-29","title":"SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning","abstract":"We present SeePhys, a large-scale multimodal benchmark for LLM reasoning grounded in physics questions ranging from middle school to PhD qualifying exams. The benchmark covers 7 fundamental domains spanning the physics discipline, incorporating 21 categories of highly heterogeneous diagrams. In contrast to prior works where visual elements mainly serve auxiliary purposes, our benchmark features a substantial proportion of vision-essential problems (75%) that mandate visual information extraction for correct solutions. Through extensive evaluation, we observe that even the most advanced visual reasoning models (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60% accuracy on our benchmark. These results reveal fundamental challenges in current large language models' visual understanding capabilities, particularly in: (i) establishing rigorous coupling between diagram interpretation and physics reasoning, and (ii) overcoming their persistent reliance on textual cues as cognitive shortcuts.","authors":["Kun Xiang","Heng Li","Terry Jingchen Zhang","Yinya Huang","Zirong Liu","Peixin Qu","Jixi He","Jiaqi Chen","Yu-Jie Yuan","Jianhua Han","Hang Xu","Hanhui Li","Mrinmaya Sachan","Xiaodan Liang"],"url":"https://arxiv.org/abs/2505.19099"}
{"created":"2025-05-29","title":"Latent Mamba Operator for Partial Differential Equations","abstract":"Neural operators have emerged as powerful data-driven frameworks for solving Partial Differential Equations (PDEs), offering significant speedups over numerical methods. However, existing neural operators struggle with scalability in high-dimensional spaces, incur high computational costs, and face challenges in capturing continuous and long-range dependencies in PDE dynamics. To address these limitations, we introduce the Latent Mamba Operator (LaMO), which integrates the efficiency of state-space models (SSMs) in latent space with the expressive power of kernel integral formulations in neural operators. We also establish a theoretical connection between state-space models (SSMs) and the kernel integral of neural operators. Extensive experiments across diverse PDE benchmarks on regular grids, structured meshes, and point clouds covering solid and fluid physics datasets, LaMOs achieve consistent state-of-the-art (SOTA) performance, with a 32.3% improvement over existing baselines in solution operator approximation, highlighting its efficacy in modeling complex PDE solutions.","authors":["Karn Tiwari","Niladri Dutta","N M Anoop Krishnan","Prathosh A P"],"url":"https://arxiv.org/abs/2505.19105"}
{"created":"2025-05-29","title":"CreatiDesign: A Unified Multi-Conditional Diffusion Transformer for Creative Graphic Design","abstract":"Graphic design plays a vital role in visual communication across advertising, marketing, and multimedia entertainment. Prior work has explored automated graphic design generation using diffusion models, aiming to streamline creative workflows and democratize design capabilities. However, complex graphic design scenarios require accurately adhering to design intent specified by multiple heterogeneous user-provided elements (\\eg images, layouts, and texts), which pose multi-condition control challenges for existing methods. Specifically, previous single-condition control models demonstrate effectiveness only within their specialized domains but fail to generalize to other conditions, while existing multi-condition methods often lack fine-grained control over each sub-condition and compromise overall compositional harmony. To address these limitations, we introduce CreatiDesign, a systematic solution for automated graphic design covering both model architecture and dataset construction. First, we design a unified multi-condition driven architecture that enables flexible and precise integration of heterogeneous design elements with minimal architectural modifications to the base diffusion model. Furthermore, to ensure that each condition precisely controls its designated image region and to avoid interference between conditions, we propose a multimodal attention mask mechanism. Additionally, we develop a fully automated pipeline for constructing graphic design datasets, and introduce a new dataset with 400K samples featuring multi-condition annotations, along with a comprehensive benchmark. Experimental results show that CreatiDesign outperforms existing models by a clear margin in faithfully adhering to user intent.","authors":["Hui Zhang","Dexiang Hong","Maoke Yang","Yutao Cheng","Zhao Zhang","Jie Shao","Xinglong Wu","Zuxuan Wu","Yu-Gang Jiang"],"url":"https://arxiv.org/abs/2505.19114"}
{"created":"2025-05-29","title":"EventEgoHands: Event-based Egocentric 3D Hand Mesh Reconstruction","abstract":"Reconstructing 3D hand mesh is challenging but an important task for human-computer interaction and AR/VR applications. In particular, RGB and/or depth cameras have been widely used in this task. However, methods using these conventional cameras face challenges in low-light environments and during motion blur. Thus, to address these limitations, event cameras have been attracting attention in recent years for their high dynamic range and high temporal resolution. Despite their advantages, event cameras are sensitive to background noise or camera motion, which has limited existing studies to static backgrounds and fixed cameras. In this study, we propose EventEgoHands, a novel method for event-based 3D hand mesh reconstruction in an egocentric view. Our approach introduces a Hand Segmentation Module that extracts hand regions, effectively mitigating the influence of dynamic background events. We evaluated our approach and demonstrated its effectiveness on the N-HOT3D dataset, improving MPJPE by approximately more than 4.5 cm (43%).","authors":["Ryosei Hara","Wataru Ikeda","Masashi Hatano","Mariko Isogawa"],"url":"https://arxiv.org/abs/2505.19169"}
{"created":"2025-05-29","title":"OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter Optimization","abstract":"Hyperparameter optimization (HPO) is a critical yet challenging aspect of machine learning model development, significantly impacting model performance and generalization. Traditional HPO methods often struggle with high dimensionality, complex interdependencies, and computational expense. This paper introduces OptiMindTune, a novel multi-agent framework designed to intelligently and efficiently optimize hyperparameters. OptiMindTune leverages the collaborative intelligence of three specialized AI agents -- a Recommender Agent, an Evaluator Agent, and a Decision Agent -- each powered by Google's Gemini models. These agents address distinct facets of the HPO problem, from model selection and hyperparameter suggestion to robust evaluation and strategic decision-making. By fostering dynamic interactions and knowledge sharing, OptiMindTune aims to converge to optimal hyperparameter configurations more rapidly and robustly than existing single-agent or monolithic approaches. Our framework integrates principles from advanced large language models, and adaptive search to achieve scalable and intelligent AutoML. We posit that this multi-agent paradigm offers a promising avenue for tackling the increasing complexity of modern machine learning model tuning.","authors":["Meher Bhaskar Madiraju","Meher Sai Preetam Madiraju"],"url":"https://arxiv.org/abs/2505.19205"}
{"created":"2025-05-29","title":"VTool-R1: VLMs Learn to Think with Images via Reinforcement Learning on Multimodal Tool Use","abstract":"Reinforcement Learning Finetuning (RFT) has significantly advanced the reasoning capabilities of large language models (LLMs) by enabling long chains of thought, self-correction, and effective tool use. While recent works attempt to extend RFT to vision-language models (VLMs), these efforts largely produce text-only reasoning conditioned on static image inputs, falling short of true multimodal reasoning in the response. In contrast, test-time methods like Visual Sketchpad incorporate visual steps but lack training mechanisms.","authors":["Mingyuan Wu","Jingcheng Yang","Jize Jiang","Meitang Li","Kaizhuo Yan","Hanchao Yu","Minjia Zhang","Chengxiang Zhai","Klara Nahrstedt"],"url":"https://arxiv.org/abs/2505.19255"}
{"created":"2025-05-29","title":"Towards Large Reasoning Models for Agriculture","abstract":"Agricultural decision-making involves complex, context-specific reasoning, where choices about crops, practices, and interventions depend heavily on geographic, climatic, and economic conditions. Traditional large language models (LLMs) often fall short in navigating this nuanced problem due to limited reasoning capacity. We hypothesize that recent advances in large reasoning models (LRMs) can better handle such structured, domain-specific inference. To investigate this, we introduce AgReason, the first expert-curated open-ended science benchmark with 100 questions for agricultural reasoning. Evaluations across thirteen open-source and proprietary models reveal that LRMs outperform conventional ones, though notable challenges persist, with the strongest Gemini-based baseline achieving 36% accuracy. We also present AgThoughts, a large-scale dataset of 44.6K question-answer pairs generated with human oversight and equipped with synthetically generated reasoning traces. Using AgThoughts, we develop AgThinker, a suite of small reasoning models that can be run on consumer-grade GPUs, and show that our dataset can be effective in unlocking agricultural reasoning abilities in LLMs. Our project page is here: https://baskargroup.github.io/Ag_reasoning/","authors":["Hossein Zaremehrjerdi","Shreyan Ganguly","Ashlyn Rairdin","Elizabeth Tranel","Benjamin Feuer","Juan Ignacio Di Salvo","Srikanth Panthulugiri","Hernan Torres Pacin","Victoria Moser","Sarah Jones","Joscif G Raigne","Yanben Shen","Heidi M. Dornath","Aditya Balu","Adarsh Krishnamurthy","Asheesh K Singh","Arti Singh","Baskar Ganapathysubramanian","Chinmay Hegde","Soumik Sarkar"],"url":"https://arxiv.org/abs/2505.19259"}
{"created":"2025-05-29","title":"MMIG-Bench: Towards Comprehensive and Explainable Evaluation of Multi-Modal Image Generation Models","abstract":"Recent multimodal image generators such as GPT-4o, Gemini 2.0 Flash, and Gemini 2.5 Pro excel at following complex instructions, editing images and maintaining concept consistency. However, they are still evaluated by disjoint toolkits: text-to-image (T2I) benchmarks that lacks multi-modal conditioning, and customized image generation benchmarks that overlook compositional semantics and common knowledge. We propose MMIG-Bench, a comprehensive Multi-Modal Image Generation Benchmark that unifies these tasks by pairing 4,850 richly annotated text prompts with 1,750 multi-view reference images across 380 subjects, spanning humans, animals, objects, and artistic styles. MMIG-Bench is equipped with a three-level evaluation framework: (1) low-level metrics for visual artifacts and identity preservation of objects; (2) novel Aspect Matching Score (AMS): a VQA-based mid-level metric that delivers fine-grained prompt-image alignment and shows strong correlation with human judgments; and (3) high-level metrics for aesthetics and human preference. Using MMIG-Bench, we benchmark 17 state-of-the-art models, including Gemini 2.5 Pro, FLUX, DreamBooth, and IP-Adapter, and validate our metrics with 32k human ratings, yielding in-depth insights into architecture and data design.","authors":["Hang Hua","Ziyun Zeng","Yizhi Song","Yunlong Tang","Liu He","Daniel Aliaga","Wei Xiong","Jiebo Luo"],"url":"https://arxiv.org/abs/2505.19415"}
{"created":"2025-05-29","title":"Balancing Computation Load and Representation Expressivity in Parallel Hybrid Neural Networks","abstract":"Attention and State-Space Models (SSMs) when combined in a hybrid network in sequence or in parallel provide complementary strengths. In a hybrid sequential pipeline they alternate between applying a transformer to the input and then feeding its output into a SSM. This results in idle periods in the individual components increasing end-to-end latency and lowering throughput caps. In the parallel hybrid architecture, the transformer operates independently in parallel with the SSM, and these pairs are cascaded, with output from one pair forming the input to the next. Two issues are (i) creating an expressive knowledge representation with the inherently divergent outputs from these separate branches, and (ii) load balancing the computation between these parallel branches, while maintaining representation fidelity. In this work we present FlowHN, a novel parallel hybrid network architecture that accommodates various strategies for load balancing, achieved through appropriate distribution of input tokens between the two branches. Two innovative differentiating factors in FlowHN include a FLOP aware dynamic token split between the attention and SSM branches yielding efficient balance in compute load, and secondly, a method to fuse the highly divergent outputs from individual branches for enhancing representation expressivity. Together they enable much better token processing speeds, avoid bottlenecks, and at the same time yield significantly improved accuracy as compared to other competing works. We conduct comprehensive experiments on autoregressive language modeling for models with 135M, 350M, and 1B parameters. FlowHN outperforms sequential hybrid models and its parallel counterpart, achieving up to 4* higher Tokens per Second (TPS) and 2* better Model FLOPs Utilization (MFU).","authors":["Mohammad Mahdi Moradi","Walid Ahmed","Shuangyue Wen","Sudhir Mudur","Weiwei Zhang","Yang Liu"],"url":"https://arxiv.org/abs/2505.19472"}
{"created":"2025-05-29","title":"Continuous Self-Improvement of Large Language Models by Test-time Training with Verifier-Driven Sample Selection","abstract":"Learning to adapt pretrained language models to unlabeled, out-of-distribution data is a critical challenge, as models often falter on structurally novel reasoning tasks even while excelling within their training distribution. We introduce a new framework called VDS-TTT - Verifier-Driven Sample Selection for Test-Time Training to efficiently address this. We use a learned verifier to score a pool of generated responses and select only from high ranking pseudo-labeled examples for fine-tuned adaptation. Specifically, for each input query our LLM generates N candidate answers; the verifier assigns a reliability score to each, and the response with the highest confidence and above a fixed threshold is paired with its query for test-time training. We fine-tune only low-rank LoRA adapter parameters, ensuring adaptation efficiency and fast convergence. Our proposed self-supervised framework is the first to synthesize verifier driven test-time training data for continuous self-improvement of the model. Experiments across three diverse benchmarks and three state-of-the-art LLMs demonstrate that VDS-TTT yields up to a 32.29% relative improvement over the base model and a 6.66% gain compared to verifier-based methods without test-time training, highlighting its effectiveness and efficiency for on-the-fly large language model adaptation.","authors":["Mohammad Mahdi Moradi","Hossam Amer","Sudhir Mudur","Weiwei Zhang","Yang Liu","Walid Ahmed"],"url":"https://arxiv.org/abs/2505.19475"}
{"created":"2025-05-29","title":"AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems","abstract":"The emergence of agentic recommender systems powered by Large Language Models (LLMs) represents a paradigm shift in personalized recommendations, leveraging LLMs' advanced reasoning and role-playing capabilities to enable autonomous, adaptive decision-making. Unlike traditional recommendation approaches, agentic recommender systems can dynamically gather and interpret user-item interactions from complex environments, generating robust recommendation strategies that generalize across diverse scenarios. However, the field currently lacks standardized evaluation protocols to systematically assess these methods. To address this critical gap, we propose: (1) an interactive textual recommendation simulator incorporating rich user and item metadata and three typical evaluation scenarios (classic, evolving-interest, and cold-start recommendation tasks); (2) a unified modular framework for developing and studying agentic recommender systems; and (3) the first comprehensive benchmark comparing 10 classical and agentic recommendation methods. Our findings demonstrate the superiority of agentic systems and establish actionable design guidelines for their core components. The benchmark environment has been rigorously validated through an open challenge and remains publicly available with a continuously maintained leaderboard~\\footnote[2]{https://tsinghua-fib-lab.github.io/AgentSocietyChallenge/pages/overview.html}, fostering ongoing community engagement and reproducible research. The benchmark is available at: \\hyperlink{https://huggingface.co/datasets/SGJQovo/AgentRecBench}{https://huggingface.co/datasets/SGJQovo/AgentRecBench}.","authors":["Yu Shang","Peijie Liu","Yuwei Yan","Zijing Wu","Leheng Sheng","Yuanqing Yu","Chumeng Jiang","An Zhang","Fengli Xu","Yu Wang","Min Zhang","Yong Li"],"url":"https://arxiv.org/abs/2505.19623"}
{"created":"2025-05-29","title":"Faster and Better LLMs via Latency-Aware Test-Time Scaling","abstract":"Test-Time Scaling (TTS) has proven effective in improving the performance of Large Language Models (LLMs) during inference. However, existing research has overlooked the efficiency of TTS from a latency-sensitive perspective. Through a latency-aware evaluation of representative TTS methods, we demonstrate that a compute-optimal TTS does not always result in the lowest latency in scenarios where latency is critical. To address this gap and achieve latency-optimal TTS, we propose two key approaches by optimizing the concurrency configurations: (1) branch-wise parallelism, which leverages multiple concurrent inference branches, and (2) sequence-wise parallelism, enabled by speculative decoding. By integrating these two approaches and allocating computational resources properly to each, our latency-optimal TTS enables a 32B model to reach 82.3% accuracy on MATH-500 within 1 minute and a smaller 3B model to achieve 72.4% within 10 seconds. Our work emphasizes the importance of latency-aware TTS and demonstrates its ability to deliver both speed and accuracy in latency-sensitive scenarios.","authors":["Zili Wang","Tianyu Zhang","Lei Zhu","Haoli Bai","Lu Hou","Shiming Xiang","Xianzhi Yu","Wulong Liu"],"url":"https://arxiv.org/abs/2505.19634"}
{"created":"2025-05-29","title":"SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond","abstract":"Recent advances such as OpenAI-o1 and DeepSeek R1 have demonstrated the potential of Reinforcement Learning (RL) to enhance reasoning abilities in Large Language Models (LLMs). While open-source replication efforts have primarily focused on mathematical and coding domains, methods and resources for developing general reasoning capabilities remain underexplored. This gap is partly due to the challenge of collecting diverse and verifiable reasoning data suitable for RL. We hypothesize that logical reasoning is critical for developing general reasoning capabilities, as logic forms a fundamental building block of reasoning. In this work, we present SynLogic, a data synthesis framework and dataset that generates diverse logical reasoning data at scale, encompassing 35 diverse logical reasoning tasks. The SynLogic approach enables controlled synthesis of data with adjustable difficulty and quantity. Importantly, all examples can be verified by simple rules, making them ideally suited for RL with verifiable rewards. In our experiments, we validate the effectiveness of RL training on the SynLogic dataset based on 7B and 32B models. SynLogic leads to state-of-the-art logical reasoning performance among open-source datasets, surpassing DeepSeek-R1-Distill-Qwen-32B by 6 points on BBEH. Furthermore, mixing SynLogic data with mathematical and coding tasks improves the training efficiency of these domains and significantly enhances reasoning generalization. Notably, our mixed training model outperforms DeepSeek-R1-Zero-Qwen-32B across multiple benchmarks. These findings position SynLogic as a valuable resource for advancing the broader reasoning capabilities of LLMs. We open-source both the data synthesis pipeline and the SynLogic dataset at https://github.com/MiniMax-AI/SynLogic.","authors":["Junteng Liu","Yuanxiang Fan","Zhuo Jiang","Han Ding","Yongyi Hu","Chi Zhang","Yiqi Shi","Shitong Weng","Aili Chen","Shiqi Chen","Yunan Huang","Mozhi Zhang","Pengyu Zhao","Junjie Yan","Junxian He"],"url":"https://arxiv.org/abs/2505.19641"}
{"created":"2025-05-29","title":"A Comprehensive Real-World Assessment of Audio Watermarking Algorithms: Will They Survive Neural Codecs?","abstract":"We introduce the Robust Audio Watermarking Benchmark (RAW-Bench), a benchmark for evaluating deep learning-based audio watermarking methods with standardized and systematic comparisons. To simulate real-world usage, we introduce a comprehensive audio attack pipeline with various distortions such as compression, background noise, and reverberation, along with a diverse test dataset including speech, environmental sounds, and music recordings. Evaluating four existing watermarking methods on RAW-bench reveals two main insights: (i) neural compression techniques pose the most significant challenge, even when algorithms are trained with such compressions; and (ii) training with audio attacks generally improves robustness, although it is insufficient in some cases. Furthermore, we find that specific distortions, such as polarity inversion, time stretching, or reverb, seriously affect certain methods. The evaluation framework is accessible at github.com/SonyResearch/raw_bench.","authors":["Yigitcan \\\"Ozer","Woosung Choi","Joan Serr\\`a","Mayank Kumar Singh","Wei-Hsiang Liao","Yuki Mitsufuji"],"url":"https://arxiv.org/abs/2505.19663"}
{"created":"2025-05-29","title":"Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations","abstract":"As the impact of large language models increases, understanding the moral values they reflect becomes ever more important. Assessing the nature of moral values as understood by these models via direct prompting is challenging due to potential leakage of human norms into model training data, and their sensitivity to prompt formulation. Instead, we propose to use word associations, which have been shown to reflect moral reasoning in humans, as low-level underlying representations to obtain a more robust picture of LLMs' moral reasoning. We study moral differences in associations from western English-speaking communities and LLMs trained predominantly on English data. First, we create a large dataset of LLM-generated word associations, resembling an existing data set of human word associations. Next, we propose a novel method to propagate moral values based on seed words derived from Moral Foundation Theory through the human and LLM-generated association graphs. Finally, we compare the resulting moral conceptualizations, highlighting detailed but systematic differences between moral values emerging from English speakers and LLM associations.","authors":["Chaoyi Xiang","Chunhua Liu","Simon De Deyne","Lea Frermann"],"url":"https://arxiv.org/abs/2505.19674"}
{"created":"2025-05-29","title":"VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models","abstract":"The emergence of Multimodal Large Language Models (MLRMs) has enabled sophisticated visual reasoning capabilities by integrating reinforcement learning and Chain-of-Thought (CoT) supervision. However, while these enhanced reasoning capabilities improve performance, they also introduce new and underexplored safety risks. In this work, we systematically investigate the security implications of advanced visual reasoning in MLRMs. Our analysis reveals a fundamental trade-off: as visual reasoning improves, models become more vulnerable to jailbreak attacks. Motivated by this critical finding, we introduce VisCRA (Visual Chain Reasoning Attack), a novel jailbreak framework that exploits the visual reasoning chains to bypass safety mechanisms. VisCRA combines targeted visual attention masking with a two-stage reasoning induction strategy to precisely control harmful outputs. Extensive experiments demonstrate VisCRA's significant effectiveness, achieving high attack success rates on leading closed-source MLRMs: 76.48% on Gemini 2.0 Flash Thinking, 68.56% on QvQ-Max, and 56.60% on GPT-4o. Our findings highlight a critical insight: the very capability that empowers MLRMs -- their visual reasoning -- can also serve as an attack vector, posing significant security risks.","authors":["Bingrui Sima","Linhua Cong","Wenxuan Wang","Kun He"],"url":"https://arxiv.org/abs/2505.19684"}
{"created":"2025-05-29","title":"JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning","abstract":"Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k.","authors":["Jing Yu Lim","Zarif Ikram","Samson Yu","Haozhe Ma","Tze-Yun Leong","Dianbo Liu"],"url":"https://arxiv.org/abs/2505.19698"}
{"created":"2025-05-29","title":"The Avengers: A Simple Recipe for Uniting Smaller Language Models to Challenge Proprietary Giants","abstract":"As proprietary giants increasingly dominate the race for ever-larger language models, a pressing question arises for the open-source community: can smaller models remain competitive across a broad range of tasks? In this paper, we present the Avengers--a simple recipe that effectively leverages the collective intelligence of open-source, smaller language models. Our framework is built upon four lightweight operations: (i) embedding: encode queries using a text embedding model; (ii) clustering: group queries based on their semantic similarity; (iii) scoring: scores each model's performance within each cluster; and (iv) voting: improve outputs via repeated sampling and voting. At inference time, each query is embedded and assigned to its nearest cluster. The top-performing model(s) within that cluster are selected to generate the response using the Self-Consistency or its multi-model variant. Remarkably, with 10 open-source models (~7B parameters each), the Avengers collectively outperforms GPT-4.1 on nine out of 15 datasets (spanning mathematics, code, logic, knowledge, and affective tasks). In particular, it surpasses GPT-4.1 on mathematics tasks by 18.21% and on code tasks by 7.46%. Furthermore, the Avengers delivers superior out-of-distribution generalization, and remains robust across various embedding models, clustering algorithms, ensemble strategies, and values of its sole parameter--the number of clusters. We have open-sourced the code on GitHub: https://github.com/ZhangYiqun018/Avengers","authors":["Yiqun Zhang","Hao Li","Chenxu Wang","Linyao Chen","Qiaosheng Zhang","Peng Ye","Shi Feng","Daling Wang","Zhen Wang","Xinrun Wang","Jia Xu","Lei Bai","Wanli Ouyang","Shuyue Hu"],"url":"https://arxiv.org/abs/2505.19797"}
{"created":"2025-05-29","title":"Progressive Scaling Visual Object Tracking","abstract":"In this work, we propose a progressive scaling training strategy for visual object tracking, systematically analyzing the influence of training data volume, model size, and input resolution on tracking performance. Our empirical study reveals that while scaling each factor leads to significant improvements in tracking accuracy, naive training suffers from suboptimal optimization and limited iterative refinement. To address this issue, we introduce DT-Training, a progressive scaling framework that integrates small teacher transfer and dual-branch alignment to maximize model potential. The resulting scaled tracker consistently outperforms state-of-the-art methods across multiple benchmarks, demonstrating strong generalization and transferability of the proposed method. Furthermore, we validate the broader applicability of our approach to additional tasks, underscoring its versatility beyond tracking.","authors":["Jack Hong","Shilin Yan","Zehao Xiao","Jiayin Cai","Xiaolong Jiang","Yao Hu","Henghui Ding"],"url":"https://arxiv.org/abs/2505.19990"}
{"created":"2025-05-29","title":"Incentivizing Strong Reasoning from Weak Supervision","abstract":"Large language models (LLMs) have demonstrated impressive performance on reasoning-intensive tasks, but enhancing their reasoning abilities typically relies on either reinforcement learning (RL) with verifiable signals or supervised fine-tuning (SFT) with high-quality long chain-of-thought (CoT) demonstrations, both of which are expensive. In this paper, we study a novel problem of incentivizing the reasoning capacity of LLMs without expensive high-quality demonstrations and reinforcement learning. We investigate whether the reasoning capabilities of LLMs can be effectively incentivized via supervision from significantly weaker models. We further analyze when and why such weak supervision succeeds in eliciting reasoning abilities in stronger models. Our findings show that supervision from significantly weaker reasoners can substantially improve student reasoning performance, recovering close to 94% of the gains of expensive RL at a fraction of the cost. Experiments across diverse benchmarks and model architectures demonstrate that weak reasoners can effectively incentivize reasoning in stronger student models, consistently improving performance across a wide range of reasoning tasks. Our results suggest that this simple weak-to-strong paradigm is a promising and generalizable alternative to costly methods for incentivizing strong reasoning capabilities at inference-time in LLMs. The code is publicly available at https://github.com/yuanyige/w2sr.","authors":["Yige Yuan","Teng Xiao","Shuchang Tao","Xue Wang","Jinyang Gao","Bolin Ding","Bingbing Xu"],"url":"https://arxiv.org/abs/2505.20072"}
{"created":"2025-05-29","title":"Inference-time Alignment in Continuous Space","abstract":"Aligning large language models with human feedback at inference time has received increasing attention due to its flexibility. Existing methods rely on generating multiple responses from the base policy for search using a reward model, which can be considered as searching in a discrete response space. However, these methods struggle to explore informative candidates when the base policy is weak or the candidate set is small, resulting in limited effectiveness. In this paper, to address this problem, we propose Simple Energy Adaptation ($\\textbf{SEA}$), a simple yet effective algorithm for inference-time alignment. In contrast to expensive search over the discrete space, SEA directly adapts original responses from the base policy toward the optimal one via gradient-based sampling in continuous latent space. Specifically, SEA formulates inference as an iterative optimization procedure on an energy function over actions in the continuous space defined by the optimal policy, enabling simple and effective alignment. For instance, despite its simplicity, SEA outperforms the second-best baseline with a relative improvement of up to $ \\textbf{77.51%}$ on AdvBench and $\\textbf{16.36%}$ on MATH. Our code is publicly available at https://github.com/yuanyige/sea","authors":["Yige Yuan","Teng Xiao","Li Yunfan","Bingbing Xu","Shuchang Tao","Yunqi Qiu","Huawei Shen","Xueqi Cheng"],"url":"https://arxiv.org/abs/2505.20081"}
{"created":"2025-05-29","title":"The Computability Path Order for Beta-Eta-Normal Higher-Order Rewriting (Full Version)","abstract":"We lift the computability path order and its extensions from plain higher-order rewriting to higher-order rewriting on beta-eta-normal forms where matching modulo beta-eta is employed. The resulting order NCPO is shown to be useful on practical examples. In particular, it can handle systems where its cousin NHORPO fails even when it is used together with the powerful transformation technique of neutralization. We also argue that automating NCPO efficiently is straightforward using SAT/SMT solvers whereas this cannot be said about the transformation technique of neutralization. Our prototype implementation supports automatic termination proof search for NCPO and is also the first one to automate NHORPO with neutralization.","authors":["Johannes Niederhauser","Aart Middeldorp"],"url":"https://arxiv.org/abs/2505.20121"}
{"created":"2025-05-29","title":"Data-Distill-Net: A Data Distillation Approach Tailored for Reply-based Continual Learning","abstract":"Replay-based continual learning (CL) methods assume that models trained on a small subset can also effectively minimize the empirical risk of the complete dataset. These methods maintain a memory buffer that stores a sampled subset of data from previous tasks to consolidate past knowledge. However, this assumption is not guaranteed in practice due to the limited capacity of the memory buffer and the heuristic criteria used for buffer data selection. To address this issue, we propose a new dataset distillation framework tailored for CL, which maintains a learnable memory buffer to distill the global information from the current task data and accumulated knowledge preserved in the previous memory buffer. Moreover, to avoid the computational overhead and overfitting risks associated with parameterizing the entire buffer during distillation, we introduce a lightweight distillation module that can achieve global information distillation solely by generating learnable soft labels for the memory buffer data. Extensive experiments show that, our method can achieve competitive results and effectively mitigates forgetting across various datasets. The source code will be publicly available.","authors":["Wenyang Liao","Quanziang Wang","Yichen Wu","Renzhen Wang","Deyu Meng"],"url":"https://arxiv.org/abs/2505.20135"}
{"created":"2025-05-29","title":"Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations","abstract":"Limited access to mental healthcare, extended wait times, and increasing capabilities of Large Language Models (LLMs) has led individuals to turn to LLMs for fulfilling their mental health needs. However, examining the multi-turn mental health conversation capabilities of LLMs remains under-explored. Existing evaluation frameworks typically focus on diagnostic accuracy and win-rates and often overlook alignment with patient-specific goals, values, and personalities required for meaningful conversations. To address this, we introduce MedAgent, a novel framework for synthetically generating realistic, multi-turn mental health sensemaking conversations and use it to create the Mental Health Sensemaking Dialogue (MHSD) dataset, comprising over 2,200 patient-LLM conversations. Additionally, we present MultiSenseEval, a holistic framework to evaluate the multi-turn conversation abilities of LLMs in healthcare settings using human-centric criteria. Our findings reveal that frontier reasoning models yield below-par performance for patient-centric communication and struggle at advanced diagnostic capabilities with average score of 31%. Additionally, we observed variation in model performance based on patient's persona and performance drop with increasing turns in the conversation. Our work provides a comprehensive synthetic data generation framework, a dataset and evaluation framework for assessing LLMs in multi-turn mental health conversations.","authors":["Mohit Chandra","Siddharth Sriraman","Harneet Singh Khanuja","Yiqiao Jin","Munmun De Choudhury"],"url":"https://arxiv.org/abs/2505.20201"}
{"created":"2025-05-29","title":"OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation","abstract":"Subject-to-Video (S2V) generation aims to create videos that faithfully incorporate reference content, providing enhanced flexibility in the production of videos. To establish the infrastructure for S2V generation, we propose OpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, and (ii) OpenS2V-5M, a million-scale dataset. In contrast to existing S2V benchmarks inherited from VBench that focus on global and coarse-grained assessment of generated videos, OpenS2V-Eval focuses on the model's ability to generate subject-consistent videos with natural subject appearance and identity fidelity. For these purposes, OpenS2V-Eval introduces 180 prompts from seven major categories of S2V, which incorporate both real and synthetic test data. Furthermore, to accurately align human preferences with S2V benchmarks, we propose three automatic metrics, NexusScore, NaturalScore and GmeScore, to separately quantify subject consistency, naturalness, and text relevance in generated videos. Building on this, we conduct a comprehensive evaluation of 16 representative S2V models, highlighting their strengths and weaknesses across different content. Moreover, we create the first open-source large-scale S2V generation dataset OpenS2V-5M, which consists of five million high-quality 720P subject-text-video triples. Specifically, we ensure subject-information diversity in our dataset by (1) segmenting subjects and building pairing information via cross-video associations and (2) prompting GPT-Image-1 on raw frames to synthesize multi-view representations. Through OpenS2V-Nexus, we deliver a robust infrastructure to accelerate future S2V generation research.","authors":["Shenghai Yuan","Xianyi He","Yufan Deng","Yang Ye","Jinfa Huang","Bin Lin","Jiebo Luo","Li Yuan"],"url":"https://arxiv.org/abs/2505.20292"}
{"created":"2025-05-29","title":"PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy","abstract":"This paper introduces PreP-OCR, a two-stage pipeline that combines document image restoration with semantic-aware post-OCR correction to enhance both visual clarity and textual consistency, thereby improving text extraction from degraded historical documents. First, we synthesize document-image pairs from plaintext, rendering them with diverse fonts and layouts and then applying a randomly ordered set of degradation operations. An image restoration model is trained on this synthetic data, using multi-directional patch extraction and fusion to process large images. Second, a ByT5 post-OCR model, fine-tuned on synthetic historical text pairs, addresses remaining OCR errors. Detailed experiments on 13,831 pages of real historical documents in English, French, and Spanish show that the PreP-OCR pipeline reduces character error rates by 63.9-70.3% compared to OCR on raw images. Our pipeline demonstrates the potential of integrating image restoration with linguistic error correction for digitizing historical archives.","authors":["Shuhao Guan","Moule Lin","Cheng Xu","Xinyi Liu","Jinman Zhao","Jiexin Fan","Qi Xu","Derek Greene"],"url":"https://arxiv.org/abs/2505.20429"}
{"created":"2025-05-29","title":"Maxwell \\`a la Helmholtz: Electromagnetic scattering by 3D perfect electric conductors via Helmholtz integral operators","abstract":"This paper introduces a novel class of indirect boundary integral equation (BIE) formulations for the solution of electromagnetic scattering problems involving smooth perfectly electric conductors (PECs) in three-dimensions. These combined-field-type BIE formulations rely exclusively on classical Helmholtz boundary operators, resulting in provably well-posed, frequency-robust, Fredholm second-kind BIEs. Notably, we prove that the proposed formulations are free from spurious resonances, while retaining the versatility of Helmholtz integral operators. The approach is based on the equivalence between the Maxwell PEC scattering problem and two independent vector Helmholtz boundary value problems for the electric and magnetic fields, with boundary conditions defined in terms of the Dirichlet and Neumann traces of the corresponding vector Helmholtz solutions. While certain aspects of this equivalence (for the electric field) have been previously exploited in the so-called field-only BIE formulations, we here rigorously establish and generalize the equivalence between Maxwell and Helmholtz problems for both fields. Finally, a variety of numerical examples highlights the robustness and accuracy of the proposed approach when combined with Density Interpolation-based Nystr\\\"om methods and fast linear algebra solvers, implemented in the open-source Julia package Inti$.$jl.","authors":["Juan Burbano-Gallegos","Carlos P\\'erez-Arancibia","Catalin Turc"],"url":"https://arxiv.org/abs/2505.20440"}
{"created":"2025-05-29","title":"In-context Language Learning for Endangered Languages in Speech Recognition","abstract":"With approximately 7,000 languages spoken worldwide, current large language models (LLMs) support only a small subset. Prior research indicates LLMs can learn new languages for certain tasks without supervised data. We extend this investigation to speech recognition, investigating whether LLMs can learn unseen, low-resource languages through in-context learning (ICL). With experiments on four diverse endangered languages that LLMs have not been trained on, we find that providing more relevant text samples enhances performance in both language modelling and Automatic Speech Recognition (ASR) tasks. Furthermore, we show that the probability-based approach outperforms the traditional instruction-based approach in language learning. Lastly, we show ICL enables LLMs to achieve ASR performance that is comparable to or even surpasses dedicated language models trained specifically for these languages, while preserving the original capabilities of the LLMs.","authors":["Zhaolin Li","Jan Niehues"],"url":"https://arxiv.org/abs/2505.20445"}
{"created":"2025-05-29","title":"HAND Me the Data: Fast Robot Adaptation via Hand Path Retrieval","abstract":"We hand the community HAND, a simple and time-efficient method for teaching robots new manipulation tasks through human hand demonstrations. Instead of relying on task-specific robot demonstrations collected via teleoperation, HAND uses easy-to-provide hand demonstrations to retrieve relevant behaviors from task-agnostic robot play data. Using a visual tracking pipeline, HAND extracts the motion of the human hand from the hand demonstration and retrieves robot sub-trajectories in two stages: first filtering by visual similarity, then retrieving trajectories with similar behaviors to the hand. Fine-tuning a policy on the retrieved data enables real-time learning of tasks in under four minutes, without requiring calibrated cameras or detailed hand pose estimation. Experiments also show that HAND outperforms retrieval baselines by over 2x in average task success rates on real robots. Videos can be found at our project website: https://liralab.usc.edu/handretrieval/.","authors":["Matthew Hong","Anthony Liang","Kevin Kim","Harshitha Rajaprakash","Jesse Thomason","Erdem B{\\i}y{\\i}k","Jesse Zhang"],"url":"https://arxiv.org/abs/2505.20455"}
{"created":"2025-05-29","title":"DIPO: Dual-State Images Controlled Articulated Object Generation Powered by Diverse Data","abstract":"We present DIPO, a novel framework for the controllable generation of articulated 3D objects from a pair of images: one depicting the object in a resting state and the other in an articulated state. Compared to the single-image approach, our dual-image input imposes only a modest overhead for data collection, but at the same time provides important motion information, which is a reliable guide for predicting kinematic relationships between parts. Specifically, we propose a dual-image diffusion model that captures relationships between the image pair to generate part layouts and joint parameters. In addition, we introduce a Chain-of-Thought (CoT) based graph reasoner that explicitly infers part connectivity relationships. To further improve robustness and generalization on complex articulated objects, we develop a fully automated dataset expansion pipeline, name LEGO-Art, that enriches the diversity and complexity of PartNet-Mobility dataset. We propose PM-X, a large-scale dataset of complex articulated 3D objects, accompanied by rendered images, URDF annotations, and textual descriptions. Extensive experiments demonstrate that DIPO significantly outperforms existing baselines in both the resting state and the articulated state, while the proposed PM-X dataset further enhances generalization to diverse and structurally complex articulated objects. Our code and dataset will be released to the community upon publication.","authors":["Ruiqi Wu","Xinjie Wang","Liu Liu","Chunle Guo","Jiaxiong Qiu","Chongyi Li","Lichao Huang","Zhizhong Su","Ming-Ming Cheng"],"url":"https://arxiv.org/abs/2505.20460"}
{"created":"2025-05-29","title":"ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image","abstract":"Vision-based tactile sensing has been widely used in perception, reconstruction, and robotic manipulation. However, collecting large-scale tactile data remains costly due to the localized nature of sensor-object interactions and inconsistencies across sensor instances. Existing approaches to scaling tactile data, such as simulation and free-form tactile generation, often suffer from unrealistic output and poor transferability to downstream tasks. To address this, we propose ControlTac, a two-stage controllable framework that generates realistic tactile images conditioned on a single reference tactile image, contact force, and contact position. With those physical priors as control input, ControlTac generates physically plausible and varied tactile images that can be used for effective data augmentation. Through experiments on three downstream tasks, we demonstrate that ControlTac can effectively augment tactile datasets and lead to consistent gains. Our three real-world experiments further validate the practical utility of our approach. Project page: https://dongyuluo.github.io/controltac.","authors":["Dongyu Luo","Kelin Yu","Amir-Hossein Shahidzadeh","Cornelia Ferm\\\"uller","Yiannis Aloimonos","Ruohan Gao"],"url":"https://arxiv.org/abs/2505.20498"}
{"created":"2025-05-29","title":"AstroVisBench: A Code Benchmark for Scientific Computing and Visualization in Astronomy","abstract":"Large Language Models (LLMs) are being explored for applications in scientific research, including their capabilities to synthesize literature, answer research questions, generate research ideas, and even conduct computational experiments. Ultimately, our goal is for these to help scientists derive novel scientific insights. In many areas of science, such insights often arise from processing and visualizing data to understand its patterns. However, evaluating whether an LLM-mediated scientific workflow produces outputs conveying the correct scientific insights is challenging to evaluate and has not been addressed in past work. We introduce AstroVisBench, the first benchmark for both scientific computing and visualization in the astronomy domain. AstroVisBench judges a language model's ability to both (1) create astronomy-specific workflows to process and analyze data and (2) visualize the results of these workflows through complex plots. Our evaluation of visualizations uses a novel LLM-as-a-judge workflow, which is validated against annotation by five professional astronomers. Using AstroVisBench we present an evaluation of state-of-the-art language models, showing a significant gap in their ability to engage in astronomy research as useful assistants. This evaluation provides a strong end-to-end evaluation for AI scientists that offers a path forward for the development of visualization-based workflows, which are central to a broad range of domains from physics to biology.","authors":["Sebastian Antony Joseph","Syed Murtaza Husain","Stella S. R. Offner","St\\'ephanie Juneau","Paul Torrey","Adam S. Bolton","Juan P. Farias","Niall Gaffney","Greg Durrett","Junyi Jessy Li"],"url":"https://arxiv.org/abs/2505.20538"}
{"created":"2025-05-29","title":"Causality and \"In-the-Wild\" Video-Based Person Re-ID: A Survey","abstract":"Video-based person re-identification (Re-ID) remains brittle in real-world deployments despite impressive benchmark performance. Most existing models rely on superficial correlations such as clothing, background, or lighting that fail to generalize across domains, viewpoints, and temporal variations. This survey examines the emerging role of causal reasoning as a principled alternative to traditional correlation-based approaches in video-based Re-ID. We provide a structured and critical analysis of methods that leverage structural causal models, interventions, and counterfactual reasoning to isolate identity-specific features from confounding factors. The survey is organized around a novel taxonomy of causal Re-ID methods that spans generative disentanglement, domain-invariant modeling, and causal transformers. We review current evaluation metrics and introduce causal-specific robustness measures. In addition, we assess practical challenges of scalability, fairness, interpretability, and privacy that must be addressed for real-world adoption. Finally, we identify open problems and outline future research directions that integrate causal modeling with efficient architectures and self-supervised learning. This survey aims to establish a coherent foundation for causal video-based person Re-ID and to catalyze the next phase of research in this rapidly evolving domain.","authors":["Md Rashidunnabi","Kailash Hambarde","Hugo Proen\\c{c}a"],"url":"https://arxiv.org/abs/2505.20540"}
{"created":"2025-05-29","title":"Paths Not Taken: Understanding and Mending the Multilingual Factual Recall Pipeline","abstract":"Multilingual large language models (LLMs) often exhibit factual inconsistencies across languages, with significantly better performance in factual recall tasks in English than in other languages. The causes of these failures, however, remain poorly understood. Using mechanistic analysis techniques, we uncover the underlying pipeline that LLMs employ, which involves using the English-centric factual recall mechanism to process multilingual queries and then translating English answers back into the target language. We identify two primary sources of error: insufficient engagement of the reliable English-centric mechanism for factual recall, and incorrect translation from English back into the target language for the final answer. To address these vulnerabilities, we introduce two vector interventions, both independent of languages and datasets, to redirect the model toward better internal paths for higher factual consistency. Our interventions combined increase the recall accuracy by over 35 percent for the lowest-performing language. Our findings demonstrate how mechanistic insights can be used to unlock latent multilingual capabilities in LLMs.","authors":["Meng Lu","Ruochen Zhang","Carsten Eickhoff","Ellie Pavlick"],"url":"https://arxiv.org/abs/2505.20546"}
{"created":"2025-05-29","title":"An Operator-Splitting Scheme for Viscosity Solutions of Constrained Second-Order PDEs","abstract":"This work presents a novel operator-splitting scheme for approximating viscosity solutions of constrained second-order partial differential equations (PDEs) with low-regularity solutions in \\( C(\\overline{\\Omega}_T) \\cap H^1(\\Omega_T) \\). By decoupling PDE evolution and constraint enforcement, the scheme leverages stabilized finite elements and implicit Euler time-stepping to ensure consistency, stability, and monotonicity, guaranteeing convergence to the unique viscosity solution via the Barles-Souganidis framework. The method supports vector-valued constraints and unstructured meshes, addressing challenges in traditional approaches such as restrictive stability conditions and ill-conditioned systems. Theoretical analysis demonstrates a convergence rate of \\( O(h^{1-\\epsilon}) \\) with a proper chosen time step. Applications to Hamilton-Jacobi equations, reaction-diffusion systems, and two-phase Navier-Stokes flows highlight the scheme's versatility and robustness, positioning it as a significant advancement in numerical methods for constrained nonlinear PDEs.","authors":["Po-Yi Wu"],"url":"https://arxiv.org/abs/2505.20618"}
{"created":"2025-05-29","title":"See through the Dark: Learning Illumination-affined Representations for Nighttime Occupancy Prediction","abstract":"Occupancy prediction aims to estimate the 3D spatial distribution of occupied regions along with their corresponding semantic labels. Existing vision-based methods perform well on daytime benchmarks but struggle in nighttime scenarios due to limited visibility and challenging lighting conditions. To address these challenges, we propose \\textbf{LIAR}, a novel framework that learns illumination-affined representations. LIAR first introduces Selective Low-light Image Enhancement (SLLIE), which leverages the illumination priors from daytime scenes to adaptively determine whether a nighttime image is genuinely dark or sufficiently well-lit, enabling more targeted global enhancement. Building on the illumination maps generated by SLLIE, LIAR further incorporates two illumination-aware components: 2D Illumination-guided Sampling (2D-IGS) and 3D Illumination-driven Projection (3D-IDP), to respectively tackle local underexposure and overexposure. Specifically, 2D-IGS modulates feature sampling positions according to illumination maps, assigning larger offsets to darker regions and smaller ones to brighter regions, thereby alleviating feature degradation in underexposed areas. Subsequently, 3D-IDP enhances semantic understanding in overexposed regions by constructing illumination intensity fields and supplying refined residual queries to the BEV context refinement process. Extensive experiments on both real and synthetic datasets demonstrate the superior performance of LIAR under challenging nighttime scenarios. The source code and pretrained models are available \\href{https://github.com/yanzq95/LIAR}{here}.","authors":["Yuan Wu","Zhiqiang Yan","Yigong Zhang","Xiang Li","Jian Yang"],"url":"https://arxiv.org/abs/2505.20641"}
{"created":"2025-05-29","title":"How Do Experts Make Sense of Integrated Process Models?","abstract":"A range of integrated modeling approaches have been developed to enable a holistic representation of business process logic together with all relevant business rules. These approaches address inherent problems with separate documentation of business process models and business rules. In this study, we explore how expert process workers make sense of the information provided through such integrated modeling approaches. To do so, we complement verbal protocol analysis with eye-tracking metrics to reveal nuanced user behaviours involved in the main phases of sensemaking, namely information foraging and information processing. By studying expert process workers engaged in tasks based on integrated modeling of business processes and rules, we provide insights that pave the way for a better understanding of sensemaking practices and improved development of business process and business rule integration approaches. Our research underscores the importance of offering personalized support mechanisms that increase the efficacy and efficiency of sensemaking practices for process knowledge workers.","authors":["Tianwa Chen","Barbara Weber","Graeme Shanks","Gianluca Demartini","Marta Indulska","Shazia Sadiq"],"url":"https://arxiv.org/abs/2505.20667"}
{"created":"2025-05-29","title":"System-driven Cloud Architecture Design Support with Structured State Management and Guided Decision Assistance","abstract":"Cloud architecture design is a complex process requiring both technical expertise and architectural knowledge to develop solutions from frequently ambiguous requirements. We present CloudArchitectBuddy, a system-driven cloud architecture design support application with two key mechanisms: (1) structured state management that enhances design understanding through explicit representation of requirements and architectural decisions, and (2) guided decision assistance that facilitates design progress through proactive verification and requirement refinement. Our study with 16 industry practitioners showed that while our approach achieved comparable design quality to a chat interface, participants rated our system higher for usability and appreciated its ability to help understand architectural relationships and identify missing requirements. However, participants also expressed a need for user-initiated interactions where they could freely provide design instructions and engage in detailed discussions with LLMs. These results suggest that integrating a chat interface into our structured and guided workflow approach would create a more practical solution, balancing systematic design support with conversational flexibility for comprehensive cloud architecture development.","authors":["Ryosuke Kohita","Akira Kasuga"],"url":"https://arxiv.org/abs/2505.20701"}
{"created":"2025-05-29","title":"VLM Can Be a Good Assistant: Enhancing Embodied Visual Tracking with Self-Improving Vision-Language Models","abstract":"We introduce a novel self-improving framework that enhances Embodied Visual Tracking (EVT) with Vision-Language Models (VLMs) to address the limitations of current active visual tracking systems in recovering from tracking failure. Our approach combines the off-the-shelf active tracking methods with VLMs' reasoning capabilities, deploying a fast visual policy for normal tracking and activating VLM reasoning only upon failure detection. The framework features a memory-augmented self-reflection mechanism that enables the VLM to progressively improve by learning from past experiences, effectively addressing VLMs' limitations in 3D spatial reasoning. Experimental results demonstrate significant performance improvements, with our framework boosting success rates by $72\\%$ with state-of-the-art RL-based approaches and $220\\%$ with PID-based methods in challenging environments. This work represents the first integration of VLM-based reasoning to assist EVT agents in proactive failure recovery, offering substantial advances for real-world robotic applications that require continuous target monitoring in dynamic, unstructured environments. Project website: https://sites.google.com/view/evt-recovery-assistant.","authors":["Kui Wu","Shuhang Xu","Hao Chen","Churan Wang","Zhoujun Li","Yizhou Wang","Fangwei Zhong"],"url":"https://arxiv.org/abs/2505.20718"}
{"created":"2025-05-29","title":"Hybrid Wave-wind System Power Optimisation Using Effective Ensemble Covariance Matrix Adaptation Evolutionary Algorithm","abstract":"Floating hybrid wind-wave systems combine offshore wind platforms with wave energy converters (WECs) to create cost-effective and reliable energy solutions. Adequately designed and tuned WECs are essential to avoid unwanted loads disrupting turbine motion while efficiently harvesting wave energy. These systems diversify energy sources, enhancing energy security and reducing supply risks while providing a more consistent power output by smoothing energy production variability. However, optimising such systems is complex due to the physical and hydrodynamic interactions between components, resulting in a challenging optimisation space. This study uses a 5-MW OC4-DeepCwind semi-submersible platform with three spherical WECs to explore these synergies. To address these challenges, we propose an effective ensemble optimisation (EEA) technique that combines covariance matrix adaptation, novelty search, and discretisation techniques. To evaluate the EEA performance, we used four sea sites located along Australia's southern coast. In this framework, geometry and power take-off parameters are simultaneously optimised to maximise the average power output of the hybrid wind-wave system. Ensemble optimisation methods enhance performance, flexibility, and robustness by identifying the best algorithm or combination of algorithms for a given problem, addressing issues like premature convergence, stagnation, and poor search space exploration. The EEA was benchmarked against 14 advanced optimisation methods, demonstrating superior solution quality and convergence rates. EEA improved total power output by 111%, 95%, and 52% compared to WOA, EO, and AHA, respectively. Additionally, in comparisons with advanced methods, LSHADE, SaNSDE, and SLPSO, EEA achieved absorbed power enhancements of 498%, 638%, and 349% at the Sydney sea site, showcasing its effectiveness in optimising hybrid energy systems.","authors":["Mehdi Neshat","Nataliia Y. Sergiienko","Leandro S. P. da Silva","Seyedali Mirjalili","Amir H. Gandomi","Ossama Abdelkhalik","John Boland"],"url":"https://arxiv.org/abs/2505.20720"}
{"created":"2025-05-29","title":"CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models","abstract":"Faithfulness hallucination are claims generated by a Large Language Model (LLM) not supported by contexts provided to the LLM. Lacking assessment standard, existing benchmarks only contain \"factual statements\" that rephrase source materials without marking \"cognitive statements\" that make inference from the given context, making the consistency evaluation and optimization of cognitive statements difficult. Inspired by how an evidence is assessed in the legislative domain, we design a rigorous framework to assess different levels of faithfulness of cognitive statements and create a benchmark dataset where we reveal insightful statistics. We design an annotation pipeline to create larger benchmarks for different LLMs automatically, and the resulting larger-scale CogniBench-L dataset can be used to train accurate cognitive hallucination detection model. We release our model and dataset at: https://github.com/FUTUREEEEEE/CogniBench","authors":["Xiaqiang Tang","Jian Li","Keyu Hu","Du Nan","Xiaolong Li","Xi Zhang","Weigao Sun","Sihong Xie"],"url":"https://arxiv.org/abs/2505.20767"}
{"created":"2025-05-29","title":"CHIMERA: A Knowledge Base of Idea Recombination in Scientific Literature","abstract":"A hallmark of human innovation is the process of recombination -- creating original ideas by integrating elements of existing mechanisms and concepts. In this work, we automatically mine the scientific literature and build CHIMERA: a large-scale knowledge base (KB) of recombination examples. CHIMERA can be used to empirically explore at scale how scientists recombine concepts and take inspiration from different areas, or to train supervised machine learning models that learn to predict new creative cross-domain directions. To build this KB, we present a novel information extraction task of extracting recombination from scientific paper abstracts, collect a high-quality corpus of hundreds of manually annotated abstracts, and use it to train an LLM-based extraction model. The model is applied to a large corpus of papers in the AI domain, yielding a KB of over 28K recombination examples. We analyze CHIMERA to explore the properties of recombination in different subareas of AI. Finally, we train a scientific hypothesis generation model using the KB, which predicts new recombination directions that real-world researchers find inspiring. Our data and code are available at https://github.com/noy-sternlicht/CHIMERA-KB","authors":["Noy Sternlicht","Tom Hope"],"url":"https://arxiv.org/abs/2505.20779"}
{"created":"2025-05-29","title":"Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models","abstract":"Inverse problems (IPs) involve reconstructing signals from noisy observations. Recently, diffusion models (DMs) have emerged as a powerful framework for solving IPs, achieving remarkable reconstruction performance. However, existing DM-based methods frequently encounter issues such as heavy computational demands and suboptimal convergence. In this work, building upon the idea of the recent work DMPlug, we propose two novel methods, DMILO and DMILO-PGD, to address these challenges. Our first method, DMILO, employs intermediate layer optimization (ILO) to alleviate the memory burden inherent in DMPlug. Additionally, by introducing sparse deviations, we expand the range of DMs, enabling the exploration of underlying signals that may lie outside the range of the diffusion model. We further propose DMILO-PGD, which integrates ILO with projected gradient descent (PGD), thereby reducing the risk of suboptimal convergence. We provide an intuitive theoretical analysis of our approaches under appropriate conditions and validate their superiority through extensive experiments on diverse image datasets, encompassing both linear and nonlinear IPs. Our results demonstrate significant performance gains over state-of-the-art methods, highlighting the effectiveness of DMILO and DMILO-PGD in addressing common challenges in DM-based IP solvers.","authors":["Yang Zheng","Wen Li","Zhaoqiang Liu"],"url":"https://arxiv.org/abs/2505.20789"}
{"created":"2025-05-29","title":"RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph","abstract":"In knowledge graph embedding, leveraging relation specific entity transformation has markedly enhanced performance. However, the consistency of embedding differences before and after transformation remains unaddressed, risking the loss of valuable inductive bias inherent in the embeddings. This inconsistency stems from two problems. First, transformation representations are specified for relations in a disconnected manner, allowing dissimilar transformations and corresponding entity embeddings for similar relations. Second, a generalized plug-in approach as a SFBR (Semantic Filter Based on Relations) disrupts this consistency through excessive concentration of entity embeddings under entity-based regularization, generating indistinguishable score distributions among relations. In this paper, we introduce a plug-in KGE method, Relation-Semantics Consistent Filter (RSCF). Its entity transformation has three features for enhancing semantic consistency: 1) shared affine transformation of relation embeddings across all relations, 2) rooted entity transformation that adds an entity embedding to its change represented by the transformed vector, and 3) normalization of the change to prevent scale reduction. To amplify the advantages of consistency that preserve semantics on embeddings, RSCF adds relation transformation and prediction modules for enhancing the semantics. In knowledge graph completion tasks with distance-based and tensor decomposition models, RSCF significantly outperforms state-of-the-art KGE methods, showing robustness across all relations and their frequencies.","authors":["Junsik Kim","Jinwook Park","Kangil Kim"],"url":"https://arxiv.org/abs/2505.20813"}
{"created":"2025-05-29","title":"GET: Goal-directed Exploration and Targeting for Large-Scale Unknown Environments","abstract":"Object search in large-scale, unstructured environments remains a fundamental challenge in robotics, particularly in dynamic or expansive settings such as outdoor autonomous exploration. This task requires robust spatial reasoning and the ability to leverage prior experiences. While Large Language Models (LLMs) offer strong semantic capabilities, their application in embodied contexts is limited by a grounding gap in spatial reasoning and insufficient mechanisms for memory integration and decision consistency.To address these challenges, we propose GET (Goal-directed Exploration and Targeting), a framework that enhances object search by combining LLM-based reasoning with experience-guided exploration. At its core is DoUT (Diagram of Unified Thought), a reasoning module that facilitates real-time decision-making through a role-based feedback loop, integrating task-specific criteria and external memory. For repeated tasks, GET maintains a probabilistic task map based on a Gaussian Mixture Model, allowing for continual updates to object-location priors as environments evolve.Experiments conducted in real-world, large-scale environments demonstrate that GET improves search efficiency and robustness across multiple LLMs and task settings, significantly outperforming heuristic and LLM-only baselines. These results suggest that structured LLM integration provides a scalable and generalizable approach to embodied decision-making in complex environments.","authors":["Lanxiang Zheng","Ruidong Mei","Mingxin Wei","Hao Ren","Hui Cheng"],"url":"https://arxiv.org/abs/2505.20828"}
{"created":"2025-05-29","title":"FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration","abstract":"As large language models become increasingly prevalent, memory bandwidth constraints significantly limit inference throughput, motivating post-training quantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ framework and an INT4-FP8 matrix multiplication kernel that accelerates LLM inference across all linear layers. Specifically, FireQ quantizes linear layer weights and key-values to INT4, and activations and queries to FP8, significantly enhancing throughput. Additionally, we introduce a three-stage pipelining for the prefill phase, which modifies the FlashAttention-3 kernel, effectively reducing time-to-first-token in the prefill phase. To minimize accuracy loss from quantization, we develop novel outlier smoothing techniques tailored separately for linear and attention layers. In linear layers, we explicitly use per-tensor scaling to prevent underflow caused by the FP8 quantization scaling factor of INT4 quantization, and channel-wise scaling to compensate for coarse granularity of INT4. In attention layers, we address quantization challenges posed by rotary positional embeddings (RoPE) by combining pre-RoPE and post-RoPE scaling strategies. FireQ significantly outperforms state-of-the-art methods, achieving 1.68x faster inference in feed-forward network layers on Llama2-7B and 1.26x faster prefill phase performance on Llama3-8B compared to QServe, with negligible accuracy loss.","authors":["Daehyeon Baek","Jieun Choi","Jimyoung Son","Kyungmin Bin","Seungbeom Choi","Kihyo Moon","Minsung Jang","Hyojung Lee"],"url":"https://arxiv.org/abs/2505.20839"}
{"created":"2025-05-29","title":"Cooperation of Experts: Fusing Heterogeneous Information with Large Margin","abstract":"Fusing heterogeneous information remains a persistent challenge in modern data analysis. While significant progress has been made, existing approaches often fail to account for the inherent heterogeneity of object patterns across different semantic spaces. To address this limitation, we propose the Cooperation of Experts (CoE) framework, which encodes multi-typed information into unified heterogeneous multiplex networks. By overcoming modality and connection differences, CoE provides a powerful and flexible model for capturing the intricate structures of real-world complex data. In our framework, dedicated encoders act as domain-specific experts, each specializing in learning distinct relational patterns in specific semantic spaces. To enhance robustness and extract complementary knowledge, these experts collaborate through a novel large margin mechanism supported by a tailored optimization strategy. Rigorous theoretical analyses guarantee the framework's feasibility and stability, while extensive experiments across diverse benchmarks demonstrate its superior performance and broad applicability. Our code is available at https://github.com/strangeAlan/CoE.","authors":["Shuo Wang","Shunyang Huang","Jinghui Yuan","Zhixiang Shen","Zhao Kang"],"url":"https://arxiv.org/abs/2505.20853"}
{"created":"2025-05-29","title":"Stereo Radargrammetry Using Deep Learning from Airborne SAR Images","abstract":"In this paper, we propose a stereo radargrammetry method using deep learning from airborne Synthetic Aperture Radar (SAR) images. Deep learning-based methods are considered to suffer less from geometric image modulation, while there is no public SAR image dataset used to train such methods. We create a SAR image dataset and perform fine-tuning of a deep learning-based image correspondence method. The proposed method suppresses the degradation of image quality by pixel interpolation without ground projection of the SAR image and divides the SAR image into patches for processing, which makes it possible to apply deep learning. Through a set of experiments, we demonstrate that the proposed method exhibits a wider range and more accurate elevation measurements compared to conventional methods.","authors":["Tatsuya Sasayama","Shintaro Ito","Koichi Ito","Takafumi Aoki"],"url":"https://arxiv.org/abs/2505.20876"}
{"created":"2025-05-29","title":"Improved Bounds for Swap Multicalibration and Swap Omniprediction","abstract":"In this paper, we consider the related problems of multicalibration -- a multigroup fairness notion and omniprediction -- a simultaneous loss minimization paradigm, both in the distributional and online settings. The recent work of Garg et al. (2024) raised the open problem of whether it is possible to efficiently achieve $O(\\sqrt{T})$ $\\ell_{2}$-multicalibration error against bounded linear functions. In this paper, we answer this question in a strongly affirmative sense. We propose an efficient algorithm that achieves $O(T^{\\frac{1}{3}})$ $\\ell_{2}$-swap multicalibration error (both in high probability and expectation). On propagating this bound onward, we obtain significantly improved rates for $\\ell_{1}$-swap multicalibration and swap omniprediction for a loss class of convex Lipschitz functions. In particular, we show that our algorithm achieves $O(T^{\\frac{2}{3}})$ $\\ell_{1}$-swap multicalibration and swap omniprediction errors, thereby improving upon the previous best-known bound of $O(T^{\\frac{7}{8}})$. As a consequence of our improved online results, we further obtain several improved sample complexity rates in the distributional setting. In particular, we establish a $O(\\varepsilon ^ {-3})$ sample complexity of efficiently learning an $\\varepsilon$-swap omnipredictor for the class of convex and Lipschitz functions, $O(\\varepsilon ^{-2.5})$ sample complexity of efficiently learning an $\\varepsilon$-swap agnostic learner for the squared loss, and $O(\\varepsilon ^ {-5}), O(\\varepsilon ^ {-2.5})$ sample complexities of learning $\\ell_{1}, \\ell_{2}$-swap multicalibrated predictors against linear functions, all of which significantly improve on the previous best-known bounds.","authors":["Haipeng Luo","Spandan Senapati","Vatsal Sharan"],"url":"https://arxiv.org/abs/2505.20885"}
{"created":"2025-05-29","title":"Embed Progressive Implicit Preference in Unified Space for Deep Collaborative Filtering","abstract":"Embedding-based collaborative filtering, often coupled with nearest neighbor search, is widely deployed in large-scale recommender systems for personalized content selection. Modern systems leverage multiple implicit feedback signals (e.g., clicks, add to cart, purchases) to model user preferences comprehensively. However, prevailing approaches adopt a feedback-wise modeling paradigm, which (1) fails to capture the structured progression of user engagement entailed among different feedback and (2) embeds feedback-specific information into disjoint spaces, making representations incommensurable, increasing system complexity, and leading to suboptimal retrieval performance. A promising alternative is Ordinal Logistic Regression (OLR), which explicitly models discrete ordered relations. However, existing OLR-based recommendation models mainly focus on explicit feedback (e.g., movie ratings) and struggle with implicit, correlated feedback, where ordering is vague and non-linear. Moreover, standard OLR lacks flexibility in handling feedback-dependent covariates, resulting in suboptimal performance in real-world systems. To address these limitations, we propose Generalized Neural Ordinal Logistic Regression (GNOLR), which encodes multiple feature-feedback dependencies into a unified, structured embedding space and enforces feedback-specific dependency learning through a nested optimization framework. Thus, GNOLR enhances predictive accuracy, captures the progression of user engagement, and simplifies the retrieval process. We establish a theoretical comparison with existing paradigms, demonstrating how GNOLR avoids disjoint spaces while maintaining effectiveness. Extensive experiments on ten real-world datasets show that GNOLR significantly outperforms state-of-the-art methods in efficiency and adaptability.","authors":["Zhongjin Zhang","Yu Liang","Cong Fu","Yuxuan Zhu","Kun Wang","Yabo Ni","Anxiang Zeng","Jiazhi Xia"],"url":"https://arxiv.org/abs/2505.20900"}
{"created":"2025-05-29","title":"HTMNet: A Hybrid Network with Transformer-Mamba Bottleneck Multimodal Fusion for Transparent and Reflective Objects Depth Completion","abstract":"Transparent and reflective objects pose significant challenges for depth sensors, resulting in incomplete depth information that adversely affects downstream robotic perception and manipulation tasks. To address this issue, we propose HTMNet, a novel hybrid model integrating Transformer, CNN, and Mamba architectures. The encoder is based on a dual-branch CNN-Transformer framework, the bottleneck fusion module adopts a Transformer-Mamba architecture, and the decoder is built upon a multi-scale fusion module. We introduce a novel multimodal fusion module grounded in self-attention mechanisms and state space models, marking the first application of the Mamba architecture in the field of transparent object depth completion and revealing its promising potential. Additionally, we design an innovative multi-scale fusion module for the decoder that combines channel attention, spatial attention, and multi-scale feature extraction techniques to effectively integrate multi-scale features through a down-fusion strategy. Extensive evaluations on multiple public datasets demonstrate that our model achieves state-of-the-art(SOTA) performance, validating the effectiveness of our approach.","authors":["Guanghu Xie","Yonglong Zhang","Zhiduo Jiang","Yang Liu","Zongwu Xie","Baoshi Cao","Hong Liu"],"url":"https://arxiv.org/abs/2505.20904"}
{"created":"2025-05-29","title":"Understanding the behavior of representation forgetting in continual learning","abstract":"In continual learning scenarios, catastrophic forgetting of previously learned tasks is a critical issue, making it essential to effectively measure such forgetting. Recently, there has been growing interest in focusing on representation forgetting, the forgetting measured at the hidden layer. In this paper, we provide the first theoretical analysis of representation forgetting and use this analysis to better understand the behavior of continual learning. First, we introduce a new metric called representation discrepancy, which measures the difference between representation spaces constructed by two snapshots of a model trained through continual learning. We demonstrate that our proposed metric serves as an effective surrogate for the representation forgetting while remaining analytically tractable. Second, through mathematical analysis of our metric, we derive several key findings about the dynamics of representation forgetting: the forgetting occurs more rapidly to a higher degree as the layer index increases, while increasing the width of the network slows down the forgetting process. Third, we support our theoretical findings through experiments on real image datasets, including Split-CIFAR100 and ImageNet1K.","authors":["Joonkyu Kim","Yejin Kim","Jy-yong Sohn"],"url":"https://arxiv.org/abs/2505.20970"}
{"created":"2025-05-29","title":"Towards Conversational Development Environments: Using Theory-of-Mind and Multi-Agent Architectures for Requirements Refinement","abstract":"Foundation Models (FMs) have shown remarkable capabilities in various natural language tasks. However, their ability to accurately capture stakeholder requirements remains a significant challenge for using FMs for software development. This paper introduces a novel approach that leverages an FM-powered multi-agent system called AlignMind to address this issue. By having a cognitive architecture that enhances FMs with Theory-of-Mind capabilities, our approach considers the mental states and perspectives of software makers. This allows our solution to iteratively clarify the beliefs, desires, and intentions of stakeholders, translating these into a set of refined requirements and a corresponding actionable natural language workflow in the often-overlooked requirements refinement phase of software engineering, which is crucial after initial elicitation. Through a multifaceted evaluation covering 150 diverse use cases, we demonstrate that our approach can accurately capture the intents and requirements of stakeholders, articulating them as both specifications and a step-by-step plan of action. Our findings suggest that the potential for significant improvements in the software development process justifies these investments. Our work lays the groundwork for future innovation in building intent-first development environments, where software makers can seamlessly collaborate with AIs to create software that truly meets their needs.","authors":["Keheliya Gallaba","Ali Arabat","Dayi Lin","Mohammed Sayagh","Ahmed E. Hassan"],"url":"https://arxiv.org/abs/2505.20973"}
{"created":"2025-05-29","title":"FCKT: Fine-Grained Cross-Task Knowledge Transfer with Semantic Contrastive Learning for Targeted Sentiment Analysis","abstract":"In this paper, we address the task of targeted sentiment analysis (TSA), which involves two sub-tasks, i.e., identifying specific aspects from reviews and determining their corresponding sentiments. Aspect extraction forms the foundation for sentiment prediction, highlighting the critical dependency between these two tasks for effective cross-task knowledge transfer. While most existing studies adopt a multi-task learning paradigm to align task-specific features in the latent space, they predominantly rely on coarse-grained knowledge transfer. Such approaches lack fine-grained control over aspect-sentiment relationships, often assuming uniform sentiment polarity within related aspects. This oversimplification neglects contextual cues that differentiate sentiments, leading to negative transfer. To overcome these limitations, we propose FCKT, a fine-grained cross-task knowledge transfer framework tailored for TSA. By explicitly incorporating aspect-level information into sentiment prediction, FCKT achieves fine-grained knowledge transfer, effectively mitigating negative transfer and enhancing task performance. Experiments on three datasets, including comparisons with various baselines and large language models (LLMs), demonstrate the effectiveness of FCKT. The source code is available on https://github.com/cwei01/FCKT.","authors":["Wei Chen","Zhao Zhang","Meng Yuan","Kepeng Xu","Fuzhen Zhuang"],"url":"https://arxiv.org/abs/2505.21040"}
{"created":"2025-05-29","title":"CityGo: Lightweight Urban Modeling and Rendering with Proxy Buildings and Residual Gaussians","abstract":"Accurate and efficient modeling of large-scale urban scenes is critical for applications such as AR navigation, UAV based inspection, and smart city digital twins. While aerial imagery offers broad coverage and complements limitations of ground-based data, reconstructing city-scale environments from such views remains challenging due to occlusions, incomplete geometry, and high memory demands. Recent advances like 3D Gaussian Splatting (3DGS) improve scalability and visual quality but remain limited by dense primitive usage, long training times, and poor suit ability for edge devices. We propose CityGo, a hybrid framework that combines textured proxy geometry with residual and surrounding 3D Gaussians for lightweight, photorealistic rendering of urban scenes from aerial perspectives. Our approach first extracts compact building proxy meshes from MVS point clouds, then uses zero order SH Gaussians to generate occlusion-free textures via image-based rendering and back-projection. To capture high-frequency details, we introduce residual Gaussians placed based on proxy-photo discrepancies and guided by depth priors. Broader urban context is represented by surrounding Gaussians, with importance-aware downsampling applied to non-critical regions to reduce redundancy. A tailored optimization strategy jointly refines proxy textures and Gaussian parameters, enabling real-time rendering of complex urban scenes on mobile GPUs with significantly reduced training and memory requirements. Extensive experiments on real-world aerial datasets demonstrate that our hybrid representation significantly reduces training time, achieving on average 1.4x speedup, while delivering comparable visual fidelity to pure 3D Gaussian Splatting approaches. Furthermore, CityGo enables real-time rendering of large-scale urban scenes on mobile consumer GPUs, with substantially reduced memory usage and energy consumption.","authors":["Weihang Liu","Yuhui Zhong","Yuke Li","Xi Chen","Jiadi Cui","Honglong Zhang","Lan Xu","Xin Lou","Yujiao Shi","Jingyi Yu","Yingliang Zhang"],"url":"https://arxiv.org/abs/2505.21041"}
{"created":"2025-05-29","title":"Advancing high-fidelity 3D and Texture Generation with 2.5D latents","abstract":"Despite the availability of large-scale 3D datasets and advancements in 3D generative models, the complexity and uneven quality of 3D geometry and texture data continue to hinder the performance of 3D generation techniques. In most existing approaches, 3D geometry and texture are generated in separate stages using different models and non-unified representations, frequently leading to unsatisfactory coherence between geometry and texture. To address these challenges, we propose a novel framework for joint generation of 3D geometry and texture. Specifically, we focus in generate a versatile 2.5D representations that can be seamlessly transformed between 2D and 3D. Our approach begins by integrating multiview RGB, normal, and coordinate images into a unified representation, termed as 2.5D latents. Next, we adapt pre-trained 2D foundation models for high-fidelity 2.5D generation, utilizing both text and image conditions. Finally, we introduce a lightweight 2.5D-to-3D refiner-decoder framework that efficiently generates detailed 3D representations from 2.5D images. Extensive experiments demonstrate that our model not only excels in generating high-quality 3D objects with coherent structure and color from text and image inputs but also significantly outperforms existing methods in geometry-conditioned texture generation.","authors":["Xin Yang","Jiantao Lin","Yingjie Xu","Haodong Li","Yingcong Chen"],"url":"https://arxiv.org/abs/2505.21050"}
{"created":"2025-05-29","title":"Faithfulness-Aware Uncertainty Quantification for Fact-Checking the Output of Retrieval Augmented Generation","abstract":"Large Language Models (LLMs) enhanced with external knowledge retrieval, an approach known as Retrieval-Augmented Generation (RAG), have shown strong performance in open-domain question answering. However, RAG systems remain susceptible to hallucinations: factually incorrect outputs that may arise either from inconsistencies in the model's internal knowledge or incorrect use of the retrieved context. Existing approaches often conflate factuality with faithfulness to the retrieved context, misclassifying factually correct statements as hallucinations if they are not directly supported by the retrieval. In this paper, we introduce FRANQ (Faithfulness-based Retrieval Augmented UNcertainty Quantification), a novel method for hallucination detection in RAG outputs. FRANQ applies different Uncertainty Quantification (UQ) techniques to estimate factuality based on whether a statement is faithful to the retrieved context or not. To evaluate FRANQ and other UQ techniques for RAG, we present a new long-form Question Answering (QA) dataset annotated for both factuality and faithfulness, combining automated labeling with manual validation of challenging examples. Extensive experiments on long- and short-form QA across multiple datasets and LLMs show that FRANQ achieves more accurate detection of factual errors in RAG-generated responses compared to existing methods.","authors":["Ekaterina Fadeeva","Aleksandr Rubashevskii","Roman Vashurin","Shehzaad Dhuliawala","Artem Shelmanov","Timothy Baldwin","Preslav Nakov","Mrinmaya Sachan","Maxim Panov"],"url":"https://arxiv.org/abs/2505.21072"}
{"created":"2025-05-29","title":"Bridging Arbitrary and Tree Metrics via Differentiable Gromov Hyperbolicity","abstract":"Trees and the associated shortest-path tree metrics provide a powerful framework for representing hierarchical and combinatorial structures in data. Given an arbitrary metric space, its deviation from a tree metric can be quantified by Gromov's $\\delta$-hyperbolicity. Nonetheless, designing algorithms that bridge an arbitrary metric to its closest tree metric is still a vivid subject of interest, as most common approaches are either heuristical and lack guarantees, or perform moderately well. In this work, we introduce a novel differentiable optimization framework, coined DeltaZero, that solves this problem. Our method leverages a smooth surrogate for Gromov's $\\delta$-hyperbolicity which enables a gradient-based optimization, with a tractable complexity. The corresponding optimization procedure is derived from a problem with better worst case guarantees than existing bounds, and is justified statistically. Experiments on synthetic and real-world datasets demonstrate that our method consistently achieves state-of-the-art distortion.","authors":["Pierre Houedry","Nicolas Courty","Florestan Martin-Baillon","Laetitia Chapel","Titouan Vayer"],"url":"https://arxiv.org/abs/2505.21073"}
{"created":"2025-05-29","title":"LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models","abstract":"Large language models (LLMs) have recently achieved impressive performance across a wide range of natural language tasks and are now widely used in real-world applications. Among them, black-box LLMs--served via APIs without access to model internals--are especially dominant due to their scalability and ease of deployment. Despite their strong capabilities, these models typically produce generalized responses that overlook personal preferences and reasoning styles. This has led to growing interest in black-box LLM personalization, which aims to tailor model outputs to user-specific context without modifying model parameters. However, existing approaches primarily focus on response-level personalization, attempting to match final outputs without modeling personal thought process. To address this limitation, we propose RPM, a framework for reasoning-level personalization that aligns the model's reasoning process with a user's personalized logic. RPM first constructs statistical user-specific factors by extracting and grouping response-influential features from user history. It then builds personalized reasoning paths that reflect how these factors are used in context. In the inference stage, RPM retrieves reasoning-aligned examples for new queries via feature-level similarity and performs inference conditioned on the structured factors and retrieved reasoning paths, enabling the model to follow user-specific reasoning trajectories. This reasoning-level personalization enhances both predictive accuracy and interpretability by grounding model outputs in user-specific logic through structured information. Extensive experiments across diverse tasks show that RPM consistently outperforms response-level personalization methods, demonstrating the effectiveness of reasoning-level personalization in black-box LLMs.","authors":["Jieyong Kim","Tongyoung Kim","Soojin Yoon","Jaehyung Kim","Dongha Lee"],"url":"https://arxiv.org/abs/2505.21082"}
{"created":"2025-05-29","title":"SageAttention2++: A More Efficient Implementation of SageAttention2","abstract":"The efficiency of attention is critical because its time complexity grows quadratically with sequence length. SageAttention2 addresses this by utilizing quantization to accelerate matrix multiplications (Matmul) in attention. To further accelerate SageAttention2, we propose to utilize the faster instruction of FP8 Matmul accumulated in FP16. The instruction is 2x faster than the FP8 Matmul used in SageAttention2. Our experiments show that SageAttention2++ achieves a 3.9x speedup over FlashAttention while maintaining the same attention accuracy as SageAttention2. This means SageAttention2++ effectively accelerates various models, including those for language, image, and video generation, with negligible end-to-end metrics loss. The code will be available at https://github.com/thu-ml/SageAttention.","authors":["Jintao Zhang","Xiaoming Xu","Jia Wei","Haofeng Huang","Pengle Zhang","Chendong Xiang","Jun Zhu","Jianfei Chen"],"url":"https://arxiv.org/abs/2505.21136"}
{"created":"2025-05-29","title":"Custom Representations of Inductive Families","abstract":"Inductive families provide a convenient way of programming with dependent types. Yet, when it comes to compilation, their default linked-tree runtime representations, as well as the need to convert between different indexed views of the same data, can lead to unsatisfactory runtime performance. In this paper, we introduce a language with dependent types, and inductive families with customisable representations. Representations are a version of Wadler's views, refined to inductive families like in Epigram, but with compilation guarantees: a represented inductive family will not leave any runtime traces behind, without relying on heuristics such as deforestation. This way, we can build a library of convenient inductive families based on a minimal set of primitives, whose re-indexing and conversion functions are erased during compilation. We show how we can express optimisation techniques such as representing Nat-like types as GMP-style big integers, without special casing in the compiler. With dependent types, reasoning about data representations is also possible through a provided modality. This yields computationally irrelevant isomorphisms between the original and represented data.","authors":["Constantine Theocharis","Edwin Brady"],"url":"https://arxiv.org/abs/2505.21225"}
{"created":"2025-05-29","title":"Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework","abstract":"We introduce copresheaf topological neural networks (CTNNs), a powerful and unifying framework that encapsulates a wide spectrum of deep learning architectures, designed to operate on structured data: including images, point clouds, graphs, meshes, and topological manifolds. While deep learning has profoundly impacted domains ranging from digital assistants to autonomous systems, the principled design of neural architectures tailored to specific tasks and data types remains one of the field's most persistent open challenges. CTNNs address this gap by grounding model design in the language of copresheaves, a concept from algebraic topology that generalizes and subsumes most practical deep learning models in use today. This abstract yet constructive formulation yields a rich design space from which theoretically sound and practically effective solutions can be derived to tackle core challenges in representation learning: long-range dependencies, oversmoothing, heterophily, and non-Euclidean domains. Our empirical results on structured data benchmarks demonstrate that CTNNs consistently outperform conventional baselines, particularly in tasks requiring hierarchical or localized sensitivity. These results underscore CTNNs as a principled, multi-scale foundation for the next generation of deep learning architectures.","authors":["Mustafa Hajij","Lennart Bastian","Sarah Osentoski","Hardik Kabaria","John L. Davenport","Sheik Dawood","Balaji Cherukuri","Joseph G. Kocheemoolayil","Nastaran Shahmansouri","Adrian Lew","Theodore Papamarkou","Tolga Birdal"],"url":"https://arxiv.org/abs/2505.21251"}
{"created":"2025-05-29","title":"Breaking the Ceiling: Exploring the Potential of Jailbreak Attacks through Expanding Strategy Space","abstract":"Large Language Models (LLMs), despite advanced general capabilities, still suffer from numerous safety risks, especially jailbreak attacks that bypass safety protocols. Understanding these vulnerabilities through black-box jailbreak attacks, which better reflect real-world scenarios, offers critical insights into model robustness. While existing methods have shown improvements through various prompt engineering techniques, their success remains limited against safety-aligned models, overlooking a more fundamental problem: the effectiveness is inherently bounded by the predefined strategy spaces. However, expanding this space presents significant challenges in both systematically capturing essential attack patterns and efficiently navigating the increased complexity. To better explore the potential of expanding the strategy space, we address these challenges through a novel framework that decomposes jailbreak strategies into essential components based on the Elaboration Likelihood Model (ELM) theory and develops genetic-based optimization with intention evaluation mechanisms. To be striking, our experiments reveal unprecedented jailbreak capabilities by expanding the strategy space: we achieve over 90% success rate on Claude-3.5 where prior methods completely fail, while demonstrating strong cross-model transferability and surpassing specialized safeguard models in evaluation accuracy. The code is open-sourced at: https://github.com/Aries-iai/CL-GSO.","authors":["Yao Huang","Yitong Sun","Shouwei Ruan","Yichi Zhang","Yinpeng Dong","Xingxing Wei"],"url":"https://arxiv.org/abs/2505.21277"}
{"created":"2025-05-29","title":"Charting the Landscape of African NLP: Mapping Progress and Shaping the Road Ahead","abstract":"With over 2,000 languages and potentially millions of speakers, Africa represents one of the richest linguistic regions in the world. Yet, this diversity is scarcely reflected in state-of-the-art natural language processing (NLP) systems and large language models (LLMs), which predominantly support a narrow set of high-resource languages. This exclusion not only limits the reach and utility of modern NLP technologies but also risks widening the digital divide across linguistic communities. Nevertheless, NLP research on African languages is active and growing. In recent years, there has been a surge of interest in this area, driven by several factors-including the creation of multilingual language resources, the rise of community-led initiatives, and increased support through funding programs. In this survey, we analyze 734 research papers on NLP for African languages published over the past five years, offering a comprehensive overview of recent progress across core tasks. We identify key trends shaping the field and conclude by outlining promising directions to foster more inclusive and sustainable NLP research for African languages.","authors":["Jesujoba O. Alabi","Michael A. Hedderich","David Ifeoluwa Adelani","Dietrich Klakow"],"url":"https://arxiv.org/abs/2505.21315"}
{"created":"2025-05-29","title":"MagicTryOn: Harnessing Diffusion Transformer for Garment-Preserving Video Virtual Try-on","abstract":"Video Virtual Try-On (VVT) aims to simulate the natural appearance of garments across consecutive video frames, capturing their dynamic variations and interactions with human body motion. However, current VVT methods still face challenges in terms of spatiotemporal consistency and garment content preservation. First, they use diffusion models based on the U-Net, which are limited in their expressive capability and struggle to reconstruct complex details. Second, they adopt a separative modeling approach for spatial and temporal attention, which hinders the effective capture of structural relationships and dynamic consistency across frames. Third, their expression of garment details remains insufficient, affecting the realism and stability of the overall synthesized results, especially during human motion. To address the above challenges, we propose MagicTryOn, a video virtual try-on framework built upon the large-scale video diffusion Transformer. We replace the U-Net architecture with a diffusion Transformer and combine full self-attention to jointly model the spatiotemporal consistency of videos. We design a coarse-to-fine garment preservation strategy. The coarse strategy integrates garment tokens during the embedding stage, while the fine strategy incorporates multiple garment-based conditions, such as semantics, textures, and contour lines during the denoising stage. Moreover, we introduce a mask-aware loss to further optimize garment region fidelity. Extensive experiments on both image and video try-on datasets demonstrate that our method outperforms existing SOTA methods in comprehensive evaluations and generalizes to in-the-wild scenarios.","authors":["Guangyuan Li","Siming Zheng","Hao Zhang","Jinwei Chen","Junsheng Luan","Binkai Ou","Lei Zhao","Bo Li","Peng-Tao Jiang"],"url":"https://arxiv.org/abs/2505.21325"}
{"created":"2025-05-29","title":"Something's Fishy In The Data Lake: A Critical Re-evaluation of Table Union Search Benchmarks","abstract":"Recent table representation learning and data discovery methods tackle table union search (TUS) within data lakes, which involves identifying tables that can be unioned with a given query table to enrich its content. These methods are commonly evaluated using benchmarks that aim to assess semantic understanding in real-world TUS tasks. However, our analysis of prominent TUS benchmarks reveals several limitations that allow simple baselines to perform surprisingly well, often outperforming more sophisticated approaches. This suggests that current benchmark scores are heavily influenced by dataset-specific characteristics and fail to effectively isolate the gains from semantic understanding. To address this, we propose essential criteria for future benchmarks to enable a more realistic and reliable evaluation of progress in semantic table union search.","authors":["Allaa Boutaleb","Bernd Amann","Hubert Naacke","Rafael Angarita"],"url":"https://arxiv.org/abs/2505.21329"}
{"created":"2025-05-29","title":"HoliTom: Holistic Token Merging for Fast Video Large Language Models","abstract":"Video large language models (video LLMs) excel at video comprehension but face significant computational inefficiency due to redundant video tokens. Existing token pruning methods offer solutions. However, approaches operating within the LLM (inner-LLM pruning), such as FastV, incur intrinsic computational overhead in shallow layers. In contrast, methods performing token pruning before the LLM (outer-LLM pruning) primarily address spatial redundancy within individual frames or limited temporal windows, neglecting the crucial global temporal dynamics and correlations across longer video sequences. This leads to sub-optimal spatio-temporal reduction and does not leverage video compressibility fully. Crucially, the synergistic potential and mutual influence of combining these strategies remain unexplored. To further reduce redundancy, we introduce HoliTom, a novel training-free holistic token merging framework. HoliTom employs outer-LLM pruning through global redundancy-aware temporal segmentation, followed by spatial-temporal merging to reduce visual tokens by over 90%, significantly alleviating the LLM's computational burden. Complementing this, we introduce a robust inner-LLM token similarity-based merging approach, designed for superior performance and compatibility with outer-LLM pruning. Evaluations demonstrate our method's promising efficiency-performance trade-off on LLaVA-OneVision-7B, reducing computational costs to 6.9% of FLOPs while maintaining 99.1% of the original performance. Furthermore, we achieve a 2.28x reduction in Time-To-First-Token (TTFT) and a 1.32x acceleration in decoding throughput, highlighting the practical benefits of our integrated pruning approach for efficient video LLMs inference.","authors":["Kele Shao","Keda Tao","Can Qin","Haoxuan You","Yang Sui","Huan Wang"],"url":"https://arxiv.org/abs/2505.21334"}
{"created":"2025-05-29","title":"PEDANTIC: A Dataset for the Automatic Examination of Definiteness in Patent Claims","abstract":"Patent claims define the scope of protection for an invention. If there are ambiguities in a claim, it is rejected by the patent office. In the US, this is referred to as indefiniteness (35 U.S.C {\\S} 112(b)) and is among the most frequent reasons for patent application rejection. The development of automatic methods for patent definiteness examination has the potential to make patent drafting and examination more efficient, but no annotated dataset has been published to date. We introduce PEDANTIC (Patent Definiteness Examination Corpus), a novel dataset of 14k US patent claims from patent applications relating to Natural Language Processing (NLP), annotated with reasons for indefiniteness. We construct PEDANTIC using a fully automatic pipeline that retrieves office action documents from the USPTO and uses Large Language Models (LLMs) to extract the reasons for indefiniteness. A human validation study confirms the pipeline's accuracy in generating high-quality annotations. To gain insight beyond binary classification metrics, we implement an LLM-as-Judge evaluation that compares the free-form reasoning of every model-cited reason with every examiner-cited reason. We show that LLM agents based on Qwen 2.5 32B and 72B struggle to outperform logistic regression baselines on definiteness prediction, even though they often correctly identify the underlying reasons. PEDANTIC provides a valuable resource for patent AI researchers, enabling the development of advanced examination models. We will publicly release the dataset and code.","authors":["Valentin Knappich","Annemarie Friedrich","Anna H\\\"atty","Simon Razniewski"],"url":"https://arxiv.org/abs/2505.21342"}
{"created":"2025-05-29","title":"OVERT: A Benchmark for Over-Refusal Evaluation on Text-to-Image Models","abstract":"Text-to-Image (T2I) models have achieved remarkable success in generating visual content from text inputs. Although multiple safety alignment strategies have been proposed to prevent harmful outputs, they often lead to overly cautious behavior -- rejecting even benign prompts -- a phenomenon known as $\\textit{over-refusal}$ that reduces the practical utility of T2I models. Despite over-refusal having been observed in practice, there is no large-scale benchmark that systematically evaluates this phenomenon for T2I models. In this paper, we present an automatic workflow to construct synthetic evaluation data, resulting in OVERT ($\\textbf{OVE}$r-$\\textbf{R}$efusal evaluation on $\\textbf{T}$ext-to-image models), the first large-scale benchmark for assessing over-refusal behaviors in T2I models. OVERT includes 4,600 seemingly harmful but benign prompts across nine safety-related categories, along with 1,785 genuinely harmful prompts (OVERT-unsafe) to evaluate the safety-utility trade-off. Using OVERT, we evaluate several leading T2I models and find that over-refusal is a widespread issue across various categories (Figure 1), underscoring the need for further research to enhance the safety alignment of T2I models without compromising their functionality. As a preliminary attempt to reduce over-refusal, we explore prompt rewriting; however, we find it often compromises faithfulness to the meaning of the original prompts. Finally, we demonstrate the flexibility of our generation framework in accommodating diverse safety requirements by generating customized evaluation data adapting to user-defined policies.","authors":["Ziheng Cheng","Yixiao Huang","Hui Xu","Somayeh Sojoudi","Xuandong Zhao","Dawn Song","Song Mei"],"url":"https://arxiv.org/abs/2505.21347"}
{"created":"2025-05-29","title":"Towards Robust Automated Perceptual Voice Quality Assessment with Speech Foundation Models","abstract":"Perceptual voice quality assessment is essential for diagnosing and monitoring voice disorders. Traditionally, expert raters use scales such as the CAPE-V and GRBAS. However, these are subjective and prone to inter-rater variability, motivating the need for automated, objective assessment methods. This study proposes VOQANet, a deep learning framework with an attention mechanism that leverages a Speech Foundation Model (SFM) to extract high-level acoustic and prosodic information from raw speech. To improve robustness and interpretability, we introduce VOQANet+, which integrates handcrafted acoustic features such as jitter, shimmer, and harmonics-to-noise ratio (HNR) with SFM embeddings into a hybrid representation. Unlike prior work focusing only on vowel-based phonation (PVQD-A subset) from the Perceptual Voice Quality Dataset (PVQD), we evaluate our models on both vowel-based and sentence-level speech (PVQD-S subset) for better generalizability. Results show that sentence-based input outperforms vowel-based input, particularly at the patient level, highlighting the benefit of longer utterances for capturing voice attributes. VOQANet consistently surpasses baseline methods in root mean squared error and Pearson correlation across CAPE-V and GRBAS dimensions, with VOQANet+ achieving further improvements. Additional tests under noisy conditions show that VOQANet+ maintains high prediction accuracy, supporting its use in real-world and telehealth settings. These findings demonstrate the value of combining SFM embeddings with domain-informed acoustic features for interpretable and robust voice quality assessment.","authors":["Whenty Ariyanti","Kuan-Yu Chen","Sabato Marco Siniscalchi","Hsin-Min Wang","Yu Tsao"],"url":"https://arxiv.org/abs/2505.21356"}
{"created":"2025-05-29","title":"AgriFM: A Multi-source Temporal Remote Sensing Foundation Model for Crop Mapping","abstract":"Accurate crop mapping fundamentally relies on modeling multi-scale spatiotemporal patterns, where spatial scales range from individual field textures to landscape-level context, and temporal scales capture both short-term phenological transitions and full growing-season dynamics. Transformer-based remote sensing foundation models (RSFMs) offer promising potential for crop mapping due to their innate ability for unified spatiotemporal processing. However, current RSFMs remain suboptimal for crop mapping: they either employ fixed spatiotemporal windows that ignore the multi-scale nature of crop systems or completely disregard temporal information by focusing solely on spatial patterns. To bridge these gaps, we present AgriFM, a multi-source remote sensing foundation model specifically designed for agricultural crop mapping. Our approach begins by establishing the necessity of simultaneous hierarchical spatiotemporal feature extraction, leading to the development of a modified Video Swin Transformer architecture where temporal down-sampling is synchronized with spatial scaling operations. This modified backbone enables efficient unified processing of long time-series satellite inputs. AgriFM leverages temporally rich data streams from three satellite sources including MODIS, Landsat-8/9 and Sentinel-2, and is pre-trained on a global representative dataset comprising over 25 million image samples supervised by land cover products. The resulting framework incorporates a versatile decoder architecture that dynamically fuses these learned spatiotemporal representations, supporting diverse downstream tasks. Comprehensive evaluations demonstrate AgriFM's superior performance over conventional deep learning approaches and state-of-the-art general-purpose RSFMs across all downstream tasks. Codes will be available at https://github.com/flyakon/AgriFM.","authors":["Wenyuan Li","Shunlin Liang","Keyan Chen","Yongzhe Chen","Han Ma","Jianglei Xu","Yichuan Ma","Shikang Guan","Husheng Fang","Zhenwei Shi"],"url":"https://arxiv.org/abs/2505.21357"}
{"created":"2025-05-29","title":"Pangu Pro MoE: Mixture of Grouped Experts for Efficient Sparsity","abstract":"The surgence of Mixture of Experts (MoE) in Large Language Models promises a small price of execution cost for a much larger model parameter count and learning capacity, because only a small fraction of parameters are activated for each input token. However, it is commonly observed that some experts are activated far more often than others, leading to system inefficiency when running the experts on different devices in parallel. Therefore, we introduce Mixture of Grouped Experts (MoGE), which groups the experts during selection and balances the expert workload better than MoE in nature. It constrains tokens to activate an equal number of experts within each predefined expert group. When a model execution is distributed on multiple devices, this architectural design ensures a balanced computational load across devices, significantly enhancing throughput, particularly for the inference phase. Further, we build Pangu Pro MoE on Ascend NPUs, a sparse model based on MoGE with 72 billion total parameters, 16 billion of which are activated for each token. The configuration of Pangu Pro MoE is optimized for Ascend 300I Duo and 800I A2 through extensive system simulation studies. Our experiments indicate that MoGE indeed leads to better expert load balancing and more efficient execution for both model training and inference on Ascend NPUs. The inference performance of Pangu Pro MoE achieves 1148 tokens/s per card and can be further improved to 1528 tokens/s per card by speculative acceleration, outperforming comparable 32B and 72B Dense models. Furthermore, we achieve an excellent cost-to-performance ratio for model inference on Ascend 300I Duo. Our studies show that Ascend NPUs are capable of training Pangu Pro MoE with massive parallelization to make it a leading model within the sub-100B total parameter class, outperforming prominent open-source models like GLM-Z1-32B and Qwen3-32B.","authors":["Yehui Tang (and Other Contributors)","Xiaosong Li (and Other Contributors)","Fangcheng Liu (and Other Contributors)","Wei Guo (and Other Contributors)","Hang Zhou (and Other Contributors)","Yaoyuan Wang (and Other Contributors)","Kai Han (and Other Contributors)","Xianzhi Yu (and Other Contributors)","Jinpeng Li (and Other Contributors)","Hui Zang (and Other Contributors)","Fei Mi (and Other Contributors)","Xiaojun Meng (and Other Contributors)","Zhicheng Liu (and Other Contributors)","Hanting Chen (and Other Contributors)","Binfan Zheng (and Other Contributors)","Can Chen (and Other Contributors)","Youliang Yan (and Other Contributors)","Ruiming Tang (and Other Contributors)","Peifeng Qin (and Other Contributors)","Xinghao Chen (and Other Contributors)","Dacheng Tao (and Other Contributors)","Yunhe Wang (and Other Contributors)"],"url":"https://arxiv.org/abs/2505.21411"}
{"created":"2025-05-29","title":"Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs","abstract":"Today's cloud-hosted applications and services are complex systems, and a performance or functional instability can have dozens or hundreds of potential root causes. Our hypothesis is that by combining the pattern matching capabilities of modern AI tools with a natural multi-modal RAG LLM interface, problem identification and resolution can be simplified. ARCA is a new multi-modal RAG LLM system that targets this domain. Step-wise evaluations show that ARCA outperforms state-of-the-art alternatives.","authors":["Yifan Wang","Kenneth P. Birman"],"url":"https://arxiv.org/abs/2505.21419"}
{"created":"2025-05-29","title":"Optimal Approximations for the Requirement Cut Problem on Sparse Graph Classes","abstract":"We study the Requirement Cut problem, a generalization of numerous classical graph partitioning problems including Multicut, Multiway Cut, $k$-Cut, and Steiner Multicut among others. Given a graph with edge costs, terminal groups $(S_1, ..., S_g)$ and integer requirements $(r_1,... , r_g)$; the goal is to compute a minimum-cost edge cut that separates each group $S_i$ into at least $r_i$ connected components. Despite many efforts, the best known approximation for Requirement Cut yields a double-logarithmic $O(\\log(g).\\log(n))$ approximation ratio as it relies on embedding general graphs into trees and solving the tree instance.","authors":["Nadym Mallek","Kirill Simonov"],"url":"https://arxiv.org/abs/2505.21433"}
{"created":"2025-05-29","title":"Quantum Monte Carlo algorithm for solving Black-Scholes PDEs for high-dimensional option pricing in finance and its complexity analysis","abstract":"In this paper we provide a quantum Monte Carlo algorithm to solve high-dimensional Black-Scholes PDEs with correlation for high-dimensional option pricing. The payoff function of the option is of general form and is only required to be continuous and piece-wise affine (CPWA), which covers most of the relevant payoff functions used in finance. We provide a rigorous error analysis and complexity analysis of our algorithm. In particular, we prove that the computational complexity of our algorithm is bounded polynomially in the space dimension $d$ of the PDE and the reciprocal of the prescribed accuracy $\\varepsilon$. Moreover, we show that for payoff functions which are bounded, our algorithm indeed has a speed-up compared to classical Monte Carlo methods. Furthermore, we provide numerical simulations in one and two dimensions using our developed package within the Qiskit framework tailored to price CPWA options with respect to the Black-Scholes model, as well as discuss the potential extension of the numerical simulations to arbitrary space dimension.","authors":["Jianjun Chen","Yongming Li","Ariel Neufeld"],"url":"https://arxiv.org/abs/2301.09241"}
{"created":"2025-05-29","title":"Learned Collusion","abstract":"Q-learning can be described as an all-purpose automaton that provides estimates (Q-values) of the continuation values associated with each available action and follows the naive policy of almost always choosing the action with highest Q-value. We consider a family of automata based on Q-values, whose policy may systematically favor some actions over others, for example through a bias that favors cooperation. We look for stable equilibrium biases, easily learned under converging logit/best-response dynamics over biases, not requiring any tacit agreement. These biases strongly foster collusion or cooperation across a rich array of payoff and monitoring structures, independently of initial Q-values.","authors":["Olivier Compte (Paris School of Economics)"],"url":"https://arxiv.org/abs/2304.12647"}
{"created":"2025-05-29","title":"Structurally Different Neural Network Blocks for the Segmentation of Atrial and Aortic Perivascular Adipose Tissue in Multi-centre CT Angiography Scans","abstract":"Since the emergence of convolutional neural networks (CNNs) and, later, vision transformers (ViTs), deep learning architectures have predominantly relied on identical block types with varying hyperparameters. We propose a novel block alternation strategy to leverage the complementary strengths of different architectural designs, assembling structurally distinct components similar to Lego blocks. We introduce LegoNet, a deep learning framework that alternates CNN-based and SwinViT-based blocks to enhance feature learning for medical image segmentation. We investigate three variations of LegoNet and apply this concept to a previously unexplored clinical problem: the segmentation of the internal mammary artery (IMA), aorta, and perivascular adipose tissue (PVAT) from computed tomography angiography (CTA) scans. These PVAT regions have been shown to possess prognostic value in assessing cardiovascular risk and primary clinical outcomes. We evaluate LegoNet on large datasets, achieving superior performance to other leading architectures. Furthermore, we assess the model's generalizability on external testing cohorts, where an expert clinician corrects the model's segmentations, achieving DSC > 0.90 across various external, international, and public cohorts. To further validate the model's clinical reliability, we perform intra- and inter-observer variability analysis, demonstrating strong agreement with human annotations. The proposed methodology has significant implications for diagnostic cardiovascular management and early prognosis, offering a robust, automated solution for vascular and perivascular segmentation and risk assessment in clinical practice, paving the way for personalised medicine.","authors":["Ikboljon Sobirov","Cheng Xie","Muhammad Siddique","Parijat Patel","Kenneth Chan","Thomas Halborg","Christos P. Kotanidis","Zarqaish Fatima","Henry West","Sheena Thomas","Maria Lyasheva","Donna Alexander","David Adlam","Praveen Rao","Das Indrajeet","Aparna Deshpande","Amrita Bajaj","Jonathan C L Rodrigues","Benjamin J Hudson","Vivek Srivastava","George Krasopoulos","Rana Sayeed","Qiang Zhang","Pete Tomlins","Cheerag Shirodaria","Keith M. Channon","Stefan Neubauer","Charalambos Antoniades","Mohammad Yaqub"],"url":"https://arxiv.org/abs/2306.03494"}
{"created":"2025-05-29","title":"Pseudorandom unitaries are neither real nor sparse nor noise-robust","abstract":"Pseudorandom quantum states (PRSs) and pseudorandom unitaries (PRUs) possess the dual nature of being efficiently constructible while appearing completely random to any efficient quantum algorithm. In this study, we establish fundamental bounds on pseudorandomness. We show that PRSs and PRUs exist only when the probability that an error occurs is negligible, ruling out their generation on noisy intermediate-scale and early fault-tolerant quantum computers. Further, we show that PRUs need imaginarity while PRS do not have this restriction. This implies that quantum randomness requires in general a complex-valued formalism of quantum mechanics, while for random quantum states real numbers suffice. Additionally, we derive lower bounds on the coherence of PRSs and PRUs, ruling out the existence of sparse PRUs and PRSs. We also show that the notions of PRS, PRUs and pseudorandom scramblers (PRSSs) are distinct in terms of resource requirements. We introduce the concept of pseudoresources, where states which contain a low amount of a given resource masquerade as high-resource states. We define pseudocoherence, pseudopurity and pseudoimaginarity, and identify three distinct types of pseudoresources in terms of their masquerading capabilities. Our work also establishes rigorous bounds on the efficiency of property testing, demonstrating the exponential complexity in distinguishing real quantum states from imaginary ones, in contrast to the efficient measurability of unitary imaginarity. Further, we show an exponential advantage in imaginarity testing when having access to the complex conjugate of the state. Lastly, we show that the transformation from a complex to a real model of quantum computation is inefficient, in contrast to the reverse process, which is efficient. Our results establish fundamental limits on property testing and provide valuable insights into quantum pseudorandomness.","authors":["Tobias Haug","Kishor Bharti","Dax Enshan Koh"],"url":"https://arxiv.org/abs/2306.11677"}
{"created":"2025-05-29","title":"Improving the Variance of Differentially Private Randomized Experiments through Clustering","abstract":"Estimating causal effects from randomized experiments is only possible if participants are willing to disclose their potentially sensitive responses. Differential privacy, a widely used framework for ensuring an algorithms privacy guarantees, can encourage participants to share their responses without the risk of de-anonymization. However, many mechanisms achieve differential privacy by adding noise to the original dataset, which reduces the precision of causal effect estimation. This introduces a fundamental trade-off between privacy and variance when performing causal analyses on differentially private data. In this work, we propose a new differentially private mechanism, \"Cluster-DP\", which leverages a given cluster structure in the data to improve the privacy-variance trade-off. While our results apply to any clustering, we demonstrate that selecting higher-quality clusters, according to a quality metric we introduce, can decrease the variance penalty without compromising privacy guarantees. Finally, we evaluate the theoretical and empirical performance of our Cluster-DP algorithm on both real and simulated data, comparing it to common baselines, including two special cases of our algorithm: its unclustered version and a uniform-prior version.","authors":["Adel Javanmard","Vahab Mirrokni","Jean Pouget-Abadie"],"url":"https://arxiv.org/abs/2308.00957"}
{"created":"2025-05-29","title":"MOSformer: Momentum encoder-based inter-slice fusion transformer for medical image segmentation","abstract":"Medical image segmentation takes an important position in various clinical applications. 2.5D-based segmentation models bridge the computational efficiency of 2D-based models with the spatial perception capabilities of 3D-based models. However, existing 2.5D-based models primarily adopt a single encoder to extract features of target and neighborhood slices, failing to effectively fuse inter-slice information, resulting in suboptimal segmentation performance. In this study, a novel momentum encoder-based inter-slice fusion transformer (MOSformer) is proposed to overcome this issue by leveraging inter-slice information at multi-scale feature maps extracted by different encoders. Specifically, dual encoders are employed to enhance feature distinguishability among different slices. One of the encoders is moving-averaged to maintain consistent slice representations. Moreover, an inter-slice fusion transformer (IF-Trans) module is developed to fuse inter-slice multi-scale features. The MOSformer is evaluated on three benchmark datasets (Synapse, ACDC, and AMOS), achieving a new state-of-the-art with 85.63%, 92.19%, and 85.43% DSC, respectively. These results demonstrate MOSformer's competitiveness in medical image segmentation.","authors":["De-Xing Huang","Xiao-Hu Zhou","Mei-Jiang Gui","Xiao-Liang Xie","Shi-Qi Liu","Shuang-Yi Wang","Zhen-Qiu Feng","Zeng-Guang Hou"],"url":"https://arxiv.org/abs/2401.11856"}
{"created":"2025-05-29","title":"Decision-Focused Forecasting: A Differentiable Multistage Optimisation Architecture","abstract":"Most decision-focused learning work has focused on single stage problems whereas many real-world decision problems are more appropriately modelled using multistage optimisation. In multistage problems contextual information is revealed over time, decisions have to be taken sequentially, and decisions now have an intertemporal effect on future decisions. Decision-focused forecasting is a recurrent differentiable optimisation architecture that expresses a fully differentiable multistage optimisation approach. This architecture enables us to account for the intertemporal decision effects of forecasts. We show what gradient adjustments are made to account for the state-path caused by forecasting. We apply the model to multistage problems in energy storage arbitrage and portfolio optimisation and report that our model outperforms existing approaches.","authors":["Egon Per\\v{s}ak","Miguel F. Anjos"],"url":"https://arxiv.org/abs/2405.14719"}
{"created":"2025-05-29","title":"SLoRD: Structural Low-Rank Descriptors for Shape Consistency in Vertebrae Segmentation","abstract":"Automatic and precise multi-class vertebrae segmentation from CT images is crucial for various clinical applications. However, due to similar appearances between adjacent vertebrae and the existence of various pathologies, existing single-stage and multi-stage methods suffer from imprecise vertebrae segmentation. Essentially, these methods fail to explicitly impose both contour precision and intra-vertebrae voxel consistency constraints synchronously, resulting in the intra-vertebrae segmentation inconsistency, which refers to multiple label predictions inside a singular vertebra. In this work, we intend to label complete binary masks with sequential indices to address that challenge. Specifically, a contour generation network is proposed based on Structural Low-Rank Descriptors for shape consistency, termed SLoRD. For a structural representation of vertebral contours, we adopt the spherical coordinate system and devise the spherical centroid to calculate contour descriptors. Due to vertebrae's similar appearances, basic contour descriptors can be acquired offline to restore original contours. Therefore, SLoRD leverages these contour priors and explicit shape constraints to facilitate regressed contour points close to vertebral surfaces. Quantitative and qualitative evaluations on VerSe 2019 and 2020 demonstrate the superior performance of our framework over other single-stage and multi-stage state-of-the-art (SOTA) methods. Further, SLoRD is a plug-and-play framework to refine the segmentation inconsistency existing in coarse predictions from other approaches. Source codes are available.","authors":["Xin You","Yixin Lou","Minghui Zhang","Jie Yang","Yun Gu"],"url":"https://arxiv.org/abs/2407.08555"}
{"created":"2025-05-29","title":"Infinite-dimensional Mahalanobis Distance with Applications to Kernelized Novelty Detection","abstract":"The Mahalanobis distance is a classical tool used to measure the covariance-adjusted distance between points in $\\bbR^d$. In this work, we extend the concept of Mahalanobis distance to separable Banach spaces by reinterpreting it as a Cameron-Martin norm associated with a probability measure. This approach leads to a basis-free, data-driven notion of anomaly distance through the so-called variance norm, which can naturally be estimated using empirical measures of a sample. Our framework generalizes the classical $\\bbR^d$, functional $(L^2[0,1])^d$, and kernelized settings; importantly, it incorporates non-injective covariance operators. We prove that the variance norm is invariant under invertible bounded linear transformations of the data, extending previous results which are limited to unitary operators. In the Hilbert space setting, we connect the variance norm to the RKHS of the covariance operator and establish consistency and convergence results for estimation using empirical measures. Using the variance norm, we introduce the notion of a kernelized nearest-neighbour Mahalanobis distance. In an empirical study on 12 real-world data sets, we demonstrate that the kernelized nearest-neighbour Mahalanobis distance outperforms the traditional kernelized Mahalanobis distance for multivariate time series novelty detection, using state-of-the-art time series kernels such as the signature, global alignment, and Volterra reservoir kernels.","authors":["Nikita Zozoulenko","Thomas Cass","Lukas Gonon"],"url":"https://arxiv.org/abs/2407.11873"}
{"created":"2025-05-29","title":"VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing","abstract":"Deep learning has brought significant improvements to the field of cross-modal representation learning. For tasks such as text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), a cross-modal fine-grained (frame-level) sequence representation is desired, emphasizing the semantic content of the text modality while de-emphasizing the paralinguistic information of the speech modality. We propose a method called \"Vector Quantized Contrastive Token-Acoustic Pre-training (VQ-CTAP)\", which uses the cross-modal aligned sequence transcoder to bring text and speech into a joint multimodal space, learning how to connect text and speech at the frame level. The proposed VQ-CTAP is a paradigm for cross-modal sequence representation learning, offering a promising solution for fine-grained generation and recognition tasks in speech processing. The VQ-CTAP can be directly applied to VC and ASR tasks without fine-tuning or additional structures. We propose a sequence-aware semantic connector, which connects multiple frozen pre-trained modules for the TTS task, exhibiting a plug-and-play capability. We design a stepping optimization strategy to ensure effective model convergence by gradually injecting and adjusting the influence of various loss components. Furthermore, we propose a semantic-transfer-wise paralinguistic consistency loss to enhance representational capabilities, allowing the model to better generalize to unseen data and capture the nuances of paralinguistic information. In addition, VQ-CTAP achieves high-compression speech coding at a rate of 25Hz from 24kHz input waveforms, which is a 960-fold reduction in the sampling rate. The audio demo is available at https://qiangchunyu.github.io/VQCTAP/","authors":["Chunyu Qiang","Wang Geng","Yi Zhao","Ruibo Fu","Tao Wang","Cheng Gong","Tianrui Wang","Qiuyu Liu","Jiangyan Yi","Zhengqi Wen","Chen Zhang","Hao Che","Longbiao Wang","Jianwu Dang","Jianhua Tao"],"url":"https://arxiv.org/abs/2408.05758"}
{"created":"2025-05-29","title":"Submonoid Membership in n-dimensional lamplighter groups and S-unit equations","abstract":"We show that Submonoid Membership is decidable in n-dimensional lamplighter groups $(\\mathbb{Z}/p\\mathbb{Z}) \\wr \\mathbb{Z}^n$ for any prime $p$ and integer $n$. More generally, we show decidability of Submonoid Membership in semidirect products of the form $\\mathcal{Y} \\rtimes \\mathbb{Z}^n$, where $\\mathcal{Y}$ is any finitely presented module over the Laurent polynomial ring $\\mathbb{F}_p[X_1^{\\pm}, \\ldots, X_n^{\\pm}]$. Combined with a result of Shafrir (2024), this gives the first example of a group $G$ and a finite index subgroup $\\widetilde{G} \\leq G$, such that Submonoid Membership is decidable in $\\widetilde{G}$ but undecidable in $G$.","authors":["Ruiwen Dong"],"url":"https://arxiv.org/abs/2409.07077"}
{"created":"2025-05-29","title":"Topological Eigenvalue Theorems for Tensor Analysis in Multi-Modal Data Fusion","abstract":"This paper presents a novel framework for tensor eigenvalue analysis in the context of multi-modal data fusion, leveraging topological invariants such as Betti numbers. Traditional approaches to tensor eigenvalue analysis often extend matrix theory, whereas this work introduces a topological perspective to enhance the understanding of tensor structures. By establishing new theorems that link eigenvalues to topological features, the proposed framework provides deeper insights into the latent structure of data, improving both interpretability and robustness. Applications in data fusion demonstrate the theoretical and practical significance of this approach, with potential for broad impact in machine learning and data science.","authors":["Ronald Katende"],"url":"https://arxiv.org/abs/2409.09392"}
{"created":"2025-05-29","title":"A Plug-and-Play Method for Guided Multi-contrast MRI Reconstruction based on Content/Style Modeling","abstract":"Since multiple MRI contrasts of the same anatomy contain redundant information, one contrast can guide the reconstruction of an undersampled subsequent contrast. To this end, several end-to-end learning-based guided reconstruction methods have been proposed. However, a key challenge is the requirement of large paired training datasets comprising raw data and aligned reference images. We propose a modular two-stage approach addressing this issue, additionally providing an explanatory framework for the multi-contrast problem based on the shared and non-shared generative factors underlying two given contrasts. A content/style model of two-contrast image data is learned from a largely unpaired image-domain dataset and is subsequently applied as a plug-and-play operator in iterative reconstruction. The disentanglement of content and style allows explicit representation of contrast-independent and contrast-specific factors. Consequently, incorporating prior information into the reconstruction reduces to a simple replacement of the aliased content of the reconstruction iterate with high-quality content derived from the reference scan. Combining this component with a data consistency step and introducing a general corrective process for the content yields an iterative scheme. We name this novel approach PnP-CoSMo. Various aspects like interpretability and convergence are explored via simulations. Furthermore, its practicality is demonstrated on the NYU fastMRI DICOM dataset, showing improved generalizability compared to end-to-end methods, and on two in-house multi-coil raw datasets, offering up to 32.6% more acceleration over learning-based non-guided reconstruction for a given SSIM. In a small radiological task, PnP-CoSMo allowed 33.3% more acceleration over clinical reconstruction at diagnostic quality.","authors":["Chinmay Rao","Matthias van Osch","Nicola Pezzotti","Jeroen de Bresser","Laurens Beljaards","Jakob Meineke","Elwin de Weerdt","Huangling Lu","Mariya Doneva","Marius Staring"],"url":"https://arxiv.org/abs/2409.13477"}
{"created":"2025-05-29","title":"On the Within-class Variation Issue in Alzheimer's Disease Detection","abstract":"Alzheimer's Disease (AD) detection employs machine learning classification models to distinguish between individuals with AD and those without. Different from conventional classification tasks, we identify within-class variation as a critical challenge in AD detection: individuals with AD exhibit a spectrum of cognitive impairments. Therefore, simplistic binary AD classification may overlook two crucial aspects: within-class heterogeneity and instance-level imbalance. In this work, we found using a sample score estimator can generate sample-specific soft scores aligning with cognitive scores. We subsequently propose two simple yet effective methods: Soft Target Distillation (SoTD) and Instance-level Re-balancing (InRe), targeting two problems respectively. Based on the ADReSS and CU-MARVEL corpora, we demonstrated and analyzed the advantages of the proposed approaches in detection performance. These findings provide insights for developing robust and reliable AD detection models.","authors":["Jiawen Kang","Dongrui Han","Lingwei Meng","Jingyan Zhou","Jinchao Li","Xixin Wu","Helen Meng"],"url":"https://arxiv.org/abs/2409.16322"}
{"created":"2025-05-29","title":"Gibbs state preparation for commuting Hamiltonian: Mapping to classical Gibbs sampling","abstract":"Gibbs state preparation, or Gibbs sampling, is a key computational technique extensively used in physics, statistics, and other scientific fields. Recent efforts for designing fast mixing Gibbs samplers for quantum Hamiltonians have largely focused on commuting local Hamiltonians (CLHs), a non-trivial subclass of Hamiltonians which include highly entangled systems such as the Toric code and quantum double model. Most previous Gibbs samplers relied on simulating the Davies generator, which is a Lindbladian associated with the thermalization process in nature.","authors":["Yeongwoo Hwang","Jiaqing Jiang"],"url":"https://arxiv.org/abs/2410.04909"}
{"created":"2025-05-29","title":"Privacy for Free in the Overparameterized Regime","abstract":"Differentially private gradient descent (DP-GD) is a popular algorithm to train deep learning models with provable guarantees on the privacy of the training data. In the last decade, the problem of understanding its performance cost with respect to standard GD has received remarkable attention from the research community, which formally derived upper bounds on the excess population risk $R_{P}$ in different learning settings. However, existing bounds typically degrade with over-parameterization, i.e., as the number of parameters $p$ gets larger than the number of training samples $n$ -- a regime which is ubiquitous in current deep-learning practice. As a result, the lack of theoretical insights leaves practitioners without clear guidance, leading some to reduce the effective number of trainable parameters to improve performance, while others use larger models to achieve better results through scale. In this work, we show that in the popular random features model with quadratic loss, for any sufficiently large $p$, privacy can be obtained for free, i.e., $\\left|R_{P} \\right| = o(1)$, not only when the privacy parameter $\\varepsilon$ has constant order, but also in the strongly private setting $\\varepsilon = o(1)$. This challenges the common wisdom that over-parameterization inherently hinders performance in private learning.","authors":["Simone Bombari","Marco Mondelli"],"url":"https://arxiv.org/abs/2410.14787"}
{"created":"2025-05-29","title":"Simultaneously Solving FBSDEs and their Associated Semilinear Elliptic PDEs with Small Neural Operators","abstract":"Forward-backwards stochastic differential equations (FBSDEs) play an important role in optimal control, game theory, economics, mathematical finance, and in reinforcement learning. Unfortunately, the available FBSDE solvers operate on \\textit{individual} FBSDEs, meaning that they cannot provide a computationally feasible strategy for solving large families of FBSDEs, as these solvers must be re-run several times. \\textit{Neural operators} (NOs) offer an alternative approach for \\textit{simultaneously solving} large families of decoupled FBSDEs by directly approximating the solution operator mapping \\textit{inputs:} terminal conditions and dynamics of the backwards process to \\textit{outputs:} solutions to the associated FBSDE. Though universal approximation theorems (UATs) guarantee the existence of such NOs, these NOs are unrealistically large. Upon making only a few simple theoretically-guided tweaks to the standard convolutional NO build, we confirm that ``small'' NOs can uniformly approximate the solution operator to structured families of FBSDEs with random terminal time, uniformly on suitable compact sets determined by Sobolev norms using a logarithmic depth, a constant width, and a polynomial rank in the reciprocal approximation error.","authors":["Takashi Furuya","Anastasis Kratsios"],"url":"https://arxiv.org/abs/2410.14788"}
{"created":"2025-05-29","title":"A Novel Characterization of the Population Area Under the Risk Coverage Curve (AURC) and Rates of Finite Sample Estimators","abstract":"The selective classifier (SC) has been proposed for rank based uncertainty thresholding, which could have applications in safety critical areas such as medical diagnostics, autonomous driving, and the justice system. The Area Under the Risk-Coverage Curve (AURC) has emerged as the foremost evaluation metric for assessing the performance of SC systems. In this work, we present a formal statistical formulation of population AURC, presenting an equivalent expression that can be interpreted as a reweighted risk function. Through Monte Carlo methods, we derive empirical AURC plug-in estimators for finite sample scenarios. The weight estimators associated with these plug-in estimators are shown to be consistent, with low bias and tightly bounded mean squared error (MSE). The plug-in estimators are proven to converge at a rate of $\\mathcal{O}(\\sqrt{\\ln(n)/n})$ demonstrating statistical consistency. We empirically validate the effectiveness of our estimators through experiments across multiple datasets, model architectures, and confidence score functions (CSFs), demonstrating consistency and effectiveness in fine-tuning AURC performance.","authors":["Han Zhou","Jordy Van Landeghem","Teodora Popordanoska","Matthew B. Blaschko"],"url":"https://arxiv.org/abs/2410.15361"}
{"created":"2025-05-29","title":"Statistical Inference for Temporal Difference Learning with Linear Function Approximation","abstract":"We investigate the statistical properties of Temporal Difference (TD) learning with Polyak-Ruppert averaging, arguably one of the most widely used algorithms in reinforcement learning, for the task of estimating the parameters of the optimal linear approximation to the value function. We make three significant contributions that improve the current state-of-the-art results: (i) we derive sharper high probability convergence guarantee that depend explicitly on the asymptotic variance and hold under weaker conditions than those normally assumed; (ii) we establish refined high-dimensional Berry-Esseen bounds over the class of convex sets, achieving faster rates than those previously established in the literature, and (iii) we propose and analyze a novel, computationally efficient online plug-in estimator of the asymptotic covariance matrix.These results enable the construction of confidence regions and simultaneous confidence intervals for the linear parameters of the value function approximation, with guaranteed finite-sample coverage. We demonstrate the applicability of our theoretical findings through numerical experiments.","authors":["Weichen Wu","Gen Li","Yuting Wei","Alessandro Rinaldo"],"url":"https://arxiv.org/abs/2410.16106"}
{"created":"2025-05-29","title":"Universal Approximation of Mean-Field Models via Transformers","abstract":"This paper investigates the use of transformers to approximate the mean-field dynamics of interacting particle systems exhibiting collective behavior. Such systems are fundamental in modeling phenomena across physics, biology, and engineering, including opinion formation, biological networks, and swarm robotics. The key characteristic of these systems is that the particles are indistinguishable, leading to permutation-equivariant dynamics. First, we empirically demonstrate that transformers are well-suited for approximating a variety of mean field models, including the Cucker-Smale model for flocking and milling, and the mean-field system for training two-layer neural networks. We validate our numerical experiments via mathematical theory. Specifically, we prove that if a finite-dimensional transformer effectively approximates the finite-dimensional vector field governing the particle system, then the $L_2$ distance between the \\textit{expected transformer} and the infinite-dimensional mean-field vector field can be uniformly bounded by a function of the number of particles observed during training. Leveraging this result, we establish theoretical bounds on the distance between the true mean-field dynamics and those obtained using the transformer.","authors":["Shiba Biswal","Karthik Elamvazhuthi","Rishi Sonthalia"],"url":"https://arxiv.org/abs/2410.16295"}
{"created":"2025-05-29","title":"A Stochastic Approximation Approach for Efficient Decentralized Optimization on Random Networks","abstract":"A challenging problem in decentralized optimization is to develop algorithms with fast convergence on random and time varying topologies under unreliable and bandwidth-constrained communication network. This paper studies a stochastic approximation approach with a Fully Stochastic Primal Dual Algorithm (FSPDA) framework. Our framework relies on a novel observation that randomness in time varying topology can be incorporated in a stochastic augmented Lagrangian formulation, whose expected value admits saddle points that coincide with stationary solutions of the decentralized optimization problem. With the FSPDA framework, we develop two new algorithms supporting efficient sparsified communication on random time varying topologies -- FSPDA-SA allows agents to execute multiple local gradient steps depending on the time varying topology to accelerate convergence, and FSPDA-STORM further incorporates a variance reduction step to improve sample complexity. For problems with smooth (possibly non-convex) objective function, within $T$ iterations, we show that FSPDA-SA (resp. FSPDA-STORM) finds an $\\mathcal{O}( 1/\\sqrt{T} )$-stationary (resp. $\\mathcal{O}( 1/T^{2/3} )$) solution. Numerical experiments show the benefits of the FSPDA algorithms.","authors":["Chung-Yiu Yau","Haoming Liu","Hoi-To Wai"],"url":"https://arxiv.org/abs/2410.18774"}
{"created":"2025-05-29","title":"Space-bounded quantum interactive proof systems","abstract":"We introduce two models of space-bounded quantum interactive proof systems, ${\\sf QIPL}$ and ${\\sf QIP_{\\rm U}L}$. The ${\\sf QIP_{\\rm U}L}$ model, a space-bounded variant of quantum interactive proofs (${\\sf QIP}$) introduced by Watrous (CC 2003) and Kitaev and Watrous (STOC 2000), restricts verifier actions to unitary circuits. In contrast, ${\\sf QIPL}$ allows logarithmically many pinching intermediate measurements per verifier action, making it the weakest model that encompasses the classical model of Condon and Ladner (JCSS 1995).","authors":["Fran\\c{c}ois Le Gall","Yupan Liu","Harumichi Nishimura","Qisheng Wang"],"url":"https://arxiv.org/abs/2410.23958"}
{"created":"2025-05-29","title":"Improving precision of A/B experiments using trigger intensity","abstract":"In industry, online randomized controlled experiment (a.k.a. A/B experiment) is a standard approach to measure the impact of a causal change. These experiments have small treatment effect to reduce the potential blast radius. As a result, these experiments often lack statistical significance due to low signal-to-noise ratio. A standard approach for improving the precision (or reducing the standard error) focuses only on the trigger observations, where the output of the treatment and the control model are different. Although evaluation with full information about trigger observations (full knowledge) improves the precision, detecting all such trigger observations is a costly affair. In this paper, we propose a sampling based evaluation method (partial knowledge) to reduce this cost. The randomness of sampling introduces bias in the estimated outcome. We theoretically analyze this bias and show that the bias is inversely proportional to the number of observations used for sampling. We also compare the proposed evaluation methods using simulation and empirical data. In simulation, bias in evaluation with partial knowledge effectively reduces to zero when a limited number of observations (<= 0.1%) are sampled for trigger estimation. In empirical setup, evaluation with partial knowledge reduces the standard error by 36.48%.","authors":["Tanmoy Das","Dohyeon Lee","Arnab Sinha"],"url":"https://arxiv.org/abs/2411.03530"}
{"created":"2025-05-29","title":"Energy and polarization based on-line interference mitigation in radio interferometry","abstract":"Radio frequency interference (RFI) is a persistent contaminant in terrestrial radio astronomy. While new radio interferometers are becoming operational, novel sources of RFI are also emerging. In order to strengthen the mitigation of RFI in modern radio interferometers, we propose an on-line RFI mitigation scheme that can be run in the correlator of such interferometers. We combine statistics based on the energy as well as the polarization alignment of the correlated signal to develop an on-line RFI mitigation scheme that can be applied to a data stream produced by the correlator in real-time, especially targeted at low duty-cycle or transient RFI detection. In order to improve the computational efficiency, we explore the use of both single precision and half precision floating point operations in implementing the RFI mitigation algorithm. This ideally suits its deployment in accelerator computing devices such as graphics processing units (GPUs) as used by the LOFAR correlator. We provide results based on real data to demonstrate the efficacy of the proposed method.","authors":["Sarod Yatawatta","Albert-Jan Boonstra","Chris P. Broekema"],"url":"https://arxiv.org/abs/2412.14775"}
{"created":"2025-05-29","title":"Quantum framework for Reinforcement Learning: Integrating Markov decision process, quantum arithmetic, and trajectory search","abstract":"This paper introduces a quantum framework for addressing reinforcement learning (RL) tasks, grounded in the quantum principles and leveraging a fully quantum model of the classical Markov decision process (MDP). By employing quantum concepts and a quantum search algorithm, this work presents the implementation and optimization of the agent-environment interactions entirely within the quantum domain, eliminating reliance on classical computations. Key contributions include the quantum-based state transitions, return calculation, and trajectory search mechanism that utilize quantum principles to demonstrate the realization of RL processes through quantum phenomena. The implementation emphasizes the fundamental role of quantum superposition in enhancing computational efficiency for RL tasks. Results demonstrate the capacity of a quantum model to achieve quantum enhancement in RL, highlighting the potential of fully quantum implementations in decision-making tasks. This work not only underscores the applicability of quantum computing in machine learning but also contributes to the field of quantum reinforcement learning (QRL) by offering a robust framework for understanding and exploiting quantum computing in RL systems.","authors":["Thet Htar Su","Shaswot Shresthamali","Masaaki Kondo"],"url":"https://arxiv.org/abs/2412.18208"}
{"created":"2025-05-29","title":"Pilot-Quantum: A Quantum-HPC Middleware for Resource, Workload and Task Management","abstract":"As quantum hardware advances, integrating quantum processing units (QPUs) into HPC environments and managing diverse infrastructure and software stacks becomes increasingly essential. Pilot-Quantum addresses these challenges as a middleware designed to provide unified application-level management of resources and workloads across hybrid quantum-classical environments. It is built on a rigorous analysis of existing quantum middleware systems and application execution patterns. It implements the Pilot Abstraction conceptual model, originally developed for HPC, to manage resources, workloads, and tasks. It is designed for quantum applications that rely on task parallelism, including (i) hybrid algorithms, such as variational approaches, and (ii) circuit cutting systems, used to partition and execute large quantum circuits. Pilot-Quantum facilitates seamless integration of QPUs, classical CPUs, and GPUs, while supporting high-level programming frameworks like Qiskit and Pennylane. This enables users to efficiently design and execute hybrid workflows across diverse computing resources. The capabilities of Pilot-Quantum are demonstrated through mini-apps -- simplified yet representative kernels focusing on critical performance bottlenecks. We demonstrate the capabilities of Pilot-Quantum through multiple mini-apps, including different circuit executions (e.g., using IBM\\'s Eagle QPU and simulators), circuit cutting, and quantum machine learning scenarios.","authors":["Pradeep Mantha","Florian J. Kiwit","Nishant Saurabh","Shantenu Jha","Andre Luckow"],"url":"https://arxiv.org/abs/2412.18519"}
{"created":"2025-05-29","title":"Negative Ties Highlight Hidden Extremes in Social Media Polarization","abstract":"Human interactions in the online world comprise a combination of positive and negative exchanges. These diverse interactions can be captured using signed network representations, where edges take positive or negative weights to indicate the sentiment of the interaction between individuals. Signed networks offer valuable insights into online political polarization by capturing antagonistic interactions and ideological divides on social media platforms. This study analyzes polarization on Men\\'eame, a Spanish social media platform that facilitates engagement with news stories through comments and voting. Using a dual-method approach -- Signed Hamiltonian Eigenvector Embedding for Proximity (SHEEP) for signed networks and Correspondence Analysis (CA) for unsigned networks -- we investigate how including negative ties enhances the understanding of structural polarization levels across different conversation topics on the platform. While the unsigned Men\\'eame network effectively delineates ideological communities, only by incorporating negative ties can we identify ideologically extreme users who engage in antagonistic behaviors: without them, the most extreme users remain indistinguishable from their less confrontational ideological peers.","authors":["Elena Candellone","Shazia'Ayn Babul","\\\"Ozg\\\"ur Togay","Alexandre Bovet","Javier Garcia-Bernardo"],"url":"https://arxiv.org/abs/2501.05590"}
{"created":"2025-05-29","title":"Random Feature Representation Boosting","abstract":"We introduce Random Feature Representation Boosting (RFRBoost), a novel method for constructing deep residual random feature neural networks (RFNNs) using boosting theory. RFRBoost uses random features at each layer to learn the functional gradient of the network representation, enhancing performance while preserving the convex optimization benefits of RFNNs. In the case of MSE loss, we obtain closed-form solutions to greedy layer-wise boosting with random features. For general loss functions, we show that fitting random feature residual blocks reduces to solving a quadratically constrained least squares problem. Through extensive numerical experiments on tabular datasets for both regression and classification, we show that RFRBoost significantly outperforms RFNNs and end-to-end trained MLP ResNets in the small- to medium-scale regime where RFNNs are typically applied. Moreover, RFRBoost offers substantial computational benefits, and theoretical guarantees stemming from boosting theory.","authors":["Nikita Zozoulenko","Thomas Cass","Lukas Gonon"],"url":"https://arxiv.org/abs/2501.18283"}
{"created":"2025-05-29","title":"Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective","abstract":"Ensuring fairness in medical image segmentation is critical due to biases in imbalanced clinical data acquisition caused by demographic attributes (e.g., age, sex, race) and clinical factors (e.g., disease severity). To address these challenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired by optimal control theory. We provide a comprehensive analysis of its underlying mechanisms and clarify dMoE's role in adapting to heterogeneous distributions in medical image segmentation. Furthermore, we integrate dMoE into multiple network architectures, demonstrating its broad applicability across diverse medical image analysis tasks. By incorporating demographic and clinical factors, dMoE achieves state-of-the-art performance on two 2D benchmark datasets and a 3D in-house dataset. Our results highlight the effectiveness of dMoE in mitigating biases from imbalanced distributions, offering a promising approach to bridging control theory and medical image segmentation within fairness learning paradigms. The source code will be made available. The source code is available at https://github.com/tvseg/dMoE.","authors":["Yujin Oh","Pengfei Jin","Sangjoon Park","Sekeun Kim","Siyeop Yoon","Kyungsang Kim","Jin Sung Kim","Xiang Li","Quanzheng Li"],"url":"https://arxiv.org/abs/2502.00619"}
{"created":"2025-05-29","title":"LoRA-One: One-Step Full Gradient Could Suffice for Fine-Tuning Large Language Models, Provably and Efficiently","abstract":"This paper explores how theory can guide and enhance practical algorithms, using Low-Rank Adaptation (LoRA, Hu et al. 2022) in large language models as a case study. We rigorously prove that, under gradient descent, LoRA adapters align with specific singular subspaces of the one-step full fine-tuning gradient. This result suggests that, by properly initializing the adapters using the one-step full gradient, subspace alignment can be achieved immediately and applicable to both linear and nonlinear models. Building on our theory, we propose a theory-driven algorithm, LoRA-One, where the linear convergence (as well as generalization) is built and incorporating preconditioners theoretically helps mitigate the effects of ill-conditioning. Besides, our theory reveals connections between LoRA-One and other gradient-alignment-based methods, helping to clarify misconceptions in the design of such algorithms. LoRA-One achieves significant empirical improvements over LoRA and its variants across benchmarks in natural language understanding, mathematical reasoning, and code generation. Code is available at: https://github.com/YuanheZ/LoRA-One.","authors":["Yuanhe Zhang","Fanghui Liu","Yudong Chen"],"url":"https://arxiv.org/abs/2502.01235"}
{"created":"2025-05-29","title":"Spurious Correlations in High Dimensional Regression: The Roles of Regularization, Simplicity Bias and Over-Parameterization","abstract":"Learning models have been shown to rely on spurious correlations between non-predictive features and the associated labels in the training data, with negative implications on robustness, bias and fairness. In this work, we provide a statistical characterization of this phenomenon for high-dimensional regression, when the data contains a predictive core feature $x$ and a spurious feature $y$. Specifically, we quantify the amount of spurious correlations $C$ learned via linear regression, in terms of the data covariance and the strength $\\lambda$ of the ridge regularization. As a consequence, we first capture the simplicity of $y$ through the spectrum of its covariance, and its correlation with $x$ through the Schur complement of the full data covariance. Next, we prove a trade-off between $C$ and the in-distribution test loss $L$, by showing that the value of $\\lambda$ that minimizes $L$ lies in an interval where $C$ is increasing. Finally, we investigate the effects of over-parameterization via the random features model, by showing its equivalence to regularized linear regression. Our theoretical results are supported by numerical experiments on Gaussian, Color-MNIST, and CIFAR-10 datasets.","authors":["Simone Bombari","Marco Mondelli"],"url":"https://arxiv.org/abs/2502.01347"}
{"created":"2025-05-29","title":"From Kernels to Features: A Multi-Scale Adaptive Theory of Feature Learning","abstract":"Feature learning in neural networks is crucial for their expressive power and inductive biases, motivating various theoretical approaches. Some approaches describe network behavior after training through a change in kernel scale from initialization, resulting in a generalization power comparable to a Gaussian process. Conversely, in other approaches training results in the adaptation of the kernel to the data, involving directional changes to the kernel. The relationship and respective strengths of these two views have so far remained unresolved. This work presents a theoretical framework of multi-scale adaptive feature learning bridging these two views. Using methods from statistical mechanics, we derive analytical expressions for network output statistics which are valid across scaling regimes and in the continuum between them. A systematic expansion of the network's probability distribution reveals that mean-field scaling requires only a saddle-point approximation, while standard scaling necessitates additional correction terms. Remarkably, we find across regimes that kernel adaptation can be reduced to an effective kernel rescaling when predicting the mean network output in the special case of a linear network. However, for linear and non-linear networks, the multi-scale adaptive approach captures directional feature learning effects, providing richer insights than what could be recovered from a rescaling of the kernel alone.","authors":["Noa Rubin","Kirsten Fischer","Javed Lindner","David Dahmen","Inbar Seroussi","Zohar Ringel","Michael Kr\\\"amer","Moritz Helias"],"url":"https://arxiv.org/abs/2502.03210"}
{"created":"2025-05-29","title":"Bridging Scales in Map Generation: A scale-aware cascaded generative mapping framework for seamless and consistent multi-scale cartographic representation","abstract":"Multi-scale tile maps are essential for geographic information services, serving as fundamental outcomes of surveying and cartographic workflows. While existing image generation networks can produce map-like outputs from remote sensing imagery, their emphasis on replicating texture rather than preserving geospatial features limits cartographic validity. Current approaches face two fundamental challenges: inadequate integration of cartographic generalization principles with dynamic multi-scale generation and spatial discontinuities arising from tile-wise generation. To address these limitations, we propose a scale-aware cartographic generation framework (SCGM) that leverages conditional guided diffusion and a multi-scale cascade architecture. The framework introduces three key innovations: a scale modality encoding mechanism to formalize map generalization relationships, a scale-driven conditional encoder for robust feature fusion, and a cascade reference mechanism ensuring cross-scale visual consistency. By hierarchically constraining large-scale map synthesis with small-scale structural priors, SCGM effectively mitigates edge artifacts while maintaining geographic fidelity. Comprehensive evaluations on cartographic benchmarks confirm the framework's ability to generate seamless multi-scale tile maps with enhanced spatial coherence and generalization-aware representation, demonstrating significant potential for emergency mapping and automated cartography applications.","authors":["Chenxing Sun","Yongyang Xu","Xuwei Xu","Xixi Fan","Jing Bai","Xiechun Lu","Zhanlong Chen"],"url":"https://arxiv.org/abs/2502.04991"}
{"created":"2025-05-29","title":"Smooth Sailing: Lipschitz-Driven Uncertainty Quantification for Spatial Association","abstract":"Estimating associations between spatial covariates and responses - rather than merely predicting responses - is central to environmental science, epidemiology, and economics. For instance, public health officials might be interested in whether air pollution has a strictly positive association with a health outcome, and the magnitude of any effect. Standard machine learning methods often provide accurate predictions but offer limited insight into covariate-response relationships. And we show that existing methods for constructing confidence (or credible) intervals for associations fail to provide nominal coverage in the face of model misspecification and distribution shift - despite both being essentially always present in spatial problems. We introduce a method that constructs valid frequentist confidence intervals for associations in spatial settings. Our method requires minimal assumptions beyond a form of spatial smoothness. In particular, we do not require model correctness or covariate overlap between training and target locations. Our approach is the first to guarantee nominal coverage in this setting and outperforms existing techniques in both real and simulated experiments.","authors":["David R. Burt","Renato Berlinghieri","Stephen Bates","Tamara Broderick"],"url":"https://arxiv.org/abs/2502.06067"}
{"created":"2025-05-29","title":"Characterization of Logarithmic Fekete Critical Configurations of at Most Six Points in All Dimensions","abstract":"We consider the logarithmic Fekete problem, which consists of placing a fixed number of points on the unit sphere in $\\mathbb{R}^d$, in such a way that the product of all pairs of mutual Euclidean distances is maximized or, equivalently, so that their logarithmic energy is minimized. Using tools from Computational Algebraic Geometry, we find and classify all critical configurations for this problem when considering at most six points in every dimension $d$. In particular, our approach gives new proofs of several key results appearing in the literature, with the benefit of using a unified approach.","authors":["Diego Armentano","Leandro Bentancur","Federico Carrasco","Marcelo Fiori","Mat\\'ias Vald\\'es","Mauricio Velasco"],"url":"https://arxiv.org/abs/2502.10152"}
{"created":"2025-05-29","title":"Combinatorial Reinforcement Learning with Preference Feedback","abstract":"In this paper, we consider combinatorial reinforcement learning with preference feedback, where a learning agent sequentially offers an action--an assortment of multiple items to--a user, whose preference feedback follows a multinomial logistic (MNL) model. This framework allows us to model real-world scenarios, particularly those involving long-term user engagement, such as in recommender systems and online advertising. However, this framework faces two main challenges: (1) the unknown value of each item, unlike traditional MNL bandits that only address single-step preference feedback, and (2) the difficulty of ensuring optimism while maintaining tractable assortment selection in the combinatorial action space with unknown values. In this paper, we assume a contextual MNL preference model, where the mean utilities are linear, and the value of each item is approximated by a general function. We propose an algorithm, MNL-VQL, that addresses these challenges, making it both computationally and statistically efficient. As a special case, for linear MDPs (with the MNL preference feedback), we establish the first regret lower bound in this framework and show that MNL-VQL achieves nearly minimax-optimal regret. To the best of our knowledge, this is the first work to provide statistical guarantees in combinatorial RL with preference feedback.","authors":["Joongkyu Lee","Min-hwan Oh"],"url":"https://arxiv.org/abs/2502.10158"}
{"created":"2025-05-29","title":"Quantifying interdisciplinary synergy in higher STEM education","abstract":"We propose a framework to quantify and utilize interdisciplinarity in science and engineering curricula in the case of university-level higher education. We analyze interdisciplinary relations by standardizing large-scale official educational data in Korea using a cutting-edge large language model and constructing knowledge maps for disciplines of scientific education. We design and evaluate single-field and integrated dual-field curricula by adapting pedagogical theory and utilizing information theory-based metrics. We develop standard curricula for individual disciplines and integrated curricula combining two fields, with their interdisciplinarity quantified by the curriculum synergy score. The results indicate higher interdisciplinarity for combinations within or across closely related fields, especially in engineering fields. Based on the analysis, engineering fields constitute the core structure of our design for curriculum interdisciplinarity, while basic natural science fields are located at peripheral stems to provide fundamental concepts.","authors":["Gahyoun Gim","Jinhyuk Yun","Sang Hoon Lee"],"url":"https://arxiv.org/abs/2502.17841"}
{"created":"2025-05-29","title":"Word problems and embedding-obstructions in cellular automata groups on groups","abstract":"We study groups of reversible cellular automata, or CA groups, on groups. More generally, we consider automorphism groups of subshifts of finite type on groups. It is known that word problems of CA groups on virtually nilpotent groups are in co-NP, and can be co-NP-hard. We show that under the Gap Conjecture of Grigorchuk, their word problems are PSPACE-hard on all other groups. On free and surface groups, we show that they are indeed always in PSPACE. On a group with co-NEXPTIME word problem, CA groups themselves have co-NEXPTIME word problem, and on the lamplighter group (which itself has polynomial-time word problem) we show they can be co-NEXPTIME-hard. We show also nonembeddability results: the group of cellular automata on a non-cyclic free group does not embed in the group of cellular automata on the integers (this solves a question of Barbieri, Carrasco-Vargas and Rivera-Burgos); and the group of cellular automata in dimension $D$ does not embed in a group of cellular automata in dimension $d$ if $D > d$ (this solves a question of Hochman).","authors":["Ville Salo"],"url":"https://arxiv.org/abs/2503.05572"}
{"created":"2025-05-29","title":"X-GAN: A Generative AI-Powered Unsupervised Model for Main Vessel Segmentation of Glaucoma Screening","abstract":"Structural changes in main retinal blood vessels serve as critical biomarkers for the onset and progression of glaucoma. Identifying these vessels is vital for vascular modeling yet highly challenging. This paper proposes X-GAN, a generative AI-powered unsupervised segmentation model designed for extracting main blood vessels from Optical Coherence Tomography Angiography (OCTA) images. The process begins with the Space Colonization Algorithm (SCA) to rapidly generate a skeleton of vessels, featuring their radii. By synergistically integrating the generative adversarial network (GAN) with biostatistical modeling of vessel radii, X-GAN enables a fast reconstruction of both 2D and 3D representations of the vessels. Based on this reconstruction, X-GAN achieves nearly 100% segmentation accuracy without relying on labeled data or high-performance computing resources. Experimental results confirm X-GAN's superiority in evaluating main vessel segmentation compared to existing deep learning models. Code is here: https://github.com/VikiXie/SatMar8.","authors":["Cheng Huang","Weizheng Xie","Tsengdar J. Lee","Jui-Kai Wang","Karanjit Kooner","Ning Zhang","Jia Zhang"],"url":"https://arxiv.org/abs/2503.06743"}
{"created":"2025-05-29","title":"Arnold Diffusion in the Full Three-Body Problem","abstract":"The full three-body problem, on the motion of three celestial bodies under their mutual gravitational attraction, is one of the oldest unsolved problems in classical mechanics. The main difficulty comes from the presence of unstable and chaotic motions, which make long-term prediction impossible. In this paper, we show that the full three-body problem exhibits a strong form of instability known as Arnold diffusion. We consider the planar full three-body problem, formulated as a perturbation of both the Kepler problem and the planar circular restricted three-body problem. We show that the system exhibits Arnold diffusion, in the sense that there is a transfer of energy -- of an amount independent of the perturbation parameter -- between the Kepler problem and the restricted three-body problem. Our argument is based on the topological method of correctly aligned windows, which is implemented into a computer assisted proof. We demonstrate that the approach can be applied to physically relevant masses of the bodies, choosing a Neptune-Triton-asteroid system as an example. In this case, we obtain explicit estimates for the range of the perturbation parameter and for the diffusion time.","authors":["Maciej J. Capinski","Marian Gidea"],"url":"https://arxiv.org/abs/2504.09273"}
{"created":"2025-05-29","title":"Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline","abstract":"In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs) assessment pipeline within QuPath, demonstrating the potential of easily accessible tools to perform complex tasks in a fully automatic fashion. First, we trained a pixel classifier to segment tumor, tumor-associated stroma, and other tissue compartments in breast cancer H&amp;E-stained whole-slide images (WSI) to isolate tumor-associated stroma for subsequent analysis. Next, we applied a pre-trained StarDist deep learning model in QuPath for cell detection and used the extracted cell features to train a binary classifier distinguishing TILs from other cells. To evaluate our TILs assessment pipeline, we calculated the TIL density in each WSI and categorized them as low, medium, or high TIL levels. Our pipeline was evaluated against pathologist-assigned TIL scores, achieving a Cohen's kappa of 0.71 on the external test set, corroborating previous research findings. These results confirm that existing software can offer a practical solution for the assessment of TILs in H&amp;E-stained WSIs of breast cancer.","authors":["Masoud Tafavvoghi","Lars Ailo Bongo","Andr\\'e Berli Delgado","Nikita Shvetsov","Anders Sildnes","Line Moi","Lill-Tove Rasmussen Busund","Kajsa M{\\o}llersen"],"url":"https://arxiv.org/abs/2504.16979"}
{"created":"2025-05-29","title":"Learning Enhanced Ensemble Filters","abstract":"The filtering distribution in hidden Markov models evolves according to the law of a mean-field model in state-observation space. The ensemble Kalman filter (EnKF) approximates this mean-field model with an ensemble of interacting particles, employing a Gaussian ansatz for the joint distribution of the state and observation at each observation time. These methods are robust, but the Gaussian ansatz limits accuracy. This shortcoming is addressed by approximating the mean-field evolution using a novel form of neural operator taking probability distributions as input: a measure neural mapping (MNM). A MNM is used to design a novel approach to filtering, the MNM-enhanced ensemble filter (MNMEF), which is defined in both the mean-field limit and for interacting ensemble particle approximations. The ensemble approach uses empirical measures as input to the MNM and is implemented using the set transformer, which is invariant to ensemble permutation and allows for different ensemble sizes. The derivation of methods from a mean-field formulation allows a single parameterization of the algorithm to be deployed at different ensemble sizes. In practice fine-tuning of a small number of parameters, for specific ensemble sizes, further enhances the accuracy of the scheme. The promise of the approach is demonstrated by its superior root mean-square-error performance relative to leading methods in filtering the Lorenz 96 and Kuramoto-Sivashinsky models.","authors":["Eviatar Bach","Ricardo Baptista","Edoardo Calvello","Bohan Chen","Andrew Stuart"],"url":"https://arxiv.org/abs/2504.17836"}
{"created":"2025-05-29","title":"Generalization Analysis for Supervised Contrastive Representation Learning under Non-IID Settings","abstract":"Contrastive Representation Learning (CRL) has achieved impressive success in various domains in recent years. Nevertheless, the theoretical understanding of the generalization behavior of CRL has remained limited. Moreover, to the best of our knowledge, the current literature only analyzes generalization bounds under the assumption that the data tuples used for contrastive learning are independently and identically distributed. However, in practice, we are often limited to a fixed pool of reusable labeled data points, making it inevitable to recycle data across tuples to create sufficiently large datasets. Therefore, the tuple-wise independence condition imposed by previous works is invalidated. In this paper, we provide a generalization analysis for the CRL framework under non-$i.i.d.$ settings that adheres to practice more realistically. Drawing inspiration from the literature on U-statistics, we derive generalization bounds which indicate that the required number of samples in each class scales as the logarithm of the covering number of the class of learnable feature representations associated to that class. Next, we apply our main results to derive excess risk bounds for common function classes such as linear maps and neural networks.","authors":["Nong Minh Hieu","Antoine Ledent"],"url":"https://arxiv.org/abs/2505.04937"}
{"created":"2025-05-29","title":"Overcoming Dimensional Factorization Limits in Discrete Diffusion Models through Quantum Joint Distribution Learning","abstract":"This study explores quantum-enhanced discrete diffusion models to overcome classical limitations in learning high-dimensional distributions. We rigorously prove that classical discrete diffusion models, which calculate per-dimension transition probabilities to avoid exponential computational cost, exhibit worst-case linear scaling of Kullback-Leibler (KL) divergence with data dimension. To address this, we propose a Quantum Discrete Denoising Diffusion Probabilistic Model (QD3PM), which enables joint probability learning through diffusion and denoising in exponentially large Hilbert spaces. By deriving posterior states through quantum Bayes' theorem, similar to the crucial role of posterior probabilities in classical diffusion models, and by learning the joint probability, we establish a solid theoretical foundation for quantum-enhanced diffusion models. For denoising, we design a quantum circuit using temporal information for parameter sharing and learnable classical-data-controlled rotations for encoding. Exploiting joint distribution learning, our approach enables single-step sampling from pure noise, eliminating iterative requirements of existing models. Simulations demonstrate the proposed model's superior accuracy in modeling complex distributions compared to factorization methods. Hence, this paper establishes a new theoretical paradigm in generative models by leveraging the quantum advantage in joint distribution learning.","authors":["Chuangtao Chen","Qinglin Zhao","MengChu Zhou","Zhimin He","Haozhen Situ"],"url":"https://arxiv.org/abs/2505.05151"}
{"created":"2025-05-29","title":"Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning","abstract":"The Continuous Wavelet Transform (CWT) is an effective tool for feature extraction in acoustic recognition using Convolutional Neural Networks (CNNs), particularly when applied to non-stationary audio. However, its high computational cost poses a significant challenge, often leading researchers to prefer alternative methods such as the Short-Time Fourier Transform (STFT). To address this issue, this paper proposes a method to reduce the computational complexity of CWT by optimizing the length of the wavelet kernel and the hop size of the output scalogram. Experimental results demonstrate that the proposed approach significantly reduces computational cost while maintaining the robust performance of the trained model in acoustic recognition tasks.","authors":["Dang Thoai Phan","Tuan Anh Huynh","Van Tuan Pham","Cao Minh Tran","Van Thuan Mai","Ngoc Quy Tran"],"url":"https://arxiv.org/abs/2505.13017"}
{"created":"2025-05-29","title":"Effect of noise and topologies on multi-photon quantum protocols","abstract":"Quantum-augmented networks aim to use quantum phenomena to improve detection and protection against malicious actors in a classical communication network. This may include multiplexing quantum signals into classical fiber optical channels and incorporating purely quantum links alongside classical links in the network. In such hybrid networks, quantum protocols based on single photons become a bottleneck for transmission distances and data speeds, thereby reducing entire network performance. Furthermore, many of the security assumptions of the single-photon protocols do not hold up in practice because of the impossibility of manufacturing single-photon emitters. Multi-photon quantum protocols, on the other hand, are designed to operate under practical assumptions and do not require single photon emitters. As a result, they provide higher levels of security guarantees and longer transmission distances. However, the effect of channel and device noise on multiphoton protocols in terms of security, transmission distances, and bit rates has not been investigated. In this paper, we focus on channel noise and present our observations on the effect of various types of noise on multi-photon protocols. We also investigate the effect of topologies such as ring, star, and torus on the noise characteristics of the multi-photon protocols. Our results show the possible advantages of switching to multi-photon protocols and give insights into the repeater placement and topology choice for quantum-augmented networks.","authors":["Nitin Jha","Abhishek Parakh","Mahadevan Subramaniam"],"url":"https://arxiv.org/abs/2505.19270"}
