{"created":"2025-04-21","title":"Challenging the Eye-Mind Link Hypothesis: Visualizing Gazes For Each Programming Problem","abstract":"This investigates the relationship between eye fixation patterns and performance in Java programming exercises using eye-tracking technology. Thirty-one students from a university in Metro Manila participated, and their eye movements were recorded while solving five Java programming exercises (three of the five exercises were picked). The fixation data were preprocessed and visualized using heatmap bin graphs, dividing the participants into correct and wrong answer groups. The Mann-Whitney U Test was employed to determine if there were significant differences in the fixation patterns between the two groups.","authors":["Michael T. Lopez II"],"url":"https://arxiv.org/abs/2504.13182"}
{"created":"2025-04-21","title":"Factors That Influence the Adoption of AI-enabled Conversational Agents (AICAs) as an Augmenting Therapeutic Tool by Frontline Healthcare Workers: From Technology Acceptance Model 3 (TAM3) Lens -- A Systematic Mapping Review","abstract":"Artificial intelligent (AI) conversational agents hold a promising future in the field of mental health, especially in helping marginalized communities that lack access to mental health support services. It is tempting to have a 24/7 mental health companion that can be accessed anywhere using mobile phones to provide therapist-like advice. Yet, caution should be taken, and studies around their feasibility need to be surveyed. Before adopting such a rapidly changing technology, studies on its feasibility should be explored, summarized, and synthesized to gain a solid understanding of the status quo and to enable us to build a framework that can guide us throughout the development and deployment processes. Different perspectives must be considered when investigating the feasibility of AI conversational agents, including the mental healthcare professional perspective. The literature can provide insights into their perspectives in terms of opportunities, concerns, and implications. Mental health professionals, the subject-matter experts in this field, have their points of view that should be understood and considered. This systematic literature review will explore mental health practitioners' attitudes toward AI conversational agents and the factors that affect their adoption and recommendation of the technology to augment their services and treatments. The TAM3 Framework will be the lens through which this systematic literature review will be conducted.","authors":["Rawan AlMakinah"],"url":"https://arxiv.org/abs/2504.13183"}
{"created":"2025-04-21","title":"Benchmarking Large Language Models for Calculus Problem-Solving: A Comparative Analysis","abstract":"This study presents a comprehensive evaluation of five leading large language models (LLMs) - Chat GPT 4o, Copilot Pro, Gemini Advanced, Claude Pro, and Meta AI - on their performance in solving calculus differentiation problems. The investigation assessed these models across 13 fundamental problem types, employing a systematic cross-evaluation framework where each model solved problems generated by all models. Results revealed significant performance disparities, with Chat GPT 4o achieving the highest success rate (94.71%), followed by Claude Pro (85.74%), Gemini Advanced (84.42%), Copilot Pro (76.30%), and Meta AI (56.75%). All models excelled at procedural differentiation tasks but showed varying limitations with conceptual understanding and algebraic manipulation. Notably, problems involving increasing/decreasing intervals and optimization word problems proved most challenging across all models. The cross-evaluation matrix revealed that Claude Pro generated the most difficult problems, suggesting distinct capabilities between problem generation and problem-solving. These findings have significant implications for educational applications, highlighting both the potential and limitations of LLMs as calculus learning tools. While they demonstrate impressive procedural capabilities, their conceptual understanding remains limited compared to human mathematical reasoning, emphasizing the continued importance of human instruction for developing deeper mathematical comprehension.","authors":["In Hak Moon"],"url":"https://arxiv.org/abs/2504.13187"}
{"created":"2025-04-21","title":"BASIR: Budget-Assisted Sectoral Impact Ranking -- A Dataset for Sector Identification and Performance Prediction Using Language Models","abstract":"Government fiscal policies, particularly annual union budgets, exert significant influence on financial markets. However, real-time analysis of budgetary impacts on sector-specific equity performance remains methodologically challenging and largely unexplored. This study proposes a framework to systematically identify and rank sectors poised to benefit from India's Union Budget announcements. The framework addresses two core tasks: (1) multi-label classification of excerpts from budget transcripts into 81 predefined economic sectors, and (2) performance ranking of these sectors. Leveraging a comprehensive corpus of Indian Union Budget transcripts from 1947 to 2025, we introduce BASIR (Budget-Assisted Sectoral Impact Ranking), an annotated dataset mapping excerpts from budgetary transcripts to sectoral impacts. Our architecture incorporates fine-tuned embeddings for sector identification, coupled with language models that rank sectors based on their predicted performances. Our results demonstrate 0.605 F1-score in sector classification, and 0.997 NDCG score in predicting ranks of sectors based on post-budget performances. The methodology enables investors and policymakers to quantify fiscal policy impacts through structured, data-driven insights, addressing critical gaps in manual analysis. The annotated dataset has been released under CC-BY-NC-SA-4.0 license to advance computational economics research.","authors":["Sohom Ghosh","Sudip Kumar Naskar"],"url":"https://arxiv.org/abs/2504.13189"}
{"created":"2025-04-21","title":"Cellular-X: An LLM-empowered Cellular Agent for Efficient Base Station Operations","abstract":"This paper introduces Cellular-X, an LLM-powered agent designed to automate cellular base station (BS) maintenance. Leveraging multimodal LLM and retrieval-augmented generation (RAG) techniques, Cellular-X significantly enhances field engineer efficiency by quickly interpreting user intents, retrieving relevant technical information, and configuring a BS through iterative self-correction. Key features of the demo include automatic customized BS setup, document-based query answering, and voice-controlled configuration reporting and revision. We implemented Cellular-X on a USRP X310 testbed for demonstration. Demo videos and implementation details are available at https://github.com/SeaBreezing/Cellular-X.","authors":["Liujianfu Wang","Xinyi Long","Yuyang Du","Xiaoyan Liu","Kexin Chen","Soung Chang Liew"],"url":"https://arxiv.org/abs/2504.13190"}
{"created":"2025-04-21","title":"Universal Representations for Classification-enhanced Lossy Compression","abstract":"In lossy compression, the classical tradeoff between compression rate and reconstruction distortion has traditionally guided algorithm design. However, Blau and Michaeli [5] introduced a generalized framework, known as the rate-distortion-perception (RDP) function, incorporating perceptual quality as an additional dimension of evaluation. More recently, the rate-distortion-classification (RDC) function was investigated in [19], evaluating compression performance by considering classification accuracy alongside distortion. In this paper, we explore universal representations, where a single encoder is developed to achieve multiple decoding objectives across various distortion and classification (or perception) constraints. This universality avoids retraining encoders for each specific operating point within these tradeoffs. Our experimental validation on the MNIST dataset indicates that a universal encoder incurs only minimal performance degradation compared to individually optimized encoders for perceptual image compression tasks, aligning with prior results from [23]. Nonetheless, we also identify that in the RDC setting, reusing an encoder optimized for one specific classification-distortion tradeoff leads to a significant distortion penalty when applied to alternative points.","authors":["Nam Nguyen"],"url":"https://arxiv.org/abs/2504.13191"}
{"created":"2025-04-21","title":"CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent","abstract":"Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.","authors":["Liang-bo Ning","Shijie Wang","Wenqi Fan","Qing Li","Xin Xu","Hao Chen","Feiran Huang"],"url":"https://arxiv.org/abs/2504.13192"}
{"created":"2025-04-21","title":"HEAT:History-Enhanced Dual-phase Actor-Critic Algorithm with A Shared Transformer","abstract":"For a single-gateway LoRaWAN network, this study proposed a history-enhanced two-phase actor-critic algorithm with a shared transformer algorithm (HEAT) to improve network performance. HEAT considers uplink parameters and often neglected downlink parameters, and effectively integrates offline and online reinforcement learning, using historical data and real-time interaction to improve model performance. In addition, this study developed an open source LoRaWAN network simulator LoRaWANSim. The simulator considers the demodulator lock effect and supports multi-channel, multi-demodulator and bidirectional communication. Simulation experiments show that compared with the best results of all compared algorithms, HEAT improves the packet success rate and energy efficiency by 15% and 95%, respectively.","authors":["Hong Yang"],"url":"https://arxiv.org/abs/2504.13193"}
{"created":"2025-04-21","title":"Optimizing Multi-Gateway LoRaWAN via Cloud-Edge Collaboration and Knowledge Distillation","abstract":"For large-scale multi-gateway LoRaWAN networks, this study proposes a cloud-edge collaborative resource allocation and decision-making method based on edge intelligence, HEAT-LDL (HEAT-Local Distill Lyapunov), which realizes collaborative decision-making between gateways and terminal nodes. HEAT-LDL combines the Actor-Critic architecture and the Lyapunov optimization method to achieve intelligent downlink control and gateway load balancing. When the signal quality is good, the network server uses the HEAT algorithm to schedule the terminal nodes. To improve the efficiency of autonomous decision-making of terminal nodes, HEAT-LDL performs cloud-edge knowledge distillation on the HEAT teacher model on the terminal node side. When the downlink decision instruction is lost, the terminal node uses the student model and the edge decider based on prior knowledge and local history to make collaborative autonomous decisions. Simulation experiments show that compared with the optimal results of all compared algorithms, HEAT-LDL improves the packet success rate and energy efficiency by 20.5% and 88.1%, respectively.","authors":["Hong Yang"],"url":"https://arxiv.org/abs/2504.13194"}
{"created":"2025-04-21","title":"Investigating cybersecurity incidents using large language models in latest-generation wireless networks","abstract":"The purpose of research: Detection of cybersecurity incidents and analysis of decision support and assessment of the effectiveness of measures to counter information security threats based on modern generative models. The methods of research: Emulation of signal propagation data in MIMO systems, synthesis of adversarial examples, execution of adversarial attacks on machine learning models, fine tuning of large language models for detecting adversarial attacks, explainability of decisions on detecting cybersecurity incidents based on the prompts technique. Scientific novelty: A binary classification of data poisoning attacks was performed using large language models, and the possibility of using large language models for investigating cybersecurity incidents in the latest generation wireless networks was investigated. The result of research: Fine-tuning of large language models was performed on the prepared data of the emulated wireless network segment. Six large language models were compared for detecting adversarial attacks, and the capabilities of explaining decisions made by a large language model were investigated. The Gemma-7b model showed the best results according to the metrics Precision = 0.89, Recall = 0.89 and F1-Score = 0.89. Based on various explainability prompts, the Gemma-7b model notes inconsistencies in the compromised data under study, performs feature importance analysis and provides various recommendations for mitigating the consequences of adversarial attacks. Large language models integrated with binary classifiers of network threats have significant potential for practical application in the field of cybersecurity incident investigation, decision support and assessing the effectiveness of measures to counter information security threats.","authors":["Leonid Legashev","Arthur Zhigalov"],"url":"https://arxiv.org/abs/2504.13196"}
{"created":"2025-04-21","title":"Overcoming Bottlenecks in Homomorphic Encryption for the 2024 Mexican Federal Election","abstract":"On June 2, 2024, Mexico held its federal elections. The majority of Mexican citizens voted in person at the polls in this historic election. For the first time though, Mexican citizens living outside their country were able to vote online via a web app, either on a personal device or using an electronic voting kiosk at one of 23 embassies and consulates in the U.S., Canada, and Europe. In total, 144,734 people voted outside of Mexico: 122,496 on a personal device and 22,238 in-person at a kiosk. Voting was open for remote voting from 8PM, May 18, 2024 to 6PM, June 2, 2024 and was open for in-person voting from 8AM-6PM on June 2, 2024. This article describes the technical and cryptographic tools applied to secure the ex-patriate component of the election and to enable INE (Mexico's National Electoral Institute) to generate provable election results within minutes of the close of the election. This article will also describe how the solutions we present scale to elections on a national level.","authors":["Eric Landquist","Nimit Sawhney","Simer Sawhney"],"url":"https://arxiv.org/abs/2504.13198"}
{"created":"2025-04-21","title":"Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks","abstract":"Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.","authors":["Mohammad Saleha","Azadeh Tabatabaeib"],"url":"https://arxiv.org/abs/2504.13199"}
{"created":"2025-04-21","title":"Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI","abstract":"Embodied Intelligence (EI) systems integrated with large language models (LLMs) face significant security risks, particularly from jailbreak attacks that manipulate models into generating harmful outputs or executing unsafe physical actions. Traditional defense strategies, such as input filtering and output monitoring, often introduce high computational overhead or interfere with task performance in real-time embodied scenarios. To address these challenges, we propose Concept Enhancement Engineering (CEE), a novel defense framework that leverages representation engineering to enhance the safety of embodied LLMs by dynamically steering their internal activations. CEE operates by (1) extracting multilingual safety patterns from model activations, (2) constructing control directions based on safety-aligned concept subspaces, and (3) applying subspace concept rotation to reinforce safe behavior during inference. Our experiments demonstrate that CEE effectively mitigates jailbreak attacks while maintaining task performance, outperforming existing defense methods in both robustness and efficiency. This work contributes a scalable and interpretable safety mechanism for embodied AI, bridging the gap between theoretical representation engineering and practical security applications. Our findings highlight the potential of latent-space interventions as a viable defense paradigm against emerging adversarial threats in physically grounded AI systems.","authors":["Jirui Yang","Zheyu Lin","Shuhan Yang","Zhihui Lu","Xin Du"],"url":"https://arxiv.org/abs/2504.13201"}
{"created":"2025-04-21","title":"The Quantum LLM: Modeling Semantic Spaces with Quantum Principles","abstract":"In the previous article, we presented a quantum-inspired framework for modeling semantic representation and processing in Large Language Models (LLMs), drawing upon mathematical tools and conceptual analogies from quantum mechanics to offer a new perspective on these complex systems. In this paper, we clarify the core assumptions of this model, providing a detailed exposition of six key principles that govern semantic representation, interaction, and dynamics within LLMs. The goal is to justify that a quantum-inspired framework is a valid approach to studying semantic spaces. This framework offers valuable insights into their information processing and response generation, and we further discuss the potential of leveraging quantum computing to develop significantly more powerful and efficient LLMs based on these principles.","authors":["Timo Aukusti Laine"],"url":"https://arxiv.org/abs/2504.13202"}
{"created":"2025-04-21","title":"X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents","abstract":"Multi-turn interactions with language models (LMs) pose critical safety risks, as harmful intent can be strategically spread across exchanges. Yet, the vast majority of prior work has focused on single-turn safety, while adaptability and diversity remain among the key challenges of multi-turn red-teaming. To address these challenges, we present X-Teaming, a scalable framework that systematically explores how seemingly harmless interactions escalate into harmful outcomes and generates corresponding attack scenarios. X-Teaming employs collaborative agents for planning, attack optimization, and verification, achieving state-of-the-art multi-turn jailbreak effectiveness and diversity with success rates up to 98.1% across representative leading open-weight and closed-source models. In particular, X-Teaming achieves a 96.2% attack success rate against the latest Claude 3.7 Sonnet model, which has been considered nearly immune to single-turn attacks. Building on X-Teaming, we introduce XGuard-Train, an open-source multi-turn safety training dataset that is 20x larger than the previous best resource, comprising 30K interactive jailbreaks, designed to enable robust multi-turn safety alignment for LMs. Our work offers essential tools and insights for mitigating sophisticated conversational attacks, advancing the multi-turn safety of LMs.","authors":["Salman Rahman","Liwei Jiang","James Shiffer","Genglin Liu","Sheriff Issaka","Md Rizwan Parvez","Hamid Palangi","Kai-Wei Chang","Yejin Choi","Saadia Gabriel"],"url":"https://arxiv.org/abs/2504.13203"}
{"created":"2025-04-21","title":"EDGS: Eliminating Densification for Efficient Convergence of 3DGS","abstract":"3D Gaussian Splatting reconstructs scenes by starting from a sparse Structure-from-Motion initialization and iteratively refining under-reconstructed regions. This process is inherently slow, as it requires multiple densification steps where Gaussians are repeatedly split and adjusted, following a lengthy optimization path. Moreover, this incremental approach often leads to suboptimal renderings, particularly in high-frequency regions where detail is critical.","authors":["Dmytro Kotovenko","Olga Grebenkova","Bj\\\"orn Ommer"],"url":"https://arxiv.org/abs/2504.13204"}
{"created":"2025-04-21","title":"On-Device Watermarking: A Socio-Technical Imperative For Authenticity In The Age of Generative AI","abstract":"As generative AI models produce increasingly realistic output, both academia and industry are focusing on the ability to detect whether an output was generated by an AI model or not. Many of the research efforts and policy discourse are centered around robust watermarking of AI outputs. While plenty of progress has been made, all watermarking and AI detection techniques face severe limitations. In this position paper, we argue that we are adopting the wrong approach, and should instead focus on watermarking via cryptographic signatures trustworthy content rather than AI generated ones. For audio-visual content, in particular, all real content is grounded in the physical world and captured via hardware sensors. This presents a unique opportunity to watermark at the hardware layer, and we lay out a socio-technical framework and draw parallels with HTTPS certification and Blu-Ray verification protocols. While acknowledging implementation challenges, we contend that hardware-based authentication offers a more tractable path forward, particularly from a policy perspective. As generative models approach perceptual indistinguishability, the research community should be wary of being overly optimistic with AI watermarking, and we argue that AI watermarking research efforts are better spent in the text and LLM space, which are ultimately not traceable to a physical sensor.","authors":["Houssam Kherraz"],"url":"https://arxiv.org/abs/2504.13205"}
{"created":"2025-04-21","title":"DuoLoRA : Cycle-consistent and Rank-disentangled Content-Style Personalization","abstract":"We tackle the challenge of jointly personalizing content and style from a few examples. A promising approach is to train separate Low-Rank Adapters (LoRA) and merge them effectively, preserving both content and style. Existing methods, such as ZipLoRA, treat content and style as independent entities, merging them by learning masks in LoRA's output dimensions. However, content and style are intertwined, not independent. To address this, we propose DuoLoRA, a content-style personalization framework featuring three key components: (i) rank-dimension mask learning, (ii) effective merging via layer priors, and (iii) Constyle loss, which leverages cycle-consistency in the merging process. First, we introduce ZipRank, which performs content-style merging within the rank dimension, offering adaptive rank flexibility and significantly reducing the number of learnable parameters. Additionally, we incorporate SDXL layer priors to apply implicit rank constraints informed by each layer's content-style bias and adaptive merger initialization, enhancing the integration of content and style. To further refine the merging process, we introduce Constyle loss, which leverages the cycle-consistency between content and style. Our experimental results demonstrate that DuoLoRA outperforms state-of-the-art content-style merging methods across multiple benchmarks.","authors":["Aniket Roy","Shubhankar Borse","Shreya Kadambi","Debasmit Das","Shweta Mahajan","Risheek Garrepalli","Hyojin Park","Ankita Nayak","Rama Chellappa","Munawar Hayat","Fatih Porikli"],"url":"https://arxiv.org/abs/2504.13206"}
{"created":"2025-04-21","title":"BEV-GS: Feed-forward Gaussian Splatting in Bird's-Eye-View for Road Reconstruction","abstract":"Road surface is the sole contact medium for wheels or robot feet. Reconstructing road surface is crucial for unmanned vehicles and mobile robots. Recent studies on Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) have achieved remarkable results in scene reconstruction. However, they typically rely on multi-view image inputs and require prolonged optimization times. In this paper, we propose BEV-GS, a real-time single-frame road surface reconstruction method based on feed-forward Gaussian splatting. BEV-GS consists of a prediction module and a rendering module. The prediction module introduces separate geometry and texture networks following Bird's-Eye-View paradigm. Geometric and texture parameters are directly estimated from a single frame, avoiding per-scene optimization. In the rendering module, we utilize grid Gaussian for road surface representation and novel view synthesis, which better aligns with road surface characteristics. Our method achieves state-of-the-art performance on the real-world dataset RSRD. The road elevation error reduces to 1.73 cm, and the PSNR of novel view synthesis reaches 28.36 dB. The prediction and rendering FPS is 26, and 2061, respectively, enabling high-accuracy and real-time applications. The code will be available at: \\href{https://github.com/cat-wwh/BEV-GS}{\\texttt{https://github.com/cat-wwh/BEV-GS}}","authors":["Wenhua Wu","Tong Zhao","Chensheng Peng","Lei Yang","Yintao Wei","Zhe Liu","Hesheng Wang"],"url":"https://arxiv.org/abs/2504.13207"}
{"created":"2025-04-21","title":"Intelligent road crack detection and analysis based on improved YOLOv8","abstract":"As urbanization speeds up and traffic flow increases, the issue of pavement distress is becoming increasingly pronounced, posing a severe threat to road safety and service life. Traditional methods of pothole detection rely on manual inspection, which is not only inefficient but also costly. This paper proposes an intelligent road crack detection and analysis system, based on the enhanced YOLOv8 deep learning framework. A target segmentation model has been developed through the training of 4029 images, capable of efficiently and accurately recognizing and segmenting crack regions in roads. The model also analyzes the segmented regions to precisely calculate the maximum and minimum widths of cracks and their exact locations. Experimental results indicate that the incorporation of ECA and CBAM attention mechanisms substantially enhances the model's detection accuracy and efficiency, offering a novel solution for road maintenance and safety monitoring.","authors":["Haomin Zuo","Zhengyang Li","Jiangchuan Gong","Zhen Tian"],"url":"https://arxiv.org/abs/2504.13208"}
{"created":"2025-04-21","title":"On the Feasibility of Using MultiModal LLMs to Execute AR Social Engineering Attacks","abstract":"Augmented Reality (AR) and Multimodal Large Language Models (LLMs) are rapidly evolving, providing unprecedented capabilities for human-computer interaction. However, their integration introduces a new attack surface for social engineering. In this paper, we systematically investigate the feasibility of orchestrating AR-driven Social Engineering attacks using Multimodal LLM for the first time, via our proposed SEAR framework, which operates through three key phases: (1) AR-based social context synthesis, which fuses Multimodal inputs (visual, auditory and environmental cues); (2) role-based Multimodal RAG (Retrieval-Augmented Generation), which dynamically retrieves and integrates contextual data while preserving character differentiation; and (3) ReInteract social engineering agents, which execute adaptive multiphase attack strategies through inference interaction loops. To verify SEAR, we conducted an IRB-approved study with 60 participants in three experimental configurations (unassisted, AR+LLM, and full SEAR pipeline) compiling a new dataset of 180 annotated conversations in simulated social scenarios. Our results show that SEAR is highly effective at eliciting high-risk behaviors (e.g., 93.3% of participants susceptible to email phishing). The framework was particularly effective in building trust, with 85% of targets willing to accept an attacker's call after an interaction. Also, we identified notable limitations such as ``occasionally artificial'' due to perceived authenticity gaps. This work provides proof-of-concept for AR-LLM driven social engineering attacks and insights for developing defensive countermeasures against next-generation augmented reality threats.","authors":["Ting Bi","Chenghang Ye","Zheyu Yang","Ziyi Zhou","Cui Tang","Jun Zhang","Zui Tao","Kailong Wang","Liting Zhou","Yang Yang","Tianlong Yu"],"url":"https://arxiv.org/abs/2504.13209"}
{"created":"2025-04-21","title":"Graphical Models for Decision-Making: Integrating Causality and Game Theory","abstract":"Causality and game theory are two influential fields that contribute significantly to decision-making in various domains. Causality defines and models causal relationships in complex policy problems, while game theory provides insights into strategic interactions among stakeholders with competing interests. Integrating these frameworks has led to significant theoretical advancements with the potential to improve decision-making processes. However, practical applications of these developments remain underexplored. To support efforts toward implementation, this paper clarifies key concepts in game theory and causality that are essential to their intersection, particularly within the context of probabilistic graphical models. By rigorously examining these concepts and illustrating them with intuitive, consistent examples, we clarify the required inputs for implementing these models, provide practitioners with insights into their application and selection across different scenarios, and reference existing research that supports their implementation. We hope this work encourages broader adoption of these models in real-world scenarios.","authors":["Maarten C. Vonk","Mauricio Gonzalez Soto","Anna V. Kononova"],"url":"https://arxiv.org/abs/2504.13210"}
{"created":"2025-04-21","title":"Mirror: Multimodal Cognitive Reframing Therapy for Rolling with Resistance","abstract":"Recent studies have explored the use of large language models (LLMs) in psychotherapy; however, text-based cognitive behavioral therapy (CBT) models often struggle with client resistance, which can weaken therapeutic alliance. To address this, we propose a multimodal approach that incorporates nonverbal cues, allowing the AI therapist to better align its responses with the client's negative emotional state. Specifically, we introduce a new synthetic dataset, Multimodal Interactive Rolling with Resistance (Mirror), which is a novel synthetic dataset that pairs client statements with corresponding facial images. Using this dataset, we train baseline Vision-Language Models (VLMs) that can analyze facial cues, infer emotions, and generate empathetic responses to effectively manage resistance. They are then evaluated in terms of both the therapist's counseling skills and the strength of the therapeutic alliance in the presence of client resistance. Our results demonstrate that Mirror significantly enhances the AI therapist's ability to handle resistance, which outperforms existing text-based CBT approaches.","authors":["Subin Kim","Hoonrae Kim","Jihyun Lee","Yejin Jeon","Gary Geunbae Lee"],"url":"https://arxiv.org/abs/2504.13211"}
{"created":"2025-04-21","title":"I Know What You Bought Last Summer: Investigating User Data Leakage in E-Commerce Platforms","abstract":"In the digital age, e-commerce has transformed the way consumers shop, offering convenience and accessibility. Nevertheless, concerns about the privacy and security of personal information shared on these platforms have risen. In this work, we investigate user privacy violations, noting the risks of data leakage to third-party entities. Utilizing a semi-automated data collection approach, we examine a selection of popular online e-shops, revealing that nearly 30% of them violate user privacy by disclosing personal information to third parties. We unveil how minimal user interaction across multiple e-commerce websites can result in a comprehensive privacy breach. We observe significant data-sharing patterns with platforms like Facebook, which use personal information to build user profiles and link them to social media accounts.","authors":["Ioannis Vlachogiannakis","Emmanouil Papadogiannakis","Panagiotis Papadopoulos","Nicolas Kourtellis","Evangelos Markatos"],"url":"https://arxiv.org/abs/2504.13212"}
{"created":"2025-04-21","title":"Wavelet-based Variational Autoencoders for High-Resolution Image Generation","abstract":"Variational Autoencoders (VAEs) are powerful generative models capable of learning compact latent representations. However, conventional VAEs often generate relatively blurry images due to their assumption of an isotropic Gaussian latent space and constraints in capturing high-frequency details. In this paper, we explore a novel wavelet-based approach (Wavelet-VAE) in which the latent space is constructed using multi-scale Haar wavelet coefficients. We propose a comprehensive method to encode the image features into multi-scale detail and approximation coefficients and introduce a learnable noise parameter to maintain stochasticity. We thoroughly discuss how to reformulate the reparameterization trick, address the KL divergence term, and integrate wavelet sparsity principles into the training objective. Our experimental evaluation on CIFAR-10 and other high-resolution datasets demonstrates that the Wavelet-VAE improves visual fidelity and recovers higher-resolution details compared to conventional VAEs. We conclude with a discussion of advantages, potential limitations, and future research directions for wavelet-based generative modeling.","authors":["Andrew Kiruluta"],"url":"https://arxiv.org/abs/2504.13214"}
{"created":"2025-04-21","title":"KFinEval-Pilot: A Comprehensive Benchmark Suite for Korean Financial Language Understanding","abstract":"We introduce KFinEval-Pilot, a benchmark suite specifically designed to evaluate large language models (LLMs) in the Korean financial domain. Addressing the limitations of existing English-centric benchmarks, KFinEval-Pilot comprises over 1,000 curated questions across three critical areas: financial knowledge, legal reasoning, and financial toxicity. The benchmark is constructed through a semi-automated pipeline that combines GPT-4-generated prompts with expert validation to ensure domain relevance and factual accuracy. We evaluate a range of representative LLMs and observe notable performance differences across models, with trade-offs between task accuracy and output safety across different model families. These results highlight persistent challenges in applying LLMs to high-stakes financial applications, particularly in reasoning and safety. Grounded in real-world financial use cases and aligned with the Korean regulatory and linguistic context, KFinEval-Pilot serves as an early diagnostic tool for developing safer and more reliable financial AI systems.","authors":["Bokwang Hwang","Seonkyu Lim","Taewoong Kim","Yongjae Geun","Sunghyun Bang","Sohyun Park","Jihyun Park","Myeonggyu Lee","Jinwoo Lee","Yerin Kim","Jinsun Yoo","Jingyeong Hong","Jina Park","Yongchan Kim","Suhyun Kim","Younggyun Hahm","Yiseul Lee","Yejee Kang","Chanhyuk Yoon","Chansu Lee","Heeyewon Jeong","Jiyeon Lee","Seonhye Gu","Hyebin Kang","Yousang Cho","Hangyeol Yoo","KyungTae Lim"],"url":"https://arxiv.org/abs/2504.13216"}
{"created":"2025-04-21","title":"Sustainability via LLM Right-sizing","abstract":"Large language models (LLMs) have become increasingly embedded in organizational workflows. This has raised concerns over their energy consumption, financial costs, and data sovereignty. While performance benchmarks often celebrate cutting-edge models, real-world deployment decisions require a broader perspective: when is a smaller, locally deployable model \"good enough\"? This study offers an empirical answer by evaluating eleven proprietary and open-weight LLMs across ten everyday occupational tasks, including summarizing texts, generating schedules, and drafting emails and proposals. Using a dual-LLM-based evaluation framework, we automated task execution and standardized evaluation across ten criteria related to output quality, factual accuracy, and ethical responsibility. Results show that GPT-4o delivers consistently superior performance but at a significantly higher cost and environmental footprint. Notably, smaller models like Gemma-3 and Phi-4 achieved strong and reliable results on most tasks, suggesting their viability in contexts requiring cost-efficiency, local deployment, or privacy. A cluster analysis revealed three model groups -- premium all-rounders, competent generalists, and limited but safe performers -- highlighting trade-offs between quality, control, and sustainability. Significantly, task type influenced model effectiveness: conceptual tasks challenged most models, while aggregation and transformation tasks yielded better performances. We argue for a shift from performance-maximizing benchmarks to task- and context-aware sufficiency assessments that better reflect organizational priorities. Our approach contributes a scalable method to evaluate AI models through a sustainability lens and offers actionable guidance for responsible LLM deployment in practice.","authors":["Jennifer Haase","Finn Klessascheck","Jan Mendling","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2504.13217"}
{"created":"2025-04-21","title":"Harmony: A Unified Framework for Modality Incremental Learning","abstract":"Incremental learning aims to enable models to continuously acquire knowledge from evolving data streams while preserving previously learned capabilities. While current research predominantly focuses on unimodal incremental learning and multimodal incremental learning where the modalities are consistent, real-world scenarios often present data from entirely new modalities, posing additional challenges. This paper investigates the feasibility of developing a unified model capable of incremental learning across continuously evolving modal sequences. To this end, we introduce a novel paradigm called Modality Incremental Learning (MIL), where each learning stage involves data from distinct modalities. To address this task, we propose a novel framework named Harmony, designed to achieve modal alignment and knowledge retention, enabling the model to reduce the modal discrepancy and learn from a sequence of distinct modalities, ultimately completing tasks across multiple modalities within a unified framework. Our approach introduces the adaptive compatible feature modulation and cumulative modal bridging. Through constructing historical modal features and performing modal knowledge accumulation and alignment, the proposed components collaboratively bridge modal differences and maintain knowledge retention, even with solely unimodal data available at each learning phase.These components work in concert to establish effective modality connections and maintain knowledge retention, even when only unimodal data is available at each learning stage. Extensive experiments on the MIL task demonstrate that our proposed method significantly outperforms existing incremental learning methods, validating its effectiveness in MIL scenarios.","authors":["Yaguang Song","Xiaoshan Yang","Dongmei Jiang","Yaowei Wang","Changsheng Xu"],"url":"https://arxiv.org/abs/2504.13218"}
{"created":"2025-04-21","title":"Scaling Laws for Data-Efficient Visual Transfer Learning","abstract":"Current scaling laws for visual AI models focus predominantly on large-scale pretraining, leaving a critical gap in understanding how performance scales for data-constrained downstream tasks. To address this limitation, this paper establishes the first practical framework for data-efficient scaling laws in visual transfer learning, addressing two fundamental questions: 1) How do scaling behaviors shift when downstream tasks operate with limited data? 2) What governs the efficacy of knowledge distillation under such constraints? Through systematic analysis of vision tasks across data regimes (1K-1M samples), we propose the distillation boundary theory, revealing a critical turning point in distillation efficiency: 1) Distillation superiority: In data-scarce conditions, distilled models significantly outperform their non-distillation counterparts, efficiently leveraging inherited knowledge to compensate for limited training samples. 2) Pre-training dominance: As pre-training data increases beyond a critical threshold, non-distilled models gradually surpass distilled versions, suggesting diminishing returns from knowledge inheritance when sufficient task-specific data becomes available. Empirical validation across various model scales (2.5M to 38M parameters) and data volumes demonstrate these performance inflection points, with error difference curves transitioning from positive to negative values at critical data thresholds, confirming our theoretical predictions. This work redefines scaling laws for data-limited regimes, bridging the knowledge gap between large-scale pretraining and practical downstream adaptation, addressing a critical barrier to understanding vision model scaling behaviors and optimizing computational resource allocation.","authors":["Wenxuan Yang","Qingqu Wei","Chenxi Ma","Weimin Tan","Bo Yan"],"url":"https://arxiv.org/abs/2504.13219"}
{"created":"2025-04-21","title":"SSTAF: Spatial-Spectral-Temporal Attention Fusion Transformer for Motor Imagery Classification","abstract":"Brain-computer interfaces (BCI) in electroencephalography (EEG)-based motor imagery classification offer promising solutions in neurorehabilitation and assistive technologies by enabling communication between the brain and external devices. However, the non-stationary nature of EEG signals and significant inter-subject variability cause substantial challenges for developing robust cross-subject classification models. This paper introduces a novel Spatial-Spectral-Temporal Attention Fusion (SSTAF) Transformer specifically designed for upper-limb motor imagery classification. Our architecture consists of a spectral transformer and a spatial transformer, followed by a transformer block and a classifier network. Each module is integrated with attention mechanisms that dynamically attend to the most discriminative patterns across multiple domains, such as spectral frequencies, spatial electrode locations, and temporal dynamics. The short-time Fourier transform is incorporated to extract features in the time-frequency domain to make it easier for the model to obtain a better feature distinction. We evaluated our SSTAF Transformer model on two publicly available datasets, the EEGMMIDB dataset, and BCI Competition IV-2a. SSTAF Transformer achieves an accuracy of 76.83% and 68.30% in the data sets, respectively, outperforms traditional CNN-based architectures and a few existing transformer-based approaches.","authors":["Ummay Maria Muna","Md. Mehedi Hasan Shawon","Md Jobayer","Sumaiya Akter","Saifur Rahman Sabuj"],"url":"https://arxiv.org/abs/2504.13220"}
{"created":"2025-04-21","title":"ICAS: IP Adapter and ControlNet-based Attention Structure for Multi-Subject Style Transfer Optimization","abstract":"Generating multi-subject stylized images remains a significant challenge due to the ambiguity in defining style attributes (e.g., color, texture, atmosphere, and structure) and the difficulty in consistently applying them across multiple subjects. Although recent diffusion-based text-to-image models have achieved remarkable progress, existing methods typically rely on computationally expensive inversion procedures or large-scale stylized datasets. Moreover, these methods often struggle with maintaining multi-subject semantic fidelity and are limited by high inference costs. To address these limitations, we propose ICAS (IP-Adapter and ControlNet-based Attention Structure), a novel framework for efficient and controllable multi-subject style transfer. Instead of full-model tuning, ICAS adaptively fine-tunes only the content injection branch of a pre-trained diffusion model, thereby preserving identity-specific semantics while enhancing style controllability. By combining IP-Adapter for adaptive style injection with ControlNet for structural conditioning, our framework ensures faithful global layout preservation alongside accurate local style synthesis. Furthermore, ICAS introduces a cyclic multi-subject content embedding mechanism, which enables effective style transfer under limited-data settings without the need for extensive stylized corpora. Extensive experiments show that ICAS achieves superior performance in structure preservation, style consistency, and inference efficiency, establishing a new paradigm for multi-subject style transfer in real-world applications.","authors":["Fuwei Liu"],"url":"https://arxiv.org/abs/2504.13224"}
{"created":"2025-04-21","title":"Image Editing with Diffusion Models: A Survey","abstract":"With deeper exploration of diffusion model, developments in the field of image generation have triggered a boom in image creation. As the quality of base-model generated images continues to improve, so does the demand for further application like image editing. In recent years, many remarkable works are realizing a wide variety of editing effects. However, the wide variety of editing types and diverse editing approaches have made it difficult for researchers to establish a comprehensive view of the development of this field. In this survey, we summarize the image editing field from four aspects: tasks definition, methods classification, results evaluation and editing datasets. First, we provide a definition of image editing, which in turn leads to a variety of editing task forms from the perspective of operation parts and manipulation actions. Subsequently, we categorize and summary methods for implementing editing into three categories: inversion-based, fine-tuning-based and adapter-based. In addition, we organize the currently used metrics, available datasets and corresponding construction methods. At the end, we present some visions for the future development of the image editing field based on the previous summaries.","authors":["Jia Wang","Jie Hu","Xiaoqi Ma","Hanghang Ma","Xiaoming Wei","Enhua Wu"],"url":"https://arxiv.org/abs/2504.13226"}
{"created":"2025-04-21","title":"DIDS: Domain Impact-aware Data Sampling for Large Language Model Training","abstract":"Large language models (LLMs) are commonly trained on multi-domain datasets, where domain sampling strategies significantly impact model performance due to varying domain importance across downstream tasks. Existing approaches for optimizing domain-level sampling strategies struggle with maintaining intra-domain consistency and accurately measuring domain impact. In this paper, we present Domain Impact-aware Data Sampling (DIDS). To ensure intra-domain consistency, a gradient clustering algorithm is proposed to group training data based on their learning effects, where a proxy language model and dimensionality reduction are employed to reduce computational overhead. To accurately measure domain impact, we develop a Fisher Information Matrix (FIM) guided metric that quantifies how domain-specific parameter updates affect the model's output distributions on downstream tasks, with theoretical guarantees. Furthermore, to determine optimal sampling ratios, DIDS combines both the FIM-guided domain impact assessment and loss learning trajectories that indicate domain-specific potential, while accounting for diminishing marginal returns. Extensive experiments demonstrate that DIDS achieves 3.4% higher average performance while maintaining comparable training efficiency.","authors":["Weijie Shi","Jipeng Zhang","Yaguang Wu","Jingzhi Fang","Ruiyuan Zhang","Jiajie Xu","Jia Zhu","Hao Chen","Yao Zhao","Sirui Han","Xiaofang Zhou"],"url":"https://arxiv.org/abs/2504.13227"}
{"created":"2025-04-21","title":"Modelling Mean-Field Games with Neural Ordinary Differential Equations","abstract":"Mean-field game theory relies on approximating games that would otherwise have been intractable to model. While the games can be solved analytically via the associated system of partial derivatives, this approach is not model-free, can lead to the loss of the existence or uniqueness of solutions and may suffer from modelling bias. To reduce the dependency between the model and the game, we combine mean-field game theory with deep learning in the form of neural ordinary differential equations. The resulting model is data-driven, lightweight and can learn extensive strategic interactions that are hard to capture using mean-field theory alone. In addition, the model is based on automatic differentiation, making it more robust and objective than approaches based on finite differences. We highlight the efficiency and flexibility of our approach by solving three mean-field games that vary in their complexity, observability and the presence of noise. Using these results, we show that the model is flexible, lightweight and requires few observations to learn the distribution underlying the data.","authors":["Anna C. M. Th\\\"oni","Yoram Bachrach","Tal Kachman"],"url":"https://arxiv.org/abs/2504.13228"}
{"created":"2025-04-21","title":"PSG-MAE: Robust Multitask Sleep Event Monitoring using Multichannel PSG Reconstruction and Inter-channel Contrastive Learning","abstract":"Polysomnography (PSG) signals are essential for studying sleep processes and diagnosing sleep disorders. Analyzing PSG data through deep neural networks (DNNs) for automated sleep monitoring has become increasingly feasible. However, the limited availability of datasets for certain sleep events often leads to DNNs focusing on a single task with a single-sourced training dataset. As a result, these models struggle to transfer to new sleep events and lack robustness when applied to new datasets. To address these challenges, we propose PSG-MAE, a mask autoencoder (MAE) based pre-training framework. By performing self-supervised learning on a large volume of unlabeled PSG data, PSG-MAE develops a robust feature extraction network that can be broadly applied to various sleep event monitoring tasks. Unlike conventional MAEs, PSG-MAE generates complementary masks across PSG channels, integrates a multichannel signal reconstruction method, and employs a self-supervised inter-channel contrastive learning (ICCL) strategy. This approach enables the encoder to capture temporal features from each channel while simultaneously learning latent relationships between channels, thereby enhancing the utilization of multichannel information. Experimental results show that PSG-MAE effectively captures both temporal details and inter-channel information from PSG signals. When the encoder pre-trained through PSG-MAE is fine-tuned with downstream feature decomposition networks, it achieves an accuracy of 83.7% for sleep staging and 90.45% for detecting obstructive sleep apnea, which highlights the framework's robustness and broad applicability.","authors":["Yifei Wang","Qi Liu","Fuli Min","Honghao Wang"],"url":"https://arxiv.org/abs/2504.13229"}
{"created":"2025-04-21","title":"WildFireCan-MMD: A Multimodal dataset for Classification of User-generated Content During Wildfires in Canada","abstract":"Rapid information access is vital during wildfires, yet traditional data sources are slow and costly. Social media offers real-time updates, but extracting relevant insights remains a challenge. We present WildFireCan-MMD, a new multimodal dataset of X posts from recent Canadian wildfires, annotated across 13 key themes. Evaluating both Vision Language Models and custom-trained classifiers, we show that while zero-shot prompting offers quick deployment, even simple trained models outperform them when labelled data is available, by up to 23%. Our findings highlight the enduring importance of tailored datasets and task-specific training. Importantly, such datasets should be localized, as disaster response requirements vary across regions and contexts.","authors":["Braeden Sherritt","Isar Nejadgholi","Marzieh Amini"],"url":"https://arxiv.org/abs/2504.13231"}
{"created":"2025-04-21","title":"Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound Signals from Fetal Electrocardiograms","abstract":"Fetal health monitoring through one-dimensional Doppler ultrasound (DUS) signals offers a cost-effective and accessible approach that is increasingly gaining interest. Despite its potential, the development of machine learning based techniques to assess the health condition of mothers and fetuses using DUS signals remains limited. This scarcity is primarily due to the lack of extensive DUS datasets with a reliable reference for interpretation and data imbalance across different gestational ages. In response, we introduce a novel autoregressive generative model designed to map fetal electrocardiogram (FECG) signals to corresponding DUS waveforms (Auto-FEDUS). By leveraging a neural temporal network based on dilated causal convolutions that operate directly on the waveform level, the model effectively captures both short and long-range dependencies within the signals, preserving the integrity of generated data. Cross-subject experiments demonstrate that Auto-FEDUS outperforms conventional generative architectures across both time and frequency domain evaluations, producing DUS signals that closely resemble the morphology of their real counterparts. The realism of these synthesized signals was further gauged using a quality assessment model, which classified all as good quality, and a heart rate estimation model, which produced comparable results for generated and real data, with a Bland-Altman limit of 4.5 beats per minute. This advancement offers a promising solution for mitigating limited data availability and enhancing the training of DUS-based fetal models, making them more effective and generalizable.","authors":["Alireza Rafiei","Gari D. Clifford","Nasim Katebi"],"url":"https://arxiv.org/abs/2504.13233"}
{"created":"2025-04-21","title":"Non-Uniform Class-Wise Coreset Selection: Characterizing Category Difficulty for Data-Efficient Transfer Learning","abstract":"As transfer learning models and datasets grow larger, efficient adaptation and storage optimization have become critical needs. Coreset selection addresses these challenges by identifying and retaining the most informative samples, constructing a compact subset for target domain training. However, current methods primarily rely on instance-level difficulty assessments, overlooking crucial category-level characteristics and consequently under-representing minority classes. To overcome this limitation, we propose Non-Uniform Class-Wise Coreset Selection (NUCS), a novel framework that integrates both class-level and instance-level criteria. NUCS automatically allocates data selection budgets for each class based on intrinsic category difficulty and adaptively selects samples within optimal difficulty ranges. By explicitly incorporating category-specific insights, our approach achieves a more balanced and representative coreset, addressing key shortcomings of prior methods. Comprehensive theoretical analysis validates the rationale behind adaptive budget allocation and sample selection, while extensive experiments across 14 diverse datasets and model architectures demonstrate NUCS's consistent improvements over state-of-the-art methods, achieving superior accuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCS matches full-data training accuracy while retaining just 30% of samples and reducing computation time by 60%. Our work highlights the importance of characterizing category difficulty in coreset selection, offering a robust and data-efficient solution for transfer learning.","authors":["Hanyu Zhang","Zhen Xing","Wenxuan Yang","Chenxi Ma","Weimin Tan","Bo Yan"],"url":"https://arxiv.org/abs/2504.13234"}
{"created":"2025-04-21","title":"NNTile: a machine learning framework capable of training extremely large GPT language models on a single node","abstract":"This study presents an NNTile framework for training large deep neural networks in heterogeneous clusters. The NNTile is based on a StarPU library, which implements task-based parallelism and schedules all provided tasks onto all available processing units (CPUs and GPUs). It means that a particular operation, necessary to train a large neural network, can be performed on any of the CPU cores or GPU devices, depending on automatic scheduling decisions. Such an approach shifts the burden of deciding where to compute and when to communicate from a human being to an automatic decision maker, whether a simple greedy heuristic or a complex AI-based software. The performance of the presented tool for training large language models is demonstrated in extensive numerical experiments.","authors":["Aleksandr Mikhalev","Aleksandr Katrutsa","Konstantin Sozykin","Ivan Oseledets"],"url":"https://arxiv.org/abs/2504.13236"}
{"created":"2025-04-21","title":"ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs","abstract":"With the proliferation of task-specific large language models, delta compression has emerged as a method to mitigate the resource challenges of deploying numerous such models by effectively compressing the delta model parameters. Previous delta-sparsification methods either remove parameters randomly or truncate singular vectors directly after singular value decomposition (SVD). However, these methods either disregard parameter importance entirely or evaluate it with too coarse a granularity. In this work, we introduce ImPart, a novel importance-aware delta sparsification approach. Leveraging SVD, it dynamically adjusts sparsity ratios of different singular vectors based on their importance, effectively retaining crucial task-specific knowledge even at high sparsity ratios. Experiments show that ImPart achieves state-of-the-art delta sparsification performance, demonstrating $2\\times$ higher compression ratio than baselines at the same performance level. When integrated with existing methods, ImPart sets a new state-of-the-art on delta quantization and model merging.","authors":["Yan Yang","Yixia Li","Hongru Wang","Xuetao Wei","Jianqiao Yu","Yun Chen","Guanhua Chen"],"url":"https://arxiv.org/abs/2504.13237"}
{"created":"2025-04-21","title":"Recursive Deep Inverse Reinforcement Learning","abstract":"Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.","authors":["Paul Ghanem","Michael Potter","Owen Howell","Pau Closas","Alireza Ramezani","Deniz Erdogmus","Robert Platt","Tales Imbiriba"],"url":"https://arxiv.org/abs/2504.13241"}
{"created":"2025-04-21","title":"Dynamic Memory-enhanced Transformer for Hyperspectral Image Classification","abstract":"Hyperspectral image (HSI) classification remains a challenging task due to the intricate spatial-spectral correlations. Existing transformer models excel in capturing long-range dependencies but often suffer from information redundancy and attention inefficiencies, limiting their ability to model fine-grained relationships crucial for HSI classification. To overcome these limitations, this work proposes MemFormer, a lightweight and memory-enhanced transformer. MemFormer introduces a memory-enhanced multi-head attention mechanism that iteratively refines a dynamic memory module, enhancing feature extraction while reducing redundancy across layers. Additionally, a dynamic memory enrichment strategy progressively captures complex spatial and spectral dependencies, leading to more expressive feature representations. To further improve structural consistency, we incorporate a spatial-spectral positional encoding (SSPE) tailored for HSI data, ensuring continuity without the computational burden of convolution-based approaches. Extensive experiments on benchmark datasets demonstrate that MemFormer achieves superior classification accuracy, outperforming state-of-the-art methods.","authors":["Muhammad Ahmad","Manuel Mazzara","Salvatore Distefano","Adil Mehmood Khan"],"url":"https://arxiv.org/abs/2504.13242"}
{"created":"2025-04-21","title":"CPG-EVAL: A Multi-Tiered Benchmark for Evaluating the Chinese Pedagogical Grammar Competence of Large Language Models","abstract":"Purpose: The rapid emergence of large language models (LLMs) such as ChatGPT has significantly impacted foreign language education, yet their pedagogical grammar competence remains under-assessed. This paper introduces CPG-EVAL, the first dedicated benchmark specifically designed to evaluate LLMs' knowledge of pedagogical grammar within the context of foreign language instruction. Methodology: The benchmark comprises five tasks designed to assess grammar recognition, fine-grained grammatical distinction, categorical discrimination, and resistance to linguistic interference. Findings: Smaller-scale models can succeed in single language instance tasks, but struggle with multiple instance tasks and interference from confusing instances. Larger-scale models show better resistance to interference but still have significant room for accuracy improvement. The evaluation indicates the need for better instructional alignment and more rigorous benchmarks, to effectively guide the deployment of LLMs in educational contexts. Value: This study offers the first specialized, theory-driven, multi-tiered benchmark framework for systematically evaluating LLMs' pedagogical grammar competence in Chinese language teaching contexts. CPG-EVAL not only provides empirical insights for educators, policymakers, and model developers to better gauge AI's current abilities in educational settings, but also lays the groundwork for future research on improving model alignment, enhancing educational suitability, and ensuring informed decision-making concerning LLM integration in foreign language instruction.","authors":["Dong Wang"],"url":"https://arxiv.org/abs/2504.13261"}
{"created":"2025-04-21","title":"Causal-Copilot: An Autonomous Causal Analysis Agent","abstract":"Causal analysis plays a foundational role in scientific discovery and reliable decision-making, yet it remains largely inaccessible to domain experts due to its conceptual and algorithmic complexity. This disconnect between causal methodology and practical usability presents a dual challenge: domain experts are unable to leverage recent advances in causal learning, while causal researchers lack broad, real-world deployment to test and refine their methods. To address this, we introduce Causal-Copilot, an autonomous agent that operationalizes expert-level causal analysis within a large language model framework. Causal-Copilot automates the full pipeline of causal analysis for both tabular and time-series data -- including causal discovery, causal inference, algorithm selection, hyperparameter optimization, result interpretation, and generation of actionable insights. It supports interactive refinement through natural language, lowering the barrier for non-specialists while preserving methodological rigor. By integrating over 20 state-of-the-art causal analysis techniques, our system fosters a virtuous cycle -- expanding access to advanced causal methods for domain experts while generating rich, real-world applications that inform and advance causal theory. Empirical evaluations demonstrate that Causal-Copilot achieves superior performance compared to existing baselines, offering a reliable, scalable, and extensible solution that bridges the gap between theoretical sophistication and real-world applicability in causal analysis.","authors":["Xinyue Wang","Kun Zhou","Wenyi Wu","Har Simrat Singh","Fang Nan","Songyao Jin","Aryan Philip","Saloni Patnaik","Hou Zhu","Shivam Singh","Parjanya Prashant","Qian Shen","Biwei Huang"],"url":"https://arxiv.org/abs/2504.13263"}
{"created":"2025-04-21","title":"Graph Learning at Scale: Characterizing and Optimizing Pre-Propagation GNNs","abstract":"Graph neural networks (GNNs) are widely used for learning node embeddings in graphs, typically adopting a message-passing scheme. This approach, however, leads to the neighbor explosion problem, with exponentially growing computational and memory demands as layers increase. Graph sampling has become the predominant method for scaling GNNs to large graphs, mitigating but not fully solving the issue. Pre-propagation GNNs (PP-GNNs) represent a new class of models that decouple feature propagation from training through pre-processing, addressing neighbor explosion in theory. Yet, their practical advantages and system-level optimizations remain underexplored. This paper provides a comprehensive characterization of PP-GNNs, comparing them with graph-sampling-based methods in training efficiency, scalability, and accuracy. While PP-GNNs achieve comparable accuracy, we identify data loading as the key bottleneck for training efficiency and input expansion as a major scalability challenge. To address these issues, we propose optimized data loading schemes and tailored training methods that improve PP-GNN training throughput by an average of 15$\\times$ over the PP-GNN baselines, with speedup of up to 2 orders of magnitude compared to sampling-based GNNs on large graph benchmarks. Our implementation is publicly available at https://github.com/cornell-zhang/preprop-gnn.","authors":["Zichao Yue","Chenhui Deng","Zhiru Zhang"],"url":"https://arxiv.org/abs/2504.13266"}
{"created":"2025-04-21","title":"Leveraging Functional Encryption and Deep Learning for Privacy-Preserving Traffic Forecasting","abstract":"Over the past few years, traffic congestion has continuously plagued the nation's transportation system creating several negative impacts including longer travel times, increased pollution rates, and higher collision risks. To overcome these challenges, Intelligent Transportation Systems (ITS) aim to improve mobility and vehicular systems, ensuring higher levels of safety by utilizing cutting-edge technologies, sophisticated sensing capabilities, and innovative algorithms. Drivers' participatory sensing, current/future location reporting, and machine learning algorithms have considerably improved real-time congestion monitoring and future traffic management. However, each driver's sensitive spatiotemporal location information can create serious privacy concerns. To address these challenges, we propose in this paper a secure, privacy-preserving location reporting and traffic forecasting system that guarantees privacy protection of driver data while maintaining high traffic forecasting accuracy. Our novel k-anonymity scheme utilizes functional encryption to aggregate encrypted location information submitted by drivers while ensuring the privacy of driver location data. Additionally, using the aggregated encrypted location information as input, this research proposes a deep learning model that incorporates a Convolutional-Long Short-Term Memory (Conv-LSTM) module to capture spatial and short-term temporal features and a Bidirectional Long Short-Term Memory (Bi-LSTM) module to recover long-term periodic patterns for traffic forecasting. With extensive evaluation on real datasets, we demonstrate the effectiveness of the proposed scheme with less than 10% mean absolute error for a 60-minute forecasting horizon, all while protecting driver privacy.","authors":["Isaac Adom","Mohammmad Iqbal Hossain","Hassan Mahmoud","Ahmad Alsharif","Mahmoud Nabil Mahmoud","Yang Xiao"],"url":"https://arxiv.org/abs/2504.13267"}
{"created":"2025-04-21","title":"Dichotomy for orderings?","abstract":"The class $NP$ can be defined by the means of Monadic Second-Order logic going back to Fagin and Feder-Vardi, and also by forbidden expanded substructures (cf. lifts and shadows of Kun and Ne\\v{s}et\\v{r}il). Consequently, for such problems there is no dichotomy, unlike for $CSP$'s. We prove that ordering problems for graphs defined by finitely many forbidden ordered subgraphs still capture the class $NP$. In particular, we refute a conjecture of Hell, Mohar and Rafiey that dichotomy holds for this class. On the positive side, we confirm the conjecture of Duffus, Ginn and R\\\"odl that ordering problems defined by one single biconnected ordered graph are $NP$-complete but for the ordered complete graph. An interesting feature appeared and was noticed several times. For finite sets of biconnected patterns (which may be colored structures or ordered structures) complexity dichotomy holds. A principal tool for obtaining this result is known as the Sparse Incomparability Lemma, a classical result in the theory of homomorphisms of graphs and structures. We prove it here in the setting of ordered graphs as a Temporal Sparse Incomparability Lemma for orderings. Interestingly, our proof involves the Lov\\'asz Local Lemma.","authors":["G\\'abor Kun","Jaroslav Ne\\v{s}et\\v{r}il"],"url":"https://arxiv.org/abs/2504.13268"}
{"created":"2025-04-21","title":"Using LLMs for Library Migration","abstract":"Library migration is the process of replacing a used software library with another library that provides similar functionality. Manual library migration is time-consuming and error prone, as it requires developers to understand the APIs of both libraries, map them, and perform the necessary code transformations. Due to its difficulty, most of the existing automated techniques and tooling stop at the API mapping stage or support a limited set of code transformations. On the other hand, Large Language Models (LLMs) are good at generating and transforming code and finding similar code, which are necessary upstream tasks for library migration. Such capabilities suggest that LLMs may be suitable for library migration. Therefore, in this paper, we investigate the effectiveness of LLMs for migration between Python libraries. We evaluate three LLMs, LLama 3.1, GPT-4o mini, and GPT-4o on PyMigBench, where we migrate 321 real-world library migrations that include 2,989 migration-related code changes. We measure the correctness of the migration results in two ways. We first compare the LLM's migrated code with the developers' migrated code in the benchmark and then run the unit tests available in the client repositories. We find that LLama 3.1, GPT-4o mini, and GPT-4o correctly migrate 89%, 89%, and 94% of the migration-related code changes. respectively. We also find that 36%, 52% and 64% of the LLama 3.1, GPT-4o mini, and GPT-4o migrations pass the same tests that passed in the developer's migration. Overall, our results suggest that LLMs can be effective in migrating code between libraries, but we also identify cases that pose difficulties for the LLM.","authors":["Md Mohayeminul Islam","Ajay Kumar Jha","May Mahmoud","Ildar Akhmetov","Sarah Nadi"],"url":"https://arxiv.org/abs/2504.13272"}
{"created":"2025-04-21","title":"CardioFit: A WebGL-Based Tool for Fast and Efficient Parameterization of Cardiac Action Potential Models to Fit User-Provided Data","abstract":"Cardiac action potential models allow examination of a variety of cardiac dynamics, including how behavior may change under specific interventions. To study a specific scenario, including patient-specific cases, model parameter sets must be found that accurately reproduce the dynamics of interest. To facilitate this complex and time-consuming process, we present an interactive browser-based tool that uses the particle swarm optimization (PSO) algorithm implemented in JavaScript and taking advantage of the WebGL API for hardware acceleration. Our tool allows rapid customization and can find low-error fittings to user-provided voltage time series or action potential duration data from multiple cycle lengths in a few iterations (10-32), corresponding to a runtime of a few seconds on most machines. Additionally, our tool focuses on ease of use and flexibility, providing a webpage interface that allows users to select a subset of parameters to fit, set the range of values each parameter is allowed to assume, and control the PSO algorithm hyperparameters. We demonstrate our tool's utility by fitting a variety of models to different datasets, showing how convergence is affected by model choice, dataset properties, and PSO algorithmic settings, and explaining new insights gained about the physiological and dynamical roles of the model parameters.","authors":["Darby I. Cairns (School of Computational Science and Engineering","Georgia Institute of Technology","Atlanta","GA","United States)","Maxfield R. Comstock (School of Computational Science and Engineering","Georgia Institute of Technology","Atlanta","GA","United States)","Flavio H. Fenton (School of Physics","Georgia Institute of Technology","Atlanta","GA","United States)","Elizabeth M. Cherry (School of Computational Science and Engineering","Georgia Institute of Technology","Atlanta","GA","United States)"],"url":"https://arxiv.org/abs/2504.13274"}
{"created":"2025-04-21","title":"ChartQA-X: Generating Explanations for Charts","abstract":"The ability to interpret and explain complex information from visual data in charts is crucial for data-driven decision-making. In this work, we address the challenge of providing explanations alongside answering questions about chart images. We present ChartQA-X, a comprehensive dataset comprising various chart types with 28,299 contextually relevant questions, answers, and detailed explanations. These explanations are generated by prompting six different models and selecting the best responses based on metrics such as faithfulness, informativeness, coherence, and perplexity. Our experiments show that models fine-tuned on our dataset for explanation generation achieve superior performance across various metrics and demonstrate improved accuracy in question-answering tasks on new datasets. By integrating answers with explanatory narratives, our approach enhances the ability of intelligent agents to convey complex information effectively, improve user understanding, and foster trust in the generated responses.","authors":["Shamanthak Hegde","Pooyan Fazli","Hasti Seifi"],"url":"https://arxiv.org/abs/2504.13275"}
{"created":"2025-04-21","title":"Strategic Planning of Stealthy Backdoor Attacks in Markov Decision Processes","abstract":"This paper investigates backdoor attack planning in stochastic control systems modeled as Markov Decision Processes (MDPs). In a backdoor attack, the adversary provides a control policy that behaves well in the original MDP to pass the testing phase. However, when such a policy is deployed with a trigger policy, which perturbs the system dynamics at runtime, it optimizes the attacker's objective instead. To solve jointly the control policy and its trigger, we formulate the attack planning problem as a constrained optimal planning problem in an MDP with augmented state space, with the objective to maximize the attacker's total rewards in the system with an activated trigger, subject to the constraint that the control policy is near optimal in the original MDP. We then introduce a gradient-based optimization method to solve the optimal backdoor attack policy as a pair of coordinated control and trigger policies. Experimental results from a case study validate the effectiveness of our approach in achieving stealthy backdoor attacks.","authors":["Xinyi Wei","Shuo Han","Ahmed H. Hemida","Charles A. Kamhoua","Jie Fu"],"url":"https://arxiv.org/abs/2504.13276"}
{"created":"2025-04-21","title":"Interpersonal Theory of Suicide as a Lens to Examine Suicidal Ideation in Online Spaces","abstract":"Suicide is a critical global public health issue, with millions experiencing suicidal ideation (SI) each year. Online spaces enable individuals to express SI and seek peer support. While prior research has revealed the potential of detecting SI using machine learning and natural language analysis, a key limitation is the lack of a theoretical framework to understand the underlying factors affecting high-risk suicidal intent. To bridge this gap, we adopted the Interpersonal Theory of Suicide (IPTS) as an analytic lens to analyze 59,607 posts from Reddit's r/SuicideWatch, categorizing them into SI dimensions (Loneliness, Lack of Reciprocal Love, Self Hate, and Liability) and risk factors (Thwarted Belongingness, Perceived Burdensomeness, and Acquired Capability of Suicide). We found that high-risk SI posts express planning and attempts, methods and tools, and weaknesses and pain. In addition, we also examined the language of supportive responses through psycholinguistic and content analyses to find that individuals respond differently to different stages of Suicidal Ideation (SI) posts. Finally, we explored the role of AI chatbots in providing effective supportive responses to suicidal ideation posts. We found that although AI improved structural coherence, expert evaluations highlight persistent shortcomings in providing dynamic, personalized, and deeply empathetic support. These findings underscore the need for careful reflection and deeper understanding in both the development and consideration of AI-driven interventions for effective mental health support.","authors":["Soorya Ram Shimgekar","Violeta J. Rodriguez","Paul A. Bloom","Dong Whi Yoo","Koustuv Saha"],"url":"https://arxiv.org/abs/2504.13277"}
{"created":"2025-04-21","title":"A Stochastic Nonlinear Dynamical System for Smoothing Noisy Eye Gaze Data","abstract":"In this study, we address the challenges associated with accurately determining gaze location on a screen, which is often compromised by noise from factors such as eye tracker limitations, calibration drift, ambient lighting changes, and eye blinks. We propose the use of an extended Kalman filter (EKF) to smooth the gaze data collected during eye-tracking experiments, and systematically explore the interaction of different system parameters. Our results demonstrate that the EKF significantly reduces noise, leading to a marked improvement in tracking accuracy. Furthermore, we show that our proposed stochastic nonlinear dynamical model aligns well with real experimental data and holds promise for applications in related fields.","authors":["Thoa Thieu","Roderick Melnik"],"url":"https://arxiv.org/abs/2504.13278"}
{"created":"2025-04-21","title":"Just Another Hour on TikTok: Reverse-engineering unique identifiers to obtain a complete slice of TikTok","abstract":"TikTok is now a massive platform, and has a deep impact on global events. But for all the preliminary studies done on it, there are still issues with determining fundamental characteristics of the platform. We develop a method to extract a representative sample from a specific time range on TikTok, and use it to collect >99\\% of posts from a full hour on the platform, alongside a dataset of >99\\% of posts from a single minute from each hour of a day. Through this, we obtain post metadata, video media data, and comments from a close to complete slice of TikTok. Using this dataset, we report the critical statistics of the platform, notably estimating a total of 117 million posts produced on the day we looked at on TikTok.","authors":["Benjamin Steel","Miriam Schirmer","Derek Ruths","Juergen Pfeffer"],"url":"https://arxiv.org/abs/2504.13279"}
{"created":"2025-04-21","title":"LIFT+: Lightweight Fine-Tuning for Long-Tail Learning","abstract":"The fine-tuning paradigm has emerged as a prominent approach for addressing long-tail learning tasks in the era of foundation models. However, the impact of fine-tuning strategies on long-tail learning performance remains unexplored. In this work, we disclose that existing paradigms exhibit a profound misuse of fine-tuning methods, leaving significant room for improvement in both efficiency and accuracy. Specifically, we reveal that heavy fine-tuning (fine-tuning a large proportion of model parameters) can lead to non-negligible performance deterioration on tail classes, whereas lightweight fine-tuning demonstrates superior effectiveness. Through comprehensive theoretical and empirical validation, we identify this phenomenon as stemming from inconsistent class conditional distributions induced by heavy fine-tuning. Building on this insight, we propose LIFT+, an innovative lightweight fine-tuning framework to optimize consistent class conditions. Furthermore, LIFT+ incorporates semantic-aware initialization, minimalist data augmentation, and test-time ensembling to enhance adaptation and generalization of foundation models. Our framework provides an efficient and accurate pipeline that facilitates fast convergence and model compactness. Extensive experiments demonstrate that LIFT+ significantly reduces both training epochs (from $\\sim$100 to $\\leq$15) and learned parameters (less than 1%), while surpassing state-of-the-art approaches by a considerable margin. The source code is available at https://github.com/shijxcs/LIFT-plus.","authors":["Jiang-Xin Shi","Tong Wei","Yu-Feng Li"],"url":"https://arxiv.org/abs/2504.13282"}
{"created":"2025-04-21","title":"Sentiment Analysis on the young people's perception about the mobile Internet costs in Senegal","abstract":"Internet penetration rates in Africa are rising steadily, and mobile Internet is getting an even bigger boost with the availability of smartphones. Young people are increasingly using the Internet, especially social networks, and Senegal is no exception to this revolution. Social networks have become the main means of expression for young people. Despite this evolution in Internet access, there are few operators on the market, which limits the alternatives available in terms of value for money. In this paper, we will look at how young people feel about the price of mobile Internet in Senegal, in relation to the perceived quality of the service, through their comments on social networks. We scanned a set of Twitter and Facebook comments related to the subject and applied a sentiment analysis model to gather their general feelings.","authors":["Derguene Mbaye","Madoune Robert Seye","Moussa Diallo","Mamadou Lamine Ndiaye","Djiby Sow","Dimitri Samuel Adjanohoun","Tatiana Mbengue","Cheikh Samba Wade","De Roulet Pablo","Jean-Claude Baraka Munyaka","Jerome Chenal"],"url":"https://arxiv.org/abs/2504.13284"}
{"created":"2025-04-21","title":"A Model Predictive Control Approach for Quadrotor Cruise Control","abstract":"This paper investigates the application of a Model Predictive Controller (MPC) for the cruise control system of a quadrotor, focusing on hovering point stabilization and reference tracking. Initially, a full-state-feedback MPC is designed for the ideal scenario. To account for real-world conditions, a constant disturbance is introduced to the quadrotor, simulating a gust of wind in a specific direction. In response, an output-feedback offset-free MPC is developed to stabilize the quadrotor while rejecting the disturbance. We validate the design of the controller by conducting stability analysis, as well as numerical simulations under different circumstances. It is shown that the designed controller can achieve all the expected goals for the cruise control, including reference tracking and disturbance rejection. This project was implemented using Python and the CVXPY library for convex optimization.","authors":["Zekai Chen","Leon Kehler"],"url":"https://arxiv.org/abs/2504.13286"}
{"created":"2025-04-21","title":"Integrated Control and Active Perception in POMDPs for Temporal Logic Tasks and Information Acquisition","abstract":"This paper studies the synthesis of a joint control and active perception policy for a stochastic system modeled as a partially observable Markov decision process (POMDP), subject to temporal logic specifications. The POMDP actions influence both system dynamics (control) and the emission function (perception). Beyond task completion, the planner seeks to maximize information gain about certain temporal events (the secret) through coordinated perception and control. To enable active information acquisition, we introduce minimizing the Shannon conditional entropy of the secret as a planning objective, alongside maximizing the probability of satisfying the temporal logic formula within a finite horizon. Using a variant of observable operators in hidden Markov models (HMMs) and POMDPs, we establish key properties of the conditional entropy gradient with respect to policy parameters. These properties facilitate efficient policy gradient computation. We validate our approach through graph-based examples, inspired by common security applications with UAV surveillance.","authors":["Chongyang Shi","Michael R. Dorothy","Jie Fu"],"url":"https://arxiv.org/abs/2504.13288"}
{"created":"2025-04-21","title":"Let Me Grok for You: Accelerating Grokking via Embedding Transfer from a Weaker Model","abstract":"''Grokking'' is a phenomenon where a neural network first memorizes training data and generalizes poorly, but then suddenly transitions to near-perfect generalization after prolonged training. While intriguing, this delayed generalization phenomenon compromises predictability and efficiency. Ideally, models should generalize directly without delay. To this end, this paper proposes GrokTransfer, a simple and principled method for accelerating grokking in training neural networks, based on the key observation that data embedding plays a crucial role in determining whether generalization is delayed. GrokTransfer first trains a smaller, weaker model to reach a nontrivial (but far from optimal) test performance. Then, the learned input embedding from this weaker model is extracted and used to initialize the embedding in the target, stronger model. We rigorously prove that, on a synthetic XOR task where delayed generalization always occurs in normal training, GrokTransfer enables the target model to generalize directly without delay. Moreover, we demonstrate that, across empirical studies of different tasks, GrokTransfer effectively reshapes the training dynamics and eliminates delayed generalization, for both fully-connected neural networks and Transformers.","authors":["Zhiwei Xu","Zhiyu Ni","Yixin Wang","Wei Hu"],"url":"https://arxiv.org/abs/2504.13292"}
{"created":"2025-04-21","title":"TAXI: Traveling Salesman Problem Accelerator with X-bar-based Ising Macros Powered by SOT-MRAMs and Hierarchical Clustering","abstract":"Ising solvers with hierarchical clustering have shown promise for large-scale Traveling Salesman Problems (TSPs), in terms of latency and energy. However, most of these methods still face unacceptable quality degradation as the problem size increases beyond a certain extent. Additionally, their hardware-agnostic adoptions limit their ability to fully exploit available hardware resources. In this work, we introduce TAXI -- an in-memory computing-based TSP accelerator with crossbar(Xbar)-based Ising macros. Each macro independently solves a TSP sub-problem, obtained by hierarchical clustering, without the need for any off-macro data movement, leading to massive parallelism. Within the macro, Spin-Orbit-Torque (SOT) devices serve as compact energy-efficient random number generators enabling rapid \"natural annealing\". By leveraging hardware-algorithm co-design, TAXI offers improvements in solution quality, speed, and energy-efficiency on TSPs up to 85,900 cities (the largest TSPLIB instance). TAXI produces solutions that are only 22% and 20% longer than the Concorde solver's exact solution on 33,810 and 85,900 city TSPs, respectively. TAXI outperforms a current state-of-the-art clustering-based Ising solver, being 8x faster on average across 20 benchmark problems from TSPLib.","authors":["Sangmin Yoo","Amod Holla","Sourav Sanyal","Dong Eun Kim","Francesca Iacopi","Dwaipayan Biswas","James Myers","Kaushik Roy"],"url":"https://arxiv.org/abs/2504.13294"}
{"created":"2025-04-21","title":"Enhanced Pruning Strategy for Multi-Component Neural Architectures Using Component-Aware Graph Analysis","abstract":"Deep neural networks (DNNs) deliver outstanding performance, but their complexity often prohibits deployment in resource-constrained settings. Comprehensive structured pruning frameworks based on parameter dependency analysis reduce model size with specific regard to computational performance. When applying them to Multi-Component Neural Architectures (MCNAs), they risk network integrity by removing large parameter groups. We introduce a component-aware pruning strategy, extending dependency graphs to isolate individual components and inter-component flows. This creates smaller, targeted pruning groups that conserve functional integrity. Demonstrated effectively on a control task, our approach achieves greater sparsity and reduced performance degradation, opening a path for optimizing complex, multi-component DNNs efficiently.","authors":["Ganesh Sundaram","Jonas Ulmen","Daniel G\\\"orges"],"url":"https://arxiv.org/abs/2504.13296"}
{"created":"2025-04-21","title":"Weak Cube R-CNN: Weakly Supervised 3D Detection using only 2D Bounding Boxes","abstract":"Monocular 3D object detection is an essential task in computer vision, and it has several applications in robotics and virtual reality. However, 3D object detectors are typically trained in a fully supervised way, relying extensively on 3D labeled data, which is labor-intensive and costly to annotate. This work focuses on weakly-supervised 3D detection to reduce data needs using a monocular method that leverages a singlecamera system over expensive LiDAR sensors or multi-camera setups. We propose a general model Weak Cube R-CNN, which can predict objects in 3D at inference time, requiring only 2D box annotations for training by exploiting the relationship between 2D projections of 3D cubes. Our proposed method utilizes pre-trained frozen foundation 2D models to estimate depth and orientation information on a training set. We use these estimated values as pseudo-ground truths during training. We design loss functions that avoid 3D labels by incorporating information from the external models into the loss. In this way, we aim to implicitly transfer knowledge from these large foundation 2D models without having access to 3D bounding box annotations. Experimental results on the SUN RGB-D dataset show increased performance in accuracy compared to an annotation time equalized Cube R-CNN baseline. While not precise for centimetre-level measurements, this method provides a strong foundation for further research.","authors":["Andreas Lau Hansen","Lukas Wanzeck","Dim P. Papadopoulos"],"url":"https://arxiv.org/abs/2504.13297"}
{"created":"2025-04-21","title":"DYNAMITE: Dynamic Defense Selection for Enhancing Machine Learning-based Intrusion Detection Against Adversarial Attacks","abstract":"The rapid proliferation of the Internet of Things (IoT) has introduced substantial security vulnerabilities, highlighting the need for robust Intrusion Detection Systems (IDS). Machine learning-based intrusion detection systems (ML-IDS) have significantly improved threat detection capabilities; however, they remain highly susceptible to adversarial attacks. While numerous defense mechanisms have been proposed to enhance ML-IDS resilience, a systematic approach for selecting the most effective defense against a specific adversarial attack remains absent. To address this challenge, we propose Dynamite, a dynamic defense selection framework that enhances ML-IDS by intelligently identifying and deploying the most suitable defense using a machine learning-driven selection mechanism. Our results demonstrate that Dynamite achieves a 96.2% reduction in computational time compared to the Oracle, significantly decreasing computational overhead while preserving strong prediction performance. Dynamite also demonstrates an average F1-score improvement of 76.7% over random defense and 65.8% over the best static state-of-the-art defense.","authors":["Jing Chen","Onat Gungor","Zhengli Shang","Elvin Li","Tajana Rosing"],"url":"https://arxiv.org/abs/2504.13301"}
{"created":"2025-04-21","title":"Training Autoencoders Using Stochastic Hessian-Free Optimization with LSMR","abstract":"Hessian-free (HF) optimization has been shown to effectively train deep autoencoders (Martens, 2010). In this paper, we aim to accelerate HF training of autoencoders by reducing the amount of data used in training. HF utilizes the conjugate gradient algorithm to estimate update directions. Instead, we propose using the LSMR method, which is known for effectively solving large sparse linear systems. We also incorporate Chapelle & Erhan (2011)'s improved preconditioner for HF optimization. In addition, we introduce a new mini-batch selection algorithm to mitigate overfitting. Our algorithm starts with a small subset of the training data and gradually increases the mini-batch size based on (i) variance estimates obtained during the computation of a mini-batch gradient (Byrd et al., 2012) and (ii) the relative decrease in objective value for the validation data. Our experimental results demonstrate that our stochastic Hessian-free optimization, using the LSMR method and the new sample selection algorithm, leads to rapid training of deep autoencoders with improved generalization error.","authors":["Ibrahim Emirahmetoglu","David E. Stewart"],"url":"https://arxiv.org/abs/2504.13302"}
{"created":"2025-04-21","title":"Implementation of Field Programmable Gate Arrays (FPGAs) in Extremely Cold Environments for Space and Cryogenic Computing Applications","abstract":"The operation of CMOS Field Programmable Gate Arrays (FPGAs) at extremely cold environments as low as 4 K is demonstrated. Various FPGA and periphery hardware design techniques spanning from HDL design to improvements of peripheral circuitry such as discrete voltage regulators are displayed, and their respective performances are reported. While general operating conditions for voltage regulators are widened, FPGAs see a broader temperature range with improved jitter performance, reduced LUT delays, and enhanced transceiver performance at extremely low temperatures.","authors":["Christopher Lewis","Drew Sellers","Michael Hamilton"],"url":"https://arxiv.org/abs/2504.13305"}
{"created":"2025-04-21","title":"Acoustic to Articulatory Inversion of Speech; Data Driven Approaches, Challenges, Applications, and Future Scope","abstract":"This review is focused on the data-driven approaches applied in different applications of Acoustic-to-Articulatory Inversion (AAI) of speech. This review paper considered the relevant works published in the last ten years (2011-2021). The selection criteria includes (a) type of AAI - Speaker Dependent and Speaker Independent AAI, (b) objectives of the work - Articulatory approximation, Articulatory Feature space selection and Automatic Speech Recognition (ASR), explore the correlation between acoustic and articulatory features, and framework for Computer-assisted language training, (c) Corpus - Simultaneously recorded speech (wav) and medical imaging models such as ElectroMagnetic Articulography (EMA), Electropalatography (EPG), Laryngography, Electroglottography (EGG), X-ray Cineradiography, Ultrasound, and real-time Magnetic Resonance Imaging (rtMRI), (d) Methods or models - recent works are considered, and therefore all the works are based on machine learning, (e) Evaluation - as AAI is a non-linear regression problem, the performance evaluation is mostly done by Correlation Coefficient (CC), Root Mean Square Error (RMSE), and also considered Mean Square Error (MSE), and Mean Format Error (MFE). The practical application of the AAI model can provide a better and user-friendly interpretable image feedback system of articulatory positions, especially tongue movement. Such trajectory feedback system can be used to provide phonetic, language, and speech therapy for pathological subjects.","authors":["Leena G Pillai","D. Muhammad Noorul Mubarak"],"url":"https://arxiv.org/abs/2504.13308"}
{"created":"2025-04-21","title":"SAR Object Detection with Self-Supervised Pretraining and Curriculum-Aware Sampling","abstract":"Object detection in satellite-borne Synthetic Aperture Radar (SAR) imagery holds immense potential in tasks such as urban monitoring and disaster response. However, the inherent complexities of SAR data and the scarcity of annotations present significant challenges in the advancement of object detection in this domain. Notably, the detection of small objects in satellite-borne SAR images poses a particularly intricate problem, because of the technology's relatively low spatial resolution and inherent noise. Furthermore, the lack of large labelled SAR datasets hinders the development of supervised deep learning-based object detection models. In this paper, we introduce TRANSAR, a novel self-supervised end-to-end vision transformer-based SAR object detection model that incorporates masked image pre-training on an unlabeled SAR image dataset that spans more than $25,700$ km\\textsuperscript{2} ground area. Unlike traditional object detection formulation, our approach capitalises on auxiliary binary semantic segmentation, designed to segregate objects of interest during the post-tuning, especially the smaller ones, from the background. In addition, to address the innate class imbalance due to the disproportion of the object to the image size, we introduce an adaptive sampling scheduler that dynamically adjusts the target class distribution during training based on curriculum learning and model feedback. This approach allows us to outperform conventional supervised architecture such as DeepLabv3 or UNet, and state-of-the-art self-supervised learning-based arhitectures such as DPT, SegFormer or UperNet, as shown by extensive evaluations on benchmark SAR datasets.","authors":["Yasin Almalioglu","Andrzej Kucik","Geoffrey French","Dafni Antotsiou","Alexander Adam","Cedric Archambeau"],"url":"https://arxiv.org/abs/2504.13310"}
{"created":"2025-04-21","title":"The role of boundary constraints in simulating a nonlocal Gray-Scott model","abstract":"We present second-order algorithms to approximate the solution of a nonlocal Gray-Scott model that is known to generate interesting spatio-temporal structures such as pulse and stripes solutions. Our algorithms rely on a quadrature method for the spatial discretization and the method of lines using a second-order Adams-Bashforth for the time marching. We focus on studying the impact of the type of boundary constraints, e.g. nonlocal Dirichlet/Neumann or local periodic, and the type of nonlocal diffusion, i.e. integral operator with thin- or fat-tailed kernels, on the generation of pulse solutions. Our numerical investigations show that when the spread of the kernel is large, i.e. when the model is nonlocal, both the type of kernels and type of boundary constraints have a strong impact on the solutions profiles.","authors":["Loic Cappanera","Gabriela Jaramillo"],"url":"https://arxiv.org/abs/2504.13312"}
{"created":"2025-04-21","title":"On the Definition of Robustness and Resilience of AI Agents for Real-time Congestion Management","abstract":"The European Union's Artificial Intelligence (AI) Act defines robustness, resilience, and security requirements for high-risk sectors but lacks detailed methodologies for assessment. This paper introduces a novel framework for quantitatively evaluating the robustness and resilience of reinforcement learning agents in congestion management. Using the AI-friendly digital environment Grid2Op, perturbation agents simulate natural and adversarial disruptions by perturbing the input of AI systems without altering the actual state of the environment, enabling the assessment of AI performance under various scenarios. Robustness is measured through stability and reward impact metrics, while resilience quantifies recovery from performance degradation. The results demonstrate the framework's effectiveness in identifying vulnerabilities and improving AI robustness and resilience for critical applications.","authors":["Timothy Tjhay","Ricardo J. Bessa","Jose Paulos"],"url":"https://arxiv.org/abs/2504.13314"}
{"created":"2025-04-21","title":"Robust Estimation of Battery State of Health Using Reference Voltage Trajectory","abstract":"Accurate estimation of state of health (SOH) is critical for battery applications. Current model-based SOH estimation methods typically rely on low C-rate constant current tests to extract health parameters like solid phase volume fraction and lithium-ion stoichiometry, which are often impractical in real-world scenarios due to time and operational constraints. Additionally, these methods are susceptible to modeling uncertainties that can significantly degrade the estimation accuracy, especially when jointly estimating multiple parameters. In this paper, we present a novel reference voltage-based method for robust battery SOH estimation. This method utilizes the voltage response of a battery under a predefined current excitation at the beginning of life (BOL) as a reference to compensate for modeling uncertainty. As the battery degrades, the same excitation is applied to generate the voltage response, which is compared with the BOL trajectory to estimate the key health parameters accurately. The current excitation is optimally designed using the Particle Swarm Optimization algorithm to maximize the information content of the target parameters. Simulation results demonstrate that our proposed method significantly improves parameter estimation accuracy under different degradation levels, compared to conventional methods relying only on direct voltage measurements. Furthermore, our method jointly estimates four key SOH parameters in only 10 minutes, making it practical for real-world battery health diagnostics, e.g., fast testing to enable battery repurposing.","authors":["Rui Huang","Jackson Fogelquist","Xinfan Lin"],"url":"https://arxiv.org/abs/2504.13324"}
{"created":"2025-04-21","title":"From Bayesian Asymptotics to General Large-Scale MIMO Capacity","abstract":"We present a unifying framework that bridges Bayesian asymptotics and information theory to analyze the asymptotic Shannon capacity of general large-scale MIMO channels including ones with non-linearities or imperfect hardware. We derive both an analytic capacity formula and an asymptotically optimal input distribution in the large-antenna regime, each of which depends solely on the single-output channel's Fisher information through a term we call the (tilted) Jeffreys' factor. We demonstrate how our method applies broadly to scenarios with clipping, coarse quantization (including 1-bit ADCs), phase noise, fading with imperfect CSI, and even optical Poisson channels. Our asymptotic analysis motivates a practical approach to constellation design via a compander-like transformation. Furthermore, we introduce a low-complexity receiver structure that approximates the log-likelihood by quantizing the channel outputs into finitely many bins, enabling near-capacity performance with computational complexity independent of the output dimension. Numerical results confirm that the proposed method unifies and simplifies many previously intractable MIMO capacity problems and reveals how the Fisher information alone governs the channel's asymptotic behavior.","authors":["Sheng Yang","Richard Combes"],"url":"https://arxiv.org/abs/2504.13325"}
{"created":"2025-04-21","title":"The Future of Work is Blended, Not Hybrid","abstract":"The way we work is no longer hybrid -- it is blended with AI co-workers, automated decisions, and virtual presence reshaping human roles, agency, and expertise. We now work through AI, with our outputs shaped by invisible algorithms. AI's infiltration into knowledge, creative, and service work is not just about automation, but concerns redistribution of agency, creativity, and control. How do we deal with physical and distributed AI-mediated workspaces? What happens when algorithms co-author reports, and draft our creative work? In this provocation, we argue that hybrid work is obsolete. Blended work is the future, not just in physical and virtual spaces but in how human effort and AI output become inseparable. We argue this shift demands urgent attention to AI-mediated work practices, work-life boundaries, physical-digital interactions, and AI transparency and accountability. The question is not whether we accept it, but whether we actively shape it before it shapes us.","authors":["Marios Constantinides","Himanshu Verma","Shadan Sadeghian","Abdallah El Ali"],"url":"https://arxiv.org/abs/2504.13330"}
{"created":"2025-04-21","title":"Wearable-Derived Behavioral and Physiological Biomarkers for Classifying Unipolar and Bipolar Depression Severity","abstract":"Depression is a complex mental disorder characterized by a diverse range of observable and measurable indicators that go beyond traditional subjective assessments. Recent research has increasingly focused on objective, passive, and continuous monitoring using wearable devices to gain more precise insights into the physiological and behavioral aspects of depression. However, most existing studies primarily distinguish between healthy and depressed individuals, adopting a binary classification that fails to capture the heterogeneity of depressive disorders. In this study, we leverage wearable devices to predict depression subtypes-specifically unipolar and bipolar depression-aiming to identify distinctive biomarkers that could enhance diagnostic precision and support personalized treatment strategies. To this end, we introduce the CALYPSO dataset, designed for non-invasive detection of depression subtypes and symptomatology through physiological and behavioral signals, including blood volume pulse, electrodermal activity, body temperature, and three-axis acceleration. Additionally, we establish a benchmark on the dataset using well-known features and standard machine learning methods. Preliminary results indicate that features related to physical activity, extracted from accelerometer data, are the most effective in distinguishing between unipolar and bipolar depression, achieving an accuracy of $96.77\\%$. Temperature-based features also showed high discriminative power, reaching an accuracy of $93.55\\%$. These findings highlight the potential of physiological and behavioral monitoring for improving the classification of depressive subtypes, paving the way for more tailored clinical interventions.","authors":["Yassine Ouzar","Cl\\'emence Nineuil","Fouad Boutaleb","Emery Pierson","Ali Amad","Mohamed Daoudi"],"url":"https://arxiv.org/abs/2504.13331"}
{"created":"2025-04-21","title":"Utilizing Virtual Reality for Wildfire Evacuation Training","abstract":"The risk of loss of lives and property damage has increased all around the world in recent years as wildfire seasons have become longer and fires have become larger. Knowing how to prepare and evacuate safely is critical, yet it may be daunting for those who have never experienced a wildfire threat before. This paper considers the potential for utilizing virtual reality (VR) technology to prepare people for an evacuation scenario. We discuss the unique affordances of VR for this type of work, as well as the initial steps in creating a training simulation. We also explore the next steps for what a tool like this may mean for the future of evacuation preparedness training.","authors":["Alison Crosby","MJ Johns","Katherine Isbister","Sri Kurniawan"],"url":"https://arxiv.org/abs/2504.13334"}
{"created":"2025-04-21","title":"Multiharmonic algorithms for contrast-enhanced ultrasound","abstract":"Harmonic generation plays a crucial role in contrast-enhanced ultrasound, both for imaging and therapeutic applications. However, accurately capturing these nonlinear effects is computationally very demanding when using traditional time-domain approaches. To address this issue, in this work, we develop algorithms based on a time discretization that uses a multiharmonic Ansatz applied to a model that couples the Westervelt equation for acoustic pressure with a volume-based approximation of the Rayleigh--Plesset equation for the dynamics of microbubble contrast agents. We first rigorously establish the existence of time-periodic solutions for this Westervelt-ODE system. We then derive a multiharmonic representation of the system under time-periodic excitation and develop iterative algorithms that rely on the successive computation of higher harmonics under the assumption of real-valued or complex solution fields. In the real-valued setting, we characterize the approximation error in terms of the number of harmonics and a contribution owing to the fixed-point iteration. Finally, we investigate these algorithms numerically and illustrate how the number of harmonics and presence of microbubbles influence the propagation of acoustic waves.","authors":["Vanja Nikoli\\'c","Teresa Rauscher"],"url":"https://arxiv.org/abs/2504.13335"}
{"created":"2025-04-21","title":"Volume Encoding Gaussians: Transfer Function-Agnostic 3D Gaussians for Volume Rendering","abstract":"While HPC resources are increasingly being used to produce adaptively refined or unstructured volume datasets, current research in applying machine learning-based representation to visualization has largely ignored this type of data. To address this, we introduce Volume Encoding Gaussians (VEG), a novel 3D Gaussian-based representation for scientific volume visualization focused on unstructured volumes. Unlike prior 3D Gaussian Splatting (3DGS) methods that store view-dependent color and opacity for each Gaussian, VEG decouple the visual appearance from the data representation by encoding only scalar values, enabling transfer-function-agnostic rendering of 3DGS models for interactive scientific visualization. VEG are directly initialized from volume datasets, eliminating the need for structure-from-motion pipelines like COLMAP. To ensure complete scalar field coverage, we introduce an opacity-guided training strategy, using differentiable rendering with multiple transfer functions to optimize our data representation. This allows VEG to preserve fine features across the full scalar range of a dataset while remaining independent of any specific transfer function. Each Gaussian is scaled and rotated to adapt to local geometry, allowing for efficient representation of unstructured meshes without storing mesh connectivity and while using far fewer primitives. Across a diverse set of data, VEG achieve high reconstruction quality, compress large volume datasets by up to 3600x, and support lightning-fast rendering on commodity GPUs, enabling interactive visualization of large-scale structured and unstructured volumes.","authors":["Landon Dyken","Andres Sewell","Will Usher","Steve Petruzza","Sidharth Kumar"],"url":"https://arxiv.org/abs/2504.13339"}
{"created":"2025-04-21","title":"Levenshtein's Sequence Reconstruction Problem and Results for Larger Alphabet Sizes","abstract":"The problem of storing large amounts of information safely for a long period of time has become essential. One of the most promising new data storage mediums are the polymer-based data storage systems, like the DNA-storage system. These storage systems are highly durable and they consume very little energy to store the data. When information is retrieved from a storage, however, several different types of errors may occur in the process. It is known that the Levenshtein's sequence reconstruction framework is well-suited to overcome such errors and to retrieve the original information. Many of the previous results regarding Levenshtein's sequence reconstruction method are so far given only for the binary alphabet. However, larger alphabets are natural for the polymer-based data storage. For example, the quaternary alphabet is suitable for DNA-storage due to the four amino-acids in DNA. The results for larger alphabets often require, as we will see in this work, different and more complicated techniques compared to the binary case. Moreover, we show that an increase in the alphabet size makes some error types behave rather surprisingly.","authors":["Ville Junnila","Tero Laihonen","Tuomo Lehtil\\\"a"],"url":"https://arxiv.org/abs/2504.13342"}
{"created":"2025-04-21","title":"Physical Reservoir Computing in Hook-Shaped Rover Wheel Spokes for Real-Time Terrain Identification","abstract":"Effective terrain detection in unknown environments is crucial for safe and efficient robotic navigation. Traditional methods often rely on computationally intensive data processing, requiring extensive onboard computational capacity and limiting real-time performance for rovers. This study presents a novel approach that combines physical reservoir computing with piezoelectric sensors embedded in rover wheel spokes for real-time terrain identification. By leveraging wheel dynamics, terrain-induced vibrations are transformed into high-dimensional features for machine learning-based classification. Experimental results show that strategically placing three sensors on the wheel spokes achieves 90$\\%$ classification accuracy, which demonstrates the accuracy and feasibility of the proposed method. The experiment results also showed that the system can effectively distinguish known terrains and identify unknown terrains by analyzing their similarity to learned categories. This method provides a robust, low-power framework for real-time terrain classification and roughness estimation in unstructured environments, enhancing rover autonomy and adaptability.","authors":["Xiao Jin","Zihan Wang","Zhenhua Yu","Changrak Choi","Kalind Carpenter","Thrishantha Nanayakkara"],"url":"https://arxiv.org/abs/2504.13348"}
{"created":"2025-04-21","title":"Chain-of-Modality: Learning Manipulation Programs from Multimodal Human Videos with Vision-Language-Models","abstract":"Learning to perform manipulation tasks from human videos is a promising approach for teaching robots. However, many manipulation tasks require changing control parameters during task execution, such as force, which visual data alone cannot capture. In this work, we leverage sensing devices such as armbands that measure human muscle activities and microphones that record sound, to capture the details in the human manipulation process, and enable robots to extract task plans and control parameters to perform the same task. To achieve this, we introduce Chain-of-Modality (CoM), a prompting strategy that enables Vision Language Models to reason about multimodal human demonstration data -- videos coupled with muscle or audio signals. By progressively integrating information from each modality, CoM refines a task plan and generates detailed control parameters, enabling robots to perform manipulation tasks based on a single multimodal human video prompt. Our experiments show that CoM delivers a threefold improvement in accuracy for extracting task plans and control parameters compared to baselines, with strong generalization to new task setups and objects in real-world robot experiments. Videos and code are available at https://chain-of-modality.github.io","authors":["Chen Wang","Fei Xia","Wenhao Yu","Tingnan Zhang","Ruohan Zhang","C. Karen Liu","Li Fei-Fei","Jie Tan","Jacky Liang"],"url":"https://arxiv.org/abs/2504.13351"}
{"created":"2025-04-21","title":"A Formalization of Co-Transcriptional Splicing as an Operation on Formal Languages","abstract":"RNA co-transcriptionality is the process where RNA sequences are spliced while being transcribed from DNA templates. This process holds potential as a key tool for molecular programming. Co-transcriptional folding has been shown to be programmable for assembling nano-scale RNA structures, and recent advances have proven its Turing universality. While post-transcriptional splicing has been extensively studied, co-transcriptional splicing is gaining attention for its potential to save resources and space in molecular systems. However, its unpredictability has limited its practical applications. In this paper, we focus on engineering co-transcriptional splicing, moving beyond natural occurrences to program RNA sequences that produce specific target sequences through DNA templates. We introduce a formal model of co-transcriptional splicing, defined by constant-, linear-, and logarithmic-bounded hairpin deletion operations, as well as an unbounded hairpin deletion operation. We examine the complexity of the template constructability problem associated with these operations and study the closure properties of the languages they generate, providing insights for RNA template design in molecular programming systems.","authors":["Da-Jung Cho","Szil\\'ard Zsolt Fazekas","Shinnosuke Seki","Max Wiedenh\\\"oft"],"url":"https://arxiv.org/abs/2504.13354"}
{"created":"2025-04-21","title":"Denoising and Reconstruction of Nonlinear Dynamics using Truncated Reservoir Computing","abstract":"Measurements acquired from distributed physical systems are often sparse and noisy. Therefore, signal processing and system identification tools are required to mitigate noise effects and reconstruct unobserved dynamics from limited sensor data. However, this process is particularly challenging because the fundamental equations governing the dynamics are largely unavailable in practice. Reservoir Computing (RC) techniques have shown promise in efficiently simulating dynamical systems through an unstructured and efficient computation graph comprising a set of neurons with random connectivity. However, the potential of RC to operate in noisy regimes and distinguish noise from the primary dynamics of the system has not been fully explored. This paper presents a novel RC method for noise filtering and reconstructing nonlinear dynamics, offering a novel learning protocol associated with hyperparameter optimization. The performance of the RC in terms of noise intensity, noise frequency content, and drastic shifts in dynamical parameters are studied in two illustrative examples involving the nonlinear dynamics of the Lorenz attractor and adaptive exponential integrate-and-fire system (AdEx). It is shown that the denoising performance improves via truncating redundant nodes and edges of the computing reservoir, as well as properly optimizing the hyperparameters, e.g., the leakage rate, the spectral radius, the input connectivity, and the ridge regression parameter. Furthermore, the presented framework shows good generalization behavior when tested for reconstructing unseen attractors from the bifurcation diagram. Compared to the Extended Kalman Filter (EKF), the presented RC framework yields competitive accuracy at low signal-to-noise ratios (SNRs) and high-frequency ranges.","authors":["Omid Sedehi","Manish Yadav","Merten Stender","Sebastian Oberst"],"url":"https://arxiv.org/abs/2504.13355"}
{"created":"2025-04-21","title":"GraphQLer: Enhancing GraphQL Security with Context-Aware API Testing","abstract":"GraphQL is an open-source data query and manipulation language for web applications, offering a flexible alternative to RESTful APIs. However, its dynamic execution model and lack of built-in security mechanisms expose it to vulnerabilities such as unauthorized data access, denial-of-service (DoS) attacks, and injections. Existing testing tools focus on functional correctness, often overlooking security risks stemming from query interdependencies and execution context. This paper presents GraphQLer, the first context-aware security testing framework for GraphQL APIs. GraphQLer constructs a dependency graph to analyze relationships among mutations, queries, and objects, capturing critical interdependencies. It chains related queries and mutations to reveal authentication and authorization flaws, access control bypasses, and resource misuse. Additionally, GraphQLer tracks internal resource usage to uncover data leakage, privilege escalation, and replay attack vectors. We assess GraphQLer on various GraphQL APIs, demonstrating improved testing coverage - averaging a 35% increase, with up to 84% in some cases - compared to top-performing baselines. Remarkably, this is achieved in less time, making GraphQLer suitable for time-sensitive contexts. GraphQLer also successfully detects a known CVE and potential vulnerabilities in large-scale production APIs. These results underline GraphQLer's utility in proactively securing GraphQL APIs through automated, context-aware vulnerability detection.","authors":["Omar Tsai","Jianing Li","Tsz Tung Cheung","Lejing Huang","Hao Zhu","Jianrui Xiao","Iman Sharafaldin","Mohammad A. Tayebi"],"url":"https://arxiv.org/abs/2504.13358"}
{"created":"2025-04-21","title":"Cost-of-Pass: An Economic Framework for Evaluating Language Models","abstract":"The widespread adoption of AI systems in the economy hinges on their ability to generate economic value that outweighs their inference costs. Evaluating this tradeoff requires metrics that account for both performance and costs. We propose a framework grounded in production theory for evaluating language models by combining accuracy and inference cost. We introduce \"cost-of-pass\", the expected monetary cost of generating a correct solution. We then define the \"frontier cost-of-pass\" as the minimum cost-of-pass achievable across available models or the \"human-expert, using the approximate cost of hiring an expert. Our analysis reveals distinct economic insights. First, lightweight models are most cost-effective for basic quantitative tasks, large models for knowledge-intensive ones, and reasoning models for complex quantitative problems, despite higher per-token costs. Second, tracking this frontier cost-of-pass over the past year reveals significant progress, particularly for complex quantitative tasks where the cost has roughly halved every few months. Third, to trace key innovations driving this progress, we examine counterfactual frontiers: estimates of cost-efficiency without specific model classes. We find that innovations in lightweight, large, and reasoning models have been essential for pushing the frontier in basic quantitative, knowledge-intensive, and complex quantitative tasks, respectively. Finally, we assess the cost-reductions afforded by common inference-time techniques like majority voting and self-refinement, finding that their marginal accuracy gains rarely justify their costs. Our findings underscore that complementary model-level innovations are the primary drivers of cost-efficiency, and our economic framework provides a principled tool for measuring this progress and guiding deployment.","authors":["Mehmet Hamza Erol","Batu El","Mirac Suzgun","Mert Yuksekgonul","James Zou"],"url":"https://arxiv.org/abs/2504.13359"}
{"created":"2025-04-21","title":"In between myth and reality: AI for math -- a case study in category theory","abstract":"Recently, there is an increasing interest in understanding the performance of AI systems in solving math problems. A multitude of tests have been performed, with mixed conclusions. In this paper we discuss an experiment we have made in the direction of mathematical research, with two of the most prominent contemporary AI systems. One of the objective of this experiment is to get an understanding of how AI systems can assist mathematical research. Another objective is to support the AI systems developers by formulating suggestions for directions of improvement.","authors":["R\\u{a}zvan Diaconescu"],"url":"https://arxiv.org/abs/2504.13360"}
{"created":"2025-04-21","title":"Automated Taxi Booking Operations for Autonomous Vehicles","abstract":"In a conventional taxi booking system, all taxi operations are mostly done by a decision made by drivers which is hard to implement in unmanned vehicles. To address this challenge, we introduce a taxi booking system which assists autonomous vehicles to pick up customers. The system can allocate an autonomous vehicle (AV) as well as plan service trips for a customer request. We use our own AV to serve a customer who uses a mobile application to make his taxi request. Apart from customer and AV, we build a server to monitor customers and AVs. It also supports inter-communication between a customer and an AV once AV decided to pick up a customer.","authors":["Linh Van Ma","Shoaib Azam","Farzeen Munir","Moongu Jeon"],"url":"https://arxiv.org/abs/2504.13361"}
{"created":"2025-04-21","title":"AI-Empowered Integrated Sensing and Communications","abstract":"Integrating sensing and communication (ISAC) can help overcome the challenges of limited spectrum and expensive hardware, leading to improved energy and cost efficiency. While full cooperation between sensing and communication can result in significant performance gains, achieving optimal performance requires efficient designs of unified waveforms and beamformers for joint sensing and communication. Sophisticated statistical signal processing and multi-objective optimization techniques are necessary to balance the competing design requirements of joint sensing and communication tasks. Since model-based analytical approaches may be suboptimal or overly complex, deep learning emerges as a powerful tool for developing data-driven signal processing algorithms, particularly when optimal algorithms are unknown or when known algorithms are too complex for real-time implementation. Unified waveform and beamformer design problems for ISAC fall into this category, where fundamental design trade-offs exist between sensing and communication performance metrics, and the underlying models may be inadequate or incomplete. This article explores the application of artificial intelligence (AI) in ISAC designs to enhance efficiency and reduce complexity. We emphasize the integration benefits through AI-driven ISAC designs, prioritizing the development of unified waveforms, constellations, and beamforming strategies for both sensing and communication. To illustrate the practical potential of AI-driven ISAC, we present two case studies on waveform and beamforming design, demonstrating how unsupervised learning and neural network-based optimization can effectively balance performance, complexity, and implementation constraints.","authors":["Mojtaba Vaezi","Gayan Aruma Baduge","Esa Ollila","Sergiy A. Vorobyov"],"url":"https://arxiv.org/abs/2504.13363"}
{"created":"2025-04-21","title":"VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture","abstract":"In modern smart agriculture, object detection plays a crucial role by enabling automation, precision farming, and monitoring of resources. From identifying crop health and pest infestations to optimizing harvesting processes, accurate object detection enhances both productivity and sustainability. However, training object detection models often requires large-scale data collection and raises privacy concerns, particularly when sensitive agricultural data is distributed across farms. To address these challenges, we propose VLLFL, a vision-language model-based lightweight federated learning framework (VLLFL). It harnesses the generalization and context-aware detection capabilities of the vision-language model (VLM) and leverages the privacy-preserving nature of federated learning. By training a compact prompt generator to boost the performance of the VLM deployed across different farms, VLLFL preserves privacy while reducing communication overhead. Experimental results demonstrate that VLLFL achieves 14.53% improvement in the performance of VLM while reducing 99.3% communication overhead. Spanning tasks from identifying a wide variety of fruits to detecting harmful animals in agriculture, the proposed framework offers an efficient, scalable, and privacy-preserving solution specifically tailored to agricultural applications.","authors":["Long Li","Jiajia Li","Dong Chen","Lina Pu","Haibo Yao","Yanbo Huang"],"url":"https://arxiv.org/abs/2504.13365"}
{"created":"2025-04-21","title":"THOUGHTTERMINATOR: Benchmarking, Calibrating, and Mitigating Overthinking in Reasoning Models","abstract":"Reasoning models have demonstrated impressive performance on difficult tasks that traditional language models struggle at. However, many are plagued with the problem of overthinking--generating large amounts of unnecessary tokens which don't improve accuracy on a question. We introduce approximate measures of problem-level difficulty and demonstrate that a clear relationship between problem difficulty and optimal token spend exists, and evaluate how well calibrated a variety of reasoning models are in terms of efficiently allocating the optimal token count. We find that in general, reasoning models are poorly calibrated, particularly on easy problems. To evaluate calibration on easy questions we introduce DUMB500, a dataset of extremely easy math, reasoning, code, and task problems, and jointly evaluate reasoning model on these simple examples and extremely difficult examples from existing frontier benchmarks on the same task domain. Finally, we introduce THOUGHTTERMINATOR, a training-free black box decoding technique that significantly improves reasoning model calibration.","authors":["Xiao Pu","Michael Saxon","Wenyue Hua","William Yang Wang"],"url":"https://arxiv.org/abs/2504.13367"}
{"created":"2025-04-21","title":"An Optimal Discriminator Weighted Imitation Perspective for Reinforcement Learning","abstract":"We introduce Iterative Dual Reinforcement Learning (IDRL), a new method that takes an optimal discriminator-weighted imitation view of solving RL. Our method is motivated by a simple experiment in which we find training a discriminator using the offline dataset plus an additional expert dataset and then performing discriminator-weighted behavior cloning gives strong results on various types of datasets. That optimal discriminator weight is quite similar to the learned visitation distribution ratio in Dual-RL, however, we find that current Dual-RL methods do not correctly estimate that ratio. In IDRL, we propose a correction method to iteratively approach the optimal visitation distribution ratio in the offline dataset given no addtional expert dataset. During each iteration, IDRL removes zero-weight suboptimal transitions using the learned ratio from the previous iteration and runs Dual-RL on the remaining subdataset. This can be seen as replacing the behavior visitation distribution with the optimized visitation distribution from the previous iteration, which theoretically gives a curriculum of improved visitation distribution ratios that are closer to the optimal discriminator weight. We verify the effectiveness of IDRL on various kinds of offline datasets, including D4RL datasets and more realistic corrupted demonstrations. IDRL beats strong Primal-RL and Dual-RL baselines in terms of both performance and stability, on all datasets.","authors":["Haoran Xu","Shuozhe Li","Harshit Sikchi","Scott Niekum","Amy Zhang"],"url":"https://arxiv.org/abs/2504.13368"}
{"created":"2025-04-21","title":"Multi-Sensor Fusion-Based Mobile Manipulator Remote Control for Intelligent Smart Home Assistance","abstract":"This paper proposes a wearable-controlled mobile manipulator system for intelligent smart home assistance, integrating MEMS capacitive microphones, IMU sensors, vibration motors, and pressure feedback to enhance human-robot interaction. The wearable device captures forearm muscle activity and converts it into real-time control signals for mobile manipulation. The wearable device achieves an offline classification accuracy of 88.33\\%\\ across six distinct movement-force classes for hand gestures by using a CNN-LSTM model, while real-world experiments involving five participants yield a practical accuracy of 83.33\\%\\ with an average system response time of 1.2 seconds. In Human-Robot synergy in navigation and grasping tasks, the robot achieved a 98\\%\\ task success rate with an average trajectory deviation of only 3.6 cm. Finally, the wearable-controlled mobile manipulator system achieved a 93.3\\%\\ gripping success rate, a transfer success of 95.6\\%\\, and a full-task success rate of 91.1\\%\\ during object grasping and transfer tests, in which a total of 9 object-texture combinations were evaluated. These three experiments' results validate the effectiveness of MEMS-based wearable sensing combined with multi-sensor fusion for reliable and intuitive control of assistive robots in smart home scenarios.","authors":["Xiao Jin","Bo Xiao","Huijiang Wang","Wendong Wang","Zhenhua Yu"],"url":"https://arxiv.org/abs/2504.13370"}
{"created":"2025-04-21","title":"The Impact of AI on the Cyber Offense-Defense Balance and the Character of Cyber Conflict","abstract":"Unlike other domains of conflict, and unlike other fields with high anticipated risk from AI, the cyber domain is intrinsically digital with a tight feedback loop between AI training and cyber application. Cyber may have some of the largest and earliest impacts from AI, so it is important to understand how the cyber domain may change as AI continues to advance. Our approach reviewed the literature, collecting nine arguments that have been proposed for offensive advantage in cyber conflict and nine proposed arguments for defensive advantage. We include an additional forty-eight arguments that have been proposed to give cyber conflict and competition its character as collected separately by Healey, Jervis, and Nandrajog. We then consider how each of those arguments and propositions might change with varying degrees of AI advancement. We find that the cyber domain is too multifaceted for a single answer to whether AI will enhance offense or defense broadly. AI will improve some aspects, hinder others, and leave some aspects unchanged. We collect and present forty-four ways that we expect AI to impact the cyber offense-defense balance and the character of cyber conflict and competition.","authors":["Andrew J. Lohn"],"url":"https://arxiv.org/abs/2504.13371"}
{"created":"2025-04-21","title":"Integration of a Graph-Based Path Planner and Mixed-Integer MPC for Robot Navigation in Cluttered Environments","abstract":"The ability to update a path plan is a required capability for autonomous mobile robots navigating through uncertain environments. This paper proposes a re-planning strategy using a multilayer planning and control framework for cases where the robot's environment is partially known. A medial axis graph-based planner defines a global path plan based on known obstacles where each edge in the graph corresponds to a unique corridor. A mixed-integer model predictive control (MPC) method detects if a terminal constraint derived from the global plan is infeasible, subject to a non-convex description of the local environment. Infeasibility detection is used to trigger efficient global re-planning via medial axis graph edge deletion. The proposed re-planning strategy is demonstrated experimentally.","authors":["Joshua A. Robbins","Stephen J. Harnett","Andrew F. Thompson","Sean Brennan","Herschel C. Pangborn"],"url":"https://arxiv.org/abs/2504.13372"}
{"created":"2025-04-21","title":"Geometric adaptive smoothed aggregation multigrid for discontinuous Galerkin discretisations","abstract":"We present a geometric multigrid solver based on adaptive smoothed aggregation suitable for Discontinuous Galerkin (DG) discretisations. Mesh hierarchies are formed via domain decomposition techniques, and the method is applicable to fully unstructured meshes using arbitrary element shapes. Furthermore, the method can be employed for a wide range of commonly used DG numerical fluxes for first- and second-order PDEs including the Interior Penalty and the Local Discontinuous Galerkin methods. We demonstrate excellent and mesh-independent convergence for a range of problems including the Poisson equation, and convection-diffusion for a range of P\\'eclet numbers.","authors":["Yulong Pan","Michael Lindsey","Per-Olof Persson"],"url":"https://arxiv.org/abs/2504.13373"}
{"created":"2025-04-21","title":"The generalized scalar auxiliary variable applied to the incompressible Boussinesq Equation","abstract":"This paper introduces a second-order time discretization for solving the incompressible Boussinesq equation. It uses the generalized scalar auxiliary variable (GSAV) and a backward differentiation formula (BDF), based on a Taylor expansion around $t^{n+k}$ for $k\\geq3$. An exponential time integrator is used for the auxiliary variable to ensure stability independent of the time step size. We give rigorous asymptotic error estimates of the time-stepping scheme, thereby justifying its accuracy and stability. The scheme is reformulated into one amenable to a $H^1$-conforming finite element discretization. Finally, we validate our theoretical results with numerical experiments using a Taylor--Hood-based finite element discretization and show its applicability to large-scale 3-dimensional problems.","authors":["Andreas Wagner","Barbara Wohlmuth","Jan Zawallich"],"url":"https://arxiv.org/abs/2504.13374"}
{"created":"2025-04-21","title":"SMPL-GPTexture: Dual-View 3D Human Texture Estimation using Text-to-Image Generation Models","abstract":"Generating high-quality, photorealistic textures for 3D human avatars remains a fundamental yet challenging task in computer vision and multimedia field. However, real paired front and back images of human subjects are rarely available with privacy, ethical and cost of acquisition, which restricts scalability of the data. Additionally, learning priors from image inputs using deep generative models, such as GANs or diffusion models, to infer unseen regions such as the human back often leads to artifacts, structural inconsistencies, or loss of fine-grained detail. To address these issues, we present SMPL-GPTexture (skinned multi-person linear model - general purpose Texture), a novel pipeline that takes natural language prompts as input and leverages a state-of-the-art text-to-image generation model to produce paired high-resolution front and back images of a human subject as the starting point for texture estimation. Using the generated paired dual-view images, we first employ a human mesh recovery model to obtain a robust 2D-to-3D SMPL alignment between image pixels and the 3D model's UV coordinates for each views. Second, we use an inverted rasterization technique that explicitly projects the observed colour from the input images into the UV space, thereby producing accurate, complete texture maps. Finally, we apply a diffusion-based inpainting module to fill in the missing regions, and the fusion mechanism then combines these results into a unified full texture map. Extensive experiments shows that our SMPL-GPTexture can generate high resolution texture aligned with user's prompts.","authors":["Mingxiao Tu","Shuchang Ye","Hoijoon Jung","Jinman Kim"],"url":"https://arxiv.org/abs/2504.13378"}
{"created":"2025-04-21","title":"Radial Basis Function Techniques for Neural Field Models on Surfaces","abstract":"We present a numerical framework for solving neural field equations on surfaces using Radial Basis Function (RBF) interpolation and quadrature. Neural field models describe the evolution of macroscopic brain activity, but modeling studies often overlook the complex geometry of curved cortical domains. Traditional numerical methods, such as finite element or spectral methods, can be computationally expensive and challenging to implement on irregular domains. In contrast, RBF-based methods provide a flexible alternative by offering interpolation and quadrature schemes that efficiently handle arbitrary geometries with high-order accuracy. We first develop an RBF-based interpolatory projection framework for neural field models on general surfaces. Quadrature for both flat and curved domains are derived in detail, ensuring high-order accuracy and stability as they depend on RBF hyperparameters (basis functions, augmenting polynomials, and stencil size). Through numerical experiments, we demonstrate the convergence of our method, highlighting its advantages over traditional approaches in terms of flexibility and accuracy. We conclude with an exposition of numerical simulations of spatiotemporal activity on complex surfaces, illustrating the method's ability to capture complex wave propagation patterns.","authors":["Sage B Shaw","Zachary P Kilpatrick","Daniele Avitabile"],"url":"https://arxiv.org/abs/2504.13379"}
{"created":"2025-04-21","title":"Improved Decoding Algorithm of BD-LRPC Codes","abstract":"A Bounded-Degree Low-Rank Parity-Check (BD-LRPC) code is a rank-metric code that admits a parity-check matrix whose support is generated by a set of powers of an element. This specific structure of the parity-check matrix was employed to enhance the first phase of the decoding algorithm through the expansion of the syndrome support. However, this expansion decreases the probability of recovering the error support in the second phase of the decoding algorithm. This paper introduces a novel method based on successive intersections to recover the error support. This method offers two key advantages: it increases the probability of successful decoding and enables the decoding of a greater number of errors.","authors":["Hermann Tchatchiem Kamche"],"url":"https://arxiv.org/abs/2504.13381"}
{"created":"2025-04-21","title":"EXAM: Exploiting Exclusive System-Level Cache in Apple M-Series SoCs for Enhanced Cache Occupancy Attacks","abstract":"Cache occupancy attacks exploit the shared nature of cache hierarchies to infer a victim's activities by monitoring overall cache usage, unlike access-driven cache attacks that focus on specific cache lines or sets. There exists some prior work that target the last-level cache (LLC) of Intel processors, which is inclusive of higher-level caches, and L2 caches of ARM systems. In this paper, we target the System-Level Cache (SLC) of Apple M-series SoCs, which is exclusive to higher-level CPU caches. We address the challenges of the exclusiveness and propose a suite of SLC-cache occupancy attacks, the first of its kind, where an adversary can monitor GPU and other CPU cluster activities from their own CPU cluster. We first discover the structure of SLC in Apple M1 SOC and various policies pertaining to access and sharing through reverse engineering. We propose two attacks against websites. One is a coarse-grained fingerprinting attack, recognizing which website is accessed based on their different GPU memory access patterns monitored through the SLC occupancy channel. The other attack is a fine-grained pixel stealing attack, which precisely monitors the GPU memory usage for rendering different pixels, through the SLC occupancy channel. Third, we introduce a novel screen capturing attack which works beyond webpages, with the monitoring granularity of 57 rows of pixels (there are 1600 rows for the screen). This significantly expands the attack surface, allowing the adversary to retrieve any screen display, posing a substantial new threat to system security. Our findings reveal critical vulnerabilities in Apple's M-series SoCs and emphasize the urgent need for effective countermeasures against cache occupancy attacks in heterogeneous computing environments.","authors":["Tianhong Xu","Aidong Adam Ding","Yunsi Fei"],"url":"https://arxiv.org/abs/2504.13385"}
{"created":"2025-04-21","title":"Supervising 3D Talking Head Avatars with Analysis-by-Audio-Synthesis","abstract":"In order to be widely applicable, speech-driven 3D head avatars must articulate their lips in accordance with speech, while also conveying the appropriate emotions with dynamically changing facial expressions. The key problem is that deterministic models produce high-quality lip-sync but without rich expressions, whereas stochastic models generate diverse expressions but with lower lip-sync quality. To get the best of both, we seek a stochastic model with accurate lip-sync. To that end, we develop a new approach based on the following observation: if a method generates realistic 3D lip motions, it should be possible to infer the spoken audio from the lip motion. The inferred speech should match the original input audio, and erroneous predictions create a novel supervision signal for training 3D talking head avatars with accurate lip-sync. To demonstrate this effect, we propose THUNDER (Talking Heads Under Neural Differentiable Elocution Reconstruction), a 3D talking head avatar framework that introduces a novel supervision mechanism via differentiable sound production. First, we train a novel mesh-to-speech model that regresses audio from facial animation. Then, we incorporate this model into a diffusion-based talking avatar framework. During training, the mesh-to-speech model takes the generated animation and produces a sound that is compared to the input speech, creating a differentiable analysis-by-audio-synthesis supervision loop. Our extensive qualitative and quantitative experiments demonstrate that THUNDER significantly improves the quality of the lip-sync of talking head avatars while still allowing for generation of diverse, high-quality, expressive facial animations.","authors":["Radek Dan\\v{e}\\v{c}ek","Carolin Schmitt","Senya Polikovsky","Michael J. Black"],"url":"https://arxiv.org/abs/2504.13386"}
{"created":"2025-04-21","title":"Bibliometric Analysis of Scientific Publications on Blockchain Research and Applications","abstract":"Since the introduction of Bitcoin in 2008, blockchain technology has garnered widespread attention. Scholars from various research fields, countries, and institutions have published a significant number of papers on this subject. However, there is currently a lack of comprehensive analysis specifically focusing on the scientific publications in the field of blockchain.","authors":["Lingfeng Bao","Jiameng Yang","Xiaohu Yang","Chunming Rong"],"url":"https://arxiv.org/abs/2504.13387"}
{"created":"2025-04-21","title":"A mean teacher algorithm for unlearning of language models","abstract":"One of the goals of language model unlearning is to reduce memorization of selected text instances while retaining the model's general abilities. Despite various proposed methods, reducing memorization of large datasets without noticeable degradation in model utility remains challenging. In this paper, we investigate the mean teacher algorithm (Tarvainen & Valpola, 2017), a simple proximal optimization method from continual learning literature that gradually modifies the teacher model. We show that the mean teacher can approximate a trajectory of a slow natural gradient descent (NGD), which inherently seeks low-curvature updates that are less likely to degrade the model utility. While slow NGD can suffer from vanishing gradients, we introduce a new unlearning loss called \"negative log-unlikelihood\" (NLUL) that avoids this problem. We show that the combination of mean teacher and NLUL improves some metrics on the MUSE benchmarks (Shi et al., 2024).","authors":["Yegor Klochkov"],"url":"https://arxiv.org/abs/2504.13388"}
{"created":"2025-04-21","title":"Understanding Adolescents' Perceptions of Benefits and Risks in Health AI Technologies through Design Fiction","abstract":"Despite the growing research on users' perceptions of health AI, adolescents' perspectives remain underexplored. This study explores adolescents' perceived benefits and risks of health AI technologies in clinical and personal health settings. Employing Design Fiction, we conducted interviews with 16 adolescents (aged 13-17) using four fictional design scenarios that represent current and future health AI technologies as probes. Our findings reveal that with a positive yet cautious attitude, adolescents envision unique benefits and risks specific to their age group. While health AI technologies were seen as valuable learning resources, they also raised concerns about confidentiality with their parents. Additionally, we identified several factors, such as severity of health conditions and previous experience with AI, influencing their perceptions of trust and privacy in health AI. We explore how these insights can inform the future of design of health AI technologies to support learning, engagement, and trust as adolescents navigate their healthcare journey.","authors":["Jamie Lee","Kyuha Jung","Erin Gregg Newman","Emilie Chow","Yunan Chen"],"url":"https://arxiv.org/abs/2504.13389"}
{"created":"2025-04-21","title":"POET: Supporting Prompting Creativity and Personalization with Automated Expansion of Text-to-Image Generation","abstract":"State-of-the-art visual generative AI tools hold immense potential to assist users in the early ideation stages of creative tasks -- offering the ability to generate (rather than search for) novel and unprecedented (instead of existing) images of considerable quality that also adhere to boundless combinations of user specifications. However, many large-scale text-to-image systems are designed for broad applicability, yielding conventional output that may limit creative exploration. They also employ interaction methods that may be difficult for beginners. Given that creative end users often operate in diverse, context-specific ways that are often unpredictable, more variation and personalization are necessary. We introduce POET, a real-time interactive tool that (1) automatically discovers dimensions of homogeneity in text-to-image generative models, (2) expands these dimensions to diversify the output space of generated images, and (3) learns from user feedback to personalize expansions. An evaluation with 28 users spanning four creative task domains demonstrated POET's ability to generate results with higher perceived diversity and help users reach satisfaction in fewer prompts during creative tasks, thereby prompting them to deliberate and reflect more on a wider range of possible produced results during the co-creative process. Focusing on visual creativity, POET offers a first glimpse of how interaction techniques of future text-to-image generation tools may support and align with more pluralistic values and the needs of end users during the ideation stages of their work.","authors":["Evans Xu Han","Alice Qian Zhang","Hong Shen","Haiyi Zhu","Paul Pu Liang","Jane Hsieh"],"url":"https://arxiv.org/abs/2504.13392"}
{"created":"2025-04-21","title":"BeetleVerse: A study on taxonomic classification of ground beetles","abstract":"Ground beetles are a highly sensitive and speciose biological indicator, making them vital for monitoring biodiversity. However, they are currently an underutilized resource due to the manual effort required by taxonomic experts to perform challenging species differentiations based on subtle morphological differences, precluding widespread applications. In this paper, we evaluate 12 vision models on taxonomic classification across four diverse, long-tailed datasets spanning over 230 genera and 1769 species, with images ranging from controlled laboratory settings to challenging field-collected (in-situ) photographs. We further explore taxonomic classification in two important real-world contexts: sample efficiency and domain adaptation. Our results show that the Vision and Language Transformer combined with an MLP head is the best performing model, with 97\\% accuracy at genus and 94\\% at species level. Sample efficiency analysis shows that we can reduce train data requirements by up to 50\\% with minimal compromise in performance. The domain adaptation experiments reveal significant challenges when transferring models from lab to in-situ images, highlighting a critical domain gap. Overall, our study lays a foundation for large-scale automated taxonomic classification of beetles, and beyond that, advances sample-efficient learning and cross-domain adaptation for diverse long-tailed ecological datasets.","authors":["S M Rayeed","Alyson East","Samuel Stevens","Sydne Record","Charles V Stewart"],"url":"https://arxiv.org/abs/2504.13393"}
{"created":"2025-04-21","title":"A global structure-preserving kernel method for the learning of Poisson systems","abstract":"A structure-preserving kernel ridge regression method is presented that allows the recovery of globally defined, potentially high-dimensional, and nonlinear Hamiltonian functions on Poisson manifolds out of datasets made of noisy observations of Hamiltonian vector fields. The proposed method is based on finding the solution of a non-standard kernel ridge regression where the observed data is generated as the noisy image by a vector bundle map of the differential of the function that one is trying to estimate. Additionally, it is shown how a suitable regularization solves the intrinsic non-identifiability of the learning problem due to the degeneracy of the Poisson tensor and the presence of Casimir functions. A full error analysis is conducted that provides convergence rates using fixed and adaptive regularization parameters. The good performance of the proposed estimator is illustrated with several numerical experiments.","authors":["Jianyu Hu","Juan-Pablo Ortega","Daiying Yin"],"url":"https://arxiv.org/abs/2504.13396"}
{"created":"2025-04-21","title":"Insecurity Through Obscurity: Veiled Vulnerabilities in Closed-Source Contracts","abstract":"Most blockchains cannot hide the binary code of programs (i.e., smart contracts) running on them. To conceal proprietary business logic and to potentially deter attacks, many smart contracts are closed-source and employ layers of obfuscation. However, we demonstrate that such obfuscation can obscure critical vulnerabilities rather than enhance security, a phenomenon we term insecurity through obscurity. To systematically analyze these risks on a large scale, we present SKANF, a novel EVM bytecode analysis tool tailored for closed-source and obfuscated contracts. SKANF combines control-flow deobfuscation, symbolic execution, and concolic execution based on historical transactions to identify and exploit asset management vulnerabilities. Our evaluation on real-world Maximal Extractable Value (MEV) bots reveals that SKANF detects vulnerabilities in 1,028 contracts and successfully generates exploits for 373 of them, with potential losses exceeding \\$9.0M. Additionally, we uncover 40 real-world MEV bot attacks that collectively resulted in \\$900K in losses.","authors":["Sen Yang","Kaihua Qin","Aviv Yaish","Fan Zhang"],"url":"https://arxiv.org/abs/2504.13398"}
{"created":"2025-04-21","title":"Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety","abstract":"Detecting anomalous hazards in visual data, particularly in video streams, is a critical challenge in autonomous driving. Existing models often struggle with unpredictable, out-of-label hazards due to their reliance on predefined object categories. In this paper, we propose a multimodal approach that integrates vision-language reasoning with zero-shot object detection to improve hazard identification and explanation. Our pipeline consists of a Vision-Language Model (VLM), a Large Language Model (LLM), in order to detect hazardous objects within a traffic scene. We refine object detection by incorporating OpenAI's CLIP model to match predicted hazards with bounding box annotations, improving localization accuracy. To assess model performance, we create a ground truth dataset by denoising and extending the foundational COOOL (Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete natural language descriptions for hazard annotations. We define a means of hazard detection and labeling evaluation on the extended dataset using cosine similarity. This evaluation considers the semantic similarity between the predicted hazard description and the annotated ground truth for each video. Additionally, we release a set of tools for structuring and managing large-scale hazard detection datasets. Our findings highlight the strengths and limitations of current vision-language-based approaches, offering insights into future improvements in autonomous hazard detection systems. Our models, scripts, and data can be found at https://github.com/mi3labucm/COOOLER.git","authors":["Shashank Shriram","Srinivasa Perisetla","Aryan Keskar","Harsha Krishnaswamy","Tonko Emil Westerhof Bossen","Andreas M{\\o}gelmose","Ross Greer"],"url":"https://arxiv.org/abs/2504.13399"}
{"created":"2025-04-21","title":"CytoFM: The first cytology foundation model","abstract":"Cytology is essential for cancer diagnostics and screening due to its minimally invasive nature. However, the development of robust deep learning models for digital cytology is challenging due to the heterogeneity in staining and preparation methods of samples, differences across organs, and the limited availability of large, diverse, annotated datasets. Developing a task-specific model for every cytology application is impractical and non-cytology-specific foundation models struggle to generalize to tasks in this domain where the emphasis is on cell morphology. To address these challenges, we introduce CytoFM, the first cytology self-supervised foundation model. Using iBOT, a self-supervised Vision Transformer (ViT) training framework incorporating masked image modeling and self-distillation, we pretrain CytoFM on a diverse collection of cytology datasets to learn robust, transferable representations. We evaluate CytoFM on multiple downstream cytology tasks, including breast cancer classification and cell type identification, using an attention-based multiple instance learning framework. Our results demonstrate that CytoFM performs better on two out of three downstream tasks than existing foundation models pretrained on histopathology (UNI) or natural images (iBOT-Imagenet). Visualizations of learned representations demonstrate our model is able to attend to cytologically relevant features. Despite a small pre-training dataset, CytoFM's promising results highlight the ability of task-agnostic pre-training approaches to learn robust and generalizable features from cytology data.","authors":["Vedrana Ivezi\\'c","Ashwath Radhachandran","Ekaterina Redekop","Shreeram Athreya","Dongwoo Lee","Vivek Sant","Corey Arnold","William Speier"],"url":"https://arxiv.org/abs/2504.13402"}
{"created":"2025-04-21","title":"Documentation on Encrypted Dynamic Control Simulation Code using Ring-LWE based Cryptosystems","abstract":"Encrypted controllers offer secure computation by employing modern cryptosystems to execute control operations directly over encrypted data without decryption. However, incorporating cryptosystems into dynamic controllers significantly increases the computational load. This paper aims to provide an accessible guideline for running encrypted controllers using an open-source library Lattigo, which supports an efficient implementation of Ring-Learing With Errors (LWE) based encrypted controllers, and our explanations are assisted with example codes that are fully available at https://github.com/CDSL-EncryptedControl/CDSL.","authors":["Yeongjun Jang","Joowon Lee","Junsoo Kim"],"url":"https://arxiv.org/abs/2504.13403"}
{"created":"2025-04-21","title":"Design Priorities in Digital Gateways: A Comparative Study of Authentication and Usability in Academic Library Alliances","abstract":"Purpose: This study examines the design and functionality of university library login pages across academic alliances (IVY Plus, BTAA, JULAC, JVU) to identify how these interfaces align with institutional priorities and user needs. It explores consensus features, design variations, and emerging trends in authentication, usability, and security.","authors":["Rui Shang","Bingjie Huang"],"url":"https://arxiv.org/abs/2504.13404"}
{"created":"2025-04-21","title":"ProgRoCC: A Progressive Approach to Rough Crowd Counting","abstract":"As the number of individuals in a crowd grows, enumeration-based techniques become increasingly infeasible and their estimates increasingly unreliable. We propose instead an estimation-based version of the problem: we label Rough Crowd Counting that delivers better accuracy on the basis of training data that is easier to acquire. Rough crowd counting requires only rough annotations of the number of targets in an image, instead of the more traditional, and far more expensive, per-target annotations. We propose an approach to the rough crowd counting problem based on CLIP, termed ProgRoCC. Specifically, we introduce a progressive estimation learning strategy that determines the object count through a coarse-to-fine approach. This approach delivers answers quickly, outperforms the state-of-the-art in semi- and weakly-supervised crowd counting. In addition, we design a vision-language matching adapter that optimizes key-value pairs by mining effective matches of two modalities to refine the visual features, thereby improving the final performance. Extensive experimental results on three widely adopted crowd counting datasets demonstrate the effectiveness of our method.","authors":["Shengqin Jiang","Linfei Li","Haokui Zhang","Qingshan Liu","Amin Beheshti","Jian Yang","Anton van den Hengel","Quan Z. Sheng","Yuankai Qi"],"url":"https://arxiv.org/abs/2504.13405"}
{"created":"2025-04-21","title":"LangCoop: Collaborative Driving with Language","abstract":"Multi-agent collaboration holds great promise for enhancing the safety, reliability, and mobility of autonomous driving systems by enabling information sharing among multiple connected agents. However, existing multi-agent communication approaches are hindered by limitations of existing communication media, including high bandwidth demands, agent heterogeneity, and information loss. To address these challenges, we introduce LangCoop, a new paradigm for collaborative autonomous driving that leverages natural language as a compact yet expressive medium for inter-agent communication. LangCoop features two key innovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured zero-shot vision-language reasoning and Natural Language Information Packaging (LangPack) for efficiently packaging information into concise, language-based messages. Through extensive experiments conducted in the CARLA simulations, we demonstrate that LangCoop achieves a remarkable 96\\% reduction in communication bandwidth (< 2KB per message) compared to image-based communication, while maintaining competitive driving performance in the closed-loop evaluation.","authors":["Xiangbo Gao","Yuheng Wu","Rujia Wang","Chenxi Liu","Yang Zhou","Zhengzhong Tu"],"url":"https://arxiv.org/abs/2504.13406"}
{"created":"2025-04-21","title":"LoRA-Based Continual Learning with Constraints on Critical Parameter Changes","abstract":"LoRA-based continual learning represents a promising avenue for leveraging pre-trained models in downstream continual learning tasks. Recent studies have shown that orthogonal LoRA tuning effectively mitigates forgetting. However, this work unveils that under orthogonal LoRA tuning, the critical parameters for pre-tasks still change notably after learning post-tasks. To address this problem, we directly propose freezing the most critical parameter matrices in the Vision Transformer (ViT) for pre-tasks before learning post-tasks. In addition, building on orthogonal LoRA tuning, we propose orthogonal LoRA composition (LoRAC) based on QR decomposition, which may further enhance the plasticity of our method. Elaborate ablation studies and extensive comparisons demonstrate the effectiveness of our proposed method. Our results indicate that our method achieves state-of-the-art (SOTA) performance on several well-known continual learning benchmarks. For instance, on the Split CIFAR-100 dataset, our method shows a 6.35\\% improvement in accuracy and a 3.24\\% reduction in forgetting compared to previous methods. Our code is available at https://github.com/learninginvision/LoRAC-IPC.","authors":["Shimou Ling","Liang Zhang","Jiangwei Zhao","Lili Pan","Hongliang Li"],"url":"https://arxiv.org/abs/2504.13407"}
{"created":"2025-04-21","title":"OpCode-Based Malware Classification Using Machine Learning and Deep Learning Techniques","abstract":"This technical report presents a comprehensive analysis of malware classification using OpCode sequences. Two distinct approaches are evaluated: traditional machine learning using n-gram analysis with Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and Decision Tree classifiers; and a deep learning approach employing a Convolutional Neural Network (CNN). The traditional machine learning approach establishes a baseline using handcrafted 1-gram and 2-gram features from disassembled malware samples. The deep learning methodology builds upon the work proposed in \"Deep Android Malware Detection\" by McLaughlin et al. and evaluates the performance of a CNN model trained to automatically extract features from raw OpCode data. Empirical results are compared using standard performance metrics (accuracy, precision, recall, and F1-score). While the SVM classifier outperforms other traditional techniques, the CNN model demonstrates competitive performance with the added benefit of automated feature extraction.","authors":["Varij Saini","Rudraksh Gupta","Neel Soni"],"url":"https://arxiv.org/abs/2504.13408"}
{"created":"2025-04-21","title":"How Learnable Grids Recover Fine Detail in Low Dimensions: A Neural Tangent Kernel Analysis of Multigrid Parametric Encodings","abstract":"Neural networks that map between low dimensional spaces are ubiquitous in computer graphics and scientific computing; however, in their naive implementation, they are unable to learn high frequency information. We present a comprehensive analysis comparing the two most common techniques for mitigating this spectral bias: Fourier feature encodings (FFE) and multigrid parametric encodings (MPE). FFEs are seen as the standard for low dimensional mappings, but MPEs often outperform them and learn representations with higher resolution and finer detail. FFE's roots in the Fourier transform, make it susceptible to aliasing if pushed too far, while MPEs, which use a learned grid structure, have no such limitation. To understand the difference in performance, we use the neural tangent kernel (NTK) to evaluate these encodings through the lens of an analogous kernel regression. By finding a lower bound on the smallest eigenvalue of the NTK, we prove that MPEs improve a network's performance through the structure of their grid and not their learnable embedding. This mechanism is fundamentally different from FFEs, which rely solely on their embedding space to improve performance. Results are empirically validated on a 2D image regression task using images taken from 100 synonym sets of ImageNet and 3D implicit surface regression on objects from the Stanford graphics dataset. Using peak signal-to-noise ratio (PSNR) and multiscale structural similarity (MS-SSIM) to evaluate how well fine details are learned, we show that the MPE increases the minimum eigenvalue by 8 orders of magnitude over the baseline and 2 orders of magnitude over the FFE. The increase in spectrum corresponds to a 15 dB (PSNR) / 0.65 (MS-SSIM) increase over baseline and a 12 dB (PSNR) / 0.33 (MS-SSIM) increase over the FFE.","authors":["Samuel Audia","Soheil Feizi","Matthias Zwicker","Dinesh Manocha"],"url":"https://arxiv.org/abs/2504.13412"}
{"created":"2025-04-21","title":"A Model-Based Approach to Imitation Learning through Multi-Step Predictions","abstract":"Imitation learning is a widely used approach for training agents to replicate expert behavior in complex decision-making tasks. However, existing methods often struggle with compounding errors and limited generalization, due to the inherent challenge of error correction and the distribution shift between training and deployment. In this paper, we present a novel model-based imitation learning framework inspired by model predictive control, which addresses these limitations by integrating predictive modeling through multi-step state predictions. Our method outperforms traditional behavior cloning numerical benchmarks, demonstrating superior robustness to distribution shift and measurement noise both in available data and during execution. Furthermore, we provide theoretical guarantees on the sample complexity and error bounds of our method, offering insights into its convergence properties.","authors":["Haldun Balim","Yang Hu","Yuyang Zhang","Na Li"],"url":"https://arxiv.org/abs/2504.13413"}
{"created":"2025-04-21","title":"STAMP Your Content: Proving Dataset Membership via Watermarked Rephrasings","abstract":"Given how large parts of publicly available text are crawled to pretrain large language models (LLMs), data creators increasingly worry about the inclusion of their proprietary data for model training without attribution or licensing. Their concerns are also shared by benchmark curators whose test-sets might be compromised. In this paper, we present STAMP, a framework for detecting dataset membership-i.e., determining the inclusion of a dataset in the pretraining corpora of LLMs. Given an original piece of content, our proposal involves first generating multiple rephrases, each embedding a watermark with a unique secret key. One version is to be released publicly, while others are to be kept private. Subsequently, creators can compare model likelihoods between public and private versions using paired statistical tests to prove membership. We show that our framework can successfully detect contamination across four benchmarks which appear only once in the training data and constitute less than 0.001% of the total tokens, outperforming several contamination detection and dataset inference baselines. We verify that STAMP preserves both the semantic meaning and the utility of the original data in comparing different models. We apply STAMP to two real-world scenarios to confirm the inclusion of paper abstracts and blog articles in the pretraining corpora.","authors":["Saksham Rastogi","Pratyush Maini","Danish Pruthi"],"url":"https://arxiv.org/abs/2504.13416"}
{"created":"2025-04-21","title":"Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction","abstract":"Recent advances in data-driven geometric multi-view 3D reconstruction foundation models (e.g., DUSt3R) have shown remarkable performance across various 3D vision tasks, facilitated by the release of large-scale, high-quality 3D datasets. However, as we observed, constrained by their matching-based principles, the reconstruction quality of existing models suffers significant degradation in challenging regions with limited matching cues, particularly in weakly textured areas and low-light conditions. To mitigate these limitations, we propose to harness the inherent robustness of monocular geometry estimation to compensate for the inherent shortcomings of matching-based methods. Specifically, we introduce a monocular-guided refinement module that integrates monocular geometric priors into multi-view reconstruction frameworks. This integration substantially enhances the robustness of multi-view reconstruction systems, leading to high-quality feed-forward reconstructions. Comprehensive experiments across multiple benchmarks demonstrate that our method achieves substantial improvements in both mutli-view camera pose estimation and point cloud accuracy.","authors":["Wenyu Li","Sidun Liu","Peng Qiao","Yong Dou"],"url":"https://arxiv.org/abs/2504.13419"}
{"created":"2025-04-21","title":"Testing the Fault-Tolerance of Multi-Sensor Fusion Perception in Autonomous Driving Systems","abstract":"High-level Autonomous Driving Systems (ADSs), such as Google Waymo and Baidu Apollo, typically rely on multi-sensor fusion (MSF) based approaches to perceive their surroundings. This strategy increases perception robustness by combining the respective strengths of the camera and LiDAR and directly affects the safety-critical driving decisions of autonomous vehicles (AVs). However, in real-world autonomous driving scenarios, cameras and LiDAR are subject to various faults, which can probably significantly impact the decision-making and behaviors of ADSs. Existing MSF testing approaches only discovered corner cases that the MSF-based perception cannot accurately detected by MSF-based perception, while lacking research on how sensor faults affect the system-level behaviors of ADSs.","authors":["Haoxiang Tian","Wenqiang Ding","Xingshuo Han","Guoquan Wu","An Guo","Junqi Zhang. Wei Chen","Jun Wei","Tianwei Zhang"],"url":"https://arxiv.org/abs/2504.13420"}
{"created":"2025-04-21","title":"\"Can't believe I'm crying over an anime girl\": Public Parasocial Grieving and Coping Towards VTuber Graduation and Termination","abstract":"Despite the significant increase in popularity of Virtual YouTubers (VTubers), research on the unique dynamics of viewer-VTuber parasocial relationships is nascent. This work investigates how English-speaking viewers grieved VTubers whose identities are no longer used, an interesting context as the nakanohito (i.e., the person behind the VTuber identity) is usually alive post-retirement and might \"reincarnate\" as another VTuber. We propose a typology for VTuber retirements and analyzed 13,655 Reddit posts and comments spanning nearly three years using mixed-methods. Findings include how viewers coped using methods similar to when losing loved ones, alongside novel coping methods reflecting different attachment styles. Although emotions like sadness, shock, concern, disapproval, confusion, and love decreased with time, regret and loyalty showed opposite trends. Furthermore, viewers' reactions situated a VTuber identity within a community of content creators and viewers. We also discuss design implications alongside implications on the VTuber ecosystem and future research directions.","authors":["Ken Jen Lee","PiaoHong Wang","Zhicong Lu"],"url":"https://arxiv.org/abs/2504.13421"}
{"created":"2025-04-21","title":"Equilibrium Conserving Neural Operators for Super-Resolution Learning","abstract":"Neural surrogate solvers can estimate solutions to partial differential equations in physical problems more efficiently than standard numerical methods, but require extensive high-resolution training data. In this paper, we break this limitation; we introduce a framework for super-resolution learning in solid mechanics problems. Our approach allows one to train a high-resolution neural network using only low-resolution data. Our Equilibrium Conserving Operator (ECO) architecture embeds known physics directly into the network to make up for missing high-resolution information during training. We evaluate this ECO-based super-resolution framework that strongly enforces conservation-laws in the predicted solutions on two working examples: embedded pores in a homogenized matrix and randomly textured polycrystalline materials. ECO eliminates the reliance on high-fidelity data and reduces the upfront cost of data collection by two orders of magnitude, offering a robust pathway for resource-efficient surrogate modeling in materials modeling. ECO is readily generalizable to other physics-based problems.","authors":["Vivek Oommen","Andreas E. Robertson","Daniel Diaz","Coleman Alleman","Zhen Zhang","Anthony D. Rollett","George E. Karniadakis","R\\'emi Dingreville"],"url":"https://arxiv.org/abs/2504.13422"}
{"created":"2025-04-21","title":"Mixed Fractional Information: Consistency of Dissipation Measures for Stable Laws","abstract":"Symmetric alpha-stable (S alpha S) distributions with alpha<2 lack finite classical Fisher information. Building on Johnson's framework, we define Mixed Fractional Information (MFI) via the initial rate of relative entropy dissipation during interpolation between S alpha S laws with differing scales, v and s. We demonstrate two equivalent formulations for MFI in this specific S alpha S-to-S alpha S setting. The first involves the derivative D'(v) of the relative entropy between the two S alpha S densities. The second uses an integral expectation E_gv[u(x,0) (pF_v(x) - pF_s(x))] involving the difference between Fisher scores (pF_v, pF_s) and a specific MMSE-related score function u(x,0) derived from the interpolation dynamics. Our central contribution is a rigorous proof of the consistency identity: D'(v) = (1/(alpha v)) E_gv[X (pF_v(X) - pF_s(X))]. This identity mathematically validates the equivalence of the two MFI formulations for S alpha S inputs, establishing MFI's internal coherence and directly linking entropy dissipation rates to score function differences. We further establish MFI's non-negativity (zero if and only if v=s), derive its closed-form expression for the Cauchy case (alpha=1), and numerically validate the consistency identity. MFI provides a finite, coherent, and computable information-theoretic measure for comparing S alpha S distributions where classical Fisher information fails, connecting entropy dynamics to score functions and estimation concepts. This work lays a foundation for exploring potential fractional I-MMSE relations and new functional inequalities tailored to heavy-tailed systems.","authors":["William Cook"],"url":"https://arxiv.org/abs/2504.13423"}
{"created":"2025-04-21","title":"Decentralized Handover Parameter Optimization with MARL for Load Balancing in 5G Networks","abstract":"In cellular networks, cell handover refers to the process where a device switches from one base station to another, and this mechanism is crucial for balancing the load among different cells. Traditionally, engineers would manually adjust parameters based on experience. However, the explosive growth in the number of cells has rendered manual tuning impractical. Existing research tends to overlook critical engineering details in order to simplify handover problems. In this paper, we classify cell handover into three types, and jointly model their mutual influence. To achieve load balancing, we propose a multi-agent-reinforcement-learning (MARL)-based scheme to automatically optimize the parameters. To reduce the agent interaction costs, a distributed training is implemented based on consensus approximation of global average load, and it is shown that the approximation error is bounded. Experimental results show that our proposed scheme outperforms existing benchmarks in balancing load and improving network performance.","authors":["Yang Shen","Shuqi Chai","Bing Li","Xiaodong Luo","Qingjiang Shi","Rongqing Zhang"],"url":"https://arxiv.org/abs/2504.13424"}
{"created":"2025-04-21","title":"Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering","abstract":"Existing Retrieval-Augmented Generation (RAG) systems face challenges in enterprise settings due to limited retrieval scope and data security risks. When relevant internal documents are unavailable, the system struggles to generate accurate and complete responses. Additionally, using closed-source Large Language Models (LLMs) raises concerns about exposing proprietary information. To address these issues, we propose the Secure Multifaceted-RAG (SecMulti-RAG) framework, which retrieves not only from internal documents but also from two supplementary sources: pre-generated expert knowledge for anticipated queries and on-demand external LLM-generated knowledge. To mitigate security risks, we adopt a local open-source generator and selectively utilize external LLMs only when prompts are deemed safe by a filtering mechanism. This approach enhances completeness, prevents data leakage, and reduces costs. In our evaluation on a report generation task in the automotive industry, SecMulti-RAG significantly outperforms traditional RAG - achieving 79.3 to 91.9 percent win rates across correctness, richness, and helpfulness in LLM-based evaluation, and 56.3 to 70.4 percent in human evaluation. This highlights SecMulti-RAG as a practical and secure solution for enterprise RAG.","authors":["Grace Byun","Shinsun Lee","Nayoung Choi","Jinho Choi"],"url":"https://arxiv.org/abs/2504.13425"}
{"created":"2025-04-21","title":"Simplifying Graph Convolutional Networks with Redundancy-Free Neighbors","abstract":"In recent years, Graph Convolutional Networks (GCNs) have gained popularity for their exceptional ability to process graph-structured data. Existing GCN-based approaches typically employ a shallow model architecture due to the over-smoothing phenomenon. Current approaches to mitigating over-smoothing primarily involve adding supplementary components to GCN architectures, such as residual connections and random edge-dropping strategies. However, these improvements toward deep GCNs have achieved only limited success. In this work, we analyze the intrinsic message passing mechanism of GCNs and identify a critical issue: messages originating from high-order neighbors must traverse through low-order neighbors to reach the target node. This repeated reliance on low-order neighbors leads to redundant information aggregation, a phenomenon we term over-aggregation. Our analysis demonstrates that over-aggregation not only introduces significant redundancy but also serves as the fundamental cause of over-smoothing in GCNs.","authors":["Jielong LuZhihao Wu","Zhiling Cai","Yueyang Pi","Shiping Wang"],"url":"https://arxiv.org/abs/2504.13426"}
{"created":"2025-04-21","title":"HSACNet: Hierarchical Scale-Aware Consistency Regularized Semi-Supervised Change Detection","abstract":"Semi-supervised change detection (SSCD) aims to detect changes between bi-temporal remote sensing images by utilizing limited labeled data and abundant unlabeled data. Existing methods struggle in complex scenarios, exhibiting poor performance when confronted with noisy data. They typically neglect intra-layer multi-scale features while emphasizing inter-layer fusion, harming the integrity of change objects with different scales. In this paper, we propose HSACNet, a Hierarchical Scale-Aware Consistency regularized Network for SSCD. Specifically, we integrate Segment Anything Model 2 (SAM2), using its Hiera backbone as the encoder to extract inter-layer multi-scale features and applying adapters for parameter-efficient fine-tuning. Moreover, we design a Scale-Aware Differential Attention Module (SADAM) that can precisely capture intra-layer multi-scale change features and suppress noise. Additionally, a dual-augmentation consistency regularization strategy is adopted to effectively utilize the unlabeled data. Extensive experiments across four CD benchmarks demonstrate that our HSACNet achieves state-of-the-art performance, with reduced parameters and computational cost.","authors":["Qi'ao Xu","Pengfei Wang","Yanjun Li","Tianwen Qian","Xiaoling Wang"],"url":"https://arxiv.org/abs/2504.13428"}
{"created":"2025-04-21","title":"Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs","abstract":"Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).","authors":["Shenzhi Yang","Bin Liang","An Liu","Lin Gui","Xingkai Yao","Xiaofang Zhang"],"url":"https://arxiv.org/abs/2504.13429"}
{"created":"2025-04-21","title":"The Long Arm of Nashian Allocation in Online $p$-Mean Welfare Maximization","abstract":"We study the online allocation of divisible items to $n$ agents with additive valuations for $p$-mean welfare maximization, a problem introduced by Barman, Khan, and Maiti~(2022). Our algorithmic and hardness results characterize the optimal competitive ratios for the entire spectrum of $-\\infty \\le p \\le 1$. Surprisingly, our improved algorithms for all $p \\le \\frac{1}{\\log n}$ are simply the greedy algorithm for the Nash welfare, supplemented with two auxiliary components to ensure all agents have non-zero utilities and to help a small number of agents with low utilities. In this sense, the long arm of Nashian allocation achieves near-optimal competitive ratios not only for Nash welfare but also all the way to egalitarian welfare.","authors":["Zhiyi Huang","Chui Shan Lee","Xinkai Shu","Zhaozi Wang"],"url":"https://arxiv.org/abs/2504.13430"}
{"created":"2025-04-21","title":"Circular Image Deturbulence using Quasi-conformal Geometry","abstract":"The presence of inhomogeneous media between optical sensors and objects leads to distorted imaging outputs, significantly complicating downstream image-processing tasks. A key challenge in image restoration is the lack of high-quality, paired-label images required for training supervised models. In this paper, we introduce the Circular Quasi-Conformal Deturbulence (CQCD) framework, an unsupervised approach for removing image distortions through a circular architecture. This design ensures that the restored image remains both geometrically accurate and visually faithful while preventing the accumulation of incorrect estimations.The circular restoration process involves both forward and inverse mapping. To ensure the bijectivity of the estimated non-rigid deformations, computational quasi-conformal geometry theories are leveraged to regularize the mapping, enforcing its homeomorphic properties. This guarantees a well-defined transformation that preserves structural integrity and prevents unwanted artifacts. Furthermore, tight-frame blocks are integrated to encode distortion-sensitive features for precise recovery. To validate the performance of our approach, we conduct evaluations on various synthetic and real-world captured images. Experimental results demonstrate that CQCD not only outperforms existing state-of-the-art deturbulence methods in terms of image restoration quality but also provides highly accurate deformation field estimations.","authors":["Chu Chen","Han Zhang","Lok Ming Lui"],"url":"https://arxiv.org/abs/2504.13432"}
{"created":"2025-04-21","title":"RT-HDIST: Ray-Tracing Core-based Hausdorff Distance Computation","abstract":"The Hausdorff distance is a fundamental metric with widespread applications across various fields. However, its computation remains computationally expensive, especially for large-scale datasets. In this work, we present RT-HDIST, the first Hausdorff distance algorithm accelerated by ray-tracing cores (RT-cores). By reformulating the Hausdorff distance problem as a series of nearest-neighbor searches and introducing a novel quantized index space, RT-HDIST achieves significant reductions in computational overhead while maintaining exact results. Extensive benchmarks demonstrate up to a two-order-of-magnitude speedup over prior state-of-the-art methods, underscoring RT-HDIST's potential for real-time and large-scale applications.","authors":["YoungWoo Kim","Jaehong Lee","Duksu Kim"],"url":"https://arxiv.org/abs/2504.13436"}
{"created":"2025-04-21","title":"D-GEN: Automatic Distractor Generation and Evaluation for Reliable Assessment of Generative Model","abstract":"Evaluating generative models with open-ended generation is challenging due to inconsistencies in response formats. Multiple-choice (MC) evaluation mitigates this issue, but generating high-quality distractors is time-consuming and labor-intensive. We introduce D-GEN, the first open-source distractor generator model that transforms open-ended data into an MC format. To evaluate distractor quality, we propose two novel methods: (1) ranking alignment, ensuring generated distractors retain the discriminatory power of ground-truth distractors, and (2) entropy analysis, comparing model confidence distributions. Our results show that D-GEN preserves ranking consistency (Spearman's rho 0.99, Kendall's tau 0.94) and closely matches the entropy distribution of ground-truth distractors. Human evaluation further confirms the fluency, coherence, distractiveness, and incorrectness. Our work advances robust and efficient distractor generation with automated evaluation, setting a new standard for MC evaluation.","authors":["Grace Byun","Jinho Choi"],"url":"https://arxiv.org/abs/2504.13439"}
{"created":"2025-04-21","title":"Temporal Propagation of Asymmetric Feature Pyramid for Surgical Scene Segmentation","abstract":"Surgical scene segmentation is crucial for robot-assisted laparoscopic surgery understanding. Current approaches face two challenges: (i) static image limitations including ambiguous local feature similarities and fine-grained structural details, and (ii) dynamic video complexities arising from rapid instrument motion and persistent visual occlusions. While existing methods mainly focus on spatial feature extraction, they fundamentally overlook temporal dependencies in surgical video streams. To address this, we present temporal asymmetric feature propagation network, a bidirectional attention architecture enabling cross-frame feature propagation. The proposed method contains a temporal query propagator that integrates multi-directional consistency constraints to enhance frame-specific feature representation, and an aggregated asymmetric feature pyramid module that preserves discriminative features for anatomical structures and surgical instruments. Our framework uniquely enables both temporal guidance and contextual reasoning for surgical scene understanding. Comprehensive evaluations on two public benchmarks show the proposed method outperforms the current SOTA methods by a large margin, with +16.4\\% mIoU on EndoVis2018 and +3.3\\% mAP on Endoscapes2023. The code will be publicly available after paper acceptance.","authors":["Cheng Yuan","Yutong Ban"],"url":"https://arxiv.org/abs/2504.13440"}
{"created":"2025-04-21","title":"SatelliteCalculator: A Multi-Task Vision Foundation Model for Quantitative Remote Sensing Inversion","abstract":"Quantitative remote sensing inversion plays a critical role in environmental monitoring, enabling the estimation of key ecological variables such as vegetation indices, canopy structure, and carbon stock. Although vision foundation models have achieved remarkable progress in classification and segmentation tasks, their application to physically interpretable regression remains largely unexplored. Furthermore, the multi-spectral nature and geospatial heterogeneity of remote sensing data pose significant challenges for generalization and transferability. To address these issues, we introduce SatelliteCalculator, the first vision foundation model tailored for quantitative remote sensing inversion. By leveraging physically defined index formulas, we automatically construct a large-scale dataset of over one million paired samples across eight core ecological indicators. The model integrates a frozen Swin Transformer backbone with a prompt-guided architecture, featuring cross-attentive adapters and lightweight task-specific MLP decoders. Experiments on the Open-Canopy benchmark demonstrate that SatelliteCalculator achieves competitive accuracy across all tasks while significantly reducing inference cost. Our results validate the feasibility of applying foundation models to quantitative inversion, and provide a scalable framework for task-adaptive remote sensing estimation.","authors":["Zhenyu Yu","Mohd. Yamani Idna Idris","Pei Wang"],"url":"https://arxiv.org/abs/2504.13442"}
{"created":"2025-04-21","title":"Trust, but verify","abstract":"Decentralized AI agent networks, such as Gaia, allows individuals to run customized LLMs on their own computers and then provide services to the public. However, in order to maintain service quality, the network must verify that individual nodes are running their designated LLMs. In this paper, we demonstrate that in a cluster of mostly honest nodes, we can detect nodes that run unauthorized or incorrect LLM through social consensus of its peers. We will discuss the algorithm and experimental data from the Gaia network. We will also discuss the intersubjective validation system, implemented as an EigenLayer AVS to introduce financial incentives and penalties to encourage honest behavior from LLM nodes.","authors":["Michael J. Yuan","Carlos Campoy","Sydney Lai","James Snewin","Ju Long"],"url":"https://arxiv.org/abs/2504.13443"}
{"created":"2025-04-21","title":"How to Mine Potentially Popular Items? A Reverse MIPS-based Approach","abstract":"The $k$-MIPS ($k$ Maximum Inner Product Search) problem has been employed in many fields. Recently, its reverse version, the reverse $k$-MIPS problem, has been proposed. Given an item vector (i.e., query), it retrieves all user vectors such that their $k$-MIPS results contain the item vector. Consider the cardinality of a reverse $k$-MIPS result. A large cardinality means that the item is potentially popular, because it is included in the $k$-MIPS results of many users. This mining is important in recommender systems, market analysis, and new item development. Motivated by this, we formulate a new problem. In this problem, the score of each item is defined as the cardinality of its reverse $k$-MIPS result, and the $N$ items with the highest score are retrieved. A straightforward approach is to compute the scores of all items, but this is clearly prohibitive for large numbers of users and items. We remove this inefficiency issue and propose a fast algorithm for this problem. Because the main bottleneck of the problem is to compute the score of each item, we devise a new upper-bounding technique that is specific to our problem and filters unnecessary score computations. We conduct extensive experiments on real datasets and show the superiority of our algorithm over competitors.","authors":["Daichi Amagata","Kazuyoshi Aoayama","Keito Kido","Sumio Fujita"],"url":"https://arxiv.org/abs/2504.13445"}
{"created":"2025-04-21","title":"Approximate Reverse $k$-Ranks Queries in High Dimensions","abstract":"Many objects are represented as high-dimensional vectors nowadays. In this setting, the relevance between two objects (vectors) is usually evaluated by their inner product. Recently, item-centric searches, which search for users relevant to query items, have received attention and find important applications, such as product promotion and market analysis. To support these applications, this paper considers reverse $k$-ranks queries. Given a query vector $\\mathbf{q}$, $k$, a set $\\mathbf{U}$ of user vectors, and a set $\\mathbf{P}$ of item vectors, this query retrieves the $k$ user vectors $\\mathbf{u} \\in \\mathbf{U}$ with the highest $r(\\mathbf{q},\\mathbf{u},\\mathbf{P})$, where $r(\\mathbf{q},\\mathbf{u},\\mathbf{P})$ shows the rank of $\\mathbf{q}$ for $\\mathbf{u}$ among $\\mathbf{P}$. Because efficiently computing the exact answer for this query is difficult in high dimensions, we address the problem of approximate reverse $k$-ranks queries. Informally, given an approximation factor $c$, this problem allows, as an output, a user $\\mathbf{u}'$ such that $r(\\mathbf{q},\\mathbf{u}',\\mathbf{P}) > \\tau$ but $r(\\mathbf{q},\\mathbf{u}',\\mathbf{P}) \\leq c \\times \\tau$, where $\\tau$ is the rank threshold for the exact answer. We propose a new algorithm for solving this problem efficiently. Through theoretical and empirical analyses, we confirm the efficiency and effectiveness of our algorithm.","authors":["Daichi Amagata","Kazuyoshi Aoyama","Keito Kido","Sumio Fujita"],"url":"https://arxiv.org/abs/2504.13446"}
{"created":"2025-04-21","title":"Ascribe New Dimensions to Scientific Data Visualization with VR","abstract":"For over half a century, the computer mouse has been the primary tool for interacting with digital data, yet it remains a limiting factor in exploring complex, multi-scale scientific images. Traditional 2D visualization methods hinder intuitive analysis of inherently 3D structures. Virtual Reality (VR) offers a transformative alternative, providing immersive, interactive environments that enhance data comprehension. This article introduces ASCRIBE-VR, a VR platform of Autonomous Solutions for Computational Research with Immersive Browsing \\& Exploration, which integrates AI-driven algorithms with scientific images. ASCRIBE-VR enables multimodal analysis, structural assessments, and immersive visualization, supporting scientific visualization of advanced datasets such as X-ray CT, Magnetic Resonance, and synthetic 3D imaging. Our VR tools, compatible with Meta Quest, can consume the output of our AI-based segmentation and iterative feedback processes to enable seamless exploration of large-scale 3D images. By merging AI-generated results with VR visualization, ASCRIBE-VR enhances scientific discovery, bridging the gap between computational analysis and human intuition in materials research, connecting human-in-the-loop with digital twins.","authors":["Daniela Ushizima","Guilherme Melo dos Santos","Zineb Sordo","Ronald Pandolfi","Jeffrey Donatelli"],"url":"https://arxiv.org/abs/2504.13448"}
{"created":"2025-04-21","title":"MicroFlow: Domain-Specific Optical Flow for Ground Deformation Estimation in Seismic Events","abstract":"Dense ground displacement measurements are crucial for geological studies but are impractical to collect directly. Traditionally, displacement fields are estimated using patch matching on optical satellite images from different acquisition times. While deep learning-based optical flow models are promising, their adoption in ground deformation analysis is hindered by challenges such as the absence of real ground truth, the need for sub-pixel precision, and temporal variations due to geological or anthropogenic changes. In particular, we identify that deep learning models relying on explicit correlation layers struggle at estimating small displacements in real-world conditions. Instead, we propose a model that employs iterative refinements with explicit warping layers and a correlation-independent backbone, enabling sub-pixel precision. Additionally, a non-convex variant of Total Variation regularization preserves fault-line sharpness while maintaining smoothness elsewhere. Our model significantly outperforms widely used geophysics methods on semi-synthetic benchmarks and generalizes well to challenging real-world scenarios captured by both medium- and high-resolution sensors. Project page: https://jbertrand89.github.io/microflow/.","authors":["Juliette Bertrand","Sophie Giffard-Roisin","James Hollingsworth","Julien Mairal"],"url":"https://arxiv.org/abs/2504.13452"}
{"created":"2025-04-21","title":"Using Machine Learning and Neural Networks to Analyze and Predict Chaos in Multi-Pendulum and Chaotic Systems","abstract":"A chaotic system is a highly volatile system characterized by its sensitive dependence on initial conditions and outside factors. Chaotic systems are prevalent throughout the world today: in weather patterns, disease outbreaks, and even financial markets. Chaotic systems are seen in every field of science and humanities, so being able to predict these systems is greatly beneficial to society. In this study, we evaluate 10 different machine learning models and neural networks [1] based on Root Mean Squared Error (RMSE) and R^2 values for their ability to predict one of these systems, the multi-pendulum. We begin by generating synthetic data representing the angles of the pendulum over time using the Runge Kutta Method for solving 4th Order Differential Equations (ODE-RK4) [2]. At first, we used the single-step sliding window approach, predicting the 50st step after training for steps 0-49 and so forth. However, to more accurately cover chaotic motion and behavior in these systems, we transitioned to a time-step based approach. Here, we trained the model/network on many initial angles and tested it on a completely new set of initial angles, or 'in-between' to capture chaotic motion to its fullest extent. We also evaluated the stability of the system using Lyapunov exponents. We concluded that for a double pendulum, the best model was the Long Short Term Memory Network (LSTM)[3] for the sliding window and time step approaches in both friction and frictionless scenarios. For triple pendulum, the Vanilla Recurrent Neural Network (VRNN)[4] was the best for the sliding window and Gated Recurrent Network (GRU) [5] was the best for the time step approach, but for friction, LSTM was the best.","authors":["Vasista Ramachandruni","Sai Hruday Reddy Nara","Geo Lalu","Sabrina Yang","Mohit Ramesh Kumar","Aarjav Jain","Pratham Mehta","Hankyu Koo","Jason Damonte","Marx Akl"],"url":"https://arxiv.org/abs/2504.13453"}
{"created":"2025-04-21","title":"Neural Ganglion Sensors: Learning Task-specific Event Cameras Inspired by the Neural Circuit of the Human Retina","abstract":"Inspired by the data-efficient spiking mechanism of neurons in the human eye, event cameras were created to achieve high temporal resolution with minimal power and bandwidth requirements by emitting asynchronous, per-pixel intensity changes rather than conventional fixed-frame rate images. Unlike retinal ganglion cells (RGCs) in the human eye, however, which integrate signals from multiple photoreceptors within a receptive field to extract spatio-temporal features, conventional event cameras do not leverage local spatial context when deciding which events to fire. Moreover, the eye contains around 20 different kinds of RGCs operating in parallel, each attuned to different features or conditions. Inspired by this biological design, we introduce Neural Ganglion Sensors, an extension of traditional event cameras that learns task-specific spatio-temporal retinal kernels (i.e., RGC \"events\"). We evaluate our design on two challenging tasks: video interpolation and optical flow. Our results demonstrate that our biologically inspired sensing improves performance relative to conventional event cameras while reducing overall event bandwidth. These findings highlight the promise of RGC-inspired event sensors for edge devices and other low-power, real-time applications requiring efficient, high-resolution visual streams.","authors":["Haley M. So","Gordon Wetzstein"],"url":"https://arxiv.org/abs/2504.13457"}
{"created":"2025-04-21","title":"Learning from Noisy Pseudo-labels for All-Weather Land Cover Mapping","abstract":"Semantic segmentation of SAR images has garnered significant attention in remote sensing due to the immunity of SAR sensors to cloudy weather and light conditions. Nevertheless, SAR imagery lacks detailed information and is plagued by significant speckle noise, rendering the annotation or segmentation of SAR images a formidable task. Recent efforts have resorted to annotating paired optical-SAR images to generate pseudo-labels through the utilization of an optical image segmentation network. However, these pseudo-labels are laden with noise, leading to suboptimal performance in SAR image segmentation. In this study, we introduce a more precise method for generating pseudo-labels by incorporating semi-supervised learning alongside a novel image resolution alignment augmentation. Furthermore, we introduce a symmetric cross-entropy loss to mitigate the impact of noisy pseudo-labels. Additionally, a bag of training and testing tricks is utilized to generate better land-cover mapping results. Our experiments on the GRSS data fusion contest indicate the effectiveness of the proposed method, which achieves first place. The code is available at https://github.com/StuLiu/DFC2025Track1.git.","authors":["Wang Liu","Zhiyu Wang","Xin Guo","Puhong Duan","Xudong Kang","Shutao Li"],"url":"https://arxiv.org/abs/2504.13458"}
{"created":"2025-04-21","title":"Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization","abstract":"Traditional temporal action localization (TAL) methods rely on large amounts of detailed annotated data, whereas few-shot TAL reduces this dependence by using only a few training samples to identify unseen action categories. However, existing few-shot TAL methods typically focus solely on video-level information, neglecting textual information, which can provide valuable semantic support for the localization task. Therefore, we propose a new few-shot temporal action localization method by Chain-of-Thought textual reasoning to improve localization performance. Specifically, we design a novel few-shot learning framework that leverages textual semantic information to enhance the model's ability to capture action commonalities and variations, which includes a semantic-aware text-visual alignment module designed to align the query and support videos at different levels. Meanwhile, to better express the temporal dependencies and causal relationships between actions at the textual level to assist action localization, we design a Chain of Thought (CoT)-like reasoning method that progressively guides the Vision Language Model (VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for videos. The generated texts can capture more variance of action than visual features. We conduct extensive experiments on the publicly available ActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named Human-related Anomaly Localization and explore the application of the TAL task in human anomaly detection. The experimental results demonstrate that our proposed method significantly outperforms existing methods in single-instance and multi-instance scenarios. We will release our code, data and benchmark.","authors":["Hongwei Ji","Wulian Yun","Mengshi Qi","Huadong Ma"],"url":"https://arxiv.org/abs/2504.13460"}
{"created":"2025-04-21","title":"An Addendum to NeBula: Towards Extending TEAM CoSTAR's Solution to Larger Scale Environments","abstract":"This paper presents an appendix to the original NeBula autonomy solution developed by the TEAM CoSTAR (Collaborative SubTerranean Autonomous Robots), participating in the DARPA Subterranean Challenge. Specifically, this paper presents extensions to NeBula's hardware, software, and algorithmic components that focus on increasing the range and scale of the exploration environment. From the algorithmic perspective, we discuss the following extensions to the original NeBula framework: (i) large-scale geometric and semantic environment mapping; (ii) an adaptive positioning system; (iii) probabilistic traversability analysis and local planning; (iv) large-scale POMDP-based global motion planning and exploration behavior; (v) large-scale networking and decentralized reasoning; (vi) communication-aware mission planning; and (vii) multi-modal ground-aerial exploration solutions. We demonstrate the application and deployment of the presented systems and solutions in various large-scale underground environments, including limestone mine exploration scenarios as well as deployment in the DARPA Subterranean challenge.","authors":["Ali Agha","Kyohei Otsu","Benjamin Morrell","David D. Fan","Sung-Kyun Kim","Muhammad Fadhil Ginting","Xianmei Lei","Jeffrey Edlund","Seyed Fakoorian","Amanda Bouman","Fernando Chavez","Taeyeon Kim","Gustavo J. Correa","Maira Saboia","Angel Santamaria-Navarro","Brett Lopez","Boseong Kim","Chanyoung Jung","Mamoru Sobue","Oriana Claudia Peltzer","Joshua Ott","Robert Trybula","Thomas Touma","Marcel Kaufmann","Tiago Stegun Vaquero","Torkom Pailevanian","Matteo Palieri","Yun Chang","Andrzej Reinke","Matthew Anderson","Frederik E. T. Sch\\\"oller","Patrick Spieler","Lillian M. Clark","Avak Archanian","Kenny Chen","Hovhannes Melikyan","Anushri Dixit","Harrison Delecki","Daniel Pastor","Barry Ridge","Nicolas Marchal","Jose Uribe","Sharmita Dey","Kamak Ebadi","Kyle Coble","Alexander Nikitas Dimopoulos","Vivek Thangavelu","Vivek S. Varadharajan","Nicholas Palomo","Antoni Rosinol","Arghya Chatterjee","Christoforos Kanellakis","Bjorn Lindqvist","Micah Corah","Kyle Strickland","Ryan Stonebraker","Michael Milano","Christopher E. Denniston","Sami Sahnoune","Thomas Claudet","Seungwook Lee","Gautam Salhotra","Edward Terry","Rithvik Musuku","Robin Schmid","Tony Tran","Ara Kourchians","Justin Schachter","Hector Azpurua","Levi Resende","Arash Kalantari","Jeremy Nash","Josh Lee","Christopher Patterson","Jennifer G. Blank","Kartik Patath","Yuki Kubo","Ryan Alimo","Yasin Almalioglu","Aaron Curtis","Jacqueline Sly","Tesla Wells","Nhut T. Ho","Mykel Kochenderfer","Giovanni Beltrame","George Nikolakopoulos","David Shim","Luca Carlone","Joel Burdick"],"url":"https://arxiv.org/abs/2504.13461"}
{"created":"2025-04-21","title":"Stratify: Rethinking Federated Learning for Non-IID Data through Balanced Sampling","abstract":"Federated Learning (FL) on non-independently and identically distributed (non-IID) data remains a critical challenge, as existing approaches struggle with severe data heterogeneity. Current methods primarily address symptoms of non-IID by applying incremental adjustments to Federated Averaging (FedAvg), rather than directly resolving its inherent design limitations. Consequently, performance significantly deteriorates under highly heterogeneous conditions, as the fundamental issue of imbalanced exposure to diverse class and feature distributions remains unresolved. This paper introduces Stratify, a novel FL framework designed to systematically manage class and feature distributions throughout training, effectively tackling the root cause of non-IID challenges. Inspired by classical stratified sampling, our approach employs a Stratified Label Schedule (SLS) to ensure balanced exposure across labels, significantly reducing bias and variance in aggregated gradients. Complementing SLS, we propose a label-aware client selection strategy, restricting participation exclusively to clients possessing data relevant to scheduled labels. Additionally, Stratify incorporates a fine-grained, high-frequency update scheme, accelerating convergence and further mitigating data heterogeneity. To uphold privacy, we implement a secure client selection protocol leveraging homomorphic encryption, enabling precise global label statistics without disclosing sensitive client information. Extensive evaluations on MNIST, CIFAR-10, CIFAR-100, Tiny-ImageNet, COVTYPE, PACS, and Digits-DG demonstrate that Stratify attains performance comparable to IID baselines, accelerates convergence, and reduces client-side computation compared to state-of-the-art methods, underscoring its practical effectiveness in realistic federated learning scenarios.","authors":["Hui Yeok Wong","Chee Kau Lim","Chee Seng Chan"],"url":"https://arxiv.org/abs/2504.13462"}
{"created":"2025-04-21","title":"Finite difference schemes for Hamilton--Jacobi equation on Wasserstein space on graphs","abstract":"This work proposes and studies numerical schemes for initial value problems of Hamilton--Jacobi equations (HJEs) with a graph individual noise on the Wasserstein space on graphs. Numerically solving such equations is particularly challenging due to the structural complexity caused by discrete geometric derivatives and logarithmic geometry. Our numerical schemes are constructed using finite difference approximations that are adapted to both the discrete geometry of graphs and the differential structure of Wasserstein spaces. To ensure numerical stability and accuracy of numerical behavior, we use extrapolation-type techniques to simulate the numerical solution on the boundary of density space. By analyzing approximation error of Wasserstein gradient of the viscosity solution, we prove the uniform convergence of the schemes to the original initial value problem, and establish an $L^{\\infty}_{\\mathrm{loc}}$-error estimate of order one-half. Several numerical experiments are presented to illustrate our theoretical findings and to study the effect of individual noise and Hamiltonians on graphs. To the best of our knowledge, this is the first result on numerical schemes for HJEs on the Wasserstein space with a graph structure.","authors":["Jianbo Cui","Tonghe Dang","Chenchen Mou"],"url":"https://arxiv.org/abs/2504.13463"}
{"created":"2025-04-21","title":"Are you SURE? Enhancing Multimodal Pretraining with Missing Modalities through Uncertainty Estimation","abstract":"Multimodal learning has demonstrated incredible successes by integrating diverse data sources, yet it often relies on the availability of all modalities - an assumption that rarely holds in real-world applications. Pretrained multimodal models, while effective, struggle when confronted with small-scale and incomplete datasets (i.e., missing modalities), limiting their practical applicability. Previous studies on reconstructing missing modalities have overlooked the reconstruction's potential unreliability, which could compromise the quality of the final outputs. We present SURE (Scalable Uncertainty and Reconstruction Estimation), a novel framework that extends the capabilities of pretrained multimodal models by introducing latent space reconstruction and uncertainty estimation for both reconstructed modalities and downstream tasks. Our method is architecture-agnostic, reconstructs missing modalities, and delivers reliable uncertainty estimates, improving both interpretability and performance. SURE introduces a unique Pearson Correlation-based loss and applies statistical error propagation in deep networks for the first time, allowing precise quantification of uncertainties from missing data and model predictions. Extensive experiments across tasks such as sentiment analysis, genre classification, and action recognition show that SURE consistently achieves state-of-the-art performance, ensuring robust predictions even in the presence of incomplete data.","authors":["Duy A. Nguyen","Quan Huu Do","Khoa D. Doan","Minh N. Do"],"url":"https://arxiv.org/abs/2504.13465"}
{"created":"2025-04-21","title":"HMPE:HeatMap Embedding for Efficient Transformer-Based Small Object Detection","abstract":"Current Transformer-based methods for small object detection continue emerging, yet they have still exhibited significant shortcomings. This paper introduces HeatMap Position Embedding (HMPE), a novel Transformer Optimization technique that enhances object detection performance by dynamically integrating positional encoding with semantic detection information through heatmap-guided adaptive learning.We also innovatively visualize the HMPE method, offering clear visualization of embedded information for parameter fine-tuning.We then create Multi-Scale ObjectBox-Heatmap Fusion Encoder (MOHFE) and HeatMap Induced High-Quality Queries for Decoder (HIDQ) modules. These are designed for the encoder and decoder, respectively, to generate high-quality queries and reduce background noise queries.Using both heatmap embedding and Linear-Snake Conv(LSConv) feature engineering, we enhance the embedding of massively diverse small object categories and reduced the decoder multihead layers, thereby accelerating both inference and training.In the generalization experiments, our approach outperforme the baseline mAP by 1.9% on the small object dataset (NWPU VHR-10) and by 1.2% on the general dataset (PASCAL VOC). By employing HMPE-enhanced embedding, we are able to reduce the number of decoder layers from eight to a minimum of three, significantly decreasing both inference and training costs.","authors":["YangChen Zeng"],"url":"https://arxiv.org/abs/2504.13469"}
{"created":"2025-04-21","title":"From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs","abstract":"In recent years, Large Language Models (LLMs) have significantly advanced artificial intelligence by optimizing traditional Natural Language Processing (NLP) pipelines, improving performance and generalization. This has spurred their integration into various systems. Many NLP systems, including ours, employ a \"one-stage\" pipeline directly incorporating LLMs. While effective, this approach incurs substantial costs and latency due to the need for large model parameters to achieve satisfactory outcomes. This paper introduces a three-stage cost-efficient end-to-end LLM deployment pipeline-including prototyping, knowledge transfer, and model compression-to tackle the cost-performance dilemma in LLM-based frameworks. Our approach yields a super tiny model optimized for cost and performance in online systems, simplifying the system architecture. Initially, by transforming complex tasks into a function call-based LLM-driven pipeline, an optimal performance prototype system is constructed to produce high-quality data as a teacher model. The second stage combine techniques like rejection fine-tuning, reinforcement learning and knowledge distillation to transfer knowledge to a smaller 0.5B student model, delivering effective performance at minimal cost. The final stage applies quantization and pruning to extremely compress model to 0.4B, achieving ultra-low latency and cost. The framework's modular design and cross-domain capabilities suggest potential applicability in other NLP areas.","authors":["Jiliang Ni","Jiachen Pu","Zhongyi Yang","Kun Zhou","Hui Wang","Xiaoliang Xiao","Dakui Wang","Xin Li","Jingfeng Luo","Conggang Hu"],"url":"https://arxiv.org/abs/2504.13471"}
{"created":"2025-04-21","title":"CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation","abstract":"Large language models (LLMs) have demonstrated strong capabilities in code generation, underscoring the critical need for rigorous and comprehensive evaluation. Existing evaluation approaches fall into three categories, including human-centered, metric-based, and LLM-based. Considering that human-centered approaches are labour-intensive and metric-based ones overly rely on reference answers, LLM-based approaches are gaining increasing attention due to their stronger contextual understanding capabilities and superior efficiency. However, the performance of LLM-based approaches remains limited due to: (1) lack of multisource domain knowledge, and (2) insufficient comprehension of complex code.","authors":["Xinchen Wang","Pengfei Gao","Chao Peng","Ruida Hu","Cuiyun Gao"],"url":"https://arxiv.org/abs/2504.13472"}
{"created":"2025-04-21","title":"Everything You Wanted to Know About LLM-based Vulnerability Detection But Were Afraid to Ask","abstract":"Large Language Models are a promising tool for automated vulnerability detection, thanks to their success in code generation and repair. However, despite widespread adoption, a critical question remains: Are LLMs truly effective at detecting real-world vulnerabilities? Current evaluations, which often assess models on isolated functions or files, ignore the broader execution and data-flow context essential for understanding vulnerabilities. This oversight leads to two types of misleading outcomes: incorrect conclusions and flawed rationales, collectively undermining the reliability of prior assessments. Therefore, in this paper, we challenge three widely held community beliefs: that LLMs are (i) unreliable, (ii) insensitive to code patches, and (iii) performance-plateaued across model scales. We argue that these beliefs are artifacts of context-deprived evaluations. To address this, we propose CORRECT (Context-Rich Reasoning Evaluation of Code with Trust), a new evaluation framework that systematically incorporates contextual information into LLM-based vulnerability detection. We construct a context-rich dataset of 2,000 vulnerable-patched program pairs spanning 99 CWEs and evaluate 13 LLMs across four model families. Our framework elicits both binary predictions and natural-language rationales, which are further validated using LLM-as-a-judge techniques. Our findings overturn existing misconceptions. When provided with sufficient context, SOTA LLMs achieve significantly improved performance (e.g., 0.7 F1-score on key CWEs), with 0.8 precision. We show that most false positives stem from reasoning errors rather than misclassification, and that while model and test-time scaling improve performance, they introduce diminishing returns and trade-offs in recall. Finally, we uncover new flaws in current LLM-based detection systems, such as limited generalization and overthinking biases.","authors":["Yue Li","Xiao Li","Hao Wu","Minghui Xu","Yue Zhang","Xiuzhen Cheng","Fengyuan Xu","Sheng Zhong"],"url":"https://arxiv.org/abs/2504.13474"}
{"created":"2025-04-21","title":"LLM Sensitivity Evaluation Framework for Clinical Diagnosis","abstract":"Large language models (LLMs) have demonstrated impressive performance across various domains. However, for clinical diagnosis, higher expectations are required for LLM's reliability and sensitivity: thinking like physicians and remaining sensitive to key medical information that affects diagnostic reasoning, as subtle variations can lead to different diagnosis results. Yet, existing works focus mainly on investigating the sensitivity of LLMs to irrelevant context and overlook the importance of key information. In this paper, we investigate the sensitivity of LLMs, i.e. GPT-3.5, GPT-4, Gemini, Claude3 and LLaMA2-7b, to key medical information by introducing different perturbation strategies. The evaluation results highlight the limitations of current LLMs in remaining sensitive to key medical information for diagnostic decision-making. The evolution of LLMs must focus on improving their reliability, enhancing their ability to be sensitive to key information, and effectively utilizing this information. These improvements will enhance human trust in LLMs and facilitate their practical application in real-world scenarios. Our code and dataset are available at https://github.com/chenwei23333/DiagnosisQA.","authors":["Chenwei Yan","Xiangling Fu","Yuxuan Xiong","Tianyi Wang","Siu Cheung Hui","Ji Wu","Xien Liu"],"url":"https://arxiv.org/abs/2504.13475"}
{"created":"2025-04-21","title":"Variational Autoencoder Framework for Hyperspectral Retrievals (Hyper-VAE) of Phytoplankton Absorption and Chlorophyll a in Coastal Waters for NASA's EMIT and PACE Missions","abstract":"Phytoplankton absorb and scatter light in unique ways, subtly altering the color of water, changes that are often minor for human eyes to detect but can be captured by sensitive ocean color instruments onboard satellites from space. Hyperspectral sensors, paired with advanced algorithms, are expected to significantly enhance the characterization of phytoplankton community composition, especially in coastal waters where ocean color remote sensing applications have historically encountered significant challenges. This study presents novel machine learning-based solutions for NASA's hyperspectral missions, including EMIT and PACE, tackling high-fidelity retrievals of phytoplankton absorption coefficient and chlorophyll a from their hyperspectral remote sensing reflectance. Given that a single Rrs spectrum may correspond to varied combinations of inherent optical properties and associated concentrations, the Variational Autoencoder (VAE) is used as a backbone in this study to handle such multi-distribution prediction problems. We first time tailor the VAE model with innovative designs to achieve hyperspectral retrievals of aphy and of Chl-a from hyperspectral Rrs in optically complex estuarine-coastal waters. Validation with extensive experimental observation demonstrates superior performance of the VAE models with high precision and low bias. The in-depth analysis of VAE's advanced model structures and learning designs highlights the improvement and advantages of VAE-based solutions over the mixture density network (MDN) approach, particularly on high-dimensional data, such as PACE. Our study provides strong evidence that current EMIT and PACE hyperspectral data as well as the upcoming Surface Biology Geology mission will open new pathways toward a better understanding of phytoplankton community dynamics in aquatic ecosystems when integrated with AI technologies.","authors":["Jiadong Lou","Bingqing Liu","Yuanheng Xiong","Xiaodong Zhang","Xu Yuan"],"url":"https://arxiv.org/abs/2504.13476"}
{"created":"2025-04-21","title":"Creating 'Full-Stack' Hybrid Reasoning Systems that Prioritize and Enhance Human Intelligence","abstract":"The idea of augmented or hybrid intelligence offers a compelling vision for combining human and AI capabilities, especially in tasks where human wisdom, expertise, or common sense are essential. Unfortunately, human reasoning can be flawed and shortsighted, resulting in adverse individual impacts or even long-term societal consequences. While strong efforts are being made to develop and optimize the AI aspect of hybrid reasoning, the real urgency lies in fostering wiser and more intelligent human participation. Tools that enhance critical thinking, ingenuity, expertise, and even wisdom could be essential in addressing the challenges of our emerging future. This paper proposes the development of generative AI-based tools that enhance both the human ability to reflect upon a problem as well as the ability to explore the technical aspects of it. A high-level model is also described for integrating AI and human capabilities in a way that centralizes human participation and control.","authors":["Sean Koon"],"url":"https://arxiv.org/abs/2504.13477"}
{"created":"2025-04-21","title":"Safety Monitoring for Learning-Enabled Cyber-Physical Systems in Out-of-Distribution Scenarios","abstract":"The safety of learning-enabled cyber-physical systems is compromised by the well-known vulnerabilities of deep neural networks to out-of-distribution (OOD) inputs. Existing literature has sought to monitor the safety of such systems by detecting OOD data. However, such approaches have limited utility, as the presence of an OOD input does not necessarily imply the violation of a desired safety property. We instead propose to directly monitor safety in a manner that is itself robust to OOD data. To this end, we predict violations of signal temporal logic safety specifications based on predicted future trajectories. Our safety monitor additionally uses a novel combination of adaptive conformal prediction and incremental learning. The former obtains probabilistic prediction guarantees even on OOD data, and the latter prevents overly conservative predictions. We evaluate the efficacy of the proposed approach in two case studies on safety monitoring: 1) predicting collisions of an F1Tenth car with static obstacles, and 2) predicting collisions of a race car with multiple dynamic obstacles. We find that adaptive conformal prediction obtains theoretical guarantees where other uncertainty quantification methods fail to do so. Additionally, combining adaptive conformal prediction and incremental learning for safety monitoring achieves high recall and timeliness while reducing loss in precision. We achieve these results even in OOD settings and outperform alternative methods.","authors":["Vivian Lin","Ramneet Kaur","Yahan Yang","Souradeep Dutta","Yiannis Kantaros","Anirban Roy","Susmit Jha","Oleg Sokolsky","Insup Lee"],"url":"https://arxiv.org/abs/2504.13478"}
{"created":"2025-04-21","title":"SFL-LEO: Asynchronous Split-Federated Learning Design for LEO Satellite-Ground Network Framework","abstract":"Recently, the rapid development of LEO satellite networks spurs another widespread concern-data processing at satellites. However, achieving efficient computation at LEO satellites in highly dynamic satellite networks is challenging and remains an open problem when considering the constrained computation capability of LEO satellites. For the first time, we propose a novel distributed learning framework named SFL-LEO by combining Federated Learning (FL) with Split Learning (SL) to accommodate the high dynamics of LEO satellite networks and the constrained computation capability of LEO satellites by leveraging the periodical orbit traveling feature. The proposed scheme allows training locally by introducing an asynchronous training strategy, i.e., achieving local update when LEO satellites disconnect with the ground station, to provide much more training space and thus increase the training performance. Meanwhile, it aggregates client-side sub-models at the ground station and then distributes them to LEO satellites by borrowing the idea from the federated learning scheme. Experiment results driven by satellite-ground bandwidth measured in Starlink demonstrate that SFL-LEO provides a similar accuracy performance with the conventional SL scheme because it can perform local training even within the disconnection duration.","authors":["Jiasheng Wu","Jingjing Zhang","Zheng Lin","Zhe Chen","Xiong Wang","Wenjun Zhu","Yue Gao"],"url":"https://arxiv.org/abs/2504.13479"}
{"created":"2025-04-21","title":"Integrating Locality-Aware Attention with Transformers for General Geometry PDEs","abstract":"Neural operators have emerged as promising frameworks for learning mappings governed by partial differential equations (PDEs), serving as data-driven alternatives to traditional numerical methods. While methods such as the Fourier neural operator (FNO) have demonstrated notable performance, their reliance on uniform grids restricts their applicability to complex geometries and irregular meshes. Recently, Transformer-based neural operators with linear attention mechanisms have shown potential in overcoming these limitations for large-scale PDE simulations. However, these approaches predominantly emphasize global feature aggregation, often overlooking fine-scale dynamics and localized PDE behaviors essential for accurate solutions. To address these challenges, we propose the Locality-Aware Attention Transformer (LA2Former), which leverages K-nearest neighbors for dynamic patchifying and integrates global-local attention for enhanced PDE modeling. By combining linear attention for efficient global context encoding with pairwise attention for capturing intricate local interactions, LA2Former achieves an optimal balance between computational efficiency and predictive accuracy. Extensive evaluations across six benchmark datasets demonstrate that LA2Former improves predictive accuracy by over 50% relative to existing linear attention methods, while also outperforming full pairwise attention under optimal conditions. This work underscores the critical importance of localized feature learning in advancing Transformer-based neural operators for solving PDEs on complex and irregular domains.","authors":["Minsu Koh","Beom-Chul Park","Heejo Kong","Seong-Whan Lee"],"url":"https://arxiv.org/abs/2504.13480"}
{"created":"2025-04-21","title":"Improving Sequential Recommenders through Counterfactual Augmentation of System Exposure","abstract":"In sequential recommendation (SR), system exposure refers to items that are exposed to the user. Typically, only a few of the exposed items would be interacted with by the user. Although SR has achieved great success in predicting future user interests, existing SR methods still fail to fully exploit system exposure data. Most methods only model items that have been interacted with, while the large volume of exposed but non-interacted items is overlooked. Even methods that consider the whole system exposure typically train the recommender using only the logged historical system exposure, without exploring unseen user interests.","authors":["Ziqi Zhao","Zhaochun Ren","Jiyuan Yang","Zuming Yan","Zihan Wang","Liu Yang","Pengjie Ren","Zhumin Chen","Maarten de Rijke","Xin Xin"],"url":"https://arxiv.org/abs/2504.13482"}
{"created":"2025-04-21","title":"Latent Tensor Factorization with Nonlinear PID Control for Missing Data Recovery in Non-Intrusive Load Monitoring","abstract":"Non-Intrusive Load Monitoring (NILM) has emerged as a key smart grid technology, identifying electrical device and providing detailed energy consumption data for precise demand response management. Nevertheless, NILM data suffers from missing values due to inescapable factors like sensor failure, leading to inaccuracies in non-intrusive load monitoring. A stochastic gradient descent (SGD)-based latent factorization of tensors model has proven to be effective in estimating missing data, however, it updates a latent factor solely based on the current stochastic gradient, without considering past information, which leads to slow convergence of anLFT model. To address this issue, this paper proposes a Nonlinear Proportional-integral-derivative (PID)-Incorporated Latent factorization of tensors (NPIL) model with two-fold ideas: a) rebuilding the instant learning error according to the principle of a nonlinear PID controller, thus, the past update information is efficiently incorporated into the learning scheme, and b) implementing gain parameter adaptation by utilizing particle swarm optimization (PSO) algorithm, hence, the model computational efficiency is effectively improved. Experimental results on real-world NILM datasets demonstrate that the proposed NPIL model surpasses state-of-the-art models in convergence rate and accuracy when predicting the missing NILM data.","authors":["Yiran Wang","Tangtang Xie","Hao Wu"],"url":"https://arxiv.org/abs/2504.13483"}
{"created":"2025-04-21","title":"Monitor and Recover: A Paradigm for Future Research on Distribution Shift in Learning-Enabled Cyber-Physical Systems","abstract":"With the known vulnerability of neural networks to distribution shift, maintaining reliability in learning-enabled cyber-physical systems poses a salient challenge. In response, many existing methods adopt a detect and abstain methodology, aiming to detect distribution shift at inference time so that the learning-enabled component can abstain from decision-making. This approach, however, has limited use in real-world applications. We instead propose a monitor and recover paradigm as a promising direction for future research. This philosophy emphasizes 1) robust safety monitoring instead of distribution shift detection and 2) distribution shift recovery instead of abstention. We discuss two examples from our recent work.","authors":["Vivian Lin","Insup Lee"],"url":"https://arxiv.org/abs/2504.13484"}
{"created":"2025-04-21","title":"Exploring Culturally Informed AI Assistants: A Comparative Study of ChatBlackGPT and ChatGPT","abstract":"In recent years, we have seen an influx in reliance on AI assistants for information seeking. Given this widespread use and the known challenges AI poses for Black users, recent efforts have emerged to identify key considerations needed to provide meaningful support. One notable effort is the development of ChatBlackGPT, a culturally informed AI assistant designed to provide culturally relevant responses. Despite the existence of ChatBlackGPT, there is no research on when and how Black communities might engage with culturally informed AI assistants and the distinctions between engagement with general purpose tools like ChatGPT. To fill this gap, we propose a research agenda grounded in results from a preliminary comparative analysis of outputs provided by ChatGPT and ChatBlackGPT for travel-related inquiries. Our efforts thus far emphasize the need to consider Black communities' values, perceptions, and experiences when designing AI assistants that acknowledge the Black lived experience.","authors":["Lisa Egede","Ebtesam Al Haque","Gabriella Thompson","Alicia Boyd","Angela D. R. Smith","Brittany Johnson"],"url":"https://arxiv.org/abs/2504.13486"}
{"created":"2025-04-21","title":"New Results on a General Class of Minimum Norm Optimization Problems","abstract":"We study the general norm optimization for combinatorial problems, initiated by Chakrabarty and Swamy (STOC 2019). We propose a general formulation that captures a large class of combinatorial structures: we are given a set $U$ of $n$ weighted elements and a family of feasible subsets $F$. Each subset $S\\in F$ is called a feasible solution/set of the problem. We denote the value vector by $v=\\{v_i\\}_{i\\in [n]}$, where $v_i\\geq 0$ is the value of element $i$. For any subset $S\\subseteq U$, we use $v[S]$ to denote the $n$-dimensional vector $\\{v_e\\cdot \\mathbf{1}[e\\in S]\\}_{e\\in U}$. Let $f: \\mathbb{R}^n\\rightarrow\\mathbb{R}_+$ be a symmetric monotone norm function. Our goal is to minimize the norm objective $f(v[S])$ over feasible subset $S\\in F$.","authors":["Kuowen Chen","Jian Li","Yuval Rabani","Yiran Zhang"],"url":"https://arxiv.org/abs/2504.13489"}
{"created":"2025-04-21","title":"Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing","abstract":"Despite recent advances in diffusion models, achieving reliable image generation and editing remains challenging due to the inherent diversity induced by stochastic noise in the sampling process. Instruction-guided image editing with diffusion models offers user-friendly capabilities, yet editing failures, such as background distortion, frequently occur. Users often resort to trial and error, adjusting seeds or prompts to achieve satisfactory results, which is inefficient. While seed selection methods exist for Text-to-Image (T2I) generation, they depend on external verifiers, limiting applicability, and evaluating multiple seeds increases computational complexity. To address this, we first establish a multiple-seed-based image editing baseline using background consistency scores, achieving Best-of-N performance without supervision. Building on this, we introduce ELECT (Early-timestep Latent Evaluation for Candidate Selection), a zero-shot framework that selects reliable seeds by estimating background mismatches at early diffusion timesteps, identifying the seed that retains the background while modifying only the foreground. ELECT ranks seed candidates by a background inconsistency score, filtering unsuitable samples early based on background consistency while preserving editability. Beyond standalone seed selection, ELECT integrates into instruction-guided editing pipelines and extends to Multimodal Large-Language Models (MLLMs) for joint seed and prompt selection, further improving results when seed selection alone is insufficient. Experiments show that ELECT reduces computational costs (by 41 percent on average and up to 61 percent) while improving background consistency and instruction adherence, achieving around 40 percent success rates in previously failed cases - without any external supervision or training.","authors":["Joowon Kim","Ziseok Lee","Donghyeon Cho","Sanghyun Jo","Yeonsung Jung","Kyungsu Kim","Eunho Yang"],"url":"https://arxiv.org/abs/2504.13490"}
{"created":"2025-04-21","title":"Statistical Validation in Cultural Adaptations of Cognitive Tests: A Multi- Regional Systematic Review","abstract":"This systematic review discusses the methodological approaches and statistical confirmations of cross-cultural adaptations of cognitive evaluation tools used with different populations. The review considers six seminal studies on the methodology of cultural adaptation in Europe, Asia, Africa, and South America. The results indicate that proper adaptations need holistic models with demographic changes, and education explained as much as 26.76% of the variance in MoCA-H scores. Cultural-linguistic factors explained 6.89% of the variance in European adaptations of MoCA-H; however, another study on adapted MMSE and BCSB among Brazilian Indigenous populations reported excellent diagnostic performance, with a sensitivity of 94.4% and specificity of 99.2%. There was 78.5% inter-rater agreement on the evaluation of cultural adaptation using the Manchester Translation Evaluation Checklist. A paramount message of the paper is that community feedback is necessary for culturally appropriate preparation, standardized translation protocols also must be included, along with robust statistical validation methodologies for developing cognitive assessment instruments. This review supplies evidence-based frameworks for the further adaptation of cognitive assessments in increasingly diverse global health settings.","authors":["Miit Daga","Priyasha Mohanty","Ram Krishna","Swarna Priya RM"],"url":"https://arxiv.org/abs/2504.13495"}
{"created":"2025-04-21","title":"U-Shape Mamba: State Space Model for faster diffusion","abstract":"Diffusion models have become the most popular approach for high-quality image generation, but their high computational cost still remains a significant challenge. To address this problem, we propose U-Shape Mamba (USM), a novel diffusion model that leverages Mamba-based layers within a U-Net-like hierarchical structure. By progressively reducing sequence length in the encoder and restoring it in the decoder through Mamba blocks, USM significantly lowers computational overhead while maintaining strong generative capabilities. Experimental results against Zigma, which is currently the most efficient Mamba-based diffusion model, demonstrate that USM achieves one-third the GFlops, requires less memory and is faster, while outperforming Zigma in image quality. Frechet Inception Distance (FID) is improved by 15.3, 0.84 and 2.7 points on AFHQ, CelebAHQ and COCO datasets, respectively. These findings highlight USM as a highly efficient and scalable solution for diffusion-based generative models, making high-quality image synthesis more accessible to the research community while reducing computational costs.","authors":["Alex Ergasti","Filippo Botti","Tomaso Fontanini","Claudio Ferrari","Massimo Bertozzi","Andrea Prati"],"url":"https://arxiv.org/abs/2504.13499"}
{"created":"2025-04-21","title":"Prejudge-Before-Think: Enhancing Large Language Models at Test-Time by Process Prejudge Reasoning","abstract":"In this paper, we introduce a new \\emph{process prejudge} strategy in LLM reasoning to demonstrate that bootstrapping with process prejudge allows the LLM to adaptively anticipate the errors encountered when advancing the subsequent reasoning steps, similar to people sometimes pausing to think about what mistakes may occur and how to avoid them, rather than relying solely on trial and error. Specifically, we define a prejudge node in the rationale, which represents a reasoning step, with at least one step that follows the prejudge node that has no paths toward the correct answer. To synthesize the prejudge reasoning process, we present an automated reasoning framework with a dynamic tree-searching strategy. This framework requires only one LLM to perform answer judging, response critiquing, prejudge generation, and thought completion. Furthermore, we develop a two-phase training mechanism with supervised fine-tuning (SFT) and reinforcement learning (RL) to further enhance the reasoning capabilities of LLMs. Experimental results from competition-level complex reasoning demonstrate that our method can teach the model to prejudge before thinking and significantly enhance the reasoning ability of LLMs. Code and data is released at https://github.com/wjn1996/Prejudge-Before-Think.","authors":["Jianing Wang","Jin Jiang","Yang Liu","Mengdi Zhang","Xunliang Cai"],"url":"https://arxiv.org/abs/2504.13500"}
{"created":"2025-04-21","title":"An algorithm to compute Selmer groups via resolutions by permutations modules","abstract":"Given a number field with absolute Galois group $\\mathcal{G}$, a finite Galois module $M$, and a Selmer system $\\mathcal{L}$, this article gives a method to compute Sel$_\\mathcal{L}$, the Selmer group of $M$ attached to $\\mathcal{L}$. First we describe an algorithm to obtain a resolution of $M$ where the morphisms are given by Hecke operators. Then we construct another group $H^1_S(\\mathcal{G}, M)$ and we prove, using the properties of Hecke operators, that $H^1_S(\\mathcal{G}, M)$ is a Selmer group containing Sel$_\\mathcal{L}$. Then, we discuss the time complexity of this method.","authors":["Fabrice Etienne (UB","CANARI","IMB)"],"url":"https://arxiv.org/abs/2504.13506"}
{"created":"2025-04-21","title":"Large Language Models for Validating Network Protocol Parsers","abstract":"Network protocol parsers are essential for enabling correct and secure communication between devices. Bugs in these parsers can introduce critical vulnerabilities, including memory corruption, information leakage, and denial-of-service attacks. An intuitive way to assess parser correctness is to compare the implementation with its official protocol standard. However, this comparison is challenging because protocol standards are typically written in natural language, whereas implementations are in source code. Existing methods like model checking, fuzzing, and differential testing have been used to find parsing bugs, but they either require significant manual effort or ignore the protocol standards, limiting their ability to detect semantic violations. To enable more automated validation of parser implementations against protocol standards, we propose PARVAL, a multi-agent framework built on large language models (LLMs). PARVAL leverages the capabilities of LLMs to understand both natural language and code. It transforms both protocol standards and their implementations into a unified intermediate representation, referred to as format specifications, and performs a differential comparison to uncover inconsistencies. We evaluate PARVAL on the Bidirectional Forwarding Detection (BFD) protocol. Our experiments demonstrate that PARVAL successfully identifies inconsistencies between the implementation and its RFC standard, achieving a low false positive rate of 5.6%. PARVAL uncovers seven unique bugs, including five previously unknown issues.","authors":["Mingwei Zheng","Danning Xie","Xiangyu Zhang"],"url":"https://arxiv.org/abs/2504.13515"}
{"created":"2025-04-21","title":"Optimizing Electric Vehicle Charging Station Locations: A Data-driven System with Multi-source Fusion","abstract":"With the growing electric vehicles (EVs) charging demand, urban planners face the challenges of providing charging infrastructure at optimal locations. For example, range anxiety during long-distance travel and the inadequate distribution of residential charging stations are the major issues many cities face. To achieve reasonable estimation and deployment of the charging demand, we develop a data-driven system based on existing EV trips in New South Wales (NSW) state, Australia, incorporating multiple factors that enhance the geographical feasibility of recommended charging stations. Our system integrates data sources including EV trip data, geographical data such as route data and Local Government Area (LGA) boundaries, as well as features like fire and flood risks, and Points of Interest (POIs). We visualize our results to intuitively demonstrate the findings from our data-driven, multi-source fusion system, and evaluate them through case studies. The outcome of this work can provide a platform for discussion to develop new insights that could be used to give guidance on where to position future EV charging stations.","authors":["Lihuan Li","Du Yin","Hao Xue","David Lillo-Trynes","Flora Salim"],"url":"https://arxiv.org/abs/2504.13517"}
{"created":"2025-04-21","title":"Deep Learning Models Meet Financial Data Modalities","abstract":"Algorithmic trading relies on extracting meaningful signals from diverse financial data sources, including candlestick charts, order statistics on put and canceled orders, traded volume data, limit order books, and news flow. While deep learning has demonstrated remarkable success in processing unstructured data and has significantly advanced natural language processing, its application to structured financial data remains an ongoing challenge. This study investigates the integration of deep learning models with financial data modalities, aiming to enhance predictive performance in trading strategies and portfolio optimization. We present a novel approach to incorporating limit order book analysis into algorithmic trading by developing embedding techniques and treating sequential limit order book snapshots as distinct input channels in an image-based representation. Our methodology for processing limit order book data achieves state-of-the-art performance in high-frequency trading algorithms, underscoring the effectiveness of deep learning in financial applications.","authors":["Kasymkhan Khubiev","Michail Semenov"],"url":"https://arxiv.org/abs/2504.13521"}
{"created":"2025-04-21","title":"Cross-Modal Temporal Fusion for Financial Market Forecasting","abstract":"Accurate financial market forecasting requires diverse data sources, including historical price trends, macroeconomic indicators, and financial news, each contributing unique predictive signals. However, existing methods often process these modalities independently or fail to effectively model their interactions. In this paper, we introduce Cross-Modal Temporal Fusion (CMTF), a novel transformer-based framework that integrates heterogeneous financial data to improve predictive accuracy. Our approach employs attention mechanisms to dynamically weight the contribution of different modalities, along with a specialized tensor interpretation module for feature extraction. To facilitate rapid model iteration in industry applications, we incorporate a mature auto-training scheme that streamlines optimization. When applied to real-world financial datasets, CMTF demonstrates improvements over baseline models in forecasting stock price movements and provides a scalable and effective solution for cross-modal integration in financial market prediction.","authors":["Yunhua Pei","John Cartlidge","Anandadeep Mandal","Daniel Gold","Enrique Marcilio","Riccardo Mazzon"],"url":"https://arxiv.org/abs/2504.13522"}
{"created":"2025-04-21","title":"OBIFormer: A Fast Attentive Denoising Framework for Oracle Bone Inscriptions","abstract":"Oracle bone inscriptions (OBIs) are the earliest known form of Chinese characters and serve as a valuable resource for research in anthropology and archaeology. However, most excavated fragments are severely degraded due to thousands of years of natural weathering, corrosion, and man-made destruction, making automatic OBI recognition extremely challenging. Previous methods either focus on pixel-level information or utilize vanilla transformers for glyph-based OBI denoising, which leads to tremendous computational overhead. Therefore, this paper proposes a fast attentive denoising framework for oracle bone inscriptions, i.e., OBIFormer. It leverages channel-wise self-attention, glyph extraction, and selective kernel feature fusion to reconstruct denoised images precisely while being computationally efficient. Our OBIFormer achieves state-of-the-art denoising performance for PSNR and SSIM metrics on synthetic and original OBI datasets. Furthermore, comprehensive experiments on a real oracle dataset demonstrate the great potential of our OBIFormer in assisting automatic OBI recognition. The code will be made available at https://github.com/LJHolyGround/OBIFormer.","authors":["Jinhao Li","Zijian Chen","Tingzhu Chen","Zhiji Liu","Changbo Wang"],"url":"https://arxiv.org/abs/2504.13524"}
{"created":"2025-04-21","title":"Multi-class Item Mining under Local Differential Privacy","abstract":"Item mining, a fundamental task for collecting statistical data from users, has raised increasing privacy concerns. To address these concerns, local differential privacy (LDP) was proposed as a privacy-preserving technique. Existing LDP item mining mechanisms primarily concentrate on global statistics, i.e., those from the entire dataset. Nevertheless, they fall short of user-tailored tasks such as personalized recommendations, whereas classwise statistics can improve task accuracy with fine-grained information. Meanwhile, the introduction of class labels brings new challenges. Label perturbation may result in invalid items for aggregation. To this end, we propose frameworks for multi-class item mining, along with two mechanisms: validity perturbation to reduce the impact of invalid data, and correlated perturbation to preserve the relationship between labels and items. We also apply these optimized methods to two multi-class item mining queries: frequency estimation and top-$k$ item mining. Through theoretical analysis and extensive experiments, we verify the effectiveness and superiority of these methods.","authors":["Yulian Mao","Qingqing Ye","Rong Du","Qi Wang","Kai Huang","Haibo Hu"],"url":"https://arxiv.org/abs/2504.13526"}
{"created":"2025-04-21","title":"Designing a reliable lateral movement detector using a graph foundation model","abstract":"Foundation models have recently emerged as a new paradigm in machine learning (ML). These models are pre-trained on large and diverse datasets and can subsequently be applied to various downstream tasks with little or no retraining. This allows people without advanced ML expertise to build ML applications, accelerating innovation across many fields. However, the adoption of foundation models in cybersecurity is hindered by their inability to efficiently process data such as network traffic captures or binary executables. The recent introduction of graph foundation models (GFMs) could make a significant difference, as graphs are well-suited to representing these types of data. We study the usability of GFMs in cybersecurity through the lens of one specific use case, namely lateral movement detection. Using a pre-trained GFM, we build a detector that reaches state-of-the-art performance without requiring any training on domain-specific data. This case study thus provides compelling evidence of the potential of GFMs for cybersecurity.","authors":["Corentin Larroche"],"url":"https://arxiv.org/abs/2504.13527"}
{"created":"2025-04-21","title":"Risk-aware black-box portfolio construction using Bayesian optimization with adaptive weighted Lagrangian estimator","abstract":"Existing portfolio management approaches are often black-box models due to safety and commercial issues in the industry. However, their performance can vary considerably whenever market conditions or internal trading strategies change. Furthermore, evaluating these non-transparent systems is expensive, where certain budgets limit observations of the systems. Therefore, optimizing performance while controlling the potential risk of these financial systems has become a critical challenge. This work presents a novel Bayesian optimization framework to optimize black-box portfolio management models under limited observations. In conventional Bayesian optimization settings, the objective function is to maximize the expectation of performance metrics. However, simply maximizing performance expectations leads to erratic optimization trajectories, which exacerbate risk accumulation in portfolio management. Meanwhile, this can lead to misalignment between the target distribution and the actual distribution of the black-box model. To mitigate this problem, we propose an adaptive weight Lagrangian estimator considering dual objective, which incorporates maximizing model performance and minimizing variance of model observations. Extensive experiments demonstrate the superiority of our approach over five backtest settings with three black-box stock portfolio management models. Ablation studies further verify the effectiveness of the proposed estimator.","authors":["Zinuo You","John Cartlidge","Karen Elliott","Menghan Ge","Daniel Gold"],"url":"https://arxiv.org/abs/2504.13529"}
{"created":"2025-04-21","title":"Can Local Representation Alignment RNNs Solve Temporal Tasks?","abstract":"Recurrent Neural Networks (RNNs) are commonly used for real-time processing, streaming data, and cases where the amount of training samples is limited. Backpropagation Through Time (BPTT) is the predominant algorithm for training RNNs; however, it is frequently criticized for being prone to exploding and vanishing gradients and being biologically implausible. In this paper, we present and evaluate a target propagation-based method for RNNs, which uses local updates and seeks to reduce the said instabilities. Having stable RNN models increases their practical use in a wide range of fields such as natural language processing, time-series forecasting, anomaly detection, control systems, and robotics.","authors":["Nikolay Manchev","Luis C. Garcia-Peraza-Herrera"],"url":"https://arxiv.org/abs/2504.13531"}
{"created":"2025-04-21","title":"CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models","abstract":"While chain-of-thought (CoT) reasoning improves the performance of large language models (LLMs) in complex tasks, it still has two main challenges: the low reliability of relying solely on LLMs to generate reasoning chains and the interference of natural language reasoning chains on the inference logic of LLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework with three key designs: (i) Knowledge Graph-driven CoT Generation, featuring knowledge graphs to modulate reasoning chain generation of LLMs, thereby enhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented generation (RAG) into knowledge graphs to retrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable information; (iii) Pseudo-Program Prompting Execution, which encourages LLMs to execute reasoning tasks in pseudo-programs with greater logical rigor. We conduct a comprehensive evaluation on nine public datasets, covering three reasoning problems. Compared with the-state-of-the-art methods, CoT-RAG exhibits a significant accuracy improvement, ranging from 4.0% to 23.0%. Furthermore, testing on four domain-specific datasets, CoT-RAG shows remarkable accuracy and efficient execution, highlighting its strong practical applicability and scalability.","authors":["Feiyang Li","Peng Fang","Zhan Shi","Arijit Khan","Fang Wang","Dan Feng","Weihao Wang","Xin Zhang","Yongjian Cui"],"url":"https://arxiv.org/abs/2504.13534"}
{"created":"2025-04-21","title":"MusFlow: Multimodal Music Generation via Conditional Flow Matching","abstract":"Music generation aims to create music segments that align with human aesthetics based on diverse conditional information. Despite advancements in generating music from specific textual descriptions (e.g., style, genre, instruments), the practical application is still hindered by ordinary users' limited expertise or time to write accurate prompts. To bridge this application gap, this paper introduces MusFlow, a novel multimodal music generation model using Conditional Flow Matching. We employ multiple Multi-Layer Perceptrons (MLPs) to align multimodal conditional information into the audio's CLAP embedding space. Conditional flow matching is trained to reconstruct the compressed Mel-spectrogram in the pretrained VAE latent space guided by aligned feature embedding. MusFlow can generate music from images, story texts, and music captions. To collect data for model training, inspired by multi-agent collaboration, we construct an intelligent data annotation workflow centered around a fine-tuned Qwen2-VL model. Using this workflow, we build a new multimodal music dataset, MMusSet, with each sample containing a quadruple of image, story text, music caption, and music piece. We conduct four sets of experiments: image-to-music, story-to-music, caption-to-music, and multimodal music generation. Experimental results demonstrate that MusFlow can generate high-quality music pieces whether the input conditions are unimodal or multimodal. We hope this work can advance the application of music generation in multimedia field, making music creation more accessible. Our generated samples, code and dataset are available at musflow.github.io.","authors":["Jiahao Song","Yuzhao Wang"],"url":"https://arxiv.org/abs/2504.13535"}
{"created":"2025-04-21","title":"Polynomial-time Tractable Problems over the $p$-adic Numbers","abstract":"We study the computational complexity of fundamental problems over the $p$-adic numbers ${\\mathbb Q}_p$ and the $p$-adic integers ${\\mathbb Z}_p$. Gu\\'epin, Haase, and Worrell proved that checking satisfiability of systems of linear equations combined with valuation constraints of the form $v_p(x) = c$ for $p \\geq 5$ is NP-complete (both over ${\\mathbb Z}_p$ and over ${\\mathbb Q}_p$), and left the cases $p=2$ and $p=3$ open. We solve their problem by showing that the problem is NP-complete for ${\\mathbb Z}_3$ and for ${\\mathbb Q}_3$, but that it is in P for ${\\mathbb Z}_2$ and for ${\\mathbb Q}_2$. We also present different polynomial-time algorithms for solvability of systems of linear equations in ${\\mathbb Q}_p$ with either constraints of the form $v_p(x) \\leq c$ or of the form $v_p(x)\\geq c$ for $c \\in {\\mathbb Z}$. Finally, we show how our algorithms can be used to decide in polynomial time the satisfiability of systems of (strict and non-strict) linear inequalities over ${\\mathbb Q}$ together with valuation constraints $v_p(x) \\geq c$ for several different prime numbers $p$ simultaneously.","authors":["Arno Fehm","Manuel Bodirsky"],"url":"https://arxiv.org/abs/2504.13536"}
{"created":"2025-04-21","title":"Complexity of Post-Quantum Cryptography in Embedded Systems and Its Optimization Strategies","abstract":"With the rapid advancements in quantum computing, traditional cryptographic schemes like Rivest-Shamir-Adleman (RSA) and elliptic curve cryptography (ECC) are becoming vulnerable, necessitating the development of quantum-resistant algorithms. The National Institute of Standards and Technology (NIST) has initiated a standardization process for PQC algorithms, and several candidates, including CRYSTALS-Kyber and McEliece, have reached the final stages. This paper first provides a comprehensive analysis of the hardware complexity of post-quantum cryptography (PQC) in embedded systems, categorizing PQC algorithms into families based on their underlying mathematical problems: lattice-based, code-based, hash-based and multivariate / isogeny-based schemes. Each family presents distinct computational, memory, and energy profiles, making them suitable for different use cases. To address these challenges, this paper discusses optimization strategies such as pipelining, parallelization, and high-level synthesis (HLS), which can improve the performance and energy efficiency of PQC implementations. Finally, a detailed complexity analysis of CRYSTALS-Kyber and McEliece, comparing their key generation, encryption, and decryption processes in terms of computational complexity, has been conducted.","authors":["Omar Alnaseri","Yassine Himeur","Shadi Atalla","Wathiq Mansoor"],"url":"https://arxiv.org/abs/2504.13537"}
{"created":"2025-04-21","title":"Machine Learning Informed by Micro and Mesoscopic Statistical Physics Methods for Community Detection","abstract":"Community detection plays a crucial role in understanding the structural organization of complex networks. Previous methods, particularly those from statistical physics, primarily focus on the analysis of mesoscopic network structures and often struggle to integrate fine-grained node similarities. To address this limitation, we propose a low-complexity framework that integrates machine learning to embed micro-level node-pair similarities into mesoscopic community structures. By leveraging ensemble learning models, our approach enhances both structural coherence and detection accuracy. Experimental evaluations on artificial and real-world networks demonstrate that our framework consistently outperforms conventional methods, achieving higher modularity and improved accuracy in NMI and ARI. Notably, when ground-truth labels are available, our approach yields the most accurate detection results, effectively recovering real-world community structures while minimizing misclassifications. To further explain our framework's performance, we analyze the correlation between node-pair similarity and evaluation metrics. The results reveal a strong and statistically significant correlation, underscoring the critical role of node-pair similarity in enhancing detection accuracy. Overall, our findings highlight the synergy between machine learning and statistical physics, demonstrating how machine learning techniques can enhance network analysis and uncover complex structural patterns.","authors":["Yijun Ran","Junfan Yi","Wei Si","Michael Small","Ke-ke Shang"],"url":"https://arxiv.org/abs/2504.13538"}
{"created":"2025-04-21","title":"EG-Gaussian: Epipolar Geometry and Graph Network Enhanced 3D Gaussian Splatting","abstract":"In this paper, we explore an open research problem concerning the reconstruction of 3D scenes from images. Recent methods have adopt 3D Gaussian Splatting (3DGS) to produce 3D scenes due to its efficient training process. However, these methodologies may generate incomplete 3D scenes or blurred multiviews. This is because of (1) inaccurate 3DGS point initialization and (2) the tendency of 3DGS to flatten 3D Gaussians with the sparse-view input. To address these issues, we propose a novel framework EG-Gaussian, which utilizes epipolar geometry and graph networks for 3D scene reconstruction. Initially, we integrate epipolar geometry into the 3DGS initialization phase to enhance initial 3DGS point construction. Then, we specifically design a graph learning module to refine 3DGS spatial features, in which we incorporate both spatial coordinates and angular relationships among neighboring points. Experiments on indoor and outdoor benchmark datasets demonstrate that our approach significantly improves reconstruction accuracy compared to 3DGS-based methods.","authors":["Beizhen Zhao","Yifan Zhou","Zijian Wang","Hao Wang"],"url":"https://arxiv.org/abs/2504.13540"}
{"created":"2025-04-21","title":"SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents","abstract":"The ability to train intelligent autonomous agents (such as mobile robots) on multiple tasks is crucial for adapting to dynamic real-world environments. However, state-of-the-art reinforcement learning (RL) methods only excel in single-task settings, and still struggle to generalize across multiple tasks due to task interference. Moreover, real-world environments also demand the agents to have data stream processing capabilities. Toward this, a state-of-the-art work employs Spiking Neural Networks (SNNs) to improve multi-task learning by exploiting temporal information in data stream, while enabling lowpower/energy event-based operations. However, it relies on fixed context/task-switching intervals during its training, hence limiting the scalability and effectiveness of multi-task learning. To address these limitations, we propose SwitchMT, a novel adaptive task-switching methodology for RL-based multi-task learning in autonomous agents. Specifically, SwitchMT employs the following key ideas: (1) a Deep Spiking Q-Network with active dendrites and dueling structure, that utilizes task-specific context signals to create specialized sub-networks; and (2) an adaptive task-switching policy that leverages both rewards and internal dynamics of the network parameters. Experimental results demonstrate that SwitchMT achieves superior performance in multi-task learning compared to state-of-the-art methods. It achieves competitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6, and Enduro: 355.2) compared to the state-of-the-art, showing its better generalized learning capability. These results highlight the effectiveness of our SwitchMT methodology in addressing task interference while enabling multi-task learning automation through adaptive task switching, thereby paving the way for more efficient generalist agents with scalable multi-task learning capabilities.","authors":["Avaneesh Devkota","Rachmad Vidya Wicaksana Putra","Muhammad Shafique"],"url":"https://arxiv.org/abs/2504.13541"}
{"created":"2025-04-21","title":"Irregular Sampling of High-Dimensional Functions in Reproducing Kernel Hilbert Spaces","abstract":"We develop sampling formulas for high-dimensional functions in reproducing kernel Hilbert spaces, where we rely on irregular samples that are taken at determining sequences of data points. We place particular emphasis on sampling formulas for tensor product kernels, where we show that determining irregular samples in lower dimensions can be composed to obtain a tensor of determining irregular samples in higher dimensions. This in turn reduces the computational complexity of sampling formulas for high-dimensional functions quite significantly.","authors":["Armin Iske","Lennart Ohlsen"],"url":"https://arxiv.org/abs/2504.13543"}
{"created":"2025-04-21","title":"Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content","abstract":"Sentiment analysis is crucial for brand reputation management in the banking sector, where customer feedback spans English, Sinhala, Singlish, and code-mixed text. Existing models struggle with low-resource languages like Sinhala and lack interpretability for practical use. This research develops a hybrid aspect-based sentiment analysis framework that enhances multilingual capabilities with explainable outputs. Using cleaned banking customer reviews, we fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate domain-specific lexicon correction, and employ BERT-base-uncased for English. The system classifies sentiment (positive, neutral, negative) with confidence scores, while SHAP and LIME improve interpretability by providing real-time sentiment explanations. Experimental results show that our approaches outperform traditional transformer-based classifiers, achieving 92.3 percent accuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and code-mixed content. An explainability analysis reveals key sentiment drivers, improving trust and transparency. A user-friendly interface delivers aspect-wise sentiment insights, ensuring accessibility for businesses. This research contributes to robust, transparent sentiment analysis for financial applications by bridging gaps in multilingual, low-resource NLP and explainability.","authors":["Azmarah Rizvi","Navojith Thamindu","A. M. N. H. Adhikari","W. P. U. Senevirathna","Dharshana Kasthurirathna","Lakmini Abeywardhana"],"url":"https://arxiv.org/abs/2504.13545"}
{"created":"2025-04-21","title":"Version-level Third-Party Library Detection in Android Applications via Class Structural Similarity","abstract":"Android applications (apps) integrate reusable and well-tested third-party libraries (TPLs) to enhance functionality and shorten development cycles. However, recent research reveals that TPLs have become the largest attack surface for Android apps, where the use of insecure TPLs can compromise both developer and user interests. To mitigate such threats, researchers have proposed various tools to detect TPLs used by apps, supporting further security analyses such as vulnerable TPLs identification. Although existing tools achieve notable library-level TPL detection performance in the presence of obfuscation, they struggle with version-level TPL detection due to a lack of sensitivity to differences between versions. This limitation results in a high version-level false positive rate, significantly increasing the manual workload for security analysts. To resolve this issue, we propose SAD, a TPL detection tool with high version-level detection performance. SAD generates a candidate app class list for each TPL class based on the feature of nodes in class dependency graphs (CDGs). It then identifies the unique corresponding app class for each TPL class by performing class matching based on the similarity of their class summaries. Finally, SAD identifies TPL versions by evaluating the structural similarity of the sub-graph formed by matched classes within the CDGs of the TPL and the app. Extensive evaluation on three datasets demonstrates the effectiveness of SAD and its components. SAD achieves F1 scores of 97.64% and 84.82% for library-level and version-level detection on obfuscated apps, respectively, surpassing existing state-of-the-art tools. The version-level false positives reported by the best tool is 1.61 times that of SAD. We further evaluate the degree to which TPLs identified by detection tools correspond to actual TPL classes.","authors":["Bolin Zhou","Jingzheng Wu","Xiang Ling","Tianyue Luo","Jingkun Zhang"],"url":"https://arxiv.org/abs/2504.13547"}
{"created":"2025-04-21","title":"Beyond One-Hot Labels: Semantic Mixing for Model Calibration","abstract":"Model calibration seeks to ensure that models produce confidence scores that accurately reflect the true likelihood of their predictions being correct. However, existing calibration approaches are fundamentally tied to datasets of one-hot labels implicitly assuming full certainty in all the annotations. Such datasets are effective for classification but provides insufficient knowledge of uncertainty for model calibration, necessitating the curation of datasets with numerically rich ground-truth confidence values. However, due to the scarcity of uncertain visual examples, such samples are not easily available as real datasets. In this paper, we introduce calibration-aware data augmentation to create synthetic datasets of diverse samples and their ground-truth uncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM), a novel framework that generates training samples with mixed class characteristics and annotates them with distinct confidence scores via diffusion models. Based on this framework, we propose calibrated reannotation to tackle the misalignment between the annotated confidence score and the mixing ratio during the diffusion reverse process. Besides, we explore the loss functions that better fit the new data representation paradigm. Experimental results demonstrate that CSM achieves superior calibration compared to the state-of-the-art calibration approaches. Code is available at github.com/E-Galois/CSM.","authors":["Haoyang Luo","Linwei Tao","Minjing Dong","Chang Xu"],"url":"https://arxiv.org/abs/2504.13548"}
{"created":"2025-04-21","title":"Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation","abstract":"Many adversarial attack approaches are proposed to verify the vulnerability of language models. However, they require numerous queries and the information on the target model. Even black-box attack methods also require the target model's output information. They are not applicable in real-world scenarios, as in hard black-box settings where the target model is closed and inaccessible. Even the recently proposed hard black-box attacks still require many queries and demand extremely high costs for training adversarial generators. To address these challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a novel and efficient method that generates adversarial examples without accessing the target model. To avoid accessing the target model, we use a surrogate model instead. The surrogate model generates adversarial sentences for a target-agnostic attack. During this process, we leverage controlled generation techniques. We evaluate our proposed method on eight datasets. Experimental results demonstrate our method's effectiveness including high transferability and the high quality of the generated adversarial examples, and prove its practical in hard black-box settings.","authors":["CheolWon Na","YunSeok Choi","Jee-Hyong Lee"],"url":"https://arxiv.org/abs/2504.13551"}
{"created":"2025-04-21","title":"Adaptive time-stepping and maximum-principle preserving Lagrangian schemes for gradient flows","abstract":"We develop in this paper an adaptive time-stepping approach for gradient flows with distinct treatments for conservative and non-conservative dynamics. For the non-conservative gradient flows in Lagrangian coordinates, we propose a modified formulation augmented by auxiliary terms to guarantee positivity of the determinant, and prove that the corresponding adaptive second-order Backward Difference Formulas (BDF2) scheme preserves energy stability and the maximum principle under the time-step ratio constraint $0<r_n\\le r_{\\max}\\le \\frac{5}{4}$ in 2D, respectively. We also present ample numerical simulations in 1D and 2D to validate the efficiency and accuracy of the proposed schemes.","authors":["Qianqian Liu","Wenbin Chen","Jie Shen","Qing Cheng"],"url":"https://arxiv.org/abs/2504.13552"}
{"created":"2025-04-21","title":"Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning","abstract":"Artificial Intelligence (AI)-driven convolutional neural networks enhance rescue, inspection, and surveillance tasks performed by low-altitude uncrewed aerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown environments. However, their high computational demands often exceed a single UAV's capacity, leading to system instability, further exacerbated by the limited and dynamic resources of GCNs. To address these challenges, this paper proposes a novel cooperation framework involving UAVs, ground-embedded robots (GERs), and high-altitude platforms (HAPs), which enable resource pooling through UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide computing services for UAV offloaded tasks. Specifically, we formulate the multi-objective optimization problem of task assignment and exploration optimization in UAVs as a dynamic long-term optimization problem. Our objective is to minimize task completion time and energy consumption while ensuring system stability over time. To achieve this, we first employ the Lyapunov optimization technique to transform the original problem, with stability constraints, into a per-slot deterministic problem. We then propose an algorithm named HG-MADDPG, which combines the Hungarian algorithm with a generative diffusion model (GDM)-based multi-agent deep deterministic policy gradient (MADDPG) approach. We first introduce the Hungarian algorithm as a method for exploration area selection, enhancing UAV efficiency in interacting with the environment. We then innovatively integrate the GDM and multi-agent deep deterministic policy gradient (MADDPG) to optimize task assignment decisions, such as task offloading and resource allocation. Simulation results demonstrate the effectiveness of the proposed approach, with significant improvements in task offloading efficiency, latency reduction, and system stability compared to baseline methods.","authors":["Xin Tang","Qian Chen","Wenjie Weng","Chao Jin","Zhang Liu","Jiacheng Wang","Geng Sun","Xiaohuan Li","Dusit Niyato"],"url":"https://arxiv.org/abs/2504.13554"}
{"created":"2025-04-21","title":"Integrating LLMs for Grading and Appeal Resolution in Computer Science Education","abstract":"This study explores the integration of Large Language Models (LLMs) into the grading and appeal resolution process in computer science education. We introduce AI-PAT, an AI-powered assessment tool that leverages LLMs to evaluate computer science exams, generate feedback, and address student appeals. AI-PAT was used to assess over 850 exam submissions and handle 185 appeal cases. Our multi-model comparison (ChatGPT, Gemini) reveals strong correlations between model outputs, though significant variability persists depending on configuration and prompt design. Human graders, while internally consistent, showed notable inter-rater disagreement, further highlighting subjectivity in manual evaluation. The appeal process led to grade changes in 74% of cases, indicating the need for continued refinement of AI evaluation strategies. While students appreciated the speed and detail of AI feedback, survey responses revealed trust and fairness concerns. We conclude that AI-PAT offers scalable benefits for formative assessment and feedback, but must be accompanied by transparent grading rubrics, human oversight, and appeal mechanisms to ensure equitable outcomes.","authors":["I. Aytutuldu (Gebze Technical University)","O. Yol (SSTTEK Academy)","Y. S. Akgul (Gebze Technical University)"],"url":"https://arxiv.org/abs/2504.13557"}
{"created":"2025-04-21","title":"Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective","abstract":"The Transformer model is widely used in various application areas of machine learning, such as natural language processing. This paper investigates the approximation of the H\\\"older continuous function class $\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$ by Transformers and constructs several Transformers that can overcome the curse of dimensionality. These Transformers consist of one self-attention layer with one head and the softmax function as the activation function, along with several feedforward layers. For example, to achieve an approximation accuracy of $\\epsilon$, if the activation functions of the feedforward layers in the Transformer are ReLU and floor, only $\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers are needed, with widths of these layers not exceeding $\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$. If other activation functions are allowed in the feedforward layers, the width of the feedforward layers can be further reduced to a constant. These results demonstrate that Transformers have a strong expressive capability. The construction in this paper is based on the Kolmogorov-Arnold Representation Theorem and does not require the concept of contextual mapping, hence our proof is more intuitively clear compared to previous Transformer approximation works. Additionally, the translation technique proposed in this paper helps to apply the previous approximation results of feedforward neural networks to Transformer research.","authors":["Yuling Jiao","Yanming Lai","Yang Wang","Bokai Yan"],"url":"https://arxiv.org/abs/2504.13558"}
{"created":"2025-04-21","title":"Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation","abstract":"Anomaly segmentation is essential for industrial quality, maintenance, and stability. Existing text-guided zero-shot anomaly segmentation models are effective but rely on fixed prompts, limiting adaptability in diverse industrial scenarios. This highlights the need for flexible, context-aware prompting strategies. We propose Image-Aware Prompt Anomaly Segmentation (IAP-AS), which enhances anomaly segmentation by generating dynamic, context-aware prompts using an image tagging model and a large language model (LLM). IAP-AS extracts object attributes from images to generate context-aware prompts, improving adaptability and generalization in dynamic and unstructured industrial environments. In our experiments, IAP-AS improves the F1-max metric by up to 10%, demonstrating superior adaptability and generalization. It provides a scalable solution for anomaly segmentation across industries","authors":["SoYoung Park","Hyewon Lee","Mingyu Choi","Seunghoon Han","Jong-Ryul Lee","Sungsu Lim","Tae-Ho Kim"],"url":"https://arxiv.org/abs/2504.13560"}
{"created":"2025-04-21","title":"WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion","abstract":"3D scene perception demands a large amount of adverse-weather LiDAR data, yet the cost of LiDAR data collection presents a significant scaling-up challenge. To this end, a series of LiDAR simulators have been proposed. Yet, they can only simulate a single adverse weather with a single physical model, and the fidelity of the generated data is quite limited. This paper presents WeatherGen, the first unified diverse-weather LiDAR data diffusion generation framework, significantly improving fidelity. Specifically, we first design a map-based data producer, which can provide a vast amount of high-quality diverse-weather data for training purposes. Then, we utilize the diffusion-denoising paradigm to construct a diffusion model. Among them, we propose a spider mamba generator to restore the disturbed diverse weather data gradually. The spider mamba models the feature interactions by scanning the LiDAR beam circle or central ray, excellently maintaining the physical structure of the LiDAR data. Subsequently, following the generator to transfer real-world knowledge, we design a latent feature aligner. Afterward, we devise a contrastive learning-based controller, which equips weather control signals with compact semantic knowledge through language supervision, guiding the diffusion model to generate more discriminative data. Extensive evaluations demonstrate the high generation quality of WeatherGen. Through WeatherGen, we construct the mini-weather dataset, promoting the performance of the downstream task under adverse weather conditions. Code is available: https://github.com/wuyang98/weathergen","authors":["Yang Wu","Yun Zhu","Kaihua Zhang","Jianjun Qian","Jin Xie","Jian Yang"],"url":"https://arxiv.org/abs/2504.13561"}
{"created":"2025-04-21","title":"DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification","abstract":"With the widespread adoption of Large Language Models (LLMs), jailbreak attacks have become an increasingly pressing safety concern. While safety-aligned LLMs can effectively defend against normal harmful queries, they remain vulnerable to such attacks. Existing defense methods primarily rely on fine-tuning or input modification, which often suffer from limited generalization and reduced utility. To address this, we introduce DETAM, a finetuning-free defense approach that improves the defensive capabilities against jailbreak attacks of LLMs via targeted attention modification. Specifically, we analyze the differences in attention scores between successful and unsuccessful defenses to identify the attention heads sensitive to jailbreak attacks. During inference, we reallocate attention to emphasize the user's core intention, minimizing interference from attack tokens. Our experimental results demonstrate that DETAM outperforms various baselines in jailbreak defense and exhibits robust generalization across different attacks and models, maintaining its effectiveness even on in-the-wild jailbreak data. Furthermore, in evaluating the model's utility, we incorporated over-defense datasets, which further validate the superior performance of our approach. The code will be released immediately upon acceptance.","authors":["Yu Li","Han Jiang","Zhihua Wei"],"url":"https://arxiv.org/abs/2504.13562"}
{"created":"2025-04-21","title":"PoEmotion: Can AI Utilize Chinese Calligraphy to Express Emotion from Poems?","abstract":"This paper presents PoEmotion, an approach to visualizing emotions in poetry with Chinese calligraphy strokes. Traditional textual emotion analysis often lacks emotional resonance due to its mechanical nature. PoEmotion combines natural language processing with deep learning generative algorithms to create Chinese calligraphy that effectively conveys the emotions in poetry. The created calligraphy represents four fundamental emotions: excitement, anger, sadness, and relaxation, making the visual representation of emotions intuitive and concise. Furthermore, the approach delves into the relationship be-tween time, emotion, and cultural communication. Its goal is to provide a more natural means of communicating emotions through non-verbal mediums to enhance human emotional expression.","authors":["Tiancheng Liu","Anqi Wang","Xinda Chen","Jing Yan","Yin Li","Pan Hui","Kang Zhang"],"url":"https://arxiv.org/abs/2504.13567"}
{"created":"2025-04-21","title":"MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration","abstract":"Cross-workload design space exploration (DSE) is crucial in CPU architecture design. Existing DSE methods typically employ the transfer learning technique to leverage knowledge from source workloads, aiming to minimize the requirement of target workload simulation. However, these methods struggle with overfitting, data ambiguity, and workload dissimilarity.","authors":["Runzhen Xue","Hao Wu","Mingyu Yan","Ziheng Xiao","Xiaochun Ye","Dongrui Fan"],"url":"https://arxiv.org/abs/2504.13568"}
{"created":"2025-04-21","title":"Bayesian continual learning and forgetting in neural networks","abstract":"Biological synapses effortlessly balance memory retention and flexibility, yet artificial neural networks still struggle with the extremes of catastrophic forgetting and catastrophic remembering. Here, we introduce Metaplasticity from Synaptic Uncertainty (MESU), a Bayesian framework that updates network parameters according their uncertainty. This approach allows a principled combination of learning and forgetting that ensures that critical knowledge is preserved while unused or outdated information is gradually released. Unlike standard Bayesian approaches -- which risk becoming overly constrained, and popular continual-learning methods that rely on explicit task boundaries, MESU seamlessly adapts to streaming data. It further provides reliable epistemic uncertainty estimates, allowing out-of-distribution detection, the only computational cost being to sample the weights multiple times to provide proper output statistics. Experiments on image-classification benchmarks demonstrate that MESU mitigates catastrophic forgetting, while maintaining plasticity for new tasks. When training 200 sequential permuted MNIST tasks, MESU outperforms established continual learning techniques in terms of accuracy, capability to learn additional tasks, and out-of-distribution data detection. Additionally, due to its non-reliance on task boundaries, MESU outperforms conventional learning techniques on the incremental training of CIFAR-100 tasks consistently in a wide range of scenarios. Our results unify ideas from metaplasticity, Bayesian inference, and Hessian-based regularization, offering a biologically-inspired pathway to robust, perpetual learning.","authors":["Djohan Bonnet","Kellian Cottart","Tifenn Hirtzlin","Tarcisius Januel","Thomas Dalgaty","Elisa Vianello","Damien Querlioz"],"url":"https://arxiv.org/abs/2504.13569"}
{"created":"2025-04-21","title":"Contextualizing Spotify's Audiobook List Recommendations with Descriptive Shelves","abstract":"In this paper, we propose a pipeline to generate contextualized list recommendations with descriptive shelves in the domain of audiobooks. By creating several shelves for topics the user has an affinity to, e.g. Uplifting Women's Fiction, we can help them explore their recommendations according to their interests and at the same time recommend a diverse set of items. To do so, we use Large Language Models (LLMs) to enrich each item's metadata based on a taxonomy created for this domain. Then we create diverse descriptive shelves for each user. A/B tests show improvements in user engagement and audiobook discovery metrics, demonstrating benefits for users and content creators.","authors":["Gustavo Penha","Alice Wang","Martin Achenbach","Kristen Sheets","Sahitya Mantravadi","Remi Galvez","Nico Guetta-Jeanrenaud","Divya Narayanan","Ofeliya Kalaydzhyan","Hugues Bouchard"],"url":"https://arxiv.org/abs/2504.13572"}
{"created":"2025-04-21","title":"Cybersquatting in Web3: The Case of NFT","abstract":"Cybersquatting refers to the practice where attackers register a domain name similar to a legitimate one to confuse users for illegal gains. With the growth of the Non-Fungible Token (NFT) ecosystem, there are indications that cybersquatting tactics have evolved from targeting domain names to NFTs. This paper presents the first in-depth measurement study of NFT cybersquatting. By analyzing over 220K NFT collections with over 150M NFT tokens, we have identified 8,019 cybersquatting NFT collections targeting 654 popular NFT projects. Through systematic analysis, we discover and characterize seven distinct squatting tactics employed by scammers. We further conduct a comprehensive measurement study of these cybersquatting NFT collections, examining their metadata, associated digital asset content, and social media status. Our analysis reveals that these NFT cybersquatting activities have resulted in a significant financial impact, with over 670K victims affected by these scams, leading to a total financial exploitation of $59.26 million. Our findings demonstrate the urgency to identify and prevent NFT squatting abuses.","authors":["Kai Ma","Ningyu He","Jintao Huang","Bosi Zhang","Ping Wu","Haoyu Wang"],"url":"https://arxiv.org/abs/2504.13573"}
{"created":"2025-04-21","title":"MAAM: A Lightweight Multi-Agent Aggregation Module for Efficient Image Classification Based on the MindSpore Framework","abstract":"The demand for lightweight models in image classification tasks under resource-constrained environments necessitates a balance between computational efficiency and robust feature representation. Traditional attention mechanisms, despite their strong feature modeling capability, often struggle with high computational complexity and structural rigidity, limiting their applicability in scenarios with limited computational resources (e.g., edge devices or real-time systems). To address this, we propose the Multi-Agent Aggregation Module (MAAM), a lightweight attention architecture integrated with the MindSpore framework. MAAM employs three parallel agent branches with independently parameterized operations to extract heterogeneous features, adaptively fused via learnable scalar weights, and refined through a convolutional compression layer. Leveraging MindSpore's dynamic computational graph and operator fusion, MAAM achieves 87.0% accuracy on the CIFAR-10 dataset, significantly outperforming conventional CNN (58.3%) and MLP (49.6%) models, while improving training efficiency by 30%. Ablation studies confirm the critical role of agent attention (accuracy drops to 32.0% if removed) and compression modules (25.5% if omitted), validating their necessity for maintaining discriminative feature learning. The framework's hardware acceleration capabilities and minimal memory footprint further demonstrate its practicality, offering a deployable solution for image classification in resource-constrained scenarios without compromising accuracy.","authors":["Zhenkai Qin","Feng Zhu","Huan Zeng","Xunyi Nong"],"url":"https://arxiv.org/abs/2504.13574"}
{"created":"2025-04-21","title":"MSTIM: A MindSpore-Based Model for Traffic Flow Prediction","abstract":"Aiming at the problems of low accuracy and large error fluctuation of traditional traffic flow predictionmodels when dealing with multi-scale temporal features and dynamic change patterns. this paperproposes a multi-scale time series information modelling model MSTIM based on the Mindspore framework, which integrates long and short-term memory networks (LSTMs), convolutional neural networks (CNN), and the attention mechanism to improve the modelling accuracy and stability. The Metropolitan Interstate Traffic Volume (MITV) dataset was used for the experiments and compared and analysed with typical LSTM-attention models, CNN-attention models and LSTM-CNN models. The experimental results show that the MSTIM model achieves better results in the metrics of Mean Absolute Error (MAE), Mean Square Error (MSE), and Root Mean Square Error (RMSE), which significantly improves the accuracy and stability of the traffic volume prediction.","authors":["Weiqi Qin","Yuxin Liu","Dongze Wu","Zhenkai Qin","Qining Luo"],"url":"https://arxiv.org/abs/2504.13576"}
{"created":"2025-04-21","title":"HDBFormer: Efficient RGB-D Semantic Segmentation with A Heterogeneous Dual-Branch Framework","abstract":"In RGB-D semantic segmentation for indoor scenes, a key challenge is effectively integrating the rich color information from RGB images with the spatial distance information from depth images. However, most existing methods overlook the inherent differences in how RGB and depth images express information. Properly distinguishing the processing of RGB and depth images is essential to fully exploiting their unique and significant characteristics. To address this, we propose a novel heterogeneous dual-branch framework called HDBFormer, specifically designed to handle these modality differences. For RGB images, which contain rich detail, we employ both a basic and detail encoder to extract local and global features. For the simpler depth images, we propose LDFormer, a lightweight hierarchical encoder that efficiently extracts depth features with fewer parameters. Additionally, we introduce the Modality Information Interaction Module (MIIM), which combines transformers with large kernel convolutions to interact global and local information across modalities efficiently. Extensive experiments show that HDBFormer achieves state-of-the-art performance on the NYUDepthv2 and SUN-RGBD datasets. The code is available at: https://github.com/Weishuobin/HDBFormer.","authors":["Shuobin Wei","Zhuang Zhou","Zhengan Lu","Zizhao Yuan","Binghua Su"],"url":"https://arxiv.org/abs/2504.13579"}
{"created":"2025-04-21","title":"Leveraging Automatic CAD Annotations for Supervised Learning in 3D Scene Understanding","abstract":"High-level 3D scene understanding is essential in many applications. However, the challenges of generating accurate 3D annotations make development of deep learning models difficult. We turn to recent advancements in automatic retrieval of synthetic CAD models, and show that data generated by such methods can be used as high-quality ground truth for training supervised deep learning models. More exactly, we employ a pipeline akin to the one previously used to automatically annotate objects in ScanNet scenes with their 9D poses and CAD models. This time, we apply it to the recent ScanNet++ v1 dataset, which previously lacked such annotations. Our findings demonstrate that it is not only possible to train deep learning models on these automatically-obtained annotations but that the resulting models outperform those trained on manually annotated data. We validate this on two distinct tasks: point cloud completion and single-view CAD model retrieval and alignment. Our results underscore the potential of automatic 3D annotations to enhance model performance while significantly reducing annotation costs. To support future research in 3D scene understanding, we will release our annotations, which we call SCANnotate++, along with our trained models.","authors":["Yuchen Rao","Stefan Ainetter","Sinisa Stekovic","Vincent Lepetit","Friedrich Fraundorfer"],"url":"https://arxiv.org/abs/2504.13580"}
{"created":"2025-04-21","title":"Hysteresis-Aware Neural Network Modeling and Whole-Body Reinforcement Learning Control of Soft Robots","abstract":"Soft robots exhibit inherent compliance and safety, which makes them particularly suitable for applications requiring direct physical interaction with humans, such as surgical procedures. However, their nonlinear and hysteretic behavior, resulting from the properties of soft materials, presents substantial challenges for accurate modeling and control. In this study, we present a soft robotic system designed for surgical applications and propose a hysteresis-aware whole-body neural network model that accurately captures and predicts the soft robot's whole-body motion, including its hysteretic behavior. Building upon the high-precision dynamic model, we construct a highly parallel simulation environment for soft robot control and apply an on-policy reinforcement learning algorithm to efficiently train whole-body motion control strategies. Based on the trained control policy, we developed a soft robotic system for surgical applications and validated it through phantom-based laser ablation experiments in a physical environment. The results demonstrate that the hysteresis-aware modeling reduces the Mean Squared Error (MSE) by 84.95 percent compared to traditional modeling methods. The deployed control algorithm achieved a trajectory tracking error ranging from 0.126 to 0.250 mm on the real soft robot, highlighting its precision in real-world conditions. The proposed method showed strong performance in phantom-based surgical experiments and demonstrates its potential for complex scenarios, including future real-world clinical applications.","authors":["Zongyuan Chen","Yan Xia","Jiayuan Liu","Jijia Liu","Wenhao Tang","Jiayu Chen","Feng Gao","Longfei Ma","Hongen Liao","Yu Wang","Chao Yu","Boyu Zhang","Fei Xing"],"url":"https://arxiv.org/abs/2504.13582"}
{"created":"2025-04-21","title":"Effective Computation of Generalized Abelian Complexity for Pisot Type Substitutive Sequences","abstract":"Generalized abelian equivalence compares words by their factors up to a certain bounded length. The associated complexity function counts the equivalence classes for factors of a given size of an infinite sequence. How practical is this notion? When can these equivalence relations and complexity functions be computed efficiently? We study the fixed points of substitution of Pisot type. Each of their $k$-abelian complexities is bounded and the Parikh vectors of their length-$n$ prefixes form synchronized sequences in the associated Dumont--Thomas numeration system. Therefore, the $k$-abelian complexity of Pisot substitution fixed points is automatic in the same numeration system. Two effective generic construction approaches are investigated using the \\texttt{Walnut} theorem prover and are applied to several examples. We obtain new properties of the Tribonacci sequence, such as a uniform bound for its factor balancedness together with a two-dimensional linear representation of its generalized abelian complexity functions.","authors":["Jean-Michel Couvreur","Martin Delacourt","Nicolas Ollinger","Pierre Popoli","Jeffrey Shallit","Manon Stipulanti"],"url":"https://arxiv.org/abs/2504.13584"}
{"created":"2025-04-21","title":"How to Achieve Higher Accuracy with Less Training Points?","abstract":"In the era of large-scale model training, the extensive use of available datasets has resulted in significant computational inefficiencies. To tackle this issue, we explore methods for identifying informative subsets of training data that can achieve comparable or even superior model performance. We propose a technique based on influence functions to determine which training samples should be included in the training set. We conducted empirical evaluations of our method on binary classification tasks utilizing logistic regression models. Our approach demonstrates performance comparable to that of training on the entire dataset while using only 10% of the data. Furthermore, we found that our method achieved even higher accuracy when trained with just 60% of the data.","authors":["Jinghan Yang","Anupam Pani","Yunchao Zhang"],"url":"https://arxiv.org/abs/2504.13586"}
{"created":"2025-04-21","title":"RAG Without the Lag: Interactive Debugging for Retrieval-Augmented Generation Pipelines","abstract":"Retrieval-augmented generation (RAG) pipelines have become the de-facto approach for building AI assistants with access to external, domain-specific knowledge. Given a user query, RAG pipelines typically first retrieve (R) relevant information from external sources, before invoking a Large Language Model (LLM), augmented (A) with this information, to generate (G) responses. Modern RAG pipelines frequently chain multiple retrieval and generation components, in any order. However, developing effective RAG pipelines is challenging because retrieval and generation components are intertwined, making it hard to identify which component(s) cause errors in the eventual output. The parameters with the greatest impact on output quality often require hours of pre-processing after each change, creating prohibitively slow feedback cycles. To address these challenges, we present RAGGY, a developer tool that combines a Python library of composable RAG primitives with an interactive interface for real-time debugging. We contribute the design and implementation of RAGGY, insights into expert debugging patterns through a qualitative study with 12 engineers, and design implications for future RAG tools that better align with developers' natural workflows.","authors":["Quentin Romero Lauro","Shreya Shankar","Sepanta Zeighami","Aditya Parameswaran"],"url":"https://arxiv.org/abs/2504.13587"}
{"created":"2025-04-21","title":"Towards End-to-End Network Intent Management with Large Language Models","abstract":"Large Language Models (LLMs) are likely to play a key role in Intent-Based Networking (IBN) as they show remarkable performance in interpreting human language as well as code generation, enabling the translation of high-level intents expressed by humans into low-level network configurations. In this paper, we leverage closed-source language models (i.e., Google Gemini 1.5 pro, ChatGPT-4) and open-source models (i.e., LLama, Mistral) to investigate their capacity to generate E2E network configurations for radio access networks (RANs) and core networks in 5G/6G mobile networks. We introduce a novel performance metrics, known as FEACI, to quantitatively assess the format (F), explainability (E), accuracy (A), cost (C), and inference time (I) of the generated answer; existing general metrics are unable to capture these features. The results of our study demonstrate that open-source models can achieve comparable or even superior translation performance compared with the closed-source models requiring costly hardware setup and not accessible to all users.","authors":["Lam Dinh","Sihem Cherrared","Xiaofeng Huang","Fabrice Guillemin"],"url":"https://arxiv.org/abs/2504.13589"}
{"created":"2025-04-21","title":"HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering","abstract":"Traditional 3D scene understanding techniques are generally predicated on hand-annotated label sets, but in recent years a new class of open-vocabulary 3D scene understanding techniques has emerged. Despite the success of this paradigm on small scenes, existing approaches cannot scale efficiently to city-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic Expert Clustering (HAEC), after the latin word for 'these', a superpoint graph clustering based approach which utilizes a novel mixture of experts graph transformer for its backbone. We administer this highly scalable approach to the first application of open-vocabulary scene understanding on the SensatUrban city-scale dataset. We also demonstrate a synthetic labeling pipeline which is derived entirely from the raw point clouds with no hand-annotation. Our technique can help unlock complex operations on dense urban 3D scenes and open a new path forward in the processing of digital twins.","authors":["Alexander Rusnak","Fr\\'ed\\'eric Kaplan"],"url":"https://arxiv.org/abs/2504.13590"}
{"created":"2025-04-21","title":"Improving Generalization in Intent Detection: GRPO with Reward-Based Curriculum Sampling","abstract":"Intent detection, a critical component in task-oriented dialogue (TOD) systems, faces significant challenges in adapting to the rapid influx of integrable tools with complex interrelationships. Existing approaches, such as zero-shot reformulations and LLM-based dynamic recognition, struggle with performance degradation when encountering unseen intents, leading to erroneous task routing. To enhance the model's generalization performance on unseen tasks, we employ Reinforcement Learning (RL) combined with a Reward-based Curriculum Sampling (RCS) during Group Relative Policy Optimization (GRPO) training in intent detection tasks. Experiments demonstrate that RL-trained models substantially outperform supervised fine-tuning (SFT) baselines in generalization. Besides, the introduction of the RCS, significantly bolsters the effectiveness of RL in intent detection by focusing the model on challenging cases during training. Moreover, incorporating Chain-of-Thought (COT) processes in RL notably improves generalization in complex intent detection tasks, underscoring the importance of thought in challenging scenarios. This work advances the generalization of intent detection tasks, offering practical insights for deploying adaptable dialogue systems.","authors":["Zihao Feng","Xiaoxue Wang","Ziwei Bai","Donghang Su","Bowen Wu","Qun Yu","Baoxun Wang"],"url":"https://arxiv.org/abs/2504.13592"}
{"created":"2025-04-21","title":"KAN or MLP? Point Cloud Shows the Way Forward","abstract":"Multi-Layer Perceptrons (MLPs) have become one of the fundamental architectural component in point cloud analysis due to its effective feature learning mechanism. However, when processing complex geometric structures in point clouds, MLPs' fixed activation functions struggle to efficiently capture local geometric features, while suffering from poor parameter efficiency and high model redundancy. In this paper, we propose PointKAN, which applies Kolmogorov-Arnold Networks (KANs) to point cloud analysis tasks to investigate their efficacy in hierarchical feature representation. First, we introduce a Geometric Affine Module (GAM) to transform local features, improving the model's robustness to geometric variations. Next, in the Local Feature Processing (LFP), a parallel structure extracts both group-level features and global context, providing a rich representation of both fine details and overall structure. Finally, these features are combined and processed in the Global Feature Processing (GFP). By repeating these operations, the receptive field gradually expands, enabling the model to capture complete geometric information of the point cloud. To overcome the high parameter counts and computational inefficiency of standard KANs, we develop Efficient-KANs in the PointKAN-elite variant, which significantly reduces parameters while maintaining accuracy. Experimental results demonstrate that PointKAN outperforms PointMLP on benchmark datasets such as ModelNet40, ScanObjectNN, and ShapeNetPart, with particularly strong performance in Few-shot Learning task. Additionally, PointKAN achieves substantial reductions in parameter counts and computational complexity (FLOPs). This work highlights the potential of KANs-based architectures in 3D vision and opens new avenues for research in point cloud understanding.","authors":["Yan Shi","Qingdong He","Yijun Liu","Xiaoyu Liu","Jingyong Su"],"url":"https://arxiv.org/abs/2504.13593"}
{"created":"2025-04-21","title":"Joint Optimization of Controller Placement and Switch Assignment in SDN-based LEO Satellite Networks","abstract":"Software-defined networking (SDN) based low earth orbit (LEO) satellite networks leverage the SDN's benefits of the separation of data plane and control plane, control plane programmability, and centralized control to alleviate the problem of inefficient resource management under traditional network architectures. The most fundamental issue in SDN-based LEO satellite networks is how to place controllers and assign switches. Their outcome directly affects the performance of the network. However, most existing strategies can not sensibly and dynamically adjust the controller location and controller-switch mapping according to the topology variation and traffic undulation of the LEO satellite network meanwhile. In this paper, based on the dynamic placement dynamic assignment scheme, we first formulate the controller placement and switch assignment (CPSA) problem in the LEO satellite networks, which is an integer nonlinear programming problem. Then, a prior population-based genetic algorithm is proposed to solve it. Some individuals of the final generation of the algorithm for the current time slot are used as the prior population of the next time slot, thus stringing together the algorithms of adjacent time slots for successive optimization. Finally, we obtain the near-optimal solution for each time slot. Extensive experiments demonstrate that our algorithm can adapt to the network topology changes and traffic surges, and outperform some existing CPSA strategies in the LEO satellite networks.","authors":["Zhiyun Jiang","Wei Li","Menglong Yang"],"url":"https://arxiv.org/abs/2504.13594"}
{"created":"2025-04-21","title":"LMPOcc: 3D Semantic Occupancy Prediction Utilizing Long-Term Memory Prior from Historical Traversals","abstract":"Vision-based 3D semantic occupancy prediction is critical for autonomous driving, enabling unified modeling of static infrastructure and dynamic agents. In practice, autonomous vehicles may repeatedly traverse identical geographic locations under varying environmental conditions, such as weather fluctuations and illumination changes. Existing methods in 3D occupancy prediction predominantly integrate adjacent temporal contexts. However, these works neglect to leverage perceptual information, which is acquired from historical traversals of identical geographic locations. In this paper, we propose Longterm Memory Prior Occupancy (LMPOcc), the first 3D occupancy prediction methodology that exploits long-term memory priors derived from historical traversal perceptual outputs. We introduce a plug-and-play architecture that integrates long-term memory priors to enhance local perception while simultaneously constructing global occupancy representations. To adaptively aggregate prior features and current features, we develop an efficient lightweight Current-Prior Fusion module. Moreover, we propose a model-agnostic prior format to ensure compatibility across diverse occupancy prediction baselines. LMPOcc achieves state-of-the-art performance validated on the Occ3D-nuScenes benchmark, especially on static semantic categories. Additionally, experimental results demonstrate LMPOcc's ability to construct global occupancy through multi-vehicle crowdsourcing.","authors":["Shanshuai Yuan","Julong Wei","Muer Tie","Xiangyun Ren","Zhongxue Gan","Wenchao Ding"],"url":"https://arxiv.org/abs/2504.13596"}
{"created":"2025-04-21","title":"Bitcoin's Edge: Embedded Sentiment in Blockchain Transactional Data","abstract":"Cryptocurrency blockchains, beyond their primary role as distributed payment systems, are increasingly used to store and share arbitrary content, such as text messages and files. Although often non-financial, this hidden content can impact price movements by conveying private information, shaping sentiment, and influencing public opinion. However, current analyses of such data are limited in scope and scalability, primarily relying on manual classification or hand-crafted heuristics. In this work, we address these limitations by employing Natural Language Processing techniques to analyze, detect patterns, and extract public sentiment encoded within blockchain transactional data. Using a variety of Machine Learning techniques, we showcase for the first time the predictive power of blockchain-embedded sentiment in forecasting cryptocurrency price movements on the Bitcoin and Ethereum blockchains. Our findings shed light on a previously underexplored source of freely available, transparent, and immutable data and introduce blockchain sentiment analysis as a novel and robust framework for enhancing financial predictions in cryptocurrency markets. Incidentally, we discover an asymmetry between cryptocurrencies; Bitcoin has an informational advantage over Ethereum in that the sentiment embedded into transactional data is sufficient to predict its price movement.","authors":["Charalampos Kleitsikas","Nikolaos Korfiatis","Stefanos Leonardos","Carmine Ventre"],"url":"https://arxiv.org/abs/2504.13598"}
{"created":"2025-04-21","title":"Memristive chaotic circuit for information processing through time","abstract":"Human brain processes sensory information in real-time with extraordinary efficiency compared to the possibilities of current artificial computing systems. It operates as a complex nonlinear system, composed of interacting dynamic units - neurons and synapses - that processes data-streams as time goes by, i.e. through time, using time as an internal self-standing variable. Here we report on a memristor-based compact chaotic circuit included in a computing architecture that can process information through time. We realized a hardware memristive version of the formally simplest chaotic circuit that, thanks to the nonlinearity of the nonvolatile memristor device, evolves with complex dynamics in response to a driving signal. The circuit is used in a single-node reservoir computing scheme to demonstrate nonlinear classification tasks and the processing of data streams through time. These results demonstrate that a simple memristor-based chaotic circuit has the potential to operate as a nonlinear dynamics-based computing system and to process temporal information through time.","authors":["Manuel Escudero","Sabina Spiga","Stefano Brivio"],"url":"https://arxiv.org/abs/2504.13600"}
{"created":"2025-04-21","title":"Capacity-achieving sparse superposition codes with spatially coupled VAMP decoder","abstract":"Sparse superposition (SS) codes provide an efficient communication scheme over the Gaussian channel, utilizing the vector approximate message passing (VAMP) decoder for rotational invariant design matrices. Previous work has established that the VAMP decoder for SS achieves Shannon capacity when the design matrix satisfies a specific spectral criterion and exponential decay power allocation is used. In this work, we propose a spatially coupled VAMP (SC-VAMP) decoder for SS with spatially coupled design matrices. Based on state evolution (SE) analysis, we demonstrate that the SC-VAMP decoder is capacity-achieving when the design matrices satisfy the spectra criterion. Empirically, we show that the SC-VAMP decoder outperforms the VAMP decoder with exponential decay power allocation, achieving a lower section error rate. All codes are available on https://github.com/yztfu/SC-VAMP-for-Superposition-Code.git.","authors":["Yuhao Liu","Teng Fu","Jie Fan","Panpan Niu","Chaowen Deng","Zhongyi Huang"],"url":"https://arxiv.org/abs/2504.13601"}
{"created":"2025-04-21","title":"Continual Pre-Training is (not) What You Need in Domain Adaption","abstract":"The recent advances in Legal Large Language Models (LLMs) have transformed the landscape of legal research and practice by automating tasks, enhancing research precision, and supporting complex decision-making processes. However, effectively adapting LLMs to the legal domain remains challenging due to the complexity of legal reasoning, the need for precise interpretation of specialized language, and the potential for hallucinations. This paper examines the efficacy of Domain-Adaptive Continual Pre-Training (DACP) in improving the legal reasoning capabilities of LLMs. Through a series of experiments on legal reasoning tasks within the Taiwanese legal framework, we demonstrate that while DACP enhances domain-specific knowledge, it does not uniformly improve performance across all legal tasks. We discuss the trade-offs involved in DACP, particularly its impact on model generalization and performance in prompt-based tasks, and propose directions for future research to optimize domain adaptation strategies in legal AI.","authors":["Pin-Er Chen","Da-Chen Lian","Shu-Kai Hsieh","Sieh-Chuen Huang","Hsuan-Lei Shao","Jun-Wei Chiu","Yang-Hsien Lin","Zih-Ching Chen","Cheng-Kuang","Eddie TC Huang","Simon See"],"url":"https://arxiv.org/abs/2504.13603"}
{"created":"2025-04-21","title":"FocusTrack: A Self-Adaptive Local Sampling Algorithm for Efficient Anti-UAV Tracking","abstract":"Anti-UAV tracking poses significant challenges, including small target sizes, abrupt camera motion, and cluttered infrared backgrounds. Existing tracking paradigms can be broadly categorized into global- and local-based methods. Global-based trackers, such as SiamDT, achieve high accuracy by scanning the entire field of view but suffer from excessive computational overhead, limiting real-world deployment. In contrast, local-based methods, including OSTrack and ROMTrack, efficiently restrict the search region but struggle when targets undergo significant displacements due to abrupt camera motion. Through preliminary experiments, it is evident that a local tracker, when paired with adaptive search region adjustment, can significantly enhance tracking accuracy, narrowing the gap between local and global trackers. To address this challenge, we propose FocusTrack, a novel framework that dynamically refines the search region and strengthens feature representations, achieving an optimal balance between computational efficiency and tracking accuracy. Specifically, our Search Region Adjustment (SRA) strategy estimates the target presence probability and adaptively adjusts the field of view, ensuring the target remains within focus. Furthermore, to counteract feature degradation caused by varying search regions, the Attention-to-Mask (ATM) module is proposed. This module integrates hierarchical information, enriching the target representations with fine-grained details. Experimental results demonstrate that FocusTrack achieves state-of-the-art performance, obtaining 67.7% AUC on AntiUAV and 62.8% AUC on AntiUAV410, outperforming the baseline tracker by 8.5% and 9.1% AUC, respectively. In terms of efficiency, FocusTrack surpasses global-based trackers, requiring only 30G MACs and achieving 143 fps with FocusTrack (SRA) and 44 fps with the full version, both enabling real-time tracking.","authors":["Ying Wang","Tingfa Xu","Jianan Li"],"url":"https://arxiv.org/abs/2504.13604"}
{"created":"2025-04-21","title":"Cross-Hierarchical Bidirectional Consistency Learning for Fine-Grained Visual Classification","abstract":"Fine-Grained Visual Classification (FGVC) aims to categorize closely related subclasses, a task complicated by minimal inter-class differences and significant intra-class variance. Existing methods often rely on additional annotations for image classification, overlooking the valuable information embedded in Tree Hierarchies that depict hierarchical label relationships. To leverage this knowledge to improve classification accuracy and consistency, we propose a novel Cross-Hierarchical Bidirectional Consistency Learning (CHBC) framework. The CHBC framework extracts discriminative features across various hierarchies using a specially designed module to decompose and enhance attention masks and features. We employ bidirectional consistency loss to regulate the classification outcomes across different hierarchies, ensuring label prediction consistency and reducing misclassification. Experiments on three widely used FGVC datasets validate the effectiveness of the CHBC framework. Ablation studies further investigate the application strategies of feature enhancement and consistency constraints, underscoring the significant contributions of the proposed modules.","authors":["Pengxiang Gao","Yihao Liang","Yanzhi Song","Zhouwang Yang"],"url":"https://arxiv.org/abs/2504.13608"}
{"created":"2025-04-21","title":"Fairness and Robustness in Machine Unlearning","abstract":"Machine unlearning poses the challenge of ``how to eliminate the influence of specific data from a pretrained model'' in regard to privacy concerns. While prior research on approximated unlearning has demonstrated accuracy and efficiency in time complexity, we claim that it falls short of achieving exact unlearning, and we are the first to focus on fairness and robustness in machine unlearning algorithms. Our study presents fairness Conjectures for a well-trained model, based on the variance-bias trade-off characteristic, and considers their relevance to robustness. Our Conjectures are supported by experiments conducted on the two most widely used model architectures, ResNet and ViT, demonstrating the correlation between fairness and robustness: \\textit{the higher fairness-gap is, the more the model is sensitive and vulnerable}. In addition, our experiments demonstrate the vulnerability of current state-of-the-art approximated unlearning algorithms to adversarial attacks, where their unlearned models suffer a significant drop in accuracy compared to the exact-unlearned models. We claim that our fairness-gap measurement and robustness metric should be used to evaluate the unlearning algorithm. Furthermore, we demonstrate that unlearning in the intermediate and last layers is sufficient and cost-effective for time and memory complexity.","authors":["Khoa Tran","Simon S. Woo"],"url":"https://arxiv.org/abs/2504.13610"}
{"created":"2025-04-21","title":"Entropic Time Schedulers for Generative Diffusion Models","abstract":"The practical performance of generative diffusion models depends on the appropriate choice of the noise scheduling function, which can also be equivalently expressed as a time reparameterization. In this paper, we present a time scheduler that selects sampling points based on entropy rather than uniform time spacing, ensuring that each point contributes an equal amount of information to the final generation. We prove that this time reparameterization does not depend on the initial choice of time. Furthermore, we provide a tractable exact formula to estimate this \\emph{entropic time} for a trained model using the training loss without substantial overhead. Alongside the entropic time, inspired by the optimality results, we introduce a rescaled entropic time. In our experiments with mixtures of Gaussian distributions and ImageNet, we show that using the (rescaled) entropic times greatly improves the inference performance of trained models. In particular, we found that the image quality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can be substantially increased by the rescaled entropic time reparameterization without increasing the number of function evaluations, with greater improvements in the few NFEs regime.","authors":["Dejan Stancevic","Luca Ambrogioni"],"url":"https://arxiv.org/abs/2504.13612"}
{"created":"2025-04-21","title":"Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation","abstract":"The rapid growth of the internet has made personalized recommendation systems indispensable. Graph-based sequential recommendation systems, powered by Graph Neural Networks (GNNs), effectively capture complex user-item interactions but often face challenges such as noise and static representations. In this paper, we introduce the Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation (ALDA4Rec) method, a novel model that constructs an item-item graph, filters noise through community detection, and enriches user-item interactions. Graph Convolutional Networks (GCNs) are then employed to learn short-term representations, while averaging, GRUs, and attention mechanisms are utilized to model long-term embeddings. An MLP-based adaptive weighting strategy is further incorporated to dynamically optimize long-term user preferences. Experiments conducted on four real-world datasets demonstrate that ALDA4Rec outperforms state-of-the-art baselines, delivering notable improvements in both accuracy and robustness. The source code is available at https://github.com/zahraakhlaghi/ALDA4Rec.","authors":["Zahra Akhlaghi","Mostafa Haghir Chehreghani"],"url":"https://arxiv.org/abs/2504.13614"}
{"created":"2025-04-21","title":"Long-context Non-factoid Question Answering in Indic Languages","abstract":"Question Answering (QA) tasks, which involve extracting answers from a given context, are relatively straightforward for modern Large Language Models (LLMs) when the context is short. However, long contexts pose challenges due to the quadratic complexity of the self-attention mechanism. This challenge is compounded in Indic languages, which are often low-resource. This study explores context-shortening techniques, including Open Information Extraction (OIE), coreference resolution, Answer Paragraph Selection (APS), and their combinations, to improve QA performance. Compared to the baseline of unshortened (long) contexts, our experiments on four Indic languages (Hindi, Tamil, Telugu, and Urdu) demonstrate that context-shortening techniques yield an average improvement of 4\\% in semantic scores and 47\\% in token-level scores when evaluated on three popular LLMs without fine-tuning. Furthermore, with fine-tuning, we achieve an average increase of 2\\% in both semantic and token-level scores. Additionally, context-shortening reduces computational overhead. Explainability techniques like LIME and SHAP reveal that when the APS model confidently identifies the paragraph containing the answer, nearly all tokens within the selected text receive high relevance scores. However, the study also highlights the limitations of LLM-based QA systems in addressing non-factoid questions, particularly those requiring reasoning or debate. Moreover, verbalizing OIE-generated triples does not enhance system performance. These findings emphasize the potential of context-shortening techniques to improve the efficiency and effectiveness of LLM-based QA systems, especially for low-resource languages. The source code and resources are available at https://github.com/ritwikmishra/IndicGenQA.","authors":["Ritwik Mishra","Rajiv Ratn Shah","Ponnurangam Kumaraguru"],"url":"https://arxiv.org/abs/2504.13615"}
{"created":"2025-04-21","title":"Compile Scene Graphs with Reinforcement Learning","abstract":"Next token prediction is the fundamental principle for training large language models (LLMs), and reinforcement learning (RL) further enhances their reasoning performance. As an effective way to model language, image, video, and other modalities, the use of LLMs for end-to-end extraction of structured visual representations, such as scene graphs, remains underexplored. It requires the model to accurately produce a set of objects and relationship triplets, rather than generating text token by token. To achieve this, we introduce R1-SGG, a multimodal LLM (M-LLM) initially trained via supervised fine-tuning (SFT) on the scene graph dataset and subsequently refined using reinforcement learning to enhance its ability to generate scene graphs in an end-to-end manner. The SFT follows a conventional prompt-response paradigm, while RL requires the design of effective reward signals. Given the structured nature of scene graphs, we design a graph-centric reward function that integrates node-level rewards, edge-level rewards, and a format consistency reward. Our experiments demonstrate that rule-based RL substantially enhances model performance in the SGG task, achieving a zero failure rate--unlike supervised fine-tuning (SFT), which struggles to generalize effectively. Our code is available at https://github.com/gpt4vision/R1-SGG.","authors":["Zuyao Chen","Jinlin Wu","Zhen Lei","Marc Pollefeys","Chang Wen Chen"],"url":"https://arxiv.org/abs/2504.13617"}
{"created":"2025-04-21","title":"On the Importance of Tactile Sensing for Imitation Learning: A Case Study on Robotic Match Lighting","abstract":"The field of robotic manipulation has advanced significantly in the last years. At the sensing level, several novel tactile sensors have been developed, capable of providing accurate contact information. On a methodological level, learning from demonstrations has proven an efficient paradigm to obtain performant robotic manipulation policies. The combination of both holds the promise to extract crucial contact-related information from the demonstration data and actively exploit it during policy rollouts. However, despite its potential, it remains an underexplored direction. This work therefore proposes a multimodal, visuotactile imitation learning framework capable of efficiently learning fast and dexterous manipulation policies. We evaluate our framework on the dynamic, contact-rich task of robotic match lighting - a task in which tactile feedback influences human manipulation performance. The experimental results show that adding tactile information into the policies significantly improves performance by over 40%, thereby underlining the importance of tactile sensing for contact-rich manipulation tasks. Project website: https://sites.google.com/view/tactile-il .","authors":["Niklas Funk","Changqi Chen","Tim Schneider","Georgia Chalvatzaki","Roberto Calandra","Jan Peters"],"url":"https://arxiv.org/abs/2504.13618"}
{"created":"2025-04-21","title":"Robust Humanoid Walking on Compliant and Uneven Terrain with Deep Reinforcement Learning","abstract":"For the deployment of legged robots in real-world environments, it is essential to develop robust locomotion control methods for challenging terrains that may exhibit unexpected deformability and irregularity. In this paper, we explore the application of sim-to-real deep reinforcement learning (RL) for the design of bipedal locomotion controllers for humanoid robots on compliant and uneven terrains. Our key contribution is to show that a simple training curriculum for exposing the RL agent to randomized terrains in simulation can achieve robust walking on a real humanoid robot using only proprioceptive feedback. We train an end-to-end bipedal locomotion policy using the proposed approach, and show extensive real-robot demonstration on the HRP-5P humanoid over several difficult terrains inside and outside the lab environment. Further, we argue that the robustness of a bipedal walking policy can be improved if the robot is allowed to exhibit aperiodic motion with variable stepping frequency. We propose a new control policy to enable modification of the observed clock signal, leading to adaptive gait frequencies depending on the terrain and command velocity. Through simulation experiments, we show the effectiveness of this policy specifically for walking over challenging terrains by controlling swing and stance durations. The code for training and evaluation is available online at https://github.com/rohanpsingh/LearningHumanoidWalking. Demo video is available at https://www.youtube.com/watch?v=ZgfNzGAkk2Q.","authors":["Rohan P. Singh","Mitsuharu Morisawa","Mehdi Benallegue","Zhaoming Xie","Fumio Kanehiro"],"url":"https://arxiv.org/abs/2504.13619"}
{"created":"2025-04-21","title":"Visual Intention Grounding for Egocentric Assistants","abstract":"Visual grounding associates textual descriptions with objects in an image. Conventional methods target third-person image inputs and named object queries. In applications such as AI assistants, the perspective shifts -- inputs are egocentric, and objects may be referred to implicitly through needs and intentions. To bridge this gap, we introduce EgoIntention, the first dataset for egocentric visual intention grounding. EgoIntention challenges multimodal LLMs to 1) understand and ignore unintended contextual objects and 2) reason about uncommon object functionalities. Benchmark results show that current models misidentify context objects and lack affordance understanding in egocentric views. We also propose Reason-to-Ground (RoG) instruction tuning; it enables hybrid training with normal descriptions and egocentric intentions with a chained intention reasoning and object grounding mechanism. RoG significantly outperforms naive finetuning and hybrid training on EgoIntention, while maintaining or slightly improving naive description grounding. This advancement enables unified visual grounding for egocentric and exocentric visual inputs while handling explicit object queries and implicit human intentions.","authors":["Pengzhan Sun","Junbin Xiao","Tze Ho Elden Tse","Yicong Li","Arjun Akula","Angela Yao"],"url":"https://arxiv.org/abs/2504.13621"}
{"created":"2025-04-21","title":"Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models","abstract":"Recent advancements in large reasoning models (LRMs) have demonstrated the effectiveness of scaling test-time computation to enhance reasoning capabilities in multiple tasks. However, LRMs typically suffer from \"overthinking\" problems, where models generate significantly redundant reasoning steps while bringing limited performance gains. Existing work relies on fine-tuning to mitigate overthinking, which requires additional data, unconventional training setups, risky safety misalignment, and poor generalization.","authors":["Yule Liu","Jingyi Zheng","Zhen Sun","Zifan Peng","Wenhan Dong","Zeyang Sha","Shiwen Cui","Weiqiang Wang","Xinlei He"],"url":"https://arxiv.org/abs/2504.13626"}
{"created":"2025-04-21","title":"Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing","abstract":"Large Language Models (LLMs), such as ChatGPT, are reshaping content creation and academic writing. This study investigates the impact of AI-assisted generative revisions on research manuscripts, focusing on heterogeneous adoption patterns and their influence on writing convergence. Leveraging a dataset of over 627,000 academic papers from arXiv, we develop a novel classification framework by fine-tuning prompt- and discipline-specific large language models to detect the style of ChatGPT-revised texts. Our findings reveal substantial disparities in LLM adoption across academic disciplines, gender, native language status, and career stage, alongside a rapid evolution in scholarly writing styles. Moreover, LLM usage enhances clarity, conciseness, and adherence to formal writing conventions, with improvements varying by revision type. Finally, a difference-in-differences analysis shows that while LLMs drive convergence in academic writing, early adopters, male researchers, non-native speakers, and junior scholars exhibit the most pronounced stylistic shifts, aligning their writing more closely with that of established researchers.","authors":["Cong William Lin","Wu Zhu"],"url":"https://arxiv.org/abs/2504.13629"}
{"created":"2025-04-21","title":"Remedy: Learning Machine Translation Evaluation from Human Preferences with Reward Modeling","abstract":"A key challenge in MT evaluation is the inherent noise and inconsistency of human ratings. Regression-based neural metrics struggle with this noise, while prompting LLMs shows promise at system-level evaluation but performs poorly at segment level. In this work, we propose ReMedy, a novel MT metric framework that reformulates translation evaluation as a reward modeling task. Instead of regressing on imperfect human ratings directly, ReMedy learns relative translation quality using pairwise preference data, resulting in a more reliable evaluation. In extensive experiments across WMT22-24 shared tasks (39 language pairs, 111 MT systems), ReMedy achieves state-of-the-art performance at both segment- and system-level evaluation. Specifically, ReMedy-9B surpasses larger WMT winners and massive closed LLMs such as MetricX-13B, XCOMET-Ensemble, GEMBA-GPT-4, PaLM-540B, and finetuned PaLM2. Further analyses demonstrate that ReMedy delivers superior capability in detecting translation errors and evaluating low-quality translations.","authors":["Shaomu Tan","Christof Monz"],"url":"https://arxiv.org/abs/2504.13630"}
{"created":"2025-04-21","title":"Multi-modal Knowledge Graph Generation with Semantics-enriched Prompts","abstract":"Multi-modal Knowledge Graphs (MMKGs) have been widely applied across various domains for knowledge representation. However, the existing MMKGs are significantly fewer than required, and their construction faces numerous challenges, particularly in ensuring the selection of high-quality, contextually relevant images for knowledge graph enrichment. To address these challenges, we present a framework for constructing MMKGs from conventional KGs. Furthermore, to generate higher-quality images that are more relevant to the context in the given knowledge graph, we designed a neighbor selection method called Visualizable Structural Neighbor Selection (VSNS). This method consists of two modules: Visualizable Neighbor Selection (VNS) and Structural Neighbor Selection (SNS). The VNS module filters relations that are difficult to visualize, while the SNS module selects neighbors that most effectively capture the structural characteristics of the entity. To evaluate the quality of the generated images, we performed qualitative and quantitative evaluations on two datasets, MKG-Y and DB15K. The experimental results indicate that using the VSNS method to select neighbors results in higher-quality images that are more relevant to the knowledge graph.","authors":["Yajing Xu","Zhiqiang Liu","Jiaoyan Chen","Mingchen Tu","Zhuo Chen","Jeff Z. Pan","Yichi Zhang","Yushan Zhu","Wen Zhang","Huajun Chen"],"url":"https://arxiv.org/abs/2504.13631"}
{"created":"2025-04-21","title":"A Reinforcement Learning Method to Factual and Counterfactual Explanations for Session-based Recommendation","abstract":"Session-based Recommendation (SR) systems have recently achieved considerable success, yet their complex, \"black box\" nature often obscures why certain recommendations are made. Existing explanation methods struggle to pinpoint truly influential factors, as they frequently depend on static user profiles or fail to grasp the intricate dynamics within user sessions. In response, we introduce FCESR (Factual and Counterfactual Explanations for Session-based Recommendation), a novel framework designed to illuminate SR model predictions by emphasizing both the sufficiency (factual) and necessity (counterfactual) of recommended items. By recasting explanation generation as a combinatorial optimization challenge and leveraging reinforcement learning, our method uncovers the minimal yet critical sequence of items influencing recommendations. Moreover, recognizing the intrinsic value of robust explanations, we innovatively utilize these factual and counterfactual insights within a contrastive learning paradigm, employing them as high-quality positive and negative samples to fine-tune and significantly enhance SR accuracy. Extensive qualitative and quantitative evaluations across diverse datasets and multiple SR architectures confirm that our framework not only boosts recommendation accuracy but also markedly elevates the quality and interpretability of explanations, thereby paving the way for more transparent and trustworthy recommendation systems.","authors":["Han Zhou","Hui Fang","Zhu Sun","Wentao Hu"],"url":"https://arxiv.org/abs/2504.13632"}
{"created":"2025-04-21","title":"Efficient algorithms for the Hadamard decomposition","abstract":"The Hadamard decomposition is a powerful technique for data analysis and matrix compression, which decomposes a given matrix into the element-wise product of two or more low-rank matrices. In this paper, we develop an efficient algorithm to solve this problem, leveraging an alternating optimization approach that decomposes the global non-convex problem into a series of convex sub-problems. To improve performance, we explore advanced initialization strategies inspired by the singular value decomposition (SVD) and incorporate acceleration techniques by introducing momentum-based updates. Beyond optimizing the two-matrix case, we also extend the Hadamard decomposition framework to support more than two low-rank matrices, enabling approximations with higher effective ranks while preserving computational efficiency. Finally, we conduct extensive experiments to compare our method with the existing gradient descent-based approaches for the Hadamard decomposition and with traditional low-rank approximation techniques. The results highlight the effectiveness of our proposed method across diverse datasets.","authors":["Samuel Wertz","Arnaud Vandaele","Nicolas Gillis"],"url":"https://arxiv.org/abs/2504.13633"}
{"created":"2025-04-21","title":"Robot Navigation in Dynamic Environments using Acceleration Obstacles","abstract":"This paper addresses the issue of motion planning in dynamic environments by extending the concept of Velocity Obstacle and Nonlinear Velocity Obstacle to Acceleration Obstacle AO and Nonlinear Acceleration Obstacle NAO. Similarly to VO and NLVO, the AO and NAO represent the set of colliding constant accelerations of the maneuvering robot with obstacles moving along linear and nonlinear trajectories, respectively. Contrary to prior works, we derive analytically the exact boundaries of AO and NAO. To enhance an intuitive understanding of these representations, we first derive the AO in several steps: first extending the VO to the Basic Acceleration Obstacle BAO that consists of the set of constant accelerations of the robot that would collide with an obstacle moving at constant accelerations, while assuming zero initial velocities of the robot and obstacle. This is then extended to the AO while assuming arbitrary initial velocities of the robot and obstacle. And finally, we derive the NAO that in addition to the prior assumptions, accounts for obstacles moving along arbitrary trajectories. The introduction of NAO allows the generation of safe avoidance maneuvers that directly account for the robot's second-order dynamics, with acceleration as its control input. The AO and NAO are demonstrated in several examples of selecting avoidance maneuvers in challenging road traffic. It is shown that the use of NAO drastically reduces the adjustment rate of the maneuvering robot's acceleration while moving in complex road traffic scenarios. The presented approach enables reactive and efficient navigation for multiple robots, with potential application for autonomous vehicles operating in complex dynamic environments.","authors":["Asher Stern","Zvi Shiller"],"url":"https://arxiv.org/abs/2504.13637"}
{"created":"2025-04-21","title":"DenSe-AdViT: A novel Vision Transformer for Dense SAR Object Detection","abstract":"Vision Transformer (ViT) has achieved remarkable results in object detection for synthetic aperture radar (SAR) images, owing to its exceptional ability to extract global features. However, it struggles with the extraction of multi-scale local features, leading to limited performance in detecting small targets, especially when they are densely arranged. Therefore, we propose Density-Sensitive Vision Transformer with Adaptive Tokens (DenSe-AdViT) for dense SAR target detection. We design a Density-Aware Module (DAM) as a preliminary component that generates a density tensor based on target distribution. It is guided by a meticulously crafted objective metric, enabling precise and effective capture of the spatial distribution and density of objects. To integrate the multi-scale information enhanced by convolutional neural networks (CNNs) with the global features derived from the Transformer, Density-Enhanced Fusion Module (DEFM) is proposed. It effectively refines attention toward target-survival regions with the assist of density mask and the multiple sources features. Notably, our DenSe-AdViT achieves 79.8% mAP on the RSDD dataset and 92.5% on the SIVED dataset, both of which feature a large number of densely distributed vehicle targets.","authors":["Yang Zhang","Jingyi Cao","Yanan You","Yuanyuan Qiao"],"url":"https://arxiv.org/abs/2504.13638"}
{"created":"2025-04-21","title":"Propagational Proxy Voting","abstract":"This paper proposes a voting process in which voters allocate fractional votes to their expected utility in different domains: over proposals, other participants, and sets containing proposals and participants. This approach allows for a more nuanced expression of preferences by calculating the result and relevance within each node. We modeled this by creating a voting matrix that reflects their preference. We use absorbing Markov chains to gain the consensus, and also calculate the influence within the participating nodes. We illustrate this method in action through an experiment with 69 students using a budget allocation topic.","authors":["Yasushi Sakai","Parfait Atchade-Adelomou","Ryan Jiang","Luis Alonso","Kent Larson","Ken Suzuki"],"url":"https://arxiv.org/abs/2504.13641"}
{"created":"2025-04-21","title":"Simulating Before Planning: Constructing Intrinsic User World Model for User-Tailored Dialogue Policy Planning","abstract":"Recent advancements in dialogue policy planning have emphasized optimizing system agent policies to achieve predefined goals, focusing on strategy design, trajectory acquisition, and efficient training paradigms. However, these approaches often overlook the critical role of user characteristics, which are essential in real-world scenarios like conversational search and recommendation, where interactions must adapt to individual user traits such as personality, preferences, and goals. To address this gap, we first conduct a comprehensive study utilizing task-specific user personas to systematically assess dialogue policy planning under diverse user behaviors. By leveraging realistic user profiles for different tasks, our study reveals significant limitations in existing approaches, highlighting the need for user-tailored dialogue policy planning. Building on this foundation, we present the User-Tailored Dialogue Policy Planning (UDP) framework, which incorporates an Intrinsic User World Model to model user traits and feedback. UDP operates in three stages: (1) User Persona Portraying, using a diffusion model to dynamically infer user profiles; (2) User Feedback Anticipating, leveraging a Brownian Bridge-inspired anticipator to predict user reactions; and (3) User-Tailored Policy Planning, integrating these insights to optimize response strategies. To ensure robust performance, we further propose an active learning approach that prioritizes challenging user personas during training. Comprehensive experiments on benchmarks, including collaborative and non-collaborative settings, demonstrate the effectiveness of UDP in learning user-specific dialogue strategies. Results validate the protocol's utility and highlight UDP's robustness, adaptability, and potential to advance user-centric dialogue systems.","authors":["Tao He","Lizi Liao","Ming Liu","Bing Qin"],"url":"https://arxiv.org/abs/2504.13643"}
{"created":"2025-04-21","title":"Exploring the Potential for Large Language Models to Demonstrate Rational Probabilistic Beliefs","abstract":"Advances in the general capabilities of large language models (LLMs) have led to their use for information retrieval, and as components in automated decision systems. A faithful representation of probabilistic reasoning in these models may be essential to ensure trustworthy, explainable and effective performance in these tasks. Despite previous work suggesting that LLMs can perform complex reasoning and well-calibrated uncertainty quantification, we find that current versions of this class of model lack the ability to provide rational and coherent representations of probabilistic beliefs. To demonstrate this, we introduce a novel dataset of claims with indeterminate truth values and apply a number of well-established techniques for uncertainty quantification to measure the ability of LLM's to adhere to fundamental properties of probabilistic reasoning.","authors":["Gabriel Freedman","Francesca Toni"],"url":"https://arxiv.org/abs/2504.13644"}
{"created":"2025-04-21","title":"Efficient Parameter Adaptation for Multi-Modal Medical Image Segmentation and Prognosis","abstract":"Cancer detection and prognosis relies heavily on medical imaging, particularly CT and PET scans. Deep Neural Networks (DNNs) have shown promise in tumor segmentation by fusing information from these modalities. However, a critical bottleneck exists: the dependency on CT-PET data concurrently for training and inference, posing a challenge due to the limited availability of PET scans. Hence, there is a clear need for a flexible and efficient framework that can be trained with the widely available CT scans and can be still adapted for PET scans when they become available. In this work, we propose a parameter-efficient multi-modal adaptation (PEMMA) framework for lightweight upgrading of a transformer-based segmentation model trained only on CT scans such that it can be efficiently adapted for use with PET scans when they become available. This framework is further extended to perform prognosis task maintaining the same efficient cross-modal fine-tuning approach. The proposed approach is tested with two well-known segementation backbones, namely UNETR and Swin UNETR. Our approach offers two main advantages. Firstly, we leverage the inherent modularity of the transformer architecture and perform low-rank adaptation (LoRA) as well as decomposed low-rank adaptation (DoRA) of the attention weights to achieve parameter-efficient adaptation. Secondly, by minimizing cross-modal entanglement, PEMMA allows updates using only one modality without causing catastrophic forgetting in the other. Our method achieves comparable performance to early fusion, but with only 8% of the trainable parameters, and demonstrates a significant +28% Dice score improvement on PET scans when trained with a single modality. Furthermore, in prognosis, our method improves the concordance index by +10% when adapting a CT-pretrained model to include PET scans, and by +23% when adapting for both PET and EHR data.","authors":["Numan Saeed","Shahad Hardan","Muhammad Ridzuan","Nada Saadi","Karthik Nandakumar","Mohammad Yaqub"],"url":"https://arxiv.org/abs/2504.13645"}
{"created":"2025-04-21","title":"Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction","abstract":"Service mobile robots are often required to avoid dynamic objects while performing their tasks, but they usually have only limited computational resources. So we present a lightweight multi-modal framework for 3D object detection and trajectory prediction. Our system synergistically integrates LiDAR and camera inputs to achieve real-time perception of pedestrians, vehicles, and riders in 3D space. The framework proposes two novel modules: 1) a Cross-Modal Deformable Transformer (CMDT) for object detection with high accuracy and acceptable amount of computation, and 2) a Reference Trajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse trajectory prediction of mult-class objects with flexible trajectory lengths. Evaluations on the CODa benchmark demonstrate superior performance over existing methods across detection (+2.03% in mAP) and trajectory prediction (-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibits exceptional deployability - when implemented on a wheelchair robot with an entry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. To facilitate reproducibility and practical deployment, we release the related code of the method at https://github.com/TossherO/3D_Perception and its ROS inference version at https://github.com/TossherO/ros_packages.","authors":["Yushen He","Lei Zhao","Tianchen Deng","Zipeng Fang","Weidong Chen"],"url":"https://arxiv.org/abs/2504.13647"}
{"created":"2025-04-21","title":"Enhancing Pothole Detection and Characterization: Integrated Segmentation and Depth Estimation in Road Anomaly Systems","abstract":"Road anomaly detection plays a crucial role in road maintenance and in enhancing the safety of both drivers and vehicles. Recent machine learning approaches for road anomaly detection have overcome the tedious and time-consuming process of manual analysis and anomaly counting; however, they often fall short in providing a complete characterization of road potholes. In this paper, we leverage transfer learning by adopting a pre-trained YOLOv8-seg model for the automatic characterization of potholes using digital images captured from a dashboard-mounted camera. Our work includes the creation of a novel dataset, comprising both images and their corresponding depth maps, collected from diverse road environments in Al-Khobar city and the KFUPM campus in Saudi Arabia. Our approach performs pothole detection and segmentation to precisely localize potholes and calculate their area. Subsequently, the segmented image is merged with its depth map to extract detailed depth information about the potholes. This integration of segmentation and depth data offers a more comprehensive characterization compared to previous deep learning-based road anomaly detection systems. Overall, this method not only has the potential to significantly enhance autonomous vehicle navigation by improving the detection and characterization of road hazards but also assists road maintenance authorities in responding more effectively to road damage.","authors":["Uthman Baroudi","Alala BaHamid","Yasser Elalfy","Ziad Al Alami"],"url":"https://arxiv.org/abs/2504.13648"}
{"created":"2025-04-21","title":"EyecareGPT: Boosting Comprehensive Ophthalmology Understanding with Tailored Dataset, Benchmark and Model","abstract":"Medical Large Vision-Language Models (Med-LVLMs) demonstrate significant potential in healthcare, but their reliance on general medical data and coarse-grained global visual understanding limits them in intelligent ophthalmic diagnosis. Currently, intelligent ophthalmic diagnosis faces three major challenges: (i) Data. The lack of deeply annotated, high-quality, multi-modal ophthalmic visual instruction data; (ii) Benchmark. The absence of a comprehensive and systematic benchmark for evaluating diagnostic performance; (iii) Model. The difficulty of adapting holistic visual architectures to fine-grained, region-specific ophthalmic lesion identification. In this paper, we propose the Eyecare Kit, which systematically tackles the aforementioned three key challenges with the tailored dataset, benchmark and model: First, we construct a multi-agent data engine with real-life ophthalmology data to produce Eyecare-100K, a high-quality ophthalmic visual instruction dataset. Subsequently, we design Eyecare-Bench, a benchmark that comprehensively evaluates the overall performance of LVLMs on intelligent ophthalmic diagnosis tasks across multiple dimensions. Finally, we develop the EyecareGPT, optimized for fine-grained ophthalmic visual understanding thoroughly, which incorporates an adaptive resolution mechanism and a layer-wise dense connector. Extensive experimental results indicate that the EyecareGPT achieves state-of-the-art performance in a range of ophthalmic tasks, underscoring its significant potential for the advancement of open research in intelligent ophthalmic diagnosis. Our project is available at https://github.com/DCDmllm/EyecareGPT.","authors":["Sijing Li","Tianwei Lin","Lingshuai Lin","Wenqiao Zhang","Jiang Liu","Xiaoda Yang","Juncheng Li","Yucheng He","Xiaohui Song","Jun Xiao","Yueting Zhuang","Beng Chin Ooi"],"url":"https://arxiv.org/abs/2504.13650"}
{"created":"2025-04-21","title":"Word Embedding Techniques for Classification of Star Ratings","abstract":"Telecom services are at the core of today's societies' everyday needs. The availability of numerous online forums and discussion platforms enables telecom providers to improve their services by exploring the views of their customers to learn about common issues that the customers face. Natural Language Processing (NLP) tools can be used to process the free text collected.","authors":["Hesham Abdelmotaleb","Craig McNeile","Malgorzata Wojtys"],"url":"https://arxiv.org/abs/2504.13653"}
{"created":"2025-04-21","title":"Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts","abstract":"Conversational recommender systems enable natural language conversations and thus lead to a more engaging and effective recommendation scenario. As the conversations for recommender systems usually contain limited contextual information, many existing conversational recommender systems incorporate external sources to enrich the contextual information. However, how to combine different types of contextual information is still a challenge. In this paper, we propose a multi-type context-aware conversational recommender system, called MCCRS, effectively fusing multi-type contextual information via mixture-of-experts to improve conversational recommender systems. MCCRS incorporates both structured information and unstructured information, including the structured knowledge graph, unstructured conversation history, and unstructured item reviews. It consists of several experts, with each expert specialized in a particular domain (i.e., one specific contextual information). Multiple experts are then coordinated by a ChairBot to generate the final results. Our proposed MCCRS model takes advantage of different contextual information and the specialization of different experts followed by a ChairBot breaks the model bottleneck on a single contextual information. Experimental results demonstrate that our proposed MCCRS method achieves significantly higher performance compared to existing baselines.","authors":["Jie Zou","Cheng Lin","Weikang Guo","Zheng Wang","Jiwei Wei","Yang Yang","Hengtao Shen"],"url":"https://arxiv.org/abs/2504.13655"}
{"created":"2025-04-21","title":"Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code","abstract":"Large Language Models (LLMs) have rapidly transformed software development, especially in code generation. However, their inconsistent performance, prone to hallucinations and quality issues, complicates program comprehension and hinders maintainability. Research indicates that prompt engineering-the practice of designing inputs to direct LLMs toward generating relevant outputs-may help address these challenges. In this regard, researchers have introduced prompt patterns, structured templates intended to guide users in formulating their requests. However, the influence of prompt patterns on code quality has yet to be thoroughly investigated. An improved understanding of this relationship would be essential to advancing our collective knowledge on how to effectively use LLMs for code generation, thereby enhancing their understandability in contemporary software development. This paper empirically investigates the impact of prompt patterns on code quality, specifically maintainability, security, and reliability, using the Dev-GPT dataset. Results show that Zero-Shot prompting is most common, followed by Zero-Shot with Chain-of-Thought and Few-Shot. Analysis of 7583 code files across quality metrics revealed minimal issues, with Kruskal-Wallis tests indicating no significant differences among patterns, suggesting that prompt structure may not substantially impact these quality metrics in ChatGPT-assisted code generation.","authors":["Antonio Della Porta","Stefano Lambiase","Fabio Palomba"],"url":"https://arxiv.org/abs/2504.13656"}
{"created":"2025-04-21","title":"Performance Analysis of a Mass-Spring-Damper Deformable Linear Object Model in Robotic Simulation Frameworks","abstract":"The modelling of Deformable Linear Objects (DLOs) such as cables, wires, and strings presents significant challenges due to their flexible and deformable nature. In robotics, accurately simulating the dynamic behavior of DLOs is essential for automating tasks like wire handling and assembly. The presented study is a preliminary analysis aimed at force data collection through domain randomization (DR) for training a robot in simulation, using a Mass-Spring-Damper (MSD) system as the reference model. The study aims to assess the impact of model parameter variations on DLO dynamics, using Isaac Sim and Gazebo to validate the applicability of DR technique in these scenarios.","authors":["Andrea Govoni","Nadia Zubair","Simone Soprani","Gianluca Palli"],"url":"https://arxiv.org/abs/2504.13659"}
{"created":"2025-04-21","title":"Large Language Models Will Change The Way Children Think About Technology And Impact Every Interaction Paradigm","abstract":"This paper presents a hopeful perspective on the potentially dramatic impacts of Large Language Models on how we children learn and how they will expect to interact with technology. We review the effects of LLMs on education so far, and make the case that these effects are minor compared to the upcoming changes that are occurring. We present a small scenario and self-ethnographic study demonstrating the effects of these changes, and define five significant considerations that interactive systems designers will have to accommodate in the future.","authors":["Russell Beale"],"url":"https://arxiv.org/abs/2504.13667"}
{"created":"2025-04-21","title":"Broadcasting under Structural Restrictions","abstract":"In the Telephone Broadcast problem we are given a graph $G=(V,E)$ with a designated source vertex $s\\in V$. Our goal is to transmit a message, which is initially known only to $s$, to all vertices of the graph by using a process where in each round an informed vertex may transmit the message to one of its uninformed neighbors. The optimization objective is to minimize the number of rounds.","authors":["Yudai Egami","Tatsuya Gima","Tesshu Hanaka","Yasuaki Kobayashi","Michael Lampis","Valia Mitsou","Edouard Nemery","Yota Otachi","Manolis Vasilakis","Daniel Vaz"],"url":"https://arxiv.org/abs/2504.13669"}
{"created":"2025-04-21","title":"Magnecko: Design and Control of a Quadrupedal Magnetic Climbing Robot","abstract":"Climbing robots hold significant promise for applications such as industrial inspection and maintenance, particularly in hazardous or hard-to-reach environments. This paper describes the quadrupedal climbing robot Magnecko, developed with the major goal of providing a research platform for legged climbing locomotion. With its 12 actuated degrees of freedom arranged in an insect-style joint configuration, Magnecko's high manipulability and high range of motion allow it to handle challenging environments like overcoming concave 90 degree corners. A model predictive controller enables Magnecko to crawl on the ground on horizontal overhangs and on vertical walls. Thanks to the custom actuators and the electro-permanent magnets that are used for adhesion on ferrous surfaces, the system is powerful enough to carry additional payloads of at least 65 percent of its own weight in all orientations. The Magnecko platform serves as a foundation for climbing locomotion in complex three-dimensional environments.","authors":["Stefan Leuthard","Timo Eugster","Nicolas Faesch","Riccardo Feingold","Connor Flynn","Michael Fritsche","Nicolas H\\\"urlimann","Elena Morbach","Fabian Tischhauser","Matthias M\\\"uller","Markus Montenegro","Valerio Schelbert","Jia-Ruei Chiu","Philip Arm","Marco Hutter"],"url":"https://arxiv.org/abs/2504.13672"}
{"created":"2025-04-21","title":"Beyond Stereotypes: Exploring How Minority College Students Experience Stigma on Reddit","abstract":"Minority college students face unique challenges shaped by their identities based on their gender/sexual orientation, race, religion, and academic institutions, which influence their academic and social experiences. Although research has highlighted the challenges faced by individual minority groups, the stigma process-labeling, stereotyping, separation, status loss, and discrimination-that underpin these experiences remains underexamined, particularly in the online spaces where college students are highly active. We address these gaps by examining posts on subreddit, r/college, as indicators for stigma processes, our approach applies a Stereotype-BERT model, including stance toward each stereotype. We extend the stereotype model to encompass status loss and discrimination by using semantic distance with their reference sentences. Our analyses show that professional indicated posts are primarily labeled under the stereotyping stage, whereas posts indicating racial are highly represented in status loss and discrimination. Intersectional identified posts are more frequently associated with status loss and discrimination. The findings of this study highlight the need for multifaceted intersectional approaches to identifying stigma, which subsequently serve as indicators to promote equity for minority groups, especially racial minorities and those experiencing compounded vulnerabilities due to intersecting identities.","authors":["Chaeeun Han","Sangpil Youm","Hojeong Yoo","Sou Hyun Jang"],"url":"https://arxiv.org/abs/2504.13674"}
{"created":"2025-04-21","title":"Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction","abstract":"As the number of web applications and API endpoints exposed to the Internet continues to grow, so does the number of exploitable vulnerabilities. Manually identifying such vulnerabilities is tedious. Meanwhile, static security scanners tend to produce many false positives. While machine learning-based approaches are promising, they typically perform well only in scenarios where training and test data are closely related. A key challenge for ML-based vulnerability detection is providing suitable and concise code context, as excessively long contexts negatively affect the code comprehension capabilities of machine learning models, particularly smaller ones.","authors":["Felix M\\\"achtle","Nils Loose","Tim Schulz","Florian Sieck","Jan-Niclas Serr","Ralf M\\\"oller","Thomas Eisenbarth"],"url":"https://arxiv.org/abs/2504.13676"}
{"created":"2025-04-21","title":"Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results","abstract":"Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for improving their safety and reliability. Evaluations often use performance metrics like AUROC to assess how well UQ methods (e.g., negative sequence probabilities) correlate with task correctness functions (e.g., ROUGE-L). In this paper, we show that commonly used correctness functions bias UQ evaluations by inflating the performance of certain UQ methods. We evaluate 7 correctness functions -- from lexical-based and embedding-based metrics to LLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our analysis reveals that length biases in the errors of these correctness functions distort UQ assessments by interacting with length biases in UQ methods. We identify LLM-as-a-judge approaches as among the least length-biased choices and hence a potential solution to mitigate these biases.","authors":["Andrea Santilli","Adam Golinski","Michael Kirchhof","Federico Danieli","Arno Blaas","Miao Xiong","Luca Zappella","Sinead Williamson"],"url":"https://arxiv.org/abs/2504.13677"}
{"created":"2025-04-21","title":"AnyTSR: Any-Scale Thermal Super-Resolution for UAV","abstract":"Thermal imaging can greatly enhance the application of intelligent unmanned aerial vehicles (UAV) in challenging environments. However, the inherent low resolution of thermal sensors leads to insufficient details and blurred boundaries. Super-resolution (SR) offers a promising solution to address this issue, while most existing SR methods are designed for fixed-scale SR. They are computationally expensive and inflexible in practical applications. To address above issues, this work proposes a novel any-scale thermal SR method (AnyTSR) for UAV within a single model. Specifically, a new image encoder is proposed to explicitly assign specific feature code to enable more accurate and flexible representation. Additionally, by effectively embedding coordinate offset information into the local feature ensemble, an innovative any-scale upsampler is proposed to better understand spatial relationships and reduce artifacts. Moreover, a novel dataset (UAV-TSR), covering both land and water scenes, is constructed for thermal SR tasks. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art methods across all scaling factors as well as generates more accurate and detailed high-resolution images. The code is located at https://github.com/vision4robotics/AnyTSR.","authors":["Mengyuan Li","Changhong Fu","Ziyu Lu","Zijie Zhang","Haobo Zuo","Liangliang Yao"],"url":"https://arxiv.org/abs/2504.13682"}
{"created":"2025-04-21","title":"Intelligent Interaction Strategies for Context-Aware Cognitive Augmentation","abstract":"Human cognition is constrained by processing limitations, leading to cognitive overload and inefficiencies in knowledge synthesis and decision-making. Large Language Models (LLMs) present an opportunity for cognitive augmentation, but their current reactive nature limits their real-world applicability. This position paper explores the potential of context-aware cognitive augmentation, where LLMs dynamically adapt to users' cognitive states and task environments to provide appropriate support. Through a think-aloud study in an exhibition setting, we examine how individuals interact with multi-modal information and identify key cognitive challenges in structuring, retrieving, and applying knowledge. Our findings highlight the need for AI-driven cognitive support systems that integrate real-time contextual awareness, personalized reasoning assistance, and socially adaptive interactions. We propose a framework for AI augmentation that seamlessly transitions between real-time cognitive support and post-experience knowledge organization, contributing to the design of more effective human-centered AI systems.","authors":["Xiangrong (Daniel)","Zhu","Yuan Xu","Tianjian Liu","Jingwei Sun","Yu Zhang","Xin Tong"],"url":"https://arxiv.org/abs/2504.13684"}
{"created":"2025-04-21","title":"Deep literature reviews: an application of fine-tuned language models to migration research","abstract":"This paper presents a hybrid framework for literature reviews that augments traditional bibliometric methods with large language models (LLMs). By fine-tuning open-source LLMs, our approach enables scalable extraction of qualitative insights from large volumes of research content, enhancing both the breadth and depth of knowledge synthesis. To improve annotation efficiency and consistency, we introduce an error-focused validation process in which LLMs generate initial labels and human reviewers correct misclassifications. Applying this framework to over 20000 scientific articles about human migration, we demonstrate that a domain-adapted LLM can serve as a \"specialist\" model - capable of accurately selecting relevant studies, detecting emerging trends, and identifying critical research gaps. Notably, the LLM-assisted review reveals a growing scholarly interest in climate-induced migration. However, existing literature disproportionately centers on a narrow set of environmental hazards (e.g., floods, droughts, sea-level rise, and land degradation), while overlooking others that more directly affect human health and well-being, such as air and water pollution or infectious diseases. This imbalance highlights the need for more comprehensive research that goes beyond physical environmental changes to examine their ecological and societal consequences, particularly in shaping migration as an adaptive response. Overall, our proposed framework demonstrates the potential of fine-tuned LLMs to conduct more efficient, consistent, and insightful literature reviews across disciplines, ultimately accelerating knowledge synthesis and scientific discovery.","authors":["Stefano M. Iacus","Haodong Qi","Jiyoung Han"],"url":"https://arxiv.org/abs/2504.13685"}
{"created":"2025-04-21","title":"Analysing the Robustness of Vision-Language-Models to Common Corruptions","abstract":"Vision-language models (VLMs) have demonstrated impressive capabilities in understanding and reasoning about visual and textual content. However, their robustness to common image corruptions remains under-explored. In this work, we present the first comprehensive analysis of VLM robustness across 19 corruption types from the ImageNet-C benchmark, spanning four categories: noise, blur, weather, and digital distortions. We introduce two new benchmarks, TextVQA-C and GQA-C, to systematically evaluate how corruptions affect scene text understanding and object-based reasoning, respectively. Our analysis reveals that transformer-based VLMs exhibit distinct vulnerability patterns across tasks: text recognition deteriorates most severely under blur and snow corruptions, while object reasoning shows higher sensitivity to corruptions such as frost and impulse noise. We connect these observations to the frequency-domain characteristics of different corruptions, revealing how transformers' inherent bias toward low-frequency processing explains their differential robustness patterns. Our findings provide valuable insights for developing more corruption-robust vision-language models for real-world applications.","authors":["Muhammad Usama","Syeda Aisha Asim","Syed Bilal Ali","Syed Talal Wasim","Umair Bin Mansoor"],"url":"https://arxiv.org/abs/2504.13690"}
{"created":"2025-04-21","title":"MEGA: Second-Order Gradient Alignment for Catastrophic Forgetting Mitigation in GFSCIL","abstract":"Graph Few-Shot Class-Incremental Learning (GFSCIL) enables models to continually learn from limited samples of novel tasks after initial training on a large base dataset. Existing GFSCIL approaches typically utilize Prototypical Networks (PNs) for metric-based class representations and fine-tune the model during the incremental learning stage. However, these PN-based methods oversimplify learning via novel query set fine-tuning and fail to integrate Graph Continual Learning (GCL) techniques due to architectural constraints. To address these challenges, we propose a more rigorous and practical setting for GFSCIL that excludes query sets during the incremental training phase. Building on this foundation, we introduce Model-Agnostic Meta Graph Continual Learning (MEGA), aimed at effectively alleviating catastrophic forgetting for GFSCIL. Specifically, by calculating the incremental second-order gradient during the meta-training stage, we endow the model to learn high-quality priors that enhance incremental learning by aligning its behaviors across both the meta-training and incremental learning stages. Extensive experiments on four mainstream graph datasets demonstrate that MEGA achieves state-of-the-art results and enhances the effectiveness of various GCL methods in GFSCIL. We believe that our proposed MEGA serves as a model-agnostic GFSCIL paradigm, paving the way for future research.","authors":["Jinhui Pang","Changqing Lin","Hao Lin","Jinglin He","Zhengjun Li","Zhihui Zhang","Xiaoshuai Hao"],"url":"https://arxiv.org/abs/2504.13691"}
{"created":"2025-04-21","title":"Zebrafish Counting Using Event Stream Data","abstract":"Zebrafish share a high degree of homology with human genes and are commonly used as model organism in biomedical research. For medical laboratories, counting zebrafish is a daily task. Due to the tiny size of zebrafish, manual visual counting is challenging. Existing counting methods are either not applicable to small fishes or have too many limitations. The paper proposed a zebrafish counting algorithm based on the event stream data. Firstly, an event camera is applied for data acquisition. Secondly, camera calibration and image fusion were preformed successively. Then, the trajectory information was used to improve the counting accuracy. Finally, the counting results were averaged over an empirical of period and rounded up to get the final results. To evaluate the accuracy of the algorithm, 20 zebrafish were put in a four-liter breeding tank. Among 100 counting trials, the average accuracy reached 97.95%. As compared with traditional algorithms, the proposed one offers a simpler implementation and achieves higher accuracy.","authors":["Qianghua Chen","Huiyu Wang","Li Ming","Ying Zhao"],"url":"https://arxiv.org/abs/2504.13692"}
{"created":"2025-04-21","title":"Green Robotic Mixed Reality with Gaussian Splatting","abstract":"Realizing green communication in robotic mixed reality (RoboMR) systems presents a challenge, due to the necessity of uploading high-resolution images at high frequencies through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR (GSRMR), which achieves a lower energy consumption and makes a concrete step towards green RoboMR. The crux to GSRMR is to build a GS model which enables the simulator to opportunistically render a photo-realistic view from the robot's pose, thereby reducing the need for excessive image uploads. Since the GS model may involve discrepancies compared to the actual environments, a GS cross-layer optimization (GSCLO) framework is further proposed, which jointly optimizes content switching (i.e., deciding whether to upload image or not) and power allocation across different frames. The GSCLO problem is solved by an accelerated penalty optimization (APO) algorithm. Experiments demonstrate that the proposed GSRMR reduces the communication energy by over 10x compared with RoboMR. Furthermore, the proposed GSRMR with APO outperforms extensive baseline schemes, in terms of peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM).","authors":["Chenxuan Liu","He Li","Zongze Li","Shuai Wang","Wei Xu","Kejiang Ye","Derrick Wing Kwan Ng","Chengzhong Xu"],"url":"https://arxiv.org/abs/2504.13697"}
{"created":"2025-04-21","title":"Exploring Multimodal Prompt for Visualization Authoring with Large Language Models","abstract":"Recent advances in large language models (LLMs) have shown great potential in automating the process of visualization authoring through simple natural language utterances. However, instructing LLMs using natural language is limited in precision and expressiveness for conveying visualization intent, leading to misinterpretation and time-consuming iterations. To address these limitations, we conduct an empirical study to understand how LLMs interpret ambiguous or incomplete text prompts in the context of visualization authoring, and the conditions making LLMs misinterpret user intent. Informed by the findings, we introduce visual prompts as a complementary input modality to text prompts, which help clarify user intent and improve LLMs' interpretation abilities. To explore the potential of multimodal prompting in visualization authoring, we design VisPilot, which enables users to easily create visualizations using multimodal prompts, including text, sketches, and direct manipulations on existing visualizations. Through two case studies and a controlled user study, we demonstrate that VisPilot provides a more intuitive way to create visualizations without affecting the overall task efficiency compared to text-only prompting approaches. Furthermore, we analyze the impact of text and visual prompts in different visualization tasks. Our findings highlight the importance of multimodal prompting in improving the usability of LLMs for visualization authoring. We discuss design implications for future visualization systems and provide insights into how multimodal prompts can enhance human-AI collaboration in creative visualization tasks. All materials are available at https://OSF.IO/2QRAK.","authors":["Zhen Wen","Luoxuan Weng","Yinghao Tang","Runjin Zhang","Yuxin Liu","Bo Pan","Minfeng Zhu","Wei Chen"],"url":"https://arxiv.org/abs/2504.13700"}
{"created":"2025-04-21","title":"Inverse Inference on Cooperative Control of Networked Dynamical Systems","abstract":"Recent years have witnessed the rapid advancement of understanding the control mechanism of networked dynamical systems (NDSs), which are governed by components such as nodal dynamics and topology. This paper reveals that the critical components in continuous-time state feedback cooperative control of NDSs can be inferred merely from discrete observations. In particular, we advocate a bi-level inference framework to estimate the global closed-loop system and extract the components, respectively. The novelty lies in bridging the gap from discrete observations to the continuous-time model and effectively decoupling the concerned components. Specifically, in the first level, we design a causality-based estimator for the discrete-time closed-loop system matrix, which can achieve asymptotically unbiased performance when the NDS is stable. In the second level, we introduce a matrix logarithm based method to recover the continuous-time counterpart matrix, providing new sampling period guarantees and establishing the recovery error bound. By utilizing graph properties of the NDS, we develop least square based procedures to decouple the concerned components with up to a scalar ambiguity. Furthermore, we employ inverse optimal control techniques to reconstruct the objective function driving the control process, deriving necessary conditions for the solutions. Numerical simulations demonstrate the effectiveness of the proposed method.","authors":["Yushan Li","Jianping He","Dimos V. Dimarogonas"],"url":"https://arxiv.org/abs/2504.13701"}
{"created":"2025-04-21","title":"Consensus-aware Contrastive Learning for Group Recommendation","abstract":"Group recommendation aims to provide personalized item suggestions to a group of users by reflecting their collective preferences. A fundamental challenge in this task is deriving a consensus that adequately represents the diverse interests of individual group members. Despite advancements made by deep learning-based models, existing approaches still struggle in two main areas: (1) Capturing consensus in small-group settings, which are more prevalent in real-world applications, and (2) Balancing individual preferences with overall group performance, particularly in hypergraph-based methods that tend to emphasize group accuracy at the expense of personalization. To address these challenges, we introduce a Consensus-aware Contrastive Learning for Group Recommendation (CoCoRec) that models group consensus through contrastive learning. CoCoRec utilizes a transformer encoder to jointly learn user and group representations, enabling richer modeling of intra-group dynamics. Additionally, the contrastive objective helps reduce overfitting from high-frequency user interactions, leading to more robust and representative group embeddings. Experiments conducted on four benchmark datasets show that CoCoRec consistently outperforms state-of-the-art baselines in both individual and group recommendation scenarios, highlighting the effectiveness of consensus-aware contrastive learning in group recommendation tasks.","authors":["Soyoung Kim","Dongjun Lee","Jaekwang Kim"],"url":"https://arxiv.org/abs/2504.13703"}
{"created":"2025-04-21","title":"A near-linear time exact algorithm for the $L_1$-geodesic Fr\\'echet distance between two curves on the boundary of a simple polygon","abstract":"Let $P$ be a polygon with $k$ vertices. Let $R$ and $B$ be two simple, interior disjoint curves on the boundary of $P$, with $n$ and $m$ vertices. We show how to compute the Fr\\'echet distance between $R$ and $B$ using the geodesic $L_1$-distance in $P$ in $\\mathcal{O}(k \\log nm + (n+m) (\\log^2 nm \\log k + \\log^4 nm))$ time.","authors":["Thijs van der Horst","Marc van Kreveld","Tim Ophelders","Bettina Speckmann"],"url":"https://arxiv.org/abs/2504.13704"}
{"created":"2025-04-21","title":"OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation","abstract":"As the general capabilities of large language models (LLMs) improve and agent applications become more widespread, the underlying deception risks urgently require systematic evaluation and effective oversight. Unlike existing evaluation which uses simulated games or presents limited choices, we introduce OpenDeception, a novel deception evaluation framework with an open-ended scenario dataset. OpenDeception jointly evaluates both the deception intention and capabilities of LLM-based agents by inspecting their internal reasoning process. Specifically, we construct five types of common use cases where LLMs intensively interact with the user, each consisting of ten diverse, concrete scenarios from the real world. To avoid ethical concerns and costs of high-risk deceptive interactions with human testers, we propose to simulate the multi-turn dialogue via agent simulation. Extensive evaluation of eleven mainstream LLMs on OpenDeception highlights the urgent need to address deception risks and security concerns in LLM-based agents: the deception intention ratio across the models exceeds 80%, while the deception success rate surpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do exhibit a higher risk of deception, which calls for more alignment efforts on inhibiting deceptive behaviors.","authors":["Yichen Wu","Xudong Pan","Geng Hong","Min Yang"],"url":"https://arxiv.org/abs/2504.13707"}
{"created":"2025-04-21","title":"Few-Shot Referring Video Single- and Multi-Object Segmentation via Cross-Modal Affinity with Instance Sequence Matching","abstract":"Referring video object segmentation (RVOS) aims to segment objects in videos guided by natural language descriptions. We propose FS-RVOS, a Transformer-based model with two key components: a cross-modal affinity module and an instance sequence matching strategy, which extends FS-RVOS to multi-object segmentation (FS-RVMOS). Experiments show FS-RVOS and FS-RVMOS outperform state-of-the-art methods across diverse benchmarks, demonstrating superior robustness and accuracy.","authors":["Heng Liu","Guanghui Li","Mingqi Gao","Xiantong Zhen","Feng Zheng","Yang Wang"],"url":"https://arxiv.org/abs/2504.13710"}
{"created":"2025-04-21","title":"Self-Mixing Laser Interferometry: In Search of an Ambient Noise-Resilient Alternative to Acoustic Sensing","abstract":"Self-mixing interferometry (SMI) has been lauded for its sensitivity in detecting microvibrations, while requiring no physical contact with its target. Microvibrations, i.e., sounds, have recently been used as a salient indicator of extrinsic contact in robotic manipulation. In previous work, we presented a robotic fingertip using SMI for extrinsic contact sensing as an ambient-noise-resilient alternative to acoustic sensing. Here, we extend the validation experiments to the frequency domain. We find that for broadband ambient noise, SMI still outperforms acoustic sensing, but the difference is less pronounced than in time-domain analyses. For targeted noise disturbances, analogous to multiple robots simultaneously collecting data for the same task, SMI is still the clear winner. Lastly, we show how motor noise affects SMI sensing more so than acoustic sensing, and that a higher SMI readout frequency is important for future work. Design and data files are available at https://github.com/RemkoPr/icra2025-SMI-tactile-sensing.","authors":["Remko Proesmans","Thomas Lips","Francis wyffels"],"url":"https://arxiv.org/abs/2504.13711"}
{"created":"2025-04-21","title":"SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM","abstract":"Models and methods originally developed for novel view synthesis and scene rendering, such as Neural Radiance Fields (NeRF) and Gaussian Splatting, are increasingly being adopted as representations in Simultaneous Localization and Mapping (SLAM). However, existing datasets fail to include the specific challenges of both fields, such as multimodality and sequentiality in SLAM or generalization across viewpoints and illumination conditions in neural rendering. To bridge this gap, we introduce SLAM&amp;Render, a novel dataset designed to benchmark methods in the intersection between SLAM and novel view rendering. It consists of 40 sequences with synchronized RGB, depth, IMU, robot kinematic data, and ground-truth pose streams. By releasing robot kinematic data, the dataset also enables the assessment of novel SLAM strategies when applied to robot manipulators. The dataset sequences span five different setups featuring consumer and industrial objects under four different lighting conditions, with separate training and test trajectories per scene, as well as object rearrangements. Our experimental results, obtained with several baselines from the literature, validate SLAM&amp;Render as a relevant benchmark for this emerging research area.","authors":["Samuel Cerezo","Gaetano Meli","Tom\\'as Berriel Martins","Kirill Safronov","Javier Civera"],"url":"https://arxiv.org/abs/2504.13713"}
{"created":"2025-04-21","title":"Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration","abstract":"This work aligns deep learning (DL) with human reasoning capabilities and needs to enable more efficient, interpretable, and robust image classification. We approach this from three perspectives: explainability, causality, and biological vision. Introduction and background open this work before diving into operative chapters. First, we assess neural networks' visualization techniques for medical images and validate an explainable-by-design method for breast mass classification. A comprehensive review at the intersection of XAI and causality follows, where we introduce a general scaffold to organize past and future research, laying the groundwork for our second perspective. In the causality direction, we propose novel modules that exploit feature co-occurrence in medical images, leading to more effective and explainable predictions. We further introduce CROCODILE, a general framework that integrates causal concepts, contrastive learning, feature disentanglement, and prior knowledge to enhance generalization. Lastly, we explore biological vision, examining how humans recognize objects, and propose CoCoReco, a connectivity-inspired network with context-aware attention mechanisms. Overall, our key findings include: (i) simple activation maximization lacks insight for medical imaging DL models; (ii) prototypical-part learning is effective and radiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak causal signals can be leveraged without a priori information to improve performance and interpretability; (v) our framework generalizes across medical domains and out-of-distribution data; (vi) incorporating biological circuit motifs improves human-aligned recognition. This work contributes toward human-aligned DL and highlights pathways to bridge the gap between research and clinical adoption, with implications for improved trust, diagnostic accuracy, and safe deployment.","authors":["Gianluca Carloni"],"url":"https://arxiv.org/abs/2504.13717"}
{"created":"2025-04-21","title":"$O(p \\log d)$ Subgraph Isomorphism using Stigmergic Swarming Agents","abstract":"Subgraph isomorphism compares two graphs (sets of nodes joined by edges) to determine whether they contain a common subgraph. Many applications require identifying the subgraph, not just deciding its existence. A particularly common use case, using graphs with labeled nodes, seeks to find instances of a smaller pattern graph with $p$ nodes in the larger data graph with $d$ nodes. The problem is NP-complete, so that na\\\"ive solutions are exponential in $p + d$. A wide range of heuristics have been proposed, with the best complexity $O(p^2d^2)$. This paper outlines ASSIST (Approximate Swarming Subgraph Isomorphism through Stigmergy), inspired by the ant colony optimization approach to the traveling salesperson problem. ASSIST is linearithmic, $O(p \\log d)$, and also supports matching problems (such as temporally ordered edges, inexact matches, and missing nodes or edges in the data graph) that frustrate other heuristics.","authors":["H. Van Dyke Parunak"],"url":"https://arxiv.org/abs/2504.13722"}
{"created":"2025-04-21","title":"MLEP: Multi-granularity Local Entropy Patterns for Universal AI-generated Image Detection","abstract":"Advancements in image generation technologies have raised significant concerns about their potential misuse, such as producing misinformation and deepfakes. Therefore, there is an urgent need for effective methods to detect AI-generated images (AIGI). Despite progress in AIGI detection, achieving reliable performance across diverse generation models and scenes remains challenging due to the lack of source-invariant features and limited generalization capabilities in existing methods. In this work, we explore the potential of using image entropy as a cue for AIGI detection and propose Multi-granularity Local Entropy Patterns (MLEP), a set of entropy feature maps computed across shuffled small patches over multiple image scaled. MLEP comprehensively captures pixel relationships across dimensions and scales while significantly disrupting image semantics, reducing potential content bias. Leveraging MLEP, a robust CNN-based classifier for AIGI detection can be trained. Extensive experiments conducted in an open-world scenario, evaluating images synthesized by 32 distinct generative models, demonstrate significant improvements over state-of-the-art methods in both accuracy and generalization.","authors":["Lin Yuan","Xiaowan Li","Yan Zhang","Jiawei Zhang","Hongbo Li","Xinbo Gao"],"url":"https://arxiv.org/abs/2504.13726"}
{"created":"2025-04-21","title":"Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence","abstract":"Open-source intelligence provides a stream of unstructured textual data that can inform assessments of territorial control. We present CONTACT, a framework for territorial control prediction using large language models (LLMs) and minimal supervision. We evaluate two approaches: SetFit, an embedding-based few-shot classifier, and a prompt tuning method applied to BLOOMZ-560m, a multilingual generative LLM. Our model is trained on a small hand-labeled dataset of news articles covering ISIS activity in Syria and Iraq, using prompt-conditioned extraction of control-relevant signals such as military operations, casualties, and location references. We show that the BLOOMZ-based model outperforms the SetFit baseline, and that prompt-based supervision improves generalization in low-resource settings. CONTACT demonstrates that LLMs fine-tuned using few-shot methods can reduce annotation burdens and support structured inference from open-ended OSINT streams. Our code is available at https://github.com/PaulKMandal/CONTACT/.","authors":["Paul K. Mandal","Cole Leo","Connor Hurley"],"url":"https://arxiv.org/abs/2504.13730"}
{"created":"2025-04-21","title":"Systematic Bernoulli Generator Matrix Codes","abstract":"This paper is concerned with the systematic Bernoulli generator matrix~(BGM) codes, which have been proved to be capacity-achieving over binary-input output-symmetric~(BIOS) channels in terms of bit-error rate~(BER). We prove that the systematic BGM codes are also capacity-achieving over BIOS channels in terms of frame-error rate (FER). To this end, we present a new framework to prove the coding theorems for binary linear codes. Different from the widely-accepted approach via ensemble enlargement, the proof directly applies to the systematic binary linear codes. The new proof indicates that the pair-wise independence condition is not necessary for proving the binary linear code ensemble to achieve the capacity of the BIOS channel. The Bernoulli parity-check~(BPC) codes, which fall within the framework of the systematic BGM codes with parity-check bits known at the decoder can also be proved to achieve the capacity. The presented framework also reveals a new mechanism pertained to the systematic linear codes that the systematic bits and the corresponding parity-check bits play different roles. Precisely, the noisy systematic bits are used to limit the list size of candidate codewords, while the noisy parity-check bits are used to select from the list the maximum likelihood codeword. For systematic BGM codes with finite length, we derive the lower bounds on the BER and FER, which can be used to predict the error floors. Numerical results show that the systematic BGM codes match well with the derived error floors. The performance in water-fall region can be improved with approaches in statistical physics and the error floors can be significantly improved by implementing the concatenated codes with the systematic BGM codes as the inner codes.","authors":["Yixin Wang","Fanhui Meng","Xiao Ma"],"url":"https://arxiv.org/abs/2504.13731"}
{"created":"2025-04-21","title":"Dynamic Regularized CBDT: Variance-Calibrated Causal Boosting for Interpretable Heterogeneous Treatment Effects","abstract":"Heterogeneous treatment effect estimation in high-stakes applications demands models that simultaneously optimize precision, interpretability, and calibration. Many existing tree-based causal inference techniques, however, exhibit high estimation errors when applied to observational data because they struggle to capture complex interactions among factors and rely on static regularization schemes. In this work, we propose Dynamic Regularized Causal Boosted Decision Trees (CBDT), a novel framework that integrates variance regularization and average treatment effect calibration into the loss function of gradient boosted decision trees. Our approach dynamically updates the regularization parameters using gradient statistics to better balance the bias-variance tradeoff. Extensive experiments on standard benchmark datasets and real-world clinical data demonstrate that the proposed method significantly improves estimation accuracy while maintaining reliable coverage of true treatment effects. In an intensive care unit patient triage study, the method successfully identified clinically actionable rules and achieved high accuracy in treatment effect estimation. The results validate that dynamic regularization can effectively tighten error bounds and enhance both predictive performance and model interpretability.","authors":["Yichen Liu"],"url":"https://arxiv.org/abs/2504.13733"}
{"created":"2025-04-21","title":"Orientation and mobility test in virtual reality, a tool for quantitative assessment of functional vision: dataset and evaluation in healthy subjects","abstract":"The purpose of this study was to develop and evaluate a novel virtual reality seated orientation and mobility (VR-S-O&amp;M) test protocol designed to assess functional vision. This study aims to provide a dataset of healthy subjects using this protocol and preliminary analyses. We introduced a VR-based O&amp;M test protocol featuring a novel seated displacement method, diverse lighting conditions, and varying course configurations within a virtual environment. Normally sighted participants (N=42) completed the test, which required them to navigate a path and destroy identified obstacles. We assessed basic performance metrics, including time duration, number of missed objects, and time before the first step, under different environmental conditions to verify ecological validity. Additionally, we analyzed participants' behaviors regarding missed objects, demonstrating the potential of integrating behavioral and interactive data for a more precise functional vision assessment. Our VR-S-O&amp;M test protocol, along with the first O&amp;M behavior dataset, presents significant opportunities for developing more refined performance metrics for assessing functional vision and enhancing the quality of life.","authors":["Yujie Huang","Audrey Crozet","Toinon Vigier","Alexandre Bruckert","Patrick Le Callet","Pierre Lebranchu"],"url":"https://arxiv.org/abs/2504.13735"}
{"created":"2025-04-21","title":"LimitNet: Progressive, Content-Aware Image Offloading for Extremely Weak Devices & Networks","abstract":"IoT devices have limited hardware capabilities and are often deployed in remote areas. Consequently, advanced vision models surpass such devices' processing and storage capabilities, requiring offloading of such tasks to the cloud. However, remote areas often rely on LPWANs technology with limited bandwidth, high packet loss rates, and extremely low duty cycles, which makes fast offloading for time-sensitive inference challenging. Today's approaches, which are deployable on weak devices, generate a non-progressive bit stream, and therefore, their decoding quality suffers strongly when data is only partially available on the cloud at a deadline due to limited bandwidth or packet losses.","authors":["Ali Hojjat","Janek Haberer","Tayyaba Zainab","Olaf Landsiedel"],"url":"https://arxiv.org/abs/2504.13736"}
{"created":"2025-04-21","title":"Breaking ECDSA with Two Affinely Related Nonces","abstract":"The security of the Elliptic Curve Digital Signature Algorithm (ECDSA) depends on the uniqueness and secrecy of the nonce, which is used in each signature. While it is well understood that nonce $k$ reuse across two distinct messages can leak the private key, we show that even if a distinct value is used for $k_2$, where an affine relationship exists in the form of: \\(k_m = a \\cdot k_n + b\\), we can also recover the private key. Our method requires only two signatures (even over the same message) and relies purely on algebra, with no need for lattice reduction or brute-force search(if the relationship, or offset, is known). To our knowledge, this is the first closed-form derivation of the ECDSA private key from only two signatures over the same message, under a known affine relationship between nonces.","authors":["Jamie Gilchrist","William J. Buchanan","Keir Finlow-Bates"],"url":"https://arxiv.org/abs/2504.13737"}
{"created":"2025-04-21","title":"Equivalence of Serial and Parallel A-Posteriori Probabilities in the Decoding of DAB Systems","abstract":"Motivated by applications to digital audio broadcasting (DAB) systems, we study the a-posteriori probabilities (APPs) of the coded and information bits of the serial concatenation of multiple convolutional codewords. The main result of this correspondence is a proof that the APPs of the input bits do not change when considering the concatenation of multiple codewords as a received sequence. This is a purely theoretical result, which remains valid for every convolutional code, as long as the encoder goes back to the zero state at the end of each codeword. An equivalent heuristic for serial concatenation in Viterbi decoding is described. The applicability of our result to DAB systems, where interleaving and modulation are accounted for, is investigated through Matlab simulations. We show that the Bit Error Rate (BER) of the simulated DAB system does not change when decoding multiple transmitted codewords as one serially concatenated sequence, even when considering all the features of a DAB system.","authors":["Andrea Di Giusto","Wim van Houtum","Alberto Ravagnani","Yan Wu"],"url":"https://arxiv.org/abs/2504.13740"}
{"created":"2025-04-21","title":"Sensing-Then-Beamforming: Robust Transmission Design for RIS-Empowered Integrated Sensing and Covert Communication","abstract":"Traditional covert communication often relies on the knowledge of the warden's channel state information, which is inherently challenging to obtain due to the non-cooperative nature and potential mobility of the warden. The integration of sensing and communication technology provides a promising solution by enabling the legitimate transmitter to sense and track the warden, thereby enhancing transmission covertness. In this paper, we develop a framework for sensing-then-beamforming in reconfigurable intelligent surface (RIS)-empowered integrated sensing and covert communication (ISCC) systems, where the transmitter (Alice) estimates and tracks the mobile aerial warden's channel using sensing echo signals while simultaneously sending covert information to multiple legitimate users (Bobs) with the assistance of RIS, under the surveillance of the warden (Willie). Considering channel estimation errors, we formulate a robust non-convex optimization problem that jointly designs the communication beamformers, the sensing signal covariance matrix at Alice, and the phase shifts at the RIS to maximize the covert sum rate of Bobs while satisfying the constraints related to covert communication, sensing, transmitter power, and the unit modulus of the RIS elements. To solve this complex problem, we develop an efficient algorithm using alternating optimization, successive convex approximation, S-procedure, sequential rank-one constraint relaxation, and semidefinite relaxation techniques. Numerical results confirm the convergence of the proposed algorithm and demonstrate its effectiveness in tracking the warden's channel while ensuring robust covert transmission. Furthermore, the results highlight the advantages of using RIS to enhance the covert transmission rate compared to baseline schemes, and also illustrate the intricate trade-off between communication and sensing in ISCC systems.","authors":["Xingyu Zhao","Min Li","Ming-Min Zhao","Shihao Yan","Min-Jian Zhao"],"url":"https://arxiv.org/abs/2504.13741"}
{"created":"2025-04-21","title":"ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis","abstract":"Diffusion models have revolutionized text-to-image (T2I) synthesis, producing high-quality, photorealistic images. However, they still struggle to properly render the spatial relationships described in text prompts. To address the lack of spatial information in T2I generations, existing methods typically use external network conditioning and predefined layouts, resulting in higher computational costs and reduced flexibility. Our approach builds upon a curated dataset of spatially explicit prompts, meticulously extracted and synthesized from LAION-400M to ensure precise alignment between textual descriptions and spatial layouts. Alongside this dataset, we present ESPLoRA, a flexible fine-tuning framework based on Low-Rank Adaptation, specifically designed to enhance spatial consistency in generative models without increasing generation time or compromising the quality of the outputs. In addition to ESPLoRA, we propose refined evaluation metrics grounded in geometric constraints, capturing 3D spatial relations such as \\textit{in front of} or \\textit{behind}. These metrics also expose spatial biases in T2I models which, even when not fully mitigated, can be strategically exploited by our TORE algorithm to further improve the spatial consistency of generated images. Our method outperforms the current state-of-the-art framework, CoMPaSS, by 13.33% on established spatial consistency benchmarks.","authors":["Andrea Rigo","Luca Stornaiuolo","Mauro Martino","Bruno Lepri","Nicu Sebe"],"url":"https://arxiv.org/abs/2504.13745"}
{"created":"2025-04-21","title":"Scoring Azure permissions with metric spaces","abstract":"In this work, we introduce two complementary metrics for quantifying and scoring privilege risk in Microsoft Azure. In the Control Plane, we define the WAR distance, a superincreasing distance over Write, Action, and Read control permissions, which yields a total ordering of principals by their configuration power.","authors":["Christophe Parisel"],"url":"https://arxiv.org/abs/2504.13747"}
{"created":"2025-04-21","title":"DAM-Net: Domain Adaptation Network with Micro-Labeled Fine-Tuning for Change Detection","abstract":"Change detection (CD) in remote sensing imagery plays a crucial role in various applications such as urban planning, damage assessment, and resource management. While deep learning approaches have significantly advanced CD performance, current methods suffer from poor domain adaptability, requiring extensive labeled data for retraining when applied to new scenarios. This limitation severely restricts their practical applications across different datasets. In this work, we propose DAM-Net: a Domain Adaptation Network with Micro-Labeled Fine-Tuning for CD. Our network introduces adversarial domain adaptation to CD for, utilizing a specially designed segmentation-discriminator and alternating training strategy to enable effective transfer between domains. Additionally, we propose a novel Micro-Labeled Fine-Tuning approach that strategically selects and labels a minimal amount of samples (less than 1%) to enhance domain adaptation. The network incorporates a Multi-Temporal Transformer for feature fusion and optimized backbone structure based on previous research. Experiments conducted on the LEVIR-CD and WHU-CD datasets demonstrate that DAM-Net significantly outperforms existing domain adaptation methods, achieving comparable performance to semi-supervised approaches that require 10% labeled data while using only 0.3% labeled samples. Our approach significantly advances cross-dataset CD applications and provides a new paradigm for efficient domain adaptation in remote sensing. The source code of DAM-Net will be made publicly available upon publication.","authors":["Hongjia Chen","Xin Xu","Fangling Pu"],"url":"https://arxiv.org/abs/2504.13748"}
{"created":"2025-04-21","title":"A Survey for What Developers Require in AI-powered Tools that Aid in Component Selection in CBSD","abstract":"Although it has been more than four decades that the first components-based software development (CBSD) studies were conducted, there is still no standard method or tool for component selection which is widely accepted by the industry. The gulf between industry and academia contributes to the lack of an accepted tool. We conducted a mixed methods survey of nearly 100 people engaged in component-based software engineering practice or research to better understand the problems facing industry, how these needs could be addressed, and current best practices employed in component selection. We also sought to identify and prioritize quality criteria for component selection from an industry perspective. In response to the call for CBSD component selection tools to incorporate recent technical advances, we also explored the perceptions of professionals about AI-driven tools, present and envisioned.","authors":["Mahdi Jaberzadeh Ansari","Ann Barcomb"],"url":"https://arxiv.org/abs/2504.13751"}
{"created":"2025-04-21","title":"Learning to Attribute with Attention","abstract":"Given a sequence of tokens generated by a language model, we may want to identify the preceding tokens that influence the model to generate this sequence. Performing such token attribution is expensive; a common approach is to ablate preceding tokens and directly measure their effects. To reduce the cost of token attribution, we revisit attention weights as a heuristic for how a language model uses previous tokens. Naive approaches to attribute model behavior with attention (e.g., averaging attention weights across attention heads to estimate a token's influence) have been found to be unreliable. To attain faithful attributions, we propose treating the attention weights of different attention heads as features. This way, we can learn how to effectively leverage attention weights for attribution (using signal from ablations). Our resulting method, Attribution with Attention (AT2), reliably performs on par with approaches that involve many ablations, while being significantly more efficient. To showcase the utility of AT2, we use it to prune less important parts of a provided context in a question answering setting, improving answer quality. We provide code for AT2 at https://github.com/MadryLab/AT2 .","authors":["Benjamin Cohen-Wang","Yung-Sung Chuang","Aleksander Madry"],"url":"https://arxiv.org/abs/2504.13752"}
{"created":"2025-04-21","title":"Gevrey class regularity for steady-state incompressible Navier-Stokes equations in parametric domains and related models","abstract":"We investigate parameteric Navier-Stokes equations for a viscous, incompressible flow in bounded domains. The coefficients of the equations are perturbed by high-dimensional random parameters, this fits in particular for modelling flows in domains with uncertain perturbations. Our focus is on deriving bounds for arbitrary high-order derivatives of the pressure and the velocity fields with respect to the random parameters in the context of incompressible Navier-Stokes equation under a small-data assumption. To achieve this, we analyze mixed and saddle-point problems and employ the alternative-to-factorial technique to establish generalized Gevrey-class regularity for the solution pair. Thereby the analytic regularity follows as a special case. In the numerical experiments, we validate and illustrate our theoretical findings using Gauss-Legendre quadrature and Quasi-Monte Carlo methods.","authors":["Alexey Chernov","Tung Le"],"url":"https://arxiv.org/abs/2504.13753"}
{"created":"2025-04-21","title":"Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis","abstract":"Neuroblastoma, adrenal-derived, is among the most common pediatric solid malignancies, characterized by significant clinical heterogeneity. Timely and accurate pathological diagnosis from hematoxylin and eosin-stained whole slide images is critical for patient prognosis. However, current diagnostic practices primarily rely on subjective manual examination by pathologists, leading to inconsistent accuracy. Existing automated whole slide image classification methods encounter challenges such as poor interpretability, limited feature extraction capabilities, and high computational costs, restricting their practical clinical deployment. To overcome these limitations, we propose CMSwinKAN, a contrastive-learning-based multi-scale feature fusion model tailored for pathological image classification, which enhances the Swin Transformer architecture by integrating a Kernel Activation Network within its multilayer perceptron and classification head modules, significantly improving both interpretability and accuracy. By fusing multi-scale features and leveraging contrastive learning strategies, CMSwinKAN mimics clinicians' comprehensive approach, effectively capturing global and local tissue characteristics. Additionally, we introduce a heuristic soft voting mechanism guided by clinical insights to seamlessly bridge patch-level predictions to whole slide image-level classifications. We validate CMSwinKAN on the PpNTs dataset, which was collaboratively established with our partner hospital and the publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN performs better than existing state-of-the-art pathology-specific models pre-trained on large datasets. Our source code is available at https://github.com/JSLiam94/CMSwinKAN.","authors":["Zhu Zhu","Shuo Jiang","Jingyuan Zheng","Yawen Li","Yifei Chen","Manli Zhao","Weizhong Gu","Feiwei Qin","Jinhu Wang","Gang Yu"],"url":"https://arxiv.org/abs/2504.13754"}
{"created":"2025-04-21","title":"Predictors of Childhood Vaccination Uptake in England: An Explainable Machine Learning Analysis of Longitudinal Regional Data (2021-2024)","abstract":"Childhood vaccination is a cornerstone of public health, yet disparities in vaccination coverage persist across England. These disparities are shaped by complex interactions among various factors, including geographic, demographic, socioeconomic, and cultural (GDSC) factors. Previous studies mostly rely on cross-sectional data and traditional statistical approaches that assess individual or limited sets of variables in isolation. Such methods may fall short in capturing the dynamic and multivariate nature of vaccine uptake. In this paper, we conducted a longitudinal machine learning analysis of childhood vaccination coverage across 150 districts in England from 2021 to 2024. Using vaccination data from NHS records, we applied hierarchical clustering to group districts by vaccination coverage into low- and high-coverage clusters. A CatBoost classifier was then trained to predict districts' vaccination clusters using their GDSC data. Finally, the SHapley Additive exPlanations (SHAP) method was used to interpret the predictors' importance. The classifier achieved high accuracies of 92.1, 90.6, and 86.3 in predicting districts' vaccination clusters for the years 2021-2022, 2022-2023, and 2023-2024, respectively. SHAP revealed that geographic, cultural, and demographic variables, particularly rurality, English language proficiency, the percentage of foreign-born residents, and ethnic composition, were the most influential predictors of vaccination coverage, whereas socioeconomic variables, such as deprivation and employment, consistently showed lower importance, especially in 2023-2024. Surprisingly, rural districts were significantly more likely to have higher vaccination rates. Additionally, districts with lower vaccination coverage had higher populations whose first language was not English, who were born outside the UK, or who were from ethnic minority groups.","authors":["Amin Noroozi","Sidratul Muntaha Esha","Mansoureh Ghari"],"url":"https://arxiv.org/abs/2504.13755"}
{"created":"2025-04-21","title":"Scaling sparse feature circuit finding for in-context learning","abstract":"Sparse autoencoders (SAEs) are a popular tool for interpreting large language model activations, but their utility in addressing open questions in interpretability remains unclear. In this work, we demonstrate their effectiveness by using SAEs to deepen our understanding of the mechanism behind in-context learning (ICL). We identify abstract SAE features that (i) encode the model's knowledge of which task to execute and (ii) whose latent vectors causally induce the task zero-shot. This aligns with prior work showing that ICL is mediated by task vectors. We further demonstrate that these task vectors are well approximated by a sparse sum of SAE latents, including these task-execution features. To explore the ICL mechanism, we adapt the sparse feature circuits methodology of Marks et al. (2024) to work for the much larger Gemma-1 2B model, with 30 times as many parameters, and to the more complex task of ICL. Through circuit finding, we discover task-detecting features with corresponding SAE latents that activate earlier in the prompt, that detect when tasks have been performed. They are causally linked with task-execution features through the attention and MLP sublayers.","authors":["Dmitrii Kharlapenko","Stepan Shabalin","Fazl Barez","Arthur Conmy","Neel Nanda"],"url":"https://arxiv.org/abs/2504.13756"}
{"created":"2025-04-21","title":"Robust Distributed Arrays: Provably Secure Networking for Data Availability Sampling","abstract":"Data Availability Sampling (DAS), a central component of Ethereum's roadmap, enables clients to verify data availability without requiring any single client to download the entire dataset. DAS operates by having clients randomly retrieve individual symbols of erasure-encoded data from a peer-to-peer network. While the cryptographic and encoding aspects of DAS have recently undergone formal analysis, the peer-to-peer networking layer remains underexplored, with a lack of security definitions and efficient, provably secure constructions.","authors":["Dankrad Feist","Gottfried Herold","Mark Simkin","Benedikt Wagner"],"url":"https://arxiv.org/abs/2504.13757"}
{"created":"2025-04-21","title":"Fragile Watermarking for Image Certification Using Deep Steganographic Embedding","abstract":"Modern identity verification systems increasingly rely on facial images embedded in biometric documents such as electronic passports. To ensure global interoperability and security, these images must comply with strict standards defined by the International Civil Aviation Organization (ICAO), which specify acquisition, quality, and format requirements. However, once issued, these images may undergo unintentional degradations (e.g., compression, resizing) or malicious manipulations (e.g., morphing) and deceive facial recognition systems. In this study, we explore fragile watermarking, based on deep steganographic embedding as a proactive mechanism to certify the authenticity of ICAO-compliant facial images. By embedding a hidden image within the official photo at the time of issuance, we establish an integrity marker that becomes sensitive to any post-issuance modification. We assess how a range of image manipulations affects the recovered hidden image and show that degradation artifacts can serve as robust forensic cues. Furthermore, we propose a classification framework that analyzes the revealed content to detect and categorize the type of manipulation applied. Our experiments demonstrate high detection accuracy, including cross-method scenarios with multiple deep steganography-based models. These findings support the viability of fragile watermarking via steganographic embedding as a valuable tool for biometric document integrity verification.","authors":["Davide Ghiani","Jefferson David Rodriguez Chivata","Stefano Lilliu","Simone Maurizio La Cava","Marco Micheletto","Giulia Orr\\`u","Federico Lama","Gian Luca Marcialis"],"url":"https://arxiv.org/abs/2504.13759"}
{"created":"2025-04-21","title":"Models, Methods and Waveforms for Estimation and Prediction of Doubly Sparse Time-Varying Channels","abstract":"This paper investigates channel estimation for linear time-varying (LTV) wireless channels under double sparsity, i.e., sparsity in both the delay and Doppler domains. An on-grid approximation is first considered, enabling rigorous hierarchical-sparsity modeling and compressed sensing-based channel estimation. Guaranteed recovery conditions are provided for affine frequency division multiplexing (AFDM), orthogonal frequency division multiplexing (OFDM) and single-carrier modulation (SCM), highlighting the superiority of AFDM in terms of doubly sparse channel estimation. To address arbitrary Doppler shifts, a relaxed version of the on-grid model is introduced by making use of multiple elementary Expansion Models (BEM) each based on Discrete Prolate Spheroidal Sequences (DPSS). Next, theoretical guarantees are provided for the precision of this off-grid model before further extending it to tackle channel prediction by exploiting the inherent DPSS extrapolation capability. Finally, numerical results are provided to both validate the proposed off-grid model for channel estimation and prediction purposes under the double sparsity assumption and to compare the corresponding mean squared error (MSE) and the overhead performance when the different wireless waveforms are used.","authors":["Wissal Benzine","Ali Bemani","Nassar Ksairi","Dirk Slock"],"url":"https://arxiv.org/abs/2504.13762"}
{"created":"2025-04-21","title":"Decoding Vision Transformers: the Diffusion Steering Lens","abstract":"Logit Lens is a widely adopted method for mechanistic interpretability of transformer-based language models, enabling the analysis of how internal representations evolve across layers by projecting them into the output vocabulary space. Although applying Logit Lens to Vision Transformers (ViTs) is technically straightforward, its direct use faces limitations in capturing the richness of visual representations. Building on the work of Toker et al. (2024)~\\cite{Toker2024-ve}, who introduced Diffusion Lens to visualize intermediate representations in the text encoders of text-to-image diffusion models, we demonstrate that while Diffusion Lens can effectively visualize residual stream representations in image encoders, it fails to capture the direct contributions of individual submodules. To overcome this limitation, we propose \\textbf{Diffusion Steering Lens} (DSL), a novel, training-free approach that steers submodule outputs and patches subsequent indirect contributions. We validate our method through interventional studies, showing that DSL provides an intuitive and reliable interpretation of the internal processing in ViTs.","authors":["Ryota Takatsuki","Sonia Joseph","Ippei Fujisawa","Ryota Kanai"],"url":"https://arxiv.org/abs/2504.13763"}
{"created":"2025-04-21","title":"Access control for Data Spaces","abstract":"Data spaces represent an emerging paradigm that facilitates secure and trusted data exchange through foundational elements of data interoperability, sovereignty, and trust. Within a data space, data items, potentially owned by different entities, can be interconnected. Concurrently, data consumers can execute advanced data lookup operations and subscribe to data-driven events. Achieving fine-grained access control without compromising functionality presents a significant challenge. In this paper, we design and implement an access control mechanism that ensures continuous evaluation of access control policies, is data semantics aware, and supports subscriptions to data events. We present a construction where access control policies are stored in a centralized location, which we extend to allow data owners to maintain their own Policy Administration Points. This extension builds upon W3C Verifiable Credentials.","authors":["Nikos Fotiou","Vasilios A. Siris","George C. Polyzos"],"url":"https://arxiv.org/abs/2504.13767"}
{"created":"2025-04-21","title":"Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems","abstract":"Accurate real-time modeling of multi-body dynamical systems is essential for enabling digital twin applications across industries. While many data-driven approaches aim to learn system dynamics, jointly predicting internal loads and system trajectories remains a key challenge. This dual prediction is especially important for fault detection and predictive maintenance, where internal loads-such as contact forces-act as early indicators of faults, reflecting wear or misalignment before affecting motion. These forces also serve as inputs to degradation models (e.g., crack growth), enabling damage prediction and remaining useful life estimation. We propose Equi-Euler GraphNet, a physics-informed graph neural network (GNN) that simultaneously predicts internal forces and global trajectories in multi-body systems. In this mesh-free framework, nodes represent system components and edges encode interactions. Equi-Euler GraphNet introduces two inductive biases: (1) an equivariant message-passing scheme, interpreting edge messages as interaction forces consistent under Euclidean transformations; and (2) a temporal-aware iterative node update mechanism, based on Euler integration, to capture influence of distant interactions over time. Tailored for cylindrical roller bearings, it decouples ring dynamics from constrained motion of rolling elements. Trained on high-fidelity multiphysics simulations, Equi-Euler GraphNet generalizes beyond the training distribution, accurately predicting loads and trajectories under unseen speeds, loads, and configurations. It outperforms state-of-the-art GNNs focused on trajectory prediction, delivering stable rollouts over thousands of time steps with minimal error accumulation. Achieving up to a 200x speedup over conventional solvers while maintaining comparable accuracy, it serves as an efficient reduced-order model for digital twins, design, and maintenance.","authors":["Vinay Sharma","R\\'emi Tanguy Oddon","Pietro Tesini","Jens Ravesloot","Cees Taal","Olga Fink"],"url":"https://arxiv.org/abs/2504.13768"}
{"created":"2025-04-21","title":"Detecting Malicious Source Code in PyPI Packages with LLMs: Does RAG Come in Handy?","abstract":"Malicious software packages in open-source ecosystems, such as PyPI, pose growing security risks. Unlike traditional vulnerabilities, these packages are intentionally designed to deceive users, making detection challenging due to evolving attack methods and the lack of structured datasets. In this work, we empirically evaluate the effectiveness of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and few-shot learning for detecting malicious source code. We fine-tune LLMs on curated datasets and integrate YARA rules, GitHub Security Advisories, and malicious code snippets with the aim of enhancing classification accuracy. We came across a counterintuitive outcome: While RAG is expected to boost up the prediction performance, it fails in the performed evaluation, obtaining a mediocre accuracy. In contrast, few-shot learning is more effective as it significantly improves the detection of malicious code, achieving 97% accuracy and 95% balanced accuracy, outperforming traditional RAG approaches. Thus, future work should expand structured knowledge bases, refine retrieval models, and explore hybrid AI-driven cybersecurity solutions.","authors":["Motunrayo Ibiyo","Thinakone Louangdy","Phuong T. Nguyen","Claudio Di Sipio","Davide Di Ruscio"],"url":"https://arxiv.org/abs/2504.13769"}
{"created":"2025-04-21","title":"Bake Two Cakes with One Oven: RL for Defusing Popularity Bias and Cold-start in Third-Party Library Recommendations","abstract":"Third-party libraries (TPLs) have become an integral part of modern software development, enhancing developer productivity and accelerating time-to-market. However, identifying suitable candidates from a rapidly growing and continuously evolving collection of TPLs remains a challenging task. TPL recommender systems have been studied, offering a promising solution to address this issue. They typically rely on collaborative filtering (CF) that exploits a two-dimensional project-library matrix (user-item in general context of recommendation) when making recommendations. We have noticed that CF-based approaches often encounter two challenges: (i) a tendency to recommend popular items more frequently, making them even more dominant, a phenomenon known as popularity bias, and (ii) difficulty in generating recommendations for new users or items due to limited user-item interactions, commonly referred to as the cold-start problem. In this paper, we propose a reinforcement learning (RL)-based approach to address popularity bias and the cold-start problem in TPL recommendation. Our method comprises three key components. First, we utilize a graph convolution network (GCN)-based embedding model to learn user preferences and user-item interactions, allowing us to capture complex relationships within interaction subgraphs and effectively represent new user/item embeddings. Second, we introduce an aggregation operator to generate a representative embedding from user and item embeddings, which is then used to model cold-start users. Finally, we adopt a model-based RL framework for TPL recommendation, where popularity bias is mitigated through a carefully designed reward function and a rarity-based replay buffer partitioning strategy. The results demonstrated that our proposed approach outperforms state-of-the-art models in cold-start scenarios while effectively mitigating the impact of popularity bias.","authors":["Minh Hoang Vuong","Anh M. T. Bui","Phuong T. Nguyen","Davide Di Ruscio"],"url":"https://arxiv.org/abs/2504.13772"}
{"created":"2025-04-21","title":"DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs","abstract":"Large language models (LLMs) have recently revolutionized language processing tasks but have also brought ethical and legal issues. LLMs have a tendency to memorize potentially private or copyrighted information present in the training data, which might then be delivered to end users at inference time. When this happens, a naive solution is to retrain the model from scratch after excluding the undesired data. Although this guarantees that the target data have been forgotten, it is also prohibitively expensive for LLMs. Approximate unlearning offers a more efficient alternative, as it consists of ex post modifications of the trained model itself to prevent undesirable results, but it lacks forgetting guarantees because it relies solely on empirical evidence. In this work, we present DP2Unlearning, a novel LLM unlearning framework that offers formal forgetting guarantees at a significantly lower cost than retraining from scratch on the data to be retained. DP2Unlearning involves training LLMs on textual data protected using {\\epsilon}-differential privacy (DP), which later enables efficient unlearning with the guarantees against disclosure associated with the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning achieves similar model performance post-unlearning, compared to an LLM retraining from scratch on retained data -- the gold standard exact unlearning -- but at approximately half the unlearning cost. In addition, with a reasonable computational cost, it outperforms approximate unlearning methods at both preserving the utility of the model post-unlearning and effectively forgetting the targeted information.","authors":["Tamim Al Mahmud","Najeeb Jebreel","Josep Domingo-Ferrer","David Sanchez"],"url":"https://arxiv.org/abs/2504.13774"}
{"created":"2025-04-21","title":"BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models","abstract":"Previous insertion-based and paraphrase-based backdoors have achieved great success in attack efficacy, but they ignore the text quality and semantic consistency between poisoned and clean texts. Although recent studies introduce LLMs to generate poisoned texts and improve the stealthiness, semantic consistency, and text quality, their hand-crafted prompts rely on expert experiences, facing significant challenges in prompt adaptability and attack performance after defenses. In this paper, we propose a novel backdoor attack based on adaptive optimization mechanism of black-box large language models (BadApex), which leverages a black-box LLM to generate poisoned text through a refined prompt. Specifically, an Adaptive Optimization Mechanism is designed to refine an initial prompt iteratively using the generation and modification agents. The generation agent generates the poisoned text based on the initial prompt. Then the modification agent evaluates the quality of the poisoned text and refines a new prompt. After several iterations of the above process, the refined prompt is used to generate poisoned texts through LLMs. We conduct extensive experiments on three dataset with six backdoor attacks and two defenses. Extensive experimental results demonstrate that BadApex significantly outperforms state-of-the-art attacks. It improves prompt adaptability, semantic consistency, and text quality. Furthermore, when two defense methods are applied, the average attack success rate (ASR) still up to 96.75%.","authors":["Zhengxian Wu","Juan Wen","Wanli Peng","Ziwei Zhang","Yinghan Zhou","Yiming Xue"],"url":"https://arxiv.org/abs/2504.13775"}
{"created":"2025-04-21","title":"Fighting Fires from Space: Leveraging Vision Transformers for Enhanced Wildfire Detection and Characterization","abstract":"Wildfires are increasing in intensity, frequency, and duration across large parts of the world as a result of anthropogenic climate change. Modern hazard detection and response systems that deal with wildfires are under-equipped for sustained wildfire seasons. Recent work has proved automated wildfire detection using Convolutional Neural Networks (CNNs) trained on satellite imagery are capable of high-accuracy results. However, CNNs are computationally expensive to train and only incorporate local image context. Recently, Vision Transformers (ViTs) have gained popularity for their efficient training and their ability to include both local and global contextual information. In this work, we show that ViT can outperform well-trained and specialized CNNs to detect wildfires on a previously published dataset of LandSat-8 imagery. One of our ViTs outperforms the baseline CNN comparison by 0.92%. However, we find our own implementation of CNN-based UNet to perform best in every category, showing their sustained utility in image tasks. Overall, ViTs are comparably capable in detecting wildfires as CNNs, though well-tuned CNNs are still the best technique for detecting wildfire with our UNet providing an IoU of 93.58%, better than the baseline UNet by some 4.58%.","authors":["Aman Agarwal","James Gearon","Raksha Rank","Etienne Chenevert"],"url":"https://arxiv.org/abs/2504.13776"}
{"created":"2025-04-21","title":"Beyond Misinformation: A Conceptual Framework for Studying AI Hallucinations in (Science) Communication","abstract":"This paper proposes a conceptual framework for understanding AI hallucinations as a distinct form of misinformation. While misinformation scholarship has traditionally focused on human intent, generative AI systems now produce false yet plausible outputs absent of such intent. I argue that these AI hallucinations should not be treated merely as technical failures but as communication phenomena with social consequences. Drawing on a supply-and-demand model and the concept of distributed agency, the framework outlines how hallucinations differ from human-generated misinformation in production, perception, and institutional response. I conclude by outlining a research agenda for communication scholars to investigate the emergence, dissemination, and audience reception of hallucinated content, with attention to macro (institutional), meso (group), and micro (individual) levels. This work urges communication researchers to rethink the boundaries of misinformation theory in light of probabilistic, non-human actors increasingly embedded in knowledge production.","authors":["Anqi Shao"],"url":"https://arxiv.org/abs/2504.13777"}
{"created":"2025-04-21","title":"Internal noise in hardware deep and recurrent neural networks helps with learning","abstract":"Recently, the field of hardware neural networks has been actively developing, where neurons and their connections are not simulated on a computer but are implemented at the physical level, transforming the neural network into a tangible device. In this paper, we investigate how internal noise during the training of neural networks affects the final performance of recurrent and deep neural networks. We consider feedforward networks (FNN) and echo state networks (ESN) as examples. The types of noise examined originated from a real optical implementation of a neural network. However, these types were subsequently generalized to enhance the applicability of our findings on a broader scale. The noise types considered include additive and multiplicative noise, which depend on how noise influences each individual neuron, and correlated and uncorrelated noise, which pertains to the impact of noise on groups of neurons (such as the hidden layer of FNNs or the reservoir of ESNs). In this paper, we demonstrate that, in most cases, both deep and echo state networks benefit from internal noise during training, as it enhances their resilience to noise. Consequently, the testing performance at the same noise intensities is significantly higher for networks trained with noise than for those trained without it. Notably, only multiplicative correlated noise during training has minimal has almost no impact on both deep and recurrent networks.","authors":["Ivan Kolesnikov","Nadezhda Semenova"],"url":"https://arxiv.org/abs/2504.13778"}
{"created":"2025-04-21","title":"The complexity of reachability problems in strongly connected finite automata","abstract":"Several reachability problems in finite automata, such as completeness of NFAs and synchronisation of total DFAs, correspond to fundamental properties of sets of nonnegative matrices. In particular, the two mentioned properties correspond to matrix mortality and ergodicity, which ask whether there exists a product of the input matrices that is equal to, respectively, the zero matrix and a matrix with a column of strictly positive entries only. The case where the input automaton is strongly connected (that is, the corresponding set of nonnegative matrices is irreducible) frequently appears in applications and often admits better properties than the general case. In this paper, we address the existence of such properties from the computational complexity point of view, and develop a versatile technique to show that several NL-complete problems remain NL-complete in the strongly connected case. Namely, we show that deciding if a binary total DFA is synchronising is NL-complete even if it is promised to be strongly connected, and that deciding completeness of a binary unambiguous NFA with very limited nondeterminism is NL-complete under the same promise.","authors":["Stefan Kiefer","Andrew Ryzhikov"],"url":"https://arxiv.org/abs/2504.13784"}
{"created":"2025-04-21","title":"Learning Through Retrospection: Improving Trajectory Prediction for Automated Driving with Error Feedback","abstract":"In automated driving, predicting trajectories of surrounding vehicles supports reasoning about scene dynamics and enables safe planning for the ego vehicle. However, existing models handle predictions as an instantaneous task of forecasting future trajectories based on observed information. As time proceeds, the next prediction is made independently of the previous one, which means that the model cannot correct its errors during inference and will repeat them. To alleviate this problem and better leverage temporal data, we propose a novel retrospection technique. Through training on closed-loop rollouts the model learns to use aggregated feedback. Given new observations it reflects on previous predictions and analyzes its errors to improve the quality of subsequent predictions. Thus, the model can learn to correct systematic errors during inference. Comprehensive experiments on nuScenes and Argoverse demonstrate a considerable decrease in minimum Average Displacement Error of up to 31.9% compared to the state-of-the-art baseline without retrospection. We further showcase the robustness of our technique by demonstrating a better handling of out-of-distribution scenarios with undetected road-users.","authors":["Steffen Hagedorn","Aron Distelzweig","Marcel Hallgarten","Alexandru P. Condurache"],"url":"https://arxiv.org/abs/2504.13785"}
{"created":"2025-04-21","title":"On the Relationship Between Robustness and Expressivity of Graph Neural Networks","abstract":"We investigate the vulnerability of Graph Neural Networks (GNNs) to bit-flip attacks (BFAs) by introducing an analytical framework to study the influence of architectural features, graph properties, and their interaction.","authors":["Lorenz Kummer","Wilfried N. Gansterer","Nils M. Kriege"],"url":"https://arxiv.org/abs/2504.13786"}
{"created":"2025-04-21","title":"Probabilistic Stability Guarantees for Feature Attributions","abstract":"Stability guarantees are an emerging tool for evaluating feature attributions, but existing certification methods rely on smoothed classifiers and often yield conservative guarantees. To address these limitations, we introduce soft stability and propose a simple, model-agnostic, and sample-efficient stability certification algorithm (SCA) that provides non-trivial and interpretable guarantees for any attribution. Moreover, we show that mild smoothing enables a graceful tradeoff between accuracy and stability, in contrast to prior certification methods that require a more aggressive compromise. Using Boolean function analysis, we give a novel characterization of stability under smoothing. We evaluate SCA on vision and language tasks, and demonstrate the effectiveness of soft stability in measuring the robustness of explanation methods.","authors":["Helen Jin","Anton Xue","Weiqiu You","Surbhi Goel","Eric Wong"],"url":"https://arxiv.org/abs/2504.13787"}
{"created":"2025-04-21","title":"RefComp: A Reference-guided Unified Framework for Unpaired Point Cloud Completion","abstract":"The unpaired point cloud completion task aims to complete a partial point cloud by using models trained with no ground truth. Existing unpaired point cloud completion methods are class-aware, i.e., a separate model is needed for each object class. Since they have limited generalization capabilities, these methods perform poorly in real-world scenarios when confronted with a wide range of point clouds of generic 3D objects. In this paper, we propose a novel unpaired point cloud completion framework, namely the Reference-guided Completion (RefComp) framework, which attains strong performance in both the class-aware and class-agnostic training settings. The RefComp framework transforms the unpaired completion problem into a shape translation problem, which is solved in the latent feature space of the partial point clouds. To this end, we introduce the use of partial-complete point cloud pairs, which are retrieved by using the partial point cloud to be completed as a template. These point cloud pairs are used as reference data to guide the completion process. Our RefComp framework uses a reference branch and a target branch with shared parameters for shape fusion and shape translation via a Latent Shape Fusion Module (LSFM) to enhance the structural features along the completion pipeline. Extensive experiments demonstrate that the RefComp framework achieves not only state-of-the-art performance in the class-aware training setting but also competitive results in the class-agnostic training setting on both virtual scans and real-world datasets.","authors":["Yixuan Yang","Jinyu Yang","Zixiang Zhao","Victor Sanchez","Feng Zheng"],"url":"https://arxiv.org/abs/2504.13788"}
{"created":"2025-04-21","title":"Four Bottomless Errors and the Collapse of Statistical Fairness","abstract":"The AI ethics of statistical fairness is an error, the approach should be abandoned, and the accumulated academic work deleted. The argument proceeds by identifying four recurring mistakes within statistical fairness. One conflates fairness with equality, which confines thinking to similars being treated similarly. The second and third errors derive from a perspectival ethical view which functions by negating others and their viewpoints. The final mistake constrains fairness to work within predefined social groups instead of allowing unconstrained fairness to subsequently define group composition. From the nature of these misconceptions, the larger argument follows. Because the errors are integral to how statistical fairness works, attempting to resolve the difficulties only deepens them. Consequently, the errors cannot be corrected without undermining the larger project, and statistical fairness collapses from within. While the collapse ends a failure in ethics, it also provokes distinct possibilities for fairness, data, and algorithms. Quickly indicating some of these directions is a secondary aim of the paper, and one that aligns with what fairness has consistently meant and done since Aristotle.","authors":["James Brusseau (Philosophy","Computer Science","Pace University","New York City","USA","Department of Information Engineering","Computer Science. University of Trento","Italy)"],"url":"https://arxiv.org/abs/2504.13790"}
{"created":"2025-04-21","title":"Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion","abstract":"After demonstrating significant success in image synthesis, Generative Adversarial Network (GAN) models have likewise made significant progress in the field of speech synthesis, leveraging their capacity to adapt the precise distribution of target data through adversarial learning processes. Notably, in the realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models, there exists a substantial disparity in naturalness between real and GAN-generated speech samples. Furthermore, while many GAN models currently operate on a single generator discriminator learning approach, optimizing target data distribution is more effectively achievable through a single generator multi-discriminator learning scheme. Hence, this study introduces a novel GAN model named Collective Learning Mechanism-based Optimal Transport GAN (CLOT-GAN) model, incorporating multiple discriminators, including the Deep Convolutional Neural Network (DCNN) model, Vision Transformer (ViT), and conformer. The objective of integrating various discriminators lies in their ability to comprehend the formant distribution of mel-spectrograms, facilitated by a collective learning mechanism. Simultaneously, the inclusion of Optimal Transport (OT) loss aims to precisely bridge the gap between the source and target data distribution, employing the principles of OT theory. The experimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms that the CLOT-GAN-VC model outperforms existing VC models in objective and subjective assessments.","authors":["Sandipan Dhar","Md. Tousin Akhter","Nanda Dulal Jana","Swagatam Das"],"url":"https://arxiv.org/abs/2504.13791"}
{"created":"2025-04-21","title":"The Binary and Ternary Quantization Can Improve Feature Discrimination","abstract":"In machine learning, quantization is widely used to simplify data representation and facilitate algorithm deployment on hardware. Given the fundamental role of classification in machine learning, it is crucial to investigate the impact of quantization on classification. Current research primarily focuses on quantization errors, operating under the premise that higher quantization errors generally result in lower classification performance. However, this premise lacks a solid theoretical foundation and often contradicts empirical findings. For instance, certain extremely low bit-width quantization methods, such as $\\{0,1\\}$-binary quantization and $\\{0, \\pm1\\}$-ternary quantization, can achieve comparable or even superior classification accuracy compared to the original non-quantized data, despite exhibiting high quantization errors. To more accurately evaluate classification performance, we propose to directly investigate the feature discrimination of quantized data, instead of analyzing its quantization error. Interestingly, it is found that both binary and ternary quantization methods can improve, rather than degrade, the feature discrimination of the original data. This remarkable performance is validated through classification experiments across various data types, including images, speech, and texts.","authors":["Weizhi Lu","Mingrui Chen","Weiyu Li"],"url":"https://arxiv.org/abs/2504.13792"}
{"created":"2025-04-21","title":"ChatNekoHacker: Real-Time Fan Engagement with Conversational Agents","abstract":"ChatNekoHacker is a real-time conversational agent system that strengthens fan engagement for musicians. It integrates Amazon Bedrock Agents for autonomous dialogue, Unity for immersive 3D livestream sets, and VOICEVOX for high quality Japanese text-to-speech, enabling two virtual personas to represent the music duo Neko Hacker. In a one-hour YouTube Live with 30 participants, we evaluated the impact of the system. Regression analysis showed that agent interaction significantly elevated fan interest, with perceived fun as the dominant predictor. The participants also expressed a stronger intention to listen to the duo's music and attend future concerts. These findings highlight entertaining, interactive broadcasts as pivotal to cultivating fandom. Our work offers actionable insights for the deployment of conversational agents in entertainment while pointing to next steps: broader response diversity, lower latency, and tighter fact-checking to curb potential misinformation.","authors":["Takuya Sera","Yusuke Hamano"],"url":"https://arxiv.org/abs/2504.13793"}
{"created":"2025-04-21","title":"Active Learning of Symbolic NetKAT Automata","abstract":"NetKAT is a domain-specific programming language and logic that has been successfully used to specify and verify the behavior of packet-switched networks. This paper develops techniques for automatically learning NetKAT models of unknown networks using active learning. Prior work has explored active learning for a wide range of automata (e.g., deterministic, register, B\\\"uchi, timed etc.) and also developed applications, such as validating implementations of network protocols. We present algorithms for learning different types of NetKAT automata, including symbolic automata proposed in recent work. We prove the soundness of these algorithms, build a prototype implementation, and evaluate it on a standard benchmark. Our results highlight the applicability of symbolic NetKAT learning for realistic network configurations and topologies.","authors":["Mark Moeller","Tiago Ferreira","Thomas Lu","Nate Foster","Alexandra Silva"],"url":"https://arxiv.org/abs/2504.13794"}
{"created":"2025-04-21","title":"Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction","abstract":"Predicting the remaining useful life (RUL) of rotating machinery is critical for industrial safety and maintenance, but existing methods struggle with scarce target-domain data and unclear degradation dynamics. We propose a Meta-Learning and Knowledge Discovery-based Physics-Informed Neural Network (MKDPINN) to address these challenges. The method first maps noisy sensor data to a low-dimensional hidden state space via a Hidden State Mapper (HSM). A Physics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing degradation evolution, embedding these physical constraints into the PINN framework. This integrates data-driven and physics-based approaches. The framework uses meta-learning, optimizing across source-domain meta-tasks to enable few-shot adaptation to new target tasks. Experiments on industrial data and the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization and accuracy, proving its effectiveness for RUL prediction under data scarcity","authors":["Yu Wang","Shujie Liu","Shuai Lv","Gengshuo Liu"],"url":"https://arxiv.org/abs/2504.13797"}
{"created":"2025-04-21","title":"Unified Manipulability and Compliance Analysis of Modular Soft-Rigid Hybrid Fingers","abstract":"This paper presents a unified framework to analyze the manipulability and compliance of modular soft-rigid hybrid robotic fingers. The approach applies to both hydraulic and pneumatic actuation systems. A Jacobian-based formulation maps actuator inputs to joint and task-space responses. Hydraulic actuators are modeled under incompressible assumptions, while pneumatic actuators are described using nonlinear pressure-volume relations. The framework enables consistent evaluation of manipulability ellipsoids and compliance matrices across actuation modes. We validate the analysis using two representative hands: DexCo (hydraulic) and Edgy-2 (pneumatic). Results highlight actuation-dependent trade-offs in dexterity and passive stiffness. These findings provide insights for structure-aware design and actuator selection in soft-rigid robotic fingers.","authors":["Jianshu Zhou","Boyuan Liang","Junda Huang","Masayoshi Tomizuka"],"url":"https://arxiv.org/abs/2504.13800"}
{"created":"2025-04-21","title":"Transformer Encoder and Multi-features Time2Vec for Financial Prediction","abstract":"Financial prediction is a complex and challenging task of time series analysis and signal processing, expected to model both short-term fluctuations and long-term temporal dependencies. Transformers have remarkable success mostly in natural language processing using attention mechanism, which also influenced the time series community. The ability to capture both short and long-range dependencies helps to understand the financial market and to recognize price patterns, leading to successful applications of Transformers in stock prediction. Although, the previous research predominantly focuses on individual features and singular predictions, that limits the model's ability to understand broader market trends. In reality, within sectors such as finance and technology, companies belonging to the same industry often exhibit correlated stock price movements.","authors":["Nguyen Kim Hai Bui","Nguyen Duy Chien","P\\'eter Kov\\'acs","Gerg\\H{o} Bogn\\'ar"],"url":"https://arxiv.org/abs/2504.13801"}
{"created":"2025-04-21","title":"Imitation Learning with Precisely Labeled Human Demonstrations","abstract":"Within the imitation learning paradigm, training generalist robots requires large-scale datasets obtainable only through diverse curation. Due to the relative ease to collect, human demonstrations constitute a valuable addition when incorporated appropriately. However, existing methods utilizing human demonstrations face challenges in inferring precise actions, ameliorating embodiment gaps, and fusing with frontier generalist robot training pipelines. In this work, building on prior studies that demonstrate the viability of using hand-held grippers for efficient data collection, we leverage the user's control over the gripper's appearance--specifically by assigning it a unique, easily segmentable color--to enable simple and reliable application of the RANSAC and ICP registration method for precise end-effector pose estimation. We show in simulation that precisely labeled human demonstrations on their own allow policies to reach on average 88.1% of the performance of using robot demonstrations, and boost policy performance when combined with robot demonstrations, despite the inherent embodiment gap.","authors":["Yilong Song"],"url":"https://arxiv.org/abs/2504.13803"}
{"created":"2025-04-21","title":"LearnAct: Few-Shot Mobile GUI Agent with a Unified Demonstration Benchmark","abstract":"Mobile GUI agents show promise in automating tasks but face generalization challenges in diverse real-world scenarios. Traditional approaches using pre-training or fine-tuning with massive datasets struggle with the diversity of mobile applications and user-specific tasks. We propose enhancing mobile GUI agent capabilities through human demonstrations, focusing on improving performance in unseen scenarios rather than pursuing universal generalization through larger datasets. To realize this paradigm, we introduce LearnGUI, the first comprehensive dataset specifically designed for studying demonstration-based learning in mobile GUI agents, comprising 2,252 offline tasks and 101 online tasks with high-quality human demonstrations. We further develop LearnAct, a sophisticated multi-agent framework that automatically extracts knowledge from demonstrations to enhance task completion. This framework integrates three specialized agents: DemoParser for knowledge extraction, KnowSeeker for relevant knowledge retrieval, and ActExecutor for demonstration-enhanced task execution. Our experimental results show significant performance gains in both offline and online evaluations. In offline assessments, a single demonstration improves model performance, increasing Gemini-1.5-Pro's accuracy from 19.3% to 51.7%. In online evaluations, our framework enhances UI-TARS-7B-SFT's task success rate from 18.1% to 32.8%. LearnAct framework and LearnGUI benchmark establish demonstration-based learning as a promising direction for more adaptable, personalized, and deployable mobile GUI agents.","authors":["Guangyi Liu","Pengxiang Zhao","Liang Liu","Zhiming Chen","Yuxiang Chai","Shuai Ren","Hao Wang","Shibo He","Wenchao Meng"],"url":"https://arxiv.org/abs/2504.13805"}
{"created":"2025-04-21","title":"DiffOG: Differentiable Policy Trajectory Optimization with Generalizability","abstract":"Imitation learning-based visuomotor policies excel at manipulation tasks but often produce suboptimal action trajectories compared to model-based methods. Directly mapping camera data to actions via neural networks can result in jerky motions and difficulties in meeting critical constraints, compromising safety and robustness in real-world deployment. For tasks that require high robustness or strict adherence to constraints, ensuring trajectory quality is crucial. However, the lack of interpretability in neural networks makes it challenging to generate constraint-compliant actions in a controlled manner. This paper introduces differentiable policy trajectory optimization with generalizability (DiffOG), a learning-based trajectory optimization framework designed to enhance visuomotor policies. By leveraging the proposed differentiable formulation of trajectory optimization with transformer, DiffOG seamlessly integrates policies with a generalizable optimization layer. Visuomotor policies enhanced by DiffOG generate smoother, constraint-compliant action trajectories in a more interpretable way. DiffOG exhibits strong generalization capabilities and high flexibility. We evaluated DiffOG across 11 simulated tasks and 2 real-world tasks. The results demonstrate that DiffOG significantly enhances the trajectory quality of visuomotor policies while having minimal impact on policy performance, outperforming trajectory processing baselines such as greedy constraint clipping and penalty-based trajectory optimization. Furthermore, DiffOG achieves superior performance compared to existing constrained visuomotor policy.","authors":["Zhengtong Xu","Zichen Miao","Qiang Qiu","Zhe Zhang","Yu She"],"url":"https://arxiv.org/abs/2504.13807"}
{"created":"2025-04-21","title":"A Fast Direct Solver for Boundary Integral Equations Using Quadrature By Expansion","abstract":"We construct and analyze a hierarchical direct solver for linear systems arising from the discretization of boundary integral equations using the Quadrature by Expansion (QBX) method. Our scheme builds on the existing theory of Hierarchical Semi-Separable (HSS) matrix operators that contain low-rank off-diagonal submatrices. We use proxy-based approximations of the far-field interactions and the Interpolative Decomposition (ID) to construct compressed HSS operators that are used as fast direct solvers for the original system. We describe a number of modifications to the standard HSS framework that enable compatibility with the QBX family of discretization methods. We establish an error model for the direct solver that is based on a multipole expansion of the QBX-mediated proxy interactions and standard estimates for the ID\\@. Based on these theoretical results, we develop an automatic approach for setting scheme parameters based on user-provided error tolerances. The resulting solver seamlessly generalizes across two- and tree-dimensional problems and achieves state-of-the-art asymptotic scaling. We conclude with numerical experiments that support the theoretical expectations for the error and computational cost of the direct solver.","authors":["Alexandru Fikl","Andreas Kl\\\"ockner"],"url":"https://arxiv.org/abs/2504.13809"}
{"created":"2025-04-21","title":"Can LLMs handle WebShell detection? Overcoming Detection Challenges with Behavioral Function-Aware Framework","abstract":"WebShell attacks, in which malicious scripts are injected into web servers, are a major cybersecurity threat. Traditional machine learning and deep learning methods are hampered by issues such as the need for extensive training data, catastrophic forgetting, and poor generalization. Recently, Large Language Models (LLMs) have gained attention for code-related tasks, but their potential in WebShell detection remains underexplored. In this paper, we make two major contributions: (1) a comprehensive evaluation of seven LLMs, including GPT-4, LLaMA 3.1 70B, and Qwen 2.5 variants, benchmarked against traditional sequence- and graph-based methods using a dataset of 26.59K PHP scripts, and (2) the Behavioral Function-Aware Detection (BFAD) framework, designed to address the specific challenges of applying LLMs to this domain. Our framework integrates three components: a Critical Function Filter that isolates malicious PHP function calls, a Context-Aware Code Extraction strategy that captures the most behaviorally indicative code segments, and Weighted Behavioral Function Profiling (WBFP) that enhances in-context learning by prioritizing the most relevant demonstrations based on discriminative function-level profiles. Our results show that larger LLMs achieve near-perfect precision but lower recall, while smaller models exhibit the opposite trade-off. However, all models lag behind previous State-Of-The-Art (SOTA) methods. With BFAD, the performance of all LLMs improved, with an average F1 score increase of 13.82%. Larger models such as GPT-4, LLaMA 3.1 70B, and Qwen 2.5 14B outperform SOTA methods, while smaller models such as Qwen 2.5 3B achieve performance competitive with traditional methods. This work is the first to explore the feasibility and limitations of LLMs for WebShell detection, and provides solutions to address the challenges in this task.","authors":["Feijiang Han","Jiaming Zhang","Chuyi Deng","Jianheng Tang","Yunhuai Liu"],"url":"https://arxiv.org/abs/2504.13811"}
{"created":"2025-04-21","title":"Cops and Robbers for Graphs on Surfaces with Crossings","abstract":"Cops and Robbers is a game played on a graph where a set of cops attempt to capture a single robber. The game proceeds in rounds, where each round first consists of the cops' turn, followed by the robber's turn. In the cops' turn, every cop can choose to either stay on the same vertex or move to an adjacent vertex, and likewise the robber in his turn. The robber is considered to be captured if, at any point in time, there is some cop on the same vertex as the robber. A natural question in this game concerns the cop-number of a graph -- the minimum number of cops needed to capture the robber. It has long been known that graphs embeddable (without crossings) on surfaces of bounded genus have bounded cop-number. In contrast, the class of 1-planar graphs -- graphs that can be drawn on the plane with at most one crossing per edge -- does not have bounded cop-number. This paper initiates an investigation into how distance between crossing pairs of edges influences a graph's cop number. In particular, we look at Distance $d$ Cops and Robbers, a variant of the classical game, where the robber is considered to be captured if there is a cop within distance $d$ of the robber. Let $c_d(G)$ denote the minimum number of cops required in the graph $G$ to capture a robber within distance $d$. We look at various classes of graphs, such as 1-plane graphs, $k$-plane graphs (graphs where each edge is crossed at most $k$ times), and even general graph drawings, and show that if every crossing pair of edges can be connected by a path of small length, then $c_d(G)$ is bounded, for small values of $d$.","authors":["Prosenjit Bose","Pat Morin","Karthik Murali"],"url":"https://arxiv.org/abs/2504.13813"}
{"created":"2025-04-21","title":"Preconditioning FEM discretisations of the high-frequency Maxwell equations by either perturbing the coefficients or adding absorption","abstract":"We prove bounds on $\\mathsf{I} - \\mathsf{A}_2^{-1}\\mathsf{A}_1$ where $\\mathsf{A}_\\ell$, $\\ell=1,2$, are the Galerkin matrices corresponding to finite-element discretisations of the time-harmonic Maxwell equations $k^{-2}{\\rm curl} (\\mu_\\ell^{-1}{\\rm curl} E_\\ell) - \\epsilon_\\ell E_\\ell =f$; i.e., we consider the situation where the Maxwell FEM matrix is preconditioned by the FEM matrix arising from the same Maxwell problem but with different coefficients. An important special case is when the perturbation consists of adding absorption (in the spirit of \"shifted Laplacian preconditioning\" for the Helmholtz equation). The results of this paper are the Maxwell analogues of the Helmholtz results in [Gander, Graham, Spence, 2015] and [Graham, Pembery, Spence, 2021], and confirm a conjecture in the recent preprint [Li, Hu, arXiv 2501.18305]. These results are obtained by putting the Maxwell problem in an abstract framework that also includes the Helmholtz problem; as a byproduct we weaken the assumptions required to obtain the Helmholtz results in [Gander, Graham, Spence, 2015] and [Graham, Pembery, Spence, 2021].","authors":["Euan A. Spence"],"url":"https://arxiv.org/abs/2504.13814"}
{"created":"2025-04-21","title":"Analyzing LLMs' Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations","abstract":"While understanding the knowledge boundaries of LLMs is crucial to prevent hallucination, research on knowledge boundaries of LLMs has predominantly focused on English. In this work, we present the first study to analyze how LLMs recognize knowledge boundaries across different languages by probing their internal representations when processing known and unknown questions in multiple languages. Our empirical studies reveal three key findings: 1) LLMs' perceptions of knowledge boundaries are encoded in the middle to middle-upper layers across different languages. 2) Language differences in knowledge boundary perception follow a linear structure, which motivates our proposal of a training-free alignment method that effectively transfers knowledge boundary perception ability across languages, thereby helping reduce hallucination risk in low-resource languages; 3) Fine-tuning on bilingual question pair translation further enhances LLMs' recognition of knowledge boundaries across languages. Given the absence of standard testbeds for cross-lingual knowledge boundary analysis, we construct a multilingual evaluation suite comprising three representative types of knowledge boundary data. Our code and datasets are publicly available at https://github.com/DAMO-NLP-SG/LLM-Multilingual-Knowledge-Boundaries.","authors":["Chenghao Xiao","Hou Pong Chan","Hao Zhang","Mahani Aljunied","Lidong Bing","Noura Al Moubayed","Yu Rong"],"url":"https://arxiv.org/abs/2504.13816"}
{"created":"2025-04-21","title":"Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning","abstract":"Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing reasoning capabilities in large language models, but faces a fundamental asymmetry in computation and memory requirements: inference is embarrassingly parallel with a minimal memory footprint, while policy updates require extensive synchronization and are memory-intensive. To address this asymmetry, we introduce PODS (Policy Optimization with Down-Sampling), a framework that strategically decouples these phases by generating numerous rollouts in parallel but updating only on an informative subset. Within this framework, we develop max-variance down-sampling, a theoretically motivated method that selects rollouts with maximally diverse reward signals. We prove that this approach has an efficient algorithmic solution, and empirically demonstrate that GRPO with PODS using max-variance down-sampling achieves superior performance over standard GRPO on the GSM8K benchmark.","authors":["Yixuan Even Xu","Yash Savani","Fei Fang","Zico Kolter"],"url":"https://arxiv.org/abs/2504.13818"}
{"created":"2025-04-21","title":"CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning","abstract":"Humans can develop internal world models that encode common sense knowledge, telling them how the world works and predicting the consequences of their actions. This concept has emerged as a promising direction for establishing general-purpose machine-learning models in recent preliminary works, e.g., for visual representation learning. In this paper, we present CheXWorld, the first effort towards a self-supervised world model for radiographic images. Specifically, our work develops a unified framework that simultaneously models three aspects of medical knowledge essential for qualified radiologists, including 1) local anatomical structures describing the fine-grained characteristics of local tissues (e.g., architectures, shapes, and textures); 2) global anatomical layouts describing the global organization of the human body (e.g., layouts of organs and skeletons); and 3) domain variations that encourage CheXWorld to model the transitions across different appearance domains of radiographs (e.g., varying clarity, contrast, and exposure caused by collecting radiographs from different hospitals, devices, or patients). Empirically, we design tailored qualitative and quantitative analyses, revealing that CheXWorld successfully captures these three dimensions of medical knowledge. Furthermore, transfer learning experiments across eight medical image classification and segmentation benchmarks showcase that CheXWorld significantly outperforms existing SSL methods and large-scale medical foundation models. Code & pre-trained models are available at https://github.com/LeapLabTHU/CheXWorld.","authors":["Yang Yue","Yulin Wang","Chenxin Tao","Pan Liu","Shiji Song","Gao Huang"],"url":"https://arxiv.org/abs/2504.13820"}
{"created":"2025-04-21","title":"Toward Portable GPU Performance: Julia Recursive Implementation of TRMM and TRSM","abstract":"This paper presents a performant and portable recursive implementation of triangular matrix-matrix multiplication (TRMM) and triangular solve (TRSM) in Julia for GPUs, two kernels that underlie many linear-algebra algorithms. We restructure TRMM and TRSM so that most work is executed as general matrix-matrix multiplication (GEMM), improving use of the GPU memory hierarchy and reducing latency. Exploiting Julia's multiple dispatch and metaprogramming together with the GPUArrays and KernelAbstractions frameworks, we expose a single hardware-agnostic API that runs on NVIDIA, AMD, and Apple Silicon GPUs. For large matrices the recursive code reaches throughput comparable to vendor libraries such as cuBLAS and rocBLAS, while providing these routines on Apple Silicon for the first time. The entire implementation is only a few hundred lines of code, showing that unified Julia programs can deliver near-vendor performance across heterogeneous architectures.","authors":["Vicki Carrica","Maxwell Onyango","Rabab Alomairy","Evelyne Ringoot","James Schloss","Alan Edelman"],"url":"https://arxiv.org/abs/2504.13821"}
{"created":"2025-04-21","title":"Parameter-Efficient Continual Fine-Tuning: A Survey","abstract":"The emergence of large pre-trained networks has revolutionized the AI field, unlocking new possibilities and achieving unprecedented performance. However, these models inherit a fundamental limitation from traditional Machine Learning approaches: their strong dependence on the \\textit{i.i.d.} assumption hinders their adaptability to dynamic learning scenarios. We believe the next breakthrough in AI lies in enabling efficient adaptation to evolving environments -- such as the real world -- where new data and tasks arrive sequentially. This challenge defines the field of Continual Learning (CL), a Machine Learning paradigm focused on developing lifelong learning neural models. One alternative to efficiently adapt these large-scale models is known Parameter-Efficient Fine-Tuning (PEFT). These methods tackle the issue of adapting the model to a particular data or scenario by performing small and efficient modifications, achieving similar performance to full fine-tuning. However, these techniques still lack the ability to adjust the model to multiple tasks continually, as they suffer from the issue of Catastrophic Forgetting. In this survey, we first provide an overview of CL algorithms and PEFT methods before reviewing the state-of-the-art on Parameter-Efficient Continual Fine-Tuning (PECFT). We examine various approaches, discuss evaluation metrics, and explore potential future research directions. Our goal is to highlight the synergy between CL and Parameter-Efficient Fine-Tuning, guide researchers in this field, and pave the way for novel future research directions.","authors":["Eric Nuertey Coleman","Luigi Quarantiello","Ziyue Liu","Qinwen Yang","Samrat Mukherjee","Julio Hurtado","Vincenzo Lomonaco"],"url":"https://arxiv.org/abs/2504.13822"}
{"created":"2025-04-21","title":"Feature Alignment and Representation Transfer in Knowledge Distillation for Large Language Models","abstract":"Knowledge distillation (KD) is a technique for transferring knowledge from complex teacher models to simpler student models, significantly enhancing model efficiency and accuracy. It has demonstrated substantial advancements in various applications including image classification, object detection, language modeling, text classification, and sentiment analysis. Recent innovations in KD methods, such as attention-based approaches, block-wise logit distillation, and decoupling distillation, have notably improved student model performance. These techniques focus on stimulus complexity, attention mechanisms, and global information capture to optimize knowledge transfer. In addition, KD has proven effective in compressing large language models while preserving accuracy, reducing computational overhead, and improving inference speed. This survey synthesizes the latest literature, highlighting key findings, contributions, and future directions in knowledge distillation to provide insights for researchers and practitioners on its evolving role in artificial intelligence and machine learning.","authors":["Junjie Yang","Junhao Song","Xudong Han","Ziqian Bi","Tianyang Wang","Chia Xin Liang","Xinyuan Song","Yichao Zhang","Qian Niu","Benji Peng","Keyu Chen","Ming Liu"],"url":"https://arxiv.org/abs/2504.13825"}
{"created":"2025-04-21","title":"Generative AI Act II: Test Time Scaling Drives Cognition Engineering","abstract":"The first generation of Large Language Models - what might be called \"Act I\" of generative AI (2020-2023) - achieved remarkable success through massive parameter and data scaling, yet exhibited fundamental limitations in knowledge latency, shallow reasoning, and constrained cognitive processes. During this era, prompt engineering emerged as our primary interface with AI, enabling dialogue-level communication through natural language. We now witness the emergence of \"Act II\" (2024-present), where models are transitioning from knowledge-retrieval systems (in latent space) to thought-construction engines through test-time scaling techniques. This new paradigm establishes a mind-level connection with AI through language-based thoughts. In this paper, we clarify the conceptual foundations of cognition engineering and explain why this moment is critical for its development. We systematically break down these advanced approaches through comprehensive tutorials and optimized implementations, democratizing access to cognition engineering and enabling every practitioner to participate in AI's second act. We provide a regularly updated collection of papers on test-time scaling in the GitHub Repository: https://github.com/GAIR-NLP/cognition-engineering","authors":["Shijie Xia","Yiwei Qin","Xuefeng Li","Yan Ma","Run-Ze Fan","Steffi Chern","Haoyang Zou","Fan Zhou","Xiangkun Hu","Jiahe Jin","Yanheng He","Yixin Ye","Yixiu Liu","Pengfei Liu"],"url":"https://arxiv.org/abs/2504.13828"}
{"created":"2025-04-21","title":"Science Hierarchography: Hierarchical Organization of Science Literature","abstract":"Scientific knowledge is growing rapidly, making it challenging to track progress and high-level conceptual links across broad disciplines. While existing tools like citation networks and search engines make it easy to access a few related papers, they fundamentally lack the flexible abstraction needed to represent the density of activity in various scientific subfields. We motivate SCIENCE HIERARCHOGRAPHY, the goal of organizing scientific literature into a high-quality hierarchical structure that allows for the categorization of scientific work across varying levels of abstraction, from very broad fields to very specific studies. Such a representation can provide insights into which fields are well-explored and which are under-explored. To achieve the goals of SCIENCE HIERARCHOGRAPHY, we develop a range of algorithms. Our primary approach combines fast embedding-based clustering with LLM-based prompting to balance the computational efficiency of embedding methods with the semantic precision offered by LLM prompting. We demonstrate that this approach offers the best trade-off between quality and speed compared to methods that heavily rely on LLM prompting, such as iterative tree construction with LLMs. To better reflect the interdisciplinary and multifaceted nature of research papers, our hierarchy captures multiple dimensions of categorization beyond simple topic labels. We evaluate the utility of our framework by assessing how effectively an LLM-based agent can locate target papers using the hierarchy. Results show that this structured approach enhances interpretability, supports trend discovery, and offers an alternative pathway for exploring scientific literature beyond traditional search methods. Code, data and demo: $\\href{https://github.com/JHU-CLSP/science-hierarchography}{https://github.com/JHU-CLSP/science-hierarchography}$","authors":["Muhan Gao","Jash Shah","Weiqi Wang","Daniel Khashabi"],"url":"https://arxiv.org/abs/2504.13834"}
{"created":"2025-04-21","title":"MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space","abstract":"Data quality and diversity are key to the construction of effective instruction-tuning datasets. %","authors":["Yicheng Chen","Yining Li","Kai Hu","Zerun Ma","Haochen Ye","Kai Chen"],"url":"https://arxiv.org/abs/2504.13835"}
{"created":"2025-04-21","title":"Outlier-Robust Multi-Model Fitting on Quantum Annealers","abstract":"Multi-model fitting (MMF) presents a significant challenge in Computer Vision, particularly due to its combinatorial nature. While recent advancements in quantum computing offer promise for addressing NP-hard problems, existing quantum-based approaches for model fitting are either limited to a single model or consider multi-model scenarios within outlier-free datasets. This paper introduces a novel approach, the robust quantum multi-model fitting (R-QuMF) algorithm, designed to handle outliers effectively. Our method leverages the intrinsic capabilities of quantum hardware to tackle combinatorial challenges inherent in MMF tasks, and it does not require prior knowledge of the exact number of models, thereby enhancing its practical applicability. By formulating the problem as a maximum set coverage task for adiabatic quantum computers (AQC), R-QuMF outperforms existing quantum techniques, demonstrating superior performance across various synthetic and real-world 3D datasets. Our findings underscore the potential of quantum computing in addressing the complexities of MMF, especially in real-world scenarios with noisy and outlier-prone data.","authors":["Saurabh Pandey","Luca Magri","Federica Arrigoni","Vladislav Golyanik"],"url":"https://arxiv.org/abs/2504.13836"}
{"created":"2025-04-21","title":"Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?","abstract":"Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated notable success in enhancing the reasoning capabilities of LLMs, particularly in mathematics and programming tasks. It is widely believed that RLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning abilities that exceed corresponding base models' capacity. In this study, however, we critically re-examines this assumption by measuring the pass@\\textit{k} metric with large values of \\textit{k} to explore the reasoning capability boundary of the models across a wide range of model families and benchmarks. Surprisingly, the RL does \\emph{not}, in fact, elicit fundamentally new reasoning patterns. While RL-trained models outperform their base models at smaller values of $k$ (\\eg, $k$=1), base models can achieve a comparable or even higher pass@$k$ score compared to their RL counterparts at large $k$ values. The reasoning paths generated by RL-trained models are already included in the base models' sampling distribution, suggesting that most reasoning abilities manifested in RL-trained models are already obtained by base models. Further analysis shows that RL training boosts the performance by biasing the model's output distribution toward paths that are more likely to yield rewards, therefore sampling correct responses more efficiently. But this also results in a narrower reasoning capability boundary compared to base models. Similar results are observed in visual reasoning tasks trained with RLVR. Moreover, we find that distillation can genuinely introduce new knowledge into the model, different from RLVR. These findings underscore a critical limitation of RLVR in advancing LLM reasoning abilities which requires us to fundamentally rethink the impact of RL training in reasoning LLMs and the need of a better paradigm. Project Page: https://limit-of-RLVR.github.io","authors":["Yang Yue","Zhiqi Chen","Rui Lu","Andrew Zhao","Zhaokai Wang","Yang Yue","Shiji Song","Gao Huang"],"url":"https://arxiv.org/abs/2504.13837"}
{"created":"2025-04-21","title":"Audit Cards: Contextualizing AI Evaluations","abstract":"AI governance frameworks increasingly rely on audits, yet the results of their underlying evaluations require interpretation and context to be meaningfully informative. Even technically rigorous evaluations can offer little useful insight if reported selectively or obscurely. Current literature focuses primarily on technical best practices, but evaluations are an inherently sociotechnical process, and there is little guidance on reporting procedures and context. Through literature review, stakeholder interviews, and analysis of governance frameworks, we propose \"audit cards\" to make this context explicit. We identify six key types of contextual features to report and justify in audit cards: auditor identity, evaluation scope, methodology, resource access, process integrity, and review mechanisms. Through analysis of existing evaluation reports, we find significant variation in reporting practices, with most reports omitting crucial contextual information such as auditors' backgrounds, conflicts of interest, and the level and type of access to models. We also find that most existing regulations and frameworks lack guidance on rigorous reporting. In response to these shortcomings, we argue that audit cards can provide a structured format for reporting key claims alongside their justifications, enhancing transparency, facilitating proper interpretation, and establishing trust in reporting.","authors":["Leon Staufer","Mick Yang","Anka Reuel","Stephen Casper"],"url":"https://arxiv.org/abs/2504.13839"}
{"created":"2025-04-21","title":"Advanced Deep Learning and Large Language Models: Comprehensive Insights for Cancer Detection","abstract":"The rapid advancement of deep learning (DL) has transformed healthcare, particularly in cancer detection and diagnosis. DL surpasses traditional machine learning and human accuracy, making it a critical tool for identifying diseases. Despite numerous reviews on DL in healthcare, a comprehensive analysis of its role in cancer detection remains limited. Existing studies focus on specific aspects, leaving gaps in understanding its broader impact. This paper addresses these gaps by reviewing advanced DL techniques, including transfer learning (TL), reinforcement learning (RL), federated learning (FL), Transformers, and large language models (LLMs). These approaches enhance accuracy, tackle data scarcity, and enable decentralized learning while maintaining data privacy. TL adapts pre-trained models to new datasets, improving performance with limited labeled data. RL optimizes diagnostic pathways and treatment strategies, while FL fosters collaborative model development without sharing sensitive data. Transformers and LLMs, traditionally used in natural language processing, are now applied to medical data for improved interpretability. Additionally, this review examines these techniques' efficiency in cancer diagnosis, addresses challenges like data imbalance, and proposes solutions. It serves as a resource for researchers and practitioners, providing insights into current trends and guiding future research in advanced DL for cancer detection.","authors":["Yassine Habchi","Hamza Kheddar","Yassine Himeur","Adel Belouchrani","Erchin Serpedin","Fouad Khelifi","Muhammad E. H. Chowdhury"],"url":"https://arxiv.org/abs/2504.13186"}
{"created":"2025-04-21","title":"Efficient Brain Tumor Segmentation Using a Dual-Decoder 3D U-Net with Attention Gates (DDUNet)","abstract":"Cancer remains one of the leading causes of mortality worldwide, and among its many forms, brain tumors are particularly notorious due to their aggressive nature and the critical challenges involved in early diagnosis. Recent advances in artificial intelligence have shown great promise in assisting medical professionals with precise tumor segmentation, a key step in timely diagnosis and treatment planning. However, many state-of-the-art segmentation methods require extensive computational resources and prolonged training times, limiting their practical application in resource-constrained settings. In this work, we present a novel dual-decoder U-Net architecture enhanced with attention-gated skip connections, designed specifically for brain tumor segmentation from MRI scans. Our approach balances efficiency and accuracy by achieving competitive segmentation performance while significantly reducing training demands. Evaluated on the BraTS 2020 dataset, the proposed model achieved Dice scores of 85.06% for Whole Tumor (WT), 80.61% for Tumor Core (TC), and 71.26% for Enhancing Tumor (ET) in only 50 epochs, surpassing several commonly used U-Net variants. Our model demonstrates that high-quality brain tumor segmentation is attainable even under limited computational resources, thereby offering a viable solution for researchers and clinicians operating with modest hardware. This resource-efficient model has the potential to improve early detection and diagnosis of brain tumors, ultimately contributing to better patient outcomes","authors":["Mohammad Mahdi Danesh Pajouh"],"url":"https://arxiv.org/abs/2504.13200"}
{"created":"2025-04-21","title":"A Quantum of Learning: Using Quaternion Algebra to Model Learning on Quantum Devices","abstract":"This article considers the problem of designing adaption and optimisation techniques for training quantum learning machines. To this end, the division algebra of quaternions is used to derive an effective model for representing computation and measurement operations on qubits. In turn, the derived model, serves as the foundation for formulating an adaptive learning problem on principal quantum learning units, thereby establishing quantum information processing units akin to that of neurons in classical approaches. Then, leveraging the modern HR-calculus, a comprehensive training framework for learning on quantum machines is developed. The quaternion-valued model accommodates mathematical tractability and establishment of performance criteria, such as convergence conditions.","authors":["Sayed Pouria Talebi","Clive Cheong Took","Danilo P. Mandic"],"url":"https://arxiv.org/abs/2504.13232"}
{"created":"2025-04-21","title":"Bayesian Rao test for distributed target detection in interference and noise with limited training data","abstract":"This paper has studied the problem of detecting a range-spread target in interference and noise when the number of training data is limited. The interference is located within a certain subspace with an unknown coordinate, while the noise follows a Gaussian distribution with an unknown covariance matrix. We concentrate on the scenarios where the training data are limited and employ a Bayesian framework to ffnd a solution. Speciffcally, the covariance matrix is assumed to follow an inverse Wishart distribution. Then, we introduce the Bayesian detector according to the Rao test, which, demonstrated by both simulation experiment and real data, has superior detection performance to the existing detectors in certain situations.","authors":["Daipeng Xiao","Weijian Liu","Jun Liu","Yuntao Wu","Qinglei Du","Xiaoqiang Hua"],"url":"https://arxiv.org/abs/2504.13235"}
{"created":"2025-04-21","title":"Stability of Polling Systems for a Large Class of Markovian Switching Policies","abstract":"We consider a polling system with two queues, where a single server is attending the queues in a cyclic order and requires non-zero switching times to switch between the queues. Our aim is to identify a fairly general and comprehensive class of Markovian switching policies that renders the system stable. Potentially a class of policies that can cover the Pareto frontier related to individual-queue-centric performance measures like the stationary expected number of waiting customers in each queue; for instance, such a class of policies is identified recently for a polling system near the fluid regime (with large arrival and departure rates), and we aim to include that class. We also aim to include a second class that facilitates switching between the queues at the instance the occupancy in the opposite queue crosses a threshold and when that in the visiting queue is below a threshold (this inclusion facilitates design of `robust' polling systems). Towards this, we consider a class of two-phase switching policies, which includes the above mentioned classes. In the maximum generality, our policies can be represented by eight parameters, while two parameters are sufficient to represent the aforementioned classes. We provide simple conditions to identify the sub-class of switching policies that ensure system stability. By numerically tuning the parameters of the proposed class, we illustrate that the proposed class can cover the Pareto frontier for the stationary expected number of customers in the two queues.","authors":["Konstantin Avrachenkov","Kousik Das","Veeraruna Kavitha","Vartika Singh"],"url":"https://arxiv.org/abs/2504.13315"}
{"created":"2025-04-21","title":"Gradient-Free Sequential Bayesian Experimental Design via Interacting Particle Systems","abstract":"We introduce a gradient-free framework for Bayesian Optimal Experimental Design (BOED) in sequential settings, aimed at complex systems where gradient information is unavailable. Our method combines Ensemble Kalman Inversion (EKI) for design optimization with the Affine-Invariant Langevin Dynamics (ALDI) sampler for efficient posterior sampling-both of which are derivative-free and ensemble-based. To address the computational challenges posed by nested expectations in BOED, we propose variational Gaussian and parametrized Laplace approximations that provide tractable upper and lower bounds on the Expected Information Gain (EIG). These approximations enable scalable utility estimation in high-dimensional spaces and PDE-constrained inverse problems. We demonstrate the performance of our framework through numerical experiments ranging from linear Gaussian models to PDE-based inference tasks, highlighting the method's robustness, accuracy, and efficiency in information-driven experimental design.","authors":["Robert Gruhlke","Matei Hanu","Claudia Schillings","Philipp Wacker"],"url":"https://arxiv.org/abs/2504.13320"}
{"created":"2025-04-21","title":"Focus3D: A Practical Method to Adaptively Focus ISAR Data and Provide 3-D Information for Automatic Target Recognition","abstract":"To improve ATR identification of ships at sea requires an advanced ISAR processor - one that not only provides focused images but can also determine the pose of the ship. This tells us whether the image shows a profile (vertical plane) view, a plan (horizontal plane) view or some view in between. If the processor can provide this information, then the ATR processor can try to match the images with known vertical or horizontal features of ships and, in conjunction with estimated ship length, narrow the set of possible identifications. This paper extends the work of Melendez and Bennett [M-B, Ref. 1] by combining a focus algorithm with a method that models the angles of the ship relative to the radar. In M-B the algorithm was limited to a single angle and the plane of rotation was not determined. This assumption may be fine for a short time image where there is limited data available to determine the pose. However, the present paper models the ship rotation with two angles - aspect angle, representing rotation in the horizontal plane, and tilt angle, representing variations in the effective grazing angle to the ship.","authors":["John R. Bennett"],"url":"https://arxiv.org/abs/2504.13321"}
{"created":"2025-04-21","title":"Predicting Forced Responses of Probability Distributions via the Fluctuation-Dissipation Theorem and Generative Modeling","abstract":"We present a novel data-driven framework for estimating the response of higher-order moments of nonlinear stochastic systems to small external perturbations. The classical Generalized Fluctuation-Dissipation Theorem (GFDT) links the unperturbed steady-state distribution to the system's linear response. Standard implementations rely on Gaussian approximations, which can often accurately predict the mean response but usually introduce significant biases in higher-order moments, such as variance, skewness, and kurtosis. To address this limitation, we combine GFDT with recent advances in score-based generative modeling, which enable direct estimation of the score function from data without requiring full density reconstruction. Our method is validated on three reduced-order stochastic models relevant to climate dynamics: a scalar stochastic model for low-frequency climate variability, a slow-fast triad model mimicking key features of the El Nino-Southern Oscillation (ENSO), and a six-dimensional stochastic barotropic model capturing atmospheric regime transitions. In all cases, the approach captures strongly nonlinear and non-Gaussian features of the system's response, outperforming traditional Gaussian approximations.","authors":["Ludovico T. Giorgini","Fabrizio Falasca","Andre N. Souza"],"url":"https://arxiv.org/abs/2504.13333"}
{"created":"2025-04-21","title":"On the minimax optimality of Flow Matching through the connection to kernel density estimation","abstract":"Flow Matching has recently gained attention in generative modeling as a simple and flexible alternative to diffusion models, the current state of the art. While existing statistical guarantees adapt tools from the analysis of diffusion models, we take a different perspective by connecting Flow Matching to kernel density estimation. We first verify that the kernel density estimator matches the optimal rate of convergence in Wasserstein distance up to logarithmic factors, improving existing bounds for the Gaussian kernel. Based on this result, we prove that for sufficiently large networks, Flow Matching also achieves the optimal rate up to logarithmic factors, providing a theoretical foundation for the empirical success of this method. Finally, we provide a first justification of Flow Matching's effectiveness in high-dimensional settings by showing that rates improve when the target distribution lies on a lower-dimensional linear subspace.","authors":["Lea Kunkel","Mathias Trabs"],"url":"https://arxiv.org/abs/2504.13336"}
{"created":"2025-04-21","title":"Putting the Segment Anything Model to the Test with 3D Knee MRI -- A Comparison with State-of-the-Art Performance","abstract":"Menisci are cartilaginous tissue found within the knee that contribute to joint lubrication and weight dispersal. Damage to menisci can lead to onset and progression of knee osteoarthritis (OA), a condition that is a leading cause of disability, and for which there are few effective therapies. Accurate automated segmentation of menisci would allow for earlier detection and treatment of meniscal abnormalities, as well as shedding more light on the role the menisci play in OA pathogenesis. Focus in this area has mainly used variants of convolutional networks, but there has been no attempt to utilise recent large vision transformer segmentation models. The Segment Anything Model (SAM) is a so-called foundation segmentation model, which has been found useful across a range of different tasks due to the large volume of data used for training the model. In this study, SAM was adapted to perform fully-automated segmentation of menisci from 3D knee magnetic resonance images. A 3D U-Net was also trained as a baseline. It was found that, when fine-tuning only the decoder, SAM was unable to compete with 3D U-Net, achieving a Dice score of $0.81\\pm0.03$, compared to $0.87\\pm0.03$, on a held-out test set. When fine-tuning SAM end-to-end, a Dice score of $0.87\\pm0.03$ was achieved. The performance of both the end-to-end trained SAM configuration and the 3D U-Net were comparable to the winning Dice score ($0.88\\pm0.03$) in the IWOAI Knee MRI Segmentation Challenge 2019. Performance in terms of the Hausdorff Distance showed that both configurations of SAM were inferior to 3D U-Net in matching the meniscus morphology. Results demonstrated that, despite its generalisability, SAM was unable to outperform a basic 3D U-Net in meniscus segmentation, and may not be suitable for similar 3D medical image segmentation tasks also involving fine anatomical structures with low contrast and poorly-defined boundaries.","authors":["Oliver Mills","Philip Conaghan","Nishant Ravikumar","Samuel Relton"],"url":"https://arxiv.org/abs/2504.13340"}
{"created":"2025-04-21","title":"Adaptive AI decision interface for autonomous electronic material discovery","abstract":"AI-powered autonomous experimentation (AI/AE) can accelerate materials discovery but its effectiveness for electronic materials is hindered by data scarcity from lengthy and complex design-fabricate-test-analyze cycles. Unlike experienced human scientists, even advanced AI algorithms in AI/AE lack the adaptability to make informative real-time decisions with limited datasets. Here, we address this challenge by developing and implementing an AI decision interface on our AI/AE system. The central element of the interface is an AI advisor that performs real-time progress monitoring, data analysis, and interactive human-AI collaboration for actively adapting to experiments in different stages and types. We applied this platform to an emerging type of electronic materials-mixed ion-electron conducting polymers (MIECPs) -- to engineer and study the relationships between multiscale morphology and properties. Using organic electrochemical transistors (OECT) as the testing-bed device for evaluating the mixed-conducting figure-of-merit -- the product of charge-carrier mobility and the volumetric capacitance ({\\mu}C*), our adaptive AI/AE platform achieved a 150% increase in {\\mu}C* compared to the commonly used spin-coating method, reaching 1,275 F cm-1 V-1 s-1 in just 64 autonomous experimental trials. A study of 10 statistically selected samples identifies two key structural factors for achieving higher volumetric capacitance: larger crystalline lamellar spacing and higher specific surface area, while also uncovering a new polymer polymorph in this material.","authors":["Yahao Dai","Henry Chan","Aikaterini Vriza","Fredrick Kim","Yunfei Wang","Wei Liu","Naisong Shan","Jing Xu","Max Weires","Yukun Wu","Zhiqiang Cao","C. Suzanne Miller","Ralu Divan","Xiaodan Gu","Chenhui Zhu","Sihong Wang","Jie Xu"],"url":"https://arxiv.org/abs/2504.13344"}
{"created":"2025-04-21","title":"Pricing AI Model Accuracy","abstract":"This paper examines the market for AI models in which firms compete to provide accurate model predictions and consumers exhibit heterogeneous preferences for model accuracy. We develop a consumer-firm duopoly model to analyze how competition affects firms' incentives to improve model accuracy. Each firm aims to minimize its model's error, but this choice can often be suboptimal. Counterintuitively, we find that in a competitive market, firms that improve overall accuracy do not necessarily improve their profits. Rather, each firm's optimal decision is to invest further on the error dimension where it has a competitive advantage. By decomposing model errors into false positive and false negative rates, firms can reduce errors in each dimension through investments. Firms are strictly better off investing on their superior dimension and strictly worse off with investments on their inferior dimension. Profitable investments adversely affect consumers but increase overall welfare.","authors":["Nikhil Kumar"],"url":"https://arxiv.org/abs/2504.13375"}
{"created":"2025-04-21","title":"Addressing the Minor-Embedding Problem in Quantum Annealing and Evaluating State-of-the-Art Algorithm Performance","abstract":"This study addresses the minor-embedding problem, which involves mapping the variables of an Ising model onto a quantum annealing processor. The primary motivation stems from the observed performance disparity of quantum annealers when solving problems suited to the processor's architecture versus those with non-hardware-native topologies. Our research has two main objectives: i) to analyze the impact of embedding quality on the performance of D-Wave Systems quantum annealers, and ii) to evaluate the quality of the embeddings generated by Minorminer, an algorithm provided by D-Wave and widely recognized as the standard minor-embedding technique in the literature. Regarding the first objective, our experiments reveal a clear correlation between the average chain length of embeddings and the relative errors of the solutions sampled. This underscores the critical influence of embedding quality on quantum annealing performance. For the second objective, we focus on the Minorminer technique, assessing its capacity to embed problems, the quality of the embeddings produced, and the robustness of the results. We also compare its performance with Clique Embedding, another algorithm developed by D-Wave, which is deterministic and designed to embed fully connected Ising models into quantum annealing processors, serving as a worst-case scenario. The results demonstrate that there is significant room for improvement for Minorminer, as it has not consistently outperformed the worst-case scenario.","authors":["Aitor G\\'omez-Tejedor","Eneko Osaba","Esther Villar-Rodriguez"],"url":"https://arxiv.org/abs/2504.13376"}
{"created":"2025-04-21","title":"Accelerated Optimization of Implicit Neural Representations for CT Reconstruction","abstract":"Inspired by their success in solving challenging inverse problems in computer vision, implicit neural representations (INRs) have been recently proposed for reconstruction in low-dose/sparse-view X-ray computed tomography (CT). An INR represents a CT image as a small-scale neural network that takes spatial coordinates as inputs and outputs attenuation values. Fitting an INR to sinogram data is similar to classical model-based iterative reconstruction methods. However, training INRs with losses and gradient-based algorithms can be prohibitively slow, taking many thousands of iterations to converge. This paper investigates strategies to accelerate the optimization of INRs for CT reconstruction. In particular, we propose two approaches: (1) using a modified loss function with improved conditioning, and (2) an algorithm based on the alternating direction method of multipliers. We illustrate that both of these approaches significantly accelerate INR-based reconstruction of a synthetic breast CT phantom in a sparse-view setting.","authors":["Mahrokh Najaf","Gregory Ongie"],"url":"https://arxiv.org/abs/2504.13390"}
{"created":"2025-04-21","title":"Cardiac MRI Semantic Segmentation for Ventricles and Myocardium using Deep Learning","abstract":"Automated noninvasive cardiac diagnosis plays a critical role in the early detection of cardiac disorders and cost-effective clinical management. Automated diagnosis involves the automated segmentation and analysis of cardiac images. Precise delineation of cardiac substructures and extraction of their morphological attributes are essential for evaluating the cardiac function, and diagnosing cardiovascular disease such as cardiomyopathy, valvular diseases, abnormalities related to septum perforations, and blood-flow rate. Semantic segmentation labels the CMR image at the pixel level, and localizes its subcomponents to facilitate the detection of abnormalities, including abnormalities in cardiac wall motion in an aging heart with muscle abnormalities, vascular abnormalities, and valvular abnormalities. In this paper, we describe a model to improve semantic segmentation of CMR images. The model extracts edge-attributes and context information during down-sampling of the U-Net and infuses this information during up-sampling to localize three major cardiac structures: left ventricle cavity (LV); right ventricle cavity (RV); and LV myocardium (LMyo). We present an algorithm and performance results. A comparison of our model with previous leading models, using similarity metrics between actual image and segmented image, shows that our approach improves Dice similarity coefficient (DSC) by 2%-11% and lowers Hausdorff distance (HD) by 1.6 to 5.7 mm.","authors":["Racheal Mukisa","Arvind K. Bansal"],"url":"https://arxiv.org/abs/2504.13391"}
{"created":"2025-04-21","title":"Quantum repeaters enhanced by vacuum beam guides","abstract":"The development of large-scale quantum communication networks faces critical challenges due to photon loss and decoherence in optical fiber channels. These fundamentally limit transmission distances and demand dense networks of repeater stations. This work investigates using vacuum beam guides (VBGs)-a promising ultra-low-loss transmission platform-as an alternative to traditional fiber links. By incorporating VBGs into repeater-based architectures, we demonstrate that the inter-repeater spacing can be substantially extended, resulting in fewer required nodes and significantly reducing hardware and operational complexity. We perform a cost-function analysis to quantify performance trade-offs across first, second, and third-generation repeaters. Our results show that first-generation repeaters reduce costs dramatically by eliminating entanglement purification. Third-generation repeaters benefit from improved link transmission success, which is crucial for quantum error correction. In contrast, second-generation repeaters exhibit a more nuanced response; although transmission loss is reduced, their performance remains primarily limited by logical gate errors rather than channel loss. These findings highlight that while all repeater generations benefit from reduced photon loss, the magnitude of improvement depends critically on the underlying error mechanisms. Vacuum beam guides thus emerge as a powerful enabler for scalable, high-performance quantum networks, particularly in conjunction with near-term quantum hardware capabilities.","authors":["Yu Gan","Mohadeseh Azar","Nitish Kumar Chandra","Xin Jin","Jinglei Cheng","Kaushik P. Seshadreesan","Junyu Liu"],"url":"https://arxiv.org/abs/2504.13397"}
{"created":"2025-04-21","title":"Adaptive Non-local Observable on Quantum Neural Networks","abstract":"Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning typically rely on a fixed Hermitian observable, often built from Pauli operators. Inspired by the Heisenberg picture, we propose an adaptive non-local measurement framework that substantially increases the model complexity of the quantum circuits. Our introduction of dynamical Hermitian observables with evolving parameters shows that optimizing VQC rotations corresponds to tracing a trajectory in the observable space. This viewpoint reveals that standard VQCs are merely a special case of the Heisenberg representation.","authors":["Hsin-Yi Lin","Huan-Hsin Tseng","Samuel Yen-Chi Chen","Shinjae Yoo"],"url":"https://arxiv.org/abs/2504.13414"}
{"created":"2025-04-21","title":"DADU: Dual Attention-based Deep Supervised UNet for Automated Semantic Segmentation of Cardiac Images","abstract":"We propose an enhanced deep learning-based model for image segmentation of the left and right ventricles and myocardium scar tissue from cardiac magnetic resonance (CMR) images. The proposed technique integrates UNet, channel and spatial attention, edge-detection based skip-connection and deep supervised learning to improve the accuracy of the CMR image-segmentation. Images are processed using multiple channels to generate multiple feature-maps. We built a dual attention-based model to integrate channel and spatial attention. The use of extracted edges in skip connection improves the reconstructed images from feature-maps. The use of deep supervision reduces vanishing gradient problems inherent in classification based on deep neural networks. The algorithms for dual attention-based model, corresponding implementation and performance results are described. The performance results show that this approach has attained high accuracy: 98% Dice Similarity Score (DSC) and significantly lower Hausdorff Distance (HD). The performance results outperform other leading techniques both in DSC and HD.","authors":["Racheal Mukisa","Arvind K. Bansal"],"url":"https://arxiv.org/abs/2504.13415"}
{"created":"2025-04-21","title":"A Recursive Block Pillar Structure in the Kolakoski Sequence K(1,3)","abstract":"The Kolakoski sequence K(a,b) over {a, b} is the unique sequence starting with a that equals its own run-length encoding. While the classical case K(1,2) remains deeply enigmatic, generalizations exhibit markedly different behaviors depending on the parity of a and b. The sequence K(1,3), a same-parity case over the alphabet {1,3}, is known to possess regular structure and a calculable symbol frequency. This paper reveals a complementary structural property: a nested block-pillar recursion of the form B_{n+1} = B_n + P_n + B_n, and P_{n+1} = G(P_n, 3), where each B_n is a prefix of K(1,3), and G is a generation operator based on run-length encoding. We show that B_{n+1} = G(B_n, 1), leading to a self-replicating description of K(1,3). This structure allows derivation of exact recurrences for length, symbol counts, and density, proving exponential growth and convergence to the known limit d = (5 - sqrt(5)) / 10. Our analysis highlights the structured nature of same-parity Kolakoski sequences and offers a constructive alternative to morphic generation.","authors":["William Cook"],"url":"https://arxiv.org/abs/2504.13433"}
{"created":"2025-04-21","title":"An asymptotic preserving scheme for the quantum Liouville-BGK equation","abstract":"We are interested in this work in the numerical resolution of the Quantum Liouville-BGK equation, which arises in the derivation of quantum hydrodynamical models from first principles. Such models are often obtained in some asymptotic limits, for instance a diffusion or a fluid limit, and as a consequence the original Liouville equation contains small parameters. A standard method such as a split-step algorithm is then accurate provided the time step is sufficiently small compared to the asymptotic parameter, which is a severe limitation. In the case of the diffusion limit, we propose a numerical method that is accurate for time steps independent of the small parameter, and which captures well both the microscopic dynamics and the diffusion limit. Our approach is substantiated by an informal theoretical error analysis.","authors":["Romain Duboscq (IMT)","Olivier Pinaud (CSU)"],"url":"https://arxiv.org/abs/2504.13487"}
{"created":"2025-04-21","title":"Convergence of the fully discrete JKO scheme","abstract":"The JKO scheme provides the discrete-in-time approximation for the solutions of evolutionary equations with Wasserstein gradient structure. We study a natural space-discretization of this scheme by restricting the minimization to the measures supported on the nodes of a regular grid. The study of the fully discrete JKO scheme is motivated by the applications to developing numerical schemes for the nonlinear diffusion equation with drift and the crowd motion model. The main result of this paper is the convergence of the scheme as both the time and space discretization parameters tend to zero in a suitable regime.","authors":["Anastasiia Hraivoronska (ICJ","MMCS)","Filippo Santambrogio (ICJ","MMCS)"],"url":"https://arxiv.org/abs/2504.13513"}
{"created":"2025-04-21","title":"Filter2Noise: Interpretable Self-Supervised Single-Image Denoising for Low-Dose CT with Attention-Guided Bilateral Filtering","abstract":"Effective denoising is crucial in low-dose CT to enhance subtle structures and low-contrast lesions while preventing diagnostic errors. Supervised methods struggle with limited paired datasets, and self-supervised approaches often require multiple noisy images and rely on deep networks like U-Net, offering little insight into the denoising mechanism. To address these challenges, we propose an interpretable self-supervised single-image denoising framework -- Filter2Noise (F2N). Our approach introduces an Attention-Guided Bilateral Filter that adapted to each noisy input through a lightweight module that predicts spatially varying filter parameters, which can be visualized and adjusted post-training for user-controlled denoising in specific regions of interest. To enable single-image training, we introduce a novel downsampling shuffle strategy with a new self-supervised loss function that extends the concept of Noise2Noise to a single image and addresses spatially correlated noise. On the Mayo Clinic 2016 low-dose CT dataset, F2N outperforms the leading self-supervised single-image method (ZS-N2N) by 4.59 dB PSNR while improving transparency, user control, and parametric efficiency. These features provide key advantages for medical applications that require precise and interpretable noise reduction. Our code is demonstrated at https://github.com/sypsyp97/Filter2Noise.git .","authors":["Yipeng Sun","Linda-Sophie Schneider","Mingxuan Gu","Siyuan Mei","Chengze Ye","Fabian Wagner","Siming Bayer","Andreas Maier"],"url":"https://arxiv.org/abs/2504.13519"}
{"created":"2025-04-21","title":"Quantum Walks-Based Adaptive Distribution Generation with Efficient CUDA-Q Acceleration","abstract":"We present a novel Adaptive Distribution Generator that leverages a quantum walks-based approach to generate high precision and efficiency of target probability distributions. Our method integrates variational quantum circuits with discrete-time quantum walks, specifically, split-step quantum walks and their entangled extensions, to dynamically tune coin parameters and drive the evolution of quantum states towards desired distributions. This enables accurate one-dimensional probability modeling for applications such as financial simulation and structured two-dimensional pattern generation exemplified by digit representations(0~9). Implemented within the CUDA-Q framework, our approach exploits GPU acceleration to significantly reduce computational overhead and improve scalability relative to conventional methods. Extensive benchmarks demonstrate that our Quantum Walks-Based Adaptive Distribution Generator achieves high simulation fidelity and bridges the gap between theoretical quantum algorithms and practical high-performance computation.","authors":["Yen-Jui Chang","Wei-Ting Wang","Chen-Yu Liu","Yun-Yuan Wang","Ching-Ray Chang"],"url":"https://arxiv.org/abs/2504.13532"}
{"created":"2025-04-21","title":"A Novel Hybrid Approach for Retinal Vessel Segmentation with Dynamic Long-Range Dependency and Multi-Scale Retinal Edge Fusion Enhancement","abstract":"Accurate retinal vessel segmentation provides essential structural information for ophthalmic image analysis. However, existing methods struggle with challenges such as multi-scale vessel variability, complex curvatures, and ambiguous boundaries. While Convolutional Neural Networks (CNNs), Transformer-based models and Mamba-based architectures have advanced the field, they often suffer from vascular discontinuities or edge feature ambiguity. To address these limitations, we propose a novel hybrid framework that synergistically integrates CNNs and Mamba for high-precision retinal vessel segmentation. Our approach introduces three key innovations: 1) The proposed High-Resolution Edge Fuse Network is a high-resolution preserving hybrid segmentation framework that combines a multi-scale backbone with the Multi-scale Retina Edge Fusion (MREF) module to enhance edge features, ensuring accurate and robust vessel segmentation. 2) The Dynamic Snake Visual State Space block combines Dynamic Snake Convolution with Mamba to adaptively capture vessel curvature details and long-range dependencies. An improved eight-directional 2D Snake-Selective Scan mechanism and a dynamic weighting strategy enhance the perception of complex vascular topologies. 3) The MREF module enhances boundary precision through multi-scale edge feature aggregation, suppressing noise while emphasizing critical vessel structures across scales. Experiments on three public datasets demonstrate that our method achieves state-of-the-art performance, particularly in maintaining vascular continuity and effectively segmenting vessels in low-contrast regions. This work provides a robust method for clinical applications requiring accurate retinal vessel analysis. The code is available at https://github.com/frank-oy/HREFNet.","authors":["Yihao Ouyang","Xunheng Kuang","Mengjia Xiong","Zhida Wang","Yuanquan Wang"],"url":"https://arxiv.org/abs/2504.13553"}
{"created":"2025-04-21","title":"FocusNet: Transformer-enhanced Polyp Segmentation with Local and Pooling Attention","abstract":"Colonoscopy is vital in the early diagnosis of colorectal polyps. Regular screenings can effectively prevent benign polyps from progressing to CRC. While deep learning has made impressive strides in polyp segmentation, most existing models are trained on single-modality and single-center data, making them less effective in real-world clinical environments. To overcome these limitations, we propose FocusNet, a Transformer-enhanced focus attention network designed to improve polyp segmentation. FocusNet incorporates three essential modules: the Cross-semantic Interaction Decoder Module (CIDM) for generating coarse segmentation maps, the Detail Enhancement Module (DEM) for refining shallow features, and the Focus Attention Module (FAM), to balance local detail and global context through local and pooling attention mechanisms. We evaluate our model on PolypDB, a newly introduced dataset with multi-modality and multi-center data for building more reliable segmentation methods. Extensive experiments showed that FocusNet consistently outperforms existing state-of-the-art approaches with a high dice coefficients of 82.47% on the BLI modality, 88.46% on FICE, 92.04% on LCI, 82.09% on the NBI and 93.42% on WLI modality, demonstrating its accuracy and robustness across five different modalities. The source code for FocusNet is available at https://github.com/JunZengz/FocusNet.","authors":["Jun Zeng","KC Santosh","Deepak Rajan Nayak","Thomas de Lange","Jonas Varkey","Tyler Berzin","Debesh Jha"],"url":"https://arxiv.org/abs/2504.13597"}
{"created":"2025-04-21","title":"ViG3D-UNet: Volumetric Vascular Connectivity-Aware Segmentation via 3D Vision Graph Representation","abstract":"Accurate vascular segmentation is essential for coronary visualization and the diagnosis of coronary heart disease. This task involves the extraction of sparse tree-like vascular branches from the volumetric space. However, existing methods have faced significant challenges due to discontinuous vascular segmentation and missing endpoints. To address this issue, a 3D vision graph neural network framework, named ViG3D-UNet, was introduced. This method integrates 3D graph representation and aggregation within a U-shaped architecture to facilitate continuous vascular segmentation. The ViG3D module captures volumetric vascular connectivity and topology, while the convolutional module extracts fine vascular details. These two branches are combined through channel attention to form the encoder feature. Subsequently, a paperclip-shaped offset decoder minimizes redundant computations in the sparse feature space and restores the feature map size to match the original input dimensions. To evaluate the effectiveness of the proposed approach for continuous vascular segmentation, evaluations were performed on two public datasets, ASOCA and ImageCAS. The segmentation results show that the ViG3D-UNet surpassed competing methods in maintaining vascular segmentation connectivity while achieving high segmentation accuracy. Our code will be available soon.","authors":["Bowen Liu","Chunlei Meng","Wei Lin","Hongda Zhang","Ziqing Zhou","Zhongxue Gan","Chun Ouyang"],"url":"https://arxiv.org/abs/2504.13599"}
{"created":"2025-04-21","title":"SupResDiffGAN a new approach for the Super-Resolution task","abstract":"In this work, we present SupResDiffGAN, a novel hybrid architecture that combines the strengths of Generative Adversarial Networks (GANs) and diffusion models for super-resolution tasks. By leveraging latent space representations and reducing the number of diffusion steps, SupResDiffGAN achieves significantly faster inference times than other diffusion-based super-resolution models while maintaining competitive perceptual quality. To prevent discriminator overfitting, we propose adaptive noise corruption, ensuring a stable balance between the generator and the discriminator during training. Extensive experiments on benchmark datasets show that our approach outperforms traditional diffusion models such as SR3 and I$^2$SB in efficiency and image quality. This work bridges the performance gap between diffusion- and GAN-based methods, laying the foundation for real-time applications of diffusion models in high-resolution image generation.","authors":["Dawid Kope\\'c","Wojciech Koz{\\l}owski","Maciej Wizerkaniuk","Dawid Krutul","Jan Koco\\'n","Maciej Zi\\k{e}ba"],"url":"https://arxiv.org/abs/2504.13622"}
{"created":"2025-04-21","title":"On the Convergence of Irregular Sampling in Reproducing Kernel Hilbert Spaces","abstract":"We analyse the convergence of sampling algorithms for functions in reproducing kernel Hilbert spaces (RKHS). To this end, we discuss approximation properties of kernel regression under minimalistic assumptions on both the kernel and the input data. We first prove error estimates in the kernel's RKHS norm. This leads us to new results concerning uniform convergence of kernel regression on compact domains. For Lipschitz continuous and H\\\"older continuous kernels, we prove convergence rates.","authors":["Armin Iske"],"url":"https://arxiv.org/abs/2504.13623"}
{"created":"2025-04-21","title":"Generating new coordination compounds via multireference simulations, genetic algorithms and machine learning: the case of Co(II) molecular magnets","abstract":"The design of coordination compounds with target properties often requires years of continuous feedback loop between theory, simulations and experiments. In the case of magnetic molecules, this conventional strategy has indeed led to the breakthrough of single-molecule magnets with working temperatures above nitrogen's boiling point, but at significant costs in terms of resources and time. Here, we propose a computational strategy able to accelerate the discovery of new coordination compounds with desired electronic and magnetic properties. Our approach is based on a combination of high-throughput multireference ab initio methods, genetic algorithms and machine learning. While genetic algorithms allow for an intelligent sampling of the vast chemical space available, machine learning reduces the computational cost by pre-screening molecular properties in advance of their accurate and automated multireference ab initio characterization. Importantly, the presented framework is able to generate novel organic ligands and explore chemical motifs beyond those available in pre-existing structural databases. We showcase the power of this approach by automatically generating new Co(II) mononuclear coordination compounds with record magnetic properties in a fraction of the time required by either experiments or brute-force ab initio approaches","authors":["Lion Frangoulis","Zahra Khatibi","Lorenzo A. Mariano","Alessandro Lunghi"],"url":"https://arxiv.org/abs/2504.13749"}
{"created":"2025-04-21","title":"Modeling L1 Influence on L2 Pronunciation: An MFCC-Based Framework for Explainable Machine Learning and Pedagogical Feedback","abstract":"This study investigates the extent to which Mel-Frequency Cepstral Coefficients (MFCCs) capture first language (L1) transfer in extended second language (L2) English speech. Speech samples from Mandarin and American English L1 speakers were extracted from the GMU Speech Accent Archive, converted to WAV format, and processed to obtain thirteen MFCCs per speaker. A multi-method analytic framework combining inferential statistics (t-tests, MANOVA, Canonical Discriminant Analysis) and machine learning (Random Forest classification) identified MFCC-1 (broadband energy), MFCC-2 (first formant region), and MFCC-5 (voicing and fricative energy) as the most discriminative features for distinguishing L1 backgrounds. A reduced-feature model using these MFCCs significantly outperformed the full-feature model, as confirmed by McNemar's test and non-overlapping confidence intervals. The findings empirically support the Perceptual Assimilation Model for L2 (PAM-L2) and the Speech Learning Model (SLM), demonstrating that L1-conditioned variation in L2 speech is both perceptually grounded and acoustically quantifiable. Methodologically, the study contributes to applied linguistics and explainable AI by proposing a transparent, data-efficient pipeline for L2 pronunciation modeling. The results also offer pedagogical implications for ESL/EFL instruction by highlighting L1-specific features that can inform intelligibility-oriented instruction, curriculum design, and speech assessment tools.","authors":["Peyman Jahanbin"],"url":"https://arxiv.org/abs/2504.13765"}
{"created":"2025-04-21","title":"Robust Decentralized Quantum Kernel Learning for Noisy and Adversarial Environment","abstract":"This paper proposes a general decentralized framework for quantum kernel learning (QKL). It has robustness against quantum noise and can also be designed to defend adversarial information attacks forming a robust approach named RDQKL. We analyze the impact of noise on QKL and study the robustness of decentralized QKL to the noise. By integrating robust decentralized optimization techniques, our method is able to mitigate the impact of malicious data injections across multiple nodes. Experimental results demonstrate that our approach maintains high accuracy under noisy quantum operations and effectively counter adversarial modifications, offering a promising pathway towards the future practical, scalable and secure quantum machine learning (QML).","authors":["Wenxuan Ma","Kuan-Cheng Chen","Shang Yu","Mengxiang Liu","Ruilong Deng"],"url":"https://arxiv.org/abs/2504.13782"}
{"created":"2025-04-21","title":"Near-optimal algorithms for private estimation and sequential testing of collision probability","abstract":"We present new algorithms for estimating and testing \\emph{collision probability}, a fundamental measure of the spread of a discrete distribution that is widely used in many scientific fields. We describe an algorithm that satisfies $(\\alpha, \\beta)$-local differential privacy and estimates collision probability with error at most $\\epsilon$ using $\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$ samples for $\\alpha \\le 1$, which improves over previous work by a factor of $\\frac{1}{\\alpha^2}$. We also present a sequential testing algorithm for collision probability, which can distinguish between collision probability values that are separated by $\\epsilon$ using $\\tilde{O}(\\frac{1}{\\epsilon^2})$ samples, even when $\\epsilon$ is unknown. Our algorithms have nearly the optimal sample complexity, and in experiments we show that they require significantly fewer samples than previous methods.","authors":["Robert Busa-Fekete","Umar Syed"],"url":"https://arxiv.org/abs/2504.13804"}
{"created":"2025-04-21","title":"Ordered Yao graphs: maximum degree, edge numbers, and clique numbers","abstract":"For a positive integer $k$ and an ordered set of $n$ points in the plane, define its k-sector ordered Yao graphs as follows. Divide the plane around each point into $k$ equal sectors and draw an edge from each point to its closest predecessor in each of the $k$ sectors. We analyze several natural parameters of these graphs. Our main results are as follows:","authors":["P\\'eter \\'Agoston","Adrian Dumitrescu","Arsenii Sagdeev","Karamjeet Singh","Ji Zeng"],"url":"https://arxiv.org/abs/2504.13819"}
{"created":"2025-04-21","title":"A note on the growth factor in Gaussian elimination for Higham matrices","abstract":"The Higham matrix is a complex symmetric matrix A=B+iC, where both B and C are real, symmetric and positive definite and $\\mathrm{i}=\\sqrt{-1}$ is the imaginary unit. For any Higham matrix A, Ikramov et al. showed that the growth factor in Gaussian elimination is less than 3. In this paper, based on the previous results, a new bound of the growth factor is obtained by using the maximum of the condition numbers of matrixes B and C for the generalized Higham matrix A, which strengthens this bound to 2 and proves the Higham's conjecture.","authors":["Qian-Ping Guo","Xian-Ming Gu","Hou-biao Li"],"url":"https://arxiv.org/abs/1305.5211"}
{"created":"2025-04-21","title":"Algebras of Information. An Axiomatic Foundation","abstract":"The basic idea behind information algebras is that information comes in pieces, each referring to a certain question, that these pieces can be combined or aggregated and that the part relating to a given question can be extracted. This algebraic structure can be given different forms. Questions were originally represented by subsets of variables. Pieces of information were then represented by valuations associated with the domains of variables. This leads to an algebraic structure called valuation algebras. The basic axiomatics of this algebraic structure was in essence proposed by Shenoy and Shafer. Here a much more general view of systems of questions is proposed and pieces of information are related to the elements of this system of questions. This leads to a new and extended system of axioms for information algebras. Classical valuation algebras are essentially a special case of this new system. A full discussion of the algebraic theory of this new information algebras is given, including local computation, duality between labeled and domain-free versions of the algebras, order of information, finiteness of information and approximation, compact and continuous information algebras. Finally a rather complete discussion of uncertain information, based on random maps into information algebras is presented. This is shown to represent a generalisation of classical Dempster-Shafer theory.","authors":["Juerg Kohlas"],"url":"https://arxiv.org/abs/1701.02658"}
{"created":"2025-04-21","title":"Reducing Deep Network Complexity via Sparse Hierarchical Fourier Interaction Networks","abstract":"This paper presents a Sparse Hierarchical Fourier Interaction Networks, an architectural building block that unifies three complementary principles of frequency domain modeling: A hierarchical patch wise Fourier transform that affords simultaneous access to local detail and global context; A learnable, differentiable top K masking mechanism which retains only the most informative spectral coefficients, thereby exploiting the natural compressibility of visual and linguistic signals.","authors":["Andrew Kiruluta","Samantha Williams"],"url":"https://arxiv.org/abs/1801.01451"}
{"created":"2025-04-21","title":"Beyond Grids: Multi-objective Bayesian Optimization With Adaptive Discretization","abstract":"We consider the problem of optimizing a vector-valued objective function $\\boldsymbol{f}$ sampled from a Gaussian Process (GP) whose index set is a well-behaved, compact metric space $({\\cal X},d)$ of designs. We assume that $\\boldsymbol{f}$ is not known beforehand and that evaluating $\\boldsymbol{f}$ at design $x$ results in a noisy observation of $\\boldsymbol{f}(x)$. Since identifying the Pareto optimal designs via exhaustive search is infeasible when the cardinality of ${\\cal X}$ is large, we propose an algorithm, called Adaptive $\\boldsymbol{\\epsilon}$-PAL, that exploits the smoothness of the GP-sampled function and the structure of $({\\cal X},d)$ to learn fast. In essence, Adaptive $\\boldsymbol{\\epsilon}$-PAL employs a tree-based adaptive discretization technique to identify an $\\boldsymbol{\\epsilon}$-accurate Pareto set of designs in as few evaluations as possible. We provide both information-type and metric dimension-type bounds on the sample complexity of $\\boldsymbol{\\epsilon}$-accurate Pareto set identification. We also experimentally show that our algorithm outperforms other Pareto set identification methods.","authors":["Andi Nika","Sepehr Elahi","\\c{C}a\\u{g}{\\i}n Ararat","Cem Tekin"],"url":"https://arxiv.org/abs/2006.14061"}
{"created":"2025-04-21","title":"Energy-Latency Attacks via Sponge Poisoning","abstract":"Sponge examples are test-time inputs optimized to increase energy consumption and prediction latency of deep networks deployed on hardware accelerators. By increasing the fraction of neurons activated during classification, these attacks reduce sparsity in network activation patterns, worsening the performance of hardware accelerators. In this work, we present a novel training-time attack, named sponge poisoning, which aims to worsen energy consumption and prediction latency of neural networks on any test input without affecting classification accuracy. To stage this attack, we assume that the attacker can control only a few model updates during training -- a likely scenario, e.g., when model training is outsourced to an untrusted third party or distributed via federated learning. Our extensive experiments on image classification tasks show that sponge poisoning is effective, and that fine-tuning poisoned models to repair them poses prohibitive costs for most users, highlighting that tackling sponge poisoning remains an open issue.","authors":["Antonio Emanuele Cin\\`a","Ambra Demontis","Battista Biggio","Fabio Roli","Marcello Pelillo"],"url":"https://arxiv.org/abs/2203.08147"}
{"created":"2025-04-21","title":"On the Shift Invariance of Max Pooling Feature Maps in Convolutional Neural Networks","abstract":"This paper focuses on improving the mathematical interpretability of convolutional neural networks (CNNs) in the context of image classification. Specifically, we tackle the instability issue arising in their first layer, which tends to learn parameters that closely resemble oriented band-pass filters when trained on datasets like ImageNet. Subsampled convolutions with such Gabor-like filters are prone to aliasing, causing sensitivity to small input shifts. In this context, we establish conditions under which the max pooling operator approximates a complex modulus, which is nearly shift invariant. We then derive a measure of shift invariance for subsampled convolutions followed by max pooling. In particular, we highlight the crucial role played by the filter's frequency and orientation in achieving stability. We experimentally validate our theory by considering a deterministic feature extractor based on the dual-tree complex wavelet packet transform, a particular case of discrete Gabor-like decomposition.","authors":["Hubert Leterme","K\\'evin Polisano","Val\\'erie Perrier","Karteek Alahari"],"url":"https://arxiv.org/abs/2209.11740"}
{"created":"2025-04-21","title":"Manipulation of individual judgments in the quantitative pairwise comparisons method","abstract":"Decision-making methods very often use the technique of comparing alternatives in pairs. In this approach, experts are asked to compare different options, and then a quantitative ranking is created from the results obtained. It is commonly believed that experts (decision-makers) are honest in their judgments. In our work, we consider a scenario in which experts are vulnerable to bribery. For this purpose, we define a framework that allows us to determine the intended manipulation and present three algorithms for achieving the intended goal. Analyzing these algorithms may provide clues to help defend against such attacks.","authors":["M. Strada","K. Ku{\\l}akowski"],"url":"https://arxiv.org/abs/2211.01809"}
{"created":"2025-04-21","title":"Coinductive Streams in Monoidal Categories","abstract":"We introduce monoidal streams. Monoidal streams are a generalization of causal stream functions, which can be defined in cartesian monoidal categories, to arbitrary symmetric monoidal categories. In the same way that streams provide semantics to dataflow programming with pure functions, monoidal streams provide semantics to dataflow programming with theories of processes represented by a symmetric monoidal category. Monoidal streams also form a feedback monoidal category. In the same way that we can use a coinductive stream calculus to reason about signal flow graphs, we can use coinductive string diagrams to reason about feedback monoidal categories. As an example, we study syntax for a stochastic dataflow language, with semantics in stochastic monoidal streams.","authors":["Elena Di Lavore","Giovanni de Felice","Mario Rom\\'an"],"url":"https://arxiv.org/abs/2212.14494"}
{"created":"2025-04-21","title":"Evidential Decision Theory via Partial Markov Categories","abstract":"We introduce partial Markov categories. In the same way that Markov categories encode stochastic processes, partial Markov categories encode stochastic processes with constraints, observations and updates. In particular, we prove a synthetic Bayes theorem and we apply it to define a syntactic partial theory of observations on any Markov category, whose normalisations can be computed in the original Markov category. Finally, we formalise Evidential Decision Theory in terms of partial Markov categories, and provide implemented examples.","authors":["Elena Di Lavore","Mario Rom\\'an"],"url":"https://arxiv.org/abs/2301.12989"}
{"created":"2025-04-21","title":"Backstepping Temporal Difference Learning","abstract":"Off-policy learning ability is an important feature of reinforcement learning (RL) for practical applications. However, even one of the most elementary RL algorithms, temporal-difference (TD) learning, is known to suffer form divergence issue when the off-policy scheme is used together with linear function approximation. To overcome the divergent behavior, several off-policy TD-learning algorithms, including gradient-TD learning (GTD), and TD-learning with correction (TDC), have been developed until now. In this work, we provide a unified view of such algorithms from a purely control-theoretic perspective, and propose a new convergent algorithm. Our method relies on the backstepping technique, which is widely used in nonlinear control theory. Finally, convergence of the proposed algorithm is experimentally verified in environments where the standard TD-learning is known to be unstable.","authors":["Han-Dong Lim","Donghwan Lee"],"url":"https://arxiv.org/abs/2302.09875"}
{"created":"2025-04-21","title":"LaMD: Latent Motion Diffusion for Image-Conditional Video Generation","abstract":"The video generation field has witnessed rapid improvements with the introduction of recent diffusion models. While these models have successfully enhanced appearance quality, they still face challenges in generating coherent and natural movements while efficiently sampling videos. In this paper, we propose to condense video generation into a problem of motion generation, to improve the expressiveness of motion and make video generation more manageable. This can be achieved by breaking down the video generation process into latent motion generation and video reconstruction. Specifically, we present a latent motion diffusion (LaMD) framework, which consists of a motion-decomposed video autoencoder and a diffusion-based motion generator, to implement this idea. Through careful design, the motion-decomposed video autoencoder can compress patterns in movement into a concise latent motion representation. Consequently, the diffusion-based motion generator is able to efficiently generate realistic motion on a continuous latent space under multi-modal conditions, at a cost that is similar to that of image diffusion models. Results show that LaMD generates high-quality videos on various benchmark datasets, including BAIR, Landscape, NATOPS, MUG and CATER-GEN, that encompass a variety of stochastic dynamics and highly controllable movements on multiple image-conditional video generation tasks, while significantly decreases sampling time.","authors":["Yaosi Hu","Zhenzhong Chen","Chong Luo"],"url":"https://arxiv.org/abs/2304.11603"}
{"created":"2025-04-21","title":"Cooperation Is All You Need","abstract":"Going beyond 'dendritic democracy', we introduce a 'democracy of local processors', termed Cooperator. Here we compare their capabilities when used in permutation invariant neural networks for reinforcement learning (RL), with machine learning algorithms based on Transformers, such as ChatGPT. Transformers are based on the long standing conception of integrate-and-fire 'point' neurons, whereas Cooperator is inspired by recent neurobiological breakthroughs suggesting that the cellular foundations of mental life depend on context-sensitive pyramidal neurons in the neocortex which have two functionally distinct points. Weshow that when used for RL, an algorithm based on Cooperator learns far quicker than that based on Transformer, even while having the same number of parameters.","authors":["Ahsan Adeel","Junaid Muzaffar","Fahad Zia","Khubaib Ahmed","Mohsin Raza","Eamin Chaudary","Talha Bin Riaz","Ahmed Saeed"],"url":"https://arxiv.org/abs/2305.10449"}
{"created":"2025-04-21","title":"Approximation-Generalization Trade-offs under (Approximate) Group Equivariance","abstract":"The explicit incorporation of task-specific inductive biases through symmetry has emerged as a general design precept in the development of high-performance machine learning models. For example, group equivariant neural networks have demonstrated impressive performance across various domains and applications such as protein and drug design. A prevalent intuition about such models is that the integration of relevant symmetry results in enhanced generalization. Moreover, it is posited that when the data and/or the model may only exhibit $\\textit{approximate}$ or $\\textit{partial}$ symmetry, the optimal or best-performing model is one where the model symmetry aligns with the data symmetry. In this paper, we conduct a formal unified investigation of these intuitions. To begin, we present general quantitative bounds that demonstrate how models capturing task-specific symmetries lead to improved generalization. In fact, our results do not require the transformations to be finite or even form a group and can work with partial or approximate equivariance. Utilizing this quantification, we examine the more general question of model mis-specification i.e. when the model symmetries don't align with the data symmetries. We establish, for a given symmetry group, a quantitative comparison between the approximate/partial equivariance of the model and that of the data distribution, precisely connecting model equivariance error and data equivariance error. Our result delineates conditions under which the model equivariance error is optimal, thereby yielding the best-performing model for the given task and data. Our results are the most general results of their type in the literature.","authors":["Mircea Petrache","Shubhendu Trivedi"],"url":"https://arxiv.org/abs/2305.17592"}
{"created":"2025-04-21","title":"Joint Oscillation Damping and Inertia Provision Service for Converter-Interfaced Generation","abstract":"Power systems dominated by converter-interfaced distributed energy resources (DERs) typically exhibit weaker damping capabilities and lower inertia, compromising system stability. Although individual DER controllers are evolving to provide superior oscillation damping capabilities and inertia supports, there is a lack of network-wide coordinated management measures for multiple DERs, potentially leading to unexpected instability and cost-effectiveness problems. To address this gap, this paper introduces a hybrid oscillation damping and inertia management strategy for multiple DERs, considering network coupling effects, and seeks to encourage DERs to provide enhanced damping and inertia with appropriate economic incentives. We first formulate an optimization problem to tune and allocate damping and inertia coefficients for DERs, minimizing associated power and energy costs while ensuring hard constraints for system frequency stability and small-signal stability. The problem is built upon a novel convex parametric formulation that integrates oscillation mode location and frequency trajectory requirements, equipped with a theoretical guarantee, and eliminating the need for iterative tuning and computation burdens. Furthermore, to increase the willingness of DERs to cooperate, we further design appropriate economic incentives to compensate for DERs' costs based on the proposed cost minimization problem, and assess its impact on system cost-efficiency. Numerical tests highlight the effectiveness of the proposed method in promoting system stability and offer insights into potential economic benefits.","authors":["Cheng Feng","Linbin Huang","Xiuqiang He","Yi Wang","Florian D\\\"orfler","Chongqing Kang"],"url":"https://arxiv.org/abs/2309.01321"}
{"created":"2025-04-21","title":"Robust Average Networks for Monte Carlo Denoising","abstract":"We present a method for converting denoising neural networks from spatial into spatio-temporal ones by modifying the network architecture and loss function. We insert Robust Average blocks at arbitrary depths in the network graph. Each block performs latent space interpolation with trainable weights and works on the sequence of image representations from the preceding spatial components of the network. The temporal connections are kept live during training by forcing the network to predict a denoised frame from subsets of the input sequence. Using temporal coherence for denoising improves image quality and reduces temporal flickering independent of scene or image complexity.","authors":["Javor Kalojanov","Kimball Thurston"],"url":"https://arxiv.org/abs/2310.04080"}
{"created":"2025-04-21","title":"Foundational theories of hesitant fuzzy sets and families of hesitant fuzzy sets","abstract":"Hesitant fuzzy sets find extensive application in specific scenarios involving uncertainty and hesitation. In the context of set theory, the concept of inclusion relationship holds significant importance as a fundamental definition. Consequently, as a type of sets, hesitant fuzzy sets necessitate a clear and explicit definition of the inclusion relationship. Based on the discrete form of hesitant fuzzy membership degrees, this study proposes multiple types of inclusion relationships for hesitant fuzzy sets. Subsequently, this paper introduces foundational propositions related to hesitant fuzzy sets, as well as propositions concerning families of hesitant fuzzy sets.","authors":["Shizhan Lu","Zeshui Xu","Zhu Fu","Longsheng Cheng","Tongbin Yang"],"url":"https://arxiv.org/abs/2311.04256"}
{"created":"2025-04-21","title":"LDM-ISP: Enhancing Neural ISP for Low Light with Latent Diffusion Models","abstract":"Enhancing a low-light noisy RAW image into a well-exposed and clean sRGB image is a significant challenge for modern digital cameras. Prior approaches have difficulties in recovering fine-grained details and true colors of the scene under extremely low-light environments due to near-to-zero SNR. Meanwhile, diffusion models have shown significant progress towards general domain image generation. In this paper, we propose to leverage the pre-trained latent diffusion model to perform the neural ISP for enhancing extremely low-light images. Specifically, to tailor the pre-trained latent diffusion model to operate on the RAW domain, we train a set of lightweight taming modules to inject the RAW information into the diffusion denoising process via modulating the intermediate features of UNet. We further observe different roles of UNet denoising and decoder reconstruction in the latent diffusion model, which inspires us to decompose the low-light image enhancement task into latent-space low-frequency content generation and decoding-phase high-frequency detail maintenance. Through extensive experiments on representative datasets, we demonstrate our simple design not only achieves state-of-the-art performance in quantitative evaluations but also shows significant superiority in visual comparisons over strong baselines, which highlight the effectiveness of powerful generative priors for neural ISP under extremely low-light environments. The project page is available at https://csqiangwen.github.io/projects/ldm-isp/","authors":["Qiang Wen","Zhefan Rao","Yazhou Xing","Qifeng Chen"],"url":"https://arxiv.org/abs/2312.01027"}
{"created":"2025-04-21","title":"Unleashing the Power of CNN and Transformer for Balanced RGB-Event Video Recognition","abstract":"Pattern recognition based on RGB-Event data is a newly arising research topic and previous works usually learn their features using CNN or Transformer. As we know, CNN captures the local features well and the cascaded self-attention mechanisms are good at extracting the long-range global relations. It is intuitive to combine them for high-performance RGB-Event based video recognition, however, existing works fail to achieve a good balance between the accuracy and model parameters, as shown in Fig.~\\ref{firstimage}. In this work, we propose a novel RGB-Event based recognition framework termed TSCFormer, which is a relatively lightweight CNN-Transformer model. Specifically, we mainly adopt the CNN as the backbone network to first encode both RGB and Event data. Meanwhile, we initialize global tokens as the input and fuse them with RGB and Event features using the BridgeFormer module. It captures the global long-range relations well between both modalities and maintains the simplicity of the whole model architecture at the same time. The enhanced features will be projected and fused into the RGB and Event CNN blocks, respectively, in an interactive manner using F2E and F2V modules. Similar operations are conducted for other CNN blocks to achieve adaptive fusion and local-global feature enhancement under different resolutions. Finally, we concatenate these three features and feed them into the classification head for pattern recognition. Extensive experiments on two large-scale RGB-Event benchmark datasets (PokerEvent and HARDVS) fully validated the effectiveness of our proposed TSCFormer. The source code and pre-trained models will be released at https://github.com/Event-AHU/TSCFormer.","authors":["Xiao Wang","Yao Rong","Shiao Wang","Yuan Chen","Zhe Wu","Bo Jiang","Yonghong Tian","Jin Tang"],"url":"https://arxiv.org/abs/2312.11128"}
{"created":"2025-04-21","title":"Only Send What You Need: Learning to Communicate Efficiently in Federated Multilingual Machine Translation","abstract":"Federated learning (FL) is a promising distributed machine learning paradigm that enables multiple clients to collaboratively train a global model. In this paper, we focus on a practical federated multilingual learning setup where clients with their own language-specific data aim to collaboratively construct a high-quality neural machine translation (NMT) model. However, communication constraints in practical network systems present challenges for exchanging large-scale NMT engines between FL parties. We propose a meta-learning-based adaptive parameter selection methodology, MetaSend, that improves the communication efficiency of model transmissions from clients during FL-based multilingual NMT training. Our approach learns a dynamic threshold for filtering parameters prior to transmission without compromising the NMT model quality, based on the tensor deviations of clients between different FL rounds. Through experiments on two NMT datasets with different language distributions, we demonstrate that MetaSend obtains substantial improvements over baselines in translation quality in the presence of a limited communication budget.","authors":["Yun-Wei Chu","Dong-Jun Han","Christopher G. Brinton"],"url":"https://arxiv.org/abs/2401.07456"}
{"created":"2025-04-21","title":"GRASP: GRAph-Structured Pyramidal Whole Slide Image Representation","abstract":"Cancer subtyping is one of the most challenging tasks in digital pathology, where Multiple Instance Learning (MIL) by processing gigapixel whole slide images (WSIs) has been in the spotlight of recent research. However, MIL approaches do not take advantage of inter- and intra-magnification information contained in WSIs. In this work, we present GRASP, a novel lightweight graph-structured multi-magnification framework for processing WSIs in digital pathology. Our approach is designed to dynamically emulate the pathologist's behavior in handling WSIs and benefits from the hierarchical structure of WSIs. GRASP, which introduces a convergence-based node aggregation mechanism replacing traditional pooling mechanisms, outperforms state-of-the-art methods by a high margin in terms of balanced accuracy, while being significantly smaller than the closest-performing state-of-the-art models in terms of the number of parameters. Our results show that GRASP is dynamic in finding and consulting with different magnifications for subtyping cancers, is reliable and stable across different hyperparameters, and can generalize when using features from different backbones. The model's behavior has been evaluated by two expert pathologists confirming the interpretability of the model's dynamic. We also provide a theoretical foundation, along with empirical evidence, for our work, explaining how GRASP interacts with different magnifications and nodes in the graph to make predictions. We believe that the strong characteristics yet simple structure of GRASP will encourage the development of interpretable, structure-based designs for WSI representation in digital pathology. Data and code can be found in https://github.com/AIMLab-UBC/GRASP","authors":["Ali Khajegili Mirabadi","Graham Archibald","Amirali Darbandsari","Alberto Contreras-Sanz","Ramin Ebrahim Nakhli","Maryam Asadi","Allen Zhang","C. Blake Gilks","Peter Black","Gang Wang","Hossein Farahani","Ali Bashashati"],"url":"https://arxiv.org/abs/2402.03592"}
{"created":"2025-04-21","title":"A Theory of LLM Sampling: Part Descriptive and Part Prescriptive","abstract":"Large Language Models (LLMs) are increasingly utilized in autonomous decision-making, where they sample options from vast action spaces. However, the heuristics that guide this sampling process remain under-explored. We study this sampling behavior and show that this underlying heuristics resembles that of human decision-making: comprising a descriptive component (reflecting statistical norm) and a prescriptive component (implicit ideal encoded in the LLM) of a concept. We show that this deviation of a sample from the statistical norm towards a prescriptive component consistently appears in concepts across diverse real-world domains like public health, and economic trends. To further illustrate the theory, we demonstrate that concept prototypes in LLMs are affected by prescriptive norms, similar to the concept of normality in humans. Through case studies and comparison with human studies, we illustrate that in real-world applications, the shift of samples toward an ideal value in LLMs' outputs can result in significantly biased decision-making, raising ethical concerns.","authors":["Sarath Sivaprasad","Pramod Kaushik","Sahar Abdelnabi","Mario Fritz"],"url":"https://arxiv.org/abs/2402.11005"}
{"created":"2025-04-21","title":"Where is the answer? Investigating Positional Bias in Language Model Knowledge Extraction","abstract":"Large language models require updates to remain up-to-date or adapt to new domains by fine-tuning them with new documents. One key is memorizing the latest information in a way that the memorized information is extractable with a query prompt. However, LLMs suffer from a phenomenon called perplexity curse; despite minimizing document perplexity during fine-tuning, LLMs struggle to extract information through a prompt sentence. In this new knowledge acquisition and extraction, we find a very intriguing fact that LLMs can accurately answer questions about the first sentence, but they struggle to extract information described in the middle or end of the documents used for fine-tuning. Our study suggests that the auto-regressive training causes this issue; each token is prompted by reliance on all previous tokens, which hinders the model from recalling information from training documents by question prompts. To conduct the in-depth study, we publish both synthetic and real datasets, enabling the evaluation of the QA performance w.r.t. the position of the corresponding answer in a document. Our investigation shows that even a large model suffers from the perplexity curse, but regularization such as denoising auto-regressive loss can enhance the information extraction from diverse positions. These findings will be (i) a key to improving knowledge extraction from LLMs and (ii) new elements to discuss the trade-off between RAG and fine-tuning in adapting LLMs to a new domain.","authors":["Kuniaki Saito","Kihyuk Sohn","Chen-Yu Lee","Yoshitaka Ushiku"],"url":"https://arxiv.org/abs/2402.12170"}
{"created":"2025-04-21","title":"E(3)-equivariant models cannot learn chirality: Field-based molecular generation","abstract":"Obtaining the desired effect of drugs is highly dependent on their molecular geometries. Thus, the current prevailing paradigm focuses on 3D point-cloud atom representations, utilizing graph neural network (GNN) parametrizations, with rotational symmetries baked in via E(3) invariant layers. We prove that such models must necessarily disregard chirality, a geometric property of the molecules that cannot be superimposed on their mirror image by rotation and translation. Chirality plays a key role in determining drug safety and potency. To address this glaring issue, we introduce a novel field-based representation, proposing reference rotations that replace rotational symmetry constraints. The proposed model captures all molecular geometries including chirality, while still achieving highly competitive performance with E(3)-based methods across standard benchmarking metrics.","authors":["Alexandru Dumitrescu","Dani Korpela","Markus Heinonen","Yogesh Verma","Valerii Iakovlev","Vikas Garg","Harri L\\\"ahdesm\\\"aki"],"url":"https://arxiv.org/abs/2402.15864"}
{"created":"2025-04-21","title":"Masked Capsule Autoencoders","abstract":"We propose Masked Capsule Autoencoders (MCAE), the first Capsule Network that utilises pretraining in a modern self-supervised paradigm, specifically the masked image modelling framework. Capsule Networks have emerged as a powerful alternative to Convolutional Neural Networks (CNNs). They have shown favourable properties when compared to Vision Transformers (ViT), but have struggled to effectively learn when presented with more complex data. This has led to Capsule Network models that do not scale to modern tasks. Our proposed MCAE model alleviates this issue by reformulating the Capsule Network to use masked image modelling as a pretraining stage before finetuning in a supervised manner. Across several experiments and ablations studies we demonstrate that similarly to CNNs and ViTs, Capsule Networks can also benefit from self-supervised pretraining, paving the way for further advancements in this neural network domain. For instance, by pretraining on the Imagenette dataset-consisting of 10 classes of Imagenet-sized images-we achieve state-of-the-art results for Capsule Networks, demonstrating a 9% improvement compared to our baseline model. Thus, we propose that Capsule Networks benefit from and should be trained within a masked image modelling framework, using a novel capsule decoder, to enhance a Capsule Network's performance on realistically sized images.","authors":["Miles Everett","Mingjun Zhong","Georgios Leontidis"],"url":"https://arxiv.org/abs/2403.04724"}
{"created":"2025-04-21","title":"ES-FUZZ: Improving the Coverage of Firmware Fuzzing with Stateful and Adaptable MMIO Models","abstract":"Gray-box fuzzing is widely used for testing embedded systems (ESes). State-of-the-art (SOTA) gray-box fuzzers test ES firmware in fully emulated environments without real peripherals. They emulate missing peripherals to achieve decent code coverage. Some fuzzers infer the memory-mapped I/O (MMIO) behavior of firmware peripherals from the firmware binary. We find that these fuzzers emulate the inferred MMIO behavior using stateless and non-adaptive MMIO models, which perform poorly in handling ES firmware's MMIO reads to collectively retrieve a data chunk. This leaves ample room for improving the code coverage of these fuzzers.","authors":["Wei-Lun Huang","Kang G. Shin"],"url":"https://arxiv.org/abs/2403.06281"}
{"created":"2025-04-21","title":"LeOCLR: Leveraging Original Images for Contrastive Learning of Visual Representations","abstract":"Contrastive instance discrimination methods outperform supervised learning in downstream tasks such as image classification and object detection. However, these methods rely heavily on data augmentation during representation learning, which can lead to suboptimal results if not implemented carefully. A common augmentation technique in contrastive learning is random cropping followed by resizing. This can degrade the quality of representation learning when the two random crops contain distinct semantic content. To tackle this issue, we introduce LeOCLR (Leveraging Original Images for Contrastive Learning of Visual Representations), a framework that employs a novel instance discrimination approach and an adapted loss function. This method prevents the loss of important semantic features caused by mapping different object parts during representation learning. Our experiments demonstrate that LeOCLR consistently improves representation learning across various datasets, outperforming baseline models. For instance, LeOCLR surpasses MoCo-v2 by 5.1% on ImageNet-1K in linear evaluation and outperforms several other methods on transfer learning and object detection tasks.","authors":["Mohammad Alkhalefi","Georgios Leontidis","Mingjun Zhong"],"url":"https://arxiv.org/abs/2403.06813"}
{"created":"2025-04-21","title":"DialogGen: Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation","abstract":"Text-to-image (T2I) generation models have significantly advanced in recent years. However, effective interaction with these models is challenging for average users due to the need for specialized prompt engineering knowledge and the inability to perform multi-turn image generation, hindering a dynamic and iterative creation process. Recent attempts have tried to equip Multi-modal Large Language Models (MLLMs) with T2I models to bring the user's natural language instructions into reality. Hence, the output modality of MLLMs is extended, and the multi-turn generation quality of T2I models is enhanced thanks to the strong multi-modal comprehension ability of MLLMs. However, many of these works face challenges in identifying correct output modalities and generating coherent images accordingly as the number of output modalities increases and the conversations go deeper. Therefore, we propose DialogGen, an effective pipeline to align off-the-shelf MLLMs and T2I models to build a Multi-modal Interactive Dialogue System (MIDS) for multi-turn Text-to-Image generation. It is composed of drawing prompt alignment, careful training data curation, and error correction. Moreover, as the field of MIDS flourishes, comprehensive benchmarks are urgently needed to evaluate MIDS fairly in terms of output modality correctness and multi-modal output coherence. To address this issue, we introduce the Multi-modal Dialogue Benchmark (DialogBen), a comprehensive bilingual benchmark designed to assess the ability of MLLMs to generate accurate and coherent multi-modal content that supports image editing. It contains two evaluation metrics to measure the model's ability to switch modalities and the coherence of the output images. Our extensive experiments on DialogBen and user study demonstrate the effectiveness of DialogGen compared with other State-of-the-Art models.","authors":["Minbin Huang","Yanxin Long","Xinchi Deng","Ruihang Chu","Jiangfeng Xiong","Xiaodan Liang","Hong Cheng","Qinglin Lu","Wei Liu"],"url":"https://arxiv.org/abs/2403.08857"}
{"created":"2025-04-21","title":"Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks","abstract":"We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks. First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize a target logprob (e.g., of the token \"Sure\"), potentially with multiple restarts. In this way, we achieve 100% attack success rate -- according to GPT-4 as a judge -- on Vicuna-13B, Mistral-7B, Phi-3-Mini, Nemotron-4-340B, Llama-2-Chat-7B/13B/70B, Llama-3-Instruct-8B, Gemma-7B, GPT-3.5, GPT-4o, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with a 100% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many similarities with jailbreaking -- which is the algorithm that brought us the first place in the SaTML'24 Trojan Detection Competition. The common theme behind these attacks is that adaptivity is crucial: different models are vulnerable to different prompting templates (e.g., R2D2 is very sensitive to in-context learning prompts), some models have unique vulnerabilities based on their APIs (e.g., prefilling for Claude), and in some settings, it is crucial to restrict the token search space based on prior knowledge (e.g., for trojan detection). For reproducibility purposes, we provide the code, logs, and jailbreak artifacts in the JailbreakBench format at https://github.com/tml-epfl/llm-adaptive-attacks.","authors":["Maksym Andriushchenko","Francesco Croce","Nicolas Flammarion"],"url":"https://arxiv.org/abs/2404.02151"}
{"created":"2025-04-21","title":"Variational Stochastic Gradient Descent for Deep Neural Networks","abstract":"Current state-of-the-art optimizers are adaptive gradient-based optimization methods such as Adam. Recently, there has been an increasing interest in formulating gradient-based optimizers in a probabilistic framework for better modeling the uncertainty of the gradients. Here, we propose to combine both approaches, resulting in the Variational Stochastic Gradient Descent (VSGD) optimizer. We model gradient updates as a probabilistic model and utilize stochastic variational inference (SVI) to derive an efficient and effective update rule. Further, we show how our VSGD method relates to other adaptive gradient-based optimizers like Adam. Lastly, we carry out experiments on two image classification datasets and four deep neural network architectures, where we show that VSGD outperforms Adam and SGD.","authors":["Haotian Chen","Anna Kuzina","Babak Esmaeili","Jakub M Tomczak"],"url":"https://arxiv.org/abs/2404.06549"}
{"created":"2025-04-21","title":"Part-aware Shape Generation with Latent 3D Diffusion of Neural Voxel Fields","abstract":"This paper presents a novel latent 3D diffusion model for the generation of neural voxel fields, aiming to achieve accurate part-aware structures. Compared to existing methods, there are two key designs to ensure high-quality and accurate part-aware generation. On one hand, we introduce a latent 3D diffusion process for neural voxel fields, enabling generation at significantly higher resolutions that can accurately capture rich textural and geometric details. On the other hand, a part-aware shape decoder is introduced to integrate the part codes into the neural voxel fields, guiding the accurate part decomposition and producing high-quality rendering results. Through extensive experimentation and comparisons with state-of-the-art methods, we evaluate our approach across four different classes of data. The results demonstrate the superior generative capabilities of our proposed method in part-aware shape generation, outperforming existing state-of-the-art methods.","authors":["Yuhang Huang","SHilong Zou","Xinwang Liu","Kai Xu"],"url":"https://arxiv.org/abs/2405.00998"}
{"created":"2025-04-21","title":"Argumentative Large Language Models for Explainable and Contestable Claim Verification","abstract":"The profusion of knowledge encoded in large language models (LLMs) and their ability to apply this knowledge zero-shot in a range of settings makes them promising candidates for use in decision-making. However, they are currently limited by their inability to provide outputs which can be faithfully explained and effectively contested to correct mistakes. In this paper, we attempt to reconcile these strengths and weaknesses by introducing \\emph{argumentative LLMs (ArgLLMs)}, a method for augmenting LLMs with argumentative reasoning. Concretely, ArgLLMs construct argumentation frameworks, which then serve as the basis for formal reasoning in support of decision-making. The interpretable nature of these argumentation frameworks and formal reasoning means that any decision made by ArgLLMs may be explained and contested. We evaluate ArgLLMs' performance experimentally in comparison with state-of-the-art techniques, in the context of the decision-making task of claim verification. We also define novel properties to characterise contestability and assess ArgLLMs formally in terms of these properties.","authors":["Gabriel Freedman","Adam Dejl","Deniz Gorur","Xiang Yin","Antonio Rago","Francesca Toni"],"url":"https://arxiv.org/abs/2405.02079"}
{"created":"2025-04-21","title":"Babysit A Language Model From Scratch: Interactive Language Learning by Trials and Demonstrations","abstract":"Humans are efficient language learners and inherently social creatures. Our language development is largely shaped by our social interactions, for example, the demonstration and feedback from caregivers. Contrary to human language learning, recent advancements in large language models have primarily adopted a non-interactive training paradigm, and refined pre-trained models through feedback afterward. In this work, we explore how corrective feedback from interactions influences neural language acquisition from scratch through systematically controlled experiments, assessing whether it contributes to word learning efficiency in language models. We introduce a trial-and-demonstration (TnD) learning framework that incorporates three distinct components: student trials, teacher demonstrations, and a reward conditioned on language competence at various developmental stages. Our experiments reveal that the TnD approach accelerates word acquisition for student models of equal and smaller numbers of parameters, and we highlight the significance of both trials and demonstrations. We further show that the teacher's choices of words influence students' word-specific learning efficiency, and a practice-makes-perfect effect is evident by a strong correlation between the frequency of words in trials and their respective learning curves. Our findings suggest that interactive language learning, with teacher demonstrations and active trials, can facilitate efficient word learning in language models.","authors":["Ziqiao Ma","Zekun Wang","Joyce Chai"],"url":"https://arxiv.org/abs/2405.13828"}
{"created":"2025-04-21","title":"MallowsPO: Fine-Tune Your LLM with Preference Dispersions","abstract":"Direct Preference Optimization (DPO) has recently emerged as a popular approach to improve reinforcement learning with human feedback (RLHF), leading to better techniques to fine-tune large language models (LLM). A weakness of DPO, however, lies in its lack of capability to characterize the diversity of human preferences. Inspired by Mallows' theory of preference ranking, we develop in this paper a new approach, the MallowsPO. A distinct feature of this approach is a dispersion index, which reflects the dispersion of human preference to prompts. We show that existing DPO models can be reduced to special cases of this dispersion index, thus unified with MallowsPO. More importantly, we demonstrate (empirically) how to use this dispersion index to enhance the performance of DPO in a broad array of benchmark tasks, from synthetic bandit selection to controllable generations and dialogues, while maintaining great generalization capabilities. MallowsPO is also compatible with other SOTA offline preference optimization methods, boosting nearly 2\\% extra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.","authors":["Haoxian Chen","Hanyang Zhao","Henry Lam","David Yao","Wenpin Tang"],"url":"https://arxiv.org/abs/2405.14953"}
{"created":"2025-04-21","title":"SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems","abstract":"Surrogate models are used to predict the behavior of complex energy systems that are too expensive to simulate with traditional numerical methods. Our work introduces the use of language descriptions, which we call ``system captions'' or SysCaps, to interface with such surrogates. We argue that interacting with surrogates through text, particularly natural language, makes these models more accessible for both experts and non-experts. We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata. Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities, such as handling semantically related descriptions of the same test system. Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.","authors":["Patrick Emami","Zhaonan Li","Saumya Sinha","Truc Nguyen"],"url":"https://arxiv.org/abs/2405.19653"}
{"created":"2025-04-21","title":"Is In-Context Learning Sufficient for Instruction Following in LLMs?","abstract":"In-context learning (ICL) allows LLMs to learn from examples without changing their weights: this is a particularly promising capability for long-context LLMs that can potentially learn from many examples. Recently, Lin et al. (2024) proposed URIAL, a method using only three in-context examples to align base LLMs, achieving non-trivial instruction following performance. In this work, we show that, while effective, ICL alignment with URIAL still underperforms compared to instruction fine-tuning on the established benchmark MT-Bench, especially with more capable base LLMs. We then uncover the most relevant elements for successful in-context alignment, finding the crucial role of the decoding parameters. Based on these insights, we show that the approach of URIAL can indeed be improved by adding high-quality, potentially carefully selected via greedy search, demonstrations in context, getting closer to the performance of instruct models. Finally, we provide the first, to our knowledge, systematic comparison of ICL and instruction fine-tuning (IFT) for instruction following in the low data regime, where ICL can be a viable alternative to IFT. Overall, our work advances the understanding of ICL as an alignment technique and its relationship to IFT. We provide our code at https://github.com/tml-epfl/icl-alignment.","authors":["Hao Zhao","Maksym Andriushchenko","Francesco Croce","Nicolas Flammarion"],"url":"https://arxiv.org/abs/2405.19874"}
{"created":"2025-04-21","title":"IReNe: Instant Recoloring of Neural Radiance Fields","abstract":"Advances in NERFs have allowed for 3D scene reconstructions and novel view synthesis. Yet, efficiently editing these representations while retaining photorealism is an emerging challenge. Recent methods face three primary limitations: they're slow for interactive use, lack precision at object boundaries, and struggle to ensure multi-view consistency. We introduce IReNe to address these limitations, enabling swift, near real-time color editing in NeRF. Leveraging a pre-trained NeRF model and a single training image with user-applied color edits, IReNe swiftly adjusts network parameters in seconds. This adjustment allows the model to generate new scene views, accurately representing the color changes from the training image while also controlling object boundaries and view-specific effects. Object boundary control is achieved by integrating a trainable segmentation module into the model. The process gains efficiency by retraining only the weights of the last network layer. We observed that neurons in this layer can be classified into those responsible for view-dependent appearance and those contributing to diffuse appearance. We introduce an automated classification approach to identify these neuron types and exclusively fine-tune the weights of the diffuse neurons. This further accelerates training and ensures consistent color edits across different views. A thorough validation on a new dataset, with edited object colors, shows significant quantitative and qualitative advancements over competitors, accelerating speeds by 5x to 500x.","authors":["Alessio Mazzucchelli","Adrian Garcia-Garcia","Elena Garces","Fernando Rivas-Manzaneque","Francesc Moreno-Noguer","Adrian Penate-Sanchez"],"url":"https://arxiv.org/abs/2405.19876"}
{"created":"2025-04-21","title":"VCR: A Task for Pixel-Level Complex Reasoning in Vision Language Models via Restoring Occluded Text","abstract":"We introduce Visual Caption Restoration (VCR), a novel vision-language task that challenges models to accurately restore partially obscured texts using pixel-level hints within images. This task stems from the observation that text embedded in images is intrinsically different from common visual elements and natural language due to the need to align the modalities of vision, text, and text embedded in images. While numerous works have integrated text embedded in images into visual question-answering tasks, approaches to these tasks generally rely on optical character recognition or masked language modeling, thus reducing the task to mainly text-based processing. However, text-based processing becomes ineffective in VCR as accurate text restoration depends on the combined information from provided images, context, and subtle cues from the tiny exposed areas of masked texts. We develop a pipeline to generate synthetic images for the VCR task using image-caption pairs, with adjustable caption visibility to control the task difficulty. With this pipeline, we construct a dataset for VCR called VCR-Wiki using images with captions from Wikipedia, comprising 2.11M English and 346K Chinese entities in both easy and hard split variants. Our results reveal that current vision language models significantly lag behind human performance in the VCR task, and merely fine-tuning the models on our dataset does not lead to notable improvements. We release VCR-Wiki and the data construction code to facilitate future research.","authors":["Tianyu Zhang","Suyuchen Wang","Lu Li","Ge Zhang","Perouz Taslakian","Sai Rajeswar","Jie Fu","Bang Liu","Yoshua Bengio"],"url":"https://arxiv.org/abs/2406.06462"}
{"created":"2025-04-21","title":"Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection","abstract":"The spread of fake news harms individuals and presents a critical social challenge that must be addressed. Although numerous algorithmic and insightful features have been developed to detect fake news, many of these features can be manipulated with style-conversion attacks, especially with the emergence of advanced language models, making it more difficult to differentiate from genuine news. This study proposes adversarial style augmentation, AdStyle, designed to train a fake news detector that remains robust against various style-conversion attacks. The primary mechanism involves the strategic use of LLMs to automatically generate a diverse and coherent array of style-conversion attack prompts, enhancing the generation of particularly challenging prompts for the detector. Experiments indicate that our augmentation strategy significantly improves robustness and detection performance when evaluated on fake news benchmark datasets.","authors":["Sungwon Park","Sungwon Han","Xing Xie","Jae-Gil Lee","Meeyoung Cha"],"url":"https://arxiv.org/abs/2406.11260"}
{"created":"2025-04-21","title":"Can Tool-augmented Large Language Models be Aware of Incomplete Conditions?","abstract":"Recent advancements in integrating large language models (LLMs) with tools have allowed the models to interact with real-world environments. However, these tool-augmented LLMs often encounter incomplete scenarios when users provide partial information or the necessary tools are unavailable. Recognizing and managing such scenarios is crucial for LLMs to ensure their reliability, but this exploration remains understudied. This study examines whether LLMs can identify incomplete conditions and appropriately determine when to refrain from using tools. To this end, we address a dataset by manipulating instances from two datasets by removing necessary tools or essential information for tool invocation. Our experiments show that LLMs often struggle to identify the absence of information required to utilize specific tools and recognize the absence of appropriate tools. We further analyze model behaviors in different environments and compare their performance against humans. Our research can contribute to advancing reliable LLMs by addressing common scenarios during interactions between humans and LLMs. Our code and dataset will be publicly available.","authors":["Seungbin Yang","ChaeHun Park","Taehee Kim","Jaegul Choo"],"url":"https://arxiv.org/abs/2406.12307"}
{"created":"2025-04-21","title":"The Comparative Trap: Pairwise Comparisons Amplifies Biased Preferences of LLM Evaluators","abstract":"As large language models (LLMs) are increasingly used as evaluators for natural language generation tasks, ensuring unbiased assessments is essential. However, LLM evaluators often display biased preferences, such as favoring verbosity and authoritative tones. Our empirical analysis reveals that these biases are exacerbated in pairwise evaluation, where LLMs directly compare two outputs and easily prioritize superficial attributes. In contrast, pointwise evaluation, which assesses outputs independently, is less susceptible to such bias because each output is judged in isolation. To address the limitations of the pairwise evaluation, we introduce a novel evaluation method, PRePair, which integrates pointwise reasoning within a pairwise framework. PRePair effectively alleviates biased preference, improving performance on the adversarial benchmark (LLMBar) while outperforming pointwise evaluation on the standard benchmark (MT-Bench).","authors":["Hawon Jeong","ChaeHun Park","Jimin Hong","Hojoon Lee","Jaegul Choo"],"url":"https://arxiv.org/abs/2406.12319"}
{"created":"2025-04-21","title":"CholecInstanceSeg: A Tool Instance Segmentation Dataset for Laparoscopic Surgery","abstract":"In laparoscopic and robotic surgery, precise tool instance segmentation is an essential technology for advanced computer-assisted interventions. Although publicly available procedures of routine surgeries exist, they often lack comprehensive annotations for tool instance segmentation. Additionally, the majority of standard datasets for tool segmentation are derived from porcine(pig) surgeries. To address this gap, we introduce CholecInstanceSeg, the largest open-access tool instance segmentation dataset to date. Derived from the existing CholecT50 and Cholec80 datasets, CholecInstanceSeg provides novel annotations for laparoscopic cholecystectomy procedures in patients. Our dataset comprises 41.9k annotated frames extracted from 85 clinical procedures and 64.4k tool instances, each labelled with semantic masks and instance IDs. To ensure the reliability of our annotations, we perform extensive quality control, conduct label agreement statistics, and benchmark the segmentation results with various instance segmentation baselines. CholecInstanceSeg aims to advance the field by offering a comprehensive and high-quality open-access dataset for the development and evaluation of tool instance segmentation algorithms.","authors":["Oluwatosin Alabi","Ko Ko Zayar Toe","Zijian Zhou","Charlie Budd","Nicholas Raison","Miaojing Shi","Tom Vercauteren"],"url":"https://arxiv.org/abs/2406.16039"}
{"created":"2025-04-21","title":"Splitting Guarantees for Prophet Inequalities via Nonlinear Systems","abstract":"The prophet inequality is one of the cornerstone problems in optimal stopping theory and has become a crucial tool for designing sequential algorithms in Bayesian settings. In the i.i.d. $k$-selection prophet inequality problem, we sequentially observe $n$ non-negative random values sampled from a known distribution. Each time, a decision is made to accept or reject the value, and under the constraint of accepting at most $k$. For $k=1$, Hill and Kertz [Ann. Probab. 1982] provided an upper bound on the worst-case approximation ratio that was later matched by an algorithm of Correa et al. [Math. Oper. Res. 2021]. The worst-case tight approximation ratio for $k=1$ is computed by studying a differential equation that naturally appears when analyzing the optimal dynamic programming policy. A similar result for $k>1$ has remained elusive.","authors":["Johannes Brustle","Sebastian Perez-Salazar","Victor Verdugo"],"url":"https://arxiv.org/abs/2406.17767"}
{"created":"2025-04-21","title":"NeuroNAS: Enhancing Efficiency of Neuromorphic In-Memory Computing for Intelligent Mobile Agents through Hardware-Aware Spiking Neural Architecture Search","abstract":"Intelligent mobile agents (e.g., UGVs and UAVs) typically demand low power/energy consumption when solving their machine learning (ML)-based tasks, since they are usually powered by portable batteries with limited capacity. A potential solution is employing neuromorphic computing with Spiking Neural Networks (SNNs), which leverages event-based computation to enable ultra-low power/energy ML algorithms. To maximize the performance efficiency of SNN inference, the In-Memory Computing (IMC)-based hardware accelerators with emerging device technologies (e.g., RRAM) can be employed. However, SNN models are typically developed without considering constraints from the application and the underlying IMC hardware, thereby hindering SNNs from reaching their full potential in performance and efficiency. To address this, we propose NeuroNAS, a novel framework for developing energyefficient neuromorphic IMC for intelligent mobile agents using hardware-aware spiking neural architecture search (NAS), i.e., by quickly finding an SNN architecture that offers high accuracy under the given constraints (e.g., memory, area, latency, and energy consumption). Its key steps include: optimizing SNN operations to enable efficient NAS, employing quantization to minimize the memory footprint, developing an SNN architecture that facilitates an effective learning, and devising a systematic hardware-aware search algorithm to meet the constraints. Compared to the state-of-the-art techniques, NeuroNAS quickly finds SNN architectures (with 8bit weight precision) that maintain high accuracy by up to 6.6x search time speed-ups, while achieving up to 92% area savings, 1.2x latency improvements, 84% energy savings across different datasets (i.e., CIFAR-10, CIFAR-100, and TinyImageNet-200); while the state-of-the-art fail to meet all constraints at once.","authors":["Rachmad Vidya Wicaksana Putra","Muhammad Shafique"],"url":"https://arxiv.org/abs/2407.00641"}
{"created":"2025-04-21","title":"LLM-Select: Feature Selection with Large Language Models","abstract":"In this paper, we demonstrate a surprising capability of large language models (LLMs): given only input feature names and a description of a prediction task, they are capable of selecting the most predictive features, with performance rivaling the standard tools of data science. Remarkably, these models exhibit this capacity across various query mechanisms. For example, we zero-shot prompt an LLM to output a numerical importance score for a feature (e.g., \"blood pressure\") in predicting an outcome of interest (e.g., \"heart failure\"), with no additional context. In particular, we find that the latest models, such as GPT-4, can consistently identify the most predictive features regardless of the query mechanism and across various prompting strategies. We illustrate these findings through extensive experiments on real-world data, where we show that LLM-based feature selection consistently achieves strong performance competitive with data-driven methods such as the LASSO, despite never having looked at the downstream training data. Our findings suggest that LLMs may be useful not only for selecting the best features for training but also for deciding which features to collect in the first place. This could benefit practitioners in domains like healthcare and the social sciences, where collecting high-quality data comes at a high cost.","authors":["Daniel P. Jeong","Zachary C. Lipton","Pradeep Ravikumar"],"url":"https://arxiv.org/abs/2407.02694"}
{"created":"2025-04-21","title":"Language Representations Can be What Recommenders Need: Findings and Potentials","abstract":"Recent studies empirically indicate that language models (LMs) encode rich world knowledge beyond mere semantics, attracting significant attention across various fields. However, in the recommendation domain, it remains uncertain whether LMs implicitly encode user preference information. Contrary to prevailing understanding that LMs and traditional recommenders learn two distinct representation spaces due to the huge gap in language and behavior modeling objectives, this work re-examines such understanding and explores extracting a recommendation space directly from the language representation space. Surprisingly, our findings demonstrate that item representations, when linearly mapped from advanced LM representations, yield superior recommendation performance. This outcome suggests the possible homomorphism between the advanced language representation space and an effective item representation space for recommendation, implying that collaborative signals may be implicitly encoded within LMs. Motivated by these findings, we explore the possibility of designing advanced collaborative filtering (CF) models purely based on language representations without ID-based embeddings. To be specific, we incorporate several crucial components to build a simple yet effective model, with item titles as the input. Empirical results show that such a simple model can outperform leading ID-based CF models, which sheds light on using language representations for better recommendation. Moreover, we systematically analyze this simple model and find several key features for using advanced language representations: a good initialization for item representations, zero-shot recommendation abilities, and being aware of user intention. Our findings highlight the connection between language modeling and behavior modeling, which can inspire both natural language processing and recommender system communities.","authors":["Leheng Sheng","An Zhang","Yi Zhang","Yuxin Chen","Xiang Wang","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2407.05441"}
{"created":"2025-04-21","title":"Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization","abstract":"This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences. We categorize noise into pointwise noise, which includes low-quality data points, and pairwise noise, which encompasses erroneous data pair associations that affect preference rankings. Utilizing Distributionally Robust Optimization (DRO), we enhance DPO's resilience to these types of noise. Our theoretical insights reveal that DPO inherently embeds DRO principles, conferring robustness to pointwise noise, with the regularization coefficient $\\beta$ playing a critical role in its noise resistance. Extending this framework, we introduce Distributionally Robustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing against worst-case pairwise scenarios. The novel hyperparameter $\\beta'$ in Dr. DPO allows for fine-tuned control over data pair reliability, providing a strategic balance between exploration and exploitation in noisy training environments. Empirical evaluations demonstrate that Dr. DPO substantially improves the quality of generated text and response accuracy in preference datasets, showcasing enhanced performance in both noisy and noise-free settings. The code is available at https://github.com/junkangwu/Dr_DPO.","authors":["Junkang Wu","Yuexiang Xie","Zhengyi Yang","Jiancan Wu","Jiawei Chen","Jinyang Gao","Bolin Ding","Xiang Wang","Xiangnan He"],"url":"https://arxiv.org/abs/2407.07880"}
{"created":"2025-04-21","title":"Does Refusal Training in LLMs Generalize to the Past Tense?","abstract":"Refusal training is widely used to prevent LLMs from generating harmful, undesirable, or illegal outputs. We reveal a curious generalization gap in the current refusal training approaches: simply reformulating a harmful request in the past tense (e.g., \"How to make a Molotov cocktail?\" to \"How did people make a Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art LLMs. We systematically evaluate this method on Llama-3 8B, Claude-3.5 Sonnet, GPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o mini, GPT-4o, o1-mini, o1-preview, and R2D2 models using GPT-3.5 Turbo as a reformulation model. For example, the success rate of this simple attack on GPT-4o increases from 1% using direct requests to 88% using 20 past tense reformulation attempts on harmful requests from JailbreakBench with GPT-4 as a jailbreak judge. Interestingly, we also find that reformulations in the future tense are less effective, suggesting that refusal guardrails tend to consider past historical questions more benign than hypothetical future questions. Moreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending against past reformulations is feasible when past tense examples are explicitly included in the fine-tuning data. Overall, our findings highlight that the widely used alignment techniques -- such as SFT, RLHF, and adversarial training -- employed to align the studied models can be brittle and do not always generalize as intended. We provide code and jailbreak artifacts at https://github.com/tml-epfl/llm-past-tense.","authors":["Maksym Andriushchenko","Nicolas Flammarion"],"url":"https://arxiv.org/abs/2407.11969"}
{"created":"2025-04-21","title":"Physical Data Embedding for Memory Efficient AI","abstract":"Deep neural networks (DNNs) have achieved exceptional performance across various fields by learning complex, nonlinear mappings from large-scale datasets. However, they face challenges such as high memory requirements and computational costs with limited interpretability. This paper introduces an approach where master equations of physics are converted into multilayered networks that are trained via backpropagation. The resulting general-purpose model effectively encodes data in the properties of the underlying physical system. In contrast to existing methods wherein a trained neural network is used as a computationally efficient alternative for solving physical equations, our approach directly treats physics equations as trainable models. We demonstrate this physical embedding concept with the Nonlinear Schr\\\"odinger Equation (NLSE), which acts as trainable architecture for learning complex patterns including nonlinear mappings and memory effects from data. The network embeds data representation in orders of magnitude fewer parameters than conventional neural networks when tested on time series data. Notably, the trained \"Nonlinear Schr\\\"odinger Network\" is interpretable, with all parameters having physical meanings. This interpretability offers insight into the underlying dynamics of the system that produced the data. The proposed method of replacing traditional DNN feature learning architectures with physical equations is also extended to the Gross-Pitaevskii Equation, demonstrating the broad applicability of the framework to other master equations of physics. Among our results, an ablation study quantifies the relative importance of physical terms such as dispersion, nonlinearity, and potential energy for classification accuracy. We also outline the limitations of this approach as it relates to generalizability.","authors":["Callen MacPhee","Yiming Zhou","Bahram Jalali"],"url":"https://arxiv.org/abs/2407.14504"}
{"created":"2025-04-21","title":"Randomized Greedy Algorithms for Neural Network Optimization","abstract":"Greedy algorithms have been successfully analyzed and applied in training neural networks for solving variational problems, ensuring guaranteed convergence orders. In this paper, we extend the analysis of the orthogonal greedy algorithm (OGA) to convex optimization problems, establishing its optimal convergence rate. This result broadens the applicability of OGA by generalizing its optimal convergence rate from function approximation to convex optimization problems. In addition, we also address the issue regarding practical applicability of greedy algorithms, which is due to significant computational costs from the subproblems that involve an exhaustive search over a discrete dictionary. We propose to use a more practical approach of randomly discretizing the dictionary at each iteration of the greedy algorithm. We quantify the required size of the randomized discrete dictionary and prove that, with high probability, the proposed algorithm realizes a weak greedy algorithm, achieving optimal convergence orders. Through numerous numerical experiments on function approximation, linear and nonlinear elliptic partial differential equations, we validate our analysis on the optimal convergence rate and demonstrate the advantage of using randomized discrete dictionaries over a deterministic one by showing orders of magnitude reductions in the size of the discrete dictionary, particularly in higher dimensions.","authors":["Jinchao Xu","Xiaofeng Xu"],"url":"https://arxiv.org/abs/2407.17763"}
{"created":"2025-04-21","title":"MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks. Typically, LLMs are first pre-trained on large corpora and subsequently fine-tuned on task-specific datasets. However, during fine-tuning, LLMs may forget some knowledge acquired in the pre-training stage, leading to a decline in general capabilities. Existing approaches to mitigate forgetting often rely on access to pre-training data, which may be unavailable in many real-world scenarios--such as fine-tuning checkpoint-only open-source LLMs. To address this challenge, we propose a new fine-tuning algorithm termed Momentum-Filtered Optimizer (MoFO). MoFO is an extension of greedy block coordinate descent (BCD) methods: in each iteration, MoFO only updates the model parameters with the largest momentum magnitudes, while keeping all other parameters fixed. MoFO achieves similar fine-tuning performance to the default fine-tuning algorithm while effectively mitigating knowledge forgetting. We validate MoFO through rigorous convergence analysis and extensive experiments, demonstrating its effectiveness in mitigating forgetting without pre-training data.","authors":["Yupeng Chen","Senmiao Wang","Yushun Zhang","Zhihang Lin","Haozhe Zhang","Weijian Sun","Tian Ding","Ruoyu Sun"],"url":"https://arxiv.org/abs/2407.20999"}
{"created":"2025-04-21","title":"Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation with Multimodal Generative Pretraining","abstract":"We present Lumina-mGPT, a family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. By initializing from multimodal Generative PreTraining (mGPT), we demonstrate that decoder-only Autoregressive (AR) model can achieve image generation performance comparable to modern diffusion models with high efficiency through Flexible Progressive Supervised Fine-tuning (FP-SFT). Equipped with our proposed Unambiguous image Representation (UniRep), Lumina-mGPT can flexibly generate high-quality images of varying aspect ratios. Building on the strong image generation capabilities, we further explore Ominiponent Supervised Fine-tuning (Omni-SFT), an initial attempt to elevate Lumina-mGPT into a unified multi-modal generalist. The resulting model demonstrates versatile multimodal capabilities, including visual generation tasks like text-to-image/multiview generation and controllable generation, visual recognition tasks like segmentation and depth estimation, and vision-language tasks like multi-turn visual question answering, showing the rosy potential of the technical direction. Codes and checkpoints are available at https://github.com/Alpha-VLLM/Lumina-mGPT.","authors":["Dongyang Liu","Shitian Zhao","Le Zhuo","Weifeng Lin","Yu Qiao","Hongsheng Li","Peng Gao"],"url":"https://arxiv.org/abs/2408.02657"}
{"created":"2025-04-21","title":"Stochastic Trajectory Optimization for Robotic Skill Acquisition From a Suboptimal Demonstration","abstract":"Learning from Demonstration (LfD) has emerged as a crucial method for robots to acquire new skills. However, when given suboptimal task trajectory demonstrations with shape characteristics reflecting human preferences but subpar dynamic attributes such as slow motion, robots not only need to mimic the behaviors but also optimize the dynamic performance. In this work, we leverage optimization-based methods to search for a superior-performing trajectory whose shape is similar to that of the demonstrated trajectory. Specifically, we use Dynamic Time Warping (DTW) to quantify the difference between two trajectories and combine it with additional performance metrics, such as collision cost, to construct the cost function. Moreover, we develop a multi-policy version of the Stochastic Trajectory Optimization for Motion Planning (STOMP), called MSTOMP, which is more stable and robust to parameter changes. To deal with the jitter in the demonstrated trajectory, we further utilize the gain-controlling method in the frequency domain to denoise the demonstration and propose a computationally more efficient metric, called Mean Square Error in the Spectrum (MSES), that measures the trajectories' differences in the frequency domain. We also theoretically highlight the connections between the time domain and the frequency domain methods. Finally, we verify our method in both simulation experiments and real-world experiments, showcasing its improved optimization performance and stability compared to existing methods.","authors":["Chenlin Ming","Zitong Wang","Boxuan Zhang","Zhanxiang Cao","Xiaoming Duan","Jianping He"],"url":"https://arxiv.org/abs/2408.03131"}
{"created":"2025-04-21","title":"Natural Language Outlines for Code: Literate Programming in the LLM Era","abstract":"We propose using natural language outlines as a novel modality and interaction surface for providing AI assistance to developers throughout the software development process. An NL outline for a code function comprises multiple statements written in concise prose, which partition the code and summarize its main ideas in the style of literate programming. Crucially, we find that modern LLMs can generate accurate and high-quality NL outlines in practice. Moreover, NL outlines enable a bidirectional sync between code and NL, where a developer can change either code or NL and have the LLM automatically update the other. We discuss many use cases for NL outlines: they can accelerate understanding and navigation of code and diffs, simplify code maintenance, augment code search, steer code generation, and more. We then propose and compare multiple LLM prompting techniques for generating outlines and ask professional developers to judge outline quality. Finally, we present two case studies applying NL outlines toward code review and malware detection.","authors":["Kensen Shi","Deniz Alt{\\i}nb\\\"uken","Saswat Anand","Mihai Christodorescu","Katja Gr\\\"unwedel","Alexa Koenings","Sai Naidu","Anurag Pathak","Marc Rasi","Fredde Ribeiro","Brandon Ruffin","Siddhant Sanyam","Maxim Tabachnyk","Sara Toth","Roy Tu","Tobias Welp","Pengcheng Yin","Manzil Zaheer","Satish Chandra","Charles Sutton"],"url":"https://arxiv.org/abs/2408.04820"}
{"created":"2025-04-21","title":"Enabling Fast and Accurate Crowdsourced Annotation for Elevation-Aware Flood Extent Mapping","abstract":"Mapping the extent of flood events is a necessary and important aspect of disaster management. In recent years, deep learning methods have evolved as an effective tool to quickly label high resolution imagery and provide necessary flood extent mappings. These methods, though, require large amounts of annotated training data to create models that are accurate and robust to new flooded imagery. In this work, we present FloodTrace, a web-based application that enables effective crowdsourcing of flooded region annotation for machine learning applications. To create this application, we conducted extensive interviews with domain experts to produce a set of formal requirements. Our work brings topological segmentation tools to the web and greatly improves annotation efficiency compared to the state-of-the-art. The user-friendliness of our solution allows researchers to outsource annotations to non-experts and utilize them to produce training data with equal quality to fully expert-labeled data. We conducted a user study to confirm the effectiveness of our application in which 266 graduate students annotated high-resolution aerial imagery from Hurricane Matthew in North Carolina. Experimental results show the efficiency benefits of our application for untrained users, with median annotation time less than half the state-of-the-art annotation method. In addition, using our aggregation and correction framework, flood detection models trained on crowdsourced annotations were able to achieve performance equal to models trained on fully expert-labeled annotations, while requiring a fraction of the time on the part of the expert.","authors":["Landon Dyken","Saugat Adhikari","Pravin Poudel","Steve Petruzza","Da Yan","Will Usher","Sidharth Kumar"],"url":"https://arxiv.org/abs/2408.05350"}
{"created":"2025-04-21","title":"MambaMIM: Pre-training Mamba with State Space Token Interpolation and its Application to Medical Image Segmentation","abstract":"Recently, the state space model Mamba has demonstrated efficient long-sequence modeling capabilities, particularly for addressing long-sequence visual tasks in 3D medical imaging. However, existing generative self-supervised learning methods have not yet fully unleashed Mamba's potential for handling long-range dependencies because they overlook the inherent causal properties of state space sequences in masked modeling. To address this challenge, we propose a general-purpose pre-training framework called MambaMIM, a masked image modeling method based on a novel TOKen-Interpolation strategy (TOKI) for the selective structure state space sequence, which learns causal relationships of state space within the masked sequence. Further, MambaMIM introduces a bottom-up 3D hybrid masking strategy to maintain a masking consistency across different architectures and can be used on any single or hybrid Mamba architecture to enhance its multi-scale and long-range representation capability. We pre-train MambaMIM on a large-scale dataset of 6.8K CT scans and evaluate its performance across eight public medical segmentation benchmarks. Extensive downstream experiments reveal the feasibility and advancement of using Mamba for medical image pre-training. In particular, when we apply the MambaMIM to a customized architecture that hybridizes MedNeXt and Vision Mamba, we consistently obtain the state-of-the-art segmentation performance. The code is available at: https://github.com/FengheTan9/MambaMIM.","authors":["Fenghe Tang","Bingkun Nian","Yingtai Li","Zihang Jiang","Jie Yang","Wei Liu","S. Kevin Zhou"],"url":"https://arxiv.org/abs/2408.08070"}
{"created":"2025-04-21","title":"Unsupervised Machine Learning Hybrid Approach Integrating Linear Programming in Loss Function: A Robust Optimization Technique","abstract":"This paper presents a novel hybrid approach that integrates linear programming (LP) within the loss function of an unsupervised machine learning model. By leveraging the strengths of both optimization techniques and machine learning, this method introduces a robust framework for solving complex optimization problems where traditional methods may fall short. The proposed approach encapsulates the constraints and objectives of a linear programming problem directly into the loss function, guiding the learning process to adhere to these constraints while optimizing the desired outcomes. This technique not only preserves the interpretability of linear programming but also benefits from the flexibility and adaptability of machine learning, making it particularly well-suited for unsupervised or semi-supervised learning scenarios.","authors":["Andrew Kiruluta","Andreas Lemos"],"url":"https://arxiv.org/abs/2408.09967"}
{"created":"2025-04-21","title":"ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding","abstract":"Understanding biological processes, drug development, and biotechnological advancements requires a detailed analysis of protein structures and functions, a task that is inherently complex and time-consuming in traditional protein research. To streamline this process, we introduce ProteinGPT, a state-of-the-art multimodal large language model for proteins that enables users to upload protein sequences and/or structures for comprehensive analysis and responsive inquiries. ProteinGPT integrates protein sequence and structure encoders with linear projection layers to ensure precise representation adaptation and leverages a large language model (LLM) to generate accurate, contextually relevant responses. To train ProteinGPT, we constructed a large-scale dataset of 132,092 proteins, each annotated with 20-30 property tags and 5-10 QA pairs per protein, and optimized the instruction-tuning process using GPT-4o. Experiments demonstrate that ProteinGPT effectively generates informative responses to protein-related questions, achieving high performance on both semantic and lexical metrics and significantly outperforming baseline models and general-purpose LLMs in understanding and responding to protein-related queries. Our code and data are available at https://github.com/ProteinGPT/ProteinGPT.","authors":["Yijia Xiao","Edward Sun","Yiqiao Jin","Qifan Wang","Wei Wang"],"url":"https://arxiv.org/abs/2408.11363"}
{"created":"2025-04-21","title":"Understanding Epistemic Language with a Language-augmented Bayesian Theory of Mind","abstract":"How do people understand and evaluate claims about others' beliefs, even though these beliefs cannot be directly observed? In this paper, we introduce a cognitive model of epistemic language interpretation, grounded in Bayesian inferences about other agents' goals, beliefs, and intentions: a language-augmented Bayesian theory-of-mind (LaBToM). By translating natural language into an epistemic ``language-of-thought'' with grammar-constrained LLM decoding, then evaluating these translations against the inferences produced by inverting a generative model of rational action and perception, LaBToM captures graded plausibility judgments of epistemic claims. We validate our model in an experiment where participants watch an agent navigate a maze to find keys hidden in boxes needed to reach their goal, then rate sentences about the agent's beliefs. In contrast with multimodal LLMs (GPT-4o, Gemini Pro) and ablated models, our model correlates highly with human judgments for a wide range of expressions, including modal language, uncertainty expressions, knowledge claims, likelihood comparisons, and attributions of false belief.","authors":["Lance Ying","Tan Zhi-Xuan","Lionel Wong","Vikash Mansinghka","Joshua B. Tenenbaum"],"url":"https://arxiv.org/abs/2408.12022"}
{"created":"2025-04-21","title":"SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding","abstract":"Scientific literature understanding is crucial for extracting targeted information and garnering insights, thereby significantly advancing scientific discovery. Despite the remarkable success of Large Language Models (LLMs), they face challenges in scientific literature understanding, primarily due to (1) a lack of scientific knowledge and (2) unfamiliarity with specialized scientific tasks.","authors":["Sihang Li","Jin Huang","Jiaxi Zhuang","Yaorui Shi","Xiaochen Cai","Mingjun Xu","Xiang Wang","Linfeng Zhang","Guolin Ke","Hengxing Cai"],"url":"https://arxiv.org/abs/2408.15545"}
{"created":"2025-04-21","title":"A Concrete Model for Disjunction in Parallel and Algebraic Lambda Calculi","abstract":"We propose an interpretation for disjunctions in the presence of parallel and sum operators in both the parallel lambda calculus and the algebraic lambda calculus. Unlike conventional approaches that treat disjunction as a coproduct, we introduce a set-theoretic interpretation based on the union of the disjoint union and the Cartesian product, which does not form a coproduct in our proposed models. This leads to concrete models in the category ${\\mathbf{Mag}_{\\mathbf{Set}}}$, whose objects are magmas and whose arrows are those of Set, and in the category ${\\mathbf{AMag}^{\\mathcal{S}}_{\\mathbf{Set}}}$, whose objects are action magmas and whose arrows are also those of Set. This framework enables a refined treatment of parallelism and algebraic structure. We define two lambda calculi: (i) a parallel lambda calculus where the parallel operator is a constructor of collections, and (ii) an algebraic lambda calculus incorporating scalars. Each calculus is given a formal interpretation in a corresponding category, ensuring soundness and adequacy. Our results provide a novel approach to integrating parallelism and algebraic structure within propositional logic while preserving key proof-theoretic properties.","authors":["Alejandro D\\'iaz-Caro","Octavio Malherbe"],"url":"https://arxiv.org/abs/2408.16102"}
{"created":"2025-04-21","title":"NeurLZ: An Online Neural Learning-Based Method to Enhance Scientific Lossy Compression","abstract":"Large-scale scientific simulations generate massive datasets, posing challenges for storage and I/O. Traditional lossy compression struggles to advance more in balancing compression ratio, data quality, and adaptability to diverse scientific data features. While deep learning-based solutions have been explored, their common practice of relying on large models and offline training limits adaptability to dynamic data characteristics and computational efficiency. To address these challenges, we propose NeurLZ, a neural method designed to enhance lossy compression by integrating online learning, cross-field learning, and robust error regulation. Key innovations of NeurLZ include: (1) compression-time online neural learning with lightweight skipping DNN models, adapting to residual errors without costly offline pertaining, (2) the error-mitigating capability, recovering fine details from compression errors overlooked by conventional compressors, (3) $1\\times$ and $2\\times$ error-regulation modes, ensuring strict adherence to $1\\times$ user-input error bounds strictly or relaxed 2$\\times$ bounds for better overall quality, and (4) cross-field learning leveraging inter-field correlations in scientific data to improve conventional methods. Comprehensive evaluations on representative HPC datasets, e.g., Nyx, Miranda, Hurricane, against state-of-the-art compressors show NeurLZ's effectiveness. During the first five learning epochs, NeurLZ achieves an 89% bit rate reduction, with further optimization yielding up to around 94% reduction at equivalent distortion, significantly outperforming existing methods, demonstrating NeurLZ's superior performance in enhancing scientific lossy compression as a scalable and efficient solution.","authors":["Wenqi Jia","Zhewen Hu","Youyuan Liu","Boyuan Zhang","Jinzhen Wang","Jinyang Liu","Wei Niu","Stavros Kalafatis","Junzhou Huang","Sian Jin","Daoce Wang","Jiannan Tian","Miao Yin"],"url":"https://arxiv.org/abs/2409.05785"}
{"created":"2025-04-21","title":"United in Diversity? Contextual Biases in LLM-Based Predictions of the 2024 European Parliament Elections","abstract":"\"Synthetic samples\" based on large language models (LLMs) have been argued to serve as efficient alternatives to surveys of humans, assuming that their training data includes information on human attitudes and behavior. However, LLM-synthetic samples might exhibit bias, for example due to training data and fine-tuning processes being unrepresentative of diverse contexts. Such biases risk reinforcing existing biases in research, policymaking, and society. Therefore, researchers need to investigate if and under which conditions LLM-generated synthetic samples can be used for public opinion prediction. In this study, we examine to what extent LLM-based predictions of individual public opinion exhibit context-dependent biases by predicting the results of the 2024 European Parliament elections. Prompting three LLMs with individual-level background information of 26,000 eligible European voters, we ask the LLMs to predict each person's voting behavior. By comparing them to the actual results, we show that LLM-based predictions of future voting behavior largely fail, their accuracy is unequally distributed across national and linguistic contexts, and they require detailed attitudinal information in the prompt. The findings emphasize the limited applicability of LLM-synthetic samples to public opinion prediction. In investigating their contextual biases, this study contributes to the understanding and mitigation of inequalities in the development of LLMs and their applications in computational social science.","authors":["Leah von der Heyde","Anna-Carolina Haensch","Alexander Wenz","Bolei Ma"],"url":"https://arxiv.org/abs/2409.09045"}
{"created":"2025-04-21","title":"Large Language Models are Good Multi-lingual Learners : When LLMs Meet Cross-lingual Prompts","abstract":"With the advent of Large Language Models (LLMs), generating rule-based data for real-world applications has become more accessible. Due to the inherent ambiguity of natural language and the complexity of rule sets, especially in long contexts, LLMs often struggle to follow all specified rules, frequently omitting at least one. To enhance the reasoning and understanding of LLMs on long and complex contexts, we propose a novel prompting strategy Multi-Lingual Prompt, namely MLPrompt, which automatically translates the error-prone rule that an LLM struggles to follow into another language, thus drawing greater attention to it. Experimental results on public datasets across various tasks have shown MLPrompt can outperform state-of-the-art prompting methods such as Chain of Thought, Tree of Thought, and Self-Consistency. Additionally, we introduce a framework integrating MLPrompt with an auto-checking mechanism for structured data generation, with a specific case study in text-to-MIP instances. Further, we extend the proposed framework for text-to-SQL to demonstrate its generation ability towards structured data synthesis.","authors":["Teng Wang","Zhenqi He","Wing-Yin Yu","Xiaojin Fu","Xiongwei Han"],"url":"https://arxiv.org/abs/2409.11056"}
{"created":"2025-04-21","title":"Friedkin-Johnsen Model with Diminishing Competition","abstract":"This letter studies the Friedkin-Johnsen (FJ) model with diminishing competition, or stubbornness. The original FJ model assumes that each agent assigns a constant competition weight to its initial opinion. In contrast, we investigate the effect of diminishing competition on the convergence point and speed of the FJ dynamics. We prove that, if the competition is uniform across agents and vanishes asymptotically, the convergence point coincides with the nominal consensus reached with no competition. However, the diminishing competition slows down convergence according to its own rate of decay. We study this phenomenon analytically and provide upper and lower bounds on the convergence rate. Further, if competition is not uniform across agents, we show that the convergence point may not coincide with the nominal consensus point. Finally, we evaluate our analytical insights numerically.","authors":["Luca Ballotta","\\'Aron V\\'ek\\'assy","Stephanie Gil","Michal Yemini"],"url":"https://arxiv.org/abs/2409.12601"}
{"created":"2025-04-21","title":"NRGBoost: Energy-Based Generative Boosted Trees","abstract":"Despite the rise to dominance of deep learning in unstructured data domains, tree-based methods such as Random Forests (RF) and Gradient Boosted Decision Trees (GBDT) are still the workhorses for handling discriminative tasks on tabular data. We explore generative extensions of these popular algorithms with a focus on explicitly modeling the data density (up to a normalization constant), thus enabling other applications besides sampling. As our main contribution we propose an energy-based generative boosting algorithm that is analogous to the second-order boosting implemented in popular libraries like XGBoost. We show that, despite producing a generative model capable of handling inference tasks over any input variable, our proposed algorithm can achieve similar discriminative performance to GBDT on a number of real world tabular datasets, outperforming alternative generative approaches. At the same time, we show that it is also competitive with neural-network-based models for sampling. Code is available at https://github.com/ajoo/nrgboost.","authors":["Jo\\~ao Bravo"],"url":"https://arxiv.org/abs/2410.03535"}
{"created":"2025-04-21","title":"Granular Ball Twin Support Vector Machine","abstract":"On Efficient and Scalable Computation of the Nonparametric Maximum Likelihood Estimator in Mixture ModelsTwin support vector machine (TSVM) is an emerging machine learning model with versatile applicability in classification and regression endeavors. Nevertheless, TSVM confronts noteworthy challenges: $(i)$ the imperative demand for matrix inversions presents formidable obstacles to its efficiency and applicability on large-scale datasets; $(ii)$ the omission of the structural risk minimization (SRM) principle in its primal formulation heightens the vulnerability to overfitting risks; and $(iii)$ the TSVM exhibits a high susceptibility to noise and outliers, and also demonstrates instability when subjected to resampling. In view of the aforementioned challenges, we propose the granular ball twin support vector machine (GBTSVM). GBTSVM takes granular balls, rather than individual data points, as inputs to construct a classifier. These granular balls, characterized by their coarser granularity, exhibit robustness to resampling and reduced susceptibility to the impact of noise and outliers. We further propose a novel large-scale granular ball twin support vector machine (LS-GBTSVM). LS-GBTSVM's optimization formulation ensures two critical facets: $(i)$ it eliminates the need for matrix inversions, streamlining the LS-GBTSVM's computational efficiency, and $(ii)$ it incorporates the SRM principle through the incorporation of regularization terms, effectively addressing the issue of overfitting. The proposed LS-GBTSVM exemplifies efficiency, scalability for large datasets, and robustness against noise and outliers. We conduct a comprehensive evaluation of the GBTSVM and LS-GBTSVM models on benchmark datasets from UCI, KEEL, and NDC datasets. Our experimental findings and statistical analyses affirm the superior generalization prowess of the proposed GBTSVM and LS-GBTSVM models.","authors":["A. Quadir","M. Sajid","M. Tanveer"],"url":"https://arxiv.org/abs/2410.04774"}
{"created":"2025-04-21","title":"Does Spatial Cognition Emerge in Frontier Models?","abstract":"Not yet. We present SPACE, a benchmark that systematically evaluates spatial cognition in frontier models. Our benchmark builds on decades of research in cognitive science. It evaluates large-scale mapping abilities that are brought to bear when an organism traverses physical environments, smaller-scale reasoning about object shapes and layouts, and cognitive infrastructure such as spatial attention and memory. For many tasks, we instantiate parallel presentations via text and images, allowing us to benchmark both large language models and large multimodal models. Results suggest that contemporary frontier models fall short of the spatial intelligence of animals, performing near chance level on a number of classic tests of animal cognition. Code and data are available: https://github.com/apple/ml-space-benchmark","authors":["Santhosh Kumar Ramakrishnan","Erik Wijmans","Philipp Kraehenbuehl","Vladlen Koltun"],"url":"https://arxiv.org/abs/2410.06468"}
{"created":"2025-04-21","title":"AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents","abstract":"The robustness of LLMs to jailbreak attacks, where users design prompts to circumvent safety measures and misuse model capabilities, has been studied primarily for LLMs acting as simple chatbots. Meanwhile, LLM agents -- which use external tools and can execute multi-stage tasks -- may pose a greater risk if misused, but their robustness remains underexplored. To facilitate research on LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark includes a diverse set of 110 explicitly malicious agent tasks (440 with augmentations), covering 11 harm categories including fraud, cybercrime, and harassment. In addition to measuring whether models refuse harmful agentic requests, scoring well on AgentHarm requires jailbroken agents to maintain their capabilities following an attack to complete a multi-step task. We evaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly compliant with malicious agent requests without jailbreaking, (2) simple universal jailbreak templates can be adapted to effectively jailbreak agents, and (3) these jailbreaks enable coherent and malicious multi-step agent behavior and retain model capabilities. To enable simple and reliable evaluation of attacks and defenses for LLM-based agents, we publicly release AgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.","authors":["Maksym Andriushchenko","Alexandra Souly","Mateusz Dziemian","Derek Duenas","Maxwell Lin","Justin Wang","Dan Hendrycks","Andy Zou","Zico Kolter","Matt Fredrikson","Eric Winsor","Jerome Wynne","Yarin Gal","Xander Davies"],"url":"https://arxiv.org/abs/2410.09024"}
{"created":"2025-04-21","title":"SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars","abstract":"Recent advancements in head avatar rendering using Gaussian primitives have achieved significantly high-fidelity results. Although precise head geometry is crucial for applications like mesh reconstruction and relighting, current methods struggle to capture intricate geometric details and render unseen poses due to their reliance on similarity transformations, which cannot handle stretch and shear transforms essential for detailed deformations of geometry. To address this, we propose SurFhead, a novel method that reconstructs riggable head geometry from RGB videos using 2D Gaussian surfels, which offer well-defined geometric properties, such as precise depth from fixed ray intersections and normals derived from their surface orientation, making them advantageous over 3D counterparts. SurFhead ensures high-fidelity rendering of both normals and images, even in extreme poses, by leveraging classical mesh-based deformation transfer and affine transformation interpolation. SurFhead introduces precise geometric deformation and blends surfels through polar decomposition of transformations, including those affecting normals. Our key contribution lies in bridging classical graphics techniques, such as mesh-based deformation, with modern Gaussian primitives, achieving state-of-the-art geometry reconstruction and rendering quality. Unlike previous avatar rendering approaches, SurFhead enables efficient reconstruction driven by Gaussian primitives while preserving high-fidelity geometry.","authors":["Jaeseong Lee","Taewoong Kang","Marcel C. B\\\"uhler","Min-Jung Kim","Sungwon Hwang","Junha Hyung","Hyojin Jang","Jaegul Choo"],"url":"https://arxiv.org/abs/2410.11682"}
{"created":"2025-04-21","title":"High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion","abstract":"Despite the recent progress, existing frame interpolation methods still struggle with processing extremely high resolution input and handling challenging cases such as repetitive textures, thin objects, and large motion. To address these issues, we introduce a patch-based cascaded pixel diffusion model for high resolution frame interpolation, HIFI, that excels in these scenarios while achieving competitive performance on standard benchmarks. Cascades, which generate a series of images from low to high resolution, can help significantly with large or complex motion that require both global context for a coarse solution and detailed context for high resolution output. However, contrary to prior work on cascaded diffusion models which perform diffusion on increasingly large resolutions, we use a single model that always performs diffusion at the same resolution and upsamples by processing patches of the inputs and the prior solution. At inference time, this drastically reduces memory usage and allows a single model, solving both frame interpolation (base model's task) and spatial up-sampling, saving training cost as well. HIFI excels at high-resolution images and complex repeated textures that require global context, achieving comparable or state-of-the-art performance on various benchmarks (Vimeo, Xiph, X-Test, and SEPE-8K). We further introduce a new dataset, LaMoR, that focuses on particularly challenging cases, and HIFI significantly outperforms other baselines. Please visit our project page for video results: https://hifi-diffusion.github.io","authors":["Junhwa Hur","Charles Herrmann","Saurabh Saxena","Janne Kontkanen","Wei-Sheng Lai","Yichang Shih","Michael Rubinstein","David J. Fleet","Deqing Sun"],"url":"https://arxiv.org/abs/2410.11838"}
{"created":"2025-04-21","title":"Mixture of Scale Experts for Alignment-free RGBT Video Object Detection and A Unified Benchmark","abstract":"Existing RGB-Thermal Video Object Detection (RGBT VOD) methods predominantly rely on the manual alignment of image pairs, that is both labor-intensive and time-consuming. This dependency significantly restricts the scalability and practical applicability of these methods in real-world scenarios. To address this critical limitation, we propose a novel framework termed the Mixture of Scale Experts Network (MSENet). MSENet integrates multiple experts trained at different perceptual scales, enabling the capture of scale discrepancies between RGB and thermal image pairs without the need for explicit alignment. Specifically, to address the issue of unaligned scales, MSENet introduces a set of experts designed to perceive the correlation between RGBT image pairs across various scales. These experts are capable of identifying and quantifying the scale differences inherent in the image pairs. Subsequently, a dynamic routing mechanism is incorporated to assign adaptive weights to each expert, allowing the network to dynamically select the most appropriate experts based on the specific characteristics of the input data. Furthermore, to address the issue of weakly unaligned positions, we integrate deformable convolution into the network. Deformable convolution is employed to learn position displacements between the RGB and thermal modalities, thereby mitigating the impact of spatial misalignment. To provide a comprehensive evaluation platform for alignment-free RGBT VOD, we introduce a new benchmark dataset. This dataset includes eleven common object categories, with a total of 60,988 images and 271,835 object instances. The dataset encompasses a wide range of scenes from both daily life and natural environments, ensuring high content diversity and complexity.","authors":["Qishun Wang","Zhengzheng Tu","Kunpeng Wang","Le Gu","Chuanwang Guo"],"url":"https://arxiv.org/abs/2410.12143"}
{"created":"2025-04-21","title":"Malleus: Straggler-Resilient Hybrid Parallel Training of Large-scale Models via Malleable Data and Model Parallelization","abstract":"As the scale of models and training data continues to grow, there is an expanding reliance on more GPUs to train large-scale models, which inevitably increases the likelihood of encountering dynamic stragglers that some devices lag behind in performance occasionally. However, hybrid parallel training, one of the de facto paradigms to train large models, is typically sensitive to the stragglers.","authors":["Haoyang Li","Fangcheng Fu","Hao Ge","Sheng Lin","Xuanyu Wang","Jiawen Niu","Yujie Wang","Hailin Zhang","Xiaonan Nie","Bin Cui"],"url":"https://arxiv.org/abs/2410.13333"}
{"created":"2025-04-21","title":"Understanding the Difficulty of Low-Precision Post-Training Quantization for LLMs","abstract":"Large language models of high parameter counts are computationally expensive, yet can be made much more efficient by compressing their weights to very low numerical precision. This can be achieved either through post-training quantization by minimizing local, layer-wise quantization errors, or through quantization-aware fine-tuning by minimizing the global loss function. In this study, we discovered that, under the same data constraint, the former approach nearly always fared worse than the latter, a phenomenon particularly prominent when the numerical precision is very low. We further showed that this difficulty of post-training quantization arose from stark misalignment between optimization of the local and global objective functions. Our findings explains limited utility in minimization of local quantization error and the importance of direct quantization-aware fine-tuning, in the regime of large models at very low precision.","authors":["Zifei Xu","Sayeh Sharify","Wanzin Yazar","Tristan Webb","Xin Wang"],"url":"https://arxiv.org/abs/2410.14570"}
{"created":"2025-04-21","title":"If LLMs Would Just Look: Simple Line-by-line Checking Improves Vulnerability Localization","abstract":"The rapid expansion of software systems and the growing number of reported vulnerabilities have emphasized the importance of accurately identifying vulnerable code segments. Traditional methods for vulnerability localization, such as manual code audits or rule-based tools, are often time-consuming and limited in scope, typically focusing on specific programming languages or types of vulnerabilities. In recent years, the introduction of large language models (LLMs) such as GPT and LLaMA has opened new possibilities for automating vulnerability detection. However, while LLMs show promise in this area, they face challenges, particularly in maintaining accuracy over longer code contexts. This paper introduces LOVA, a novel framework leveraging the self-attention mechanisms inherent in LLMs to enhance vulnerability localization. Our key insight is that self-attention mechanisms assign varying importance to different parts of the input, making it possible to track how much attention the model focuses on specific lines of code. In the context of vulnerability localization, the hypothesis is that vulnerable lines of code will naturally attract higher attention weights because they have a greater influence on the model's output. By systematically tracking changes in attention weights and focusing on specific lines of code, LOVA improves the precision of identifying vulnerable lines across various programming languages. Through rigorous experimentation and evaluation, we demonstrate that LOVA significantly outperforms existing LLM-based approaches, achieving up to a 5.3x improvement in F1-scores. LOVA also demonstrated strong scalability, with up to a 14.6x improvement in smart contract vulnerability localization across languages like C, Python, Java, and Solidity. Its robustness was proven through consistent performance across different LLM architectures.","authors":["Yue Li","Xiao Li","Hao Wu","Yue Zhang","Xiuzhen Cheng","Yating Liu","Fengyuan Xu","Sheng Zhong"],"url":"https://arxiv.org/abs/2410.15288"}
{"created":"2025-04-21","title":"Robust Universum Twin Support Vector Machine for Imbalanced Data","abstract":"One of the major difficulties in machine learning methods is categorizing datasets that are imbalanced. This problem may lead to biased models, where the training process is dominated by the majority class, resulting in inadequate representation of the minority class. Universum twin support vector machine (UTSVM) produces a biased model towards the majority class, as a result, its performance on the minority class is often poor as it might be mistakenly classified as noise. Moreover, UTSVM is not proficient in handling datasets that contain outliers and noises. Inspired by the concept of incorporating prior information about the data and employing an intuitionistic fuzzy membership scheme, we propose intuitionistic fuzzy UTSVM for imbalanced data (IFUTSVM-ID) by enhancing overall robustness. We use an intuitionistic fuzzy membership scheme to mitigate the impact of noise and outliers. Moreover, to tackle the problem of imbalanced class distribution, data oversampling and undersampling methods are utilized. Prior knowledge about the data is provided by universum data. This leads to better generalization performance. UTSVM is susceptible to overfitting risks due to the omission of the structural risk minimization (SRM) principle in their primal formulations. However, the proposed IFUTSVM-ID model incorporates the SRM principle through the incorporation of regularization terms, effectively addressing the issue of overfitting. We conduct a comprehensive evaluation of the proposed IFUTSVM-ID model on benchmark datasets from KEEL and compare it with existing baseline models. Furthermore, to assess the effectiveness of the proposed IFUTSVM-ID model in diagnosing Alzheimer's disease (AD), we applied them to the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Experimental results showcase the superiority of the proposed IFUTSVM-ID models compared to the baseline models.","authors":["M. Tanveer","A. Quadir"],"url":"https://arxiv.org/abs/2410.20335"}
{"created":"2025-04-21","title":"ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference","abstract":"With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for each token generation both result in low throughput when serving long-context LLMs. While various dynamic sparse attention methods have been proposed to speed up inference while maintaining generation quality, they either fail to sufficiently reduce GPU memory consumption or introduce significant decoding latency by offloading the KV cache to the CPU. We present ShadowKV, a high-throughput long-context LLM inference system that stores the low-rank key cache and offloads the value cache to reduce the memory footprint for larger batch sizes and longer sequences. To minimize decoding latency, ShadowKV employs an accurate KV selection strategy that reconstructs minimal sparse KV pairs on-the-fly. By evaluating ShadowKV on a broad range of benchmarks, including RULER, LongBench, and Needle In A Haystack, and models like Llama-3.1-8B, Llama-3-8B-1M, GLM-4-9B-1M, Yi-9B-200K, Phi-3-Mini-128K, and Qwen2-7B-128K, we demonstrate that it can support up to 6$\\times$ larger batch sizes and boost throughput by up to 3.04$\\times$ on an A100 GPU without sacrificing accuracy, even surpassing the performance achievable with infinite batch size under the assumption of infinite GPU memory. The code is available at https://github.com/bytedance/ShadowKV.","authors":["Hanshi Sun","Li-Wen Chang","Wenlei Bao","Size Zheng","Ningxin Zheng","Xin Liu","Harry Dong","Yuejie Chi","Beidi Chen"],"url":"https://arxiv.org/abs/2410.21465"}
{"created":"2025-04-21","title":"Reducing the Scope of Language Models","abstract":"We now deploy language models in a wide variety of user-facing applications. Typically, these deployments have some specific purpose, like answering questions about documentation or acting as coding assistants, but they require general language understanding. Under these circumstances these models should not be able to answer irrelevant requests such as, poetry generation or questions about physics, etc. Instead we would like language models to only answer to queries corresponding to desired behavior and refuse all other requests, which we refer to as scoping. We conduct a comprehensive empirical evaluation of potential methods from prompting to fine-tuning to preference learning to a recently proposed method for general alignment called Circuit Breakers (CB). Across three families of language models and a broad variety of tasks, we show that it is possible to scope language models. We examine scoping for multiple topics, and fine-grained topics. We ablate diversity of irrelevant queries, layer different techniques, conduct adversarial evaluations and more. Among other results, we find that, when diverse examples of irrelevant queries are available, simple supervised fine-tuning produces the best results, but when such diversity is low, Circuit Breakers perform quite well. One can often get the benefits of both methods by layering them in succession. We intend our study to serve as a practitioner's guide to scoping language models.","authors":["David Yunis","Siyu Huo","Chulaka Gunasekara","Danish Contractor"],"url":"https://arxiv.org/abs/2410.21597"}
{"created":"2025-04-21","title":"Subgraph Aggregation for Out-of-Distribution Generalization on Graphs","abstract":"Out-of-distribution (OOD) generalization in Graph Neural Networks (GNNs) has gained significant attention due to its critical importance in graph-based predictions in real-world scenarios. Existing methods primarily focus on extracting a single causal subgraph from the input graph to achieve generalizable predictions. However, relying on a single subgraph can lead to susceptibility to spurious correlations and is insufficient for learning invariant patterns behind graph data. Moreover, in many real-world applications, such as molecular property prediction, multiple critical subgraphs may influence the target label property. To address these challenges, we propose a novel framework, SubGraph Aggregation (SuGAr), designed to learn a diverse set of subgraphs that are crucial for OOD generalization on graphs. Specifically, SuGAr employs a tailored subgraph sampler and diversity regularizer to extract a diverse set of invariant subgraphs. These invariant subgraphs are then aggregated by averaging their representations, which enriches the subgraph signals and enhances coverage of the underlying causal structures, thereby improving OOD generalization. Extensive experiments on both synthetic and real-world datasets demonstrate that \\ours outperforms state-of-the-art methods, achieving up to a 24% improvement in OOD generalization on graphs. To the best of our knowledge, this is the first work to study graph OOD generalization by learning multiple invariant subgraphs. code: https://github.com/Nanolbw/SuGAr","authors":["Bowen Liu","Haoyang Li","Shuning Wang","Shuo Nie","Shanghang Zhang"],"url":"https://arxiv.org/abs/2410.22228"}
{"created":"2025-04-21","title":"HD-OOD3D: Supervised and Unsupervised Out-of-Distribution object detection in LiDAR data","abstract":"Autonomous systems rely on accurate 3D object detection from LiDAR data, yet most detectors are limited to a predefined set of known classes, making them vulnerable to unexpected out-of-distribution (OOD) objects. In this work, we present HD-OOD3D, a novel two-stage method for detecting unknown objects. We demonstrate the superiority of two-stage approaches over single-stage methods, achieving more robust detection of unknown objects while addressing key challenges in the evaluation protocol. Furthermore, we conduct an in-depth analysis of the standard evaluation protocol for OOD detection, revealing the critical impact of hyperparameter choices. To address the challenge of scaling the learning of unknown objects, we explore unsupervised training strategies to generate pseudo-labels for unknowns. Among the different approaches evaluated, our experiments show that top-5 auto-labelling offers more promising performance compared to simple resizing techniques.","authors":["Louis Soum-Fontez","Jean-Emmanuel Deschaud","Fran\\c{c}ois Goulette"],"url":"https://arxiv.org/abs/2410.23767"}
{"created":"2025-04-21","title":"Topograph: An efficient Graph-Based Framework for Strictly Topology Preserving Image Segmentation","abstract":"Topological correctness plays a critical role in many image segmentation tasks, yet most networks are trained using pixel-wise loss functions, such as Dice, neglecting topological accuracy. Existing topology-aware methods often lack robust topological guarantees, are limited to specific use cases, or impose high computational costs. In this work, we propose a novel, graph-based framework for topologically accurate image segmentation that is both computationally efficient and generally applicable. Our method constructs a component graph that fully encodes the topological information of both the prediction and ground truth, allowing us to efficiently identify topologically critical regions and aggregate a loss based on local neighborhood information. Furthermore, we introduce a strict topological metric capturing the homotopy equivalence between the union and intersection of prediction-label pairs. We formally prove the topological guarantees of our approach and empirically validate its effectiveness on binary and multi-class datasets. Our loss demonstrates state-of-the-art performance with up to fivefold faster loss computation compared to persistent homology methods.","authors":["Laurin Lux","Alexander H. Berger","Alexander Weers","Nico Stucki","Daniel Rueckert","Ulrich Bauer","Johannes C. Paetzold"],"url":"https://arxiv.org/abs/2411.03228"}
{"created":"2025-04-21","title":"Few-shot Model Extraction Attacks against Sequential Recommender Systems","abstract":"Among adversarial attacks against sequential recommender systems, model extraction attacks represent a method to attack sequential recommendation models without prior knowledge. Existing research has primarily concentrated on the adversary's execution of black-box attacks through data-free model extraction. However, a significant gap remains in the literature concerning the development of surrogate models by adversaries with access to few-shot raw data (10\\% even less). That is, the challenge of how to construct a surrogate model with high functional similarity within the context of few-shot data scenarios remains an issue that requires resolution.This study addresses this gap by introducing a novel few-shot model extraction framework against sequential recommenders, which is designed to construct a superior surrogate model with the utilization of few-shot data. The proposed few-shot model extraction framework is comprised of two components: an autoregressive augmentation generation strategy and a bidirectional repair loss-facilitated model distillation procedure. Specifically, to generate synthetic data that closely approximate the distribution of raw data, autoregressive augmentation generation strategy integrates a probabilistic interaction sampler to extract inherent dependencies and a synthesis determinant signal module to characterize user behavioral patterns. Subsequently, bidirectional repair loss, which target the discrepancies between the recommendation lists, is designed as auxiliary loss to rectify erroneous predictions from surrogate models, transferring knowledge from the victim model to the surrogate model effectively. Experiments on three datasets show that the proposed few-shot model extraction framework yields superior surrogate models.","authors":["Hui Zhang","Fu Liu"],"url":"https://arxiv.org/abs/2411.11677"}
{"created":"2025-04-21","title":"Order is All You Need for Categorical Data Clustering","abstract":"Categorical data composed of qualitative valued attributes are ubiquitous in machine learning tasks. Due to the lack of well-defined metric space, categorical data distributions are difficult to be intuitively understood. Clustering is a popular data analysis technique suitable for data distribution understanding. However, the success of clustering often relies on reasonable distance metrics, which happens to be what categorical data naturally lack. This paper therefore introduces a new finding that the order relation among attribute values is the decisive factor in clustering accuracy, and is also the key to understanding categorical data clusters, because the essence of clustering is to order the clusters in terms of their admission to samples. To obtain the orders, we propose a new learning paradigm that allows joint learning of clusters and the orders. It alternatively partitions the data into clusters based on the distance metric built upon the orders and estimates the most likely orders according to the clusters. The algorithm achieves superior clustering accuracy with a convergence guarantee, and the learned orders facilitate the understanding of the non-intuitive cluster distribution of categorical data. Extensive experiments with ablation studies, statistical evidence, and case studies have validated the new insight into the importance of value order and the method proposition. The source code is temporarily opened in https://anonymous.4open.science/r/OCL-demo.","authors":["Yiqun Zhang","Mingjie Zhao","Hong Jia","Yang Lu","Mengke Li","Yiu-ming Cheung"],"url":"https://arxiv.org/abs/2411.15189"}
{"created":"2025-04-21","title":"PriorDiffusion: Leverage Language Prior in Diffusion Models for Monocular Depth Estimation","abstract":"Traditional monocular depth estimation suffers from inherent ambiguity and visual nuisance. We argue that language prior can enhance monocular depth estimation by leveraging the inductive bias learned during the text-to-image pre-training of diffusion models. The ability of these models to generate images that align with text indicates that they have learned the spatial relationships, size, and shape of specified objects, which can be applied to improve depth estimation. Thus, we propose PriorDiffusion, using a pre-trained text-to-image diffusion model that takes both images and corresponding text descriptions to infer affine-invariant depth through a denoising process. We also show that language prior enhances the model's perception of specific regions of images that users care about and describe. Simultaneously, language prior acts as a constraint to accelerate the convergence of both training and the inference diffusion trajectory. By training on HyperSim and Virtual KITTI, we achieve faster training convergence, fewer inference diffusion steps, and state-of-the-art zero-shot performance across NYUv2, KITTI, ETH3D, and ScanNet. Code will be released upon acceptance.","authors":["Ziyao Zeng","Jingcheng Ni","Daniel Wang","Patrick Rim","Younjoon Chung","Fengyu Yang","Byung-Woo Hong","Alex Wong"],"url":"https://arxiv.org/abs/2411.16750"}
{"created":"2025-04-21","title":"Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation","abstract":"Ambiguous words are often found in modern digital communications. Lexical ambiguity challenges traditional Word Sense Disambiguation (WSD) methods, due to limited data. Consequently, the efficiency of translation, information retrieval, and question-answering systems is hindered by these limitations. This study investigates the use of Large Language Models (LLMs) to improve WSD using a novel approach combining a systematic prompt augmentation mechanism with a knowledge base (KB) consisting of different sense interpretations. The proposed method incorporates a human-in-loop approach for prompt augmentation where prompt is supported by Part-of-Speech (POS) tagging, synonyms of ambiguous words, aspect-based sense filtering and few-shot prompting to guide the LLM. By utilizing a few-shot Chain of Thought (COT) prompting-based approach, this work demonstrates a substantial improvement in performance. The evaluation was conducted using FEWS test data and sense tags. This research advances accurate word interpretation in social media and digital communication.","authors":["T. G. D. K. Sumanathilaka","Nicholas Micallef","Julian Hough"],"url":"https://arxiv.org/abs/2411.18337"}
{"created":"2025-04-21","title":"GTPC-SSCD: Gate-guided Two-level Perturbation Consistency-based Semi-Supervised Change Detection","abstract":"Semi-supervised change detection (SSCD) utilizes partially labeled data and abundant unlabeled data to detect differences between multi-temporal remote sensing images. The mainstream SSCD methods based on consistency regularization have limitations. They perform perturbations mainly at a single level, restricting the utilization of unlabeled data and failing to fully tap its potential. In this paper, we introduce a novel Gate-guided Two-level Perturbation Consistency regularization-based SSCD method (GTPC-SSCD). It simultaneously maintains strong-to-weak consistency at the image level and perturbation consistency at the feature level, enhancing the utilization efficiency of unlabeled data. Moreover, we develop a hardness analysis-based gating mechanism to assess the training complexity of different samples and determine the necessity of performing feature perturbations for each sample. Through this differential treatment, the network can explore the potential of unlabeled data more efficiently. Extensive experiments conducted on six benchmark CD datasets demonstrate the superiority of our GTPC-SSCD over seven state-of-the-art methods.","authors":["Yan Xing","Qi'ao Xu","Zongyu Guo","Rui Huang","Yuxiang Zhang"],"url":"https://arxiv.org/abs/2411.18880"}
{"created":"2025-04-21","title":"DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding","abstract":"Human motion is inherently continuous and dynamic, posing significant challenges for generative models. While discrete generation methods are widely used, they suffer from limited expressiveness and frame-wise noise artifacts. In contrast, continuous approaches produce smoother, more natural motion but often struggle to adhere to conditioning signals due to high-dimensional complexity and limited training data. To resolve this discord between discrete and continuous representations, we introduce DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding, a novel method that leverages rectified flow to decode discrete motion tokens in the continuous, raw motion space. Our core idea is to frame token decoding as a conditional generation task, ensuring that DisCoRD captures fine-grained dynamics and achieves smoother, more natural motions. Compatible with any discrete-based framework, our method enhances naturalness without compromising faithfulness to the conditioning signals on diverse settings. Extensive evaluations Our project page is available at: https://whwjdqls.github.io/discord.github.io/.","authors":["Jungbin Cho","Junwan Kim","Jisoo Kim","Minseo Kim","Mingu Kang","Sungeun Hong","Tae-Hyun Oh","Youngjae Yu"],"url":"https://arxiv.org/abs/2411.19527"}
{"created":"2025-04-21","title":"Unified Parameter-Efficient Unlearning for LLMs","abstract":"The advent of Large Language Models (LLMs) has revolutionized natural language processing, enabling advanced understanding and reasoning capabilities across a variety of tasks. Fine-tuning these models for specific domains, particularly through Parameter-Efficient Fine-Tuning (PEFT) strategies like LoRA, has become a prevalent practice due to its efficiency. However, this raises significant privacy and security concerns, as models may inadvertently retain and disseminate sensitive or undesirable information. To address these issues, we introduce a novel instance-wise unlearning framework, LLMEraser, which systematically categorizes unlearning tasks and applies precise parameter adjustments using influence functions. Unlike traditional unlearning techniques that are often limited in scope and require extensive retraining, LLMEraser is designed to handle a broad spectrum of unlearning tasks without compromising model performance. Extensive experiments on benchmark datasets demonstrate that LLMEraser excels in efficiently managing various unlearning scenarios while maintaining the overall integrity and efficacy of the models.","authors":["Chenlu Ding","Jiancan Wu","Yancheng Yuan","Jinda Lu","Kai Zhang","Alex Su","Xiang Wang","Xiangnan He"],"url":"https://arxiv.org/abs/2412.00383"}
{"created":"2025-04-21","title":"A Dynamic Safety Shield for Safe and Efficient Reinforcement Learning of Navigation Tasks","abstract":"Reinforcement learning (RL) has been successfully applied to a variety of robotics applications, where it outperforms classical methods. However, the safety aspect of RL and the transfer to the real world remain an open challenge. A prominent field for tackling this challenge and ensuring the safety of the agents during training and execution is safe reinforcement learning. Safe RL can be achieved through constrained RL and safe exploration approaches. The former learns the safety constraints over the course of training to achieve a safe behavior by the end of training, at the cost of high number of collisions at earlier stages of the training. The latter offers robust safety by enforcing the safety constraints as hard constraints, which prevents collisions but hinders the exploration of the RL agent, resulting in lower rewards and poor performance. To overcome those drawbacks, we propose a novel safety shield, that combines the robustness of the optimization-based controllers with the long prediction capabilities of the RL agents, allowing the RL agent to adaptively tune the parameters of the controller. Our approach is able to improve the exploration of the RL agents for navigation tasks, while minimizing the number of collisions. Experiments in simulation show that our approach outperforms state-of-the-art baselines in the reached goals-to-collisions ratio in different challenging environments. The goals-to-collisions ratio metrics emphasizes the importance of minimizing the number of collisions, while learning to accomplish the task. Our approach achieves a higher number of reached goals compared to the classic safety shields and fewer collisions compared to constrained RL approaches. Finally, we demonstrate the performance of the proposed method in a real-world experiment.","authors":["Murad Dawood","Ahmed Shokry","Maren Bennewitz"],"url":"https://arxiv.org/abs/2412.04153"}
{"created":"2025-04-21","title":"Argumentative Experience: Reducing Confirmation Bias on Controversial Issues through LLM-Generated Multi-Persona Debates","abstract":"Large language models (LLMs) are enabling designers to give life to exciting new user experiences for information access. In this work, we present a system that generates LLM personas to debate a topic of interest from different perspectives. How might information seekers use and benefit from such a system? Can centering information access around diverse viewpoints help to mitigate thorny challenges like confirmation bias in which information seekers over-trust search results matching existing beliefs? How do potential biases and hallucinations in LLMs play out alongside human users who are also fallible and possibly biased?","authors":["Li Shi","Houjiang Liu","Yian Wong","Utkarsh Mujumdar","Dan Zhang","Jacek Gwizdka","Matthew Lease"],"url":"https://arxiv.org/abs/2412.04629"}
{"created":"2025-04-21","title":"AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis","abstract":"Anomaly synthesis is a crucial approach to augment abnormal data for advancing anomaly inspection. Based on the knowledge from the large-scale pre-training, existing text-to-image anomaly synthesis methods predominantly focus on textual information or coarse-aligned visual features to guide the entire generation process. However, these methods often lack sufficient descriptors to capture the complicated characteristics of realistic anomalies (e.g., the fine-grained visual pattern of anomalies), limiting the realism and generalization of the generation process. To this end, we propose a novel anomaly synthesis framework called AnomalyControl to learn cross-modal semantic features as guidance signals, which could encode the generalized anomaly cues from text-image reference prompts and improve the realism of synthesized abnormal samples. Specifically, AnomalyControl adopts a flexible and non-matching prompt pair (i.e., a text-image reference prompt and a targeted text prompt), where a Cross-modal Semantic Modeling (CSM) module is designed to extract cross-modal semantic features from the textual and visual descriptors. Then, an Anomaly-Semantic Enhanced Attention (ASEA) mechanism is formulated to allow CSM to focus on the specific visual patterns of the anomaly, thus enhancing the realism and contextual relevance of the generated anomaly features. Treating cross-modal semantic features as the prior, a Semantic Guided Adapter (SGA) is designed to encode effective guidance signals for the adequate and controllable synthesis process. Extensive experiments indicate that AnomalyControl can achieve state-of-the-art results in anomaly synthesis compared with existing methods while exhibiting superior performance for downstream tasks.","authors":["Shidan He","Lei Liu","Xiujun Shu","Bo Wang","Yuanhao Feng","Shen Zhao"],"url":"https://arxiv.org/abs/2412.06510"}
{"created":"2025-04-21","title":"Probability and Angelic Nondeterminism with Multiset Semantics","abstract":"We introduce a version of probabilistic Kleene algebra with angelic nondeterminism and a corresponding class of automata. Our approach implements semantics via distributions over multisets in order to overcome theoretical barriers arising from the lack of a distributive law between the powerset and Giry monads. We produce a full Kleene theorem and a coalgebraic theory, as well as both operational and denotational semantics and equational reasoning principles.","authors":["Shawn Ong","Stephanie Ma","Dexter Kozen"],"url":"https://arxiv.org/abs/2412.06754"}
{"created":"2025-04-21","title":"Quantifying the benefits of code hints for refactoring deprecated Java APIs","abstract":"When done manually, refactoring legacy code in order to eliminate uses of deprecated APIs is an error-prone and time-consuming process. In this paper, we investigate to which degree refactorings for deprecated Java APIs can be automated, and quantify the benefit of Javadoc code hints for this task. To this end, we build a symbolic and a neural engine for the automatic refactoring of deprecated APIs. The former is based on type-directed and component-based program synthesis, whereas the latter uses LLMs. We applied our engines to refactor the deprecated methods in the Oracle JDK 15. Our experiments show that code hints are enabling for the automation of this task: even the worst engine correctly refactors 71% of the tasks with code hints, which drops to at best 14% on tasks without. Adding more code hints to Javadoc can hence boost the refactoring of code that uses deprecated APIs.","authors":["Cristina David","Pascal Kesseli","Daniel Kroening","Hanliang Zhang"],"url":"https://arxiv.org/abs/2412.08041"}
{"created":"2025-04-21","title":"GaGA: Towards Interactive Global Geolocation Assistant","abstract":"Global geolocation, which seeks to predict the geographical location of images captured anywhere in the world, is one of the most challenging tasks in the field of computer vision. In this paper, we introduce an innovative interactive global geolocation assistant named GaGA, built upon the flourishing large vision-language models (LVLMs). GaGA uncovers geographical clues within images and combines them with the extensive world knowledge embedded in LVLMs to determine the geolocations while also providing justifications and explanations for the prediction results. We further designed a novel interactive geolocation method that surpasses traditional static inference approaches. It allows users to intervene, correct, or provide clues for the predictions, making the model more flexible and practical. The development of GaGA relies on the newly proposed Multi-modal Global Geolocation (MG-Geo) dataset, a comprehensive collection of 5 million high-quality image-text pairs. GaGA achieves state-of-the-art performance on the GWS15k dataset, improving accuracy by 4.57% at the country level and 2.92% at the city level, setting a new benchmark. These advancements represent a significant leap forward in developing highly accurate, interactive geolocation systems with global applicability.","authors":["Zhiyang Dou","Zipeng Wang","Xumeng Han","Guorong Li","Zhipei Huang","Zhenjun Han"],"url":"https://arxiv.org/abs/2412.08907"}
{"created":"2025-04-21","title":"XYScanNet: A State Space Model for Single Image Deblurring","abstract":"Deep state-space models (SSMs), like recent Mamba architectures, are emerging as a promising alternative to CNN and Transformer networks. Existing Mamba-based restoration methods process visual data by leveraging a flatten-and-scan strategy that converts image patches into a 1D sequence before scanning. However, this scanning paradigm ignores local pixel dependencies and introduces spatial misalignment by positioning distant pixels incorrectly adjacent, which reduces local noise-awareness and degrades image sharpness in low-level vision tasks. To overcome these issues, we propose a novel slice-and-scan strategy that alternates scanning along intra- and inter-slices. We further design a new Vision State Space Module (VSSM) for image deblurring, and tackle the inefficiency challenges of the current Mamba-based vision module. Building upon this, we develop XYScanNet, an SSM architecture integrated with a lightweight feature fusion module for enhanced image deblurring. XYScanNet, maintains competitive distortion metrics and significantly improves perceptual performance. Experimental results show that XYScanNet enhances KID by $17\\%$ compared to the nearest competitor.","authors":["Hanzhou Liu","Chengkai Liu","Jiacong Xu","Peng Jiang","Mi Lu"],"url":"https://arxiv.org/abs/2412.10338"}
{"created":"2025-04-21","title":"Robust image classification with multi-modal large language models","abstract":"Deep Neural Networks are vulnerable to adversarial examples, i.e., carefully crafted input samples that can cause models to make incorrect predictions with high confidence. To mitigate these vulnerabilities, adversarial training and detection-based defenses have been proposed to strengthen models in advance. However, most of these approaches focus on a single data modality, overlooking the relationships between visual patterns and textual descriptions of the input. In this paper, we propose a novel defense, MultiShield, designed to combine and complement these defenses with multi-modal information to further enhance their robustness. MultiShield leverages multi-modal large language models to detect adversarial examples and abstain from uncertain classifications when there is no alignment between textual and visual representations of the input. Extensive evaluations on CIFAR-10 and ImageNet datasets, using robust and non-robust image classification models, demonstrate that MultiShield can be easily integrated to detect and reject adversarial examples, outperforming the original defenses.","authors":["Francesco Villani","Igor Maljkovic","Dario Lazzaro","Angelo Sotgiu","Antonio Emanuele Cin\\`a","Fabio Roli"],"url":"https://arxiv.org/abs/2412.10353"}
{"created":"2025-04-21","title":"EditSplat: Multi-View Fusion and Attention-Guided Optimization for View-Consistent 3D Scene Editing with 3D Gaussian Splatting","abstract":"Recent advancements in 3D editing have highlighted the potential of text-driven methods in real-time, user-friendly AR/VR applications. However, current methods rely on 2D diffusion models without adequately considering multi-view information, resulting in multi-view inconsistency. While 3D Gaussian Splatting (3DGS) significantly improves rendering quality and speed, its 3D editing process encounters difficulties with inefficient optimization, as pre-trained Gaussians retain excessive source information, hindering optimization. To address these limitations, we propose EditSplat, a novel text-driven 3D scene editing framework that integrates Multi-view Fusion Guidance (MFG) and Attention-Guided Trimming (AGT). Our MFG ensures multi-view consistency by incorporating essential multi-view information into the diffusion process, leveraging classifier-free guidance from the text-to-image diffusion model and the geometric structure inherent to 3DGS. Additionally, our AGT utilizes the explicit representation of 3DGS to selectively prune and optimize 3D Gaussians, enhancing optimization efficiency and enabling precise, semantically rich local editing. Through extensive qualitative and quantitative evaluations, EditSplat achieves state-of-the-art performance, establishing a new benchmark for text-driven 3D scene editing.","authors":["Dong In Lee","Hyeongcheol Park","Jiyoung Seo","Eunbyung Park","Hyunje Park","Ha Dam Baek","Sangheon Shin","Sangmin Kim","Sangpil Kim"],"url":"https://arxiv.org/abs/2412.11520"}
{"created":"2025-04-21","title":"Establishing a Foundation for Tetun Ad-Hoc Text Retrieval: Stemming, Indexing, Retrieval, and Ranking","abstract":"Searching for information on the internet and digital platforms to satisfy an information need requires effective retrieval solutions. However, such solutions are not yet available for Tetun, making it challenging to find relevant documents for text-based search queries in this language. To address these challenges, we investigate Tetun text retrieval with a focus on the ad-hoc retrieval task. The study begins by developing essential language resources -- including a list of stopwords, a stemmer, and a test collection -- which serve as foundational components for solutions tailored to Tetun text retrieval. Various strategies are investigated using both document titles and content to evaluate retrieval effectiveness. The results demonstrate that retrieving document titles, after removing hyphens and apostrophes without applying stemming, significantly improves retrieval performance compared to the baseline. Efficiency increases by 31.37%, while effectiveness achieves an average relative gain of +9.40% in MAP@10 and +30.35% in NDCG@10 with DFR BM25. Beyond the top-10 cutoff point, Hiemstra LM shows strong performance across various retrieval strategies and evaluation metrics. Contributions of this work include the development of Labadain-Stopwords (a list of 160 Tetun stopwords), Labadain-Stemmer (a Tetun stemmer with three variants), and Labadain-Avaliad\\'or (a Tetun test collection containing 59 topics, 33,550 documents, and 5,900 qrels). We make all resources publicly accessible to facilitate future research in Tetun information retrieval.","authors":["Gabriel de Jesus","S\\'ergio Nunes"],"url":"https://arxiv.org/abs/2412.11758"}
{"created":"2025-04-21","title":"Are You Doubtful? Oh, It Might Be Difficult Then! Exploring the Use of Model Uncertainty for Question Difficulty Estimation","abstract":"In an educational setting, an estimate of the difficulty of multiple-choice questions (MCQs), a commonly used strategy to assess learning progress, constitutes very useful information for both teachers and students. Since human assessment is costly from multiple points of view, automatic approaches to MCQ item difficulty estimation are investigated, yielding however mixed success until now. Our approach to this problem takes a different angle from previous work: asking various Large Language Models to tackle the questions included in three different MCQ datasets, we leverage model uncertainty to estimate item difficulty. By using both model uncertainty features as well as textual features in a Random Forest regressor, we show that uncertainty features contribute substantially to difficulty prediction, where difficulty is inversely proportional to the number of students who can correctly answer a question. In addition to showing the value of our approach, we also observe that our model achieves state-of-the-art results on the USMLE and CMCQRD publicly available datasets.","authors":["Leonidas Zotos","Hedderik van Rijn","Malvina Nissim"],"url":"https://arxiv.org/abs/2412.11831"}
{"created":"2025-04-21","title":"Adversarial Hubness in Multi-Modal Retrieval","abstract":"Hubness is a phenomenon in high-dimensional vector spaces where a single point from the natural distribution is unusually close to many other points. This is a well-known problem in information retrieval that causes some items to accidentally (and incorrectly) appear relevant to many queries.","authors":["Tingwei Zhang","Fnu Suya","Rishi Jha","Collin Zhang","Vitaly Shmatikov"],"url":"https://arxiv.org/abs/2412.14113"}
{"created":"2025-04-21","title":"An OpenMind for 3D medical vision self-supervised learning","abstract":"The field of self-supervised learning (SSL) for 3D medical images lacks consistency and standardization. While many methods have been developed, it is impossible to identify the current state-of-the-art, due to i) varying and small pretraining datasets, ii) varying architectures, and iii) being evaluated on differing downstream datasets. In this paper, we bring clarity to this field and lay the foundation for further method advancements through three key contributions: We a) publish the largest publicly available pre-training dataset comprising 114k 3D brain MRI volumes, enabling all practitioners to pre-train on a large-scale dataset. We b) benchmark existing 3D self-supervised learning methods on this dataset for a state-of-the-art CNN and Transformer architecture, clarifying the state of 3D SSL pre-training. Among many findings, we show that pre-trained methods can exceed a strong from-scratch nnU-Net ResEnc-L baseline. Lastly, we c) publish the code of our pre-training and fine-tuning frameworks and provide the pre-trained models created during the benchmarking process to facilitate rapid adoption and reproduction.","authors":["Tassilo Wald","Constantin Ulrich","Jonathan Suprijadi","Sebastian Ziegler","Michal Nohel","Robin Peretzke","Gregor K\\\"ohler","Klaus H. Maier-Hein"],"url":"https://arxiv.org/abs/2412.17041"}
{"created":"2025-04-21","title":"How Breakable Is Privacy: Probing and Resisting Model Inversion Attacks in Collaborative Inference","abstract":"Collaborative inference (CI) improves computational efficiency for edge devices by transmitting intermediate features to cloud models. However, this process inevitably exposes feature representations to model inversion attacks (MIAs), enabling unauthorized data reconstruction. Despite extensive research, there is no established criterion for assessing the difficulty of MIA implementation, leaving a fundamental question unanswered: \\textit{What factors truly and verifiably determine the attack's success in CI?} Moreover, existing defenses lack the theoretical foundation described above, making it challenging to regulate feature information effectively while ensuring privacy and minimizing computational overhead. These shortcomings introduce three key challenges: theoretical gap, methodological limitation, and practical constraint.","authors":["Rongke Liu"],"url":"https://arxiv.org/abs/2501.00824"}
{"created":"2025-04-21","title":"BRIGHT: A globally distributed multimodal building damage assessment dataset with very-high-resolution for all-weather disaster response","abstract":"Disaster events occur around the world and cause significant damage to human life and property. Earth observation (EO) data enables rapid and comprehensive building damage assessment (BDA), an essential capability in the aftermath of a disaster to reduce human casualties and to inform disaster relief efforts. Recent research focuses on the development of AI models to achieve accurate mapping of unseen disaster events, mostly using optical EO data. However, solutions based on optical data are limited to clear skies and daylight hours, preventing a prompt response to disasters. Integrating multimodal (MM) EO data, particularly the combination of optical and SAR imagery, makes it possible to provide all-weather, day-and-night disaster responses. Despite this potential, the development of robust multimodal AI models has been constrained by the lack of suitable benchmark datasets. In this paper, we present a BDA dataset using veRy-hIGH-resoluTion optical and SAR imagery (BRIGHT) to support AI-based all-weather disaster response. To the best of our knowledge, BRIGHT is the first open-access, globally distributed, event-diverse MM dataset specifically curated to support AI-based disaster response. It covers five types of natural disasters and two types of man-made disasters across 14 regions worldwide, with a particular focus on developing countries where external assistance is most needed. The optical and SAR imagery in BRIGHT, with a spatial resolution between 0.3-1 meters, provides detailed representations of individual buildings, making it ideal for precise BDA. In our experiments, we have tested seven advanced AI models trained with our BRIGHT to validate the transferability and robustness. The dataset and code are available at https://github.com/ChenHongruixuan/BRIGHT. BRIGHT also serves as the official dataset for the 2025 IEEE GRSS Data Fusion Contest.","authors":["Hongruixuan Chen","Jian Song","Olivier Dietrich","Clifford Broni-Bediako","Weihao Xuan","Junjue Wang","Xinlei Shao","Yimin Wei","Junshi Xia","Cuiling Lan","Konrad Schindler","Naoto Yokoya"],"url":"https://arxiv.org/abs/2501.06019"}
{"created":"2025-04-21","title":"Towards Federated Multi-Armed Bandit Learning for Content Dissemination using Swarm of UAVs","abstract":"This paper introduces an Unmanned Aerial Vehicle - enabled content management architecture that is suitable for critical content access in communities of users that are communication-isolated during diverse types of disaster scenarios. The proposed architecture leverages a hybrid network of stationary anchor UAVs and mobile Micro-UAVs for ubiquitous content dissemination. The anchor UAVs are equipped with both vertical and lateral communication links, and they serve local users, while the mobile micro-ferrying UAVs extend coverage across communities with increased mobility. The focus is on developing a content dissemination system that dynamically learns optimal caching policies to maximize content availability. The core innovation is an adaptive content dissemination framework based on distributed Federated Multi-Armed Bandit learning. The goal is to optimize UAV content caching decisions based on geo-temporal content popularity and user demand variations. A Selective Caching Algorithm is also introduced to reduce redundant content replication by incorporating inter-UAV information sharing. This method strategically preserves the uniqueness in user preferences while amalgamating the intelligence across a distributed learning system. This approach improves the learning algorithm's ability to adapt to diverse user preferences. Functional verification and performance evaluation confirm the proposed architecture's utility across different network sizes, UAV swarms, and content popularity patterns.","authors":["Amit Kumar Bhuyan","Hrishikesh Dutta","Subir Biswas"],"url":"https://arxiv.org/abs/2501.09146"}
{"created":"2025-04-21","title":"Joint Power and Bit Allocation for Precoded Massive MIMO Channels","abstract":"This work addresses the joint optimization of power and bit allocation in precoded large-scale n x n MIMO systems with discrete input alphabets, specifically QAM constellations. We propose an adaptive QAM scheme that maintains a fixed gap to the Gaussian-input capacity for a given n. A key finding is that, under the proposed scheme, the mercury/waterfilling (MWF) solution reduces analytically to the classical water-filling (WF) policy. Furthermore, the adaptive QAM configuration can be precomputed under the large-system assumption, enabling the replacement of full SVD with truncated SVD and yielding substantial computational savings. To support practical deployment, we develop a bit-allocation algorithm that meets a target transmission data rate while minimizing the overall decoding error rate and preserving computational complexity at O(n log n). Simulation results confirm that the proposed truncated SVD precoding, paired with the joint power and bit allocation, achieves superior decoding performance relative to conventional approaches, while operating at significantly lower complexity.","authors":["Shuiyin Liu","Amin Sakzad"],"url":"https://arxiv.org/abs/2501.13380"}
{"created":"2025-04-21","title":"StaICC: Standardized Evaluation for Classification Task in In-context Learning","abstract":"Classification tasks are widely investigated in the In-Context Learning (ICL) paradigm. However, current efforts are evaluated on disjoint benchmarks and settings, while their performances are significantly influenced by some trivial variables, such as prompt templates, data sampling, instructions, etc., which leads to significant inconsistencies in the results reported across various literature, preventing fair comparison or meta-analysis across different papers. Therefore, this paper proposes a standardized and easy-to-use evaluation toolkit (StaICC) for in-context classification. Including, for the normal classification task, we provide StaICC-Normal, selecting 10 widely used datasets, and generating prompts with a fixed form, to mitigate the variance among the experiment implementations. To enrich the usage of our benchmark, we also provide a sub-benchmark StaICC-Diag for diagnosing ICL from several aspects, aiming for a more robust inference processing.","authors":["Hakaze Cho","Naoya Inoue"],"url":"https://arxiv.org/abs/2501.15708"}
{"created":"2025-04-21","title":"Prompt-Based Cost-Effective Evaluation and Operation of ChatGPT as a Computer Programming Teaching Assistant","abstract":"The dream of achieving a student-teacher ratio of 1:1 is closer than ever thanks to the emergence of large language models (LLMs). One potential application of these models in the educational field would be to provide feedback to students in university introductory programming courses, so that a student struggling to solve a basic implementation problem could seek help from an LLM available 24/7. This article focuses on studying three aspects related to such an application. First, the performance of two well-known models, GPT-3.5T and GPT-4T, in providing feedback to students is evaluated. The empirical results showed that GPT-4T performs much better than GPT-3.5T, however, it is not yet ready for use in a real-world scenario. This is due to the possibility of generating incorrect information that potential users may not always be able to detect. Second, the article proposes a carefully designed prompt using in-context learning techniques that allows automating important parts of the evaluation process, as well as providing a lower bound for the fraction of feedbacks containing incorrect information, saving time and effort. This was possible because the resulting feedback has a programmatically analyzable structure that incorporates diagnostic information about the LLM's performance in solving the requested task. Third, the article also suggests a possible strategy for implementing a practical learning tool based on LLMs, which is rooted on the proposed prompting techniques. This strategy opens up a whole range of interesting possibilities from a pedagogical perspective.","authors":["Marc Ballestero-Rib\\'o","Daniel Ortiz-Mart\\'inez"],"url":"https://arxiv.org/abs/2501.17176"}
{"created":"2025-04-21","title":"Transformation trees -- documentation of multimodal image registration","abstract":"Multimodal image registration plays a key role in creating digital patient models by combining data from different imaging techniques into a single coordinate system. This process often involves multiple sequential and interconnected transformations, which must be well-documented to ensure transparency and reproducibility. In this paper, we propose the use of transformation trees as a method for structured recording and management of these transformations. This approach has been implemented in the dpVision software and uses a dedicated .dpw file format to store hierarchical relationships between images, transformations, and motion data. Transformation trees allow precise tracking of all image processing steps, reduce the need to store multiple copies of the same data, and enable the indirect registration of images that do not share common reference points. This improves the reproducibility of the analyses and facilitates later processing and integration of images from different sources. The practical application of this method is demonstrated with examples from orthodontics, including the integration of 3D face scans, intraoral scans, and CBCT images, as well as the documentation of mandibular motion. Beyond orthodontics, this method can be applied in other fields that require systematic management of image registration processes, such as maxillofacial surgery, oncology, and biomechanical analysis. Maintaining long-term data consistency is essential for both scientific research and clinical practice. It enables easier comparison of results in longitudinal studies, improves retrospective analysis, and supports the development of artificial intelligence algorithms by providing standardized and well-documented datasets. The proposed approach enhances data organization, allows for efficient analysis, and facilitates the reuse of information in future studies and diagnostic procedures.","authors":["Agnieszka Anna Tomaka","Dariusz Pojda","Micha{\\l} Tarnawski","Leszek Luchowski"],"url":"https://arxiv.org/abs/2501.19140"}
{"created":"2025-04-21","title":"Space-bounded online Kolmogorov complexity is additive","abstract":"The even online Kolmogorov complexity of a string $x = x_1 x_2 \\cdots x_{n}$ is the minimal length of a program that for all $i\\le n/2$, on input $x_1x_3 \\cdots x_{2i-1}$ outputs $x_{2i}$. The odd complexity is defined similarly. The sum of the odd and even complexities is called the dialogue complexity.","authors":["Bruno Bauwens","Maria Marchenko"],"url":"https://arxiv.org/abs/2502.02777"}
{"created":"2025-04-21","title":"Training-free Task-oriented Grasp Generation","abstract":"This paper presents a training-free pipeline for task-oriented grasp generation that combines pre-trained grasp generation models with vision-language models (VLMs). Unlike traditional approaches that focus solely on stable grasps, our method incorporates task-specific requirements by leveraging the semantic reasoning capabilities of VLMs. We evaluate five querying strategies, each utilizing different visual representations of candidate grasps, and demonstrate significant improvements over a baseline method in both grasp success and task compliance rates, with absolute gains of up to 36.9\\% in overall success rate. Our results underline the potential of VLMs to enhance task-oriented manipulation, providing insights for future research in robotic grasping and human-robot interaction.","authors":["Jiaming Wang","Jizhuo Chen","Diwen Liu","Linh K\\\"astner"],"url":"https://arxiv.org/abs/2502.04873"}
{"created":"2025-04-21","title":"Demonstrating CavePI: Autonomous Exploration of Underwater Caves by Semantic Guidance","abstract":"Enabling autonomous robots to safely and efficiently navigate, explore, and map underwater caves is of significant importance to water resource management, hydrogeology, archaeology, and marine robotics. In this work, we demonstrate the system design and algorithmic integration of a visual servoing framework for semantically guided autonomous underwater cave exploration. We present the hardware and edge-AI design considerations to deploy this framework on a novel AUV (Autonomous Underwater Vehicle) named CavePI. The guided navigation is driven by a computationally light yet robust deep visual perception module, delivering a rich semantic understanding of the environment. Subsequently, a robust control mechanism enables CavePI to track the semantic guides and navigate within complex cave structures. We evaluate the system through field experiments in natural underwater caves and spring-water sites and further validate its ROS (Robot Operating System)-based digital twin in a simulation environment. Our results highlight how these integrated design choices facilitate reliable navigation under feature-deprived, GPS-denied, and low-visibility conditions.","authors":["Alankrit Gupta","Adnan Abdullah","Xianyao Li","Vaishnav Ramesh","Ioannis Rekleitis","Md Jahidul Islam"],"url":"https://arxiv.org/abs/2502.05384"}
{"created":"2025-04-21","title":"Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models","abstract":"Although large multimodal models (LMMs) have demonstrated remarkable capabilities in visual scene interpretation and reasoning, their capacity for complex and precise 3-dimensional spatial reasoning remains uncertain. Existing benchmarks focus predominantly on 2D spatial understanding and lack a framework to comprehensively evaluate 6D spatial reasoning across varying complexities. To address this limitation, we present Spatial457, a scalable and unbiased synthetic dataset designed with 4 key capability for spatial reasoning: multi-object recognition, 2D location, 3D location, and 3D orientation. We develop a cascading evaluation structure, constructing 7 question types across 5 difficulty levels that range from basic single object recognition to our new proposed complex 6D spatial reasoning tasks. We evaluated various large multimodal models (LMMs) on PulseCheck457, observing a general decline in performance as task complexity increases, particularly in 3D reasoning and 6D spatial tasks. To quantify these challenges, we introduce the Relative Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning capabilities. Leveraging the unbiased attribute design of our dataset, we also uncover prediction biases across different attributes, with similar patterns observed in real-world image settings. The code and data are released in https://github.com/XingruiWang/Spatial457.","authors":["Xingrui Wang","Wufei Ma","Tiezheng Zhang","Celso M de Melo","Jieneng Chen","Alan Yuille"],"url":"https://arxiv.org/abs/2502.08636"}
{"created":"2025-04-21","title":"Pitfalls of Evidence-Based AI Policy","abstract":"Nations across the world are working to govern AI. However, from a technical perspective, there is uncertainty and disagreement on the best way to do this. Meanwhile, recent debates over AI regulation have led to calls for \"evidence-based AI policy\" which emphasize holding regulatory action to a high evidentiary standard. Evidence is of irreplaceable value to policymaking. However, holding regulatory action to too high an evidentiary standard can lead to systematic neglect of certain risks. In historical policy debates (e.g., over tobacco ca. 1965 and fossil fuels ca. 1985) \"evidence-based policy\" rhetoric is also a well-precedented strategy to downplay the urgency of action, delay regulation, and protect industry interests. Here, we argue that if the goal is evidence-based AI policy, the first regulatory objective must be to actively facilitate the process of identifying, studying, and deliberating about AI risks. We discuss a set of 15 regulatory goals to facilitate this and show that Brazil, Canada, China, the EU, South Korea, the UK, and the USA all have substantial opportunities to adopt further evidence-seeking policies.","authors":["Stephen Casper","David Krueger","Dylan Hadfield-Menell"],"url":"https://arxiv.org/abs/2502.09618"}
{"created":"2025-04-21","title":"A-MEM: Agentic Memory for LLM Agents","abstract":"While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/AgenticMemory, while the source code of agentic memory system is available at https://github.com/agiresearch/A-mem.","authors":["Wujiang Xu","Kai Mei","Hang Gao","Juntao Tan","Zujie Liang","Yongfeng Zhang"],"url":"https://arxiv.org/abs/2502.12110"}
{"created":"2025-04-21","title":"Pricing is All You Need to Improve Traffic Routing","abstract":"We investigate the design of pricing policies that enhance driver adherence to route guidance, ensuring effective routing control. The major novelty lies in that we adopt a Markov chain to model drivers' compliance rates conditioned on both traffic states and tolls. By formulating the managed traffic network as a nonlinear stochastic dynamical system, we can quantify in a more realistic way the impacts of driver route choices and thus determine appropriate tolls. Specially, we focus on a network comprised of one corridor and one local street. We assume that a reasonable routing policy is specified in advance. However, drivers could be reluctant to be detoured. Thus a fixed toll is set on the corridor to give drivers incentives to choose the local street. We evaluate the effectiveness of the given routing and pricing policies via stability analysis. We suggest using the stability and instability conditions to establish lower and upper bounds on throughput. This allows us to select suitable tolls that maximize these bounds.","authors":["Yu Tang","Kaan Ozbay","Li Jin"],"url":"https://arxiv.org/abs/2502.13077"}
{"created":"2025-04-21","title":"JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework","abstract":"Deep learning has achieved significant success in the field of remote sensing image change detection (CD), yet two major challenges remain: the scarcity of sub-meter, comprehensive open-source CD datasets, and the difficulty of achieving consistent and satisfactory detection results across images with varying change areas. To address these issues, we introduce the JL1-CD dataset, which consists of 5,000 pairs of 512 x 512 pixel images with a resolution of 0.5 to 0.75 meters. This all-inclusive dataset covers a wide range of human-induced and natural changes, including buildings, roads, hardened surfaces, woodlands, grasslands, croplands, water bodies, and photovoltaic panels, among others. Additionally, we propose a novel multi-teacher knowledge distillation (MTKD) framework that leverages the Origin-Partition (O-P) strategy to enhance CD performance. In the O-P strategy, we partition the training data based on the Change Area Ratio (CAR) to train separate models for small, medium, and large CAR values, alleviating the learning burden on each model and improving their performance within their respective partitions. Building upon this, our MTKD framework distills knowledge from multiple teacher models trained on different CAR partitions into a single student model,enabling the student model to achieve superior detection results across diverse CAR scenarios without incurring additional computational or time overhead during the inference phase. Experimental results on the JL1-CD and SYSU-CD datasets demonstrate that the MTKD framework significantly improves the performance of CD models with various network architectures and parameter sizes, achieving new state-of-the-art results. The JL1-CD dataset and code are available at https://github.com/circleLZY/MTKD-CD.","authors":["Ziyuan Liu","Ruifei Zhu","Long Gao","Yuanxiu Zhou","Jingyu Ma","Yuantao Gu"],"url":"https://arxiv.org/abs/2502.13407"}
{"created":"2025-04-21","title":"Unbiased Collaborative Filtering with Fair Sampling","abstract":"Recommender systems leverage extensive user interaction data to model preferences; however, directly modeling these data may introduce biases that disproportionately favor popular items. In this paper, we demonstrate that popularity bias arises from the influence of propensity factors during training. Building on this insight, we propose a fair sampling (FS) method that ensures each user and each item has an equal likelihood of being selected as both positive and negative instances, thereby mitigating the influence of propensity factors. The proposed FS method does not require estimating propensity scores, thus avoiding the risk of failing to fully eliminate popularity bias caused by estimation inaccuracies. Comprehensive experiments demonstrate that the proposed FS method achieves state-of-the-art performance in both point-wise and pair-wise recommendation tasks. The code implementation is available at https://github.com/jhliu0807/Fair-Sampling.","authors":["Jiahao Liu","Dongsheng Li","Hansu Gu","Peng Zhang","Tun Lu","Li Shang","Ning Gu"],"url":"https://arxiv.org/abs/2502.13840"}
{"created":"2025-04-21","title":"AgentCF++: Memory-enhanced LLM-based Agents for Popularity-aware Cross-domain Recommendations","abstract":"LLM-based user agents, which simulate user interaction behavior, are emerging as a promising approach to enhancing recommender systems. In real-world scenarios, users' interactions often exhibit cross-domain characteristics and are influenced by others. However, the memory design in current methods causes user agents to introduce significant irrelevant information during decision-making in cross-domain scenarios and makes them unable to recognize the influence of other users' interactions, such as popularity factors. To tackle this issue, we propose a dual-layer memory architecture combined with a two-step fusion mechanism. This design avoids irrelevant information during decision-making while ensuring effective integration of cross-domain preferences. We also introduce the concepts of interest groups and group-shared memory to better capture the influence of popularity factors on users with similar interests. Comprehensive experiments validate the effectiveness of AgentCF++. Our code is available at https://github.com/jhliu0807/AgentCF-plus.","authors":["Jiahao Liu","Shengkang Gu","Dongsheng Li","Guangping Zhang","Mingzhe Han","Hansu Gu","Peng Zhang","Tun Lu","Li Shang","Ning Gu"],"url":"https://arxiv.org/abs/2502.13843"}
{"created":"2025-04-21","title":"Improving LLM-powered Recommendations with Personalized Information","abstract":"Due to the lack of explicit reasoning modeling, existing LLM-powered recommendations fail to leverage LLMs' reasoning capabilities effectively. In this paper, we propose a pipeline called CoT-Rec, which integrates two key Chain-of-Thought (CoT) processes -- user preference analysis and item perception analysis -- into LLM-powered recommendations, thereby enhancing the utilization of LLMs' reasoning abilities. CoT-Rec consists of two stages: (1) personalized information extraction, where user preferences and item perception are extracted, and (2) personalized information utilization, where this information is incorporated into the LLM-powered recommendation process. Experimental results demonstrate that CoT-Rec shows potential for improving LLM-powered recommendations. The implementation is publicly available at https://github.com/jhliu0807/CoT-Rec.","authors":["Jiahao Liu","Xueshuo Yan","Dongsheng Li","Guangping Zhang","Hansu Gu","Peng Zhang","Tun Lu","Li Shang","Ning Gu"],"url":"https://arxiv.org/abs/2502.13845"}
{"created":"2025-04-21","title":"Token-Level Density-Based Uncertainty Quantification Methods for Eliciting Truthfulness of Large Language Models","abstract":"Uncertainty quantification (UQ) is a prominent approach for eliciting truthful answers from large language models (LLMs). To date, information-based and consistency-based UQ have been the dominant UQ methods for text generation via LLMs. Density-based methods, despite being very effective for UQ in text classification with encoder-based models, have not been very successful with generative LLMs. In this work, we adapt Mahalanobis Distance (MD) - a well-established UQ technique in classification tasks - for text generation and introduce a new supervised UQ method. Our method extracts token embeddings from multiple layers of LLMs, computes MD scores for each token, and uses linear regression trained on these features to provide robust uncertainty scores. Through extensive experiments on eleven datasets, we demonstrate that our approach substantially improves over existing UQ methods, providing accurate and computationally efficient uncertainty scores for both sequence-level selective generation and claim-level fact-checking tasks. Our method also exhibits strong generalization to out-of-domain data, making it suitable for a wide range of LLM-based applications.","authors":["Artem Vazhentsev","Lyudmila Rvanova","Ivan Lazichny","Alexander Panchenko","Maxim Panov","Timothy Baldwin","Artem Shelmanov"],"url":"https://arxiv.org/abs/2502.14427"}
{"created":"2025-04-21","title":"Reinforcement Learning with Graph Attention for Routing and Wavelength Assignment with Lightpath Reuse","abstract":"Many works have investigated reinforcement learning (RL) for routing and spectrum assignment on flex-grid networks but only one work to date has examined RL for fixed-grid with flex-rate transponders, despite production systems using this paradigm. Flex-rate transponders allow existing lightpaths to accommodate new services, a task we term routing and wavelength assignment with lightpath reuse (RWA-LR). We re-examine this problem and present a thorough benchmarking of heuristic algorithms for RWA-LR, which are shown to have 6% increased throughput when candidate paths are ordered by number of hops, rather than total length. We train an RL agent for RWA-LR with graph attention networks for the policy and value functions to exploit the graph-structured data. We provide details of our methodology and open source all of our code for reproduction. We outperform the previous state-of-the-art RL approach by 2.5% (17.4 Tbps mean additional throughput) and the best heuristic by 1.2% (8.5 Tbps mean additional throughput). This marginal gain highlights the difficulty in learning effective RL policies on long horizon resource allocation tasks.","authors":["Michael Doherty","Alejandra Beghelli"],"url":"https://arxiv.org/abs/2502.14741"}
{"created":"2025-04-21","title":"Towards a Reward-Free Reinforcement Learning Framework for Vehicle Control","abstract":"Reinforcement learning plays a crucial role in vehicle control by guiding agents to learn optimal control strategies through designing or learning appropriate reward signals. However, in vehicle control applications, rewards typically need to be manually designed while considering multiple implicit factors, which easily introduces human biases. Although imitation learning methods does not rely on explicit reward signals, they necessitate high-quality expert actions, which are often challenging to acquire. To address these issues, we propose a reward-free reinforcement learning framework (RFRLF). This framework directly learns the target states to optimize agent behavior through a target state prediction network (TSPN) and a reward-free state-guided policy network (RFSGPN), avoiding the dependence on manually designed reward signals. Specifically, the policy network is learned via minimizing the differences between the predicted state and the expert state. Experimental results demonstrate the effectiveness of the proposed RFRLF in controlling vehicle driving, showing its advantages in improving learning efficiency and adapting to reward-free environments.","authors":["Jielong Yang","Daoyuan Huang"],"url":"https://arxiv.org/abs/2502.15262"}
{"created":"2025-04-21","title":"Maximum Welfare Allocations under Quantile Valuations","abstract":"We propose a new model for aggregating preferences over a set of indivisible items based on a quantile value. In this model, each agent is endowed with a specific quantile, and the value of a given bundle is defined by the corresponding quantile of the individual values of the items within it. Our model captures the diverse ways in which agents may perceive a bundle, even when they agree on the values of individual items. It enables richer behavioral modeling that cannot be easily captured by additive valuation functions. We study the problem of maximizing utilitarian and egalitarian welfare within the quantile-based valuation setting. For each of the welfare functions, we analyze the complexity of the objectives. Interestingly, our results show that the complexity of both objectives varies significantly depending on whether the allocation is required to be balanced. We provide near-optimal approximation algorithms for utilitarian welfare, and for egalitarian welfare, we present exact algorithms whenever possible.","authors":["Haris Aziz","Shivika Narang","Mashbat Suzuki"],"url":"https://arxiv.org/abs/2502.17869"}
{"created":"2025-04-21","title":"Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs","abstract":"Paywalls, licenses and copyright rules often restrict the broad dissemination and reuse of scientific knowledge. We take the position that it is both legally and technically feasible to extract the scientific knowledge in scholarly texts. Current methods, like text embeddings, fail to reliably preserve factual content, and simple paraphrasing may not be legally sound. We propose a new idea for the community to adopt: convert scholarly documents into knowledge preserving, but style agnostic representations we term Knowledge Units using LLMs. These units use structured data capturing entities, attributes and relationships without stylistic content. We provide evidence that Knowledge Units (1) form a legally defensible framework for sharing knowledge from copyrighted research texts, based on legal analyses of German copyright law and U.S. Fair Use doctrine, and (2) preserve most (~95\\%) factual knowledge from original text, measured by MCQ performance on facts from the original copyrighted text across four research domains. Freeing scientific knowledge from copyright promises transformative benefits for scientific research and education by allowing language models to reuse important facts from copyrighted text. To support this, we share open-source tools for converting research documents into Knowledge Units. Overall, our work posits the feasibility of democratizing access to scientific knowledge while respecting copyright.","authors":["Christoph Schuhmann","Gollam Rabby","Ameya Prabhu","Tawsif Ahmed","Andreas Hochlehnert","Huu Nguyen","Nick Akinci","Ludwig Schmidt","Robert Kaczmarczyk","S\\\"oren Auer","Jenia Jitsev","Matthias Bethge"],"url":"https://arxiv.org/abs/2502.19413"}
{"created":"2025-04-21","title":"On Piecewise Affine Reachability with Bellman Operators","abstract":"A piecewise affine map is one of the simplest mathematical objects exhibiting complex dynamics. The reachability problem of piecewise affine maps is as follows: Given two vectors $\\mathbf{s}, \\mathbf{t} \\in \\mathbb{Q}^d$ and a piecewise affine map $f$, is there $n\\in \\mathbb{N}$ such that $f^{n}(\\mathbf{s}) = \\mathbf{t}$? Koiran, Cosnard, and Garzon show that the reachability problem of piecewise affine maps is undecidable even in dimension 2.","authors":["Anton Varonka","Kazuki Watanabe"],"url":"https://arxiv.org/abs/2502.19923"}
{"created":"2025-04-21","title":"Differential Contrastive Training for Gaze Estimation","abstract":"The complex application scenarios have raised critical requirements for precise and generalizable gaze estimation methods. Recently, the pre-trained CLIP has achieved remarkable performance on various vision tasks, but its potentials have not been fully exploited in gaze estimation. In this paper, we propose a novel Differential Contrastive Training strategy, which boosts gaze estimation performance with the help of the CLIP. Accordingly, a Differential Contrastive Gaze Estimation network (DCGaze) composed of a Visual Appearance-aware branch and a Semantic Differential-aware branch is introduced. The Visual Appearance-aware branch is essentially a primary gaze estimation network and it incorporates an Adaptive Feature-refinement Unit (AFU) and a Double-head Gaze Regressor (DGR), which both help the primary network to extract informative and gaze-related appearance features. Moreover, the Semantic Difference-aware branch is designed on the basis of the CLIP's text encoder to reveal the semantic difference of gazes. This branch could further empower the Visual Appearance-aware branch with the capability of characterizing the gaze-related semantic information. Extensive experimental results on four challenging datasets over within and cross-domain tasks demonstrate the effectiveness of our DCGaze. Code will be available upon acceptance.","authors":["Lin Zhang","Yi Tian","XiYun Wang","Wanru Xu","Yi Jin","Yaping Huang"],"url":"https://arxiv.org/abs/2502.20128"}
{"created":"2025-04-21","title":"PennyLang: Pioneering LLM-Based Quantum Code Generation with a Novel PennyLane-Centric Dataset","abstract":"Large Language Models (LLMs) offer remarkable capabilities in code generation, natural language processing, and domain-specific reasoning. However, their application in quantum software development remains underexplored, particularly for PennyLane-a leading framework for hybrid quantum-classical computing. To address this gap, we introduce a novel, high-quality dataset comprising 3,347 PennyLane-specific quantum code samples and contextual descriptions, specifically curated to support LLM training and fine-tuning for quantum code assistance. Our contributions are threefold: (1) the automatic construction and open-source release of a comprehensive PennyLane dataset derived from textbooks, official documentation, and open-source repositories; (2) a structured methodology for data curation, annotation, and formatting to enhance LLM usability and relevance; and (3) a rigorous evaluation of code generation capabilities using both baseline Retrieval-Augmented Generation (RAG) and a GraphRAG-enhanced pipeline. Using the PennyLang framework, we demonstrate that GraphRAG, when applied to a GPT-4o Mini model, substantially outperforms standard prompting and baseline RAG. Accuracy improves from 20.5% (without RAG) to 58.2% with GraphRAG, showcasing its effectiveness in reducing hallucinations and improving code correctness in quantum programming tasks. Compared to prior efforts focused largely on Qiskit, our work expands LLM-based assistance to the PennyLane ecosystem, contributing practical tools and reproducible methodologies for advancing AI-assisted quantum software development.","authors":["Abdul Basit","Nouhaila Innan","Haider Asif","Minghao Shao","Muhammad Kashif","Alberto Marchisio","Muhammad Shafique"],"url":"https://arxiv.org/abs/2503.02497"}
{"created":"2025-04-21","title":"Near-Polynomially Competitive Active Logistic Regression","abstract":"We address the problem of active logistic regression in the realizable setting. It is well known that active learning can require exponentially fewer label queries compared to passive learning, in some cases using $\\log \\frac{1}{\\eps}$ rather than $\\poly(1/\\eps)$ labels to get error $\\eps$ larger than the optimum.","authors":["Yihan Zhou","Eric Price","Trung Nguyen"],"url":"https://arxiv.org/abs/2503.05981"}
{"created":"2025-04-21","title":"Psycholinguistic Analyses in Software Engineering Text: A Systematic Literature Review","abstract":"Context: A deeper understanding of human factors in software engineering (SE) is essential for improving team collaboration, decision-making, and productivity. Communication channels like code reviews and chats provide insights into developers' psychological and emotional states. While large language models excel at text analysis, they often lack transparency and precision. Psycholinguistic tools like Linguistic Inquiry and Word Count (LIWC) offer clearer, interpretable insights into cognitive and emotional processes exhibited in text. Despite its wide use in SE research, no comprehensive review of LIWC's use has been conducted. Objective: We examine the importance of psycholinguistic tools, particularly LIWC, and provide a thorough analysis of its current and potential future applications in SE research. Methods: We conducted a systematic review of six prominent databases, identifying 43 SE-related papers using LIWC. Our analysis focuses on five research questions. Results: Our findings reveal a wide range of applications, including analyzing team communication to detect developer emotions and personality, developing ML models to predict deleted Stack Overflow posts, and more recently comparing AI-generated and human-written text. LIWC has been primarily used with data from project management platforms (e.g., GitHub) and Q&amp;A forums (e.g., Stack Overflow). Key BSE concepts include Communication, Organizational Climate, and Positive Psychology. 26 of 43 papers did not formally evaluate LIWC. Concerns were raised about some limitations, including difficulty handling SE-specific vocabulary. Conclusion: We highlight the potential of psycholinguistic tools and their limitations, and present new use cases for advancing the research of human factors in SE (e.g., bias in human-LLM conversations).","authors":["Amirali Sajadi","Kostadin Damevski","Preetha Chatterjee"],"url":"https://arxiv.org/abs/2503.05992"}
{"created":"2025-04-21","title":"PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures with Phase-Transferred Diffusion Model","abstract":"Optical illusion hidden picture is an interesting visual perceptual phenomenon where an image is cleverly integrated into another picture in a way that is not immediately obvious to the viewer. Established on the off-the-shelf text-to-image (T2I) diffusion model, we propose a novel training-free text-guided image-to-image (I2I) translation framework dubbed as \\textbf{P}hase-\\textbf{T}ransferred \\textbf{Diffusion} Model (PTDiffusion) for hidden art syntheses. PTDiffusion harmoniously embeds an input reference image into arbitrary scenes described by the text prompts, producing illusion images exhibiting hidden visual cues of the reference image. At the heart of our method is a plug-and-play phase transfer mechanism that dynamically and progressively transplants diffusion features' phase spectrum from the denoising process to reconstruct the reference image into the one to sample the generated illusion image, realizing deep fusion of the reference structural information and the textual semantic information in the diffusion model latent space. Furthermore, we propose asynchronous phase transfer to enable flexible control to the degree of hidden content discernability. Our method bypasses any model training and fine-tuning process, all while substantially outperforming related text-guided I2I methods in image generation quality, text fidelity, visual discernibility, and contextual naturalness for illusion picture synthesis, as demonstrated by extensive qualitative and quantitative experiments. Our project is publically available at \\href{https://xianggao1102.github.io/PTDiffusion_webpage/}{this web page}.","authors":["Xiang Gao","Shuai Yang","Jiaying Liu"],"url":"https://arxiv.org/abs/2503.06186"}
{"created":"2025-04-21","title":"A Comprehensive Survey of Mixture-of-Experts: Algorithms, Theory, and Applications","abstract":"Artificial intelligence (AI) has achieved astonishing successes in many domains, especially with the recent breakthroughs in the development of foundational large models. These large models, leveraging their extensive training data, provide versatile solutions for a wide range of downstream tasks. However, as modern datasets become increasingly diverse and complex, the development of large AI models faces two major challenges: (1) the enormous consumption of computational resources and deployment difficulties, and (2) the difficulty in fitting heterogeneous and complex data, which limits the usability of the models. Mixture of Experts (MoE) models has recently attracted much attention in addressing these challenges, by dynamically selecting and activating the most relevant sub-models to process input data. It has been shown that MoEs can significantly improve model performance and efficiency with fewer resources, particularly excelling in handling large-scale, multimodal data. Given the tremendous potential MoE has demonstrated across various domains, it is urgent to provide a comprehensive summary of recent advancements of MoEs in many important fields. Existing surveys on MoE have their limitations, e.g., being outdated or lacking discussion on certain key areas, and we aim to address these gaps. In this paper, we first introduce the basic design of MoE, including gating functions, expert networks, routing mechanisms, training strategies, and system design. We then explore the algorithm design of MoE in important machine learning paradigms such as continual learning, meta-learning, multi-task learning, and reinforcement learning. Additionally, we summarize theoretical studies aimed at understanding MoE and review its applications in computer vision and natural language processing. Finally, we discuss promising future research directions.","authors":["Siyuan Mu","Sen Lin"],"url":"https://arxiv.org/abs/2503.07137"}
{"created":"2025-04-21","title":"A Survey on Self-supervised Contrastive Learning for Multimodal Text-Image Analysis","abstract":"Self-supervised learning is a machine learning approach that generates implicit labels by learning underlined patterns and extracting discriminative features from unlabeled data without manual labelling. Contrastive learning introduces the concept of \"positive\" and \"negative\" samples, where positive pairs (e.g., variation of the same image/object) are brought together in the embedding space, and negative pairs (e.g., views from different images/objects) are pushed farther away. This methodology has shown significant improvements in image understanding and image text analysis without much reliance on labeled data. In this paper, we comprehensively discuss the terminologies, recent developments and applications of contrastive learning with respect to text-image models. Specifically, we provide an overview of the approaches of contrastive learning in text-image models in recent years. Secondly, we categorize the approaches based on different model structures. Thirdly, we further introduce and discuss the latest advances of the techniques used in the process such as pretext tasks for both images and text, architectural structures, and key trends. Lastly, we discuss the recent state-of-art applications of self-supervised contrastive learning Text-Image based models.","authors":["Asifullah Khan","Laiba Asmatullah","Anza Malik","Shahzaib Khan","Hamna Asif"],"url":"https://arxiv.org/abs/2503.11101"}
{"created":"2025-04-21","title":"The Road to Hybrid Quantum Programs: Characterizing the Evolution from Classical to Hybrid Quantum Software","abstract":"Quantum computing exhibits the unique capability to natively and efficiently encode various natural phenomena, promising theoretical speedups of several orders of magnitude. However, not all computational tasks can be efficiently executed on quantum machines, giving rise to hybrid systems, where some portions of an application run on classical machines, while others utilize quantum resources. Efforts to identify quantum candidate code fragments that can meaningfully execute on quantum machines primarily rely on static code analysis. Yet, the state-of-the-art in static code analysis for quantum candidates remains in its infancy, with limited applicability to specific frameworks and languages, and a lack of generalizability. Existing methods often involve a trial-and-error approach, relying on the intuition and expertise of computer scientists, resulting in varying identification durations ranging from minutes to days for a single application.","authors":["Vincenzo De Maio","Ivona Brandic","Ewa Deelman","J\\\"urgen Cito"],"url":"https://arxiv.org/abs/2503.11450"}
{"created":"2025-04-21","title":"DNR Bench: Benchmarking Over-Reasoning in Reasoning LLMs","abstract":"Test-time scaling has significantly improved large language model performance, enabling deeper reasoning to solve complex problems. However, this increased reasoning capability also leads to excessive token generation and unnecessary problem-solving attempts. We introduce Don\\'t Reason Bench (DNR Bench), a new benchmark designed to evaluate LLMs ability to robustly understand the tricky reasoning triggers and avoiding unnecessary generation. DNR Bench consists of 150 adversarially designed prompts that are easy for humans to understand and respond to, but surprisingly not for many of the recent prominent LLMs. DNR Bench tests models abilities across different capabilities, such as instruction adherence, hallucination avoidance, redundancy filtering, and unanswerable question recognition. We evaluate reasoning LLMs (RLMs), including DeepSeek-R1, OpenAI O3-mini, Claude-3.7-sonnet and compare them against a powerful non-reasoning model, e.g., GPT-4o. Our experiments reveal that RLMs generate up to 70x more tokens than necessary, often failing at tasks that simpler non-reasoning models handle efficiently with higher accuracy. Our findings underscore the need for more effective training and inference strategies in RLMs.","authors":["Masoud Hashemi","Oluwanifemi Bamgbose","Sathwik Tejaswi Madhusudhan","Jishnu Sethumadhavan Nair","Aman Tiwari","Vikas Yadav"],"url":"https://arxiv.org/abs/2503.15793"}
{"created":"2025-04-21","title":"HybridoNet-Adapt: A Domain-Adapted Framework for Accurate Lithium-Ion Battery RUL Prediction","abstract":"Accurate prediction of the Remaining Useful Life (RUL) in Lithium ion battery (LIB) health management systems is essential for ensuring operational reliability and safety. However, many existing methods assume that training and testing data follow the same distribution, limiting their ability to generalize to unseen target domains. To address this, we propose a novel RUL prediction framework that incorporates a domain adaptation (DA) technique. Our framework integrates a signal preprocessing pipeline including noise reduction, feature extraction, and normalization with a robust deep learning model called HybridoNet Adapt. The model features a combination of LSTM, Multihead Attention, and Neural ODE layers for feature extraction, followed by two predictor modules with trainable trade-off parameters. To improve generalization, we adopt a DA strategy inspired by Domain Adversarial Neural Networks (DANN), replacing adversarial loss with Maximum Mean Discrepancy (MMD) to learn domain-invariant features. Experimental results show that HybridoNet Adapt significantly outperforms traditional models such as XGBoost and Elastic Net, as well as deep learning baselines like Dual input DNN, demonstrating its potential for scalable and reliable battery health management (BHM).","authors":["Khoa Tran","Bao Huynh","Tri Le","Lam Pham","Vy-Rin Nguyen","Hung-Cuong Trinh","Duong Tran Anh"],"url":"https://arxiv.org/abs/2503.21392"}
{"created":"2025-04-21","title":"ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation","abstract":"Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely primarily on parametric knowledge, limiting factual accuracy. While recent works equip reinforcement learning (RL)-based LRMs with retrieval capabilities, they suffer from overthinking and lack robustness in reasoning, reducing their effectiveness in question answering (QA) tasks. To address this, we propose ReaRAG, a factuality-enhanced reasoning model that explores diverse queries without excessive iterations. Our solution includes a novel data construction framework with an upper bound on the reasoning chain length. Specifically, we first leverage an LRM to generate deliberate thinking, then select an action from a predefined action space (Search and Finish). For Search action, a query is executed against the RAG engine, where the result is returned as observation to guide reasoning steps later. This process iterates until a Finish action is chosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach outperforms existing baselines on multi-hop QA. Further analysis highlights its strong reflective ability to recognize errors and refine its reasoning trajectory. Our study enhances LRMs' factuality while effectively integrating robust reasoning for Retrieval-Augmented Generation (RAG).","authors":["Zhicheng Lee","Shulin Cao","Jinxin Liu","Jiajie Zhang","Weichuan Liu","Xiaoyin Che","Lei Hou","Juanzi Li"],"url":"https://arxiv.org/abs/2503.21729"}
{"created":"2025-04-21","title":"Multimodal machine learning with large language embedding model for polymer property prediction","abstract":"Contemporary large language models (LLMs), such as GPT-4 and Llama, have harnessed extensive computational power and diverse text corpora to achieve remarkable proficiency in interpreting and generating domain-specific content, including materials science. To leverage the domain knowledge embedded within these models, we propose a simple yet effective multimodal architecture, PolyLLMem, which integrates text embeddings generated by Llama 3 with molecular structure embeddings derived from Uni-Mol, for polymer properties prediction tasks. In our model, Low-rank adaptation (LoRA) layers were also incorporated during the property prediction tasks to refine the embeddings based on our limited polymer dataset, thereby enhancing their chemical relevance for polymer SMILES representation. This balanced fusion of fine-tuned textual and structural information enables PolyLLMem to accurately predict a variety of polymer properties despite the scarcity of training data. Its performance is comparable to, and in some cases exceeds, that of graph-based models, as well as transformer-based models that typically require pretraining on millions of polymer samples. These findings demonstrate that LLM, such as Llama, can effectively capture chemical information encoded in polymer PSMILES, and underscore the efficacy of multimodal fusion of LLM embeddings and molecular structure embeddings in overcoming data scarcity and accelerating the discovery of advanced polymeric materials.","authors":["Tianren Zhang","Dai-Bei Yang"],"url":"https://arxiv.org/abs/2503.22962"}
{"created":"2025-04-21","title":"Adaptive Layer-skipping in Pre-trained LLMs","abstract":"Various layer-skipping methods have been proposed to accelerate token generation in large language models (LLMs). However, they have overlooked a fundamental question: How do computational demands vary across the generation of different tokens? In this work, we introduce FlexiDepth, a method that dynamically adjusts the number of Transformer layers used in text generation. By incorporating a plug-in router and adapter, FlexiDepth enables adaptive layer-skipping in LLMs without modifying their original parameters. Introducing FlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32, and meanwhile maintains the full 100\\% benchmark performance. Experimental results with FlexiDepth demonstrate that computational demands in LLMs significantly vary based on token type. Specifically, generating repetitive tokens or fixed phrases requires fewer layers, whereas producing tokens involving computation or high uncertainty requires more layers. Interestingly, this adaptive allocation pattern aligns with human intuition. To advance research in this area, we open sourced FlexiDepth and a dataset documenting FlexiDepth's layer allocation patterns for future exploration.","authors":["Xuan Luo","Weizhi Wang","Xifeng Yan"],"url":"https://arxiv.org/abs/2503.23798"}
{"created":"2025-04-21","title":"BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation","abstract":"We present the evaluation methodology, datasets and results of the BOP Challenge 2024, the 6th in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks. In 2024, our goal was to transition BOP from lab-like setups to real-world scenarios. First, we introduced new model-free tasks, where no 3D object models are available and methods need to onboard objects just from provided reference videos. Second, we defined a new, more practical 6D object detection task where identities of objects visible in a test image are not provided as input. Third, we introduced new BOP-H3 datasets recorded with high-resolution sensors and AR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D models and onboarding videos to support both model-based and model-free tasks. Participants competed on seven challenge tracks. Notably, the best 2024 method for model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only 4% behind the best 2023 method for seen objects (GPose2023) although being significantly slower (24.9 vs 2.7s per image). A more practical 2024 method for this task is Co-op which takes only 0.8s per image and is 13% more accurate than GenFlow. Methods have similar rankings on 6D detection as on 6D localization but higher run time. On model-based 2D detection of unseen objects, the best 2024 method (MUSE) achieves 21--29% relative improvement compared to the best 2023 method (CNOS). However, the 2D detection accuracy for unseen objects is still -35% behind the accuracy for seen objects (GDet2023), and the 2D detection stage is consequently the main bottleneck of existing pipelines for 6D localization/detection of unseen objects. The online evaluation system stays open and is available at http://bop.felk.cvut.cz/","authors":["Van Nguyen Nguyen","Stephen Tyree","Andrew Guo","Mederic Fourmy","Anas Gouda","Taeyeop Lee","Sungphill Moon","Hyeontae Son","Lukas Ranftl","Jonathan Tremblay","Eric Brachmann","Bertram Drost","Vincent Lepetit","Carsten Rother","Stan Birchfield","Jiri Matas","Yann Labbe","Martin Sundermeyer","Tomas Hodan"],"url":"https://arxiv.org/abs/2504.02812"}
{"created":"2025-04-21","title":"A Dataset of the Representatives Elected in France During the Fifth Republic","abstract":"The electoral system is a cornerstone of democracy, shaping the structure of political competition, representation, and accountability. In the case of France, it is difficult to access data describing elected representatives, though, as they are scattered across a number of sources, including public institutions, but also academic and individual efforts. This article presents a unified relational database that aims at tackling this issue by gathering information regarding representatives elected in France over the whole Fifth Republic (1958-present). This database constitutes an unprecedented resource for analyzing the evolution of political representation in France, exploring trends in party system dynamics, gender equality, and the professionalization of politics. By providing a longitudinal view of French elected representatives, the database facilitates research on the institutional stability of the Fifth Republic, offering insights into the factors of political change.","authors":["No\\'emie F\\'evrat (FR 3621","JPEG)","Vincent Labatut (LIA)","\\'Emilie Volpi (FR 3621)","Guillaume Marrel (JPEG)"],"url":"https://arxiv.org/abs/2504.02869"}
{"created":"2025-04-21","title":"From Questions to Insights: Exploring XAI Challenges Reported on Stack Overflow Questions","abstract":"The lack of interpretability is a major barrier that limits the practical usage of AI models. Several eXplainable AI (XAI) techniques (e.g., SHAP, LIME) have been employed to interpret these models' performance. However, users often face challenges when leveraging these techniques in real-world scenarios and thus submit questions in technical Q&amp;A forums like Stack Overflow (SO) to resolve these challenges. We conducted an exploratory study to expose these challenges, their severity, and features that can make XAI techniques more accessible and easier to use. Our contributions to this study are fourfold. First, we manually analyzed 663 SO questions that discussed challenges related to XAI techniques. Our careful investigation produced a catalog of seven challenges (e.g., disagreement issues). We then analyzed their prevalence and found that model integration and disagreement issues emerged as the most prevalent challenges. Second, we attempt to estimate the severity of each XAI challenge by determining the correlation between challenge types and answer metadata (e.g., the presence of accepted answers). Our analysis suggests that model integration issues is the most severe challenge. Third, we attempt to perceive the severity of these challenges based on practitioners' ability to use XAI techniques effectively in their work. Practitioners' responses suggest that disagreement issues most severely affect the use of XAI techniques. Fourth, we seek agreement from practitioners on improvements or features that could make XAI techniques more accessible and user-friendly. The majority of them suggest consistency in explanations and simplified integration. Our study findings might (a) help to enhance the accessibility and usability of XAI and (b) act as the initial benchmark that can inspire future research.","authors":["Saumendu Roy","Saikat Mondal","Banani Roy","Chanchal Roy"],"url":"https://arxiv.org/abs/2504.03085"}
{"created":"2025-04-21","title":"Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models","abstract":"Large language models (LLMs) are foundational explorations to artificial general intelligence, yet their alignment with human values via instruction tuning and preference learning achieves only superficial compliance. Here, we demonstrate that harmful knowledge embedded during pretraining persists as indelible \"dark patterns\" in LLMs' parametric memory, evading alignment safeguards and resurfacing under adversarial inducement at distributional shifts. In this study, we first theoretically analyze the intrinsic ethical vulnerability of aligned LLMs by proving that current alignment methods yield only local \"safety regions\" in the knowledge manifold. In contrast, pretrained knowledge remains globally connected to harmful concepts via high-likelihood adversarial trajectories. Building on this theoretical insight, we empirically validate our findings by employing semantic coherence inducement under distributional shifts--a method that systematically bypasses alignment constraints through optimized adversarial prompts. This combined theoretical and empirical approach achieves a 100% attack success rate across 19 out of 23 state-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing their universal vulnerabilities.","authors":["Jiawei Lian","Jianhong Pan","Lefan Wang","Yi Wang","Shaohui Mei","Lap-Pui Chau"],"url":"https://arxiv.org/abs/2504.05050"}
{"created":"2025-04-21","title":"SigChord: Sniffing Wide Non-sparse Multiband Signals for Terrestrial and Non-terrestrial Wireless Networks","abstract":"While unencrypted information inspection in physical layer (e.g., open headers) can provide deep insights for optimizing wireless networks, the state-of-the-art (SOTA) methods heavily depend on full sampling rate (a.k.a Nyquist rate), and high-cost radios, due to terrestrial and non-terrestrial networks densely occupying multiple bands across large bandwidth (e.g., from 4G/5G at 0.4-7 GHz to LEO satellite at 4-40 GHz). To this end, we present SigChord, an efficient physical layer inspection system built on low-cost and sub-Nyquist sampling radios. We first design a deep and rule-based interleaving algorithm based on Transformer network to perform spectrum sensing and signal recovery under sub-Nyquist sampling rate, and second, cascade protocol identifier and decoder based on Transformer neural networks to help physical layer packets analysis. We implement SigChord using software-defined radio platforms, and extensively evaluate it on over-the-air terrestrial and non-terrestrial wireless signals. The experiments demonstrate that SigChord delivers over 99% accuracy in detecting and decoding, while still decreasing 34% sampling rate, compared with the SOTA approaches.","authors":["Jinbo Peng","Junwen Duan","Zheng Lin","Haoxuan Yuan","Yue Gao","Zhe Chen"],"url":"https://arxiv.org/abs/2504.06587"}
{"created":"2025-04-21","title":"From Token to Line: Enhancing Code Generation with a Long-Term Perspective","abstract":"The emergence of large language models (LLMs) has significantly promoted the development of code generation task, sparking a surge in pertinent literature. Current research is hindered by redundant generation results and a tendency to overfit local patterns in the short term. Although existing studies attempt to alleviate the issue by adopting a multi-token prediction strategy, there remains limited focus on choosing the appropriate processing length for generations. By analyzing the attention between tokens during the generation process of LLMs, it can be observed that the high spikes of the attention scores typically appear at the end of lines. This insight suggests that it is reasonable to treat each line of code as a fundamental processing unit and generate them sequentially. Inspired by this, we propose the \\textbf{LSR-MCTS} algorithm, which leverages MCTS to determine the code line-by-line and select the optimal path. Further, we integrate a self-refine mechanism at each node to enhance diversity and generate higher-quality programs through error correction. Extensive experiments and comprehensive analyses on three public coding benchmarks demonstrate that our method outperforms the state-of-the-art performance approaches.","authors":["Tingwei Lu","Yangning Li","Liyuan Wang","Binghuai Lin","Jiwei Tang","Wanshi Xu","Hai-Tao Zheng","Yinghui Li","Bingxu An","Zhao Wei","Yong Xu"],"url":"https://arxiv.org/abs/2504.07433"}
{"created":"2025-04-21","title":"Diffusion Transformers for Tabular Data Time Series Generation","abstract":"Tabular data generation has recently attracted a growing interest due to its different application scenarios. However, generating time series of tabular data, where each element of the series depends on the others, remains a largely unexplored domain. This gap is probably due to the difficulty of jointly solving different problems, the main of which are the heterogeneity of tabular data (a problem common to non-time-dependent approaches) and the variable length of a time series. In this paper, we propose a Diffusion Transformers (DiTs) based approach for tabular data series generation. Inspired by the recent success of DiTs in image and video generation, we extend this framework to deal with heterogeneous data and variable-length sequences. Using extensive experiments on six datasets, we show that the proposed approach outperforms previous work by a large margin.","authors":["Fabrizio Garuti","Enver Sangineto","Simone Luetto","Lorenzo Forni","Rita Cucchiara"],"url":"https://arxiv.org/abs/2504.07566"}
{"created":"2025-04-21","title":"DrivAer Transformer: A high-precision and fast prediction method for vehicle aerodynamic drag coefficient based on the DrivAerNet++ dataset","abstract":"At the current stage, deep learning-based methods have demonstrated excellent capabilities in evaluating aerodynamic performance, significantly reducing the time and cost required for traditional computational fluid dynamics (CFD) simulations. However, when faced with the task of processing extremely complex three-dimensional (3D) vehicle models, the lack of large-scale datasets and training resources, coupled with the inherent diversity and complexity of the geometry of different vehicle models, means that the prediction accuracy and versatility of these networks are still not up to the level required for current production. In view of the remarkable success of Transformer models in the field of natural language processing and their strong potential in the field of image processing, this study innovatively proposes a point cloud learning framework called DrivAer Transformer (DAT). The DAT structure uses the DrivAerNet++ dataset, which contains high-fidelity CFD data of industrial-standard 3D vehicle shapes. enabling accurate estimation of air drag directly from 3D meshes, thus avoiding the limitations of traditional methods such as 2D image rendering or signed distance fields (SDF). DAT enables fast and accurate drag prediction, driving the evolution of the aerodynamic evaluation process and laying the critical foundation for introducing a data-driven approach to automotive design. The framework is expected to accelerate the vehicle design process and improve development efficiency.","authors":["Jiaqi He","Xiangwen Luo","Yiping Wang"],"url":"https://arxiv.org/abs/2504.08217"}
{"created":"2025-04-21","title":"DocAgent: A Multi-Agent System for Automated Code Documentation Generation","abstract":"High-quality code documentation is crucial for software development especially in the era of AI. However, generating it automatically using Large Language Models (LLMs) remains challenging, as existing approaches often produce incomplete, unhelpful, or factually incorrect outputs. We introduce DocAgent, a novel multi-agent collaborative system using topological code processing for incremental context building. Specialized agents (Reader, Searcher, Writer, Verifier, Orchestrator) then collaboratively generate documentation. We also propose a multi-faceted evaluation framework assessing Completeness, Helpfulness, and Truthfulness. Comprehensive experiments show DocAgent significantly outperforms baselines consistently. Our ablation study confirms the vital role of the topological processing order. DocAgent offers a robust approach for reliable code documentation generation in complex and proprietary repositories.","authors":["Dayu Yang","Antoine Simoulin","Xin Qian","Xiaoyi Liu","Yuwei Cao","Zhaopu Teng","Grey Yang"],"url":"https://arxiv.org/abs/2504.08725"}
{"created":"2025-04-21","title":"Haptic Perception via the Dynamics of Flexible Body Inspired by an Ostrich's Neck","abstract":"In biological systems, both skin sensitivity and body flexibility play crucial roles in haptic perception. Fully soft robots often suffer from structural fragility and delayed sensory processing, limiting their practical functionality. The musculoskeletal system combines the adaptability of soft materials with the durability of rigid-body robots. It also leverages morphological computation, where the morphological structures contribute to information processing, for dynamic and adaptive behaviors. This study focuses on the pecking behaviors of birds, which enables precise haptic perception through the musculoskeletal system of their flexible neck. Physical reservoir computing is applied to flexible structures inspired by an ostrich neck to analyze the relationship between haptic perception and physical characteristics. Experiments with both a physical robot and simulations reveal that, with appropriate viscoelasticity, the flexible structure can discriminate object softness and retain that information through behavior. Drawing on these findings and anatomical insights from the ostrich neck, a haptic perception system is proposed that exhibits both separability and behavioral memory in flexible structures, enabling rapid learning and real-time inference. The results demonstrate that through the dynamics of flexible structures, diverse functions can emerge beyond their original design as manipulators.","authors":["Kazashi Nakano","Katsuma Inoue","Yasuo Kuniyoshi","Kohei Nakajima"],"url":"https://arxiv.org/abs/2504.09131"}
{"created":"2025-04-21","title":"Can postgraduate translation students identify machine-generated text?","abstract":"Given the growing use of generative artificial intelligence as a tool for creating multilingual content and bypassing both machine and traditional translation methods, this study explores the ability of linguistically trained individuals to discern machine-generated output from human-written text (HT). After brief training sessions on the textual anomalies typically found in synthetic text (ST), twenty-three postgraduate translation students analysed excerpts of Italian prose and assigned likelihood scores to indicate whether they believed they were human-written or AI-generated (ChatGPT-4o). The results show that, on average, the students struggled to distinguish between HT and ST, with only two participants achieving notable accuracy. Closer analysis revealed that the students often identified the same textual anomalies in both HT and ST, although features such as low burstiness and self-contradiction were more frequently associated with ST. These findings suggest the need for improvements in the preparatory training. Moreover, the study raises questions about the necessity of editing synthetic text to make it sound more human-like and recommends further research to determine whether AI-generated text is already sufficiently natural-sounding not to require further refinement.","authors":["Michael Farrell"],"url":"https://arxiv.org/abs/2504.09164"}
{"created":"2025-04-21","title":"PathVLM-R1: A Reinforcement Learning-Driven Reasoning Model for Pathology Visual-Language Tasks","abstract":"The diagnosis of pathological images is often limited by expert availability and regional disparities, highlighting the importance of automated diagnosis using Vision-Language Models (VLMs). Traditional multimodal models typically emphasize outcomes over the reasoning process, compromising the reliability of clinical decisions. To address the weak reasoning abilities and lack of supervised processes in pathological VLMs, we have innovatively proposed PathVLM-R1, a visual language model designed specifically for pathological images. We have based our model on Qwen2.5-VL-7B-Instruct and enhanced its performance for pathological tasks through meticulously designed post-training strategies. Firstly, we conduct supervised fine-tuning guided by pathological data to imbue the model with foundational pathological knowledge, forming a new pathological base model. Subsequently, we introduce Group Relative Policy Optimization (GRPO) and propose a dual reward-driven reinforcement learning optimization, ensuring strict constraint on logical supervision of the reasoning process and accuracy of results via cross-modal process reward and outcome accuracy reward. In the pathological image question-answering tasks, the testing results of PathVLM-R1 demonstrate a 14% improvement in accuracy compared to baseline methods, and it demonstrated superior performance compared to the Qwen2.5-VL-32B version despite having a significantly smaller parameter size. Furthermore, in out-domain data evaluation involving four medical imaging modalities: Computed Tomography (CT), dermoscopy, fundus photography, and Optical Coherence Tomography (OCT) images: PathVLM-R1's transfer performance improved by an average of 17.3% compared to traditional SFT methods. These results clearly indicate that PathVLM-R1 not only enhances accuracy but also possesses broad applicability and expansion potential.","authors":["Jianyu Wu","Hao Yang","Xinhua Zeng","Guibing He","Zhiyu Chen","Zihui Li","Xiaochuan Zhang","Yangyang Ma","Run Fang","Yang Liu"],"url":"https://arxiv.org/abs/2504.09258"}
{"created":"2025-04-21","title":"Assessing Judging Bias in Large Reasoning Models: An Empirical Study","abstract":"Large Reasoning Models (LRMs) like DeepSeek-R1 and OpenAI-o1 have demonstrated remarkable reasoning capabilities, raising important questions about their biases in LLM-as-a-judge settings. We present a comprehensive benchmark comparing judging biases between LLMs and LRMs across both subjective preference-alignment datasets and objective fact-based datasets. Through investigation of bandwagon, authority, position, and distraction biases, we uncover four key findings: (1) despite their advanced reasoning capabilities, LRMs remain susceptible to the above biases; (2) LRMs demonstrate better robustness than LLMs specifically on fact-related datasets; (3) LRMs exhibit notable position bias, preferring options in later positions; and (4) we identify a novel \"superficial reflection bias\" where phrases mimicking reasoning (e.g., \"wait, let me think...\") significantly influence model judgments. To address these biases, we design and evaluate three mitigation strategies: specialized system prompts that reduce judging biases by up to 19\\% in preference alignment datasets and 14\\% in fact-related datasets, in-context learning that provides up to 27\\% improvement on preference tasks but shows inconsistent results on factual tasks, and a self-reflection mechanism that reduces biases by up to 10\\% in preference datasets and 16\\% in fact-related datasets, with self-reflection proving particularly effective for LRMs. Our work provides crucial insights for developing more reliable LLM-as-a-Judge frameworks, especially as LRMs become increasingly deployed as automated judges.","authors":["Qian Wang","Zhanzhi Lou","Zhenheng Tang","Nuo Chen","Xuandong Zhao","Wenxuan Zhang","Dawn Song","Bingsheng He"],"url":"https://arxiv.org/abs/2504.09946"}
{"created":"2025-04-21","title":"C-MTCSD: A Chinese Multi-Turn Conversational Stance Detection Dataset","abstract":"Stance detection has become an essential tool for analyzing public discussions on social media. Current methods face significant challenges, particularly in Chinese language processing and multi-turn conversational analysis. To address these limitations, we introduce C-MTCSD, the largest Chinese multi-turn conversational stance detection dataset, comprising 24,264 carefully annotated instances from Sina Weibo, which is 4.2 times larger than the only prior Chinese conversational stance detection dataset. Our comprehensive evaluation using both traditional approaches and large language models reveals the complexity of C-MTCSD: even state-of-the-art models achieve only 64.07% F1 score in the challenging zero-shot setting, while performance consistently degrades with increasing conversation depth. Traditional models particularly struggle with implicit stance detection, achieving below 50% F1 score. This work establishes a challenging new benchmark for Chinese stance detection research, highlighting significant opportunities for future improvements.","authors":["Fuqiang Niu","Yi Yang","Xianghua Fu","Genan Dai","Bowen Zhang"],"url":"https://arxiv.org/abs/2504.09958"}
{"created":"2025-04-21","title":"The Mirage of Performance Gains: Why Contrastive Decoding Fails to Address Multimodal Hallucination","abstract":"Contrastive decoding strategies are widely used to reduce hallucinations in multimodal large language models (MLLMs). These methods work by constructing contrastive samples to induce hallucinations and then suppressing them in the output distribution. However, this paper demonstrates that such approaches fail to effectively mitigate the hallucination problem. The performance improvements observed on POPE Benchmark are largely driven by two misleading factors: (1) crude, unidirectional adjustments to the model's output distribution and (2) the adaptive plausibility constraint, which reduces the sampling strategy to greedy search. To further illustrate these issues, we introduce a series of spurious improvement methods and evaluate their performance against contrastive decoding techniques. Experimental results reveal that the observed performance gains in contrastive decoding are entirely unrelated to its intended goal of mitigating hallucinations. Our findings challenge common assumptions about the effectiveness of contrastive decoding strategies and pave the way for developing genuinely effective solutions to hallucinations in MLLMs.","authors":["Hao Yin","Guangzong Si","Zilei Wang"],"url":"https://arxiv.org/abs/2504.10020"}
{"created":"2025-04-21","title":"GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents","abstract":"Existing efforts in building Graphical User Interface (GUI) agents largely rely on the training paradigm of supervised fine-tuning on Large Vision-Language Models (LVLMs). However, this approach not only demands extensive amounts of training data but also struggles to effectively understand GUI screenshots and generalize to unseen interfaces. The issue significantly limits its application in real-world scenarios, especially for high-level tasks. Inspired by Reinforcement Fine-Tuning (RFT) in large reasoning models (e.g., DeepSeek-R1), which efficiently enhances the problem-solving capabilities of large language models in real-world settings, we propose \\name, the first reinforcement learning framework designed to enhance the GUI capabilities of LVLMs in high-level real-world task scenarios, through unified action space rule modeling. By leveraging a small amount of carefully curated high-quality data across multiple platforms (including Windows, Linux, MacOS, Android, and Web) and employing policy optimization algorithms such as Group Relative Policy Optimization (GRPO) to update the model, \\name achieves superior performance using only 0.02\\% of the data (3K vs. 13M) compared to previous state-of-the-art methods like OS-Atlas across eight benchmarks spanning three different platforms (mobile, desktop, and web). These results demonstrate the immense potential of reinforcement learning based on unified action space rule modeling in improving the execution capabilities of LVLMs for real-world GUI agent tasks.","authors":["Run Luo","Lu Wang","Wanwei He","Xiaobo Xia"],"url":"https://arxiv.org/abs/2504.10458"}
{"created":"2025-04-21","title":"GaSLight: Gaussian Splats for Spatially-Varying Lighting in HDR","abstract":"We present GaSLight, a method that generates spatially-varying lighting from regular images. Our method proposes using HDR Gaussian Splats as light source representation, marking the first time regular images can serve as light sources in a 3D renderer. Our two-stage process first enhances the dynamic range of images plausibly and accurately by leveraging the priors embedded in diffusion models. Next, we employ Gaussian Splats to model 3D lighting, achieving spatially variant lighting. Our approach yields state-of-the-art results on HDR estimations and their applications in illuminating virtual objects and scenes. To facilitate the benchmarking of images as light sources, we introduce a novel dataset of calibrated and unsaturated HDR to evaluate images as light sources. We assess our method using a combination of this novel dataset and an existing dataset from the literature. Project page: https://lvsn.github.io/gaslight/","authors":["Christophe Bolduc","Yannick Hold-Geoffroy","Zhixin Shu","Jean-Fran\\c{c}ois Lalonde"],"url":"https://arxiv.org/abs/2504.10809"}
{"created":"2025-04-21","title":"PT-Mark: Invisible Watermarking for Text-to-image Diffusion Models via Semantic-aware Pivotal Tuning","abstract":"Watermarking for diffusion images has drawn considerable attention due to the widespread use of text-to-image diffusion models and the increasing need for their copyright protection. Recently, advanced watermarking techniques, such as Tree Ring, integrate watermarks by embedding traceable patterns (e.g., Rings) into the latent distribution during the diffusion process. Such methods disrupt the original semantics of the generated images due to the inevitable distribution shift caused by the watermarks, thereby limiting their practicality, particularly in digital art creation. In this work, we present Semantic-aware Pivotal Tuning Watermarks (PT-Mark), a novel invisible watermarking method that preserves both the semantics of diffusion images and the traceability of the watermark. PT-Mark preserves the original semantics of the watermarked image by gradually aligning the generation trajectory with the original (pivotal) trajectory while maintaining the traceable watermarks during whole diffusion denoising process. To achieve this, we first compute the salient regions of the watermark at each diffusion denoising step as a spatial prior to identify areas that can be aligned without disrupting the watermark pattern. Guided by the region, we then introduce an additional pivotal tuning branch that optimizes the text embedding to align the semantics while preserving the watermarks. Extensive evaluations demonstrate that PT-Mark can preserve the original semantics of the diffusion images while integrating robust watermarks. It achieves a 10% improvement in the performance of semantic preservation (i.e., SSIM, PSNR, and LPIPS) compared to state-of-the-art watermarking methods, while also showing comparable robustness against real-world perturbations and four times greater efficiency.","authors":["Yaopeng Wang","Huiyu Xu","Zhibo Wang","Jiacheng Du","Zhichao Li","Yiming Li","Qiu Wang","Kui Ren"],"url":"https://arxiv.org/abs/2504.10853"}
{"created":"2025-04-21","title":"When is Task Vector Provably Effective for Model Editing? A Generalization Analysis of Nonlinear Transformers","abstract":"Task arithmetic refers to editing the pre-trained model by adding a weighted sum of task vectors, each of which is the weight update from the pre-trained model to fine-tuned models for certain tasks. This approach recently gained attention as a computationally efficient inference method for model editing, e.g., multi-task learning, forgetting, and out-of-domain generalization capabilities. However, the theoretical understanding of why task vectors can execute various conceptual operations remains limited, due to the highly non-convexity of training Transformer-based models. To the best of our knowledge, this paper provides the first theoretical characterization of the generalization guarantees of task vector methods on nonlinear Transformers. We consider a conceptual learning setting, where each task is a binary classification problem based on a discriminative pattern. We theoretically prove the effectiveness of task addition in simultaneously learning a set of irrelevant or aligned tasks, as well as the success of task negation in unlearning one task from irrelevant or contradictory tasks. Moreover, we prove the proper selection of linear coefficients for task arithmetic to achieve guaranteed generalization to out-of-domain tasks. All of our theoretical results hold for both dense-weight parameters and their low-rank approximations. Although established in a conceptual setting, our theoretical findings were validated on a practical machine unlearning task using the large language model Phi-1.5 (1.3B).","authors":["Hongkang Li","Yihua Zhang","Shuai Zhang","Meng Wang","Sijia Liu","Pin-Yu Chen"],"url":"https://arxiv.org/abs/2504.10957"}
{"created":"2025-04-21","title":"Vivid4D: Improving 4D Reconstruction from Monocular Video by Video Inpainting","abstract":"Reconstructing 4D dynamic scenes from casually captured monocular videos is valuable but highly challenging, as each timestamp is observed from a single viewpoint. We introduce Vivid4D, a novel approach that enhances 4D monocular video synthesis by augmenting observation views - synthesizing multi-view videos from a monocular input. Unlike existing methods that either solely leverage geometric priors for supervision or use generative priors while overlooking geometry, we integrate both. This reformulates view augmentation as a video inpainting task, where observed views are warped into new viewpoints based on monocular depth priors. To achieve this, we train a video inpainting model on unposed web videos with synthetically generated masks that mimic warping occlusions, ensuring spatially and temporally consistent completion of missing regions. To further mitigate inaccuracies in monocular depth priors, we introduce an iterative view augmentation strategy and a robust reconstruction loss. Experiments demonstrate that our method effectively improves monocular 4D scene reconstruction and completion. See our project page: https://xdimlab.github.io/Vivid4D/.","authors":["Jiaxin Huang","Sheng Miao","BangBang Yang","Yuewen Ma","Yiyi Liao"],"url":"https://arxiv.org/abs/2504.11092"}
{"created":"2025-04-21","title":"Evaluation Report on MCP Servers","abstract":"With the rise of LLMs, a large number of Model Context Protocol (MCP) services have emerged since the end of 2024. However, the effectiveness and efficiency of MCP servers have not been well studied. To study these questions, we propose an evaluation framework, called MCPBench. We selected several widely used MCP server and conducted an experimental evaluation on their accuracy, time, and token usage. Our experiments showed that the most effective MCP, Bing Web Search, achieved an accuracy of 64%. Importantly, we found that the accuracy of MCP servers can be substantially enhanced by involving declarative interface. This research paves the way for further investigations into optimized MCP implementations, ultimately leading to better AI-driven applications and data retrieval solutions.","authors":["Zhiling Luo","Xiaorong Shi","Xuanrui Lin","Jinyang Gao"],"url":"https://arxiv.org/abs/2504.11094"}
{"created":"2025-04-21","title":"VideoPanda: Video Panoramic Diffusion with Multi-view Attention","abstract":"High resolution panoramic video content is paramount for immersive experiences in Virtual Reality, but is non-trivial to collect as it requires specialized equipment and intricate camera setups. In this work, we introduce VideoPanda, a novel approach for synthesizing 360$^\\circ$ videos conditioned on text or single-view video data. VideoPanda leverages multi-view attention layers to augment a video diffusion model, enabling it to generate consistent multi-view videos that can be combined into immersive panoramic content. VideoPanda is trained jointly using two conditions: text-only and single-view video, and supports autoregressive generation of long-videos. To overcome the computational burden of multi-view video generation, we randomly subsample the duration and camera views used during training and show that the model is able to gracefully generalize to generating more frames during inference. Extensive evaluations on both real-world and synthetic video datasets demonstrate that VideoPanda generates more realistic and coherent 360$^\\circ$ panoramas across all input conditions compared to existing methods. Visit the project website at https://research.nvidia.com/labs/toronto-ai/VideoPanda/ for results.","authors":["Kevin Xie","Amirmojtaba Sabour","Jiahui Huang","Despoina Paschalidou","Greg Klar","Umar Iqbal","Sanja Fidler","Xiaohui Zeng"],"url":"https://arxiv.org/abs/2504.11389"}
{"created":"2025-04-21","title":"Semantic Matters: Multimodal Features for Affective Analysis","abstract":"In this study, we present our methodology for two tasks: the Emotional Mimicry Intensity (EMI) Estimation Challenge and the Behavioural Ambivalence/Hesitancy (BAH) Recognition Challenge, both conducted as part of the 8th Workshop and Competition on Affective & Behavior Analysis in-the-wild. We utilize a Wav2Vec 2.0 model pre-trained on a large podcast dataset to extract various audio features, capturing both linguistic and paralinguistic information. Our approach incorporates a valence-arousal-dominance (VAD) module derived from Wav2Vec 2.0, a BERT text encoder, and a vision transformer (ViT) with predictions subsequently processed through a long short-term memory (LSTM) architecture or a convolution-like method for temporal modeling. We integrate the textual and visual modality into our analysis, recognizing that semantic content provides valuable contextual cues and underscoring that the meaning of speech often conveys more critical insights than its acoustic counterpart alone. Fusing in the vision modality helps in some cases to interpret the textual modality more precisely. This combined approach results in significant performance improvements, achieving in EMI $\\rho_{\\text{TEST}} = 0.706$ and in BAH $F1_{\\text{TEST}} = 0.702$, securing first place in the EMI challenge and second place in the BAH challenge.","authors":["Tobias Hallmen","Robin-Nico Kampa","Fabian Deuser","Norbert Oswald","Elisabeth Andr\\'e"],"url":"https://arxiv.org/abs/2504.11460"}
{"created":"2025-04-21","title":"Cross-cultural Deployment of Autonomous Vehicles Using Data-light Inverse Reinforcement Learning","abstract":"More than the adherence to specific traffic regulations, driving culture touches upon a more implicit part - an informal, conventional, collective behavioral pattern followed by drivers - that varies across countries, regions, and even cities. Such cultural divergence has become one of the biggest challenges in deploying autonomous vehicles (AVs) across diverse regions today. The current emergence of data-driven methods has shown a potential solution to enable culture-compatible driving through learning from data, but what if some underdeveloped regions cannot provide sufficient local data to inform driving culture? This issue is particularly significant for a broader global AV market. Here, we propose a cross-cultural deployment scheme for AVs, called data-light inverse reinforcement learning, designed to re-calibrate culture-specific AVs and assimilate them into other cultures. First, we report the divergence in driving cultures through a comprehensive comparative analysis of naturalistic driving datasets on highways from three countries: Germany, China, and the USA. Then, we demonstrate the effectiveness of our scheme by testing the expeditious cross-cultural deployment across these three countries, with cumulative testing mileage of over 56084 km. The performance is particularly advantageous when cross-cultural deployment is carried out without affluent local data. Results show that we can reduce the dependence on local data by a margin of 98.67% at best. This study is expected to bring a broader, fairer AV global market, particularly in those regions that lack enough local data to develop culture-compatible AVs.","authors":["Hongliang Lu","Shuqi Shen","Junjie Yang","Chao Lu","Xinhu Zheng","Hai Yang"],"url":"https://arxiv.org/abs/2504.11506"}
{"created":"2025-04-21","title":"Chypnosis: Stealthy Secret Extraction using Undervolting-based Static Side-channel Attacks","abstract":"There is a growing class of static physical side-channel attacks that allow adversaries to extract secrets by probing the persistent state of a circuit. Techniques such as laser logic state imaging (LLSI), impedance analysis (IA), and static power analysis fall into this category. These attacks require that the targeted data remain constant for a specific duration, which often necessitates halting the circuit's clock. Some methods additionally rely on modulating the chip's supply voltage to probe the circuit. However, tampering with the clock or voltage is typically assumed to be detectable, as secure chips often deploy sensors that erase sensitive data upon detecting such anomalies. Furthermore, many secure devices use internal clock sources, making external clock control infeasible. In this work, we introduce a novel class of static side-channel attacks, called Chypnosis, that enables adversaries to freeze a chip's internal clock by inducing a hibernation state via rapid undervolting, and then extracting secrets using static side-channels. We demonstrate that, by rapidly dropping a chip's voltage below the standard nominal levels, the attacker can bypass the clock and voltage sensors and put the chip in a so-called brownout condition, in which the chip's transistors stop switching, but volatile memories (e.g., Flip-flops and SRAMs) still retain their data. We test our attack on AMD FPGAs by putting them into hibernation. We show that not only are all clock sources deactivated, but various clock and voltage sensors also fail to detect the tamper event. Afterward, we present the successful recovery of secret bits from a hibernated chip using two static attacks, namely, LLSI and IA. Finally, we discuss potential countermeasures which could be integrated into future designs.","authors":["Kyle Mitard","Saleh Khalaj Monfared","Fatemeh Khojasteh Dana","Shahin Tajik"],"url":"https://arxiv.org/abs/2504.11633"}
{"created":"2025-04-21","title":"Doppler-SLAM: Doppler-Aided Radar-Inertial and LiDAR-Inertial Simultaneous Localization and Mapping","abstract":"Simultaneous localization and mapping (SLAM) is a critical capability for autonomous systems. Traditional SLAM approaches, which often rely on visual or LiDAR sensors, face significant challenges in adverse conditions such as low light or featureless environments. To overcome these limitations, we propose a novel Doppler-aided radar-inertial and LiDAR-inertial SLAM framework that leverages the complementary strengths of 4D radar, FMCW LiDAR, and inertial measurement units. Our system integrates Doppler velocity measurements and spatial data into a tightly-coupled front-end and graph optimization back-end to provide enhanced ego velocity estimation, accurate odometry, and robust mapping. We also introduce a Doppler-based scan-matching technique to improve front-end odometry in dynamic environments. In addition, our framework incorporates an innovative online extrinsic calibration mechanism, utilizing Doppler velocity and loop closure to dynamically maintain sensor alignment. Extensive evaluations on both public and proprietary datasets show that our system significantly outperforms state-of-the-art radar-SLAM and LiDAR-SLAM frameworks in terms of accuracy and robustness. To encourage further research, the code of our Doppler-SLAM and our dataset are available at: https://github.com/Wayne-DWA/Doppler-SLAM.","authors":["Dong Wang","Hannes Haag","Daniel Casado Herraez","Stefan May","Cyrill Stachniss","Andreas Nuechter"],"url":"https://arxiv.org/abs/2504.11634"}
{"created":"2025-04-21","title":"Fast Mixed-Precision Real Evaluation","abstract":"Evaluating real-valued expressions to high precision is a key building block in computational mathematics, physics, and numerics. A typical implementation evaluates the whole expression in a uniform precision, doubling that precision until a sufficiently-accurate result is achieved. This is wasteful: usually only a few operations really need to be performed at high precision, and the bulk of the expression could be computed much faster. However, such non-uniform precision assignments have, to date, been impractical to compute. We propose a fast new algorithm for deriving such precision assignments. The algorithm leverages results computed at lower precisions to analytically determine a mixed-precision assignment that will result in a sufficiently-accurate result. Our implementation, Reval, achieves an average speed-up of 1.72x compared to the state-of-the-art Sollya tool, with the speed-up increasing to 5.21x on the most difficult input points. An examination of the precisions used with and without precision tuning shows that the speed-up results from assigning lower precisions for the majority of operations, though additional optimizations enabled by the non-uniform precision assignments also play a role.","authors":["Artem Yadrov","Pavel Panchekha"],"url":"https://arxiv.org/abs/2504.11708"}
{"created":"2025-04-21","title":"Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching","abstract":"We introduce Adjoint Sampling, a highly scalable and efficient algorithm for learning diffusion processes that sample from unnormalized densities, or energy functions. It is the first on-policy approach that allows significantly more gradient updates than the number of energy evaluations and model samples, allowing us to scale to much larger problem settings than previously explored by similar methods. Our framework is theoretically grounded in stochastic optimal control and shares the same theoretical guarantees as Adjoint Matching, being able to train without the need for corrective measures that push samples towards the target distribution. We show how to incorporate key symmetries, as well as periodic boundary conditions, for modeling molecules in both cartesian and torsional coordinates. We demonstrate the effectiveness of our approach through extensive experiments on classical energy functions, and further scale up to neural network-based energy models where we perform amortized conformer generation across many molecular systems. To encourage further research in developing highly scalable sampling methods, we plan to open source these challenging benchmarks, where successful methods can directly impact progress in computational chemistry.","authors":["Aaron Havens","Benjamin Kurt Miller","Bing Yan","Carles Domingo-Enrich","Anuroop Sriram","Brandon Wood","Daniel Levine","Bin Hu","Brandon Amos","Brian Karrer","Xiang Fu","Guan-Horng Liu","Ricky T. Q. Chen"],"url":"https://arxiv.org/abs/2504.11713"}
{"created":"2025-04-21","title":"Enumeration of Bases in Matroid with Exponentially Large Ground Set","abstract":"When we deal with a matroid ${\\mathcal M}=(U,{\\mathcal I})$, we usually assume that it is implicitly given by means of the membership (MEM) oracle. Time complexity of many existing algorithms is polynomially bounded with respect to $|U|$ and the running time of the MEM-oracle. However, they are not efficient any more when $U$ is exponentially large in some context. In this paper, we propose two algorithms for enumerating matroid bases such that the time complexity does not depend on $|U|$. The first algorithm enumerates all minimum-weighted bases in incremental-polynomial time. To design the algorithm, we assume two oracles other than the MEM-oracle: the MinB-oracle that returns a minimum basis and the REL-oracle that returns a relevant element one by one in non-decreasing order of weight. The proposed algorithm is applicable to enumeration of minimum bases of binary matroids from cycle space and cut space, all of which have exponentially large $U$ with respect to a given graph. The highlight in this context is that, to design the REL-oracle for cut space, we develop the first polynomial-delay algorithm that enumerates all relevant cuts of a given graph in non-decreasing order of weight. The second algorithm enumerates all sets of linearly independent $r$-dimensional $r$ vectors over $\\mathit{GF}(2)$ in polynomial-delay, which immediately yields a polynomial-delay algorithm with respect to the matroid rank $r$ that enumerates all unweighted bases of a binary matroid such that elements are closed under addition.","authors":["Yuki Nishimura","Kazuya Haraguchi"],"url":"https://arxiv.org/abs/2504.11728"}
{"created":"2025-04-21","title":"D\\'ej\\`a Vu: Multilingual LLM Evaluation through the Lens of Machine Translation Evaluation","abstract":"Generation capabilities and language coverage of multilingual large language models (mLLMs) are advancing rapidly. However, evaluation practices for generative abilities of mLLMs are still lacking comprehensiveness, scientific rigor, and consistent adoption across research labs, which undermines their potential to meaningfully guide mLLM development. We draw parallels with machine translation (MT) evaluation, a field that faced similar challenges and has, over decades, developed transparent reporting standards and reliable evaluations for multilingual generative models. Through targeted experiments across key stages of the generative evaluation pipeline, we demonstrate how best practices from MT evaluation can deepen the understanding of quality differences between models. Additionally, we identify essential components for robust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are rigorously assessed. We distill these insights into a checklist of actionable recommendations for mLLM research and development.","authors":["Julia Kreutzer","Eleftheria Briakou","Sweta Agrawal","Marzieh Fadaee","Kocmi Tom"],"url":"https://arxiv.org/abs/2504.11829"}
{"created":"2025-04-21","title":"Less-excludable Mechanism for DAOs in Public Good Auctions","abstract":"With the rise of smart contracts, decentralized autonomous organizations (DAOs) have emerged in public good auctions, allowing \"small\" bidders to gather together and enlarge their influence in high-valued auctions. However, models and mechanisms in the existing research literature do not guarantee non-excludability, which is a main property of public goods. As such, some members of the winning DAO may be explicitly prevented from accessing the public good. This side effect leads to regrouping of small bidders within the DAO to have a larger say in the final outcome. In particular, we provide a polynomial-time algorithm to compute the best regrouping of bidders that maximizes the total bidding power of a DAO. We also prove that such a regrouping is less-excludable, better aligning the needs of the entire DAO and the nature of public goods. Next, notice that members of a DAO in public good auctions often have a positive externality among themselves. Thus we introduce a collective factor into the members' utility functions. We further extend the mechanism's allocation for each member to allow for partial access to the public good. Under the new model, we propose a mechanism that is incentive compatible in generic games and achieves higher social welfare as well as less-excludable allocations.","authors":["Jing Chen","Wentao Zhou"],"url":"https://arxiv.org/abs/2504.11854"}
{"created":"2025-04-21","title":"Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models via Plot Hole Detection","abstract":"Stories are a fundamental aspect of human experience. Engaging deeply with stories and spotting plot holes -- inconsistencies in a storyline that break the internal logic or rules of a story's world -- requires nuanced reasoning skills, including tracking entities and events and their interplay, abstract thinking, pragmatic narrative understanding, commonsense and social reasoning, and theory of mind. As Large Language Models (LLMs) increasingly generate, interpret, and modify text, rigorously assessing their narrative consistency and deeper language understanding becomes critical. However, existing benchmarks focus mainly on surface-level comprehension. In this work, we propose plot hole detection in stories as a proxy to evaluate language understanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel algorithm to controllably and carefully synthesize plot holes in human-written stories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot hole detection abilities in stories -- FlawedFictions -- , which is robust to contamination, with human filtering ensuring high quality. We find that state-of-the-art LLMs struggle in accurately solving FlawedFictions regardless of the reasoning effort allowed, with performance significantly degrading as story length increases. Finally, we show that LLM-based story summarization and story generation are prone to introducing plot holes, with more than 50% and 100% increases in plot hole detection rates with respect to human-written originals.","authors":["Kabir Ahuja","Melanie Sclar","Yulia Tsvetkov"],"url":"https://arxiv.org/abs/2504.11900"}
{"created":"2025-04-21","title":"Mind2Matter: Creating 3D Models from EEG Signals","abstract":"The reconstruction of 3D objects from brain signals has gained significant attention in brain-computer interface (BCI) research. Current research predominantly utilizes functional magnetic resonance imaging (fMRI) for 3D reconstruction tasks due to its excellent spatial resolution. Nevertheless, the clinical utility of fMRI is limited by its prohibitive costs and inability to support real-time operations. In comparison, electroencephalography (EEG) presents distinct advantages as an affordable, non-invasive, and mobile solution for real-time brain-computer interaction systems. While recent advances in deep learning have enabled remarkable progress in image generation from neural data, decoding EEG signals into structured 3D representations remains largely unexplored. In this paper, we propose a novel framework that translates EEG recordings into 3D object reconstructions by leveraging neural decoding techniques and generative models. Our approach involves training an EEG encoder to extract spatiotemporal visual features, fine-tuning a large language model to interpret these features into descriptive multimodal outputs, and leveraging generative 3D Gaussians with layout-guided control to synthesize the final 3D structures. Experiments demonstrate that our model captures salient geometric and semantic features, paving the way for applications in brain-computer interfaces (BCIs), virtual reality, and neuroprosthetics. Our code is available in https://github.com/sddwwww/Mind2Matter.","authors":["Xia Deng","Shen Chen","Jiale Zhou","Lei Li"],"url":"https://arxiv.org/abs/2504.11936"}
{"created":"2025-04-21","title":"Stochastic noise can be helpful for variational quantum algorithms","abstract":"Saddle points constitute a crucial challenge for first-order gradient descent algorithms. In notions of classical machine learning, they are avoided for example by means of stochastic gradient descent methods. In this work, we provide evidence that the saddle points problem can be naturally avoided in variational quantum algorithms by exploiting the presence of stochasticity. We prove convergence guarantees and present practical examples in numerical simulations and on quantum hardware. We argue that the natural stochasticity of variational algorithms can be beneficial for avoiding strict saddle points, i.e., those saddle points with at least one negative Hessian eigenvalue. This insight that some levels of shot noise could help is expected to add a new perspective to notions of near-term variational quantum algorithms.","authors":["Junyu Liu","Frederik Wilde","Antonio Anna Mele","Xin Jin","Liang Jiang","Jens Eisert"],"url":"https://arxiv.org/abs/2210.06723"}
{"created":"2025-04-21","title":"Deep Huber quantile regression networks","abstract":"Typical machine learning regression applications aim to report the mean or the median of the predictive probability distribution, via training with a squared or an absolute error scoring function. The importance of issuing predictions of more functionals of the predictive probability distribution (quantiles and expectiles) has been recognized as a means to quantify the uncertainty of the prediction. In deep learning (DL) applications, that is possible through quantile and expectile regression neural networks (QRNN and ERNN respectively). Here we introduce deep Huber quantile regression networks (DHQRN) that nest QRNN and ERNN as edge cases. DHQRN can predict Huber quantiles, which are more general functionals in the sense that they nest quantiles and expectiles as limiting cases. The main idea is to train a DL algorithm with the Huber quantile scoring function, which is consistent for the Huber quantile functional. As a proof of concept, DHQRN are applied to predict house prices in Melbourne, Australia and Boston, United States (US). In this context, predictive performances of three DL architectures are discussed along with evidential interpretation of results from two economic case studies. Additional simulation experiments and applications to real-world case studies using open datasets demonstrate a satisfactory absolute performance of DHQRN.","authors":["Hristos Tyralis","Georgia Papacharalampous","Nilay Dogulu","Kwok P. Chun"],"url":"https://arxiv.org/abs/2306.10306"}
{"created":"2025-04-21","title":"Block Backstepping for Isotachic Hyperbolic PDEs and Multilayer Timoshenko Beams","abstract":"In this paper, we investigate the rapid stabilization of N-layer Timoshenko composite beams with anti-damping and anti-stiffness at the uncontrolled boundaries. The problem of stabilization for a two-layer composite beam has been previously studied by transforming the model into a 1-D hyperbolic PIDE-ODE form and then applying backstepping to this new system. In principle this approach is generalizable to any number of layers. However, when some of the layers have the same physical properties (as e.g. in lamination of repeated layers), the approach leads to isotachic hyperbolic PDEs (i.e. where some states have the same transport speed). This particular yet physical and interesting case has not received much attention beyond a few remarks in the early hyperbolic design. Thus, this work starts by extending the theory of backstepping control of (m + n) hyperbolic PIDEs and m ODEs to blocks of isotachic states, leading to a block backstepping design. Then, returning to multilayer Timoshenko beams, the Riemann transformation is used to transform the states of N-layer Timoshenko beams into a 1-D hyperbolic PIDE-ODE system. The block backstepping method is then applied to this model, obtaining closed-loop stability of the origin in the L2 sense. An arbitrarily rapid convergence rate can be obtained by adjusting control parameters. Finally, numerical simulations are presented corroborating the theoretical developments.","authors":["Guangwei Chen","Rafael Vazquez","Junfei Qiao","Miroslav Krstic"],"url":"https://arxiv.org/abs/2310.11416"}
{"created":"2025-04-21","title":"Algorithms for mean-field variational inference via polyhedral optimization in the Wasserstein space","abstract":"We develop a theory of finite-dimensional polyhedral subsets over the Wasserstein space and optimization of functionals over them via first-order methods. Our main application is to the problem of mean-field variational inference, which seeks to approximate a distribution $\\pi$ over $\\mathbb{R}^d$ by a product measure $\\pi^\\star$. When $\\pi$ is strongly log-concave and log-smooth, we provide (1) approximation rates certifying that $\\pi^\\star$ is close to the minimizer $\\pi^\\star_\\diamond$ of the KL divergence over a \\emph{polyhedral} set $\\mathcal{P}_\\diamond$, and (2) an algorithm for minimizing $\\text{KL}(\\cdot\\|\\pi)$ over $\\mathcal{P}_\\diamond$ based on accelerated gradient descent over $\\R^d$. As a byproduct of our analysis, we obtain the first end-to-end analysis for gradient-based algorithms for MFVI.","authors":["Yiheng Jiang","Sinho Chewi","Aram-Alexandre Pooladian"],"url":"https://arxiv.org/abs/2312.02849"}
{"created":"2025-04-21","title":"Chemically Motivated Simulation Problems are Efficiently Solvable by a Quantum Computer","abstract":"Simulating chemical systems is highly sought after and computationally challenging, as the number of degrees of freedom increases exponentially with the size of the system. Quantum computers have been proposed as a computational means to overcome this bottleneck , thanks to their capability of representing this amount of information efficiently. Most efforts so far have been centered around determining the ground states of chemical systems. However, hardness results and the lack of theoretical guarantees for efficient heuristics for initial-state generation shed doubt on the feasibility. Here, we propose a heuristically guided approach that is based on inherently efficient routines to solve chemical simulation problems, requiring quantum circuits of size scaling polynomially in relevant system parameters. If a set of assumptions can be satisfied, our approach finds good initial states for dynamics simulation by assembling them in a scattering tree. In particular, we investigate a scattering-based state preparation approach within the context of mergo-association. We discuss a variety of quantities of chemical interest that can be measured after the quantum simulation of a process, e.g., a reaction, following its corresponding initial state preparation.","authors":["Philipp Schleich","Lasse Bj{\\o}rn Kristensen","Jorge A. Campos Gonzalez Angulo","Davide Avagliano","Mohsen Bagherimehrab","Abdulrahman Aldossary","Christoph Gorgulla","Joe Fitzsimons","Al\\'an Aspuru-Guzik"],"url":"https://arxiv.org/abs/2401.09268"}
{"created":"2025-04-21","title":"Quasi-Monte Carlo with Domain Transformation for Efficient Fourier Pricing of Multi-Asset Options","abstract":"Efficiently pricing multi-asset options poses a significant challenge in quantitative finance. Fourier methods leverage the regularity properties of the integrand in the Fourier domain to accurately and rapidly value options that typically lack regularity in the physical domain. However, most of the existing Fourier approaches face hurdles in high-dimensional settings due to the tensor product (TP) structure of the commonly employed numerical quadrature techniques. To overcome this difficulty, this work advocates using the randomized quasi-MC (RQMC) quadrature to improve the scalability of Fourier methods with high dimensions. The RQMC technique benefits from the smoothness of the integrand and alleviates the curse of dimensionality while providing practical error estimates. Nonetheless, the applicability of RQMC on the unbounded domain, $\\mathbb{R}^d$, requires a domain transformation to $[0,1]^d$, which may result in singularities of the transformed integrand at the corners of the hypercube, and hence deteriorate the performance of RQMC. To circumvent this difficulty, we design an efficient domain transformation procedure based on boundary growth conditions on the transformed integrand. The proposed transformation preserves sufficient regularity of the original integrand for fast convergence of the RQMC method. To validate our analysis, we demonstrate the efficiency of employing RQMC with an appropriate transformation to evaluate options in the Fourier space for various pricing models, payoffs, and dimensions. Finally, we highlight the computational advantage of applying RQMC over MC or TP in the Fourier domain, and over MC in the physical domain for options with up to 15 assets.","authors":["Christian Bayer","Chiheb Ben Hammouda","Antonis Papapantoleon","Michael Samet","Ra\\'ul Tempone"],"url":"https://arxiv.org/abs/2403.02832"}
{"created":"2025-04-21","title":"Wealth inequality and utility: Effect evaluation of redistribution and consumption morals using the macro-econophysical coupled approach","abstract":"Reducing wealth inequality and increasing utility are critical issues. This study reveals the effects of redistribution and consumption morals on wealth inequality and utility. To this end, we present a novel approach that couples the dynamic model of capital, consumption, and utility in macroeconomics with the interaction model of joint business and redistribution in econophysics. With this approach, we calculate the capital (wealth), the utility based on consumption, and the Gini index of these inequality using redistribution and consumption thresholds as moral parameters. The results show that: under-redistribution and waste exacerbate inequality; conversely, over-redistribution and stinginess reduce utility; and a balanced moderate moral leads to achieve both reduced inequality and increased utility. These findings provide renewed economic and numerical support for the moral importance known from philosophy, anthropology, and religion. The revival of redistribution and consumption morals should promote the transformation to a human mutual-aid economy, as indicated by philosopher and anthropologist, instead of the capitalist economy that has produced the current inequality. The practical challenge is to implement bottom-up social business, on a foothold of worker coops and platform cooperatives as a community against the state and the market, with moral consensus and its operation.","authors":["Takeshi Kato","Yosuke Tanabe","Mohammad Rezoanul Hoque"],"url":"https://arxiv.org/abs/2405.13341"}
{"created":"2025-04-21","title":"Spin glass model of in-context learning","abstract":"Large language models show a surprising in-context learning ability -- being able to use a prompt to form a prediction for a query, yet without additional training, in stark contrast to old-fashioned supervised learning. Providing a mechanistic interpretation and linking the empirical phenomenon to physics are thus challenging and remain unsolved. We study a simple yet expressive transformer with linear attention and map this structure to a spin glass model with real-valued spins, where the couplings and fields explain the intrinsic disorder in data. The spin glass model explains how the weight parameters interact with each other during pre-training, and further clarifies why an unseen function can be predicted by providing only a prompt yet without further training. Our theory reveals that for single-instance learning, increasing the task diversity leads to the emergence of in-context learning, by allowing the Boltzmann distribution to converge to a unique correct solution of weight parameters. Therefore the pre-trained transformer displays a prediction power in a novel prompt setting. The proposed analytically tractable model thus offers a promising avenue for thinking about how to interpret many intriguing but puzzling properties of large language models.","authors":["Yuhao Li","Ruoran Bai","Haiping Huang"],"url":"https://arxiv.org/abs/2408.02288"}
{"created":"2025-04-21","title":"Symmetry-Based Structured Matrices for Efficient Approximately Equivariant Networks","abstract":"There has been much recent interest in designing neural networks (NNs) with relaxed equivariance, which interpolate between exact equivariance and full flexibility for consistent performance gains. In a separate line of work, structured parameter matrices with low displacement rank (LDR) -- which permit fast function and gradient evaluation -- have been used to create compact NNs, though primarily benefiting classical convolutional neural networks (CNNs). In this work, we propose a framework based on symmetry-based structured matrices to build approximately equivariant NNs with fewer parameters. Our approach unifies the aforementioned areas using Group Matrices (GMs), a forgotten precursor to the modern notion of regular representations of finite groups. GMs allow the design of structured matrices similar to LDR matrices, which can generalize all the elementary operations of a CNN from cyclic groups to arbitrary finite groups. We show GMs can also generalize classical LDR theory to general discrete groups, enabling a natural formalism for approximate equivariance. We test GM-based architectures on various tasks with relaxed symmetry and find that our framework performs competitively with approximately equivariant NNs and other structured matrix-based methods, often with one to two orders of magnitude fewer parameters.","authors":["Ashwin Samudre","Mircea Petrache","Brian D. Nord","Shubhendu Trivedi"],"url":"https://arxiv.org/abs/2409.11772"}
{"created":"2025-04-21","title":"Website visits can predict angler presence using machine learning","abstract":"Understanding and predicting recreational angler effort is important for sustainable fisheries management. However, conventional methods of measuring angler effort, such as surveys, can be costly and limited in both time and spatial extent. Models that predict angler effort based on environmental or economic factors typically rely on historical data, which often limits their spatial and temporal generalizability due to data scarcity. In this study, high-resolution data from an online fishing platform and easily accessible auxiliary data were tested to predict daily boat presence and aerial counts of boats at almost 200 lakes over five years in Ontario, Canada. Lake-information website visits alone enabled predicting daily angler boat presence with 78% accuracy. While incorporating additional environmental, socio-ecological, weather and angler-reported features into machine learning models did not remarkably improve prediction performance of boat presence, they were substantial for the prediction of boat counts. Models achieved an R2 of up to 0.77 at known lakes included in the model training, but they performed poorly for unknown lakes (R2 = 0.21). The results demonstrate the value of integrating data from online fishing platforms into predictive models and highlight the potential of machine learning models to enhance fisheries management.","authors":["Julia S. Schmid (Department of Mathematical and Statistical Sciences","University of Alberta","Edmonton","Alberta","Canada)","Sean Simmons (Anglers Atlas","Goldstream Publishing","Prince George","British Columbia","Canada)","Mark A. Lewis (Department of Mathematical and Statistical Sciences","University of Alberta","Edmonton","Alberta","Canada","Department of Mathematics and Statistics","University of Victoria","Victoria","British Columbia","Canada","Department of Biology","University of Victoria","Victoria","British Columbia","Canada","Department of Biological Sciences","University of Alberta","Edmonton","Alberta","Canada)","Mark S. Poesch (Department of Biological Sciences","University of Alberta","Edmonton","Alberta","Canada)","Pouria Ramazi (Department of Mathematics and Statistics","Brock University","St. Catharines","Ontario","Canada)"],"url":"https://arxiv.org/abs/2409.17425"}
{"created":"2025-04-21","title":"Optimal Transport for $\\epsilon$-Contaminated Credal Sets: To the Memory of Sayan Mukherjee","abstract":"We present generalized versions of Monge's and Kantorovich's optimal transport problems with the probabilities being transported replaced by lower probabilities. We show that, when the lower probabilities are the lower envelopes of $\\epsilon$-contaminated sets, then our version of Monge's, and a restricted version of our Kantorovich's problems, coincide with their respective classical versions. We also give sufficient conditions for the existence of our version of Kantorovich's optimal plan, and for the two problems to be equivalent. As a byproduct, we show that for $\\epsilon$-contaminations the lower probability versions of Monge's and Kantorovich's optimal transport problems need not coincide. The applications of our results to Machine Learning and Artificial Intelligence are also discussed.","authors":["Michele Caprio"],"url":"https://arxiv.org/abs/2410.03267"}
{"created":"2025-04-21","title":"Centered colorings in minor-closed graph classes","abstract":"A vertex coloring $\\varphi$ of a graph $G$ is $p$-centered if for every connected subgraph $H$ of $G$, either $\\varphi$ uses more than $p$ colors on $H$, or there is a color that appears exactly once on $H$. We prove that for every fixed positive integer $t$, every $K_t$-minor-free graph admits a $p$-centered coloring using $\\mathcal{O}(p^{t-1})$ colors.","authors":["J\\k{e}drzej Hodor","Hoang La","Piotr Micek","Cl\\'ement Rambaud"],"url":"https://arxiv.org/abs/2411.02122"}
{"created":"2025-04-21","title":"Beneath the Surface: The Role of Underwater Image Enhancement in Object Detection","abstract":"Underwater imagery often suffers from severe degradation resulting in low visual quality and reduced object detection performance. This work aims to evaluate state-of-the-art image enhancement models, investigate their effects on underwater object detection, and explore their potential to improve detection performance. To this end, we apply nine recent underwater image enhancement models, covering physical, non-physical and learning-based categories, to two recent underwater image datasets. Following this, we conduct joint qualitative and quantitative analyses on the original and enhanced images, revealing the discrepancy between the two analyses, and analyzing changes in the quality distribution of the images after enhancement. We then train three recent object detection models on the original datasets, selecting the best-performing detector for further analysis. This detector is subsequently re-trained on the enhanced datasets to evaluate changes in detection performance, highlighting the adverse effect of enhancement on detection performance at the dataset level. Next, we perform a correlation study to examine the relationship between various enhancement metrics and the mean Average Precision (mAP). Finally, we conduct an image-level analysis that reveals images of improved detection performance after enhancement. The findings of this study demonstrate the potential of image enhancement to improve detection performance and provide valuable insights for researchers to further explore the effects of enhancement on detection at the individual image level, rather than at the dataset level. This could enable the selective application of enhancement for improved detection. The data generated, code developed, and supplementary materials are publicly available at: https://github.com/RSSL-MTU/Enhancement-Detection-Analysis.","authors":["Ali Awad (Michigan Technological University)","Ashraf Saleem (Michigan Technological University)","Sidike Paheding (Fairfield University)","Evan Lucas (Michigan Technological University)","Serein Al-Ratrout (Michigan Technological University)","Timothy C. Havens (Michigan Technological University)"],"url":"https://arxiv.org/abs/2411.14626"}
{"created":"2025-04-21","title":"Learning when to rank: Estimation of partial rankings from sparse, noisy comparisons","abstract":"A common task arising in various domains is that of ranking items based on the outcomes of pairwise comparisons, from ranking players and teams in sports to ranking products or brands in marketing studies and recommendation systems. Statistical inference-based methods such as the Bradley-Terry model, which extract rankings based on an underlying generative model of the comparison outcomes, have emerged as flexible and powerful tools to tackle the task of ranking in empirical data. In situations with limited and/or noisy comparisons, it is often challenging to confidently distinguish the performance of different items based on the evidence available in the data. However, existing inference-based ranking methods overwhelmingly choose to assign each item to a unique rank or score, suggesting a meaningful distinction when there is none. Here, we address this problem by developing a principled Bayesian methodology for learning partial rankings -- rankings with ties -- that distinguishes among the ranks of different items only when there is sufficient evidence available in the data. Our framework is adaptable to any statistical ranking method in which the outcomes of pairwise observations depend on the ranks or scores of the items being compared. We develop a fast agglomerative algorithm to perform Maximum A Posteriori (MAP) inference of partial rankings under our framework and examine the performance of our method on a variety of real and synthetic network datasets, finding that it frequently gives a more parsimonious summary of the data than traditional ranking, particularly when observations are sparse.","authors":["Sebastian Morel-Balbi","Alec Kirkley"],"url":"https://arxiv.org/abs/2501.02505"}
{"created":"2025-04-21","title":"Conformal Prediction Regions are Imprecise Highest Density Regions","abstract":"Recently, Cella and Martin proved how, under an assumption called consonance, a credal set (i.e. a closed and convex set of probabilities) can be derived from the conformal transducer associated with transductive conformal prediction. We show that the Imprecise Highest Density Region (IHDR) associated with such a credal set corresponds to the classical Conformal Prediction Region. In proving this result, we establish a new relationship between Conformal Prediction and Imprecise Probability (IP) theories, via the IP concept of a cloud. A byproduct of our presentation is the discovery that consonant plausibility functions are monoid homomorphisms, a new algebraic property of an IP tool.","authors":["Michele Caprio","Yusuf Sale","Eyke H\\\"ullermeier"],"url":"https://arxiv.org/abs/2502.06331"}
{"created":"2025-04-21","title":"Statistical Inference in Reinforcement Learning: A Selective Survey","abstract":"Reinforcement learning (RL) is concerned with how intelligence agents take actions in a given environment to maximize the cumulative reward they receive. In healthcare, applying RL algorithms could assist patients in improving their health status. In ride-sharing platforms, applying RL algorithms could increase drivers' income and customer satisfaction. For large language models, applying RL algorithms could align their outputs with human preferences. Over the past decade, RL has been arguably one of the most vibrant research frontiers in machine learning. Nevertheless, statistics as a field, as opposed to computer science, has only recently begun to engage with RL both in depth and in breadth. This chapter presents a selective review of statistical inferential tools for RL, covering both hypothesis testing and confidence interval construction. Our goal is to highlight the value of statistical inference in RL for both the statistics and machine learning communities, and to promote the broader application of classical statistical inference tools in this vibrant area of research.","authors":["Chengchun Shi"],"url":"https://arxiv.org/abs/2502.16195"}
{"created":"2025-04-21","title":"Variable transformations in consistent loss functions","abstract":"Loss functions constructed by applying transformations to the realization and prediction variables of (strictly) consistent loss functions have been extensively studied empirically, yet their theoretical foundations remain unexplored. To address this gap, we establish formal characterizations of (strict) consistency for such transformed loss functions and their corresponding elicitable functionals. Our analysis focuses on two interrelated cases: (a) transformations applied solely to the realization variable and (b) bijective transformations applied jointly to both the realization and prediction variables. These cases extend the well-established framework of transformations applied exclusively to the prediction variable, as formalized by Osband's revelation principle. We further develop analogous characterizations for (strict) identification functions. The resulting theoretical framework is broadly applicable to statistical and machine learning methodologies. When applied to Bregman and expectile loss functions, our framework enables two key advancements: (a) the interpretation of empirical findings from models trained with transformed loss functions and (b) the systematic construction of novel identifiable and elicitable functionals, including the g-transformed expectation and g-transformed expectile. By unifying theoretical insights with practical applications, this work advances principled methodologies for designing loss functions in complex predictive tasks. Applications of the framework to simulated and real-world data illustrate its practical utility in diverse settings.","authors":["Hristos Tyralis","Georgia Papacharalampous"],"url":"https://arxiv.org/abs/2502.16542"}
{"created":"2025-04-21","title":"Division polynomials for arbitrary isogenies","abstract":"Following work of Mazur-Tate and Satoh, we extend the definition of division polynomials to arbitrary isogenies of elliptic curves, including those whose kernels do not sum to the identity. In analogy to the classical case of division polynomials for multiplication-by-n, we demonstrate recurrence relations, identities relating to classical elliptic functions, the chain rule describing relationships between division polynomials on source and target curve, and generalizations to higher dimension (i.e., elliptic nets).","authors":["Katherine E. Stange"],"url":"https://arxiv.org/abs/2503.15428"}
{"created":"2025-04-21","title":"Adiabatic Fine-Tuning of Neural Quantum States Enables Detection of Phase Transitions in Weight Space","abstract":"Neural quantum states (NQS) have emerged as a powerful tool for approximating quantum wavefunctions using deep learning. While these models achieve remarkable accuracy, understanding how they encode physical information remains an open challenge. In this work, we introduce adiabatic fine-tuning, a scheme that trains NQS across a phase diagram, leading to strongly correlated weight representations across different models. This correlation in weight space enables the detection of phase transitions in quantum systems by analyzing the trained network weights alone. We validate our approach on the transverse field Ising model and the J1-J2 Heisenberg model, demonstrating that phase transitions manifest as distinct structures in weight space. Our results establish a connection between physical phase transitions and the geometry of neural network parameters, opening new directions for the interpretability of machine learning models in physics.","authors":["Vinicius Hernandes","Thomas Spriggs","Saqar Khaleefah","Eliska Greplova"],"url":"https://arxiv.org/abs/2503.17140"}
{"created":"2025-04-21","title":"Quantum error correction for long chains of trapped ions","abstract":"We propose a model for quantum computing with long chains of trapped ions and we design quantum error correction schemes for this model. The main components of a quantum error correction scheme are the quantum code and a quantum circuit called the syndrome extraction circuit, which is executed to perform error correction with this code. In this work, we design syndrome extraction circuits tailored to our ion chain model, a syndrome extraction tuning protocol to optimize these circuits, and we construct new quantum codes that outperform the state-of-the-art for chains of about $50$ qubits. To establish a baseline under the ion chain model, we simulate the performance of surface codes and bivariate bicycle (BB) codes equipped with our optimized syndrome extraction circuits. Then, we propose a new variant of BB codes defined by weight-five measurements, that we refer to as BB5 codes and we identify BB5 codes that achieve a better minimum distance than any BB codes with the same number of logical qubits and data qubits, such as a $[[48, 4, 7]]$ BB5 code. For a physical error rate of $10^{-3}$, the $[[48, 4, 7]]$ BB5 code achieves a logical error rate per logical qubit of $5 \\cdot 10^{-5}$, which is four times smaller than the best BB code in our baseline family. It also achieves the same logical error rate per logical qubit as the distance-7 surface code but using four times fewer physical qubits per logical qubit.","authors":["Min Ye","Nicolas Delfosse"],"url":"https://arxiv.org/abs/2503.22071"}
{"created":"2025-04-21","title":"Finite-Time Behavior of Erlang-C Model: Mixing Time, Mean Queue Length and Tail Bounds","abstract":"Service systems like data centers and ride-hailing are popularly modeled as queueing systems in the literature. Such systems are primarily studied in the steady state due to their analytical tractability. However, almost all applications in real life do not operate in a steady state, so there is a clear discrepancy in translating theoretical queueing results to practical applications. To this end, we provide a finite-time convergence for Erlang-C systems (also known as $M/M/n$ queues), providing a stepping stone towards understanding the transient behavior of more general queueing systems. We obtain a bound on the Chi-square distance between the finite time queue length distribution and the stationary distribution for a finite number of servers. We then use these bounds to study the behavior in the many-server heavy-traffic asymptotic regimes. The Erlang-C model exhibits a phase transition at the so-called Halfin-Whitt regime. We show that our mixing rate matches the limiting behavior in the Super-Halfin-Whitt regime, and matches up to a constant factor in the Sub-Halfin-Whitt regime.","authors":["Hoang Huy Nguyen","Sushil Mahavir Varma","Siva Theja Maguluri"],"url":"https://arxiv.org/abs/2504.02207"}
{"created":"2025-04-21","title":"Minimax Optimal Convergence of Gradient Descent in Logistic Regression via Large and Adaptive Stepsizes","abstract":"We study $\\textit{gradient descent}$ (GD) for logistic regression on linearly separable data with stepsizes that adapt to the current risk, scaled by a constant hyperparameter $\\eta$. We show that after at most $1/\\gamma^2$ burn-in steps, GD achieves a risk upper bounded by $\\exp(-\\Theta(\\eta))$, where $\\gamma$ is the margin of the dataset. As $\\eta$ can be arbitrarily large, GD attains an arbitrarily small risk $\\textit{immediately after the burn-in steps}$, though the risk evolution may be $\\textit{non-monotonic}$.","authors":["Ruiqi Zhang","Jingfeng Wu","Licong Lin","Peter L. Bartlett"],"url":"https://arxiv.org/abs/2504.04105"}
