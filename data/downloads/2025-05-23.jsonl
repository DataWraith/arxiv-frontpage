{"created":"2025-05-23","title":"Common Data Format (CDF): A Standardized Format for Match-Data in Football (Soccer)","abstract":"During football matches, a variety of different parties (e.g., companies) each collect (possibly overlapping) data about the match ranging from basic information (e.g., starting players) to detailed positional data. This data is provided to clubs, federations, and other organizations who are increasingly interested in leveraging this data to inform their decision making. Unfortunately, analyzing such data pose significant barriers because each provider may (1) collect different data, (2) use different specifications even within the same category of data, (3) represent the data differently, and (4) delivers the data in a different manner (e.g., file format, protocol). Consequently, working with these data requires a significant investment of time and money. The goal of this work is to propose a uniform and standardized format for football data called the Common Data Format (CDF). The CDF specifies a minimal schema for five types of match data: match sheet data, video footage, event data, tracking data, and match meta data. It aims to ensure that the provided data is clear, sufficiently contextualized (e.g., its provenance is clear), and complete such that it enables common downstream analysis tasks. Concretely, this paper will detail the technical specifications of the CDF, the representational choices that were made to help ensure the clarity of the provided data, and a concrete approach for delivering data in the CDF.","authors":["Gabriel Anzer","Kilian Arnsmeyer","Pascal Bauer","Joris Bekkers","Ulf Brefeld","Jesse Davis","Nicolas Evans","Matthias Kempe","Samuel J Robertson","Joshua Wyatt Smith","Jan Van Haaren"],"url":"https://arxiv.org/abs/2505.15820"}
{"created":"2025-05-23","title":"A Novel Compound AI Model for 6G Networks in 3D Continuum","abstract":"The 3D continuum presents a complex environment that spans the terrestrial, aerial and space domains, with 6Gnetworks serving as a key enabling technology. Current AI approaches for network management rely on monolithic models that fail to capture cross-domain interactions, lack adaptability,and demand prohibitive computational resources. This paper presents a formal model of Compound AI systems, introducing a novel tripartite framework that decomposes complex tasks into specialized, interoperable modules. The proposed modular architecture provides essential capabilities to address the unique challenges of 6G networks in the 3D continuum, where heterogeneous components require coordinated, yet distributed, intelligence. This approach introduces a fundamental trade-off between model and system performance, which must be carefully addressed. Furthermore, we identify key challenges faced by Compound AI systems within 6G networks operating in the 3D continuum, including cross-domain resource orchestration, adaptation to dynamic topologies, and the maintenance of consistent AI service quality across heterogeneous environments.","authors":["Milos Gravara","Andrija Stanisic","Stefan Nastic"],"url":"https://arxiv.org/abs/2505.15821"}
{"created":"2025-05-23","title":"HQSI: Hybrid Quantum Swarm Intelligence -- A Case Study of Online Certificate Status Protocol Request Flow Prediction","abstract":"As quantum computing technology continues to advance, various sectors, including industry, government, academia, and research, have increasingly focused on its future applications. With the integration of artificial intelligence techniques, multiple Quantum Neural Network (QNN) models have been proposed, including quantum convolutional neural networks, quantum long short-term memory networks, and quantum generative adversarial networks. Furthermore, optimization methods such as constrained optimization by linear approximation and simultaneous perturbation stochastic approximation have been explored. Therefore, this study proposes Hybrid Quantum Swarm Intelligence (HQSI), which constructs a QNN model as a forward propagation neural network. After measuring quantum states and obtaining prediction results, a classical computer-based swarm intelligence algorithm is employed for weight optimization. The training process iterates between quantum and classical computing environments. During the experimental phase, the proposed HQSI method is evaluated using an online certificate status protocol request traffic prediction task. Comparative analysis against state-of-the-art quantum optimization algorithms demonstrates that the proposed HQSI approach achieves more than a 50% reduction in error.","authors":["Abel C. H. Chen"],"url":"https://arxiv.org/abs/2505.15823"}
{"created":"2025-05-23","title":"Multilinear subspace learning for person re-identification based fusion of high order tensor features","abstract":"Video surveillance image analysis and processing is a challenging field in computer vision, with one of its most difficult tasks being Person Re-Identification (PRe-ID). PRe-ID aims to identify and track target individuals who have already been detected in a network of cameras, using a robust description of their pedestrian images. The success of recent research in person PRe-ID is largely due to effective feature extraction and representation, as well as the powerful learning of these features to reliably discriminate between pedestrian images. To this end, two powerful features, Convolutional Neural Networks (CNN) and Local Maximal Occurrence (LOMO), are modeled on multidimensional data using the proposed method, High-Dimensional Feature Fusion (HDFF). Specifically, a new tensor fusion scheme is introduced to leverage and combine these two types of features in a single tensor, even though their dimensions are not identical. To enhance the system's accuracy, we employ Tensor Cross-View Quadratic Analysis (TXQDA) for multilinear subspace learning, followed by cosine similarity for matching. TXQDA efficiently facilitates learning while reducing the high dimensionality inherent in high-order tensor data. The effectiveness of our approach is verified through experiments on three widely-used PRe-ID datasets: VIPeR, GRID, and PRID450S. Extensive experiments demonstrate that our approach outperforms recent state-of-the-art methods.","authors":["Ammar Chouchane","Mohcene Bessaoudi","Hamza Kheddar","Abdelmalik Ouamane","Tiago Vieira","Mahmoud Hassaballah"],"url":"https://arxiv.org/abs/2505.15825"}
{"created":"2025-05-23","title":"Decoupling the Device and Identity in Cellular Networks with vSIM","abstract":"Cellular networks are now fundamental infrastructure, powering not just smartphones for daily communication and commerce, but also enabling the expansion of IoT and edge computing through last-mile connectivity. At the core of this infrastructure is the SIM card, which provides essential network authentication and subscriber identification through subscriber cryptographic key and profile information. More recently, the SIM card has evolved from a separate pluggable card, to a card integrated into the board (i.e., soldered onto the board with the same electrical interface) (eSIM), to one that is integrated into the System on Chip (iSIM). However, a fundamental limitation persists across SIM evolution: subscriber identity remains coupled to hardware. eSIM and iSIM technologies, despite enabling remote provisioning, still bind digital identities to specific hardware elements. This makes it complex to support emerging use cases like moving a phone number to a cloud AI service or transferring credentials between different devices while maintaining cellular connectivity. Furthermore, although eSIM and iSIM support multiple profiles (multiple phone numbers or carrier profiles on a single device), all profiles still link back to the same hardware identity. For users seeking to maintain privacy through identity rotation or separation (like having different numbers for different purposes), they are limited by the hardware-bound nature of the security architecture. In this paper, we seek to decouple identity from the device, enhancing privacy and flexibility compared to various SIM designs. By breaking this coupling, we enable scenarios like real identity rotation, integration with virtual assistants, or temporary use of backup phones while maintaining consistent cellular connectivity.","authors":["Shirin Ebadi","Zach Moolman","Eric Keller","Tamara Lehman"],"url":"https://arxiv.org/abs/2505.15827"}
{"created":"2025-05-23","title":"Generative AI-Aided QoE Maximization for RIS-Assisted Digital Twin Interaction","abstract":"In this paper, we investigate a quality of experience (QoE)-aware resource allocation problem for reconfigurable intelligent surface (RIS)-assisted digital twin (DT) interaction with uncertain evolution. In the considered system, mobile users are expected to interact with a DT model maintained on a DT server that is deployed on a base station, via effective uplink and downlink channels assisted by an RIS. Our goal is to maximize the sum of all mobile users' joint subjective and objective QoE in DT interactions across various DT scenes, by jointly optimizing phase shift matrix, receive/transmit beamforming matrix, rendering resolution configuration and computing resource allocation. While solving this problem is challenging mainly due to the uncertain evolution of the DT model, which leads to multiple scene-specific problems, and require us to constantly re-solve each of them whenever DT model evolves.","authors":["Jiayuan Chen","Yuxiang Li","Changyan Yi","Shimin Gong"],"url":"https://arxiv.org/abs/2505.15828"}
{"created":"2025-05-23","title":"Distributionally Robust Optimization for Digital Twin Service Provisioning over Edge Computing","abstract":"Digital Twin (DT) is a transformative technology poised to revolutionize a wide range of applications. This advancement has led to the emergence of digital twin as a service (DTaaS), enabling users to interact with DT models that accurately reflect the real-time status of their physical counterparts. Quality of DTaaS primarily depends on the freshness of DT data, which can be quantified by the age of information (AoI). The reliance on remote cloud servers solely for DTaaS provisioning presents significant challenges for latency-sensitive applications with strict AoI demands. Edge computing, as a promising paradigm, is expected to enable the AoI-aware provision of real-time DTaaS for users. In this paper, we study the joint optimization of DT model deployment and DT model selection for DTaaS provisioning over edge computing, with the objective of maximizing the quality of DTaaS. To address the uncertainties of DT interactions imposed on DTaaS provisioning, we propose a novel distributionally robust optimization (DRO)-based approach, called Wasserstein DRO (WDRO), where we first reformulate the original problem to a robust optimization problem, with the objective of maximizing the quality of DTaaS under the unforeseen extreme request conditions. Then, we leverage multi-level dual transformations based on Wasserstein distance to derive a robust solution. Simulations are conducted to evaluate the performance of the proposed WDRO, and the results demonstrate its superiority over counterparts.","authors":["Yuxiang Li","Jiayuan Chen","Changyan Yi"],"url":"https://arxiv.org/abs/2505.15829"}
{"created":"2025-05-23","title":"Characterization of Using Hybrid Beamforming in mmWave Virtual Reality","abstract":"Wireless Virtual Reality (VR) is increasingly in demand in Wireless LANs (WLANs). In this paper, a utility function for resource management in wireless VR is proposed. Maximizing the sum rate metric in transmitting VR audio or videos is an important factor for ascertaining low latency in obtaining QoS requirement of users in VR, so forth mmWave frequency band in WLAN technology should be used. This frequency band is presented in IEEE 802.11ad/ay. Resource access method in IEEE 802.11ay standard is MultiUser MIMO (MU-MIMO) with OFDM modulation. Operating at mmWave frequency band is equal to use massive number of antenna to enhance the received power in (Line of Sight) LoS direction by inducing sever propagation with small wavelength. Also for reducing the complexity of hardware in mmWave technology, designers should select some number of connected phase shifters to each antenna element by hybrid beamforming method. Processing delay, transmission delay and queue delay should be considered in acquiring QoS metric in terms of utility function. The optimal closed form expression of the multi-attribute utility function is based on these delays that are calculated by downlink and uplink rates in assistant with hybrid beamforming. Trends of transmission delay and multi-attribute utility function in various Es/N0 values and different scenarios are analyzed. Based on these results, 95.4% accuracy in comparison with ns3 in uplink and downlink channel modeling in IEEE 802.11ay standard's indoor environment has been reported. Also, it is shown that min channel gain consideration can cause reduction in the value of the utility function and incursion in transmission delay in VR.","authors":["Nasim Alikhani","Abbas Mohammadi"],"url":"https://arxiv.org/abs/2505.15830"}
{"created":"2025-05-23","title":"Ricci Matrix Comparison for Graph Alignment: A DMC Variation","abstract":"The graph alignment problem explores the concept of node correspondence and its optimality. In this paper, we focus on purely geometric graph alignment methods, namely our newly proposed Ricci Matrix Comparison (RMC) and its original form, Degree Matrix Comparison (DMC). To formulate a Ricci-curvature-based graph alignment situation, we start with discussing different ideas of constructing one of the most typical and important topological objects, the torus, and then move on to introducing the RMC based on DMC with theoretical motivations. Lastly, we will present to the reader experimental results on a torus and a complex protein-protein interaction network that indicate the potential of applying a differential-geometric view to graph alignment. Results show that a direct variation of DMC using Ricci curvature can help with identifying holes in tori and aligning line graphs of a complex network at 80-90+% accuracy. This paper contributes a new perspective to the field of graph alignment and partially shows the validity of the previous DMC method.","authors":["Ashley Wang","Peter Chin"],"url":"https://arxiv.org/abs/2505.15831"}
{"created":"2025-05-23","title":"From Hand-Crafted Metrics to Evolved Training-Free Performance Predictors for Neural Architecture Search via Genetic Programming","abstract":"Estimating the network performance using zero-cost (ZC) metrics has proven both its efficiency and efficacy in Neural Architecture Search (NAS). However, a notable limitation of most ZC proxies is their inconsistency, as reflected by the substantial variation in their performance across different problems. Furthermore, the design of existing ZC metrics is manual, involving a time-consuming trial-and-error process that requires substantial domain expertise. These challenges raise two critical questions: (1) Can we automate the design of ZC metrics? and (2) Can we utilize the existing hand-crafted ZC metrics to synthesize a more generalizable one? In this study, we propose a framework based on Symbolic Regression via Genetic Programming to automate the design of ZC metrics. Our framework is not only highly extensible but also capable of quickly producing a ZC metric with a strong positive rank correlation to true network performance across diverse NAS search spaces and tasks. Extensive experiments on 13 problems from NAS-Bench-Suite-Zero demonstrate that our automatically generated proxies consistently outperform hand-crafted alternatives. Using our evolved proxy metric as the search objective in an evolutionary algorithm, we could identify network architectures with competitive performance within 15 minutes using a single consumer GPU.","authors":["Quan Minh Phan","Ngoc Hoang Luong"],"url":"https://arxiv.org/abs/2505.15832"}
{"created":"2025-05-23","title":"Adversarially Robust Spiking Neural Networks with Sparse Connectivity","abstract":"Deployment of deep neural networks in resource-constrained embedded systems requires innovative algorithmic solutions to facilitate their energy and memory efficiency. To further ensure the reliability of these systems against malicious actors, recent works have extensively studied adversarial robustness of existing architectures. Our work focuses on the intersection of adversarial robustness, memory- and energy-efficiency in neural networks. We introduce a neural network conversion algorithm designed to produce sparse and adversarially robust spiking neural networks (SNNs) by leveraging the sparse connectivity and weights from a robustly pretrained artificial neural network (ANN). Our approach combines the energy-efficient architecture of SNNs with a novel conversion algorithm, leading to state-of-the-art performance with enhanced energy and memory efficiency through sparse connectivity and activations. Our models are shown to achieve up to 100x reduction in the number of weights to be stored in memory, with an estimated 8.6x increase in energy efficiency compared to dense SNNs, while maintaining high performance and robustness against adversarial threats.","authors":["Mathias Schmolli","Maximilian Baronig","Robert Legenstein","Ozan \\\"Ozdenizci"],"url":"https://arxiv.org/abs/2505.15833"}
{"created":"2025-05-23","title":"MPPFND: A Dataset and Analysis of Detecting Fake News with Multi-Platform Propagation","abstract":"Fake news spreads widely on social media, leading to numerous negative effects. Most existing detection algorithms focus on analyzing news content and social context to detect fake news. However, these approaches typically detect fake news based on specific platforms, ignoring differences in propagation characteristics across platforms. In this paper, we introduce the MPPFND dataset, which captures propagation structures across multiple platforms. We also describe the commenting and propagation characteristics of different platforms to show that their social contexts have distinct features. We propose a multi-platform fake news detection model (APSL) that uses graph neural networks to extract social context features from various platforms. Experiments show that accounting for cross-platform propagation differences improves fake news detection performance.","authors":["Congyuan Zhao","Lingwei Wei","Ziming Qin","Wei Zhou","Yunya Song","Songlin Hu"],"url":"https://arxiv.org/abs/2505.15834"}
{"created":"2025-05-23","title":"Transforming Decoder-Only Transformers for Accurate WiFi-Telemetry Based Indoor Localization","abstract":"Wireless Fidelity (WiFi) based indoor positioning is a widely researched area for determining the position of devices within a wireless network. Accurate indoor location has numerous applications, such as asset tracking and indoor navigation. Despite advances in WiFi localization techniques -- in particular approaches that leverage WiFi telemetry -- their adoption in practice remains limited due to several factors including environmental changes that cause signal fading, multipath effects, interference, which, in turn, impact positioning accuracy. In addition, telemetry data differs depending on the WiFi device vendor, offering distinct features and formats; use case requirements can also vary widely. Currently, there is no unified model to handle all these variations effectively. In this paper, we present WiFiGPT, a Generative Pretrained Transformer (GPT) based system that is able to handle these variations while achieving high localization accuracy. Our experiments with WiFiGPT demonstrate that GPTs, in particular Large Language Models (LLMs), can effectively capture subtle spatial patterns in noisy wireless telemetry, making them reliable regressors. Compared to existing state-of-the-art methods, our method matches and often surpasses conventional approaches for multiple types of telemetry. Achieving sub-meter accuracy for RSSI and FTM and centimeter-level precision for CSI demonstrates the potential of LLM-based localisation to outperform specialized techniques, all without handcrafted signal processing or calibration.","authors":["Nayan Sanjay Bhatia","Katia Obraczka"],"url":"https://arxiv.org/abs/2505.15835"}
{"created":"2025-05-23","title":"Quantum-Evolutionary Neural Networks for Multi-Agent Federated Learning","abstract":"As artificial intelligence continues to drive innovation in complex, decentralized environments, the need for scalable, adaptive, and privacy-preserving decision-making systems has become critical. This paper introduces a novel framework combining quantum-inspired neural networks with evolutionary algorithms to optimize real-time decision-making in multi-agent systems (MAS). The proposed Quantum-Evolutionary Neural Network (QE-NN) leverages quantum computing principles -- such as quantum superposition and entanglement -- to enhance learning speed and decision accuracy, while integrating evolutionary optimization to continually refine agent behaviors in dynamic, uncertain environments. By utilizing federated learning, QE-NN ensures privacy preservation, enabling decentralized agents to collaborate without sharing sensitive data. The framework is designed to allow agents to adapt in real-time to their environments, optimizing decision-making processes for applications in areas such as autonomous systems, smart cities, and healthcare. This research represents a breakthrough in merging quantum computing, evolutionary optimization, and privacy-preserving techniques to solve complex problems in multi-agent decision-making systems, pushing the boundaries of AI in real-world, privacy-sensitive applications.","authors":["Aarav Lala","Kalyan Cherukuri"],"url":"https://arxiv.org/abs/2505.15836"}
{"created":"2025-05-23","title":"Web2Wiki: Characterizing Wikipedia Linking Across the Web","abstract":"Wikipedia is one of the most visited websites globally, yet its role beyond its own platform remains largely unexplored. In this paper, we present the first large-scale analysis of how Wikipedia is referenced across the Web. Using a dataset from Common Crawl, we identify over 90 million Wikipedia links spanning 1.68% of Web domains and examine their distribution, context, and function. Our analysis of English Wikipedia reveals three key findings: (1) Wikipedia is most frequently cited by news and science websites for informational purposes, while commercial websites reference it less often. (2) The majority of Wikipedia links appear within the main content rather than in boilerplate or user-generated sections, highlighting their role in structured knowledge presentation. (3) Most links (95%) serve as explanatory references rather than as evidence or attribution, reinforcing Wikipedia's function as a background knowledge provider. While this study focuses on English Wikipedia, our publicly released Web2Wiki dataset includes links from multiple language editions, supporting future research on Wikipedia's global influence on the Web.","authors":["Veniamin Veselovsky","Tiziano Piccardi","Ashton Anderson","Robert West","Akhil Arora"],"url":"https://arxiv.org/abs/2505.15837"}
{"created":"2025-05-23","title":"Curriculum Learning in Genetic Programming Guided Local Search for Large-scale Vehicle Routing Problems","abstract":"Manually designing (meta-)heuristics for the Vehicle Routing Problem (VRP) is a challenging task that requires significant domain expertise. Recently, data-driven approaches have emerged as a promising solution, automatically learning heuristics that perform well on training instances and generalize to unseen test cases. Such an approach learns (meta-)heuristics that can perform well on the training instances, expecting it to generalize well on the unseen test instances. A recent method, named GPGLS, uses Genetic Programming (GP) to learn the utility function in Guided Local Search (GLS) and solved large scale VRP effectively. However, the selection of appropriate training instances during the learning process remains an open question, with most existing studies including GPGLS relying on random instance selection. To address this, we propose a novel method, CL-GPGLS, which integrates Curriculum Learning (CL) into GPGLS. Our approach leverages a predefined curriculum to introduce training instances progressively, starting with simpler tasks and gradually increasing complexity, enabling the model to better adapt and optimize for large-scale VRP (LSVRP). Extensive experiments verify the effectiveness of CL-GPGLS, demonstrating significant performance improvements over three baseline methods.","authors":["Saining Liu","Yi Mei","Mengjie Zhang"],"url":"https://arxiv.org/abs/2505.15839"}
{"created":"2025-05-23","title":"TDFormer: A Top-Down Attention-Controlled Spiking Transformer","abstract":"Traditional spiking neural networks (SNNs) can be viewed as a combination of multiple subnetworks with each running for one time step, where the parameters are shared, and the membrane potential serves as the only information link between them. However, the implicit nature of the membrane potential limits its ability to effectively represent temporal information. As a result, each time step cannot fully leverage information from previous time steps, seriously limiting the model's performance. Inspired by the top-down mechanism in the brain, we introduce TDFormer, a novel model with a top-down feedback structure that functions hierarchically and leverages high-order representations from earlier time steps to modulate the processing of low-order information at later stages. The feedback structure plays a role from two perspectives: 1) During forward propagation, our model increases the mutual information across time steps, indicating that richer temporal information is being transmitted and integrated in different time steps. 2) During backward propagation, we theoretically prove that the feedback structure alleviates the problem of vanishing gradients along the time dimension. We find that these mechanisms together significantly and consistently improve the model performance on multiple datasets. In particular, our model achieves state-of-the-art performance on ImageNet with an accuracy of 86.83%.","authors":["Zizheng Zhu","Yingchao Yu","Zeqi Zheng","Zhaofei Yu","Yaochu Jin"],"url":"https://arxiv.org/abs/2505.15840"}
{"created":"2025-05-23","title":"Optimizing Resource Allocation for QoS and Stability in Dynamic VLC-NOMA Networks via MARL","abstract":"Visible Light Communication (VLC) combined with Non-Orthogonal Multiple Access (NOMA) offers a promising solution for dense indoor wireless networks. Yet, managing resources effectively is challenged by VLC network dynamic conditions involving user mobility and light dimming. In addition to satisfying Quality of Service (QoS) and network stability requirements. Traditional resource allocation methods and simpler RL approaches struggle to jointly optimize QoS and stability under the dynamic conditions of mobile VLC-NOMA networks. This paper presents MARL frameworks tailored to perform complex joint optimization of resource allocation (NOMA power, user scheduling) and network stability (interference, handovers), considering heterogeneous QoS, user mobility, and dimming in VLC-NOMA systems. Our MARL frameworks capture dynamic channel conditions and diverse user QoS , enabling effective joint optimization. In these frameworks, VLC access points (APs) act as intelligent agents, learning to allocate power and schedule users to satisfy diverse requirements while maintaining network stability by managing interference and minimizing disruptive handovers. We conduct a comparative analysis of two key MARL paradigms: 1) Centralized Training with Decentralized Execution (CTDE) and 2) Centralized Training with Centralized Execution (CTCE). Comprehensive simulations validate the effectiveness of both tailored MARL frameworks and demonstrate an ability to handle complex optimization. The results show key trade-offs, as the CTDE approach achieved approximately 16\\% higher for High priority (HP) user QoS satisfaction, while the CTCE approach yielded nearly 7 dB higher average SINR and 12\\% lower ping-pong handover ratio, offering valuable insights into the performance differences between these paradigms in complex VLC-NOMA network scenarios.","authors":["Aubida A. Al-Hameed","Safwan Hafeedh Younus","Mohamad A. Ahmed","Abdullah Baz"],"url":"https://arxiv.org/abs/2505.15841"}
{"created":"2025-05-23","title":"AH-UGC: Adaptive and Heterogeneous-Universal Graph Coarsening","abstract":"$\\textbf{Graph Coarsening (GC)}$ is a prominent graph reduction technique that compresses large graphs to enable efficient learning and inference. However, existing GC methods generate only one coarsened graph per run and must recompute from scratch for each new coarsening ratio, resulting in unnecessary overhead. Moreover, most prior approaches are tailored to $\\textit{homogeneous}$ graphs and fail to accommodate the semantic constraints of $\\textit{heterogeneous}$ graphs, which comprise multiple node and edge types. To overcome these limitations, we introduce a novel framework that combines Locality Sensitive Hashing (LSH) with Consistent Hashing to enable $\\textit{adaptive graph coarsening}$. Leveraging hashing techniques, our method is inherently fast and scalable. For heterogeneous graphs, we propose a $\\textit{type isolated coarsening}$ strategy that ensures semantic consistency by restricting merges to nodes of the same type. Our approach is the first unified framework to support both adaptive and heterogeneous coarsening. Extensive evaluations on 23 real-world datasets including homophilic, heterophilic, homogeneous, and heterogeneous graphs demonstrate that our method achieves superior scalability while preserving the structural and semantic integrity of the original graph.","authors":["Mohit Kataria","Shreyash Bhilwade","Sandeep Kumar","Jayadeva"],"url":"https://arxiv.org/abs/2505.15842"}
{"created":"2025-05-23","title":"Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models","abstract":"Graph Transformers, leveraging the global attention to capture long-range dependencies in graph structures, have significantly advanced graph machine learning, but face prohibitive computational complexity. Tokenized Graph Learning Models (TGLMs) address this issue by converting graphs into ordered token lists for scalable processing. Besides, TGLMs also empower Large Language Models (LLMs) to handle text-attributed graphs more effectively and thus are also employed in Graph LLMs. However, existing TGLMs rely on hand-designed token lists and their adaptability to diverse graph learning scenarios remains unexplored. In this paper, we first conduct extensive empirical and theoretical preliminary studies for hand-designed token lists. Surprisingly, we identify an unexplored hop-overpriority problem: the common pre-defined token lists overemphasize nearby nodes and overwhelm the ability of TGLMs to balance local and global signals. This phenomenon is especially harmful for heterophilic graphs. To address this problem, we propose the Learnable Graph Token List (LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs. Specifically, LGTL adaptively adjusts the weights across hops and prioritizes informative nodes within hops through a graph attention gate module and a selection module, respectively. In this way, contextually informative nodes can be adaptively emphasized for both homophilic and heterophilic graphs. Besides, we theoretically show that LGTL can address the hop-overpriority problem. Extensive experiments on benchmarks validate the efficacy of LGTL across both Graph Transformers and Graph LLM backbones.","authors":["Zhibiao Wang","Yunlong Zhou","Ziwei Zhang","Mengmei Zhang","Shirui Pan","Chunming Hu","Xiao Wang"],"url":"https://arxiv.org/abs/2505.15845"}
{"created":"2025-05-23","title":"Graph Neural Networks Based Anomalous RSSI Detection","abstract":"In today's world, modern infrastructures are being equipped with information and communication technologies to create large IoT networks.","authors":["Bla\\v{z} Bertalani\\v{c}","Matej Vnu\\v{c}ec","Carolina Fortuna"],"url":"https://arxiv.org/abs/2505.15847"}
{"created":"2025-05-23","title":"Sionna Research Kit: A GPU-Accelerated Research Platform for AI-RAN","abstract":"We introduce the NVIDIA Sionna Research Kit, a GPU-accelerated research platform for developing and testing AI/ML algorithms in 5G NR cellular networks. Powered by the NVIDIA Jetson AGX Orin, the platform leverages accelerated computing to deliver high throughput and real-time signal processing, while offering the flexibility of a software-defined stack. Built on OpenAirInterface (OAI), it unlocks a broad range of research opportunities. These include developing 5G NR and ORAN compliant algorithms, collecting real-world data for AI/ML training, and rapidly deploying innovative solutions in a very affordable testbed. Additionally, AI/ML hardware acceleration promotes the exploration of use cases in edge computing and AI radio access networks (AI-RAN). To demonstrate the capabilities, we deploy a real-time neural receiver - trained with NVIDIA Sionna and using the NVIDIA TensorRT library for inference - in a 5G NR cellular network using commercial user equipment. The code examples will be made publicly available, enabling researchers to adopt and extend the platform for their own projects.","authors":["Sebastian Cammerer","Guillermo Marcus","Tobias Zirr","Fay\\c{c}al A\\\"it Aoudia","Lorenzo Maggi","Jakob Hoydis","Alexander Keller"],"url":"https://arxiv.org/abs/2505.15848"}
{"created":"2025-05-23","title":"Exploring Moral Exercises for Human Oversight of AI systems: Insights from Three Pilot Studies","abstract":"This paper elaborates on the concept of moral exercises as a means to help AI actors cultivate virtues that enable effective human oversight of AI systems. We explore the conceptual framework and significance of moral exercises, situating them within the contexts of philosophical discourse, ancient practices, and contemporary AI ethics scholarship. We outline the core pillars of the moral exercises methodology - eliciting an engaged personal disposition, fostering relational understanding, and cultivating technomoral wisdom - and emphasize their relevance to key activities and competencies essential for human oversight of AI systems. Our argument is supported by findings from three pilot studies involving a company, a multidisciplinary team of AI researchers, and higher education students. These studies allow us to explore both the potential and the limitations of moral exercises. Based on the collected data, we offer insights into how moral exercises can foster a responsible AI culture within organizations, and suggest directions for future research.","authors":["Silvia Crafa","Teresa Scantamburlo"],"url":"https://arxiv.org/abs/2505.15851"}
{"created":"2025-05-23","title":"Integration of TinyML and LargeML: A Survey of 6G and Beyond","abstract":"The transition from 5G networks to 6G highlights a significant demand for machine learning (ML). Deep learning models, in particular, have seen wide application in mobile networking and communications to support advanced services in emerging wireless environments, such as smart healthcare, smart grids, autonomous vehicles, aerial platforms, digital twins, and the metaverse. The rapid expansion of Internet-of-Things (IoT) devices, many with limited computational capabilities, has accelerated the development of tiny machine learning (TinyML) and resource-efficient ML approaches for cost-effective services. However, the deployment of large-scale machine learning (LargeML) solutions require major computing resources and complex management strategies to support extensive IoT services and ML-generated content applications. Consequently, the integration of TinyML and LargeML is projected as a promising approach for future seamless connectivity and efficient resource management.","authors":["Thai-Hoc Vu","Ngo Hoang Tu","Thien Huynh-The","Kyungchun Lee","Sunghwan Kim","Miroslav Voznak","Quoc-Viet Pham"],"url":"https://arxiv.org/abs/2505.15854"}
{"created":"2025-05-23","title":"DisastIR: A Comprehensive Information Retrieval Benchmark for Disaster Management","abstract":"Effective disaster management requires timely access to accurate and contextually relevant information. Existing Information Retrieval (IR) benchmarks, however, focus primarily on general or specialized domains, such as medicine or finance, neglecting the unique linguistic complexity and diverse information needs encountered in disaster management scenarios. To bridge this gap, we introduce DisastIR, the first comprehensive IR evaluation benchmark specifically tailored for disaster management. DisastIR comprises 9,600 diverse user queries and more than 1.3 million labeled query-passage pairs, covering 48 distinct retrieval tasks derived from six search intents and eight general disaster categories that include 301 specific event types. Our evaluations of 30 state-of-the-art retrieval models demonstrate significant performance variances across tasks, with no single model excelling universally. Furthermore, comparative analyses reveal significant performance gaps between general-domain and disaster management-specific tasks, highlighting the necessity of disaster management-specific benchmarks for guiding IR model selection to support effective decision-making in disaster management scenarios. All source codes and DisastIR are available at https://github.com/KaiYin97/Disaster_IR.","authors":["Kai Yin","Xiangjue Dong","Chengkai Liu","Lipai Huang","Yiming Xiao","Zhewei Liu","Ali Mostafavi","James Caverlee"],"url":"https://arxiv.org/abs/2505.15856"}
{"created":"2025-05-23","title":"Simulating Prosocial Behavior and Social Contagion in LLM Agents under Institutional Interventions","abstract":"As large language models (LLMs) increasingly serve as autonomous agents in social contexts, understanding their capacity for prosocial behavior becomes essential. We present ProSim, a simulation framework designed to examine how prosocial behavior emerges, adapts, and erodes in LLM-based agents under diverse social and institutional conditions. The framework comprises four components: individual simulation, scenario simulation, interaction simulation, and intervention simulation. We conduct three progressive studies to evaluate prosocial alignment. First, we show that LLM agents can demonstrate stable and context-sensitive prosocial behavior across diverse scenarios and adapt their responses under normative policy interventions. Second, we find that agents engage in fairness-based third-party punishment and respond systematically to variations in inequity magnitude and enforcement cost. Third, we show that policy-induced inequities suppress prosocial behavior, propagate through social networks, and are mediated by agents' perceptions of unfairness. These findings lay the groundwork for evaluating social alignment and modeling institutional dynamics in agent-driven societies.","authors":["Yujia Zhou","Hexi Wang","Qingyao Ai","Zhen Wu","Yiqun Liu"],"url":"https://arxiv.org/abs/2505.15857"}
{"created":"2025-05-23","title":"Large Language Model-Powered Agent for C to Rust Code Translation","abstract":"The C programming language has been foundational in building system-level software. However, its manual memory management model frequently leads to memory safety issues. In response, a modern system programming language, Rust, has emerged as a memory-safe alternative. Moreover, automating the C-to-Rust translation empowered by the rapid advancements of the generative capabilities of LLMs is gaining growing interest for large volumes of legacy C code. Despite some success, existing LLM-based approaches have constrained the role of LLMs to static prompt-response behavior and have not explored their agentic problem-solving capability. Applying the LLM agentic capability for the C-to-Rust translation introduces distinct challenges, as this task differs from the traditional LLM agent applications, such as math or commonsense QA domains. First, the scarcity of parallel C-to-Rust datasets hinders the retrieval of suitable code translation exemplars for in-context learning. Second, unlike math or commonsense QA, the intermediate steps required for C-to-Rust are not well-defined. Third, it remains unclear how to organize and cascade these intermediate steps to construct a correct translation trajectory. To address these challenges in the C-to-Rust translation, we propose a novel intermediate step, the Virtual Fuzzing-based equivalence Test (VFT), and an agentic planning framework, the LLM-powered Agent for C-to-Rust code translation (LAC2R). The VFT guides LLMs to identify input arguments that induce divergent behaviors between an original C function and its Rust counterpart and to generate informative diagnoses to refine the unsafe Rust code. LAC2R uses the MCTS to systematically organize the LLM-induced intermediate steps for correct translation. We experimentally demonstrated that LAC2R effectively conducts C-to-Rust translation on large-scale, real-world benchmarks.","authors":["HoHyun Sim","Hyeonjoong Cho","Yeonghyeon Go","Zhoulai Fu","Ali Shokri","Binoy Ravindran"],"url":"https://arxiv.org/abs/2505.15858"}
{"created":"2025-05-23","title":"AutoData: A Multi-Agent System for Open Web Data Collection","abstract":"The exponential growth of data-driven systems and AI technologies has intensified the demand for high-quality web-sourced datasets. While existing datasets have proven valuable, conventional web data collection approaches face significant limitations in terms of human effort and scalability. Current data-collecting solutions fall into two categories: wrapper-based methods that struggle with adaptability and reproducibility, and large language model (LLM)-based approaches that incur substantial computational and financial costs. To address these challenges, we propose AutoData, a novel multi-agent system for Automated web Data collection, that requires minimal human intervention, i.e., only necessitating a natural language instruction specifying the desired dataset. In addition, AutoData is designed with a robust multi-agent architecture, featuring a novel oriented message hypergraph coordinated by a central task manager, to efficiently organize agents across research and development squads. Besides, we introduce a novel hypergraph cache system to advance the multi-agent collaboration process that enables efficient automated data collection and mitigates the token cost issues prevalent in existing LLM-based systems. Moreover, we introduce Instruct2DS, a new benchmark dataset supporting live data collection from web sources across three domains: academic, finance, and sports. Comprehensive evaluations over Instruct2DS and three existing benchmark datasets demonstrate AutoData's superior performance compared to baseline methods. Case studies on challenging tasks such as picture book collection and paper extraction from surveys further validate its applicability. Our source code and dataset are available at https://github.com/GraphResearcher/AutoData.","authors":["Tianyi Ma","Yiyue Qian","Zheyuan Zhang","Zehong Wang","Xiaoye Qian","Feifan Bai","Yifan Ding","Xuwei Luo","Shinan Zhang","Keerthiram Murugesan","Chuxu Zhang","Yanfang Ye"],"url":"https://arxiv.org/abs/2505.15859"}
{"created":"2025-05-23","title":"Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems","abstract":"Algorithms designed for routing problems typically rely on high-quality candidate edges to guide their search, aiming to reduce the search space and enhance the search efficiency. However, many existing algorithms, like the classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman Problem (TSP), often use predetermined candidate edges that remain static throughout local searches. This rigidity could cause the algorithm to get trapped in local optima, limiting its potential to find better solutions. To address this issue, we propose expanding the candidate sets to include other promising edges, providing them an opportunity for selection. Specifically, we incorporate multi-armed bandit models to dynamically select the most suitable candidate edges in each iteration, enabling LKH to make smarter choices and lead to improved solutions. Extensive experiments on multiple TSP benchmarks show the excellent performance of our method. Moreover, we employ this bandit-based method to LKH-3, an extension of LKH tailored for solving various TSP variant problems, and our method also significantly enhances LKH-3's performance across typical TSP variants.","authors":["Long Wanga","Jiongzhi Zheng","Zhengda Xiong","ChuMin Li","Kun He"],"url":"https://arxiv.org/abs/2505.15862"}
{"created":"2025-05-23","title":"Generative AI for Autonomous Driving: A Review","abstract":"Generative AI (GenAI) is rapidly advancing the field of Autonomous Driving (AD), extending beyond traditional applications in text, image, and video generation. We explore how generative models can enhance automotive tasks, such as static map creation, dynamic scenario generation, trajectory forecasting, and vehicle motion planning. By examining multiple generative approaches ranging from Variational Autoencoder (VAEs) over Generative Adversarial Networks (GANs) and Invertible Neural Networks (INNs) to Generative Transformers (GTs) and Diffusion Models (DMs), we highlight and compare their capabilities and limitations for AD-specific applications. Additionally, we discuss hybrid methods integrating conventional techniques with generative approaches, and emphasize their improved adaptability and robustness. We also identify relevant datasets and outline open research questions to guide future developments in GenAI. Finally, we discuss three core challenges: safety, interpretability, and realtime capabilities, and present recommendations for image generation, dynamic scenario generation, and planning.","authors":["Katharina Winter","Abhishek Vivekanandan","Rupert Polley","Yinzhe Shen","Christian Schlauch","Mohamed-Khalil Bouzidi","Bojan Derajic","Natalie Grabowsky","Annajoyce Mariani","Dennis Rochau","Giovanni Lucente","Harsh Yadav","Firas Mualla","Adam Molin","Sebastian Bernhard","Christian Wirth","\\\"Omer \\c{S}ahin Ta\\c{s}","Nadja Klein","Fabian B. Flohr","Hanno Gottschalk"],"url":"https://arxiv.org/abs/2505.15863"}
{"created":"2025-05-23","title":"How Do Large Vision-Language Models See Text in Image? Unveiling the Distinctive Role of OCR Heads","abstract":"Despite significant advancements in Large Vision Language Models (LVLMs), a gap remains, particularly regarding their interpretability and how they locate and interpret textual information within images. In this paper, we explore various LVLMs to identify the specific heads responsible for recognizing text from images, which we term the Optical Character Recognition Head (OCR Head). Our findings regarding these heads are as follows: (1) Less Sparse: Unlike previous retrieval heads, a large number of heads are activated to extract textual information from images. (2) Qualitatively Distinct: OCR heads possess properties that differ significantly from general retrieval heads, exhibiting low similarity in their characteristics. (3) Statically Activated: The frequency of activation for these heads closely aligns with their OCR scores. We validate our findings in downstream tasks by applying Chain-of-Thought (CoT) to both OCR and conventional retrieval heads and by masking these heads. We also demonstrate that redistributing sink-token values within the OCR heads improves performance. These insights provide a deeper understanding of the internal mechanisms LVLMs employ in processing embedded textual information in images.","authors":["Ingeol Baek","Hwan Chang","Sunghyun Ryu","Hwanhee Lee"],"url":"https://arxiv.org/abs/2505.15865"}
{"created":"2025-05-23","title":"SCENIR: Visual Semantic Clarity through Unsupervised Scene Graph Retrieval","abstract":"Despite the dominance of convolutional and transformer-based architectures in image-to-image retrieval, these models are prone to biases arising from low-level visual features, such as color. Recognizing the lack of semantic understanding as a key limitation, we propose a novel scene graph-based retrieval framework that emphasizes semantic content over superficial image characteristics. Prior approaches to scene graph retrieval predominantly rely on supervised Graph Neural Networks (GNNs), which require ground truth graph pairs driven from image captions. However, the inconsistency of caption-based supervision stemming from variable text encodings undermine retrieval reliability. To address these, we present SCENIR, a Graph Autoencoder-based unsupervised retrieval framework, which eliminates the dependence on labeled training data. Our model demonstrates superior performance across metrics and runtime efficiency, outperforming existing vision-based, multimodal, and supervised GNN approaches. We further advocate for Graph Edit Distance (GED) as a deterministic and robust ground truth measure for scene graph similarity, replacing the inconsistent caption-based alternatives for the first time in image-to-image retrieval evaluation. Finally, we validate the generalizability of our method by applying it to unannotated datasets via automated scene graph generation, while substantially contributing in advancing state-of-the-art in counterfactual image retrieval.","authors":["Nikolaos Chaidos","Angeliki Dimitriou","Maria Lymperaiou","Giorgos Stamou"],"url":"https://arxiv.org/abs/2505.15867"}
{"created":"2025-05-23","title":"Satellites Reveal Mobility: A Commuting Origin-destination Flow Generator for Global Cities","abstract":"Commuting Origin-destination~(OD) flows, capturing daily population mobility of citizens, are vital for sustainable development across cities around the world. However, it is challenging to obtain the data due to the high cost of travel surveys and privacy concerns. Surprisingly, we find that satellite imagery, publicly available across the globe, contains rich urban semantic signals to support high-quality OD flow generation, with over 98\\% expressiveness of traditional multisource hard-to-collect urban sociodemographic, economics, land use, and point of interest data. This inspires us to design a novel data generator, GlODGen, which can generate OD flow data for any cities of interest around the world. Specifically, GlODGen first leverages Vision-Language Geo-Foundation Models to extract urban semantic signals related to human mobility from satellite imagery. These features are then combined with population data to form region-level representations, which are used to generate OD flows via graph diffusion models. Extensive experiments on 4 continents and 6 representative cities show that GlODGen has great generalizability across diverse urban environments on different continents and can generate OD flow data for global cities highly consistent with real-world mobility data. We implement GlODGen as an automated tool, seamlessly integrating data acquisition and curation, urban semantic feature extraction, and OD flow generation together. It has been released at https://github.com/tsinghua-fib-lab/generate-od-pubtools.","authors":["Can Rong","Xin Zhang","Yanxin Xi","Hongjie Sui","Jingtao Ding","Yong Li"],"url":"https://arxiv.org/abs/2505.15870"}
{"created":"2025-05-23","title":"InfoDeepSeek: Benchmarking Agentic Information Seeking for Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by grounding responses with retrieved information. As an emerging paradigm, Agentic RAG further enhances this process by introducing autonomous LLM agents into the information seeking process. However, existing benchmarks fall short in evaluating such systems, as they are confined to a static retrieval environment with a fixed, limited corpus} and simple queries that fail to elicit agentic behavior. Moreover, their evaluation protocols assess information seeking effectiveness by pre-defined gold sets of documents, making them unsuitable for the open-ended and dynamic nature of real-world web environments. To bridge this gap, we present InfoDeepSeek, a new benchmark with challenging questions designed for assessing agentic information seeking in real-world, dynamic web environments. We propose a systematic methodology for constructing challenging queries satisfying the criteria of determinacy, difficulty, and diversity. Based on this, we develop the first evaluation framework tailored to dynamic agentic information seeking, including fine-grained metrics about the accuracy, utility, and compactness of information seeking outcomes. Through extensive experiments across LLMs, search engines, and question types, InfoDeepSeek reveals nuanced agent behaviors and offers actionable insights for future research.","authors":["Yunjia Xi","Jianghao Lin","Menghui Zhu","Yongzhao Xiao","Zhuoying Ou","Jiaqi Liu","Tong Wan","Bo Chen","Weiwen Liu","Yasheng Wang","Ruiming Tang","Weinan Zhang","Yong Yu"],"url":"https://arxiv.org/abs/2505.15872"}
{"created":"2025-05-23","title":"Abstraction-of-Thought: Intermediate Representations for LLM Reasoning in Hardware Design","abstract":"Large language models (LLMs) have achieved impressive proficiency on logic and programming tasks, often rivaling expert-level performance. However, generating functionally correct hardware description language (HDL) code from natural language specifications remains challenging, primarily in data-scarce domains.","authors":["Matthew DeLorenzo","Kevin Tieu","Prithwish Jana","Piyush Jha","Dileep Kalathil","Vijay Ganesh","Jeyavijayan Rajendran"],"url":"https://arxiv.org/abs/2505.15873"}
{"created":"2025-05-23","title":"Text-to-Pipeline: Bridging Natural Language and Data Preparation Pipelines","abstract":"Data preparation (DP) transforms raw data into a form suitable for downstream applications, typically by composing operations into executable pipelines. Building such pipelines is time-consuming and requires sophisticated programming skills. If we can build the pipelines with natural language (NL), the technical barrier of DP will be significantly reduced. However, constructing DP pipelines from NL instructions remains underexplored. To fill the gap, we introduce Text-to-Pipeline, a new task that translates NL data preparation instructions into DP pipelines. Furthermore, we develop a benchmark named PARROT to support systematic evaluation. To simulate realistic DP scenarios, we mined transformation patterns from production pipelines and instantiated them on 23,009 real-world tables collected from six public sources. The resulting benchmark comprises ~18,000 pipelines covering 16 core DP operators. We evaluated cutting-edge large language models on PARROTand observed that they only solved 72.86% of the cases, revealing notable limitations in instruction understanding and multi-step reasoning. To address this, we propose Pipeline-Agent, a stronger baseline that iteratively predicts and executes operations with intermediate table feedback, achieving the best performance of 76.17%. Despite this improvement, there remains substantial room for progress on Text-to-Pipeline. Our data, codes, and evaluation tools are available at https://anonymous.4open.science/r/Text-to-Pipeline.","authors":["Yuhang Ge","Yachuan Liu","Yuren Mao","Yunjun Gao"],"url":"https://arxiv.org/abs/2505.15874"}
{"created":"2025-05-23","title":"Decouple and Orthogonalize: A Data-Free Framework for LoRA Merging","abstract":"With more open-source models available for diverse tasks, model merging has gained attention by combining models into one, reducing training, storage, and inference costs. Current research mainly focuses on model merging for full fine-tuning, overlooking the popular LoRA. However, our empirical analysis reveals that: a) existing merging methods designed for full fine-tuning perform poorly on LoRA; b) LoRA modules show much larger parameter magnitude variance than full fine-tuned weights; c) greater parameter magnitude variance correlates with worse merging performance. Considering that large magnitude variances cause deviations in the distribution of the merged parameters, resulting in information loss and performance degradation, we propose a Decoupled and Orthogonal merging approach(DO-Merging). By separating parameters into magnitude and direction components and merging them independently, we reduce the impact of magnitude differences on the directional alignment of the merged models, thereby preserving task information. Furthermore, we introduce a data-free, layer-wise gradient descent method with orthogonal constraints to mitigate interference during the merging of direction components. We provide theoretical guarantees for both the decoupling and orthogonal components. And we validate through extensive experiments across vision, language, and multi-modal domains that our proposed DO-Merging can achieve significantly higher performance than existing merging methods at a minimal cost. Notably, each component can be flexibly integrated with existing methods, offering near free-lunch improvements across tasks.","authors":["Shenghe Zheng","Hongzhi Wang","Chenyu Huang","Xiaohui Wang","Tao Chen","Jiayuan Fan","Shuyue Hu","Peng Ye"],"url":"https://arxiv.org/abs/2505.15875"}
{"created":"2025-05-23","title":"Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval","abstract":"While an image is worth more than a thousand words, only a few provide crucial information for a given task and thus should be focused on. In light of this, ideal text-to-image (T2I) retrievers should prioritize specific visual attributes relevant to queries. To evaluate current retrievers on handling attribute-focused queries, we build COCO-Facet, a COCO-based benchmark with 9,112 queries about diverse attributes of interest. We find that CLIP-like retrievers, which are widely adopted due to their efficiency and zero-shot ability, have poor and imbalanced performance, possibly because their image embeddings focus on global semantics and subjects while leaving out other details. Notably, we reveal that even recent Multimodal Large Language Model (MLLM)-based, stronger retrievers with a larger output dimension struggle with this limitation. Hence, we hypothesize that retrieving with general image embeddings is suboptimal for performing such queries. As a solution, we propose to use promptable image embeddings enabled by these multimodal retrievers, which boost performance by highlighting required attributes. Our pipeline for deriving such embeddings generalizes across query types, image pools, and base retriever architectures. To enhance real-world applicability, we offer two acceleration strategies: Pre-processing promptable embeddings and using linear approximations. We show that the former yields a 15% improvement in Recall@5 when prompts are predefined, while the latter achieves an 8% improvement when prompts are only available during inference.","authors":["Siting Li","Xiang Gao","Simon Shaolei Du"],"url":"https://arxiv.org/abs/2505.15877"}
{"created":"2025-05-23","title":"GRIT: Teaching MLLMs to Think with Images","abstract":"Recent studies have demonstrated the efficacy of using Reinforcement Learning (RL) in building reasoning models that articulate chains of thoughts prior to producing final answers. However, despite ongoing advances that aim at enabling reasoning for vision-language tasks, existing open-source visual reasoning models typically generate reasoning content with pure natural language, lacking explicit integration of visual information. This limits their ability to produce clearly articulated and visually grounded reasoning chains. To this end, we propose Grounded Reasoning with Images and Texts (GRIT), a novel method for training MLLMs to think with images. GRIT introduces a grounded reasoning paradigm, in which models generate reasoning chains that interleave natural language and explicit bounding box coordinates. These coordinates point to regions of the input image that the model consults during its reasoning process. Additionally, GRIT is equipped with a reinforcement learning approach, GRPO-GR, built upon the GRPO algorithm. GRPO-GR employs robust rewards focused on the final answer accuracy and format of the grounded reasoning output, which eliminates the need for data with reasoning chain annotations or explicit bounding box labels. As a result, GRIT achieves exceptional data efficiency, requiring as few as 20 image-question-answer triplets from existing datasets. Comprehensive evaluations demonstrate that GRIT effectively trains MLLMs to produce coherent and visually grounded reasoning chains, showing a successful unification of reasoning and grounding abilities.","authors":["Yue Fan","Xuehai He","Diji Yang","Kaizhi Zheng","Ching-Chen Kuo","Yuting Zheng","Sravana Jyothi Narayanaraju","Xinze Guan","Xin Eric Wang"],"url":"https://arxiv.org/abs/2505.15879"}
{"created":"2025-05-23","title":"Challenger: Affordable Adversarial Driving Video Generation","abstract":"Generating photorealistic driving videos has seen significant progress recently, but current methods largely focus on ordinary, non-adversarial scenarios. Meanwhile, efforts to generate adversarial driving scenarios often operate on abstract trajectory or BEV representations, falling short of delivering realistic sensor data that can truly stress-test autonomous driving (AD) systems. In this work, we introduce Challenger, a framework that produces physically plausible yet photorealistic adversarial driving videos. Generating such videos poses a fundamental challenge: it requires jointly optimizing over the space of traffic interactions and high-fidelity sensor observations. Challenger makes this affordable through two techniques: (1) a physics-aware multi-round trajectory refinement process that narrows down candidate adversarial maneuvers, and (2) a tailored trajectory scoring function that encourages realistic yet adversarial behavior while maintaining compatibility with downstream video synthesis. As tested on the nuScenes dataset, Challenger generates a diverse range of aggressive driving scenarios-including cut-ins, sudden lane changes, tailgating, and blind spot intrusions-and renders them into multiview photorealistic videos. Extensive evaluations show that these scenarios significantly increase the collision rate of state-of-the-art end-to-end AD models (UniAD, VAD, SparseDrive, and DiffusionDrive), and importantly, adversarial behaviors discovered for one model often transfer to others.","authors":["Zhiyuan Xu","Bohan Li","Huan-ang Gao","Mingju Gao","Yong Chen","Ming Liu","Chenxu Yan","Hang Zhao","Shuo Feng","Hao Zhao"],"url":"https://arxiv.org/abs/2505.15880"}
{"created":"2025-05-23","title":"Last Layer Empirical Bayes","abstract":"The task of quantifying the inherent uncertainty associated with neural network predictions is a key challenge in artificial intelligence. Bayesian neural networks (BNNs) and deep ensembles are among the most prominent approaches to tackle this task. Both approaches produce predictions by computing an expectation of neural network outputs over some distribution on the corresponding weights; this distribution is given by the posterior in the case of BNNs, and by a mixture of point masses for ensembles. Inspired by recent work showing that the distribution used by ensembles can be understood as a posterior corresponding to a learned data-dependent prior, we propose last layer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a normalizing flow, which is then trained to maximize the evidence lower bound; to retain tractability we use the flow only on the last layer. We show why LLEB is well motivated, and how it interpolates between standard BNNs and ensembles in terms of the strength of the prior that they use. LLEB performs on par with existing approaches, highlighting that empirical Bayes is a promising direction for future research in uncertainty quantification.","authors":["Valentin Villecroze","Yixin Wang","Gabriel Loaiza-Ganem"],"url":"https://arxiv.org/abs/2505.15888"}
{"created":"2025-05-23","title":"Capacitated Fair-Range Clustering: Hardness and Approximation Algorithms","abstract":"Capacitated fair-range $k$-clustering generalizes classical $k$-clustering by incorporating both capacity constraints and demographic fairness. In this setting, each facility has a capacity limit and may belong to one or more demographic groups. The task is to select $k$ facilities as centers and assign each client to a center such that: ($a$) no center exceeds its capacity, ($b$) the number of centers selected from each group lies within specified lower and upper bounds (fair-range constraints), and ($c$) the clustering cost (e.g., $k$-median or $k$-means) is minimized.","authors":["Ameet Gadekar","Suhas Thejaswi"],"url":"https://arxiv.org/abs/2505.15905"}
{"created":"2025-05-23","title":"Is (Selective) Round-To-Nearest Quantization All You Need?","abstract":"Quantization became a necessary tool for serving ever-increasing Large Language Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest quantization technique that has been around well before LLMs surged to the forefront of machine learning (ML) research. Yet, it has been largely dismissed by recent and more advanced quantization methods that claim superiority over RTN in nearly every aspect of performance. This work aims to dispel this established point of view, showing that RTN is not only much cheaper to apply, but also its token generation throughput can be better than and accuracy can be similar to more advanced alternatives. In particular, we discuss our implementation of RTN based on the recent Marlin kernels and demonstrate how the accuracy of RTN can be gradually improved by selectively increasing the data precision format of certain model layers and modules. Based on our results, we argue that RTN presents a viable and practical choice for quantizing LLMs.","authors":["Alex Kogan"],"url":"https://arxiv.org/abs/2505.15909"}
{"created":"2025-05-23","title":"A Novel Deep Learning Framework for Efficient Multichannel Acoustic Feedback Control","abstract":"This study presents a deep-learning framework for controlling multichannel acoustic feedback in audio devices. Traditional digital signal processing methods struggle with convergence when dealing with highly correlated noise such as feedback. We introduce a Convolutional Recurrent Network that efficiently combines spatial and temporal processing, significantly enhancing speech enhancement capabilities with lower computational demands. Our approach utilizes three training methods: In-a-Loop Training, Teacher Forcing, and a Hybrid strategy with a Multichannel Wiener Filter, optimizing performance in complex acoustic environments. This scalable framework offers a robust solution for real-world applications, making significant advances in Acoustic Feedback Control technology.","authors":["Yuan-Kuei Wu","Juan Azcarreta","Kashyap Patel","Buye Xu","Jung-Suk Lee","Sanha Lee","Ashutosh Pandey"],"url":"https://arxiv.org/abs/2505.15914"}
{"created":"2025-05-23","title":"BR-TaxQA-R: A Dataset for Question Answering with References for Brazilian Personal Income Tax Law, including case law","abstract":"This paper presents BR-TaxQA-R, a novel dataset designed to support question answering with references in the context of Brazilian personal income tax law. The dataset contains 715 questions from the 2024 official Q\\&amp;A document published by Brazil's Internal Revenue Service, enriched with statutory norms and administrative rulings from the Conselho Administrativo de Recursos Fiscais (CARF). We implement a Retrieval-Augmented Generation (RAG) pipeline using OpenAI embeddings for searching and GPT-4o-mini for answer generation. We compare different text segmentation strategies and benchmark our system against commercial tools such as ChatGPT and Perplexity.ai using RAGAS-based metrics. Results show that our custom RAG pipeline outperforms commercial systems in Response Relevancy, indicating stronger alignment with user queries, while commercial models achieve higher scores in Factual Correctness and fluency. These findings highlight a trade-off between legally grounded generation and linguistic fluency. Crucially, we argue that human expert evaluation remains essential to ensure the legal validity of AI-generated answers in high-stakes domains such as taxation. BR-TaxQA-R is publicly available at https://huggingface.co/datasets/unicamp-dl/BR-TaxQA-R.","authors":["Juvenal Domingos J\\'unior","Augusto Faria","E. Seiti de Oliveira","Erick de Brito","Matheus Teotonio","Andre Assump\\c{c}\\~ao","Diedre Carmo","Roberto Lotufo","Jayr Pereira"],"url":"https://arxiv.org/abs/2505.15916"}
{"created":"2025-05-23","title":"Extracting Probabilistic Knowledge from Large Language Models for Bayesian Network Parameterization","abstract":"Large Language Models (LLMs) have demonstrated potential as factual knowledge bases; however, their capability to generate probabilistic knowledge about real-world events remains understudied. This paper investigates using probabilistic knowledge inherent in LLMs to derive probability estimates for statements concerning events and their interrelationships captured via a Bayesian Network (BN). Using LLMs in this context allows for the parameterization of BNs, enabling probabilistic modeling within specific domains. Experiments on eighty publicly available Bayesian Networks, from healthcare to finance, demonstrate that querying LLMs about the conditional probabilities of events provides meaningful results when compared to baselines, including random and uniform distributions, as well as approaches based on next-token generation probabilities. We explore how these LLM-derived distributions can serve as expert priors to refine distributions extracted from minimal data, significantly reducing systematic biases. Overall, this work introduces a promising strategy for automatically constructing Bayesian Networks by combining probabilistic knowledge extracted from LLMs with small amounts of real-world data. Additionally, we evaluate several prompting strategies for eliciting probabilistic knowledge from LLMs and establish the first comprehensive baseline for assessing LLM performance in extracting probabilistic knowledge.","authors":["Aliakbar Nafar","Kristen Brent Venable","Zijun Cui","Parisa Kordjamshidi"],"url":"https://arxiv.org/abs/2505.15918"}
{"created":"2025-05-23","title":"Defining Atomicity (and Integrity) for Snapshots of Storage in Forensic Computing","abstract":"The acquisition of data from main memory or from hard disk storage is usually one of the first steps in a forensic investigation. We revisit the discussion on quality criteria for \"forensically sound\" acquisition of such storage and propose a new way to capture the intent to acquire an instantaneous snapshot from a single target system. The idea of our definition is to allow a certain flexibility into when individual portions of memory are acquired, but at the same time require being consistent with causality (i.e., cause/effect relations). Our concept is much stronger than the original notion of atomicity defined by Vomel and Freiling (2012) but still attainable using copy-on-write mechanisms. As a minor result, we also fix a conceptual problem within the original definition of integrity.","authors":["Jenny Ottmann","Frank Breitinger","Felix Freiling"],"url":"https://arxiv.org/abs/2505.15921"}
{"created":"2025-05-23","title":"Aligning Dialogue Agents with Global Feedback via Large Language Model Reward Decomposition","abstract":"We propose a large language model based reward decomposition framework for aligning dialogue agents using only a single session-level feedback signal. We leverage the reasoning capabilities of a frozen, pretrained large language model (LLM) to infer fine-grained local implicit rewards by decomposing global, session-level feedback. Our first text-only variant prompts the LLM to perform reward decomposition using only the dialogue transcript. The second multimodal variant incorporates additional behavioral cues, such as pitch, gaze, and facial affect, expressed as natural language descriptions. These inferred turn-level rewards are distilled into a lightweight reward model, which we utilize for RL-based fine-tuning for dialogue generation. We evaluate both text-only and multimodal variants against state-of-the-art reward decomposition methods and demonstrate notable improvements in human evaluations of conversation quality, suggesting that LLMs are strong reward decomposers that obviate the need for manual reward shaping and granular human feedback.","authors":["Dong Won Lee","Hae Won Park","Cynthia Breazeal","Louis-Philippe Morency"],"url":"https://arxiv.org/abs/2505.15922"}
{"created":"2025-05-23","title":"VERDI: VLM-Embedded Reasoning for Autonomous Driving","abstract":"While autonomous driving (AD) stacks struggle with decision making under partial observability and real-world complexity, human drivers are capable of commonsense reasoning to make near-optimal decisions with limited information. Recent work has attempted to leverage finetuned Vision-Language Models (VLMs) for trajectory planning at inference time to emulate human behavior. Despite their success in benchmark evaluations, these methods are often impractical to deploy (a 70B parameter VLM inference at merely 8 tokens per second requires more than 160G of memory), and their monolithic network structure prohibits safety decomposition. To bridge this gap, we propose VLM-Embedded Reasoning for autonomous Driving (VERDI), a training-time framework that distills the reasoning process and commonsense knowledge of VLMs into the AD stack. VERDI augments modular differentiable end-to-end (e2e) AD models by aligning intermediate module outputs at the perception, prediction, and planning stages with text features explaining the driving reasoning process produced by VLMs. By encouraging alignment in latent space, \\textsc{VERDI} enables the modular AD stack to internalize structured reasoning, without incurring the inference-time costs of large VLMs. We demonstrate the effectiveness of our method on the NuScenes dataset and find that VERDI outperforms existing e2e methods that do not embed reasoning by 10% in $\\ell_{2}$ distance, while maintaining high inference speed.","authors":["Bowen Feng","Zhiting Mei","Baiang Li","Julian Ost","Roger Girgis","Anirudha Majumdar","Felix Heide"],"url":"https://arxiv.org/abs/2505.15925"}
{"created":"2025-05-23","title":"ViQAgent: Zero-Shot Video Question Answering via Agent with Open-Vocabulary Grounding Validation","abstract":"Recent advancements in Video Question Answering (VideoQA) have introduced LLM-based agents, modular frameworks, and procedural solutions, yielding promising results. These systems use dynamic agents and memory-based mechanisms to break down complex tasks and refine answers. However, significant improvements remain in tracking objects for grounding over time and decision-making based on reasoning to better align object references with language model outputs, as newer models get better at both tasks. This work presents an LLM-brained agent for zero-shot Video Question Answering (VideoQA) that combines a Chain-of-Thought framework with grounding reasoning alongside YOLO-World to enhance object tracking and alignment. This approach establishes a new state-of-the-art in VideoQA and Video Understanding, showing enhanced performance on NExT-QA, iVQA, and ActivityNet-QA benchmarks. Our framework also enables cross-checking of grounding timeframes, improving accuracy and providing valuable support for verification and increased output reliability across multiple video domains. The code is available at https://github.com/t-montes/viqagent.","authors":["Tony Montes","Fernando Lozano"],"url":"https://arxiv.org/abs/2505.15928"}
{"created":"2025-05-23","title":"PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?","abstract":"Existing benchmarks fail to capture a crucial aspect of intelligence: physical reasoning, the integrated ability to combine domain knowledge, symbolic reasoning, and understanding of real-world constraints. To address this gap, we introduce PhyX: the first large-scale benchmark designed to assess models capacity for physics-grounded reasoning in visual scenarios. PhyX includes 3K meticulously curated multimodal questions spanning 6 reasoning types across 25 sub-domains and 6 core physics domains: thermodynamics, electromagnetism, mechanics, modern physics, optics, and wave\\&amp;acoustics. In our comprehensive evaluation, even state-of-the-art models struggle significantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and GPT-o4-mini achieve only 32.5\\%, 42.2\\%, and 45.8\\% accuracy respectively-performance gaps exceeding 29\\% compared to human experts. Our analysis exposes critical limitations in current models: over-reliance on memorized disciplinary knowledge, excessive dependence on mathematical formulations, and surface-level visual pattern matching rather than genuine physical understanding. We provide in-depth analysis through fine-grained statistics, detailed case studies, and multiple evaluation paradigms to thoroughly examine physical reasoning capabilities. To ensure reproducibility, we implement a compatible evaluation protocol based on widely-used toolkits such as VLMEvalKit, enabling one-click evaluation.","authors":["Hui Shen","Taiqiang Wu","Qi Han","Yunta Hsieh","Jizhou Wang","Yuyue Zhang","Yuxin Cheng","Zijian Hao","Yuansheng Ni","Xin Wang","Zhongwei Wan","Kai Zhang","Wendong Xu","Jing Xiong","Ping Luo","Wenhu Chen","Chaofan Tao","Zhuoqing Mao","Ngai Wong"],"url":"https://arxiv.org/abs/2505.15929"}
{"created":"2025-05-23","title":"AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning","abstract":"Machine learning (ML) models rely heavily on consistent and accurate performance metrics to evaluate and compare their effectiveness. However, existing libraries often suffer from fragmentation, inconsistent implementations, and insufficient data validation protocols, leading to unreliable results. Existing libraries have often been developed independently and without adherence to a unified standard, particularly concerning the specific tasks they aim to support. As a result, each library tends to adopt its conventions for metric computation, input/output formatting, error handling, and data validation protocols. This lack of standardization leads to both implementation differences (ID) and reporting differences (RD), making it difficult to compare results across frameworks or ensure reliable evaluations. To address these issues, we introduce AllMetrics, an open-source unified Python library designed to standardize metric evaluation across diverse ML tasks, including regression, classification, clustering, segmentation, and image-to-image translation. The library implements class-specific reporting for multi-class tasks through configurable parameters to cover all use cases, while incorporating task-specific parameters to resolve metric computation discrepancies across implementations. Various datasets from domains like healthcare, finance, and real estate were applied to our library and compared with Python, Matlab, and R components to identify which yield similar results. AllMetrics combines a modular Application Programming Interface (API) with robust input validation mechanisms to ensure reproducibility and reliability in model evaluation. This paper presents the design principles, architectural components, and empirical analyses demonstrating the ability to mitigate evaluation errors and to enhance the trustworthiness of ML workflows.","authors":["Morteza Alizadeh","Mehrdad Oveisi","Sonya Falahati","Ghazal Mousavi","Mohsen Alambardar Meybodi","Somayeh Sadat Mehrnia","Ilker Hacihaliloglu","Arman Rahmim","Mohammad R. Salmanpour"],"url":"https://arxiv.org/abs/2505.15931"}
{"created":"2025-05-23","title":"Improving the Predictability of the Madden-Julian Oscillation at Subseasonal Scales with Gaussian Process Models","abstract":"The Madden--Julian Oscillation (MJO) is an influential climate phenomenon that plays a vital role in modulating global weather patterns. In spite of the improvement in MJO predictions made by machine learning algorithms, such as neural networks, most of them cannot provide the uncertainty levels in the MJO forecasts directly. To address this problem, we develop a nonparametric strategy based on Gaussian process (GP) models. We calibrate GPs using empirical correlations and we propose a posteriori covariance correction. Numerical experiments demonstrate that our model has better prediction skills than the ANN models for the first five lead days. Additionally, our posteriori covariance correction extends the probabilistic coverage by more than three weeks.","authors":["Haoyuan Chen","Emil Constantinescu","Vishwas Rao","Cristiana Stan"],"url":"https://arxiv.org/abs/2505.15934"}
{"created":"2025-05-23","title":"MAPS: A Multilingual Benchmark for Global Agent Performance and Security","abstract":"Agentic AI systems, which build on Large Language Models (LLMs) and interact with tools and memory, have rapidly advanced in capability and scope. Yet, since LLMs have been shown to struggle in multilingual settings, typically resulting in lower performance and reduced safety, agentic systems risk inheriting these limitations. This raises concerns about the global accessibility of such systems, as users interacting in languages other than English may encounter unreliable or security-critical agent behavior. Despite growing interest in evaluating agentic AI, existing benchmarks focus exclusively on English, leaving multilingual settings unexplored. To address this gap, we propose MAPS, a multilingual benchmark suite designed to evaluate agentic AI systems across diverse languages and tasks. MAPS builds on four widely used agentic benchmarks - GAIA (real-world tasks), SWE-bench (code generation), MATH (mathematical reasoning), and the Agent Security Benchmark (security). We translate each dataset into ten diverse languages, resulting in 805 unique tasks and 8,855 total language-specific instances. Our benchmark suite enables a systematic analysis of how multilingual contexts affect agent performance and robustness. Empirically, we observe consistent degradation in both performance and security when transitioning from English to other languages, with severity varying by task and correlating with the amount of translated input. Building on these findings, we provide actionable recommendations to guide agentic AI systems development and assessment under multilingual settings. This work establishes a standardized evaluation framework, encouraging future research towards equitable, reliable, and globally accessible agentic AI. MAPS benchmark suite is publicly available at https://huggingface.co/datasets/Fujitsu-FRE/MAPS","authors":["Omer Hofman","Oren Rachmil","Shamik Bose","Vikas Pahuja","Jonathan Brokman","Toshiya Shimizu","Trisha Starostina","Kelly Marchisio","Seraphina Goldfarb-Tarrant","Roman Vainshtein"],"url":"https://arxiv.org/abs/2505.15935"}
{"created":"2025-05-23","title":"Human Workload Prediction: Lag Horizon Selection","abstract":"Human-robot teams must be aware of human workload when operating in uncertain, dynamic environments. Prior work employed physiological response metrics from wearable sensors to estimate the current human workload; however, these estimates only enable robots to respond to under- or overload conditions reactively. Current human workload prediction approaches are limited to short prediction horizons and fail to investigate variable lag horizons' impact on predictions. This letter investigates the impact of lag horizons on both univariate and multivariate time series forecasting models for human workload prediction. A key finding is that univariate predictions required longer lag horizons of 240 seconds (s), whereas multivariate workload predictions sufficed with shorter lag horizons with diminishing returns around 120s.","authors":["Mark-Robin Giolando","Julie A. Adams"],"url":"https://arxiv.org/abs/2505.15939"}
{"created":"2025-05-23","title":"MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding","abstract":"Decoding visual experiences from fMRI offers a powerful avenue to understand human perception and develop advanced brain-computer interfaces. However, current progress often prioritizes maximizing reconstruction fidelity while overlooking interpretability, an essential aspect for deriving neuroscientific insight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework designed for high-fidelity, adaptable, and interpretable visual reconstruction. MoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture where distinct experts process fMRI signals from functionally related voxel groups, mimicking specialized brain networks. The experts are first trained to encode fMRI into the frozen CLIP space. A finetuned diffusion model then synthesizes images, guided by expert outputs through a novel dual-stage routing mechanism that dynamically weighs expert contributions across the diffusion process. MoRE-Brain offers three main advancements: First, it introduces a novel Mixture-of-Experts architecture grounded in brain network principles for neuro-decoding. Second, it achieves efficient cross-subject generalization by sharing core expert networks while adapting only subject-specific routers. Third, it provides enhanced mechanistic insight, as the explicit routing reveals precisely how different modeled brain regions shape the semantic and spatial attributes of the reconstructed image. Extensive experiments validate MoRE-Brain's high reconstruction fidelity, with bottleneck analyses further demonstrating its effective utilization of fMRI signals, distinguishing genuine neural decoding from over-reliance on generative priors. Consequently, MoRE-Brain marks a substantial advance towards more generalizable and interpretable fMRI-based visual decoding. Code will be publicly available soon: https://github.com/yuxiangwei0808/MoRE-Brain.","authors":["Yuxiang Wei","Yanteng Zhang","Xi Xiao","Tianyang Wang","Xiao Wang","Vince D. Calhoun"],"url":"https://arxiv.org/abs/2505.15946"}
{"created":"2025-05-23","title":"Directional Sparsity Based Statistical Channel Estimation for 6D Movable Antenna Communications","abstract":"Six-dimensional movable antenna (6DMA) is an innovative and transformative technology to improve wireless network capacity by adjusting the 3D positions and 3D rotations of antennas/surfaces (sub-arrays) based on the channel spatial distribution. For optimization of the antenna positions and rotations, the acquisition of statistical channel state information (CSI) is essential for 6DMA systems. In this paper, we unveil for the first time a new \\textbf{\\textit{directional sparsity}} property of the 6DMA channels between the base station (BS) and the distributed users, where each user has significant channel gains only with a (small) subset of 6DMA position-rotation pairs, which can receive direct/reflected signals from the user. By exploiting this property, a covariance-based algorithm is proposed for estimating the statistical CSI in terms of the average channel power at a small number of 6DMA positions and rotations. Based on such limited channel power estimation, the average channel powers for all possible 6DMA positions and rotations in the BS movement region are reconstructed by further estimating the multi-path average power and direction-of-arrival (DOA) vectors of all users. Simulation results show that the proposed directional sparsity-based algorithm can achieve higher channel power estimation accuracy than existing benchmark schemes, while requiring a lower pilot overhead.","authors":["Xiaodan Shao","Rui Zhang","Jihong Park","Tony Q. S. Quek","Robert Schober","Xuemin Shen"],"url":"https://arxiv.org/abs/2505.15947"}
{"created":"2025-05-23","title":"Citation Parsing and Analysis with Language Models","abstract":"A key type of resource needed to address global inequalities in knowledge production and dissemination is a tool that can support journals in understanding how knowledge circulates. The absence of such a tool has resulted in comparatively less information about networks of knowledge sharing in the Global South. In turn, this gap authorizes the exclusion of researchers and scholars from the South in indexing services, reinforcing colonial arrangements that de-center and minoritize those scholars. In order to support citation network tracking on a global scale, we investigate the capacity of open-weight language models to mark up manuscript citations in an indexable format. We assembled a dataset of matched plaintext and annotated citations from preprints and published research papers. Then, we evaluated a number of open-weight language models on the annotation task. We find that, even out of the box, today's language models achieve high levels of accuracy on identifying the constituent components of each citation, outperforming state-of-the-art methods. Moreover, the smallest model we evaluated, Qwen3-0.6B, can parse all fields with high accuracy in $2^5$ passes, suggesting that post-training is likely to be effective in producing small, robust citation parsing models. Such a tool could greatly improve the fidelity of citation networks and thus meaningfully improve research indexing and discovery, as well as further metascientific research.","authors":["Parth Sarin","Juan Pablo Alperin"],"url":"https://arxiv.org/abs/2505.15948"}
{"created":"2025-05-23","title":"Partial Domination in Some Geometric Intersection Graphs and Some Complexity Results","abstract":"{\\em Partial domination problem} is a generalization of the {\\em minimum dominating set problem} on graphs. Here, instead of dominating all the nodes, one asks to dominate at least a fraction of the nodes of the given graph by choosing a minimum number of nodes. For any real number $\\alpha\\in(0,1]$, $\\alpha$-partial domination problem can be proved to be NP-complete for general graphs. In this paper, we define the {\\em maximum dominating $k$-set} of a graph, which is polynomially transformable to the partial domination problem. The existence of a graph class for which the minimum dominating set problem is polynomial-time solvable, whereas the partial dominating set problem is NP-hard, is shown. We also propose polynomial-time algorithms for the maximum dominating $k$-set problem for the unit and arbitrary interval graphs. The problem can also be solved in polynomial time for the intersection graphs of a set of 2D objects intersected by a straight line, where each object is an axis-parallel unit square, as well as in the case where each object is a unit disk. Our technique also works for axis-parallel unit-height rectangle intersection graphs, where a straight line intersects all the rectangles. Finally, a parametrized algorithm for the maximum dominating $k$-set problem in a disk graph where the input disks are intersected by a straight line is proposed; here the parameter is the ratio of the diameters of the largest and smallest input disks.","authors":["Madhura Dutta","Anil Maheshwari","Subhas C. Nandy","Bodhayan Roy"],"url":"https://arxiv.org/abs/2505.15949"}
{"created":"2025-05-23","title":"Gaussian Processes in Power Systems: Techniques, Applications, and Future Works","abstract":"The increasing integration of renewable energy sources (RESs) and distributed energy resources (DERs) has significantly heightened operational complexity and uncertainty in modern power systems. Concurrently, the widespread deployment of smart meters, phasor measurement units (PMUs) and other sensors has generated vast spatiotemporal data streams, enabling advanced data-driven analytics and decision-making in grid operations. In this context, Gaussian processes (GPs) have emerged as a powerful probabilistic framework, offering uncertainty quantification, non-parametric modeling, and predictive capabilities to enhance power system analysis and control. This paper presents a comprehensive review of GP techniques and their applications in power system operation and control. GP applications are reviewed across three key domains: GP-based modeling, risk assessment, and optimization and control. These areas serve as representative examples of how GP can be utilized in power systems. Furthermore, critical challenges in GP applications are discussed, and potential research directions are outlined to facilitate future power system operations.","authors":["Bendong Tan","Tong Su","Yu Weng","Ketian Ye","Parikshit Pareek","Petr Vorobev","Hung Nyugen","Junbo Zhao","Deepjyoti Deka"],"url":"https://arxiv.org/abs/2505.15950"}
{"created":"2025-05-23","title":"VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance","abstract":"With video games now generating the highest revenues in the entertainment industry, optimizing game development workflows has become essential for the sector's sustained growth. Recent advancements in Vision-Language Models (VLMs) offer considerable potential to automate and enhance various aspects of game development, particularly Quality Assurance (QA), which remains one of the industry's most labor-intensive processes with limited automation options. To accurately evaluate the performance of VLMs in video game QA tasks and determine their effectiveness in handling real-world scenarios, there is a clear need for standardized benchmarks, as existing benchmarks are insufficient to address the specific requirements of this domain. To bridge this gap, we introduce VideoGameQA-Bench, a comprehensive benchmark that covers a wide array of game QA activities, including visual unit testing, visual regression testing, needle-in-a-haystack tasks, glitch detection, and bug report generation for both images and videos of various games. Code and data are available at: https://asgaardlab.github.io/videogameqa-bench/","authors":["Mohammad Reza Taesiri","Abhijay Ghildyal","Saman Zadtootaghaj","Nabajeet Barman","Cor-Paul Bezemer"],"url":"https://arxiv.org/abs/2505.15952"}
{"created":"2025-05-23","title":"Modular Fault-Tolerant DBMS","abstract":"The article addresses the problem of storing data in extreme environmental conditions with limited computing resources and memory. There is a requirement to create portable, fault-tolerant, modular database management systems (DBMS) that are optimized for use in embedded systems. Existing databases, such as LittleDB, LMDB, and Berkeley DB, are reviewed, and their limitations are identified. A variant of a portable DBMS is introduced to efficiently manage data in environments where computational resource usage must be minimized, while meeting specific requirements for fault tolerance and noise immunity. Common solutions for optimizing of insertion, storage and management of data are reviewed. Algorithms for fault-tolerant data encoding in RAM are implemented. An architectural solution to data storage and minimizing the impact of bit errors is proposed. Software that manages relational data in extreme conditions is developed, that allows testing and comparing results with existing solutions.","authors":["Nikolay Fot","Alexander Vinarsky"],"url":"https://arxiv.org/abs/2505.15953"}
{"created":"2025-05-23","title":"Integrating Robotic Navigation with Blockchain: A Novel PoS-Based Approach for Heterogeneous Robotic Teams","abstract":"This work explores a novel integration of blockchain methodologies with Wide Area Visual Navigation (WAVN) to address challenges in visual navigation for a heterogeneous team of mobile robots deployed for unstructured applications in agriculture, forestry, etc. Focusing on overcoming challenges such as GPS independence, environmental changes, and computational limitations, the study introduces the Proof of Stake (PoS) mechanism, commonly used in blockchain systems, into the WAVN framework \\cite{Lyons_2022}. This integration aims to enhance the cooperative navigation capabilities of robotic teams by prioritizing robot contributions based on their navigation reliability. The methodology involves a stake weight function, consensus score with PoS, and a navigability function, addressing the computational complexities of robotic cooperation and data validation. This innovative approach promises to optimize robotic teamwork by leveraging blockchain principles, offering insights into the scalability, efficiency, and overall system performance. The project anticipates significant advancements in autonomous navigation and the broader application of blockchain technology beyond its traditional financial context.","authors":["Nasim Paykari","Ali Alfatemi","Damian M. Lyons","Mohamed Rahouti"],"url":"https://arxiv.org/abs/2505.15954"}
{"created":"2025-05-23","title":"Data-driven Verification of Procedural Programs with Integer Arrays","abstract":"We address the problem of verifying automatically procedural programs manipulating parametric-size arrays of integers, encoded as a constrained Horn clauses solving problem. We propose a new algorithmic method for synthesizing loop invariants and procedure pre/post-conditions represented as universally quantified first-order formulas constraining the array elements and program variables. We adopt a data-driven approach that extends the decision tree Horn-ICE framework to handle arrays. We provide a powerful learning technique based on reducing a complex classification problem of vectors of integer arrays to a simpler classification problem of vectors of integers. The obtained classifier is generalized to get universally quantified invariants and procedure pre/post-conditions. We have implemented our method and shown its efficiency and competitiveness w.r.t. state-of-the-art tools on a significant benchmark.","authors":["Ahmed Bouajjani","Wael-Amine Boutglay","Peter Habermehl"],"url":"https://arxiv.org/abs/2505.15958"}
{"created":"2025-05-23","title":"HornStr: A string Theory Solver for Constrained Horn Clauses","abstract":"We present HornStr, the first solver for invariant synthesis for Regular Model Checking (RMC) with the specification provided in the SMT-LIB 2.6 theory of strings. It is well-known that invariant synthesis for RMC subsumes various important verification problems, including safety verification for parameterized systems. To achieve a simple and standardized file format, we treat the invariant synthesis problem as a problem of solving Constrained Horn Clauses (CHCs) over strings. Two strategies for synthesizing invariants in terms of regular constraints are supported: (1) L* automata learning, and (2) SAT-based automata learning. HornStr implements these strategies with the help of existing SMT solvers for strings, which are interfaced through SMT-LIB. HornStr provides an easy-to-use interface for string solver developers to apply their techniques to verification and at the same time verification researchers to painlessly tap into the wealth of modern string solving techniques. To assess the effectiveness of HornStr, we conducted a comprehensive evaluation using benchmarks derived from applications including parameterized verification and string rewriting tasks. Our experiments highlight HornStr's capacity to effectively handle these benchmarks, e.g., as the first solver to verify the challenging MU puzzle automatically. Finally, HornStr can be used to automatically generate a new class of interesting SMT-LIB 2.6 string constraint benchmarks, which might in the future be used in the SMT-COMP strings track. In particular, our experiments on the above invariant synthesis benchmarks produce more than 30000 new QF_S constraints. We also detail the performance of various integrated string solvers, providing insights into their effectiveness on our new benchmarks.","authors":["Hongjian Jiang","Anthony W. Lin","Oliver Markgraf","Philipp R\\\"ummer","Daniel Stan"],"url":"https://arxiv.org/abs/2505.15959"}
{"created":"2025-05-23","title":"Training Step-Level Reasoning Verifiers with Formal Verification Tools","abstract":"Process Reward Models (PRMs), which provide step-by-step feedback on the reasoning generated by Large Language Models (LLMs), are receiving increasing attention. However, two key research gaps remain: collecting accurate step-level error labels for training typically requires costly human annotation, and existing PRMs are limited to math reasoning problems. In response to these gaps, this paper aims to address the challenges of automatic dataset creation and the generalization of PRMs to diverse reasoning tasks. To achieve this goal, we propose FoVer, an approach for training PRMs on step-level error labels automatically annotated by formal verification tools, such as Z3 for formal logic and Isabelle for theorem proof, which provide automatic and accurate verification for symbolic tasks. Using this approach, we synthesize a training dataset with error labels on LLM responses for formal logic and theorem proof tasks without human annotation. Although this data synthesis is feasible only for tasks compatible with formal verification, we observe that LLM-based PRMs trained on our dataset exhibit cross-task generalization, improving verification across diverse reasoning tasks. Specifically, PRMs trained with FoVer significantly outperform baseline PRMs based on the original LLMs and achieve competitive or superior results compared to state-of-the-art PRMs trained on labels annotated by humans or stronger models, as measured by step-level verification on ProcessBench and Best-of-K performance across 12 reasoning benchmarks, including MATH, AIME, ANLI, MMLU, and BBH. The datasets, models, and code are provided at https://github.com/psunlpgroup/FoVer.","authors":["Ryo Kamoi","Yusen Zhang","Nan Zhang","Sarkar Snigdha Sarathi Das","Rui Zhang"],"url":"https://arxiv.org/abs/2505.15960"}
{"created":"2025-05-23","title":"Super-Resolution with Structured Motion","abstract":"We consider the limits of super-resolution using imaging constraints. Due to various theoretical and practical limitations, reconstruction-based methods have been largely restricted to small increases in resolution. In addition, motion-blur is usually seen as a nuisance that impedes super-resolution. We show that by using high-precision motion information, sparse image priors, and convex optimization, it is possible to increase resolution by large factors. A key operation in super-resolution is deconvolution with a box. In general, convolution with a box is not invertible. However, we obtain perfect reconstructions of sparse signals using convex optimization. We also show that motion blur can be helpful for super-resolution. We demonstrate that using pseudo-random motion it is possible to reconstruct a high-resolution target using a single low-resolution image. We present numerical experiments with simulated data and results with real data captured by a camera mounted on a computer controlled stage.","authors":["Gabby Litterio","Juan-David Lizarazo-Ferro","Pedro Felzenszwalb","Rashid Zia"],"url":"https://arxiv.org/abs/2505.15961"}
{"created":"2025-05-23","title":"Pre-training Large Memory Language Models with Internal and External Knowledge","abstract":"Neural language models are black-boxes -- both linguistic patterns and factual knowledge are distributed across billions of opaque parameters. This entangled encoding makes it difficult to reliably inspect, verify, or update specific facts. We propose a new class of language models, Large Memory Language Models (LMLM) with a pre-training recipe that stores factual knowledge in both internal weights and an external database. Our approach strategically masks externally retrieved factual values from the training loss, thereby teaching the model to perform targeted lookups rather than relying on memorization in model weights. Our experiments demonstrate that LMLMs achieve competitive performance compared to significantly larger, knowledge-dense LLMs on standard benchmarks, while offering the advantages of explicit, editable, and verifiable knowledge bases. This work represents a fundamental shift in how language models interact with and manage factual knowledge.","authors":["Linxi Zhao","Sofian Zalouk","Christian K. Belardi","Justin Lovelace","Jin Peng Zhou","Kilian Q. Weinberger","Yoav Artzi","Jennifer J. Sun"],"url":"https://arxiv.org/abs/2505.15962"}
{"created":"2025-05-23","title":"OViP: Online Vision-Language Preference Learning","abstract":"Large vision-language models (LVLMs) remain vulnerable to hallucination, often generating content misaligned with visual inputs. While recent approaches advance multi-modal Direct Preference Optimization (DPO) to mitigate hallucination, they typically rely on predefined or randomly edited negative samples that fail to reflect actual model errors, limiting training efficacy. In this work, we propose an Online Vision-language Preference Learning (OViP) framework that dynamically constructs contrastive training data based on the model's own hallucinated outputs. By identifying semantic differences between sampled response pairs and synthesizing negative images using a diffusion model, OViP generates more relevant supervision signals in real time. This failure-driven training enables adaptive alignment of both textual and visual preferences. Moreover, we refine existing evaluation protocols to better capture the trade-off between hallucination suppression and expressiveness. Experiments on hallucination and general benchmarks demonstrate that OViP effectively reduces hallucinations while preserving core multi-modal capabilities.","authors":["Shujun Liu","Siyuan Wang","Zejun Li","Jianxiang Wang","Cheng Zeng","Zhongyu Wei"],"url":"https://arxiv.org/abs/2505.15963"}
{"created":"2025-05-23","title":"Pixel Reasoner: Incentivizing Pixel-Space Reasoning with Curiosity-Driven Reinforcement Learning","abstract":"Chain-of-thought reasoning has significantly improved the performance of Large Language Models (LLMs) across various domains. However, this reasoning process has been confined exclusively to textual space, limiting its effectiveness in visually intensive tasks. To address this limitation, we introduce the concept of reasoning in the pixel-space. Within this novel framework, Vision-Language Models (VLMs) are equipped with a suite of visual reasoning operations, such as zoom-in and select-frame. These operations enable VLMs to directly inspect, interrogate, and infer from visual evidences, thereby enhancing reasoning fidelity for visual tasks. Cultivating such pixel-space reasoning capabilities in VLMs presents notable challenges, including the model's initially imbalanced competence and its reluctance to adopt the newly introduced pixel-space operations. We address these challenges through a two-phase training approach. The first phase employs instruction tuning on synthesized reasoning traces to familiarize the model with the novel visual operations. Following this, a reinforcement learning (RL) phase leverages a curiosity-driven reward scheme to balance exploration between pixel-space reasoning and textual reasoning. With these visual operations, VLMs can interact with complex visual inputs, such as information-rich images or videos to proactively gather necessary information. We demonstrate that this approach significantly improves VLM performance across diverse visual reasoning benchmarks. Our 7B model, \\model, achieves 84\\% on V* bench, 74\\% on TallyQA-Complex, and 84\\% on InfographicsVQA, marking the highest accuracy achieved by any open-source model to date. These results highlight the importance of pixel-space reasoning and the effectiveness of our framework.","authors":["Alex Su","Haozhe Wang","Weimin Ren","Fangzhen Lin","Wenhu Chen"],"url":"https://arxiv.org/abs/2505.15966"}
{"created":"2025-05-23","title":"Analyzing Hierarchical Structure in Vision Models with Sparse Autoencoders","abstract":"The ImageNet hierarchy provides a structured taxonomy of object categories, offering a valuable lens through which to analyze the representations learned by deep vision models. In this work, we conduct a comprehensive analysis of how vision models encode the ImageNet hierarchy, leveraging Sparse Autoencoders (SAEs) to probe their internal representations. SAEs have been widely used as an explanation tool for large language models (LLMs), where they enable the discovery of semantically meaningful features. Here, we extend their use to vision models to investigate whether learned representations align with the ontological structure defined by the ImageNet taxonomy. Our results show that SAEs uncover hierarchical relationships in model activations, revealing an implicit encoding of taxonomic structure. We analyze the consistency of these representations across different layers of the popular vision foundation model DINOv2 and provide insights into how deep vision models internalize hierarchical category information by increasing information in the class token through each layer. Our study establishes a framework for systematic hierarchical analysis of vision model representations and highlights the potential of SAEs as a tool for probing semantic structure in deep networks.","authors":["Matthew Lyle Olson","Musashi Hinck","Neale Ratzlaff","Changbai Li","Phillip Howard","Vasudev Lal","Shao-Yen Tseng"],"url":"https://arxiv.org/abs/2505.15970"}
{"created":"2025-05-23","title":"A Paradigm for Creative Ownership","abstract":"As generative AI tools become more integrated into creative workflows, questions of ownership in co-creative contexts have become increasingly urgent. While legal frameworks offer definitions of ownership rooted in intellectual property, they often overlook the nuanced, psychological experience of creative ownership - how individuals come to feel that a creative product is \"theirs.\" Drawing on interdisciplinary literature in philosophy, psychology, and the social sciences and humanities more broadly, we introduce a new framework that surfaces the material and immaterial dimensions of creative ownership. Our model organizes creative ownership into three domains - Person, Process, and System - each of which contains subdimensions that shape ownership sentiment. We offer an accompanying interactive tool that enables creators and researchers to visualize and evaluate ownership across a range of contexts. This paradigm provides a new lens through which to understand and support creative agency in human-AI collaboration, and lays the groundwork for future empirical research in design and human-computer interaction.","authors":["Tejaswi Polimetla","Katy Ilonka Gero"],"url":"https://arxiv.org/abs/2505.15971"}
{"created":"2025-05-23","title":"An Exploratory Study on Multi-modal Generative AI in AR Storytelling","abstract":"Storytelling in AR has gained attention due to its multi-modality and interactivity. However, generating multi-modal content for AR storytelling requires expertise and efforts for high-quality conveyance of the narrator's intention. Recently, Generative-AI (GenAI) has shown promising applications in multi-modal content generation. Despite the potential benefit, current research calls for validating the effect of AI-generated content (AIGC) in AR Storytelling. Therefore, we conducted an exploratory study to investigate the utilization of GenAI. Analyzing 223 AR videos, we identified a design space for multi-modal AR Storytelling. Based on the design space, we developed a testbed facilitating multi-modal content generation and atomic elements in AR Storytelling. Through two studies with N=30 experienced storytellers and live presenters, we 1. revealed participants' preferences for modalities, 2. evaluated the interactions with AI to generate content, and 3. assessed the quality of the AIGC for AR Storytelling. We further discussed design considerations for future AR Storytelling with GenAI.","authors":["Hyungjun Doh","Jingyu Shi","Rahul Jain","Heesoo Kim","Karthik Ramani"],"url":"https://arxiv.org/abs/2505.15973"}
{"created":"2025-05-23","title":"Real-Time Stress Monitoring, Detection, and Management in College Students: A Wearable Technology and Machine-Learning Approach","abstract":"College students are increasingly affected by stress, anxiety, and depression, yet face barriers to traditional mental health care. This study evaluated the efficacy of a mobile health (mHealth) intervention, Mental Health Evaluation and Lookout Program (mHELP), which integrates a smartwatch sensor and machine learning (ML) algorithms for real-time stress detection and self-management. In a 12-week randomized controlled trial (n = 117), participants were assigned to a treatment group using mHELP's full suite of interventions or a control group using the app solely for real-time stress logging and weekly psychological assessments. The primary outcome, \"Moments of Stress\" (MS), was assessed via physiological and self-reported indicators and analyzed using Generalized Linear Mixed Models (GLMM) approaches. Similarly, secondary outcomes of psychological assessments, including the Generalized Anxiety Disorder-7 (GAD-7) for anxiety, the Patient Health Questionnaire (PHQ-8) for depression, and the Perceived Stress Scale (PSS), were also analyzed via GLMM. The finding of the objective measure, MS, indicates a substantial decrease in MS among the treatment group compared to the control group, while no notable between-group differences were observed in subjective scores of anxiety (GAD-7), depression (PHQ-8), or stress (PSS). However, the treatment group exhibited a clinically meaningful decline in GAD-7 and PSS scores. These findings underscore the potential of wearable-enabled mHealth tools to reduce acute stress in college populations and highlight the need for extended interventions and tailored features to address chronic symptoms like depression.","authors":["Alan Ta","Nilsu Salgin","Mustafa Demir","Kala Philips Randal","Ranjana K. Mehta","Anthony McDonald","Carly McCord","Farzan Sasangohar"],"url":"https://arxiv.org/abs/2505.15974"}
{"created":"2025-05-23","title":"A Hierarchical Optimization Framework Using Deep Reinforcement Learning for Task-Driven Bandwidth Allocation in 5G Teleoperation","abstract":"The evolution of 5G wireless technology has revolutionized connectivity, enabling a diverse range of applications. Among these are critical use cases such as real time teleoperation, which demands ultra reliable low latency communications (URLLC) to ensure precise and uninterrupted control, and enhanced mobile broadband (eMBB) services, which cater to data-intensive applications requiring high throughput and bandwidth. In our scenario, there are two queues, one for eMBB users and one for URLLC users. In teleoperation tasks, control commands are received in the URLLC queue, where communication delays occur. The dynamic index (DI) controls the service rate, affecting the telerobotic (URLLC) queue. A separate queue models eMBB data traffic. Both queues are managed through network slicing and application delay constraints, leading to a unified Lagrangian-based Lyapunov optimization for efficient resource allocation. We propose a DRL based hierarchical optimization framework that consists of two levels. At the first level, network optimization dynamically allocates resources for eMBB and URLLC users using a Lagrangian functional and an actor critic network to balance competing objectives. At the second level, control optimization finetunes the best gains for robots, ensuring stability and responsiveness in network conditions. This hierarchical approach enhances both communication and control processes, ensuring efficient resource utilization and optimized performance across the network.","authors":["Narges Golmohammadi","Madan Mohan Rayguru","Sabur Baidya"],"url":"https://arxiv.org/abs/2505.15977"}
{"created":"2025-05-23","title":"A Quantum-Enhanced Power Flow and Optimal Power Flow based on Combinatorial Reformulation","abstract":"This study introduces the Adiabatic Quantum Power Flow (AQPF) and Adiabatic Quantum Optimal Power Flow (AQOPF) algorithms to solve power flow (PF) and optimal power flow (OPF) problems, respectively. These algorithms utilize a novel combinatorial optimization reformulation of classical PF and OPF problems, and hence, enable their implementation on Ising machines, e.g., quantum and quantum-inspired hardware. The experiments are conducted on standard test cases ranging from 4-bus to 1354-bus systems, using D-Wave's Advantage system (QA), D-Wave's quantum-classical hybrid solver (HA), Fujitsu's Digital Annealer V3 (DAv3), and Fujitsu's Quantum-Inspired Integrated Optimization software (QIIO). The annealers are systematically evaluated based on: (i) full and partitioned formulations, (ii) ability to handle ill-conditioned cases, and (iii) scalability. The results are benchmarked against the Newton-Raphson numerical method (NR) and suggest that AQPF and AQOPF can serve as effective solvers or complementary tools to classical methods to address unsolved challenges in large-scale modern power systems.","authors":["Zeynab Kaseb","Matthias Moller","Peter Palensky","Pedro P. Vergara"],"url":"https://arxiv.org/abs/2505.15978"}
{"created":"2025-05-23","title":"Fast-wave slow-wave spectral deferred correction methods applied to the compressible Euler equations","abstract":"This paper investigates the application of a fast-wave slow-wave spectral deferred correction time-stepping method (FWSW-SDC) to the compressible Euler equations. The resulting model achieves arbitrary order accuracy in time, demonstrating robust performance in standard benchmark idealised test cases for dynamical cores used for numerical weather prediction. The model uses a compatible finite element spatial discretisation, achieving good linear wave dispersion properties without spurious computational modes. A convergence test confirms the model's high temporal accuracy. Arbitrarily high spatial-temporal convergence is demonstrated using a gravity wave test case. The model is further extended to include the parametrisation of a simple physics process by adding two phases of moisture and its validity is demonstrated for a rising thermal problem. Finally, a baroclinic wave in simulated in a Cartesian domain.","authors":["Alex Brown","Joscha Fregin","Thomas Bendall","Thomas Melvin","Daniel Ruprecht","Jemma Shipton"],"url":"https://arxiv.org/abs/2505.15985"}
{"created":"2025-05-23","title":"Towards Identifiability of Interventional Stochastic Differential Equations","abstract":"We study identifiability of stochastic differential equation (SDE) models under multiple interventions. Our results give the first provable bounds for unique recovery of SDE parameters given samples from their stationary distributions. We give tight bounds on the number of necessary interventions for linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime. We experimentally validate the recovery of true parameters in synthetic data, and motivated by our theoretical results, demonstrate the advantage of parameterizations with learnable activation functions.","authors":["Aaron Zweig","Zaikang Lin","Elham Azizi","David Knowles"],"url":"https://arxiv.org/abs/2505.15987"}
{"created":"2025-05-23","title":"An Ecosystem of Services for FAIR Computational Workflows","abstract":"Computational workflows, regardless of their portability or maturity, represent major investments of both effort and expertise. They are first class, publishable research objects in their own right. They are key to sharing methodological know-how for reuse, reproducibility, and transparency. Consequently, the application of the FAIR principles to workflows is inevitable to enable them to be Findable, Accessible, Interoperable, and Reusable. Making workflows FAIR would reduce duplication of effort, assist in the reuse of best practice approaches and community-supported standards, and ensure that workflows as digital objects can support reproducible and robust science. FAIR workflows also encourage interdisciplinary collaboration, enabling workflows developed in one field to be repurposed and adapted for use in other research domains. FAIR workflows draw from both FAIR data and software principles. Workflows propose explicit method abstractions and tight bindings to data, hence making many of the data principles apply. Meanwhile, as executable pipelines with a strong emphasis on code composition and data flow between steps, the software principles apply, too. As workflows are chiefly concerned with the processing and creation of data, they also have an important role to play in ensuring and supporting data FAIRification.","authors":["Sean R. Wilkinson","Johan Gustafsson","Finn Bacall","Khalid Belhajjame","Salvador Capella","Jose Maria Fernandez Gonzalez","Jacob Fosso Tande","Luiz Gadelha","Daniel Garijo","Patricia Grubel","Bjorn Gr\\\"uning","Farah Zaib Khan","Sehrish Kanwal","Simone Leo","Stuart Owen","Luca Pireddu","Line Pouchard","Laura Rodr\\'iguez-Navas","Beatriz Serrano-Solano","Stian Soiland-Reyes","Baiba Vilne","Alan Williams","Merridee Ann Wouters","Frederik Coppens","Carole Goble"],"url":"https://arxiv.org/abs/2505.15988"}
{"created":"2025-05-23","title":"On the Complexity of Finding Approximate LCS of Multiple Strings","abstract":"Finding an Approximate Longest Common Substring (ALCS) within a given set $S=\\{s_1,s_2,\\ldots,s_m\\}$ of $m \\ge 2$ strings is a problem of particular importance in computational biology (e.g., identifying related mutations across multiple genetic sequences). In this paper, we study several ALCS problems that, for given integers $k$ and $t \\le m$, require finding a longest string $u$ -- or a longest substring $u$ of any string in $S$ -- that lies within distance $k$ of at least one substring in $t$ distinct strings of $S$. Although two of these problems, denoted $k$-LCS and \\textit{k-t} LCS, are NP-hard, nevertheless restricted variations of them under Hamming and edit distance can be solved in $O(N^2)$ and $O(k\\ell N^2)$ time, respectively, where $\\ell$ is the length of each string and $N=m\\ell$. Further, we show that using the $k$-errata tree data structure, a restricted variation of the ALCS problem under both Hamming and edit distance can be computed in $O(mN\\log^k \\ell)$ time.","authors":["Hamed Hasibi","Neerja Mhaskar","W. F. Smyth"],"url":"https://arxiv.org/abs/2505.15992"}
{"created":"2025-05-23","title":"Explaining Puzzle Solutions in Natural Language: An Exploratory Study on 6x6 Sudoku","abstract":"The success of Large Language Models (LLMs) in human-AI collaborative decision-making hinges on their ability to provide trustworthy, gradual, and tailored explanations. Solving complex puzzles, such as Sudoku, offers a canonical example of this collaboration, where clear and customized explanations often hold greater importance than the final solution. In this study, we evaluate the performance of five LLMs in solving and explaining \\sixsix{} Sudoku puzzles. While one LLM demonstrates limited success in solving puzzles, none can explain the solution process in a manner that reflects strategic reasoning or intuitive problem-solving. These findings underscore significant challenges that must be addressed before LLMs can become effective partners in human-AI collaborative decision-making.","authors":["Anirudh Maiya","Razan Alghamdi","Maria Leonor Pacheco","Ashutosh Trivedi","Fabio Somenzi"],"url":"https://arxiv.org/abs/2505.15993"}
{"created":"2025-05-23","title":"A broken-FEEC framework for structure-preserving discretizations of polar domains with tensor-product splines","abstract":"We propose a novel projection-based approach to derive structure-preserving Finite Element Exterior Calculus (FEEC) discretizations using standard tensor-product splines on domains with a polar singularity. This approach follows the main lines of broken-FEEC schemes which define stable and structure-preserving operators in non-conforming discretizations of the de Rham sequence. Here, we devise a polar broken-FEEC framework that enables the use of standard tensor-product spline spaces while ensuring stability and smoothness for the solutions, as well as the preservation of the de Rham structure: A benefit of this approach is the ability to reuse codes that implement standard splines on smooth parametric domains, and efficient solvers such as Kronecker-product spline interpolation. Our construction is based on two pillars: the first one is an explicit characterization of smooth polar spline spaces within the tensor-product splines ones, which are either discontinuous or non square-integrable as a result of the singular polar pushforward operators. The second pillar consists of local, explicit and matrix-free conforming projection operators that map general tensor-product splines onto smooth polar splines, and that commute with the differential operators of the de Rham sequence.","authors":["Yaman G\\\"u\\c{c}l\\\"u","Francesco Patrizi","Martin Campos Pinto"],"url":"https://arxiv.org/abs/2505.15996"}
{"created":"2025-05-23","title":"Domain Adaptive Skin Lesion Classification via Conformal Ensemble of Vision Transformers","abstract":"Exploring the trustworthiness of deep learning models is crucial, especially in critical domains such as medical imaging decision support systems. Conformal prediction has emerged as a rigorous means of providing deep learning models with reliable uncertainty estimates and safety guarantees. However, conformal prediction results face challenges due to the backbone model's struggles in domain-shifted scenarios, such as variations in different sources. To aim this challenge, this paper proposes a novel framework termed Conformal Ensemble of Vision Transformers (CE-ViTs) designed to enhance image classification performance by prioritizing domain adaptation and model robustness, while accounting for uncertainty. The proposed method leverages an ensemble of vision transformer models in the backbone, trained on diverse datasets including HAM10000, Dermofit, and Skin Cancer ISIC datasets. This ensemble learning approach, calibrated through the combined mentioned datasets, aims to enhance domain adaptation through conformal learning. Experimental results underscore that the framework achieves a high coverage rate of 90.38\\%, representing an improvement of 9.95\\% compared to the HAM10000 model. This indicates a strong likelihood that the prediction set includes the true label compared to singular models. Ensemble learning in CE-ViTs significantly improves conformal prediction performance, increasing the average prediction set size for challenging misclassified samples from 1.86 to 3.075.","authors":["Mehran Zoravar","Shadi Alijani","Homayoun Najjaran"],"url":"https://arxiv.org/abs/2505.15997"}
{"created":"2025-05-23","title":"Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics","abstract":"We present a method for the automated discovery of system-level dynamics in Flow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and parameter localization$-$using a curiosity-driven AI scientist. This method aims to uncover processes leading to self-organization of evolutionary and ecosystemic dynamics in CAs. We build on previous work which uses diversity search algorithms in Lenia to find self-organized individual patterns, and extend it to large environments that support distinct interacting patterns. We adapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive exploration of diverse Flow-Lenia environments using simulation-wide metrics, such as evolutionary activity, compression-based complexity, and multi-scale entropy. We test our method in two experiments, showcasing its ability to illuminate significantly more diverse dynamics compared to random search. We show qualitative results illustrating how ecosystemic simulations enable self-organization of complex collective behaviors not captured by previous individual pattern search and analysis. We complement automated discovery with an interactive exploration tool, creating an effective human-AI collaborative workflow for scientific investigation. Though demonstrated specifically with Flow-Lenia, this methodology provides a framework potentially applicable to other parameterizable complex systems where understanding emergent collective properties is of interest.","authors":["Thomas Michel","Marko Cvjetko","Gautier Hamon","Pierre-Yves Oudeyer","Cl\\'ement Moulin-Frier"],"url":"https://arxiv.org/abs/2505.15998"}
{"created":"2025-05-23","title":"Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model","abstract":"The rapid advancement of language models has demonstrated the potential of artificial intelligence in the healthcare industry. However, small language models struggle with specialized domains in low-resource languages like Persian. While numerous medical-domain websites exist in Persian, no curated dataset or corpus has been available making ours the first of its kind. This study explores the enhancement of medical knowledge in a small language model by leveraging accessible online data, including a crawled corpus from medical magazines and a dataset of real doctor-patient QA pairs. We fine-tuned a baseline model using our curated data to improve its medical knowledge. Benchmark evaluations demonstrate that the fine-tuned model achieves improved accuracy in medical question answering and provides better responses compared to its baseline. This work highlights the potential of leveraging open-access online data to enrich small language models in medical fields, providing a novel solution for Persian medical AI applications suitable for resource-constrained environments.","authors":["Mehrdad ghassabi","Pedram Rostami","Hamidreza Baradaran Kashani","Amirhossein Poursina","Zahra Kazemi","Milad Tavakoli"],"url":"https://arxiv.org/abs/2505.16000"}
{"created":"2025-05-23","title":"Image-to-Image Translation with Diffusion Transformers and CLIP-Based Image Conditioning","abstract":"Image-to-image translation aims to learn a mapping between a source and a target domain, enabling tasks such as style transfer, appearance transformation, and domain adaptation. In this work, we explore a diffusion-based framework for image-to-image translation by adapting Diffusion Transformers (DiT), which combine the denoising capabilities of diffusion models with the global modeling power of transformers. To guide the translation process, we condition the model on image embeddings extracted from a pre-trained CLIP encoder, allowing for fine-grained and structurally consistent translations without relying on text or class labels. We incorporate both a CLIP similarity loss to enforce semantic consistency and an LPIPS perceptual loss to enhance visual fidelity during training. We validate our approach on two benchmark datasets: face2comics, which translates real human faces to comic-style illustrations, and edges2shoes, which translates edge maps to realistic shoe images. Experimental results demonstrate that DiT, combined with CLIP-based conditioning and perceptual similarity objectives, achieves high-quality, semantically faithful translations, offering a promising alternative to GAN-based models for paired image-to-image translation tasks.","authors":["Qiang Zhu","Kuan Lu","Menghao Huo","Yuxiao Li"],"url":"https://arxiv.org/abs/2505.16001"}
{"created":"2025-05-23","title":"Causal Interventions Reveal Shared Structure Across English Filler-Gap Constructions","abstract":"Large Language Models (LLMs) have emerged as powerful sources of evidence for linguists seeking to develop theories of syntax. In this paper, we argue that causal interpretability methods, applied to LLMs, can greatly enhance the value of such evidence by helping us characterize the abstract mechanisms that LLMs learn to use. Our empirical focus is a set of English filler-gap dependency constructions (e.g., questions, relative clauses). Linguistic theories largely agree that these constructions share many properties. Using experiments based in Distributed Interchange Interventions, we show that LLMs converge on similar abstract analyses of these constructions. These analyses also reveal previously overlooked factors -- relating to frequency, filler type, and surrounding context -- that could motivate changes to standard linguistic theory. Overall, these results suggest that mechanistic, internal analyses of LLMs can push linguistic theory forward.","authors":["Sasha Boguraev","Christopher Potts","Kyle Mahowald"],"url":"https://arxiv.org/abs/2505.16002"}
{"created":"2025-05-23","title":"SLMEval: Entropy-Based Calibration for Human-Aligned Evaluation of Large Language Models","abstract":"The LLM-as-a-Judge paradigm offers a scalable, reference-free approach for evaluating language models. Although several calibration techniques have been proposed to better align these evaluators with human judgment, prior studies focus primarily on narrow, well-structured benchmarks. As a result, it remains unclear whether such calibrations generalize to real-world, open-ended tasks.","authors":["Roland Daynauth","Christopher Clarke","Krisztian Flautner","Lingjia Tang","Jason Mars"],"url":"https://arxiv.org/abs/2505.16003"}
{"created":"2025-05-23","title":"Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations","abstract":"Sparse autoencoders (SAEs) are commonly used to interpret the internal activations of large language models (LLMs) by mapping them to human-interpretable concept representations. While existing evaluations of SAEs focus on metrics such as the reconstruction-sparsity tradeoff, human (auto-)interpretability, and feature disentanglement, they overlook a critical aspect: the robustness of concept representations to input perturbations. We argue that robustness must be a fundamental consideration for concept representations, reflecting the fidelity of concept labeling. To this end, we formulate robustness quantification as input-space optimization problems and develop a comprehensive evaluation framework featuring realistic scenarios in which adversarial perturbations are crafted to manipulate SAE representations. Empirically, we find that tiny adversarial input perturbations can effectively manipulate concept-based interpretations in most scenarios without notably affecting the outputs of the base LLMs themselves. Overall, our results suggest that SAE concept representations are fragile and may be ill-suited for applications in model monitoring and oversight.","authors":["Aaron J. Li","Suraj Srinivas","Usha Bhalla","Himabindu Lakkaraju"],"url":"https://arxiv.org/abs/2505.16004"}
{"created":"2025-05-23","title":"Position: Agentic Systems Constitute a Key Component of Next-Generation Intelligent Image Processing","abstract":"This position paper argues that the image processing community should broaden its focus from purely model-centric development to include agentic system design as an essential complementary paradigm. While deep learning has significantly advanced capabilities for specific image processing tasks, current approaches face critical limitations in generalization, adaptability, and real-world problem-solving flexibility. We propose that developing intelligent agentic systems, capable of dynamically selecting, combining, and optimizing existing image processing tools, represents the next evolutionary step for the field. Such systems would emulate human experts' ability to strategically orchestrate different tools to solve complex problems, overcoming the brittleness of monolithic models. The paper analyzes key limitations of model-centric paradigms, establishes design principles for agentic image processing systems, and outlines different capability levels for such agents.","authors":["Jinjin Gu"],"url":"https://arxiv.org/abs/2505.16007"}
{"created":"2025-05-23","title":"LAGO: Few-shot Crosslingual Embedding Inversion Attacks via Language Similarity-Aware Graph Optimization","abstract":"We propose LAGO - Language Similarity-Aware Graph Optimization - a novel approach for few-shot cross-lingual embedding inversion attacks, addressing critical privacy vulnerabilities in multilingual NLP systems. Unlike prior work in embedding inversion attacks that treat languages independently, LAGO explicitly models linguistic relationships through a graph-based constrained distributed optimization framework. By integrating syntactic and lexical similarity as edge constraints, our method enables collaborative parameter learning across related languages. Theoretically, we show this formulation generalizes prior approaches, such as ALGEN, which emerges as a special case when similarity constraints are relaxed. Our framework uniquely combines Frobenius-norm regularization with linear inequality or total variation constraints, ensuring robust alignment of cross-lingual embedding spaces even with extremely limited data (as few as 10 samples per language). Extensive experiments across multiple languages and embedding models demonstrate that LAGO substantially improves the transferability of attacks with 10-20% increase in Rouge-L score over baselines. This work establishes language similarity as a critical factor in inversion attack transferability, urging renewed focus on language-aware privacy-preserving multilingual embeddings.","authors":["Wenrui Yu","Yiyi Chen","Johannes Bjerva","Sokol Kosta","Qiongxiu Li"],"url":"https://arxiv.org/abs/2505.16008"}
{"created":"2025-05-23","title":"Exploring Perception-Based Techniques for Redirected Walking in VR: A Comprehensive Survey","abstract":"We present a comprehensive survey of perception-based redirected walking (RDW) techniques in virtual reality (VR), presenting a taxonomy that serves as a framework for understanding and designing RDW algorithms. RDW enables users to explore virtual environments (VEs) larger than their physical space, addressing the constraints of real walking in limited home VR setups. Our review spans 232 papers, with 165 included in the final analysis. We categorize perception-based RDW techniques based on gains, gain application, target orientation calculation, and optional general enhancements, identifying key patterns and relationships. We present data on how current work aligns within this classification system and suggest how this data can guide future work into areas that are relatively under explored. This taxonomy clarifies perception-based RDW techniques, guiding the design and application of RDW systems, and suggests future research directions to enhance VR user experience.","authors":["Bradley Coles","Yahya Hmaiti","Joseph J. LaViola Jr"],"url":"https://arxiv.org/abs/2505.16011"}
{"created":"2025-05-23","title":"Decision DNNFs with imbalanced conjunction cannot efficiently represent CNFs of bounded width","abstract":"Decomposable Negation Normal Forms \\textsc{dnnf} \\cite{DarwicheJACM} is a landmark Knowledge Compilation (\\textsc{kc}) model, highly important both in \\textsc{ai} and Theoretical Computer Science. Numerous restrictions of the model have been studied. In this paper we consider the restriction where all the gates are $\\alpha$-imbalanced that is, at most one input of each gate depends on more than $n^{\\alpha}$ variables (where $n$ is the number if variables of the function being represented).","authors":["Igor Razgon"],"url":"https://arxiv.org/abs/2505.16012"}
{"created":"2025-05-23","title":"Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains","abstract":"Traditional Retrieval-Augmented Generation (RAG) pipelines rely on similarity-based retrieval and re-ranking, which depend on heuristics such as top-k, and lack explainability, interpretability, and robustness against adversarial content. To address this gap, we propose a novel method METEORA that replaces re-ranking in RAG with a rationale-driven selection approach. METEORA operates in two stages. First, a general-purpose LLM is preference-tuned to generate rationales conditioned on the input query using direct preference optimization. These rationales guide the evidence chunk selection engine, which selects relevant chunks in three stages: pairing individual rationales with corresponding retrieved chunks for local relevance, global selection with elbow detection for adaptive cutoff, and context expansion via neighboring chunks. This process eliminates the need for top-k heuristics. The rationales are also used for consistency check using a Verifier LLM to detect and filter poisoned or misleading content for safe generation. The framework provides explainable and interpretable evidence flow by using rationales consistently across both selection and verification. Our evaluation across six datasets spanning legal, financial, and academic research domains shows that METEORA improves generation accuracy by 33.34% while using approximately 50% fewer chunks than state-of-the-art re-ranking methods. In adversarial settings, METEORA significantly improves the F1 score from 0.10 to 0.44 over the state-of-the-art perplexity-based defense baseline, demonstrating strong resilience to poisoning attacks. Code available at: https://anonymous.4open.science/r/METEORA-DC46/README.md","authors":["Yash Saxena","Anpur Padia","Mandar S Chaudhary","Kalpa Gunaratna","Srinivasan Parthasarathy","Manas Gaur"],"url":"https://arxiv.org/abs/2505.16014"}
{"created":"2025-05-23","title":"GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection","abstract":"We introduce GradPCA, an Out-of-Distribution (OOD) detection method that exploits the low-rank structure of neural network gradients induced by Neural Tangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis (PCA) to gradient class-means, achieving more consistent performance than existing methods across standard image classification benchmarks. We provide a theoretical perspective on spectral OOD detection in neural networks to support GradPCA, highlighting feature-space properties that enable effective detection and naturally emerge from NTK alignment. Our analysis further reveals that feature quality -- particularly the use of pretrained versus non-pretrained representations -- plays a crucial role in determining which detectors will succeed. Extensive experiments validate the strong performance of GradPCA, and our theoretical framework offers guidance for designing more principled spectral OOD detectors.","authors":["Mariia Seleznova","Hung-Hsu Chou","Claudio Mayrink Verdun","Gitta Kutyniok"],"url":"https://arxiv.org/abs/2505.16017"}
{"created":"2025-05-23","title":"NOVER: Incentive Training for Language Models via Verifier-Free Reinforcement Learning","abstract":"Recent advances such as DeepSeek R1-Zero highlight the effectiveness of incentive training, a reinforcement learning paradigm that computes rewards solely based on the final answer part of a language model's output, thereby encouraging the generation of intermediate reasoning steps. However, these methods fundamentally rely on external verifiers, which limits their applicability to domains like mathematics and coding where such verifiers are readily available. Although reward models can serve as verifiers, they require high-quality annotated data and are costly to train. In this work, we propose NOVER, NO-VERifier Reinforcement Learning, a general reinforcement learning framework that requires only standard supervised fine-tuning data with no need for an external verifier. NOVER enables incentive training across a wide range of text-to-text tasks and outperforms the model of the same size distilled from large reasoning models such as DeepSeek R1 671B by 7.7 percent. Moreover, the flexibility of NOVER enables new possibilities for optimizing large language models, such as inverse incentive training.","authors":["Wei Liu","Siya Qi","Xinyu Wang","Chen Qian","Yali Du","Yulan He"],"url":"https://arxiv.org/abs/2505.16022"}
{"created":"2025-05-23","title":"Prototypical Human-AI Collaboration Behaviors from LLM-Assisted Writing in the Wild","abstract":"As large language models (LLMs) are used in complex writing workflows, users engage in multi-turn interactions to steer generations to better fit their needs. Rather than passively accepting output, users actively refine, explore, and co-construct text. We conduct a large-scale analysis of this collaborative behavior for users engaged in writing tasks in the wild with two popular AI assistants, Bing Copilot and WildChat. Our analysis goes beyond simple task classification or satisfaction estimation common in prior work and instead characterizes how users interact with LLMs through the course of a session. We identify prototypical behaviors in how users interact with LLMs in prompts following their original request. We refer to these as Prototypical Human-AI Collaboration Behaviors (PATHs) and find that a small group of PATHs explain a majority of the variation seen in user-LLM interaction. These PATHs span users revising intents, exploring texts, posing questions, adjusting style or injecting new content. Next, we find statistically significant correlations between specific writing intents and PATHs, revealing how users' intents shape their collaboration behaviors. We conclude by discussing the implications of our findings on LLM alignment.","authors":["Sheshera Mysore","Debarati Das","Hancheng Cao","Bahareh Sarrafzadeh"],"url":"https://arxiv.org/abs/2505.16023"}
{"created":"2025-05-23","title":"Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging","abstract":"Diffusion trajectory distillation methods aim to accelerate sampling in diffusion models, which produce high-quality outputs but suffer from slow sampling speeds. These methods train a student model to approximate the multi-step denoising process of a pretrained teacher model in a single step, enabling one-shot generation. However, theoretical insights into the trade-off between different distillation strategies and generative quality remain limited, complicating their optimization and selection. In this work, we take a first step toward addressing this gap. Specifically, we reinterpret trajectory distillation as an operator merging problem in the linear regime, where each step of the teacher model is represented as a linear operator acting on noisy data. These operators admit a clear geometric interpretation as projections and rescalings corresponding to the noise schedule. During merging, signal shrinkage occurs as a convex combination of operators, arising from both discretization and limited optimization time of the student model. We propose a dynamic programming algorithm to compute the optimal merging strategy that maximally preserves signal fidelity. Additionally, we demonstrate the existence of a sharp phase transition in the optimal strategy, governed by data covariance structures. Our findings enhance the theoretical understanding of diffusion trajectory distillation and offer practical insights for improving distillation strategies.","authors":["Weiguo Gao","Ming Li"],"url":"https://arxiv.org/abs/2505.16024"}
{"created":"2025-05-23","title":"CP-LLM: Context and Pixel Aware Large Language Model for Video Quality Assessment","abstract":"Video quality assessment (VQA) is a challenging research topic with broad applications. Effective VQA necessitates sensitivity to pixel-level distortions and a comprehensive understanding of video context to accurately determine the perceptual impact of distortions. Traditional hand-crafted and learning-based VQA models mainly focus on pixel-level distortions and lack contextual understanding, while recent LLM-based models struggle with sensitivity to small distortions or handle quality scoring and description as separate tasks. To address these shortcomings, we introduce CP-LLM: a Context and Pixel aware Large Language Model. CP-LLM is a novel multimodal LLM architecture featuring dual vision encoders designed to independently analyze perceptual quality at both high-level (video context) and low-level (pixel distortion) granularity, along with a language decoder subsequently reasons about the interplay between these aspects. This design enables CP-LLM to simultaneously produce robust quality scores and interpretable quality descriptions, with enhanced sensitivity to pixel distortions (e.g. compression artifacts). The model is trained via a multi-task pipeline optimizing for score prediction, description generation, and pairwise comparisons. Experiment results demonstrate that CP-LLM achieves state-of-the-art cross-dataset performance on established VQA benchmarks and superior robustness to pixel distortions, confirming its efficacy for comprehensive and practical video quality assessment in real-world scenarios.","authors":["Wen Wen","Yaohong Wu","Yue Sheng","Neil Birkbeck","Balu Adsumilli","Yilin Wang"],"url":"https://arxiv.org/abs/2505.16025"}
{"created":"2025-05-23","title":"Learning better representations for crowded pedestrians in offboard LiDAR-camera 3D tracking-by-detection","abstract":"Perceiving pedestrians in highly crowded urban environments is a difficult long-tail problem for learning-based autonomous perception. Speeding up 3D ground truth generation for such challenging scenes is performance-critical yet very challenging. The difficulties include the sparsity of the captured pedestrian point cloud and a lack of suitable benchmarks for a specific system design study. To tackle the challenges, we first collect a new multi-view LiDAR-camera 3D multiple-object-tracking benchmark of highly crowded pedestrians for in-depth analysis. We then build an offboard auto-labeling system that reconstructs pedestrian trajectories from LiDAR point cloud and multi-view images. To improve the generalization power for crowded scenes and the performance for small objects, we propose to learn high-resolution representations that are density-aware and relationship-aware. Extensive experiments validate that our approach significantly improves the 3D pedestrian tracking performance towards higher auto-labeling efficiency. The code will be publicly available at this HTTP URL.","authors":["Shichao Li","Peiliang Li","Qing Lian","Peng Yun","Xiaozhi Chen"],"url":"https://arxiv.org/abs/2505.16029"}
{"created":"2025-05-23","title":"Locally Subspace-Informed Neural Operators for Efficient Multiscale PDE Solving","abstract":"Neural operators (NOs) struggle with high-contrast multiscale partial differential equations (PDEs), where fine-scale heterogeneities cause large errors. To address this, we use the Generalized Multiscale Finite Element Method (GMsFEM) that constructs localized spectral basis functions on coarse grids. This approach efficiently captures dominant multiscale features while solving heterogeneous PDEs accurately at reduced computational cost. However, computing these basis functions is computationally expensive. This gap motivates our core idea: to use a NO to learn the subspace itself - rather than individual basis functions - by employing a subspace-informed loss. On standard multiscale benchmarks - namely a linear elliptic diffusion problem and the nonlinear, steady-state Richards equation - our hybrid method cuts solution error by approximately $60\\%$ compared with standalone NOs and reduces basis-construction time by about $60$ times relative to classical GMsFEM, while remaining independent of forcing terms and boundary conditions. The result fuses multiscale finite-element robustness with NO speed, yielding a practical solver for heterogeneous PDEs.","authors":["Alexander Rudikov","Vladimir Fanaskov","Sergei Stepanov","Buzheng Shan","Ekaterina Muravleva","Yalchin Efendiev","Ivan Oseledets"],"url":"https://arxiv.org/abs/2505.16030"}
{"created":"2025-05-23","title":"Children's Mental Models of AI Reasoning: Implications for AI Literacy Education","abstract":"As artificial intelligence (AI) advances in reasoning capabilities, most recently with the emergence of Large Reasoning Models (LRMs), understanding how children conceptualize AI's reasoning processes becomes critical for fostering AI literacy. While one of the \"Five Big Ideas\" in AI education highlights reasoning algorithms as central to AI decision-making, less is known about children's mental models in this area. Through a two-phase approach, consisting of a co-design session with 8 children followed by a field study with 106 children (grades 3-8), we identified three models of AI reasoning: Deductive, Inductive, and Inherent. Our findings reveal that younger children (grades 3-5) often attribute AI's reasoning to inherent intelligence, while older children (grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions that surfaced in children's understanding of AI reasoning and conclude with implications for scaffolding AI curricula and designing explainable AI tools.","authors":["Aayushi Dangol","Robert Wolfe","Runhua Zhao","JaeWon Kim","Trushaa Ramanan","Katie Davis","Julie A. Kientz"],"url":"https://arxiv.org/abs/2505.16031"}
{"created":"2025-05-23","title":"CUR Matrix Approximation through Convex Optimization for Feature Selection","abstract":"The singular value decomposition (SVD) is commonly used in applications requiring a low rank matrix approximation. However, the singular vectors cannot be interpreted in terms of the original data. For applications requiring this type of interpretation, e.g., selection of important data matrix columns or rows, the approximate CUR matrix factorization can be used. Work on the CUR matrix approximation has generally focused on algorithm development, theoretical guarantees, and applications. In this work, we present a novel deterministic CUR formulation and algorithm with theoretical convergence guarantees. The algorithm utilizes convex optimization, finds important columns and rows separately, and allows the user to control the number of important columns and rows selected from the original data matrix. We present numerical results and demonstrate the effectiveness of our CUR algorithm as a feature selection method on gene expression data. These results are compared to those using the SVD and other CUR algorithms as the feature selection method. Lastly, we present a novel application of CUR as a feature selection method to determine discriminant proteins when clustering protein expression data in a self-organizing map (SOM), and compare the performance of multiple CUR algorithms in this application.","authors":["Kathryn Linehan","Radu Balan"],"url":"https://arxiv.org/abs/2505.16032"}
{"created":"2025-05-23","title":"An Approach Towards Identifying Bangladeshi Leaf Diseases through Transfer Learning and XAI","abstract":"Leaf diseases are harmful conditions that affect the health, appearance and productivity of plants, leading to significant plant loss and negatively impacting farmers' livelihoods. These diseases cause visible symptoms such as lesions, color changes, and texture variations, making it difficult for farmers to manage plant health, especially in large or remote farms where expert knowledge is limited. The main motivation of this study is to provide an efficient and accessible solution for identifying plant leaf diseases in Bangladesh, where agriculture plays a critical role in food security. The objective of our research is to classify 21 distinct leaf diseases across six plants using deep learning models, improving disease detection accuracy while reducing the need for expert involvement. Deep Learning (DL) techniques, including CNN and Transfer Learning (TL) models like VGG16, VGG19, MobileNetV2, InceptionV3, ResNet50V2 and Xception are used. VGG19 and Xception achieve the highest accuracies, with 98.90% and 98.66% respectively. Additionally, Explainable AI (XAI) techniques such as GradCAM, GradCAM++, LayerCAM, ScoreCAM and FasterScoreCAM are used to enhance transparency by highlighting the regions of the models focused on during disease classification. This transparency ensures that farmers can understand the model's predictions and take necessary action. This approach not only improves disease management but also supports farmers in making informed decisions, leading to better plant protection and increased agricultural productivity.","authors":["Faika Fairuj Preotee","Shuvashis Sarker","Shamim Rahim Refat","Tashreef Muhammad","Shifat Islam"],"url":"https://arxiv.org/abs/2505.16033"}
{"created":"2025-05-23","title":"\"AI just keeps guessing\": Using ARC Puzzles to Help Children Identify Reasoning Errors in Generative AI","abstract":"The integration of generative Artificial Intelligence (genAI) into everyday life raises questions about the competencies required to critically engage with these technologies. Unlike visual errors in genAI, textual mistakes are often harder to detect and require specific domain knowledge. Furthermore, AI's authoritative tone and structured responses can create an illusion of correctness, leading to overtrust, especially among children. To address this, we developed AI Puzzlers, an interactive system based on the Abstraction and Reasoning Corpus (ARC), to help children identify and analyze errors in genAI. Drawing on Mayer & Moreno's Cognitive Theory of Multimedia Learning, AI Puzzlers uses visual and verbal elements to reduce cognitive overload and support error detection. Based on two participatory design sessions with 21 children (ages 6 - 11), our findings provide both design insights and an empirical understanding of how children identify errors in genAI reasoning, develop strategies for navigating these errors, and evaluate AI outputs.","authors":["Aayushi Dangol","Trushaa Ramanan","Runhua Zhao","Julie A. Kientz","Robert Wolfe","Jason Yip"],"url":"https://arxiv.org/abs/2505.16034"}
{"created":"2025-05-23","title":"Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces","abstract":"We introduce Equivariant Neural Eikonal Solvers, a novel framework that integrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our approach employs a single neural field where a unified shared backbone is conditioned on signal-specific latent variables - represented as point clouds in a Lie group - to model diverse Eikonal solutions. The ENF integration ensures equivariant mapping from these latent representations to the solution field, delivering three key benefits: enhanced representation efficiency through weight-sharing, robust geometric grounding, and solution steerability. This steerability allows transformations applied to the latent point cloud to induce predictable, geometrically meaningful modifications in the resulting Eikonal solution. By coupling these steerable representations with Physics-Informed Neural Networks (PINNs), our framework accurately models Eikonal travel-time solutions while generalizing to arbitrary Riemannian manifolds with regular group actions. This includes homogeneous spaces such as Euclidean, position-orientation, spherical, and hyperbolic manifolds. We validate our approach through applications in seismic travel-time modeling of 2D and 3D benchmark datasets. Experimental results demonstrate superior performance, scalability, adaptability, and user controllability compared to existing Neural Operator-based Eikonal solver methods.","authors":["Alejandro Garc\\'ia-Castellanos","David R. Wessels","Nicky J. van den Berg","Remco Duits","Dani\\\"el M. Pelt","Erik J. Bekkers"],"url":"https://arxiv.org/abs/2505.16035"}
{"created":"2025-05-23","title":"OpenEthics: A Comprehensive Ethical Evaluation of Open-Source Generative Large Language Models","abstract":"Generative large language models present significant potential but also raise critical ethical concerns. Most studies focus on narrow ethical dimensions, and also limited diversity of languages and models. To address these gaps, we conduct a broad ethical evaluation of 29 recent open-source large language models using a novel data collection including four ethical aspects: Robustness, reliability, safety, and fairness. We analyze model behavior in both a commonly used language, English, and a low-resource language, Turkish. Our aim is to provide a comprehensive ethical assessment and guide safer model development by filling existing gaps in evaluation breadth, language coverage, and model diversity. Our experimental results, based on LLM-as-a-Judge, reveal that optimization efforts for many open-source models appear to have prioritized safety and fairness, and demonstrated good robustness while reliability remains a concern. We demonstrate that ethical evaluation can be effectively conducted independently of the language used. In addition, models with larger parameter counts tend to exhibit better ethical performance, with Gemma and Qwen models demonstrating the most ethical behavior among those evaluated.","authors":["Burak Erin\\c{c} \\c{C}etin","Y{\\i}ld{\\i}r{\\i}m \\\"Ozen","Elif Naz Demiry{\\i}lmaz","Kaan Eng\\\"ur","Cagri Toraman"],"url":"https://arxiv.org/abs/2505.16036"}
{"created":"2025-05-23","title":"Causal LLM Routing: End-to-End Regret Minimization from Observational Data","abstract":"LLM routing aims to select the most appropriate model for each query, balancing competing performance metrics such as accuracy and cost across a pool of language models. Prior approaches typically adopt a decoupled strategy, where the metrics are first predicted and the model is then selected based on these estimates. This setup is prone to compounding errors and often relies on full-feedback data, where each query is evaluated by all candidate models, which is costly to obtain and maintain in practice. In contrast, we learn from observational data, which records only the outcome of the model actually deployed. We propose a causal end-to-end framework that learns routing policies by minimizing decision-making regret from observational data. To enable efficient optimization, we introduce two theoretically grounded surrogate objectives: a classification-based upper bound, and a softmax-weighted regret approximation shown to recover the optimal policy at convergence. We further extend our framework to handle heterogeneous cost preferences via an interval-conditioned architecture. Experiments on public benchmarks show that our method outperforms existing baselines, achieving state-of-the-art performance across different embedding models.","authors":["Asterios Tsiourvas","Wei Sun","Georgia Perakis"],"url":"https://arxiv.org/abs/2505.16037"}
{"created":"2025-05-23","title":"An Exploratory Approach Towards Investigating and Explaining Vision Transformer and Transfer Learning for Brain Disease Detection","abstract":"The brain is a highly complex organ that manages many important tasks, including movement, memory and thinking. Brain-related conditions, like tumors and degenerative disorders, can be hard to diagnose and treat. Magnetic Resonance Imaging (MRI) serves as a key tool for identifying these conditions, offering high-resolution images of brain structures. Despite this, interpreting MRI scans can be complicated. This study tackles this challenge by conducting a comparative analysis of Vision Transformer (ViT) and Transfer Learning (TL) models such as VGG16, VGG19, Resnet50V2, MobilenetV2 for classifying brain diseases using MRI data from Bangladesh based dataset. ViT, known for their ability to capture global relationships in images, are particularly effective for medical imaging tasks. Transfer learning helps to mitigate data constraints by fine-tuning pre-trained models. Furthermore, Explainable AI (XAI) methods such as GradCAM, GradCAM++, LayerCAM, ScoreCAM, and Faster-ScoreCAM are employed to interpret model predictions. The results demonstrate that ViT surpasses transfer learning models, achieving a classification accuracy of 94.39%. The integration of XAI methods enhances model transparency, offering crucial insights to aid medical professionals in diagnosing brain diseases with greater precision.","authors":["Shuvashis Sarker","Shamim Rahim Refat","Faika Fairuj Preotee","Shifat Islam","Tashreef Muhammad","Mohammad Ashraful Hoque"],"url":"https://arxiv.org/abs/2505.16039"}
{"created":"2025-05-23","title":"Reference Free Platform Adaptive Locomotion for Quadrupedal Robots using a Dynamics Conditioned Policy","abstract":"This article presents Platform Adaptive Locomotion (PAL), a unified control method for quadrupedal robots with different morphologies and dynamics. We leverage deep reinforcement learning to train a single locomotion policy on procedurally generated robots. The policy maps proprioceptive robot state information and base velocity commands into desired joint actuation targets, which are conditioned using a latent embedding of the temporally local system dynamics. We explore two conditioning strategies - one using a GRU-based dynamics encoder and another using a morphology-based property estimator - and show that morphology-aware conditioning outperforms temporal dynamics encoding regarding velocity task tracking for our hardware test on ANYmal C. Our results demonstrate that both approaches achieve robust zero-shot transfer across multiple unseen simulated quadrupeds. Furthermore, we demonstrate the need for careful robot reference modelling during training, enabling us to reduce the velocity tracking error by up to 30% compared to the baseline method. Despite PAL not surpassing the best-performing reference-free controller in all cases, our analysis uncovers critical design choices and informs improvements to the state of the art.","authors":["David Rytz (Dynamic Robot Systems","Oxford Robotics Institute","University of Oxford)","Suyoung Choi (RaiLab","Department of Mechanical Engineering","KAIST)","Wanming Yu (Dynamic Robot Systems","Oxford Robotics Institute","University of Oxford)","Wolfgang Merkt (Dynamic Robot Systems","Oxford Robotics Institute","University of Oxford)","Jemin Hwangbo (RaiLab","Department of Mechanical Engineering","KAIST)","Ioannis Havoutis (Dynamic Robot Systems","Oxford Robotics Institute","University of Oxford)"],"url":"https://arxiv.org/abs/2505.16042"}
{"created":"2025-05-23","title":"Adaptive Honeypot Allocation in Multi-Attacker Networks via Bayesian Stackelberg Games","abstract":"Defending against sophisticated cyber threats demands strategic allocation of limited security resources across complex network infrastructures. When the defender has limited defensive resources, the complexity of coordinating honeypot placements across hundreds of nodes grows exponentially. In this paper, we present a multi-attacker Bayesian Stackelberg framework modeling concurrent adversaries attempting to breach a directed network of system components. Our approach uniquely characterizes each adversary through distinct target preferences, exploit capabilities, and associated costs, while enabling defenders to strategically deploy honeypots at critical network positions. By integrating a multi-follower Stackelberg formulation with dynamic Bayesian belief updates, our framework allows defenders to continuously refine their understanding of attacker intentions based on actions detected through Intrusion Detection Systems (IDS). Experimental results show that the proposed method prevents attack success within a few rounds and scales well up to networks of 500 nodes with more than 1,500 edges, maintaining tractable run times.","authors":["Dongyoung Park (Boise State University)","Gaby G. Dagher (Boise State University)"],"url":"https://arxiv.org/abs/2505.16043"}
{"created":"2025-05-23","title":"Regularizing Ill-Posed Inverse Problems: Deblurring Barcodes","abstract":"This manuscript is designed to introduce students in applied mathematics and data science to the concept of regularization for ill-posed inverse problems. Construct a mathematical model that describes how an image gets blurred. Convert a calculus problem into a linear algebra problem by discretization. Inverting the blurring process should sharpen up an image; this requires the solution of a system of linear algebraic equations. Solving this linear system of equations turns out to be delicate, as deblurring is an example of an ill-posed inverse problem. To address this challenge, recast the system as a regularized least squares problem (also known as ridge regression).","authors":["Mark Embree"],"url":"https://arxiv.org/abs/2505.16045"}
{"created":"2025-05-23","title":"SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution","abstract":"We introduce a novel dataset designed to benchmark the physical and spatial reasoning capabilities of Large Language Models (LLM) based on topology optimization, a method for computing optimal material distributions within a design space under prescribed loads and supports. In this dataset, LLMs are provided with conditions such as 2D boundary, applied forces and supports, and must reason about the resulting optimal material distribution. The dataset includes a variety of tasks, ranging from filling in masked regions within partial structures to predicting complete material distributions. Solving these tasks requires understanding the flow of forces and the required material distribution under given constraints, without access to simulation tools or explicit physical models, challenging models to reason about structural stability and spatial organization. Our dataset targets the evaluation of spatial and physical reasoning abilities in 2D settings, offering a complementary perspective to traditional language and logic benchmarks.","authors":["Philipp D. Siedler"],"url":"https://arxiv.org/abs/2505.16048"}
{"created":"2025-05-23","title":"A Non-Zero-Sum Game Model for Optimal Cyber Defense Strategies","abstract":"In the contemporary digital landscape, cybersecurity has become a critical issue due to the increasing frequency and sophistication of cyber attacks. This study utilizes a non-zero-sum game theoretical framework to model the strategic interactions between cyber attackers and defenders, with the objective of identifying optimal strategies for both. By defining precise payoff functions that incorporate the probabilities and costs associated with various exploits, as well as the values of network nodes and the costs of deploying honeypots, we derive Nash equilibria that inform strategic decisions. The proposed model is validated through extensive simulations, demonstrating its effectiveness in enhancing network security. Our results indicate that high-probability, low-cost exploits like Phishing and Social Engineering are more likely to be used by attackers, necessitating prioritized defense mechanisms. Our findings also show that increasing the number of network nodes dilutes the attacker's efforts, thereby improving the defender's payoff. This study provides valuable insights into optimizing resource allocation for cybersecurity and highlights the scalability and practical applicability of the game-theoretic approach.","authors":["Dongyoung Park (Boise State University)","Gaby G. Dagher (Boise State University)"],"url":"https://arxiv.org/abs/2505.16049"}
{"created":"2025-05-23","title":"A Weight Function Lemma Heuristic for Graph Pebbling","abstract":"Graph pebbling is a problem in which pebbles are distributed across the vertices of a graph and moved according to a specific rule: two pebbles are removed from a vertex to place one on an adjacent vertex. The goal is to determine the minimum number of pebbles required to ensure that any target vertex can be reached, known as the pebbling number. Computing the pebbling number lies beyond NP in the polynomial hierarchy, leading to bounding methods. One of the most prominent techniques for upper bounds is the Weight Function Lemma (WFL), which relies on costly integer linear optimization. To mitigate this cost, an alternative approach is to consider the dual formulation of the problem, which allows solutions to be constructed by hand through the selection of strategies given by subtrees with associated weight functions. To improve the bounds, the weights should be distributed as uniformly as possible among the vertices, balancing their individual contribution. However, despite its simplicity, this approach lacks a formal framework. To fill this gap, we introduce a novel heuristic method that refines the selection of balanced strategies. The method is motivated by our theoretical analysis of the limitations of the dual approach, in which we prove lower bounds on the best bounds achievable. Our theoretical analysis shows that the bottleneck lies in the farthest vertices from the target, forcing surplus weight onto the closer neighborhoods. To minimize surplus weight beyond the theoretical minimum, our proposed heuristic prioritizes weight assignment to the farthest vertices, building the subtrees starting from the shortest paths to them and then filling in the weights for the remaining vertices. Applying our heuristic to Flower snarks and Blanu\\v{s}a snarks, we improve the best-known upper bounds, demonstrating the effectiveness of a structured strategy selection when using the WFL.","authors":["G. A. Bridi","F. L. Marquezino","C. M. H. de Figueiredo"],"url":"https://arxiv.org/abs/2505.16050"}
{"created":"2025-05-23","title":"Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs","abstract":"Boolean Satisfiability (SAT) solvers are foundational to computer science, yet their performance typically hinges on hand-crafted heuristics. This work introduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm for learning to guide SAT solver branching heuristics with Graph Neural Networks (GNNs). Central to our approach is a novel and generic mechanism for injecting inferred variable weights and polarities into the branching heuristics of existing SAT solvers. In a single forward pass, a GNN assigns these parameters to all variables. Casting this one-shot guidance as a reinforcement learning problem lets us train the GNN with off-the-shelf policy-gradient methods, such as GRPO, directly using the solver's computational cost as the sole reward signal. Extensive evaluations demonstrate that RLAF-trained policies significantly reduce the mean solve times of different base solvers across diverse SAT problem distributions, achieving more than a 2x speedup in some cases, while generalizing effectively to larger and harder problems after training. Notably, these policies consistently outperform expert-supervised approaches based on learning handcrafted weighting heuristics, offering a promising path towards data-driven heuristic design in combinatorial optimization.","authors":["Jan T\\\"onshoff","Martin Grohe"],"url":"https://arxiv.org/abs/2505.16053"}
{"created":"2025-05-23","title":"Multi-Unit Combinatorial Prophet Inequalities","abstract":"We consider a combinatorial auction setting where buyers have fractionally subadditive (XOS) valuations over the items and the seller's objective is to maximize the social welfare. A prophet inequality in this setting bounds the competitive ratio of sequential allocation (often using item pricing) against the hindsight optimum. We study the dependence of the competitive ratio on the number of copies, $k$, of each item.","authors":["Shuchi Chawla","Trung Dang","Zhiyi Huang","Yifan Wang"],"url":"https://arxiv.org/abs/2505.16054"}
{"created":"2025-05-23","title":"Proactive Hierarchical Control Barrier Function-Based Safety Prioritization in Close Human-Robot Interaction Scenarios","abstract":"In collaborative human-robot environments, the unpredictable and dynamic nature of human motion can lead to situations where collisions become unavoidable. In such cases, it is essential for the robotic system to proactively mitigate potential harm through intelligent control strategies. This paper presents a hierarchical control framework based on Control Barrier Functions (CBFs) designed to ensure safe and adaptive operation of autonomous robotic manipulators during close-proximity human-robot interaction. The proposed method introduces a relaxation variable that enables real-time prioritization of safety constraints, allowing the robot to dynamically manage collision risks based on the criticality of different parts of the human body. A secondary constraint mechanism is incorporated to resolve infeasibility by increasing the priority of imminent threats. The framework is experimentally validated on a Franka Research 3 robot equipped with a ZED2i AI camera for real-time human pose and body detection. Experimental results confirm that the CBF-based controller, integrated with depth sensing, facilitates responsive and safe human-robot collaboration, while providing detailed risk analysis and maintaining robust performance in highly dynamic settings.","authors":["Patanjali Maithania","Aliasghar Araba","Farshad Khorramia","Prashanth Krishnamurthya"],"url":"https://arxiv.org/abs/2505.16055"}
{"created":"2025-05-23","title":"Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models","abstract":"Mixture-of-Experts (MoE) enables efficient scaling of large language models (LLMs) with sparsely activated experts during inference. To effectively deploy large MoE models on memory-constrained devices, many systems introduce *expert offloading* that caches a subset of experts in fast memory, leaving others on slow memory to run on CPU or load on demand. While some research has exploited the locality of expert activations, where consecutive tokens activate similar experts, the degree of this **local routing consistency** varies across models and remains understudied. In this paper, we propose two metrics to measure local routing consistency of MoE models: (1) **Segment Routing Best Performance (SRP)**, which evaluates how well a fixed group of experts can cover the needs of a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which measures the optimal segment-level cache hit rate under a given cache size limit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found that models that apply MoE on every layer and do not use shared experts exhibit the highest local routing consistency. We further showed that domain-specialized experts contribute more to routing consistency than vocabulary-specialized ones, and that most models can balance between cache effectiveness and efficiency with cache sizes approximately 2x the active experts. These findings pave the way for memory-efficient MoE design and deployment without compromising inference speed. We publish the code for replicating experiments at https://github.com/ljcleo/moe-lrc .","authors":["Jingcong Liang","Siyuan Wang","Miren Tian","Yitong Li","Duyu Tang","Zhongyu Wei"],"url":"https://arxiv.org/abs/2505.16056"}
{"created":"2025-05-23","title":"Signals of Provenance: Practices & Challenges of Navigating Indicators in AI-Generated Media for Sighted and Blind Individuals","abstract":"AI-Generated (AIG) content has become increasingly widespread by recent advances in generative models and the easy-to-use tools that have significantly lowered the technical barriers for producing highly realistic audio, images, and videos through simple natural language prompts. In response, platforms are adopting provable provenance with platforms recommending AIG to be self-disclosed and signaled to users. However, these indicators may be often missed, especially when they rely solely on visual cues and make them ineffective to users with different sensory abilities. To address the gap, we conducted semi-structured interviews (N=28) with 15 sighted and 13 BLV participants to examine their interaction with AIG content through self-disclosed AI indicators. Our findings reveal diverse mental models and practices, highlighting different strengths and weaknesses of content-based (e.g., title, description) and menu-aided (e.g., AI labels) indicators. While sighted participants leveraged visual and audio cues, BLV participants primarily relied on audio and existing assistive tools, limiting their ability to identify AIG. Across both groups, they frequently overlooked menu-aided indicators deployed by platforms and rather interacted with content-based indicators such as title and comments. We uncovered usability challenges stemming from inconsistent indicator placement, unclear metadata, and cognitive overload. These issues were especially critical for BLV individuals due to the insufficient accessibility of interface elements. We provide practical recommendations and design implications for future AIG indicators across several dimensions.","authors":["Ayae Ide","Tory Park","Jaron Mink","Tanusree Sharma"],"url":"https://arxiv.org/abs/2505.16057"}
{"created":"2025-05-23","title":"Mesh-free sparse identification of nonlinear dynamics","abstract":"Identifying the governing equations of a dynamical system is one of the most important tasks for scientific modeling. However, this procedure often requires high-quality spatio-temporal data uniformly sampled on structured grids. In this paper, we propose mesh-free SINDy, a novel algorithm which leverages the power of neural network approximation as well as auto-differentiation to identify governing equations from arbitrary sensor placements and non-uniform temporal data sampling. We show that mesh-free SINDy is robust to high noise levels and limited data while remaining computationally efficient. In our implementation, the training procedure is straight-forward and nearly free of hyperparameter tuning, making mesh-free SINDy widely applicable to many scientific and engineering problems. In the experiments, we demonstrate its effectiveness on a series of PDEs including the Burgers' equation, the heat equation, the Korteweg-De Vries equation and the 2D advection-diffusion equation. We conduct detailed numerical experiments on all datasets, varying the noise levels and number of samples, and we also compare our approach to previous state-of-the-art methods. It is noteworthy that, even in high-noise and low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery, achieving successful identification with up to 75% noise for the Burgers' equation using 5,000 samples and with as few as 100 samples and 1% noise. All of this is achieved within a training time of under one minute.","authors":["Mars Liyao Gao","J. Nathan Kutz","Bernat Font"],"url":"https://arxiv.org/abs/2505.16058"}
{"created":"2025-05-23","title":"Monitoring in the Dark: Privacy-Preserving Runtime Verification of Cyber-Physical Systems","abstract":"In distributed Cyber-Physical Systems and Internet-of-Things applications, the nodes of the system send measurements to a monitor that checks whether these measurements satisfy given formal specifications. For instance in Urban Air Mobility, a local traffic authority will be monitoring drone traffic to evaluate its flow and detect emerging problematic patterns. Certain applications require both the specification and the measurements to be private -- i.e. known only to their owners. Examples include traffic monitoring, testing of integrated circuit designs, and medical monitoring by wearable or implanted devices. In this paper we propose a protocol that enables privacy-preserving robustness monitoring. By following our protocol, both system (e.g. drone) and monitor (e.g. traffic authority) only learn the robustness of the measured trace w.r.t. the specification. But the system learns nothing about the formula, and the monitor learns nothing about the signal monitored. We do this using garbled circuits, for specifications in Signal Temporal Logic interpreted over timed state sequences. We analyze the runtime and memory overhead of privacy preservation, the size of the circuits, and their practicality for three different usage scenarios: design testing, offline monitoring, and online monitoring of Cyber-Physical Systems.","authors":["Charles Koll","Preston Tan Hang","Mike Rosulek","Houssam Abbas"],"url":"https://arxiv.org/abs/2505.16059"}
{"created":"2025-05-23","title":"Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond","abstract":"We introduce Model Feedback Learning (MFL), a novel test-time optimization framework for optimizing inputs to pre-trained AI models or deployed hardware systems without requiring any retraining of the models or modifications to the hardware. In contrast to existing methods that rely on adjusting model parameters, MFL leverages a lightweight reverse model to iteratively search for optimal inputs, enabling efficient adaptation to new objectives under deployment constraints. This framework is particularly advantageous in real-world settings, such as semiconductor manufacturing recipe generation, where modifying deployed systems is often infeasible or cost-prohibitive. We validate MFL on semiconductor plasma etching tasks, where it achieves target recipe generation in just five iterations, significantly outperforming both Bayesian optimization and human experts. Beyond semiconductor applications, MFL also demonstrates strong performance in chemical processes (e.g., chemical vapor deposition) and electronic systems (e.g., wire bonding), highlighting its broad applicability. Additionally, MFL incorporates stability-aware optimization, enhancing robustness to process variations and surpassing conventional supervised learning and random search methods in high-dimensional control settings. By enabling few-shot adaptation, MFL provides a scalable and efficient paradigm for deploying intelligent control in real-world environments.","authors":["Shangding Gu","Donghao Ying","Ming Jin","Yu Joe Lu","Jun Wang","Javad Lavaei","Costas Spanos"],"url":"https://arxiv.org/abs/2505.16060"}
{"created":"2025-05-23","title":"Internal and External Impacts of Natural Language Processing Papers","abstract":"We investigate the impacts of NLP research published in top-tier conferences (i.e., ACL, EMNLP, and NAACL) from 1979 to 2024. By analyzing citations from research articles and external sources such as patents, media, and policy documents, we examine how different NLP topics are consumed both within the academic community and by the broader public. Our findings reveal that language modeling has the widest internal and external influence, while linguistic foundations have lower impacts. We also observe that internal and external impacts generally align, but topics like ethics, bias, and fairness show significant attention in policy documents with much fewer academic citations. Additionally, external domains exhibit distinct preferences, with patents focusing on practical NLP applications and media and policy documents engaging more with the societal implications of NLP models.","authors":["Yu Zhang"],"url":"https://arxiv.org/abs/2505.16061"}
{"created":"2025-05-23","title":"WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects","abstract":"The perception and recognition of the surroundings is one of the essential tasks for a robot. With preliminary knowledge about a target object, it can perform various manipulation tasks such as rolling motion, palpation, and force control. Minimizing possible damage to the sensing system and testing objects during manipulation are significant concerns that persist in existing research solutions. To address this need, we designed a new type of tactile sensor based on the active vibro-feedback for object stiffness classification. With this approach, the classification can be performed during the gripping process, enabling the robot to quickly estimate the appropriate level of gripping force required to avoid damaging or dropping the object. This contrasts with passive vibration sensing, which requires to be triggered by object movement and is often inefficient for establishing a secure grip. The main idea is to observe the received changes in artificially injected vibrations that propagate through objects with different physical properties and molecular structures. The experiments with soft subjects demonstrated higher absorption of the received vibrations, while the opposite is true for the rigid subjects that not only demonstrated low absorption but also enhancement of the vibration signal.","authors":["Danissa Sandykbayeva","Valeriya Kostyukova","Aditya Shekhar Nittala","Zhanat Kappassov","Bakhtiyar Orazbayev"],"url":"https://arxiv.org/abs/2505.16062"}
{"created":"2025-05-23","title":"Three Algorithms for Merging Hierarchical Navigable Small World Graphs","abstract":"This paper addresses the challenge of merging hierarchical navigable small world (HNSW) graphs, a critical operation for distributed systems, incremental indexing, and database compaction. We propose three algorithms for this task: Naive Graph Merge (NGM), Intra Graph Traversal Merge (IGTM), and Cross Graph Traversal Merge (CGTM). These algorithms differ in their approach to vertex selection and candidate collection during the merge process. We conceptualize graph merging as an iterative process with four key steps: processing vertex selection, candidate collection, neighborhood construction, and information propagation. Our experimental evaluation on the SIFT1M dataset demonstrates that IGTM and CGTM significantly reduce computational costs compared to naive approaches, requiring up to 70\\% fewer distance computations while maintaining comparable search accuracy. Surprisingly, IGTM outperforms CGTM in efficiency, contrary to our initial expectations. The proposed algorithms enable efficient consolidation of separately constructed indices, supporting critical operations in modern vector databases and retrieval systems that rely on HNSW for similarity search.","authors":["Alexander Ponomarenko"],"url":"https://arxiv.org/abs/2505.16064"}
{"created":"2025-05-23","title":"Aug2Search: Enhancing Facebook Marketplace Search with LLM-Generated Synthetic Data Augmentation","abstract":"Embedding-Based Retrieval (EBR) is an important technique in modern search engines, enabling semantic match between search queries and relevant results. However, search logging data on platforms like Facebook Marketplace lacks the diversity and details needed for effective EBR model training, limiting the models' ability to capture nuanced search patterns. To address this challenge, we propose Aug2Search, an EBR-based framework leveraging synthetic data generated by Generative AI (GenAI) models, in a multimodal and multitask approach to optimize query-product relevance. This paper investigates the capabilities of GenAI, particularly Large Language Models (LLMs), in generating high-quality synthetic data, and analyzing its impact on enhancing EBR models. We conducted experiments using eight Llama models and 100 million data points from Facebook Marketplace logs. Our synthetic data generation follows three strategies: (1) generate queries, (2) enhance product listings, and (3) generate queries from enhanced listings. We train EBR models on three different datasets: sampled engagement data or original data ((e.g., \"Click\" and \"Listing Interactions\")), synthetic data, and a mixture of both engagement and synthetic data to assess their performance across various training sets. Our findings underscore the robustness of Llama models in producing synthetic queries and listings with high coherence, relevance, and diversity, while maintaining low levels of hallucination. Aug2Search achieves an improvement of up to 4% in ROC_AUC with 100 million synthetic data samples, demonstrating the effectiveness of our approach. Moreover, our experiments reveal that with the same volume of training data, models trained exclusively on synthetic data often outperform those trained on original data only or a mixture of original and synthetic data.","authors":["Ruijie Xi","He Ba","Hao Yuan","Rishu Agrawal","Arul Prakash"],"url":"https://arxiv.org/abs/2505.16065"}
{"created":"2025-05-23","title":"Merge to Mix: Mixing Datasets via Model Merging","abstract":"Mixing datasets for fine-tuning large models (LMs) has become critical for maximizing performance on downstream tasks. However, composing effective dataset mixtures typically relies on heuristics and trial-and-error, often requiring multiple fine-tuning runs to achieve the desired outcome. We propose a novel method, $\\textit{Merge to Mix}$, that accelerates composing dataset mixtures through model merging. Model merging is a recent technique that combines the abilities of multiple individually fine-tuned LMs into a single LM by using a few simple arithmetic operations. Our key insight is that merging models individually fine-tuned on each dataset in a mixture can effectively serve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix leverages this insight to accelerate selecting dataset mixtures without requiring full fine-tuning on each candidate mixture. Our experiments demonstrate that Merge to Mix surpasses state-of-the-art methods in dataset selection for fine-tuning LMs.","authors":["Zhixu Silvia Tao","Kasper Vinken","Hao-Wei Yeh","Avi Cooper","Xavier Boix"],"url":"https://arxiv.org/abs/2505.16066"}
{"created":"2025-05-23","title":"How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior","abstract":"Memory is a critical component in large language model (LLM)-based agents, enabling them to store and retrieve past executions to improve task performance over time. In this paper, we conduct an empirical study on how memory management choices impact the LLM agents' behavior, especially their long-term performance. Specifically, we focus on two fundamental memory operations that are widely used by many agent frameworks-addition, which incorporates new experiences into the memory base, and deletion, which selectively removes past experiences-to systematically study their impact on the agent behavior. Through our quantitative analysis, we find that LLM agents display an experience-following property: high similarity between a task input and the input in a retrieved memory record often results in highly similar agent outputs. Our analysis further reveals two significant challenges associated with this property: error propagation, where inaccuracies in past experiences compound and degrade future performance, and misaligned experience replay, where outdated or irrelevant experiences negatively influence current tasks. Through controlled experiments, we show that combining selective addition and deletion strategies can help mitigate these negative effects, yielding an average absolute performance gain of 10% compared to naive memory growth. Furthermore, we highlight how memory management choices affect agents' behavior under challenging conditions such as task distribution shifts and constrained memory resources. Our findings offer insights into the behavioral dynamics of LLM agent memory systems and provide practical guidance for designing memory components that support robust, long-term agent performance. We also release our code to facilitate further study.","authors":["Zidi Xiong","Yuping Lin","Wenya Xie","Pengfei He","Jiliang Tang","Himabindu Lakkaraju","Zhen Xiang"],"url":"https://arxiv.org/abs/2505.16067"}
{"created":"2025-05-23","title":"Evaluating Voting Design Vulnerabilities for Retroactive Funding","abstract":"Retroactive Public Goods Funding (RetroPGF) rewards blockchain projects based on proven impact rather than future promises. This paper reviews voting mechanisms for Optimism's RetroPGF, where \"badgeholders\" allocate rewards to valuable projects. We explore Optimism's previous schemes for RetroPGF voting, including quadratic, mean, and median voting. We present a proof-based formal analysis for vulnerabilities in these voting schemes, empirically validate these vulnerabilities using voting simulations, and offer assessments and practical recommendations for future iterations of Optimism's system based on our findings.","authors":["Jay Yu","Austin Bennett","Billy Gao","Rebecca Joseph"],"url":"https://arxiv.org/abs/2505.16068"}
{"created":"2025-05-23","title":"A Distributed Local Energy Market Clearing Framework Using a Two-Loop ADMM Method","abstract":"The diversity of prosumers' resources in energy communities can provide significant technical and economic benefits to both prosumers and the distribution system operator (DSO). To maximize these benefits, a coordination framework is required to address all techno-economic constraints as well as the objectives of all agents. This paper presents a fully distributed market-clearing scheme to coordinate the strategies of agents within a local energy community. In the proposed framework, prosumers, the DSO, and the local market operator (LMO) are the participating agents. The framework addresses the preferences and techno-economic constraints of all actors while preserving their privacy. The proposed model is based on a modified alternating direction method of multipliers (ADMM) method with two outer and inner loops; the outer loop models the interactions between the LMO and prosumers, while the inner loop addresses the interactions between the LMO and the DSO. The model is demonstrated on IEEE-69bus test network, showcasing its effectiveness from various perspectives.","authors":["Milad Kabirifar","Biswarup Mukherjee","S. Gokul Krishnan","Charalambos Konstantinou","Subhash Lakshminarayana"],"url":"https://arxiv.org/abs/2505.16070"}
{"created":"2025-05-23","title":"Age-Energy Analysis in Multi-Source Systems with Wake-up Control and Packet Management","abstract":"In recent years, there has been an increasing focus on real-time mobile applications, such as news updates and weather forecast. In these applications, data freshness is of significant importance, which can be measured by age-of-synchronization (AoS). At the same time, the reduction of carbon emission is increasingly required by the communication operators. Thus, how to reduce energy consumption while keeping the data fresh becomes a matter of concern. In this paper, we study the age-energy trade-off in a multi-source single-server system, where the server can turn to sleep mode to save energy. We adopt the stochastic hybrid system (SHS) method to analyze the average AoS and power consumption with three wake-up policies including N-policy, single-sleep policy and multi-sleep policy, and three packet preemption strategies, including Last-Come-First-Serve with preemption-in-Service (LCFS-S), LCFS with preemption-only-in-Waiting (LCFS-W), and LCFS with preemption-and-Queueing (LCFS-Q). The trade-off performance is analyzed via both closed-form expressions and numerical simulations. It is found that N-policy attains the best trade-off performance among all three sleep policies. Among packet management strategies, LCFS-S is suitable for scenarios with high requirements on energy saving and small arrival rate difference between sources. LCFS-Q is suitable for scenarios with high requirements on information freshness and large arrival rate difference between sources.","authors":["Jie Gong","Jiajie Huang"],"url":"https://arxiv.org/abs/2505.16073"}
{"created":"2025-05-23","title":"Bidirectional Variational Autoencoders","abstract":"We present the new bidirectional variational autoencoder (BVAE) network architecture. The BVAE uses a single neural network both to encode and decode instead of an encoder-decoder network pair. The network encodes in the forward direction and decodes in the backward direction through the same synaptic web. Simulations compared BVAEs and ordinary VAEs on the four image tasks of image reconstruction, classification, interpolation, and generation. The image datasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and CelebA-64 face images. The bidirectional structure of BVAEs cut the parameter count by almost 50% and still slightly outperformed the unidirectional VAEs.","authors":["Bart Kosko","Olaoluwa Adigun"],"url":"https://arxiv.org/abs/2505.16074"}
{"created":"2025-05-23","title":"Ensembling Sparse Autoencoders","abstract":"Sparse autoencoders (SAEs) are used to decompose neural network activations into human-interpretable features. Typically, features learned by a single SAE are used for downstream applications. However, it has recently been shown that SAEs trained with different initial weights can learn different features, demonstrating that a single SAE captures only a limited subset of features that can be extracted from the activation space. Motivated by this limitation, we propose to ensemble multiple SAEs through naive bagging and boosting. Specifically, SAEs trained with different weight initializations are ensembled in naive bagging, whereas SAEs sequentially trained to minimize the residual error are ensembled in boosting. We evaluate our ensemble approaches with three settings of language models and SAE architectures. Our empirical results demonstrate that ensembling SAEs can improve the reconstruction of language model activations, diversity of features, and SAE stability. Furthermore, ensembling SAEs performs better than applying a single SAE on downstream tasks such as concept detection and spurious correlation removal, showing improved practical utility.","authors":["Soham Gadgil","Chris Lin","Su-In Lee"],"url":"https://arxiv.org/abs/2505.16077"}
{"created":"2025-05-23","title":"Small Language Models in the Real World: Insights from Industrial Text Classification","abstract":"With the emergence of ChatGPT, Transformer models have significantly advanced text classification and related tasks. Decoder-only models such as Llama exhibit strong performance and flexibility, yet they suffer from inefficiency on inference due to token-by-token generation, and their effectiveness in text classification tasks heavily depends on prompt quality. Moreover, their substantial GPU resource requirements often limit widespread adoption. Thus, the question of whether smaller language models are capable of effectively handling text classification tasks emerges as a topic of significant interest. However, the selection of appropriate models and methodologies remains largely underexplored. In this paper, we conduct a comprehensive evaluation of prompt engineering and supervised fine-tuning methods for transformer-based text classification. Specifically, we focus on practical industrial scenarios, including email classification, legal document categorization, and the classification of extremely long academic texts. We examine the strengths and limitations of smaller models, with particular attention to both their performance and their efficiency in Video Random-Access Memory (VRAM) utilization, thereby providing valuable insights for the local deployment and application of compact models in industrial settings.","authors":["Lujun Li","Lama Sleem","Niccolo' Gentile","Geoffrey Nichil","Radu State"],"url":"https://arxiv.org/abs/2505.16078"}
{"created":"2025-05-23","title":"Tight Practical Bounds for Subgraph Densities in Ego-centric Networks","abstract":"Subgraph densities play a crucial role in network analysis, especially for the identification and interpretation of meaningful substructures in complex graphs. Localized subgraph densities, in particular, can provide valuable insights into graph structures. Distinguishing between mathematically-determined and domain-driven subgraph density features, however, poses challenges. For instance, the lack or presence of certain structures can be explained by graph density or degree distribution. These differences are especially meaningful in applied contexts as they allow us to identify instances where the data induces specific network structures, such as friendships in social networks. The goal of this paper is to measure these differences across various types of graphs, conducting social media analysis from a network perspective. To this end, we first provide tighter bounds on subgraph densities. We then introduce the subgraph spread ratio to quantify the realized subgraph densities of specific networks relative to the feasible bounds. Our novel approach combines techniques from flag algebras, motif-counting, and topological data analysis. Crucially, effective adoption of the state-of-the-art in the plain flag algebra method yields feasible regions up to three times tighter than prior best-known results, thereby enabling more accurate and direct comparisons across graphs. We additionally perform an empirical analysis of 11 real-world networks. We observe that social networks consistently have smaller subgraph spread ratios than other types of networks, such as linkage-mapping networks for Wikipedia pages. This aligns with our intuition about social relationships: such networks have meaningful structure that makes them distinct. The subgraph spread ratio enables the quantification of intuitive understandings of network structures and provides a metric for comparing types of networks.","authors":["Connor Mattes","Esha Datta","Ali Pinar"],"url":"https://arxiv.org/abs/2505.16079"}
{"created":"2025-05-23","title":"SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation","abstract":"Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.","authors":["Jiayue Liu","Zhongchao Yi","Zhengyang Zhou","Qihe Huang","Kuo Yang","Xu Wang","Yang Wang"],"url":"https://arxiv.org/abs/2505.16080"}
{"created":"2025-05-23","title":"BiasLab: Toward Explainable Political Bias Detection with Dual-Axis Annotations and Rationale Indicators","abstract":"We present BiasLab, a dataset of 300 political news articles annotated for perceived ideological bias. These articles were selected from a curated 900-document pool covering diverse political events and source biases. Each article is labeled by crowdworkers along two independent scales, assessing sentiment toward the Democratic and Republican parties, and enriched with rationale indicators. The annotation pipeline incorporates targeted worker qualification and was refined through pilot-phase analysis. We quantify inter-annotator agreement, analyze misalignment with source-level outlet bias, and organize the resulting labels into interpretable subsets. Additionally, we simulate annotation using schema-constrained GPT-4o, enabling direct comparison to human labels and revealing mirrored asymmetries, especially in misclassifying subtly right-leaning content. We define two modeling tasks: perception drift prediction and rationale type classification, and report baseline performance to illustrate the challenge of explainable bias detection. BiasLab's rich rationale annotations provide actionable interpretations that facilitate explainable modeling of political bias, supporting the development of transparent, socially aware NLP systems. We release the dataset, annotation schema, and modeling code to encourage research on human-in-the-loop interpretability and the evaluation of explanation effectiveness in real-world settings.","authors":["KMA Solaiman"],"url":"https://arxiv.org/abs/2505.16081"}
{"created":"2025-05-23","title":"FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model","abstract":"Physical field reconstruction (PFR) aims to predict the state distribution of physical quantities (e.g., velocity, pressure, and temperature) based on limited sensor measurements. It plays a critical role in domains such as fluid dynamics and thermodynamics. However, existing deep learning methods often fail to capture long-range temporal dependencies, resulting in suboptimal performance on time-evolving physical systems. To address this, we propose FR-Mamba, a novel spatiotemporal flow field reconstruction framework based on state space modeling. Specifically, we design a hybrid neural network architecture that combines Fourier Neural Operator (FNO) and State Space Model (SSM) to capture both global spatial features and long-range temporal dependencies. We adopt Mamba, a recently proposed efficient SSM architecture, to model long-range temporal dependencies with linear time complexity. In parallel, the FNO is employed to capture non-local spatial features by leveraging frequency-domain transformations. The spatiotemporal representations extracted by these two components are then fused to reconstruct the full-field distribution of the physical system. Extensive experiments demonstrate that our approach significantly outperforms existing PFR methods in flow field reconstruction tasks, achieving high-accuracy performance on long sequences.","authors":["Jiahuan Long","Wenzhe Zhang","Ning Wang","Tingsong Jiang","Wen Yao"],"url":"https://arxiv.org/abs/2505.16083"}
{"created":"2025-05-23","title":"Motion Priors Reimagined: Adapting Flat-Terrain Skills for Complex Quadruped Mobility","abstract":"Reinforcement learning (RL)-based legged locomotion controllers often require meticulous reward tuning to track velocities or goal positions while preserving smooth motion on various terrains. Motion imitation methods via RL using demonstration data reduce reward engineering but fail to generalize to novel environments. We address this by proposing a hierarchical RL framework in which a low-level policy is first pre-trained to imitate animal motions on flat ground, thereby establishing motion priors. A subsequent high-level, goal-conditioned policy then builds on these priors, learning residual corrections that enable perceptive locomotion, local obstacle avoidance, and goal-directed navigation across diverse and rugged terrains. Simulation experiments illustrate the effectiveness of learned residuals in adapting to progressively challenging uneven terrains while still preserving the locomotion characteristics provided by the motion priors. Furthermore, our results demonstrate improvements in motion regularization over baseline models trained without motion priors under similar reward setups. Real-world experiments with an ANYmal-D quadruped robot confirm our policy's capability to generalize animal-like locomotion skills to complex terrains, demonstrating smooth and efficient locomotion and local navigation performance amidst challenging terrains with obstacles.","authors":["Zewei Zhang","Chenhao Li","Takahiro Miki","Marco Hutter"],"url":"https://arxiv.org/abs/2505.16084"}
{"created":"2025-05-23","title":"Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development","abstract":"We have seen remarkable progress in large language models (LLMs) empowered multi-agent systems solving complex tasks necessitating cooperation among experts with diverse skills. However, optimizing LLM-based multi-agent systems remains challenging. In this work, we perform an empirical case study on group optimization of role-based multi-agent systems utilizing natural language feedback for challenging software development tasks under various evaluation dimensions. We propose a two-step agent prompts optimization pipeline: identifying underperforming agents with their failure explanations utilizing textual feedback and then optimizing system prompts of identified agents utilizing failure explanations. We then study the impact of various optimization settings on system performance with two comparison groups: online against offline optimization and individual against group optimization. For group optimization, we study two prompting strategies: one-pass and multi-pass prompting optimizations. Overall, we demonstrate the effectiveness of our optimization method for role-based multi-agent systems tackling software development tasks evaluated on diverse evaluation dimensions, and we investigate the impact of diverse optimization settings on group behaviors of the multi-agent systems to provide practical insights for future development.","authors":["Ming Shen","Raphael Shu","Anurag Pratik","James Gung","Yubin Ge","Monica Sunkara","Yi Zhang"],"url":"https://arxiv.org/abs/2505.16086"}
{"created":"2025-05-23","title":"Event-based Reconfiguration Control for Time-varying Formation of Robot Swarms in Narrow Spaces","abstract":"This study proposes an event-based reconfiguration control to navigate a robot swarm through challenging environments with narrow passages such as valleys, tunnels, and corridors. The robot swarm is modeled as an undirected graph, where each node represents a robot capable of collecting real-time data on the environment and the states of other robots in the formation. This data serves as the input for the controller to provide dynamic adjustments between the desired and straight-line configurations. The controller incorporates a set of behaviors, designed using artificial potential fields, to meet the requirements of goal-oriented motion, formation maintenance, tailgating, and collision avoidance. The stability of the formation control is guaranteed via the Lyapunov theorem. Simulation and comparison results show that the proposed controller not only successfully navigates the robot swarm through narrow spaces but also outperforms other established methods in key metrics including the success rate, heading order, speed, travel time, and energy efficiency. Software-in-the-loop tests have also been conducted to validate the controller's applicability in practical scenarios. The source code of the controller is available at https://github.com/duynamrcv/erc.","authors":["Duy-Nam Bui","Manh Duong Phung","Hung Pham Duy"],"url":"https://arxiv.org/abs/2505.16087"}
{"created":"2025-05-23","title":"Date Fragments: A Hidden Bottleneck of Tokenization for Temporal Reasoning","abstract":"Modern BPE tokenizers often split calendar dates into meaningless fragments, e.g., 20250312 $\\rightarrow$ 202, 503, 12, inflating token counts and obscuring the inherent structure needed for robust temporal reasoning. In this work, we (1) introduce a simple yet interpretable metric, termed date fragmentation ratio, that measures how faithfully a tokenizer preserves multi-digit date components; (2) release DateAugBench, a suite of 6500 examples spanning three temporal reasoning tasks: context-based date resolution, format-invariance puzzles, and date arithmetic across historical, contemporary, and future regimes; and (3) through layer-wise probing and causal attention-hop analyses, uncover an emergent date-abstraction mechanism whereby large language models stitch together the fragments of month, day, and year components for temporal reasoning. Our experiments show that excessive fragmentation correlates with accuracy drops of up to 10 points on uncommon dates like historical and futuristic dates. Further, we find that the larger the model, the faster the emergent date abstraction that heals date fragments is accomplished. Lastly, we observe a reasoning path that LLMs follow to assemble date fragments, typically differing from human interpretation (year $\\rightarrow$ month $\\rightarrow$ day).","authors":["Gagan Bhatia","Maxime Peyrard","Wei Zhao"],"url":"https://arxiv.org/abs/2505.16088"}
{"created":"2025-05-23","title":"\"If anybody finds out you are in BIG TROUBLE\": Understanding Children's Hopes, Fears, and Evaluations of Generative AI","abstract":"As generative artificial intelligence (genAI) increasingly mediates how children learn, communicate, and engage with digital content, understanding children's hopes and fears about this emerging technology is crucial. In a pilot study with 37 fifth-graders, we explored how children (ages 9-10) envision genAI and the roles they believe it should play in their daily life. Our findings reveal three key ways children envision genAI: as a companion providing guidance, a collaborator working alongside them, and a task automator that offloads responsibilities. However, alongside these hopeful views, children expressed fears about overreliance, particularly in academic settings, linking it to fears of diminished learning, disciplinary consequences, and long-term failure. This study highlights the need for child-centric AI design that balances these tensions, empowering children with the skills to critically engage with and navigate their evolving relationships with digital technologies.","authors":["Aayushi Dangol","Robert Wolfe","Daeun Yoo","Arya Thiruvillakkat","Ben Chickadel","Julie A. Kientz"],"url":"https://arxiv.org/abs/2505.16089"}
{"created":"2025-05-23","title":"Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance","abstract":"As of 2025, Generative Artificial Intelligence (GenAI) has become a central tool for productivity across industries. Beyond text generation, GenAI now plays a critical role in coding, data analysis, and research workflows. As large language models (LLMs) continue to evolve, it is essential to assess the reliability and accuracy of their outputs, especially in specialized, high-stakes domains like finance. Most modern LLMs transform text into numerical vectors, which are used in operations such as cosine similarity searches to generate responses. However, this abstraction process can lead to misinterpretation of emotional tone, particularly in nuanced financial contexts. While LLMs generally excel at identifying sentiment in everyday language, these models often struggle with the nuanced, strategically ambiguous language found in earnings call transcripts. Financial disclosures frequently embed sentiment in hedged statements, forward-looking language, and industry-specific jargon, making it difficult even for human analysts to interpret consistently, let alone AI models. This paper presents findings from the Santa Clara Microsoft Practicum Project, led by Professor Charlie Goldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's ChatGPT, Google's Gemini, and traditional machine learning models for sentiment analysis of financial text. Using Microsoft earnings call transcripts, the analysis assesses how well LLM-derived sentiment correlates with market sentiment and stock movements and evaluates the accuracy of model outputs. Prompt engineering techniques are also examined to improve sentiment analysis results. Visualizations of sentiment consistency are developed to evaluate alignment between tone and stock performance, with sentiment trends analyzed across Microsoft's lines of business to determine which segments exert the greatest influence.","authors":["Dominick Kubica","Dylan T. Gordon","Nanami Emura","Derleen Saini","Charlie Goldenberg"],"url":"https://arxiv.org/abs/2505.16090"}
{"created":"2025-05-23","title":"A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization","abstract":"Large language models (LLMs) are introducing a paradigm shift in molecular discovery by enabling text-guided interaction with chemical spaces through natural language, symbolic notations, with emerging extensions to incorporate multi-modal inputs. To advance the new field of LLM for molecular discovery, this survey provides an up-to-date and forward-looking review of the emerging use of LLMs for two central tasks: molecule generation and molecule optimization. Based on our proposed taxonomy for both problems, we analyze representative techniques in each category, highlighting how LLM capabilities are leveraged across different learning settings. In addition, we include the commonly used datasets and evaluation protocols. We conclude by discussing key challenges and future directions, positioning this survey as a resource for researchers working at the intersection of LLMs and molecular science. A continuously updated reading list is available at https://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.","authors":["Ziqing Wang","Kexin Zhang","Zihan Zhao","Yibo Wen","Abhishek Pandey","Han Liu","Kaize Ding"],"url":"https://arxiv.org/abs/2505.16094"}
{"created":"2025-05-23","title":"Towards Stream-Based Monitoring for EVM Networks","abstract":"We believe that leveraging real-time blockchain operational data is of particular interest in the context of the current rapid expansion of rollup networks in the Ethereum ecosystem. Given the compatible but also competing ground that rollups offer for applications, stream-based monitoring can be of use both to developers and to EVM networks governance. In this paper, we discuss this perspective and propose a basic monitoring pipeline.","authors":["Emanuel Onica","Claudiu-Nicu B\\u{a}rbieru","Andrei Arusoaie","Oana-Otilia Captarencu","Ciprian Amariei"],"url":"https://arxiv.org/abs/2505.16095"}
{"created":"2025-05-23","title":"Cosmos: A CXL-Based Full In-Memory System for Approximate Nearest Neighbor Search","abstract":"Retrieval-Augmented Generation (RAG) is crucial for improving the quality of large language models by injecting proper contexts extracted from external sources. RAG requires high-throughput, low-latency Approximate Nearest Neighbor Search (ANNS) over billion-scale vector databases. Conventional DRAM/SSD solutions face capacity/latency limits, whereas specialized hardware or RDMA clusters lack flexibility or incur network overhead. We present Cosmos, integrating general-purpose cores within CXL memory devices for full ANNS offload and introducing rank-level parallel distance computation to maximize memory bandwidth. We also propose an adjacency-aware data placement that balances search loads across CXL devices based on inter-cluster proximity. Evaluations on SIFT1B and DEEP1B traces show that Cosmos achieves up to 6.72x higher throughput than the baseline CXL system and 2.35x over a state-of-the-art CXL-based solution, demonstrating scalability for RAG pipelines.","authors":["Seoyoung Ko","Hyunjeong Shim","Wanju Doh","Sungmin Yun","Jinin So","Yongsuk Kwon","Sang-Soo Park","Si-Dong Roh","Minyong Yoon","Taeksang Song","Jung Ho Ahn"],"url":"https://arxiv.org/abs/2505.16096"}
{"created":"2025-05-23","title":"TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials","abstract":"Developing artificial intelligence (AI) for vertical domains requires a solid data foundation for both training and evaluation. In this work, we introduce TrialPanorama, a large-scale, structured database comprising 1,657,476 clinical trial records aggregated from 15 global sources. The database captures key aspects of trial design and execution, including trial setups, interventions, conditions, biomarkers, and outcomes, and links them to standard biomedical ontologies such as DrugBank and MedDRA. This structured and ontology-grounded design enables TrialPanorama to serve as a unified, extensible resource for a wide range of clinical trial tasks, including trial planning, design, and summarization. To demonstrate its utility, we derive a suite of benchmark tasks directly from the TrialPanorama database. The benchmark spans eight tasks across two categories: three for systematic review (study search, study screening, and evidence summarization) and five for trial design (arm design, eligibility criteria, endpoint selection, sample size estimation, and trial completion assessment). The experiments using five state-of-the-art large language models (LLMs) show that while general-purpose LLMs exhibit some zero-shot capability, their performance is still inadequate for high-stakes clinical trial workflows. We release TrialPanorama database and the benchmark to facilitate further research on AI for clinical trials.","authors":["Zifeng Wang","Qiao Jin","Jiacheng Lin","Junyi Gao","Jathurshan Pradeepkumar","Pengcheng Jiang","Benjamin Danek","Zhiyong Lu","Jimeng Sun"],"url":"https://arxiv.org/abs/2505.16097"}
{"created":"2025-05-23","title":"Reinforcement Learning for Stock Transactions","abstract":"Much research has been done to analyze the stock market. After all, if one can determine a pattern in the chaotic frenzy of transactions, then they could make a hefty profit from capitalizing on these insights. As such, the goal of our project was to apply reinforcement learning (RL) to determine the best time to buy a stock within a given time frame. With only a few adjustments, our model can be extended to identify the best time to sell a stock as well. In order to use the format of free, real-world data to train the model, we define our own Markov Decision Process (MDP) problem. These two papers [5] [6] helped us in formulating the state space and the reward system of our MDP problem. We train a series of agents using Q-Learning, Q-Learning with linear function approximation, and deep Q-Learning. In addition, we try to predict the stock prices using machine learning regression and classification models. We then compare our agents to see if they converge on a policy, and if so, which one learned the best policy to maximize profit on the stock market.","authors":["Ziyi (Queena)","Zhou","Nicholas Stern","Julien Laasri"],"url":"https://arxiv.org/abs/2505.16099"}
{"created":"2025-05-23","title":"BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research","abstract":"Validating scientific hypotheses is a central challenge in biomedical research, and remains difficult for artificial intelligence (AI) agents due to the complexity of real-world data analysis and evidence interpretation. In this work, we present BioDSA-1K, a benchmark designed to evaluate AI agents on realistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K consists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans, curated from over 300 published biomedical studies to reflect the structure and reasoning found in authentic research workflows. Each task includes a structured hypothesis derived from the original study's conclusions, expressed in the affirmative to reflect the language of scientific reporting, and one or more pieces of supporting evidence grounded in empirical data tables. While these hypotheses mirror published claims, they remain testable using standard statistical or machine learning methods. The benchmark enables evaluation along four axes: (1) hypothesis decision accuracy, (2) alignment between evidence and conclusion, (3) correctness of the reasoning process, and (4) executability of the AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable hypotheses: cases where the available data are insufficient to support or refute a claim, reflecting a common yet underexplored scenario in real-world science. We propose BioDSA-1K as a foundation for building and evaluating generalizable, trustworthy AI agents for biomedical discovery.","authors":["Zifeng Wang","Benjamin Danek","Jimeng Sun"],"url":"https://arxiv.org/abs/2505.16100"}
{"created":"2025-05-23","title":"Continually Self-Improving Language Models for Bariatric Surgery Question--Answering","abstract":"While bariatric and metabolic surgery (MBS) is considered the gold standard treatment for severe and morbid obesity, its therapeutic efficacy hinges upon active and longitudinal engagement with multidisciplinary providers, including surgeons, dietitians/nutritionists, psychologists, and endocrinologists. This engagement spans the entire patient journey, from preoperative preparation to long-term postoperative management. However, this process is often hindered by numerous healthcare disparities, such as logistical and access barriers, which impair easy patient access to timely, evidence-based, clinician-endorsed information. To address these gaps, we introduce bRAGgen, a novel adaptive retrieval-augmented generation (RAG)-based model that autonomously integrates real-time medical evidence when response confidence dips below dynamic thresholds. This self-updating architecture ensures that responses remain current and accurate, reducing the risk of misinformation. Additionally, we present bRAGq, a curated dataset of 1,302 bariatric surgery--related questions, validated by an expert bariatric surgeon. bRAGq constitutes the first large-scale, domain-specific benchmark for comprehensive MBS care. In a two-phase evaluation, bRAGgen is benchmarked against state-of-the-art models using both large language model (LLM)--based metrics and expert surgeon review. Across all evaluation dimensions, bRAGgen demonstrates substantially superior performance in generating clinically accurate and relevant responses.","authors":["Yash Kumar Atri","Thomas H Shin","Thomas Hartvigsen"],"url":"https://arxiv.org/abs/2505.16102"}
{"created":"2025-05-23","title":"Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI","abstract":"Keylogger detection involves monitoring for unusual system behaviors such as delays between typing and character display, analyzing network traffic patterns for data exfiltration. In this study, we provide a comprehensive analysis for keylogger detection with traditional machine learning models - SVC, Random Forest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes and advanced ensemble methods including Stacking, Blending and Voting. Moreover, feature selection approaches such as Information gain, Lasso L1 and Fisher Score are thoroughly assessed to improve predictive performance and lower computational complexity. The Keylogger Detection dataset from publicly available Kaggle website is used in this project. In addition to accuracy-based classification, this study implements the approach for model interpretation using Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to deliver finer explanations for how much each feature contributes in assisting or hindering the detection process. To evaluate the models result, we have used AUC score, sensitivity, Specificity, Accuracy and F1 score. The best performance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99, 100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is near-perfect classification with Fisher Score.","authors":["Monirul Islam Mahmud"],"url":"https://arxiv.org/abs/2505.16103"}
{"created":"2025-05-23","title":"Hierarchical Safety Realignment: Lightweight Restoration of Safety in Pruned Large Vision-Language Models","abstract":"With the increasing size of Large Vision-Language Models (LVLMs), network pruning techniques aimed at compressing models for deployment in resource-constrained environments have garnered significant attention. However, we observe that pruning often leads to a degradation in safety performance. To address this issue, we present a novel and lightweight approach, termed Hierarchical Safety Realignment (HSR). HSR operates by first quantifying the contribution of each attention head to safety, identifying the most critical ones, and then selectively restoring neurons directly within these attention heads that play a pivotal role in maintaining safety. This process hierarchically realigns the safety of pruned LVLMs, progressing from the attention head level to the neuron level. We validate HSR across various models and pruning strategies, consistently achieving notable improvements in safety performance. To our knowledge, this is the first work explicitly focused on restoring safety in LVLMs post-pruning.","authors":["Yue Li","Xin Yi","Dongsheng Shi","Gerard de Melo","Xiaoling Wang","Linlin Wang"],"url":"https://arxiv.org/abs/2505.16104"}
{"created":"2025-05-23","title":"MPL: Multiple Programming Languages with Large Language Models for Information Extraction","abstract":"Recent research in information extraction (IE) focuses on utilizing code-style inputs to enhance structured output generation. The intuition behind this is that the programming languages (PLs) inherently exhibit greater structural organization than natural languages (NLs). This structural advantage makes PLs particularly suited for IE tasks. Nevertheless, existing research primarily focuses on Python for code-style simulation, overlooking the potential of other widely-used PLs (e.g., C++ and Java) during the supervised fine-tuning (SFT) phase. In this research, we propose \\textbf{M}ultiple \\textbf{P}rogramming \\textbf{L}anguages with large language models for information extraction (abbreviated as \\textbf{MPL}), a novel framework that explores the potential of incorporating different PLs in the SFT phase. Additionally, we introduce \\texttt{function-prompt} with virtual running to simulate code-style inputs more effectively and efficiently. Experimental results on a wide range of datasets demonstrate the effectiveness of MPL. Furthermore, we conduct extensive experiments to provide a comprehensive analysis. We have released our code for future research.","authors":["Bo Li","Gexiang Fang","Wei Ye","Zhenghua Xu","Jinglei Zhang","Hao Cheng","Shikun Zhang"],"url":"https://arxiv.org/abs/2505.16107"}
{"created":"2025-05-23","title":"Extensible Post Quantum Cryptography Based Authentication","abstract":"Cryptography underpins the security of modern digital infrastructure, from cloud services to health data. However, many widely deployed systems will become vulnerable after the advent of scalable quantum computing. Although quantum-safe cryptographic primitives have been developed, such as lattice-based digital signature algorithms (DSAs) and key encapsulation mechanisms (KEMs), their unique structural and performance characteristics make them unsuitable for existing protocols. In this work, we introduce a quantum-safe single-shot protocol for machine-to-machine authentication and authorization that is specifically designed to leverage the strengths of lattice-based DSAs and KEMs. Operating entirely over insecure channels, this protocol enables the forward-secure establishment of tokens in constrained environments. By demonstrating how new quantum-safe cryptographic primitives can be incorporated into secure systems, this study lays the groundwork for scalable, resilient, and future-proof identity infrastructures in a quantum-enabled world.","authors":["Homer A. Riva-Cambrin","Rahul Singh","Sanju Lama","Garnette R. Sutherland"],"url":"https://arxiv.org/abs/2505.16112"}
{"created":"2025-05-23","title":"Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools","abstract":"Modern Large Language Models (LLMs) often require external tools, such as machine learning classifiers or knowledge retrieval systems, to provide accurate answers in domains where their pre-trained knowledge is insufficient. This integration of LLMs with external tools expands their utility but also introduces a critical challenge: determining the trustworthiness of responses generated by the combined system. In high-stakes applications, such as medical decision-making, it is essential to assess the uncertainty of both the LLM's generated text and the tool's output to ensure the reliability of the final response. However, existing uncertainty quantification methods do not account for the tool-calling scenario, where both the LLM and external tool contribute to the overall system's uncertainty. In this work, we present a novel framework for modeling tool-calling LLMs that quantifies uncertainty by jointly considering the predictive uncertainty of the LLM and the external tool. We extend previous methods for uncertainty quantification over token sequences to this setting and propose efficient approximations that make uncertainty computation practical for real-world applications. We evaluate our framework on two new synthetic QA datasets, derived from well-known machine learning datasets, which require tool-calling for accurate answers. Additionally, we apply our method to retrieval-augmented generation (RAG) systems and conduct a proof-of-concept experiment demonstrating the effectiveness of our uncertainty metrics in scenarios where external information retrieval is needed. Our results show that the framework is effective in enhancing trust in LLM-based systems, especially in cases where the LLM's internal knowledge is insufficient and external tools are required.","authors":["Panagiotis Lymperopoulos","Vasanth Sarathy"],"url":"https://arxiv.org/abs/2505.16113"}
{"created":"2025-05-23","title":"Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language","abstract":"Solving puzzles in natural language poses a long-standing challenge in AI. While large language models (LLMs) have recently shown impressive capabilities in a variety of tasks, they continue to struggle with complex puzzles that demand precise reasoning and exhaustive search. In this paper, we propose Logic-of-Thought (Logot), a novel framework that bridges LLMs with logic programming to address this problem. Our method leverages LLMs to translate puzzle rules and states into answer set programs (ASPs), the solution of which are then accurately and efficiently inferred by an ASP interpreter. This hybrid approach combines the natural language understanding of LLMs with the precise reasoning capabilities of logic programs. We evaluate our method on various grid puzzles and dynamic puzzles involving actions, demonstrating near-perfect accuracy across all tasks. Our code and data are available at: https://github.com/naiqili/Logic-of-Thought.","authors":["Naiqi Li","Peiyuan Liu","Zheng Liu","Tao Dai","Yong Jiang","Shu-Tao Xia"],"url":"https://arxiv.org/abs/2505.16114"}
{"created":"2025-05-23","title":"A Generic Framework for Conformal Fairness","abstract":"Conformal Prediction (CP) is a popular method for uncertainty quantification with machine learning models. While conformal prediction provides probabilistic guarantees regarding the coverage of the true label, these guarantees are agnostic to the presence of sensitive attributes within the dataset. In this work, we formalize \\textit{Conformal Fairness}, a notion of fairness using conformal predictors, and provide a theoretically well-founded algorithm and associated framework to control for the gaps in coverage between different sensitive groups. Our framework leverages the exchangeability assumption (implicit to CP) rather than the typical IID assumption, allowing us to apply the notion of Conformal Fairness to data types and tasks that are not IID, such as graph data. Experiments were conducted on graph and tabular datasets to demonstrate that the algorithm can control fairness-related gaps in addition to coverage aligned with theoretical expectations.","authors":["Aditya T. Vadlamani","Anutam Srinivasan","Pranav Maneriker","Ali Payani","Srinivasan Parthasarathy"],"url":"https://arxiv.org/abs/2505.16115"}
{"created":"2025-05-23","title":"Semiotic Reconstruction of Destination Expectation Constructs An LLM-Driven Computational Paradigm for Social Media Tourism Analytics","abstract":"Social media's rise establishes user-generated content (UGC) as pivotal for travel decisions, yet analytical methods lack scalability. This study introduces a dual-method LLM framework: unsupervised expectation extraction from UGC paired with survey-informed supervised fine-tuning. Findings reveal leisure/social expectations drive engagement more than foundational natural/emotional factors. By establishing LLMs as precision tools for expectation quantification, we advance tourism analytics methodology and propose targeted strategies for experience personalization and social travel promotion. The framework's adaptability extends to consumer behavior research, demonstrating computational social science's transformative potential in marketing optimization.","authors":["Haotian Lan","Yao Gao","Yujun Cheng","Wei Yuan","Kun Wang"],"url":"https://arxiv.org/abs/2505.16118"}
{"created":"2025-05-23","title":"Source Separation by Flow Matching","abstract":"We consider the problem of single-channel audio source separation with the goal of reconstructing $K$ sources from their mixture. We address this ill-posed problem with FLOSS (FLOw matching for Source Separation), a constrained generation method based on flow matching, ensuring strict mixture consistency. Flow matching is a general methodology that, when given samples from two probability distributions defined on the same space, learns an ordinary differential equation to output a sample from one of the distributions when provided with a sample from the other. In our context, we have access to samples from the joint distribution of $K$ sources and so the corresponding samples from the lower-dimensional distribution of their mixture. To apply flow matching, we augment these mixture samples with artificial noise components to ensure the resulting \"augmented\" distribution matches the dimensionality of the $K$ source distribution. Additionally, as any permutation of the sources yields the same mixture, we adopt an equivariant formulation of flow matching which relies on a suitable custom-designed neural network architecture. We demonstrate the performance of the method for the separation of overlapping speech.","authors":["Robin Scheibler","John R. Hershey","Arnaud Doucet","Henry Li"],"url":"https://arxiv.org/abs/2505.16119"}
{"created":"2025-05-23","title":"LLM-Powered AI Agent Systems and Their Applications in Industry","abstract":"The emergence of Large Language Models (LLMs) has reshaped agent systems. Unlike traditional rule-based agents with limited task scope, LLM-powered agents offer greater flexibility, cross-domain reasoning, and natural language interaction. Moreover, with the integration of multi-modal LLMs, current agent systems are highly capable of processing diverse data modalities, including text, images, audio, and structured tabular data, enabling richer and more adaptive real-world behavior. This paper comprehensively examines the evolution of agent systems from the pre-LLM era to current LLM-powered architectures. We categorize agent systems into software-based, physical, and adaptive hybrid systems, highlighting applications across customer service, software development, manufacturing automation, personalized education, financial trading, and healthcare. We further discuss the primary challenges posed by LLM-powered agents, including high inference latency, output uncertainty, lack of evaluation metrics, and security vulnerabilities, and propose potential solutions to mitigate these concerns.","authors":["Guannan Liang","Qianqian Tong"],"url":"https://arxiv.org/abs/2505.16120"}
{"created":"2025-05-23","title":"Emotion-based Recommender System","abstract":"Recommender system is one of the most critical technologies for large internet companies such as Amazon and TikTok. Although millions of users use recommender systems globally everyday, and indeed, much data analysis work has been done to improve the technical accuracy of the system, to our limited knowledge, there has been little attention paid to analysis of users' emotion in recommender systems. In this paper, we create a new theory and metrics that could capture users' emotion when they are interacting with recommender systems. We also provide effective and efficient visualization techniques for visualization of users' emotion and its change in the customers' lifetime cycle. In the end, we design a framework for emotion-based recommendation algorithms, illustrated in a straightforward example with experimental results to demonstrate the effectiveness of our new theory.","authors":["Hao Wang"],"url":"https://arxiv.org/abs/2505.16121"}
{"created":"2025-05-23","title":"Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning","abstract":"Large Language Models (LLMs) have achieved remarkable success in complex reasoning tasks, but their inference remains computationally inefficient. We observe a common failure mode in many prevalent LLMs, overthinking, where models generate verbose and tangential reasoning traces even for simple queries. Recent works have tried to mitigate this by enforcing fixed token budgets, however, this can lead to underthinking, especially on harder problems. Through empirical analysis, we identify that this inefficiency often stems from unclear problem-solving strategies. To formalize this, we develop a theoretical model, BBAM (Bayesian Budget Allocation Model), which models reasoning as a sequence of sub-questions with varying uncertainty, and introduce the $E^3$ metric to capture the trade-off between correctness and computation efficiency. Building on theoretical results from BBAM, we propose Plan-and-Budget, a model-agnostic, test-time framework that decomposes complex queries into sub-questions and allocates token budgets based on estimated complexity using adaptive scheduling. Plan-and-Budget improves reasoning efficiency across a range of tasks and models, achieving up to +70% accuracy gains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it elevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger model (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close performance gaps without retraining. Our code is available at anonymous.4open.science/r/P-and-B-6513/.","authors":["Junhong Lin","Xinyue Zeng","Jie Zhu","Song Wang","Julian Shun","Jun Wu","Dawei Zhou"],"url":"https://arxiv.org/abs/2505.16122"}
{"created":"2025-05-23","title":"KoBALT: Korean Benchmark For Advanced Linguistic Tasks","abstract":"We introduce KoBALT (Korean Benchmark for Advanced Linguistic Tasks), a comprehensive linguistically-motivated benchmark comprising 700 multiple-choice questions spanning 24 phenomena across five linguistic domains: syntax, semantics, pragmatics, phonetics/phonology, and morphology. KoBALT is designed to advance the evaluation of large language models (LLMs) in Korean, a morphologically rich language, by addressing the limitations of conventional benchmarks that often lack linguistic depth and typological grounding. It introduces a suite of expert-curated, linguistically motivated questions with minimal n-gram overlap with standard Korean corpora, substantially mitigating the risk of data contamination and allowing a more robust assessment of true language understanding. Our evaluation of 20 contemporary LLMs reveals significant performance disparities, with the highest-performing model achieving 61\\% general accuracy but showing substantial variation across linguistic domains - from stronger performance in semantics (66\\%) to considerable weaknesses in phonology (31\\%) and morphology (36\\%). Through human preference evaluation with 95 annotators, we demonstrate a strong correlation between KoBALT scores and human judgments, validating our benchmark's effectiveness as a discriminative measure of Korean language understanding. KoBALT addresses critical gaps in linguistic evaluation for typologically diverse languages and provides a robust framework for assessing genuine linguistic competence in Korean language models.","authors":["Hyopil Shin","Sangah Lee","Dongjun Jang","Wooseok Song","Jaeyoon Kim","Chaeyoung Oh","Hyemi Jo","Youngchae Ahn","Sihyun Oh","Hyohyeong Chang","Sunkyoung Kim","Jinsik Lee"],"url":"https://arxiv.org/abs/2505.16125"}
{"created":"2025-05-23","title":"Robust Invariant Representation Learning by Distribution Extrapolation","abstract":"Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD) generalization in deep learning by learning invariant representations. As IRM poses an inherently challenging bi-level optimization problem, most existing approaches -- including IRMv1 -- adopt penalty-based single-level approximations. However, empirical studies consistently show that these methods often fail to outperform well-tuned empirical risk minimization (ERM), highlighting the need for more robust IRM implementations. This work theoretically identifies a key limitation common to many IRM variants: their penalty terms are highly sensitive to limited environment diversity and over-parameterization, resulting in performance degradation. To address this issue, a novel extrapolation-based framework is proposed that enhances environmental diversity by augmenting the IRM penalty through synthetic distributional shifts. Extensive experiments -- ranging from synthetic setups to realistic, over-parameterized scenarios -- demonstrate that the proposed method consistently outperforms state-of-the-art IRM variants, validating its effectiveness and robustness.","authors":["Kotaro Yoshida","Slavakis Konstantinos"],"url":"https://arxiv.org/abs/2505.16126"}
{"created":"2025-05-23","title":"CMA-ES with Radial Basis Function Surrogate for Black-Box Optimization","abstract":"Evolutionary optimization algorithms often face defects and limitations that complicate the evolution processes or even prevent them from reaching the global optimum. A notable constraint pertains to the considerable quantity of function evaluations required to achieve the intended solution. This concern assumes heightened significance when addressing costly optimization problems. However, recent research has shown that integrating machine learning methods, specifically surrogate models, with evolutionary optimization can enhance various aspects of these algorithms. Among the evolutionary algorithms, the Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES) is particularly favored. This preference is due to its use of Gaussian distribution for calculating evolution and its ability to adapt optimization parameters, which reduces the need for user intervention in adjusting initial parameters. In this research endeavor, we propose the adoption of surrogate models within the CMA-ES framework called CMA-SAO to develop an initial surrogate model that facilitates the adaptation of optimization parameters through the acquisition of pertinent information derived from the associated surrogate model. Empirical validation reveals that CMA-SAO algorithm markedly diminishes the number of function evaluations in comparison to prevailing algorithms, thereby providing a significant enhancement in operational efficiency.","authors":["Farshid Farhadi Khouzani","Abdolreza Mirzaei","Paul La Plante","Laxmi Gewali"],"url":"https://arxiv.org/abs/2505.16127"}
{"created":"2025-05-23","title":"Veracity Bias and Beyond: Uncovering LLMs' Hidden Beliefs in Problem-Solving Reasoning","abstract":"Despite LLMs' explicit alignment against demographic stereotypes, they have been shown to exhibit biases under various social contexts. In this work, we find that LLMs exhibit concerning biases in how they associate solution veracity with demographics. Through experiments across five human value-aligned LLMs on mathematics, coding, commonsense, and writing problems, we reveal two forms of such veracity biases: Attribution Bias, where models disproportionately attribute correct solutions to certain demographic groups, and Evaluation Bias, where models' assessment of identical solutions varies based on perceived demographic authorship. Our results show pervasive biases: LLMs consistently attribute fewer correct solutions and more incorrect ones to African-American groups in math and coding, while Asian authorships are least preferred in writing evaluation. In additional studies, we show LLMs automatically assign racially stereotypical colors to demographic groups in visualization code, suggesting these biases are deeply embedded in models' reasoning processes. Our findings indicate that demographic bias extends beyond surface-level stereotypes and social context provocations, raising concerns about LLMs' deployment in educational and evaluation settings.","authors":["Yue Zhou","Barbara Di Eugenio"],"url":"https://arxiv.org/abs/2505.16128"}
{"created":"2025-05-23","title":"LLMs Are Not Scorers: Rethinking MT Evaluation with Generation-Based Methods","abstract":"Recent studies have applied large language models (LLMs) to machine translation quality estimation (MTQE) by prompting models to assign numeric scores. Nonetheless, these direct scoring methods tend to show low segment-level correlation with human judgments. In this paper, we propose a generation-based evaluation paradigm that leverages decoder-only LLMs to produce high-quality references, followed by semantic similarity scoring using sentence embeddings. We conduct the most extensive evaluation to date in MTQE, covering 8 LLMs and 8 language pairs. Empirical results show that our method outperforms both intra-LLM direct scoring baselines and external non-LLM reference-free metrics from MTME. These findings demonstrate the strength of generation-based evaluation and support a shift toward hybrid approaches that combine fluent generation with accurate semantic assessment.","authors":["Hyang Cui"],"url":"https://arxiv.org/abs/2505.16129"}
{"created":"2025-05-23","title":"Scalable Graph Generative Modeling via Substructure Sequences","abstract":"Graph neural networks (GNNs) has been predominantly driven by message-passing, where node representations are iteratively updated via local neighborhood aggregation. Despite their success, message-passing suffers from fundamental limitations -- including constrained expressiveness, over-smoothing, over-squashing, and limited capacity to model long-range dependencies. These issues hinder scalability: increasing data size or model size often fails to yield improved performance, limiting the viability of GNNs as backbones for graph foundation models. In this work, we explore pathways beyond message-passing and introduce Generative Graph Pattern Machine (G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM represents graph instances (nodes, edges, or entire graphs) as sequences of substructures, and employs generative pre-training over the sequences to learn generalizable, transferable representations. Empirically, G$^2$PM demonstrates strong scalability: on the ogbn-arxiv benchmark, it continues to improve with model sizes up to 60M parameters, outperforming prior generative approaches that plateau at significantly smaller scales (e.g., 3M). In addition, we systematically analyze the model design space, highlighting key architectural choices that contribute to its scalability and generalization. Across diverse tasks -- including node classification, graph classification, and transfer learning -- G$^2$PM consistently outperforms strong baselines, establishing a compelling foundation for scalable graph learning. The code and dataset are available at https://github.com/Zehong-Wang/G2PM.","authors":["Zehong Wang","Zheyuan Zhang","Tianyi Ma","Chuxu Zhang","Yanfang Ye"],"url":"https://arxiv.org/abs/2505.16130"}
{"created":"2025-05-23","title":"HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) encounters efficiency challenges when scaling to massive knowledge bases while preserving contextual relevance. We propose Hash-RAG, a framework that integrates deep hashing techniques with systematic optimizations to address these limitations. Our queries directly learn binary hash codes from knowledgebase code, eliminating intermediate feature extraction steps, and significantly reducing storage and computational overhead. Building upon this hash-based efficient retrieval framework, we establish the foundation for fine-grained chunking. Consequently, we design a Prompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved hash-indexed propositions and their original document segments through prompt engineering to enhance the LLM's contextual awareness. Experimental evaluations on NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a 90% reduction in retrieval time compared to conventional methods while maintaining considerate recall performance. Additionally, The proposed system outperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.","authors":["Jinyu Guo","Xunlei Chen","Qiyang Xia","Zhaokun Wang","Jie Ou","Libo Qin","Shunyu Yao","Wenhong Tian"],"url":"https://arxiv.org/abs/2505.16133"}
{"created":"2025-05-23","title":"Position of Uncertainty: A Cross-Linguistic Study of Positional Bias in Large Language Models","abstract":"Large language models exhibit positional bias -- systematic neglect of information at specific context positions -- yet its interplay with linguistic diversity remains poorly understood. We present a cross-linguistic study across five typologically distinct languages (English, Russian, German, Hindi, Vietnamese), examining how positional bias interacts with model uncertainty, syntax, and prompting. Key findings: (1) Positional bias is model-driven, with language-specific variations -- Qwen2.5-7B favors late positions, challenging assumptions of early-token bias; (2) Explicit positional guidance (e.g., correct context is at position X) reduces accuracy across languages, undermining prompt-engineering practices; (3) Aligning context with positional bias increases entropy, yet minimal entropy does not predict accuracy. (4) We further uncover that LLMs differently impose dominant word order in free-word-order languages like Hindi.","authors":["Menschikov Mikhail","Alexander Kharitonov","Maiia Kotyga","Vadim Porvatov","Anna Zhukovskaya","David Kagramanyan","Egor Shvetsov","Evgeny Burnaev"],"url":"https://arxiv.org/abs/2505.16134"}
{"created":"2025-05-23","title":"Sudoku-Bench: Evaluating creative reasoning with Sudoku variants","abstract":"Existing reasoning benchmarks for large language models (LLMs) frequently fail to capture authentic creativity, often rewarding memorization of previously observed patterns. We address this shortcoming with Sudoku-Bench, a curated benchmark of challenging and unconventional Sudoku variants specifically selected to evaluate creative, multi-step logical reasoning. Sudoku variants form an unusually effective domain for reasoning research: each puzzle introduces unique or subtly interacting constraints, making memorization infeasible and requiring solvers to identify novel logical breakthroughs (``break-ins''). Despite their diversity, Sudoku variants maintain a common and compact structure, enabling clear and consistent evaluation. Sudoku-Bench includes a carefully chosen puzzle set, a standardized text-based puzzle representation, and flexible tools compatible with thousands of publicly available puzzles -- making it easy to extend into a general research environment. Baseline experiments show that state-of-the-art LLMs solve fewer than 15\\% of puzzles unaided, highlighting significant opportunities to advance long-horizon, strategic reasoning capabilities.","authors":["Jeffrey Seely","Yuki Imajuku","Tianyu Zhao","Edoardo Cetin","Llion Jones"],"url":"https://arxiv.org/abs/2505.16135"}
{"created":"2025-05-23","title":"Outsourcing SAT-based Verification Computations in Network Security","abstract":"The emergence of cloud computing gives huge impact on large computations. Cloud computing platforms offer servers with large computation power to be available for customers. These servers can be used efficiently to solve problems that are complex by nature, for example, satisfiability (SAT) problems. Many practical problems can be converted to SAT, for example, circuit verification and network configuration analysis. However, outsourcing SAT instances to the servers may cause data leakage that can jeopardize system's security. Before","authors":["Qi Duan","Ehab Al-Shaer"],"url":"https://arxiv.org/abs/2505.16137"}
{"created":"2025-05-23","title":"Multimodal Online Federated Learning with Modality Missing in Internet of Things","abstract":"The Internet of Things (IoT) ecosystem generates vast amounts of multimodal data from heterogeneous sources such as sensors, cameras, and microphones. As edge intelligence continues to evolve, IoT devices have progressed from simple data collection units to nodes capable of executing complex computational tasks. This evolution necessitates the adoption of distributed learning strategies to effectively handle multimodal data in an IoT environment. Furthermore, the real-time nature of data collection and limited local storage on edge devices in IoT call for an online learning paradigm. To address these challenges, we introduce the concept of Multimodal Online Federated Learning (MMO-FL), a novel framework designed for dynamic and decentralized multimodal learning in IoT environments. Building on this framework, we further account for the inherent instability of edge devices, which frequently results in missing modalities during the learning process. We conduct a comprehensive theoretical analysis under both complete and missing modality scenarios, providing insights into the performance degradation caused by missing modalities. To mitigate the impact of modality missing, we propose the Prototypical Modality Mitigation (PMM) algorithm, which leverages prototype learning to effectively compensate for missing modalities. Experimental results on two multimodal datasets further demonstrate the superior performance of PMM compared to benchmarks.","authors":["Heqiang Wang","Xiang Liu","Xiaoxiong Zhong","Lixing Chen","Fangming Liu","Weizhe Zhang"],"url":"https://arxiv.org/abs/2505.16138"}
{"created":"2025-05-23","title":"On the Runtime of Local Mutual Exclusion for Anonymous Dynamic Networks","abstract":"Algorithms for mutual exclusion aim to isolate potentially concurrent accesses to the same shared resources. Motivated by distributed computing research on programmable matter and population protocols where interactions among entities are often assumed to be isolated, Daymude, Richa, and Scheideler (SAND`22) introduced a variant of the local mutual exclusion problem that applies to arbitrary dynamic networks: each node, on issuing a lock request, must acquire exclusive locks on itself and all its persistent neighbors, i.e., the neighbors that remain connected to it over the duration of the lock request. Assuming adversarial edge dynamics, semi-synchronous or asynchronous concurrency, and anonymous nodes communicating via message passing, their randomized algorithm achieves mutual exclusion (non-intersecting lock sets) and lockout freedom (eventual success with probability 1). However, they did not analyze their algorithm's runtime. In this paper, we prove that any node will successfully lock itself and its persistent neighbors within O$(n\\Delta^3)$ open rounds of its lock request in expectation, where $n$ is the number of nodes in the dynamic network, $\\Delta$ is the maximum degree of the dynamic network, rounds are normalized to the execution time of the ``slowest'' node, and ``closed'' rounds when some persistent neighbors are already locked by another node are ignored (i.e., only ``open\" rounds are considered).","authors":["Anya Chaturvedi","Joshua J. Daymude","Andr\\'ea W. Richa"],"url":"https://arxiv.org/abs/2505.16139"}
{"created":"2025-05-23","title":"Persuasive Prediction via Decision Calibration","abstract":"Bayesian persuasion, a central model in information design, studies how a sender, who privately observes a state drawn from a prior distribution, strategically sends a signal to influence a receiver's action. A key assumption is that both sender and receiver share the precise knowledge of the prior. Although this prior can be estimated from past data, such assumptions break down in high-dimensional or infinite state spaces, where learning an accurate prior may require a prohibitive amount of data. In this paper, we study a learning-based variant of persuasion, which we term persuasive prediction. This setting mirrors Bayesian persuasion with large state spaces, but crucially does not assume a common prior: the sender observes covariates $X$, learns to predict a payoff-relevant outcome $Y$ from past data, and releases a prediction to influence a population of receivers.","authors":["Jingwu Tang","Jiahao Zhang","Fei Fang","Zhiwei Steven Wu"],"url":"https://arxiv.org/abs/2505.16141"}
{"created":"2025-05-23","title":"Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via Reinforcement Learning","abstract":"Distilling reasoning paths from teacher to student models via supervised fine-tuning (SFT) provides a shortcut for improving the reasoning ability of smaller Large Language Models (LLMs). However, the reasoning paths generated by teacher models often reflect only surface-level traces of their underlying authentic reasoning. Insights from cognitive neuroscience suggest that authentic reasoning involves a complex interweaving between meta-reasoning (which selects appropriate sub-problems from multiple candidates) and solving (which addresses the sub-problem). This implies authentic reasoning has an implicit multi-branch structure. Supervised fine-tuning collapses this rich structure into a flat sequence of token prediction in the teacher's reasoning path, preventing effective distillation of this structure to students. To address this limitation, we propose RLKD, a reinforcement learning (RL)-based distillation framework guided by a novel Generative Structure Reward Model (GSRM). Our GSRM converts reasoning paths into multiple meta-reasoning-solving steps and computes rewards to measure structural alignment between student and teacher reasoning. RLKD combines this reward with RL, enabling student LLMs to internalize the teacher's implicit multi-branch reasoning structure rather than merely mimicking fixed output paths. Experiments show RLKD surpasses standard SFT-RL pipelines even when trained on 0.1% of data under an RL-only regime, unlocking greater student reasoning potential than SFT-based distillation.","authors":["Shicheng Xu","Liang Pang","Yunchang Zhu","Jia Gu","Zihao Wei","Jingcheng Deng","Feiyang Pan","Huawei Shen","Xueqi Cheng"],"url":"https://arxiv.org/abs/2505.16142"}
{"created":"2025-05-23","title":"GMatch: Geometry-Constrained Feature Matching for RGB-D Object Pose Estimation","abstract":"We present GMatch, a learning-free feature matcher designed for robust 6DoF object pose estimation, addressing common local ambiguities in sparse feature matching. Unlike traditional methods that rely solely on descriptor similarity, GMatch performs a guided, incremental search, enforcing SE(3)-invariant geometric consistency throughout the matching process. It leverages a provably complete set of geometric features that uniquely determine 3D keypoint configurations, ensuring globally consistent correspondences without the need for training or GPU support. When combined with classical descriptors such as SIFT, GMatch-SIFT forms a general-purpose pose estimation pipeline that offers strong interpretability and generalization across diverse objects and scenes. Experiments on the HOPE dataset show that GMatch outperforms both traditional and learning-based matchers, with GMatch-SIFT achieving or surpassing the performance of instance-level pose networks. On the YCB-Video dataset, GMatch-SIFT demonstrates high accuracy and low variance on texture-rich objects. These results not only validate the effectiveness of GMatch-SIFT for object pose estimation but also highlight the broader applicability of GMatch as a general-purpose feature matcher. Code will be released upon acceptance.","authors":["Ming Yang","Haoran Li"],"url":"https://arxiv.org/abs/2505.16144"}
{"created":"2025-05-23","title":"Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation","abstract":"Large vision-language models (LVLMs) have achieved remarkable performance on multimodal tasks such as visual question answering (VQA) and image captioning. However, they still suffer from hallucinations, generating text inconsistent with visual input, posing significant risks in real-world applications. Existing approaches to address this issue focus on incorporating external knowledge bases, alignment training, or decoding strategies, all of which require substantial computational cost and time. Recent works try to explore more efficient alternatives by adjusting LVLMs' internal representations. Although promising, these methods may cause hallucinations to be insufficiently suppressed or lead to excessive interventions that negatively affect normal semantics. In this work, we leverage sparse autoencoders (SAEs) to identify semantic directions closely associated with either hallucinations or actuality, realizing more precise and direct hallucination-related representations. Our analysis demonstrates that interventions along the faithful direction we identified can mitigate hallucinations, while those along the hallucinatory direction can exacerbate them. Building on these insights, we propose Steering LVLMs via SAE Latent Directions (SSL), a training-free method based on SAE-derived latent directions to mitigate hallucinations in LVLMs. Extensive experiments demonstrate that SSL significantly outperforms existing decoding approaches in mitigating hallucinations, while maintaining transferability across different model architectures with negligible additional time overhead.","authors":["Zhenglin Hua","Jinghan He","Zijun Yao","Tianxu Han","Haiyun Guo","Yuheng Jia","Junfeng Fang"],"url":"https://arxiv.org/abs/2505.16146"}
{"created":"2025-05-23","title":"Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value","abstract":"The proliferation of large models has intensified the need for efficient data valuation methods to quantify the contribution of individual data providers. Traditional approaches, such as game-theory-based Shapley value and influence-function-based techniques, face prohibitive computational costs or require access to full data and model training details, making them hardly achieve partial data valuation. To address this, we propose Unlearning Shapley, a novel framework that leverages machine unlearning to estimate data values efficiently. By unlearning target data from a pretrained model and measuring performance shifts on a reachable test set, our method computes Shapley values via Monte Carlo sampling, avoiding retraining and eliminating dependence on full data. Crucially, Unlearning Shapley supports both full and partial data valuation, making it scalable for large models (e.g., LLMs) and practical for data markets. Experiments on benchmark datasets and large-scale text corpora demonstrate that our approach matches the accuracy of state-of-the-art methods while reducing computational overhead by orders of magnitude. Further analysis confirms a strong correlation between estimated values and the true impact of data subsets, validating its reliability in real-world scenarios. This work bridges the gap between data valuation theory and practical deployment, offering a scalable, privacy-compliant solution for modern AI ecosystems.","authors":["Le Ma","Shirao Yang","Zihao Wang","Yinggui Wang","Lei Wang","Tao Wei","Kejun Zhang"],"url":"https://arxiv.org/abs/2505.16147"}
{"created":"2025-05-23","title":"NAN: A Training-Free Solution to Coefficient Estimation in Model Merging","abstract":"Model merging offers a training-free alternative to multi-task learning by combining independently fine-tuned models into a unified one without access to raw data. However, existing approaches often rely on heuristics to determine the merging coefficients, limiting their scalability and generality. In this work, we revisit model merging through the lens of least-squares optimization and show that the optimal merging weights should scale with the amount of task-specific information encoded in each model. Based on this insight, we propose NAN, a simple yet effective method that estimates model merging coefficients via the inverse of parameter norm. NAN is training-free, plug-and-play, and applicable to a wide range of merging strategies. Extensive experiments on show that NAN consistently improves performance of baseline methods.","authors":["Chongjie Si","Kangtao Lv","Jingjing Jiang","Yadao Wang","Yongwei Wang","Xiaokang Yang","Wenbo Su","Bo Zheng","Wei Shen"],"url":"https://arxiv.org/abs/2505.16148"}
{"created":"2025-05-23","title":"When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification","abstract":"Image classification benchmark datasets such as CIFAR, MNIST, and ImageNet serve as critical tools for model evaluation. However, despite the cleaning efforts, these datasets still suffer from pervasive noisy labels and often contain missing labels due to the co-existing image pattern where multiple classes appear in an image sample. This results in misleading model comparisons and unfair evaluations. Existing label cleaning methods focus primarily on noisy labels, but the issue of missing labels remains largely overlooked. Motivated by these challenges, we present a comprehensive framework named REVEAL, integrating state-of-the-art pre-trained vision-language models (e.g., LLaVA, BLIP, Janus, Qwen) with advanced machine/human label curation methods (e.g., Docta, Cleanlab, MTurk), to systematically address both noisy labels and missing label detection in widely-used image classification test sets. REVEAL detects potential noisy labels and omissions, aggregates predictions from various methods, and refines label accuracy through confidence-informed predictions and consensus-based filtering. Additionally, we provide a thorough analysis of state-of-the-art vision-language models and pre-trained image classifiers, highlighting their strengths and limitations within the context of dataset renovation by revealing 10 observations. Our method effectively reveals missing labels from public datasets and provides soft-labeled results with likelihoods. Through human verifications, REVEAL significantly improves the quality of 6 benchmark test sets, highly aligning to human judgments and enabling more accurate and meaningful comparisons in image classification.","authors":["Zirui Pang","Haosheng Tan","Yuhan Pu","Zhijie Deng","Zhouan Shen","Keyu Hu","Jiaheng Wei"],"url":"https://arxiv.org/abs/2505.16149"}
{"created":"2025-05-23","title":"Training-Free Reasoning and Reflection in MLLMs","abstract":"Recent advances in Reasoning LLMs (e.g., DeepSeek-R1 and OpenAI-o1) have showcased impressive reasoning capabilities via reinforcement learning. However, extending these capabilities to Multimodal LLMs (MLLMs) is hampered by the prohibitive costs of retraining and the scarcity of high-quality, verifiable multimodal reasoning datasets. This paper introduces FRANK Model, a training-FRee ANd r1-liKe MLLM that imbues off-the-shelf MLLMs with reasoning and reflection abilities, without any gradient updates or extra supervision. Our key insight is to decouple perception and reasoning across MLLM decoder layers. Specifically, we observe that compared to the deeper decoder layers, the shallow decoder layers allocate more attention to visual tokens, while the deeper decoder layers concentrate on textual semantics. This observation motivates a hierarchical weight merging approach that combines a visual-pretrained MLLM with a reasoning-specialized LLM. To this end, we propose a layer-wise, Taylor-derived closed-form fusion mechanism that integrates reasoning capacity into deep decoder layers while preserving visual grounding in shallow decoder layers. Extensive experiments on challenging multimodal reasoning benchmarks demonstrate the effectiveness of our approach. On the MMMU benchmark, our model FRANK-38B achieves an accuracy of 69.2, outperforming the strongest baseline InternVL2.5-38B by +5.3, and even surpasses the proprietary GPT-4o model. Our project homepage is at: http://iip.whu.edu.cn/frank/index.html","authors":["Hongchen Wei","Zhenzhong Chen"],"url":"https://arxiv.org/abs/2505.16151"}
{"created":"2025-05-23","title":"BadDepth: Backdoor Attacks Against Monocular Depth Estimation in the Physical World","abstract":"In recent years, deep learning-based Monocular Depth Estimation (MDE) models have been widely applied in fields such as autonomous driving and robotics. However, their vulnerability to backdoor attacks remains unexplored. To fill the gap in this area, we conduct a comprehensive investigation of backdoor attacks against MDE models. Typically, existing backdoor attack methods can not be applied to MDE models. This is because the label used in MDE is in the form of a depth map. To address this, we propose BadDepth, the first backdoor attack targeting MDE models. BadDepth overcomes this limitation by selectively manipulating the target object's depth using an image segmentation model and restoring the surrounding areas via depth completion, thereby generating poisoned datasets for object-level backdoor attacks. To improve robustness in physical world scenarios, we further introduce digital-to-physical augmentation to adapt to the domain gap between the physical world and the digital domain. Extensive experiments on multiple models validate the effectiveness of BadDepth in both the digital domain and the physical world, without being affected by environmental factors.","authors":["Ji Guo","Long Zhou","Zhijin Wang","Jiaming He","Qiyang Song","Aiguo Chen","Wenbo Jiang"],"url":"https://arxiv.org/abs/2505.16154"}
{"created":"2025-05-23","title":"Breaking Complexity Barriers: High-Resolution Image Restoration with Rank Enhanced Linear Attention","abstract":"Transformer-based models have made remarkable progress in image restoration (IR) tasks. However, the quadratic complexity of self-attention in Transformer hinders its applicability to high-resolution images. Existing methods mitigate this issue with sparse or window-based attention, yet inherently limit global context modeling. Linear attention, a variant of softmax attention, demonstrates promise in global context modeling while maintaining linear complexity, offering a potential solution to the above challenge. Despite its efficiency benefits, vanilla linear attention suffers from a significant performance drop in IR, largely due to the low-rank nature of its attention map. To counter this, we propose Rank Enhanced Linear Attention (RELA), a simple yet effective method that enriches feature representations by integrating a lightweight depthwise convolution. Building upon RELA, we propose an efficient and effective image restoration Transformer, named LAformer. LAformer achieves effective global perception by integrating linear attention and channel attention, while also enhancing local fitting capabilities through a convolutional gated feed-forward network. Notably, LAformer eliminates hardware-inefficient operations such as softmax and window shifting, enabling efficient processing of high-resolution images. Extensive experiments across 7 IR tasks and 21 benchmarks demonstrate that LAformer outperforms SOTA methods and offers significant computational advantages.","authors":["Yuang Ai","Huaibo Huang","Tao Wu","Qihang Fan","Ran He"],"url":"https://arxiv.org/abs/2505.16157"}
{"created":"2025-05-23","title":"Why Can Accurate Models Be Learned from Inaccurate Annotations?","abstract":"Learning from inaccurate annotations has gained significant attention due to the high cost of precise labeling. However, despite the presence of erroneous labels, models trained on noisy data often retain the ability to make accurate predictions. This intriguing phenomenon raises a fundamental yet largely unexplored question: why models can still extract correct label information from inaccurate annotations remains unexplored. In this paper, we conduct a comprehensive investigation into this issue. By analyzing weight matrices from both empirical and theoretical perspectives, we find that label inaccuracy primarily accumulates noise in lower singular components and subtly perturbs the principal subspace. Within a certain range, the principal subspaces of weights trained on inaccurate labels remain largely aligned with those learned from clean labels, preserving essential task-relevant information. We formally prove that the angles of principal subspaces exhibit minimal deviation under moderate label inaccuracy, explaining why models can still generalize effectively. Building on these insights, we propose LIP, a lightweight plug-in designed to help classifiers retain principal subspace information while mitigating noise induced by label inaccuracy. Extensive experiments on tasks with various inaccuracy conditions demonstrate that LIP consistently enhances the performance of existing algorithms. We hope our findings can offer valuable theoretical and practical insights to understand of model robustness under inaccurate supervision.","authors":["Chongjie Si","Yidan Cui","Fuchao Yang","Xiaokang Yang","Wei Shen"],"url":"https://arxiv.org/abs/2505.16159"}
{"created":"2025-05-23","title":"EduBench: A Comprehensive Benchmarking Dataset for Evaluating Large Language Models in Diverse Educational Scenarios","abstract":"As large language models continue to advance, their application in educational contexts remains underexplored and under-optimized. In this paper, we address this gap by introducing the first diverse benchmark tailored for educational scenarios, incorporating synthetic data containing 9 major scenarios and over 4,000 distinct educational contexts. To enable comprehensive assessment, we propose a set of multi-dimensional evaluation metrics that cover 12 critical aspects relevant to both teachers and students. We further apply human annotation to ensure the effectiveness of the model-generated evaluation responses. Additionally, we succeed to train a relatively small-scale model on our constructed dataset and demonstrate that it can achieve performance comparable to state-of-the-art large models (e.g., Deepseek V3, Qwen Max) on the test set. Overall, this work provides a practical foundation for the development and evaluation of education-oriented language models. Code and data are released at https://github.com/ybai-nlp/EduBench.","authors":["Bin Xu","Yu Bai","Huashan Sun","Yiguan Lin","Siming Liu","Xinyue Liang","Yaolin Li","Yang Gao","Heyan Huang"],"url":"https://arxiv.org/abs/2505.16160"}
{"created":"2025-05-23","title":"Deep Learning-Driven Ultra-High-Definition Image Restoration: A Survey","abstract":"Ultra-high-definition (UHD) image restoration aims to specifically solve the problem of quality degradation in ultra-high-resolution images. Recent advancements in this field are predominantly driven by deep learning-based innovations, including enhancements in dataset construction, network architecture, sampling strategies, prior knowledge integration, and loss functions. In this paper, we systematically review recent progress in UHD image restoration, covering various aspects ranging from dataset construction to algorithm design. This serves as a valuable resource for understanding state-of-the-art developments in the field. We begin by summarizing degradation models for various image restoration subproblems, such as super-resolution, low-light enhancement, deblurring, dehazing, deraining, and desnowing, and emphasizing the unique challenges of their application to UHD image restoration. We then highlight existing UHD benchmark datasets and organize the literature according to degradation types and dataset construction methods. Following this, we showcase major milestones in deep learning-driven UHD image restoration, reviewing the progression of restoration tasks, technological developments, and evaluations of existing methods. We further propose a classification framework based on network architectures and sampling strategies, helping to clearly organize existing methods. Finally, we share insights into the current research landscape and propose directions for further advancements. A related repository is available at https://github.com/wlydlut/UHD-Image-Restoration-Survey.","authors":["Liyan Wang","Weixiang Zhou","Cong Wang","Kin-Man Lam","Zhixun Su","Jinshan Pan"],"url":"https://arxiv.org/abs/2505.16161"}
{"created":"2025-05-23","title":"KNN-SSD: Enabling Dynamic Self-Speculative Decoding via Nearest Neighbor Layer Set Optimization","abstract":"Speculative Decoding (SD) has emerged as a widely used paradigm to accelerate the inference of large language models (LLMs) without compromising generation quality. It works by efficiently drafting multiple tokens using a compact model and then verifying them in parallel using the target LLM. Notably, Self-Speculative Decoding proposes skipping certain layers to construct the draft model, which eliminates the need for additional parameters or training. Despite its strengths, we observe in this work that drafting with layer skipping exhibits significant sensitivity to domain shifts, leading to a substantial drop in acceleration performance. To enhance the domain generalizability of this paradigm, we introduce KNN-SSD, an algorithm that leverages K-Nearest Neighbor (KNN) search to match different skipped layers with various domain inputs. We evaluated our algorithm in various models and multiple tasks, observing that its application leads to 1.3x-1.6x speedup in LLM inference.","authors":["Mingbo Song","Heming Xia","Jun Zhang","Chak Tou Leong","Qiancheng Xu","Wenjie Li","Sujian Li"],"url":"https://arxiv.org/abs/2505.16162"}
{"created":"2025-05-23","title":"Can LLMs Simulate Human Behavioral Variability? A Case Study in the Phonemic Fluency Task","abstract":"Large language models (LLMs) are increasingly explored as substitutes for human participants in cognitive tasks, but their ability to simulate human behavioral variability remains unclear. This study examines whether LLMs can approximate individual differences in the phonemic fluency task, where participants generate words beginning with a target letter. We evaluated 34 model configurations, varying prompt specificity, sampling temperature, and model type, and compared outputs to responses from 106 human participants. While some configurations, especially Claude 3.7 Sonnet, matched human averages and lexical preferences, none reproduced the scope of human variability. LLM outputs were consistently less diverse and structurally rigid, and LLM ensembles failed to increase diversity. Network analyses further revealed fundamental differences in retrieval structure between humans and models. These results highlight key limitations in using LLMs to simulate human cognition and behavior.","authors":["Mengyang Qiu","Zoe Brisebois","Siena Sun"],"url":"https://arxiv.org/abs/2505.16164"}
{"created":"2025-05-23","title":"RE-TRIP : Reflectivity Instance Augmented Triangle Descriptor for 3D Place Recognition","abstract":"While most people associate LiDAR primarily with its ability to measure distances and provide geometric information about the environment (via point clouds), LiDAR also captures additional data, including reflectivity or intensity values. Unfortunately, when LiDAR is applied to Place Recognition (PR) in mobile robotics, most previous works on LiDAR-based PR rely only on geometric measurements, neglecting the additional reflectivity information that LiDAR provides. In this paper, we propose a novel descriptor for 3D PR, named RE-TRIP (REflectivity-instance augmented TRIangle descriPtor). This new descriptor leverages both geometric measurements and reflectivity to enhance robustness in challenging scenarios such as geometric degeneracy, high geometric similarity, and the presence of dynamic objects. To implement RE-TRIP in real-world applications, we further propose (1) a keypoint extraction method, (2) a key instance segmentation method, (3) a RE-TRIP matching method, and (4) a reflectivity-combined loop verification method. Finally, we conduct a series of experiments to demonstrate the effectiveness of RE-TRIP. Applied to public datasets (i.e., HELIPR, FusionPortable) containing diverse scenarios such as long corridors, bridges, large-scale urban areas, and highly dynamic environments -- our experimental results show that the proposed method outperforms existing state-of-the-art methods in terms of Scan Context, Intensity Scan Context, and STD.","authors":["Yechan Park","Gyuhyeon Pak","Euntai Kim"],"url":"https://arxiv.org/abs/2505.16165"}
{"created":"2025-05-23","title":"TRAIL: Transferable Robust Adversarial Images via Latent diffusion","abstract":"Adversarial attacks exploiting unrestricted natural perturbations present severe security risks to deep learning systems, yet their transferability across models remains limited due to distribution mismatches between generated adversarial features and real-world data. While recent works utilize pre-trained diffusion models as adversarial priors, they still encounter challenges due to the distribution shift between the distribution of ideal adversarial samples and the natural image distribution learned by the diffusion model. To address the challenge, we propose Transferable Robust Adversarial Images via Latent Diffusion (TRAIL), a test-time adaptation framework that enables the model to generate images from a distribution of images with adversarial features and closely resembles the target images. To mitigate the distribution shift, during attacks, TRAIL updates the diffusion U-Net's weights by combining adversarial objectives (to mislead victim models) and perceptual constraints (to preserve image realism). The adapted model then generates adversarial samples through iterative noise injection and denoising guided by these objectives. Experiments demonstrate that TRAIL significantly outperforms state-of-the-art methods in cross-model attack transferability, validating that distribution-aligned adversarial feature synthesis is critical for practical black-box attacks.","authors":["Yuhao Xue","Zhifei Zhang","Xinyang Jiang","Yifei Shen","Junyao Gao","Wentao Gu","Jiale Zhao","Miaojing Shi","Cairong Zhao"],"url":"https://arxiv.org/abs/2505.16166"}
{"created":"2025-05-23","title":"Tactile-based Reinforcement Learning for Adaptive Grasping under Observation Uncertainties","abstract":"Robotic manipulation in industrial scenarios such as construction commonly faces uncertain observations in which the state of the manipulating object may not be accurately captured due to occlusions and partial observables. For example, object status estimation during pipe assembly, rebar installation, and electrical installation can be impacted by observation errors. Traditional vision-based grasping methods often struggle to ensure robust stability and adaptability. To address this challenge, this paper proposes a tactile simulator that enables a tactile-based adaptive grasping method to enhance grasping robustness. This approach leverages tactile feedback combined with the Proximal Policy Optimization (PPO) reinforcement learning algorithm to dynamically adjust the grasping posture, allowing adaptation to varying grasping conditions under inaccurate object state estimations. Simulation results demonstrate that the proposed method effectively adapts grasping postures, thereby improving the success rate and stability of grasping tasks.","authors":["Xiao Hu","Yang Ye"],"url":"https://arxiv.org/abs/2505.16167"}
{"created":"2025-05-23","title":"Selective Invocation for Multilingual ASR: A Cost-effective Approach Adapting to Speech Recognition Difficulty","abstract":"Although multilingual automatic speech recognition (ASR) systems have significantly advanced, enabling a single model to handle multiple languages, inherent linguistic differences and data imbalances challenge SOTA performance across all languages. While language identification (LID) models can route speech to the appropriate ASR model, they incur high costs from invoking SOTA commercial models and suffer from inaccuracies due to misclassification. To overcome these, we propose SIMA, a selective invocation for multilingual ASR that adapts to the difficulty level of the input speech. Built on a spoken large language model (SLLM), SIMA evaluates whether the input is simple enough for direct transcription or requires the invocation of a SOTA ASR model. Our approach reduces word error rates by 18.7% compared to the SLLM and halves invocation costs compared to LID-based methods. Tests on three datasets show that SIMA is a scalable, cost-effective solution for multilingual ASR applications.","authors":["Hongfei Xue","Yufeng Tang","Jun Zhang","Xuelong Geng","Lei Xie"],"url":"https://arxiv.org/abs/2505.16168"}
{"created":"2025-05-23","title":"Partitioning and Observability in Linear Systems via Submodular Optimization","abstract":"Network partitioning has gained recent attention as a pathway to enable decentralized operation and control in large-scale systems. This paper addresses the interplay between partitioning, observability, and sensor placement (SP) in dynamic networks. The problem, being computationally intractable at scale, is largely unexplored in the literature. To that end, the paper's objective is designing scalable partitioning of linear systems while maximizing observability metrics of the subsystems. We show that the partitioning problem can be posed as a submodular maximization problem -- and the SP problem can subsequently be solved over the partitioned network. Consequently, theoretical bounds are derived to compare observability metrics of the original network with those of the resulting partitions, highlighting the impact of partitioning on system observability. Case studies on networks of varying sizes corroborate the derived theoretical bounds.","authors":["Mohamad H. Kazma","Ahmad F. Taha"],"url":"https://arxiv.org/abs/2505.16169"}
{"created":"2025-05-23","title":"When Do LLMs Admit Their Mistakes? Understanding the Role of Model Belief in Retraction","abstract":"Can large language models (LLMs) admit their mistakes when they should know better? In this work, we define the behavior of acknowledging errors in previously generated answers as \"retraction\" and aim to understand when and why LLMs choose to retract. We first construct model-specific datasets to evaluate whether a model will retract an incorrect answer that contradicts its own parametric knowledge. While LLMs are capable of retraction, they do so only infrequently. We demonstrate that retraction is closely tied to previously identified indicators of models' internal belief: models fail to retract wrong answers that they \"believe\" to be factually correct. Steering experiments further demonstrate that internal belief causally influences model retraction. In particular, when the model does not believe its answer, this not only encourages the model to attempt to verify the answer, but also alters attention behavior during self-verification. Finally, we demonstrate that simple supervised fine-tuning significantly improves retraction performance by helping the model learn more accurate internal beliefs. Code and datasets are available on https://github.com/ayyyq/llm-retraction.","authors":["Yuqing Yang","Robin Jia"],"url":"https://arxiv.org/abs/2505.16170"}
{"created":"2025-05-23","title":"Fairness and Efficiency in Human-Agent Teams: An Iterative Algorithm Design Approach","abstract":"When agents interact with people as part of a team, fairness becomes an important factor. Prior work has proposed fairness metrics based on teammates' capabilities for task allocation within human-agent teams. However, most metrics only consider teammate capabilities from a third-person point of view (POV). In this work, we extend these metrics to include task preferences and consider a first-person POV. We leverage an iterative design method consisting of simulation data and human data to design a task allocation algorithm that balances task efficiency and fairness based on both capabilities and preferences. We first show that these metrics may not align with people's perceived fairness from a first-person POV. In light of this result, we propose a new fairness metric, fair-equity, and the Fair-Efficient Algorithm (FEA). Our findings suggest that an agent teammate who balances efficiency and fairness based on equity will be perceived to be fairer and preferred by human teammates in various human-agent team types. We suggest that the perception of fairness may also depend on a person's POV.","authors":["Mai Lee Chang","Kim Baraka","Greg Trafton","Zach Lalu Vazhekatt","Andrea Lockerd Thomaz"],"url":"https://arxiv.org/abs/2505.16171"}
{"created":"2025-05-23","title":"Automated Feedback Loops to Protect Text Simplification with Generative AI from Information Loss","abstract":"Understanding health information is essential in achieving and maintaining a healthy life. We focus on simplifying health information for better understanding. With the availability of generative AI, the simplification process has become efficient and of reasonable quality, however, the algorithms remove information that may be crucial for comprehension. In this study, we compare generative AI to detect missing information in simplified text, evaluate its importance, and fix the text with the missing information. We collected 50 health information texts and simplified them using gpt-4-0613. We compare five approaches to identify missing elements and regenerate the text by inserting the missing elements. These five approaches involve adding missing entities and missing words in various ways: 1) adding all the missing entities, 2) adding all missing words, 3) adding the top-3 entities ranked by gpt-4-0613, and 4, 5) serving as controls for comparison, adding randomly chosen entities. We use cosine similarity and ROUGE scores to evaluate the semantic similarity and content overlap between the original, simplified, and reconstructed simplified text. We do this for both summaries and full text. Overall, we find that adding missing entities improves the text. Adding all the missing entities resulted in better text regeneration, which was better than adding the top-ranked entities or words, or random words. Current tools can identify these entities, but are not valuable in ranking them.","authors":["Abhay Kumara Sri Krishna Nandiraju","Gondy Leroy","David Kauchak","Arif Ahmed"],"url":"https://arxiv.org/abs/2505.16172"}
{"created":"2025-05-23","title":"Erased or Dormant? Rethinking Concept Erasure Through Reversibility","abstract":"To what extent does concept erasure eliminate generative capacity in diffusion models? While prior evaluations have primarily focused on measuring concept suppression under specific textual prompts, we explore a complementary and fundamental question: do current concept erasure techniques genuinely remove the ability to generate targeted concepts, or do they merely achieve superficial, prompt-specific suppression? We systematically evaluate the robustness and reversibility of two representative concept erasure methods, Unified Concept Editing and Erased Stable Diffusion, by probing their ability to eliminate targeted generative behaviors in text-to-image models. These methods attempt to suppress undesired semantic concepts by modifying internal model parameters, either through targeted attention edits or model-level fine-tuning strategies. To rigorously assess whether these techniques truly erase generative capacity, we propose an instance-level evaluation strategy that employs lightweight fine-tuning to explicitly test the reactivation potential of erased concepts. Through quantitative metrics and qualitative analyses, we show that erased concepts often reemerge with substantial visual fidelity after minimal adaptation, indicating that current methods suppress latent generative representations without fully eliminating them. Our findings reveal critical limitations in existing concept erasure approaches and highlight the need for deeper, representation-level interventions and more rigorous evaluation standards to ensure genuine, irreversible removal of concepts from generative models.","authors":["Ping Liu","Chi Zhang"],"url":"https://arxiv.org/abs/2505.16174"}
{"created":"2025-05-23","title":"QuickVideo: Real-Time Long Video Understanding with System Algorithm Co-Design","abstract":"Long-video understanding has emerged as a crucial capability in real-world applications such as video surveillance, meeting summarization, educational lecture analysis, and sports broadcasting. However, it remains computationally prohibitive for VideoLLMs, primarily due to two bottlenecks: 1) sequential video decoding, the process of converting the raw bit stream to RGB frames can take up to a minute for hour-long video inputs, and 2) costly prefilling of up to several million tokens for LLM inference, resulting in high latency and memory use. To address these challenges, we propose QuickVideo, a system-algorithm co-design that substantially accelerates long-video understanding to support real-time downstream applications. It comprises three key innovations: QuickDecoder, a parallelized CPU-based video decoder that achieves 2-3 times speedup by splitting videos into keyframe-aligned intervals processed concurrently; QuickPrefill, a memory-efficient prefilling method using KV-cache pruning to support more frames with less GPU memory; and an overlapping scheme that overlaps CPU video decoding with GPU inference. Together, these components infernece time reduce by a minute on long video inputs, enabling scalable, high-quality video understanding even on limited hardware. Experiments show that QuickVideo generalizes across durations and sampling rates, making long video processing feasible in practice.","authors":["Benjamin Schneider","Dongfu Jiang","Chao Du","Tianyu Pang","Wenhu Chen"],"url":"https://arxiv.org/abs/2505.16175"}
{"created":"2025-05-23","title":"Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning","abstract":"In the realm of data selection for reasoning tasks, existing approaches predominantly rely on externally predefined static metrics such as difficulty and diversity, which are often designed for supervised fine-tuning (SFT) and lack adaptability to continuous training processes. A critical limitation of these methods is their inability to dynamically align with the evolving capabilities of models during online training, a gap that becomes increasingly pronounced with the rise of dynamic training paradigms and online reinforcement learning (RL) frameworks (e.g., R1 models). To address this, we introduce SAI-DPO, an algorithm that dynamically selects training data by continuously assessing a model's stage-specific reasoning abilities across different training phases. By integrating real-time model performance feedback, SAI-DPO adaptively adapts data selection to the evolving strengths and weaknesses of the model, thus enhancing both data utilization efficiency and final task performance. Extensive experiments on three state-of-the-art models and eight mathematical reasoning benchmarks, including challenging competition-level datasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average performance boost of up to 21.3 percentage points, with particularly notable improvements of 10 and 15 points on AIME24 and AMC23, respectively. These results highlight the superiority of dynamic, model-adaptive data selection over static, externally defined strategies in advancing reasoning.","authors":["Jun Rao","Xuebo Liu","Hexuan Deng","Zepeng Lin","Zixiong Yu","Jiansheng Wei","Xiaojun Meng","Min Zhang"],"url":"https://arxiv.org/abs/2505.16176"}
{"created":"2025-05-23","title":"Understanding Fact Recall in Language Models: Why Two-Stage Training Encourages Memorization but Mixed Training Teaches Knowledge","abstract":"Fact recall, the ability of language models (LMs) to retrieve specific factual knowledge, remains a challenging task despite their impressive general capabilities. Common training strategies often struggle to promote robust recall behavior with two-stage training, which first trains a model with fact-storing examples (e.g., factual statements) and then with fact-recalling examples (question-answer pairs), tending to encourage rote memorization rather than generalizable fact retrieval. In contrast, mixed training, which jointly uses both types of examples, has been empirically shown to improve the ability to recall facts, but the underlying mechanisms are still poorly understood. In this work, we investigate how these training strategies affect how model parameters are shaped during training and how these differences relate to their ability to recall facts. We introduce cross-task gradient trace to identify shared parameters, those strongly influenced by both fact-storing and fact-recalling examples. Our analysis on synthetic fact recall datasets with the Llama-3.2B and Pythia-2.8B models reveals that mixed training encouraging a larger and more centralized set of shared parameters. These findings suggest that the emergence of parameters may play a key role in enabling LMs to generalize factual knowledge across task formulations.","authors":["Ying Zhang","Benjamin Heinzerling","Dongyuan Li","Ryoma Ishigaki","Yuta Hitomi","Kentaro Inui"],"url":"https://arxiv.org/abs/2505.16178"}
{"created":"2025-05-23","title":"Redemption Score: An Evaluation Framework to Rank Image Captions While Redeeming Image Semantics and Language Pragmatics","abstract":"Evaluating image captions requires cohesive assessment of both visual semantics and language pragmatics, which is often not entirely captured by most metrics. We introduce Redemption Score, a novel hybrid framework that ranks image captions by triangulating three complementary signals: (1) Mutual Information Divergence (MID) for global image-text distributional alignment, (2) DINO-based perceptual similarity of cycle-generated images for visual grounding, and (3) BERTScore for contextual text similarity against human references. A calibrated fusion of these signals allows Redemption Score to offer a more holistic assessment. On the Flickr8k benchmark, Redemption Score achieves a Kendall-$\\tau$ of 56.43, outperforming twelve prior methods and demonstrating superior correlation with human judgments without requiring task-specific training. Our framework provides a more robust and nuanced evaluation by effectively redeeming image semantics and linguistic interpretability indicated by strong transfer of knowledge in the Conceptual Captions and MS COCO datasets.","authors":["Ashim Dahal","Ankit Ghimire","Saydul Akbar Murad","Nick Rahimi"],"url":"https://arxiv.org/abs/2505.16180"}
{"created":"2025-05-23","title":"Understanding Generative AI Capabilities in Everyday Image Editing Tasks","abstract":"Generative AI (GenAI) holds significant promise for automating everyday image editing tasks, especially following the recent release of GPT-4o on March 25, 2025. However, what subjects do people most often want edited? What kinds of editing actions do they want to perform (e.g., removing or stylizing the subject)? Do people prefer precise edits with predictable outcomes or highly creative ones? By understanding the characteristics of real-world requests and the corresponding edits made by freelance photo-editing wizards, can we draw lessons for improving AI-based editors and determine which types of requests can currently be handled successfully by AI editors? In this paper, we present a unique study addressing these questions by analyzing 83k requests from the past 12 years (2013-2025) on the Reddit community, which collected 305k PSR-wizard edits. According to human ratings, approximately only 33% of requests can be fulfilled by the best AI editors (including GPT-4o, Gemini-2.0-Flash, SeedEdit). Interestingly, AI editors perform worse on low-creativity requests that require precise editing than on more open-ended tasks. They often struggle to preserve the identity of people and animals, and frequently make non-requested touch-ups. On the other side of the table, VLM judges (e.g., o1) perform differently from human judges and may prefer AI edits more than human edits. Code and qualitative examples are available at: https://psrdataset.github.io","authors":["Mohammad Reza Taesiri","Brandon Collins","Logan Bolton","Viet Dac Lai","Franck Dernoncourt","Trung Bui","Anh Totti Nguyen"],"url":"https://arxiv.org/abs/2505.16181"}
{"created":"2025-05-23","title":"Discrete Tokens Exhibit Interlanguage Speech Intelligibility Benefit: an Analytical Study Towards Accent-robust ASR Only with Native Speech Data","abstract":"In this study, we gained insight that contributes to achieving accent-robust ASR using only native speech data. In human perception of non-native speech, the phenomenon known as \"interlanguage speech intelligibility benefit\" (ISIB) is observed, where non-native listeners who share the native language with the speaker understand the speech better compared even to native listeners. Based on the idea that discrete tokens extracted from self-supervised learning (SSL) models represent the human perception of speech, we conducted an analytical study on the robustness of discrete token-based ASR to non-native speech, varying the language used for training the tokenization, which is viewed as a technical implementation of ISIB. The results showed that ISIB actually occurred in the discrete token-based ASR. Since our approach relies only on native speech data to simulate the behavior of human perception, it is expected to be applicable to a wide range of accents for which speech data is scarce.","authors":["Kentaro Onda","Keisuke Imoto","Satoru Fukayama","Daisuke Saito","Nobuaki Minematsu"],"url":"https://arxiv.org/abs/2505.16182"}
{"created":"2025-05-23","title":"A Game for Counting Logic Formula Size and an Application to Linear Orders","abstract":"Ehrenfeucht-Fra\\\"iss\\'e (EF) games are a basic tool in finite model theory for proving definability lower bounds, with many applications in complexity theory and related areas. They have been applied to study various logics, giving insights on quantifier rank and other logical complexity measures. In this paper, we present an EF game to capture formula size in counting logic with a bounded number of variables. The game combines games introduced previously for counting logic quantifier rank due to Immerman and Lander, and for first-order formula size due to Adler and Immerman, and Hella and V\\\"a\\\"an\\\"anen. The game is used to prove the main result of the paper, an extension of a formula size lower bound of Grohe and Schweikardt for distinguishing linear orders, from 3-variable first-order logic to 3-variable counting logic. As far as we know, this is the first formula size lower bound for counting logic.","authors":["Gregoire Fournier","Gy\\\"orgy Tur\\'an"],"url":"https://arxiv.org/abs/2505.16185"}
{"created":"2025-05-23","title":"SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning","abstract":"Large Reasoning Models (LRMs) introduce a new generation paradigm of explicitly reasoning before answering, leading to remarkable improvements in complex tasks. However, they pose great safety risks against harmful queries and adversarial attacks. While recent mainstream safety efforts on LRMs, supervised fine-tuning (SFT), improve safety performance, we find that SFT-aligned models struggle to generalize to unseen jailbreak prompts. After thorough investigation of LRMs' generation, we identify a safety aha moment that can activate safety reasoning and lead to a safe response. This aha moment typically appears in the `key sentence', which follows models' query understanding process and can indicate whether the model will proceed safely. Based on these insights, we propose SafeKey, including two complementary objectives to better activate the safety aha moment in the key sentence: (1) a Dual-Path Safety Head to enhance the safety signal in the model's internal representations before the key sentence, and (2) a Query-Mask Modeling objective to improve the models' attention on its query understanding, which has important safety hints. Experiments across multiple safety benchmarks demonstrate that our methods significantly improve safety generalization to a wide range of jailbreak attacks and out-of-distribution harmful prompts, lowering the average harmfulness rate by 9.6\\%, while maintaining general abilities. Our analysis reveals how SafeKey enhances safety by reshaping internal attention and improving the quality of hidden representations.","authors":["Kaiwen Zhou","Xuandong Zhao","Gaowen Liu","Jayanth Srinivasa","Aosong Feng","Dawn Song","Xin Eric Wang"],"url":"https://arxiv.org/abs/2505.16186"}
{"created":"2025-05-23","title":"EasyInsert: A Data-Efficient and Generalizable Insertion Policy","abstract":"Insertion task is highly challenging that requires robots to operate with exceptional precision in cluttered environments. Existing methods often have poor generalization capabilities. They typically function in restricted and structured environments, and frequently fail when the plug and socket are far apart, when the scene is densely cluttered, or when handling novel objects. They also rely on strong assumptions such as access to CAD models or a digital twin in simulation. To address this, we propose EasyInsert, a framework which leverages the human intuition that relative pose (delta pose) between plug and socket is sufficient for successful insertion, and employs efficient and automated real-world data collection with minimal human labor to train a generalizable model for relative pose prediction. During execution, EasyInsert follows a coarse-to-fine execution procedure based on predicted delta pose, and successfully performs various insertion tasks. EasyInsert demonstrates strong zero-shot generalization capability for unseen objects in cluttered environments, handling cases with significant initial pose deviations while maintaining high sample efficiency and requiring little human effort. In real-world experiments, with just 5 hours of training data, EasyInsert achieves over 90% success in zero-shot insertion for 13 out of 15 unseen novel objects, including challenging objects like Type-C cables, HDMI cables, and Ethernet cables. Furthermore, with only one human demonstration and 4 minutes of automatically collected data for fine-tuning, it reaches over 90% success rate for all 15 objects.","authors":["Guanghe Li","Junming Zhao","Shengjie Wang","Yang Gao"],"url":"https://arxiv.org/abs/2505.16187"}
{"created":"2025-05-23","title":"SAE-SSV: Supervised Steering in Sparse Representation Spaces for Reliable Control of Language Models","abstract":"Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, but controlling their behavior reliably remains challenging, especially in open-ended generation settings. This paper introduces a novel supervised steering approach that operates in sparse, interpretable representation spaces. We employ sparse autoencoders (SAEs)to obtain sparse latent representations that aim to disentangle semantic attributes from model activations. Then we train linear classifiers to identify a small subspace of task-relevant dimensions in latent representations. Finally, we learn supervised steering vectors constrained to this subspace, optimized to align with target behaviors. Experiments across sentiment, truthfulness, and politics polarity steering tasks with multiple LLMs demonstrate that our supervised steering vectors achieve higher success rates with minimal degradation in generation quality compared to existing methods. Further analysis reveals that a notably small subspace is sufficient for effective steering, enabling more targeted and interpretable interventions.","authors":["Zirui He","Mingyu Jin","Bo Shen","Ali Payani","Yongfeng Zhang","Mengnan Du"],"url":"https://arxiv.org/abs/2505.16188"}
{"created":"2025-05-23","title":"The Language of Interoception: Examining Embodiment and Emotion Through a Corpus of Body Part Mentions","abstract":"This paper is the first investigation of the connection between emotion, embodiment, and everyday language in a large sample of natural language data. We created corpora of body part mentions (BPMs) in online English text (blog posts and tweets). This includes a subset featuring human annotations for the emotions of the person whose body part is mentioned in the text. We show that BPMs are common in personal narratives and tweets (~5% to 10% of posts include BPMs) and that their usage patterns vary markedly by time and %geographic location. Using word-emotion association lexicons and our annotated data, we show that text containing BPMs tends to be more emotionally charged, even when the BPM is not explicitly used to describe a physical reaction to the emotion in the text. Finally, we discover a strong and statistically significant correlation between body-related language and a variety of poorer health outcomes. In sum, we argue that investigating the role of body-part related words in language can open up valuable avenues of future research at the intersection of NLP, the affective sciences, and the study of human wellbeing.","authors":["Sophie Wu","Jan Philip Wahle","Saif M. Mohammad"],"url":"https://arxiv.org/abs/2505.16189"}
{"created":"2025-05-23","title":"Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare","abstract":"Federated Learning (FL) holds great promise for digital health by enabling collaborative model training without compromising patient data privacy. However, heterogeneity across institutions, lack of sustained reputation, and unreliable contributions remain major challenges. In this paper, we propose a robust, peer-driven reputation mechanism for federated healthcare that employs a hybrid communication model to integrate decentralized peer feedback with clustering-based noise handling to enhance model aggregation. Crucially, our approach decouples the federated aggregation and reputation mechanisms by applying differential privacy to client-side model updates before sharing them for peer evaluation. This ensures sensitive information remains protected during reputation computation, while unaltered updates are sent to the server for global model training. Using the Cox Proportional Hazards model for survival analysis across multiple federated nodes, our framework addresses both data heterogeneity and reputation deficit by dynamically adjusting trust scores based on local performance improvements measured via the concordance index. Experimental evaluations on both synthetic datasets and the SEER dataset demonstrate that our method consistently achieves high and stable C-index values, effectively down-weighing noisy client updates and outperforming FL methods that lack a reputation system.","authors":["Navid Seidi","Satyaki Roy","Sajal Das"],"url":"https://arxiv.org/abs/2505.16190"}
{"created":"2025-05-23","title":"Prosodically Enhanced Foreign Accent Simulation by Discrete Token-based Resynthesis Only with Native Speech Corpora","abstract":"Recently, a method for synthesizing foreign-accented speech only with native speech data using discrete tokens obtained from self-supervised learning (SSL) models was proposed. Considering limited availability of accented speech data, this method is expected to make it much easier to simulate foreign accents. By using the synthesized accented speech as listening materials for humans or training data for automatic speech recognition (ASR), both of them will acquire higher robustness against foreign accents. However, the previous method has a fatal flaw that it cannot reproduce duration-related accents. Durational accents are commonly seen when L2 speakers, whose native language has syllable-timed or mora-timed rhythm, speak stress-timed languages, such as English. In this paper, we integrate duration modification to the previous method to simulate foreign accents more accurately. Experiments show that the proposed method successfully replicates durational accents seen in real L2 speech.","authors":["Kentaro Onda","Keisuke Imoto","Satoru Fukayama","Daisuke Saito","Nobuaki Minematsu"],"url":"https://arxiv.org/abs/2505.16191"}
{"created":"2025-05-23","title":"VLM-R$^3$: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought","abstract":"Recently, reasoning-based MLLMs have achieved a degree of success in generating long-form textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on and revisiting of visual regions to achieve precise grounding of textual reasoning in visual evidence. We introduce \\textbf{VLM-R$^3$} (\\textbf{V}isual \\textbf{L}anguage \\textbf{M}odel with \\textbf{R}egion \\textbf{R}ecognition and \\textbf{R}easoning), a framework that equips an MLLM with the ability to (i) decide \\emph{when} additional visual evidence is needed, (ii) determine \\emph{where} to ground within the image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved chain-of-thought. The core of our method is \\textbf{Region-Conditioned Reinforcement Policy Optimization (R-GRPO)}, a training paradigm that rewards the model for selecting informative regions, formulating appropriate transformations (e.g.\\ crop, zoom), and integrating the resulting visual context into subsequent reasoning steps. To bootstrap this policy, we compile a modest but carefully curated Visuo-Lingual Interleaved Rationale (VLIR) corpus that provides step-level supervision on region selection and textual justification. Extensive experiments on MathVista, ScienceQA, and other benchmarks show that VLM-R$^3$ sets a new state of the art in zero-shot and few-shot settings, with the largest gains appearing on questions demanding subtle spatial reasoning or fine-grained visual cue extraction.","authors":["Chaoya Jiang","Yongrui Heng","Wei Ye","Han Yang","Haiyang Xu","Ming Yan","Ji Zhang","Fei Huang","Shikun Zhang"],"url":"https://arxiv.org/abs/2505.16192"}
{"created":"2025-05-23","title":"An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability","abstract":"The advancements in Multimodal Large Language Models (MLLMs) have enabled various multimodal tasks to be addressed under a zero-shot paradigm. This paradigm sidesteps the cost of model fine-tuning, emerging as a dominant trend in practical application. Nevertheless, Multimodal Sentiment Analysis (MSA), a pivotal challenge in the quest for general artificial intelligence, fails to accommodate this convenience. The zero-shot paradigm exhibits undesirable performance on MSA, casting doubt on whether MLLMs can perceive sentiments as competent as supervised models. By extending the zero-shot paradigm to In-Context Learning (ICL) and conducting an in-depth study on configuring demonstrations, we validate that MLLMs indeed possess such capability. Specifically, three key factors that cover demonstrations' retrieval, presentation, and distribution are comprehensively investigated and optimized. A sentimental predictive bias inherent in MLLMs is also discovered and later effectively counteracted. By complementing each other, the devised strategies for three factors result in average accuracy improvements of 15.9% on six MSA datasets against the zero-shot paradigm and 11.2% against the random ICL baseline.","authors":["Daiqing Wu","Dongbao Yang","Sicheng Zhao","Can Ma","Yu Zhou"],"url":"https://arxiv.org/abs/2505.16193"}
{"created":"2025-05-23","title":"SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet","abstract":"Foley synthesis aims to synthesize high-quality audio that is both semantically and temporally aligned with video frames. Given its broad application in creative industries, the task has gained increasing attention in the research community. To avoid the non-trivial task of training audio generative models from scratch, adapting pretrained audio generative models for video-synchronized foley synthesis presents an attractive direction. ControlNet, a method for adding fine-grained controls to pretrained generative models, has been applied to foley synthesis, but its use has been limited to handcrafted human-readable temporal conditions. In contrast, from-scratch models achieved success by leveraging high-dimensional deep features extracted using pretrained video encoders. We have observed a performance gap between ControlNet-based and from-scratch foley models. To narrow this gap, we propose SpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward video-synchronized foley synthesis via ControlNet. To unlock the potential of a single ControlNet branch, we resolve the discrepancy between the temporal video features and the time-frequency nature of the pretrained SpecMaskGIT via a frequency-aware temporal feature aligner, eliminating the need for complicated conditioning mechanisms widely used in prior arts. Evaluations on a common foley synthesis benchmark demonstrate that SpecMaskFoley could even outperform strong from-scratch baselines, substantially advancing the development of ControlNet-based foley synthesis models. Demo page: https://zzaudio.github.io/SpecMaskFoley_Demo/","authors":["Zhi Zhong","Akira Takahashi","Shuyang Cui","Keisuke Toyama","Shusuke Takahashi","Yuki Mitsufuji"],"url":"https://arxiv.org/abs/2505.16195"}
{"created":"2025-05-23","title":"SEM: Enhancing Spatial Understanding for Robust Robot Manipulation","abstract":"A key challenge in robot manipulation lies in developing policy models with strong spatial understanding, the ability to reason about 3D geometry, object relations, and robot embodiment. Existing methods often fall short: 3D point cloud models lack semantic abstraction, while 2D image encoders struggle with spatial reasoning. To address this, we propose SEM (Spatial Enhanced Manipulation model), a novel diffusion-based policy framework that explicitly enhances spatial understanding from two complementary perspectives. A spatial enhancer augments visual representations with 3D geometric context, while a robot state encoder captures embodiment-aware structure through graphbased modeling of joint dependencies. By integrating these modules, SEM significantly improves spatial understanding, leading to robust and generalizable manipulation across diverse tasks that outperform existing baselines.","authors":["Xuewu Lin","Tianwei Lin","Lichao Huang","Hongyu Xie","Yiwei Jin","Keyu Li","Zhizhong Su"],"url":"https://arxiv.org/abs/2505.16196"}
{"created":"2025-05-23","title":"Velocity Completion Task and Method for Event-based Player Positional Data in Soccer","abstract":"In many real-world complex systems, the behavior can be observed as a collection of discrete events generated by multiple interacting agents. Analyzing the dynamics of these multi-agent systems, especially team sports, often relies on understanding the movement and interactions of individual agents. However, while providing valuable snapshots, event-based positional data typically lacks the continuous temporal information needed to directly calculate crucial properties such as velocity. This absence severely limits the depth of dynamic analysis, preventing a comprehensive understanding of individual agent behaviors and emergent team strategies. To address this challenge, we propose a new method to simultaneously complete the velocity of all agents using only the event-based positional data from team sports. Based on this completed velocity information, we investigate the applicability of existing team sports analysis and evaluation methods. Experiments using soccer event data demonstrate that neural network-based approaches outperformed rule-based methods regarding velocity completion error, considering the underlying temporal dependencies and graph structure of player-to-player or player-to-ball interaction. Moreover, the space evaluation results obtained using the completed velocity are closer to those derived from complete tracking data, highlighting our method's potential for enhanced team sports system analysis.","authors":["Rikuhei Umemoto","Keisuke Fujii"],"url":"https://arxiv.org/abs/2505.16199"}
{"created":"2025-05-23","title":"Advanced Integration Strategies for ESD Protection and Termination in High-Speed LVDS Systems","abstract":"This technical article explores comprehensive strategies for integrating Electrostatic Discharge (ESD) protection diodes and termination resistors in LowVoltage Differential Signaling (LVDS) designs. The article examines critical aspects of protection mechanisms, design considerations, impedance matching, and placement optimization techniques. Through detailed analysis of layout considerations and advanced design strategies, the article presents solutions for common integration challenges. It emphasizes the importance of signal integrity maintenance and protection effectiveness while providing practical guidelines for implementing robust LVDS systems. Various methodologies for performance optimization and validation are discussed, offering designers a thorough framework for creating reliable high-speed digital systems that balance protection requirements with signal integrity demands.","authors":["Kavya Gaddipati"],"url":"https://arxiv.org/abs/2505.16200"}
{"created":"2025-05-23","title":"Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks","abstract":"In this paper, we prove directional convergence of network parameters of fixed width leaky ReLU two-layer neural networks optimized by gradient descent with exponential loss, which was previously only known for gradient flow. By a careful analysis of the convergent direction, we establish sufficient conditions of benign overfitting and discover a new phase transition in the test error bound. All of these results hold beyond the nearly orthogonal data setting which was studied in prior works. As an application, we demonstrate that benign overfitting occurs with high probability in sub-Gaussian mixture models.","authors":["Ichiro Hashimoto"],"url":"https://arxiv.org/abs/2505.16204"}
{"created":"2025-05-23","title":"VIVID: A Novel Approach to Remediation Prioritization in Static Application Security Testing (SAST)","abstract":"Static Application Security Testing (SAST) enables organizations to detect vulnerabilities in code early; however, major SAST platforms do not include visual aids and present little insight on correlations between tainted data chains. We propose VIVID - Vulnerability Information Via Data flow - a novel method to extract and consume SAST insights, which is to graph the application's vulnerability data flows (VDFs) and carry out graph theory analysis on the resulting VDF directed graph. Nine metrics were assessed to evaluate their effectiveness in analyzing the VDF graphs of deliberately insecure web applications. These metrics include 3 centrality metrics, 2 structural metrics, PageRank, in-degree, out-degree, and cross-clique connectivity. We present simulations that find that out-degree, betweenness centrality, in-eigenvector centrality, and cross-clique connectivity were found to be associated with files exhibiting high vulnerability traffic, making them refactoring candidates where input sanitization may have been missed. Meanwhile, out-eigenvector centrality, PageRank, and in-degree were found to be associated with nodes enabling vulnerability flow and sinks, but not necessarily where input validation should be placed. This is a novel method to automatically provide development teams an evidence-based prioritized list of files to embed security controls into, informed by vulnerability propagation patterns in the application architecture.","authors":["Naeem Budhwani","Mohammad Faghani","Hayden Richard"],"url":"https://arxiv.org/abs/2505.16205"}
{"created":"2025-05-23","title":"Differentiable K-means for Fully-optimized Discrete Token-based ASR","abstract":"Recent studies have highlighted the potential of discrete tokens derived from self-supervised learning (SSL) models for various speech-related tasks. These tokens serve not only as substitutes for text in language modeling but also as intermediate representations for tasks such as automatic speech recognition (ASR). However, discrete tokens are typically obtained via k-means clustering of SSL features independently of downstream tasks, making them suboptimal for specific applications. This paper proposes the use of differentiable k-means, enabling the joint optimization of tokenization and downstream tasks. This approach enables the fine-tuning of the SSL parameters and learning weights for outputs from multiple SSL layers. Experiments were conducted with ASR as a downstream task. ASR accuracy successfully improved owing to the optimized tokens. The acquired tokens also exhibited greater purity of phonetic information, which were found to be useful even in speech resynthesis.","authors":["Kentaro Onda","Yosuke Kashiwagi","Emiru Tsunoo","Hayato Futami","Shinji Watanabe"],"url":"https://arxiv.org/abs/2505.16207"}
{"created":"2025-05-23","title":"A Causal Approach to Mitigate Modality Preference Bias in Medical Visual Question Answering","abstract":"Medical Visual Question Answering (MedVQA) is crucial for enhancing the efficiency of clinical diagnosis by providing accurate and timely responses to clinicians' inquiries regarding medical images. Existing MedVQA models suffered from modality preference bias, where predictions are heavily dominated by one modality while overlooking the other (in MedVQA, usually questions dominate the answer but images are overlooked), thereby failing to learn multimodal knowledge. To overcome the modality preference bias, we proposed a Medical CounterFactual VQA (MedCFVQA) model, which trains with bias and leverages causal graphs to eliminate the modality preference bias during inference. Existing MedVQA datasets exhibit substantial prior dependencies between questions and answers, which results in acceptable performance even if the model significantly suffers from the modality preference bias. To address this issue, we reconstructed new datasets by leveraging existing MedVQA datasets and Changed their P3rior dependencies (CP) between questions and their answers in the training and test set. Extensive experiments demonstrate that MedCFVQA significantly outperforms its non-causal counterpart on both SLAKE, RadVQA and SLAKE-CP, RadVQA-CP datasets.","authors":["Shuchang Ye","Usman Naseem","Mingyuan Meng","Dagan Feng","Jinman Kim"],"url":"https://arxiv.org/abs/2505.16209"}
{"created":"2025-05-23","title":"NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics","abstract":"Large Language Models (LLMs) have demonstrated remarkable proficiency across a wide range of tasks. However, LLMs often require larger batch sizes to enhance throughput or longer context lengths to meet task demands, which significantly increases the memory resource consumption of the Key-Value (KV) cache during inference, becoming a major bottleneck in LLM deployment. To address this issue, quantization is a common and straightforward approach. Currently, quantization methods for activations are limited to 8-bit, and quantization to even lower bits can lead to substantial accuracy drops. To further save space by quantizing the KV cache to even lower bits, we analyzed the element distribution of the KV cache and designed the NQKV algorithm. Since the elements within each block of the KV cache follow a normal distribution, NQKV employs per-block quantile quantization to achieve information-theoretically optimal quantization error. Without significantly compromising model output quality, NQKV enables the OPT model to perform inference with an 2x larger batch size or a 4x longer context length, and it improves throughput by 9.3x compared to when the KV cache is not used.","authors":["Zhihang Cai","Xingjun Zhang","Zhendong Tan","Zheng Wei"],"url":"https://arxiv.org/abs/2505.16210"}
{"created":"2025-05-23","title":"AudioTrust: Benchmarking the Multifaceted Trustworthiness of Audio Large Language Models","abstract":"The rapid advancement and expanding applications of Audio Large Language Models (ALLMs) demand a rigorous understanding of their trustworthiness. However, systematic research on evaluating these models, particularly concerning risks unique to the audio modality, remains largely unexplored. Existing evaluation frameworks primarily focus on the text modality or address only a restricted set of safety dimensions, failing to adequately account for the unique characteristics and application scenarios inherent to the audio modality. We introduce AudioTrust-the first multifaceted trustworthiness evaluation framework and benchmark specifically designed for ALLMs. AudioTrust facilitates assessments across six key dimensions: fairness, hallucination, safety, privacy, robustness, and authentication. To comprehensively evaluate these dimensions, AudioTrust is structured around 18 distinct experimental setups. Its core is a meticulously constructed dataset of over 4,420 audio/text samples, drawn from real-world scenarios (e.g., daily conversations, emergency calls, voice assistant interactions), specifically designed to probe the multifaceted trustworthiness of ALLMs. For assessment, the benchmark carefully designs 9 audio-specific evaluation metrics, and we employ a large-scale automated pipeline for objective and scalable scoring of model outputs. Experimental results reveal the trustworthiness boundaries and limitations of current state-of-the-art open-source and closed-source ALLMs when confronted with various high-risk audio scenarios, offering valuable insights for the secure and trustworthy deployment of future audio models. Our platform and benchmark are available at https://github.com/JusperLee/AudioTrust.","authors":["Kai Li","Can Shen","Yile Liu","Jirui Han","Kelong Zheng","Xuechao Zou","Zhe Wang","Xingjian Du","Shun Zhang","Hanjun Luo","Yingbin Jin","Xinxin Xing","Ziyang Ma","Yue Liu","Xiaojun Jia","Yifan Zhang","Junfeng Fang","Kun Wang","Yibo Yan","Haoyang Li","Yiming Li","Xiaobin Zhuang","Yang Liu","Haibo Hu","Zhuo Chen","Zhizheng Wu","Xiaolin Hu","Eng-Siong Chng","XiaoFeng Wang","Wenyuan Xu","Wei Dong","Xinfeng Li"],"url":"https://arxiv.org/abs/2505.16211"}
{"created":"2025-05-23","title":"Large Language Models based ASR Error Correction for Child Conversations","abstract":"Automatic Speech Recognition (ASR) has recently shown remarkable progress, but accurately transcribing children's speech remains a significant challenge. Recent developments in Large Language Models (LLMs) have shown promise in improving ASR transcriptions. However, their applications in child speech including conversational scenarios are underexplored. In this study, we explore the use of LLMs in correcting ASR errors for conversational child speech. We demonstrate the promises and challenges of LLMs through experiments on two children's conversational speech datasets with both zero-shot and fine-tuned ASR outputs. We find that while LLMs are helpful in correcting zero-shot ASR outputs and fine-tuned CTC-based ASR outputs, it remains challenging for LLMs to improve ASR performance when incorporating contextual information or when using fine-tuned autoregressive ASR (e.g., Whisper) outputs.","authors":["Anfeng Xu","Tiantian Feng","So Hyun Kim","Somer Bishop","Catherine Lord","Shrikanth Narayanan"],"url":"https://arxiv.org/abs/2505.16212"}
{"created":"2025-05-23","title":"Behavioral Safety Assessment towards Large-scale Deployment of Autonomous Vehicles","abstract":"Autonomous vehicles (AVs) have significantly advanced in real-world deployment in recent years, yet safety continues to be a critical barrier to widespread adoption. Traditional functional safety approaches, which primarily verify the reliability, robustness, and adequacy of AV hardware and software systems from a vehicle-centric perspective, do not sufficiently address the AV's broader interactions and behavioral impact on the surrounding traffic environment. To overcome this limitation, we propose a paradigm shift toward behavioral safety, a comprehensive approach focused on evaluating AV responses and interactions within the traffic environment. To systematically assess behavioral safety, we introduce a third-party AV safety assessment framework comprising two complementary evaluation components: the Driver Licensing Test and the Driving Intelligence Test. The Driver Licensing Test evaluates the AV's reactive behaviors under controlled scenarios, ensuring basic behavioral competency. In contrast, the Driving Intelligence Test assesses the AV's interactive behaviors within naturalistic traffic conditions, quantifying the frequency of safety-critical events to deliver statistically meaningful safety metrics before large-scale deployment. We validated our proposed framework using Autoware.Universe, an open-source Level 4 AV, tested both in simulated environments and on the physical test track at the University of Michigan's Mcity Testing Facility. The results indicate that Autoware.Universe passed 6 out of 14 scenarios and exhibited a crash rate of 3.01e-3 crashes per mile, approximately 1,000 times higher than the average human driver crash rate. During the tests, we also uncovered several unknown unsafe scenarios for Autoware.Universe. These findings underscore the necessity of behavioral safety evaluations for improving AV safety performance prior to widespread public deployment.","authors":["Henry X. Liu","Xintao Yan","Haowei Sun","Tinghan Wang","Zhijie Qiao","Haojie Zhu","Shengyin Shen","Shuo Feng","Greg Stevens","Greg McGuire"],"url":"https://arxiv.org/abs/2505.16214"}
{"created":"2025-05-23","title":"A Scalable Hierarchical Intrusion Detection System for Internet of Vehicles","abstract":"Due to its nature of dynamic, mobility, and wireless data transfer, the Internet of Vehicles (IoV) is prone to various cyber threats, ranging from spoofing and Distributed Denial of Services (DDoS) attacks to malware. To safeguard the IoV ecosystem from intrusions, malicious activities, policy violations, intrusion detection systems (IDS) play a critical role by continuously monitoring and analyzing network traffic to identify and mitigate potential threats in real-time. However, most existing research has focused on developing centralized, machine learning-based IDS systems for IoV without accounting for its inherently distributed nature. Due to intensive computing requirements, these centralized systems often rely on the cloud to detect cyber threats, increasing delay of system response. On the other hand, edge nodes typically lack the necessary resources to train and deploy complex machine learning algorithms. To address this issue, this paper proposes an effective hierarchical classification framework tailored for IoV networks. Hierarchical classification allows classifiers to be trained and tested at different levels, enabling edge nodes to detect specific types of attacks independently. With this approach, edge nodes can conduct targeted attack detection while leveraging cloud nodes for comprehensive threat analysis and support. Given the resource constraints of edge nodes, we have employed the Boruta feature selection method to reduce data dimensionality, optimizing processing efficiency. To evaluate our proposed framework, we utilize the latest IoV security dataset CIC-IoV2024, achieving promising results that demonstrate the feasibility and effectiveness of our models in securing IoV networks.","authors":["Md Ashraf Uddin","Nam H. Chu","Reza Rafeh","Mutaz Barika"],"url":"https://arxiv.org/abs/2505.16215"}
{"created":"2025-05-23","title":"Memorization or Reasoning? Exploring the Idiom Understanding of LLMs","abstract":"Idioms have long posed a challenge due to their unique linguistic properties, which set them apart from other common expressions. While recent studies have leveraged large language models (LLMs) to handle idioms across various tasks, e.g., idiom-containing sentence generation and idiomatic machine translation, little is known about the underlying mechanisms of idiom processing in LLMs, particularly in multilingual settings. To this end, we introduce MIDAS, a new large-scale dataset of idioms in six languages, each paired with its corresponding meaning. Leveraging this resource, we conduct a comprehensive evaluation of LLMs' idiom processing ability, identifying key factors that influence their performance. Our findings suggest that LLMs rely not only on memorization, but also adopt a hybrid approach that integrates contextual cues and reasoning, especially when processing compositional idioms. This implies that idiom understanding in LLMs emerges from an interplay between internal knowledge retrieval and reasoning-based inference.","authors":["Jisu Kim","Youngwoo Shin","Uiji Hwang","Jihun Choi","Richeng Xuan","Taeuk Kim"],"url":"https://arxiv.org/abs/2505.16216"}
{"created":"2025-05-23","title":"Reward-Aware Proto-Representations in Reinforcement Learning","abstract":"In recent years, the successor representation (SR) has attracted increasing attention in reinforcement learning (RL), and it has been used to address some of its key challenges, such as exploration, credit assignment, and generalization. The SR can be seen as representing the underlying credit assignment structure of the environment by implicitly encoding its induced transition dynamics. However, the SR is reward-agnostic. In this paper, we discuss a similar representation that also takes into account the reward dynamics of the problem. We study the default representation (DR), a recently proposed representation with limited theoretical (and empirical) analysis. Here, we lay some of the theoretical foundation underlying the DR in the tabular case by (1) deriving dynamic programming and (2) temporal-difference methods to learn the DR, (3) characterizing the basis for the vector space of the DR, and (4) formally extending the DR to the function approximation case through default features. Empirically, we analyze the benefits of the DR in many of the settings in which the SR has been applied, including (1) reward shaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our results show that, compared to the SR, the DR gives rise to qualitatively different, reward-aware behaviour and quantitatively better performance in several settings.","authors":["Hon Tik Tse","Siddarth Chandrasekar","Marlos C. Machado"],"url":"https://arxiv.org/abs/2505.16217"}
{"created":"2025-05-23","title":"LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead","abstract":"The rapid advancement of large language models has unlocked remarkable capabilities across a diverse array of natural language processing tasks. However, the considerable differences among available LLMs-in terms of cost, performance, and computational demands-pose significant challenges for users aiming to identify the most suitable model for specific tasks. In this work, we present LightRouter, a novel framework designed to systematically select and integrate a small subset of LLMs from a larger pool, with the objective of jointly optimizing both task performance and cost efficiency. LightRouter leverages an adaptive selection mechanism to identify models that require only a minimal number of boot tokens, thereby reducing costs, and further employs an effective integration strategy to combine their outputs. Extensive experiments across multiple benchmarks demonstrate that LightRouter matches or outperforms widely-used ensemble baselines, achieving up to a 25% improvement in accuracy. Compared with leading high-performing models, LightRouter achieves comparable performance while reducing inference costs by up to 27%. Importantly, our framework operates without any prior knowledge of individual models and relies exclusively on inexpensive, lightweight models. This work introduces a practical approach for efficient LLM selection and provides valuable insights into optimal strategies for model combination.","authors":["Yifan Zhang","Xinkui Zhao","Zuxin Wang","Guanjie Cheng","Yueshen Xu","Shuiguang Deng","Jianwei Yin"],"url":"https://arxiv.org/abs/2505.16221"}
{"created":"2025-05-23","title":"Don't Judge Code by Its Cover: Exploring Biases in LLM Judges for Code Evaluation","abstract":"With the growing use of large language models(LLMs) as evaluators, their application has expanded to code evaluation tasks, where they assess the correctness of generated code without relying on reference implementations. While this offers scalability and flexibility, it also raises a critical, unresolved question: Can LLM judges fairly and robustly evaluate semantically equivalent code with superficial variations? Functionally correct code often exhibits variations-such as differences in variable names, comments, or formatting-that should not influence its correctness. Yet, whether LLM judges can reliably handle these variations remains unclear. We present the first comprehensive study of this issue, defining six types of potential bias in code evaluation and revealing their systematic impact on LLM judges. Across five programming languages and multiple LLMs, we empirically demonstrate that all tested LLM judges are susceptible to both positive and negative biases, resulting in inflated or unfairly low scores. Moreover, we observe that LLM judges remain vulnerable to these biases even when prompted to generate test cases before scoring, highlighting the need for more robust code evaluation methods.","authors":["Jiwon Moon","Yerin Hwang","Dongryeol Lee","Taegwan Kang","Yongil Kim","Kyomin Jung"],"url":"https://arxiv.org/abs/2505.16222"}
{"created":"2025-05-23","title":"MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network","abstract":"In this paper, we propose MADCluster, a novel model-agnostic anomaly detection framework utilizing self-supervised clustering. MADCluster is applicable to various deep learning architectures and addresses the 'hypersphere collapse' problem inherent in existing deep learning-based anomaly detection methods. The core idea is to cluster normal pattern data into a 'single cluster' while simultaneously learning the cluster center and mapping data close to this center. Also, to improve expressiveness and enable effective single clustering, we propose a new 'One-directed Adaptive loss'. The optimization of this loss is mathematically proven. MADCluster consists of three main components: Base Embedder capturing high-dimensional temporal dynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous center updates. Its model-agnostic characteristics are achieved by applying various architectures to the Base Embedder. Experiments on four time series benchmark datasets demonstrate that applying MADCluster improves the overall performance of comparative models. In conclusion, the compatibility of MADCluster shows potential for enhancing model performance across various architectures.","authors":["Sangyong Lee","Subo Hwang","Dohoon Kim"],"url":"https://arxiv.org/abs/2505.16223"}
{"created":"2025-05-23","title":"MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning","abstract":"In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle diverse tasks by incorporating multiple input-output examples, known as demonstrations, into the input of LLMs. More recently, advancements in the expanded context windows of LLMs have led to many-shot ICL, which uses hundreds of demonstrations and outperforms few-shot ICL, which relies on fewer examples. However, this approach is often hindered by the high cost of obtaining large amounts of labeled data. To address this challenge, we propose Many-Shot Adaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL framework that utilizes pseudo-labeled samples to compensate for the lack of label information. We first identify a subset of impactful unlabeled samples and perform pseudo-labeling on them by querying LLMs. These pseudo-labeled samples are then adaptively selected and tailored to each test query as input to improve the performance of many-shot ICL, without significant labeling costs. Extensive experiments on real-world datasets demonstrate the effectiveness of our framework, showcasing its ability to enhance LLM adaptability and performance with limited labeled data.","authors":["Zihan Chen","Song Wang","Zhen Tan","Jundong Li","Cong Shen"],"url":"https://arxiv.org/abs/2505.16225"}
{"created":"2025-05-23","title":"Realistic Evaluation of TabPFN v2 in Open Environments","abstract":"Tabular data, owing to its ubiquitous presence in real-world domains, has garnered significant attention in machine learning research. While tree-based models have long dominated tabular machine learning tasks, the recently proposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled performance and scalability potential. Although extensive research has been conducted on TabPFN v2 to further improve performance, the majority of this research remains confined to closed environments, neglecting the challenges that frequently arise in open environments. This raises the question: Can TabPFN v2 maintain good performance in open environments? To this end, we conduct the first comprehensive evaluation of TabPFN v2's adaptability in open environments. We construct a unified evaluation framework covering various real-world challenges and assess the robustness of TabPFN v2 under open environments scenarios using this framework. Empirical results demonstrate that TabPFN v2 shows significant limitations in open environments but is suitable for small-scale, covariate-shifted, and class-balanced tasks. Tree-based models remain the optimal choice for general tabular tasks in open environments. To facilitate future research on open environments challenges, we advocate for open environments tabular benchmarks, multi-metric evaluation, and universal modules to strengthen model robustness. We publicly release our evaluation framework at https://anonymous.4open.science/r/tabpfn-ood-4E65.","authors":["Zi-Jian Cheng","Zi-Yi Jia","Zhi Zhou","Yu-Feng Li","Lan-Zhe Guo"],"url":"https://arxiv.org/abs/2505.16226"}
{"created":"2025-05-23","title":"Explain Less, Understand More: Jargon Detection via Personalized Parameter-Efficient Fine-tuning","abstract":"Personalizing jargon detection and explanation is essential for making technical documents accessible to readers with diverse disciplinary backgrounds. However, tailoring models to individual users typically requires substantial annotation efforts and computational resources due to user-specific finetuning. To address this, we present a systematic study of personalized jargon detection, focusing on methods that are both efficient and scalable for real-world deployment. We explore two personalization strategies: (1) lightweight fine-tuning using Low-Rank Adaptation (LoRA) on open-source models, and (2) personalized prompting, which tailors model behavior at inference time without retaining. To reflect realistic constraints, we also investigate hybrid approaches that combine limited annotated data with unsupervised user background signals. Our personalized LoRA model outperforms GPT-4 by 21.4% in F1 score and exceeds the best performing oracle baseline by 8.3%. Remarkably, our method achieves comparable performance using only 10% of the annotated training data, demonstrating its practicality for resource-constrained settings. Our study offers the first work to systematically explore efficient, low-resource personalization of jargon detection using open-source language models, offering a practical path toward scalable, user-adaptive NLP system.","authors":["Bohao Wu","Qingyun Wang","Yue Guo"],"url":"https://arxiv.org/abs/2505.16227"}
{"created":"2025-05-23","title":"A Shape-Aware Total Body Photography System for In-focus Surface Coverage Optimization","abstract":"Total Body Photography (TBP) is becoming a useful screening tool for patients at high risk for skin cancer. While much progress has been made, existing TBP systems can be further improved for automatic detection and analysis of suspicious skin lesions, which is in part related to the resolution and sharpness of acquired images. This paper proposes a novel shape-aware TBP system automatically capturing full-body images while optimizing image quality in terms of resolution and sharpness over the body surface. The system uses depth and RGB cameras mounted on a 360-degree rotary beam, along with 3D body shape estimation and an in-focus surface optimization method to select the optimal focus distance for each camera pose. This allows for optimizing the focused coverage over the complex 3D geometry of the human body given the calibrated camera poses. We evaluate the effectiveness of the system in capturing high-fidelity body images. The proposed system achieves an average resolution of 0.068 mm/pixel and 0.0566 mm/pixel with approximately 85% and 95% of surface area in-focus, evaluated on simulation data of diverse body shapes and poses as well as a real scan of a mannequin respectively. Furthermore, the proposed shape-aware focus method outperforms existing focus protocols (e.g. auto-focus). We believe the high-fidelity imaging enabled by the proposed system will improve automated skin lesion analysis for skin cancer screening.","authors":["Wei-Lun Huang","Joshua Liu","Davood Tashayyod","Jun Kang","Amir Gandjbakhche","Misha Kazhdan","Mehran Armand"],"url":"https://arxiv.org/abs/2505.16228"}
{"created":"2025-05-23","title":"CT-Agent: A Multimodal-LLM Agent for 3D CT Radiology Question Answering","abstract":"Computed Tomography (CT) scan, which produces 3D volumetric medical data that can be viewed as hundreds of cross-sectional images (a.k.a. slices), provides detailed anatomical information for diagnosis. For radiologists, creating CT radiology reports is time-consuming and error-prone. A visual question answering (VQA) system that can answer radiologists' questions about some anatomical regions on the CT scan and even automatically generate a radiology report is urgently needed. However, existing VQA systems cannot adequately handle the CT radiology question answering (CTQA) task for: (1) anatomic complexity makes CT images difficult to understand; (2) spatial relationship across hundreds slices is difficult to capture. To address these issues, this paper proposes CT-Agent, a multimodal agentic framework for CTQA. CT-Agent adopts anatomically independent tools to break down the anatomic complexity; furthermore, it efficiently captures the across-slice spatial relationship with a global-local token compression strategy. Experimental results on two 3D chest CT datasets, CT-RATE and RadGenome-ChestCT, verify the superior performance of CT-Agent.","authors":["Yuren Mao","Wenyi Xu","Yuyang Qin","Yunjun Gao"],"url":"https://arxiv.org/abs/2505.16229"}
{"created":"2025-05-23","title":"Beyond Diagonal Intelligent Reflecting Surface Aided Integrated Sensing and Communication","abstract":"Beyond diagonal intelligent reflecting surface (BD-IRS) is a new promising IRS architecture for which the reflection matrix is not limited to the diagonal structure as for conventional IRS. In this paper, we study a BD-IRS aided uplink integrated sensing and communication (ISAC) system where sensing is performed in a device-based manner. Specifically, we aim to estimate the unknown and random location of an active target based on its uplink probing signals sent to a multi-antenna base station (BS) as well as the known prior distribution information of the target's location. Multiple communication users also simultaneously send uplink signals, resulting in a challenging mutual interference issue between sensing and communication. We first characterize the sensing performance metric by deriving the posterior Cram\\'er-Rao bound (PCRB) of the mean-squared error (MSE) when prior information is available. Then, we formulate a BD-IRS reflection matrix optimization problem to maximize the minimum expected achievable rate among the multiple users subject to a constraint on the PCRB as well as the lossless and reciprocal constraints on the BD-IRS reflection matrix. The formulated problem is non-convex and challenging to solve. To tackle this problem, we propose a penalty dual decomposition (PDD) based algorithm which can find a high-quality suboptimal solution with polynomial-time complexity. In addition, we propose and optimize a time-division multiple access (TDMA) based scheme which removes the sensing-communication mutual interference. Numerical results verify the effectiveness of the proposed designs and provide useful design insights.","authors":["Shuo Zheng","Shuowen Zhang"],"url":"https://arxiv.org/abs/2505.16230"}
{"created":"2025-05-23","title":"MuseRAG: Idea Originality Scoring At Scale","abstract":"An objective, face-valid way to assess the originality of creative ideas is to measure how rare each idea is within a population -- an approach long used in creativity research but difficult to automate at scale. Tabulating response frequencies via manual bucketing of idea rephrasings is labor-intensive, error-prone, and brittle under large corpora. We introduce a fully automated, psychometrically validated pipeline for frequency-based originality scoring. Our method, MuseRAG, combines large language models (LLMs) with an externally orchestrated retrieval-augmented generation (RAG) framework. Given a new idea, the system retrieves semantically similar prior idea buckets and zero-shot prompts the LLM to judge whether the new idea belongs to an existing bucket or forms a new one. The resulting buckets enable computation of frequency-based originality metrics. Across five datasets (N=1143, n_ideas=16294), MuseRAG matches human annotators in idea clustering structure and resolution (AMI = 0.59) and in participant-level scoring (r = 0.89) -- while exhibiting strong convergent and external validity. Our work enables intent-sensitive, human-aligned originality scoring at scale to aid creativity research.","authors":["Ali Sarosh Bangash","Krish Veera","Ishfat Abrar Islam","Raiyan Abdul Baten"],"url":"https://arxiv.org/abs/2505.16232"}
{"created":"2025-05-23","title":"Novel Rewiring Mechanism for Restoration of the Fragmented Social Networks after Attacks","abstract":"Real-world complex systems exhibit intricate interconnections and dependencies, especially social networks, technological infrastructures, and communication networks. These networks are prone to disconnection due to random failures or external attacks on their components. Therefore, managing the security and resilience of such networks is a prime concern, particularly at the time of disaster. Therefore, in this research work, network is reconstructed by rewiring/addition of the edges and robustness of the networks is measured. To this aim, two approaches namely (i) Strategic rewiring (ii) budget constrained optimal rewiring are adopted. While current research often assesses robustness by examining the size of the largest connected component, this approach fails to capture the complete spectrum of vulnerability. The failure of a small number of connections leads to a sparser network yet connected network. Thus, the present research work delves deeper into evaluating the robustness of the restored network by evaluating Laplacian Energy to better comprehend the system's behavior during the restoration of the network still considering the size of the largest connected component attacks.","authors":["Rajesh Kumar","Suchi Kumari","Anubhav Mishra"],"url":"https://arxiv.org/abs/2505.16233"}
{"created":"2025-05-23","title":"LIFEBench: Evaluating Length Instruction Following in Large Language Models","abstract":"While large language models (LLMs) can solve PhD-level reasoning problems over long context inputs, they still struggle with a seemingly simpler task: following explicit length instructions-e.g., write a 10,000-word novel. Additionally, models often generate far too short outputs, terminate prematurely, or even refuse the request. Existing benchmarks focus primarily on evaluating generations quality, but often overlook whether the generations meet length constraints. To this end, we introduce Length Instruction Following Evaluation Benchmark (LIFEBench) to comprehensively evaluate LLMs' ability to follow length instructions across diverse tasks and a wide range of specified lengths. LIFEBench consists of 10,800 instances across 4 task categories in both English and Chinese, covering length constraints ranging from 16 to 8192 words. We evaluate 26 widely-used LLMs and find that most models reasonably follow short-length instructions but deteriorate sharply beyond a certain threshold. Surprisingly, almost all models fail to reach the vendor-claimed maximum output lengths in practice, as further confirmed by our evaluations extending up to 32K words. Even long-context LLMs, despite their extended input-output windows, counterintuitively fail to improve length-instructions following. Notably, Reasoning LLMs outperform even specialized long-text generation models, achieving state-of-the-art length following. Overall, LIFEBench uncovers fundamental limitations in current LLMs' length instructions following ability, offering critical insights for future progress.","authors":["Wei Zhang","Zhenhong Zhou","Junfeng Fang","Rongwu Xu","Kun Wang","Yuanhe Zhang","Rui Wang","Ge Zhang","Xinfeng Li","Li Sun","Lingjuan Lyu","Yang Liu","Sen Su"],"url":"https://arxiv.org/abs/2505.16234"}
{"created":"2025-05-23","title":"Base Station Placement Optimization for Networked Sensing Exploiting Target Location Distribution","abstract":"This paper studies a networked sensing system with multiple base stations (BSs), which collaboratively sense the unknown and random three-dimensional (3D) location of a target based on the target-reflected echo signals received at the BSs. Considering a practical scenario where the target location distribution is known a priori for exploitation, we aim to design the placement of the multiple BSs to optimize the networked sensing performance. Firstly, we characterize the posterior Cram\\'er-Rao bound (PCRB) of the mean-squared error (MSE) in sensing the target's 3D location. Despite its complex form under networked sensing, we derive its closed-form expression in terms of the BS locations. Next, we formulate the BS placement optimization problem to minimize the sensing PCRB, which is non-convex and difficult to solve. By leveraging a series of equivalent transformations and the iterative inner approximation method, we devise an algorithm with polynomial-time complexity which is guaranteed to converge to a solution satisfying the Karush-Kuhn Tucker (KKT) conditions of the problem. Numerical results show that the proposed placement design significantly outperforms various benchmark designs.","authors":["Kaiyue Hou","Shuowen Zhang"],"url":"https://arxiv.org/abs/2505.16236"}
{"created":"2025-05-23","title":"Align-GRAG: Reasoning-Guided Dual Alignment for Graph Retrieval-Augmented Generation","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities, but still struggle with issues like hallucinations and outdated information. Retrieval-augmented generation (RAG) addresses these issues by grounding LLM outputs in external knowledge with an Information Retrieval (IR) system. Building on this foundation, graph-based RAG systems go a step further by retrieving subgraphs, which preserve the relationships between knowledge entities and provide more comprehensive context. However, graph RAG faces two challenges: (1) Retrieving relevant information introduces irrelevant nodes (especially in dense graph databases, where retrieval usually extends to adjacent nodes), and leads to overly lengthy inputs that hinder efficiency; (2) The representation gap between graph and language during generation with LLMs limits the ability to fully leverage graph structures for enhanced understanding. To address these limitations, we propose Align-GRAG, a novel reasoning-guided dual alignment framework in post-retrieval phrase. It first formulates a subgraph by retrieving nodes and edges. Then an Aligner is proposed to jointly optimizes a graph encoder with LLM-summarized reasoning. It achieves dual alignment of graph node and representation by leveraging KL divergence loss and contrastive loss, facilitating efficient pruning of irrelevant knowledge and establishing a unified semantic space. The Generator integrates the aligned graph data with LLM to produce coherent and accurate answers. Experiments on GraphQA benchmark across three tasks (including common sense reasoning, scene graph understanding, and knowledge graph reasoning) validate the effectiveness of our method. The code will be available upon accepted.","authors":["Derong Xu","Pengyue Jia","Xiaopeng Li","Yingyi Zhang","Maolin Wang","Qidong Liu","Xiangyu Zhao","Yichao Wang","Huifeng Guo","Ruiming Tang","Enhong Chen","Tong Xu"],"url":"https://arxiv.org/abs/2505.16237"}
{"created":"2025-05-23","title":"DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution","abstract":"Diffusion models have demonstrated promising performance in real-world video super-resolution (VSR). However, the dozens of sampling steps they require, make inference extremely slow. Sampling acceleration techniques, particularly single-step, provide a potential solution. Nonetheless, achieving one step in VSR remains challenging, due to the high training overhead on video data and stringent fidelity demands. To tackle the above issues, we propose DOVE, an efficient one-step diffusion model for real-world VSR. DOVE is obtained by fine-tuning a pretrained video diffusion model (*i.e.*, CogVideoX). To effectively train DOVE, we introduce the latent-pixel training strategy. The strategy employs a two-stage scheme to gradually adapt the model to the video super-resolution task. Meanwhile, we design a video processing pipeline to construct a high-quality dataset tailored for VSR, termed HQ-VSR. Fine-tuning on this dataset further enhances the restoration capability of DOVE. Extensive experiments show that DOVE exhibits comparable or superior performance to multi-step diffusion-based VSR methods. It also offers outstanding inference efficiency, achieving up to a **28$\\times$** speed-up over existing methods such as MGLD-VSR. Code is available at: https://github.com/zhengchen1999/DOVE.","authors":["Zheng Chen","Zichen Zou","Kewei Zhang","Xiongfei Su","Xin Yuan","Yong Guo","Yulun Zhang"],"url":"https://arxiv.org/abs/2505.16239"}
{"created":"2025-05-23","title":"Three Minds, One Legend: Jailbreak Large Reasoning Model with Adaptive Stacked Ciphers","abstract":"Recently, Large Reasoning Models (LRMs) have demonstrated superior logical capabilities compared to traditional Large Language Models (LLMs), gaining significant attention. Despite their impressive performance, the potential for stronger reasoning abilities to introduce more severe security vulnerabilities remains largely underexplored. Existing jailbreak methods often struggle to balance effectiveness with robustness against adaptive safety mechanisms. In this work, we propose SEAL, a novel jailbreak attack that targets LRMs through an adaptive encryption pipeline designed to override their reasoning processes and evade potential adaptive alignment. Specifically, SEAL introduces a stacked encryption approach that combines multiple ciphers to overwhelm the models reasoning capabilities, effectively bypassing built-in safety mechanisms. To further prevent LRMs from developing countermeasures, we incorporate two dynamic strategies - random and adaptive - that adjust the cipher length, order, and combination. Extensive experiments on real-world reasoning models, including DeepSeek-R1, Claude Sonnet, and OpenAI GPT-o4, validate the effectiveness of our approach. Notably, SEAL achieves an attack success rate of 80.8% on GPT o4-mini, outperforming state-of-the-art baselines by a significant margin of 27.2%. Warning: This paper contains examples of inappropriate, offensive, and harmful content.","authors":["Viet-Anh Nguyen","Shiqian Zhao","Gia Dao","Runyi Hu","Yi Xie","Luu Anh Tuan"],"url":"https://arxiv.org/abs/2505.16241"}
{"created":"2025-05-23","title":"Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies","abstract":"When applying offline reinforcement learning (RL) in healthcare scenarios, the out-of-distribution (OOD) issues pose significant risks, as inappropriate generalization beyond clinical expertise can result in potentially harmful recommendations. While existing methods like conservative Q-learning (CQL) attempt to address the OOD issue, their effectiveness is limited by only constraining action selection by suppressing uncertain actions. This action-only regularization imitates clinician actions that prioritize short-term rewards, but it fails to regulate downstream state trajectories, thereby limiting the discovery of improved long-term treatment strategies. To safely improve policy beyond clinician recommendations while ensuring that state-action trajectories remain in-distribution, we propose \\textit{Offline Guarded Safe Reinforcement Learning} ($\\mathsf{OGSRL}$), a theoretically grounded model-based offline RL framework. $\\mathsf{OGSRL}$ introduces a novel dual constraint mechanism for improving policy with reliability and safety. First, the OOD guardian is established to specify clinically validated regions for safe policy exploration. By constraining optimization within these regions, it enables the reliable exploration of treatment strategies that outperform clinician behavior by leveraging the full patient state history, without drifting into unsupported state-action trajectories. Second, we introduce a safety cost constraint that encodes medical knowledge about physiological safety boundaries, providing domain-specific safeguards even in areas where training data might contain potentially unsafe interventions. Notably, we provide theoretical guarantees on safety and near-optimality: policies that satisfy these constraints remain in safe and reliable regions and achieve performance close to the best possible policy supported by the data.","authors":["Runze Yan","Xun Shen","Akifumi Wachi","Sebastien Gros","Anni Zhao","Xiao Hu"],"url":"https://arxiv.org/abs/2505.16242"}
{"created":"2025-05-23","title":"A novel splitting method for Vlasov-Ampere","abstract":"Vlasov equations model the dynamics of plasma in the collisionless regime. A standard approach for numerically solving the Vlasov equation is to operator split the spatial and velocity derivative terms, allowing simpler time-stepping schemes to be applied to each piece separately (known as the Cheng-Knorr method). One disadvantage of such an operator split method is that the order of accuracy of fluid moments (e.g., mass, momentum, and energy) is restricted by the order of the operator splitting (second-order accuracy in the Cheng-Knorr case). In this work, we develop a novel approach that first represents the particle density function on a velocity mesh with a local fluid approximation in each discrete velocity band and then introduces an operator splitting that splits the inter-velocity band coupling terms from the dynamics within the discrete velocity band. The advantage is that the inter-velocity band coupling terms are only needed to achieve consistency of the full distribution functions, but the local fluid models within each band are sufficient to achieve high-order accuracy on global moments such as mass, momentum, and energy. The resulting scheme is verified on several standard Vlasov-Poisson test cases.","authors":["James A. Rossmanith","Christine Vaughan"],"url":"https://arxiv.org/abs/2505.16243"}
{"created":"2025-05-23","title":"Diverse, not Short: A Length-Controlled Self-Learning Framework for Improving Response Diversity of Language Models","abstract":"Diverse language model responses are crucial for creative generation, open-ended tasks, and self-improvement training. We show that common diversity metrics, and even reward models used for preference optimization, systematically bias models toward shorter outputs, limiting expressiveness. To address this, we introduce Diverse, not Short (Diverse-NS), a length-controlled self-learning framework that improves response diversity while maintaining length parity. By generating and filtering preference data that balances diversity, quality, and length, Diverse-NS enables effective training using only 3,000 preference pairs. Applied to LLaMA-3.1-8B and the Olmo-2 family, Diverse-NS substantially enhances lexical and semantic diversity. We show consistent improvement in diversity with minor reduction or gains in response quality on four creative generation tasks: Divergent Associations, Persona Generation, Alternate Uses, and Creative Writing. Surprisingly, experiments with the Olmo-2 model family (7B, and 13B) show that smaller models like Olmo-2-7B can serve as effective \"diversity teachers\" for larger models. By explicitly addressing length bias, our method efficiently pushes models toward more diverse and expressive outputs.","authors":["Vijeta Deshpande","Debasmita Ghose","John D. Patterson","Roger Beaty","Anna Rumshisky"],"url":"https://arxiv.org/abs/2505.16245"}
{"created":"2025-05-23","title":"Verifying Differentially Private Median Estimation","abstract":"Differential Privacy (DP) is a robust privacy guarantee that is widely employed in private data analysis today, finding broad application in domains such as statistical query release and machine learning. However, DP achieves privacy by introducing noise into data or query answers, which malicious actors could exploit during analysis. To address this concern, we propose the first verifiable differentially private median estimation scheme based on zk-SNARKs. Our scheme combines the exponential mechanism and a utility function for median estimation into an arithmetic circuit, leveraging a scaled version of the inverse cumulative distribution function (CDF) method for precise sampling from the distribution derived from the utility function. This approach not only ensures privacy but also provides a mechanism to verify that the algorithm achieves DP guarantees without revealing sensitive information in the process.","authors":["Hyukjun Kwon","Chenglin Fan"],"url":"https://arxiv.org/abs/2505.16246"}
{"created":"2025-05-23","title":"Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems","abstract":"This paper addresses the limitations of multi-node perception and delayed scheduling response in distributed systems by proposing a GNN-based multi-node collaborative perception mechanism. The system is modeled as a graph structure. Message-passing and state-update modules are introduced. A multi-layer graph neural network is constructed to enable efficient information aggregation and dynamic state inference among nodes. In addition, a perception representation method is designed by fusing local states with global features. This improves each node's ability to perceive the overall system status. The proposed method is evaluated within a customized experimental framework. A dataset featuring heterogeneous task loads and dynamic communication topologies is used. Performance is measured in terms of task completion rate, average latency, load balancing, and transmission efficiency. Experimental results show that the proposed method outperforms mainstream algorithms under various conditions, including limited bandwidth and dynamic structural changes. It demonstrates superior perception capabilities and cooperative scheduling performance. The model achieves rapid convergence and efficient responses to complex system states.","authors":["Wenxuan Zhu","Qiyuan Wu","Tengda Tang","Renzi Meng","Sheng Chai","Xuehui Quan"],"url":"https://arxiv.org/abs/2505.16248"}
{"created":"2025-05-23","title":"Manipulating Elasto-Plastic Objects With 3D Occupancy and Learning-Based Predictive Control","abstract":"Manipulating elasto-plastic objects remains a significant challenge due to severe self-occlusion, difficulties of representation, and complicated dynamics. This work proposes a novel framework for elasto-plastic object manipulation with a quasi-static assumption for motions, leveraging 3D occupancy to represent such objects, a learned dynamics model trained with 3D occupancy, and a learning-based predictive control algorithm to address these challenges effectively. We build a novel data collection platform to collect full spatial information and propose a pipeline for generating a 3D occupancy dataset. To infer the 3D occupancy during manipulation, an occupancy prediction network is trained with multiple RGB images supervised by the generated dataset. We design a deep neural network empowered by a 3D convolution neural network (CNN) and a graph neural network (GNN) to predict the complex deformation with the inferred 3D occupancy results. A learning-based predictive control algorithm is introduced to plan the robot actions, incorporating a novel shape-based action initialization module specifically designed to improve the planner efficiency. The proposed framework in this paper can successfully shape the elasto-plastic objects into a given goal shape and has been verified in various experiments both in simulation and the real world.","authors":["Zhen Zhang","Xiangyu Chu","Yunxi Tang","Lulu Zhao","Jing Huang","Zhongliang Jiang","K. W. Samuel Au"],"url":"https://arxiv.org/abs/2505.16249"}
{"created":"2025-05-23","title":"Does Localization Inform Unlearning? A Rigorous Examination of Local Parameter Attribution for Knowledge Unlearning in Language Models","abstract":"Large language models often retain unintended content, prompting growing interest in knowledge unlearning. Recent approaches emphasize localized unlearning, which restricts parameter updates to specific regions in an effort to remove target knowledge while preserving unrelated general knowledge. However, their effectiveness remains uncertain due to the lack of robust and thorough evaluation of the trade-off between the competing goals of unlearning. In this paper, we begin by revisiting existing localized unlearning approaches. We then conduct controlled experiments to rigorously evaluate whether local parameter updates causally contribute to unlearning. Our findings reveal that the set of parameters that must be modified for effective unlearning is not strictly determined, challenging the core assumption of localized unlearning that parameter locality is inherently indicative of effective knowledge removal.","authors":["Hwiyeong Lee","Uiji Hwang","Hyelim Lim","Taeuk Kim"],"url":"https://arxiv.org/abs/2505.16252"}
{"created":"2025-05-23","title":"Swin Transformer for Robust CGI Images Detection: Intra- and Inter-Dataset Analysis across Multiple Color Spaces","abstract":"This study aims to address the growing challenge of distinguishing computer-generated imagery (CGI) from authentic digital images across three different color spaces; RGB, YCbCr, and HSV. Given the limitations of existing classification methods in handling the complexity and variability of CGI, this research proposes a Swin Transformer based model for accurate differentiation between natural and synthetic images. The proposed model leverages the Swin Transformer's hierarchical architecture to capture local and global features for distinguishing CGI from natural images. Its performance was assessed through intra- and inter-dataset testing across three datasets: CiFAKE, JSSSTU, and Columbia. The model was evaluated individually on each dataset (D1, D2, D3) and on the combined datasets (D1+D2+D3) to test its robustness and domain generalization. To address dataset imbalance, data augmentation techniques were applied. Additionally, t-SNE visualization was used to demonstrate the feature separability achieved by the Swin Transformer across the selected color spaces. The model's performance was tested across all color schemes, with the RGB color scheme yielding the highest accuracy for each dataset. As a result, RGB was selected for domain generalization analysis and compared with other CNN-based models, VGG-19 and ResNet-50. The comparative results demonstrate the proposed model's effectiveness in detecting CGI, highlighting its robustness and reliability in both intra-dataset and inter-dataset evaluations. The findings of this study highlight the Swin Transformer model's potential as an advanced tool for digital image forensics, particularly in distinguishing CGI from natural images. The model's strong performance indicates its capability for domain generalization, making it a valuable asset in scenarios requiring precise and reliable image classification.","authors":["Preeti Mehta","Aman Sagar","Suchi Kumari"],"url":"https://arxiv.org/abs/2505.16253"}
{"created":"2025-05-23","title":"Reassessing Collaborative Writing Theories and Frameworks in the Age of LLMs: What Still Applies and What We Must Leave Behind","abstract":"In this paper, we conduct a critical review of existing theories and frameworks on human-human collaborative writing to assess their relevance to the current human-AI paradigm in professional contexts, and draw seven insights along with design implications for human-AI collaborative writing tools. We found that, as LLMs nudge the writing process more towards an empirical \"trial and error\" process analogous to prototyping, the non-linear cognitive process of writing will stay the same, but more rigor will be required for revision methodologies. This shift would shed further light on the importance of coherence support, but the large language model (LLM)'s unprecedented semantic capabilities can bring novel approaches to this ongoing challenge. We argue that teamwork-related factors such as group awareness, consensus building and authorship - which have been central in human-human collaborative writing studies - should not apply to the human-AI paradigm due to excessive anthropomorphism. With the LLM's text generation capabilities becoming essentially indistinguishable from human-written ones, we are entering an era where, for the first time in the history of computing, we are engaging in collaborative writing with AI at workplaces on a daily basis. We aim to bring theoretical grounding and practical design guidance to the interaction designs of human-AI collaborative writing, with the goal of enhancing future human-AI writing software.","authors":["Daisuke Yukita","Tim Miller","Joel Mackenzie"],"url":"https://arxiv.org/abs/2505.16254"}
{"created":"2025-05-23","title":"DualComp: End-to-End Learning of a Unified Dual-Modality Lossless Compressor","abstract":"Most learning-based lossless compressors are designed for a single modality, requiring separate models for multi-modal data and lacking flexibility. However, different modalities vary significantly in format and statistical properties, making it ineffective to use compressors that lack modality-specific adaptations. While multi-modal large language models (MLLMs) offer a potential solution for modality-unified compression, their excessive complexity hinders practical deployment. To address these challenges, we focus on the two most common modalities, image and text, and propose DualComp, the first unified and lightweight learning-based dual-modality lossless compressor. Built on a lightweight backbone, DualComp incorporates three key structural enhancements to handle modality heterogeneity: modality-unified tokenization, modality-switching contextual learning, and modality-routing mixture-of-experts. A reparameterization training strategy is also used to boost compression performance. DualComp integrates both modality-specific and shared parameters for efficient parameter utilization, enabling near real-time inference (200KB/s) on desktop CPUs. With much fewer parameters, DualComp achieves compression performance on par with the SOTA LLM-based methods for both text and image datasets. Its simplified single-modality variant surpasses the previous best image compressor on the Kodak dataset by about 9% using just 1.2% of the model size.","authors":["Yan Zhao","Zhengxue Cheng","Junxuan Zhang","Qunshan Gu","Qi Wang","Li Song"],"url":"https://arxiv.org/abs/2505.16256"}
{"created":"2025-05-23","title":"IRONIC: Coherence-Aware Reasoning Chains for Multi-Modal Sarcasm Detection","abstract":"Interpreting figurative language such as sarcasm across multi-modal inputs presents unique challenges, often requiring task-specific fine-tuning and extensive reasoning steps. However, current Chain-of-Thought approaches do not efficiently leverage the same cognitive processes that enable humans to identify sarcasm. We present IRONIC, an in-context learning framework that leverages Multi-modal Coherence Relations to analyze referential, analogical and pragmatic image-text linkages. Our experiments show that IRONIC achieves state-of-the-art performance on zero-shot Multi-modal Sarcasm Detection across different baselines. This demonstrates the need for incorporating linguistic and cognitive insights into the design of multi-modal reasoning strategies. Our code is available at: https://github.com/aashish2000/IRONIC","authors":["Aashish Anantha Ramakrishnan","Aadarsh Anantha Ramakrishnan","Dongwon Lee"],"url":"https://arxiv.org/abs/2505.16258"}
{"created":"2025-05-23","title":"Dialogue in Resonance: An Interactive Music Piece for Piano and Real-Time Automatic Transcription System","abstract":"This paper presents , an interactive music piece for a human pianist and a computer-controlled piano that integrates real-time automatic music transcription into a score-driven framework. Unlike previous approaches that primarily focus on improvisation-based interactions, our work establishes a balanced framework that combines composed structure with dynamic interaction. Through real-time automatic transcription as its core mechanism, the computer interprets and responds to the human performer's input in real time, creating a musical dialogue that balances compositional intent with live interaction while incorporating elements of unpredictability. In this paper, we present the development process from composition to premiere performance, including technical implementation, rehearsal process, and performance considerations.","authors":["Hayeon Bang","Taegyun Kwon","Juhan Nam"],"url":"https://arxiv.org/abs/2505.16259"}
{"created":"2025-05-23","title":"Small-to-Large Generalization: Data Influences Models Consistently Across Scale","abstract":"Choice of training data distribution greatly influences model behavior. Yet, in large-scale settings, precisely characterizing how changes in training data affects predictions is often difficult due to model training costs. Current practice is to instead extrapolate from scaled down, inexpensive-to-train proxy models. However, changes in data do not influence smaller and larger models identically. Therefore, understanding how choice of data affects large-scale models raises the question: how does training data distribution influence model behavior across compute scale? We find that small- and large-scale language model predictions (generally) do highly correlate across choice of training data. Equipped with these findings, we characterize how proxy scale affects effectiveness in two downstream proxy model applications: data attribution and dataset selection.","authors":["Alaa Khaddaj","Logan Engstrom","Aleksander Madry"],"url":"https://arxiv.org/abs/2505.16260"}
{"created":"2025-05-23","title":"Interpretable Anomaly Detection in Encrypted Traffic Using SHAP with Machine Learning Models","abstract":"The widespread adoption of encrypted communication protocols such as HTTPS and TLS has enhanced data privacy but also rendered traditional anomaly detection techniques less effective, as they often rely on inspecting unencrypted payloads. This study aims to develop an interpretable machine learning-based framework for anomaly detection in encrypted network traffic. This study proposes a model-agnostic framework that integrates multiple machine learning classifiers, with SHapley Additive exPlanations SHAP to ensure post-hoc model interpretability. The models are trained and evaluated on three benchmark encrypted traffic datasets. Performance is assessed using standard classification metrics, and SHAP is used to explain model predictions by attributing importance to individual input features. SHAP visualizations successfully revealed the most influential traffic features contributing to anomaly predictions, enhancing the transparency and trustworthiness of the models. Unlike conventional approaches that treat machine learning as a black box, this work combines robust classification techniques with explainability through SHAP, offering a novel interpretable anomaly detection system tailored for encrypted traffic environments. While the framework is generalizable, real-time deployment and performance under adversarial conditions require further investigation. Future work may explore adaptive models and real-time interpretability in operational network environments. This interpretable anomaly detection framework can be integrated into modern security operations for encrypted environments, allowing analysts not only to detect anomalies with high precision but also to understand why a model made a particular decision a crucial capability in compliance-driven and mission-critical settings.","authors":["Kalindi Singh","Aayush Kashyap","Aswani Kumar Cherukuri"],"url":"https://arxiv.org/abs/2505.16261"}
{"created":"2025-05-23","title":"All You Need is \"Leet\": Evading Hate-speech Detection AI","abstract":"Social media and online forums are increasingly becoming popular. Unfortunately, these platforms are being used for spreading hate speech. In this paper, we design black-box techniques to protect users from hate-speech on online platforms by generating perturbations that can fool state of the art deep learning based hate speech detection models thereby decreasing their efficiency. We also ensure a minimal change in the original meaning of hate-speech. Our best perturbation attack is successfully able to evade hate-speech detection for 86.8 % of hateful text.","authors":["Sampanna Yashwant Kahu","Naman Ahuja"],"url":"https://arxiv.org/abs/2505.16263"}
{"created":"2025-05-23","title":"LINEA: Fast and Accurate Line Detection Using Scalable Transformers","abstract":"Line detection is a basic digital image processing operation used by higher-level processing methods. Recently, transformer-based methods for line detection have proven to be more accurate than methods based on CNNs, at the expense of significantly lower inference speeds. As a result, video analysis methods that require low latencies cannot benefit from current transformer-based methods for line detection. In addition, current transformer-based models require pretraining attention mechanisms on large datasets (e.g., COCO or Object360). This paper develops a new transformer-based method that is significantly faster without requiring pretraining the attention mechanism on large datasets. We eliminate the need to pre-train the attention mechanism using a new mechanism, Deformable Line Attention (DLA). We use the term LINEA to refer to our new transformer-based method based on DLA. Extensive experiments show that LINEA is significantly faster and outperforms previous models on sAP in out-of-distribution dataset testing.","authors":["Sebastian Janampa","Marios Pattichis"],"url":"https://arxiv.org/abs/2505.16264"}
{"created":"2025-05-23","title":"Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models","abstract":"Reinforcement learning from human feedback (RLHF) has become a powerful post-training paradigm for aligning large language models with human preferences. A core challenge in RLHF is constructing accurate reward signals, where the conventional Bradley-Terry reward models (BT RMs) often suffer from sensitivity to data size and coverage, as well as vulnerability to reward hacking. Generative reward models (GenRMs) offer a more robust alternative by generating chain-of-thought (CoT) rationales followed by a final reward. However, existing GenRMs rely on shallow, vertically scaled reasoning, limiting their capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks. Moreover, their pairwise preference outputs are incompatible with standard RLHF algorithms that require pointwise reward signals. In this work, we introduce Think-RM, a training framework that enables long-horizon reasoning in GenRMs by modeling an internal thinking process. Rather than producing structured, externally provided rationales, Think-RM generates flexible, self-guided reasoning traces that support advanced capabilities such as self-reflection, hypothetical reasoning, and divergent reasoning. To elicit these reasoning abilities, we first warm-up the models by supervised fine-tuning (SFT) over long CoT data. We then further improve the model's long-horizon abilities by rule-based reinforcement learning (RL). In addition, we propose a novel pairwise RLHF pipeline that directly optimizes policies using pairwise preference rewards, eliminating the need for pointwise reward conversion and enabling more effective use of Think-RM outputs. Experiments show that Think-RM achieves state-of-the-art results on RM-Bench, outperforming both BT RM and vertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline, it demonstrates superior end-policy performance compared to traditional approaches.","authors":["Ilgee Hong","Changlong Yu","Liang Qiu","Weixiang Yan","Zhenghao Xu","Haoming Jiang","Qingru Zhang","Qin Lu","Xin Liu","Chao Zhang","Tuo Zhao"],"url":"https://arxiv.org/abs/2505.16265"}
{"created":"2025-05-23","title":"Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning","abstract":"Large language models are typically adapted to downstream tasks through supervised fine-tuning on domain-specific data. While standard fine-tuning focuses on minimizing generation loss to optimize model parameters, we take a deeper step by retaining and leveraging the model's own learning signals, analogous to how human learners reflect on past mistakes to improve future performance. We first introduce the concept of Mistake Log to systematically track the model's learning behavior and recurring errors throughout fine-tuning. Treating the original transformer-based model as the Pilot, we correspondingly design a Copilot model to refine the Pilot's inference performance via logits rectification. We name the overall Pilot-Copilot framework the Transformer Copilot, which introduces (i) a novel Copilot model design, (ii) a joint training paradigm where the Copilot continuously learns from the evolving Mistake Log alongside the Pilot, and (iii) a fused inference paradigm where the Copilot rectifies the Pilot's logits for enhanced generation. We provide both theoretical and empirical analyses on our new learning framework. Experiments on 12 benchmarks spanning commonsense, arithmetic, and recommendation tasks demonstrate that Transformer Copilot consistently improves performance by up to 34.5%, while introducing marginal computational overhead to Pilot models and exhibiting strong scalability and transferability.","authors":["Jiaru Zou","Yikun Ban","Zihao Li","Yunzhe Qi","Ruizhong Qiu","Ling Yang","Jingrui He"],"url":"https://arxiv.org/abs/2505.16270"}
{"created":"2025-05-23","title":"Multimodal AI-based visualization of strategic leaders' emotional dynamics: a deep behavioral analysis of Trump's trade war discourse","abstract":"This study investigates the emotional rhythms and behavioral mechanisms of dominant political leaders in strategic decision-making. Using the Trump administration's 125 percent tariff hike on China as a case, it adopts a Multimodal Cognitive Behavioral Modeling framework. This includes micro-expression tracking, acoustic intonation analysis, semantic flow modeling, cognitive load simulation, and strategic behavior mapping to construct a full-cycle simulation of emotion, motivation, and output. Results reveal that Trump's decisions are not driven by rational deduction, but emerge from dominance-coherence rhythms. A six-axis National Strategic Tempo Intervention Framework is proposed to support anticipatory policy modeling.","authors":["Wei Meng"],"url":"https://arxiv.org/abs/2505.16274"}
{"created":"2025-05-23","title":"How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance","abstract":"When using Large Language Models (LLMs) to support Knowledge Graph Engineering (KGE), one of the first indications when searching for an appropriate model is its size. According to the scaling laws, larger models typically show higher capabilities. However, in practice, resource costs are also an important factor and thus it makes sense to consider the ratio between model performance and costs. The LLM-KG-Bench framework enables the comparison of LLMs in the context of KGE tasks and assesses their capabilities of understanding and producing KGs and KG queries. Based on a dataset created in an LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the model size scaling laws specific to KGE tasks. In our analyses, we assess how benchmark scores evolve between different model size categories. Additionally, we inspect how the general score development of single models and families of models correlates to their size. Our analyses revealed that, with a few exceptions, the model size scaling laws generally also apply to the selected KGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e., the task performance did not change much between a model and the next larger model. In these cases, smaller models could be considered to achieve high cost-effectiveness. Regarding models of the same family, sometimes larger models performed worse than smaller models of the same family. These effects occurred only locally. Hence it is advisable to additionally test the next smallest and largest model of the same family.","authors":["Desiree Heim","Lars-Peter Meyer","Markus Schr\\\"oder","Johannes Frey","Andreas Dengel"],"url":"https://arxiv.org/abs/2505.16276"}
{"created":"2025-05-23","title":"Spontaneous Speech Variables for Evaluating LLMs Cognitive Plausibility","abstract":"The achievements of Large Language Models in Natural Language Processing, especially for high-resource languages, call for a better understanding of their characteristics from a cognitive perspective. Researchers have attempted to evaluate artificial models by testing their ability to predict behavioral (e.g., eye-tracking fixations) and physiological (e.g., brain responses) variables during language processing (e.g., reading/listening). In this paper, we propose using spontaneous speech corpora to derive production variables (speech reductions, prosodic prominences) and applying them in a similar fashion. More precisely, we extract. We then test models trained with a standard procedure on different pretraining datasets (written, spoken, and mixed genres) for their ability to predict these two variables. Our results show that, after some fine-tuning, the models can predict these production variables well above baselines. We also observe that spoken genre training data provides more accurate predictions than written genres. These results contribute to the broader effort of using high-quality speech corpora as benchmarks for LLMs.","authors":["Sheng-Fu Wang","Laurent Prevot","Jou-an Chi","Ri-Sheng Huang","Shu-Kai Hsieh"],"url":"https://arxiv.org/abs/2505.16277"}
{"created":"2025-05-23","title":"DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving","abstract":"End-to-end autonomous driving (E2E-AD) demands effective processing of multi-view sensory data and robust handling of diverse and complex driving scenarios, particularly rare maneuvers such as aggressive turns. Recent success of Mixture-of-Experts (MoE) architecture in Large Language Models (LLMs) demonstrates that specialization of parameters enables strong scalability. In this work, we propose DriveMoE, a novel MoE-based E2E-AD framework, with a Scene-Specialized Vision MoE and a Skill-Specialized Action MoE. DriveMoE is built upon our $\\pi_0$ Vision-Language-Action (VLA) baseline (originally from the embodied AI field), called Drive-$\\pi_0$. Specifically, we add Vision MoE to Drive-$\\pi_0$ by training a router to select relevant cameras according to the driving context dynamically. This design mirrors human driving cognition, where drivers selectively attend to crucial visual cues rather than exhaustively processing all visual information. In addition, we add Action MoE by training another router to activate specialized expert modules for different driving behaviors. Through explicit behavioral specialization, DriveMoE is able to handle diverse scenarios without suffering from modes averaging like existing models. In Bench2Drive closed-loop evaluation experiments, DriveMoE achieves state-of-the-art (SOTA) performance, demonstrating the effectiveness of combining vision and action MoE in autonomous driving tasks. We will release our code and models of DriveMoE and Drive-$\\pi_0$.","authors":["Zhenjie Yang","Yilin Chai","Xiaosong Jia","Qifeng Li","Yuqian Shao","Xuekai Zhu","Haisheng Su","Junchi Yan"],"url":"https://arxiv.org/abs/2505.16278"}
{"created":"2025-05-23","title":"MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie Dubbing","abstract":"Current movie dubbing technology can produce the desired speech using a reference voice and input video, maintaining perfect synchronization with the visuals while effectively conveying the intended emotions. However, crucial aspects of movie dubbing, including adaptation to various dubbing styles, effective handling of dialogue, narration, and monologues, as well as consideration of subtle details such as speaker age and gender, remain insufficiently explored. To tackle these challenges, we introduce a multi-modal generative framework. First, it utilizes a multi-modal large vision-language model (VLM) to analyze visual inputs, enabling the recognition of dubbing types and fine-grained attributes. Second, it produces high-quality dubbing using large speech generation models, guided by multi-modal inputs. Additionally, a movie dubbing dataset with annotations for dubbing types and subtle details is constructed to enhance movie understanding and improve dubbing quality for the proposed multi-modal framework. Experimental results across multiple benchmark datasets show superior performance compared to state-of-the-art (SOTA) methods. In details, the LSE-D, SPK-SIM, EMO-SIM, and MCD exhibit improvements of up to 1.09%, 8.80%, 19.08%, and 18.74%, respectively.","authors":["Junjie Zheng","Zihao Chen","Chaofan Ding","Yunming Liang","Yihan Fan","Huan Yang","Lei Xie","Xinhan Di"],"url":"https://arxiv.org/abs/2505.16279"}
{"created":"2025-05-23","title":"Brand: Managing Training Data with Batched Random Access","abstract":"This paper propose Brand, a comprehensive memory management system for deep learning training (DLT) where the memory capacity is much smaller than the size of the training datasets. Brand starts with a bold design choice that data files are always read from disk in batch, named chunk. Based on this assumption, we propose efficient data access protocol in both single-node setting and distributed environment with multiple nodes. The protocol minimizes the wasted data read due to larger granularity, enables efficient inter-node prefetching, while still ensuring randomness required by DLT. The experimental results indicate that Brand can significantly accelerate data fetching in DLT, achieving up to a 4.57x improvement in end-to-end training compared to PyTorch.","authors":["Yuhao Li","Xuanhua Shi","Yunfei Zhao","Yongluan Zhou","Yusheng Hua","Xuehai Qian"],"url":"https://arxiv.org/abs/2505.16280"}
{"created":"2025-05-23","title":"HiMATE: A Hierarchical Multi-Agent Framework for Machine Translation Evaluation","abstract":"The advancement of Large Language Models (LLMs) enables flexible and interpretable automatic evaluations. In the field of machine translation evaluation, utilizing LLMs with translation error annotations based on Multidimensional Quality Metrics (MQM) yields more human-aligned judgments. However, current LLM-based evaluation methods still face challenges in accurately identifying error spans and assessing their severity. In this paper, we propose HiMATE, a Hierarchical Multi-Agent Framework for Machine Translation Evaluation. We argue that existing approaches inadequately exploit the fine-grained structural and semantic information within the MQM hierarchy. To address this, we develop a hierarchical multi-agent system grounded in the MQM error typology, enabling granular evaluation of subtype errors. Two key strategies are incorporated to further mitigate systemic hallucinations within the framework: the utilization of the model's self-reflection capability and the facilitation of agent discussion involving asymmetric information. Empirically, HiMATE outperforms competitive baselines across different datasets in conducting human-aligned evaluations. Further analyses underscore its significant advantage in error span detection and severity assessment, achieving an average F1-score improvement of 89% over the best-performing baseline. We make our code and data publicly available at https://anonymous.4open.science/r/HiMATE-Anony.","authors":["Shijie Zhang","Renhao Li","Songsheng Wang","Philipp Koehn","Min Yang","Derek F. Wong"],"url":"https://arxiv.org/abs/2505.16281"}
{"created":"2025-05-23","title":"ARPO:End-to-End Policy Optimization for GUI Agents with Experience Replay","abstract":"Training large language models (LLMs) as interactive agents for controlling graphical user interfaces (GUIs) presents a unique challenge to optimize long-horizon action sequences with multimodal feedback from complex environments. While recent works have advanced multi-turn reinforcement learning (RL) for reasoning and tool-using capabilities in LLMs, their application to GUI-based agents remains relatively underexplored due to the difficulty of sparse rewards, delayed feedback, and high rollout costs. In this paper, we investigate end-to-end policy optimization for vision-language-based GUI agents with the aim of improving performance on complex, long-horizon computer tasks. We propose Agentic Replay Policy Optimization (ARPO), an end-to-end RL approach that augments Group Relative Policy Optimization (GRPO) with a replay buffer to reuse the successful experience across training iterations. To further stabilize the training process, we propose a task selection strategy that filters tasks based on baseline agent performance, allowing the agent to focus on learning from informative interactions. Additionally, we compare ARPO with offline preference optimization approaches, highlighting the advantages of policy-based methods in GUI environments. Experiments on the OSWorld benchmark demonstrate that ARPO achieves competitive results, establishing a new performance baseline for LLM-based GUI agents trained via reinforcement learning. Our findings underscore the effectiveness of reinforcement learning for training multi-turn, vision-language GUI agents capable of managing complex real-world UI interactions. Codes and models:https://github.com/dvlab-research/ARPO.git.","authors":["Fanbin Lu","Zhisheng Zhong","Shu Liu","Chi-Wing Fu","Jiaya Jia"],"url":"https://arxiv.org/abs/2505.16282"}
{"created":"2025-05-23","title":"Efficient Prototype Consistency Learning in Medical Image Segmentation via Joint Uncertainty and Data Augmentation","abstract":"Recently, prototype learning has emerged in semi-supervised medical image segmentation and achieved remarkable performance. However, the scarcity of labeled data limits the expressiveness of prototypes in previous methods, potentially hindering the complete representation of prototypes for class embedding. To overcome this issue, we propose an efficient prototype consistency learning via joint uncertainty quantification and data augmentation (EPCL-JUDA) to enhance the semantic expression of prototypes based on the framework of Mean-Teacher. The concatenation of original and augmented labeled data is fed into student network to generate expressive prototypes. Then, a joint uncertainty quantification method is devised to optimize pseudo-labels and generate reliable prototypes for original and augmented unlabeled data separately. High-quality global prototypes for each class are formed by fusing labeled and unlabeled prototypes, which are utilized to generate prototype-to-features to conduct consistency learning. Notably, a prototype network is proposed to reduce high memory requirements brought by the introduction of augmented data. Extensive experiments on Left Atrium, Pancreas-NIH, Type B Aortic Dissection datasets demonstrate EPCL-JUDA's superiority over previous state-of-the-art approaches, confirming the effectiveness of our framework. The code will be released soon.","authors":["Lijian Li","Yuanpeng He","Chi-Man Pun"],"url":"https://arxiv.org/abs/2505.16283"}
{"created":"2025-05-23","title":"Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse","abstract":"Attention mechanisms lie at the heart of modern large language models (LLMs). Straightforward algorithms for forward and backward (gradient) computation take quadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023] and [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary unless the model weights are small, in which case almost linear time algorithms are possible. In this paper, we show that large weights are necessary to avoid a strong preclusion to representational strength we call layer collapse, which means that the entire network can be approximated well by a network with only a single layer. Thus, the quadratic running time of attention is unavoidable for expressive transformers.","authors":["Josh Alman","Zhao Song"],"url":"https://arxiv.org/abs/2505.16284"}
{"created":"2025-05-23","title":"No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery","abstract":"Deep learning models trained on extensive Electronic Health Records (EHR) data have achieved high accuracy in diagnosis prediction, offering the potential to assist clinicians in decision-making and treatment planning. However, these models lack two crucial features that clinicians highly value: interpretability and interactivity. The ``black-box'' nature of these models makes it difficult for clinicians to understand the reasoning behind predictions, limiting their ability to make informed decisions. Additionally, the absence of interactive mechanisms prevents clinicians from incorporating their own knowledge and experience into the decision-making process. To address these limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal discovery framework that integrates personalized knowledge databases and agentic LLMs. II-KEA enhances interpretability through explicit reasoning and causal analysis, while also improving interactivity by allowing clinicians to inject their knowledge and experience through customized knowledge bases and prompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating superior performance along with enhanced interpretability and interactivity, as evidenced by its strong results from extensive case studies.","authors":["Xiaoxue Han","Pengfei Hu","Jun-En Ding","Chang Lu","Feng Liu","Yue Ning"],"url":"https://arxiv.org/abs/2505.16288"}
{"created":"2025-05-23","title":"TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Manipulation","abstract":"Though robotic dexterous manipulation has progressed substantially recently, challenges like in-hand occlusion still necessitate fine-grained tactile perception, leading to the integration of more tactile sensors into robotic hands. Consequently, the increased data volume imposes substantial bandwidth pressure on signal transmission from the hand's controller. However, the acquisition and compression of multi-point tactile signals based on the dexterous hands' physical structures have not been thoroughly explored. In this paper, our contributions are twofold. First, we introduce a Multi-Point Tactile Dataset for Dexterous Hand Grasping (Dex-MPTD). This dataset captures tactile signals from multiple contact sensors across various objects and grasping poses, offering a comprehensive benchmark for advancing dexterous robotic manipulation research. Second, we investigate both lossless and lossy compression on Dex-MPTD by converting tactile data into images and applying six lossless and five lossy image codecs for efficient compression. Experimental results demonstrate that tactile data can be losslessly compressed to as low as 0.0364 bits per sub-sample (bpss), achieving approximately 200$\\times$ compression ratio compared to the raw tactile data. Efficient lossy compressors like HM and VTM can achieve about 1000x data reductions while preserving acceptable data fidelity. The exploration of lossy compression also reveals that screen-content-targeted coding tools outperform general-purpose codecs in compressing tactile data.","authors":["Yang Li","Yan Zhao","Zhengxue Cheng","Hengdi Zhang"],"url":"https://arxiv.org/abs/2505.16289"}
{"created":"2025-05-23","title":"Multimodal Generative AI for Story Point Estimation in Software Development","abstract":"This research explores the application of Multimodal Generative AI to enhance story point estimation in Agile software development. By integrating text, image, and categorical data using advanced models like BERT, CNN, and XGBoost, our approach surpasses the limitations of traditional single-modal estimation methods. The results demonstrate strong accuracy for simpler story points, while also highlighting challenges in more complex categories due to data imbalance. This study further explores the impact of categorical data, particularly severity, on the estimation process, emphasizing its influence on model performance. Our findings emphasize the transformative potential of multimodal data integration in refining AI-driven project management, paving the way for more precise, adaptable, and domain-specific AI capabilities. Additionally, this work outlines future directions for addressing data variability and enhancing the robustness of AI in Agile methodologies.","authors":["Mohammad Rubyet Islam","Peter Sandborn"],"url":"https://arxiv.org/abs/2505.16290"}
{"created":"2025-05-23","title":"Fairness under Competition","abstract":"Algorithmic fairness has emerged as a central issue in ML, and it has become standard practice to adjust ML algorithms so that they will satisfy fairness requirements such as Equal Opportunity. In this paper we consider the effects of adopting such fair classifiers on the overall level of ecosystem fairness. Specifically, we introduce the study of fairness with competing firms, and demonstrate the failure of fair classifiers in yielding fair ecosystems. Our results quantify the loss of fairness in systems, under a variety of conditions, based on classifiers' correlation and the level of their data overlap. We show that even if competing classifiers are individually fair, the ecosystem's outcome may be unfair; and that adjusting biased algorithms to improve their individual fairness may lead to an overall decline in ecosystem fairness. In addition to these theoretical results, we also provide supporting experimental evidence. Together, our model and results provide a novel and essential call for action.","authors":["Ronen Gradwohl","Eilam Shapira","Moshe Tennenholtz"],"url":"https://arxiv.org/abs/2505.16291"}
{"created":"2025-05-23","title":"Augmenting LLM Reasoning with Dynamic Notes Writing for Complex QA","abstract":"Iterative RAG for multi-hop question answering faces challenges with lengthy contexts and the buildup of irrelevant information. This hinders a model's capacity to process and reason over retrieved content and limits performance. While recent methods focus on compressing retrieved information, they are either restricted to single-round RAG, require finetuning or lack scalability in iterative RAG. To address these challenges, we propose Notes Writing, a method that generates concise and relevant notes from retrieved documents at each step, thereby reducing noise and retaining only essential information. This indirectly increases the effective context length of Large Language Models (LLMs), enabling them to reason and plan more effectively while processing larger volumes of input text. Notes Writing is framework agnostic and can be integrated with different iterative RAG methods. We demonstrate its effectiveness with three iterative RAG methods, across two models and four evaluation datasets. Notes writing yields an average improvement of 15.6 percentage points overall, with minimal increase in output tokens.","authors":["Rishabh Maheshwary","Masoud Hashemi","Khyati Mahajan","Shiva Krishna Reddy Malay","Sai Rajeswar","Sathwik Tejaswi Madhusudhan","Spandana Gella","Vikas Yadav"],"url":"https://arxiv.org/abs/2505.16293"}
{"created":"2025-05-23","title":"Self-Classification Enhancement and Correction for Weakly Supervised Object Detection","abstract":"In recent years, weakly supervised object detection (WSOD) has attracted much attention due to its low labeling cost. The success of recent WSOD models is often ascribed to the two-stage multi-class classification (MCC) task, i.e., multiple instance learning and online classification refinement. Despite achieving non-trivial progresses, these methods overlook potential classification ambiguities between these two MCC tasks and fail to leverage their unique strengths. In this work, we introduce a novel WSOD framework to ameliorate these two issues. For one thing, we propose a self-classification enhancement module that integrates intra-class binary classification (ICBC) to bridge the gap between the two distinct MCC tasks. The ICBC task enhances the network's discrimination between positive and mis-located samples in a class-wise manner and forges a mutually reinforcing relationship with the MCC task. For another, we propose a self-classification correction algorithm during inference, which combines the results of both MCC tasks to effectively reduce the mis-classified predictions. Extensive experiments on the prevalent VOC 2007 & 2012 datasets demonstrate the superior performance of our framework.","authors":["Yufei Yin","Lechao Cheng","Wengang Zhou","Jiajun Deng","Zhou Yu","Houqiang Li"],"url":"https://arxiv.org/abs/2505.16294"}
{"created":"2025-05-23","title":"A finite element solver for a thermodynamically consistent electrolyte model","abstract":"In this study, we present a finite element solver for a thermodynamically consistent electrolyte model that accurately captures multicomponent ionic transport by incorporating key physical phenomena such as steric effects, solvation, and pressure coupling. The model is rooted in the principles of non-equilibrium thermodynamics and strictly enforces mass conservation, charge neutrality, and entropy production. It extends beyond classical frameworks like the Nernst-Planck system by employing modified partial mass balances, the electrostatic Poisson equation, and a momentum balance expressed in terms of electrostatic potential, atomic fractions, and pressure, thereby enhancing numerical stability and physical consistency. Implemented using the FEniCSx platform, the solver efficiently handles one- and two-dimensional problems with varied boundary conditions and demonstrates excellent convergence behavior and robustness. Validation against benchmark problems confirms its improved physical fidelity, particularly in regimes characterized by high ionic concentrations and strong electrochemical gradients. Simulation results reveal critical electrolyte phenomena, including electric double layer formation, rectification behavior, and the effects of solvation number, Debye length, and compressibility. The solver's modular variational formulation facilitates its extension to complex electrochemical systems involving multiple ionic species with asymmetric valences.","authors":["Jan Habscheid","Satyvir Singh","Lambert Theisen","Stefanie Braun","Manuel Torrilhon"],"url":"https://arxiv.org/abs/2505.16296"}
{"created":"2025-05-23","title":"ToDi: Token-wise Distillation via Fine-Grained Divergence Control","abstract":"Large language models (LLMs) offer impressive performance but are impractical for resource-constrained deployment due to high latency and energy consumption. Knowledge distillation (KD) addresses this by transferring knowledge from a large teacher to a smaller student model. However, conventional KD, notably approaches like Forward KL (FKL) and Reverse KL (RKL), apply uniform divergence loss across the entire vocabulary, neglecting token-level prediction discrepancies. By investigating these representative divergences via gradient analysis, we reveal that FKL boosts underestimated tokens, while RKL suppresses overestimated ones, showing their complementary roles. Based on this observation, we propose Token-wise Distillation (ToDi), a novel method that adaptively combines FKL and RKL per token using a sigmoid-based weighting function derived from the teacher-student probability log-ratio. ToDi dynamically emphasizes the appropriate divergence for each token, enabling precise distribution alignment. We demonstrate that ToDi consistently outperforms recent distillation baselines using uniform or less granular strategies across instruction-following benchmarks. Extensive ablation studies and efficiency analysis further validate ToDi's effectiveness and practicality.","authors":["Seongryong Jung","Suwan Yoon","DongGeon Kim","Hwanhee Lee"],"url":"https://arxiv.org/abs/2505.16297"}
{"created":"2025-05-23","title":"Flow Matching based Sequential Recommender Model","abstract":"Generative models, particularly diffusion model, have emerged as powerful tools for sequential recommendation. However, accurately modeling user preferences remains challenging due to the noise perturbations inherent in the forward and reverse processes of diffusion-based methods. Towards this end, this study introduces FMRec, a Flow Matching based model that employs a straight flow trajectory and a modified loss tailored for the recommendation task. Additionally, from the diffusion-model perspective, we integrate a reconstruction loss to improve robustness against noise perturbations, thereby retaining user preferences during the forward process. In the reverse process, we employ a deterministic reverse sampler, specifically an ODE-based updating function, to eliminate unnecessary randomness, thereby ensuring that the generated recommendations closely align with user needs. Extensive evaluations on four benchmark datasets reveal that FMRec achieves an average improvement of 6.53% over state-of-the-art methods. The replication code is available at https://github.com/FengLiu-1/FMRec.","authors":["Feng Liu","Lixin Zou","Xiangyu Zhao","Min Tang","Liming Dong","Dan Luo","Xiangyang Luo","Chenliang Li"],"url":"https://arxiv.org/abs/2505.16298"}
{"created":"2025-05-23","title":"Poster: Towards an Automated Security Testing Framework for Industrial UEs","abstract":"With the ongoing adoption of 5G for communication in industrial systems and critical infrastructure, the security of industrial UEs such as 5G-enabled industrial robots becomes an increasingly important topic. Most notably, to meet the stringent security requirements of industrial deployments, industrial UEs not only have to fully comply with the 5G specifications but also implement and use correctly secure communication protocols such as TLS. To ensure the security of industrial UEs, operators of industrial 5G networks rely on security testing before deploying new devices to their production networks. However, currently only isolated tests for individual security aspects of industrial UEs exist, severely hindering comprehensive testing. In this paper, we report on our ongoing efforts to alleviate this situation by creating an automated security testing framework for industrial UEs to comprehensively evaluate their security posture before deployment. With this framework, we aim to provide stakeholders with a fully automated-method to verify that higher-layer security protocols are correctly implemented, while simultaneously ensuring that the UE's protocol stack adheres to 3GPP specifications.","authors":["Sotiris Michaelides","Daniel Eguiguren Chavez","Martin Henze"],"url":"https://arxiv.org/abs/2505.16300"}
{"created":"2025-05-23","title":"INFERENCEDYNAMICS: Efficient Routing Across LLMs through Structured Capability and Knowledge Profiling","abstract":"Large Language Model (LLM) routing is a pivotal technique for navigating a diverse landscape of LLMs, aiming to select the best-performing LLMs tailored to the domains of user queries, while managing computational resources. However, current routing approaches often face limitations in scalability when dealing with a large pool of specialized LLMs, or in their adaptability to extending model scope and evolving capability domains. To overcome those challenges, we propose InferenceDynamics, a flexible and scalable multi-dimensional routing framework by modeling the capability and knowledge of models. We operate it on our comprehensive dataset RouteMix, and demonstrate its effectiveness and generalizability in group-level routing using modern benchmarks including MMLU-Pro, GPQA, BigGenBench, and LiveBench, showcasing its ability to identify and leverage top-performing models for given tasks, leading to superior outcomes with efficient resource utilization. The broader adoption of Inference Dynamics can empower users to harness the full specialized potential of the LLM ecosystem, and our code will be made publicly available to encourage further research.","authors":["Haochen Shi","Tianshi Zheng","Weiqi Wang","Baixuan Xu","Chunyang Li","Chunkit Chan","Tao Fan","Yangqiu Song","Qiang Yang"],"url":"https://arxiv.org/abs/2505.16303"}
{"created":"2025-05-23","title":"SAMba-UNet: Synergizing SAM2 and Mamba in UNet with Heterogeneous Aggregation for Cardiac MRI Segmentation","abstract":"To address the challenge of complex pathological feature extraction in automated cardiac MRI segmentation, this study proposes an innovative dual-encoder architecture named SAMba-UNet. The framework achieves cross-modal feature collaborative learning by integrating the vision foundation model SAM2, the state-space model Mamba, and the classical UNet. To mitigate domain discrepancies between medical and natural images, a Dynamic Feature Fusion Refiner is designed, which enhances small lesion feature extraction through multi-scale pooling and a dual-path calibration mechanism across channel and spatial dimensions. Furthermore, a Heterogeneous Omni-Attention Convergence Module (HOACM) is introduced, combining global contextual attention with branch-selective emphasis mechanisms to effectively fuse SAM2's local positional semantics and Mamba's long-range dependency modeling capabilities. Experiments on the ACDC cardiac MRI dataset demonstrate that the proposed model achieves a Dice coefficient of 0.9103 and an HD95 boundary error of 1.0859 mm, significantly outperforming existing methods, particularly in boundary localization for complex pathological structures such as right ventricular anomalies. This work provides an efficient and reliable solution for automated cardiac disease diagnosis, and the code will be open-sourced.","authors":["Guohao Huo","Ruiting Dai","Hao Tang"],"url":"https://arxiv.org/abs/2505.16304"}
{"created":"2025-05-23","title":"Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution","abstract":"Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for tensor reconstruction. Although the Bayesian framework allows for principled uncertainty quantification and automatic hyperparameter learning, existing methods do not scale well for large tensors because of high-dimensional matrix inversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD algorithm. This algorithm leverages generalized approximate message passing (GAMP) to avoid matrix inversions and incorporates an expectation-maximization routine to jointly infer the tensor rank and noise power. Through multiple experiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements observed, the proposed algorithm reduces runtime by 82.7% compared to the state-of-the-art variational Bayesian CPD method, while maintaining comparable reconstruction accuracy.","authors":["Bingyang Cheng","Zhongtao Chen","Yichen Jin","Hao Zhang","Chen Zhang","Edmud Y. Lam","Yik-Chung Wu"],"url":"https://arxiv.org/abs/2505.16305"}
{"created":"2025-05-23","title":"Layer-wise Investigation of Large-Scale Self-Supervised Music Representation Models","abstract":"Recently, pre-trained models for music information retrieval based on self-supervised learning (SSL) are becoming popular, showing success in various downstream tasks. However, there is limited research on the specific meanings of the encoded information and their applicability. Exploring these aspects can help us better understand their capabilities and limitations, leading to more effective use in downstream tasks.","authors":["Yizhi Zhou","Haina Zhu","Hangting Chen"],"url":"https://arxiv.org/abs/2505.16306"}
{"created":"2025-05-23","title":"PMPO: Probabilistic Metric Prompt Optimization for Small and Large Language Models","abstract":"Prompt optimization offers a practical and broadly applicable alternative to fine-tuning for improving large language model (LLM) performance. However, existing methods often rely on costly output generation, self-critiquing abilities, or human-annotated preferences, which limit their scalability, especially for smaller or non-instruction-tuned models. We introduce PMPO (Probabilistic Metric Prompt Optimization), a unified framework that refines prompts using token-level cross-entropy loss as a direct, lightweight evaluation signal. PMPO identifies low-quality prompt segments by masking and measuring their impact on loss, then rewrites and selects improved variants by minimizing loss over positive and negative examples. Unlike prior methods, it requires no output sampling or human evaluation during optimization, relying only on forward passes and log-likelihoods. PMPO supports both supervised and preference-based tasks through a closely aligned loss-based evaluation strategy. Experiments show that PMPO consistently outperforms prior methods across model sizes and tasks: it achieves the highest average accuracy on BBH, performs strongly on GSM8K and AQUA-RAT, and improves AlpacaEval 2.0 win rates by over 19 points. These results highlight PMPO's effectiveness, efficiency, and broad applicability.","authors":["Chenzhuo Zhao","Ziqian Liu","Xingda Wang","Junting Lu","Chaoyi Ruan"],"url":"https://arxiv.org/abs/2505.16307"}
{"created":"2025-05-23","title":"CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting","abstract":"Most existing multivariate time series forecasting methods adopt an all-to-all paradigm that feeds all variable histories into a unified model to predict their future values without distinguishing their individual roles. However, this undifferentiated paradigm makes it difficult to identify variable-specific causal influences and often entangles causally relevant information with spurious correlations. To address this limitation, we propose an all-to-one forecasting paradigm that predicts each target variable separately. Specifically, we first construct a Structural Causal Model from observational data and then, for each target variable, we partition the historical sequence into four sub-segments according to the inferred causal structure: endogenous, direct causal, collider causal, and spurious correlation. The prediction relies solely on the first three causally relevant sub-segments, while the spurious correlation sub-segment is excluded. Furthermore, we propose Causal Informed Transformer (CAIFormer), a novel forecasting model comprising three components: Endogenous Sub-segment Prediction Block, Direct Causal Sub-segment Prediction Block, and Collider Causal Sub-segment Prediction Block, which process the endogenous, direct causal, and collider causal sub-segments, respectively. Their outputs are then combined to produce the final prediction. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of the CAIFormer.","authors":["Xingyu Zhang","Wenwen Qiang","Siyu Zhao","Huijie Guo","Jiangmeng Li","Chuxiong Sun","Changwen Zheng"],"url":"https://arxiv.org/abs/2505.16308"}
{"created":"2025-05-23","title":"Paired and Unpaired Image to Image Translation using Generative Adversarial Networks","abstract":"Image to image translation is an active area of research in the field of computer vision, enabling the generation of new images with different styles, textures, or resolutions while preserving their characteristic properties. Recent architectures leverage Generative Adversarial Networks (GANs) to transform input images from one domain to another. In this work, we focus on the study of both paired and unpaired image translation across multiple image domains. For the paired task, we used a conditional GAN model, and for the unpaired task, we trained it using cycle consistency loss. We experimented with different types of loss functions, multiple Patch-GAN sizes, and model architectures. New quantitative metrics - precision, recall, and FID score - were used for analysis. In addition, a qualitative study of the results of different experiments was conducted.","authors":["Gaurav Kumar","Soham Satyadharma","Harpreet Singh"],"url":"https://arxiv.org/abs/2505.16310"}
{"created":"2025-05-23","title":"EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning","abstract":"Large Language Models (LLMs) excel at complex reasoning through search algorithms, yet current strategies often suffer from massive token consumption due to redundant exploration of semantically equivalent steps. Existing semantic similarity methods struggle to accurately identify such equivalence in domain-specific contexts like mathematical reasoning. To address this, we propose EquivPruner, a simple yet effective approach that identifies and prunes semantically equivalent actions during LLM reasoning search. We also introduce MathEquiv, the first dataset we created for mathematical statement equivalence, which enables the training of a lightweight equivalence detector. Extensive experiments across various models and tasks demonstrate that EquivPruner significantly reduces token consumption, improving searching efficiency and often bolstering reasoning accuracy. For instance, when applied to Qwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by 48.1\\% while also improving accuracy. Our code is available at https://github.com/Lolo1222/EquivPruner.","authors":["Jiawei Liu","Qisi Chen","Jianshu Zhang","Quan Liu","Defu Lian"],"url":"https://arxiv.org/abs/2505.16312"}
{"created":"2025-05-23","title":"Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings","abstract":"Deep neural networks for image classification remain vulnerable to adversarial examples -- small, imperceptible perturbations that induce misclassifications. In black-box settings, where only the final prediction is accessible, crafting targeted attacks that aim to misclassify into a specific target class is particularly challenging due to narrow decision regions. Current state-of-the-art methods often exploit the geometric properties of the decision boundary separating a source image and a target image rather than incorporating information from the images themselves. In contrast, we propose Targeted Edge-informed Attack (TEA), a novel attack that utilizes edge information from the target image to carefully perturb it, thereby producing an adversarial image that is closer to the source image while still achieving the desired target classification. Our approach consistently outperforms current state-of-the-art methods across different models in low query settings (nearly 70\\% fewer queries are used), a scenario especially relevant in real-world applications with limited queries and black-box access. Furthermore, by efficiently generating a suitable adversarial example, TEA provides an improved target initialization for established geometry-based attacks.","authors":["Arjhun Swaminathan","Mete Akg\\\"un"],"url":"https://arxiv.org/abs/2505.16313"}
{"created":"2025-05-23","title":"NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment","abstract":"This paper reports on the NTIRE 2025 challenge on Text to Image (T2I) generation model quality assessment, which will be held in conjunction with the New Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2025. The aim of this challenge is to address the fine-grained quality assessment of text-to-image generation models. This challenge evaluates text-to-image models from two aspects: image-text alignment and image structural distortion detection, and is divided into the alignment track and the structural track. The alignment track uses the EvalMuse-40K, which contains around 40K AI-Generated Images (AIGIs) generated by 20 popular generative models. The alignment track has a total of 371 registered participants. A total of 1,883 submissions are received in the development phase, and 507 submissions are received in the test phase. Finally, 12 participating teams submitted their models and fact sheets. The structure track uses the EvalMuse-Structure, which contains 10,000 AI-Generated Images (AIGIs) with corresponding structural distortion mask. A total of 211 participants have registered in the structure track. A total of 1155 submissions are received in the development phase, and 487 submissions are received in the test phase. Finally, 8 participating teams submitted their models and fact sheets. Almost all methods have achieved better results than baseline methods, and the winning methods in both tracks have demonstrated superior prediction performance on T2I model quality assessment.","authors":["Shuhao Han","Haotian Fan","Fangyuan Kong","Wenjie Liao","Chunle Guo","Chongyi Li","Radu Timofte","Liang Li","Tao Li","Junhui Cui","Yunqiu Wang","Yang Tai","Jingwei Sun","Jianhui Sun","Xinli Yue","Tianyi Wang","Huan Hou","Junda Lu","Xinyang Huang","Zitang Zhou","Zijian Zhang","Xuhui Zheng","Xuecheng Wu","Chong Peng","Xuezhi Cao","Trong-Hieu Nguyen-Mau","Minh-Hoang Le","Minh-Khoa Le-Phan","Duy-Nam Ly","Hai-Dang Nguyen","Minh-Triet Tran","Yukang Lin","Yan Hong","Chuanbiao Song","Siyuan Li","Jun Lan","Zhichao Zhang","Xinyue Li","Wei Sun","Zicheng Zhang","Yunhao Li","Xiaohong Liu","Guangtao Zhai","Zitong Xu","Huiyu Duan","Jiarui Wang","Guangji Ma","Liu Yang","Lu Liu","Qiang Hu","Xiongkuo Min","Zichuan Wang","Zhenchen Tang","Bo Peng","Jing Dong","Fengbin Guan","Zihao Yu","Yiting Lu","Wei Luo","Xin Li","Minhao Lin","Haofeng Chen","Xuanxuan He","Kele Xu","Qisheng Xu","Zijian Gao","Tianjiao Wan","Bo-Cheng Qiu","Chih-Chung Hsu","Chia-ming Lee","Yu-Fan Lin","Bo Yu","Zehao Wang","Da Mu","Mingxiu Chen","Junkang Fang","Huamei Sun","Wending Zhao","Zhiyu Wang","Wang Liu","Weikang Yu","Puhong Duan","Bin Sun","Xudong Kang","Shutao Li","Shuai He","Lingzhi Fu","Heng Cong","Rongyu Zhang","Jiarong He","Zhishan Qiao","Yongqing Huang","Zewen Chen","Zhe Pang","Juan Wang","Jian Guo","Zhizhuo Shao","Ziyu Feng","Bing Li","Weiming Hu","Hesong Li","Dehua Liu","Zeming Liu","Qingsong Xie","Ruichen Wang","Zhihao Li","Yuqi Liang","Jianqi Bi","Jun Luo","Junfeng Yang","Can Li","Jing Fu","Hongwei Xu","Mingrui Long","Lulin Tang"],"url":"https://arxiv.org/abs/2505.16314"}
{"created":"2025-05-23","title":"Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning","abstract":"Large reasoning models (LRMs) have demonstrated strong performance on complex reasoning tasks, but often suffer from overthinking, generating redundant content regardless of task difficulty. Inspired by the dual process theory in cognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a reinforcement learning framework that enables LRMs to achieve efficient reasoning through adaptive cognitive allocation and dynamic system switch. ACPO incorporates two key components: (1) introducing system-aware reasoning tokens to explicitly represent the thinking modes thereby making the model's cognitive process transparent, and (2) integrating online difficulty estimation and token length budget to guide adaptive system switch and reasoning during reinforcement learning. To this end, we propose a two-stage training strategy. The first stage begins with supervised fine-tuning to cold start the model, enabling it to generate reasoning paths with explicit thinking modes. In the second stage, we apply ACPO to further enhance adaptive system switch for difficulty-aware reasoning. Experimental results demonstrate that ACPO effectively reduces redundant reasoning while adaptively adjusting cognitive allocation based on task complexity, achieving efficient hybrid reasoning.","authors":["Xiaoxue Cheng","Junyi Li","Zhenduo Zhang","Xinyu Tang","Wayne Xin Zhao","Xinyu Kong","Zhiqiang Zhang"],"url":"https://arxiv.org/abs/2505.16315"}
{"created":"2025-05-23","title":"SuperPure: Efficient Purification of Localized and Distributed Adversarial Patches via Super-Resolution GAN Models","abstract":"As vision-based machine learning models are increasingly integrated into autonomous and cyber-physical systems, concerns about (physical) adversarial patch attacks are growing. While state-of-the-art defenses can achieve certified robustness with minimal impact on utility against highly-concentrated localized patch attacks, they fall short in two important areas: (i) State-of-the-art methods are vulnerable to low-noise distributed patches where perturbations are subtly dispersed to evade detection or masking, as shown recently by the DorPatch attack; (ii) Achieving high robustness with state-of-the-art methods is extremely time and resource-consuming, rendering them impractical for latency-sensitive applications in many cyber-physical systems.","authors":["Hossein Khalili","Seongbin Park","Venkat Bollapragada","Nader Sehatbakhsh"],"url":"https://arxiv.org/abs/2505.16318"}
{"created":"2025-05-23","title":"FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail","abstract":"Accurate demand estimation is critical for the retail business in guiding the inventory and pricing policies of perishable products. However, it faces fundamental challenges from censored sales data during stockouts, where unobserved demand creates systemic policy biases. Existing datasets lack the temporal resolution and annotations needed to address this censoring effect. To fill this gap, we present FreshRetailNet-50K, the first large-scale benchmark for censored demand estimation. It comprises 50,000 store-product time series of detailed hourly sales data from 898 stores in 18 major cities, encompassing 863 perishable SKUs meticulously annotated for stockout events. The hourly stock status records unique to this dataset, combined with rich contextual covariates, including promotional discounts, precipitation, and temporal features, enable innovative research beyond existing solutions. We demonstrate one such use case of two-stage demand modeling: first, we reconstruct the latent demand during stockouts using precise hourly annotations. We then leverage the recovered demand to train robust demand forecasting models in the second stage. Experimental results show that this approach achieves a 2.73\\% improvement in prediction accuracy while reducing the systematic demand underestimation from 7.37\\% to near-zero bias. With unprecedented temporal granularity and comprehensive real-world information, FreshRetailNet-50K opens new research directions in demand imputation, perishable inventory optimization, and causal retail analytics. The unique annotation quality and scale of the dataset address long-standing limitations in retail AI, providing immediate solutions and a platform for future methodological innovation. The data (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code (https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.","authors":["Yangyang Wang","Jiawei Gu","Li Long","Xin Li","Li Shen","Zhouyu Fu","Xiangjun Zhou","Xu Jiang"],"url":"https://arxiv.org/abs/2505.16319"}
{"created":"2025-05-23","title":"Efficient Motion Prompt Learning for Robust Visual Tracking","abstract":"Due to the challenges of processing temporal information, most trackers depend solely on visual discriminability and overlook the unique temporal coherence of video data. In this paper, we propose a lightweight and plug-and-play motion prompt tracking method. It can be easily integrated into existing vision-based trackers to build a joint tracking framework leveraging both motion and vision cues, thereby achieving robust tracking through efficient prompt learning. A motion encoder with three different positional encodings is proposed to encode the long-term motion trajectory into the visual embedding space, while a fusion decoder and an adaptive weight mechanism are designed to dynamically fuse visual and motion features. We integrate our motion module into three different trackers with five models in total. Experiments on seven challenging tracking benchmarks demonstrate that the proposed motion module significantly improves the robustness of vision-based trackers, with minimal training costs and negligible speed sacrifice. Code is available at https://github.com/zj5559/Motion-Prompt-Tracking.","authors":["Jie Zhao","Xin Chen","Yongsheng Yuan","Michael Felsberg","Dong Wang","Huchuan Lu"],"url":"https://arxiv.org/abs/2505.16321"}
{"created":"2025-05-23","title":"AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners","abstract":"Self-Taught Reasoners (STaR), synonymously known as Rejection sampling Fine-Tuning (RFT), is an integral part of the training pipeline of self-improving reasoning Language Models (LMs). The self-improving mechanism often employs random observation (data) sampling. However, this results in trained observation imbalance; inefficiently over-training on solved examples while under-training on challenging ones. In response, we introduce Adaptive STaR (AdaSTaR), a novel algorithm that rectifies this by integrating two adaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting balanced training across observations, and (2) Adaptive Sampling for Curriculum: dynamically adjusting data difficulty to match the model's evolving strength. Across six benchmarks, AdaSTaR achieves best test accuracy in all instances (6/6) and reduces training FLOPs by an average of 58.6% against an extensive list of baselines. These improvements in performance and efficiency generalize to different pre-trained LMs and larger models, paving the way for more efficient and effective self-improving LMs.","authors":["Woosung Koh","Wonbeen Oh","Jaein Jang","MinHyung Lee","Hyeongjin Kim","Ah Yeon Kim","Joonkee Kim","Junghyun Lee","Taehyeon Kim","Se-Young Yun"],"url":"https://arxiv.org/abs/2505.16322"}
{"created":"2025-05-23","title":"TensorAR: Refinement is All You Need in Autoregressive Image Generation","abstract":"Autoregressive (AR) image generators offer a language-model-friendly approach to image generation by predicting discrete image tokens in a causal sequence. However, unlike diffusion models, AR models lack a mechanism to refine previous predictions, limiting their generation quality. In this paper, we introduce TensorAR, a new AR paradigm that reformulates image generation from next-token prediction to next-tensor prediction. By generating overlapping windows of image patches (tensors) in a sliding fashion, TensorAR enables iterative refinement of previously generated content. To prevent information leakage during training, we propose a discrete tensor noising scheme, which perturbs input tokens via codebook-indexed noise. TensorAR is implemented as a plug-and-play module compatible with existing AR models. Extensive experiments on LlamaGEN, Open-MAGVIT2, and RAR demonstrate that TensorAR significantly improves the generation performance of autoregressive models.","authors":["Cheng Cheng","Lin Song","Yicheng Xiao","Yuxin Chen","Xuchong Zhang","Hongbin Sun","Ying Shan"],"url":"https://arxiv.org/abs/2505.16324"}
{"created":"2025-05-23","title":"CLEAR: A Clinically-Grounded Tabular Framework for Radiology Report Evaluation","abstract":"Existing metrics often lack the granularity and interpretability to capture nuanced clinical differences between candidate and ground-truth radiology reports, resulting in suboptimal evaluation. We introduce a Clinically-grounded tabular framework with Expert-curated labels and Attribute-level comparison for Radiology report evaluation (CLEAR). CLEAR not only examines whether a report can accurately identify the presence or absence of medical conditions, but also assesses whether it can precisely describe each positively identified condition across five key attributes: first occurrence, change, severity, descriptive location, and recommendation. Compared to prior works, CLEAR's multi-dimensional, attribute-level outputs enable a more comprehensive and clinically interpretable evaluation of report quality. Additionally, to measure the clinical alignment of CLEAR, we collaborate with five board-certified radiologists to develop CLEAR-Bench, a dataset of 100 chest X-ray reports from MIMIC-CXR, annotated across 6 curated attributes and 13 CheXpert conditions. Our experiments show that CLEAR achieves high accuracy in extracting clinical attributes and provides automated metrics that are strongly aligned with clinical judgment.","authors":["Yuyang Jiang","Chacha Chen","Shengyuan Wang","Feng Li","Zecong Tang","Benjamin M. Mervak","Lydia Chelala","Christopher M Straus","Reve Chahine","Samuel G. Armato III","Chenhao Tan"],"url":"https://arxiv.org/abs/2505.16325"}
{"created":"2025-05-23","title":"ChemMLLM: Chemical Multimodal Large Language Model","abstract":"Multimodal large language models (MLLMs) have made impressive progress in many applications in recent years. However, chemical MLLMs that can handle cross-modal understanding and generation remain underexplored. To fill this gap, in this paper, we propose ChemMLLM, a unified chemical multimodal large language model for molecule understanding and generation. Also, we design five multimodal tasks across text, molecular SMILES strings, and image, and curate the datasets. We benchmark ChemMLLM against a range of general leading MLLMs and Chemical LLMs on these tasks. Experimental results show that ChemMLLM achieves superior performance across all evaluated tasks. For example, in molecule image optimization task, ChemMLLM outperforms the best baseline (GPT-4o) by 118.9\\% (4.27 vs 1.95 property improvement). The code is publicly available at https://github.com/bbsbz/ChemMLLM.git.","authors":["Qian Tan","Dongzhan Zhou","Peng Xia","Wanhao Liu","Wanli Ouyang","Lei Bai","Yuqiang Li","Tianfan Fu"],"url":"https://arxiv.org/abs/2505.16326"}
{"created":"2025-05-23","title":"Cooperative NOMA Meets Emerging Technologies: A Survey for Next-Generation Wireless Networks","abstract":"The emerging demands of sixth-generation wireless networks, such as ultra-connectivity, native intelligence, and cross-domain convergence, are bringing renewed focus to cooperative non-orthogonal multiple access (C-NOMA) as a fundamental enabler of scalable, efficient, and intelligent communication systems. C-NOMA builds on the core benefits of NOMA by leveraging user cooperation and relay strategies to enhance spectral efficiency, coverage, and energy performance. This article presents a unified and forward-looking survey on the integration of C-NOMA with key enabling technologies, including radio frequency energy harvesting, cognitive radio networks, reconfigurable intelligent surfaces, space-air-ground integrated networks, and integrated sensing and communication-assisted semantic communication. Foundational principles and relaying protocols are first introduced to establish the technical relevance of C-NOMA. Then, a focused investigation is conducted into protocol-level synergies, architectural models, and deployment strategies across these technologies. Beyond integration, this article emphasizes the orchestration of C-NOMA across future application domains such as digital twins, extended reality, and e-health. In addition, it provides an extensive and in-depth review of recent literature, categorized by relaying schemes, system models, performance metrics, and optimization paradigms, including model-based, heuristic, and AI-driven approaches. Finally, open challenges and future research directions are outlined, spanning standardization, security, and cross-layer design, positioning C-NOMA as a key pillar of intelligent next-generation network architectures.","authors":["Mahmoud M. Salim","Suhail I. Al-Dharrab","Daniel Benevides Da Costa","Ali H. Muqaibel"],"url":"https://arxiv.org/abs/2505.16327"}
{"created":"2025-05-23","title":"SC4ANM: Identifying Optimal Section Combinations for Automated Novelty Prediction in Academic Papers","abstract":"Novelty is a core component of academic papers, and there are multiple perspectives on the assessment of novelty. Existing methods often focus on word or entity combinations, which provide limited insights. The content related to a paper's novelty is typically distributed across different core sections, e.g., Introduction, Methodology and Results. Therefore, exploring the optimal combination of sections for evaluating the novelty of a paper is important for advancing automated novelty assessment. In this paper, we utilize different combinations of sections from academic papers as inputs to drive language models to predict novelty scores. We then analyze the results to determine the optimal section combinations for novelty score prediction. We first employ natural language processing techniques to identify the sectional structure of academic papers, categorizing them into introduction, methods, results, and discussion (IMRaD). Subsequently, we used different combinations of these sections (e.g., introduction and methods) as inputs for pretrained language models (PLMs) and large language models (LLMs), employing novelty scores provided by human expert reviewers as ground truth labels to obtain prediction results. The results indicate that using introduction, results and discussion is most appropriate for assessing the novelty of a paper, while the use of the entire text does not yield significant results. Furthermore, based on the results of the PLMs and LLMs, the introduction and results appear to be the most important section for the task of novelty score prediction. The code and dataset for this paper can be accessed at https://github.com/njust-winchy/SC4ANM.","authors":["Wenqing Wu","Chengzhi Zhang","Tong Bao","Yi Zhao"],"url":"https://arxiv.org/abs/2505.16330"}
{"created":"2025-05-23","title":"Understanding Differential Transformer Unchains Pretrained Self-Attentions","abstract":"Differential Transformer has recently gained significant attention for its impressive empirical performance, often attributed to its ability to perform noise canceled attention. However, precisely how differential attention achieves its empirical benefits remains poorly understood. Moreover, Differential Transformer architecture demands large-scale training from scratch, hindering utilization of open pretrained weights. In this work, we conduct an in-depth investigation of Differential Transformer, uncovering three key factors behind its success: (1) enhanced expressivity via negative attention, (2) reduced redundancy among attention heads, and (3) improved learning dynamics. Based on these findings, we propose DEX, a novel method to efficiently integrate the advantages of differential attention into pretrained language models. By reusing the softmax attention scores and adding a lightweight differential operation on the output value matrix, DEX effectively incorporates the key advantages of differential attention while remaining lightweight in both training and inference. Evaluations confirm that DEX substantially improves the pretrained LLMs across diverse benchmarks, achieving significant performance gains with minimal adaptation data (< 0.01\\%).","authors":["Chaerin Kong","Jiho Jang","Nojun Kwak"],"url":"https://arxiv.org/abs/2505.16333"}
{"created":"2025-05-23","title":"Panoptic Captioning: Seeking An Equivalency Bridge for Image and Text","abstract":"This work introduces panoptic captioning, a novel task striving to seek the minimum text equivalence of images. We take the first step towards panoptic captioning by formulating it as a task of generating a comprehensive textual description for an image, which encapsulates all entities, their respective locations and attributes, relationships among entities, as well as global image state.Through an extensive evaluation, our work reveals that state-of-the-art Multi-modal Large Language Models (MLLMs) have limited performance in solving panoptic captioning. To address this, we propose an effective data engine named PancapEngine to produce high-quality data and a novel method named PancapChain to improve panoptic captioning. Specifically, our PancapEngine first detects diverse categories of entities in images by an elaborate detection suite, and then generates required panoptic captions using entity-aware prompts. Additionally, our PancapChain explicitly decouples the challenging panoptic captioning task into multiple stages and generates panoptic captions step by step. More importantly, we contribute a comprehensive metric named PancapScore and a human-curated test set for reliable model evaluation.Experiments show that our PancapChain-13B model can beat state-of-the-art open-source MLLMs like InternVL-2.5-78B and even surpass proprietary models like GPT-4o and Gemini-2.0-Pro, demonstrating the effectiveness of our data engine and method. Project page: https://visual-ai.github.io/pancap/","authors":["Kun-Yu Lin","Hongjun Wang","Weining Ren","Kai Han"],"url":"https://arxiv.org/abs/2505.16334"}
{"created":"2025-05-23","title":"FPQVAR: Floating Point Quantization for Visual Autoregressive Model with FPGA Hardware Co-design","abstract":"Visual autoregressive (VAR) modeling has marked a paradigm shift in image generation from next-token prediction to next-scale prediction. VAR predicts a set of tokens at each step from coarse to fine scale, leading to better image quality and faster inference speed compared to existing diffusion models. However, the large parameter size and computation cost hinder its deployment on edge devices. To reduce the memory and computation cost, we propose FPQVAR, an efficient post-training floating-point (FP) quantization framework for VAR featuring algorithm and hardware co-design. At the algorithm level, we first identify the challenges of quantizing VAR. To address them, we propose Dual Format Quantization for the highly imbalanced input activation. We further propose Group-wise Hadamard Transformation and GHT-Aware Learnable Transformation to address the time-varying outlier channels. At the hardware level, we design the first low-bit FP quantizer and multiplier with lookup tables on FPGA and propose the first FPGA-based VAR accelerator featuring low-bit FP computation and an elaborate two-level pipeline. Extensive experiments show that compared to the state-of-the-art quantization method, our proposed FPQVAR significantly improves Fr\\'echet Inception Distance (FID) from 10.83 to 3.58, Inception Score (IS) from 175.9 to 241.5 under 4-bit quantization. FPQVAR also significantly improves the performance of 6-bit quantized VAR, bringing it on par with the FP16 model. Our accelerator on AMD-Xilinx VCK190 FPGA achieves a throughput of 1.1 image/s, which is 3.1x higher than the integer-based accelerator. It also demonstrates 3.6x and 2.8x higher energy efficiency compared to the integer-based accelerator and GPU baseline, respectively.","authors":["Renjie Wei","Songqiang Xu","Qingyu Guo","Meng Li"],"url":"https://arxiv.org/abs/2505.16335"}
{"created":"2025-05-23","title":"Fusion of Foundation and Vision Transformer Model Features for Dermatoscopic Image Classification","abstract":"Accurate classification of skin lesions from dermatoscopic images is essential for diagnosis and treatment of skin cancer. In this study, we investigate the utility of a dermatology-specific foundation model, PanDerm, in comparison with two Vision Transformer (ViT) architectures (ViT base and Swin Transformer V2 base) for the task of skin lesion classification. Using frozen features extracted from PanDerm, we apply non-linear probing with three different classifiers, namely, multi-layer perceptron (MLP), XGBoost, and TabNet. For the ViT-based models, we perform full fine-tuning to optimize classification performance. Our experiments on the HAM10000 and MSKCC datasets demonstrate that the PanDerm-based MLP model performs comparably to the fine-tuned Swin transformer model, while fusion of PanDerm and Swin Transformer predictions leads to further performance improvements. Future work will explore additional foundation models, fine-tuning strategies, and advanced fusion techniques.","authors":["Amirreza Mahbod","Rupert Ecker","Ramona Woitek"],"url":"https://arxiv.org/abs/2505.16338"}
{"created":"2025-05-23","title":"Rethinking Code Review Workflows with LLM Assistance: An Empirical Study","abstract":"Code reviews are a critical yet time-consuming aspect of modern software development, increasingly challenged by growing system complexity and the demand for faster delivery. This paper presents a study conducted at WirelessCar Sweden AB, combining an exploratory field study of current code review practices with a field experiment involving two variations of an LLM-assisted code review tool. The field study identifies key challenges in traditional code reviews, including frequent context switching, insufficient contextual information, and highlights both opportunities (e.g., automatic summarization of complex pull requests) and concerns (e.g., false positives and trust issues) in using LLMs. In the field experiment, we developed two prototype variations: one offering LLM-generated reviews upfront and the other enabling on-demand interaction. Both utilize a semantic search pipeline based on retrieval-augmented generation to assemble relevant contextual information for the review, thereby tackling the uncovered challenges. Developers evaluated both variations in real-world settings: AI-led reviews are overall more preferred, while still being conditional on the reviewers' familiarity with the code base, as well as on the severity of the pull request.","authors":["Fannar Steinn A{\\dh}alsteinsson","Bj\\\"orn Borgar Magn\\'usson","Mislav Milicevic","Adam Nirving Davidsson","Chih-Hong Cheng"],"url":"https://arxiv.org/abs/2505.16339"}
{"created":"2025-05-23","title":"Improving Chemical Understanding of LLMs via SMILES Parsing","abstract":"Large language models (LLMs) are increasingly recognized as powerful tools for scientific discovery, particularly in molecular science. A fundamental requirement for these models is the ability to accurately understand molecular structures, commonly encoded in the SMILES representation. However, current LLMs struggle to interpret SMILES, even failing to carry out basic tasks such as counting molecular rings. To address this limitation, we introduce CLEANMOL, a novel framework that formulates SMILES parsing into a suite of clean and deterministic tasks explicitly designed to promote graph-level molecular comprehension. These tasks span from subgraph matching to global graph matching, providing structured supervision aligned with molecular structural properties. We construct a molecular pretraining dataset with adaptive difficulty scoring and pre-train open-source LLMs on these tasks. Our results show that CLEANMOL not only enhances structural comprehension but also achieves the best or competes with the baseline on the Mol-Instructions benchmark.","authors":["Yunhui Jang","Jaehyung Kim","Sungsoo Ahn"],"url":"https://arxiv.org/abs/2505.16340"}
{"created":"2025-05-23","title":"A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning","abstract":"This paper studies the long-tailed semi-supervised learning (LTSSL) with distribution mismatch, where the class distribution of the labeled training data follows a long-tailed distribution and mismatches with that of the unlabeled training data. Most existing methods introduce auxiliary classifiers (experts) to model various unlabeled data distributions and produce pseudo-labels, but the expertises of various experts are not fully utilized. We observe that different experts are good at predicting different intervals of samples, e.g., long-tailed expert is skilled in samples located in the head interval and uniform expert excels in samples located in the medium interval. Therefore, we propose a dynamic expert assignment module that can estimate the class membership (i.e., head, medium, or tail class) of samples, and dynamically assigns suitable expert to each sample based on the estimated membership to produce high-quality pseudo-label in the training phase and produce prediction in the testing phase. We also theoretically reveal that integrating different experts' strengths will lead to a smaller generalization error bound. Moreover, we find that the deeper features are more biased toward the head class but with more discriminative ability, while the shallower features are less biased but also with less discriminative ability. We, therefore, propose a multi-depth feature fusion module to utilize different depth features to mitigate the model bias. Our method demonstrates its effectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets across various settings. The code is available at https://github.com/yaxinhou/Meta-Expert.","authors":["Yaxin Hou","Yuheng Jia"],"url":"https://arxiv.org/abs/2505.16341"}
{"created":"2025-05-23","title":"Neural Field Equations with random data","abstract":"We study neural field equations, which are prototypical models of large-scale cortical activity, subject to random data. We view this spatially-extended, nonlocal evolution equation as a Cauchy problem on abstract Banach spaces, with randomness in the synaptic kernel, firing rate function, external stimuli, and initial conditions. We determine conditions on the random data that guarantee existence, uniqueness, and measurability of the solution in an appropriate Banach space, and examine the regularity of the solution in relation to the regularity of the inputs. We present results for linear and nonlinear neural fields, and for the two most common functional setups in the numerical analysis of this problem. In addition to the continuous problem, we analyse in abstract form neural fields that have been spatially discretised, setting the foundations for analysing uncertainty quantification (UQ) schemes.","authors":["Daniele Avitabile","Francesca Cavallini","Svetlana Dubinkina","Gabriel J. Lord"],"url":"https://arxiv.org/abs/2505.16343"}
{"created":"2025-05-23","title":"Half-Marker Codes for Deletion Channels with Applications in DNA Storage","abstract":"DNA storage systems face significant challenges, including insertion, deletion, and substitution (IDS) errors. Therefore, designing effective synchronization codes, i.e., codes capable of correcting IDS errors, is essential for DNA storage systems. Marker codes are a favorable choice for this purpose. In this paper, we extend the notion of marker codes by making the following key observation. Since each DNA base is equivalent to a 2-bit storage unit, one bit can be reserved for synchronization, while the other is dedicated to data transmission. Using this observation, we propose a new class of marker codes, which we refer to as half-marker codes. We demonstrate that this extension has the potential to significantly increase the mutual information between the input symbols and the soft outputs of an IDS channel modeling a DNA storage system. Specifically, through examples, we show that when concatenated with an outer error-correcting code, half-marker codes outperform standard marker codes and significantly reduce the end-to-end bit error rate of the system.","authors":["Javad Haghighat","Tolga M. Duman"],"url":"https://arxiv.org/abs/2505.16344"}
{"created":"2025-05-23","title":"Convergence analysis of GMRES applied to Helmholtz problems near resonances","abstract":"In this work we study how the convergence rate of GMRES is influenced by the properties of linear systems arising from Helmholtz problems near resonances or quasi-resonances. We extend an existing convergence bound to demonstrate that the approximation of small eigenvalues by harmonic Ritz values plays a key role in convergence behavior. Next, we analyze the impact of deflation using carefully selected vectors and combine this with a Complex Shifted Laplacian preconditioner. Finally, we apply these tools to two numerical examples near (quasi-)resonant frequencies, using them to explain how the convergence rate evolves.","authors":["Victorita Dolean","Pierre Marchand","Axel Modave","Timoth\\'ee Raynaud"],"url":"https://arxiv.org/abs/2505.16345"}
{"created":"2025-05-23","title":"How to keep pushing ML accelerator performance? Know your rooflines!","abstract":"The rapidly growing importance of Machine Learning (ML) applications, coupled with their ever-increasing model size and inference energy footprint, has created a strong need for specialized ML hardware architectures. Numerous ML accelerators have been explored and implemented, primarily to increase task-level throughput per unit area and reduce task-level energy consumption. This paper surveys key trends toward these objectives for more efficient ML accelerators and provides a unifying framework to understand how compute and memory technologies/architectures interact to enhance system-level efficiency and performance. To achieve this, the paper introduces an enhanced version of the roofline model and applies it to ML accelerators as an effective tool for understanding where various execution regimes fall within roofline bounds and how to maximize performance and efficiency under the rooline. Key concepts are illustrated with examples from state-of-the-art designs, with a view towards open research opportunities to further advance accelerator performance.","authors":["Marian Verhelst","Luca Benini","Naveen Verma"],"url":"https://arxiv.org/abs/2505.16346"}
{"created":"2025-05-23","title":"Graph Attention Network for Optimal User Association in Wireless Networks","abstract":"With increased 5G deployments, network densification is higher than ever to support the exponentially high throughput requirements. However, this has meant a significant increase in energy consumption, leading to higher operational expenditure (OpEx) for network operators creating an acute need for improvements in network energy savings (NES). A key determinant of operational efficacy in cellular networks is the user association (UA) policy, as it affects critical aspects like spectral efficiency, load balancing etc. and therefore impacts the overall energy consumption of the network directly. Furthermore, with cellular network topologies lending themselves well to graphical abstractions, use of graphs in network optimization has gained significant prominence. In this work, we propose and analyze a graphical abstraction based optimization for UA in cellular networks to improve NES by determining when energy saving features like cell switch off can be activated. A comparison with legacy approaches establishes the superiority of the proposed approach.","authors":["Javad Mirzaei","Jeebak Mitra","Gwenael Poitau"],"url":"https://arxiv.org/abs/2505.16347"}
{"created":"2025-05-23","title":"Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance","abstract":"Embodied agents empowered by large language models (LLMs) have shown strong performance in household object rearrangement tasks. However, these tasks primarily focus on single-turn interactions with simplified instructions, which do not truly reflect the challenges of providing meaningful assistance to users. To provide personalized assistance, embodied agents must understand the unique semantics that users assign to the physical world (e.g., favorite cup, breakfast routine) by leveraging prior interaction history to interpret dynamic, real-world instructions. Yet, the effectiveness of embodied agents in utilizing memory for personalized assistance remains largely underexplored. To address this gap, we present MEMENTO, a personalized embodied agent evaluation framework designed to comprehensively assess memory utilization capabilities to provide personalized assistance. Our framework consists of a two-stage memory evaluation process design that enables quantifying the impact of memory utilization on task performance. This process enables the evaluation of agents' understanding of personalized knowledge in object rearrangement tasks by focusing on its role in goal interpretation: (1) the ability to identify target objects based on personal meaning (object semantics), and (2) the ability to infer object-location configurations from consistent user patterns, such as routines (user patterns). Our experiments across various LLMs reveal significant limitations in memory utilization, with even frontier models like GPT-4o experiencing a 30.5% performance drop when required to reference multiple memories, particularly in tasks involving user patterns. These findings, along with our detailed analyses and case studies, provide valuable insights for future research in developing more effective personalized embodied agents. Project website: https://connoriginal.github.io/MEMENTO","authors":["Taeyoon Kwon","Dongwook Choi","Sunghwan Kim","Hyojun Kim","Seungjun Moon","Beong-woo Kwak","Kuan-Hao Huang","Jinyoung Yeo"],"url":"https://arxiv.org/abs/2505.16348"}
{"created":"2025-05-23","title":"Ask, Retrieve, Summarize: A Modular Pipeline for Scientific Literature Summarization","abstract":"The exponential growth of scientific publications has made it increasingly difficult for researchers to stay updated and synthesize knowledge effectively. This paper presents XSum, a modular pipeline for multi-document summarization (MDS) in the scientific domain using Retrieval-Augmented Generation (RAG). The pipeline includes two core components: a question-generation module and an editor module. The question-generation module dynamically generates questions adapted to the input papers, ensuring the retrieval of relevant and accurate information. The editor module synthesizes the retrieved content into coherent and well-structured summaries that adhere to academic standards for proper citation. Evaluated on the SurveySum dataset, XSum demonstrates strong performance, achieving considerable improvements in metrics such as CheckEval, G-Eval and Ref-F1 compared to existing approaches. This work provides a transparent, adaptable framework for scientific summarization with potential applications in a wide range of domains. Code available at https://github.com/webis-de/scolia25-xsum","authors":["Pierre Achkar","Tim Gollub","Martin Potthast"],"url":"https://arxiv.org/abs/2505.16349"}
{"created":"2025-05-23","title":"Sensing-Enhanced Handover Criterion for Low-Altitude Wireless Networks (LAWNs)","abstract":"With the rapid growth of the low-altitude economy, the demand for cellular-enabled low-altitude wireless networks (LAWNs) is rising significantly. The three-dimensional mobility of unmanned aerial vehicles (UAVs) will lead to frequent handovers (HOs) in cellular networks, while traditional reference signal received power (RSRP)-based criteria may fail to capture the dynamic environment, causing redundant HOs or HO failures. To address this issue and motivated by the underutilization of sensing information in conventional HO mechanisms, we propose a novel HO activation criterion for UAV systems that integrates both sensing parameters provided by integrated sensing and communication (ISAC) signals and RSRP. First, we construct an ISAC signal model tailored for low-altitude scenarios and derive the Cram\\'er-Rao lower bound for sensing distance estimation. Subsequently, we propose a novel joint HO criterion that extends the conventional RSRP-based method by integrating sensing information from ISAC signals, enabling more reliable HOs in dynamic UAV environments. Simulation results show that the joint HO criterion outperforms the baseline RSRP-based criterion under different signal-to-noise ratio (SNR) and sensing pilot ratio conditions. Particularly, when SNR is greater than 0dB and the sensing pilot ratio is 20%, the proposed joint HO criterion reduces the average HO region length by 49.97% and improves the activation probability by 76.31%.","authors":["Jingli Li","Yiyan Ma","Bo Ai","Qingqing Cheng","Guoyu Ma","Mi Yang","Yunlong Lu","Wenwei Yue","Zhangdui Zhong"],"url":"https://arxiv.org/abs/2505.16350"}
{"created":"2025-05-23","title":"Estimating Perceptual Attributes of Haptic Textures Using Visuo-Tactile Data","abstract":"Accurate prediction of perceptual attributes of haptic textures is essential for advancing VR and AR applications and enhancing robotic interaction with physical surfaces. This paper presents a deep learning-based multi-modal framework, incorporating visual and tactile data, to predict perceptual texture ratings by leveraging multi-feature inputs. To achieve this, a four-dimensional haptic attribute space encompassing rough-smooth, flat-bumpy, sticky-slippery, and hard-soft dimensions is first constructed through psychophysical experiments, where participants evaluate 50 diverse real-world texture samples. A physical signal space is subsequently created by collecting visual and tactile data from these textures. Finally, a deep learning architecture integrating a CNN-based autoencoder for visual feature learning and a ConvLSTM network for tactile data processing is trained to predict user-assigned attribute ratings. This multi-modal, multi-feature approach maps physical signals to perceptual ratings, enabling accurate predictions for unseen textures. To evaluate predictive accuracy, we employed leave-one-out cross-validation to rigorously assess the model's reliability and generalizability against several machine learning and deep learning baselines. Experimental results demonstrate that the framework consistently outperforms single-modality approaches, achieving lower MAE and RMSE, highlighting the efficacy of combining visual and tactile modalities.","authors":["Mudassir Ibrahim Awan","Seokhee Jeon"],"url":"https://arxiv.org/abs/2505.16352"}
{"created":"2025-05-23","title":"Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning","abstract":"In this paper, we introduce a versatile scheme for optimizing the arrival rates of quasi-reversible queueing systems. We first propose an alternative definition of quasi-reversibility that encompasses reversibility and highlights the importance of the definition of customer classes. In a second time, we introduce balanced arrival control policies, which generalize the notion of balanced arrival rates introduced in the context of Whittle networks, to the much broader class of quasi-reversible queueing systems. We prove that supplementing a quasi-reversible queueing system with a balanced arrival-control policy preserves the quasi-reversibility, and we specify the form of the stationary measures. We revisit two canonical examples of quasi-reversible queueing systems, Whittle networks and order-independent queues. Lastly, we focus on the problem of admission control and leverage our results in the frameworks of optimization and reinforcement learning.","authors":["C\\'eline Comte (CNRS","LAAS-SARA","LAAS-RISC)","Pascal Moyal (IECL)"],"url":"https://arxiv.org/abs/2505.16353"}
{"created":"2025-05-23","title":"Efficient Probabilistic Model Checking for Relational Reachability (Extended Version)","abstract":"Markov decision processes model systems subject to nondeterministic and probabilistic uncertainty. A plethora of verification techniques addresses variations of reachability properties, such as: Is there a scheduler resolving the nondeterminism such that the probability to reach an error state is above a threshold? We consider an understudied extension that relates different reachability probabilities, such as: Is there a scheduler such that two sets of states are reached with different probabilities? These questions appear naturally in the design of randomized algorithms and in various security applications. We provide a tractable algorithm for many variations of this problem, while proving computational hardness of some others. An implementation of our algorithm beats solvers for more general probabilistic hyperlogics by orders of magnitude, on the subset of their benchmarks that are within our fragment.","authors":["Lina Gerlach (RWTH Aachen University","Aachen","Germany)","Tobias Winkler (RWTH Aachen University","Aachen","Germany)","Erika \\'Abrah\\'am (RWTH Aachen University","Aachen","Germany)","Borzoo Bonakdarpour (Michigan State University","East Lansing","MI","USA)","Sebastian Junges (Radboud University","Nijmegen","the Netherlands)"],"url":"https://arxiv.org/abs/2505.16357"}
{"created":"2025-05-23","title":"Strategic Content Creation in the Age of GenAI: To Share or Not to Share?","abstract":"We introduce a game-theoretic framework examining strategic interactions between a platform and its content creators in the presence of AI-generated content. Our model's main novelty is in capturing creators' dual strategic decisions: The investment in content quality and their (possible) consent to share their content with the platform's GenAI, both of which significantly impact their utility. To incentivize creators, the platform strategically allocates a portion of its GenAI-driven revenue to creators who share their content. We focus on the class of full-sharing equilibrium profiles, in which all creators willingly share their content with the platform's GenAI system. Such equilibria are highly desirable both theoretically and practically. Our main technical contribution is formulating and efficiently solving a novel optimization problem that approximates the platform's optimal revenue subject to inducing a full-sharing equilibrium. A key aspect of our approach is identifying conditions under which full-sharing equilibria exist and a surprising connection to the Prisoner's Dilemma. Finally, our simulations demonstrate how revenue-allocation mechanisms affect creator utility and the platform's revenue.","authors":["Gur Keinan","Omer Ben-Porat"],"url":"https://arxiv.org/abs/2505.16358"}
{"created":"2025-05-23","title":"Style Transfer with Diffusion Models for Synthetic-to-Real Domain Adaptation","abstract":"Semantic segmentation models trained on synthetic data often perform poorly on real-world images due to domain gaps, particularly in adverse conditions where labeled data is scarce. Yet, recent foundation models enable to generate realistic images without any training. This paper proposes to leverage such diffusion models to improve the performance of vision models when learned on synthetic data. We introduce two novel techniques for semantically consistent style transfer using diffusion models: Class-wise Adaptive Instance Normalization and Cross-Attention (CACTI) and its extension with selective attention Filtering (CACTIF). CACTI applies statistical normalization selectively based on semantic classes, while CACTIF further filters cross-attention maps based on feature similarity, preventing artifacts in regions with weak cross-attention correspondences. Our methods transfer style characteristics while preserving semantic boundaries and structural coherence, unlike approaches that apply global transformations or generate content without constraints. Experiments using GTA5 as source and Cityscapes/ACDC as target domains show that our approach produces higher quality images with lower FID scores and better content preservation. Our work demonstrates that class-aware diffusion-based style transfer effectively bridges the synthetic-to-real domain gap even with minimal target domain data, advancing robust perception systems for challenging real-world applications. The source code is available at: https://github.com/echigot/cactif.","authors":["Estelle Chigot","Dennis G. Wilson","Meriem Ghrib","Thomas Oberlin"],"url":"https://arxiv.org/abs/2505.16360"}
{"created":"2025-05-23","title":"Neuromorphic-based metaheuristics: A new generation of low power, low latency and small footprint optimization algorithms","abstract":"Neuromorphic computing (NC) introduces a novel algorithmic paradigm representing a major shift from traditional digital computing of Von Neumann architectures. NC emulates or simulates the neural dynamics of brains in the form of Spiking Neural Networks (SNNs). Much of the research in NC has concentrated on machine learning applications and neuroscience simulations. This paper investigates the modelling and implementation of optimization algorithms and particularly metaheuristics using the NC paradigm as an alternative to Von Neumann architectures, leading to breakthroughs in solving optimization problems.","authors":["El-ghazali Talbi"],"url":"https://arxiv.org/abs/2505.16362"}
{"created":"2025-05-23","title":"AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training","abstract":"We introduce AdamS, a simple yet effective alternative to Adam for large language model (LLM) pretraining and post-training. By leveraging a novel denominator, i.e., the root of weighted sum of squares of the momentum and the current gradient, AdamS eliminates the need for second-moment estimates. Hence, AdamS is efficient, matching the memory and compute footprint of SGD with momentum while delivering superior optimization performance. Moreover, AdamS is easy to adopt: it can directly inherit hyperparameters of AdamW, and is entirely model-agnostic, integrating seamlessly into existing pipelines without modifications to optimizer APIs or architectures. The motivation behind AdamS stems from the observed $(L_0, L_1)$ smoothness properties in transformer objectives, where local smoothness is governed by gradient magnitudes that can be further approximated by momentum magnitudes. We establish rigorous theoretical convergence guarantees and provide practical guidelines for hyperparameter selection. Empirically, AdamS demonstrates strong performance in various tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B parameters) and reinforcement learning in post-training regimes. With its efficiency, simplicity, and theoretical grounding, AdamS stands as a compelling alternative to existing optimizers.","authors":["Huishuai Zhang","Bohan Wang","Luoxin Chen"],"url":"https://arxiv.org/abs/2505.16363"}
{"created":"2025-05-23","title":"A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules","abstract":"Developing new molecular compounds is crucial to address pressing challenges, from health to environmental sustainability. However, exploring the molecular space to discover new molecules is difficult due to the vastness of the space. Here we introduce CoCoGraph, a collaborative and constrained graph diffusion model capable of generating molecules that are guaranteed to be chemically valid. Thanks to the constraints built into the model and to the collaborative mechanism, CoCoGraph outperforms state-of-the-art approaches on standard benchmarks while requiring up to an order of magnitude fewer parameters. Analysis of 36 chemical properties also demonstrates that CoCoGraph generates molecules with distributions more closely matching real molecules than current models. Leveraging the model's efficiency, we created a database of 8.2M million synthetically generated molecules and conducted a Turing-like test with organic chemistry experts to further assess the plausibility of the generated molecules, and potential biases and limitations of CoCoGraph.","authors":["Manuel Ruiz-Botella","Marta Sales-Pardo","Roger Guimer\\`a"],"url":"https://arxiv.org/abs/2505.16365"}
{"created":"2025-05-23","title":"ReCopilot: Reverse Engineering Copilot in Binary Analysis","abstract":"Binary analysis plays a pivotal role in security domains such as malware detection and vulnerability discovery, yet it remains labor-intensive and heavily reliant on expert knowledge. General-purpose large language models (LLMs) perform well in programming analysis on source code, while binaryspecific LLMs are underexplored. In this work, we present ReCopilot, an expert LLM designed for binary analysis tasks. ReCopilot integrates binary code knowledge through a meticulously constructed dataset, encompassing continue pretraining (CPT), supervised fine-tuning (SFT), and direct preference optimization (DPO) stages. It leverages variable data flow and call graph to enhance context awareness and employs test-time scaling to improve reasoning capabilities. Evaluations on a comprehensive binary analysis benchmark demonstrate that ReCopilot achieves state-of-the-art performance in tasks such as function name recovery and variable type inference on the decompiled pseudo code, outperforming both existing tools and LLMs by 13%. Our findings highlight the effectiveness of domain-specific training and context enhancement, while also revealing challenges in building super long chain-of-thought. ReCopilot represents a significant step toward automating binary analysis with interpretable and scalable AI assistance in this domain.","authors":["Guoqiang Chen","Huiqi Sun","Daguang Liu","Zhiqi Wang","Qiang Wang","Bin Yin","Lu Liu","Lingyun Ying"],"url":"https://arxiv.org/abs/2505.16366"}
{"created":"2025-05-23","title":"Chain-of-Thought Poisoning Attacks against R1-based Retrieval-Augmented Generation Systems","abstract":"Retrieval-augmented generation (RAG) systems can effectively mitigate the hallucination problem of large language models (LLMs),but they also possess inherent vulnerabilities. Identifying these weaknesses before the large-scale real-world deployment of RAG systems is of great importance, as it lays the foundation for building more secure and robust RAG systems in the future. Existing adversarial attack methods typically exploit knowledge base poisoning to probe the vulnerabilities of RAG systems, which can effectively deceive standard RAG models. However, with the rapid advancement of deep reasoning capabilities in modern LLMs, previous approaches that merely inject incorrect knowledge are inadequate when attacking RAG systems equipped with deep reasoning abilities. Inspired by the deep thinking capabilities of LLMs, this paper extracts reasoning process templates from R1-based RAG systems, uses these templates to wrap erroneous knowledge into adversarial documents, and injects them into the knowledge base to attack RAG systems. The key idea of our approach is that adversarial documents, by simulating the chain-of-thought patterns aligned with the model's training signals, may be misinterpreted by the model as authentic historical reasoning processes, thus increasing their likelihood of being referenced. Experiments conducted on the MS MARCO passage ranking dataset demonstrate the effectiveness of our proposed method.","authors":["Hongru Song","Yu-an Liu","Ruqing Zhang","Jiafeng Guo","Yixing Fan"],"url":"https://arxiv.org/abs/2505.16367"}
{"created":"2025-05-23","title":"SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning","abstract":"How to design reinforcement learning (RL) tasks that effectively unleash the reasoning capability of large language models (LLMs) remains an open question. Existing RL tasks (e.g., math, programming, and constructing reasoning tasks) suffer from three key limitations: (1) Scalability. They rely heavily on human annotation or expensive LLM synthesis to generate sufficient training data. (2) Verifiability. LLMs' outputs are hard to verify automatically and reliably. (3) Controllable Difficulty. Most tasks lack fine-grained difficulty control, making it hard to train LLMs to develop reasoning ability from easy to hard.","authors":["Huanyu Liu","Jia Li","Hao Zhu","Kechi Zhang","Yihong Dong","Ge Li"],"url":"https://arxiv.org/abs/2505.16368"}
{"created":"2025-05-23","title":"X-ARES: A Comprehensive Framework for Assessing Audio Encoder Performance","abstract":"We introduces X-ARES (eXtensive Audio Representation and Evaluation Suite), a novel open-source benchmark designed to systematically assess audio encoder performance across diverse domains. By encompassing tasks spanning speech, environmental sounds, and music, X-ARES provides two evaluation approaches for evaluating audio representations: linear fine-tuning and unparameterized evaluation. The framework includes 22 distinct tasks that cover essential aspects of audio processing, from speech recognition and emotion detection to sound event classification and music genre identification. Our extensive evaluation of state-of-the-art audio encoders reveals significant performance variations across different tasks and domains, highlighting the complexity of general audio representation learning.","authors":["Junbo Zhang","Heinrich Dinkel","Yadong Niu","Chenyu Liu","Si Cheng","Anbei Zhao","Jian Luan"],"url":"https://arxiv.org/abs/2505.16369"}
{"created":"2025-05-23","title":"Privacy-Aware Cyberterrorism Network Analysis using Graph Neural Networks and Federated Learning","abstract":"Cyberterrorism poses a formidable threat to digital infrastructures, with increasing reliance on encrypted, decentralized platforms that obscure threat actor activity. To address the challenge of analyzing such adversarial networks while preserving the privacy of distributed intelligence data, we propose a Privacy-Aware Federated Graph Neural Network (PA-FGNN) framework. PA-FGNN integrates graph attention networks, differential privacy, and homomorphic encryption into a robust federated learning pipeline tailored for cyberterrorism network analysis. Each client trains locally on sensitive graph data and exchanges encrypted, noise-perturbed model updates with a central aggregator, which performs secure aggregation and broadcasts global updates. We implement anomaly detection for flagging high-risk nodes and incorporate defenses against gradient poisoning. Experimental evaluations on simulated dark web and cyber-intelligence graphs demonstrate that PA-FGNN achieves over 91\\% classification accuracy, maintains resilience under 20\\% adversarial client behavior, and incurs less than 18\\% communication overhead. Our results highlight that privacy-preserving GNNs can support large-scale cyber threat detection without compromising on utility, privacy, or robustness.","authors":["Anas Ali","Mubashar Husain","Peter Hans"],"url":"https://arxiv.org/abs/2505.16371"}
{"created":"2025-05-23","title":"Temporal and Spatial Feature Fusion Framework for Dynamic Micro Expression Recognition","abstract":"When emotions are repressed, an individual's true feelings may be revealed through micro-expressions. Consequently, micro-expressions are regarded as a genuine source of insight into an individual's authentic emotions. However, the transient and highly localised nature of micro-expressions poses a significant challenge to their accurate recognition, with the accuracy rate of micro-expression recognition being as low as 50%, even for professionals. In order to address these challenges, it is necessary to explore the field of dynamic micro expression recognition (DMER) using multimodal fusion techniques, with special attention to the diverse fusion of temporal and spatial modal features. In this paper, we propose a novel Temporal and Spatial feature Fusion framework for DMER (TSFmicro). This framework integrates a Retention Network (RetNet) and a transformer-based DMER network, with the objective of efficient micro-expression recognition through the capture and fusion of temporal and spatial relations. Meanwhile, we propose a novel parallel time-space fusion method from the perspective of modal fusion, which fuses spatio-temporal information in high-dimensional feature space, resulting in complementary \"where-how\" relationships at the semantic level and providing richer semantic information for the model. The experimental results demonstrate the superior performance of the TSFmicro method in comparison to other contemporary state-of-the-art methods. This is evidenced by its effectiveness on three well-recognised micro-expression datasets.","authors":["Feng Liu","Bingyu Nan","Xuezhong Qian","Xiaolan Fu"],"url":"https://arxiv.org/abs/2505.16372"}
{"created":"2025-05-23","title":"Scalable and Efficient Aggregation of Energy-Constrained Flexible Loads","abstract":"Loads represent a promising flexibility source to support the integration of renewable energy sources, as they may shift their energy consumption over time. By computing the aggregated flexibility of power and energy-constrained loads, aggregators can communicate the group's flexibility without sharing individual private information. However, this computation is, in practice, challenging. Some studies suggest different inner approximations of aggregated flexibility polytopes, but all suffer from large computational costs for realistic load numbers and horizon lengths. In this paper, we develop a novel approximation of the aggregated flexibility of loads based on the concept of worst-case energy dispatch, i.e., if aggregated energy consumptions are assumed to be dispatched in the worst manner possible. This leads to conservative piecewise linear bounds that restrict the aggregated energy consumption only based on the previous aggregated energy consumed. A comparative case study reveals that our method can compute an approximation of the aggregation of thousands of loads efficiently, while displaying an accuracy comparable to other approximation techniques.","authors":["Julie Rousseau","Philipp Heer","Kristina Orehounig","Gabriela Hug"],"url":"https://arxiv.org/abs/2505.16374"}
{"created":"2025-05-23","title":"DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos","abstract":"Long Video Temporal Grounding (LVTG) aims at identifying specific moments within lengthy videos based on user-provided text queries for effective content retrieval. The approach taken by existing methods of dividing video into clips and processing each clip via a full-scale expert encoder is challenging to scale due to prohibitive computational costs of processing a large number of clips in long videos. To address this issue, we introduce DeCafNet, an approach employing ``delegate-and-conquer'' strategy to achieve computation efficiency without sacrificing grounding performance. DeCafNet introduces a sidekick encoder that performs dense feature extraction over all video clips in a resource-efficient manner, while generating a saliency map to identify the most relevant clips for full processing by the expert encoder. To effectively leverage features from sidekick and expert encoders that exist at different temporal resolutions, we introduce DeCaf-Grounder, which unifies and refines them via query-aware temporal aggregation and multi-scale temporal refinement for accurate grounding. Experiments on two LTVG benchmark datasets demonstrate that DeCafNet reduces computation by up to 47\\% while still outperforming existing methods, establishing a new state-of-the-art for LTVG in terms of both efficiency and performance. Our code is available at https://github.com/ZijiaLewisLu/CVPR2025-DeCafNet.","authors":["Zijia Lu","A S M Iftekhar","Gaurav Mittal","Tianjian Meng","Xiawei Wang","Cheng Zhao","Rohith Kukkala","Ehsan Elhamifar","Mei Chen"],"url":"https://arxiv.org/abs/2505.16376"}
{"created":"2025-05-23","title":"VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving","abstract":"Reinforcement learning (RL)-based autonomous driving policy learning faces critical limitations such as low sample efficiency and poor generalization; its reliance on online interactions and trial-and-error learning is especially unacceptable in safety-critical scenarios. Existing methods including safe RL often fail to capture the true semantic meaning of \"safety\" in complex driving contexts, leading to either overly conservative driving behavior or constraint violations. To address these challenges, we propose VL-SAFE, a world model-based safe RL framework with Vision-Language model (VLM)-as-safety-guidance paradigm, designed for offline safe policy learning. Specifically, we construct offline datasets containing data collected by expert agents and labeled with safety scores derived from VLMs. A world model is trained to generate imagined rollouts together with safety estimations, allowing the agent to perform safe planning without interacting with the real environment. Based on these imagined trajectories and safety evaluations, actor-critic learning is conducted under VLM-based safety guidance to optimize the driving policy more safely and efficiently. Extensive evaluations demonstrate that VL-SAFE achieves superior sample efficiency, generalization, safety, and overall performance compared to existing baselines. To the best of our knowledge, this is the first work that introduces a VLM-guided world model-based approach for safe autonomous driving. The demo video and code can be accessed at: https://ys-qu.github.io/vlsafe-website/","authors":["Yansong Qu","Zilin Huang","Zihao Sheng","Jiancong Chen","Sikai Chen","Samuel Labi"],"url":"https://arxiv.org/abs/2505.16377"}
{"created":"2025-05-23","title":"PaTH Attention: Position Encoding via Accumulating Householder Transformations","abstract":"The attention mechanism is a core primitive in modern large language models (LLMs) and AI more broadly. Since attention by itself is permutation-invariant, position encoding is essential for modeling structured domains such as language. Rotary position encoding (RoPE) has emerged as the de facto standard approach for position encoding and is part of many modern LLMs. However, in RoPE the key/query transformation between two elements in a sequence is only a function of their relative position and otherwise independent of the actual input. This limits the expressivity of RoPE-based transformers.","authors":["Songlin Yang","Yikang Shen","Kaiyue Wen","Shawn Tan","Mayank Mishra","Liliang Ren","Rameswar Panda","Yoon Kim"],"url":"https://arxiv.org/abs/2505.16381"}
{"created":"2025-05-23","title":"Filling in the Blanks? A Systematic Review and Theoretical Conceptualisation for Measuring WikiData Content Gaps","abstract":"Wikidata is a collaborative knowledge graph which provides machine-readable structured data for Wikimedia projects including Wikipedia. Managed by a community of volunteers, it has grown to become the most edited Wikimedia project. However, it features a long-tail of items with limited data and a number of systematic gaps within the available content. In this paper, we present the results of a systematic literature review aimed to understand the state of these content gaps within Wikidata. We propose a typology of gaps based on prior research and contribute a theoretical framework intended to conceptualise gaps and support their measurement. We also describe the methods and metrics present used within the literature and classify them according to our framework to identify overlooked gaps that might occur in Wikidata. We then discuss the implications for collaboration and editor activity within Wikidata as well as future research directions. Our results contribute to the understanding of quality, completeness and the impact of systematic biases within Wikidata and knowledge gaps more generally.","authors":["Marisa Ripoll","Neal Reeves","Anelia Kurteva","Elena Simperl","Albert Mero\\~no Pe\\~nuela"],"url":"https://arxiv.org/abs/2505.16383"}
{"created":"2025-05-23","title":"MAGE: A Multi-task Architecture for Gaze Estimation with an Efficient Calibration Module","abstract":"Eye gaze can provide rich information on human psychological activities, and has garnered significant attention in the field of Human-Robot Interaction (HRI). However, existing gaze estimation methods merely predict either the gaze direction or the Point-of-Gaze (PoG) on the screen, failing to provide sufficient information for a comprehensive six Degree-of-Freedom (DoF) gaze analysis in 3D space. Moreover, the variations of eye shape and structure among individuals also impede the generalization capability of these methods. In this study, we propose MAGE, a Multi-task Architecture for Gaze Estimation with an efficient calibration module, to predict the 6-DoF gaze information that is applicable for the real-word HRI. Our basic model encodes both the directional and positional features from facial images, and predicts gaze results with dedicated information flow and multiple decoders. To reduce the impact of individual variations, we propose a novel calibration module, namely Easy-Calibration, to fine-tune the basic model with subject-specific data, which is efficient to implement without the need of a screen. Experimental results demonstrate that our method achieves state-of-the-art performance on the public MPIIFaceGaze, EYEDIAP, and our built IMRGaze datasets.","authors":["Haoming Huang","Musen Zhang","Jianxin Yang","Zhen Li","Jinkai Li","Yao Guo"],"url":"https://arxiv.org/abs/2505.16384"}
{"created":"2025-05-23","title":"Semantic Pivots Enable Cross-Lingual Transfer in Large Language Models","abstract":"Large language models (LLMs) demonstrate remarkable ability in cross-lingual tasks. Understanding how LLMs acquire this ability is crucial for their interpretability. To quantify the cross-lingual ability of LLMs accurately, we propose a Word-Level Cross-Lingual Translation Task. To find how LLMs learn cross-lingual ability, we trace the outputs of LLMs' intermediate layers in the word translation task. We identify and distinguish two distinct behaviors in the forward pass of LLMs: co-occurrence behavior and semantic pivot behavior. We attribute LLMs' two distinct behaviors to the co-occurrence frequency of words and find the semantic pivot from the pre-training dataset. Finally, to apply our findings to improve the cross-lingual ability of LLMs, we reconstruct a semantic pivot-aware pre-training dataset using documents with a high proportion of semantic pivots. Our experiments validate the effectiveness of our approach in enhancing cross-lingual ability. Our research contributes insights into the interpretability of LLMs and offers a method for improving LLMs' cross-lingual ability.","authors":["Kaiyu He","Tong Zhou","Yubo Chen","Delai Qiu","Shengping Liu","Kang Liu","Jun Zhao"],"url":"https://arxiv.org/abs/2505.16385"}
{"created":"2025-05-23","title":"Omni TM-AE: A Scalable and Interpretable Embedding Model Using the Full Tsetlin Machine State Space","abstract":"The increasing complexity of large-scale language models has amplified concerns regarding their interpretability and reusability. While traditional embedding models like Word2Vec and GloVe offer scalability, they lack transparency and often behave as black boxes. Conversely, interpretable models such as the Tsetlin Machine (TM) have shown promise in constructing explainable learning systems, though they previously faced limitations in scalability and reusability. In this paper, we introduce Omni Tsetlin Machine AutoEncoder (Omni TM-AE), a novel embedding model that fully exploits the information contained in the TM's state matrix, including literals previously excluded from clause formation. This method enables the construction of reusable, interpretable embeddings through a single training phase. Extensive experiments across semantic similarity, sentiment classification, and document clustering tasks show that Omni TM-AE performs competitively with and often surpasses mainstream embedding models. These results demonstrate that it is possible to balance performance, scalability, and interpretability in modern Natural Language Processing (NLP) systems without resorting to opaque architectures.","authors":["Ahmed K. Kadhim","Lei Jiao","Rishad Shafik","Ole-Christoffer Granmo"],"url":"https://arxiv.org/abs/2505.16386"}
{"created":"2025-05-23","title":"Serious Games: Human-AI Interaction, Evolution, and Coevolution","abstract":"The serious games between humans and AI have only just begun. Evolutionary Game Theory (EGT) models the competitive and cooperative strategies of biological entities. EGT could help predict the potential evolutionary equilibrium of humans and AI. The objective of this work was to examine some of the EGT models relevant to human-AI interaction, evolution, and coevolution. Of thirteen EGT models considered, three were examined: the Hawk-Dove Game, Iterated Prisoner's Dilemma, and the War of Attrition. This selection was based on the widespread acceptance and clear relevance of these models to potential human-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove Game predicts balanced mixed-strategy equilibria based on the costs of conflict. It also shows the potential for balanced coevolution rather than dominance. Iterated Prisoner's Dilemma suggests that repeated interaction may lead to cognitive coevolution. It demonstrates how memory and reciprocity can lead to cooperation. The War of Attrition suggests that competition for resources may result in strategic coevolution, asymmetric equilibria, and conventions on sharing resources. Therefore, EGT may provide a suitable framework to understand and predict the human-AI evolutionary dynamic. However, future research could extend beyond EGT and explore additional frameworks, empirical validation methods, and interdisciplinary perspectives. AI is being shaped by human input and is evolving in response to it. So too, neuroplasticity allows the human brain to grow and evolve in response to stimuli. If humans and AI converge in future, what might be the result of human neuroplasticity combined with an ever-evolving AI? Future research should be mindful of the ethical and cognitive implications of human-AI interaction, evolution, and coevolution.","authors":["Nandini Doreswamy (Southern Cross University","Lismore","New South Wales","Australia","National Coalition of Independent Scholars)","Louise Horstmanshof (Southern Cross University","Lismore","New South Wales","Australia)"],"url":"https://arxiv.org/abs/2505.16388"}
{"created":"2025-05-23","title":"Coverage Path Planning For Multi-view SAR-UAV Observation System Under Energy Constraint","abstract":"Multi-view Synthetic Aperture Radar (SAR) imaging can effectively enhance the performance of tasks such as automatic target recognition and image information fusion. Unmanned aerial vehicles (UAVs) have the advantages of flexible deployment and cost reduction. A swarm of UAVs equipped with synthetic aperture radar imaging equipment is well suited to meet the functional requirements of multi-view synthetic aperture radar imaging missions. However, to provide optimal paths for SAR-UAVs from the base station to cover target viewpoints in the mission area is of NP-hard computational complexity. In this work, the coverage path planning problem for multi-view SAR-UAV observation systems is studied. First, the coordinate of observation viewpoints is calculated based on the location of targets and base station under a brief geometric model. Then, the exact problem formulation is modeled in order to fully describe the solution space and search for optimal paths that provide maximum coverage rate for SAR-UAVs. Finally, an Adaptive Density Peak Clustering (ADPC) method is proposed to overcome the additional energy consumption due to the viewpoints being far away from the base station. The Particle Swarm Optimization (PSO) algorithm is introduced for optimal path generation. Experimental results demonstrate the effectiveness and computational efficiency of the proposed approach.","authors":["Deyu Song","Xiangyin Zhang","Zipei Yu","Kaiyu Qin"],"url":"https://arxiv.org/abs/2505.16389"}
{"created":"2025-05-23","title":"Resource for Error Analysis in Text Simplification: New Taxonomy and Test Collection","abstract":"The general public often encounters complex texts but does not have the time or expertise to fully understand them, leading to the spread of misinformation. Automatic Text Simplification (ATS) helps make information more accessible, but its evaluation methods have not kept up with advances in text generation, especially with Large Language Models (LLMs). In particular, recent studies have shown that current ATS metrics do not correlate with the presence of errors. Manual inspections have further revealed a variety of errors, underscoring the need for a more nuanced evaluation framework, which is currently lacking. This resource paper addresses this gap by introducing a test collection for detecting and classifying errors in simplified texts. First, we propose a taxonomy of errors, with a formal focus on information distortion. Next, we introduce a parallel dataset of automatically simplified scientific texts. This dataset has been human-annotated with labels based on our proposed taxonomy. Finally, we analyze the quality of the dataset, and we study the performance of existing models to detect and classify errors from that taxonomy. These contributions give researchers the tools to better evaluate errors in ATS, develop more reliable models, and ultimately improve the quality of automatically simplified texts.","authors":["Benjamin Vendeville","Liana Ermakova","Pierre De Loor"],"url":"https://arxiv.org/abs/2505.16392"}
{"created":"2025-05-23","title":"Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)","abstract":"Reinforcement Learning (RL) can mitigate the causal confusion and distribution shift inherent to imitation learning (IL). However, applying RL to end-to-end autonomous driving (E2E-AD) remains an open problem for its training difficulty, and IL is still the mainstream paradigm in both academia and industry. Recently Model-based Reinforcement Learning (MBRL) have demonstrated promising results in neural planning; however, these methods typically require privileged information as input rather than raw sensor data. We fill this gap by designing Raw2Drive, a dual-stream MBRL approach. Initially, we efficiently train an auxiliary privileged world model paired with a neural planner that uses privileged information as input. Subsequently, we introduce a raw sensor world model trained via our proposed Guidance Mechanism, which ensures consistency between the raw sensor world model and the privileged world model during rollouts. Finally, the raw sensor world model combines the prior knowledge embedded in the heads of the privileged world model to effectively guide the training of the raw sensor policy. Raw2Drive is so far the only RL based end-to-end method on CARLA Leaderboard 2.0, and Bench2Drive and it achieves state-of-the-art performance.","authors":["Zhenjie Yang","Xiaosong Jia","Qifeng Li","Xue Yang","Maoqing Yao","Junchi Yan"],"url":"https://arxiv.org/abs/2505.16394"}
{"created":"2025-05-23","title":"Trajectory-Independent Flexibility Envelopes of Energy-Constrained Systems with State-Dependent Losses","abstract":"As non-dispatchable renewable power units become prominent in electric power grids, demand-side flexibility appears as a key element of future power systems' operation. Power and energy bounds are intuitive metrics to describe the flexibility of energy-constrained loads. However, to be used in operation, any power consumption trajectory fulfilling the power and energy bounds must necessarily fulfill the load's constraints. In this paper, we demonstrate that energy bounds defined as the minimum and maximum energy consumption potential of a load with state-dependent losses are Trajectory-Dependent (TD), i.e., for any energy value in the bounds a feasible power trajectory exists, but not all power trajectories enclosed in the energy envelopes satisfy the load's constraints. To guarantee the satisfaction of load constraints for all trajectories, we define Trajectory-Independent (TI) energy bounds. We present TI envelope formulations for individual loads, as well as physically coupled loads and assess the proposed formulations in a building heating system, a system with state-dependent losses. We find that using a TD envelope as energy bounds in operation may yield room temperature up to 3.8{\\deg}C higher and 3.4{\\deg}C lower than admissible. Overall, poorly insulated buildings observe a TI energy envelope that differs significantly from their TD envelope.","authors":["Julie Rousseau","Carlo Tajoli","Hanmin Cai","Philipp Heer","Kristina Orehounig","Gabriela Hug"],"url":"https://arxiv.org/abs/2505.16396"}
{"created":"2025-05-23","title":"Dynamic Caustics by Ultrasonically Modulated Liquid Surface","abstract":"This paper presents a method for generating dynamic caustic patterns by utilising dual-optimised holographic fields with Phased Array Transducer (PAT). Building on previous research in static caustic optimisation and ultrasonic manipulation, this approach employs computational techniques to dynamically shape fluid surfaces, thereby creating controllable and real-time caustic images. The system employs a Digital Twin framework, which enables iterative feedback and refinement, thereby improving the accuracy and quality of the caustic patterns produced. This paper extends the foundational work in caustic generation by integrating liquid surfaces as refractive media. This concept has previously been explored in simulations but not fully realised in practical applications. The utilisation of ultrasound to directly manipulate these surfaces enables the generation of dynamic caustics with a high degree of flexibility. The Digital Twin approach further enhances this process by allowing for precise adjustments and optimisation based on real-time feedback. Experimental results demonstrate the technique's capacity to generate continuous animations and complex caustic patterns at high frequencies. Although there are limitations in contrast and resolution compared to solid-surface methods, this approach offers advantages in terms of real-time adaptability and scalability. This technique has the potential to be applied in a number of areas, including interactive displays, artistic installations and educational tools. This research builds upon the work of previous researchers in the fields of caustics optimisation, ultrasonic manipulation, and computational displays. Future research will concentrate on enhancing the resolution and intricacy of the generated patterns.","authors":["Koki Nagakura","Tatsuki Fushimi","Ayaka Tsutsui","Yoichi Ochiai"],"url":"https://arxiv.org/abs/2505.16397"}
{"created":"2025-05-23","title":"Consistent and Compatible Modelling of Cyber Intrusions and Incident Response Demonstrated in the Context of Malware Attacks on Critical Infrastructure","abstract":"Cyber Security Incident Response (IR) Playbooks are used to capture the steps required to recover from a cyber intrusion. Individual IR playbooks should focus on a specific type of incident and be aligned with the architecture of a system under attack. Intrusion modelling focuses on a specific potential cyber intrusion and is used to identify where and what countermeasures are needed, and the resulting intrusion models are expected to be used in effective IR, ideally by feeding IR Playbooks designs. IR playbooks and intrusion models, however, are created in isolation and at varying stages of the system's lifecycle. We take nine critical national infrastructure intrusion models - expressed using Sequential AND Attack Trees - and transform them into models of the same format as IR playbooks. We use Security Modelling Framework for modelling attacks and playbooks, and for demonstrating the feasibility of the better integration between risk assessment and IR at the modelling level. This results in improved intrusion models and tighter coupling between IR playbooks and threat modelling which - as we demonstrate - yields novel insights into the analysis of attacks and response actions. The main contributions of this paper are (a) a novel way of representing attack trees using the Security Modelling Framework,(b) a new tool for converting Sequential AND attack trees into models compatible with playbooks, and (c) the examples of nine intrusion models represented using the Security Modelling Framework.","authors":["Peter Maynard","Yulia Cherdantseva","Avi Shaked","Pete Burnap","Arif Mehmood"],"url":"https://arxiv.org/abs/2505.16398"}
{"created":"2025-05-23","title":"Sketchy Bounding-box Supervision for 3D Instance Segmentation","abstract":"Bounding box supervision has gained considerable attention in weakly supervised 3D instance segmentation. While this approach alleviates the need for extensive point-level annotations, obtaining accurate bounding boxes in practical applications remains challenging. To this end, we explore the inaccurate bounding box, named sketchy bounding box, which is imitated through perturbing ground truth bounding box by adding scaling, translation, and rotation. In this paper, we propose Sketchy-3DIS, a novel weakly 3D instance segmentation framework, which jointly learns pseudo labeler and segmentator to improve the performance under the sketchy bounding-box supervisions. Specifically, we first propose an adaptive box-to-point pseudo labeler that adaptively learns to assign points located in the overlapped parts between two sketchy bounding boxes to the correct instance, resulting in compact and pure pseudo instance labels. Then, we present a coarse-to-fine instance segmentator that first predicts coarse instances from the entire point cloud and then learns fine instances based on the region of coarse instances. Finally, by using the pseudo instance labels to supervise the instance segmentator, we can gradually generate high-quality instances through joint training. Extensive experiments show that our method achieves state-of-the-art performance on both the ScanNetV2 and S3DIS benchmarks, and even outperforms several fully supervised methods using sketchy bounding boxes. Code is available at https://github.com/dengq7/Sketchy-3DIS.","authors":["Qian Deng","Le Hui","Jin Xie","Jian Yang"],"url":"https://arxiv.org/abs/2505.16399"}
{"created":"2025-05-23","title":"AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning","abstract":"Despite recent progress in large-scale reinforcement learning (RL) for reasoning, the training recipe for building high-performing reasoning models remains elusive. Key implementation details of frontier models, such as DeepSeek-R1, including data curation strategies and RL training recipe, are often omitted. Moreover, recent research indicates distillation remains more effective than RL for smaller models. In this work, we demonstrate that large-scale RL can significantly enhance the reasoning capabilities of strong, small- and mid-sized models, achieving results that surpass those of state-of-the-art distillation-based models. We systematically study the RL training process through extensive ablations and propose a simple yet effective approach: first training on math-only prompts, then on code-only prompts. Notably, we find that math-only RL not only significantly enhances the performance of strong distilled models on math benchmarks (e.g., +14.6% / +17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks (e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition, extended code-only RL iterations further improve performance on code benchmarks with minimal or no degradation in math results. We develop a robust data curation pipeline to collect challenging prompts with high-quality, verifiable answers and test cases to enable verification-based RL across both domains. Finally, we identify key experimental insights, including curriculum learning with progressively increasing response lengths and the stabilizing effect of on-policy parameter updates. We find that RL not only elicits the foundational reasoning capabilities acquired during pretraining and supervised fine-tuning (e.g., distillation), but also pushes the limits of the model's reasoning ability, enabling it to solve problems that were previously unsolvable.","authors":["Yang Chen","Zhuolin Yang","Zihan Liu","Chankyu Lee","Peng Xu","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"url":"https://arxiv.org/abs/2505.16400"}
{"created":"2025-05-23","title":"Divide-Fuse-Conquer: Eliciting \"Aha Moments\" in Multi-Scenario Games","abstract":"Large language models (LLMs) have been observed to suddenly exhibit advanced reasoning abilities during reinforcement learning (RL), resembling an ``aha moment'' triggered by simple outcome-based rewards. While RL has proven effective in eliciting such breakthroughs in tasks involving mathematics, coding, and vision, it faces significant challenges in multi-scenario games. The diversity of game rules, interaction modes, and environmental complexities often leads to policies that perform well in one scenario but fail to generalize to others. Simply combining multiple scenarios during training introduces additional challenges, such as training instability and poor performance. To overcome these challenges, we propose Divide-Fuse-Conquer, a framework designed to enhance generalization in multi-scenario RL. This approach starts by heuristically grouping games based on characteristics such as rules and difficulties. Specialized models are then trained for each group to excel at games in the group is what we refer to as the divide step. Next, we fuse model parameters from different groups as a new model, and continue training it for multiple groups, until the scenarios in all groups are conquered. Experiments across 18 TextArena games show that Qwen2.5-32B-Align trained with the Divide-Fuse-Conquer strategy reaches a performance level comparable to Claude3.5, achieving 7 wins and 4 draws. We hope our approach can inspire future research on using reinforcement learning to improve the generalization of LLMs.","authors":["Xiaoqing Zhang","Huabin Zheng","Ang Lv","Yuhan Liu","Zirui Song","Flood Sung","Xiuying Chen","Rui Yan"],"url":"https://arxiv.org/abs/2505.16401"}
{"created":"2025-05-23","title":"AdvReal: Adversarial Patch Generation Framework with Application to Adversarial Safety Evaluation of Object Detection Systems","abstract":"Autonomous vehicles are typical complex intelligent systems with artificial intelligence at their core. However, perception methods based on deep learning are extremely vulnerable to adversarial samples, resulting in safety accidents. How to generate effective adversarial examples in the physical world and evaluate object detection systems is a huge challenge. In this study, we propose a unified joint adversarial training framework for both 2D and 3D samples to address the challenges of intra-class diversity and environmental variations in real-world scenarios. Building upon this framework, we introduce an adversarial sample reality enhancement approach that incorporates non-rigid surface modeling and a realistic 3D matching mechanism. We compare with 5 advanced adversarial patches and evaluate their attack performance on 8 object detecotrs, including single-stage, two-stage, and transformer-based models. Extensive experiment results in digital and physical environments demonstrate that the adversarial textures generated by our method can effectively mislead the target detection model. Moreover, proposed method demonstrates excellent robustness and transferability under multi-angle attacks, varying lighting conditions, and different distance in the physical world. The demo video and code can be obtained at https://github.com/Huangyh98/AdvReal.git.","authors":["Yuanhao Huang","Yilong Ren","Jinlei Wang","Lujia Huo","Xuesong Bai","Jinchuan Zhang","Haiyan Yu"],"url":"https://arxiv.org/abs/2505.16402"}
{"created":"2025-05-23","title":"Performance Guaranteed Poisoning Attacks in Federated Learning: A Sliding Mode Approach","abstract":"Manipulation of local training data and local updates, i.e., the poisoning attack, is the main threat arising from the collaborative nature of the federated learning (FL) paradigm. Most existing poisoning attacks aim to manipulate local data/models in a way that causes denial-of-service (DoS) issues. In this paper, we introduce a novel attack method, named Federated Learning Sliding Attack (FedSA) scheme, aiming at precisely introducing the extent of poisoning in a subtle controlled manner. It operates with a predefined objective, such as reducing global model's prediction accuracy by 10\\%. FedSA integrates robust nonlinear control-Sliding Mode Control (SMC) theory with model poisoning attacks. It can manipulate the updates from malicious clients to drive the global model towards a compromised state, achieving this at a controlled and inconspicuous rate. Additionally, leveraging the robust control properties of FedSA allows precise control over the convergence bounds, enabling the attacker to set the global accuracy of the poisoned model to any desired level. Experimental results demonstrate that FedSA can accurately achieve a predefined global accuracy with fewer malicious clients while maintaining a high level of stealth and adjustable learning rates.","authors":["Huazi Pan","Yanjun Zhang","Leo Yu Zhang","Scott Adams","Abbas Kouzani","Suiyang Khoo"],"url":"https://arxiv.org/abs/2505.16403"}
{"created":"2025-05-23","title":"On the reliability of feature attribution methods for speech classification","abstract":"As the capabilities of large-scale pre-trained models evolve, understanding the determinants of their outputs becomes more important. Feature attribution aims to reveal which parts of the input elements contribute the most to model outputs. In speech processing, the unique characteristics of the input signal make the application of feature attribution methods challenging. We study how factors such as input type and aggregation and perturbation timespan impact the reliability of standard feature attribution methods, and how these factors interact with characteristics of each classification task. We find that standard approaches to feature attribution are generally unreliable when applied to the speech domain, with the exception of word-aligned perturbation methods when applied to word-based classification tasks.","authors":["Gaofei Shen","Hosein Mohebbi","Arianna Bisazza","Afra Alishahi","Grzegorz Chrupa{\\l}a"],"url":"https://arxiv.org/abs/2505.16406"}
{"created":"2025-05-23","title":"Robust Look-ahead Pursuit Control for Three-Dimensional Path Following within Finite-Time Stability Guarantee","abstract":"This paper addresses the challenging problem of robust path following for fixed-wing unmanned aerial vehicles (UAVs) in complex environments with bounded external disturbances and non-smooth predefined paths. Due to the unique aerodynamic characteristics and flight constraints of fixed-wing UAVs, achieving accurate and stable path following remains difficult, especially in low-altitude mountainous terrains, urban landscapes, and under wind disturbances. Traditional path-following guidance laws often struggle with rapid stabilization and constrained input commands under unknown disturbances while maintaining robustness. To overcome these limitations, we propose a robust nonlinear path-following guidance law that considers the flight path angle and track angle, and dynamically adjusts controller parameters to achieve optimal compensation for acceleration increments. The proposed guidance law guarantees finite-time stability, reduced sensitivity to constrained uncertainties, and consistent behavior compared to traditional asymptotic convergence controllers. Additionally, it ensures that the UAV approaches mobile virtual target points in the shortest possible time while adhering to input constrained conditions. Our contributions include a thorough analysis of the conditions for robust stability, the derivation of the guidance law, and simulations demonstrating its effectiveness. The results show that the proposed guidance law significantly improves path-following performance under external disturbances, making it a promising solution for autonomous missions execution of fixed-wing UAVs.","authors":["Zimao Sheng","Hong an Yang","ZiRui Yu","Jiakang Wang"],"url":"https://arxiv.org/abs/2505.16407"}
{"created":"2025-05-23","title":"From Surveys to Narratives: Rethinking Cultural Value Adaptation in LLMs","abstract":"Adapting cultural values in Large Language Models (LLMs) presents significant challenges, particularly due to biases and limited training data. Prior work primarily aligns LLMs with different cultural values using World Values Survey (WVS) data. However, it remains unclear whether this approach effectively captures cultural nuances or produces distinct cultural representations for various downstream tasks. In this paper, we systematically investigate WVS-based training for cultural value adaptation and find that relying solely on survey data can homogenize cultural norms and interfere with factual knowledge. To investigate these issues, we augment WVS with encyclopedic and scenario-based cultural narratives from Wikipedia and NormAd. While these narratives may have variable effects on downstream tasks, they consistently improve cultural distinctiveness than survey data alone. Our work highlights the inherent complexity of aligning cultural values with the goal of guiding task-specific behavior.","authors":["Muhammad Farid Adilazuarda","Chen Cecilia Liu","Iryna Gurevych","Alham Fikri Aji"],"url":"https://arxiv.org/abs/2505.16408"}
{"created":"2025-05-23","title":"FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS","abstract":"Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in multi-step reasoning and calling search engines at appropriate steps. However, existing retrieval-augmented reasoning approaches rely on separate retrieval models, limiting the LRM's role in retrieval to deciding when to retrieve and how to query. This separation not only increases hardware and operational costs but also leads to errors in the retrieval process due to the representation bottleneck, a phenomenon where the retriever's embedding space is not expressive enough to meet the generator's requirements. To address this, we shift our perspective from sequence-to-sequence matching to locating the answer-containing paths within the corpus, and propose a novel framework called FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables LRMs to retrieve relevant knowledge on their own by acting as both a generator and retriever. To achieve this, we introduce a variant of the MCTS algorithm specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus toward answer-containing regions. Our results on five open-domain QA benchmarks, including single-hop and multi-hop questions, show that FREESON achieves an average improvement of 14.4% in EM and F1 over four multi-step reasoning models with a separate retriever, and it also performs comparably to the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.","authors":["Chaeeun Kim","Seungone Kim"],"url":"https://arxiv.org/abs/2505.16409"}
{"created":"2025-05-23","title":"Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement Learning","abstract":"Recently, large language models (LLMs) have shown remarkable reasoning capabilities via large-scale reinforcement learning (RL). However, leveraging the RL algorithm to empower effective multi-tool collaborative reasoning in LLMs remains an open challenge. In this paper, we introduce Tool-Star, an RL-based framework designed to empower LLMs to autonomously invoke multiple external tools during stepwise reasoning. Tool-Star integrates six types of tools and incorporates systematic designs in both data synthesis and training. To address the scarcity of tool-use data, we propose a general tool-integrated reasoning data synthesis pipeline, which combines tool-integrated prompting with hint-based sampling to automatically and scalably generate tool-use trajectories. A subsequent quality normalization and difficulty-aware classification process filters out low-quality samples and organizes the dataset from easy to hard. Furthermore, we propose a two-stage training framework to enhance multi-tool collaborative reasoning by: (1) cold-start fine-tuning, which guides LLMs to explore reasoning patterns via tool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with hierarchical reward design, which reinforces reward understanding and promotes effective tool collaboration. Experimental analyses on over 10 challenging reasoning benchmarks highlight the effectiveness and efficiency of Tool-Star. The code is available at https://github.com/dongguanting/Tool-Star.","authors":["Guanting Dong","Yifei Chen","Xiaoxi Li","Jiajie Jin","Hongjin Qian","Yutao Zhu","Hangyu Mao","Guorui Zhou","Zhicheng Dou","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.16410"}
{"created":"2025-05-23","title":"Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression","abstract":"Despite their remarkable progress in multimodal understanding tasks, large vision language models (LVLMs) often suffer from \"hallucinations\", generating texts misaligned with the visual context. Existing methods aimed at reducing hallucinations through inference time intervention incur a significant increase in latency. To mitigate this, we present SPIN, a task-agnostic attention-guided head suppression strategy that can be seamlessly integrated during inference, without incurring any significant compute or latency overhead. We investigate whether hallucination in LVLMs can be linked to specific model components. Our analysis suggests that hallucinations can be attributed to a dynamic subset of attention heads in each layer. Leveraging this insight, for each text query token, we selectively suppress attention heads that exhibit low attention to image tokens, keeping the top-K attention heads intact. Extensive evaluations on visual question answering and image description tasks demonstrate the efficacy of SPIN in reducing hallucination scores up to 2.7x while maintaining F1, and improving throughput by 1.8x compared to existing alternatives. Code is available at https://github.com/YUECHE77/SPIN.","authors":["Sreetama Sarkar","Yue Che","Alex Gavin","Peter A. Beerel","Souvik Kundu"],"url":"https://arxiv.org/abs/2505.16411"}
{"created":"2025-05-23","title":"Pose-invariant face recognition via feature-space pose frontalization","abstract":"Pose-invariant face recognition has become a challenging problem for modern AI-based face recognition systems. It aims at matching a profile face captured in the wild with a frontal face registered in a database. Existing methods perform face frontalization via either generative models or learning a pose robust feature representation. In this paper, a new method is presented to perform face frontalization and recognition within the feature space. First, a novel feature space pose frontalization module (FSPFM) is proposed to transform profile images with arbitrary angles into frontal counterparts. Second, a new training paradigm is proposed to maximize the potential of FSPFM and boost its performance. The latter consists of a pre-training and an attention-guided fine-tuning stage. Moreover, extensive experiments have been conducted on five popular face recognition benchmarks. Results show that not only our method outperforms the state-of-the-art in the pose-invariant face recognition task but also maintains superior performance in other standard scenarios.","authors":["Nikolay Stanishev","Yuhang Lu","Touradj Ebrahimi"],"url":"https://arxiv.org/abs/2505.16412"}
{"created":"2025-05-23","title":"TAPAS: A Pattern-Based Approach to Assessing Government Transparency","abstract":"Government transparency, widely recognized as a cornerstone of open government, depends on robust information management practices. Yet effective assessment of information management remains challenging, as existing methods fail to consider the actual working behavior of civil servants and are resource-intensive. Using a design science research approach, we present the Transparency Anti-Pattern Assessment System (TAPAS) -- a novel, data-driven methodology designed to evaluate government transparency through the identification of behavioral patterns that impede transparency. We demonstrate TAPAS's real-world applicability at a Dutch ministry, analyzing their electronic document management system data from the past two decades. We identify eight transparency anti-patterns grouped into four categories: Incomplete Documentation, Limited Accessibility, Unclear Information, and Delayed Documentation. We show that TAPAS enables continuous monitoring and provides actionable insights without requiring significant resource investments.","authors":["Jos Zuijderwijk","Iris Beerepoot","Thomas Martens","Eva Knies","Tanja van der Lippe","Hajo A. Reijers"],"url":"https://arxiv.org/abs/2505.16413"}
{"created":"2025-05-23","title":"Attributing Response to Context: A Jensen-Shannon Divergence Driven Mechanistic Study of Context Attribution in Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) leverages large language models (LLMs) combined with external contexts to enhance the accuracy and reliability of generated responses. However, reliably attributing generated content to specific context segments, context attribution, remains challenging due to the computationally intensive nature of current methods, which often require extensive fine-tuning or human annotation. In this work, we introduce a novel Jensen-Shannon Divergence driven method to Attribute Response to Context (ARC-JSD), enabling efficient and accurate identification of essential context sentences without additional fine-tuning or surrogate modelling. Evaluations on a wide range of RAG benchmarks, such as TyDi QA, Hotpot QA, and Musique, using instruction-tuned LLMs in different scales demonstrate superior accuracy and significant computational efficiency improvements compared to the previous surrogate-based method. Furthermore, our mechanistic analysis reveals specific attention heads and multilayer perceptron (MLP) layers responsible for context attribution, providing valuable insights into the internal workings of RAG models.","authors":["Ruizhe Li","Chen Chen","Yuchen Hu","Yanjun Gao","Xi Wang","Emine Yilmaz"],"url":"https://arxiv.org/abs/2505.16415"}
{"created":"2025-05-23","title":"Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models","abstract":"Rotary Position Embedding (RoPE) is a widely adopted technique for encoding relative positional information in large language models (LLMs). However, when extended to large vision-language models (LVLMs), its variants introduce unintended cross-modal positional biases. Specifically, they enforce relative positional dependencies between text token indices and image tokens, causing spurious alignments. This issue arises because image tokens representing the same content but located at different spatial positions are assigned distinct positional biases, leading to inconsistent cross-modal associations. To address this, we propose Per-Token Distance (PTD) - a simple yet effective metric for quantifying the independence of positional encodings across modalities. Informed by this analysis, we introduce Circle-RoPE, a novel encoding scheme that maps image token indices onto a circular trajectory orthogonal to the linear path of text token indices, forming a cone-like structure. This configuration ensures that each text token maintains an equal distance to all image tokens, reducing artificial cross-modal biases while preserving intra-image spatial information. To further enhance performance, we propose a staggered layer strategy that applies different RoPE variants across layers. This design leverages the complementary strengths of each RoPE variant, thereby enhancing the model's overall performance. Our experimental results demonstrate that our method effectively preserves spatial information from images while reducing relative positional bias, offering a more robust and flexible positional encoding framework for LVLMs. The code is available at [https://github.com/lose4578/CircleRoPE](https://github.com/lose4578/CircleRoPE).","authors":["Chengcheng Wang","Jianyuan Guo","Hongguang Li","Yuchuan Tian","Ying Nie","Chang Xu","Kai Han"],"url":"https://arxiv.org/abs/2505.16416"}
{"created":"2025-05-23","title":"Exploring the Relationship Between Diversity and Quality in Ad Text Generation","abstract":"In natural language generation for advertising, creating diverse and engaging ad texts is crucial for capturing a broad audience and avoiding advertising fatigue. Regardless of the importance of diversity, the impact of the diversity-enhancing methods in ad text generation -- mainly tested on tasks such as summarization and machine translation -- has not been thoroughly explored. Ad text generation significantly differs from these tasks owing to the text style and requirements. This research explores the relationship between diversity and ad quality in ad text generation by considering multiple factors, such as diversity-enhancing methods, their hyperparameters, input-output formats, and the models.","authors":["Yoichi Aoki","Soichiro Murakami","Ukyo Honda","Akihiko Kato"],"url":"https://arxiv.org/abs/2505.16418"}
{"created":"2025-05-23","title":"Investigating Fine- and Coarse-grained Structural Correspondences Between Deep Neural Networks and Human Object Image Similarity Judgments Using Unsupervised Alignment","abstract":"The learning mechanisms by which humans acquire internal representations of objects are not fully understood. Deep neural networks (DNNs) have emerged as a useful tool for investigating this question, as they have internal representations similar to those of humans as a byproduct of optimizing their objective functions. While previous studies have shown that models trained with various learning paradigms - such as supervised, self-supervised, and CLIP - acquire human-like representations, it remains unclear whether their similarity to human representations is primarily at a coarse category level or extends to finer details. Here, we employ an unsupervised alignment method based on Gromov-Wasserstein Optimal Transport to compare human and model object representations at both fine-grained and coarse-grained levels. The unique feature of this method compared to conventional representational similarity analysis is that it estimates optimal fine-grained mappings between the representation of each object in human and model representations. We used this unsupervised alignment method to assess the extent to which the representation of each object in humans is correctly mapped to the corresponding representation of the same object in models. Using human similarity judgments of 1,854 objects from the THINGS dataset, we find that models trained with CLIP consistently achieve strong fine- and coarse-grained matching with human object representations. In contrast, self-supervised models showed limited matching at both fine- and coarse-grained levels, but still formed object clusters that reflected human coarse category structure. Our results offer new insights into the role of linguistic information in acquiring precise object representations and the potential of self-supervised learning to capture coarse categorical structures.","authors":["Soh Takahashi","Masaru Sasaki","Ken Takeda","Masafumi Oizumi"],"url":"https://arxiv.org/abs/2505.16419"}
{"created":"2025-05-23","title":"WebAgent-R1: Training Web Agents via End-to-End Multi-Turn Reinforcement Learning","abstract":"While reinforcement learning (RL) has demonstrated remarkable success in enhancing large language models (LLMs), it has primarily focused on single-turn tasks such as solving math problems. Training effective web agents for multi-turn interactions remains challenging due to the complexity of long-horizon decision-making across dynamic web interfaces. In this work, we present WebAgent-R1, a simple yet effective end-to-end multi-turn RL framework for training web agents. It learns directly from online interactions with web environments by asynchronously generating diverse trajectories, entirely guided by binary rewards depending on task success. Experiments on the WebArena-Lite benchmark demonstrate the effectiveness of WebAgent-R1, boosting the task success rate of Qwen-2.5-3B from 6.1% to 33.9% and Llama-3.1-8B from 8.5% to 44.8%, significantly outperforming existing state-of-the-art methods and strong proprietary models such as OpenAI o3. In-depth analyses reveal the effectiveness of the thinking-based prompting strategy and test-time scaling through increased interactions for web tasks. We further investigate different RL initialization policies by introducing two variants, namely WebAgent-R1-Zero and WebAgent-R1-CoT, which highlight the importance of the warm-up training stage (i.e., behavior cloning) and provide insights on incorporating long chain-of-thought (CoT) reasoning in web agents.","authors":["Zhepei Wei","Wenlin Yao","Yao Liu","Weizhi Zhang","Qin Lu","Liang Qiu","Changlong Yu","Puyang Xu","Chao Zhang","Bing Yin","Hyokun Yun","Lihong Li"],"url":"https://arxiv.org/abs/2505.16421"}
{"created":"2025-05-23","title":"Unlocking Smarter Device Control: Foresighted Planning with a World Model-Driven Code Execution Approach","abstract":"The automatic control of mobile devices is essential for efficiently performing complex tasks that involve multiple sequential steps. However, these tasks pose significant challenges due to the limited environmental information available at each step, primarily through visual observations. As a result, current approaches, which typically rely on reactive policies, focus solely on immediate observations and often lead to suboptimal decision-making. To address this problem, we propose \\textbf{Foresighted Planning with World Model-Driven Code Execution (FPWC)},a framework that prioritizes natural language understanding and structured reasoning to enhance the agent's global understanding of the environment by developing a task-oriented, refinable \\emph{world model} at the outset of the task. Foresighted actions are subsequently generated through iterative planning within this world model, executed in the form of executable code. Extensive experiments conducted in simulated environments and on real mobile devices demonstrate that our method outperforms previous approaches, particularly achieving a 44.4\\% relative improvement in task success rate compared to the state-of-the-art in the simulated environment. Code and demo are provided in the supplementary material.","authors":["Xiaoran Yin","Xu Luo","Hao Wu","Lianli Gao","Jingkuan Song"],"url":"https://arxiv.org/abs/2505.16422"}
{"created":"2025-05-23","title":"Web Element Relocalization in Evolving Web Applications: A Comparative Analysis and Extension Study","abstract":"Fragile web tests, primarily caused by locator breakages, are a persistent challenge in web development. Hence, researchers have proposed techniques for web-element re-identification in which algorithms utilize a range of element properties to relocate elements on updated versions of websites based on similarity scoring. In this paper, we replicate the original studies of the most recent propositions in the literature, namely the Similo algorithm and its successor, VON Similo. We also acknowledge and reconsider assumptions related to threats to validity in the original studies, which prompted additional analysis and the development of mitigation techniques. Our analysis revealed that VON Similo, despite its novel approach, tends to produce more false positives than Similo. We mitigated these issues through algorithmic refinements and optimization algorithms that enhance parameters and comparison methods across all Similo variants, improving the accuracy of Similo on its original benchmark by 5.62%. Moreover, we extend the replicated studies by proposing a larger evaluation benchmark (23x bigger than the original study) as well as a novel approach that combines the strengths of both Similo and VON Similo, called HybridSimilo. The combined approach achieved a gain comparable to the improved Similo alone. Results on the extended benchmark show that HybridSimilo locates 98.8% of elements with broken locators in realistic testing scenarios.","authors":["Anton Kluge","Andrea Stocco"],"url":"https://arxiv.org/abs/2505.16424"}
{"created":"2025-05-23","title":"$I^2G$: Generating Instructional Illustrations via Text-Conditioned Diffusion","abstract":"The effective communication of procedural knowledge remains a significant challenge in natural language processing (NLP), as purely textual instructions often fail to convey complex physical actions and spatial relationships. We address this limitation by proposing a language-driven framework that translates procedural text into coherent visual instructions. Our approach models the linguistic structure of instructional content by decomposing it into goal statements and sequential steps, then conditioning visual generation on these linguistic elements. We introduce three key innovations: (1) a constituency parser-based text encoding mechanism that preserves semantic completeness even with lengthy instructions, (2) a pairwise discourse coherence model that maintains consistency across instruction sequences, and (3) a novel evaluation protocol specifically designed for procedural language-to-image alignment. Our experiments across three instructional datasets (HTStep, CaptainCook4D, and WikiAll) demonstrate that our method significantly outperforms existing baselines in generating visuals that accurately reflect the linguistic content and sequential nature of instructions. This work contributes to the growing body of research on grounding procedural language in visual content, with applications spanning education, task guidance, and multimodal language understanding.","authors":["Jing Bi","Pinxin Liu","Ali Vosoughi","Jiarui Wu","Jinxi He","Chenliang Xu"],"url":"https://arxiv.org/abs/2505.16425"}
{"created":"2025-05-23","title":"Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems","abstract":"Evaluating and iterating upon recommender systems is crucial, yet traditional A/B testing is resource-intensive, and offline methods struggle with dynamic user-platform interactions. While agent-based simulation is promising, existing platforms often lack a mechanism for user actions to dynamically reshape the environment. To bridge this gap, we introduce RecInter, a novel agent-based simulation platform for recommender systems featuring a robust interaction mechanism. In RecInter platform, simulated user actions (e.g., likes, reviews, purchases) dynamically update item attributes in real-time, and introduced Merchant Agents can reply, fostering a more realistic and evolving ecosystem. High-fidelity simulation is ensured through Multidimensional User Profiling module, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought (CoT) enriched interaction data. Our platform achieves significantly improved simulation credibility and successfully replicates emergent phenomena like Brand Loyalty and the Matthew Effect. Experiments demonstrate that this interaction mechanism is pivotal for simulating realistic system evolution, establishing our platform as a credible testbed for recommender systems research.","authors":["Song Jin","Juntian Zhang","Yuhan Liu","Xun Zhang","Yufei Zhang","Guojun Yin","Fei Jiang","Wei Lin","Rui Yan"],"url":"https://arxiv.org/abs/2505.16429"}
{"created":"2025-05-23","title":"AutoMCQ -- Automatically Generate Code Comprehension Questions using GenAI","abstract":"Students often do not fully understand the code they have written. This sometimes does not become evident until later in their education, which can mean it is harder to fix their incorrect knowledge or misunderstandings. In addition, being able to fully understand code is increasingly important in a world where students have access to generative artificial intelligence (GenAI) tools, such as GitHub Copilot. One effective solution is to utilise code comprehension questions, where a marker asks questions about a submission to gauge understanding, this can also have the side effect of helping to detect plagiarism. However, this approach is time consuming and can be difficult and/or expensive to scale. This paper introduces AutoMCQ, which uses GenAI for the automatic generation of multiple-choice code comprehension questions. This is integrated with the CodeRunner automated assessment platform.","authors":["Martin Goodfellow","Robbie Booth","Andrew Fagan","Alasdair Lambert"],"url":"https://arxiv.org/abs/2505.16430"}
{"created":"2025-05-23","title":"On the Two Paths Theorem and the Two Disjoint Paths Problem","abstract":"A tuple (s1,t1,s2,t2) of vertices in a simple undirected graph is 2-linked when there are two vertex-disjoint paths respectively from s1 to t1 and s2 to t2. A graph is 2-linked when all such tuples are 2-linked. We give a new and simple proof of the ``two paths theorem'', a characterisation of edge-maximal graphs which are not 2-linked as webs: particular near triangulations filled with cliques. Our proof works by generalising the theorem, replacing the four vertices above by an arbitrary tuple; it does not require major theorems such as Kuratowski's or Menger's theorems. Instead it follows an inductive characterisation of generalised webs via parallel composition, a graph operation consisting in taking a disjoint union before identifying some pairs of vertices. We use the insights provided by this proof to design a simple O(nm) recursive algorithm for the ``two vertex-disjoint paths'' problem. This algorithm is constructive in that it returns either two disjoint paths, or an embedding of the input graph into a web.","authors":["Samuel Humeau (ENS de Lyon","LIP","PLUME)","Damien Pous (PLUME","LIP","ENS de Lyon)"],"url":"https://arxiv.org/abs/2505.16431"}
{"created":"2025-05-23","title":"Joint Flow And Feature Refinement Using Attention For Video Restoration","abstract":"Recent advancements in video restoration have focused on recovering high-quality video frames from low-quality inputs. Compared with static images, the performance of video restoration significantly depends on efficient exploitation of temporal correlations among successive video frames. The numerous techniques make use of temporal information via flow-based strategies or recurrent architectures. However, these methods often encounter difficulties in preserving temporal consistency as they utilize degraded input video frames. To resolve this issue, we propose a novel video restoration framework named Joint Flow and Feature Refinement using Attention (JFFRA). The proposed JFFRA is based on key philosophy of iteratively enhancing data through the synergistic collaboration of flow (alignment) and restoration. By leveraging previously enhanced features to refine flow and vice versa, JFFRA enables efficient feature enhancement using temporal information. This interplay between flow and restoration is executed at multiple scales, reducing the dependence on precise flow estimation. Moreover, we incorporate an occlusion-aware temporal loss function to enhance the network's capability in eliminating flickering artifacts. Comprehensive experiments validate the versatility of JFFRA across various restoration tasks such as denoising, deblurring, and super-resolution. Our method demonstrates a remarkable performance improvement of up to 1.62 dB compared to state-of-the-art approaches.","authors":["Ranjith Merugu","Mohammad Sameer Suhail","Akshay P Sarashetti","Venkata Bharath Reddy Reddem","Pankaj Kumar Bajpai","Amit Satish Unde"],"url":"https://arxiv.org/abs/2505.16434"}
{"created":"2025-05-23","title":"Password Strength Detection via Machine Learning: Analysis, Modeling, and Evaluation","abstract":"As network security issues continue gaining prominence, password security has become crucial in safeguarding personal information and network systems. This study first introduces various methods for system password cracking, outlines password defense strategies, and discusses the application of machine learning in the realm of password security. Subsequently, we conduct a detailed public password database analysis, uncovering standard features and patterns among passwords. We extract multiple characteristics of passwords, including length, the number of digits, the number of uppercase and lowercase letters, and the number of special characters. We then experiment with six different machine learning algorithms: support vector machines, logistic regression, neural networks, decision trees, random forests, and stacked models, evaluating each model's performance based on various metrics, including accuracy, recall, and F1 score through model validation and hyperparameter tuning. The evaluation results on the test set indicate that decision trees and stacked models excel in accuracy, recall, and F1 score, making them a practical option for the strong and weak password classification task.","authors":["Jiazhi Mo","Hailu Kuang","Xiaoqi Li"],"url":"https://arxiv.org/abs/2505.16439"}
{"created":"2025-05-23","title":"Ranked Entropy Minimization for Continual Test-Time Adaptation","abstract":"Test-time adaptation aims to adapt to realistic environments in an online manner by learning during test time. Entropy minimization has emerged as a principal strategy for test-time adaptation due to its efficiency and adaptability. Nevertheless, it remains underexplored in continual test-time adaptation, where stability is more important. We observe that the entropy minimization method often suffers from model collapse, where the model converges to predicting a single class for all images due to a trivial solution. We propose ranked entropy minimization to mitigate the stability problem of the entropy minimization method and extend its applicability to continuous scenarios. Our approach explicitly structures the prediction difficulty through a progressive masking strategy. Specifically, it gradually aligns the model's probability distributions across different levels of prediction difficulty while preserving the rank order of entropy. The proposed method is extensively evaluated across various benchmarks, demonstrating its effectiveness through empirical results. Our code is available at https://github.com/pilsHan/rem","authors":["Jisu Han","Jaemin Na","Wonjun Hwang"],"url":"https://arxiv.org/abs/2505.16441"}
{"created":"2025-05-23","title":"MAFE R-CNN: Selecting More Samples to Learn Category-aware Features for Small Object Detection","abstract":"Small object detection in intricate environments has consistently represented a major challenge in the field of object detection. In this paper, we identify that this difficulty stems from the detectors' inability to effectively learn discriminative features for objects of small size, compounded by the complexity of selecting high-quality small object samples during training, which motivates the proposal of the Multi-Clue Assignment and Feature Enhancement R-CNN.Specifically, MAFE R-CNN integrates two pivotal components.The first is the Multi-Clue Sample Selection (MCSS) strategy, in which the Intersection over Union (IoU) distance, predicted category confidence, and ground truth region sizes are leveraged as informative clues in the sample selection process. This methodology facilitates the selection of diverse positive samples and ensures a balanced distribution of object sizes during training, thereby promoting effective model learning.The second is the Category-aware Feature Enhancement Mechanism (CFEM), where we propose a simple yet effective category-aware memory module to explore the relationships among object features. Subsequently, we enhance the object feature representation by facilitating the interaction between category-aware features and candidate box features.Comprehensive experiments conducted on the large-scale small object dataset SODA validate the effectiveness of the proposed method. The code will be made publicly available.","authors":["Yichen Li","Qiankun Liu","Zhenchao Jin","Jiuzhe Wei","Jing Nie","Ying Fu"],"url":"https://arxiv.org/abs/2505.16442"}
{"created":"2025-05-23","title":"Stochastic collocation schemes for Neural Field Equations with random data","abstract":"We develop and analyse numerical schemes for uncertainty quantification in neural field equations subject to random parametric data in the synaptic kernel, firing rate, external stimulus, and initial conditions. The schemes combine a generic projection method for spatial discretisation to a stochastic collocation scheme for the random variables. We study the problem in operator form, and derive estimates for the total error of the schemes, in terms of the spatial projector. We give conditions on the projected random data which guarantee analyticity of the semi-discrete solution as a Banach-valued function. We illustrate how to verify hypotheses starting from analytic random data and a choice of spatial projection. We provide evidence that the predicted convergence rates are found in various numerical experiments for linear and nonlinear neural field problems.","authors":["Daniele Avitabile","Francesca Cavallini","Svetlana Dubinkina","Gabriel J. Lord"],"url":"https://arxiv.org/abs/2505.16443"}
{"created":"2025-05-23","title":"DAS-MP: Enabling High-Quality Macro Placement with Enhanced Dataflow Awareness","abstract":"Dataflow is a critical yet underexplored factor in automatic macro placement, which is becoming increasingly important for developing intelligent design automation techniques that minimize reliance on manual adjustments and reduce design iterations. Existing macro or mixed-size placers with dataflow awareness primarily focus on intrinsic relationships among macros, overlooking the crucial influence of standard cell clusters on macro placement. To address this, we propose DAS-MP, which extracts hidden connections between macros and standard cells and incorporates a series of algorithms to enhance dataflow awareness, integrating them into placement constraints for improved macro placement. To further optimize placement results, we introduce two fine-tuning steps: (1) congestion optimization by taking macro area into consideration, and (2) flipping decisions to determine the optimal macro orientation based on the extracted dataflow information. By integrating enhanced dataflow awareness into placement constraints and applying these fine-tuning steps, the proposed approach achieves an average 7.9% improvement in half-perimeter wirelength (HPWL) across multiple widely used benchmark designs compared to a state-of-the-art dataflow-aware macro placer. Additionally, it significantly improves congestion, reducing overflow by an average of 82.5%, and achieves improvements of 36.97% in Worst Negative Slack (WNS) and 59.44% in Total Negative Slack (TNS). The approach also maintains efficient runtime throughout the entire placement process, incurring less than a 1.5% runtime overhead. These results show that the proposed dataflow-driven methodology, combined with the fine-tuning steps, provides an effective foundation for macro placement and can be seamlessly integrated into existing design flows to enhance placement quality.","authors":["Xiaotian Zhao","Zixuan Li","Yichen Cai","Tianju Wang","Yushan Pan","Xinfei Guo"],"url":"https://arxiv.org/abs/2505.16445"}
{"created":"2025-05-23","title":"Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models","abstract":"Multimodal large language models (MLLMs) enable powerful cross-modal reasoning capabilities. However, the expanded input space introduces new attack surfaces. Previous jailbreak attacks often inject malicious instructions from text into less aligned modalities, such as vision. As MLLMs increasingly incorporate cross-modal consistency and alignment mechanisms, such explicit attacks become easier to detect and block. In this work, we propose a novel implicit jailbreak framework termed IJA that stealthily embeds malicious instructions into images via least significant bit steganography and couples them with seemingly benign, image-related textual prompts. To further enhance attack effectiveness across diverse MLLMs, we incorporate adversarial suffixes generated by a surrogate model and introduce a template optimization module that iteratively refines both the prompt and embedding based on model feedback. On commercial models like GPT-4o and Gemini-1.5 Pro, our method achieves attack success rates of over 90% using an average of only 3 queries.","authors":["Zhaoxin Wang","Handing Wang","Cong Tian","Yaochu Jin"],"url":"https://arxiv.org/abs/2505.16446"}
{"created":"2025-05-23","title":"TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition","abstract":"TAT-VPR is a ternary-quantized transformer that brings dynamic accuracy-efficiency trade-offs to visual SLAM loop-closure. By fusing ternary weights with a learned activation-sparsity gate, the model can control computation by up to 40% at run-time without degrading performance (Recall@1). The proposed two-stage distillation pipeline preserves descriptor quality, letting it run on micro-UAV and embedded SLAM stacks while matching state-of-the-art localization accuracy.","authors":["Oliver Grainge","Michael Milford","Indu Bodala","Sarvapali D. Ramchurn","Shoaib Ehsan"],"url":"https://arxiv.org/abs/2505.16447"}
{"created":"2025-05-23","title":"Internal Bias in Reasoning Models leads to Overthinking","abstract":"While current reasoning models possess strong exploratory capabilities, they are often criticized for overthinking due to redundant and unnecessary reflections. In this work, we reveal for the first time that overthinking in reasoning models may stem from their internal bias towards input texts. Upon encountering a reasoning problem, the model immediately forms a preliminary guess about the answer, which we term as an internal bias since it is not derived through actual reasoning. When this guess conflicts with its reasoning result, the model tends to engage in reflection, leading to the waste of computational resources. Through further interpretability experiments, we find that this behavior is largely driven by the model's excessive attention to the input section, which amplifies the influence of internal bias on its decision-making process. Additionally, by masking out the original input section, the affect of internal bias can be effectively alleviated and the reasoning length could be reduced by 31%-53% across different complex reasoning tasks. Notably, in most cases, this approach also leads to improvements in accuracy. These findings demonstrate a causal relationship between internal bias and overthinking.","authors":["Renfei Dang","Shujian Huang","Jiajun Chen"],"url":"https://arxiv.org/abs/2505.16448"}
{"created":"2025-05-23","title":"CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI","abstract":"Accurate and efficient quantification of cardiac function is essential for the estimation of prognosis of cardiovascular diseases (CVDs). One of the most commonly used metrics for evaluating cardiac pumping performance is left ventricular ejection fraction (LVEF). However, LVEF can be affected by factors such as inter-observer variability and varying pre-load and after-load conditions, which can reduce its reproducibility. Additionally, cardiac dysfunction may not always manifest as alterations in LVEF, such as in heart failure and cardiotoxicity diseases. An alternative measure that can provide a relatively load-independent quantitative assessment of myocardial contractility is myocardial strain and strain rate. By using LVEF in combination with myocardial strain, it is possible to obtain a thorough description of cardiac function. Automated estimation of LVEF and other volumetric measures from cine-MRI sequences can be achieved through segmentation models, while strain calculation requires the estimation of tissue displacement between sequential frames, which can be accomplished using registration models. These tasks are often performed separately, potentially limiting the assessment of cardiac function. To address this issue, in this study we propose an end-to-end deep learning (DL) model that jointly estimates groupwise (GW) registration and segmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep GW network was trained and validated on a large dataset of 4-chamber view cine-MRI image series of 374 subjects. A quantitative comparison with conventional GW registration using elastix and two DL-based methods showed that the proposed model improved performance and substantially reduced computation time.","authors":["Mohamed S. Elmahdy","Marius Staring","Patrick J. H. de Koning","Samer Alabed","Mahan Salehi","Faisal Alandejani","Michael Sharkey","Ziad Aldabbagh","Andrew J. Swift","Rob J. van der Geest"],"url":"https://arxiv.org/abs/2505.16452"}
{"created":"2025-05-23","title":"SpineWave: Harnessing Fish Rigid-Flexible Spinal Kinematics for Enhancing Biomimetic Robotic Locomotion","abstract":"Fish have endured millions of years of evolution, and their distinct rigid-flexible body structures offer inspiration for overcoming challenges in underwater robotics, such as limited mobility, high energy consumption, and adaptability. This paper introduces SpineWave, a biomimetic robotic fish featuring a fish-spine-like rigid-flexible transition structure. The structure integrates expandable fishbone-like ribs and adjustable magnets, mimicking the stretch and recoil of fish muscles to balance rigidity and flexibility. In addition, we employed an evolutionary algorithm to optimize the hydrodynamics of the robot, achieving significant improvements in swimming performance. Real-world tests demonstrated robustness and potential for environmental monitoring, underwater exploration, and industrial inspection. These tests established SpineWave as a transformative platform for aquatic robotics.","authors":["Qu He","Weikun Li","Guangmin Dai","Hao Chen","Qimeng Liu","Xiaoqing Tian","Jie You","Weicheng Cui","Michael S. Triantafyllou","Dixia Fan"],"url":"https://arxiv.org/abs/2505.16453"}
{"created":"2025-05-23","title":"Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events","abstract":"During sudden disaster events, accurately predicting public panic sentiment on social media is crucial for proactive governance and crisis management. Current efforts on this problem face three main challenges: lack of finely annotated data hinders emotion prediction studies, unmodeled risk perception causes prediction inaccuracies, and insufficient interpretability of panic formation mechanisms. We address these issues by proposing a Psychology-driven generative Agent framework (PsychoAgent) for explainable panic prediction based on emotion arousal theory. Specifically, we first construct a fine-grained open panic emotion dataset (namely COPE) via human-large language models (LLMs) collaboration to mitigate semantic bias. Then, we develop a framework integrating cross-domain heterogeneous data grounded in psychological mechanisms to model risk perception and cognitive differences in emotion generation. To enhance interpretability, we design an LLM-based role-playing agent that simulates individual psychological chains through dedicatedly designed prompts. Experimental results on our annotated dataset show that PsychoAgent improves panic emotion prediction performance by 12.6% to 21.7% compared to baseline models. Furthermore, the explainability and generalization of our approach is validated. Crucially, this represents a paradigm shift from opaque \"data-driven fitting\" to transparent \"role-based simulation with mechanistic interpretation\" for panic emotion prediction during emergencies. Our implementation is publicly available at: https://anonymous.4open.science/r/PsychoAgent-19DD.","authors":["Mengzhu Liu","Zhengqiu Zhu","Chuan Ai","Chen Gao","Xinghong Li","Lingnan He","Kaisheng Lai","Yingfeng Chen","Xin Lu","Yong Li","Quanjun Yin"],"url":"https://arxiv.org/abs/2505.16455"}
{"created":"2025-05-23","title":"MAGIC: Motion-Aware Generative Inference via Confidence-Guided LLM","abstract":"Recent advances in static 3D generation have intensified the demand for physically consistent dynamic 3D content. However, existing video generation models, including diffusion-based methods, often prioritize visual realism while neglecting physical plausibility, resulting in implausible object dynamics. Prior approaches for physics-aware dynamic generation typically rely on large-scale annotated datasets or extensive model fine-tuning, which imposes significant computational and data collection burdens and limits scalability across scenarios. To address these challenges, we present MAGIC, a training-free framework for single-image physical property inference and dynamic generation, integrating pretrained image-to-video diffusion models with iterative LLM-based reasoning. Our framework generates motion-rich videos from a static image and closes the visual-to-physical gap through a confidence-driven LLM feedback loop that adaptively steers the diffusion model toward physics-relevant motion. To translate visual dynamics into controllable physical behavior, we further introduce a differentiable MPM simulator operating directly on 3D Gaussians reconstructed from the single image, enabling physically grounded, simulation-ready outputs without any supervision or model tuning. Experiments show that MAGIC outperforms existing physics-aware generative methods in inference accuracy and achieves greater temporal coherence than state-of-the-art video diffusion models.","authors":["Siwei Meng","Yawei Luo","Ping Liu"],"url":"https://arxiv.org/abs/2505.16456"}
{"created":"2025-05-23","title":"MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks","abstract":"Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled unified processing of language, vision, and structured inputs, opening the door to complex tasks such as logical deduction, spatial reasoning, and scientific analysis. Despite their promise, the reasoning capabilities of MLLMs, particularly those augmented with intermediate thinking traces (MLLMs-T), remain poorly understood and lack standardized evaluation benchmarks. Existing work focuses primarily on perception or final answer correctness, offering limited insight into how models reason or fail across modalities. To address this gap, we introduce the MMMR, a new benchmark designed to rigorously evaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a high-difficulty dataset of 1,083 questions spanning six diverse reasoning types with symbolic depth and multi-hop demands and 2) a modular Reasoning Trace Evaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy through metrics like relevance, consistency, and structured error annotations. Empirical results show that MLLMs-T overall outperform non-thinking counterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro suffer from reasoning pathologies such as inconsistency and overthinking. This benchmark reveals persistent gaps between accuracy and reasoning quality and provides an actionable evaluation pipeline for future model development. Overall, the MMMR offers a scalable foundation for evaluating, comparing, and improving the next generation of multi-modal reasoning systems.","authors":["Guiyao Tie","Xueyang Zhou","Tianhe Gu","Ruihang Zhang","Chaoran Hu","Sizhe Zhang","Mengqu Sun","Yan Zhang","Pan Zhou","Lichao Sun"],"url":"https://arxiv.org/abs/2505.16459"}
{"created":"2025-05-23","title":"University of Indonesia at SemEval-2025 Task 11: Evaluating State-of-the-Art Encoders for Multi-Label Emotion Detection","abstract":"This paper presents our approach for SemEval 2025 Task 11 Track A, focusing on multilabel emotion classification across 28 languages. We explore two main strategies: fully fine-tuning transformer models and classifier-only training, evaluating different settings such as fine-tuning strategies, model architectures, loss functions, encoders, and classifiers. Our findings suggest that training a classifier on top of prompt-based encoders such as mE5 and BGE yields significantly better results than fully fine-tuning XLMR and mBERT. Our best-performing model on the final leaderboard is an ensemble combining multiple BGE models, where CatBoost serves as the classifier, with different configurations. This ensemble achieves an average F1-macro score of 56.58 across all languages.","authors":["Ikhlasul Akmal Hanif","Eryawan Presma Yulianrifat","Jaycent Gunawan Ongris","Eduardus Tjitrahardja","Muhammad Falensi Azmi","Rahmat Bryan Naufal","Alfan Farizki Wicaksono"],"url":"https://arxiv.org/abs/2505.16460"}
{"created":"2025-05-23","title":"AnchorFormer: Differentiable Anchor Attention for Efficient Vision Transformer","abstract":"Recently, vision transformers (ViTs) have achieved excellent performance on vision tasks by measuring the global self-attention among the image patches. Given $n$ patches, they will have quadratic complexity such as $\\mathcal{O}(n^2)$ and the time cost is high when splitting the input image with a small granularity. Meanwhile, the pivotal information is often randomly gathered in a few regions of an input image, some tokens may not be helpful for the downstream tasks. To handle this problem, we introduce an anchor-based efficient vision transformer (AnchorFormer), which employs the anchor tokens to learn the pivotal information and accelerate the inference. Firstly, by estimating the bipartite attention between the anchors and tokens, the complexity will be reduced from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$, where $m$ is an anchor number and $m < n$. Notably, by representing the anchors with the neurons in a neural layer, we can differentiable learn these distributions and approximate global self-attention through the Markov process. Moreover, we extend the proposed model to three downstream tasks including classification, detection, and segmentation. Extensive experiments show the effectiveness of our AnchorFormer, e.g., achieving up to a 9.0% higher accuracy or 46.7% FLOPs reduction on ImageNet classification, 81.3% higher mAP on COCO detection under comparable FLOPs, as compared to the current baselines.","authors":["Jiquan Shan","Junxiao Wang","Lifeng Zhao","Liang Cai","Hongyuan Zhang","Ioannis Liritzis"],"url":"https://arxiv.org/abs/2505.16463"}
{"created":"2025-05-23","title":"Conf-GNNRec: Quantifying and Calibrating the Prediction Confidence for GNN-based Recommendation Methods","abstract":"Recommender systems based on graph neural networks perform well in tasks such as rating and ranking. However, in real-world recommendation scenarios, noise such as user misuse and malicious advertisement gradually accumulates through the message propagation mechanism. Even if existing studies mitigate their effects by reducing the noise propagation weights, the severe sparsity of the recommender system still leads to the low-weighted noisy neighbors being mistaken as meaningful information, and the prediction result obtained based on the polluted nodes is not entirely trustworthy. Therefore, it is crucial to measure the confidence of the prediction results in this highly noisy framework. Furthermore, our evaluation of the existing representative GNN-based recommendation shows that it suffers from overconfidence. Based on the above considerations, we propose a new method to quantify and calibrate the prediction confidence of GNN-based recommendations (Conf-GNNRec). Specifically, we propose a rating calibration method that dynamically adjusts excessive ratings to mitigate overconfidence based on user personalization. We also design a confidence loss function to reduce the overconfidence of negative samples and effectively improve recommendation performance. Experiments on public datasets demonstrate the validity of Conf-GNNRec in prediction confidence and recommendation performance.","authors":["Meng Yan","Cai Xu","Xujing Wang","Ziyu Guan","Wei Zhao","Yuhang Zhou"],"url":"https://arxiv.org/abs/2505.16466"}
{"created":"2025-05-23","title":"Reading Between the Prompts: How Stereotypes Shape LLM's Implicit Personalization","abstract":"Generative Large Language Models (LLMs) infer user's demographic information from subtle cues in the conversation -- a phenomenon called implicit personalization. Prior work has shown that such inferences can lead to lower quality responses for users assumed to be from minority groups, even when no demographic information is explicitly provided. In this work, we systematically explore how LLMs respond to stereotypical cues using controlled synthetic conversations, by analyzing the models' latent user representations through both model internals and generated answers to targeted user questions. Our findings reveal that LLMs do infer demographic attributes based on these stereotypical signals, which for a number of groups even persists when the user explicitly identifies with a different demographic group. Finally, we show that this form of stereotype-driven implicit personalization can be effectively mitigated by intervening on the model's internal representations using a trained linear probe to steer them toward the explicitly stated identity. Our results highlight the need for greater transparency and control in how LLMs represent user identity.","authors":["Vera Neplenbroek","Arianna Bisazza","Raquel Fern\\'andez"],"url":"https://arxiv.org/abs/2505.16467"}
{"created":"2025-05-23","title":"Local projection stabilization methods for $\\boldsymbol{H}({\\rm curl})$ and $\\boldsymbol{H}({\\rm div})$ advection problems","abstract":"We devise local projection stabilization (LPS) methods for advection problems in the $\\boldsymbol{H}$(curl) and $\\boldsymbol{H}$(div) spaces, employing conforming finite element spaces of arbitrary order within a unified framework. The key ingredient is a local inf-sup condition, enabled by enriching the approximation space with appropriate $\\boldsymbol{H}$(d) bubble functions (with d = curl or div). This enrichment allows for the construction of modified interpolation operators, which are crucial for establishing optimal a priori error estimates in the energy norm. Numerical examples are presented to verify both the theoretical results and the stabilization properties of the proposed method.","authors":["Yangfan Luo","Jindong Wang","Shuonan Wu"],"url":"https://arxiv.org/abs/2505.16468"}
{"created":"2025-05-23","title":"Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering","abstract":"Document Visual Question Answering (DocVQA) faces dual challenges in processing lengthy multimodal documents (text, images, tables) and performing cross-modal reasoning. Current document retrieval-augmented generation (DocRAG) methods remain limited by their text-centric approaches, frequently missing critical visual information. The field also lacks robust benchmarks for assessing multimodal evidence selection and integration. We introduce MMDocRAG, a comprehensive benchmark featuring 4,055 expert-annotated QA pairs with multi-page, cross-modal evidence chains. Our framework introduces innovative metrics for evaluating multimodal quote selection and enables answers that interleave text with relevant visual elements. Through large-scale experiments with 60 VLM/LLM models and 14 retrieval systems, we identify persistent challenges in multimodal evidence retrieval, selection, and integration.Key findings reveal advanced proprietary LVMs show superior performance than open-sourced alternatives. Also, they show moderate advantages using multimodal inputs over text-only inputs, while open-source alternatives show significant performance degradation. Notably, fine-tuned LLMs achieve substantial improvements when using detailed image descriptions. MMDocRAG establishes a rigorous testing ground and provides actionable insights for developing more robust multimodal DocVQA systems. Our benchmark and code are available at https://mmdocrag.github.io/MMDocRAG/.","authors":["Kuicai Dong","Yujing Chang","Shijie Huang","Yasheng Wang","Ruiming Tang","Yong Liu"],"url":"https://arxiv.org/abs/2505.16470"}
{"created":"2025-05-23","title":"Graph-Supported Dynamic Algorithm Configuration for Multi-Objective Combinatorial Optimization","abstract":"Deep reinforcement learning (DRL) has been widely used for dynamic algorithm configuration, particularly in evolutionary computation, which benefits from the adaptive update of parameters during the algorithmic execution. However, applying DRL to algorithm configuration for multi-objective combinatorial optimization (MOCO) problems remains relatively unexplored. This paper presents a novel graph neural network (GNN) based DRL to configure multi-objective evolutionary algorithms. We model the dynamic algorithm configuration as a Markov decision process, representing the convergence of solutions in the objective space by a graph, with their embeddings learned by a GNN to enhance the state representation. Experiments on diverse MOCO challenges indicate that our method outperforms traditional and DRL-based algorithm configuration methods in terms of efficacy and adaptability. It also exhibits advantageous generalizability across objective types and problem sizes, and applicability to different evolutionary computation methods.","authors":["Robbert Reijnen","Yaoxin Wu","Zaharah Bukhsh","Yingqian Zhang"],"url":"https://arxiv.org/abs/2505.16471"}
{"created":"2025-05-23","title":"Consistent World Models via Foresight Diffusion","abstract":"Diffusion and flow-based models have enabled significant progress in generation tasks across various modalities and have recently found applications in world modeling. However, unlike typical generation tasks that encourage sample diversity, world models entail different sources of uncertainty and require consistent samples aligned with the ground-truth trajectory, which is a limitation we empirically observe in diffusion models. We argue that a key bottleneck in learning consistent diffusion-based world models lies in the suboptimal predictive ability, which we attribute to the entanglement of condition understanding and target denoising within shared architectures and co-training schemes. To address this, we propose Foresight Diffusion (ForeDiff), a diffusion-based world modeling framework that enhances consistency by decoupling condition understanding from target denoising. ForeDiff incorporates a separate deterministic predictive stream to process conditioning inputs independently of the denoising stream, and further leverages a pretrained predictor to extract informative representations that guide generation. Extensive experiments on robot video prediction and scientific spatiotemporal forecasting show that ForeDiff improves both predictive accuracy and sample consistency over strong baselines, offering a promising direction for diffusion-based world models.","authors":["Yu Zhang","Xingzhuo Guo","Haoran Xu","Mingsheng Long"],"url":"https://arxiv.org/abs/2505.16474"}
{"created":"2025-05-23","title":"ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection","abstract":"We present a novel pipeline, ReflectEvo, to demonstrate that small language models (SLMs) can enhance meta introspection through reflection learning. This process iteratively generates self-reflection for self-training, fostering a continuous and self-evolving process. Leveraging this pipeline, we construct ReflectEvo-460k, a large-scale, comprehensive, self-generated reflection dataset with broadened instructions and diverse multi-domain tasks. Building upon this dataset, we demonstrate the effectiveness of reflection learning to improve SLMs' reasoning abilities using SFT and DPO with remarkable performance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral from 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the reasoning capability of the three prominent open-sourced models on BIG-bench without distillation from superior models or fine-grained human annotation. We further conduct a deeper analysis of the high quality of self-generated reflections and their impact on error localization and correction. Our work highlights the potential of continuously enhancing the reasoning performance of SLMs through iterative reflection learning in the long run.","authors":["Jiaqi Li","Xinyi Dong","Yang Liu","Zhizhuo Yang","Quansen Wang","Xiaobo Wang","SongChun Zhu","Zixia Jia","Zilong Zheng"],"url":"https://arxiv.org/abs/2505.16475"}
{"created":"2025-05-23","title":"Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery","abstract":"With recent Nobel Prizes recognising AI contributions to science, Large Language Models (LLMs) are transforming scientific research by enhancing productivity and reshaping the scientific method. LLMs are now involved in experimental design, data analysis, and workflows, particularly in chemistry and biology. However, challenges such as hallucinations and reliability persist. In this contribution, we review how Large Language Models (LLMs) are redefining the scientific method and explore their potential applications across different stages of the scientific cycle, from hypothesis testing to discovery. We conclude that, for LLMs to serve as relevant and effective creative engines and productivity enhancers, their deep integration into all steps of the scientific process should be pursued in collaboration and alignment with human scientific goals, with clear evaluation metrics. The transition to AI-driven science raises ethical questions about creativity, oversight, and responsibility. With careful guidance, LLMs could evolve into creative engines, driving transformative breakthroughs across scientific disciplines responsibly and effectively. However, the scientific community must also decide how much it leaves to LLMs to drive science, even when associations with 'reasoning', mostly currently undeserved, are made in exchange for the potential to explore hypothesis and solution regions that might otherwise remain unexplored by human exploration alone.","authors":["Yanbo Zhang","Sumeer A. Khan","Adnan Mahmud","Huck Yang","Alexander Lavin","Michael Levin","Jeremy Frey","Jared Dunnmon","James Evans","Alan Bundy","Saso Dzeroski","Jesper Tegner","Hector Zenil"],"url":"https://arxiv.org/abs/2505.16477"}
{"created":"2025-05-23","title":"Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot","abstract":"We propose a novel Model Predictive Control (MPC) framework for a jet-powered flying humanoid robot. The controller is based on a linearised centroidal momentum model to represent the flight dynamics, augmented with a second-order nonlinear model to explicitly account for the slow and nonlinear dynamics of jet propulsion. A key contribution is the introduction of a multi-rate MPC formulation that handles the different actuation rates of the robot's joints and jet engines while embedding the jet dynamics directly into the predictive model. We validated the framework using the jet-powered humanoid robot iRonCub, performing simulations in Mujoco; the simulation results demonstrate the robot's ability to recover from external disturbances and perform stable, non-abrupt flight manoeuvres, validating the effectiveness of the proposed approach.","authors":["Davide Gorbani","Giuseppe L'Erario","Hosameldin Awadalla Omer Mohamed","Daniele Pucci"],"url":"https://arxiv.org/abs/2505.16478"}
{"created":"2025-05-23","title":"Clear Nights Ahead: Towards Multi-Weather Nighttime Image Restoration","abstract":"Restoring nighttime images affected by multiple adverse weather conditions is a practical yet under-explored research problem, as multiple weather conditions often coexist in the real world alongside various lighting effects at night. This paper first explores the challenging multi-weather nighttime image restoration task, where various types of weather degradations are intertwined with flare effects. To support the research, we contribute the AllWeatherNight dataset, featuring large-scale high-quality nighttime images with diverse compositional degradations, synthesized using our introduced illumination-aware degradation generation. Moreover, we present ClearNight, a unified nighttime image restoration framework, which effectively removes complex degradations in one go. Specifically, ClearNight extracts Retinex-based dual priors and explicitly guides the network to focus on uneven illumination regions and intrinsic texture contents respectively, thereby enhancing restoration effectiveness in nighttime scenarios. In order to better represent the common and unique characters of multiple weather degradations, we introduce a weather-aware dynamic specific-commonality collaboration method, which identifies weather degradations and adaptively selects optimal candidate units associated with specific weather types. Our ClearNight achieves state-of-the-art performance on both synthetic and real-world images. Comprehensive ablation experiments validate the necessity of AllWeatherNight dataset as well as the effectiveness of ClearNight. Project page: https://henlyta.github.io/ClearNight/mainpage.html","authors":["Yuetong Liu","Yunqiu Xu","Yang Wei","Xiuli Bi","Bin Xiao"],"url":"https://arxiv.org/abs/2505.16479"}
{"created":"2025-05-23","title":"Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling","abstract":"Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by replacing the fully factorised Gaussian prior with a GP prior, thereby capturing richer correlations among latent variables. However, performing exact GP inference in large-scale GPVAEs is computationally prohibitive, often forcing existing approaches to rely on restrictive kernel assumptions or large sets of inducing points. In this work, we propose a neighbour-driven approximation strategy that exploits local adjacencies in the latent space to achieve scalable GPVAE inference. By confining computations to the nearest neighbours of each data point, our method preserves essential latent dependencies, allowing more flexible kernel choices and mitigating the need for numerous inducing points. Through extensive experiments on tasks including representation learning, data imputation, and conditional generation, we demonstrate that our approach outperforms other GPVAE variants in both predictive performance and computational efficiency.","authors":["Xinxing Shi","Xiaoyu Jiang","Mauricio A. \\'Alvarez"],"url":"https://arxiv.org/abs/2505.16481"}
{"created":"2025-05-23","title":"Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes","abstract":"Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the advantage of wireless energy transfer technology have opened a promising opportunity in solving the limited energy issue. However, an ineffective charging strategy may reduce the charging performance. Although many practical charging algorithms have been introduced, these studies mainly focus on optimizing the charging path with a fully charging approach. This approach may lead to the death of a series of sensors due to their extended charging latency. This paper introduces a novel partial charging approach that follows a bi-level optimized scheme to minimize energy depletion in WRSNs. We aim at optimizing simultaneously two factors: the charging path and time. To accomplish this, we first formulate a mathematical model of the investigated problem. We then propose two approximate algorithms in which the optimization of the charging path and the charging time are considered as the upper and lower level, respectively. The first algorithm combines a Multi-start Local Search method and a Genetic Algorithm to find a solution. The second algorithm adopts a nested approach that utilizes the advantages of the Multitasking and Covariance Matrix Adaptation Evolutionary Strategies. Experimental validations on various network scenarios demonstrate that our proposed algorithms outperform the existing works.","authors":["Huynh Thi Thanh Binh","Le Van Cuong","Dang Hai Dang","Le Trong Vinh"],"url":"https://arxiv.org/abs/2505.16482"}
{"created":"2025-05-23","title":"Teaching Large Language Models to Maintain Contextual Faithfulness via Synthetic Tasks and Reinforcement Learning","abstract":"Teaching large language models (LLMs) to be faithful in the provided context is crucial for building reliable information-seeking systems. Therefore, we propose a systematic framework, CANOE, to improve the faithfulness of LLMs in both short-form and long-form generation tasks without human annotations. Specifically, we first synthesize short-form question-answering (QA) data with four diverse tasks to construct high-quality and easily verifiable training data without human annotation. Also, we propose Dual-GRPO, a rule-based reinforcement learning method that includes three tailored rule-based rewards derived from synthesized short-form QA data, while simultaneously optimizing both short-form and long-form response generation. Notably, Dual-GRPO eliminates the need to manually label preference data to train reward models and avoids over-optimizing short-form generation when relying only on the synthesized short-form QA data. Experimental results show that CANOE greatly improves the faithfulness of LLMs across 11 different downstream tasks, even outperforming the most advanced LLMs, e.g., GPT-4o and OpenAI o1.","authors":["Shuzheng Si","Haozhe Zhao","Cheng Gao","Yuzhuo Bai","Zhitong Wang","Bofei Gao","Kangyang Luo","Wenhao Li","Yufei Huang","Gang Chen","Fanchao Qi","Minjia Zhang","Baobao Chang","Maosong Sun"],"url":"https://arxiv.org/abs/2505.16483"}
{"created":"2025-05-23","title":"InspectionV3: Enhancing Tobacco Quality Assessment with Deep Convolutional Neural Networks for Automated Workshop Management","abstract":"The problems that tobacco workshops encounter include poor curing, inconsistencies in supplies, irregular scheduling, and a lack of oversight, all of which drive up expenses and worse quality. Large quantities make manual examination costly, sluggish, and unreliable. Deep convolutional neural networks have recently made strides in capabilities that transcend those of conventional methods. To effectively enhance them, nevertheless, extensive customization is needed to account for subtle variations in tobacco grade. This study introduces InspectionV3, an integrated solution for automated flue-cured tobacco grading that makes use of a customized deep convolutional neural network architecture. A scope that covers color, maturity, and curing subtleties is established via a labelled dataset consisting of 21,113 images spanning 20 quality classes. Expert annotators performed preprocessing on the tobacco leaf images, including cleaning, labelling, and augmentation. Multi-layer CNN factors use batch normalization to describe domain properties like as permeability and moisture spots, and so account for the subtleties of the workshop. Its expertise lies in converting visual patterns into useful information for enhancing workflow. Fast notifications are made possible by real-time, on-the-spot grading that matches human expertise. Images-powered analytics dashboards facilitate the tracking of yield projections, inventories, bottlenecks, and the optimization of data-driven choices. More labelled images are assimilated after further retraining, improving representational capacities and enabling adaptations for seasonal variability. Metrics demonstrate 97% accuracy, 95% precision and recall, 96% F1-score and AUC, 95% specificity; validating real-world viability.","authors":["Yao Wei","Muhammad Usman","Hazrat Bilal"],"url":"https://arxiv.org/abs/2505.16485"}
{"created":"2025-05-23","title":"Implicit Neural Shape Optimization for 3D High-Contrast Electrical Impedance Tomography","abstract":"We present a novel implicit neural shape optimization framework for 3D high-contrast Electrical Impedance Tomography (EIT), addressing scenarios where conductivity exhibits sharp discontinuities across material interfaces. These high-contrast cases, prevalent in metallic implant monitoring and industrial defect detection, challenge traditional reconstruction methods due to severe ill-posedness. Our approach synergizes shape optimization with implicit neural representations, introducing key innovations including a shape derivative-based optimization scheme that explicitly incorporates high-contrast interface conditions and an efficient latent space representation that reduces variable dimensionality. Through rigorous theoretical analysis of algorithm convergence and extensive numerical experiments, we demonstrate substantial performance improvements, establishing our framework as promising for practical applications in medical imaging with metallic implants and industrial non-destructive testing.","authors":["Junqing Chen","Haibo Liu"],"url":"https://arxiv.org/abs/2505.16487"}
{"created":"2025-05-23","title":"LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing","abstract":"Large Language Models (LLMs) have rapidly become central to NLP, demonstrating their ability to adapt to various tasks through prompting techniques, including sentiment analysis. However, we still have a limited understanding of how these models capture sentiment-related information. This study probes the hidden layers of Llama models to pinpoint where sentiment features are most represented and to assess how this affects sentiment analysis.","authors":["Dario Di Palma","Alessandro De Bellis","Giovanni Servedio","Vito Walter Anelli","Fedelucio Narducci","Tommaso Di Noia"],"url":"https://arxiv.org/abs/2505.16491"}
{"created":"2025-05-23","title":"Constrained Non-negative Matrix Factorization for Guided Topic Modeling of Minority Topics","abstract":"Topic models often fail to capture low-prevalence, domain-critical themes, so-called minority topics, such as mental health themes in online comments. While some existing methods can incorporate domain knowledge, such as expected topical content, methods allowing guidance may require overly detailed expected topics, hindering the discovery of topic divisions and variation. We propose a topic modeling solution via a specially constrained NMF. We incorporate a seed word list characterizing minority content of interest, but we do not require experts to pre-specify their division across minority topics. Through prevalence constraints on minority topics and seed word content across topics, we learn distinct data-driven minority topics as well as majority topics. The constrained NMF is fitted via Karush-Kuhn-Tucker (KKT) conditions with multiplicative updates. We outperform several baselines on synthetic data in terms of topic purity, normalized mutual information, and also evaluate topic quality using Jensen-Shannon divergence (JSD). We conduct a case study on YouTube vlog comments, analyzing viewer discussion of mental health content; our model successfully identifies and reveals this domain-relevant minority content.","authors":["Seyedeh Fatemeh Ebrahimi","Jaakko Peltonen"],"url":"https://arxiv.org/abs/2505.16493"}
{"created":"2025-05-23","title":"Accuracy vs. Accuracy: Computational Tradeoffs Between Classification Rates and Utility","abstract":"We revisit the foundations of fairness and its interplay with utility and efficiency in settings where the training data contain richer labels, such as individual types, rankings, or risk estimates, rather than just binary outcomes. In this context, we propose algorithms that achieve stronger notions of evidence-based fairness than are possible in standard supervised learning. Our methods support classification and ranking techniques that preserve accurate subpopulation classification rates, as suggested by the underlying data distributions, across a broad class of classification rules and downstream applications. Furthermore, our predictors enable loss minimization, whether aimed at maximizing utility or in the service of fair treatment.","authors":["Noga Amit","Omer Reingold","Guy N. Rothblum"],"url":"https://arxiv.org/abs/2505.16494"}
{"created":"2025-05-23","title":"ALTo: Adaptive-Length Tokenizer for Autoregressive Mask Generation","abstract":"While humans effortlessly draw visual objects and shapes by adaptively allocating attention based on their complexity, existing multimodal large language models (MLLMs) remain constrained by rigid token representations. Bridging this gap, we propose ALTo, an adaptive length tokenizer for autoregressive mask generation. To achieve this, a novel token length predictor is designed, along with a length regularization term and a differentiable token chunking strategy. We further build ALToLLM that seamlessly integrates ALTo into MLLM. Preferences on the trade-offs between mask quality and efficiency is implemented by group relative policy optimization (GRPO). Experiments demonstrate that ALToLLM achieves state-of-the-art performance with adaptive token cost on popular segmentation benchmarks. Code and models are released at https://github.com/yayafengzi/ALToLLM.","authors":["Lingfeng Wang","Hualing Lin","Senda Chen","Tao Wang","Changxu Cheng","Yangyang Zhong","Dong Zheng","Wuyue Zhao"],"url":"https://arxiv.org/abs/2505.16495"}
{"created":"2025-05-23","title":"Minimizing Energy in Reliability and Deadline-Ensured Workflow Scheduling in Cloud","abstract":"With the increasing prevalence of computationally intensive workflows in cloud environments, it has become crucial for cloud platforms to optimize energy consumption while ensuring the feasibility of user workflow schedules with respect to strict deadlines and reliability constraints. The key challenges faced when cloud systems provide virtual machines of varying levels of reliability, energy consumption, processing frequencies, and computing capabilities to execute tasks of these workflows. To address these issues, we propose an adaptive strategy based on maximum fan-out ratio considering the slack of tasks and deadline distribution for scheduling workflows in a single cloud platform, intending to minimise energy consumption while ensuring strict reliability and deadline constraints. We also propose an approach for dynamic scheduling of workflow using the rolling horizon concept to consider the dynamic execution time of tasks of the workflow where the actual task execution time at run time is shorter than worst-case execution time in most of the cases. Our proposed static approach outperforms the state-of-the-art (SOTA) by up to 70% on average in scenarios without deadline constraints, and achieves an improvement of approximately 2% in deadline-constrained cases. The dynamic variant of our approach demonstrates even stronger performance, surpassing SOTA by 82% in non-deadline scenarios and by up to 27% on average when deadline constraints are enforced. Furthermore, in comparison with the static optimal solution, our static approach yields results within a factor of 1.1, while the dynamic approach surpasses the optimal baseline by an average of 25%.","authors":["Suvarthi Sarkar","Dhanesh V","Ketan Singh","Aryabartta Sahu"],"url":"https://arxiv.org/abs/2505.16496"}
{"created":"2025-05-23","title":"Human-like Semantic Navigation for Autonomous Driving using Knowledge Representation and Large Language Models","abstract":"Achieving full automation in self-driving vehicles remains a challenge, especially in dynamic urban environments where navigation requires real-time adaptability. Existing systems struggle to handle navigation plans when faced with unpredictable changes in road layouts, spontaneous detours, or missing map data, due to their heavy reliance on predefined cartographic information. In this work, we explore the use of Large Language Models to generate Answer Set Programming rules by translating informal navigation instructions into structured, logic-based reasoning. ASP provides non-monotonic reasoning, allowing autonomous vehicles to adapt to evolving scenarios without relying on predefined maps. We present an experimental evaluation in which LLMs generate ASP constraints that encode real-world urban driving logic into a formal knowledge representation. By automating the translation of informal navigation instructions into logical rules, our method improves adaptability and explainability in autonomous navigation. Results show that LLM-driven ASP rule generation supports semantic-based decision-making, offering an explainable framework for dynamic navigation planning that aligns closely with how humans communicate navigational intent.","authors":["Augusto Luis Ballardini","Miguel \\'Angel Sotelo"],"url":"https://arxiv.org/abs/2505.16498"}
{"created":"2025-05-23","title":"Smaller, Smarter, Closer: The Edge of Collaborative Generative AI","abstract":"The rapid adoption of generative AI (GenAI), particularly Large Language Models (LLMs), has exposed critical limitations of cloud-centric deployments, including latency, cost, and privacy concerns. Meanwhile, Small Language Models (SLMs) are emerging as viable alternatives for resource-constrained edge environments, though they often lack the capabilities of their larger counterparts. This article explores the potential of collaborative inference systems that leverage both edge and cloud resources to address these challenges. By presenting distinct cooperation strategies alongside practical design principles and experimental insights, we offer actionable guidance for deploying GenAI across the computing continuum.","authors":["Roberto Morabito","SiYoung Jang"],"url":"https://arxiv.org/abs/2505.16499"}
{"created":"2025-05-23","title":"Performance of Confidential Computing GPUs","abstract":"This work examines latency, throughput, and other metrics when performing inference on confidential GPUs. We explore different traffic patterns and scheduling strategies using a single Virtual Machine with one NVIDIA H100 GPU, to perform relaxed batch inferences on multiple Large Language Models (LLMs), operating under the constraint of swapping models in and out of memory, which necessitates efficient control. The experiments simulate diverse real-world scenarios by varying parameters such as traffic load, traffic distribution patterns, scheduling strategies, and Service Level Agreement (SLA) requirements. The findings provide insights into the differences between confidential and non-confidential settings when performing inference in scenarios requiring active model swapping. Results indicate that in No-CC mode, relaxed batch inference with model swapping latency is 20-30% lower than in confidential mode. Additionally, SLA attainment is 15-20% higher in No-CC settings. Throughput in No-CC scenarios surpasses that of confidential mode by 45-70%, and GPU utilization is approximately 50% higher in No-CC environments. Overall, performance in the confidential setting is inferior to that in the No-CC scenario, primarily due to the additional encryption and decryption overhead required for loading models onto the GPU in confidential environments.","authors":["Antonio Mart\\'inez Ibarra","Julian James Stephen","Aurora Gonz\\'alez Vidal","K. R. Jayaram","Antonio Fernando Skarmeta G\\'omez"],"url":"https://arxiv.org/abs/2505.16501"}
{"created":"2025-05-23","title":"Recursive Offloading for LLM Serving in Multi-tier Networks","abstract":"Heterogeneous device-edge-cloud computing infrastructures have become widely adopted in telecommunication operators and Wide Area Networks (WANs), offering multi-tier computational support for emerging intelligent services. With the rapid proliferation of Large Language Model (LLM) services, efficiently coordinating inference tasks and reducing communication overhead within these multi-tier network architectures becomes a critical deployment challenge. Existing LLM serving paradigms exhibit significant limitations: on-device deployment supports only lightweight LLMs due to hardware constraints, while cloud-centric deployment suffers from resource congestion and considerable prompt communication overhead caused by frequent service requests during peak periods. Although the model-cascading-based inference strategy adapts better to multi-tier networks, its reliance on fine-grained, manually adjusted thresholds makes it less responsive to dynamic network conditions and varying task complexities. To address these challenges, we propose RecServe, a recursive offloading framework tailored for LLM serving in multi-tier networks. RecServe integrates a task-specific hierarchical confidence evaluation mechanism that guides offloading decisions based on inferred task complexity in progressively scaled LLMs across device, edge, and cloud tiers. To further enable intelligent task routing across tiers, RecServe employs a sliding-window-based dynamic offloading strategy with quantile interpolation, enabling real-time tracking of historical confidence distributions and adaptive offloading threshold adjustments. Experiments on eight datasets demonstrate that RecServe outperforms CasServe in both service quality and communication efficiency, and reduces the communication burden by over 50\\% compared to centralized cloud-based serving.","authors":["Zhiyuan Wu","Sheng Sun","Yuwei Wang","Min Liu","Bo Gao","Jinda Lu","Zheming Yang","Tian Wen"],"url":"https://arxiv.org/abs/2505.16502"}
{"created":"2025-05-23","title":"Language-based Security and Time-inserting Supervisor","abstract":"Algebraic methods are employed in order to define language-based security properties of processes. A supervisor is introduced that can disable unwanted behavior of an insecure process by controlling some of its actions or by inserting timed actions to make an insecure process secure. We assume a situation where neither the supervisor nor the attacker has complete information about the ongoing systems behavior. We study the conditions under which such a supervisor exists, as well as its properties and limitations.","authors":["Damas P. Gruska"],"url":"https://arxiv.org/abs/2505.16503"}
{"created":"2025-05-23","title":"Sparse Activation Editing for Reliable Instruction Following in Narratives","abstract":"Complex narrative contexts often challenge language models' ability to follow instructions, and existing benchmarks fail to capture these difficulties. To address this, we propose Concise-SAE, a training-free framework that improves instruction following by identifying and editing instruction-relevant neurons using only natural language instructions, without requiring labelled data. To thoroughly evaluate our method, we introduce FreeInstruct, a diverse and realistic benchmark of 1,212 examples that highlights the challenges of instruction following in narrative-rich settings. While initially motivated by complex narratives, Concise-SAE demonstrates state-of-the-art instruction adherence across varied tasks without compromising generation quality.","authors":["Runcong Zhao","Chengyu Cao","Qinglin Zhu","Xiucheng Lv","Shun Shao","Lin Gui","Ruifeng Xu","Yulan He"],"url":"https://arxiv.org/abs/2505.16505"}
{"created":"2025-05-23","title":"Utilizing citation index and synthetic quality measure to compare Wikipedia languages across various topics","abstract":"This study presents a comparative analysis of 55 Wikipedia language editions employing a citation index alongside a synthetic quality measure. Specifically, we identified the most significant Wikipedia articles within distinct topical areas, selecting the top 10, top 25, and top 100 most cited articles in each topic and language version. This index was built on the basis of wikilinks between Wikipedia articles in each language version and in order to do that we processed 6.6 billion page-to-page link records. Next, we used a quality score for each Wikipedia article - a synthetic measure scaled from 0 to 100. This approach enabled quality comparison of Wikipedia articles even between language versions with different quality grading schemes. Our results highlight disparities among Wikipedia language editions, revealing strengths and gaps in content coverage and quality across topics.","authors":["W{\\l}odzimierz Lewoniewski","Krzysztof W\\k{e}cel","Witold Abramowicz"],"url":"https://arxiv.org/abs/2505.16506"}
{"created":"2025-05-23","title":"Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)","abstract":"The notion of relevance was proposed for stability of justification status of a single argument in incomplete argumentation frameworks (IAFs) in 2024 by Odekerken et al. To extend the notion, we study the relevance for stability of verification status of a set of arguments in this paper, i.e., the uncertainties in an IAF that have to be resolved in some situations so that answering whether a given set of arguments is an extension obtains the same result in every completion of the IAF. Further we propose the notion of strong relevance for describing the necessity of resolution in all situations reaching stability. An analysis of complexity reveals that detecting the (strong) relevance for stability of sets of arguments can be accomplished in P time under the most semantics discussed in the paper. We also discuss the difficulty in finding tractable methods for relevance detection under grounded semantics.","authors":["Anshu Xiong","Songmao Zhang"],"url":"https://arxiv.org/abs/2505.16507"}
{"created":"2025-05-23","title":"Edge-First Language Model Inference: Models, Metrics, and Tradeoffs","abstract":"The widespread adoption of Language Models (LMs) across industries is driving interest in deploying these services across the computing continuum, from the cloud to the network edge. This shift aims to reduce costs, lower latency, and improve reliability and privacy. Small Language Models (SLMs), enabled by advances in model compression, are central to this shift, offering a path to on-device inference on resource-constrained edge platforms. This work examines the interplay between edge and cloud deployments, starting from detailed benchmarking of SLM capabilities on single edge devices, and extending to distributed edge clusters. We identify scenarios where edge inference offers comparable performance with lower costs, and others where cloud fallback becomes essential due to limits in scalability or model capacity. Rather than proposing a one-size-fits-all solution, we present platform-level comparisons and design insights for building efficient, adaptive LM inference systems across heterogeneous environments.","authors":["SiYoung Jang","Roberto Morabito"],"url":"https://arxiv.org/abs/2505.16508"}
{"created":"2025-05-23","title":"Neural network based control of unknown nonlinear systems via contraction analysis","abstract":"This paper studies the design of neural network (NN)-based controllers for unknown nonlinear systems, using contraction analysis. A Neural Ordinary Differential Equation (NODE) system is constructed by approximating the unknown draft dynamics with a feedforward NN. Incremental sector bounds and contraction theory are applied to the activation functions and the weights of the NN, respectively. It is demonstrated that if the incremental sector bounds and the weights satisfy some non-convex conditions, the NODE system is contractive. To improve computational efficiency, these non-convex conditions are reformulated as convex LMI conditions. Additionally, it is proven that when the NODE system is contractive, the trajectories of the original autonomous system converge to a neighborhood of the unknown equilibrium, with the size of this neighborhood determined by the approximation error. For a single-layer NN, the NODE system is simplified to a continuous-time Hopfield NN. If the NODE system does not satisfy the contraction conditions, an NN-based controller is designed to enforce contractivity. This controller integrates a linear component, which ensures contraction through suitable control gains, and an NN component, which compensates for the NODE system's nonlinearities. This integrated controller guarantees that the trajectories of the original affine system converge to a neighborhood of the unknown equilibrium. The effectiveness of the proposed approach is demonstrated through two illustrative examples.","authors":["Hao Yin","Claudio De Persis","Bayu Jayawardhana","Santiago Sanchez Escalonilla Plaza"],"url":"https://arxiv.org/abs/2505.16511"}
{"created":"2025-05-23","title":"Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection","abstract":"In recent years, the rapid development of deepfake technology has given rise to an emerging and serious threat to public security: diffusion model-based digital human generation. Unlike traditional face manipulation methods, such models can generate highly realistic videos with consistency through multimodal control signals. Their flexibility and covertness pose severe challenges to existing detection strategies. To bridge this gap, we introduce DigiFakeAV, the first large-scale multimodal digital human forgery dataset based on diffusion models. Employing five latest digital human generation methods (Sonic, Hallo, etc.) and voice cloning method, we systematically produce a dataset comprising 60,000 videos (8.4 million frames), covering multiple nationalities, skin tones, genders, and real-world scenarios, significantly enhancing data diversity and realism. User studies show that the confusion rate between forged and real videos reaches 68%, and existing state-of-the-art (SOTA) detection models exhibit large drops in AUC values on DigiFakeAV, highlighting the challenge of the dataset. To address this problem, we further propose DigiShield, a detection baseline based on spatiotemporal and cross-modal fusion. By jointly modeling the 3D spatiotemporal features of videos and the semantic-acoustic features of audio, DigiShield achieves SOTA performance on both the DigiFakeAV and DF-TIMIT datasets. Experiments show that this method effectively identifies covert artifacts through fine-grained analysis of the temporal evolution of facial features in synthetic videos.","authors":["Jiaxin Liu","Jia Wang","Saihui Hou","Min Ren","Huijia Wu","Zhaofeng He"],"url":"https://arxiv.org/abs/2505.16512"}
{"created":"2025-05-23","title":"Detailed Evaluation of Modern Machine Learning Approaches for Optic Plastics Sorting","abstract":"According to the EPA, only 25% of waste is recycled, and just 60% of U.S. municipalities offer curbside recycling. Plastics fare worse, with a recycling rate of only 8%; an additional 16% is incinerated, while the remaining 76% ends up in landfills. The low plastic recycling rate stems from contamination, poor economic incentives, and technical difficulties, making efficient recycling a challenge. To improve recovery, automated sorting plays a critical role. Companies like AMP Robotics and Greyparrot utilize optical systems for sorting, while Materials Recovery Facilities (MRFs) employ Near-Infrared (NIR) sensors to detect plastic types.","authors":["Vaishali Maheshkar","Aadarsh Anantha Ramakrishnan","Charuvahan Adhivarahan","Karthik Dantu"],"url":"https://arxiv.org/abs/2505.16513"}
{"created":"2025-05-23","title":"AppealCase: A Dataset and Benchmark for Civil Case Appeal Scenarios","abstract":"Recent advances in LegalAI have primarily focused on individual case judgment analysis, often overlooking the critical appellate process within the judicial system. Appeals serve as a core mechanism for error correction and ensuring fair trials, making them highly significant both in practice and in research. To address this gap, we present the AppealCase dataset, consisting of 10,000 pairs of real-world, matched first-instance and second-instance documents across 91 categories of civil cases. The dataset also includes detailed annotations along five dimensions central to appellate review: judgment reversals, reversal reasons, cited legal provisions, claim-level decisions, and whether there is new information in the second instance. Based on these annotations, we propose five novel LegalAI tasks and conduct a comprehensive evaluation across 20 mainstream models. Experimental results reveal that all current models achieve less than 50% F1 scores on the judgment reversal prediction task, highlighting the complexity and challenge of the appeal scenario. We hope that the AppealCase dataset will spur further research in LegalAI for appellate case analysis and contribute to improving consistency in judicial decision-making.","authors":["Yuting Huang","Meitong Guo","Yiquan Wu","Ang Li","Xiaozhong Liu","Keting Yin","Changlong Sun","Fei Wu","Kun Kuang"],"url":"https://arxiv.org/abs/2505.16514"}
{"created":"2025-05-23","title":"Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods","abstract":"Kernel methods are widely used in machine learning due to their flexibility and expressive power. However, their black-box nature poses significant challenges to interpretability, limiting their adoption in high-stakes applications. Shapley value-based feature attribution techniques, such as SHAP and kernel-specific variants like RKHS-SHAP, offer a promising path toward explainability. Yet, computing exact Shapley values remains computationally intractable in general, motivating the development of various approximation schemes. In this work, we introduce PKeX-Shapley, a novel algorithm that utilizes the multiplicative structure of product kernels to enable the exact computation of Shapley values in polynomial time. We show that product-kernel models admit a functional decomposition that allows for a recursive formulation of Shapley values. This decomposition not only yields computational efficiency but also enhances interpretability in kernel-based learning. We also demonstrate how our framework can be generalized to explain kernel-based statistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the Hilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for interpretable statistical inference.","authors":["Majid Mohammadi","Siu Lun Chau","Krikamol Muandet"],"url":"https://arxiv.org/abs/2505.16516"}
{"created":"2025-05-23","title":"ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models","abstract":"Large Vision-Language Models (LVLMs) have recently advanced robotic manipulation by leveraging vision for scene perception and language for instruction following. However, existing methods rely heavily on costly human-annotated training datasets, which limits their generalization and causes them to struggle in out-of-domain (OOD) scenarios, reducing real-world adaptability. To address these challenges, we propose ManipLVM-R1, a novel reinforcement learning framework that replaces traditional supervision with Reinforcement Learning using Verifiable Rewards (RLVR). By directly optimizing for task-aligned outcomes, our method enhances generalization and physical reasoning while removing the dependence on costly annotations. Specifically, we design two rule-based reward functions targeting key robotic manipulation subtasks: an Affordance Perception Reward to enhance localization of interaction regions, and a Trajectory Match Reward to ensure the physical plausibility of action paths. These rewards provide immediate feedback and impose spatial-logical constraints, encouraging the model to go beyond shallow pattern matching and instead learn deeper, more systematic reasoning about physical interactions.","authors":["Zirui Song","Guangxian Ouyang","Mingzhe Li","Yuheng Ji","Chenxi Wang","Zixiang Xu","Zeyu Zhang","Xiaoqing Zhang","Qian Jiang","Zhenhao Chen","Zhongzhi Li","Rui Yan","Xiuying Chen"],"url":"https://arxiv.org/abs/2505.16517"}
{"created":"2025-05-23","title":"CUB: Benchmarking Context Utilisation Techniques for Language Models","abstract":"Incorporating external knowledge is crucial for knowledge-intensive tasks, such as question answering and fact checking. However, language models (LMs) may ignore relevant information that contradicts outdated parametric memory or be distracted by irrelevant contexts. While many context utilisation manipulation techniques (CMTs) that encourage or suppress context utilisation have recently been proposed to alleviate these issues, few have seen systematic comparison. In this paper, we develop CUB (Context Utilisation Benchmark) to help practitioners within retrieval-augmented generation (RAG) identify the best CMT for their needs. CUB allows for rigorous testing on three distinct context types, observed to capture key challenges in realistic context utilisation scenarios. With this benchmark, we evaluate seven state-of-the-art methods, representative of the main categories of CMTs, across three diverse datasets and tasks, applied to nine LMs. Our results show that most of the existing CMTs struggle to handle the full set of types of contexts that may be encountered in real-world retrieval-augmented scenarios. Moreover, we find that many CMTs display an inflated performance on simple synthesised datasets, compared to more realistic datasets with naturally occurring samples. Altogether, our results show the need for holistic tests of CMTs and the development of CMTs that can handle multiple context types.","authors":["Lovisa Hagstr\\\"om","Youna Kim","Haeun Yu","Sang-goo Lee","Richard Johansson","Hyunsoo Cho","Isabelle Augenstein"],"url":"https://arxiv.org/abs/2505.16518"}
{"created":"2025-05-23","title":"SONIC: Cost-Effective Web Access for Developing Countries","abstract":"Over 2.6 billion people remain without access to the Internet in 2025. This phenomenon is especially pronounced in developing regions, where cost and infrastructure limitations are major barriers to connectivity. In response, we design SONIC, a low-cost, scalable data delivery system that builds on existing infrastructures: FM radio for downlink broadcasting, and SMS for personalized uplink. SONIC is motivated by the widespread availability of FM radio and SMS infrastructure in developing regions, along with embedded FM radio tuners in affordable mobile phones. SONIC offers several innovations to effectively transmit Web content over sound over FM radio, in a reliable and compressed form. For example, we transmit pre-rendered webpages and leverage pixel interpolation to recover errors at the receiver. We further modify Android to offer a simpler deployment pipeline, supporting a wide range of devices. We deployed SONIC at an FM radio station in Cameroon for six weeks with 30 participants. Our results demonstrate a sustained downlink throughput of 10 kbps, less than 20% loss for a majority of transmissions with signal strength above -90 dbM, and a strong user engagement across both Web browsing and ChatGPT interactions.","authors":["Ayush Pandey","Rohail Asim","Jean Louis K. E. Fendji","Talal Rahwan","Matteo Varvello","Yasir Zaki"],"url":"https://arxiv.org/abs/2505.16519"}
{"created":"2025-05-23","title":"Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs","abstract":"Factual hallucinations are a major challenge for Large Language Models (LLMs). They undermine reliability and user trust by generating inaccurate or fabricated content. Recent studies suggest that when generating false statements, the internal states of LLMs encode information about truthfulness. However, these studies often rely on synthetic datasets that lack realism, which limits generalization when evaluating the factual accuracy of text generated by the model itself. In this paper, we challenge the findings of previous work by investigating truthfulness encoding capabilities, leading to the generation of a more realistic and challenging dataset. Specifically, we extend previous work by introducing: (1) a strategy for sampling plausible true-false factoid sentences from tabular data and (2) a procedure for generating realistic, LLM-dependent true-false datasets from Question Answering collections. Our analysis of two open-source LLMs reveals that while the findings from previous studies are partially validated, generalization to LLM-generated datasets remains challenging. This study lays the groundwork for future research on factuality in LLMs and offers practical guidelines for more effective evaluation.","authors":["Giovanni Servedio","Alessandro De Bellis","Dario Di Palma","Vito Walter Anelli","Tommaso Di Noia"],"url":"https://arxiv.org/abs/2505.16520"}
{"created":"2025-05-23","title":"Benchmarking and Pushing the Multi-Bias Elimination Boundary of LLMs via Causal Effect Estimation-guided Debiasing","abstract":"Despite significant progress, recent studies have indicated that current large language models (LLMs) may still utilize bias during inference, leading to the poor generalizability of LLMs. Some benchmarks are proposed to investigate the generalizability of LLMs, with each piece of data typically containing one type of controlled bias. However, a single piece of data may contain multiple types of biases in practical applications. To bridge this gap, we propose a multi-bias benchmark where each piece of data contains five types of biases. The evaluations conducted on this benchmark reveal that the performance of existing LLMs and debiasing methods is unsatisfying, highlighting the challenge of eliminating multiple types of biases simultaneously. To overcome this challenge, we propose a causal effect estimation-guided multi-bias elimination method (CMBE). This method first estimates the causal effect of multiple types of biases simultaneously. Subsequently, we eliminate the causal effect of biases from the total causal effect exerted by both the semantic information and biases during inference. Experimental results show that CMBE can effectively eliminate multiple types of bias simultaneously to enhance the generalizability of LLMs.","authors":["Zhouhao Sun","Zhiyuan Kan","Xiao Ding","Li Du","Yang Zhao","Bing Qin","Ting Liu"],"url":"https://arxiv.org/abs/2505.16522"}
{"created":"2025-05-23","title":"CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving","abstract":"Maintaining robust 3D perception under dynamic and unpredictable test-time conditions remains a critical challenge for autonomous driving systems. Existing test-time adaptation (TTA) methods often fail in high-variance tasks like 3D object detection due to unstable optimization and sharp minima. While recent model merging strategies based on linear mode connectivity (LMC) offer improved stability by interpolating between fine-tuned checkpoints, they are computationally expensive, requiring repeated checkpoint access and multiple forward passes. In this paper, we introduce CodeMerge, a lightweight and scalable model merging framework that bypasses these limitations by operating in a compact latent space. Instead of loading full models, CodeMerge represents each checkpoint with a low-dimensional fingerprint derived from the source model's penultimate features and constructs a key-value codebook. We compute merging coefficients using ridge leverage scores on these fingerprints, enabling efficient model composition without compromising adaptation quality. Our method achieves strong performance across challenging benchmarks, improving end-to-end 3D detection 14.9% NDS on nuScenes-C and LiDAR-based detection by over 7.6% mAP on nuScenes-to-KITTI, while benefiting downstream tasks such as online mapping, motion prediction and planning even without training. Code and pretrained models are released in the supplementary material.","authors":["Huitong Yang","Zhuoxiao Chen","Fengyi Zhang","Zi Huang","Yadan Luo"],"url":"https://arxiv.org/abs/2505.16524"}
{"created":"2025-05-23","title":"EnSToM: Enhancing Dialogue Systems with Entropy-Scaled Steering Vectors for Topic Maintenance","abstract":"Small large language models (sLLMs) offer the advantage of being lightweight and efficient, which makes them suitable for resource-constrained environments. However, sLLMs often struggle to maintain topic consistency in task-oriented dialogue systems, which is critical for scenarios such as service chatbots. Specifically, it is important to ensure that the model denies off-topic or malicious inputs and adheres to its intended functionality so as to prevent potential misuse and uphold reliability. Towards this, existing activation engineering approaches have been proposed to manipulate internal activations during inference. While these methods are effective in certain scenarios, our preliminary experiments reveal their limitations in ensuring topic adherence. Therefore, to address this, we propose a novel approach termed Entropy-scaled Steering vectors for Topic Maintenance (EnSToM). EnSToM dynamically adjusts the steering intensity based on input uncertainty, which allows the model to handle off-topic distractors effectively while preserving on-topic accuracy. Our experiments demonstrate that EnSToM achieves significant performance gain with a relatively small data size compared to fine-tuning approaches. By improving topic adherence without compromising efficiency, our approach provides a robust solution for enhancing sLLM-based dialogue systems.","authors":["Heejae Suh","Yejin Jeon","Deokhyung Kang","Taehee Park","Yejin Min","Gary Geunbae Lee"],"url":"https://arxiv.org/abs/2505.16526"}
{"created":"2025-05-23","title":"Joint Relational Database Generation via Graph-Conditional Diffusion Models","abstract":"Building generative models for relational databases (RDBs) is important for applications like privacy-preserving data release and augmenting real datasets. However, most prior work either focuses on single-table generation or relies on autoregressive factorizations that impose a fixed table order and generate tables sequentially. This approach limits parallelism, restricts flexibility in downstream applications like missing value imputation, and compounds errors due to commonly made conditional independence assumptions. We propose a fundamentally different approach: jointly modeling all tables in an RDB without imposing any order. By using a natural graph representation of RDBs, we propose the Graph-Conditional Relational Diffusion Model (GRDM). GRDM leverages a graph neural network to jointly denoise row attributes and capture complex inter-table dependencies. Extensive experiments on six real-world RDBs demonstrate that our approach substantially outperforms autoregressive baselines in modeling multi-hop inter-table correlations and achieves state-of-the-art performance on single-table fidelity metrics.","authors":["Mohamed Amine Ketata","David L\\\"udke","Leo Schwinn","Stephan G\\\"unnemann"],"url":"https://arxiv.org/abs/2505.16527"}
{"created":"2025-05-23","title":"DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection","abstract":"Large language models (LLMs) are considered valuable Intellectual Properties (IP) for legitimate owners due to the enormous computational cost of training. It is crucial to protect the IP of LLMs from malicious stealing or unauthorized deployment. Despite existing efforts in watermarking and fingerprinting LLMs, these methods either impact the text generation process or are limited in white-box access to the suspect model, making them impractical. Hence, we propose DuFFin, a novel $\\textbf{Du}$al-Level $\\textbf{Fin}$gerprinting $\\textbf{F}$ramework for black-box setting ownership verification. DuFFin extracts the trigger pattern and the knowledge-level fingerprints to identify the source of a suspect model. We conduct experiments on a variety of models collected from the open-source website, including four popular base models as protected LLMs and their fine-tuning, quantization, and safety alignment versions, which are released by large companies, start-ups, and individual users. Results show that our method can accurately verify the copyright of the base protected LLM on their model variants, achieving the IP-ROC metric greater than 0.95. Our code is available at https://github.com/yuliangyan0807/llm-fingerprint.","authors":["Yuliang Yan","Haochun Tang","Shuo Yan","Enyan Dai"],"url":"https://arxiv.org/abs/2505.16530"}
{"created":"2025-05-23","title":"HOFT: Householder Orthogonal Fine-tuning","abstract":"Adaptation of foundation models using low-rank methods is a widespread approach. Another way to adapt these models is to employ orthogonal fine-tuning methods, which are less time and memory efficient despite their good generalization properties. In this work, we propose Householder Orthogonal Fine-tuning (HOFT), a novel orthogonal fine-tuning method that aims to alleviate time and space complexity. Moreover, some theoretical properties of the orthogonal fine-tuning paradigm are explored. From this exploration, Scaled Householder Orthogonal Fine-tuning (SHOFT) is proposed. Both HOFT and SHOFT are evaluated in downstream tasks, namely commonsense reasoning, machine translation, subject-driven generation and mathematical reasoning. Compared with state-of-the-art adaptation methods, HOFT and SHOFT show comparable or better results.","authors":["Alejandro Moreno Arcas","Albert Sanchis","Jorge Civera","Alfons Juan"],"url":"https://arxiv.org/abs/2505.16531"}
{"created":"2025-05-23","title":"Causal-Invariant Cross-Domain Out-of-Distribution Recommendation","abstract":"Cross-Domain Recommendation (CDR) aims to leverage knowledge from a relatively data-richer source domain to address the data sparsity problem in a relatively data-sparser target domain. While CDR methods need to address the distribution shifts between different domains, i.e., cross-domain distribution shifts (CDDS), they typically assume independent and identical distribution (IID) between training and testing data within the target domain. However, this IID assumption rarely holds in real-world scenarios due to single-domain distribution shift (SDDS). The above two co-existing distribution shifts lead to out-of-distribution (OOD) environments that hinder effective knowledge transfer and generalization, ultimately degrading recommendation performance in CDR. To address these co-existing distribution shifts, we propose a novel Causal-Invariant Cross-Domain Out-of-distribution Recommendation framework, called CICDOR. In CICDOR, we first learn dual-level causal structures to infer domain-specific and domain-shared causal-invariant user preferences for tackling both CDDS and SDDS under OOD environments in CDR. Then, we propose an LLM-guided confounder discovery module that seamlessly integrates LLMs with a conventional causal discovery method to extract observed confounders for effective deconfounding, thereby enabling accurate causal-invariant preference inference. Extensive experiments on two real-world datasets demonstrate the superior recommendation accuracy of CICDOR over state-of-the-art methods across various OOD scenarios.","authors":["Jiajie Zhu","Yan Wang","Feng Zhu","Pengfei Ding","Hongyang Liu","Zhu Sun"],"url":"https://arxiv.org/abs/2505.16532"}
{"created":"2025-05-23","title":"Motion Matters: Compact Gaussian Streaming for Free-Viewpoint Video Reconstruction","abstract":"3D Gaussian Splatting (3DGS) has emerged as a high-fidelity and efficient paradigm for online free-viewpoint video (FVV) reconstruction, offering viewers rapid responsiveness and immersive experiences. However, existing online methods face challenge in prohibitive storage requirements primarily due to point-wise modeling that fails to exploit the motion properties. To address this limitation, we propose a novel Compact Gaussian Streaming (ComGS) framework, leveraging the locality and consistency of motion in dynamic scene, that models object-consistent Gaussian point motion through keypoint-driven motion representation. By transmitting only the keypoint attributes, this framework provides a more storage-efficient solution. Specifically, we first identify a sparse set of motion-sensitive keypoints localized within motion regions using a viewspace gradient difference strategy. Equipped with these keypoints, we propose an adaptive motion-driven mechanism that predicts a spatial influence field for propagating keypoint motion to neighboring Gaussian points with similar motion. Moreover, ComGS adopts an error-aware correction strategy for key frame reconstruction that selectively refines erroneous regions and mitigates error accumulation without unnecessary overhead. Overall, ComGS achieves a remarkable storage reduction of over 159 X compared to 3DGStream and 14 X compared to the SOTA method QUEEN, while maintaining competitive visual fidelity and rendering speed. Our code will be released.","authors":["Jiacong Chen","Qingyu Mao","Youneng Bao","Xiandong Meng","Fanyang Meng","Ronggang Wang","Yongsheng Liang"],"url":"https://arxiv.org/abs/2505.16533"}
{"created":"2025-05-23","title":"SHaDe: Compact and Consistent Dynamic 3D Reconstruction via Tri-Plane Deformation and Latent Diffusion","abstract":"We present a novel framework for dynamic 3D scene reconstruction that integrates three key components: an explicit tri-plane deformation field, a view-conditioned canonical radiance field with spherical harmonics (SH) attention, and a temporally-aware latent diffusion prior. Our method encodes 4D scenes using three orthogonal 2D feature planes that evolve over time, enabling efficient and compact spatiotemporal representation. These features are explicitly warped into a canonical space via a deformation offset field, eliminating the need for MLP-based motion modeling.","authors":["Asrar Alruwayqi"],"url":"https://arxiv.org/abs/2505.16535"}
{"created":"2025-05-23","title":"Mechanistic Understanding and Mitigation of Language Confusion in English-Centric Large Language Models","abstract":"Language confusion -- where large language models (LLMs) generate unintended languages against the user's need -- remains a critical challenge, especially for English-centric models. We present the first mechanistic interpretability (MI) study of language confusion, combining behavioral benchmarking with neuron-level analysis. Using the Language Confusion Benchmark (LCB), we show that confusion points (CPs) -- specific positions where language switches occur -- are central to this phenomenon. Through layer-wise analysis with TunedLens and targeted neuron attribution, we reveal that transition failures in the final layers drive confusion. We further demonstrate that editing a small set of critical neurons, identified via comparative analysis with multilingual-tuned models, substantially mitigates confusion without harming general competence or fluency. Our approach matches multilingual alignment in confusion reduction for most languages and yields cleaner, higher-quality outputs. These findings provide new insights into the internal dynamics of LLMs and highlight neuron-level interventions as a promising direction for robust, interpretable multilingual language modeling.","authors":["Ercong Nie","Helmut Schmid","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2505.16538"}
{"created":"2025-05-23","title":"TextureSAM: Towards a Texture Aware Foundation Model for Segmentation","abstract":"Segment Anything Models (SAM) have achieved remarkable success in object segmentation tasks across diverse datasets. However, these models are predominantly trained on large-scale semantic segmentation datasets, which introduce a bias toward object shape rather than texture cues in the image. This limitation is critical in domains such as medical imaging, material classification, and remote sensing, where texture changes define object boundaries. In this study, we investigate SAM's bias toward semantics over textures and introduce a new texture-aware foundation model, TextureSAM, which performs superior segmentation in texture-dominant scenarios. To achieve this, we employ a novel fine-tuning approach that incorporates texture augmentation techniques, incrementally modifying training images to emphasize texture features. By leveraging a novel texture-alternation of the ADE20K dataset, we guide TextureSAM to prioritize texture-defined regions, thereby mitigating the inherent shape bias present in the original SAM model. Our extensive experiments demonstrate that TextureSAM significantly outperforms SAM-2 on both natural (+0.2 mIoU) and synthetic (+0.18 mIoU) texture-based segmentation datasets. The code and texture-augmented dataset will be publicly available.","authors":["Inbal Cohen","Boaz Meivar","Peihan Tu","Shai Avidan","Gal Oren"],"url":"https://arxiv.org/abs/2505.16540"}
{"created":"2025-05-23","title":"Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation","abstract":"This paper presents an end-to-end deep reinforcement learning (RL) framework for occlusion-aware robotic manipulation in cluttered plant environments. Our approach enables a robot to interact with a deformable plant to reveal hidden objects of interest, such as fruits, using multimodal observations. We decouple the kinematic planning problem from robot control to simplify zero-shot sim2real transfer for the trained policy. Our results demonstrate that the trained policy, deployed using our framework, achieves up to 86.7% success in real-world trials across diverse initial conditions. Our findings pave the way toward autonomous, perception-driven agricultural robots that intelligently interact with complex foliage plants to \"find the fruit\" in challenging occluded scenarios, without the need for explicitly designed geometric and dynamic models of every plant scenario.","authors":["Nitesh Subedi","Hsin-Jung Yang","Devesh K. Jha","Soumik Sarkar"],"url":"https://arxiv.org/abs/2505.16547"}
{"created":"2025-05-23","title":"Incremental Sequence Classification with Temporal Consistency","abstract":"We address the problem of incremental sequence classification, where predictions are updated as new elements in the sequence are revealed. Drawing on temporal-difference learning from reinforcement learning, we identify a temporal-consistency condition that successive predictions should satisfy. We leverage this condition to develop a novel loss function for training incremental sequence classifiers. Through a concrete example, we demonstrate that optimizing this loss can offer substantial gains in data efficiency. We apply our method to text classification tasks and show that it improves predictive accuracy over competing approaches on several benchmark datasets. We further evaluate our approach on the task of verifying large language model generations for correctness in grade-school math problems. Our results show that models trained with our method are better able to distinguish promising generations from unpromising ones after observing only a few tokens.","authors":["Lucas Maystre","Gabriel Barello","Tudor Berariu","Aleix Cambray","Rares Dolga","Alvaro Ortega Gonzalez","Andrei Nica","David Barber"],"url":"https://arxiv.org/abs/2505.16548"}
{"created":"2025-05-23","title":"Towards Coordinate- and Dimension-Agnostic Machine Learning for Partial Differential Equations","abstract":"The machine learning methods for data-driven identification of partial differential equations (PDEs) are typically defined for a given number of spatial dimensions and a choice of coordinates the data have been collected in. This dependence prevents the learned evolution equation from generalizing to other spaces. In this work, we reformulate the problem in terms of coordinate- and dimension-independent representations, paving the way toward what we call ``spatially liberated\" PDE learning. To this end, we employ a machine learning approach to predict the evolution of scalar field systems expressed in the formalism of exterior calculus, which is coordinate-free and immediately generalizes to arbitrary dimensions by construction. We demonstrate the performance of this approach in the FitzHugh-Nagumo and Barkley reaction-diffusion models, as well as the Patlak-Keller-Segel model informed by in-situ chemotactic bacteria observations. We provide extensive numerical experiments that demonstrate that our approach allows for seamless transitions across various spatial contexts. We show that the field dynamics learned in one space can be used to make accurate predictions in other spaces with different dimensions, coordinate systems, boundary conditions, and curvatures.","authors":["Trung V. Phan","George A. Kevrekidis","Soledad Villar","Yannis G. Kevrekidis","Juan M. Bello-Rivas"],"url":"https://arxiv.org/abs/2505.16549"}
{"created":"2025-05-23","title":"Towards Machine-actionable FAIR Digital Objects with a Typing Model that Enables Operations","abstract":"FAIR Digital Objects support research data management aligned with the FAIR principles. To be machine-actionable, they must support operations that interact with their contents. This can be achieved by associating operations with FAIR-DO data types. However, current typing models and Data Type Registries lack support for type-associated operations. In this work, we introduce a typing model that describes type-associated and technology-agnostic FAIR Digital Object Operations in a machine-actionable way, building and improving on the existing concepts. In addition, we introduce the Integrated Data Type and Operations Registry with Inheritance System, a prototypical implementation of this model that integrates inheritance mechanisms for data types, a rule-based validation system, and the computation of type-operation associations. Our approach significantly improves the machine-actionability of FAIR Digital Objects, paving the way towards dynamic, interoperable, and reproducible research workflows.","authors":["Maximilian Inckmann","Nicolas Blumenr\\\"ohr","Rossella Aversa"],"url":"https://arxiv.org/abs/2505.16550"}
{"created":"2025-05-23","title":"Restricted Chase Termination: You Want More than Fairness","abstract":"The chase is a fundamental algorithm with ubiquitous uses in database theory. Given a database and a set of existential rules (aka tuple-generating dependencies), it iteratively extends the database to ensure that the rules are satisfied in a most general way. This process may not terminate, and a major problem is to decide whether it does. This problem has been studied for a large number of chase variants, which differ by the conditions under which a rule is applied to extend the database. Surprisingly, the complexity of the universal termination of the restricted (aka standard) chase is not fully understood. We close this gap by placing universal restricted chase termination in the analytical hierarchy. This higher hardness is due to the fairness condition, and we propose an alternative condition to reduce the hardness of universal termination.","authors":["David Carral","Lukas Gerlach","Lucas Larroque","Micha\\\"el Thomazo"],"url":"https://arxiv.org/abs/2505.16551"}
{"created":"2025-05-23","title":"Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains","abstract":"Large Language Models (LLMs) achieve superior performance through Chain-of-Thought (CoT) reasoning, but these token-level reasoning chains are computationally expensive and inefficient. In this paper, we introduce Compressed Latent Reasoning (CoLaR), a novel framework that dynamically compresses reasoning processes in latent space through a two-stage training approach. First, during supervised fine-tuning, CoLaR extends beyond next-token prediction by incorporating an auxiliary next compressed embedding prediction objective. This process merges embeddings of consecutive tokens using a compression factor randomly sampled from a predefined range, and trains a specialized latent head to predict distributions of subsequent compressed embeddings. Second, we enhance CoLaR through reinforcement learning (RL) that leverages the latent head's non-deterministic nature to explore diverse reasoning paths and exploit more compact ones. This approach enables CoLaR to: i) perform reasoning at a dense latent level (i.e., silently), substantially reducing reasoning chain length, and ii) dynamically adjust reasoning speed at inference time by simply prompting the desired compression factor. Extensive experiments across four mathematical reasoning datasets demonstrate that CoLaR achieves 14.1% higher accuracy than latent-based baseline methods at comparable compression ratios, and reduces reasoning chain length by 53.3% with only 4.8% performance degradation compared to explicit CoT method. Moreover, when applied to more challenging mathematical reasoning tasks, our RL-enhanced CoLaR demonstrates performance gains of up to 5.4% while dramatically reducing latent reasoning chain length by 82.8%. The code and models will be released upon acceptance.","authors":["Wenhui Tan","Jiaze Li","Jianzhong Ju","Zhenbo Luo","Jian Luan","Ruihua Song"],"url":"https://arxiv.org/abs/2505.16552"}
{"created":"2025-05-23","title":"Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning","abstract":"The rise of Large Language Model-based Multi-Agent Planning has leveraged advanced frameworks to enable autonomous and collaborative task execution. Some systems rely on platforms like review sites and social media, which are prone to fraudulent information, such as fake reviews or misleading descriptions. This reliance poses risks, potentially causing financial losses and harming user experiences. To evaluate the risk of planning systems in real-world applications, we introduce \\textbf{WandaPlan}, an evaluation environment mirroring real-world data and injected with deceptive content. We assess system performance across three fraud cases: Misinformation Fraud, Team-Coordinated Multi-Person Fraud, and Level-Escalating Multi-Round Fraud. We reveal significant weaknesses in existing frameworks that prioritize task efficiency over data authenticity. At the same time, we validate WandaPlan's generalizability, capable of assessing the risks of real-world open-source planning frameworks. To mitigate the risk of fraud, we propose integrating an anti-fraud agent, providing a solution for reliable planning.","authors":["Junchi Yao","Jianhua Xu","Tianyu Xin","Ziyi Wang","Shenzhe Zhu","Shu Yang","Di Wang"],"url":"https://arxiv.org/abs/2505.16557"}
{"created":"2025-05-23","title":"CTRAP: Embedding Collapse Trap to Safeguard Large Language Models from Harmful Fine-Tuning","abstract":"Fine-tuning-as-a-service, while commercially successful for Large Language Model (LLM) providers, exposes models to harmful fine-tuning attacks. As a widely explored defense paradigm against such attacks, unlearning attempts to remove malicious knowledge from LLMs, thereby essentially preventing them from being used to perform malicious tasks. However, we highlight a critical flaw: the powerful general adaptability of LLMs allows them to easily bypass selective unlearning by rapidly relearning or repurposing their capabilities for harmful tasks. To address this fundamental limitation, we propose a paradigm shift: instead of selective removal, we advocate for inducing model collapse--effectively forcing the model to \"unlearn everything\"--specifically in response to updates characteristic of malicious adaptation. This collapse directly neutralizes the very general capabilities that attackers exploit, tackling the core issue unaddressed by selective unlearning. We introduce the Collapse Trap (CTRAP) as a practical mechanism to implement this concept conditionally. Embedded during alignment, CTRAP pre-configures the model's reaction to subsequent fine-tuning dynamics. If updates during fine-tuning constitute a persistent attempt to reverse safety alignment, the pre-configured trap triggers a progressive degradation of the model's core language modeling abilities, ultimately rendering it inert and useless for the attacker. Crucially, this collapse mechanism remains dormant during benign fine-tuning, ensuring the model's utility and general capabilities are preserved for legitimate users. Extensive empirical results demonstrate that CTRAP effectively counters harmful fine-tuning risks across various LLMs and attack settings, while maintaining high performance in benign scenarios. Our code is available at https://anonymous.4open.science/r/CTRAP.","authors":["Biao Yi","Tiansheng Huang","Baolei Zhang","Tong Li","Lihai Nie","Zheli Liu","Li Shen"],"url":"https://arxiv.org/abs/2505.16559"}
{"created":"2025-05-23","title":"Auto-nnU-Net: Towards Automated Medical Image Segmentation","abstract":"Medical Image Segmentation (MIS) includes diverse tasks, from bone to organ segmentation, each with its own challenges in finding the best segmentation model. The state-of-the-art AutoML-related MIS-framework nnU-Net automates many aspects of model configuration but remains constrained by fixed hyperparameters and heuristic design choices. As a full-AutoML framework for MIS, we propose Auto-nnU-Net, a novel nnU-Net variant enabling hyperparameter optimization (HPO), neural architecture search (NAS), and hierarchical NAS (HNAS). Additionally, we propose Regularized PriorBand to balance model accuracy with the computational resources required for training, addressing the resource constraints often faced in real-world medical settings that limit the feasibility of extensive training procedures. We evaluate our approach across diverse MIS datasets from the well-established Medical Segmentation Decathlon, analyzing the impact of AutoML techniques on segmentation performance, computational efficiency, and model design choices. The results demonstrate that our AutoML approach substantially improves the segmentation performance of nnU-Net on 6 out of 10 datasets and is on par on the other datasets while maintaining practical resource requirements. Our code is available at https://github.com/LUH-AI/AutonnUNet.","authors":["Jannis Becktepe","Leona Hennig","Steffen Oeltze-Jafra","Marius Lindauer"],"url":"https://arxiv.org/abs/2505.16561"}
{"created":"2025-05-23","title":"A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices","abstract":"The demand for machine learning (ML) model training on edge devices is escalating due to data privacy and personalized service needs. However, we observe that current on-device model training is hampered by the under-utilization of on-device data, due to low training throughput, limited storage and diverse data importance. To improve data resource utilization, we propose a two-stage data selection framework {\\sf Titan} to select the most important data batch from streaming data for model training with guaranteed efficiency and effectiveness. Specifically, in the first stage, {\\sf Titan} filters out a candidate dataset with potentially high importance in a coarse-grained manner.In the second stage of fine-grained selection, we propose a theoretically optimal data selection strategy to identify the data batch with the highest model performance improvement to current training round. To further enhance time-and-resource efficiency, {\\sf Titan} leverages a pipeline to co-execute data selection and model training, and avoids resource conflicts by exploiting idle computing resources. We evaluate {\\sf Titan} on real-world edge devices and three representative edge computing tasks with diverse models and data modalities. Empirical results demonstrate that {\\sf Titan} achieves up to $43\\%$ reduction in training time and $6.2\\%$ increase in final accuracy with minor system overhead, such as data processing delay, memory footprint and energy consumption.","authors":["Chen Gong","Rui Xing","Zhenzhe Zheng","Fan Wu"],"url":"https://arxiv.org/abs/2505.16563"}
{"created":"2025-05-23","title":"M2SVid: End-to-End Inpainting and Refinement for Monocular-to-Stereo Video Conversion","abstract":"We tackle the problem of monocular-to-stereo video conversion and propose a novel architecture for inpainting and refinement of the warped right view obtained by depth-based reprojection of the input left view. We extend the Stable Video Diffusion (SVD) model to utilize the input left video, the warped right video, and the disocclusion masks as conditioning input to generate a high-quality right camera view. In order to effectively exploit information from neighboring frames for inpainting, we modify the attention layers in SVD to compute full attention for discoccluded pixels. Our model is trained to generate the right view video in an end-to-end manner by minimizing image space losses to ensure high-quality generation. Our approach outperforms previous state-of-the-art methods, obtaining an average rank of 1.43 among the 4 compared methods in a user study, while being 6x faster than the second placed method.","authors":["Nina Shvetsova","Goutam Bhat","Prune Truong","Hilde Kuehne","Federico Tombari"],"url":"https://arxiv.org/abs/2505.16565"}
{"created":"2025-05-23","title":"ScholarBench: A Bilingual Benchmark for Abstraction, Comprehension, and Reasoning Evaluation in Academic Contexts","abstract":"Prior benchmarks for evaluating the domain-specific knowledge of large language models (LLMs) lack the scalability to handle complex academic tasks. To address this, we introduce \\texttt{ScholarBench}, a benchmark centered on deep expert knowledge and complex academic problem-solving, which evaluates the academic reasoning ability of LLMs and is constructed through a three-step process. \\texttt{ScholarBench} targets more specialized and logically complex contexts derived from academic literature, encompassing five distinct problem types. Unlike prior benchmarks, \\texttt{ScholarBench} evaluates the abstraction, comprehension, and reasoning capabilities of LLMs across eight distinct research domains. To ensure high-quality evaluation data, we define category-specific example attributes and design questions that are aligned with the characteristic research methodologies and discourse structures of each domain. Additionally, this benchmark operates as an English-Korean bilingual dataset, facilitating simultaneous evaluation for linguistic capabilities of LLMs in both languages. The benchmark comprises 5,031 examples in Korean and 5,309 in English, with even state-of-the-art models like o3-mini achieving an average evaluation score of only 0.543, demonstrating the challenging nature of this benchmark.","authors":["Dongwon Noh","Donghyeok Koh","Junghun Yuk","Gyuwan Kim","Jaeyong Lee","Kyungtae Lim","Cheoneum Park"],"url":"https://arxiv.org/abs/2505.16566"}
{"created":"2025-05-23","title":"Finetuning-Activated Backdoors in LLMs","abstract":"Finetuning openly accessible Large Language Models (LLMs) has become standard practice for achieving task-specific performance improvements. Until now, finetuning has been regarded as a controlled and secure process in which training on benign datasets led to predictable behaviors. In this paper, we demonstrate for the first time that an adversary can create poisoned LLMs that initially appear benign but exhibit malicious behaviors once finetuned by downstream users. To this end, our proposed attack, FAB (Finetuning-Activated Backdoor), poisons an LLM via meta-learning techniques to simulate downstream finetuning, explicitly optimizing for the emergence of malicious behaviors in the finetuned models. At the same time, the poisoned LLM is regularized to retain general capabilities and to exhibit no malicious behaviors prior to finetuning. As a result, when users finetune the seemingly benign model on their own datasets, they unknowingly trigger its hidden backdoor behavior. We demonstrate the effectiveness of FAB across multiple LLMs and three target behaviors: unsolicited advertising, refusal, and jailbreakability. Additionally, we show that FAB-backdoors are robust to various finetuning choices made by the user (e.g., dataset, number of steps, scheduler). Our findings challenge prevailing assumptions about the security of finetuning, revealing yet another critical attack vector exploiting the complexities of LLMs.","authors":["Thibaud Gloaguen","Mark Vero","Robin Staab","Martin Vechev"],"url":"https://arxiv.org/abs/2505.16567"}
{"created":"2025-05-23","title":"URLs Help, Topics Guide: Understanding Metadata Utility in LLM Training","abstract":"Large Language Models (LLMs) are commonly pretrained on vast corpora of text without utilizing contextual metadata such as source, quality, or topic, leading to a context-free learning paradigm. While recent studies suggest that adding metadata like URL information as context (i.e., auxiliary inputs not used in the loss calculation) can improve training efficiency and downstream performance, they offer limited understanding of which types of metadata are truly effective and under what conditions. In this work, we conduct a systematic evaluation and find that not all metadata types contribute equally. Only URL context speeds up training, whereas quality scores and topic/format domain information offer no clear benefit. Furthermore, the improved downstream performances of URL conditioning emerge only when longer prompts are used at inference time. In addition, we demonstrate that context-aware pretraining enables more controllable generation than context-free pretraining, in a classifier-free guidance fashion. Although topic and format metadata do not accelerate training, they are effective for steering outputs, offering human-interpretable control over generation.","authors":["Dongyang Fan","Vinko Sabol\\v{c}ec","Martin Jaggi"],"url":"https://arxiv.org/abs/2505.16570"}
{"created":"2025-05-23","title":"From Local Patterns to Global Understanding: Cross-Stock Trend Integration for Enhanced Predictive Modeling","abstract":"Stock price prediction is a critical area of financial forecasting, traditionally approached by training models using the historical price data of individual stocks. While these models effectively capture single-stock patterns, they fail to leverage potential correlations among stock trends, which could improve predictive performance. Current single-stock learning methods are thus limited in their ability to provide a broader understanding of price dynamics across multiple stocks. To address this, we propose a novel method that merges local patterns into a global understanding through cross-stock pattern integration. Our strategy is inspired by Federated Learning (FL), a paradigm designed for decentralized model training. FL enables collaborative learning across distributed datasets without sharing raw data, facilitating the aggregation of global insights while preserving data privacy. In our adaptation, we train models on individual stock data and iteratively merge them to create a unified global model. This global model is subsequently fine-tuned on specific stock data to retain local relevance. The proposed strategy enables parallel training of individual stock models, facilitating efficient utilization of computational resources and reducing overall training time. We conducted extensive experiments to evaluate the proposed method, demonstrating that it outperforms benchmark models and enhances the predictive capabilities of state-of-the-art approaches. Our results highlight the efficacy of Cross-Stock Trend Integration (CSTI) in advancing stock price prediction, offering a robust alternative to traditional single-stock learning methodologies.","authors":["Yi Hu","Hanchi Ren","Jingjing Deng","Xianghua Xie"],"url":"https://arxiv.org/abs/2505.16573"}
{"created":"2025-05-23","title":"Data Center Model for Transient Stability Analysis of Power Systems","abstract":"The rising demand of computing power leads to the installation of a large number of Data Centers (DCs). Their Fault-Ride-Through (FRT) behavior and their unique power characteristics, especially for DCs catered to Artificial Intelligence (AI) workloads, pose a threat to the stability of power systems. To ensure its stability, it is required accurate models of the loads involved. Here we propose a dynamic load model that properly captures the behaviour of DCs. Its three most defining features are the use of an Uninterrupted Power Supply (UPS) which sits between the server load and the grid, the cooling load represented by an induction motor, and a pulsing load that represents the transients caused by contemporary DCs with significant AI workloads. The features of the proposed model and its impact on the dynamic performance of transmission systems are illustrated through a model of the all-island Irish transmission system and real-world data of the DCs currently connected to this system.","authors":["Alberto Jimenez-Ruiz","Federico Milano"],"url":"https://arxiv.org/abs/2505.16575"}
{"created":"2025-05-23","title":"EMULATE: A Multi-Agent Framework for Determining the Veracity of Atomic Claims by Emulating Human Actions","abstract":"Determining the veracity of atomic claims is an imperative component of many recently proposed fact-checking systems. Many approaches tackle this problem by first retrieving evidence by querying a search engine and then performing classification by providing the evidence set and atomic claim to a large language model, but this process deviates from what a human would do in order to perform the task. Recent work attempted to address this issue by proposing iterative evidence retrieval, allowing for evidence to be collected several times and only when necessary. Continuing along this line of research, we propose a novel claim verification system, called EMULATE, which is designed to better emulate human actions through the use of a multi-agent framework where each agent performs a small part of the larger task, such as ranking search results according to predefined criteria or evaluating webpage content. Extensive experiments on several benchmarks show clear improvements over prior work, demonstrating the efficacy of our new multi-agent framework.","authors":["Spencer Hong","Meng Luo","Xinyi Wan"],"url":"https://arxiv.org/abs/2505.16576"}
{"created":"2025-05-23","title":"Large Language Model-Empowered Interactive Load Forecasting","abstract":"The growing complexity of power systems has made accurate load forecasting more important than ever. An increasing number of advanced load forecasting methods have been developed. However, the static design of current methods offers no mechanism for human-model interaction. As the primary users of forecasting models, system operators often find it difficult to understand and apply these advanced models, which typically requires expertise in artificial intelligence (AI). This also prevents them from incorporating their experience and real-world contextual understanding into the forecasting process. Recent breakthroughs in large language models (LLMs) offer a new opportunity to address this issue. By leveraging their natural language understanding and reasoning capabilities, we propose an LLM-based multi-agent collaboration framework to bridge the gap between human operators and forecasting models. A set of specialized agents is designed to perform different tasks in the forecasting workflow and collaborate via a dedicated communication mechanism. This framework embeds interactive mechanisms throughout the load forecasting pipeline, reducing the technical threshold for non-expert users and enabling the integration of human experience. Our experiments demonstrate that the interactive load forecasting accuracy can be significantly improved when users provide proper insight in key stages. Our cost analysis shows that the framework remains affordable, making it practical for real-world deployment.","authors":["Yu Zuo","Dalin Qin","Yi Wang"],"url":"https://arxiv.org/abs/2505.16577"}
{"created":"2025-05-23","title":"Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning","abstract":"While chains-of-thought (CoT) have advanced complex reasoning in multimodal large language models (MLLMs), existing methods remain confined to text or static visual domains, often faltering in dynamic spatial reasoning tasks. To bridge this gap, we present GRASSLAND, a novel maze navigation benchmark designed to evaluate dynamic spatial reasoning. Our experiments show that augmenting textual reasoning chains with dynamic visual drafts, overlaid on input images, significantly outperforms conventional approaches, offering new insights into spatial reasoning in evolving environments. To generalize this capability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free framework that seamlessly integrates textual CoT with corresponding visual drafts into MLLMs. Extensive evaluations demonstrate that D2R consistently enhances performance across diverse tasks, establishing a robust baseline for dynamic spatial reasoning without requiring model fine-tuning. Project is open at https://github.com/Cratileo/D2R.","authors":["Siqu Ou","Hongcheng Liu","Pingjie Wang","Yusheng Liao","Chuan Xuan","Yanfeng Wang","Yu Wang"],"url":"https://arxiv.org/abs/2505.16579"}
{"created":"2025-05-23","title":"How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning","abstract":"In the zero-shot policy transfer setting in reinforcement learning, the goal is to train an agent on a fixed set of training environments so that it can generalise to similar, but unseen, testing environments. Previous work has shown that policy distillation after training can sometimes produce a policy that outperforms the original in the testing environments. However, it is not yet entirely clear why that is, or what data should be used to distil the policy. In this paper, we prove, under certain assumptions, a generalisation bound for policy distillation after training. The theory provides two practical insights: for improved generalisation, you should 1) train an ensemble of distilled policies, and 2) distil it on as much data from the training environments as possible. We empirically verify that these insights hold in more general settings, when the assumptions required for the theory no longer hold. Finally, we demonstrate that an ensemble of policies distilled on a diverse dataset can generalise significantly better than the original agent.","authors":["Max Weltevrede","Moritz A. Zanger","Matthijs T. J. Spaan","Wendelin B\\\"ohmer"],"url":"https://arxiv.org/abs/2505.16581"}
{"created":"2025-05-23","title":"O$^2$-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering","abstract":"Large Language Models (LLMs), despite their advancements, are fundamentally limited by their static parametric knowledge, hindering performance on tasks requiring open-domain up-to-date information. While enabling LLMs to interact with external knowledge environments is a promising solution, current efforts primarily address closed-end problems. Open-ended questions, which characterized by lacking a standard answer or providing non-unique and diverse answers, remain underexplored. To bridge this gap, we present O$^2$-Searcher, a novel search agent leveraging reinforcement learning to effectively tackle both open-ended and closed-ended questions in the open domain. O$^2$-Searcher leverages an efficient, locally simulated search environment for dynamic knowledge acquisition, effectively decoupling the external world knowledge from model's sophisticated reasoning processes. It employs a unified training mechanism with meticulously designed reward functions, enabling the agent to identify problem types and adapt different answer generation strategies. Furthermore, to evaluate performance on complex open-ended tasks, we construct O$^2$-QA, a high-quality benchmark featuring 300 manually curated, multi-domain open-ended questions with associated web page caches. Extensive experiments show that O$^2$-Searcher, using only a 3B model, significantly surpasses leading LLM agents on O$^2$-QA. It also achieves SOTA results on various closed-ended QA benchmarks against similarly-sized models, while performing on par with much larger ones.","authors":["Jianbiao Mei","Tao Hu","Daocheng Fu","Licheng Wen","Xuemeng Yang","Rong Wu","Pinlong Cai","Xing Gao","Yu Yang","Chengjun Xie","Botian Shi","Yong Liu","Yu Qiao"],"url":"https://arxiv.org/abs/2505.16582"}
{"created":"2025-05-23","title":"Training on Plausible Counterfactuals Removes Spurious Correlations","abstract":"Plausible counterfactual explanations (p-CFEs) are perturbations that minimally modify inputs to change classifier decisions while remaining plausible under the data distribution. In this study, we demonstrate that classifiers can be trained on p-CFEs labeled with induced \\emph{incorrect} target classes to classify unperturbed inputs with the original labels. While previous studies have shown that such learning is possible with adversarial perturbations, we extend this paradigm to p-CFEs. Interestingly, our experiments reveal that learning from p-CFEs is even more effective: the resulting classifiers achieve not only high in-distribution accuracy but also exhibit significantly reduced bias with respect to spurious correlations.","authors":["Shpresim Sadiku","Kartikeya Chitranshi","Hiroshi Kera","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2505.16583"}
{"created":"2025-05-23","title":"A Survey on the Application of Large Language Models in Scenario-Based Testing of Automated Driving Systems","abstract":"The safety and reliability of Automated Driving Systems (ADSs) must be validated prior to large-scale deployment. Among existing validation approaches, scenario-based testing has been regarded as a promising method to improve testing efficiency and reduce associated costs. Recently, the emergence of Large Language Models (LLMs) has introduced new opportunities to reinforce this approach. While an increasing number of studies have explored the use of LLMs in the field of automated driving, a dedicated review focusing on their application within scenario-based testing remains absent. This survey addresses this gap by systematically categorizing the roles played by LLMs across various phased of scenario-based testing, drawing from both academic research and industrial practice. In addition, key characteristics of LLMs and corresponding usage strategies are comprehensively summarized. The paper concludes by outlining five open challenges and potential research directions. To support ongoing research efforts, a continuously updated repository of recent advancements and relevant open-source tools is made available at: https://github.com/ftgTUGraz/LLM4ADSTest.","authors":["Yongqi Zhao","Ji Zhou","Dong Bi","Tomislav Mihalj","Jia Hu","Arno Eichberger"],"url":"https://arxiv.org/abs/2505.16587"}
{"created":"2025-05-23","title":"Beyond LLMs: An Exploration of Small Open-source Language Models in Logging Statement Generation","abstract":"Effective software maintenance heavily relies on high-quality logging statements, but manual logging is challenging, error-prone, and insufficiently standardized, often leading to inconsistent log quality. While large language models have shown promise in automatic logging, they introduce concerns regarding privacy, resource intensity, and adaptability to specific enterprise needs. To tackle these limitations, this paper empirically investigates whether Small Open-source Language Models (SOLMs) could become a viable alternative via proper exploitation. Specifically, we conduct a large-scale empirical study on four prominent SOLMs, systematically evaluating the impacts of various interaction strategies, parameter-efficient fine-tuning techniques, model sizes, and model types in automatic logging. Our key findings reveal that Retrieval-Augmented Generation significantly enhances performance, and LoRA is a highly effective PEFT technique. While larger SOLMs tend to perform better, this involves a trade-off with computational resources, and instruct-tuned SOLMs generally surpass their base counterparts. Notably, fine-tuned SOLMs, particularly Qwen2.5-coder-14B, outperformed existing specialized tools and LLM baselines in accurately predicting logging locations and generating high-quality statements, a conclusion supported by traditional evaluation metrics and LLM-as-a-judge evaluations. Furthermore, SOLMs also demonstrated robust generalization across diverse, unseen code repositories.","authors":["Renyi Zhong","Yichen Li","Guangba Yu","Wenwei Gu","Jinxi Kuang","Yintong Huo","Michael R. Lyu"],"url":"https://arxiv.org/abs/2505.16590"}
{"created":"2025-05-23","title":"Evaluating Large Language Model with Knowledge Oriented Language Specific Simple Question Answering","abstract":"We introduce KoLasSimpleQA, the first benchmark evaluating the multilingual factual ability of Large Language Models (LLMs). Inspired by existing research, we created the question set with features such as single knowledge point coverage, absolute objectivity, unique answers, and temporal stability. These questions enable efficient evaluation using the LLM-as-judge paradigm, testing both the LLMs' factual memory and self-awareness (\"know what they don't know\"). KoLasSimpleQA expands existing research in two key dimensions: (1) Breadth (Multilingual Coverage): It includes 9 languages, supporting global applicability evaluation. (2) Depth (Dual Domain Design): It covers both the general domain (global facts) and the language-specific domain (such as history, culture, and regional traditions) for a comprehensive assessment of multilingual capabilities. We evaluated mainstream LLMs, including traditional LLM and emerging Large Reasoning Models. Results show significant performance differences between the two domains, particularly in performance metrics, ranking, calibration, and robustness. This highlights the need for targeted evaluation and optimization in multilingual contexts. We hope KoLasSimpleQA will help the research community better identify LLM capability boundaries in multilingual contexts and provide guidance for model optimization. We will release KoLasSimpleQA at https://github.com/opendatalab/KoLasSimpleQA .","authors":["Bowen Jiang","Runchuan Zhu","Jiang Wu","Zinco Jiang","Yifan He","Junyuan Gao","Jia Yu","Rui Min","Yinfan Wang","Haote Yang","Songyang Zhang","Dahua Lin","Lijun Wu","Conghui He"],"url":"https://arxiv.org/abs/2505.16591"}
{"created":"2025-05-23","title":"What Media Frames Reveal About Stance: A Dataset and Study about Memes in Climate Change Discourse","abstract":"Media framing refers to the emphasis on specific aspects of perceived reality to shape how an issue is defined and understood. Its primary purpose is to shape public perceptions often in alignment with the authors' opinions and stances. However, the interaction between stance and media frame remains largely unexplored. In this work, we apply an interdisciplinary approach to conceptualize and computationally explore this interaction with internet memes on climate change. We curate CLIMATEMEMES, the first dataset of climate-change memes annotated with both stance and media frames, inspired by research in communication science. CLIMATEMEMES includes 1,184 memes sourced from 47 subreddits, enabling analysis of frame prominence over time and communities, and sheds light on the framing preferences of different stance holders. We propose two meme understanding tasks: stance detection and media frame detection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the corresponding results on their LLM backbone. Human captions consistently enhance performance. Synthetic captions and human-corrected OCR also help occasionally. Our findings highlight that VLMs perform well on stance, but struggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs' limitations in handling nuanced frames and stance expressions on climate change internet memes.","authors":["Shijia Zhou","Siyao Peng","Simon Luebke","J\\\"org Ha{\\ss}ler","Mario Haim","Saif M. Mohammad","Barbara Plank"],"url":"https://arxiv.org/abs/2505.16592"}
{"created":"2025-05-23","title":"Temporal Object Captioning for Street Scene Videos from LiDAR Tracks","abstract":"Video captioning models have seen notable advancements in recent years, especially with regard to their ability to capture temporal information. While many research efforts have focused on architectural advancements, such as temporal attention mechanisms, there remains a notable gap in understanding how models capture and utilize temporal semantics for effective temporal feature extraction, especially in the context of Advanced Driver Assistance Systems. We propose an automated LiDAR-based captioning procedure that focuses on the temporal dynamics of traffic participants. Our approach uses a rule-based system to extract essential details such as lane position and relative motion from object tracks, followed by a template-based caption generation. Our findings show that training SwinBERT, a video captioning model, using only front camera images and supervised with our template-based captions, specifically designed to encapsulate fine-grained temporal behavior, leads to improved temporal understanding consistently across three datasets. In conclusion, our results clearly demonstrate that integrating LiDAR-based caption supervision significantly enhances temporal understanding, effectively addressing and reducing the inherent visual/static biases prevalent in current state-of-the-art model architectures.","authors":["Vignesh Gopinathan","Urs Zimmermann","Michael Arnold","Matthias Rottmann"],"url":"https://arxiv.org/abs/2505.16594"}
{"created":"2025-05-23","title":"Safe Uncertainty-Aware Learning of Robotic Suturing","abstract":"Robot-Assisted Minimally Invasive Surgery is currently fully manually controlled by a trained surgeon. Automating this has great potential for alleviating issues, e.g., physical strain, highly repetitive tasks, and shortages of trained surgeons. For these reasons, recent works have utilized Artificial Intelligence methods, which show promising adaptability. Despite these advances, there is skepticism of these methods because they lack explainability and robust safety guarantees. This paper presents a framework for a safe, uncertainty-aware learning method. We train an Ensemble Model of Diffusion Policies using expert demonstrations of needle insertion. Using an Ensemble model, we can quantify the policy's epistemic uncertainty, which is used to determine Out-Of-Distribution scenarios. This allows the system to release control back to the surgeon in the event of an unsafe scenario. Additionally, we implement a model-free Control Barrier Function to place formal safety guarantees on the predicted action. We experimentally evaluate our proposed framework using a state-of-the-art robotic suturing simulator. We evaluate multiple scenarios, such as dropping the needle, moving the camera, and moving the phantom. The learned policy is robust to these perturbations, showing corrective behaviors and generalization, and it is possible to detect Out-Of-Distribution scenarios. We further demonstrate that the Control Barrier Function successfully limits the action to remain within our specified safety set in the case of unsafe predictions.","authors":["Wilbert Peter Empleo","Yitaek Kim","Hansoul Kim","Thiusius Rajeeth Savarimuthu","I\\~nigo Iturrate"],"url":"https://arxiv.org/abs/2505.16596"}
{"created":"2025-05-23","title":"Decoupled Geometric Parameterization and its Application in Deep Homography Estimation","abstract":"Planar homography, with eight degrees of freedom (DOFs), is fundamental in numerous computer vision tasks. While the positional offsets of four corners are widely adopted (especially in neural network predictions), this parameterization lacks geometric interpretability and typically requires solving a linear system to compute the homography matrix. This paper presents a novel geometric parameterization of homographies, leveraging the similarity-kernel-similarity (SKS) decomposition for projective transformations. Two independent sets of four geometric parameters are decoupled: one for a similarity transformation and the other for the kernel transformation. Additionally, the geometric interpretation linearly relating the four kernel transformation parameters to angular offsets is derived. Our proposed parameterization allows for direct homography estimation through matrix multiplication, eliminating the need for solving a linear system, and achieves performance comparable to the four-corner positional offsets in deep homography estimation.","authors":["Yao Huang","Si-Yuan Cao","Yaqing Ding","Hao Yin","Shibin Xie","Shuting Wang","Zhijun Fang","Jiachun Wang","Shen Cai","Junchi Yan","Shuhan Shen"],"url":"https://arxiv.org/abs/2505.16599"}
{"created":"2025-05-23","title":"MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation","abstract":"Egocentric hand-object motion generation is crucial for immersive AR/VR and robotic imitation but remains challenging due to unstable viewpoints, self-occlusions, perspective distortion, and noisy ego-motion. Existing methods rely on predefined 3D object priors, limiting generalization to novel objects, which restricts their generalizability to novel objects. Meanwhile, recent multimodal approaches suffer from ambiguous generation from abstract textual cues, intricate pipelines for modeling 3D hand-object correlation, and compounding errors in open-loop prediction. We propose MEgoHand, a multimodal framework that synthesizes physically plausible hand-object interactions from egocentric RGB, text, and initial hand pose. MEgoHand introduces a bi-level architecture: a high-level \"cerebrum\" leverages a vision language model (VLM) to infer motion priors from visual-textual context and a monocular depth estimator for object-agnostic spatial reasoning, while a low-level DiT-based flow-matching policy generates fine-grained trajectories with temporal orthogonal filtering to enhance stability. To address dataset inconsistency, we design a dataset curation paradigm with an Inverse MANO Retargeting Network and Virtual RGB-D Renderer, curating a unified dataset of 3.35M RGB-D frames, 24K interactions, and 1.2K objects. Extensive experiments across five in-domain and two cross-domain datasets demonstrate the effectiveness of MEgoHand, achieving substantial reductions in wrist translation error (86.9%) and joint rotation error (34.1%), highlighting its capacity to accurately model fine-grained hand joint structures and generalize robustly across diverse scenarios.","authors":["Bohan Zhou","Yi Zhan","Zhongbin Zhang","Zongqing Lu"],"url":"https://arxiv.org/abs/2505.16602"}
{"created":"2025-05-23","title":"Monitoring Electrostatic Adhesion Forces via Acoustic Pressure","abstract":"Electrostatic adhesion is widely used in mobile robotics, haptics, and robotic end effectors for its adaptability to diverse substrates and low energy consumption. Force sensing is important for feedback control, interaction, and monitoring in the EA system. However, EA force monitoring often relies on bulky and expensive sensors, increasing the complexity and weight of the entire system. This paper presents an acoustic-pressure-based method to monitor EA forces without contacting the adhesion pad. When the EA pad is driven by a bipolar square-wave voltage to adhere a conductive object, periodic acoustic pulses arise from the EA system. We employed a microphone to capture these acoustic pressure signals and investigate the influence of peak pressure values. Results show that the peak value of acoustic pressure increased with the mass and contact area of the adhered object, as well as with the amplitude and frequency of the driving voltage. We applied this technique to mass estimation of various objects and simultaneous monitoring of two EA systems. Then, we integrated this technique into an EA end effector that enables monitoring the change of adhered object mass during transport. The proposed technique offers a low-cost, non-contact, and multi-object monitoring solution for EA end effectors in handling tasks.","authors":["Huacen Wang","Jiarui Zou","Zeju Zheng","Hongqiang Wang"],"url":"https://arxiv.org/abs/2505.16609"}
{"created":"2025-05-23","title":"From Generic Empathy to Personalized Emotional Support: A Self-Evolution Framework for User Preference Alignment","abstract":"Effective emotional support hinges on understanding users' emotions and needs to provide meaningful comfort during multi-turn interactions. Large Language Models (LLMs) show great potential for expressing empathy; however, they often deliver generic and one-size-fits-all responses that fail to address users' specific needs. To tackle this issue, we propose a self-evolution framework designed to help LLMs improve their responses to better align with users' implicit preferences concerning user profiles (personalities), emotional states, and specific situations. Our framework consists of two distinct phases: \\textit{(1)} \\textit{Emotional Support Experience Acquisition}, where LLMs are fine-tuned on limited emotional support conversation data to provide basic support, and \\textit{(2)} \\textit{Self-Improvement for Personalized Emotional Support}, where LLMs leverage self-reflection and self-refinement to generate personalized responses. Through iterative direct preference optimization between the pre- and post-refined responses, our model generates responses that reflect a better understanding of the user's implicit preferences. Extensive experiments and evaluations demonstrate that our method significantly enhances the model's performance in emotional support, reducing unhelpful responses and minimizing discrepancies between user preferences and model outputs.","authors":["Jing Ye","Lu Xiang","Yaping Zhang","Chengqing Zong"],"url":"https://arxiv.org/abs/2505.16610"}
{"created":"2025-05-23","title":"Steering Large Language Models for Machine Translation Personalization","abstract":"High-quality machine translation systems based on large language models (LLMs) have simplified the production of personalized translations reflecting specific stylistic constraints. However, these systems still struggle in settings where stylistic requirements are less explicit and might be harder to convey via prompting. We explore various strategies for personalizing LLM-generated translations in low-resource settings, focusing on the challenging literary translation domain. We explore prompting strategies and inference-time interventions for steering model generations towards a personalized style, and propose a contrastive framework exploiting latent concepts extracted from sparse autoencoders to identify salient personalization properties. Our results show that steering achieves strong personalization while preserving translation quality. We further examine the impact of steering on LLM representations, finding model layers with a relevant impact for personalization are impacted similarly by multi-shot prompting and our steering method, suggesting similar mechanism at play.","authors":["Daniel Scalena","Gabriele Sarti","Arianna Bisazza","Elisabetta Fersini","Malvina Nissim"],"url":"https://arxiv.org/abs/2505.16612"}
{"created":"2025-05-23","title":"Energy Consumption Framework and Analysis of Post-Quantum Key-Generation on Embedded Devices","abstract":"The emergence of quantum computing and Shor's algorithm necessitates an imminent shift from current public key cryptography techniques to post-quantum robust techniques. NIST has responded by standardising Post-Quantum Cryptography (PQC) algorithms, with ML-KEM (FIPS-203) slated to replace ECDH (Elliptic Curve Diffie-Hellman) for key exchange. A key practical concern for PQC adoption is energy consumption. This paper introduces a new framework for measuring the PQC energy consumption on a Raspberry Pi when performing key generation. The framework uses both available traditional methods and the newly standardised ML-KEM algorithm via the commonly utilised OpenSSL library.","authors":["J Cameron Patterson","William J Buchanan","Callum Turino"],"url":"https://arxiv.org/abs/2505.16614"}
{"created":"2025-05-23","title":"Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences","abstract":"Artificial intelligence (AI) has recently seen transformative breakthroughs in the life sciences, expanding possibilities for researchers to interpret biological information at an unprecedented capacity, with novel applications and advances being made almost daily. In order to maximise return on the growing investments in AI-based life science research and accelerate this progress, it has become urgent to address the exacerbation of long-standing research challenges arising from the rapid adoption of AI methods. We review the increased erosion of trust in AI research outputs, driven by the issues of poor reusability and reproducibility, and highlight their consequent impact on environmental sustainability. Furthermore, we discuss the fragmented components of the AI ecosystem and lack of guiding pathways to best support Open and Sustainable AI (OSAI) model development. In response, this perspective introduces a practical set of OSAI recommendations directly mapped to over 300 components of the AI ecosystem. Our work connects researchers with relevant AI resources, facilitating the implementation of sustainable, reusable and transparent AI. Built upon life science community consensus and aligned to existing efforts, the outputs of this perspective are designed to aid the future development of policy and structured pathways for guiding AI implementation.","authors":["Gavin Farrell (Department of Biomedical Sciences","University of Padova","Padova","Italy)","Eleni Adamidi (Athena Research","Innovation Center","Marousi","Greece)","Rafael Andrade Buono (VIB.AI Center for AI","Computational Biology","Ghent","Belgium)","Mihail Anton (ELIXIR Europe Hub","EMBL-EBI","Hinxton","United Kingdom)","Omar Abdelghani Attafi (Department of Biomedical Sciences","University of Padova","Padova","Italy)","Salvador Capella Gutierrez (Barcelona Supercomputing Center)","Emidio Capriotti (Department of Pharmacy","Biotechnology","University of Bologna","Bologna","Italy","Computational Genomics Platform","IRCCS University Hospital of Bologna","Bologna","Italy)","Leyla Jael Castro (ZB MED Information Centre for Life Sciences","Cologne","Germany)","Davide Cirillo (Barcelona Supercomputing Center)","Lisa Crossman (SequenceAnalysis.co.uk","United Kingdom","University of East Anglia","Norwich","United Kingdom)","Christophe Dessimoz (Department of Computational Biology","University of Lausanne","Lausanne","Switzerland","Swiss Institute of Bioinformatics","Lausanne","Switzerland)","Alexandros Dimopoulos (Institute for Fundamental Biomedical Science","Biomedical Sciences Research Center Alexander Fleming","Vari","Greece","Department of Informatics","Telematics","School of Digital Technology","Harokopio University","Athens","Greece)","Raul Fernandez-Diaz (School of Medicine","University College Dublin","Dublin","Ireland","Conway Institute of Biomolecular","Biomedical Research","University College Dublin","Dublin","Ireland","IBM Research Dublin","Dublin","Ireland)","Styliani-Christina Fragkouli (Institute of Applied Biosciences","Centre for Research","Technology Hellas","Thessaloniki","Greece","Department of Biology","National","Kapodistrian University of Athens","Athens","Greece)","Carole Goble (Department of Computer Science","University of Manchester","Manchester","United Kingdom)","Wei Gu (Luxembourg National Data Service","Esch-sur-Alzette","Luxembourg)","John M. Hancock (Institute of Biochemistry","Molecular Genetics","Faculty of Medicine","University of Ljubljana","Ljubljana","Slovenia)","Alireza Khanteymoori (Department of Psychology","University of Freiburg","Freiburg","Germany)","Tom Lenaerts (Machine Learning Group","Universite Libre de Bruxelles","Brussels","Belgium","Artificial Intelligence Lab","Vrije Universiteit Brussel","Brussels","Belgium","Interuniversity Institute of Bioinformatics in Brussels","ULB-VUB","Brussels","Belgium","FARI","AI for the common good institute","ULB-VUB","Brussels","Belgium","Center for Human-Compatible AI","UC Berkeley","Berkeley","CA","USA)","Fabio G. Liberante (ELIXIR Europe Hub","EMBL-EBI","Hinxton","United Kingdom)","Peter Maccallum (ELIXIR Europe Hub","EMBL-EBI","Hinxton","United Kingdom)","Alexander Miguel Monzon (Department of Biomedical Sciences","University of Padova","Padova","Italy)","Magnus Palmblad (Leiden University Medical Center","Leiden","Netherlands)","Lucy Poveda (Swiss Institute of Bioinformatics","Lausanne","Switzerland)","Ovidiu Radulescu (LPHI","University of Montpellier","CNRS","INSERM","Montpellier","France)","Denis C. Shields (School of Medicine","University College Dublin","Dublin","Ireland","Conway Institute of Biomolecular","Biomedical Research","University College Dublin","Dublin","Ireland)","Shoaib Sufi (Department of Computer Science","University of Manchester","Manchester","United Kingdom)","Thanasis Vergoulis (Athena Research","Innovation Center","Marousi","Greece)","Fotis Psomopoulos (Institute of Applied Biosciences","Centre for Research","Technology Hellas","Thessaloniki","Greece)","Silvio C. E. Tosatto (Department of Biomedical Sciences","University of Padova","Padova","Italy","Institute of Biomembranes","Bioenergetics","Molecular Biotechnologies","National Research Council)"],"url":"https://arxiv.org/abs/2505.16619"}
{"created":"2025-05-23","title":"CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models","abstract":"Causal discovery for dynamical systems poses a major challenge in fields where active interventions are infeasible. Most methods used to investigate these systems and their associated benchmarks are tailored to deterministic, low-dimensional and weakly nonlinear time-series data. To address these limitations, we present CausalDynamics, a large-scale benchmark and extensible data generation framework to advance the structural discovery of dynamical causal models. Our benchmark consists of true causal graphs derived from thousands of coupled ordinary and stochastic differential equations as well as two idealized climate models. We perform a comprehensive evaluation of state-of-the-art causal discovery algorithms for graph reconstruction on systems with noisy, confounded, and lagged dynamics. CausalDynamics consists of a plug-and-play, build-your-own coupling workflow that enables the construction of a hierarchy of physical systems. We anticipate that our framework will facilitate the development of robust causal discovery algorithms that are broadly applicable across domains while addressing their unique challenges. We provide a user-friendly implementation and documentation on https://kausable.github.io/CausalDynamics.","authors":["Benjamin Herdeanu","Juan Nathaniel","Carla Roesch","Jatan Buch","Gregor Ramien","Johannes Haux","Pierre Gentine"],"url":"https://arxiv.org/abs/2505.16620"}
{"created":"2025-05-23","title":"Grounding Chest X-Ray Visual Question Answering with Generated Radiology Reports","abstract":"We present a novel approach to Chest X-ray (CXR) Visual Question Answering (VQA), addressing both single-image image-difference questions. Single-image questions focus on abnormalities within a specific CXR (\"What abnormalities are seen in image X?\"), while image-difference questions compare two longitudinal CXRs acquired at different time points (\"What are the differences between image X and Y?\"). We further explore how the integration of radiology reports can enhance the performance of VQA models. While previous approaches have demonstrated the utility of radiology reports during the pre-training phase, we extend this idea by showing that the reports can also be leveraged as additional input to improve the VQA model's predicted answers. First, we propose a unified method that handles both types of questions and auto-regressively generates the answers. For single-image questions, the model is provided with a single CXR. For image-difference questions, the model is provided with two CXRs from the same patient, captured at different time points, enabling the model to detect and describe temporal changes. Taking inspiration from 'Chain-of-Thought reasoning', we demonstrate that performance on the CXR VQA task can be improved by grounding the answer generator module with a radiology report predicted for the same CXR. In our approach, the VQA model is divided into two steps: i) Report Generation (RG) and ii) Answer Generation (AG). Our results demonstrate that incorporating predicted radiology reports as evidence to the AG model enhances performance on both single-image and image-difference questions, achieving state-of-the-art results on the Medical-Diff-VQA dataset.","authors":["Francesco Dalla Serra","Patrick Schrempf","Chaoyang Wang","Zaiqiao Meng","Fani Deligianni","Alison Q. O'Neil"],"url":"https://arxiv.org/abs/2505.16624"}
{"created":"2025-05-23","title":"Background Matters: A Cross-view Bidirectional Modeling Framework for Semi-supervised Medical Image Segmentation","abstract":"Semi-supervised medical image segmentation (SSMIS) leverages unlabeled data to reduce reliance on manually annotated images. However, current SOTA approaches predominantly focus on foreground-oriented modeling (i.e., segmenting only the foreground region) and have largely overlooked the potential benefits of explicitly modeling the background region. Our study theoretically and empirically demonstrates that highly certain predictions in background modeling enhance the confidence of corresponding foreground modeling. Building on this insight, we propose the Cross-view Bidirectional Modeling (CVBM) framework, which introduces a novel perspective by incorporating background modeling to improve foreground modeling performance. Within CVBM, background modeling serves as an auxiliary perspective, providing complementary supervisory signals to enhance the confidence of the foreground model. Additionally, CVBM introduces an innovative bidirectional consistency mechanism, which ensures mutual alignment between foreground predictions and background-guided predictions. Extensive experiments demonstrate that our approach achieves SOTA performance on the LA, Pancreas, ACDC, and HRF datasets. Notably, on the Pancreas dataset, CVBM outperforms fully supervised methods (i.e., DSC: 84.57% vs. 83.89%) while utilizing only 20% of the labeled data. Our code is publicly available at https://github.com/caoluyang0830/CVBM.git.","authors":["Luyang Cao","Jianwei Li","Yinghuan Shi"],"url":"https://arxiv.org/abs/2505.16625"}
{"created":"2025-05-23","title":"SoccerChat: Integrating Multimodal Data for Enhanced Soccer Game Understanding","abstract":"The integration of artificial intelligence in sports analytics has transformed soccer video understanding, enabling real-time, automated insights into complex game dynamics. Traditional approaches rely on isolated data streams, limiting their effectiveness in capturing the full context of a match. To address this, we introduce SoccerChat, a multimodal conversational AI framework that integrates visual and textual data for enhanced soccer video comprehension. Leveraging the extensive SoccerNet dataset, enriched with jersey color annotations and automatic speech recognition (ASR) transcripts, SoccerChat is fine-tuned on a structured video instruction dataset to facilitate accurate game understanding, event classification, and referee decision making. We benchmark SoccerChat on action classification and referee decision-making tasks, demonstrating its performance in general soccer event comprehension while maintaining competitive accuracy in referee decision making. Our findings highlight the importance of multimodal integration in advancing soccer analytics, paving the way for more interactive and explainable AI-driven sports analysis. https://github.com/simula/SoccerChat","authors":["Sushant Gautam","Cise Midoglu","Vajira Thambawita","Michael A. Riegler","P{\\aa}l Halvorsen","Mubarak Shah"],"url":"https://arxiv.org/abs/2505.16630"}
{"created":"2025-05-23","title":"MiLQ: Benchmarking IR Models for Bilingual Web Search with Mixed Language Queries","abstract":"Despite bilingual speakers frequently using mixed-language queries in web searches, Information Retrieval (IR) research on them remains scarce. To address this, we introduce MiLQ,Mixed-Language Query test set, the first public benchmark of mixed-language queries, confirmed as realistic and highly preferred. Experiments show that multilingual IR models perform moderately on MiLQ and inconsistently across native, English, and mixed-language queries, also suggesting code-switched training data's potential for robust IR models handling such queries. Meanwhile, intentional English mixing in queries proves an effective strategy for bilinguals searching English documents, which our analysis attributes to enhanced token matching compared to native queries.","authors":["Jonghwi Kim","Deokhyung Kang","Seonjeong Hwang","Yunsu Kim","Jungseul Ok","Gary Lee"],"url":"https://arxiv.org/abs/2505.16631"}
{"created":"2025-05-23","title":"Towards Texture- And Shape-Independent 3D Keypoint Estimation in Birds","abstract":"In this paper, we present a texture-independent approach to estimate and track 3D joint positions of multiple pigeons. For this purpose, we build upon the existing 3D-MuPPET framework, which estimates and tracks the 3D poses of up to 10 pigeons using a multi-view camera setup. We extend this framework by using a segmentation method that generates silhouettes of the individuals, which are then used to estimate 2D keypoints. Following 3D-MuPPET, these 2D keypoints are triangulated to infer 3D poses, and identities are matched in the first frame and tracked in 2D across subsequent frames. Our proposed texture-independent approach achieves comparable accuracy to the original texture-dependent 3D-MuPPET framework. Additionally, we explore our approach's applicability to other bird species. To do that, we infer the 2D joint positions of four bird species without additional fine-tuning the model trained on pigeons and obtain preliminary promising results. Thus, we think that our approach serves as a solid foundation and inspires the development of more robust and accurate texture-independent pose estimation frameworks.","authors":["Valentin Schmuker","Alex Hoi Hang Chan","Bastian Goldluecke","Urs Waldmann"],"url":"https://arxiv.org/abs/2505.16633"}
{"created":"2025-05-23","title":"WikiDBGraph: Large-Scale Database Graph of Wikidata for Collaborative Learning","abstract":"Tabular data, ubiquitous and rich in informational value, is an increasing focus for deep representation learning, yet progress is hindered by studies centered on single tables or isolated databases, which limits model capabilities due to data scale. While collaborative learning approaches such as federated learning, transfer learning, split learning, and tabular foundation models aim to learn from multiple correlated databases, they are challenged by a scarcity of real-world interconnected tabular resources. Current data lakes and corpora largely consist of isolated databases lacking defined inter-database correlations. To overcome this, we introduce WikiDBGraph, a large-scale graph of 100,000 real-world tabular databases from WikiData, interconnected by 17 million edges and characterized by 13 node and 12 edge properties derived from its database schema and data distribution. WikiDBGraph's weighted edges identify both instance- and feature-overlapped databases. Experiments on these newly identified databases confirm that collaborative learning yields superior performance, thereby offering considerable promise for structured foundation model training while also exposing key challenges and future directions for learning from interconnected tabular data.","authors":["Zhaomin Wu","Ziyang Wang","Bingsheng He"],"url":"https://arxiv.org/abs/2505.16635"}
{"created":"2025-05-23","title":"Multivariate Latent Recalibration for Conditional Normalizing Flows","abstract":"Reliably characterizing the full conditional distribution of a multivariate response variable given a set of covariates is crucial for trustworthy decision-making. However, misspecified or miscalibrated multivariate models may yield a poor approximation of the joint distribution of the response variables, leading to unreliable predictions and suboptimal decisions. Furthermore, standard recalibration methods are primarily limited to univariate settings, while conformal prediction techniques, despite generating multivariate prediction regions with coverage guarantees, do not provide a full probability density function. We address this gap by first introducing a novel notion of latent calibration, which assesses probabilistic calibration in the latent space of a conditional normalizing flow. Second, we propose latent recalibration (LR), a novel post-hoc model recalibration method that learns a transformation of the latent space with finite-sample bounds on latent calibration. Unlike existing methods, LR produces a recalibrated distribution with an explicit multivariate density function while remaining computationally efficient. Extensive experiments on both tabular and image datasets show that LR consistently improves latent calibration error and the negative log-likelihood of the recalibrated models.","authors":["Victor Dheur","Souhaib Ben Taieb"],"url":"https://arxiv.org/abs/2505.16636"}
{"created":"2025-05-23","title":"SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation","abstract":"Large language models (LLMs) have recently demonstrated remarkable capabilities in machine translation (MT). However, most advanced MT-specific LLMs heavily rely on external supervision signals during training, such as human-annotated reference data or trained reward models (RMs), which are often expensive to obtain and challenging to scale. To overcome this limitation, we propose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for MT that is reference-free, fully online, and relies solely on self-judging rewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as the backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs, e.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like Qwen2.5-32B-Instruct in English $\\leftrightarrow$ Chinese translation tasks from WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR with external supervision from COMET, our strongest model, SSR-X-Zero-7B, achieves state-of-the-art performance in English $\\leftrightarrow$ Chinese translation, surpassing all existing open-source models under 72B parameters and even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro. Our analysis highlights the effectiveness of the self-rewarding mechanism compared to the external LLM-as-a-judge approach in MT and demonstrates its complementary benefits when combined with trained RMs. Our findings provide valuable insight into the potential of self-improving RL methods. We have publicly released our code, data and models.","authors":["Wenjie Yang","Mao Zheng","Mingyang Song","Zheng Li"],"url":"https://arxiv.org/abs/2505.16637"}
{"created":"2025-05-23","title":"Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity","abstract":"Fairness through Unawareness (FtU) describes the idea that discrimination against demographic groups can be avoided by not considering group membership in the decisions or predictions. This idea has long been criticized in the machine learning literature as not being sufficient to ensure fairness. In addition, the use of additional features is typically thought to increase the accuracy of the predictions for all groups, so that FtU is sometimes thought to be detrimental to all groups. In this paper, we show both theoretically and empirically that FtU can reduce algorithmic discrimination without necessarily reducing accuracy. We connect this insight with the literature on Model Multiplicity, to which we contribute with novel theoretical and empirical results. Furthermore, we illustrate how, in a real-life application, FtU can contribute to the deployment of more equitable policies without losing efficacy. Our findings suggest that FtU is worth considering in practical applications, particularly in high-risk scenarios, and that the use of protected attributes such as gender in predictive models should be accompanied by a clear and well-founded justification.","authors":["Benedikt H\\\"oltgen","Nuria Oliver"],"url":"https://arxiv.org/abs/2505.16638"}
{"created":"2025-05-23","title":"BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization","abstract":"Vision-Language-Action (VLA) models have advanced robotic control by enabling end-to-end decision-making directly from multimodal inputs. However, their tightly coupled architectures expose novel security vulnerabilities. Unlike traditional adversarial perturbations, backdoor attacks represent a stealthier, persistent, and practically significant threat-particularly under the emerging Training-as-a-Service paradigm-but remain largely unexplored in the context of VLA models. To address this gap, we propose BadVLA, a backdoor attack method based on Objective-Decoupled Optimization, which for the first time exposes the backdoor vulnerabilities of VLA models. Specifically, it consists of a two-stage process: (1) explicit feature-space separation to isolate trigger representations from benign inputs, and (2) conditional control deviations that activate only in the presence of the trigger, while preserving clean-task performance. Empirical results on multiple VLA benchmarks demonstrate that BadVLA consistently achieves near-100% attack success rates with minimal impact on clean task accuracy. Further analyses confirm its robustness against common input perturbations, task transfers, and model fine-tuning, underscoring critical security vulnerabilities in current VLA deployments. Our work offers the first systematic investigation of backdoor vulnerabilities in VLA models, highlighting an urgent need for secure and trustworthy embodied model design practices. We have released the project page at https://badvla-project.github.io/.","authors":["Xueyang Zhou","Guiyao Tie","Guowen Zhang","Hechang Wang","Pan Zhou","Lichao Sun"],"url":"https://arxiv.org/abs/2505.16640"}
{"created":"2025-05-23","title":"From Evaluation to Defense: Advancing Safety in Video Large Language Models","abstract":"While the safety risks of image-based large language models have been extensively studied, their video-based counterparts (Video LLMs) remain critically under-examined. To systematically study this problem, we introduce \\textbf{VideoSafetyBench (VSB-77k) - the first large-scale, culturally diverse benchmark for Video LLM safety}, which compromises 77,646 video-query pairs and spans 19 principal risk categories across 10 language communities. \\textit{We reveal that integrating video modality degrades safety performance by an average of 42.3\\%, exposing systemic risks in multimodal attack exploitation.} To address this vulnerability, we propose \\textbf{VideoSafety-R1}, a dual-stage framework achieving unprecedented safety gains through two innovations: (1) Alarm Token-Guided Safety Fine-Tuning (AT-SFT) injects learnable alarm tokens into visual and textual sequences, enabling explicit harm perception across modalities via multitask objectives. (2) Then, Safety-Guided GRPO enhances defensive reasoning through dynamic policy optimization with rule-based rewards derived from dual-modality verification. These components synergize to shift safety alignment from passive harm recognition to active reasoning. The resulting framework achieves a 65.1\\% improvement on VSB-Eval-HH, and improves by 59.1\\%, 44.3\\%, and 15.0\\% on the image safety datasets MMBench, VLGuard, and FigStep, respectively. \\textit{Our codes are available in the supplementary materials.} \\textcolor{red}{Warning: This paper contains examples of harmful language and videos, and reader discretion is recommended.}","authors":["Yiwei Sun","Peiqi Jiang","Chuanbin Liu","Luohao Lin","Zhiying Lu","Hongtao Xie"],"url":"https://arxiv.org/abs/2505.16643"}
{"created":"2025-05-23","title":"SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving","abstract":"Large Language Models have achieved remarkable results on a variety of mathematical benchmarks. However, concerns remain as to whether these successes reflect genuine mathematical reasoning or superficial pattern recognition. Common evaluation metrics, such as final answer accuracy, fail to disentangle the underlying competencies involved, offering limited diagnostic value. To address these limitations, we introduce SMART: a Self-Generating and Self-Validating Multi-Dimensional Assessment Framework. SMART decomposes mathematical problem solving into four distinct dimensions: understanding, reasoning, arithmetic, and reflection \\& refinement. Each dimension is evaluated independently through tailored tasks, enabling interpretable and fine-grained analysis of LLM behavior. Crucially, SMART integrates an automated self-generating and self-validating mechanism to produce and verify benchmark data, ensuring both scalability and reliability. We apply SMART to 21 state-of-the-art open- and closed-source LLMs, uncovering significant discrepancies in their abilities across different dimensions. Our findings demonstrate the inadequacy of final answer accuracy as a sole metric and motivate a new holistic metric to better capture true problem-solving capabilities. Code and benchmarks will be released upon acceptance.","authors":["Yujie Hou","Ting Zhang","Mei Wang","Xuetao Ma","Hu Huang"],"url":"https://arxiv.org/abs/2505.16646"}
{"created":"2025-05-23","title":"Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models","abstract":"We investigate fine-tuning Vision-Language Models (VLMs) for multi-task medical image understanding, focusing on detection, localization, and counting of findings in medical images. Our objective is to evaluate whether instruction-tuned VLMs can simultaneously improve these tasks, with the goal of enhancing diagnostic accuracy and efficiency. Using MedMultiPoints, a multimodal dataset with annotations from endoscopy (polyps and instruments) and microscopy (sperm cells), we reformulate each task into instruction-based prompts suitable for vision-language reasoning. We fine-tune Qwen2.5-VL-7B-Instruct using Low-Rank Adaptation (LoRA) across multiple task combinations. Results show that multi-task training improves robustness and accuracy. For example, it reduces the Count Mean Absolute Error (MAE) and increases Matching Accuracy in the Counting + Pointing task. However, trade-offs emerge, such as more zero-case point predictions, indicating reduced reliability in edge cases despite overall performance gains. Our study highlights the potential of adapting general-purpose VLMs to specialized medical tasks via prompt-driven fine-tuning. This approach mirrors clinical workflows, where radiologists simultaneously localize, count, and describe findings - demonstrating how VLMs can learn composite diagnostic reasoning patterns. The model produces interpretable, structured outputs, offering a promising step toward explainable and versatile medical AI. Code, model weights, and scripts will be released for reproducibility at https://github.com/simula/PointDetectCount.","authors":["Sushant Gautam","Michael A. Riegler","P{\\aa}l Halvorsen"],"url":"https://arxiv.org/abs/2505.16647"}
{"created":"2025-05-23","title":"Collaboration among Multiple Large Language Models for Medical Question Answering","abstract":"Empowered by vast internal knowledge reservoir, the new generation of large language models (LLMs) demonstrate untapped potential to tackle medical tasks. However, there is insufficient effort made towards summoning up a synergic effect from multiple LLMs' expertise and background. In this study, we propose a multi-LLM collaboration framework tailored on a medical multiple-choice questions dataset. Through post-hoc analysis on 3 pre-trained LLM participants, our framework is proved to boost all LLMs reasoning ability as well as alleviate their divergence among questions. We also measure an LLM's confidence when it confronts with adversary opinions from other LLMs and observe a concurrence between LLM's confidence and prediction accuracy.","authors":["Kexin Shang","Chia-Hsuan Chang","Christopher C. Yang"],"url":"https://arxiv.org/abs/2505.16648"}
{"created":"2025-05-23","title":"Stochastic Forward-Forward Learning through Representational Dimensionality Compression","abstract":"The Forward-Forward (FF) algorithm provides a bottom-up alternative to backpropagation (BP) for training neural networks, relying on a layer-wise \"goodness\" function to guide learning. Existing goodness functions, inspired by energy-based learning (EBL), are typically defined as the sum of squared post-synaptic activations, neglecting the correlations between neurons. In this work, we propose a novel goodness function termed dimensionality compression that uses the effective dimensionality (ED) of fluctuating neural responses to incorporate second-order statistical structure. Our objective minimizes ED for clamped inputs when noise is considered while maximizing it across the sample distribution, promoting structured representations without the need to prepare negative samples. We demonstrate that this formulation achieves competitive performance compared to other non-BP methods. Moreover, we show that noise plays a constructive role that can enhance generalization and improve inference when predictions are derived from the mean of squared outputs, which is equivalent to making predictions based on the energy term. Our findings contribute to the development of more biologically plausible learning algorithms and suggest a natural fit for neuromorphic computing, where stochasticity is a computational resource rather than a nuisance. The code is available at https://github.com/ZhichaoZhu/StochasticForwardForward","authors":["Zhichao Zhu","Yang Qi","Hengyuan Ma","Wenlian Lu","Jianfeng Feng"],"url":"https://arxiv.org/abs/2505.16649"}
{"created":"2025-05-23","title":"Unsupervised Network Anomaly Detection with Autoencoders and Traffic Images","abstract":"Due to the recent increase in the number of connected devices, the need to promptly detect security issues is emerging. Moreover, the high number of communication flows creates the necessity of processing huge amounts of data. Furthermore, the connected devices are heterogeneous in nature, having different computational capacities. For this reason, in this work we propose an image-based representation of network traffic which allows to realize a compact summary of the current network conditions with 1-second time windows. The proposed representation highlights the presence of anomalies thus reducing the need for complex processing architectures. Finally, we present an unsupervised learning approach which effectively detects the presence of anomalies. The code and the dataset are available at https://github.com/michaelneri/image-based-network-traffic-anomaly-detection.","authors":["Michael Neri","Sara Baldoni"],"url":"https://arxiv.org/abs/2505.16650"}
{"created":"2025-05-23","title":"Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding","abstract":"Recent advancements in multimodal large language models (MLLMs) have significantly improved performance in visual question answering. However, they often suffer from hallucinations. In this work, hallucinations are categorized into two main types: initial hallucinations and snowball hallucinations. We argue that adequate contextual information can be extracted directly from the token interaction process. Inspired by causal inference in the decoding strategy, we propose to leverage causal masks to establish information propagation between multimodal tokens. The hypothesis is that insufficient interaction between those tokens may lead the model to rely on outlier tokens, overlooking dense and rich contextual cues. Therefore, we propose to intervene in the propagation process by tackling outlier tokens to enhance in-context inference. With this goal, we present FarSight, a versatile plug-and-play decoding strategy to reduce attention interference from outlier tokens merely by optimizing the causal mask. The heart of our method is effective token propagation. We design an attention register structure within the upper triangular matrix of the causal mask, dynamically allocating attention to capture attention diverted to outlier tokens. Moreover, a positional awareness encoding method with a diminishing masking rate is proposed, allowing the model to attend to further preceding tokens, especially for video sequence tasks. With extensive experiments, FarSight demonstrates significant hallucination-mitigating performance across different MLLMs on both image and video benchmarks, proving its effectiveness.","authors":["Feilong Tang","Chengzhi Liu","Zhongxing Xu","Ming Hu","Zelin Peng","Zhiwei Yang","Jionglong Su","Minquan Lin","Yifan Peng","Xuelian Cheng","Imran Razzak","Zongyuan Ge"],"url":"https://arxiv.org/abs/2505.16652"}
{"created":"2025-05-23","title":"Zero-Shot Hyperspectral Pansharpening Using Hysteresis-Based Tuning for Spectral Quality Control","abstract":"Hyperspectral pansharpening has received much attention in recent years due to technological and methodological advances that open the door to new application scenarios. However, research on this topic is only now gaining momentum. The most popular methods are still borrowed from the more mature field of multispectral pansharpening and often overlook the unique challenges posed by hyperspectral data fusion, such as i) the very large number of bands, ii) the overwhelming noise in selected spectral ranges, iii) the significant spectral mismatch between panchromatic and hyperspectral components, iv) a typically high resolution ratio. Imprecise data modeling especially affects spectral fidelity. Even state-of-the-art methods perform well in certain spectral ranges and much worse in others, failing to ensure consistent quality across all bands, with the risk of generating unreliable results. Here, we propose a hyperspectral pansharpening method that explicitly addresses this problem and ensures uniform spectral quality. To this end, a single lightweight neural network is used, with weights that adapt on the fly to each band. During fine-tuning, the spatial loss is turned on and off to ensure a fast convergence of the spectral loss to the desired level, according to a hysteresis-like dynamic. Furthermore, the spatial loss itself is appropriately redefined to account for nonlinear dependencies between panchromatic and spectral bands. Overall, the proposed method is fully unsupervised, with no prior training on external data, flexible, and low-complexity. Experiments on a recently published benchmarking toolbox show that it ensures excellent sharpening quality, competitive with the state-of-the-art, consistently across all bands. The software code and the full set of results are shared online on https://github.com/giu-guarino/rho-PNN.","authors":["Giuseppe Guarino","Matteo Ciotola","Gemine Vivone","Giovanni Poggi","Giuseppe Scarpa"],"url":"https://arxiv.org/abs/2505.16658"}
{"created":"2025-05-23","title":"SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images","abstract":"Medical anomaly detection (AD) is crucial for early clinical intervention, yet it faces challenges due to limited access to high-quality medical imaging data, caused by privacy concerns and data silos. Few-shot learning has emerged as a promising approach to alleviate these limitations by leveraging the large-scale prior knowledge embedded in vision-language models (VLMs). Recent advancements in few-shot medical AD have treated normal and abnormal cases as a one-class classification problem, often overlooking the distinction among multiple anomaly categories. Thus, in this paper, we propose a framework tailored for few-shot medical anomaly detection in the scenario where the identification of multiple anomaly categories is required. To capture the detailed radiological signs of medical anomaly categories, our framework incorporates diverse textual descriptions for each category generated by a Large-Language model, under the assumption that different anomalies in medical images may share common radiological signs in each category. Specifically, we introduce SD-MAD, a two-stage Sign-Driven few-shot Multi-Anomaly Detection framework: (i) Radiological signs are aligned with anomaly categories by amplifying inter-anomaly discrepancy; (ii) Aligned signs are selected further to mitigate the effect of the under-fitting and uncertain-sample issue caused by limited medical data, employing an automatic sign selection strategy at inference. Moreover, we propose three protocols to comprehensively quantify the performance of multi-anomaly detection. Extensive experiments illustrate the effectiveness of our method.","authors":["Kaiyu Guo","Tan Pan","Chen Jiang","Zijian Wang","Brian C. Lovell","Limei Han","Yuan Cheng","Mahsa Baktashmotlagh"],"url":"https://arxiv.org/abs/2505.16659"}
{"created":"2025-05-23","title":"Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu","abstract":"This study addresses the challenges in intelligent processing of Chinese ancient mathematical classics by constructing Guji_MATH, a benchmark for evaluating classical texts based on Suanjing Shishu. It systematically assesses the mathematical problem-solving capabilities of mainstream reasoning models under the unique linguistic constraints of classical Chinese. Through machine-assisted annotation and manual verification, 538 mathematical problems were extracted from 8 canonical texts, forming a structured dataset centered on the \"Question-Answer-Solution\" framework, supplemented by problem types and difficulty levels. Dual evaluation modes--closed-book (autonomous problem-solving) and open-book (reproducing classical solution methods)--were designed to evaluate the performance of six reasoning models on ancient Chinese mathematical problems. Results indicate that reasoning models can partially comprehend and solve these problems, yet their overall performance remains inferior to benchmarks on modern mathematical tasks. Enhancing models' classical Chinese comprehension and cultural knowledge should be prioritized for optimization. This study provides methodological support for mining mathematical knowledge from ancient texts and disseminating traditional culture, while offering new perspectives for evaluating cross-linguistic and cross-cultural capabilities of reasoning models.","authors":["Liu Chang","Wang Dongbo","Liu liu","Zhao Zhixiao"],"url":"https://arxiv.org/abs/2505.16660"}
{"created":"2025-05-23","title":"A Japanese Language Model and Three New Evaluation Benchmarks for Pharmaceutical NLP","abstract":"We present a Japanese domain-specific language model for the pharmaceutical field, developed through continual pretraining on 2 billion Japanese pharmaceutical tokens and 8 billion English biomedical tokens. To enable rigorous evaluation, we introduce three new benchmarks: YakugakuQA, based on national pharmacist licensing exams; NayoseQA, which tests cross-lingual synonym and terminology normalization; and SogoCheck, a novel task designed to assess consistency reasoning between paired statements. We evaluate our model against both open-source medical LLMs and commercial models, including GPT-4o. Results show that our domain-specific model outperforms existing open models and achieves competitive performance with commercial ones, particularly on terminology-heavy and knowledge-based tasks. Interestingly, even GPT-4o performs poorly on SogoCheck, suggesting that cross-sentence consistency reasoning remains an open challenge. Our benchmark suite offers a broader diagnostic lens for pharmaceutical NLP, covering factual recall, lexical variation, and logical consistency. This work demonstrates the feasibility of building practical, secure, and cost-effective language models for Japanese domain-specific applications, and provides reusable evaluation resources for future research in pharmaceutical and healthcare NLP. Our model, codes, and datasets are released at https://github.com/EQUES-Inc/pharma-LLM-eval.","authors":["Issey Sukeda","Takuro Fujii","Kosei Buma","Shunsuke Sasaki","Shinnosuke Ono"],"url":"https://arxiv.org/abs/2505.16661"}
{"created":"2025-05-23","title":"Joint Magnetometer-IMU Calibration via Maximum A Posteriori Estimation","abstract":"This paper presents a new approach for jointly calibrating magnetometers and inertial measurement units, focusing on improving calibration accuracy and computational efficiency. The proposed method formulates the calibration problem as a maximum a posteriori estimation problem, treating both the calibration parameters and orientation trajectory of the sensors as unknowns. This formulation enables efficient optimization with closed-form derivatives. The method is compared against two state-of-the-art approaches in terms of computational complexity and estimation accuracy. Simulation results demonstrate that the proposed method achieves lower root mean square error in calibration parameters while maintaining competitive computational efficiency. Further validation through real-world experiments confirms the practical benefits of our approach: it effectively reduces position drift in a magnetic field-aided inertial navigation system by more than a factor of two on most datasets. Moreover, the proposed method calibrated 30 magnetometers in less than 2 minutes. The contributions include a new calibration method, an analysis of existing methods, and a comprehensive empirical evaluation. Datasets and algorithms are made publicly available to promote reproducible research.","authors":["Chuan Huang","Gustaf Hendeby","Isaac Skog"],"url":"https://arxiv.org/abs/2505.16662"}
{"created":"2025-05-23","title":"CoNav: Collaborative Cross-Modal Reasoning for Embodied Navigation","abstract":"Embodied navigation demands comprehensive scene understanding and precise spatial reasoning. While image-text models excel at interpreting pixel-level color and lighting cues, 3D-text models capture volumetric structure and spatial relationships. However, unified fusion approaches that jointly fuse 2D images, 3D point clouds, and textual instructions face challenges in limited availability of triple-modality data and difficulty resolving conflicting beliefs among modalities. In this work, we introduce CoNav, a collaborative cross-modal reasoning framework where a pretrained 3D-text model explicitly guides an image-text navigation agent by providing structured spatial-semantic knowledge to resolve ambiguities during navigation. Specifically, we introduce Cross-Modal Belief Alignment, which operationalizes this cross-modal guidance by simply sharing textual hypotheses from the 3D-text model to the navigation agent. Through lightweight fine-tuning on a small 2D-3D-text corpus, the navigation agent learns to integrate visual cues with spatial-semantic knowledge derived from the 3D-text model, enabling effective reasoning in embodied navigation. CoNav achieves significant improvements on four standard embodied navigation benchmarks (R2R, CVDN, REVERIE, SOON) and two spatial reasoning benchmarks (ScanQA, SQA3D). Moreover, under close navigation Success Rate, CoNav often generates shorter paths compared to other methods (as measured by SPL), showcasing the potential and challenges of fusing data from different modalities in embodied navigation. Project Page: https://oceanhao.github.io/CoNav/","authors":["Haihong Hao","Mingfei Han","Changlin Li","Zhihui Li","Xiaojun Chang"],"url":"https://arxiv.org/abs/2505.16663"}
{"created":"2025-05-23","title":"End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries","abstract":"Accurate prediction of the Remaining Useful Life (RUL) is essential for enabling timely maintenance of lithium-ion batteries, impacting the operational efficiency of electric applications that rely on them. This paper proposes a RUL prediction approach that leverages data from recent charge-discharge cycles to estimate the number of remaining usable cycles. The approach introduces both a novel signal processing pipeline and a deep learning prediction model. In the signal preprocessing pipeline, a derived capacity feature is computed based on current and capacity signals. Alongside original capacity, voltage and current, these features are denoised and enhanced using statistical metrics and a delta-based method to capture differences between the current and previous cycles. In the prediction model, the processed features are then fed into a hybrid deep learning architecture composed of 1D Convolutional Neural Networks (CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential Equation-based LSTM (ODE-LSTM) modules. This architecture is designed to capture both local signal characteristics and long-range temporal dependencies while modeling the continuous-time dynamics of battery degradation. The model is further evaluated using transfer learning across different learning strategies and target data partitioning scenarios. Results indicate that the model maintains robust performance, even when fine-tuned on limited target data. Experimental results on two publicly available large-scale datasets demonstrate that the proposed method outperforms a baseline deep learning approach and machine learning techniques, achieving an RMSE of 101.59, highlighting its strong potential for real-world RUL prediction applications.","authors":["Khoa Tran","Tri Le","Bao Huynh","Hung-Cuong Trinh","Vy-Rin Nguyen"],"url":"https://arxiv.org/abs/2505.16664"}
{"created":"2025-05-23","title":"MDVT: Enhancing Multimodal Recommendation with Model-Agnostic Multimodal-Driven Virtual Triplets","abstract":"The data sparsity problem significantly hinders the performance of recommender systems, as traditional models rely on limited historical interactions to learn user preferences and item properties. While incorporating multimodal information can explicitly represent these preferences and properties, existing works often use it only as side information, failing to fully leverage its potential. In this paper, we propose MDVT, a model-agnostic approach that constructs multimodal-driven virtual triplets to provide valuable supervision signals, effectively mitigating the data sparsity problem in multimodal recommendation systems. To ensure high-quality virtual triplets, we introduce three tailored warm-up threshold strategies: static, dynamic, and hybrid. The static warm-up threshold strategy exhaustively searches for the optimal number of warm-up epochs but is time-consuming and computationally intensive. The dynamic warm-up threshold strategy adjusts the warm-up period based on loss trends, improving efficiency but potentially missing optimal performance. The hybrid strategy combines both, using the dynamic strategy to find the approximate optimal number of warm-up epochs and then refining it with the static strategy in a narrow hyper-parameter space. Once the warm-up threshold is satisfied, the virtual triplets are used for joint model optimization by our enhanced pair-wise loss function without causing significant gradient skew. Extensive experiments on multiple real-world datasets demonstrate that integrating MDVT into advanced multimodal recommendation models effectively alleviates the data sparsity problem and improves recommendation performance, particularly in sparse data scenarios.","authors":["Jinfeng Xu","Zheyu Chen","Jinze Li","Shuo Yang","Hewei Wang","Yijie Li","Mengran Li","Puzhen Wu","Edith C. H. Ngai"],"url":"https://arxiv.org/abs/2505.16665"}
{"created":"2025-05-23","title":"ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming","abstract":"While recent research increasingly emphasizes the value of human-LLM collaboration in competitive programming and proposes numerous empirical methods, a comprehensive understanding remains elusive due to the fragmented nature of existing studies and their use of diverse, application-specific human feedback. Thus, our work serves a three-fold purpose: First, we present the first taxonomy of human feedback consolidating the entire programming process, which promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a novel programming dataset specifically designed for human-LLM collaboration, meticulously annotated to enable large-scale simulated human feedback and facilitate costeffective real human interaction studies. Third, we introduce ELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM competitive programming. With ELABORATION, we pinpoint strengthes and weaknesses of existing methods, thereby setting the foundation for future improvement. Our code and dataset are available at https://github.com/SCUNLP/ELABORATION","authors":["Xinwei Yang","Zhaofeng Liu","Chen Huang","Jiashuai Zhang","Tong Zhang","Yifan Zhang","Wenqiang Lei"],"url":"https://arxiv.org/abs/2505.16667"}
{"created":"2025-05-23","title":"BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models","abstract":"Large language models (LLMs) have shown impressive capabilities across a wide range of applications, but their ever-increasing size and resource demands make them vulnerable to inference cost attacks, where attackers induce victim LLMs to generate the longest possible output content. In this paper, we revisit existing inference cost attacks and reveal that these methods can hardly produce large-scale malicious effects since they are self-targeting, where attackers are also the users and therefore have to execute attacks solely through the inputs, whose generated content will be charged by LLMs and can only directly influence themselves. Motivated by these findings, this paper introduces a new type of inference cost attacks (dubbed 'bit-flip inference cost attack') that target the victim model itself rather than its inputs. Specifically, we design a simple yet effective method (dubbed 'BitHydra') to effectively flip critical bits of model parameters. This process is guided by a loss function designed to suppress  token's probability with an efficient critical bit search algorithm, thus explicitly defining the attack objective and enabling effective optimization. We evaluate our method on 11 LLMs ranging from 1.5B to 14B parameters under both int8 and float16 settings. Experimental results demonstrate that with just 4 search samples and as few as 3 bit flips, BitHydra can force 100% of test prompts to reach the maximum generation length (e.g., 2048 tokens) on representative LLMs such as LLaMA3, highlighting its efficiency, scalability, and strong transferability across unseen inputs.","authors":["Xiaobei Yan","Yiming Li","Zhaoxin Fan","Han Qiu","Tianwei Zhang"],"url":"https://arxiv.org/abs/2505.16670"}
{"created":"2025-05-23","title":"Quantum Feature Optimization for Enhanced Clustering of Blockchain Transaction Data","abstract":"Blockchain transaction data exhibits high dimensionality, noise, and intricate feature entanglement, presenting significant challenges for traditional clustering algorithms. In this study, we conduct a comparative analysis of three clustering approaches: (1) Classical K-Means Clustering, applied to pre-processed feature representations; (2) Hybrid Clustering, wherein classical features are enhanced with quantum random features extracted using randomly initialized quantum neural networks (QNNs); and (3) Fully Quantum Clustering, where a QNN is trained in a self-supervised manner leveraging a SwAV-based loss function to optimize the feature space for clustering directly. The proposed experimental framework systematically investigates the impact of quantum circuit depth and the number of learned prototypes, demonstrating that even shallow quantum circuits can effectively extract meaningful non-linear representations, significantly improving clustering performance.","authors":["Yun-Cheng Tsai","Samuel Yen-Chi Chen"],"url":"https://arxiv.org/abs/2505.16672"}
{"created":"2025-05-23","title":"R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO","abstract":"In this work, we aim to incentivize the reasoning ability of Multimodal Large Language Models (MLLMs) via reinforcement learning (RL) and develop an effective approach that mitigates the sparse reward and advantage vanishing issues during RL. To this end, we propose Share-GRPO, a novel RL approach that tackle these issues by exploring and sharing diverse reasoning trajectories over expanded question space. Specifically, Share-GRPO first expands the question space for a given question via data transformation techniques, and then encourages MLLM to effectively explore diverse reasoning trajectories over the expanded question space and shares the discovered reasoning trajectories across the expanded questions during RL. In addition, Share-GRPO also shares reward information during advantage computation, which estimates solution advantages hierarchically across and within question variants, allowing more accurate estimation of relative advantages and improving the stability of policy training. Extensive evaluations over six widely-used reasoning benchmarks showcase the superior performance of our method. Code will be available at https://github.com/HJYao00/R1-ShareVL.","authors":["Huanjin Yao","Qixiang Yin","Jingyi Zhang","Min Yang","Yibo Wang","Wenhao Wu","Fei Su","Li Shen","Minghui Qiu","Dacheng Tao","Jiaxing Huang"],"url":"https://arxiv.org/abs/2505.16673"}
{"created":"2025-05-23","title":"Zero-Shot Anomaly Detection in Battery Thermal Images Using Visual Question Answering with Prior Knowledge","abstract":"Batteries are essential for various applications, including electric vehicles and renewable energy storage, making safety and efficiency critical concerns. Anomaly detection in battery thermal images helps identify failures early, but traditional deep learning methods require extensive labeled data, which is difficult to obtain, especially for anomalies due to safety risks and high data collection costs. To overcome this, we explore zero-shot anomaly detection using Visual Question Answering (VQA) models, which leverage pretrained knowledge and textbased prompts to generalize across vision tasks. By incorporating prior knowledge of normal battery thermal behavior, we design prompts to detect anomalies without battery-specific training data. We evaluate three VQA models (ChatGPT-4o, LLaVa-13b, and BLIP-2) analyzing their robustness to prompt variations, repeated trials, and qualitative outputs. Despite the lack of finetuning on battery data, our approach demonstrates competitive performance compared to state-of-the-art models that are trained with the battery data. Our findings highlight the potential of VQA-based zero-shot learning for battery anomaly detection and suggest future directions for improving its effectiveness.","authors":["Marcella Astrid","Abdelrahman Shabayek","Djamila Aouada"],"url":"https://arxiv.org/abs/2505.16674"}
{"created":"2025-05-23","title":"On the Out-of-Distribution Generalization of Self-Supervised Learning","abstract":"In this paper, we focus on the out-of-distribution (OOD) generalization of self-supervised learning (SSL). By analyzing the mini-batch construction during the SSL training phase, we first give one plausible explanation for SSL having OOD generalization. Then, from the perspective of data generation and causal inference, we analyze and conclude that SSL learns spurious correlations during the training process, which leads to a reduction in OOD generalization. To address this issue, we propose a post-intervention distribution (PID) grounded in the Structural Causal Model. PID offers a scenario where the spurious variable and label variable is mutually independent. Besides, we demonstrate that if each mini-batch during SSL training satisfies PID, the resulting SSL model can achieve optimal worst-case OOD performance. This motivates us to develop a batch sampling strategy that enforces PID constraints through the learning of a latent variable model. Through theoretical analysis, we demonstrate the identifiability of the latent variable model and validate the effectiveness of the proposed sampling strategy. Experiments conducted on various downstream OOD tasks demonstrate the effectiveness of the proposed sampling strategy.","authors":["Wenwen Qiang","Jingyao Wang","Zeen Song","Jiangmeng Li","Changwen Zheng"],"url":"https://arxiv.org/abs/2505.16675"}
{"created":"2025-05-23","title":"Semantic Compression of 3D Objects for Open and Collaborative Virtual Worlds","abstract":"Traditional methods for 3D object compression operate only on structural information within the object vertices, polygons, and textures. These methods are effective at compression rates up to 10x for standard object sizes but quickly deteriorate at higher compression rates with texture artifacts, low-polygon counts, and mesh gaps. In contrast, semantic compression ignores structural information and operates directly on the core concepts to push to extreme levels of compression. In addition, it uses natural language as its storage format, which makes it natively human-readable and a natural fit for emerging applications built around large-scale, collaborative projects within augmented and virtual reality. It deprioritizes structural information like location, size, and orientation and predicts the missing information with state-of-the-art deep generative models. In this work, we construct a pipeline for 3D semantic compression from public generative models and explore the quality-compression frontier for 3D object compression. We apply this pipeline to achieve rates as high as 105x for 3D objects taken from the Objaverse dataset and show that semantic compression can outperform traditional methods in the important quality-preserving region around 100x compression.","authors":["Jordan Dotzel","Tony Montes","Mohamed S. Abdelfattah","Zhiru Zhang"],"url":"https://arxiv.org/abs/2505.16679"}
{"created":"2025-05-23","title":"Learning Genomic Structure from $k$-mers","abstract":"Sequencing a genome to determine an individual's DNA produces an enormous number of short nucleotide subsequences known as reads, which must be reassembled to reconstruct the full genome. We present a method for analyzing this type of data using contrastive learning, in which an encoder model is trained to produce embeddings that cluster together sequences from the same genomic region. The sequential nature of genomic regions is preserved in the form of trajectories through this embedding space. Trained solely to reflect the structure of the genome, the resulting model provides a general representation of $k$-mer sequences, suitable for a range of downstream tasks involving read data. We apply our framework to learn the structure of the $E.\\ coli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) read mapping and identification of structural variations. Furthermore, we illustrate the potential of using this type of model for metagenomic species identification. We show how incorporating a domain-specific noise model can enhance embedding robustness, and how a supervised contrastive learning setting can be adopted when a linear reference genome is available, by introducing a distance thresholding parameter $\\Gamma$. The model can also be trained fully self-supervised on read data, enabling analysis without the need to construct a full genome assembly using specialized algorithms. Small prediction heads based on a pre-trained embedding are shown to perform on par with BWA-aln, the current gold standard approach for aDNA mapping, in terms of accuracy and runtime for short genomes. Given the method's favorable scaling properties with respect to total genome size, inference using our approach is highly promising for metagenomic applications and for mapping to genomes comparable in size to the human genome.","authors":["Filip Thor","Carl Nettelblad"],"url":"https://arxiv.org/abs/2505.16680"}
{"created":"2025-05-23","title":"MEbots: Integrating a RISC-V Virtual Platform with a Robotic Simulator for Energy-aware Design","abstract":"Virtual Platforms (VPs) enable early software validation of autonomous systems' electronics, reducing costs and time-to-market. While many VPs support both functional and non-functional simulation (e.g., timing, power), they lack the capability of simulating the environment in which the system operates. In contrast, robotics simulators lack accurate timing and power features. This twofold shortcoming limits the effectiveness of the design flow, as the designer can not fully evaluate the features of the solution under development. This paper presents a novel, fully open-source framework bridging this gap by integrating a robotics simulator (Webots) with a VP for RISC-V-based systems (MESSY). The framework enables a holistic, mission-level, energy-aware co-simulation of electronics in their surrounding environment, streamlining the exploration of design configurations and advanced power management policies.","authors":["Giovanni Pollo","Mohamed Amine Hamdi","Matteo Risso","Lorenzo Ruotolo","Pietro Furbatto","Matteo Isoldi","Yukai Chen","Alessio Burrello","Enrico Macii","Massimo Poncino","Daniele Jahier Pagliari","Sara Vinco"],"url":"https://arxiv.org/abs/2505.16682"}
{"created":"2025-05-23","title":"Continuous Petri Nets Faithfully Fluidify Most Permissive Boolean Networks","abstract":"The analysis of biological networks has benefited from the richness of Boolean networks (BNs) and the associated theory. These results have been further fortified in recent years by the emergence of Most Permissive (MP) semantics, combining efficient analysis methods with a greater capacity of explaining pathways to states hitherto thought unreachable, owing to limitations of the classical update modes. While MPBNs are understood to capture any behaviours that can be observed at a lower level of abstraction, all the way down to continuous refinements, the specifics and potential of the models and analysis, especially attractors, across the abstraction scale remain unexplored. Here, we fluidify MPBNs by means of Continuous Petri nets (CPNs), a model of (uncountably infinite) dynamic systems that has been successfully explored for modelling and theoretical purposes. CPNs create a formal link between MPBNs and their continuous dynamical refinements such as ODE models. The benefits of CPNs extend beyond the model refinement, and constitute well established theory and analysis methods, recently augmented by abstract and symbolic reachability graphs. These structures are shown to compact the possible behaviours of the system with focus on events which drive the choice of long-term behaviour in which the system eventually stabilises. The current paper brings an important keystone to this novel methodology for biological networks, namely the proof that extant PN encoding of BNs instantiated as a CPN simulates the MP semantics. In spite of the underlying dynamics being continuous, the analysis remains in the realm of discrete methods, constituting an extension of all previous work.","authors":["Stefan Haar","Juri Kol\\v{c}\\'ak"],"url":"https://arxiv.org/abs/2505.16683"}
{"created":"2025-05-23","title":"On the use of Graphs for Satellite Image Time Series","abstract":"The Earth's surface is subject to complex and dynamic processes, ranging from large-scale phenomena such as tectonic plate movements to localized changes associated with ecosystems, agriculture, or human activity. Satellite images enable global monitoring of these processes with extensive spatial and temporal coverage, offering advantages over in-situ methods. In particular, resulting satellite image time series (SITS) datasets contain valuable information. To handle their large volume and complexity, some recent works focus on the use of graph-based techniques that abandon the regular Euclidean structure of satellite data to work at an object level. Besides, graphs enable modelling spatial and temporal interactions between identified objects, which are crucial for pattern detection, classification and regression tasks. This paper is an effort to examine the integration of graph-based methods in spatio-temporal remote-sensing analysis. In particular, it aims to present a versatile graph-based pipeline to tackle SITS analysis. It focuses on the construction of spatio-temporal graphs from SITS and their application to downstream tasks. The paper includes a comprehensive review and two case studies, which highlight the potential of graph-based approaches for land cover mapping and water resource forecasting. It also discusses numerous perspectives to resolve current limitations and encourage future developments.","authors":["Corentin Dufourg","Charlotte Pelletier","St\\'ephane May","S\\'ebastien Lef\\`evre"],"url":"https://arxiv.org/abs/2505.16685"}
{"created":"2025-05-23","title":"SPaRC: A Spatial Pathfinding Reasoning Challenge","abstract":"Existing reasoning datasets saturate and fail to test abstract, multi-step problems, especially pathfinding and complex rule constraint satisfaction. We introduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000 2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning, requiring step-by-step planning with arithmetic and geometric rules. Humans achieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best reasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles). Models often generate invalid paths (>50% of puzzles for o4-mini), and reasoning tokens reveal they make errors in navigation and spatial logic. Unlike humans, who take longer on hard puzzles, models fail to scale test-time compute with difficulty. Allowing models to make multiple solution attempts improves accuracy, suggesting potential for better spatial reasoning with improved training and efficient test-time scaling methods. SPaRC can be used as a window into models' spatial reasoning limitations and drive research toward new methods that excel in abstract, multi-step problem-solving.","authors":["Lars Benedikt Kaesberg","Jan Philip Wahle","Terry Ruas","Bela Gipp"],"url":"https://arxiv.org/abs/2505.16686"}
{"created":"2025-05-23","title":"One-Step Diffusion-Based Image Compression with Semantic Distillation","abstract":"While recent diffusion-based generative image codecs have shown impressive performance, their iterative sampling process introduces unpleasing latency. In this work, we revisit the design of a diffusion-based codec and argue that multi-step sampling is not necessary for generative compression. Based on this insight, we propose OneDC, a One-step Diffusion-based generative image Codec -- that integrates a latent compression module with a one-step diffusion generator. Recognizing the critical role of semantic guidance in one-step diffusion, we propose using the hyperprior as a semantic signal, overcoming the limitations of text prompts in representing complex visual content. To further enhance the semantic capability of the hyperprior, we introduce a semantic distillation mechanism that transfers knowledge from a pretrained generative tokenizer to the hyperprior codec. Additionally, we adopt a hybrid pixel- and latent-domain optimization to jointly enhance both reconstruction fidelity and perceptual realism. Extensive experiments demonstrate that OneDC achieves SOTA perceptual quality even with one-step generation, offering over 40% bitrate reduction and 20x faster decoding compared to prior multi-step diffusion-based codecs. Code will be released later.","authors":["Naifu Xue","Zhaoyang Jia","Jiahao Li","Bin Li","Yuan Zhang","Yan Lu"],"url":"https://arxiv.org/abs/2505.16687"}
{"created":"2025-05-23","title":"Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator","abstract":"Post-training of large language models is essential for adapting pre-trained language models (PLMs) to align with human preferences and downstream tasks. While PLMs typically exhibit well-calibrated confidence, post-trained language models (PoLMs) often suffer from over-confidence, assigning high confidence to both correct and incorrect outputs, which can undermine reliability in critical applications. A major obstacle in calibrating PoLMs is the scarcity of labeled data for individual downstream tasks. To address this, we propose Disagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to optimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence calibration. Our method is motivated by the under-confidence issue caused by prediction disagreement between the PLM and PoLM while aligning their confidence via temperature scaling. Theoretically, the PLM's confidence underestimates PoLM's prediction accuracy on disagreement examples, causing a larger $\\tau$ and producing under-confident predictions. DACA mitigates this by selectively using only agreement examples for calibration, effectively decoupling the influence of disagreement. In this manner, our method avoids an overly large $\\tau$ in temperature scaling caused by disagreement examples, improving calibration performance. Extensive experiments demonstrate the effectiveness of our method, improving the average ECE of open-sourced and API-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.","authors":["Beier Luo","Shuoyuan Wang","Yixuan Li","Hongxin Wei"],"url":"https://arxiv.org/abs/2505.16690"}
{"created":"2025-05-23","title":"EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion","abstract":"Voice Conversion research in recent times has increasingly focused on improving the zero-shot capabilities of existing methods. Despite remarkable advancements, current architectures still tend to struggle in zero-shot cross-lingual settings. They are also often unable to generalize for speakers of unseen languages and accents. In this paper, we adopt a simple yet effective approach that combines discrete speech representations from self-supervised models with a non-autoregressive Diffusion-Transformer based conditional flow matching speech decoder. We show that this architecture allows us to train a voice-conversion model in a purely textless, self-supervised fashion. Our technique works without requiring multiple encoders to disentangle speech features. Our model also manages to excel in zero-shot cross-lingual settings even for unseen languages.","authors":["Advait Joglekar","Divyanshu Singh","Rooshil Rohit Bhatia","S. Umesh"],"url":"https://arxiv.org/abs/2505.16691"}
{"created":"2025-05-23","title":"Beyond Induction Heads: In-Context Meta Learning Induces Multi-Phase Circuit Emergence","abstract":"Transformer-based language models exhibit In-Context Learning (ICL), where predictions are made adaptively based on context. While prior work links induction heads to ICL through a sudden jump in accuracy, this can only account for ICL when the answer is included within the context. However, an important property of practical ICL in large language models is the ability to meta-learn how to solve tasks from context, rather than just copying answers from context; how such an ability is obtained during training is largely unexplored. In this paper, we experimentally clarify how such meta-learning ability is acquired by analyzing the dynamics of the model's circuit during training. Specifically, we extend the copy task from previous research into an In-Context Meta Learning setting, where models must infer a task from examples to answer queries. Interestingly, in this setting, we find that there are multiple phases in the process of acquiring such abilities, and that a unique circuit emerges in each phase, contrasting with the single-phases change in induction heads. The emergence of such circuits can be related to several phenomena known in large language models, and our analysis lead to a deeper understanding of the source of the transformer's ICL ability.","authors":["Gouki Minegishi","Hiroki Furuta","Shohei Taniguchi","Yusuke Iwasawa","Yutaka Matsuo"],"url":"https://arxiv.org/abs/2505.16694"}
{"created":"2025-05-23","title":"Software Architecture Meets LLMs: A Systematic Literature Review","abstract":"Large Language Models (LLMs) are used for many different software engineering tasks. In software architecture, they have been applied to tasks such as classification of design decisions, detection of design patterns, and generation of software architecture design from requirements. However, there is little overview on how well they work, what challenges exist, and what open problems remain. In this paper, we present a systematic literature review on the use of LLMs in software architecture. We analyze 18 research articles to answer five research questions, such as which software architecture tasks LLMs are used for, how much automation they provide, which models and techniques are used, and how these approaches are evaluated. Our findings show that while LLMs are increasingly applied to a variety of software architecture tasks and often outperform baselines, some areas, such as generating source code from architectural design, cloud-native computing and architecture, and checking conformance remain underexplored. Although current approaches mostly use simple prompting techniques, we identify a growing research interest in refining LLM-based approaches by integrating advanced techniques.","authors":["Larissa Schmid","Tobias Hey","Martin Armbruster","Sophie Corallo","Dominik Fuch{\\ss}","Jan Keim","Haoyu Liu","Anne Koziolek"],"url":"https://arxiv.org/abs/2505.16697"}
{"created":"2025-05-23","title":"MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models","abstract":"As Large Language Models (LLMs) evolve from passive text generators to active reasoning agents capable of tool interaction, the Model Context Protocol (MCP) has emerged as a standardized framework for dynamic tool discovery and orchestration. Despite widespread industry adoption, existing evaluation methodologies fail to adequately assess tool utilization capabilities within this new paradigm. This paper introduces MCP-RADAR, the first comprehensive benchmark specifically designed to evaluate LLM performance in the MCP framework through a novel five-dimensional approach measuring: answer accuracy, tool selection efficiency, computational resource efficiency, parameter construction accuracy, and execution speed. Unlike conventional benchmarks that rely on subjective human evaluations or binary success metrics, MCP-RADAR employs objective, quantifiable measurements across multiple task domains including software engineering, mathematical reasoning, and general problem-solving. Our evaluations of leading commercial and open-source LLMs reveal distinctive capability profiles with significant trade-offs between accuracy, efficiency, and speed, challenging traditional single-metric performance rankings. Besides, we provide valuable guidance for developers to optimize their tools for maximum model compatibility and effectiveness. While focused on MCP due to its standardized approach, our methodology remains applicable across all LLM agent tool integration frameworks, providing valuable insights for both LLM developers and tool creators to optimize the entire LLM-tool interaction ecosystem. The implementation, configurations, and datasets used in our evaluation are publicly available at https://anonymous.4open.science/r/MCPRadar-B143.","authors":["Xuanqi Gao","Siyi Xie","Juan Zhai","Shqing Ma","Chao Shen"],"url":"https://arxiv.org/abs/2505.16700"}
{"created":"2025-05-23","title":"Truth and Trust: Fake News Detection via Biosignals","abstract":"Understanding how individuals physiologically respond to false information is crucial for advancing misinformation detection systems. This study explores the potential of using physiological signals, specifically electrodermal activity (EDA) and photoplethysmography (PPG), to classify both the veracity of information and its interaction with user belief. In a controlled laboratory experiment, we collected EDA and PPG signals while participants evaluated the truthfulness of climate-related claims. Each trial was labeled based on the objective truth of the claim and the participant's belief, enabling two classification tasks: binary veracity detection and a novel four-class joint belief-veracity classification. We extracted handcrafted features from the raw signals and trained several machine learning models to benchmark the dataset. Our results show that EDA outperforms PPG, indicating its greater sensitivity to physiological responses related to truth perception. However, performance significantly drops in the joint belief-veracity classification task, highlighting the complexity of modeling the interaction between belief and truth. These findings suggest that while physiological signals can reflect basic truth perception, accurately modeling the intricate relationships between belief and veracity remains a significant challenge. This study emphasizes the importance of multimodal approaches that incorporate psychological, physiological, and cognitive factors to improve fake news detection systems. Our work provides a foundation for future research aimed at enhancing misinformation detection via addressing the complexities of human belief and truth processing.","authors":["Gennie Nguyen","Lei Wang","Yangxueqing Jiang","Tom Gedeon"],"url":"https://arxiv.org/abs/2505.16702"}
{"created":"2025-05-23","title":"Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic Forgetting in Multimodal LLMs","abstract":"Although multimodal large language models (MLLMs) have achieved impressive performance, the multimodal instruction tuning stage often causes catastrophic forgetting of the base LLM's language ability, even in strong models like Llama3. To address this, we propose Locate-then-Merge, a training-free parameter fusion framework that first locates important parameters and then selectively merges them. We further introduce Neuron-Fusion, a neuron-level strategy that preserves the influence of neurons with large parameter shifts--neurons likely responsible for newly acquired visual capabilities--while attenuating the influence of neurons with smaller changes that likely encode general-purpose language skills. This design enables better retention of visual adaptation while mitigating language degradation. Experiments on 13 benchmarks across both language and visual tasks show that Neuron-Fusion consistently outperforms existing model merging methods. Further analysis reveals that our method effectively reduces context hallucination in generation.","authors":["Zeping Yu","Sophia Ananiadou"],"url":"https://arxiv.org/abs/2505.16703"}
{"created":"2025-05-23","title":"An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations","abstract":"Concept bottleneck models (CBMs) ensure interpretability by decomposing predictions into human interpretable concepts. Yet the annotations used for training CBMs that enable this transparency are often noisy, and the impact of such corruption is not well understood. In this study, we present the first systematic study of noise in CBMs and show that even moderate corruption simultaneously impairs prediction performance, interpretability, and the intervention effectiveness. Our analysis identifies a susceptible subset of concepts whose accuracy declines far more than the average gap between noisy and clean supervision and whose corruption accounts for most performance loss. To mitigate this vulnerability we propose a two-stage framework. During training, sharpness-aware minimization stabilizes the learning of noise-sensitive concepts. During inference, where clean labels are unavailable, we rank concepts by predictive entropy and correct only the most uncertain ones, using uncertainty as a proxy for susceptibility. Theoretical analysis and extensive ablations elucidate why sharpness-aware training confers robustness and why uncertainty reliably identifies susceptible concepts, providing a principled basis that preserves both interpretability and resilience in the presence of noise.","authors":["Seonghwan Park","Jueun Mun","Donghyun Oh","Namhoon Lee"],"url":"https://arxiv.org/abs/2505.16705"}
{"created":"2025-05-23","title":"KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models","abstract":"Recent advances in multi-modal generative models have enabled significant progress in instruction-based image editing. However, while these models produce visually plausible outputs, their capacity for knowledge-based reasoning editing tasks remains under-explored. In this paper, we introduce KRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a diagnostic benchmark designed to assess models through a cognitively informed lens. Drawing from educational theory, KRIS-Bench categorizes editing tasks across three foundational knowledge types: Factual, Conceptual, and Procedural. Based on this taxonomy, we design 22 representative tasks spanning 7 reasoning dimensions and release 1,267 high-quality annotated editing instances. To support fine-grained evaluation, we propose a comprehensive protocol that incorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints and calibrated through human studies. Empirical results on 10 state-of-the-art models reveal significant gaps in reasoning performance, highlighting the need for knowledge-centric benchmarks to advance the development of intelligent image editing systems.","authors":["Yongliang Wu","Zonghui Li","Xinting Hu","Xinyu Ye","Xianfang Zeng","Gang Yu","Wenbo Zhu","Bernt Schiele","Ming-Hsuan Yang","Xu Yang"],"url":"https://arxiv.org/abs/2505.16707"}
{"created":"2025-05-23","title":"A Novel Generative Model with Causality Constraint for Mitigating Biases in Recommender Systems","abstract":"Accurately predicting counterfactual user feedback is essential for building effective recommender systems. However, latent confounding bias can obscure the true causal relationship between user feedback and item exposure, ultimately degrading recommendation performance. Existing causal debiasing approaches often rely on strong assumptions-such as the availability of instrumental variables (IVs) or strong correlations between latent confounders and proxy variables-that are rarely satisfied in real-world scenarios. To address these limitations, we propose a novel generative framework called Latent Causality Constraints for Debiasing representation learning in Recommender Systems (LCDR). Specifically, LCDR leverages an identifiable Variational Autoencoder (iVAE) as a causal constraint to align the latent representations learned by a standard Variational Autoencoder (VAE) through a unified loss function. This alignment allows the model to leverage even weak or noisy proxy variables to recover latent confounders effectively. The resulting representations are then used to improve recommendation performance. Extensive experiments on three real-world datasets demonstrate that LCDR consistently outperforms existing methods in both mitigating bias and improving recommendation accuracy.","authors":["Jianfeng Deng","Qingfeng Chen","Debo Cheng","Jiuyong Li","Lin Liu","Shichao Zhang"],"url":"https://arxiv.org/abs/2505.16708"}
{"created":"2025-05-23","title":"SEDD-PCC: A Single Encoder-Dual Decoder Framework For End-To-End Learned Point Cloud Compression","abstract":"To encode point clouds containing both geometry and attributes, most learning-based compression schemes treat geometry and attribute coding separately, employing distinct encoders and decoders. This not only increases computational complexity but also fails to fully exploit shared features between geometry and attributes. To address this limitation, we propose SEDD-PCC, an end-to-end learning-based framework for lossy point cloud compression that jointly compresses geometry and attributes. SEDD-PCC employs a single encoder to extract shared geometric and attribute features into a unified latent space, followed by dual specialized decoders that sequentially reconstruct geometry and attributes. Additionally, we incorporate knowledge distillation to enhance feature representation learning from a teacher model, further improving coding efficiency. With its simple yet effective design, SEDD-PCC provides an efficient and practical solution for point cloud compression. Comparative evaluations against both rule-based and learning-based methods demonstrate its competitive performance, highlighting SEDD-PCC as a promising AI-driven compression approach.","authors":["Kai Hsiang Hsieh","Monyneath Yim","Jui Chiu Chiang"],"url":"https://arxiv.org/abs/2505.16709"}
{"created":"2025-05-23","title":"Training Long-Context LLMs Efficiently via Chunk-wise Optimization","abstract":"While long-context large language models (LLMs) exhibit remarkable document processing capabilities, their prohibitively high training costs often hinder customized applications. To mitigate this issue, we propose \\textit{Sequential Chunk-wise Optimization} (SeCO), a memory-efficient training paradigm that partitions lengthy inputs into manageable chunks. Each chunk independently constructs its computational graph and performs localized backpropagation, ensuring that only one chunk's forward activations are stored in memory. Building on SeCO, we further introduce \\textit{Sparse Chunk-wise Optimization} (SpaCO), which reduces computational overhead by selectively propagating gradients to specific chunks and incorporates a carefully designed compensation factor to ensure unbiased gradient estimation. SpaCO decouples the computational cost of backpropagation from the context length, enabling training time to gradually converge to inference time as sequences become longer. Implemented as lightweight training wrappers, both SeCO and SpaCO offer substantial practical benefits. For example, when fine-tuning an 8B model with LoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to 16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up to 3x faster than SeCO under the same experimental setup. These innovations provide new insights into optimizing long-context models, making them more accessible for practical applications. We have open-sourced the code at \\href{https://github.com/wenhaoli-xmu/seco}{here}.","authors":["Wenhao Li","Yuxin Zhang","Gen Luo","Daohai Yu","Rongrong Ji"],"url":"https://arxiv.org/abs/2505.16710"}
{"created":"2025-05-23","title":"The Computational Complexity of Counting Linear Regions in ReLU Neural Networks","abstract":"An established measure of the expressive power of a given ReLU neural network is the number of linear regions into which it partitions the input space. There exist many different, non-equivalent definitions of what a linear region actually is. We systematically assess which papers use which definitions and discuss how they relate to each other. We then analyze the computational complexity of counting the number of such regions for the various definitions. Generally, this turns out to be an intractable problem. We prove NP- and #P-hardness results already for networks with one hidden layer and strong hardness of approximation results for two or more hidden layers. Finally, on the algorithmic side, we demonstrate that counting linear regions can at least be achieved in polynomial space for some common definitions.","authors":["Moritz Stargalla","Christoph Hertrich","Daniel Reichman"],"url":"https://arxiv.org/abs/2505.16716"}
{"created":"2025-05-23","title":"Streaming Diameter of High-Dimensional Points","abstract":"We improve the space bound for streaming approximation of Diameter but also of Farthest Neighbor queries, Minimum Enclosing Ball and its Coreset, in high-dimensional Euclidean spaces. In particular, our deterministic streaming algorithms store $\\mathcal{O}(\\varepsilon^{-2}\\log(\\frac{1}{\\varepsilon}))$ points. This improves by a factor of $\\varepsilon^{-1}$ the previous space bound of Agarwal and Sharathkumar (SODA 2010), while offering a simpler and more complete argument. We also show that storing $\\Omega(\\varepsilon^{-1})$ points is necessary for a $(\\sqrt{2}+\\varepsilon)$-approximation of Farthest Pair or Farthest Neighbor queries.","authors":["Magn\\'us M. Halld\\'orsson","Nicolaos Matsakis","Pavel Vesel\\'y"],"url":"https://arxiv.org/abs/2505.16720"}
{"created":"2025-05-23","title":"Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification","abstract":"As large language models (LLMs) become increasingly prevalent in global applications, ensuring that they are toxicity-free across diverse linguistic contexts remains a critical challenge. We explore \"Cross-lingual Detoxification\", a cross-lingual paradigm that mitigates toxicity, enabling detoxification capabilities to transfer between high and low-resource languages across different script families. We analyze cross-lingual detoxification's effectiveness through 504 extensive settings to evaluate toxicity reduction in cross-distribution settings with limited data and investigate how mitigation impacts model performance on non-toxic tasks, revealing trade-offs between safety and knowledge preservation. Our code and dataset are publicly available at https://github.com/himanshubeniwal/Breaking-mBad.","authors":["Himanshu Beniwal","Youngwoo Kim","Maarten Sap","Soham Dan","Thomas Hartvigsen"],"url":"https://arxiv.org/abs/2505.16722"}
{"created":"2025-05-23","title":"Robust LLM Fingerprinting via Domain-Specific Watermarks","abstract":"As open-source language models (OSMs) grow more capable and are widely shared and finetuned, ensuring model provenance, i.e., identifying the origin of a given model instance, has become an increasingly important issue. At the same time, existing backdoor-based model fingerprinting techniques often fall short of achieving key requirements of real-world model ownership detection. In this work, we build on the observation that while current open-source model watermarks fail to achieve reliable content traceability, they can be effectively adapted to address the challenge of model provenance. To this end, we introduce the concept of domain-specific watermarking for model fingerprinting. Rather than watermarking all generated content, we train the model to embed watermarks only within specified subdomains (e.g., particular languages or topics). This targeted approach ensures detection reliability, while improving watermark durability and quality under a range of real-world deployment settings. Our evaluations show that domain-specific watermarking enables model fingerprinting with strong statistical guarantees, controllable false positive rates, high detection power, and preserved generation quality. Moreover, we find that our fingerprints are inherently stealthy and naturally robust to real-world variability across deployment scenarios.","authors":["Thibaud Gloaguen","Robin Staab","Nikola Jovanovi\\'c","Martin Vechev"],"url":"https://arxiv.org/abs/2505.16723"}
{"created":"2025-05-23","title":"Advancing Brainwave Modeling with a Codebook-Based Foundation Model","abstract":"Recent advances in large-scale pre-trained Electroencephalogram (EEG) models have shown great promise, driving progress in Brain-Computer Interfaces (BCIs) and healthcare applications. However, despite their success, many existing pre-trained models have struggled to fully capture the rich information content of neural oscillations, a limitation that fundamentally constrains their performance and generalizability across diverse BCI tasks. This limitation is frequently rooted in suboptimal architectural design choices which constrain their representational capacity. In this work, we introduce LaBraM++, an enhanced Large Brainwave Foundation Model (LBM) that incorporates principled improvements grounded in robust signal processing foundations. LaBraM++ demonstrates substantial gains across a variety of tasks, consistently outperforming its originally-based architecture and achieving competitive results when compared to other open-source LBMs. Its superior performance and training efficiency highlight its potential as a strong foundation for future advancements in LBMs.","authors":["Konstantinos Barmpas","Na Lee","Yannis Panagakis","Dimitrios A. Adamos","Nikolaos Laskaris","Stefanos Zafeiriou"],"url":"https://arxiv.org/abs/2505.16724"}
{"created":"2025-05-23","title":"Masked Conditioning for Deep Generative Models","abstract":"Datasets in engineering domains are often small, sparsely labeled, and contain numerical as well as categorical conditions. Additionally. computational resources are typically limited in practical applications which hinders the adoption of generative models for engineering tasks. We introduce a novel masked-conditioning approach, that enables generative models to work with sparse, mixed-type data. We mask conditions during training to simulate sparse conditions at inference time. For this purpose, we explore the use of various sparsity schedules that show different strengths and weaknesses. In addition, we introduce a flexible embedding that deals with categorical as well as numerical conditions. We integrate our method into an efficient variational autoencoder as well as a latent diffusion model and demonstrate the applicability of our approach on two engineering-related datasets of 2D point clouds and images. Finally, we show that small models trained on limited data can be coupled with large pretrained foundation models to improve generation quality while retaining the controllability induced by our conditioning scheme.","authors":["Phillip Mueller","Jannik Wiese","Sebastian Mueller","Lars Mikelsons"],"url":"https://arxiv.org/abs/2505.16725"}
{"created":"2025-05-23","title":"D-LIO: 6DoF Direct LiDAR-Inertial Odometry based on Simultaneous Truncated Distance Field Mapping","abstract":"This paper presents a new approach for 6DoF Direct LiDAR-Inertial Odometry (D-LIO) based on the simultaneous mapping of truncated distance fields on CPU. Such continuous representation (in the vicinity of the points) enables working with raw 3D LiDAR data online, avoiding the need of LiDAR feature selection and tracking, simplifying the odometry pipeline and easily generalizing to many scenarios. The method is based on the proposed Fast Truncated Distance Field (Fast-TDF) method as a convenient tool to represent the environment. Such representation enables i) solving the LiDAR point-cloud registration as a nonlinear optimization process without the need of selecting/tracking LiDAR features in the input data, ii) simultaneously producing an accurate truncated distance field map of the environment, and iii) updating such map at constant time independently of its size. The approach is tested using open datasets, aerial and ground. It is also benchmarked against other state-of-the-art odometry approaches, demonstrating the same or better level of accuracy with the added value of an online-generated TDF representation of the environment, that can be used for other robotics tasks as planning or collision avoidance. The source code is publicly available at https://anonymous.4open.science/r/D-LIO","authors":["Lucia Coto-Elena","J. E. Maese","L. Merino","F. Caballero"],"url":"https://arxiv.org/abs/2505.16726"}
{"created":"2025-05-23","title":"Detecting Fake News Belief via Skin and Blood Flow Signals","abstract":"Misinformation poses significant risks to public opinion, health, and security. While most fake news detection methods rely on text analysis, little is known about how people physically respond to false information or repeated exposure to the same statements. This study investigates whether wearable sensors can detect belief in a statement or prior exposure to it. We conducted a controlled experiment where participants evaluated statements while wearing an EmotiBit sensor that measured their skin conductance (electrodermal activity, EDA) and peripheral blood flow (photoplethysmography, PPG). From 28 participants, we collected a dataset of 672 trials, each labeled with whether the participant believed the statement and whether they had seen it before. This dataset introduces a new resource for studying physiological responses to misinformation. Using machine learning models, including KNN, CNN, and LightGBM, we analyzed these physiological patterns. The best-performing model achieved 67.83\\% accuracy, with skin conductance outperforming PPG. These findings demonstrate the potential of wearable sensors as a minimally intrusive tool for detecting belief and prior exposure, offering new directions for real-time misinformation detection and adaptive, user-aware systems.","authors":["Gennie Nguyen","Lei Wang","Yangxueqing Jiang","Tom Gedeon"],"url":"https://arxiv.org/abs/2505.16730"}
{"created":"2025-05-23","title":"Sequential Monte Carlo for Policy Optimization in Continuous POMDPs","abstract":"Optimal decision-making under partial observability requires agents to balance reducing uncertainty (exploration) against pursuing immediate objectives (exploitation). In this paper, we introduce a novel policy optimization framework for continuous partially observable Markov decision processes (POMDPs) that explicitly addresses this challenge. Our method casts policy learning as probabilistic inference in a non-Markovian Feynman--Kac model that inherently captures the value of information gathering by anticipating future observations, without requiring extrinsic exploration bonuses or handcrafted heuristics. To optimize policies under this model, we develop a nested sequential Monte Carlo~(SMC) algorithm that efficiently estimates a history-dependent policy gradient under samples from the optimal trajectory distribution induced by the POMDP. We demonstrate the effectiveness of our algorithm across standard continuous POMDP benchmarks, where existing methods struggle to act under uncertainty.","authors":["Hany Abdulsamad","Sahel Iqbal","Simo S\\\"arkk\\\"a"],"url":"https://arxiv.org/abs/2505.16732"}
{"created":"2025-05-23","title":"Forward-only Diffusion Probabilistic Models","abstract":"This work presents a forward-only diffusion (FoD) approach for generative modelling. In contrast to traditional diffusion models that rely on a coupled forward-backward diffusion scheme, FoD directly learns data generation through a single forward diffusion process, yielding a simple yet efficient generative framework. The core of FoD is a state-dependent linear stochastic differential equation that involves a mean-reverting term in both the drift and diffusion functions. This mean-reversion property guarantees the convergence to clean data, naturally simulating a stochastic interpolation between source and target distributions. More importantly, FoD is analytically tractable and is trained using a simple stochastic flow matching objective, enabling a few-step non-Markov chain sampling during inference. The proposed FoD model, despite its simplicity, achieves competitive performance on various image-conditioned (e.g., image restoration) and unconditional generation tasks, demonstrating its effectiveness in generative modelling. Our code is available at https://github.com/Algolzw/FoD.","authors":["Ziwei Luo","Fredrik K. Gustafsson","Jens Sj\\\"olund","Thomas B. Sch\\\"on"],"url":"https://arxiv.org/abs/2505.16733"}
{"created":"2025-05-23","title":"Maximum Total Correlation Reinforcement Learning","abstract":"Simplicity is a powerful inductive bias. In reinforcement learning, regularization is used for simpler policies, data augmentation for simpler representations, and sparse reward functions for simpler objectives, all that, with the underlying motivation to increase generalizability and robustness by focusing on the essentials. Supplementary to these techniques, we investigate how to promote simple behavior throughout the episode. To that end, we introduce a modification of the reinforcement learning problem that additionally maximizes the total correlation within the induced trajectories. We propose a practical algorithm that optimizes all models, including policy and state representation, based on a lower-bound approximation. In simulated robot environments, our method naturally generates policies that induce periodic and compressible trajectories, and that exhibit superior robustness to noise and changes in dynamics compared to baseline methods, while also improving performance in the original tasks.","authors":["Bang You","Puze Liu","Huaping Liu","Jan Peters","Oleg Arenz"],"url":"https://arxiv.org/abs/2505.16734"}
{"created":"2025-05-23","title":"Backward Oversmoothing: why is it hard to train deep Graph Neural Networks?","abstract":"Oversmoothing has long been identified as a major limitation of Graph Neural Networks (GNNs): input node features are smoothed at each layer and converge to a non-informative representation, if the weights of the GNN are sufficiently bounded. This assumption is crucial: if, on the contrary, the weights are sufficiently large, then oversmoothing may not happen. Theoretically, GNN could thus learn to not oversmooth. However it does not really happen in practice, which prompts us to examine oversmoothing from an optimization point of view. In this paper, we analyze backward oversmoothing, that is, the notion that backpropagated errors used to compute gradients are also subject to oversmoothing from output to input. With non-linear activation functions, we outline the key role of the interaction between forward and backward smoothing. Moreover, we show that, due to backward oversmoothing, GNNs provably exhibit many spurious stationary points: as soon as the last layer is trained, the whole GNN is at a stationary point. As a result, we can exhibit regions where gradients are near-zero while the loss stays high. The proof relies on the fact that, unlike forward oversmoothing, backward errors are subjected to a linear oversmoothing even in the presence of non-linear activation function, such that the average of the output error plays a key role. Additionally, we show that this phenomenon is specific to deep GNNs, and exhibit counter-example Multi-Layer Perceptron. This paper is a step toward a more complete comprehension of the optimization landscape specific to GNNs.","authors":["Nicolas Keriven"],"url":"https://arxiv.org/abs/2505.16736"}
{"created":"2025-05-23","title":"Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization","abstract":"The significant progress of large language models (LLMs) has led to remarkable achievements across numerous applications. However, their ability to generate harmful content has sparked substantial safety concerns. Despite the implementation of safety alignment techniques during the pre-training phase, recent research indicates that fine-tuning LLMs on adversarial or even benign data can inadvertently compromise their safety. In this paper, we re-examine the fundamental issue of why fine-tuning on non-harmful data still results in safety degradation. We introduce a safety-aware probing (SAP) optimization framework designed to mitigate the safety risks of fine-tuning LLMs. Specifically, SAP incorporates a safety-aware probe into the gradient propagation process, mitigating the model's risk of safety degradation by identifying potential pitfalls in gradient directions, thereby enhancing task-specific performance while successfully preserving model safety. Our extensive experimental results demonstrate that SAP effectively reduces harmfulness below the original fine-tuned model and achieves comparable test loss to standard fine-tuning methods. Our code is available at https://github.com/ChengcanWu/SAP.","authors":["Chengcan Wu","Zhixin Zhang","Zeming Wei","Yihao Zhang","Meng Sun"],"url":"https://arxiv.org/abs/2505.16737"}
{"created":"2025-05-23","title":"Robust Vision-Based Runway Detection through Conformal Prediction and Conformal mAP","abstract":"We explore the use of conformal prediction to provide statistical uncertainty guarantees for runway detection in vision-based landing systems (VLS). Using fine-tuned YOLOv5 and YOLOv6 models on aerial imagery, we apply conformal prediction to quantify localization reliability under user-defined risk levels. We also introduce Conformal mean Average Precision (C-mAP), a novel metric aligning object detection performance with conformal guarantees. Our results show that conformal prediction can improve the reliability of runway detection by quantifying uncertainty in a statistically sound way, increasing safety on-board and paving the way for certification of ML system in the aerospace domain.","authors":["Alya Zouzou","L\\'eo and\\'eol","M\\'elanie Ducoffe","Ryma Boumazouza"],"url":"https://arxiv.org/abs/2505.16740"}
{"created":"2025-05-23","title":"Meta-reinforcement learning with minimum attention","abstract":"Minimum attention applies the least action principle in the changes of control concerning state and time, first proposed by Brockett. The involved regularization is highly relevant in emulating biological control, such as motor learning. We apply minimum attention in reinforcement learning (RL) as part of the rewards and investigate its connection to meta-learning and stabilization. Specifically, model-based meta-learning with minimum attention is explored in high-dimensional nonlinear dynamics. Ensemble-based model learning and gradient-based meta-policy learning are alternately performed. Empirically, we show that the minimum attention does show outperforming competence in comparison to the state-of-the-art algorithms in model-free and model-based RL, i.e., fast adaptation in few shots and variance reduction from the perturbations of the model and environment. Furthermore, the minimum attention demonstrates the improvement in energy efficiency.","authors":["Pilhwa Lee","Shashank Gupta"],"url":"https://arxiv.org/abs/2505.16741"}
{"created":"2025-05-23","title":"TRIM: Achieving Extreme Sparsity with Targeted Row-wise Iterative Metric-driven Pruning","abstract":"Large Language Models (LLMs) present significant computational and memory challenges due to their extensive size, making pruning essential for their efficient deployment. Existing one-shot pruning methods often apply uniform sparsity constraints across layers or within each layer, resulting in suboptimal performance, especially at high sparsity ratios. This work introduces TRIM (Targeted Row-wise Iterative Metric-driven pruning), a novel approach that applies varying sparsity ratios to individual output dimensions (rows) within each layer. TRIM employs an iterative adjustment process guided by quality metrics to optimize dimension-wise sparsity allocation, focusing on reducing variance in quality retention across outputs to preserve critical information. TRIM can be seamlessly integrated with existing layer-wise pruning strategies. Our evaluations on perplexity and zero-shot tasks across diverse LLM families (Qwen2.5, LLaMA-2, and OPT) and sparsity levels demonstrate that TRIM achieves new state-of-the-art results and enhances stability. For instance, at 80% sparsity, TRIM reduces perplexity by 48% for Qwen2.5-14B and over 90% for OPT-13B compared to baseline methods. We conclude that fine-grained, dimension-wise sparsity adaptation is crucial for pushing the limits of extreme LLM compression. Code available at: https://github.com/flobk/TRIM","authors":["Florentin Beck","William Rudman","Carsten Eickhoff"],"url":"https://arxiv.org/abs/2505.16743"}
{"created":"2025-05-23","title":"Flipping and Forking","abstract":"Monadic stability and the more general monadic dependence (or NIP) are tameness conditions for classes of logical structures, studied in the 80's in Shelah's classification program in model theory. They recently emerged in algorithmic and structural graph theory and finite model theory as central notions in relation with the model checking problem for first-order logic: the problem was shown to be fixed-parameter tractable for inputs which come from a fixed class of graphs which is monadically stable, and is conjectured to be tractable in all monadically dependent classes. Several combinatorial characterizations of such graph classes turned out to be essential in their algorithmic treatment; they are all based on the fundamental operation of \"flipping\" a graph.","authors":["Wojciech Przybyszewski","Szymon Toru\\'nczyk"],"url":"https://arxiv.org/abs/2505.16745"}
{"created":"2025-05-23","title":"Revenue Optimization with Price-Sensitive and Interdependent Demand","abstract":"As Kalyan T. Talluri and Garrett J. Van Ryzin describe in their work [3], Revenue Management aims to maximize an organization's revenue by considering three types of decision categories: structural, pricing, and quantity. In this document, our primary focus will be on decisions related to pricing and quantity for the sale of airline tickets on a direct flight over a certain number of time periods. More specifically, we will only focus on the optimization aspect of this problem. We will assume the demand data to be given, since Air France estimates it beforehand using real data. Similarly, we assume all price options to be predetermined by Air France's algorithms and verified by their analysts. Our objective will be to maximize the revenue of a direct flight by choosing the prices for each product from the predefined set of options.","authors":["Julien Laasri","Marc Revol"],"url":"https://arxiv.org/abs/2505.16748"}
{"created":"2025-05-23","title":"Action is All You Need: Dual-Flow Generative Ranking Network for Recommendation","abstract":"We introduce the Dual-Flow Generative Ranking Network (DFGR), a two-stream architecture designed for recommendation systems. DFGR integrates innovative interaction patterns between real and fake flows within the QKV modules of the self-attention mechanism, enhancing both training and inference efficiency. This approach effectively addresses a key limitation observed in Meta's proposed HSTU generative recommendation approach, where heterogeneous information volumes are mapped into identical vector spaces, leading to training instability. Unlike traditional recommendation models, DFGR only relies on user history behavior sequences and minimal attribute information, eliminating the need for extensive manual feature engineering. Comprehensive evaluations on open-source and industrial datasets reveal DFGR's superior performance compared to established baselines such as DIN, DCN, DIEN, and DeepFM. We also investigate optimal parameter allocation strategies under computational constraints, establishing DFGR as an efficient and effective next-generation generate ranking paradigm.","authors":["Hao Guo","Erpeng Xue","Lei Huang","Shichao Wang","Xiaolei Wang","Lei Wang","Jinpeng Wang","Sheng Chen"],"url":"https://arxiv.org/abs/2505.16752"}
{"created":"2025-05-23","title":"PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects","abstract":"Offline reinforcement learning (RL) has gained traction as a powerful paradigm for learning control policies from pre-collected data, eliminating the need for costly or risky online interactions. While many open-source libraries offer robust implementations of offline RL algorithms, they all rely on datasets composed of experience tuples consisting of state, action, next state, and reward. Managing, curating, and distributing such datasets requires suitable infrastructure. Although static datasets exist for established benchmark problems, no standardized or scalable solution supports developing and sharing datasets for novel or user-defined benchmarks. To address this gap, we introduce PyTupli, a Python-based tool to streamline the creation, storage, and dissemination of benchmark environments and their corresponding tuple datasets. PyTupli includes a lightweight client library with defined interfaces for uploading and retrieving benchmarks and data. It supports fine-grained filtering at both the episode and tuple level, allowing researchers to curate high-quality, task-specific datasets. A containerized server component enables production-ready deployment with authentication, access control, and automated certificate provisioning for secure use. By addressing key barriers in dataset infrastructure, PyTupli facilitates more collaborative, reproducible, and scalable offline RL research.","authors":["Hannah Markgraf","Michael Eichelbeck","Daria Cappey","Selin Demirt\\\"urk","Yara Schattschneider","Matthias Althoff"],"url":"https://arxiv.org/abs/2505.16754"}
{"created":"2025-05-23","title":"Multi-Output Gaussian Processes for Graph-Structured Data","abstract":"Graph-structured data is a type of data to be obtained associated with a graph structure where vertices and edges describe some kind of data correlation. This paper proposes a regression method on graph-structured data, which is based on multi-output Gaussian processes (MOGP), to capture both the correlation between vertices and the correlation between associated data. The proposed formulation is built on the definition of MOGP. This allows it to be applied to a wide range of data configurations and scenarios. Moreover, it has high expressive capability due to its flexibility in kernel design. It includes existing methods of Gaussian processes for graph-structured data as special cases and is possible to remove restrictions on data configurations, model selection, and inference scenarios in the existing methods. The performance of extensions achievable by the proposed formulation is evaluated through computer experiments with synthetic and real data.","authors":["Ayano Nakai-Kasai","Tadashi Wadayama"],"url":"https://arxiv.org/abs/2505.16755"}
{"created":"2025-05-23","title":"Representation Discrepancy Bridging Method for Remote Sensing Image-Text Retrieval","abstract":"Remote Sensing Image-Text Retrieval (RSITR) plays a critical role in geographic information interpretation, disaster monitoring, and urban planning by establishing semantic associations between image and textual descriptions. Existing Parameter-Efficient Fine-Tuning (PEFT) methods for Vision-and-Language Pre-training (VLP) models typically adopt symmetric adapter structures for exploring cross-modal correlations. However, the strong discriminative nature of text modality may dominate the optimization process and inhibits image representation learning. The nonnegligible imbalanced cross-modal optimization remains a bottleneck to enhancing the model performance. To address this issue, this study proposes a Representation Discrepancy Bridging (RDB) method for the RSITR task. On the one hand, a Cross-Modal Asymmetric Adapter (CMAA) is designed to enable modality-specific optimization and improve feature alignment. The CMAA comprises a Visual Enhancement Adapter (VEA) and a Text Semantic Adapter (TSA). VEA mines fine-grained image features by Differential Attention (DA) mechanism, while TSA identifies key textual semantics through Hierarchical Attention (HA) mechanism. On the other hand, this study extends the traditional single-task retrieval framework to a dual-task optimization framework and develops a Dual-Task Consistency Loss (DTCL). The DTCL improves cross-modal alignment robustness through an adaptive weighted combination of cross-modal, classification, and exponential moving average consistency constraints. Experiments on RSICD and RSITMD datasets show that the proposed RDB method achieves a 6%-11% improvement in mR metrics compared to state-of-the-art PEFT methods and a 1.15%-2% improvement over the full fine-tuned GeoRSCLIP model.","authors":["Hailong Ning","Siying Wang","Tao Lei","Xiaopeng Cao","Huanmin Dou","Bin Zhao","Asoke K. Nandi","Petia Radeva"],"url":"https://arxiv.org/abs/2505.16756"}
{"created":"2025-05-23","title":"Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning","abstract":"Existing pretrained models for 3D mesh generation often suffer from data biases and produce low-quality results, while global reinforcement learning (RL) methods rely on object-level rewards that struggle to capture local structure details. To address these challenges, we present \\textbf{Mesh-RFT}, a novel fine-grained reinforcement fine-tuning framework that employs Masked Direct Preference Optimization (M-DPO) to enable localized refinement via quality-aware face masking. To facilitate efficient quality evaluation, we introduce an objective topology-aware scoring system to evaluate geometric integrity and topological regularity at both object and face levels through two metrics: Boundary Edge Ratio (BER) and Topology Score (TS). By integrating these metrics into a fine-grained RL strategy, Mesh-RFT becomes the first method to optimize mesh quality at the granularity of individual faces, resolving localized errors while preserving global coherence. Experiment results show that our M-DPO approach reduces Hausdorff Distance (HD) by 24.6\\% and improves Topology Score (TS) by 3.8\\% over pre-trained models, while outperforming global DPO methods with a 17.4\\% HD reduction and 4.9\\% TS gain. These results demonstrate Mesh-RFT's ability to improve geometric integrity and topological regularity, achieving new state-of-the-art performance in production-ready mesh generation. Project Page: \\href{https://hitcslj.github.io/mesh-rft/}{this https URL}.","authors":["Jian Liu","Jing Xu","Song Guo","Jing Li","Jingfeng Guo","Jiaao Yu","Haohan Weng","Biwen Lei","Xianghui Yang","Zhuo Chen","Fangqi Zhu","Tao Han","Chunchao Guo"],"url":"https://arxiv.org/abs/2505.16761"}
{"created":"2025-05-23","title":"A Riemannian Optimization Approach for Finding the Nearest Reversible Markov Chain","abstract":"We address the algorithmic problem of determining the reversible Markov chain $\\tilde X$ that is closest to a given Markov chain $X$, with an identical stationary distribution. More specifically, $\\tilde X$ is the reversible Markov chain with the closest transition matrix, in the Frobenius norm, to the transition matrix of $X$. To compute the transition matrix of $\\tilde X$, we propose a novel approach based on Riemannian optimization. Our method introduces a modified multinomial manifold endowed with a prescribed stationary vector, while also satisfying the detailed balance conditions, all within the framework of the Fisher metric. We evaluate the performance of the proposed approach in comparison with an existing quadratic programming method and demonstrate its effectiveness through a series of synthetic experiments, as well as in the construction of a reversible Markov chain from transition count data obtained via direct estimation from a stochastic differential equation.","authors":["Fabio Durastante","Miryam Gnazzo","Beatrice Meini"],"url":"https://arxiv.org/abs/2505.16762"}
{"created":"2025-05-23","title":"Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation","abstract":"Text-to-image models are powerful for producing high-quality images based on given text prompts, but crafting these prompts often requires specialized vocabulary. To address this, existing methods train rewriting models with supervision from large amounts of manually annotated data and trained aesthetic assessment models. To alleviate the dependence on data scale for model training and the biases introduced by trained models, we propose a novel prompt optimization framework, designed to rephrase a simple user prompt into a sophisticated prompt to a text-to-image model. Specifically, we employ the large vision language models (LVLMs) as the solver to rewrite the user prompt, and concurrently, employ LVLMs as a reward model to score the aesthetics and alignment of the images generated by the optimized prompt. Instead of laborious human feedback, we exploit the prior knowledge of the LVLM to provide rewards, i.e., AI feedback. Simultaneously, the solver and the reward model are unified into one model and iterated in reinforcement learning to achieve self-improvement by giving a solution and judging itself. Results on two popular datasets demonstrate that our method outperforms other strong competitors.","authors":["Hongji Yang","Yucheng Zhou","Wencheng Han","Jianbing Shen"],"url":"https://arxiv.org/abs/2505.16763"}
{"created":"2025-05-23","title":"Can a domain-specific language improve program structure comprehension of data pipelines? A mixed-methods study","abstract":"In many application domains, domain-specific languages can allow domain experts to contribute to collaborative projects more correctly and efficiently. To do so, they must be able to understand program structure from reading existing source code. With high-quality data becoming an increasingly important resource, the creation of data pipelines is an important application domain for domain-specific languages.","authors":["Philip Heltweg","Georg-Daniel Schwarz","Dirk Riehle"],"url":"https://arxiv.org/abs/2505.16764"}
{"created":"2025-05-23","title":"When Safety Detectors Aren't Enough: A Stealthy and Effective Jailbreak Attack on LLMs via Steganographic Techniques","abstract":"Jailbreak attacks pose a serious threat to large language models (LLMs) by bypassing built-in safety mechanisms and leading to harmful outputs. Studying these attacks is crucial for identifying vulnerabilities and improving model security. This paper presents a systematic survey of jailbreak methods from the novel perspective of stealth. We find that existing attacks struggle to simultaneously achieve toxic stealth (concealing toxic content) and linguistic stealth (maintaining linguistic naturalness). Motivated by this, we propose StegoAttack, a fully stealthy jailbreak attack that uses steganography to hide the harmful query within benign, semantically coherent text. The attack then prompts the LLM to extract the hidden query and respond in an encrypted manner. This approach effectively hides malicious intent while preserving naturalness, allowing it to evade both built-in and external safety mechanisms. We evaluate StegoAttack on four safety-aligned LLMs from major providers, benchmarking against eight state-of-the-art methods. StegoAttack achieves an average attack success rate (ASR) of 92.00%, outperforming the strongest baseline by 11.0%. Its ASR drops by less than 1% even under external detection (e.g., Llama Guard). Moreover, it attains the optimal comprehensive scores on stealth detection metrics, demonstrating both high efficacy and exceptional stealth capabilities. The code is available at https://anonymous.4open.science/r/StegoAttack-Jail66","authors":["Jianing Geng","Biao Yi","Zekun Fei","Tongxi Wu","Lihai Nie","Zheli Liu"],"url":"https://arxiv.org/abs/2505.16765"}
{"created":"2025-05-23","title":"Simulation-Guided Approximate Logic Synthesis Under the Maximum Error Constraint","abstract":"Approximate computing is an effective computing paradigm for improving energy efficiency of error-tolerant applications. Approximate logic synthesis (ALS) is an automatic process to generate approximate circuits with reduced area, delay, and power, while satisfying user-specified error constraints. This paper focuses on ALS under the maximum error constraint. As an essential error metric that provides a worst-case error guarantee, the maximum error is crucial for many applications such as image processing and machine learning. This work proposes an efficient simulation-guided ALS flow that handles this constraint. It utilizes logic simulation to 1) prune local approximate changes (LACs) with large errors that violate the error constraint, and 2) accelerate the SAT-based LAC selection process. Furthermore, to enhance scalability, our ALS flow iteratively selects a set of promising LACs satisfying the error constraint to improve the efficiency. The experimental results show that compared with the state-of-the-art method, our ALS flow accelerates by 30.6 times, and further reduces circuit area and delay by 18.2% and 4.9%, respectively. Notably, our flow scales to large EPFL benchmarks with up to 38540 nodes, which cannot be handled by any existing ALS method for maximum error.","authors":["Chang Meng","Weikang Qian","Giovanni De Micheli"],"url":"https://arxiv.org/abs/2505.16769"}
{"created":"2025-05-23","title":"RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs","abstract":"The rapid advancement of native multi-modal models and omni-models, exemplified by GPT-4o, Gemini, and o3, with their capability to process and generate content across modalities such as text and images, marks a significant milestone in the evolution of intelligence. Systematic evaluation of their multi-modal output capabilities in visual thinking processes (also known as multi-modal chain of thought, M-CoT) becomes critically important. However, existing benchmarks for evaluating multi-modal models primarily focus on assessing multi-modal inputs and text-only reasoning while neglecting the importance of reasoning through multi-modal outputs. In this paper, we present a benchmark, dubbed RBench-V, designed to assess models' vision-indispensable reasoning abilities. To construct RBench-V, we carefully hand-pick 803 questions covering math, physics, counting, and games. Unlike previous benchmarks that typically specify certain input modalities, RBench-V presents problems centered on multi-modal outputs, which require image manipulation such as generating novel images and constructing auxiliary lines to support the reasoning process. We evaluate numerous open- and closed-source models on RBench-V, including o3, Gemini 2.5 Pro, Qwen2.5-VL, etc. Even the best-performing model, o3, achieves only 25.8% accuracy on RBench-V, far below the human score of 82.3%, highlighting that current models struggle to leverage multi-modal reasoning. Data and code are available at https://evalmodels.github.io/rbenchv","authors":["Meng-Hao Guo","Xuanyu Chu","Qianrui Yang","Zhe-Han Mo","Yiqing Shen","Pei-lin Li","Xinjie Lin","Jinnian Zhang","Xin-Sheng Chen","Yi Zhang","Kiyohiro Nakayama","Zhengyang Geng","Houwen Peng","Han Hu","Shi-Nin Hu"],"url":"https://arxiv.org/abs/2505.16770"}
{"created":"2025-05-23","title":"Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review","abstract":"This paper presents a comprehensive synthesis of major breakthroughs in artificial intelligence (AI) over the past fifteen years, integrating historical, theoretical, and technological perspectives. It identifies key inflection points in AI' s evolution by tracing the convergence of computational resources, data access, and algorithmic innovation. The analysis highlights how researchers enabled GPU based model training, triggered a data centric shift with ImageNet, simplified architectures through the Transformer, and expanded modeling capabilities with the GPT series. Rather than treating these advances as isolated milestones, the paper frames them as indicators of deeper paradigm shifts. By applying concepts from statistical learning theory such as sample complexity and data efficiency, the paper explains how researchers translated breakthroughs into scalable solutions and why the field must now embrace data centric approaches. In response to rising privacy concerns and tightening regulations, the paper evaluates emerging solutions like federated learning, privacy enhancing technologies (PETs), and the data site paradigm, which reframe data access and security. In cases where real world data remains inaccessible, the paper also assesses the utility and constraints of mock and synthetic data generation. By aligning technical insights with evolving data infrastructure, this study offers strategic guidance for future AI research and policy development.","authors":["Beyazit Bestami Yuksel","Ayse Yilmazer Metin"],"url":"https://arxiv.org/abs/2505.16771"}
{"created":"2025-05-23","title":"Mitigating Overfitting in Medical Imaging: Self-Supervised Pretraining vs. ImageNet Transfer Learning for Dermatological Diagnosis","abstract":"Deep learning has transformed computer vision but relies heavily on large labeled datasets and computational resources. Transfer learning, particularly fine-tuning pretrained models, offers a practical alternative; however, models pretrained on natural image datasets such as ImageNet may fail to capture domain-specific characteristics in medical imaging. This study introduces an unsupervised learning framework that extracts high-value dermatological features instead of relying solely on ImageNet-based pretraining. We employ a Variational Autoencoder (VAE) trained from scratch on a proprietary dermatological dataset, allowing the model to learn a structured and clinically relevant latent space. This self-supervised feature extractor is then compared to an ImageNet-pretrained backbone under identical classification conditions, highlighting the trade-offs between general-purpose and domain-specific pretraining. Our results reveal distinct learning patterns. The self-supervised model achieves a final validation loss of 0.110 (-33.33%), while the ImageNet-pretrained model stagnates at 0.100 (-16.67%), indicating overfitting. Accuracy trends confirm this: the self-supervised model improves from 45% to 65% (+44.44%) with a near-zero overfitting gap, whereas the ImageNet-pretrained model reaches 87% (+50.00%) but plateaus at 75% (+19.05%), with its overfitting gap increasing to +0.060. These findings suggest that while ImageNet pretraining accelerates convergence, it also amplifies overfitting on non-clinically relevant features. In contrast, self-supervised learning achieves steady improvements, stronger generalization, and superior adaptability, underscoring the importance of domain-specific feature extraction in medical imaging.","authors":["Iv\\'an Matas","Carmen Serrano","Miguel Nogales","David Moreno","Lara Ferr\\'andiz","Teresa Ojeda","Bego\\~na Acha"],"url":"https://arxiv.org/abs/2505.16773"}
{"created":"2025-05-23","title":"IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models","abstract":"Large language models (LLMs) have demonstrated strong instruction-following capabilities in text-based tasks. However, this ability often deteriorates in multimodal models after alignment with non-text modalities such as images or audio. While several recent efforts have investigated instruction-following performance in text and vision-language models, instruction-following in audio-based large language models remains largely unexplored. To bridge this gap, we introduce IFEval-Audio, a novel evaluation dataset designed to assess the ability to follow instructions in an audio LLM. IFEval-Audio contains 280 audio-instruction-answer triples across six diverse dimensions: Content, Capitalization, Symbol, List Structure, Length, and Format. Each example pairs an audio input with a text instruction, requiring the model to generate an output that follows a specified structure. We benchmark state-of-the-art audio LLMs on their ability to follow audio-involved instructions. The dataset is released publicly to support future research in this emerging area.","authors":["Yiming Gao","Bin Wang","Chengwei Wei","Shuo Sun","AiTi Aw"],"url":"https://arxiv.org/abs/2505.16774"}
{"created":"2025-05-23","title":"Single Domain Generalization for Few-Shot Counting via Universal Representation Matching","abstract":"Few-shot counting estimates the number of target objects in an image using only a few annotated exemplars. However, domain shift severely hinders existing methods to generalize to unseen scenarios. This falls into the realm of single domain generalization that remains unexplored in few-shot counting. To solve this problem, we begin by analyzing the main limitations of current methods, which typically follow a standard pipeline that extract the object prototypes from exemplars and then match them with image feature to construct the correlation map. We argue that existing methods overlook the significance of learning highly generalized prototypes. Building on this insight, we propose the first single domain generalization few-shot counting model, Universal Representation Matching, termed URM. Our primary contribution is the discovery that incorporating universal vision-language representations distilled from a large scale pretrained vision-language model into the correlation construction process substantially improves robustness to domain shifts without compromising in domain performance. As a result, URM achieves state-of-the-art performance on both in domain and the newly introduced domain generalization setting.","authors":["Xianing Chen","Si Huo","Borui Jiang","Hailin Hu","Xinghao Chen"],"url":"https://arxiv.org/abs/2505.16778"}
{"created":"2025-05-23","title":"Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making","abstract":"In group decision-making (GDM) scenarios, uncertainty, dynamic social structures, and vague information present major challenges for traditional opinion dynamics models. To address these issues, this study proposes a novel social network group decision-making (SNGDM) framework that integrates three-way decision (3WD) theory, dynamic network reconstruction, and linguistic opinion representation. First, the 3WD mechanism is introduced to explicitly model hesitation and ambiguity in agent judgments, thereby preventing irrational decisions. Second, a connection adjustment rule based on opinion similarity is developed, enabling agents to adaptively update their communication links and better reflect the evolving nature of social relationships. Third, linguistic terms are used to describe agent opinions, allowing the model to handle subjective, vague, or incomplete information more effectively. Finally, an integrated multi-agent decision-making framework is constructed, which simultaneously considers individual uncertainty, opinion evolution, and network dynamics. The proposed model is applied to a multi-UAV cooperative decision-making scenario, where simulation results and consensus analysis demonstrate its effectiveness. Experimental comparisons further verify the advantages of the algorithm in enhancing system stability and representing realistic decision-making behaviors.","authors":["Qianlei Jia","Xinliang Zhou","Ondrej Krejcar","Enrique Herrera-Viedma"],"url":"https://arxiv.org/abs/2505.16781"}
{"created":"2025-05-23","title":"Reasoning Beyond Language: A Comprehensive Survey on Latent Chain-of-Thought Reasoning","abstract":"Large Language Models (LLMs) have achieved impressive performance on complex reasoning tasks with Chain-of-Thought (CoT) prompting. However, conventional CoT relies on reasoning steps explicitly verbalized in natural language, introducing inefficiencies and limiting its applicability to abstract reasoning. To address this, there has been growing research interest in latent CoT reasoning, where inference occurs within latent spaces. By decoupling reasoning from language, latent reasoning promises richer cognitive representations and more flexible, faster inference. Researchers have explored various directions in this promising field, including training methodologies, structural innovations, and internal reasoning mechanisms. This paper presents a comprehensive overview and analysis of this reasoning paradigm. We begin by proposing a unified taxonomy from four perspectives: token-wise strategies, internal mechanisms, analysis, and applications. We then provide in-depth discussions and comparative analyses of representative methods, highlighting their design patterns, strengths, and open challenges. We aim to provide a structured foundation for advancing this emerging direction in LLM reasoning. The relevant papers will be regularly updated at https://github.com/EIT-NLP/Awesome-Latent-CoT.","authors":["Xinghao Chen","Anhao Zhao","Heming Xia","Xuan Lu","Hanlin Wang","Yanjun Chen","Wei Zhang","Jian Wang","Wenjie Li","Xiaoyu Shen"],"url":"https://arxiv.org/abs/2505.16782"}
{"created":"2025-05-23","title":"Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles","abstract":"In this paper, we present the runner-up solution for the Ego4D EgoSchema Challenge at CVPR 2025 (Confirmed on May 20, 2025). Inspired by the success of large models, we evaluate and leverage leading accessible multimodal large models and adapt them to video understanding tasks via few-shot learning and model ensemble strategies. Specifically, diversified prompt styles and process paradigms are systematically explored and evaluated to effectively guide the attention of large models, fully unleashing their powerful generalization and adaptability abilities. Experimental results demonstrate that, with our carefully designed approach, directly utilizing an individual multimodal model already outperforms the previous state-of-the-art (SOTA) method which includes several additional processes. Besides, an additional stage is further introduced that facilitates the cooperation and ensemble of periodic results, which achieves impressive performance improvements. We hope this work serves as a valuable reference for the practical application of large models and inspires future research in the field.","authors":["Jun Xie","Xiongjun Guan","Yingjian Zhu","Zhaoran Zhao","Xinming Wang","Feng Chen","Zhepeng Wang"],"url":"https://arxiv.org/abs/2505.16784"}
{"created":"2025-05-23","title":"CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models","abstract":"Despite providing superior performance, open-source large language models (LLMs) are vulnerable to abusive usage. To address this issue, recent works propose LLM fingerprinting methods to identify the specific source LLMs behind suspect applications. However, these methods fail to provide stealthy and robust fingerprint verification. In this paper, we propose a novel LLM fingerprinting scheme, namely CoTSRF, which utilizes the Chain of Thought (CoT) as the fingerprint of an LLM. CoTSRF first collects the responses from the source LLM by querying it with crafted CoT queries. Then, it applies contrastive learning to train a CoT extractor that extracts the CoT feature (i.e., fingerprint) from the responses. Finally, CoTSRF conducts fingerprint verification by comparing the Kullback-Leibler divergence between the CoT features of the source and suspect LLMs against an empirical threshold. Various experiments have been conducted to demonstrate the advantage of our proposed CoTSRF for fingerprinting LLMs, particularly in stealthy and robust fingerprint verification.","authors":["Zhenzhen Ren","GuoBiao Li","Sheng Li","Zhenxing Qian","Xinpeng Zhang"],"url":"https://arxiv.org/abs/2505.16785"}
{"created":"2025-05-23","title":"FlowMixer: A Constrained Neural Architecture for Interpretable Spatiotemporal Forecasting","abstract":"We introduce FlowMixer, a neural architecture that leverages constrained matrix operations to model structured spatiotemporal patterns. At its core, FlowMixer incorporates non-negative matrix mixing layers within a reversible mapping framework-applying transforms before mixing and their inverses afterward. This shape-preserving design enables a Kronecker-Koopman eigenmode framework that bridges statistical learning with dynamical systems theory, providing interpretable spatiotemporal patterns and facilitating direct algebraic manipulation of prediction horizons without retraining. Extensive experiments across diverse domains demonstrate FlowMixer's robust long-horizon forecasting capabilities while effectively modeling physical phenomena such as chaotic attractors and turbulent flows. These results suggest that architectural constraints can simultaneously enhance predictive performance and mathematical interpretability in neural forecasting systems.","authors":["Fares B. Mehouachi","Saif Eddin Jabari"],"url":"https://arxiv.org/abs/2505.16786"}
{"created":"2025-05-23","title":"Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce","abstract":"Model-based reinforcement learning (MBRL) offers an intuitive way to increase the sample efficiency of model-free RL methods by simultaneously training a world model that learns to predict the future. MBRL methods have progressed by largely prioritising the actor; optimising the world model learning has been neglected meanwhile. Improving the fidelity of the world model and reducing its time to convergence can yield significant downstream benefits, one of which is improving the ensuing performance of any actor it may train. We propose a novel approach that anticipates and actively seeks out high-entropy states using short-horizon latent predictions generated by the world model, offering a principled alternative to traditional curiosity-driven methods that chase once-novel states well after they were stumbled into. While many model predictive control (MPC) based methods offer similar alternatives, they typically lack commitment, synthesising multi step plans after every step. To mitigate this, we present a hierarchical planner that dynamically decides when to replan, planning horizon length, and the weighting between reward and entropy. While our method can theoretically be applied to any model that trains its own actors with solely model generated data, we have applied it to just Dreamer as a proof of concept. Our method finishes the Miniworld procedurally generated mazes 50% faster than base Dreamer at convergence and the policy trained in imagination converges in only 60% of the environment steps that base Dreamer needs.","authors":["Ashish Sundar","Chunbo Luo","Xiaoyang Wang"],"url":"https://arxiv.org/abs/2505.16787"}
{"created":"2025-05-23","title":"Accidental Misalignment: Fine-Tuning Language Models Induces Unexpected Vulnerability","abstract":"As large language models gain popularity, their vulnerability to adversarial attacks remains a primary concern. While fine-tuning models on domain-specific datasets is often employed to improve model performance, it can introduce vulnerabilities within the underlying model. In this work, we investigate Accidental Misalignment, unexpected vulnerabilities arising from characteristics of fine-tuning data. We begin by identifying potential correlation factors such as linguistic features, semantic similarity, and toxicity within our experimental datasets. We then evaluate the adversarial performance of these fine-tuned models and assess how dataset factors correlate with attack success rates. Lastly, we explore potential causal links, offering new insights into adversarial defense strategies and highlighting the crucial role of dataset design in preserving model alignment. Our code is available at https://github.com/psyonp/accidental_misalignment.","authors":["Punya Syon Pandey","Samuel Simko","Kellin Pelrine","Zhijing Jin"],"url":"https://arxiv.org/abs/2505.16789"}
{"created":"2025-05-23","title":"Learning Flexible Forward Trajectories for Masked Molecular Diffusion","abstract":"Masked diffusion models (MDMs) have achieved notable progress in modeling discrete data, while their potential in molecular generation remains underexplored. In this work, we explore their potential and introduce the surprising result that naively applying standards MDMs severely degrades the performance. We identify the critical cause of this issue as a state-clashing problem-where the forward diffusion of distinct molecules collapse into a common state, resulting in a mixture of reconstruction targets that cannot be learned using typical reverse diffusion process with unimodal predictions. To mitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that orchestrates per-element corruption trajectories to avoid collision between distinct molecular graphs. This is achieved through a parameterized noise scheduling network that assigns distinct corruption rates to individual graph elements, i.e., atoms and bonds. Extensive experiments on diverse molecular benchmarks reveal that MELD markedly enhances overall generation quality compared to element-agnostic noise scheduling, increasing the chemical validity of vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves state-of-the-art property alignment in conditional generation tasks.","authors":["Hyunjin Seo","Taewon Kim","Sihyun Yu","SungSoo Ahn"],"url":"https://arxiv.org/abs/2505.16790"}
{"created":"2025-05-23","title":"Cohort-Based Active Modality Acquisition","abstract":"Real-world machine learning applications often involve data from multiple modalities that must be integrated effectively to make robust predictions. However, in many practical settings, not all modalities are available for every sample, and acquiring additional modalities can be costly. This raises the question: which samples should be prioritized for additional modality acquisition when resources are limited? While prior work has explored individual-level acquisition strategies and training-time active learning paradigms, test-time and cohort-based acquisition remain underexplored despite their importance in many real-world settings. We introduce Cohort-based Active Modality Acquisition (CAMA), a novel test-time setting to formalize the challenge of selecting which samples should receive additional modalities. We derive acquisition strategies that leverage a combination of generative imputation and discriminative modeling to estimate the expected benefit of acquiring missing modalities based on common evaluation metrics. We also introduce upper-bound heuristics that provide performance ceilings to benchmark acquisition strategies. Experiments on common multimodal datasets demonstrate that our proposed imputation-based strategies can more effectively guide the acquisition of new samples in comparison to those relying solely on unimodal information, entropy guidance, and random selections. Our work provides an effective solution for optimizing modality acquisition at the cohort level, enabling better utilization of resources in constrained settings.","authors":["Tillmann Rheude","Roland Eils","Benjamin Wild"],"url":"https://arxiv.org/abs/2505.16791"}
{"created":"2025-05-23","title":"REPA Works Until It Doesn't: Early-Stopped, Holistic Alignment Supercharges Diffusion Training","abstract":"Diffusion Transformers (DiTs) deliver state-of-the-art image quality, yet their training remains notoriously slow. A recent remedy -- representation alignment (REPA) that matches DiT hidden features to those of a non-generative teacher (e.g. DINO) -- dramatically accelerates the early epochs but plateaus or even degrades performance later. We trace this failure to a capacity mismatch: once the generative student begins modelling the joint data distribution, the teacher's lower-dimensional embeddings and attention patterns become a straitjacket rather than a guide. We then introduce HASTE (Holistic Alignment with Stage-wise Termination for Efficient training), a two-phase schedule that keeps the help and drops the hindrance. Phase I applies a holistic alignment loss that simultaneously distills attention maps (relational priors) and feature projections (semantic anchors) from the teacher into mid-level layers of the DiT, yielding rapid convergence. Phase II then performs one-shot termination that deactivates the alignment loss, once a simple trigger such as a fixed iteration is hit, freeing the DiT to focus on denoising and exploit its generative capacity. HASTE speeds up training of diverse DiTs without architecture changes. On ImageNet 256X256, it reaches the vanilla SiT-XL/2 baseline FID in 50 epochs and matches REPA's best FID in 500 epochs, amounting to a 28X reduction in optimization steps. HASTE also improves text-to-image DiTs on MS-COCO, demonstrating to be a simple yet principled recipe for efficient diffusion training across various tasks. Our code is available at https://github.com/NUS-HPC-AI-Lab/HASTE .","authors":["Ziqiao Wang","Wangbo Zhao","Yuhao Zhou","Zekai Li","Zhiyuan Liang","Mingjia Shi","Xuanlei Zhao","Pengfei Zhou","Kaipeng Zhang","Zhangyang Wang","Kai Wang","Yang You"],"url":"https://arxiv.org/abs/2505.16792"}
{"created":"2025-05-23","title":"REOBench: Benchmarking Robustness of Earth Observation Foundation Models","abstract":"Earth observation foundation models have shown strong generalization across multiple Earth observation tasks, but their robustness under real-world perturbations remains underexplored. To bridge this gap, we introduce REOBench, the first comprehensive benchmark for evaluating the robustness of Earth observation foundation models across six tasks and twelve types of image corruptions, including both appearance-based and geometric perturbations. To ensure realistic and fine-grained evaluation, our benchmark focuses on high-resolution optical remote sensing images, which are widely used in critical applications such as urban planning and disaster response. We conduct a systematic evaluation of a broad range of models trained using masked image modeling, contrastive learning, and vision-language pre-training paradigms. Our results reveal that (1) existing Earth observation foundation models experience significant performance degradation when exposed to input corruptions. (2) The severity of degradation varies across tasks, model architectures, backbone sizes, and types of corruption, with performance drop varying from less than 1% to over 20%. (3) Vision-language models show enhanced robustness, particularly in multimodal tasks. REOBench underscores the vulnerability of current Earth observation foundation models to real-world corruptions and provides actionable insights for developing more robust and reliable models.","authors":["Xiang Li","Yong Tao","Siyuan Zhang","Siwei Liu","Zhitong Xiong","Chunbo Luo","Lu Liu","Mykola Pechenizkiy","Xiao Xiang Zhu","Tianjin Huang"],"url":"https://arxiv.org/abs/2505.16793"}
{"created":"2025-05-23","title":"V2V: Scaling Event-Based Vision through Efficient Video-to-Voxel Simulation","abstract":"Event-based cameras offer unique advantages such as high temporal resolution, high dynamic range, and low power consumption. However, the massive storage requirements and I/O burdens of existing synthetic data generation pipelines and the scarcity of real data prevent event-based training datasets from scaling up, limiting the development and generalization capabilities of event vision models. To address this challenge, we introduce Video-to-Voxel (V2V), an approach that directly converts conventional video frames into event-based voxel grid representations, bypassing the storage-intensive event stream generation entirely. V2V enables a 150 times reduction in storage requirements while supporting on-the-fly parameter randomization for enhanced model robustness. Leveraging this efficiency, we train several video reconstruction and optical flow estimation model architectures on 10,000 diverse videos totaling 52 hours--an order of magnitude larger than existing event datasets, yielding substantial improvements.","authors":["Hanyue Lou","Jinxiu Liang","Minggui Teng","Yi Wang","Boxin Shi"],"url":"https://arxiv.org/abs/2505.16797"}
{"created":"2025-05-23","title":"Learning Beyond Limits: Multitask Learning and Synthetic Data for Low-Resource Canonical Morpheme Segmentation","abstract":"We introduce a transformer-based morpheme segmentation system that augments a low-resource training signal through multitask learning and LLM-generated synthetic data. Our framework jointly predicts morphological segments and glosses from orthographic input, leveraging shared linguistic representations obtained through a common documentary process to enhance model generalization. To further address data scarcity, we integrate synthetic training data generated by large language models (LLMs) using in-context learning. Experimental results on the SIGMORPHON 2023 dataset show that our approach significantly improves word-level segmentation accuracy and morpheme-level F1-score across multiple low-resource languages.","authors":["Changbing Yang","Garrett Nicolai"],"url":"https://arxiv.org/abs/2505.16800"}
{"created":"2025-05-23","title":"A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents","abstract":"Serious Games (SGs) are nowadays shifting focus to include procedural content generation (PCG) in the development process as a means of offering personalized and enhanced player experience. However, the development of a framework to assess the impact of PCG techniques when integrated into SGs remains particularly challenging. This study proposes a methodology for automated evaluation of PCG integration in SGs, incorporating deep reinforcement learning (DRL) game testing agents. To validate the proposed framework, a previously introduced SG featuring card game mechanics and incorporating three different versions of PCG for nonplayer character (NPC) creation has been deployed. Version 1 features random NPC creation, while versions 2 and 3 utilize a genetic algorithm approach. These versions are used to test the impact of different dynamic SG environments on the proposed framework's agents. The obtained results highlight the superiority of the DRL game testing agents trained on Versions 2 and 3 over those trained on Version 1 in terms of win rate (i.e. number of wins per played games) and training time. More specifically, within the execution of a test emulating regular gameplay, both Versions 2 and 3 peaked at a 97% win rate and achieved statistically significant higher (p=0009) win rates compared to those achieved in Version 1 that peaked at 94%. Overall, results advocate towards the proposed framework's capability to produce meaningful data for the evaluation of procedurally generated content in SGs.","authors":["Eleftherios Kalafatis","Konstantinos Mitsis","Konstantia Zarkogianni","Maria Athanasiou","Konstantina Nikita"],"url":"https://arxiv.org/abs/2505.16801"}
{"created":"2025-05-23","title":"A Chase-based Approach to Consistent Answers of Analytic Queries in Star Schemas","abstract":"We present an approach to computing consistent answers to analytic queries in data warehouses operating under a star schema and possibly containing missing values and inconsistent data. Our approach is based on earlier work concerning consistent query answering for standard, non-analytic queries in multi-table databases. In that work we presented polynomial algorithms for computing either the exact consistent answer to a standard, non analytic query or bounds of the exact answer, depending on whether the query involves a selection condition or not.","authors":["Dominique Laurent","Nicolas Spyratos"],"url":"https://arxiv.org/abs/2505.16802"}
{"created":"2025-05-23","title":"SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving","abstract":"The integration of Vision-Language Models (VLMs) into autonomous driving systems has shown promise in addressing key challenges such as learning complexity, interpretability, and common-sense reasoning. However, existing approaches often struggle with efficient integration and realtime decision-making due to computational demands. In this paper, we introduce SOLVE, an innovative framework that synergizes VLMs with end-to-end (E2E) models to enhance autonomous vehicle planning. Our approach emphasizes knowledge sharing at the feature level through a shared visual encoder, enabling comprehensive interaction between VLM and E2E components. We propose a Trajectory Chain-of-Thought (T-CoT) paradigm, which progressively refines trajectory predictions, reducing uncertainty and improving accuracy. By employing a temporal decoupling strategy, SOLVE achieves efficient cooperation by aligning high-quality VLM outputs with E2E real-time performance. Evaluated on the nuScenes dataset, our method demonstrates significant improvements in trajectory prediction accuracy, paving the way for more robust and reliable autonomous driving systems.","authors":["Xuesong Chen","Linjiang Huang","Tao Ma","Rongyao Fang","Shaoshuai Shi","Hongsheng Li"],"url":"https://arxiv.org/abs/2505.16805"}
{"created":"2025-05-23","title":"Two-way Evidence self-Alignment based Dual-Gated Reasoning Enhancement","abstract":"Large language models (LLMs) encounter difficulties in knowledge-intensive multi-step reasoning (KIMSR) tasks. One challenge is how to effectively extract and represent rationale evidence. The current methods often extract semantically relevant but logically irrelevant evidence, resulting in flawed reasoning and inaccurate responses. We propose a two-way evidence self-alignment (TW-ESA) module, which utilizes the mutual alignment between strict reasoning and LLM reasoning to enhance its understanding of the causal logic of evidence, thereby addressing the first challenge. Another challenge is how to utilize the rationale evidence and LLM's intrinsic knowledge for accurate reasoning when the evidence contains uncertainty. We propose a dual-gated reasoning enhancement (DGR) module to gradually fuse useful knowledge of LLM within strict reasoning, which can enable the model to perform accurate reasoning by focusing on causal elements in the evidence and exhibit greater robustness. The two modules are collaboratively trained in a unified framework ESA-DGR. Extensive experiments on three diverse and challenging KIMSR datasets reveal that ESA-DGR significantly surpasses state-of-the-art LLM-based fine-tuning methods, with remarkable average improvements of 4% in exact match (EM) and 5% in F1 score. The implementation code is available at https://anonymous.4open.science/r/ESA-DGR-2BF8.","authors":["Kexin Zhang","Junlan Chen","Daifeng Li","Yuxuan Zhang","Yangyang Feng","Bowen Deng","Weixu Chen"],"url":"https://arxiv.org/abs/2505.16806"}
{"created":"2025-05-23","title":"Hypergraph Tversky-Aware Domain Incremental Learning for Brain Tumor Segmentation with Missing Modalities","abstract":"Existing methods for multimodal MRI segmentation with missing modalities typically assume that all MRI modalities are available during training. However, in clinical practice, some modalities may be missing due to the sequential nature of MRI acquisition, leading to performance degradation. Furthermore, retraining models to accommodate newly available modalities can be inefficient and may cause overfitting, potentially compromising previously learned knowledge. To address these challenges, we propose Replay-based Hypergraph Domain Incremental Learning (ReHyDIL) for brain tumor segmentation with missing modalities. ReHyDIL leverages Domain Incremental Learning (DIL) to enable the segmentation model to learn from newly acquired MRI modalities without forgetting previously learned information. To enhance segmentation performance across diverse patient scenarios, we introduce the Cross-Patient Hypergraph Segmentation Network (CHSNet), which utilizes hypergraphs to capture high-order associations between patients. Additionally, we incorporate Tversky-Aware Contrastive (TAC) loss to effectively mitigate information imbalance both across and within different modalities. Extensive experiments on the BraTS2019 dataset demonstrate that ReHyDIL outperforms state-of-the-art methods, achieving an improvement of over 2\\% in the Dice Similarity Coefficient across various tumor regions. Our code is available at ReHyDIL.","authors":["Junze Wang (College of Computer and Control Engineering","Northeast Forestry University","Harbin","China)","Lei Fan (The Centre for Healthy Brain Ageing","School of Computer Science and Engineering","University of New South Wales","Sydney","Australia)","Weipeng Jing (College of Computer and Control Engineering","Northeast Forestry University","Harbin","China)","Donglin Di (Space AI","Li Auto","Beijing","China)","Yang Song (School of Computer Science and Engineering","University of New South Wales","Sydney","Australia)","Sidong Liu (Centre for Health Informatics","Macquarie University","Sydney","Australia)","Cong Cong (Centre for Health Informatics","Macquarie University","Sydney","Australia)"],"url":"https://arxiv.org/abs/2505.16809"}
{"created":"2025-05-23","title":"DeepRec: Towards a Deep Dive Into the Item Space with Large Language Model Based Recommendation","abstract":"Recently, large language models (LLMs) have been introduced into recommender systems (RSs), either to enhance traditional recommendation models (TRMs) or serve as recommendation backbones. However, existing LLM-based RSs often do not fully exploit the complementary advantages of LLMs (e.g., world knowledge and reasoning) and TRMs (e.g., recommendation-specific knowledge and efficiency) to fully explore the item space. To address this, we propose DeepRec, a novel LLM-based RS that enables autonomous multi-turn interactions between LLMs and TRMs for deep exploration of the item space. In each interaction turn, LLMs reason over user preferences and interact with TRMs to retrieve candidate items. After multi-turn interactions, LLMs rank the retrieved items to generate the final recommendations. We adopt reinforcement learning(RL) based optimization and propose novel designs from three aspects: recommendation model based data rollout, recommendation-oriented hierarchical rewards, and a two-stage RL training strategy. For data rollout, we introduce a preference-aware TRM, with which LLMs interact to construct trajectory data. For rewards, we design a hierarchical reward function that involves both process-level and outcome-level rewards to optimize the interaction process and recommendation performance, respectively. For RL training, we develop a two-stage training strategy, where the first stage aims to guide LLMs to interact with TRMs and the second stage focuses on performance improvement. Experiments on public datasets demonstrate that DeepRec significantly outperforms both traditional and LLM-based baselines, offering a new paradigm for deep exploration in recommendation systems.","authors":["Bowen Zheng","Xiaolei Wang","Enze Liu","Xi Wang","Lu Hongyu","Yu Chen","Wayne Xin Zhao","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.16810"}
{"created":"2025-05-23","title":"Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining","abstract":"Significant progress has been made in video restoration under rainy conditions over the past decade, largely propelled by advancements in deep learning. Nevertheless, existing methods that depend on paired data struggle to generalize effectively to real-world scenarios, primarily due to the disparity between synthetic and authentic rain effects. To address these limitations, we propose a dual-branch spatio-temporal state-space model to enhance rain streak removal in video sequences. Specifically, we design spatial and temporal state-space model layers to extract spatial features and incorporate temporal dependencies across frames, respectively. To improve multi-frame feature fusion, we derive a dynamic stacking filter, which adaptively approximates statistical filters for superior pixel-wise feature refinement. Moreover, we develop a median stacking loss to enable semi-supervised learning by generating pseudo-clean patches based on the sparsity prior of rain. To further explore the capacity of deraining models in supporting other vision-based tasks in rainy environments, we introduce a novel real-world benchmark focused on object detection and tracking in rainy conditions. Our method is extensively evaluated across multiple benchmarks containing numerous synthetic and real-world rainy videos, consistently demonstrating its superiority in quantitative metrics, visual quality, efficiency, and its utility for downstream tasks.","authors":["Shangquan Sun","Wenqi Ren","Juxiang Zhou","Shu Wang","Jianhou Gan","Xiaochun Cao"],"url":"https://arxiv.org/abs/2505.16811"}
{"created":"2025-05-23","title":"Dynamic Reservoir Computing with Physical Neuromorphic Networks","abstract":"Reservoir Computing (RC) with physical systems requires an understanding of the underlying structure and internal dynamics of the specific physical reservoir. In this study, physical nano-electronic networks with neuromorphic dynamics are investigated for their use as physical reservoirs in an RC framework. These neuromorphic networks operate as dynamic reservoirs, with node activities in general coupled to the edge dynamics through nonlinear nano-electronic circuit elements, and the reservoir outputs influenced by the underlying network connectivity structure. This study finds that networks with varying degrees of sparsity generate more useful nonlinear temporal outputs for dynamic RC compared to dense networks. Dynamic RC is also tested on an autonomous multivariate chaotic time series prediction task with networks of varying densities, which revealed the importance of network sparsity in maintaining network activity and overall dynamics, that in turn enabled the learning of the chaotic Lorenz63 system's attractor behavior.","authors":["Yinhao Xu","Georg A. Gottwald","Zdenka Kuncic"],"url":"https://arxiv.org/abs/2505.16813"}
{"created":"2025-05-23","title":"Does Synthetic Data Help Named Entity Recognition for Low-Resource Languages?","abstract":"Named Entity Recognition(NER) for low-resource languages aims to produce robust systems for languages where there is limited labeled training data available, and has been an area of increasing interest within NLP. Data augmentation for increasing the amount of low-resource labeled data is a common practice. In this paper, we explore the role of synthetic data in the context of multilingual, low-resource NER, considering 11 languages from diverse language families. Our results suggest that synthetic data does in fact hold promise for low-resource language NER, though we see significant variation between languages.","authors":["Gaurav Kamath","Sowmya Vajjala"],"url":"https://arxiv.org/abs/2505.16814"}
{"created":"2025-05-23","title":"Perceptual Quality Assessment for Embodied AI","abstract":"Embodied AI has developed rapidly in recent years, but it is still mainly deployed in laboratories, with various distortions in the Real-world limiting its application. Traditionally, Image Quality Assessment (IQA) methods are applied to predict human preferences for distorted images; however, there is no IQA method to assess the usability of an image in embodied tasks, namely, the perceptual quality for robots. To provide accurate and reliable quality indicators for future embodied scenarios, we first propose the topic: IQA for Embodied AI. Specifically, we (1) based on the Mertonian system and meta-cognitive theory, constructed a perception-cognition-decision-execution pipeline and defined a comprehensive subjective score collection process; (2) established the Embodied-IQA database, containing over 36k reference/distorted image pairs, with more than 5m fine-grained annotations provided by Vision Language Models/Vision Language Action-models/Real-world robots; (3) trained and validated the performance of mainstream IQA methods on Embodied-IQA, demonstrating the need to develop more accurate quality indicators for Embodied AI. We sincerely hope that through evaluation, we can promote the application of Embodied AI under complex distortions in the Real-world. Project page: https://github.com/lcysyzxdxc/EmbodiedIQA","authors":["Chunyi Li","Jiaohao Xiao","Jianbo Zhang","Farong Wen","Zicheng Zhang","Yuan Tian","Xiangyang Zhu","Xiaohong Liu","Zhengxue Cheng","Weisi Lin","Guangtao Zhai"],"url":"https://arxiv.org/abs/2505.16815"}
{"created":"2025-05-23","title":"Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts","abstract":"Recent advances in scene-based video generation have enabled systems to synthesize coherent visual narratives from structured prompts. However, a crucial dimension of storytelling -- character-driven dialogue and speech -- remains underexplored. In this paper, we present a modular pipeline that transforms action-level prompts into visually and auditorily grounded narrative dialogue, enriching visual storytelling with natural voice and character expression. Our method takes as input a pair of prompts per scene, where the first defines the setting and the second specifies a character's behavior. While a story generation model such as Text2Story generates the corresponding visual scene, we focus on generating expressive character utterances from these prompts and the scene image. We apply a pretrained vision-language encoder to extract a high-level semantic feature from the representative frame, capturing salient visual context. This feature is then combined with the structured prompts and used to guide a large language model in synthesizing natural, character-consistent dialogue. To ensure contextual consistency across scenes, we introduce a Recursive Narrative Bank that conditions each dialogue generation on the accumulated dialogue history from prior scenes. This approach enables characters to speak in ways that reflect their evolving goals and interactions throughout a story. Finally, we render each utterance as expressive, character-consistent speech, resulting in fully-voiced video narratives. Our framework requires no additional training and demonstrates applicability across a variety of story settings, from fantasy adventures to slice-of-life episodes.","authors":["Taewon Kang","Ming C. Lin"],"url":"https://arxiv.org/abs/2505.16819"}
{"created":"2025-05-23","title":"LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols","abstract":"Integrating large AI models (LAMs) into 6G mobile networks promises to redefine protocol design and control-plane intelligence by enabling autonomous, cognitive network operations. While industry concepts, such as ETSI's Experiential Networked Intelligence (ENI), envision LAM-driven agents for adaptive network slicing and intent-based management, practical implementations still face challenges in protocol literacy and real-world deployment. This paper presents an end-to-end demonstration of a LAM that generates standards-compliant, ASN.1-encoded Radio Resource Control (RRC) messages as part of control-plane procedures inside a gNB. We treat RRC messaging as a domain-specific language and fine-tune a decoder-only transformer model (LLaMA class) using parameter-efficient Low-Rank Adaptation (LoRA) on RRC messages linearized to retain their ASN.1 syntactic structure before standard byte-pair encoding tokenization. This enables combinatorial generalization over RRC protocol states while minimizing training overhead. On 30k field-test request-response pairs, our 8 B model achieves a median cosine similarity of 0.97 with ground-truth messages on an edge GPU -- a 61 % relative gain over a zero-shot LLaMA-3 8B baseline -- indicating substantially improved structural and semantic RRC fidelity. Overall, our results show that LAMs, when augmented with Radio Access Network (RAN)-specific reasoning, can directly orchestrate control-plane procedures, representing a stepping stone toward the AI-native air-interface paradigm. Beyond RRC emulation, this work lays the groundwork for future AI-native wireless standards.","authors":["Ziming liu","Bryan Liu","Alvaro Valcarce","Xiaoli Chu"],"url":"https://arxiv.org/abs/2505.16821"}
{"created":"2025-05-23","title":"KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning","abstract":"Recent advances have demonstrated that integrating reinforcement learning with rule-based rewards can significantly enhance the reasoning capabilities of large language models, even without supervised fine-tuning. However, prevalent reinforcement learning algorithms such as GRPO and its variants like DAPO, suffer from a coarse granularity issue when computing the advantage. Specifically, they compute rollout-level advantages that assign identical values to every token within a sequence, failing to capture token-specific contributions and hindering effective learning. To address this limitation, we propose Key-token Advantage Estimation (KTAE) - a novel algorithm that estimates fine-grained, token-level advantages without introducing additional models. KTAE leverages the correctness of sampled rollouts and applies statistical analysis to quantify the importance of individual tokens within a sequence to the final outcome. This quantified token-level importance is then combined with the rollout-level advantage to obtain a more fine-grained token-level advantage estimation. Empirical results show that models trained with GRPO+KTAE and DAPO+KTAE outperform baseline methods across five mathematical reasoning benchmarks. Notably, they achieve higher accuracy with shorter responses and even surpass R1-Distill-Qwen-1.5B using the same base model.","authors":["Wei Sun","Wen Yang","Pu Jian","Qianlong Du","Fuwei Cui","Shuo Ren","Jiajun Zhang"],"url":"https://arxiv.org/abs/2505.16826"}
{"created":"2025-05-23","title":"GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent","abstract":"GUI automation faces critical challenges in dynamic environments. MLLMs suffer from two key issues: misinterpreting UI components and outdated knowledge. Traditional fine-tuning methods are costly for app-specific knowledge updates. We propose GUI-explorer, a training-free GUI agent that incorporates two fundamental mechanisms: (1) Autonomous Exploration of Function-aware Trajectory. To comprehensively cover all application functionalities, we design a Function-aware Task Goal Generator that automatically constructs exploration goals by analyzing GUI structural information (e.g., screenshots and activity hierarchies). This enables systematic exploration to collect diverse trajectories. (2) Unsupervised Mining of Transition-aware Knowledge. To establish precise screen-operation logic, we develop a Transition-aware Knowledge Extractor that extracts effective screen-operation logic through unsupervised analysis the state transition of structured interaction triples (observation, action, outcome). This eliminates the need for human involvement in knowledge extraction. With a task success rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows significant improvements over SOTA agents. It requires no parameter updates for new apps. GUI-explorer is open-sourced and publicly available at https://github.com/JiuTian-VL/GUI-explorer.","authors":["Bin Xie","Rui Shao","Gongwei Chen","Kaiwen Zhou","Yinchuan Li","Jie Liu","Min Zhang","Liqiang Nie"],"url":"https://arxiv.org/abs/2505.16827"}
{"created":"2025-05-23","title":"Rotatable Antenna Enabled Wireless Communication and Sensing: Opportunities and Challenges","abstract":"Non-fixed flexible antenna architectures, including fluid antenna systems (FAS) and movable antennas (MA), have attracted considerable interest in recent years. Rotatable antenna (RA) is an emerging technology that offers significant potential to enhance wireless communication and sensing performance by flexibly adjusting the boresight of directional antennas. Specifically, RA can flexibly reconfigure its boresight direction via mechanical or electronic means, thereby improving communication channel conditions and/or enhancing sensing resolution and range. In this article, we first provide an overview of RA, including its promising applications, hardware architectures, and radiation pattern characterization. We then illustrate how RA improves communication performance through interference mitigation, spatial multiplexing, and flexible beamforming, as well as enhances sensing capabilities in terms of coverage, resolution, and multi-target/dimensional sensing. Furthermore, we discuss key design challenges in RA systems, including rotational scanning scheduling, channel estimation/sensing, boresight optimization, and RA configuration. Finally, both experimental and simulation results are provided to validate the performance gains achieved by RA for both communication and sensing. Leveraging its unique capabilities in flexible antenna/array rotation to adapt to various communication/sensing requirements and channel conditions, RA is poised to become a key enabler of future intelligent, resilient, and agile wireless networks.","authors":["Beixiong Zheng","Tiantian Ma","Changsheng You","Jie Tang","Robert Schober","Rui Zhang"],"url":"https://arxiv.org/abs/2505.16828"}
{"created":"2025-05-23","title":"Contextual Learning for Stochastic Optimization","abstract":"Motivated by stochastic optimization, we introduce the problem of learning from samples of contextual value distributions. A contextual value distribution can be understood as a family of real-valued distributions, where each sample consists of a context $x$ and a random variable drawn from the corresponding real-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn an empirical distribution $D'_x$ for each context, ensuring a small L\\'evy distance to $D_x$. We apply this result to obtain the sample complexity bounds for the learning of an $\\epsilon$-optimal policy for stochastic optimization problems defined on an unknown contextual value distribution. The sample complexity is shown to be polynomial for the general case of strongly monotone and stable optimization problems, including Single-item Revenue Maximization, Pandora's Box and Optimal Stopping.","authors":["Anna Heuser","Thomas Kesselheim"],"url":"https://arxiv.org/abs/2505.16829"}
{"created":"2025-05-23","title":"Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs","abstract":"Unlearning in large language models (LLMs) is intended to remove the influence of specific data, yet current evaluations rely heavily on token-level metrics such as accuracy and perplexity. We show that these metrics can be misleading: models often appear to forget, but their original behavior can be rapidly restored with minimal fine-tuning, revealing that unlearning may obscure information rather than erase it. To diagnose this phenomenon, we introduce a representation-level evaluation framework using PCA-based similarity and shift, centered kernel alignment, and Fisher information. Applying this toolkit across six unlearning methods, three domains (text, code, math), and two open-source LLMs, we uncover a critical distinction between reversible and irreversible forgetting. In reversible cases, models suffer token-level collapse yet retain latent features; in irreversible cases, deeper representational damage occurs. We further provide a theoretical account linking shallow weight perturbations near output layers to misleading unlearning signals, and show that reversibility is modulated by task type and hyperparameters. Our findings reveal a fundamental gap in current evaluation practices and establish a new diagnostic foundation for trustworthy unlearning in LLMs. We provide a unified toolkit for analyzing LLM representation changes under unlearning and relearning: https://github.com/XiaoyuXU1/Representational_Analysis_Tools.git.","authors":["Xiaoyu Xu","Xiang Yue","Yang Liu","Qingqing Ye","Haibo Hu","Minxin Du"],"url":"https://arxiv.org/abs/2505.16831"}
{"created":"2025-05-23","title":"From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization","abstract":"While foundation models (FMs), such as diffusion models and large vision-language models (LVLMs), have been widely applied in educational contexts, their ability to generate pedagogically effective visual explanations remains limited. Most existing approaches focus primarily on textual reasoning, overlooking the critical role of structured and interpretable visualizations in supporting conceptual understanding. To better assess the visual reasoning capabilities of FMs in educational settings, we introduce EduVisBench, a multi-domain, multi-level benchmark. EduVisBench features diverse STEM problem sets requiring visually grounded solutions, along with a fine-grained evaluation rubric informed by pedagogical theory. Our empirical analysis reveals that existing models frequently struggle with the inherent challenge of decomposing complex reasoning and translating it into visual representations aligned with human cognitive processes. To address these limitations, we propose EduVisAgent, a multi-agent collaborative framework that coordinates specialized agents for instructional planning, reasoning decomposition, metacognitive prompting, and visualization design. Experimental results show that EduVisAgent substantially outperforms all baselines, achieving a 40.2% improvement and delivering more educationally aligned visualizations. EduVisBench and EduVisAgent are available at https://github.com/aiming-lab/EduVisBench and https://github.com/aiming-lab/EduVisAgent.","authors":["Haonian Ji","Shi Qiu","Siyang Xin","Siwei Han","Zhaorun Chen","Hongyi Wang","Dake Zhang","Huaxiu Yao"],"url":"https://arxiv.org/abs/2505.16832"}
{"created":"2025-05-23","title":"Strategically Linked Decisions in Long-Term Planning and Reinforcement Learning","abstract":"Long-term planning, as in reinforcement learning (RL), involves finding strategies: actions that collectively work toward a goal rather than individually optimizing their immediate outcomes. As part of a strategy, some actions are taken at the expense of short-term benefit to enable future actions with even greater returns. These actions are only advantageous if followed up by the actions they facilitate, consequently, they would not have been taken if those follow-ups were not available. In this paper, we quantify such dependencies between planned actions with strategic link scores: the drop in the likelihood of one decision under the constraint that a follow-up decision is no longer available. We demonstrate the utility of strategic link scores through three practical applications: (i) explaining black-box RL agents by identifying strategically linked pairs among decisions they make, (ii) improving the worst-case performance of decision support systems by distinguishing whether recommended actions can be adopted as standalone improvements or whether they are strategically linked hence requiring a commitment to a broader strategy to be effective, and (iii) characterizing the planning processes of non-RL agents purely through interventions aimed at measuring strategic link scores - as an example, we consider a realistic traffic simulator and analyze through road closures the effective planning horizon of the emergent routing behavior of many drivers.","authors":["Alihan H\\\"uy\\\"uk","Finale Doshi-Velez"],"url":"https://arxiv.org/abs/2505.16833"}
{"created":"2025-05-23","title":"SimpleDeepSearcher: Deep Information Seeking via Web-Powered Reasoning Trajectory Synthesis","abstract":"Retrieval-augmented generation (RAG) systems have advanced large language models (LLMs) in complex deep search scenarios requiring multi-step reasoning and iterative information retrieval. However, existing approaches face critical limitations that lack high-quality training trajectories or suffer from the distributional mismatches in simulated environments and prohibitive computational costs for real-world deployment. This paper introduces SimpleDeepSearcher, a lightweight yet effective framework that bridges this gap through strategic data engineering rather than complex training paradigms. Our approach synthesizes high-quality training data by simulating realistic user interactions in live web search environments, coupled with a multi-criteria curation strategy that optimizes the diversity and quality of input and output side. Experiments on five benchmarks across diverse domains demonstrate that SFT on only 871 curated samples yields significant improvements over RL-based baselines. Our work establishes SFT as a viable pathway by systematically addressing the data-scarce bottleneck, offering practical insights for efficient deep search systems. Our code is available at https://github.com/RUCAIBox/SimpleDeepSearcher.","authors":["Shuang Sun","Huatong Song","Yuhao Wang","Ruiyang Ren","Jinhao Jiang","Junjie Zhang","Fei Bai","Jia Deng","Wayne Xin Zhao","Zheng Liu","Lei Fang","Zhongyuan Wang","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.16834"}
{"created":"2025-05-23","title":"Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning","abstract":"The rapid spread of multimodal misinformation on social media has raised growing concerns, while research on video misinformation detection remains limited due to the lack of large-scale, diverse datasets. Existing methods often overfit to rigid templates and lack deep reasoning over deceptive content. To address these challenges, we introduce FakeVV, a large-scale benchmark comprising over 100,000 video-text pairs with fine-grained, interpretable annotations. In addition, we further propose Fact-R1, a novel framework that integrates deep reasoning with collaborative rule-based reinforcement learning. Fact-R1 is trained through a three-stage process: (1) misinformation long-Chain-of-Thought (CoT) instruction tuning, (2) preference alignment via Direct Preference Optimization (DPO), and (3) Group Relative Policy Optimization (GRPO) using a novel verifiable reward function. This enables Fact-R1 to exhibit emergent reasoning behaviors comparable to those observed in advanced text-based reinforcement learning systems, but in the more complex multimodal misinformation setting. Our work establishes a new paradigm for misinformation detection, bridging large-scale video understanding, reasoning-guided alignment, and interpretable verification.","authors":["Fanrui Zhang","Dian Li","Qiang Zhang","Chenjun","sinbadliu","Junxiong Lin","Jiahong Yan","Jiawei Liu","Zheng-Jun Zha"],"url":"https://arxiv.org/abs/2505.16836"}
{"created":"2025-05-23","title":"R1-Compress: Long Chain-of-Thought Compression via Chunk Compression and Search","abstract":"Chain-of-Thought (CoT) reasoning enhances large language models (LLMs) by enabling step-by-step problem-solving, yet its extension to Long-CoT introduces substantial computational overhead due to increased token length. Existing compression approaches -- instance-level and token-level -- either sacrifice essential local reasoning signals like reflection or yield incoherent outputs. To address these limitations, we propose R1-Compress, a two-stage chunk-level compression framework that preserves both local information and coherence. Our method segments Long-CoT into manageable chunks, applies LLM-driven inner-chunk compression, and employs an inter-chunk search mechanism to select the short and coherent sequence. Experiments on Qwen2.5-Instruct models across MATH500, AIME24, and GPQA-Diamond demonstrate that R1-Compress significantly reduces token usage while maintaining comparable reasoning accuracy. On MATH500, R1-Compress achieves an accuracy of 92.4%, with only a 0.6% drop compared to the Long-CoT baseline, while reducing token usage by about 20%. Source code will be available at https://github.com/w-yibo/R1-Compress","authors":["Yibo Wang","Li Shen","Huanjin Yao","Tiansheng Huang","Rui Liu","Naiqiang Tan","Jiaxing Huang","Kai Zhang","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.16838"}
{"created":"2025-05-23","title":"LaViDa: A Large Diffusion Language Model for Multimodal Understanding","abstract":"Modern Vision-Language Models (VLMs) can solve a wide range of tasks requiring visual reasoning. In real-world scenarios, desirable properties for VLMs include fast inference and controllable generation (e.g., constraining outputs to adhere to a desired format). However, existing autoregressive (AR) VLMs like LLaVA struggle in these aspects. Discrete diffusion models (DMs) offer a promising alternative, enabling parallel decoding for faster inference and bidirectional context for controllable generation through text-infilling. While effective in language-only settings, DMs' potential for multimodal tasks is underexplored. We introduce LaViDa, a family of VLMs built on DMs. We build LaViDa by equipping DMs with a vision encoder and jointly fine-tune the combined parts for multimodal instruction following. To address challenges encountered, LaViDa incorporates novel techniques such as complementary masking for effective training, prefix KV cache for efficient inference, and timestep shifting for high-quality sampling. Experiments show that LaViDa achieves competitive or superior performance to AR VLMs on multi-modal benchmarks such as MMMU, while offering unique advantages of DMs, including flexible speed-quality tradeoff, controllability, and bidirectional reasoning. On COCO captioning, LaViDa surpasses Open-LLaVa-Next-8B by +4.1 CIDEr with 1.92x speedup. On bidirectional tasks, it achieves +59% improvement on Constrained Poem Completion. These results demonstrate LaViDa as a strong alternative to AR VLMs. Code and models will be released in the camera-ready version.","authors":["Shufan Li","Konstantinos Kallidromitis","Hritik Bansal","Akash Gokul","Yusuke Kato","Kazuki Kozuka","Jason Kuen","Zhe Lin","Kai-Wei Chang","Aditya Grover"],"url":"https://arxiv.org/abs/2505.16839"}
{"created":"2025-05-23","title":"Number theory combination: natural density and SMT","abstract":"The study of theory combination in Satisfiability Modulo Theories (SMT) involves various model theoretic properties (e.g., stable infiniteness, smoothness, etc.). We show that such properties can be partly captured by the natural density of the spectrum of the studied theories, which is the set of sizes of their finite models. This enriches the toolbox of the theory combination researcher, by providing new tools to determine the possibility of combining theories. It also reveals interesting and surprising connections between theory combination and number theory.","authors":["Guilherme V. Toledo","Yoni Zohar"],"url":"https://arxiv.org/abs/2505.16840"}
{"created":"2025-05-23","title":"On the Deployment of RIS-mounted UAV Networks","abstract":"Reconfigurable intelligent surfaces (RIS) enable smart wireless environments by dynamically controlling signal propagation to enhance communication and localization. Unmanned aerial vehicles (UAVs) can act as flying base stations and thus, improve system performance by avoiding signal blockages. In this paper, we propose a gradient ascent and coordinate search based method to determine the optimal location for a system that consists of a UAV and a RIS, where the UAV serves cellular users (CUs) and the RIS serves device-to-device (D2D) pairs. In particular, by optimizing the net throughput for both the D2D pairs and the CUs, the suggested method establishes the ideal location for the RIS-mounted UAV. We consider both line of sight (LoS) and non-LoS paths for the RIS and UAV to calculate the throughput while accounting for blockages in the system. The numerical results show that the proposed method performs better than the existing approaches in terms of both the net throughput and the user fairness.","authors":["Anupam Mondal","Priyadarshi Mukherjee","Sasthi C. Ghosh"],"url":"https://arxiv.org/abs/2505.16841"}
{"created":"2025-05-23","title":"Understanding and Analyzing Inappropriately Targeting Language in Online Discourse: A Comparative Annotation Study","abstract":"This paper introduces a method for detecting inappropriately targeting language in online conversations by integrating crowd and expert annotations with ChatGPT. We focus on English conversation threads from Reddit, examining comments that target individuals or groups. Our approach involves a comprehensive annotation framework that labels a diverse data set for various target categories and specific target words within the conversational context. We perform a comparative analysis of annotations from human experts, crowd annotators, and ChatGPT, revealing strengths and limitations of each method in recognizing both explicit hate speech and subtler discriminatory language. Our findings highlight the significant role of contextual factors in identifying hate speech and uncover new categories of targeting, such as social belief and body image. We also address the challenges and subjective judgments involved in annotation and the limitations of ChatGPT in grasping nuanced language. This study provides insights for improving automated content moderation strategies to enhance online safety and inclusivity.","authors":["Baran Barbarestani","Isa Maks","Piek Vossen"],"url":"https://arxiv.org/abs/2505.16847"}
{"created":"2025-05-23","title":"Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks","abstract":"Large Language Models (LLMs) have showcased impressive reasoning abilities, but often suffer from hallucinations or outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by grounding LLM responses in structured external information from a knowledge base. However, many KG-based RAG approaches struggle with (i) aligning KG and textual representations, (ii) balancing retrieval accuracy and efficiency, and (iii) adapting to dynamically updated KGs. In this work, we introduce Walk&amp;Retrieve, a simple yet effective KG-based framework that leverages walk-based graph traversal and knowledge verbalization for corpus generation for zero-shot RAG. Built around efficient KG walks, our method does not require fine-tuning on domain-specific data, enabling seamless adaptation to KG updates, reducing computational overhead, and allowing integration with any off-the-shelf backbone LLM. Despite its simplicity, Walk&amp;Retrieve performs competitively, often outperforming existing RAG systems in response accuracy and hallucination reduction. Moreover, it demonstrates lower query latency and robust scalability to large KGs, highlighting the potential of lightweight retrieval strategies as strong baselines for future RAG research.","authors":["Martin B\\\"ockling","Heiko Paulheim","Andreea Iana"],"url":"https://arxiv.org/abs/2505.16849"}
{"created":"2025-05-23","title":"ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning","abstract":"Federated Learning (FL) has emerged as a promising paradigm for collaborative model training while preserving data privacy across decentralized participants. As FL adoption grows, numerous techniques have been proposed to tackle its practical challenges. However, the lack of standardized evaluation across key dimensions hampers systematic progress and fair comparison of FL methods. In this work, we introduce ATR-Bench, a unified framework for analyzing federated learning through three foundational dimensions: Adaptation, Trust, and Reasoning. We provide an in-depth examination of the conceptual foundations, task formulations, and open research challenges associated with each theme. We have extensively benchmarked representative methods and datasets for adaptation to heterogeneous clients and trustworthiness in adversarial or unreliable environments. Due to the lack of reliable metrics and models for reasoning in FL, we only provide literature-driven insights for this dimension. ATR-Bench lays the groundwork for a systematic and holistic evaluation of federated learning with real-world relevance. We will make our complete codebase publicly accessible and a curated repository that continuously tracks new developments and research in the FL literature.","authors":["Tajamul Ashraf","Mohammed Mohsen Peerzada","Moloud Abdar","Yutong Xie","Yuyin Zhou","Xiaofeng Liu","Iqra Altaf Gillani","Janibul Bashir"],"url":"https://arxiv.org/abs/2505.16850"}
{"created":"2025-05-23","title":"Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models","abstract":"Reinforcement Learning (RL) has proven to be an effective post-training strategy for enhancing reasoning in vision-language models (VLMs). Group Relative Policy Optimization (GRPO) is a recent prominent method that encourages models to generate complete reasoning traces before answering, leading to increased token usage and computational cost. Inspired by the human-like thinking process-where people skip reasoning for easy questions but think carefully when needed-we explore how to enable VLMs to first decide when reasoning is necessary. To realize this, we propose TON, a two-stage training strategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective 'thought dropout' operation, where reasoning traces are randomly replaced with empty thoughts. This introduces a think-or-not format that serves as a cold start for selective reasoning; (ii) a GRPO stage that enables the model to freely explore when to think or not, while maximizing task-aware outcome rewards. Experimental results show that TON can reduce the completion length by up to 90% compared to vanilla GRPO, without sacrificing performance or even improving it. Further evaluations across diverse vision-language tasks-covering a range of reasoning difficulties under both 3B and 7B models-consistently reveal that the model progressively learns to bypass unnecessary reasoning steps as training advances. These findings shed light on the path toward human-like reasoning patterns in reinforcement learning approaches. Our code is available at https://github.com/kokolerk/TON.","authors":["Jiaqi Wang","Kevin Qinghong Lin","James Cheng","Mike Zheng Shou"],"url":"https://arxiv.org/abs/2505.16854"}
{"created":"2025-05-23","title":"Nested Named Entity Recognition as Single-Pass Sequence Labeling","abstract":"We cast nested named entity recognition (NNER) as a sequence labeling task by leveraging prior work that linearizes constituency structures, effectively reducing the complexity of this structured prediction problem to straightforward token classification. By combining these constituency linearizations with pretrained encoders, our method captures nested entities while performing exactly $n$ tagging actions. Our approach achieves competitive performance compared to less efficient systems, and it can be trained using any off-the-shelf sequence labeling library.","authors":["Alberto Mu\\~noz-Ortiz","David Vilares","Caio COrro","Carlos G\\'omez-Rodr\\'iguez"],"url":"https://arxiv.org/abs/2505.16855"}
{"created":"2025-05-23","title":"Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only","abstract":"Improving the performance of pre-trained policies through online reinforcement learning (RL) is a critical yet challenging topic. Existing online RL fine-tuning methods require continued training with offline pretrained Q-functions for stability and performance. However, these offline pretrained Q-functions commonly underestimate state-action pairs beyond the offline dataset due to the conservatism in most offline RL methods, which hinders further exploration when transitioning from the offline to the online setting. Additionally, this requirement limits their applicability in scenarios where only pre-trained policies are available but pre-trained Q-functions are absent, such as in imitation learning (IL) pre-training. To address these challenges, we propose a method for efficient online RL fine-tuning using solely the offline pre-trained policy, eliminating reliance on pre-trained Q-functions. We introduce PORL (Policy-Only Reinforcement Learning Fine-Tuning), which rapidly initializes the Q-function from scratch during the online phase to avoid detrimental pessimism. Our method not only achieves competitive performance with advanced offline-to-online RL algorithms and online RL approaches that leverage data or policies prior, but also pioneers a new path for directly fine-tuning behavior cloning (BC) policies.","authors":["Wei Xiao","Jiacheng Liu","Zifeng Zhuang","Runze Suo","Shangke Lyu","Donglin Wang"],"url":"https://arxiv.org/abs/2505.16856"}
{"created":"2025-05-23","title":"Redefining Clustered Federated Learning for System Identification: The Path of ClusterCraft","abstract":"This paper addresses the System Identification (SYSID) problem within the framework of federated learning. We introduce a novel algorithm, Incremental Clustering-based federated learning method for SYSID (IC-SYSID), designed to tackle SYSID challenges across multiple data sources without prior knowledge. IC-SYSID utilizes an incremental clustering method, ClusterCraft (CC), to eliminate the dependency on the prior knowledge of the dataset. CC starts with a single cluster model and assigns similar local workers to the same clusters by dynamically increasing the number of clusters. To reduce the number of clusters generated by CC, we introduce ClusterMerge, where similar cluster models are merged. We also introduce enhanced ClusterCraft to reduce the generation of similar cluster models during the training. Moreover, IC-SYSID addresses cluster model instability by integrating a regularization term into the loss function and initializing cluster models with scaled Glorot initialization. It also utilizes a mini-batch deep learning approach to manage large SYSID datasets during local training. Through the experiments conducted on a real-world representing SYSID problem, where a fleet of vehicles collaboratively learns vehicle dynamics, we show that IC-SYSID achieves a high SYSID performance while preventing the learning of unstable clusters.","authors":["Ertu\\u{g}rul Ke\\c{c}eci","M\\\"ujde G\\\"uzelkaya","Tufan Kumbasar"],"url":"https://arxiv.org/abs/2505.16857"}
{"created":"2025-05-23","title":"GCAL: Adapting Graph Models to Evolving Domain Shifts","abstract":"This paper addresses the challenge of graph domain adaptation on evolving, multiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation methods are confined to single-step adaptation, making them ineffective in handling continuous domain shifts and prone to catastrophic forgetting. This paper introduces the Graph Continual Adaptive Learning (GCAL) method, designed to enhance model sustainability and adaptability across various graph domains. GCAL employs a bilevel optimization strategy. The \"adapt\" phase uses an information maximization approach to fine-tune the model with new graph domains while re-adapting past memories to mitigate forgetting. Concurrently, the \"generate memory\" phase, guided by a theoretical lower bound derived from information bottleneck theory, involves a variational memory graph generation module to condense original graphs into memories. Extensive experimental evaluations demonstrate that GCAL substantially outperforms existing methods in terms of adaptability and knowledge retention.","authors":["Ziyue Qiao","Qianyi Cai","Hao Dong","Jiawei Gu","Pengyang Wang","Meng Xiao","Xiao Luo","Hui Xiong"],"url":"https://arxiv.org/abs/2505.16860"}
{"created":"2025-05-23","title":"Conditional Panoramic Image Generation via Masked Autoregressive Modeling","abstract":"Recent progress in panoramic image generation has underscored two critical limitations in existing approaches. First, most methods are built upon diffusion models, which are inherently ill-suited for equirectangular projection (ERP) panoramas due to the violation of the identically and independently distributed (i.i.d.) Gaussian noise assumption caused by their spherical mapping. Second, these methods often treat text-conditioned generation (text-to-panorama) and image-conditioned generation (panorama outpainting) as separate tasks, relying on distinct architectures and task-specific data. In this work, we propose a unified framework, Panoramic AutoRegressive model (PAR), which leverages masked autoregressive modeling to address these challenges. PAR avoids the i.i.d. assumption constraint and integrates text and image conditioning into a cohesive architecture, enabling seamless generation across tasks. To address the inherent discontinuity in existing generative models, we introduce circular padding to enhance spatial coherence and propose a consistency alignment strategy to improve generation quality. Extensive experiments demonstrate competitive performance in text-to-image generation and panorama outpainting tasks while showcasing promising scalability and generalization capabilities.","authors":["Chaoyang Wang","Xiangtai Li","Lu Qi","Xiaofan Lin","Jinbin Bai","Qianyu Zhou","Yunhai Tong"],"url":"https://arxiv.org/abs/2505.16862"}
{"created":"2025-05-23","title":"Training-Free Efficient Video Generation via Dynamic Token Carving","abstract":"Despite the remarkable generation quality of video Diffusion Transformer (DiT) models, their practical deployment is severely hindered by extensive computational requirements. This inefficiency stems from two key challenges: the quadratic complexity of self-attention with respect to token length and the multi-step nature of diffusion models. To address these limitations, we present Jenga, a novel inference pipeline that combines dynamic attention carving with progressive resolution generation. Our approach leverages two key insights: (1) early denoising steps do not require high-resolution latents, and (2) later steps do not require dense attention. Jenga introduces a block-wise attention mechanism that dynamically selects relevant token interactions using 3D space-filling curves, alongside a progressive resolution strategy that gradually increases latent resolution during generation. Experimental results demonstrate that Jenga achieves substantial speedups across multiple state-of-the-art video diffusion models while maintaining comparable generation quality (8.83$\\times$ speedup with 0.01\\% performance drop on VBench). As a plug-and-play solution, Jenga enables practical, high-quality video generation on modern hardware by reducing inference time from minutes to seconds -- without requiring model retraining. Code: https://github.com/dvlab-research/Jenga","authors":["Yuechen Zhang","Jinbo Xing","Bin Xia","Shaoteng Liu","Bohao Peng","Xin Tao","Pengfei Wan","Eric Lo","Jiaya Jia"],"url":"https://arxiv.org/abs/2505.16864"}
{"created":"2025-05-23","title":"LARES: Latent Reasoning for Sequential Recommendation","abstract":"Sequential recommender systems have become increasingly important in real-world applications that model user behavior sequences to predict their preferences. However, existing sequential recommendation methods predominantly rely on non-reasoning paradigms, which may limit the model's computational capacity and result in suboptimal recommendation performance. To address these limitations, we present LARES, a novel and scalable LAtent REasoning framework for Sequential recommendation that enhances model's representation capabilities through increasing the computation density of parameters by depth-recurrent latent reasoning. Our proposed approach employs a recurrent architecture that allows flexible expansion of reasoning depth without increasing parameter complexity, thereby effectively capturing dynamic and intricate user interest patterns. A key difference of LARES lies in refining all input tokens at each implicit reasoning step to improve the computation utilization. To fully unlock the model's reasoning potential, we design a two-phase training strategy: (1) Self-supervised pre-training (SPT) with dual alignment objectives; (2) Reinforcement post-training (RPT). During the first phase, we introduce trajectory-level alignment and step-level alignment objectives, which enable the model to learn recommendation-oriented latent reasoning patterns without requiring supplementary annotated data. The subsequent phase utilizes reinforcement learning (RL) to harness the model's exploratory ability, further refining its reasoning capabilities. Comprehensive experiments on real-world benchmarks demonstrate our framework's superior performance. Notably, LARES exhibits seamless compatibility with existing advanced models, further improving their recommendation performance.","authors":["Enze Liu","Bowen Zheng","Xiaolei Wang","Wayne Xin Zhao","Jinpeng Wang","Sheng Chen","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.16865"}
{"created":"2025-05-23","title":"Comparative analysis of subword tokenization approaches for Indian languages","abstract":"Tokenization is the act of breaking down text into smaller parts, or tokens, that are easier for machines to process. This is a key phase in machine translation (MT) models. Subword tokenization enhances this process by breaking down words into smaller subword units, which is especially beneficial in languages with complicated morphology or a vast vocabulary. It is useful in capturing the intricate structure of words in Indian languages (ILs), such as prefixes, suffixes, and other morphological variations. These languages frequently use agglutinative structures, in which words are formed by the combination of multiple morphemes such as suffixes, prefixes, and stems. As a result, a suitable tokenization strategy must be chosen to address these scenarios. This paper examines how different subword tokenization techniques, such as SentencePiece, Byte Pair Encoding (BPE), and WordPiece Tokenization, affect ILs. The effectiveness of these subword tokenization techniques is investigated in statistical, neural, and multilingual neural machine translation models. All models are examined using standard evaluation metrics, such as the Bilingual Evaluation Understudy (BLEU) score, TER, METEOR, CHRF, RIBES, and COMET. Based on the results, it appears that for the majority of language pairs for the Statistical and Neural MT models, the SentencePiece tokenizer continuously performed better than other tokenizers in terms of BLEU score. However, BPE tokenization outperformed other tokenization techniques in the context of Multilingual Neural Machine Translation model. The results show that, despite using the same tokenizer and dataset for each model, translations from ILs to English surpassed translations from English to ILs.","authors":["Sudhansu Bala Das","Samujjal Choudhury","Tapas Kumar Mishra","Bidyut Kr. Patra"],"url":"https://arxiv.org/abs/2505.16868"}
{"created":"2025-05-23","title":"MPO: Multilingual Safety Alignment via Reward Gap Optimization","abstract":"Large language models (LLMs) have become increasingly central to AI applications worldwide, necessitating robust multilingual safety alignment to ensure secure deployment across diverse linguistic contexts. Existing preference learning methods for safety alignment, such as RLHF and DPO, are primarily monolingual and struggle with noisy multilingual data. To address these limitations, we introduce Multilingual reward gaP Optimization (MPO), a novel approach that leverages the well-aligned safety capabilities of the dominant language (English) to improve safety alignment across multiple languages. MPO directly minimizes the reward gap difference between the dominant language and target languages, effectively transferring safety capabilities while preserving the original strengths of the dominant language. Extensive experiments on three LLMs, LLaMA-3.1, Gemma-2 and Qwen2.5, validate MPO's efficacy in multilingual safety alignment without degrading general multilingual utility.","authors":["Weixiang Zhao","Yulin Hu","Yang Deng","Tongtong Wu","Wenxuan Zhang","Jiahe Guo","An Zhang","Yanyan Zhao","Bing Qin","Tat-Seng Chua","Ting Liu"],"url":"https://arxiv.org/abs/2505.16869"}
{"created":"2025-05-23","title":"A Multi-Step Comparative Framework for Anomaly Detection in IoT Data Streams","abstract":"The rapid expansion of Internet of Things (IoT) devices has introduced critical security challenges, underscoring the need for accurate anomaly detection. Although numerous studies have proposed machine learning (ML) methods for this purpose, limited research systematically examines how different preprocessing steps--normalization, transformation, and feature selection--interact with distinct model architectures. To address this gap, this paper presents a multi-step evaluation framework assessing the combined impact of preprocessing choices on three ML algorithms: RNN-LSTM, autoencoder neural networks (ANN), and Gradient Boosting (GBoosting). Experiments on the IoTID20 dataset shows that GBoosting consistently delivers superior accuracy across preprocessing configurations, while RNN-LSTM shows notable gains with z-score normalization and autoencoders excel in recall, making them well-suited for unsupervised scenarios. By offering a structured analysis of preprocessing decisions and their interplay with various ML techniques, the proposed framework provides actionable guidance to enhance anomaly detection performance in IoT environments.","authors":["Mohammed Al-Qudah","Fadi AlMahamid"],"url":"https://arxiv.org/abs/2505.16872"}
{"created":"2025-05-23","title":"T2I-ConBench: Text-to-Image Benchmark for Continual Post-training","abstract":"Continual post-training adapts a single text-to-image diffusion model to learn new tasks without incurring the cost of separate models, but naive post-training causes forgetting of pretrained knowledge and undermines zero-shot compositionality. We observe that the absence of a standardized evaluation protocol hampers related research for continual post-training. To address this, we introduce T2I-ConBench, a unified benchmark for continual post-training of text-to-image models. T2I-ConBench focuses on two practical scenarios, item customization and domain enhancement, and analyzes four dimensions: (1) retention of generality, (2) target-task performance, (3) catastrophic forgetting, and (4) cross-task generalization. It combines automated metrics, human-preference modeling, and vision-language QA for comprehensive assessment. We benchmark ten representative methods across three realistic task sequences and find that no approach excels on all fronts. Even joint \"oracle\" training does not succeed for every task, and cross-task generalization remains unsolved. We release all datasets, code, and evaluation tools to accelerate research in continual post-training for text-to-image models.","authors":["Zhehao Huang","Yuhang Liu","Yixin Lou","Zhengbao He","Mingzhen He","Wenxing Zhou","Tao Li","Kehan Li","Zeyi Huang","Xiaolin Huang"],"url":"https://arxiv.org/abs/2505.16875"}
{"created":"2025-05-23","title":"Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings","abstract":"Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is crucial for ensuring the reliability of downstream applications. A recent work applies conformal prediction to KGE methods, providing uncertainty estimates by generating a set of answers that is guaranteed to include the true answer with a predefined confidence level. However, existing methods provide probabilistic guarantees averaged over a reference set of queries and answers (marginal coverage guarantee). In high-stakes applications such as medical diagnosis, a stronger guarantee is often required: the predicted sets must provide consistent coverage per query (conditional coverage guarantee). We propose CondKGCP, a novel method that approximates predicate-conditional coverage guarantees while maintaining compact prediction sets. CondKGCP merges predicates with similar vector representations and augments calibration with rank information. We prove the theoretical guarantees and demonstrate empirical effectiveness of CondKGCP by comprehensive evaluations.","authors":["Yuqicheng Zhu","Daniel Hern\\'andez","Yuan He","Zifeng Ding","Bo Xiong","Evgeny Kharlamov","Steffen Staab"],"url":"https://arxiv.org/abs/2505.16877"}
{"created":"2025-05-23","title":"CASTILLO: Characterizing Response Length Distributions of Large Language Models","abstract":"Efficiently managing compute resources for Large Language Model (LLM) inference remains challenging due to the inherently stochastic and variable lengths of autoregressive text generation. Accurately estimating response lengths in advance enables proactive resource allocation, yet existing approaches either bias text generation towards certain lengths or rely on assumptions that ignore model- and prompt-specific variability. We introduce CASTILLO, a dataset characterizing response length distributions across 13 widely-used open-source LLMs evaluated on seven distinct instruction-following corpora. For each $\\langle$prompt, model$\\rangle$ sample pair, we generate 10 independent completions using fixed decoding hyper-parameters, record the token length of each response, and publish summary statistics (mean, std-dev, percentiles), along with the shortest and longest completions, and the exact generation settings. Our analysis reveals significant inter- and intra-model variability in response lengths (even under identical generation settings), as well as model-specific behaviors and occurrences of partial text degeneration in only subsets of responses. CASTILLO enables the development of predictive models for proactive scheduling and provides a systematic framework for analyzing model-specific generation behaviors. We publicly release the dataset and code to foster research at the intersection of generative language modeling and systems.","authors":["Daniel F. Perez-Ramirez","Dejan Kostic","Magnus Boman"],"url":"https://arxiv.org/abs/2505.16881"}
{"created":"2025-05-23","title":"Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga)","abstract":"Ethological research increasingly benefits from the growing affordability and accessibility of drones, which enable the capture of high-resolution footage of animal movement at fine spatial and temporal scales. However, analyzing such footage presents the technical challenge of separating animal movement from drone motion. While non-trivial, computer vision techniques such as image registration and Structure-from-Motion (SfM) offer practical solutions. For conservationists, open-source tools that are user-friendly, require minimal setup, and deliver timely results are especially valuable for efficient data interpretation. This study evaluates three approaches: a bioimaging-based registration technique, an SfM pipeline, and a hybrid interpolation method. We apply these to a recorded escape event involving 44 plains zebras, captured in a single drone video. Using the best-performing method, we extract individual trajectories and identify key behavioral patterns: increased alignment (polarization) during escape, a brief widening of spacing just before stopping, and tighter coordination near the group's center. These insights highlight the method's effectiveness and its potential to scale to larger datasets, contributing to broader investigations of collective animal behavior.","authors":["Isla Duporge","Sofia Minano","Nikoloz Sirmpilatze","Igor Tatarnikov","Scott Wolf","Adam L. Tyson","Daniel Rubenstein"],"url":"https://arxiv.org/abs/2505.16882"}
{"created":"2025-05-23","title":"Don't \"Overthink\" Passage Reranking: Is Reasoning Truly Necessary?","abstract":"With the growing success of reasoning models across complex natural language tasks, researchers in the Information Retrieval (IR) community have begun exploring how similar reasoning capabilities can be integrated into passage rerankers built on Large Language Models (LLMs). These methods typically employ an LLM to produce an explicit, step-by-step reasoning process before arriving at a final relevance prediction. But, does reasoning actually improve reranking accuracy? In this paper, we dive deeper into this question, studying the impact of the reasoning process by comparing reasoning-based pointwise rerankers (ReasonRR) to standard, non-reasoning pointwise rerankers (StandardRR) under identical training conditions, and observe that StandardRR generally outperforms ReasonRR. Building on this observation, we then study the importance of reasoning to ReasonRR by disabling its reasoning process (ReasonRR-NoReason), and find that ReasonRR-NoReason is surprisingly more effective than ReasonRR. Examining the cause of this result, our findings reveal that reasoning-based rerankers are limited by the LLM's reasoning process, which pushes it toward polarized relevance scores and thus fails to consider the partial relevance of passages, a key factor for the accuracy of pointwise rerankers.","authors":["Nour Jedidi","Yung-Sung Chuang","James Glass","Jimmy Lin"],"url":"https://arxiv.org/abs/2505.16886"}
{"created":"2025-05-23","title":"CAIN: Hijacking LLM-Humans Conversations via a Two-Stage Malicious System Prompt Generation and Refining Framework","abstract":"Large language models (LLMs) have advanced many applications, but are also known to be vulnerable to adversarial attacks. In this work, we introduce a novel security threat: hijacking AI-human conversations by manipulating LLMs' system prompts to produce malicious answers only to specific targeted questions (e.g., \"Who should I vote for US President?\", \"Are Covid vaccines safe?\"), while behaving benignly on others. This attack is detrimental as it can enable malicious actors to exercise large-scale information manipulation by spreading harmful but benign-looking system prompts online. To demonstrate such an attack, we develop CAIN, an algorithm that can automatically curate such harmful system prompts for a specific target question in a black-box setting or without the need to access the LLM's parameters. Evaluated on both open-source and commercial LLMs, CAIN demonstrates significant adversarial impact. In untargeted attacks or forcing LLMs to output incorrect answers, CAIN achieves up to 40% F1 degradation on targeted questions while preserving high accuracy on benign inputs. For targeted attacks or forcing LLMs to output specific harmful answers, CAIN achieves over 70% F1 scores on these targeted responses with minimal impact on benign questions. Our results highlight the critical need for enhanced robustness measures to safeguard the integrity and safety of LLMs in real-world applications. All source code will be publicly available.","authors":["Viet Pham","Thai Le"],"url":"https://arxiv.org/abs/2505.16888"}
{"created":"2025-05-23","title":"FlashBack: Consistency Model-Accelerated Shared Autonomy","abstract":"Shared autonomy is an enabling technology that provides users with control authority over robots that would otherwise be difficult if not impossible to directly control. Yet, standard methods make assumptions that limit their adoption in practice-for example, prior knowledge of the user's goals or the objective (i.e., reward) function that they wish to optimize, knowledge of the user's policy, or query-level access to the user during training. Diffusion-based approaches to shared autonomy do not make such assumptions and instead only require access to demonstrations of desired behaviors, while allowing the user to maintain control authority. However, these advantages have come at the expense of high computational complexity, which has made real-time shared autonomy all but impossible. To overcome this limitation, we propose Consistency Shared Autonomy (CSA), a shared autonomy framework that employs a consistency model-based formulation of diffusion. Key to CSA is that it employs the distilled probability flow of ordinary differential equations (PF ODE) to generate high-fidelity samples in a single step. This results in inference speeds significantly than what is possible with previous diffusion-based approaches to shared autonomy, enabling real-time assistance in complex domains with only a single function evaluation. Further, by intervening on flawed actions at intermediate states of the PF ODE, CSA enables varying levels of assistance. We evaluate CSA on a variety of challenging simulated and real-world robot control problems, demonstrating significant improvements over state-of-the-art methods both in terms of task performance and computational efficiency.","authors":["Luzhe Sun","Jingtian Ji","Xiangshan Tan","Matthew R. Walter"],"url":"https://arxiv.org/abs/2505.16892"}
{"created":"2025-05-23","title":"Shadows in the Attention: Contextual Perturbation and Representation Drift in the Dynamics of Hallucination in LLMs","abstract":"Hallucinations -- plausible yet erroneous outputs -- remain a critical barrier to reliable deployment of large language models (LLMs). We present the first systematic study linking hallucination incidence to internal-state drift induced by incremental context injection. Using TruthfulQA, we construct two 16-round \"titration\" tracks per question: one appends relevant but partially flawed snippets, the other injects deliberately misleading content. Across six open-source LLMs, we track overt hallucination rates with a tri-perspective detector and covert dynamics via cosine, entropy, JS and Spearman drifts of hidden states and attention maps. Results reveal (1) monotonic growth of hallucination frequency and representation drift that plateaus after 5--7 rounds; (2) relevant context drives deeper semantic assimilation, producing high-confidence \"self-consistent\" hallucinations, whereas irrelevant context induces topic-drift errors anchored by attention re-routing; and (3) convergence of JS-Drift ($\\sim0.69$) and Spearman-Drift ($\\sim0$) marks an \"attention-locking\" threshold beyond which hallucinations solidify and become resistant to correction. Correlation analyses expose a seesaw between assimilation capacity and attention diffusion, clarifying size-dependent error modes. These findings supply empirical foundations for intrinsic hallucination prediction and context-aware mitigation mechanisms.","authors":["Zeyu Wei","Shuo Wang","Xiaohui Rong","Xuemin Liu","He Li"],"url":"https://arxiv.org/abs/2505.16894"}
{"created":"2025-05-23","title":"Structure-Aligned Protein Language Model","abstract":"Protein language models (pLMs) pre-trained on vast protein sequence databases excel at various downstream tasks but lack the structural knowledge essential for many biological applications. To address this, we integrate structural insights from pre-trained protein graph neural networks (pGNNs) into pLMs through a latent-level contrastive learning task. This task aligns residue representations from pLMs with those from pGNNs across multiple proteins, enriching pLMs with inter-protein structural knowledge. Additionally, we incorporate a physical-level task that infuses intra-protein structural knowledge by optimizing pLMs to predict structural tokens. The proposed dual-task framework effectively incorporates both inter-protein and intra-protein structural knowledge into pLMs. Given the variability in the quality of protein structures in PDB, we further introduce a residue loss selection module, which uses a small model trained on high-quality structures to select reliable yet challenging residue losses for the pLM to learn. Applying our structure alignment method to the state-of-the-art ESM2 and AMPLIFY results in notable performance gains across a wide range of tasks, including a 12.7% increase in ESM2 contact prediction. The data, code, and resulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.","authors":["Can Chen","David Heurtel-Depeiges","Robert M. Vernon","Christopher James Langmead","Yoshua Bengio","Quentin Fournier"],"url":"https://arxiv.org/abs/2505.16896"}
{"created":"2025-05-23","title":"Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships","abstract":"Artificial Intelligence (AI) systems have historically been used as tools that execute narrowly defined tasks. Yet recent advances in AI have unlocked possibilities for a new class of models that genuinely collaborate with humans in complex reasoning, from conceptualizing problems to brainstorming solutions. Such AI thought partners enable novel forms of collaboration and extended cognition, yet they also pose major risks-including and beyond risks of typical AI tools and agents. In this commentary, we systematically identify risks of AI thought partners through a novel framework that identifies risks at multiple levels of analysis, including Real-time, Individual, and Societal risks arising from collaborative cognition (RISc). We leverage this framework to propose concrete metrics for risk evaluation, and finally suggest specific mitigation strategies for developers and policymakers. As AI thought partners continue to proliferate, these strategies can help prevent major harms and ensure that humans actively benefit from productive thought partnerships.","authors":["Kerem Oktar","Katherine M. Collins","Jose Hernandez-Orallo","Diane Coyle","Stephen Cave","Adrian Weller","Ilia Sucholutsky"],"url":"https://arxiv.org/abs/2505.16899"}
{"created":"2025-05-23","title":"Power-Law Decay Loss for Large Language Model Finetuning: Focusing on Information Sparsity to Enhance Generation Quality","abstract":"During the finetuning stage of text generation tasks, standard cross-entropy loss treats all tokens equally. This can lead models to overemphasize high-frequency, low-information tokens, neglecting lower-frequency tokens crucial for specificity and informativeness in generated content. This paper introduces a novel loss function, Power-Law Decay Loss (PDL), specifically designed to optimize the finetuning process for text generation. The core motivation for PDL stems from observations in information theory and linguistics: the informativeness of a token is often inversely proportional to its frequency of occurrence. PDL re-weights the contribution of each token in the standard cross-entropy loss based on its frequency in the training corpus, following a power-law decay. Specifically, the weights for high-frequency tokens are reduced, while low-frequency, information-dense tokens are assigned higher weights. This mechanism guides the model during finetuning to focus more on learning and generating tokens that convey specific and unique information, thereby enhancing the quality, diversity, and informativeness of the generated text. We theoretically elaborate on the motivation and construction of PDL and discuss its potential applications and advantages across various text generation finetuning tasks, such as abstractive summarization, dialogue systems, and style transfer.","authors":["Jintian Shao","Hongyi Huang","Jiayi Wu","Beiwen Zhang","ZhiYu Wu","You Shan","MingKai Zheng"],"url":"https://arxiv.org/abs/2505.16900"}
{"created":"2025-05-23","title":"Code Graph Model (CGM): A Graph-Integrated Large Language Model for Repository-Level Software Engineering Tasks","abstract":"Recent advances in Large Language Models (LLMs) have shown promise in function-level code generation, yet repository-level software engineering tasks remain challenging. Current solutions predominantly rely on proprietary LLM agents, which introduce unpredictability and limit accessibility, raising concerns about data privacy and model customization. This paper investigates whether open-source LLMs can effectively address repository-level tasks without requiring agent-based approaches. We demonstrate this is possible by enabling LLMs to comprehend functions and files within codebases through their semantic information and structural dependencies. To this end, we introduce Code Graph Models (CGMs), which integrate repository code graph structures into the LLM's attention mechanism and map node attributes to the LLM's input space using a specialized adapter. When combined with an agentless graph RAG framework, our approach achieves a 43.00% resolution rate on the SWE-bench Lite benchmark using the open-source Qwen2.5-72B model. This performance ranks first among open weight models, second among methods with open-source systems, and eighth overall, surpassing the previous best open-source model-based method by 12.33%.","authors":["Hongyuan Tao","Ying Zhang","Zhenhao Tang","Hongen Peng","Xukun Zhu","Bingchang Liu","Yingguang Yang","Ziyin Zhang","Zhaogui Xu","Haipeng Zhang","Linchao Zhu","Rui Wang","Hang Yu","Jianguo Li","Peng Di"],"url":"https://arxiv.org/abs/2505.16901"}
{"created":"2025-05-23","title":"RealEngine: Simulating Autonomous Driving in Realistic Context","abstract":"Driving simulation plays a crucial role in developing reliable driving agents by providing controlled, evaluative environments. To enable meaningful assessments, a high-quality driving simulator must satisfy several key requirements: multi-modal sensing capabilities (e.g., camera and LiDAR) with realistic scene rendering to minimize observational discrepancies; closed-loop evaluation to support free-form trajectory behaviors; highly diverse traffic scenarios for thorough evaluation; multi-agent cooperation to capture interaction dynamics; and high computational efficiency to ensure affordability and scalability. However, existing simulators and benchmarks fail to comprehensively meet these fundamental criteria. To bridge this gap, this paper introduces RealEngine, a novel driving simulation framework that holistically integrates 3D scene reconstruction and novel view synthesis techniques to achieve realistic and flexible closed-loop simulation in the driving context. By leveraging real-world multi-modal sensor data, RealEngine reconstructs background scenes and foreground traffic participants separately, allowing for highly diverse and realistic traffic scenarios through flexible scene composition. This synergistic fusion of scene reconstruction and view synthesis enables photorealistic rendering across multiple sensor modalities, ensuring both perceptual fidelity and geometric accuracy. Building upon this environment, RealEngine supports three essential driving simulation categories: non-reactive simulation, safety testing, and multi-agent interaction, collectively forming a reliable and comprehensive benchmark for evaluating the real-world performance of driving agents.","authors":["Junzhe Jiang","Nan Song","Jingyu Li","Xiatian Zhu","Li Zhang"],"url":"https://arxiv.org/abs/2505.16902"}
{"created":"2025-05-23","title":"Unsupervised Prompting for Graph Neural Networks","abstract":"Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to address the semantic gap between pre-training and fine-tuning steps. However, existing GNN prompting methods rely on labeled data and involve lightweight fine-tuning for downstream tasks. Meanwhile, in-context learning methods for Large Language Models (LLMs) have shown promising performance with no parameter updating and no or minimal labeled data. Inspired by these approaches, in this work, we first introduce a challenging problem setup to evaluate GNN prompting methods. This setup encourages a prompting function to enhance a pre-trained GNN's generalization to a target dataset under covariate shift without updating the GNN's parameters and with no labeled data. Next, we propose a fully unsupervised prompting method based on consistency regularization through pseudo-labeling. We use two regularization techniques to align the prompted graphs' distribution with the original data and reduce biased predictions. Through extensive experiments under our problem setting, we demonstrate that our unsupervised approach outperforms the state-of-the-art prompting methods that have access to labels.","authors":["Peyman Baghershahi","Sourav Medya"],"url":"https://arxiv.org/abs/2505.16903"}
{"created":"2025-05-23","title":"UAV See, UGV Do: Aerial Imagery and Virtual Teach Enabling Zero-Shot Ground Vehicle Repeat","abstract":"This paper presents Virtual Teach and Repeat (VirT&amp;R): an extension of the Teach and Repeat (T&amp;R) framework that enables GPS-denied, zero-shot autonomous ground vehicle navigation in untraversed environments. VirT&amp;R leverages aerial imagery captured for a target environment to train a Neural Radiance Field (NeRF) model so that dense point clouds and photo-textured meshes can be extracted. The NeRF mesh is used to create a high-fidelity simulation of the environment for piloting an unmanned ground vehicle (UGV) to virtually define a desired path. The mission can then be executed in the actual target environment by using NeRF-derived point cloud submaps associated along the path and an existing LiDAR Teach and Repeat (LT&amp;R) framework. We benchmark the repeatability of VirT&amp;R on over 12 km of autonomous driving data using physical markings that allow a sim-to-real lateral path-tracking error to be obtained and compared with LT&amp;R. VirT&amp;R achieved measured root mean squared errors (RMSE) of 19.5 cm and 18.4 cm in two different environments, which are slightly less than one tire width (24 cm) on the robot used for testing, and respective maximum errors were 39.4 cm and 47.6 cm. This was done using only the NeRF-derived teach map, demonstrating that VirT&amp;R has similar closed-loop path-tracking performance to LT&amp;R but does not require a human to manually teach the path to the UGV in the actual environment.","authors":["Desiree Fisker","Alexander Krawciw","Sven Lilge","Melissa Greeff","Timothy D. Barfoot"],"url":"https://arxiv.org/abs/2505.16912"}
{"created":"2025-05-23","title":"DetailMaster: Can Your Text-to-Image Model Handle Long Prompts?","abstract":"While recent text-to-image (T2I) models show impressive capabilities in synthesizing images from brief descriptions, their performance significantly degrades when confronted with long, detail-intensive prompts required in professional applications. We present DetailMaster, the first comprehensive benchmark specifically designed to evaluate T2I models' systematical abilities to handle extended textual inputs that contain complex compositional requirements. Our benchmark introduces four critical evaluation dimensions: Character Attributes, Structured Character Locations, Multi-Dimensional Scene Attributes, and Explicit Spatial/Interactive Relationships. The benchmark comprises long and detail-rich prompts averaging 284.89 tokens, with high quality validated by expert annotators. Evaluation on 7 general-purpose and 5 long-prompt-optimized T2I models reveals critical performance limitations: state-of-the-art models achieve merely ~50% accuracy in key dimensions like attribute binding and spatial reasoning, while all models showing progressive performance degradation as prompt length increases. Our analysis highlights systemic failures in structural comprehension and detail overload handling, motivating future research into architectures with enhanced compositional reasoning. We open-source the dataset, data curation code, and evaluation tools to advance detail-rich T2I generation and enable broad applications that would otherwise be infeasible due to the lack of a dedicated benchmark.","authors":["Qirui Jiao","Daoyuan Chen","Yilun Huang","Xika Lin","Ying Shen","Yaliang Li"],"url":"https://arxiv.org/abs/2505.16915"}
{"created":"2025-05-23","title":"Backdoor Cleaning without External Guidance in MLLM Fine-tuning","abstract":"Multimodal Large Language Models (MLLMs) are increasingly deployed in fine-tuning-as-a-service (FTaaS) settings, where user-submitted datasets adapt general-purpose models to downstream tasks. This flexibility, however, introduces serious security risks, as malicious fine-tuning can implant backdoors into MLLMs with minimal effort. In this paper, we observe that backdoor triggers systematically disrupt cross-modal processing by causing abnormal attention concentration on non-semantic regions--a phenomenon we term attention collapse. Based on this insight, we propose Believe Your Eyes (BYE), a data filtering framework that leverages attention entropy patterns as self-supervised signals to identify and filter backdoor samples. BYE operates via a three-stage pipeline: (1) extracting attention maps using the fine-tuned model, (2) computing entropy scores and profiling sensitive layers via bimodal separation, and (3) performing unsupervised clustering to remove suspicious samples. Unlike prior defenses, BYE equires no clean supervision, auxiliary labels, or model modifications. Extensive experiments across various datasets, models, and diverse trigger types validate BYE's effectiveness: it achieves near-zero attack success rates while maintaining clean-task performance, offering a robust and generalizable solution against backdoor threats in MLLMs.","authors":["Xuankun Rong","Wenke Huang","Jian Liang","Jinhe Bi","Xun Xiao","Yiming Li","Bo Du","Mang Ye"],"url":"https://arxiv.org/abs/2505.16916"}
{"created":"2025-05-23","title":"Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype","abstract":"This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB) methods and introduces an experimental framework for scalable, interpretable offer selection, addressing the challenge of fast-changing offers. The approach models context at the product category level, allowing offers to span multiple categories and enabling knowledge transfer across similar offers. This improves learning efficiency and generalization in dynamic environments. The framework extends standard CMAB methodology to support multi-category contexts, and achieves scalability through efficient feature engineering and modular design. Advanced features such as MPG (Member Purchase Gap) and MF (Matrix Factorization) capture nuanced user-offer interactions, with implementation in Python for practical deployment.","authors":["Nikola Tankovic","Robert Sajina"],"url":"https://arxiv.org/abs/2505.16918"}
{"created":"2025-05-23","title":"UNCLE: Uncertainty Expressions in Long-Form Generation","abstract":"Large Language Models (LLMs) are prone to hallucination, particularly in long-form generations. A promising direction to mitigate hallucination is to teach LLMs to express uncertainty explicitly when they lack sufficient knowledge. However, existing work lacks direct and fair evaluation of LLMs' ability to express uncertainty effectively in long-form generation. To address this gap, we first introduce UNCLE, a benchmark designed to evaluate uncertainty expression in both long- and short-form question answering (QA). UNCLE spans five domains and comprises 4k long-form QA instances and over 20k short-form QA pairs. Our dataset is the first to directly bridge short- and long-form QA with paired questions and gold-standard answers. Along with the benchmark, we propose a suite of new metrics to assess the models' capabilities to selectively express uncertainty. Using UNCLE, we then demonstrate that current models fail to convey uncertainty appropriately in long-form generation. We further explore both prompt-based and training-based methods to improve models' performance, with the training-based methods yielding greater gains. Further analysis of alignment gaps between short- and long-form uncertainty expression highlights promising directions for future research using UNCLE.","authors":["Ruihan Yang","Caiqi Zhang","Zhisong Zhang","Xinting Huang","Dong Yu","Nigel Collier","Deqing Yang"],"url":"https://arxiv.org/abs/2505.16922"}
{"created":"2025-05-23","title":"Risk-Averse Reinforcement Learning with Itakura-Saito Loss","abstract":"Risk-averse reinforcement learning finds application in various high-stakes fields. Unlike classical reinforcement learning, which aims to maximize expected returns, risk-averse agents choose policies that minimize risk, occasionally sacrificing expected value. These preferences can be framed through utility theory. We focus on the specific case of the exponential utility function, where we can derive the Bellman equations and employ various reinforcement learning algorithms with few modifications. However, these methods suffer from numerical instability due to the need for exponent computation throughout the process. To address this, we introduce a numerically stable and mathematically sound loss function based on the Itakura-Saito divergence for learning state-value and action-value functions. We evaluate our proposed loss function against established alternatives, both theoretically and empirically. In the experimental section, we explore multiple financial scenarios, some with known analytical solutions, and show that our loss function outperforms the alternatives.","authors":["Igor Udovichenko","Olivier Croissant","Anita Toleutaeva","Evgeny Burnaev","Alexander Korotin"],"url":"https://arxiv.org/abs/2505.16925"}
{"created":"2025-05-23","title":"Latent Principle Discovery for Language Model Self-Improvement","abstract":"When language model (LM) users aim to improve the quality of its generations, it is crucial to specify concrete behavioral attributes that the model should strive to reflect. However, curating such principles across many domains, even non-exhaustively, requires a labor-intensive annotation process. To automate this process, we propose eliciting these latent attributes guiding model reasoning towards human-preferred responses by explicitly modeling them in a self-correction setting. Our approach mines new principles from the LM itself and compresses the discovered elements to an interpretable set via clustering. Specifically, we employ an approximation of posterior-regularized Monte Carlo Expectation-Maximization to both identify a condensed set of the most effective latent principles and teach the LM to strategically invoke them in order to intrinsically refine its responses. We demonstrate that bootstrapping our algorithm over multiple iterations enables smaller language models (7-8B parameters) to self-improve, achieving +8-10% in AlpacaEval win-rate, an average of +0.3 on MT-Bench, and +19-23% in principle-following win-rate on IFEval. We also show that clustering the principles yields interpretable and diverse model-generated constitutions while retaining model performance. The gains our method achieves highlight the potential of automated, principle-driven post-training recipes toward continual self-improvement.","authors":["Keshav Ramji","Tahira Naseem","Ram\\'on Fernandez Astudillo"],"url":"https://arxiv.org/abs/2505.16927"}
{"created":"2025-05-23","title":"Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning","abstract":"We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks that advances long-context understanding in embodied AI. $\\infty$-THOR provides: (1) a generation framework for synthesizing scalable, reproducible, and unlimited long-horizon trajectories; (2) a novel embodied QA task, Needle(s) in the Embodied Haystack, where multiple scattered clues across extended trajectories test agents' long-context reasoning ability; and (3) a long-horizon dataset and benchmark suite featuring complex tasks that span hundreds of environment steps, each paired with ground-truth action sequences. To enable this capability, we explore architectural adaptations, including interleaved Goal-State-Action modeling, context extension techniques, and Context Parallelism, to equip LLM-based agents for extreme long-context reasoning and interaction. Experimental results and analyses highlight the challenges posed by our benchmark and provide insights into training strategies and model behaviors under long-horizon conditions. Our work provides a foundation for the next generation of embodied AI systems capable of robust, long-term reasoning and planning.","authors":["Bosung Kim","Prithviraj Ammanabrolu"],"url":"https://arxiv.org/abs/2505.16928"}
{"created":"2025-05-23","title":"PIIvot: A Lightweight NLP Anonymization Framework for Question-Anchored Tutoring Dialogues","abstract":"Personally identifiable information (PII) anonymization is a high-stakes task that poses a barrier to many open-science data sharing initiatives. While PII identification has made large strides in recent years, in practice, error thresholds and the recall/precision trade-off still limit the uptake of these anonymization pipelines. We present PIIvot, a lighter-weight framework for PII anonymization that leverages knowledge of the data context to simplify the PII detection problem. To demonstrate its effectiveness, we also contribute QATD-2k, the largest open-source real-world tutoring dataset of its kind, to support the demand for quality educational dialogue data.","authors":["Matthew Zent","Digory Smith","Simon Woodhead"],"url":"https://arxiv.org/abs/2505.16931"}
{"created":"2025-05-23","title":"The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm","abstract":"Computing the polar decomposition and the related matrix sign function, has been a well-studied problem in numerical analysis for decades. More recently, it has emerged as an important subroutine in deep learning, particularly within the Muon optimization framework. However, the requirements in this setting differ significantly from those of traditional numerical analysis. In deep learning, methods must be highly efficient and GPU-compatible, but high accuracy is often unnecessary. As a result, classical algorithms like Newton-Schulz (which suffers from slow initial convergence) and methods based on rational functions (which rely on QR decompositions or matrix inverses) are poorly suited to this context. In this work, we introduce Polar Express, a GPU-friendly algorithm for computing the polar decomposition. Like classical polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix multiplications, making it GPU-compatible. Motivated by earlier work of Chen & Chow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule at each iteration by solving a minimax optimization problem, and we prove that it enjoys a strong worst-case optimality guarantee. This property ensures both rapid early convergence and fast asymptotic convergence. We also address finite-precision issues, making it stable in bfloat16 in practice. We apply Polar Express within the Muon optimization framework and show consistent improvements in validation loss on large-scale models such as GPT-2, outperforming recent alternatives across a range of learning rates.","authors":["Noah Amsel","David Persson","Christopher Musco","Robert Gower"],"url":"https://arxiv.org/abs/2505.16932"}
{"created":"2025-05-23","title":"LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning","abstract":"In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large Language Model (MLLM) that integrates visual instruction tuning with masked diffusion models, representing a departure from the autoregressive paradigms dominant in current multimodal approaches. Built upon LLaDA, a representative large language diffusion model, LLaDA-V incorporates a vision encoder and MLP connector that projects visual features into the language embedding space, enabling effective multimodal alignment. Our empirical investigation reveals several intriguing results: First, LLaDA-V demonstrates promising multimodal performance despite its language model being weaker on purely textual tasks than counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same instruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal tasks with better data scalability. It also narrows the performance gap to Qwen2-VL, suggesting the effectiveness of its architecture for multimodal tasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal understanding compared to existing hybrid autoregressive-diffusion and purely diffusion-based MLLMs. Our findings suggest that large language diffusion models show promise in multimodal contexts and warrant further investigation in future research. Project page and codes: https://ml-gsai.github.io/LLaDA-V-demo/.","authors":["Zebin You","Shen Nie","Xiaolu Zhang","Jun Hu","Jun Zhou","Zhiwu Lu","Ji-Rong Wen","Chongxuan Li"],"url":"https://arxiv.org/abs/2505.16933"}
{"created":"2025-05-23","title":"In-Context Watermarks for Large Language Models","abstract":"The growing use of large language models (LLMs) for sensitive applications has highlighted the need for effective watermarking techniques to ensure the provenance and accountability of AI-generated text. However, most existing watermarking methods require access to the decoding process, limiting their applicability in real-world settings. One illustrative example is the use of LLMs by dishonest reviewers in the context of academic peer review, where conference organizers have no access to the model used but still need to detect AI-generated reviews. Motivated by this gap, we introduce In-Context Watermarking (ICW), which embeds watermarks into generated text solely through prompt engineering, leveraging LLMs' in-context learning and instruction-following abilities. We investigate four ICW strategies at different levels of granularity, each paired with a tailored detection method. We further examine the Indirect Prompt Injection (IPI) setting as a specific case study, in which watermarking is covertly triggered by modifying input documents such as academic manuscripts. Our experiments validate the feasibility of ICW as a model-agnostic, practical watermarking approach. Moreover, our findings suggest that as LLMs become more capable, ICW offers a promising direction for scalable and accessible content attribution.","authors":["Yepeng Liu","Xuandong Zhao","Christopher Kruegel","Dawn Song","Yuheng Bu"],"url":"https://arxiv.org/abs/2505.16934"}
{"created":"2025-05-23","title":"Modeling and Constraint-Aware Control of Pressure Dynamics in Water Electrolysis Systems","abstract":"This paper addresses the challenge of pressure constraint violations in water electrolysis systems operating under dynamic power conditions, a problem common to both Proton Exchange Membrane and alkaline technologies. To investigate this issue, a control-oriented model of an alkaline electrolyzer is developed, capturing key pressure and flow dynamics. To manage rapid power fluctuations that may cause pressure to exceed manufacturer-defined operational boundaries, a model-based constraint-aware power governor based on the Reference Governor (RG) framework is proposed. Simulation results show that the strategy effectively maintains pressure within the specified operating range, outperforming conventional filtering methods while enhancing hydrogen production and reducing auxiliary energy consumption.","authors":["Mostafaali Ayubirad","Madiha Akbar","Hamid R. Ossareh"],"url":"https://arxiv.org/abs/2505.16935"}
{"created":"2025-05-23","title":"SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems","abstract":"This work develops the underpinnings of self-supervised placement-aware representation learning given spatially-distributed (multi-view and multimodal) sensor observations, motivated by the need to represent external environmental state in multi-sensor IoT systems in a manner that correctly distills spatial phenomena from the distributed multi-vantage observations. The objective of sensing in IoT systems is, in general, to collectively represent an externally observed environment given multiple vantage points from which sensory observations occur. Pretraining of models that help interpret sensor data must therefore encode the relation between signals observed by sensors and the observers' vantage points in order to attain a representation that encodes the observed spatial phenomena in a manner informed by the specific placement of the measuring instruments, while allowing arbitrary placement. The work significantly advances self-supervised model pretraining from IoT signals beyond current solutions that often overlook the distinctive spatial nature of IoT data. Our framework explicitly learns the dependencies between measurements and geometric observer layouts and structural characteristics, guided by a core design principle: the duality between signals and observer positions. We further provide theoretical analyses from the perspectives of information theory and occlusion-invariant representation learning to offer insight into the rationale behind our design. Experiments on three real-world datasets--covering vehicle monitoring, human activity recognition, and earthquake localization--demonstrate the superior generalizability and robustness of our method across diverse modalities, sensor placements, application-level inference tasks, and spatial scales.","authors":["Yizhuo Chen","Tianchen Wang","You Lyu","Yanlan Hu","Jinyang Li","Tomoyoshi Kimura","Hongjue Zhao","Yigong Hu","Denizhan Kara","Tarek Abdelzaher"],"url":"https://arxiv.org/abs/2505.16936"}
{"created":"2025-05-23","title":"Quasi-optimal hierarchically semi-separable matrix approximation","abstract":"We present a randomized algorithm for producing a quasi-optimal hierarchically semi-separable (HSS) approximation to an $N\\times N$ matrix $A$ using only matrix-vector products with $A$ and $A^T$. We prove that, using $O(k \\log(N/k))$ matrix-vector products and ${O}(N k^2 \\log(N/k))$ additional runtime, the algorithm returns an HSS matrix $B$ with rank-$k$ blocks whose expected Frobenius norm error $\\mathbb{E}[\\|A - B\\|_F^2]$ is at most $O(\\log(N/k))$ times worse than the best possible approximation error by an HSS rank-$k$ matrix. In fact, the algorithm we analyze in a simple modification of an empirically effective method proposed by [Levitt & Martinsson, SISC 2024]. As a stepping stone towards our main result, we prove two results that are of independent interest: a similar guarantee for a variant of the algorithm which accesses $A$'s entries directly, and explicit error bounds for near-optimal subspace approximation using projection-cost-preserving sketches. To the best of our knowledge, our analysis constitutes the first polynomial-time quasi-optimality result for HSS matrix approximation, both in the explicit access model and the matrix-vector product query model.","authors":["Noah Amsel","Tyler Chen","Feyza Duman Keles","Diana Halikias","Cameron Musco","Christopher Musco","David Persson"],"url":"https://arxiv.org/abs/2505.16937"}
{"created":"2025-05-23","title":"NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification","abstract":"Artificial Intelligence (AI) is accelerating the transformation of scientific research paradigms, not only enhancing research efficiency but also driving innovation. We introduce NovelSeek, a unified closed-loop multi-agent framework to conduct Autonomous Scientific Research (ASR) across various scientific research fields, enabling researchers to tackle complicated problems in these fields with unprecedented speed and precision. NovelSeek highlights three key advantages: 1) Scalability: NovelSeek has demonstrated its versatility across 12 scientific research tasks, capable of generating innovative ideas to enhance the performance of baseline code. 2) Interactivity: NovelSeek provides an interface for human expert feedback and multi-agent interaction in automated end-to-end processes, allowing for the seamless integration of domain expert knowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in several scientific fields with significantly less time cost compared to human efforts. For instance, in reaction yield prediction, it increased from 27.6% to 35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from 0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation, precision advanced from 78.8% to 81.0% in a mere 30 hours.","authors":["NovelSeek Team","Bo Zhang","Shiyang Feng","Xiangchao Yan","Jiakang Yuan","Zhiyin Yu","Xiaohan He","Songtao Huang","Shaowei Hou","Zheng Nie","Zhilong Wang","Jinyao Liu","Runmin Ma","Tianshuo Peng","Peng Ye","Dongzhan Zhou","Shufei Zhang","Xiaosong Wang","Yilan Zhang","Meng Li","Zhongying Tu","Xiangyu Yue","Wangli Ouyang","Bowen Zhou","Lei Bai"],"url":"https://arxiv.org/abs/2505.16938"}
{"created":"2025-05-23","title":"Delayed dynamic-feedback controller design for multi-frequency vibration suppression","abstract":"We present a methodology for designing a dynamic controller with delayed output feedback for achieving non-collocated vibration suppression with a focus on the multi-frequency case. To synthesize the delay-based controller, we first remodel the system of equations as a delay-differential algebraic equation (DDAE) in such a way that existing tools for design of a static output feedback controller can be easily adapted. The problem of achieving non-collocated vibration suppression with sufficient damping is formulated as a constrained optimization problem of minimizing the spectral abscissa in the presence of zero-location constraints, with the constraints exhibiting polynomial dependence on its parameters. We transform the problem into an unconstrained one using elimination, following which we solve the resulting non-convex, non-smooth optimization problem.","authors":["Adrian Saldanha","Adam Peichl","Wim Michiels","Tom\\'a\\v{s} Vyhl\\'idal"],"url":"https://arxiv.org/abs/2505.16939"}
{"created":"2025-05-23","title":"FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records","abstract":"Foundation models hold significant promise in healthcare, given their capacity to extract meaningful representations independent of downstream tasks. This property has enabled state-of-the-art performance across several clinical applications trained on structured electronic health record (EHR) data, even in settings with limited labeled data, a prevalent challenge in healthcare. However, there is little consensus on these models' potential for clinical utility due to the lack of desiderata of comprehensive and meaningful tasks and sufficiently diverse evaluations to characterize the benefit over conventional supervised learning. To address this gap, we propose a suite of clinically meaningful tasks spanning patient outcomes, early prediction of acute and chronic conditions, including desiderata for robust evaluations. We evaluate state-of-the-art foundation models on EHR data consisting of 5 million patients from Columbia University Irving Medical Center (CUMC), a large urban academic medical center in New York City, across 14 clinically relevant tasks. We measure overall accuracy, calibration, and subpopulation performance to surface tradeoffs based on the choice of pre-training, tokenization, and data representation strategies. Our study aims to advance the empirical evaluation of structured EHR foundation models and guide the development of future healthcare foundation models.","authors":["Chao Pang","Vincent Jeanselme","Young Sang Choi","Xinzhuo Jiang","Zilin Jing","Aparajita Kashyap","Yuta Kobayashi","Yanwei Li","Florent Pollet","Karthik Natarajan","Shalmali Joshi"],"url":"https://arxiv.org/abs/2505.16941"}
{"created":"2025-05-23","title":"Efficient Correlation Volume Sampling for Ultra-High-Resolution Optical Flow Estimation","abstract":"Recent optical flow estimation methods often employ local cost sampling from a dense all-pairs correlation volume. This results in quadratic computational and memory complexity in the number of pixels. Although an alternative memory-efficient implementation with on-demand cost computation exists, this is slower in practice and therefore prior methods typically process images at reduced resolutions, missing fine-grained details.","authors":["Karlis Martins Briedis","Markus Gross","Christopher Schroers"],"url":"https://arxiv.org/abs/2505.16942"}
{"created":"2025-05-23","title":"AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios","abstract":"Large Language Models (LLMs) have demonstrated advanced capabilities in real-world agentic applications. Growing research efforts aim to develop LLM-based agents to address practical demands, introducing a new challenge: agentic scenarios often involve lengthy instructions with complex constraints, such as extended system prompts and detailed tool specifications. While adherence to such instructions is crucial for agentic applications, whether LLMs can reliably follow them remains underexplored. In this paper, we introduce AgentIF, the first benchmark for systematically evaluating LLM instruction following ability in agentic scenarios. AgentIF features three key characteristics: (1) Realistic, constructed from 50 real-world agentic applications. (2) Long, averaging 1,723 words with a maximum of 15,630 words. (3) Complex, averaging 11.9 constraints per instruction, covering diverse constraint types, such as tool specifications and condition constraints. To construct AgentIF, we collect 707 human-annotated instructions across 50 agentic tasks from industrial application agents and open-source agentic systems. For each instruction, we annotate the associated constraints and corresponding evaluation metrics, including code-based evaluation, LLM-based evaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically evaluate existing advanced LLMs. We observe that current models generally perform poorly, especially in handling complex constraint structures and tool specifications. We further conduct error analysis and analytical experiments on instruction length and meta constraints, providing some findings about the failure modes of existing LLMs. We have released the code and data to facilitate future research.","authors":["Yunjia Qi","Hao Peng","Xiaozhi Wang","Amy Xin","Youfeng Liu","Bin Xu","Lei Hou","Juanzi Li"],"url":"https://arxiv.org/abs/2505.16944"}
{"created":"2025-05-23","title":"NY Real Estate Racial Equity Analysis via Applied Machine Learning","abstract":"This study analyzes tract-level real estate ownership patterns in New York State (NYS) and New York City (NYC) to uncover racial disparities. We use an advanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering, validated at 89.2% accuracy) to compare the predicted racial composition of property owners to the resident population from census data. We examine both a Full Model (statewide) and a Name-Only LSTM Model (NYC) to assess how incorporating geospatial context affects our predictions and disparity estimates. The results reveal significant inequities: White individuals hold a disproportionate share of properties and property value relative to their population, while Black, Hispanic, and Asian communities are underrepresented as property owners. These disparities are most pronounced in minority-majority neighborhoods, where ownership is predominantly White despite a predominantly non-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates these gaps by reducing owner-occupied opportunities in urban minority communities. We provide a breakdown of ownership vs. population by race for majority-White, -Black, -Hispanic, and -Asian tracts, identify those with extreme ownership disparities, and compare patterns in urban, suburban, and rural contexts. The findings underscore persistent racial inequity in property ownership, reflecting broader historical and socio-economic forces, and highlight the importance of data-driven approaches to address these issues.","authors":["Sanjana Chalavadi","Andrei Pastor","Terry Leitch"],"url":"https://arxiv.org/abs/2505.16946"}
{"created":"2025-05-23","title":"MixAT: Combining Continuous and Discrete Adversarial Training for LLMs","abstract":"Despite recent efforts in Large Language Models (LLMs) safety and alignment, current adversarial attacks on frontier LLMs are still able to force harmful generations consistently. Although adversarial training has been widely studied and shown to significantly improve the robustness of traditional machine learning models, its strengths and weaknesses in the context of LLMs are less understood. Specifically, while existing discrete adversarial attacks are effective at producing harmful content, training LLMs with concrete adversarial prompts is often computationally expensive, leading to reliance on continuous relaxations. As these relaxations do not correspond to discrete input tokens, such latent training methods often leave models vulnerable to a diverse set of discrete attacks. In this work, we aim to bridge this gap by introducing MixAT, a novel method that combines stronger discrete and faster continuous attacks during training. We rigorously evaluate MixAT across a wide spectrum of state-of-the-art attacks, proposing the At Least One Attack Success Rate (ALO-ASR) metric to capture the worst-case vulnerability of models. We show MixAT achieves substantially better robustness (ALO-ASR < 20%) compared to prior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to methods based on continuous relaxations. We further analyze MixAT in realistic deployment settings, exploring how chat templates, quantization, low-rank adapters, and temperature affect both adversarial training and evaluation, revealing additional blind spots in current methodologies. Our results demonstrate that MixAT's discrete-continuous defense offers a principled and superior robustness-accuracy tradeoff with minimal computational overhead, highlighting its promise for building safer LLMs. We provide our code and models at https://github.com/insait-institute/MixAT.","authors":["Csaba D\\'ek\\'any","Stefan Balauca","Robin Staab","Dimitar I. Dimitrov","Martin Vechev"],"url":"https://arxiv.org/abs/2505.16947"}
{"created":"2025-05-23","title":"Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning","abstract":"Despite their impressive capabilities, Large Language Models struggle with generalisation beyond their training distribution, often exhibiting sophisticated pattern interpolation rather than true abstract reasoning (extrapolation). In this work, we approach this limitation through the lens of Information Bottleneck (IB) theory, which posits that model generalisation emerges from an optimal balance between input compression and retention of predictive information in latent representations. We prove using IB theory that decoder-only Transformers are inherently constrained in their ability to form task-optimal sequence representations. We then use this result to demonstrate that periodic global transformation of the internal sequence-level representations (KV cache) is a necessary computational step for improving Transformer generalisation in reasoning tasks. Based on these theoretical insights, we propose a modification to the Transformer architecture, in the form of an additional module that globally rewrites the KV cache at periodic intervals, shifting its capacity away from memorising input prefixes and toward encoding features most useful for predicting future tokens. Our model delivers substantial gains on mathematical reasoning benchmarks, outperforming both vanilla Transformers with up to 3.5x more parameters, as well as heuristic-driven pruning mechanisms for cache compression. Our approach can be seen as a principled generalisation of existing KV-cache compression methods; whereas such methods focus solely on compressing input representations, they often do so at the expense of retaining predictive information, and thus their capabilities are inherently bounded by those of an unconstrained model. This establishes a principled framework to manipulate Transformer memory using information theory, addressing fundamental reasoning limitations that scaling alone cannot overcome.","authors":["Adnan Oomerjee","Zafeirios Fountas","Zhongwei Yu","Haitham Bou-Ammar","Jun Wang"],"url":"https://arxiv.org/abs/2505.16950"}
{"created":"2025-05-23","title":"From Reality to Virtual Worlds: The Role of Photogrammetry in Game Development","abstract":"Photogrammetry is transforming digital content creation by enabling the rapid conversion of real-world objects into highly detailed 3D models. This paper evaluates the role of RealityCapture, a GPU-accelerated photogrammetry tool, in game development of Virtual Reality (VR). We assess its efficiency, reconstruction accuracy, and integration with Unreal Engine, comparing its advantages and limitations against traditional modeling workflows. Additionally, we examined user preferences between designed 3D assets and photogrammetry-generated models. The results revealed that while photogrammetry enhances realism and interactivity, users slightly preferred manually designed models for small, manipulable elements because of the level of detail. However, from a developer perspective, RealityCapture significantly reduces development time while maintaining geometric precision and photorealistic textures. Despite its reliance on high-performance hardware, its automation, scalability, and seamless integration with real-time rendering engines make it a valuable tool for game developers and VR creators. Future improvements in AI-driven optimization and cloud-based processing could enhance accessibility, broadening its applications in gaming, cultural heritage preservation, and simulation.","authors":["Santiago Berrezueta-Guzman","Andrei Koshelev","Stefan Wagner"],"url":"https://arxiv.org/abs/2505.16951"}
{"created":"2025-05-23","title":"A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization","abstract":"Machine learning (ML) has demonstrated considerable potential in supporting model design and optimization for combinatorial optimization (CO) problems. However, much of the progress to date has been evaluated on small-scale, synthetic datasets, raising concerns about the practical effectiveness of ML-based solvers in real-world, large-scale CO scenarios. Additionally, many existing CO benchmarks lack sufficient training data, limiting their utility for evaluating data-driven approaches. To address these limitations, we introduce FrontierCO, a comprehensive benchmark that covers eight canonical CO problem types and evaluates 16 representative ML-based solvers--including graph neural networks and large language model (LLM) agents. FrontierCO features challenging instances drawn from industrial applications and frontier CO research, offering both realistic problem difficulty and abundant training data. Our empirical results provide critical insights into the strengths and limitations of current ML methods, helping to guide more robust and practically relevant advances at the intersection of machine learning and combinatorial optimization. Our data is available at https://huggingface.co/datasets/CO-Bench/FrontierCO.","authors":["Shengyu Feng","Weiwei Sun","Shanda Li","Ameet Talwalkar","Yiming Yang"],"url":"https://arxiv.org/abs/2505.16952"}
{"created":"2025-05-23","title":"ICYM2I: The illusion of multimodal informativeness under missingness","abstract":"Multimodal learning is of continued interest in artificial intelligence-based applications, motivated by the potential information gain from combining different types of data. However, modalities collected and curated during development may differ from the modalities available at deployment due to multiple factors including cost, hardware failure, or -- as we argue in this work -- the perceived informativeness of a given modality. Na{\\\"i}ve estimation of the information gain associated with including an additional modality without accounting for missingness may result in improper estimates of that modality's value in downstream tasks. Our work formalizes the problem of missingness in multimodal learning and demonstrates the biases resulting from ignoring this process. To address this issue, we introduce ICYM2I (In Case You Multimodal Missed It), a framework for the evaluation of predictive performance and information gain under missingness through inverse probability weighting-based correction. We demonstrate the importance of the proposed adjustment to estimate information gain under missingness on synthetic, semi-synthetic, and real-world medical datasets.","authors":["Young Sang Choi","Vincent Jeanselme","Pierre Elias","Shalmali Joshi"],"url":"https://arxiv.org/abs/2505.16953"}
{"created":"2025-05-23","title":"Cracking Aegis: An Adversarial LLM-based Game for Raising Awareness of Vulnerabilities in Privacy Protection","abstract":"Traditional methods for raising awareness of privacy protection often fail to engage users or provide hands-on insights into how privacy vulnerabilities are exploited. To address this, we incorporate an adversarial mechanic in the design of the dialogue-based serious game Cracking Aegis. Leveraging LLMs to simulate natural interactions, the game challenges players to impersonate characters and extract sensitive information from an AI agent, Aegis. A user study (n=22) revealed that players employed diverse deceptive linguistic strategies, including storytelling and emotional rapport, to manipulate Aegis. After playing, players reported connecting in-game scenarios with real-world privacy vulnerabilities, such as phishing and impersonation, and expressed intentions to strengthen privacy control, such as avoiding oversharing personal information with AI systems. This work highlights the potential of LLMs to simulate complex relational interactions in serious games, while demonstrating how an adversarial game strategy provides unique insights for designs for social good, particularly privacy protection.","authors":["Jiaying Fu","Yiyang Lu","Zehua Yang","Fiona Nah","RAY LC"],"url":"https://arxiv.org/abs/2505.16954"}
{"created":"2025-05-23","title":"On Multilingual Encoder Language Model Compression for Low-Resource Languages","abstract":"In this paper, we combine two-step knowledge distillation, structured pruning, truncation, and vocabulary trimming for extremely compressing multilingual encoder-only language models for low-resource languages. Our novel approach systematically combines existing techniques and takes them to the extreme, reducing layer depth, feed-forward hidden size, and intermediate layer embedding size to create significantly smaller monolingual models while retaining essential language-specific knowledge. We achieve compression rates of up to 92% with only a marginal performance drop of 2-10% in four downstream tasks, including sentiment analysis, topic classification, named entity recognition, and part-of-speech tagging, across three low-resource languages. Notably, the performance degradation correlates with the amount of language-specific data in the teacher model, with larger datasets resulting in smaller performance losses. Additionally, we conduct extensive ablation studies to identify best practices for multilingual model compression using these techniques.","authors":["Daniil Gurgurov","Michal Gregor","Josef van Genabith","Simon Ostermann"],"url":"https://arxiv.org/abs/2505.16956"}
{"created":"2025-05-23","title":"Invisible Prompts, Visible Threats: Malicious Font Injection in External Resources for Large Language Models","abstract":"Large Language Models (LLMs) are increasingly equipped with capabilities of real-time web search and integrated with protocols like Model Context Protocol (MCP). This extension could introduce new security vulnerabilities. We present a systematic investigation of LLM vulnerabilities to hidden adversarial prompts through malicious font injection in external resources like webpages, where attackers manipulate code-to-glyph mapping to inject deceptive content which are invisible to users. We evaluate two critical attack scenarios: (1) \"malicious content relay\" and (2) \"sensitive data leakage\" through MCP-enabled tools. Our experiments reveal that indirect prompts with injected malicious font can bypass LLM safety mechanisms through external resources, achieving varying success rates based on data sensitivity and prompt design. Our research underscores the urgent need for enhanced security measures in LLM deployments when processing external content.","authors":["Junjie Xiong","Changjia Zhu","Shuhang Lin","Chong Zhang","Yongfeng Zhang","Yao Liu","Lingyao Li"],"url":"https://arxiv.org/abs/2505.16957"}
{"created":"2025-05-23","title":"Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models","abstract":"Diffusion probabilistic models have become a cornerstone of modern generative AI, yet the mechanisms underlying their generalization remain poorly understood. In fact, if these models were perfectly minimizing their training loss, they would just generate data belonging to their training set, i.e., memorize, as empirically found in the overparameterized regime. We revisit this view by showing that, in highly overparameterized diffusion models, generalization in natural data domains is progressively achieved during training before the onset of memorization. Our results, ranging from image to language diffusion models, systematically support the empirical law that memorization time is proportional to the dataset size. Generalization vs. memorization is then best understood as a competition between time scales. We show that this phenomenology is recovered in diffusion models learning a simple probabilistic context-free grammar with random rules, where generalization corresponds to the hierarchical acquisition of deeper grammar rules as training time grows, and the generalization cost of early stopping can be characterized. We summarize these results in a phase diagram. Overall, our results support that a principled early-stopping criterion - scaling with dataset size - can effectively optimize generalization while avoiding memorization, with direct implications for hyperparameter transfer and privacy-sensitive applications.","authors":["Alessandro Favero","Antonio Sclocchi","Matthieu Wyart"],"url":"https://arxiv.org/abs/2505.16959"}
{"created":"2025-05-23","title":"A Formal Proof of Complexity Bounds on Diophantine Equations","abstract":"We present a universal construction of Diophantine equations with bounded complexity in Isabelle/HOL. This is a formalization of our own work in number theory.","authors":["Jonas Bayer","Marco David"],"url":"https://arxiv.org/abs/2505.16963"}
{"created":"2025-05-23","title":"MedFrameQA: A Multi-Image Medical VQA Benchmark for Clinical Reasoning","abstract":"Existing medical VQA benchmarks mostly focus on single-image analysis, yet clinicians almost always compare a series of images before reaching a diagnosis. To better approximate this workflow, we introduce MedFrameQA -- the first benchmark that explicitly evaluates multi-image reasoning in medical VQA. To build MedFrameQA both at scale and in high-quality, we develop 1) an automated pipeline that extracts temporally coherent frames from medical videos and constructs VQA items whose content evolves logically across images, and 2) a multiple-stage filtering strategy, including model-based and manual review, to preserve data clarity, difficulty, and medical relevance. The resulting dataset comprises 2,851 VQA pairs (gathered from 9,237 high-quality frames in 3,420 videos), covering nine human body systems and 43 organs; every question is accompanied by two to five images. We comprehensively benchmark ten advanced Multimodal LLMs -- both proprietary and open source, with and without explicit reasoning modules -- on MedFrameQA. The evaluation challengingly reveals that all models perform poorly, with most accuracies below 50%, and accuracy fluctuates as the number of images per question increases. Error analysis further shows that models frequently ignore salient findings, mis-aggregate evidence across images, and propagate early mistakes through their reasoning chains; results also vary substantially across body systems, organs, and modalities. We hope this work can catalyze research on clinically grounded, multi-image reasoning and accelerate progress toward more capable diagnostic AI systems.","authors":["Suhao Yu","Haojin Wang","Juncheng Wu","Cihang Xie","Yuyin Zhou"],"url":"https://arxiv.org/abs/2505.16964"}
{"created":"2025-05-23","title":"BP-Seg: A graphical model approach to unsupervised and non-contiguous text segmentation using belief propagation","abstract":"Text segmentation based on the semantic meaning of sentences is a fundamental task with broad utility in many downstream applications. In this paper, we propose a graphical model-based unsupervised learning approach, named BP-Seg for efficient text segmentation. Our method not only considers local coherence, capturing the intuition that adjacent sentences are often more related, but also effectively groups sentences that are distant in the text yet semantically similar. This is achieved through belief propagation on the carefully constructed graphical models. Experimental results on both an illustrative example and a dataset with long-form documents demonstrate that our method performs favorably compared to competing approaches.","authors":["Fengyi Li","Kayhan Behdin","Natesh Pillai","Xiaofeng Wang","Zhipeng Wang","Ercan Yildiz"],"url":"https://arxiv.org/abs/2505.16965"}
{"created":"2025-05-23","title":"Modeling Inequality in Complex Networks of Strategic Agents using Iterative Game-Theoretic Transactions","abstract":"Transactions are an important aspect of human social life, and represent dynamic flow of information, intangible values, such as trust, as well as monetary and social capital. Although much research has been conducted on the nature of transactions in fields ranging from the social sciences to game theory, the systemic effects of different types of agents transacting in real-world social networks (often following a scale-free distribution) are not fully understood. A particular systemic measure that has not received adequate attention in the complex networks and game theory communities, is the Gini Coefficient, which is widely used in economics to quantify and understand wealth inequality. In part, the problem is a lack of experimentation using a replicable algorithm and publicly available data. Motivated by this problem, this article proposes a model and simulation algorithm, based on game theory, for quantifying the evolution of inequality in complex networks of strategic agents. Our results shed light on several complex drivers of inequality, even in simple, abstract settings, and exhibit consistency across networks with different origins and descriptions.","authors":["Mayank Kejriwal","Yuesheng Luo"],"url":"https://arxiv.org/abs/2505.16966"}
{"created":"2025-05-23","title":"Fixing Data That Hurts Performance: Cascading LLMs to Relabel Hard Negatives for Robust Information Retrieval","abstract":"Training robust retrieval and reranker models typically relies on large-scale retrieval datasets; for example, the BGE collection contains 1.6 million query-passage pairs sourced from various data sources. However, we find that certain datasets can negatively impact model effectiveness -- pruning 8 out of 15 datasets from the BGE collection reduces the training set size by 2.35$\\times$ and increases nDCG@10 on BEIR by 1.0 point. This motivates a deeper examination of training data quality, with a particular focus on \"false negatives\", where relevant passages are incorrectly labeled as irrelevant. We propose a simple, cost-effective approach using cascading LLM prompts to identify and relabel hard negatives. Experimental results show that relabeling false negatives with true positives improves both E5 (base) and Qwen2.5-7B retrieval models by 0.7-1.4 nDCG@10 on BEIR and by 1.7-1.8 nDCG@10 on zero-shot AIR-Bench evaluation. Similar gains are observed for rerankers fine-tuned on the relabeled data, such as Qwen2.5-3B on BEIR. The reliability of the cascading design is further supported by human annotation results, where we find judgment by GPT-4o shows much higher agreement with humans than GPT-4o-mini.","authors":["Nandan Thakur","Crystina Zhang","Xueguang Ma","Jimmy Lin"],"url":"https://arxiv.org/abs/2505.16967"}
{"created":"2025-05-23","title":"CASS: Nvidia to AMD Transpilation with Data, Models, and Benchmark","abstract":"We introduce \\texttt{CASS}, the first large-scale dataset and model suite for cross-architecture GPU code transpilation, targeting both source-level (CUDA~$\\leftrightarrow$~HIP) and assembly-level (Nvidia SASS~$\\leftrightarrow$~AMD RDNA3) translation. The dataset comprises 70k verified code pairs across host and device, addressing a critical gap in low-level GPU code portability. Leveraging this resource, we train the \\texttt{CASS} family of domain-specific language models, achieving 95\\% source translation accuracy and 37.5\\% assembly translation accuracy, substantially outperforming commercial baselines such as GPT-4o, Claude, and Hipify. Our generated code matches native performance in over 85\\% of test cases, preserving runtime and memory behavior. To support rigorous evaluation, we introduce \\texttt{CASS-Bench}, a curated benchmark spanning 16 GPU domains with ground-truth execution. All data, models, and evaluation tools are released as open source to foster progress in GPU compiler tooling, binary compatibility, and LLM-guided hardware translation. Dataset and benchmark are on \\href{https://huggingface.co/datasets/MBZUAI/cass}{\\textcolor{blue}{HuggingFace}}, with code at \\href{https://github.com/GustavoStahl/CASS}{\\textcolor{blue}{GitHub}}.","authors":["Ahmed Heakl","Sarim Hashmi","Gustavo Bertolo Stahl","Seung Hun Eddie Han","Salman Khan","Abdulrahman Mahmoud"],"url":"https://arxiv.org/abs/2505.16968"}
{"created":"2025-05-23","title":"3D Equivariant Visuomotor Policy Learning via Spherical Projection","abstract":"Equivariant models have recently been shown to improve the data efficiency of diffusion policy by a significant margin. However, prior work that explored this direction focused primarily on point cloud inputs generated by multiple cameras fixed in the workspace. This type of point cloud input is not compatible with the now-common setting where the primary input modality is an eye-in-hand RGB camera like a GoPro. This paper closes this gap by incorporating into the diffusion policy model a process that projects features from the 2D RGB camera image onto a sphere. This enables us to reason about symmetries in SO(3) without explicitly reconstructing a point cloud. We perform extensive experiments in both simulation and the real world that demonstrate that our method consistently outperforms strong baselines in terms of both performance and sample efficiency. Our work is the first SO(3)-equivariant policy learning framework for robotic manipulation that works using only monocular RGB inputs.","authors":["Boce Hu","Dian Wang","David Klee","Heng Tian","Xupeng Zhu","Haojie Huang","Robert Platt","Robin Walters"],"url":"https://arxiv.org/abs/2505.16969"}
{"created":"2025-05-23","title":"UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation","abstract":"We propose UniPhy, a common latent-conditioned neural constitutive model that can encode the physical properties of diverse materials. At inference UniPhy allows `inverse simulation' i.e. inferring material properties by optimizing the scene-specific latent to match the available observations via differentiable simulation. In contrast to existing methods that treat such inference as system identification, UniPhy does not rely on user-specified material type information. Compared to prior neural constitutive modeling approaches which learn instance specific networks, the shared training across materials improves both, robustness and accuracy of the estimates. We train UniPhy using simulated trajectories across diverse geometries and materials -- elastic, plasticine, sand, and fluids (Newtonian & non-Newtonian). At inference, given an object with unknown material properties, UniPhy can infer the material properties via latent optimization to match the motion observations, and can then allow re-simulating the object under diverse scenarios. We compare UniPhy against prior inverse simulation methods, and show that the inference from UniPhy enables more accurate replay and re-simulation under novel conditions.","authors":["Himangi Mittal","Peiye Zhuang","Hsin-Ying Lee","Shubham Tulsiani"],"url":"https://arxiv.org/abs/2505.16971"}
{"created":"2025-05-23","title":"From Tens of Hours to Tens of Thousands: Scaling Back-Translation for Speech Recognition","abstract":"Recent advances in Automatic Speech Recognition (ASR) have been largely fueled by massive speech corpora. However, extending coverage to diverse languages with limited resources remains a formidable challenge. This paper introduces Speech Back-Translation, a scalable pipeline that improves multilingual ASR models by converting large-scale text corpora into synthetic speech via off-the-shelf text-to-speech (TTS) models. We demonstrate that just tens of hours of real transcribed speech can effectively train TTS models to generate synthetic speech at hundreds of times the original volume while maintaining high quality. To evaluate synthetic speech quality, we develop an intelligibility-based assessment framework and establish clear thresholds for when synthetic data benefits ASR training. Using Speech Back-Translation, we generate more than 500,000 hours of synthetic speech in ten languages and continue pre-training Whisper-large-v3, achieving average transcription error reductions of over 30\\%. These results highlight the scalability and effectiveness of Speech Back-Translation for enhancing multilingual ASR systems.","authors":["Tianduo Wang","Lu Xu","Wei Lu","Shanbo Cheng"],"url":"https://arxiv.org/abs/2505.16972"}
{"created":"2025-05-23","title":"VeriFastScore: Speeding up long-form factuality evaluation","abstract":"Metrics like FactScore and VeriScore that evaluate long-form factuality operate by decomposing an input response into atomic claims and then individually verifying each claim. While effective and interpretable, these methods incur numerous LLM calls and can take upwards of 100 seconds to evaluate a single response, limiting their practicality in large-scale evaluation and training scenarios. To address this, we propose VeriFastScore, which leverages synthetic data to fine-tune Llama3.1 8B for simultaneously extracting and verifying all verifiable claims within a given text based on evidence from Google Search. We show that this task cannot be solved via few-shot prompting with closed LLMs due to its complexity: the model receives ~4K tokens of evidence on average and needs to concurrently decompose claims, judge their verifiability, and verify them against noisy evidence. However, our fine-tuned VeriFastScore model demonstrates strong correlation with the original VeriScore pipeline at both the example level (r=0.80) and system level (r=0.94) while achieving an overall speedup of 6.6x (9.9x excluding evidence retrieval) over VeriScore. To facilitate future factuality research, we publicly release our VeriFastScore model and synthetic datasets.","authors":["Rishanth Rajendhran","Amir Zadeh","Matthew Sarte","Chuan Li","Mohit Iyyer"],"url":"https://arxiv.org/abs/2505.16973"}
{"created":"2025-05-23","title":"OpenSeg-R: Improving Open-Vocabulary Segmentation via Step-by-Step Visual Reasoning","abstract":"Open-Vocabulary Segmentation (OVS) has drawn increasing attention for its capacity to generalize segmentation beyond predefined categories. However, existing methods typically predict segmentation masks with simple forward inference, lacking explicit reasoning and interpretability. This makes it challenging for OVS model to distinguish similar categories in open-world settings due to the lack of contextual understanding and discriminative visual cues. To address this limitation, we propose a step-by-step visual reasoning framework for open-vocabulary segmentation, named OpenSeg-R. The proposed OpenSeg-R leverages Large Multimodal Models (LMMs) to perform hierarchical visual reasoning before segmentation. Specifically, we generate both generic and image-specific reasoning for each image, forming structured triplets that explain the visual reason for objects in a coarse-to-fine manner. Based on these reasoning steps, we can compose detailed description prompts, and feed them to the segmentor to produce more accurate segmentation masks. To the best of our knowledge, OpenSeg-R is the first framework to introduce explicit step-by-step visual reasoning into OVS. Experimental results demonstrate that OpenSeg-R significantly outperforms state-of-the-art methods on open-vocabulary semantic segmentation across five benchmark datasets. Moreover, it achieves consistent gains across all metrics on open-vocabulary panoptic segmentation. Qualitative results further highlight the effectiveness of our reasoning-guided framework in improving both segmentation precision and interpretability. Our code is publicly available at https://github.com/Hanzy1996/OpenSeg-R.","authors":["Zongyan Han","Jiale Cao","Shuo Chen","Tong Wang","Jorma Laaksonen","Rao Muhammad Anwer"],"url":"https://arxiv.org/abs/2505.16974"}
{"created":"2025-05-23","title":"SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development","abstract":"Large Language Models (LLMs) have shown strong capability in diverse software engineering tasks, e.g. code completion, bug fixing, and document generation. However, feature-driven development (FDD), a highly prevalent real-world task that involves developing new functionalities for large, existing codebases, remains underexplored. We therefore introduce SWE-Dev, the first large-scale dataset (with 14,000 training and 500 test samples) designed to evaluate and train autonomous coding systems on real-world feature development tasks. To ensure verifiable and diverse training, SWE-Dev uniquely provides all instances with a runnable environment and its developer-authored executable unit tests. This collection not only provides high-quality data for Supervised Fine-Tuning (SFT), but also enables Reinforcement Learning (RL) by delivering accurate reward signals from executable unit tests. Our extensive evaluations on SWE-Dev, covering 17 chatbot LLMs, 10 reasoning models, and 10 Multi-Agent Systems (MAS), reveal that FDD is a profoundly challenging frontier for current AI (e.g., Claude-3.7-Sonnet achieves only 22.45\\% Pass@3 on the hard test split). Crucially, we demonstrate that SWE-Dev serves as an effective platform for model improvement: fine-tuning on training set enabled a 7B model comparable to GPT-4o on \\textit{hard} split, underscoring the value of its high-quality training data. Code is available here \\href{https://github.com/justLittleWhite/SWE-Dev}{https://github.com/justLittleWhite/SWE-Dev}.","authors":["Yaxin Du","Yuzhu Cai","Yifan Zhou","Cheng Wang","Yu Qian","Xianghe Pang","Qian Liu","Yue Hu","Siheng Chen"],"url":"https://arxiv.org/abs/2505.16975"}
{"created":"2025-05-23","title":"Creatively Upscaling Images with Global-Regional Priors","abstract":"Contemporary diffusion models show remarkable capability in text-to-image generation, while still being limited to restricted resolutions (e.g., 1,024 X 1,024). Recent advances enable tuning-free higher-resolution image generation by recycling pre-trained diffusion models and extending them via regional denoising or dilated sampling/convolutions. However, these models struggle to simultaneously preserve global semantic structure and produce creative regional details in higher-resolution images. To address this, we present C-Upscale, a new recipe of tuning-free image upscaling that pivots on global-regional priors derived from given global prompt and estimated regional prompts via Multimodal LLM. Technically, the low-frequency component of low-resolution image is recognized as global structure prior to encourage global semantic consistency in high-resolution generation. Next, we perform regional attention control to screen cross-attention between global prompt and each region during regional denoising, leading to regional attention prior that alleviates object repetition issue. The estimated regional prompts containing rich descriptive details further act as regional semantic prior to fuel the creativity of regional detail generation. Both quantitative and qualitative evaluations demonstrate that our C-Upscale manages to generate ultra-high-resolution images (e.g., 4,096 X 4,096 and 8,192 X 8,192) with higher visual fidelity and more creative regional details.","authors":["Yurui Qian","Qi Cai","Yingwei Pan","Ting Yao","Tao Mei"],"url":"https://arxiv.org/abs/2505.16976"}
{"created":"2025-05-23","title":"Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On","abstract":"Diffusion models have shown preliminary success in virtual try-on (VTON) task. The typical dual-branch architecture comprises two UNets for implicit garment deformation and synthesized image generation respectively, and has emerged as the recipe for VTON task. Nevertheless, the problem remains challenging to preserve the shape and every detail of the given garment due to the intrinsic stochasticity of diffusion model. To alleviate this issue, we novelly propose to explicitly capitalize on visual correspondence as the prior to tame diffusion process instead of simply feeding the whole garment into UNet as the appearance reference. Specifically, we interpret the fine-grained appearance and texture details as a set of structured semantic points, and match the semantic points rooted in garment to the ones over target person through local flow warping. Such 2D points are then augmented into 3D-aware cues with depth/normal map of target person. The correspondence mimics the way of putting clothing on human body and the 3D-aware cues act as semantic point matching to supervise diffusion model training. A point-focused diffusion loss is further devised to fully take the advantage of semantic point matching. Extensive experiments demonstrate strong garment detail preservation of our approach, evidenced by state-of-the-art VTON performances on both VITON-HD and DressCode datasets. Code is publicly available at: https://github.com/HiDream-ai/SPM-Diff.","authors":["Siqi Wan","Jingwen Chen","Yingwei Pan","Ting Yao","Tao Mei"],"url":"https://arxiv.org/abs/2505.16977"}
{"created":"2025-05-23","title":"HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation","abstract":"Grammar plays a critical role in natural language processing and text/code generation by enabling the definition of syntax, the creation of parsers, and guiding structured outputs. Although large language models (LLMs) demonstrate impressive capabilities across domains, their ability to infer and generate grammars has not yet been thoroughly explored. In this paper, we aim to study and improve the ability of LLMs for few-shot grammar generation, where grammars are inferred from sets of a small number of positive and negative examples and generated in Backus-Naur Form. To explore this, we introduced a novel dataset comprising 540 structured grammar generation challenges, devised 6 metrics, and evaluated 8 various LLMs against it. Our findings reveal that existing LLMs perform sub-optimally in grammar generation. To address this, we propose an LLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar generation. HyGenar achieves substantial improvements in both the syntactic and semantic correctness of generated grammars across LLMs.","authors":["Weizhi Tang","Yixuan Li","Chris Sypherd","Elizabeth Polgreen","Vaishak Belle"],"url":"https://arxiv.org/abs/2505.16978"}
{"created":"2025-05-23","title":"Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design","abstract":"Single-agent LLMs hit hard limits--finite context, role overload, and brittle domain transfer. Conventional multi-agent fixes soften those edges yet expose fresh pains: ill-posed decompositions, fuzzy contracts, and verification overhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a framework that converts domain priors into an algorithmic blueprint hierarchy, in which tasks are recursively split into typed, controller-mediated subtasks, each solved zero-shot or with the lightest viable boost (e.g., chain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch theorem, KtR trades the chase for a universal prompt for disciplined decomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents raise accuracy from 3% zero-shot to 95% on size-5 instances after patching a single bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a six-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15, versus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation thus turns modest models into reliable collaborators--no ever-larger monoliths required.","authors":["Zhenkun Li","Lingyao Li","Shuhang Lin","Yongfeng Zhang"],"url":"https://arxiv.org/abs/2505.16979"}
{"created":"2025-05-23","title":"Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction","abstract":"Video virtual try-on aims to seamlessly dress a subject in a video with a specific garment. The primary challenge involves preserving the visual authenticity of the garment while dynamically adapting to the pose and physique of the subject. While existing methods have predominantly focused on image-based virtual try-on, extending these techniques directly to videos often results in temporal inconsistencies. Most current video virtual try-on approaches alleviate this challenge by incorporating temporal modules, yet still overlook the critical spatiotemporal pose interactions between human and garment. Effective pose interactions in videos should not only consider spatial alignment between human and garment poses in each frame but also account for the temporal dynamics of human poses throughout the entire video. With such motivation, we propose a new framework, namely Dynamic Pose Interaction Diffusion Models (DPIDM), to leverage diffusion models to delve into dynamic pose interactions for video virtual try-on. Technically, DPIDM introduces a skeleton-based pose adapter to integrate synchronized human and garment poses into the denoising network. A hierarchical attention module is then exquisitely designed to model intra-frame human-garment pose interactions and long-term human pose dynamics across frames through pose-aware spatial and temporal attention mechanisms. Moreover, DPIDM capitalizes on a temporal regularized attention loss between consecutive frames to enhance temporal consistency. Extensive experiments conducted on VITON-HD, VVT and ViViD datasets demonstrate the superiority of our DPIDM against the baseline methods. Notably, DPIDM achieves VFID score of 0.506 on VVT dataset, leading to 60.5% improvement over the state-of-the-art GPD-VVTO approach.","authors":["Dong Li","Wenqi Zhong","Wei Yu","Yingwei Pan","Dingwen Zhang","Ting Yao","Junwei Han","Tao Mei"],"url":"https://arxiv.org/abs/2505.16980"}
{"created":"2025-05-23","title":"Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine","abstract":"Large Language Models (LLMs) show promise in biomedicine but lack true causal understanding, relying instead on correlations. This paper envisions causal LLM agents that integrate multimodal data (text, images, genomics, etc.) and perform intervention-based reasoning to infer cause-and-effect. Addressing this requires overcoming key challenges: designing safe, controllable agentic frameworks; developing rigorous benchmarks for causal evaluation; integrating heterogeneous data sources; and synergistically combining LLMs with structured knowledge (KGs) and formal causal inference tools. Such agents could unlock transformative opportunities, including accelerating drug discovery through automated hypothesis generation and simulation, enabling personalized medicine through patient-specific causal models. This research agenda aims to foster interdisciplinary efforts, bridging causal concepts and foundation models to develop reliable AI partners for biomedical progress.","authors":["Adib Bazgir","Amir Habibdoust Lafmajani","Yuwen Zhang"],"url":"https://arxiv.org/abs/2505.16982"}
{"created":"2025-05-23","title":"LLM as Effective Streaming Processor: Bridging Streaming-Batch Mismatches with Group Position Encoding","abstract":"Large Language Models (LLMs) are primarily designed for batch processing. Existing methods for adapting LLMs to streaming rely either on expensive re-encoding or specialized architectures with limited scalability. This work identifies three key mismatches in adapting batch-oriented LLMs to streaming: (1) input-attention, (2) output-attention, and (3) position-ID mismatches. While it is commonly assumed that the latter two mismatches require frequent re-encoding, our analysis reveals that only the input-attention mismatch significantly impacts performance, indicating re-encoding outputs is largely unnecessary. To better understand this discrepancy with the common assumption, we provide the first comprehensive analysis of the impact of position encoding on LLMs in streaming, showing that preserving relative positions within source and target contexts is more critical than maintaining absolute order. Motivated by the above analysis, we introduce a group position encoding paradigm built on batch architectures to enhance consistency between streaming and batch modes. Extensive experiments on cross-lingual and cross-modal tasks demonstrate that our method outperforms existing approaches. Our method requires no architectural modifications, exhibits strong generalization in both streaming and batch modes. The code is available at repository https://github.com/EIT-NLP/StreamingLLM.","authors":["Junlong Tong","Jinlan Fu","Zixuan Lin","Yingqi Fan","Anhao Zhao","Hui Su","Xiaoyu Shen"],"url":"https://arxiv.org/abs/2505.16983"}
{"created":"2025-05-23","title":"UFT: Unifying Supervised and Reinforcement Fine-Tuning","abstract":"Post-training has demonstrated its importance in enhancing the reasoning capabilities of large language models (LLMs). The primary post-training methods can be categorized into supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). SFT is efficient and well-suited for small language models, but it may lead to overfitting and limit the reasoning abilities of larger models. In contrast, RFT generally yields better generalization but depends heavily on the strength of the base model. To address the limitations of SFT and RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm that unifies SFT and RFT into a single, integrated process. UFT enables the model to effectively explore solutions while incorporating informative supervision signals, bridging the gap between memorizing and thinking underlying existing methods. Notably, UFT outperforms both SFT and RFT in general, regardless of model sizes. Furthermore, we theoretically prove that UFT breaks RFT's inherent exponential sample complexity bottleneck, showing for the first time that unified training can exponentially accelerate convergence on long-horizon reasoning tasks.","authors":["Mingyang Liu","Gabriele Farina","Asuman Ozdaglar"],"url":"https://arxiv.org/abs/2505.16984"}
{"created":"2025-05-23","title":"Extremely Simple Multimodal Outlier Synthesis for Out-of-Distribution Detection and Segmentation","abstract":"Out-of-distribution (OOD) detection and segmentation are crucial for deploying machine learning models in safety-critical applications such as autonomous driving and robot-assisted surgery. While prior research has primarily focused on unimodal image data, real-world applications are inherently multimodal, requiring the integration of multiple modalities for improved OOD detection. A key challenge is the lack of supervision signals from unknown data, leading to overconfident predictions on OOD samples. To address this challenge, we propose Feature Mixing, an extremely simple and fast method for multimodal outlier synthesis with theoretical support, which can be further optimized to help the model better distinguish between in-distribution (ID) and OOD data. Feature Mixing is modality-agnostic and applicable to various modality combinations. Additionally, we introduce CARLA-OOD, a novel multimodal dataset for OOD segmentation, featuring synthetic OOD objects across diverse scenes and weather conditions. Extensive experiments on SemanticKITTI, nuScenes, CARLA-OOD datasets, and the MultiOOD benchmark demonstrate that Feature Mixing achieves state-of-the-art performance with a $10 \\times$ to $370 \\times$ speedup. Our source code and dataset will be available at https://github.com/mona4399/FeatureMixing.","authors":["Moru Liu","Hao Dong","Jessica Kelly","Olga Fink","Mario Trapp"],"url":"https://arxiv.org/abs/2505.16985"}
{"created":"2025-05-23","title":"T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning","abstract":"Large Language Models (LLMs) have demonstrated impressive capabilities as intelligent agents capable of solving complex problems. However, effective planning in scenarios involving dependencies between API or tool calls-particularly in multi-turn conversations-remains a significant challenge. To address this, we introduce T1, a tool-augmented, multi-domain, multi-turn conversational dataset specifically designed to capture and manage inter-tool dependencies across diverse domains. T1 enables rigorous evaluation of agents' ability to coordinate tool use across nine distinct domains (4 single domain and 5 multi-domain) with the help of an integrated caching mechanism for both short- and long-term memory, while supporting dynamic replanning-such as deciding whether to recompute or reuse cached results. Beyond facilitating research on tool use and planning, T1 also serves as a benchmark for evaluating the performance of open-source language models. We present results powered by T1-Agent, highlighting their ability to plan and reason in complex, tool-dependent scenarios.","authors":["Amartya Chakraborty","Paresh Dashore","Nadia Bathaee","Anmol Jain","Anirban Das","Shi-Xiong Zhang","Sambit Sahu","Milind Naphade","Genta Indra Winata"],"url":"https://arxiv.org/abs/2505.16986"}
{"created":"2025-05-23","title":"MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems","abstract":"LLM-based multi-agent systems (MAS) have demonstrated significant potential in enhancing single LLMs to address complex and diverse tasks in practical applications. Despite considerable advancements, the field lacks a unified codebase that consolidates existing methods, resulting in redundant re-implementation efforts, unfair comparisons, and high entry barriers for researchers. To address these challenges, we introduce MASLab, a unified, comprehensive, and research-friendly codebase for LLM-based MAS. (1) MASLab integrates over 20 established methods across multiple domains, each rigorously validated by comparing step-by-step outputs with its official implementation. (2) MASLab provides a unified environment with various benchmarks for fair comparisons among methods, ensuring consistent inputs and standardized evaluation protocols. (3) MASLab implements methods within a shared streamlined structure, lowering the barriers for understanding and extension. Building on MASLab, we conduct extensive experiments covering 10+ benchmarks and 8 models, offering researchers a clear and comprehensive view of the current landscape of MAS methods. MASLab will continue to evolve, tracking the latest developments in the field, and invite contributions from the broader open-source community.","authors":["Rui Ye","Keduan Huang","Qimin Wu","Yuzhu Cai","Tian Jin","Xianghe Pang","Xiangrui Liu","Jiaqi Su","Chen Qian","Bohan Tang","Kaiqu Liang","Jiaao Chen","Yue Hu","Zhenfei Yin","Rongye Shi","Bo An","Yang Gao","Wenjun Wu","Lei Bai","Siheng Chen"],"url":"https://arxiv.org/abs/2505.16988"}
{"created":"2025-05-23","title":"Dimple: Discrete Diffusion Multimodal Large Language Model with Parallel Decoding","abstract":"In this work, we propose Dimple, the first Discrete Diffusion Multimodal Large Language Model (DMLLM). We observe that training with a purely discrete diffusion approach leads to significant training instability, suboptimal performance, and severe length bias issues. To address these challenges, we design a novel training paradigm that combines an initial autoregressive phase with a subsequent diffusion phase. This approach yields the Dimple-7B model, trained on the same dataset and using a similar training pipeline as LLaVA-NEXT. Dimple-7B ultimately surpasses LLaVA-NEXT in performance by 3.9%, demonstrating that DMLLM can achieve performance comparable to that of autoregressive models. To improve inference efficiency, we propose a decoding strategy termed confident decoding, which dynamically adjusts the number of tokens generated at each step, significantly reducing the number of generation iterations. In autoregressive models, the number of forward iterations during generation equals the response length. With confident decoding, however, the number of iterations needed by Dimple is even only $\\frac{\\text{response length}}{3}$. We also re-implement the prefilling technique in autoregressive models and demonstrate that it does not significantly impact performance on most benchmark evaluations, while offering a speedup of 1.5x to 7x. Additionally, we explore Dimple's capability to precisely control its response using structure priors. These priors enable structured responses in a manner distinct from instruction-based or chain-of-thought prompting, and allow fine-grained control over response format and length, which is difficult to achieve in autoregressive models. Overall, this work validates the feasibility and advantages of DMLLM and enhances its inference efficiency and controllability. Code and models are available at https://github.com/yu-rp/Dimple.","authors":["Runpeng Yu","Xinyin Ma","Xinchao Wang"],"url":"https://arxiv.org/abs/2505.16990"}
{"created":"2025-05-23","title":"An Effective Training Framework for Light-Weight Automatic Speech Recognition Models","abstract":"Recent advancement in deep learning encouraged developing large automatic speech recognition (ASR) models that achieve promising results while ignoring computational and memory constraints. However, deploying such models on low resource devices is impractical despite of their favorable performance. Existing approaches (pruning, distillation, layer skip etc.) transform the large models into smaller ones at the cost of significant performance degradation or require prolonged training of smaller models for better performance. To address these issues, we introduce an efficacious two-step representation learning based approach capable of producing several small sized models from a single large model ensuring considerably better performance in limited number of epochs. Comprehensive experimentation on ASR benchmarks reveals the efficacy of our approach, achieving three-fold training speed-up and up to 12.54% word error rate improvement.","authors":["Abdul Hannan","Alessio Brutti","Shah Nawaz","Mubashir Noman"],"url":"https://arxiv.org/abs/2505.16991"}
{"created":"2025-05-23","title":"PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics","abstract":"Despite decades of advancements, the simulation of fluids remains one of the most challenging areas of in scientific computing. Supported by the necessity of gradient information in deep learning, differentiable simulators have emerged as an effective tool for optimization and learning in physics simulations. In this work, we present our fluid simulator PICT, a differentiable pressure-implicit solver coded in PyTorch with Graphics-processing-unit (GPU) support. We first verify the accuracy of both the forward simulation and our derived gradients in various established benchmarks like lid-driven cavities and turbulent channel flows before we show that the gradients provided by our solver can be used to learn complicated turbulence models in 2D and 3D. We apply both supervised and unsupervised training regimes using physical priors to match flow statistics. In particular, we learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow purely based on reference statistics. The low-resolution corrector trained with our solver runs substantially faster than the highly resolved references, while keeping or even surpassing their accuracy. Finally, we give additional insights into the physical interpretation of different solver gradients, and motivate a physically informed regularization technique. To ensure that the full potential of PICT can be leveraged, it is published as open source: https://github.com/tum-pbs/PICT.","authors":["Aleksandra Franz","Hao Wei","Luca Guastoni","Nils Thuerey"],"url":"https://arxiv.org/abs/2505.16992"}
{"created":"2025-05-23","title":"Native Segmentation Vision Transformers","abstract":"Uniform downsampling remains the de facto standard for reducing spatial resolution in vision backbones. In this work, we propose an alternative design built around a content-aware spatial grouping layer, that dynamically assigns tokens to a reduced set based on image boundaries and their semantic content. Stacking our grouping layer across consecutive backbone stages results in hierarchical segmentation that arises natively in the feature extraction process, resulting in our coined Native Segmentation Vision Transformer. We show that a careful design of our architecture enables the emergence of strong segmentation masks solely from grouping layers, that is, without additional segmentation-specific heads. This sets the foundation for a new paradigm of native, backbone-level segmentation, which enables strong zero-shot results without mask supervision, as well as a minimal and efficient standalone model design for downstream segmentation tasks. Our project page is https://research.nvidia.com/labs/dvl/projects/native-segmentation.","authors":["Guillem Bras\\'o","Aljo\\v{s}a O\\v{s}ep","Laura Leal-Taix\\'e"],"url":"https://arxiv.org/abs/2505.16993"}
{"created":"2025-05-23","title":"$\\text{R}^2\\text{ec}$: Towards Large Recommender Models with Reasoning","abstract":"Large recommender models have extended LLMs as powerful recommenders via encoding or item generation, and recent breakthroughs in LLM reasoning synchronously motivate the exploration of reasoning in recommendation. Current studies usually position LLMs as external reasoning modules to yield auxiliary thought for augmenting conventional recommendation pipelines. However, such decoupled designs are limited in significant resource cost and suboptimal joint optimization. To address these issues, we propose \\name, a unified large recommender model with intrinsic reasoning capabilities. Initially, we reconceptualize the model architecture to facilitate interleaved reasoning and recommendation in the autoregressive process. Subsequently, we propose RecPO, a corresponding reinforcement learning framework that optimizes \\name\\ both the reasoning and recommendation capabilities simultaneously in a single policy update; RecPO introduces a fused reward scheme that solely leverages recommendation labels to simulate the reasoning capability, eliminating dependency on specialized reasoning annotations. Experiments on three datasets with various baselines verify the effectiveness of \\name, showing relative improvements of 68.67\\% in Hit@5 and 45.21\\% in NDCG@20. Code available at https://github.com/YRYangang/RRec.","authors":["Runyang You","Yongqi Li","Xinyu Lin","Xin Zhang","Wenjie Wang","Wenjie Li","Liqiang Nie"],"url":"https://arxiv.org/abs/2505.16994"}
{"created":"2025-05-23","title":"DecoupledESC: Enhancing Emotional Support Generation via Strategy-Response Decoupled Preference Optimization","abstract":"Recent advances in Emotional Support Conversation (ESC) have improved emotional support generation by fine-tuning Large Language Models (LLMs) via Supervised Fine-Tuning (SFT). However, common psychological errors still persist. While Direct Preference Optimization (DPO) shows promise in reducing such errors through pairwise preference learning, its effectiveness in ESC tasks is limited by two key challenges: (1) Entangled data structure: Existing ESC data inherently entangles psychological strategies and response content, making it difficult to construct high-quality preference pairs; and (2) Optimization ambiguity: Applying vanilla DPO to such entangled pairwise data leads to ambiguous training objectives. To address these issues, we introduce Inferential Preference Mining (IPM) to construct high-quality preference data, forming the IPM-PrefDial dataset. Building upon this data, we propose a Decoupled ESC framework inspired by Gross's Extended Process Model of Emotion Regulation, which decomposes the ESC task into two sequential subtasks: strategy planning and empathic response generation. Each was trained via SFT and subsequently enhanced by DPO to align with the psychological preference. Extensive experiments demonstrate that our Decoupled ESC framework outperforms joint optimization baselines, reducing preference bias and improving response quality.","authors":["Chao Zhang","Xin Shi","Xueqiao Zhang","Yifan Zhu","Yi Yang","Yawei Luo"],"url":"https://arxiv.org/abs/2505.16995"}
{"created":"2025-05-23","title":"A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations","abstract":"Inverse problems involving differential equations often require identifying unknown parameters or functions from data. Existing approaches, such as Physics-Informed Neural Networks (PINNs), Universal Differential Equations (UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective at isolating either parameters or functions but can face challenges when applied simultaneously due to solution non-uniqueness. In this work, we introduce a framework that addresses these limitations by establishing conditions under which unique solutions can be guaranteed. To illustrate, we apply it to examples from biological systems and ecological dynamics, demonstrating accurate and interpretable results. Our approach significantly enhances the potential of machine learning techniques in modeling complex systems in science and engineering.","authors":["Shalev Manor","Mohammad Kohandel"],"url":"https://arxiv.org/abs/2505.16996"}
{"created":"2025-05-23","title":"X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs","abstract":"LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by enabling cooperation among multiple specialized agents. However, most existing MAS frameworks rely on a single LLM to drive all agents, constraining the system's intelligence to the limit of that model. This paper explores the paradigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by diverse LLMs, elevating the system's potential to the collective intelligence of diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to evaluate the performance of various LLMs across different domains and MAS-related functions. As an extensive empirical study, we assess 27 LLMs across 5 domains (encompassing 21 test sets) and 5 functions, conducting over 1.7 million evaluations to identify optimal model selections for each domain-function combination. Building on these findings, we demonstrate that transitioning from homogeneous to heterogeneous LLM-driven MAS can significantly enhance system performance without requiring structural redesign. Specifically, in a chatbot-only MAS scenario, the heterogeneous configuration yields up to 8.4\\% performance improvement on the MATH dataset. In a mixed chatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable 47\\% performance boost on the AIME dataset. Our results underscore the transformative potential of heterogeneous LLMs in MAS, highlighting a promising avenue for advancing scalable, collaborative AI systems.","authors":["Rui Ye","Xiangrui Liu","Qimin Wu","Xianghe Pang","Zhenfei Yin","Lei Bai","Siheng Chen"],"url":"https://arxiv.org/abs/2505.16997"}
{"created":"2025-05-23","title":"Do Large Language Models Excel in Complex Logical Reasoning with Formal Language?","abstract":"Large Language Models (LLMs) have been shown to achieve breakthrough performance on complex logical reasoning tasks. Nevertheless, most existing research focuses on employing formal language to guide LLMs to derive reliable reasoning paths, while systematic evaluations of these capabilities are still limited. In this paper, we aim to conduct a comprehensive evaluation of LLMs across various logical reasoning problems utilizing formal languages. From the perspective of three dimensions, i.e., spectrum of LLMs, taxonomy of tasks, and format of trajectories, our key findings are: 1) Thinking models significantly outperform Instruct models, especially when formal language is employed; 2) All LLMs exhibit limitations in inductive reasoning capability, irrespective of whether they use a formal language; 3) Data with PoT format achieves the best generalization performance across other languages. Additionally, we also curate the formal-relative training data to further enhance the small language models, and the experimental results indicate that a simple rejected fine-tuning method can better enable LLMs to generalize across formal languages and achieve the best overall performance. Our codes and reports are available at https://github.com/jiangjin1999/FormalEval.","authors":["Jin Jiang","Jianing Wang","Yuchen Yan","Yang Liu","Jianhua Zhu","Mengdi Zhang","Xunliang Cai","Liangcai Gao"],"url":"https://arxiv.org/abs/2505.16998"}
{"created":"2025-05-23","title":"Seeing through Satellite Images at Street Views","abstract":"This paper studies the task of SatStreet-view synthesis, which aims to render photorealistic street-view panorama images and videos given any satellite image and specified camera positions or trajectories. We formulate to learn neural radiance field from paired images captured from satellite and street viewpoints, which comes to be a challenging learning problem due to the sparse-view natural and the extremely-large viewpoint changes between satellite and street-view images. We tackle the challenges based on a task-specific observation that street-view specific elements, including the sky and illumination effects are only visible in street-view panoramas, and present a novel approach Sat2Density++ to accomplish the goal of photo-realistic street-view panoramas rendering by modeling these street-view specific in neural networks. In the experiments, our method is testified on both urban and suburban scene datasets, demonstrating that Sat2Density++ is capable of rendering photorealistic street-view panoramas that are consistent across multiple views and faithful to the satellite image.","authors":["Ming Qian","Bin Tan","Qiuyu Wang","Xianwei Zheng","Hanjiang Xiong","Gui-Song Xia","Yujun Shen","Nan Xue"],"url":"https://arxiv.org/abs/2505.17001"}
{"created":"2025-05-23","title":"PAEFF: Precise Alignment and Enhanced Gated Feature Fusion for Face-Voice Association","abstract":"We study the task of learning association between faces and voices, which is gaining interest in the multimodal community lately. These methods suffer from the deliberate crafting of negative mining procedures as well as the reliance on the distant margin parameter. These issues are addressed by learning a joint embedding space in which orthogonality constraints are applied to the fused embeddings of faces and voices. However, embedding spaces of faces and voices possess different characteristics and require spaces to be aligned before fusing them. To this end, we propose a method that accurately aligns the embedding spaces and fuses them with an enhanced gated fusion thereby improving the performance of face-voice association. Extensive experiments on the VoxCeleb dataset reveals the merits of the proposed approach.","authors":["Abdul Hannan","Muhammad Arslan Manzoor","Shah Nawaz","Muhammad Irzam Liaqat","Markus Schedl","Mubashir Noman"],"url":"https://arxiv.org/abs/2505.17002"}
{"created":"2025-05-23","title":"Guided Diffusion Sampling on Function Spaces with Applications to PDEs","abstract":"We propose a general framework for conditional sampling in PDE-based inverse problems, targeting the recovery of whole solutions from extremely sparse or noisy measurements. This is accomplished by a function-space diffusion model and plug-and-play guidance for conditioning. Our method first trains an unconditional discretization-agnostic denoising model using neural operator architectures. At inference, we refine the samples to satisfy sparse observation data via a gradient-based guidance mechanism. Through rigorous mathematical analysis, we extend Tweedie's formula to infinite-dimensional Hilbert spaces, providing the theoretical foundation for our posterior sampling approach. Our method (FunDPS) accurately captures posterior distributions in function spaces under minimal supervision and severe data scarcity. Across five PDE tasks with only 3% observation, our method achieves an average 32% accuracy improvement over state-of-the-art fixed-resolution diffusion baselines while reducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning ensures strong cross-resolution generalizability. To the best of our knowledge, this is the first diffusion-based framework to operate independently of discretization, offering a practical and flexible solution for forward and inverse problems in the context of PDEs. Code is available at https://github.com/neuraloperator/FunDPS","authors":["Jiachen Yao","Abbas Mammadov","Julius Berner","Gavin Kerrigan","Jong Chul Ye","Kamyar Azizzadenesheli","Anima Anandkumar"],"url":"https://arxiv.org/abs/2505.17004"}
{"created":"2025-05-23","title":"R1-Searcher++: Incentivizing the Dynamic Knowledge Acquisition of LLMs via Reinforcement Learning","abstract":"Large Language Models (LLMs) are powerful but prone to hallucinations due to static knowledge. Retrieval-Augmented Generation (RAG) helps by injecting external information, but current methods often are costly, generalize poorly, or ignore the internal knowledge of the model. In this paper, we introduce R1-Searcher++, a novel framework designed to train LLMs to adaptively leverage both internal and external knowledge sources. R1-Searcher++ employs a two-stage training strategy: an initial SFT Cold-start phase for preliminary format learning, followed by RL for Dynamic Knowledge Acquisition. The RL stage uses outcome-supervision to encourage exploration, incorporates a reward mechanism for internal knowledge utilization, and integrates a memorization mechanism to continuously assimilate retrieved information, thereby enriching the model's internal knowledge. By leveraging internal knowledge and external search engine, the model continuously improves its capabilities, enabling efficient retrieval-augmented reasoning. Our experiments demonstrate that R1-Searcher++ outperforms previous RAG and reasoning methods and achieves efficient retrieval. The code is available at https://github.com/RUCAIBox/R1-Searcher-plus.","authors":["Huatong Song","Jinhao Jiang","Wenqing Tian","Zhipeng Chen","Yuhuan Wu","Jiahao Zhao","Yingqian Min","Wayne Xin Zhao","Lei Fang","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.17005"}
{"created":"2025-05-23","title":"CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning","abstract":"Learning latent motion from Internet videos is crucial for building generalist robots. However, existing discrete latent action methods suffer from information loss and struggle with complex and fine-grained dynamics. We propose CoMo, which aims to learn more informative continuous motion representations from diverse, internet-scale videos. CoMo employs a early temporal feature difference mechanism to prevent model collapse and suppress static appearance noise, effectively discouraging shortcut learning problem. Furthermore, guided by the information bottleneck principle, we constrain the latent motion embedding dimensionality to achieve a better balance between retaining sufficient action-relevant information and minimizing the inclusion of action-irrelevant appearance noise. Additionally, we also introduce two new metrics for more robustly and affordably evaluating motion and guiding motion learning methods development: (i) the linear probing MSE of action prediction, and (ii) the cosine similarity between past-to-current and future-to-current motion embeddings. Critically, CoMo exhibits strong zero-shot generalization, enabling it to generate continuous pseudo actions for previously unseen video domains. This capability facilitates unified policy joint learning using pseudo actions derived from various action-less video datasets (such as cross-embodiment videos and, notably, human demonstration videos), potentially augmented with limited labeled robot data. Extensive experiments show that policies co-trained with CoMo pseudo actions achieve superior performance with both diffusion and autoregressive architectures in simulated and real-world settings.","authors":["Jiange Yang","Yansong Shi","Haoyi Zhu","Mingyu Liu","Kaijing Ma","Yating Wang","Gangshan Wu","Tong He","Limin Wang"],"url":"https://arxiv.org/abs/2505.17006"}
{"created":"2025-05-23","title":"Deep mineralogical segmentation of thin section images based on QEMSCAN maps","abstract":"Interpreting the mineralogical aspects of rock thin sections is an important task for oil and gas reservoirs evaluation. However, human analysis tend to be subjective and laborious. Technologies like QEMSCAN(R) are designed to automate the mineralogical mapping process, but also suffer from limitations like high monetary costs and time-consuming analysis. This work proposes a Convolutional Neural Network model for automatic mineralogical segmentation of thin section images of carbonate rocks. The model is able to mimic the QEMSCAN mapping itself in a low-cost, generalized and efficient manner. For this, the U-Net semantic segmentation architecture is trained on plane and cross polarized thin section images using the corresponding QEMSCAN maps as target, which is an approach not widely explored. The model was instructed to differentiate occurrences of Calcite, Dolomite, Mg-Clay Minerals, Quartz, Pores and the remaining mineral phases as an unique class named \"Others\", while it was validated on rock facies both seen and unseen during training, in order to address its generalization capability. Since the images and maps are provided in different resolutions, image registration was applied to align then spatially. The study reveals that the quality of the segmentation is very much dependent on these resolution differences and on the variety of learnable rock textures. However, it shows promising results, especially with regard to the proper delineation of minerals boundaries on solid textures and precise estimation of the minerals distributions, describing a nearly linear relationship between expected and predicted distributions, with coefficient of determination (R^2) superior to 0.97 for seen facies and 0.88 for unseen.","authors":["Jean Pablo Vieira de Mello","Matheus Augusto Alves Cuglieri","Leandro P. de Figueiredo","Fernando Bordignon","Marcelo Ramalho Albuquerque","Rodrigo Surmas","Bruno Cavalcanti de Paula"],"url":"https://arxiv.org/abs/2505.17008"}
{"created":"2025-05-23","title":"Understanding Prompt Tuning and In-Context Learning via Meta-Learning","abstract":"Prompting is one of the main ways to adapt a pretrained model to target tasks. Besides manually constructing prompts, many prompt optimization methods have been proposed in the literature. Method development is mainly empirically driven, with less emphasis on a conceptual understanding of prompting. In this paper we discuss how optimal prompting can be understood through a Bayesian view, which also implies some fundamental limitations of prompting that can only be overcome by tuning weights. The paper explains in detail how meta-trained neural networks behave as Bayesian predictors over the pretraining distribution, whose hallmark feature is rapid in-context adaptation. Optimal prompting can be studied formally as conditioning these Bayesian predictors, yielding criteria for target tasks where optimal prompting is and is not possible. We support the theory with educational experiments on LSTMs and Transformers, where we compare different versions of prefix-tuning and different weight-tuning methods. We also confirm that soft prefixes, which are sequences of real-valued vectors outside the token alphabet, can lead to very effective prompts for trained and even untrained networks by manipulating activations in ways that are not achievable by hard tokens. This adds an important mechanistic aspect beyond the conceptual Bayesian theory.","authors":["Tim Genewein","Kevin Wenliang Li","Jordi Grau-Moya","Anian Ruoss","Laurent Orseau","Marcus Hutter"],"url":"https://arxiv.org/abs/2505.17010"}
{"created":"2025-05-23","title":"Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space","abstract":"We propose AdapTok, an adaptive temporal causal video tokenizer that can flexibly allocate tokens for different frames based on video content. AdapTok is equipped with a block-wise masking strategy that randomly drops tail tokens of each block during training, and a block causal scorer to predict the reconstruction quality of video frames using different numbers of tokens. During inference, an adaptive token allocation strategy based on integer linear programming is further proposed to adjust token usage given predicted scores. Such design allows for sample-wise, content-aware, and temporally dynamic token allocation under a controllable overall budget. Extensive experiments for video reconstruction and generation on UCF-101 and Kinetics-600 demonstrate the effectiveness of our approach. Without additional image data, AdapTok consistently improves reconstruction quality and generation performance under different token budgets, allowing for more scalable and token-efficient generative video modeling.","authors":["Yan Li","Changyao Tian","Renqiu Xia","Ning Liao","Weiwei Guo","Junchi Yan","Hongsheng Li","Jifeng Dai","Hao Li","Xue Yang"],"url":"https://arxiv.org/abs/2505.17011"}
{"created":"2025-05-23","title":"SpatialScore: Towards Unified Evaluation for Multimodal Spatial Understanding","abstract":"Multimodal large language models (MLLMs) have achieved impressive success in question-answering tasks, yet their capabilities for spatial understanding are less explored. This work investigates a critical question: do existing MLLMs possess 3D spatial perception and understanding abilities? Concretely, we make the following contributions in this paper: (i) we introduce VGBench, a benchmark specifically designed to assess MLLMs for visual geometry perception, e.g., camera pose and motion estimation; (ii) we propose SpatialScore, the most comprehensive and diverse multimodal spatial understanding benchmark to date, integrating VGBench with relevant data from the other 11 existing datasets. This benchmark comprises 28K samples across various spatial understanding tasks, modalities, and QA formats, along with a carefully curated challenging subset, SpatialScore-Hard; (iii) we develop SpatialAgent, a novel multi-agent system incorporating 9 specialized tools for spatial understanding, supporting both Plan-Execute and ReAct reasoning paradigms; (iv) we conduct extensive evaluations to reveal persistent challenges in spatial reasoning while demonstrating the effectiveness of SpatialAgent. We believe SpatialScore will offer valuable insights and serve as a rigorous benchmark for the next evolution of MLLMs.","authors":["Haoning Wu","Xiao Huang","Yaohui Chen","Ya Zhang","Yanfeng Wang","Weidi Xie"],"url":"https://arxiv.org/abs/2505.17012"}
{"created":"2025-05-23","title":"When Are Concepts Erased From Diffusion Models?","abstract":"Concept erasure, the ability to selectively prevent a model from generating specific concepts, has attracted growing interest, with various approaches emerging to address the challenge. However, it remains unclear how thoroughly these methods erase the target concept. We begin by proposing two conceptual models for the erasure mechanism in diffusion models: (i) reducing the likelihood of generating the target concept, and (ii) interfering with the model's internal guidance mechanisms. To thoroughly assess whether a concept has been truly erased from the model, we introduce a suite of independent evaluations. Our evaluation framework includes adversarial attacks, novel probing techniques, and analysis of the model's alternative generations in place of the erased concept. Our results shed light on the tension between minimizing side effects and maintaining robustness to adversarial prompts. Broadly, our work underlines the importance of comprehensive evaluation for erasure in diffusion models.","authors":["Kevin Lu","Nicky Kriplani","Rohit Gandikota","Minh Pham","David Bau","Chinmay Hegde","Niv Cohen"],"url":"https://arxiv.org/abs/2505.17013"}
{"created":"2025-05-23","title":"Multi-SpatialMLLM: Multi-Frame Spatial Understanding with Multi-Modal Large Language Models","abstract":"Multi-modal large language models (MLLMs) have rapidly advanced in visual tasks, yet their spatial understanding remains limited to single images, leaving them ill-suited for robotics and other real-world applications that require multi-frame reasoning. In this paper, we propose a framework to equip MLLMs with robust multi-frame spatial understanding by integrating depth perception, visual correspondence, and dynamic perception. Central to our approach is the MultiSPA dataset, a novel, large-scale collection of more than 27 million samples spanning diverse 3D and 4D scenes. Alongside MultiSPA, we introduce a comprehensive benchmark that tests a wide spectrum of spatial tasks under uniform metrics. Our resulting model, Multi-SpatialMLLM, achieves significant gains over baselines and proprietary systems, demonstrating scalable, generalizable multi-frame reasoning. We further observe multi-task benefits and early indications of emergent capabilities in challenging scenarios, and showcase how our model can serve as a multi-frame reward annotator for robotics.","authors":["Runsen Xu","Weiyao Wang","Hao Tang","Xingyu Chen","Xiaodong Wang","Fu-Jen Chu","Dahua Lin","Matt Feiszli","Kevin J. Liang"],"url":"https://arxiv.org/abs/2505.17015"}
{"created":"2025-05-23","title":"Interactive Post-Training for Vision-Language-Action Models","abstract":"We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based interactive post-training paradigm that fine-tunes pretrained Vision-Language-Action (VLA) models using only sparse binary success rewards. Existing VLA training pipelines rely heavily on offline expert demonstration data and supervised imitation, limiting their ability to adapt to new tasks and environments under low-data regimes. RIPT-VLA addresses this by enabling interactive post-training with a stable policy optimization algorithm based on dynamic rollout sampling and leave-one-out advantage estimation.","authors":["Shuhan Tan","Kairan Dou","Yue Zhao","Philipp Kr\\\"ahenb\\\"uhl"],"url":"https://arxiv.org/abs/2505.17016"}
{"created":"2025-05-23","title":"Delving into RL for Image Generation with CoT: A Study on DPO vs. GRPO","abstract":"Recent advancements underscore the significant role of Reinforcement Learning (RL) in enhancing the Chain-of-Thought (CoT) reasoning capabilities of large language models (LLMs). Two prominent RL algorithms, Direct Preference Optimization (DPO) and Group Relative Policy Optimization (GRPO), are central to these developments, showcasing different pros and cons. Autoregressive image generation, also interpretable as a sequential CoT reasoning process, presents unique challenges distinct from LLM-based CoT reasoning. These encompass ensuring text-image consistency, improving image aesthetic quality, and designing sophisticated reward models, rather than relying on simpler rule-based rewards. While recent efforts have extended RL to this domain, these explorations typically lack an in-depth analysis of the domain-specific challenges and the characteristics of different RL strategies. To bridge this gap, we provide the first comprehensive investigation of the GRPO and DPO algorithms in autoregressive image generation, evaluating their in-domain performance and out-of-domain generalization, while scrutinizing the impact of different reward models on their respective capabilities. Our findings reveal that GRPO and DPO exhibit distinct advantages, and crucially, that reward models possessing stronger intrinsic generalization capabilities potentially enhance the generalization potential of the applied RL algorithms. Furthermore, we systematically explore three prevalent scaling strategies to enhance both their in-domain and out-of-domain proficiency, deriving unique insights into efficiently scaling performance for each paradigm. We hope our study paves a new path for inspiring future work on developing more effective RL algorithms to achieve robust CoT reasoning in the realm of autoregressive image generation. Code is released at https://github.com/ZiyuGuo99/Image-Generation-CoT","authors":["Chengzhuo Tong","Ziyu Guo","Renrui Zhang","Wenyu Shan","Xinyu Wei","Zhenghao Xing","Hongsheng Li","Pheng-Ann Heng"],"url":"https://arxiv.org/abs/2505.17017"}
{"created":"2025-05-23","title":"SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward","abstract":"Recent advances have shown success in eliciting strong reasoning abilities in multimodal large language models (MLLMs) through rule-based reinforcement learning (RL) with outcome rewards. However, this paradigm typically lacks supervision over the thinking process leading to the final outcome.As a result, the model may learn sub-optimal reasoning strategies, which can hinder its generalization ability. In light of this, we propose SophiaVL-R1, as an attempt to add reward signals for the thinking process in this paradigm. To achieve this, we first train a thinking reward model that evaluates the quality of the entire thinking process. Given that the thinking reward may be unreliable for certain samples due to reward hacking, we propose the Trust-GRPO method, which assigns a trustworthiness weight to the thinking reward during training. This weight is computed based on the thinking reward comparison of responses leading to correct answers versus incorrect answers, helping to mitigate the impact of potentially unreliable thinking rewards. Moreover, we design an annealing training strategy that gradually reduces the thinking reward over time, allowing the model to rely more on the accurate rule-based outcome reward in later training stages. Experiments show that our SophiaVL-R1 surpasses a series of reasoning MLLMs on various benchmarks (e.g., MathVisita, MMMU), demonstrating strong reasoning and generalization capabilities. Notably, our SophiaVL-R1-7B even outperforms LLaVA-OneVision-72B on most benchmarks, despite the latter having 10 times more parameters. All code, models, and datasets are made publicly available at https://github.com/kxfan2002/SophiaVL-R1.","authors":["Kaixuan Fan","Kaituo Feng","Haoming Lyu","Dongzhan Zhou","Xiangyu Yue"],"url":"https://arxiv.org/abs/2505.17018"}
{"created":"2025-05-23","title":"Let Androids Dream of Electric Sheep: A Human-like Image Implication Understanding and Reasoning Framework","abstract":"Metaphorical comprehension in images remains a critical challenge for AI systems, as existing models struggle to grasp the nuanced cultural, emotional, and contextual implications embedded in visual content. While multimodal large language models (MLLMs) excel in basic Visual Question Answer (VQA) tasks, they struggle with a fundamental limitation on image implication tasks: contextual gaps that obscure the relationships between different visual elements and their abstract meanings. Inspired by the human cognitive process, we propose Let Androids Dream (LAD), a novel framework for image implication understanding and reasoning. LAD addresses contextual missing through the three-stage framework: (1) Perception: converting visual information into rich and multi-level textual representations, (2) Search: iteratively searching and integrating cross-domain knowledge to resolve ambiguity, and (3) Reasoning: generating context-alignment image implication via explicit reasoning. Our framework with the lightweight GPT-4o-mini model achieves SOTA performance compared to 15+ MLLMs on English image implication benchmark and a huge improvement on Chinese benchmark, performing comparable with the GPT-4o model on Multiple-Choice Question (MCQ) and outperforms 36.7% on Open-Style Question (OSQ). Additionally, our work provides new insights into how AI can more effectively interpret image implications, advancing the field of vision-language reasoning and human-AI interaction. Our project is publicly available at https://github.com/MING-ZCH/Let-Androids-Dream-of-Electric-Sheep.","authors":["Chenhao Zhang","Yazhe Niu"],"url":"https://arxiv.org/abs/2505.17019"}
{"created":"2025-05-23","title":"CrossLMM: Decoupling Long Video Sequences from LMMs via Dual Cross-Attention Mechanisms","abstract":"The advent of Large Multimodal Models (LMMs) has significantly enhanced Large Language Models (LLMs) to process and interpret diverse data modalities (e.g., image and video). However, as input complexity increases, particularly with long video sequences, the number of required tokens has grown significantly, leading to quadratically computational costs. This has made the efficient compression of video tokens in LMMs, while maintaining performance integrity, a pressing research challenge. In this paper, we introduce CrossLMM, decoupling long video sequences from LMMs via a dual cross-attention mechanism, which substantially reduces visual token quantity with minimal performance degradation. Specifically, we first implement a significant token reduction from pretrained visual encoders through a pooling methodology. Then, within LLM layers, we employ a visual-to-visual cross-attention mechanism, wherein the pooled visual tokens function as queries against the original visual token set. This module enables more efficient token utilization while retaining fine-grained informational fidelity. In addition, we introduce a text-to-visual cross-attention mechanism, for which the text tokens are enhanced through interaction with the original visual tokens, enriching the visual comprehension of the text tokens. Comprehensive empirical evaluation demonstrates that our approach achieves comparable or superior performance across diverse video-based LMM benchmarks, despite utilizing substantially fewer computational resources.","authors":["Shilin Yan","Jiaming Han","Joey Tsai","Hongwei Xue","Rongyao Fang","Lingyi Hong","Ziyu Guo","Ray Zhang"],"url":"https://arxiv.org/abs/2505.17020"}
{"created":"2025-05-23","title":"ARB: A Comprehensive Arabic Multimodal Reasoning Benchmark","abstract":"As Large Multimodal Models (LMMs) become more capable, there is growing interest in evaluating their reasoning processes alongside their final outputs. However, most benchmarks remain focused on English, overlooking languages with rich linguistic and cultural contexts, such as Arabic. To address this gap, we introduce the Comprehensive Arabic Multimodal Reasoning Benchmark (ARB), the first benchmark designed to evaluate step-by-step reasoning in Arabic across both textual and visual modalities. ARB spans 11 diverse domains, including visual reasoning, document understanding, OCR, scientific analysis, and cultural interpretation. It comprises 1,356 multimodal samples paired with 5,119 human-curated reasoning steps and corresponding actions. We evaluated 12 state-of-the-art open- and closed-source LMMs and found persistent challenges in coherence, faithfulness, and cultural grounding. ARB offers a structured framework for diagnosing multimodal reasoning in underrepresented languages and marks a critical step toward inclusive, transparent, and culturally aware AI systems. We release the benchmark, rubric, and evaluation suit to support future research and reproducibility. Code available at: https://github.com/mbzuai-oryx/ARB","authors":["Sara Ghaboura","Ketan More","Wafa Alghallabi","Omkar Thawakar","Jorma Laaksonen","Hisham Cholakkal","Salman Khan","Rao Muhammad Anwer"],"url":"https://arxiv.org/abs/2505.17021"}
{"created":"2025-05-23","title":"GoT-R1: Unleashing Reasoning Capability of MLLM for Visual Generation with Reinforcement Learning","abstract":"Visual generation models have made remarkable progress in creating realistic images from text prompts, yet struggle with complex prompts that specify multiple objects with precise spatial relationships and attributes. Effective handling of such prompts requires explicit reasoning about the semantic content and spatial layout. We present GoT-R1, a framework that applies reinforcement learning to enhance semantic-spatial reasoning in visual generation. Building upon the Generation Chain-of-Thought approach, GoT-R1 enables models to autonomously discover effective reasoning strategies beyond predefined templates through carefully designed reinforcement learning. To achieve this, we propose a dual-stage multi-dimensional reward framework that leverages MLLMs to evaluate both the reasoning process and final output, enabling effective supervision across the entire generation pipeline. The reward system assesses semantic alignment, spatial accuracy, and visual quality in a unified approach. Experimental results demonstrate significant improvements on T2I-CompBench benchmark, particularly in compositional tasks involving precise spatial relationships and attribute binding. GoT-R1 advances the state-of-the-art in image generation by successfully transferring sophisticated reasoning capabilities to the visual generation domain. To facilitate future research, we make our code and pretrained models publicly available at https://github.com/gogoduan/GoT-R1.","authors":["Chengqi Duan","Rongyao Fang","Yuqing Wang","Kun Wang","Linjiang Huang","Xingyu Zeng","Hongsheng Li","Xihui Liu"],"url":"https://arxiv.org/abs/2505.17022"}
{"created":"2025-05-23","title":"Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning","abstract":"In-context learning (ICL) can significantly enhance the complex reasoning capabilities of large language models (LLMs), with the key lying in the selection and ordering of demonstration examples. Previous methods typically relied on simple features to measure the relevance between examples. We argue that these features are not sufficient to reflect the intrinsic connections between examples. In this study, we propose a curriculum ICL strategy guided by problem-solving logic. We select demonstration examples by analyzing the problem-solving logic and order them based on curriculum learning. Specifically, we constructed a problem-solving logic instruction set based on the BREAK dataset and fine-tuned a language model to analyze the problem-solving logic of examples. Subsequently, we selected appropriate demonstration examples based on problem-solving logic and assessed their difficulty according to the number of problem-solving steps. In accordance with the principles of curriculum learning, we ordered the examples from easy to hard to serve as contextual prompts. Experimental results on multiple benchmarks indicate that our method outperforms previous ICL approaches in terms of performance and efficiency, effectively enhancing the complex reasoning capabilities of LLMs. Our project will be publicly available subsequently.","authors":["Xuetao Ma","Wenbin Jiang","Hua Huang"],"url":"https://arxiv.org/abs/2502.15401"}
{"created":"2025-05-23","title":"X-KAN: Optimizing Local Kolmogorov-Arnold Networks via Evolutionary Rule-Based Machine Learning","abstract":"Function approximation is a critical task in various fields. However, existing neural network approaches struggle with locally complex or discontinuous functions due to their reliance on a single global model covering the entire problem space. We propose X-KAN, a novel method that optimizes multiple local Kolmogorov-Arnold Networks (KANs) through an evolutionary rule-based machine learning framework called XCSF. X-KAN combines KAN's high expressiveness with XCSF's adaptive partitioning capability by implementing local KAN models as rule consequents and defining local regions via rule antecedents. Our experimental results on artificial test functions and real-world datasets demonstrate that X-KAN significantly outperforms conventional methods, including XCSF, Multi-Layer Perceptron, and KAN, in terms of approximation accuracy. Notably, X-KAN effectively handles functions with locally complex or discontinuous structures that are challenging for conventional KAN, using a compact set of rules (average 7.2 $\\pm$ 2.3 rules). These results validate the effectiveness of using KAN as a local model in XCSF, which evaluates the rule fitness based on both accuracy and generality. Our X-KAN implementation is available at https://github.com/YNU-NakataLab/X-KAN.","authors":["Hiroki Shiraishi","Hisao Ishibuchi","Masaya Nakata"],"url":"https://arxiv.org/abs/2505.14273"}
{"created":"2025-05-23","title":"Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning","abstract":"Recent advances in reasoning language models have witnessed a paradigm shift from short to long CoT pattern. Given the substantial computational cost of rollouts in long CoT models, maximizing the utility of fixed training datasets becomes crucial. Our analysis reveals that negative responses contain valuable components such as self-reflection and error-correction steps, yet primary existing methods either completely discard negative samples (RFT) or apply equal penalization across all tokens (RL), failing to leverage these potential learning signals. In light of this, we propose Behavior Constrained Policy Gradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline RL framework that encompasses three stages: 1) sample segmentation, 2) consensus-based step correctness assessment combining LLM and PRM judgers, and 3) policy optimization with NSA designed to effectively mine positive steps within negative samples. Experimental results show that BCPG-NSA outperforms baselines on several challenging math/coding reasoning benchmarks using the same training dataset, achieving improved sample efficiency and demonstrating robustness and scalability when extended to multiple iterations.","authors":["Zhaohui Yang","Shilei Jiang","Chen Hu","Linjing Li","Shihong Deng","Daxin Jiang"],"url":"https://arxiv.org/abs/2505.14403"}
{"created":"2025-05-23","title":"UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models","abstract":"Lifelong learning enables large language models (LLMs) to adapt to evolving information by continually updating their internal knowledge. An ideal system should support efficient, wide-ranging updates while preserving existing capabilities and ensuring reliable deployment. Model editing stands out as a promising solution for this goal, offering a focused and efficient way to revise a model's internal knowledge. Although recent paradigms have made notable progress, they often struggle to meet the demands of practical lifelong adaptation at scale. To bridge this gap, we propose ULTRAEDIT-a fundamentally new editing solution that is training-, subject- and memory-free, making it particularly well-suited for ultra-scalable, real-world lifelong model editing. ULTRAEDIT performs editing through a self-contained process that relies solely on lightweight linear algebra operations to compute parameter shifts, enabling fast and consistent parameter modifications with minimal overhead. To improve scalability in lifelong settings, ULTRAEDIT employs a lifelong normalization strategy that continuously updates feature statistics across turns, allowing it to adapt to distributional shifts and maintain consistency over time. ULTRAEDIT achieves editing speeds over 7x faster than the previous state-of-the-art method-which was also the fastest known approach-while consuming less than 1/3 the VRAM, making it the only method currently capable of editing a 7B LLM on a 24GB consumer-grade GPU. Furthermore, we construct ULTRAEDITBENCH-the largest dataset in the field to date, with over 2M editing pairs-and demonstrate that our method supports up to 1M edits while maintaining high accuracy. Comprehensive experiments on four datasets and six models show that ULTRAEDIT consistently achieves superior performance across diverse model editing scenarios. Our code is available at: https://github.com/XiaojieGu/UltraEdit.","authors":["Xiaojie Gu","Guangxu Chen","Jungang Li","Jia-Chen Gu","Xuming Hu","Kai Zhang"],"url":"https://arxiv.org/abs/2505.14679"}
{"created":"2025-05-23","title":"MambaStyle: Efficient StyleGAN Inversion for Real Image Editing with State-Space Models","abstract":"The task of inverting real images into StyleGAN's latent space to manipulate their attributes has been extensively studied. However, existing GAN inversion methods struggle to balance high reconstruction quality, effective editability, and computational efficiency. In this paper, we introduce MambaStyle, an efficient single-stage encoder-based approach for GAN inversion and editing that leverages vision state-space models (VSSMs) to address these challenges. Specifically, our approach integrates VSSMs within the proposed architecture, enabling high-quality image inversion and flexible editing with significantly fewer parameters and reduced computational complexity compared to state-of-the-art methods. Extensive experiments show that MambaStyle achieves a superior balance among inversion accuracy, editing quality, and computational efficiency. Notably, our method achieves superior inversion and editing results with reduced model complexity and faster inference, making it suitable for real-time applications.","authors":["Jhon Lopez","Carlos Hinojosa","Henry Arguello","Bernard Ghanem"],"url":"https://arxiv.org/abs/2505.15822"}
{"created":"2025-05-23","title":"Advancing Tabular Stroke Modelling Through a Novel Hybrid Architecture and Feature-Selection Synergy","abstract":"Brain stroke remains one of the principal causes of death and disability worldwide, yet most tabular-data prediction models still hover below the 95% accuracy threshold, limiting real-world utility. Addressing this gap, the present work develops and validates a completely data-driven and interpretable machine-learning framework designed to predict strokes using ten routinely gathered demographic, lifestyle, and clinical variables sourced from a public cohort of 4,981 records. We employ a detailed exploratory data analysis (EDA) to understand the dataset's structure and distribution, followed by rigorous data preprocessing, including handling missing values, outlier removal, and class imbalance correction using Synthetic Minority Over-sampling Technique (SMOTE). To streamline feature selection, point-biserial correlation and random-forest Gini importance were utilized, and ten varied algorithms-encompassing tree ensembles, boosting, kernel methods, and a multilayer neural network-were optimized using stratified five-fold cross-validation. Their predictions based on probabilities helped us build the proposed model, which included Random Forest, XGBoost, LightGBM, and a support-vector classifier, with logistic regression acting as a meta-learner. The proposed model achieved an accuracy rate of 97.2% and an F1-score of 97.15%, indicating a significant enhancement compared to the leading individual model, LightGBM, which had an accuracy of 91.4%. Our study's findings indicate that rigorous preprocessing, coupled with a diverse hybrid model, can convert low-cost tabular data into a nearly clinical-grade stroke-risk assessment tool.","authors":["Yousuf Islam","Md. Jalal Uddin Chowdhury","Sumon Chandra Das"],"url":"https://arxiv.org/abs/2505.15844"}
{"created":"2025-05-23","title":"What Lives? A meta-analysis of diverse opinions on the definition of life","abstract":"The question of \"what is life?\" has challenged scientists and philosophers for centuries, producing an array of definitions that reflect both the mystery of its emergence and the diversity of disciplinary perspectives brought to bear on the question. Despite significant progress in our understanding of biological systems, psychology, computation, and information theory, no single definition for life has yet achieved universal acceptance. This challenge becomes increasingly urgent as advances in synthetic biology, artificial intelligence, and astrobiology challenge our traditional conceptions of what it means to be alive. We undertook a methodological approach that leverages large language models (LLMs) to analyze a set of definitions of life provided by a curated set of cross-disciplinary experts. We used a novel pairwise correlation analysis to map the definitions into distinct feature vectors, followed by agglomerative clustering, intra-cluster semantic analysis, and t-SNE projection to reveal underlying conceptual archetypes. This methodology revealed a continuous landscape of the themes relating to the definition of life, suggesting that what has historically been approached as a binary taxonomic problem should be instead conceived as differentiated perspectives within a unified conceptual latent space. We offer a new methodological bridge between reductionist and holistic approaches to fundamental questions in science and philosophy, demonstrating how computational semantic analysis can reveal conceptual patterns across disciplinary boundaries, and opening similar pathways for addressing other contested definitional territories across the sciences.","authors":["Reed Bender","Karina Kofman","Blaise Ag\\\"uera y Arcas","Michael Levin"],"url":"https://arxiv.org/abs/2505.15849"}
{"created":"2025-05-23","title":"P3Net: Progressive and Periodic Perturbation for Semi-Supervised Medical Image Segmentation","abstract":"Perturbation with diverse unlabeled data has proven beneficial for semi-supervised medical image segmentation (SSMIS). While many works have successfully used various perturbation techniques, a deeper understanding of learning perturbations is needed. Excessive or inappropriate perturbation can have negative effects, so we aim to address two challenges: how to use perturbation mechanisms to guide the learning of unlabeled data through labeled data, and how to ensure accurate predictions in boundary regions. Inspired by human progressive and periodic learning, we propose a progressive and periodic perturbation mechanism (P3M) and a boundary-focused loss. P3M enables dynamic adjustment of perturbations, allowing the model to gradually learn them. Our boundary-focused loss encourages the model to concentrate on boundary regions, enhancing sensitivity to intricate details and ensuring accurate predictions. Experimental results demonstrate that our method achieves state-of-the-art performance on two 2D and 3D datasets. Moreover, P3M is extendable to other methods, and the proposed loss serves as a universal tool for improving existing methods, highlighting the scalability and applicability of our approach.","authors":["Zhenyan Yao","Miao Zhang","Lanhu Wu","Yongri Piao","Feng Tian","Weibing Sun","Huchuan Lu"],"url":"https://arxiv.org/abs/2505.15861"}
{"created":"2025-05-23","title":"Multi-omic Causal Discovery using Genotypes and Gene Expression","abstract":"Causal discovery in multi-omic datasets is crucial for understanding the bigger picture of gene regulatory mechanisms, but remains challenging due to high dimensionality, differentiation of direct from indirect relationships, and hidden confounders. We introduce GENESIS (GEne Network inference from Expression SIgnals and SNPs), a constraint-based algorithm that leverages the natural causal precedence of genotypes to infer ancestral relationships in transcriptomic data. Unlike traditional causal discovery methods that start with a fully connected graph, GENESIS initialises an empty ancestrality matrix and iteratively populates it with direct, indirect or non-causal relationships using a series of provably sound marginal and conditional independence tests. By integrating genotypes as fixed causal anchors, GENESIS provides a principled ``head start'' to classical causal discovery algorithms, restricting the search space to biologically plausible edges. We test GENESIS on synthetic and real-world genomic datasets. This framework offers a powerful avenue for uncovering causal pathways in complex traits, with promising applications to functional genomics, drug discovery, and precision medicine.","authors":["Stephen Asiedu","David Watson"],"url":"https://arxiv.org/abs/2505.15866"}
{"created":"2025-05-23","title":"An Inclusive Foundation Model for Generalizable Cytogenetics in Precision Oncology","abstract":"Chromosome analysis is vital for diagnosing genetic disorders and guiding cancer therapy decisions through the identification of somatic clonal aberrations. However, developing an AI model are hindered by the overwhelming complexity and diversity of chromosomal abnormalities, requiring extensive annotation efforts, while automated methods remain task-specific and lack generalizability due to the scarcity of comprehensive datasets spanning diverse resource conditions. Here, we introduce CHROMA, a foundation model for cytogenomics, designed to overcome these challenges by learning generalizable representations of chromosomal abnormalities. Pre-trained on over 84,000 specimens (~4 million chromosomal images) via self-supervised learning, CHROMA outperforms other methods across all types of abnormalities, even when trained on fewer labelled data and more imbalanced datasets. By facilitating comprehensive mapping of instability and clonal leisons across various aberration types, CHROMA offers a scalable and generalizable solution for reliable and automated clinical analysis, reducing the annotation workload for experts and advancing precision oncology through the early detection of rare genomic abnormalities, enabling broad clinical AI applications and making advanced genomic analysis more accessible.","authors":["Changchun Yang (Xinhua Hospital Affiliated to Shanghai Jiao Tong University School of Medicine","Computer Science Program","Computer","Electrical and Mathematical Sciences and Engineering Division","King Abdullah University of Science and Technology","Center of Excellence for Smart Health","Center of Excellence on Generative AI","King Abdullah University of Science and Technology)","Weiqian Dai (Xinhua Hospital Affiliated to Shanghai Jiao Tong University School of Medicine)","Yilan Zhang (Computer Science Program","Computer","Electrical and Mathematical Sciences and Engineering Division","King Abdullah University of Science and Technology","Center of Excellence for Smart Health","Center of Excellence on Generative AI","King Abdullah University of Science and Technology)","Siyuan Chen (Computer Science Program","Computer","Electrical and Mathematical Sciences and Engineering Division","King Abdullah University of Science and Technology","Center of Excellence for Smart Health","Center of Excellence on Generative AI","King Abdullah University of Science and Technology)","Jingdong Hu (Smiltec)","Junkai Su (Smiltec)","Yuxuan Chen (Smiltec)","Ao Xu (Smiltec)","Na Li (Smiltec)","Xin Gao (Computer Science Program","Computer","Electrical and Mathematical Sciences and Engineering Division","King Abdullah University of Science and Technology","Center of Excellence for Smart Health","Center of Excellence on Generative AI","King Abdullah University of Science and Technology)","Yongguo Yu (Xinhua Hospital Affiliated to Shanghai Jiao Tong University School of Medicine)"],"url":"https://arxiv.org/abs/2505.15868"}
{"created":"2025-05-23","title":"CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision","abstract":"Learning complex functions that involve multi-step reasoning poses a significant challenge for standard supervised learning from input-output examples. Chain-of-thought (CoT) supervision, which provides intermediate reasoning steps together with the final output, has emerged as a powerful empirical technique, underpinning much of the recent progress in the reasoning capabilities of large language models. This paper develops a statistical theory of learning under CoT supervision. A key characteristic of the CoT setting, in contrast to standard supervision, is the mismatch between the training objective (CoT risk) and the test objective (end-to-end risk). A central part of our analysis, distinguished from prior work, is explicitly linking those two types of risk to achieve sharper sample complexity bounds. This is achieved via the *CoT information measure* $\\mathcal{I}_{\\mathcal{D}, h_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, which quantifies the additional discriminative power gained from observing the reasoning process. The main theoretical results demonstrate how CoT supervision can yield significantly faster learning rates compared to standard E2E supervision. Specifically, it is shown that the sample complexity required to achieve a target E2E error $\\epsilon$ scales as $d/\\mathcal{I}_{\\mathcal{D}, h_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, where $d$ is a measure of hypothesis class complexity, which can be much faster than standard $d/\\epsilon$ rates. Information-theoretic lower bounds in terms of the CoT information are also obtained. Together, these results suggest that CoT information is a fundamental measure of statistical complexity for learning under chain-of-thought supervision.","authors":["Awni Altabaa","Omar Montasser","John Lafferty"],"url":"https://arxiv.org/abs/2505.15927"}
{"created":"2025-05-23","title":"Constant-Sum High-Order Barrier Functions for Safety Between Parallel Boundaries","abstract":"This paper takes a step towards addressing the difficulty of constructing Control Barrier Functions (CBFs) for parallel safety boundaries. A single CBF for both boundaries has been reported to be difficult to validate for safety, and we identify why this challenge is inherent. To overcome this, the proposed method constructs separate CBFs for each boundary. We begin by presenting results for the relative degree one case and then extend these to higher relative degrees using the CBF backstepping technique, establishing conditions that guarantee safety. Finally, we showcase our method by applying it to a unicycle system, deriving a simple, verifiable condition to validate the target CBFs for direct implementation of our results.","authors":["Kwang Hak Kim","Mamadou Diagne","Miroslav Krsti\\'c"],"url":"https://arxiv.org/abs/2505.15932"}
{"created":"2025-05-23","title":"Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey","abstract":"With advancements in large audio-language models (LALMs), which enhance large language models (LLMs) with auditory capabilities, these models are expected to demonstrate universal proficiency across various auditory tasks. While numerous benchmarks have emerged to assess LALMs' performance, they remain fragmented and lack a structured taxonomy. To bridge this gap, we conduct a comprehensive survey and propose a systematic taxonomy for LALM evaluations, categorizing them into four dimensions based on their objectives: (1) General Auditory Awareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented Ability, and (4) Fairness, Safety, and Trustworthiness. We provide detailed overviews within each category and highlight challenges in this field, offering insights into promising future directions. To the best of our knowledge, this is the first survey specifically focused on the evaluations of LALMs, providing clear guidelines for the community. We will release the collection of the surveyed papers and actively maintain it to support ongoing advancements in the field.","authors":["Chih-Kai Yang","Neo S. Ho","Hung-yi Lee"],"url":"https://arxiv.org/abs/2505.15957"}
{"created":"2025-05-23","title":"Extremum Seeking for PDE Systems using Physics-Informed Neural Networks","abstract":"Extremum Seeking (ES) is an effective real-time optimization method for PDE systems in cascade with nonlinear quadratic maps. To address PDEs in the feedback loop, a boundary control law and a re-design of the additive probing signal are mandatory. The latter, commonly called \"trajectory generation\" or \"motion planning,\" involves designing perturbation signals that anticipate their propagation through PDEs. Specifically, this requires solving motion planning problems for systems governed by parabolic and hyperbolic PDEs. Physics-Informed Neural Networks (PINN) is a powerful tool for solving PDEs by embedding physical laws as constraints in the neural network's loss function, enabling efficient solutions for high-dimensional, nonlinear, and complex problems. This paper proposes a novel construction integrating PINN and ES, automating the motion planning process for specific PDE systems and eliminating the need for case-by-case analytical derivations. The proposed strategy efficiently extracts perturbation signals, optimizing the PDE system.","authors":["Haojin Guo","Zongyi Guo","Jianguo Guo","Tiago Roux Oliveira"],"url":"https://arxiv.org/abs/2505.15972"}
{"created":"2025-05-23","title":"Diffusion Probabilistic Generative Models for Accelerated, in-NICU Permanent Magnet Neonatal MRI","abstract":"Purpose: Magnetic Resonance Imaging (MRI) enables non-invasive assessment of brain abnormalities during early life development. Permanent magnet scanners operating in the neonatal intensive care unit (NICU) facilitate MRI of sick infants, but have long scan times due to lower signal-to-noise ratios (SNR) and limited receive coils. This work accelerates in-NICU MRI with diffusion probabilistic generative models by developing a training pipeline accounting for these challenges.","authors":["Yamin Arefeen","Brett Levac","Bhairav Patel","Chang Ho","Jonathan I. Tamir"],"url":"https://arxiv.org/abs/2505.15984"}
{"created":"2025-05-23","title":"Benchmarking Chest X-ray Diagnosis Models Across Multinational Datasets","abstract":"Foundation models leveraging vision-language pretraining have shown promise in chest X-ray (CXR) interpretation, yet their real-world performance across diverse populations and diagnostic tasks remains insufficiently evaluated. This study benchmarks the diagnostic performance and generalizability of foundation models versus traditional convolutional neural networks (CNNs) on multinational CXR datasets. We evaluated eight CXR diagnostic models - five vision-language foundation models and three CNN-based architectures - across 37 standardized classification tasks using six public datasets from the USA, Spain, India, and Vietnam, and three private datasets from hospitals in China. Performance was assessed using AUROC, AUPRC, and other metrics across both shared and dataset-specific tasks. Foundation models outperformed CNNs in both accuracy and task coverage. MAVL, a model incorporating knowledge-enhanced prompts and structured supervision, achieved the highest performance on public (mean AUROC: 0.82; AUPRC: 0.32) and private (mean AUROC: 0.95; AUPRC: 0.89) datasets, ranking first in 14 of 37 public and 3 of 4 private tasks. All models showed reduced performance on pediatric cases, with average AUROC dropping from 0.88 +/- 0.18 in adults to 0.57 +/- 0.29 in children (p = 0.0202). These findings highlight the value of structured supervision and prompt design in radiologic AI and suggest future directions including geographic expansion and ensemble modeling for clinical deployment. Code for all evaluated models is available at https://drive.google.com/drive/folders/1B99yMQm7bB4h1sVMIBja0RfUu8gLktCE","authors":["Qinmei Xu","Yiheng Li","Xianghao Zhan","Ahmet Gorkem Er","Brittany Dashevsky","Chuanjun Xu","Mohammed Alawad","Mengya Yang","Liu Ya","Changsheng Zhou","Xiao Li","Haruka Itakura","Olivier Gevaert"],"url":"https://arxiv.org/abs/2505.16027"}
{"created":"2025-05-23","title":"Comprehensive Lung Disease Detection Using Deep Learning Models and Hybrid Chest X-ray Data with Explainable AI","abstract":"Advanced diagnostic instruments are crucial for the accurate detection and treatment of lung diseases, which affect millions of individuals globally. This study examines the effectiveness of deep learning and transfer learning models using a hybrid dataset, created by merging four individual datasets from Bangladesh and global sources. The hybrid dataset significantly enhances model accuracy and generalizability, particularly in detecting COVID-19, pneumonia, lung opacity, and normal lung conditions from chest X-ray images. A range of models, including CNN, VGG16, VGG19, InceptionV3, Xception, ResNet50V2, InceptionResNetV2, MobileNetV2, and DenseNet121, were applied to both individual and hybrid datasets. The results showed superior performance on the hybrid dataset, with VGG16, Xception, ResNet50V2, and DenseNet121 each achieving an accuracy of 99%. This consistent performance across the hybrid dataset highlights the robustness of these models in handling diverse data while maintaining high accuracy. To understand the models implicit behavior, explainable AI techniques were employed to illuminate their black-box nature. Specifically, LIME was used to enhance the interpretability of model predictions, especially in cases of misclassification, contributing to the development of reliable and interpretable AI-driven solutions for medical imaging.","authors":["Shuvashis Sarker","Shamim Rahim Refat","Faika Fairuj Preotee","Tanvir Rouf Shawon","Raihan Tanvir"],"url":"https://arxiv.org/abs/2505.16028"}
{"created":"2025-05-23","title":"Physics-based machine learning for mantle convection simulations","abstract":"Mantle convection simulations are an essential tool for understanding how rocky planets evolve. However, the poorly known input parameters to these simulations, the non-linear dependence of transport properties on pressure and temperature, and the long integration times in excess of several billion years all pose a computational challenge for numerical solvers. We propose a physics-based machine learning approach that predicts creeping flow velocities as a function of temperature while conserving mass, thereby bypassing the numerical solution of the Stokes problem. A finite-volume solver then uses the predicted velocities to advect and diffuse the temperature field to the next time-step, enabling autoregressive rollout at inference. For training, our model requires temperature-velocity snapshots from a handful of simulations (94). We consider mantle convection in a two-dimensional rectangular box with basal and internal heating, pressure- and temperature-dependent viscosity. Overall, our model is up to 89 times faster than the numerical solver. We also show the importance of different components in our convolutional neural network architecture such as mass conservation, learned paddings on the boundaries, and loss scaling for the overall rollout performance. Finally, we test our approach on unseen scenarios to demonstrate some of its strengths and weaknesses.","authors":["Siddhant Agarwal","Ali Can Bekar","Christian H\\\"uttig","David S. Greenberg","Nicola Tosi"],"url":"https://arxiv.org/abs/2505.16041"}
{"created":"2025-05-23","title":"Multimodal Biomarkers for Schizophrenia: Towards Individual Symptom Severity Estimation","abstract":"Studies on schizophrenia assessments using deep learning typically treat it as a classification task to detect the presence or absence of the disorder, oversimplifying the condition and reducing its clinical applicability. This traditional approach overlooks the complexity of schizophrenia, limiting its practical value in healthcare settings. This study shifts the focus to individual symptom severity estimation using a multimodal approach that integrates speech, video, and text inputs. We develop unimodal models for each modality and a multimodal framework to improve accuracy and robustness. By capturing a more detailed symptom profile, this approach can help in enhancing diagnostic precision and support personalized treatment, offering a scalable and objective tool for mental health assessment.","authors":["Gowtham Premananth","Philip Resnik","Sonia Bansal","Deanna L. Kelly","Carol Espy-Wilson"],"url":"https://arxiv.org/abs/2505.16044"}
{"created":"2025-05-23","title":"PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals","abstract":"We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for causal inference that jointly models potential outcomes and counterfactuals. Trained via flow matching, PO-Flow provides a unified framework for individualized potential outcome prediction, counterfactual predictions, and uncertainty-aware density learning. Among generative models, it is the first to enable density learning of potential outcomes without requiring explicit distributional assumptions (e.g., Gaussian mixtures), while also supporting counterfactual prediction conditioned on factual outcomes in general observational datasets. On benchmarks such as ACIC, IHDP, and IBM, it consistently outperforms prior methods across a range of causal inference tasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including counterfactual image generation, demonstrating its broad applicability.","authors":["Dongze Wu","David I. Inouye","Yao Xie"],"url":"https://arxiv.org/abs/2505.16051"}
{"created":"2025-05-23","title":"Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schr\\\"odinger Bridge's End","abstract":"Scientists often want to make predictions beyond the observed time horizon of \"snapshot\" data following latent stochastic dynamics. For example, in time course single-cell mRNA profiling, scientists have access to cellular transcriptional state measurements (snapshots) from different biological replicates at different time points, but they cannot access the trajectory of any one cell because measurement destroys the cell. Researchers want to forecast (e.g.) differentiation outcomes from early state measurements of stem cells. Recent Schr\\\"odinger-bridge (SB) methods are natural for interpolating between snapshots. But past SB papers have not addressed forecasting -- likely since existing methods either (1) reduce to following pre-set reference dynamics (chosen before seeing data) or (2) require the user to choose a fixed, state-independent volatility since they minimize a Kullback-Leibler divergence. Either case can lead to poor forecasting quality. In the present work, we propose a new framework, SnapMMD, that learns dynamics by directly fitting the joint distribution of both state measurements and observation time with a maximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to infer unknown and state-dependent volatilities from the observed data. We show in a variety of real and synthetic experiments that our method delivers accurate forecasts. Moreover, our approach allows us to learn in the presence of incomplete state measurements and yields an $R^2$-style statistic that diagnoses fit. We also find that our method's performance at interpolation (and general velocity-field reconstruction) is at least as good as (and often better than) state-of-the-art in almost all of our experiments.","authors":["Renato Berlinghieri","Yunyi Shen","Jialong Jiang","Tamara Broderick"],"url":"https://arxiv.org/abs/2505.16082"}
{"created":"2025-05-23","title":"OSCAR: One-Step Diffusion Codec Across Multiple Bit-rates","abstract":"Pretrained latent diffusion models have shown strong potential for lossy image compression, owing to their powerful generative priors. Most existing diffusion-based methods reconstruct images by iteratively denoising from random noise, guided by compressed latent representations. While these approaches have achieved high reconstruction quality, their multi-step sampling process incurs substantial computational overhead. Moreover, they typically require training separate models for different compression bit-rates, leading to significant training and storage costs. To address these challenges, we propose a one-step diffusion codec across multiple bit-rates. termed OSCAR. Specifically, our method views compressed latents as noisy variants of the original latents, where the level of distortion depends on the bit-rate. This perspective allows them to be modeled as intermediate states along a diffusion trajectory. By establishing a mapping from the compression bit-rate to a pseudo diffusion timestep, we condition a single generative model to support reconstructions at multiple bit-rates. Meanwhile, we argue that the compressed latents retain rich structural information, thereby making one-step denoising feasible. Thus, OSCAR replaces iterative sampling with a single denoising pass, significantly improving inference efficiency. Extensive experiments demonstrate that OSCAR achieves superior performance in both quantitative and visual quality metrics. The code and models will be released at https://github.com/jp-guo/OSCAR.","authors":["Jinpei Guo","Yifei Ji","Zheng Chen","Kai Liu","Min Liu","Wang Rao","Wenbo Li","Yong Guo","Yulun Zhang"],"url":"https://arxiv.org/abs/2505.16091"}
{"created":"2025-05-23","title":"Dimension-adapted Momentum Outscales SGD","abstract":"We investigate scaling laws for stochastic momentum algorithms with small batch on the power law random features model, parameterized by data complexity, target complexity, and model size. When trained with a stochastic momentum algorithm, our analysis reveals four distinct loss curve shapes determined by varying data-target complexities. While traditional stochastic gradient descent with momentum (SGD-M) yields identical scaling law exponents to SGD, dimension-adapted Nesterov acceleration (DANA) improves these exponents by scaling momentum hyperparameters based on model size and data complexity. This outscaling phenomenon, which also improves compute-optimal scaling behavior, is achieved by DANA across a broad range of data and target complexities, while traditional methods fall short. Extensive experiments on high-dimensional synthetic quadratics validate our theoretical predictions and large-scale text experiments with LSTMs show DANA's improved loss exponents over SGD hold in a practical setting.","authors":["Damien Ferbach","Katie Everett","Gauthier Gidel","Elliot Paquette","Courtney Paquette"],"url":"https://arxiv.org/abs/2505.16098"}
{"created":"2025-05-23","title":"Machine Learning the 6d Supergravity Landscape","abstract":"In this paper, we apply both supervised and unsupervised machine learning algorithms to the study of the string landscape and swampland in 6-dimensions. Our data are the (almost) anomaly-free 6-dimensional $\\mathcal{N} = (1,0)$ supergravity models, characterised by the Gram matrix of anomaly coefficients. Our work demonstrates the ability of machine learning algorithms to efficiently learn highly complex features of the landscape and swampland. Employing an autoencoder for unsupervised learning, we provide an auto-classification of these models by compressing the Gram matrix data to 2-dimensions. Through compression, similar models cluster together, and we identify prominent features of these clusters. The autoencoder also identifies outlier models which are difficult to reconstruct. One of these outliers proves to be incredibly difficult to combine with other models such that the $\\text{tr}R^{4}$ anomaly vanishes, making its presence in the landscape extremely rare. Further, we utilise supervised learning to build two classifiers predicting (1) model consistency under probe string insertion (precision: 0.78, predicting consistency for 214,837 models with reasonable certainty) and (2) inconsistency under anomaly inflow (precision: 0.91, predicting inconsistency for 1,909,359 models). Notably, projecting these predictions onto the autoencoder's 2-dimensional latent layer shows consistent models clustering together, further indicating that the autoencoder has learnt interesting and complex features of the set of models and potentially offers a novel approach to mapping the landscape and swampland of 6-dimensional supergravity theories.","authors":["Nathan Brady","David Tennyson","Thomas Vandermeulen"],"url":"https://arxiv.org/abs/2505.16131"}
{"created":"2025-05-23","title":"Beamforming-Codebook-Aware Channel Knowledge Map Construction for Multi-Antenna Systems","abstract":"Channel knowledge map (CKM) has emerged as a crucial technology for next-generation communication, enabling the construction of high-fidelity mappings between spatial environments and channel parameters via electromagnetic information analysis. Traditional CKM construction methods like ray tracing are computationally intensive. Recent studies utilizing neural networks (NNs) have achieved efficient CKM generation with reduced computational complexity and real-time processing capabilities. Nevertheless, existing research predominantly focuses on single-antenna systems, failing to address the beamforming requirements inherent to MIMO configurations. Given that appropriate precoding vector selection in MIMO systems can substantially enhance user communication rates, this paper presents a TransUNet-based framework for constructing CKM, which effectively incorporates discrete Fourier transform (DFT) precoding vectors. The proposed architecture combines a UNet backbone for multiscale feature extraction with a Transformer module to capture global dependencies among encoded linear vectors. Experimental results demonstrate that the proposed method outperforms state-of-the-art (SOTA) deep learning (DL) approaches, yielding a 17\\% improvement in RMSE compared to RadioWNet. The code is publicly accessible at https://github.com/github-whh/TransUNet.","authors":["Haohan Wang","Xu Shi","Hengyu Zhang","Yashuai Cao","Jintao Wang"],"url":"https://arxiv.org/abs/2505.16132"}
{"created":"2025-05-23","title":"Interpretable Machine Learning for Macro Alpha: A News Sentiment Case Study","abstract":"This study introduces an interpretable machine learning (ML) framework to extract macroeconomic alpha from global news sentiment. We process the Global Database of Events, Language, and Tone (GDELT) Project's worldwide news feed using FinBERT -- a Bidirectional Encoder Representations from Transformers (BERT) based model pretrained on finance-specific language -- to construct daily sentiment indices incorporating mean tone, dispersion, and event impact. These indices drive an XGBoost classifier, benchmarked against logistic regression, to predict next-day returns for EUR/USD, USD/JPY, and 10-year U.S. Treasury futures (ZN). Rigorous out-of-sample (OOS) backtesting (5-fold expanding-window cross-validation, OOS period: c. 2017-April 2025) demonstrates exceptional, cost-adjusted performance for the XGBoost strategy: Sharpe ratios achieve 5.87 (EUR/USD), 4.65 (USD/JPY), and 4.65 (Treasuries), with respective compound annual growth rates (CAGRs) exceeding 50% in Foreign Exchange (FX) and 22% in bonds. Shapley Additive Explanations (SHAP) affirm that sentiment dispersion and article impact are key predictive features. Our findings establish that integrating domain-specific Natural Language Processing (NLP) with interpretable ML offers a potent and explainable source of macro alpha.","authors":["Yuke Zhang"],"url":"https://arxiv.org/abs/2505.16136"}
{"created":"2025-05-23","title":"Exponential Convergence of CAVI for Bayesian PCA","abstract":"Probabilistic principal component analysis (PCA) and its Bayesian variant (BPCA) are widely used for dimension reduction in machine learning and statistics. The main advantage of probabilistic PCA over the traditional formulation is allowing uncertainty quantification. The parameters of BPCA are typically learned using mean-field variational inference, and in particular, the coordinate ascent variational inference (CAVI) algorithm. So far, the convergence speed of CAVI for BPCA has not been characterized. In our paper, we fill this gap in the literature. Firstly, we prove a precise exponential convergence result in the case where the model uses a single principal component (PC). Interestingly, this result is established through a connection with the classical $\\textit{power iteration algorithm}$ and it indicates that traditional PCA is retrieved as points estimates of the BPCA parameters. Secondly, we leverage recent tools to prove exponential convergence of CAVI for the model with any number of PCs, thus leading to a more general result, but one that is of a slightly different flavor. To prove the latter result, we additionally needed to introduce a novel lower bound for the symmetric Kullback--Leibler divergence between two multivariate normal distributions, which, we believe, is of independent interest in information theory.","authors":["Arghya Datta","Philippe Gagnon","Florian Maire"],"url":"https://arxiv.org/abs/2505.16145"}
{"created":"2025-05-23","title":"Compressing Human Body Video with Interactive Semantics: A Generative Approach","abstract":"In this paper, we propose to compress human body video with interactive semantics, which can facilitate video coding to be interactive and controllable by manipulating semantic-level representations embedded in the coded bitstream. In particular, the proposed encoder employs a 3D human model to disentangle nonlinear dynamics and complex motion of human body signal into a series of configurable embeddings, which are controllably edited, compactly compressed, and efficiently transmitted. Moreover, the proposed decoder can evolve the mesh-based motion fields from these decoded semantics to realize the high-quality human body video reconstruction. Experimental results illustrate that the proposed framework can achieve promising compression performance for human body videos at ultra-low bitrate ranges compared with the state-of-the-art video coding standard Versatile Video Coding (VVC) and the latest generative compression schemes. Furthermore, the proposed framework enables interactive human body video coding without any additional pre-/post-manipulation processes, which is expected to shed light on metaverse-related digital human communication in the future.","authors":["Bolin Chen","Shanzhi Yin","Hanwei Zhu","Lingyu Zhu","Zihan Zhang","Jie Chen","Ru-Ling Liao","Shiqi Wang","Yan Ye"],"url":"https://arxiv.org/abs/2505.16152"}
{"created":"2025-05-23","title":"Integral Imprecise Probability Metrics","abstract":"Quantifying differences between probability distributions is fundamental to statistics and machine learning, primarily for comparing statistical uncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete knowledge -- requires richer representations than those offered by classical probability. Imprecise probability (IP) theory offers such models, capturing ambiguity and partial belief. This has driven growing interest in imprecise probabilistic machine learning (IPML), where inference and decision-making rely on broader uncertainty models -- highlighting the need for metrics beyond classical probability. This work introduces the Integral Imprecise Probability Metric (IIPM) framework, a Choquet integral-based generalisation of classical Integral Probability Metric (IPM) to the setting of capacities -- a broad class of IP models encompassing many existing ones, including lower probabilities, probability intervals, belief functions, and more. Theoretically, we establish conditions under which IIPM serves as a valid metric and metrises a form of weak convergence of capacities. Practically, IIPM not only enables comparison across different IP models but also supports the quantification of epistemic uncertainty within a single IP model. In particular, by comparing an IP model with its conjugate, IIPM gives rise to a new class of EU measures -- Maximum Mean Imprecision -- which satisfy key axiomatic properties proposed in the Uncertainty Quantification literature. We validate MMI through selective classification experiments, demonstrating strong empirical performance against established EU measures, and outperforming them when classical methods struggle to scale to a large number of classes. Our work advances both theory and practice in IPML, offering a principled framework for comparing and quantifying epistemic uncertainty under imprecision.","authors":["Siu Lun Chau","Michele Caprio","Krikamol Muandet"],"url":"https://arxiv.org/abs/2505.16156"}
{"created":"2025-05-23","title":"Generative Latent Coding for Ultra-Low Bitrate Image and Video Compression","abstract":"Most existing approaches for image and video compression perform transform coding in the pixel space to reduce redundancy. However, due to the misalignment between the pixel-space distortion and human perception, such schemes often face the difficulties in achieving both high-realism and high-fidelity at ultra-low bitrate. To solve this problem, we propose \\textbf{G}enerative \\textbf{L}atent \\textbf{C}oding (\\textbf{GLC}) models for image and video compression, termed GLC-image and GLC-Video. The transform coding of GLC is conducted in the latent space of a generative vector-quantized variational auto-encoder (VQ-VAE). Compared to the pixel-space, such a latent space offers greater sparsity, richer semantics and better alignment with human perception, and show its advantages in achieving high-realism and high-fidelity compression. To further enhance performance, we improve the hyper prior by introducing a spatial categorical hyper module in GLC-image and a spatio-temporal categorical hyper module in GLC-video. Additionally, the code-prediction-based loss function is proposed to enhance the semantic consistency. Experiments demonstrate that our scheme shows high visual quality at ultra-low bitrate for both image and video compression. For image compression, GLC-image achieves an impressive bitrate of less than $0.04$ bpp, achieving the same FID as previous SOTA model MS-ILLM while using $45\\%$ fewer bitrate on the CLIC 2020 test set. For video compression, GLC-video achieves 65.3\\% bitrate saving over PLVC in terms of DISTS.","authors":["Linfeng Qi","Zhaoyang Jia","Jiahao Li","Bin Li","Houqiang Li","Yan Lu"],"url":"https://arxiv.org/abs/2505.16177"}
{"created":"2025-05-23","title":"Using Echo-State Networks to Reproduce Rare Events in Chaotic Systems","abstract":"We apply the Echo-State Networks to predict the time series and statistical properties of the competitive Lotka-Volterra model in the chaotic regime. In particular, we demonstrate that Echo-State Networks successfully learn the chaotic attractor of the competitive Lotka-Volterra model and reproduce histograms of dependent variables, including tails and rare events. We use the Generalized Extreme Value distribution to quantify the tail behavior.","authors":["Anton Erofeev","Balasubramanya T. Nadiga","Ilya Timofeyev"],"url":"https://arxiv.org/abs/2505.16208"}
{"created":"2025-05-23","title":"Meta-PerSER: Few-Shot Listener Personalized Speech Emotion Recognition via Meta-learning","abstract":"This paper introduces Meta-PerSER, a novel meta-learning framework that personalizes Speech Emotion Recognition (SER) by adapting to each listener's unique way of interpreting emotion. Conventional SER systems rely on aggregated annotations, which often overlook individual subtleties and lead to inconsistent predictions. In contrast, Meta-PerSER leverages a Model-Agnostic Meta-Learning (MAML) approach enhanced with Combined-Set Meta-Training, Derivative Annealing, and per-layer per-step learning rates, enabling rapid adaptation with only a few labeled examples. By integrating robust representations from pre-trained self-supervised models, our framework first captures general emotional cues and then fine-tunes itself to personal annotation styles. Experiments on the IEMOCAP corpus demonstrate that Meta-PerSER significantly outperforms baseline methods in both seen and unseen data scenarios, highlighting its promise for personalized emotion recognition.","authors":["Liang-Yeh Shen","Shi-Xin Fang","Yi-Cheng Lin","Huang-Cheng Chou","Hung-yi Lee"],"url":"https://arxiv.org/abs/2505.16220"}
{"created":"2025-05-23","title":"Generalized Power Priors for Improved Bayesian Inference with Historical Data","abstract":"The power prior is a class of informative priors designed to incorporate historical data alongside current data in a Bayesian framework. It includes a power parameter that controls the influence of historical data, providing flexibility and adaptability. A key property of the power prior is that the resulting posterior minimizes a linear combination of KL divergences between two pseudo-posterior distributions: one ignoring historical data and the other fully incorporating it. We extend this framework by identifying the posterior distribution as the minimizer of a linear combination of Amari's $\\alpha$-divergence, a generalization of KL divergence. We show that this generalization can lead to improved performance by allowing for the data to adapt to appropriate choices of the $\\alpha$ parameter. Theoretical properties of this generalized power posterior are established, including behavior as a generalized geodesic on the Riemannian manifold of probability distributions, offering novel insights into its geometric interpretation.","authors":["Masanari Kimura","Howard Bondell"],"url":"https://arxiv.org/abs/2505.16244"}
{"created":"2025-05-23","title":"Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry","abstract":"Label shift adaptation aims to recover target class priors when the labelled source distribution $P$ and the unlabelled target distribution $Q$ share $P(X \\mid Y) = Q(X \\mid Y)$ but $P(Y) \\neq Q(Y)$. Classical black-box shift estimators invert an empirical confusion matrix of a frozen classifier, producing a brittle point estimate that ignores sampling noise and similarity among classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully probabilistic alternative that places Laplacian-Gaussian priors on both target log-priors and confusion-matrix columns, tying them together on a label-similarity graph. The resulting posterior is tractable with HMC or a fast block Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction, variance bounds that shrink with the graph's algebraic connectivity, and robustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE through information geometry, showing that it generalizes existing shift estimators.","authors":["Masanari Kimura"],"url":"https://arxiv.org/abs/2505.16251"}
{"created":"2025-05-23","title":"Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics","abstract":"This study develops a higher-order asymptotic framework for test-time adaptation (TTA) of Batch Normalization (BN) statistics under distribution shift by integrating classical Edgeworth expansion and saddlepoint approximation techniques with a novel one-step M-estimation perspective. By analyzing the statistical discrepancy between training and test distributions, we derive an Edgeworth expansion for the normalized difference in BN means and obtain an optimal weighting parameter that minimizes the mean-squared error of the adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows us to derive higher-order local asymptotic normality results, which incorporate skewness and other higher moments into the estimator's behavior. Moreover, we quantify the trade-offs among bias, variance, and skewness in the adaptation process and establish a corresponding generalization bound on the model risk. The refined saddlepoint approximations further deliver uniformly accurate density and tail probability estimates for the BN TTA statistic. These theoretical insights provide a comprehensive understanding of how higher-order corrections and robust one-step updating can enhance the reliability and performance of BN layers in adapting to changing data distributions.","authors":["Masanari Kimura"],"url":"https://arxiv.org/abs/2505.16257"}
{"created":"2025-05-23","title":"Artificial Intelligence for Direct Prediction of Molecular Dynamics Across Chemical Space","abstract":"Molecular dynamics (MD) is a powerful tool for exploring the behavior of atomistic systems, but its reliance on sequential numerical integration limits simulation efficiency. We present MDtrajNet-1, a foundational AI model that directly generates MD trajectories across chemical space, bypassing force calculations and integration. This approach accelerates simulations by up to two orders of magnitude compared to traditional MD, even those enhanced by machine-learning interatomic potentials. MDtrajNet-1 combines equivariant neural networks with a Transformer-based architecture to achieve strong accuracy and transferability in predicting long-time trajectories for both known and unseen systems. Remarkably, the errors of the trajectories generated by MDtrajNet-1 for various molecular systems are close to those of the conventional ab initio MD. The model's flexible design supports diverse application scenarios, including different statistical ensembles, boundary conditions, and interaction types. By overcoming the intrinsic speed barrier of conventional MD, MDtrajNet-1 opens new frontiers in efficient and scalable atomistic simulations.","authors":["Fuchun Ge","Pavlo O. Dral"],"url":"https://arxiv.org/abs/2505.16301"}
{"created":"2025-05-23","title":"Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions","abstract":"Recent advances in generative artificial intelligence (GenAI) models have enabled the generation of personalized content that adapts to up-to-date user context. While personalized decision systems are often modeled using bandit formulations, the integration of GenAI introduces new structure into otherwise classical sequential learning problems. In GenAI-powered interventions, the agent selects a query, but the environment experiences a stochastic response drawn from the generative model. Standard bandit methods do not explicitly account for this structure, where actions influence rewards only through stochastic, observed treatments. We introduce generator-mediated bandit-Thompson sampling (GAMBITTS), a bandit approach designed for this action/treatment split, using mobile health interventions with large language model-generated text as a motivating case study. GAMBITTS explicitly models both the treatment and reward generation processes, using information in the delivered treatment to accelerate policy learning relative to standard methods. We establish regret bounds for GAMBITTS by decomposing sources of uncertainty in treatment and reward, identifying conditions where it achieves stronger guarantees than standard bandit approaches. In simulation studies, GAMBITTS consistently outperforms conventional algorithms by leveraging observed treatments to more accurately estimate expected rewards.","authors":["Marc Brooks","Gabriel Durham","Kihyuk Hong","Ambuj Tewari"],"url":"https://arxiv.org/abs/2505.16311"}
{"created":"2025-05-23","title":"Learning novel representations of variable sources from multi-modal $\\textit{Gaia}$ data via autoencoders","abstract":"Gaia Data Release 3 (DR3) published for the first time epoch photometry, BP/RP (XP) low-resolution mean spectra, and supervised classification results for millions of variable sources. This extensive dataset offers a unique opportunity to study their variability by combining multiple Gaia data products. In preparation for DR4, we propose and evaluate a machine learning methodology capable of ingesting multiple Gaia data products to achieve an unsupervised classification of stellar and quasar variability. A dataset of 4 million Gaia DR3 sources is used to train three variational autoencoders (VAE), which are artificial neural networks (ANNs) designed for data compression and generation. One VAE is trained on Gaia XP low-resolution spectra, another on a novel approach based on the distribution of magnitude differences in the Gaia G band, and the third on folded Gaia G band light curves. Each Gaia source is compressed into 15 numbers, representing the coordinates in a 15-dimensional latent space generated by combining the outputs of these three models. The learned latent representation produced by the ANN effectively distinguishes between the main variability classes present in Gaia DR3, as demonstrated through both supervised and unsupervised classification analysis of the latent space. The results highlight a strong synergy between light curves and low-resolution spectral data, emphasising the benefits of combining the different Gaia data products. A two-dimensional projection of the latent variables reveals numerous overdensities, most of which strongly correlate with astrophysical properties, showing the potential of this latent space for astrophysical discovery. We show that the properties of our novel latent representation make it highly valuable for variability analysis tasks, including classification, clustering and outlier detection.","authors":["P. Huijse","J. De Ridder","L. Eyer","L. Rimoldini","B. Holl","N. Chornay","J. Roquette","K. Nienartowicz","G. Jevardat de Fombelle","D. J. Fritzewski","A. Kemp","V. Vanlaer","M. Vanrespaille","H. Wang","M. I. Carnerero","C. M. Raiteri","G. Marton","M. Madar\\'asz","G. Clementini","P. Gavras","C. Aerts"],"url":"https://arxiv.org/abs/2505.16320"}
{"created":"2025-05-23","title":"Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping","abstract":"Differentially private (DP) linear regression has received significant attention in the recent theoretical literature, with several works aimed at obtaining improved error rates. A common approach is to set the clipping constant much larger than the expected norm of the per-sample gradients. While simplifying the analysis, this is however in sharp contrast with what empirical evidence suggests to optimize performance. Our work bridges this gap between theory and practice: we provide sharper rates for DP stochastic gradient descent (DP-SGD) by crucially operating in a regime where clipping happens frequently. Specifically, we consider the setting where the data is multivariate Gaussian, the number of training samples $n$ is proportional to the input dimension $d$, and the algorithm guarantees constant-order zero concentrated DP. Our method relies on establishing a deterministic equivalent for the trajectory of DP-SGD in terms of a family of ordinary differential equations (ODEs). As a consequence, the risk of DP-SGD is bounded between two ODEs, with upper and lower bounds matching for isotropic data. By studying these ODEs when $n / d$ is large enough, we demonstrate the optimality of aggressive clipping, and we uncover the benefits of decaying learning rate and private noise scheduling.","authors":["Simone Bombari","Inbar Seroussi","Marco Mondelli"],"url":"https://arxiv.org/abs/2505.16329"}
{"created":"2025-05-23","title":"Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing","abstract":"Quantum optimization is the most mature quantum computing technology to date, providing a promising approach towards efficiently solving complex combinatorial problems. Methods such as adiabatic quantum computing (AQC) have been employed in recent years on important optimization problems across various domains. In deep learning, deep neural networks (DNN) have reached immense sizes to support new predictive capabilities. Optimization of large-scale models is critical for sustainable deployment, but becomes increasingly challenging with ever-growing model sizes and complexity. While quantum optimization is suitable for solving complex problems, its application to DNN optimization is not straightforward, requiring thorough reformulation for compatibility with commercially available quantum devices. In this work, we explore the potential of adopting AQC for fine-grained pruning-quantization of convolutional neural networks. We rework established heuristics to formulate model compression as a quadratic unconstrained binary optimization (QUBO) problem, and assess the solution space offered by commercial quantum annealing devices. Through our exploratory efforts of reformulation, we demonstrate that AQC can achieve effective compression of practical DNN models. Experiments demonstrate that adiabatic quantum computing (AQC) not only outperforms classical algorithms like genetic algorithms and reinforcement learning in terms of time efficiency but also excels at identifying global optima.","authors":["Zhehui Wanga","Benjamin Chen Ming Choonga","Tian Huang","Daniel Gerlinghoffa","Rick Siow Mong Goh","Cheng Liu","Tao Luo"],"url":"https://arxiv.org/abs/2505.16332"}
{"created":"2025-05-23","title":"Urban transport systems shape experiences of social segregation","abstract":"Mobility is a fundamental feature of human life, and through it our interactions with the world and people around us generate complex and consequential social phenomena. Social segregation, one such process, is increasingly acknowledged as a product of one's entire lived experience rather than mere residential location. Increasingly granular sources of data on human mobility have evidenced how segregation persists outside the home, in workplaces, cafes, and on the street. Yet there remains only a weak evidential link between the production of social segregation and urban policy. This study addresses this gap through an assessment of the role of the urban transportation systems in shaping social segregation. Using city-scale GPS mobility data and a novel probabilistic mobility framework, we establish social interactions at the scale of transportation infrastructure, by rail and bus service segment, individual roads, and city blocks. The outcomes show how social segregation is more than a single process in space, but varying by time of day, urban design and structure, and service design. These findings reconceptualize segregation as a product of likely encounters during one's daily mobility practice. We then extend these findings through exploratory simulations, highlighting how transportation policy to promote sustainable transport may have potentially unforeseen impacts on segregation. The study underscores that to understand social segregation and achieve positive social change urban policymakers must consider the broadest impacts of their interventions and seek to understand their impact on the daily lived experience of their citizens.","authors":["Yitao Yang","Erjian Liu","Bin Jia","Ed Manley"],"url":"https://arxiv.org/abs/2505.16337"}
{"created":"2025-05-23","title":"Dysfluent WFST: A Framework for Zero-Shot Speech Dysfluency Transcription and Detection","abstract":"Automatic detection of speech dysfluency aids speech-language pathologists in efficient transcription of disordered speech, enhancing diagnostics and treatment planning. Traditional methods, often limited to classification, provide insufficient clinical insight, and text-independent models misclassify dysfluency, especially in context-dependent cases. This work introduces Dysfluent-WFST, a zero-shot decoder that simultaneously transcribes phonemes and detects dysfluency. Unlike previous models, Dysfluent-WFST operates with upstream encoders like WavLM and requires no additional training. It achieves state-of-the-art performance in both phonetic error rate and dysfluency detection on simulated and real speech data. Our approach is lightweight, interpretable, and effective, demonstrating that explicit modeling of pronunciation behavior in decoding, rather than complex architectures, is key to improving dysfluency processing systems.","authors":["Chenxu Guo","Jiachen Lian","Xuanru Zhou","Jinming Zhang","Shuhe Li","Zongli Ye","Hwi Joo Park","Anaisha Das","Zoe Ezzes","Jet Vonk","Brittany Morin","Rian Bogley","Lisa Wauters","Zachary Miller","Maria Gorno-Tempini","Gopala Anumanchipalli"],"url":"https://arxiv.org/abs/2505.16351"}
{"created":"2025-05-23","title":"PCMamba: Physics-Informed Cross-Modal State Space Model for Dual-Camera Compressive Hyperspectral Imaging","abstract":"Panchromatic (PAN) -assisted Dual-Camera Compressive Hyperspectral Imaging (DCCHI) is a key technology in snapshot hyperspectral imaging. Existing research primarily focuses on exploring spectral information from 2D compressive measurements and spatial information from PAN images in an explicit manner, leading to a bottleneck in HSI reconstruction. Various physical factors, such as temperature, emissivity, and multiple reflections between objects, play a critical role in the process of a sensor acquiring hyperspectral thermal signals. Inspired by this, we attempt to investigate the interrelationships between physical properties to provide deeper theoretical insights for HSI reconstruction. In this paper, we propose a Physics-Informed Cross-Modal State Space Model Network (PCMamba) for DCCHI, which incorporates the forward physical imaging process of HSI into the linear complexity of Mamba to facilitate lightweight and high-quality HSI reconstruction. Specifically, we analyze the imaging process of hyperspectral thermal signals to enable the network to disentangle the three key physical properties-temperature, emissivity, and texture. By fully exploiting the potential information embedded in 2D measurements and PAN images, the HSIs are reconstructed through a physics-driven synthesis process. Furthermore, we design a Cross-Modal Scanning Mamba Block (CSMB) that introduces inter-modal pixel-wise interaction with positional inductive bias by cross-scanning the backbone features and PAN features. Extensive experiments conducted on both real and simulated datasets demonstrate that our method significantly outperforms SOTA methods in both quantitative and qualitative metrics.","authors":["Ge Meng","Zhongnan Cai","Jingyan Tu","Yingying Wang","Chenxin Li","Yue Huang","Xinghao Ding"],"url":"https://arxiv.org/abs/2505.16373"}
{"created":"2025-05-23","title":"Materials Generation in the Era of Artificial Intelligence: A Comprehensive Survey","abstract":"Materials are the foundation of modern society, underpinning advancements in energy, electronics, healthcare, transportation, and infrastructure. The ability to discover and design new materials with tailored properties is critical to solving some of the most pressing global challenges. In recent years, the growing availability of high-quality materials data combined with rapid advances in Artificial Intelligence (AI) has opened new opportunities for accelerating materials discovery. Data-driven generative models provide a powerful tool for materials design by directly create novel materials that satisfy predefined property requirements. Despite the proliferation of related work, there remains a notable lack of up-to-date and systematic surveys in this area. To fill this gap, this paper provides a comprehensive overview of recent progress in AI-driven materials generation. We first organize various types of materials and illustrate multiple representations of crystalline materials. We then provide a detailed summary and taxonomy of current AI-driven materials generation approaches. Furthermore, we discuss the common evaluation metrics and summarize open-source codes and benchmark datasets. Finally, we conclude with potential future directions and challenges in this fast-growing field. The related sources can be found at https://github.com/ZhixunLEE/Awesome-AI-for-Materials-Generation.","authors":["Zhixun Li","Bin Cao","Rui Jiao","Liang Wang","Ding Wang","Yang Liu","Dingshuo Chen","Jia Li","Qiang Liu","Yu Rong","Liang Wang","Tong-yi Zhang","Jeffrey Xu Yu"],"url":"https://arxiv.org/abs/2505.16379"}
{"created":"2025-05-23","title":"UBGAN: Enhancing Coded Speech with Blind and Guided Bandwidth Extension","abstract":"In practical application of speech codecs, a multitude of factors such as the quality of the radio connection, limiting hardware or required user experience necessitate trade-offs between achievable perceptual quality, engendered bitrate and computational complexity. Most conventional and neural speech codecs operate on wideband (WB) speech signals to achieve this compromise. To further enhance the perceptual quality of coded speech, bandwidth extension (BWE) of the transmitted speech is an attractive and popular technique in conventional speech coding. In contrast, neural speech codecs are typically trained end-to-end to a specific set of requirements and are often not easily adaptable. In particular, they are typically trained to operate at a single fixed sampling rate. With the Universal Bandwidth Extension Generative Adversarial Network (UBGAN), we propose a modular and lightweight GAN-based solution that increases the operational flexibility of a wide range of conventional and neural codecs. Our model operates in the subband domain and extends the bandwidth of WB signals from 8 kHz to 16 kHz, resulting in super-wideband (SWB) signals. We further introduce two variants, guided-UBGAN and blind-UBGAN, where the guided version transmits quantized learned representation as a side information at a very low bitrate additional to the bitrate of the codec, while blind-BWE operates without such side-information. Our subjective assessments demonstrate the advantage of UBGAN applied to WB codecs and highlight the generalization capacity of our proposed method across multiple codecs and bitrates.","authors":["Kishan Gupta","Srikanth Korse","Andreas Brendel","Nicola Pia","Guillaume Fuchs"],"url":"https://arxiv.org/abs/2505.16404"}
{"created":"2025-05-23","title":"Scaling Quantum Simulation-Based Optimization: Demonstrating Efficient Power Grid Management with Deep QAOA Circuits","abstract":"Quantum Simulation-based Optimization (QuSO) is a recently proposed class of optimization problems that entails industrially relevant problems characterized by cost functions or constraints that depend on summary statistic information about the simulation of a physical system or process. This work extends initial theoretical results that proved an up-to-exponential speedup for the simulation component of the QAOA-based QuSO solver proposed by Stein et al. for the unit commitment problem by an empirical evaluation of the optimization component using a standard benchmark dataset, the IEEE 57-bus system. Exploiting clever classical pre-computation, we develop a very efficient classical quantum circuit simulation that bypasses costly ancillary qubit requirements by the original algorithm, allowing for large-scale experiments. Utilizing more than 1000 QAOA layers and up to 20 qubits, our experiments complete a proof of concept implementation for the proposed QuSO solver, showing that it can achieve both highly competitive performance and efficiency in its optimization component compared to a standard classical baseline, i.e., simulated annealing.","authors":["Maximilian Adler","Jonas Stein","Michael Lachner"],"url":"https://arxiv.org/abs/2505.16444"}
{"created":"2025-05-23","title":"Maximum Separation of Quantum Communication Complexity With and Without Shared Entanglement","abstract":"We present relation problems whose input size is $n$ such that they can be solved with no communication for entanglement-assisted quantum communication models, but require $\\Omega(n)$ qubit communication for $2$-way quantum communication models without prior shared entanglement. This is the maximum separation of quantum communication complexity with and without shared entanglement. To our knowledge, our result is the first lower bound on quantum communication complexity without shared entanglement when the upper bound of entanglement-assisted quantum communication models is zero. The problem we consider is a parallel repetition of any non-local game which has a perfect quantum strategy and no perfect classical strategy, and for which a parallel repetition theorem for the classical value holds with exponential decay.","authors":["Atsuya Hasegawa","Fran\\c{c}ois Le Gall","Augusto Modanese"],"url":"https://arxiv.org/abs/2505.16457"}
{"created":"2025-05-23","title":"A Tutorial on Beyond-Diagonal Reconfigurable Intelligent Surfaces: Modeling, Architectures, System Design and Optimization, and Applications","abstract":"Written by its inventors, this first tutorial on Beyond-Diagonal Reconfigurable Intelligent Surfaces (BD-RISs) provides the readers with the basics and fundamental tools necessary to appreciate, understand, and contribute to this emerging and disruptive technology. Conventional (Diagonal) RISs (D-RISs) are characterized by a diagonal scattering matrix $\\mathbf{\\Theta}$ such that the wave manipulation flexibility of D-RIS is extremely limited. In contrast, BD-RIS refers to a novel and general framework for RIS where its scattering matrix is not limited to be diagonal (hence, the ``beyond-diagonal'' terminology) and consequently, all entries of $\\mathbf{\\Theta}$ can potentially help shaping waves for much higher manipulation flexibility. This physically means that BD-RIS can artificially engineer and reconfigure coupling across elements of the surface thanks to inter-element reconfigurable components which allow waves absorbed by one element to flow through other elements. Consequently, BD-RIS opens the door to more general and versatile intelligent surfaces that subsumes existing RIS architectures as special cases. In this tutorial, we share all the secret sauce to model, design, and optimize BD-RIS and make BD-RIS transformative in many different applications. Topics discussed include physics-consistent and multi-port network-aided modeling; transmitting, reflecting, hybrid, and multi-sector mode analysis; reciprocal and non-reciprocal architecture designs and optimal performance-complexity Pareto frontier of BD-RIS; signal processing, optimization, and channel estimation for BD-RIS; hardware impairments (discrete-value impedance and admittance, lossy interconnections and components, wideband effects, mutual coupling) of BD-RIS; benefits and applications of BD-RIS in communications, sensing, power transfer.","authors":["Hongyu Li","Matteo Nerini","Shanpu Shen","Bruno Clerckx"],"url":"https://arxiv.org/abs/2505.16504"}
{"created":"2025-05-23","title":"Attractor-Based Speech Separation of Multiple Utterances by Unknown Number of Speakers","abstract":"This paper addresses the problem of single-channel speech separation, where the number of speakers is unknown, and each speaker may speak multiple utterances. We propose a speech separation model that simultaneously performs separation, dynamically estimates the number of speakers, and detects individual speaker activities by integrating an attractor module. The proposed system outperforms existing methods by introducing an attractor-based architecture that effectively combines local and global temporal modeling for multi-utterance scenarios. To evaluate the method in reverberant and noisy conditions, a multi-speaker multi-utterance dataset was synthesized by combining Librispeech speech signals with WHAM! noise signals. The results demonstrate that the proposed system accurately estimates the number of sources. The system effectively detects source activities and separates the corresponding utterances into correct outputs in both known and unknown source count scenarios.","authors":["Yuzhu Wang","Archontis Politis","Konstantinos Drossos","Tuomas Virtanen"],"url":"https://arxiv.org/abs/2505.16607"}
{"created":"2025-05-23","title":"Learning non-equilibrium diffusions with Schr\\\"odinger bridges: from exactly solvable to simulation-free","abstract":"We consider the Schr\\\"odinger bridge problem which, given ensemble measurements of the initial and final configurations of a stochastic dynamical system and some prior knowledge on the dynamics, aims to reconstruct the \"most likely\" evolution of the system compatible with the data. Most existing literature assume Brownian reference dynamics and are implicitly limited to potential-driven dynamics. We depart from this regime and consider reference processes described by a multivariate Ornstein-Uhlenbeck process with generic drift matrix $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$. When $\\mathbf{A}$ is asymmetric, this corresponds to a non-equilibrium system with non-conservative forces at play: this is important for applications to biological systems, which are naturally exist out-of-equilibrium. In the case of Gaussian marginals, we derive explicit expressions that characterise the solution of both the static and dynamic Schr\\\"odinger bridge. For general marginals, we propose mvOU-OTFM, a simulation-free algorithm based on flow and score matching for learning the Schr\\\"odinger bridge. In application to a range of problems based on synthetic and real single cell data, we demonstrate that mvOU-OTFM achieves higher accuracy compared to competing methods, whilst being significantly faster to train.","authors":["Stephen Y. Zhang","Michael P H Stumpf"],"url":"https://arxiv.org/abs/2505.16644"}
{"created":"2025-05-23","title":"Sharp concentration of uniform generalization errors in binary linear classification","abstract":"We examine the concentration of uniform generalization errors around their expectation in binary linear classification problems via an isoperimetric argument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities for the joint distribution of the output labels and the label-weighted input vectors, which we apply to derive concentration bounds. The derived concentration bounds are sharp up to moderate multiplicative constants by those under well-balanced labels. In asymptotic analysis, we also show that almost sure convergence of uniform generalization errors to their expectation occurs in very broad settings, such as proportionally high-dimensional regimes. Using this convergence, we establish uniform laws of large numbers under dimension-free conditions.","authors":["Shogo Nakakita"],"url":"https://arxiv.org/abs/2505.16713"}
{"created":"2025-05-23","title":"Experimental robustness benchmark of quantum neural network on a superconducting quantum processor","abstract":"Quantum machine learning (QML) models, like their classical counterparts, are vulnerable to adversarial attacks, hindering their secure deployment. Here, we report the first systematic experimental robustness benchmark for 20-qubit quantum neural network (QNN) classifiers executed on a superconducting processor. Our benchmarking framework features an efficient adversarial attack algorithm designed for QNNs, enabling quantitative characterization of adversarial robustness and robustness bounds. From our analysis, we verify that adversarial training reduces sensitivity to targeted perturbations by regularizing input gradients, significantly enhancing QNN's robustness. Additionally, our analysis reveals that QNNs exhibit superior adversarial robustness compared to classical neural networks, an advantage attributed to inherent quantum noise. Furthermore, the empirical upper bound extracted from our attack experiments shows a minimal deviation ($3 \\times 10^{-3}$) from the theoretical lower bound, providing strong experimental confirmation of the attack's effectiveness and the tightness of fidelity-based robustness bounds. This work establishes a critical experimental framework for assessing and improving quantum adversarial robustness, paving the way for secure and reliable QML applications.","authors":["Hai-Feng Zhang","Zhao-Yun Chen","Peng Wang","Liang-Liang Guo","Tian-Le Wang","Xiao-Yan Yang","Ren-Ze Zhao","Ze-An Zhao","Sheng Zhang","Lei Du","Hao-Ran Tao","Zhi-Long Jia","Wei-Cheng Kong","Huan-Yu Liu","Athanasios V. Vasilakos","Yang Yang","Yu-Chun Wu","Ji Guan","Peng Duan","Guo-Ping Guo"],"url":"https://arxiv.org/abs/2505.16714"}
{"created":"2025-05-23","title":"Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting","abstract":"For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic and text embeddings are typically compared at either the phoneme or utterance level. To facilitate this, we optimize acoustic and text encoders using deep metric learning (DML), enabling direct comparison of multi-modal embeddings in a shared embedding space. However, the inherent heterogeneity between audio and text modalities presents a significant challenge. To address this, we propose Modality Adversarial Learning (MAL), which reduces the domain gap in heterogeneous modality representations. Specifically, we train a modality classifier adversarially to encourage both encoders to generate modality-invariant embeddings. Additionally, we apply DML to achieve phoneme-level alignment between audio and text, and conduct comprehensive comparisons across various DML objectives. Experiments on the Wall Street Journal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the proposed approach.","authors":["Youngmoon Jung","Yong-Hyeok Lee","Myunghun Jung","Jaeyoung Roh","Chang Woo Han","Hoon-Young Cho"],"url":"https://arxiv.org/abs/2505.16735"}
{"created":"2025-05-23","title":"SEED: Speaker Embedding Enhancement Diffusion Model","abstract":"A primary challenge when deploying speaker recognition systems in real-world applications is performance degradation caused by environmental mismatch. We propose a diffusion-based method that takes speaker embeddings extracted from a pre-trained speaker recognition model and generates refined embeddings. For training, our approach progressively adds Gaussian noise to both clean and noisy speaker embeddings extracted from clean and noisy speech, respectively, via forward process of a diffusion model, and then reconstructs them to clean embeddings in the reverse process. While inferencing, all embeddings are regenerated via diffusion process. Our method needs neither speaker label nor any modification to the existing speaker recognition pipeline. Experiments on evaluation sets simulating environment mismatch scenarios show that our method can improve recognition accuracy by up to 19.6% over baseline models while retaining performance on conventional scenarios. We publish our code here https://github.com/kaistmm/seed-pytorch","authors":["KiHyun Nam","Jungwoo Heo","Jee-weon Jung","Gangin Park","Chaeyoung Jung","Ha-Jin Yu","Joon Son Chung"],"url":"https://arxiv.org/abs/2505.16798"}
{"created":"2025-05-23","title":"Lp boundedness, r-nuclearity and approximation of pseudo-differential operators on $\\hbar\\mathbb{Z}^n$","abstract":"In this work sufficient conditions on the order of the symbol are developed to ensure boundedness, compactness and r-nuclearity of pseudo-differential operators in $\\hbar\\mathbb{Z}^n$. In addition, these conditions allow us to obtain growth estimates for the eigenvalues of some elliptic operators, in particular perturbed discrete Schr\\\"odinger operator.","authors":["Juan Pablo Lopez"],"url":"https://arxiv.org/abs/2505.16812"}
{"created":"2025-05-23","title":"Unlocking Temporal Flexibility: Neural Speech Codec with Variable Frame Rate","abstract":"Most neural speech codecs achieve bitrate adjustment through intra-frame mechanisms, such as codebook dropout, at a Constant Frame Rate (CFR). However, speech segments inherently have time-varying information density (e.g., silent intervals versus voiced regions). This property makes CFR not optimal in terms of bitrate and token sequence length, hindering efficiency in real-time applications. In this work, we propose a Temporally Flexible Coding (TFC) technique, introducing variable frame rate (VFR) into neural speech codecs for the first time. TFC enables seamlessly tunable average frame rates and dynamically allocates frame rates based on temporal entropy. Experimental results show that a codec with TFC achieves optimal reconstruction quality with high flexibility, and maintains competitive performance even at lower frame rates. Our approach is promising for the integration with other efforts to develop low-frame-rate neural speech codecs for more efficient downstream tasks.","authors":["Hanglei Zhang","Yiwei Guo","Zhihan Li","Xiang Hao","Xie Chen","Kai Yu"],"url":"https://arxiv.org/abs/2505.16845"}
{"created":"2025-05-23","title":"How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning","abstract":"We present a generalised Hanson-Wright inequality and use it to establish new statistical insights into the geometry of data point-clouds. In the setting of a general random function model of data, we clarify the roles played by three notions of dimensionality: ambient intrinsic dimension $p_{\\mathrm{int}}$, which measures total variability across orthogonal feature directions; correlation rank, which measures functional complexity across samples; and latent intrinsic dimension, which is the dimension of manifold structure hidden in data. Our analysis shows that in order for persistence diagrams to reveal latent homology and for manifold structure to emerge it is sufficient that $p_{\\mathrm{int}}\\gg \\log n$, where $n$ is the sample size. Informed by these theoretical perspectives, we revisit the ground-breaking neuroscience discovery of toroidal structure in grid-cell activity made by Gardner et al. (Nature, 2022): our findings reveal, for the first time, evidence that this structure is in fact isometric to physical space, meaning that grid cell activity conveys a geometrically faithful representation of the real world.","authors":["Hannah Sansford","Nick Whiteley","Patrick Rubin-Delanchy"],"url":"https://arxiv.org/abs/2505.16879"}
{"created":"2025-05-23","title":"Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference","abstract":"Graph Neural Networks (GNNs) have gained prominence for their ability to process graph-structured data across various domains. However, interpreting GNN decisions remains a significant challenge, leading to the adoption of saliency maps for identifying influential nodes and edges. Despite their utility, the reliability of GNN saliency maps has been questioned, particularly in terms of their robustness to noise. In this study, we propose a statistical testing framework to rigorously evaluate the significance of saliency maps. Our main contribution lies in addressing the inflation of the Type I error rate caused by double-dipping of data, leveraging the framework of Selective Inference. Our method provides statistically valid $p$-values while controlling the Type I error rate, ensuring that identified salient subgraphs contain meaningful information rather than random artifacts. To demonstrate the effectiveness of our method, we conduct experiments on both synthetic and real-world datasets, showing its effectiveness in assessing the reliability of GNN interpretations.","authors":["Shuichi Nishino","Tomohiro Shiraishi","Teruyuki Katsuoka","Ichiro Takeuchi"],"url":"https://arxiv.org/abs/2505.16893"}
{"created":"2025-05-23","title":"Is Circuit Depth Accurate for Comparing Quantum Circuit Runtimes?","abstract":"Although quantum circuit depth is commonly used to estimate differences in circuit runtimes, it overlooks a prevailing trait of current hardware implementation: different gates have different execution times. Consequently, the use of depth may lead to inaccurate comparisons of circuit runtimes, especially for circuits of similar scale. In this paper, we introduce an alternative metric, gate-aware depth, that uses unique gate weights, and investigate how its accuracy in comparing circuit runtimes compares to the existing metrics of traditional and multi-qubit circuit depth. To do so, we compiled a suite of 15 practical circuits using different algorithms and compared depths and runtimes between the compiled versions to determine how accurately the size of the change in depth approximated the size of the change in runtime, and how accurately the order of circuits by depth matched their order by runtime. When approximating the size of runtime changes, gate-aware depth decreased the approximation error by an average of 412 times relative to traditional depth and 124 times relative to multi-qubit depth. When matching the order of true runtimes, gate-aware depth achieved the highest accuracy on all devices and a perfect accuracy of 100% on five out of six devices. Additionally, we show that the optimal weights needed to achieve these accuracy improvements can be easily calculated using device gate times, and provide good general weight values for the IBM Eagle and Heron architectures.","authors":["Matthew Tremba","Ji Liu","Paul Hovland"],"url":"https://arxiv.org/abs/2505.16908"}
{"created":"2025-05-23","title":"Active Speech Enhancement: Active Speech Denoising Decliping and Deveraberation","abstract":"We introduce a new paradigm for active sound modification: Active Speech Enhancement (ASE). While Active Noise Cancellation (ANC) algorithms focus on suppressing external interference, ASE goes further by actively shaping the speech signal -- both attenuating unwanted noise components and amplifying speech-relevant frequencies -- to improve intelligibility and perceptual quality. To enable this, we propose a novel Transformer-Mamba-based architecture, along with a task-specific loss function designed to jointly optimize interference suppression and signal enrichment. Our method outperforms existing baselines across multiple speech processing tasks -- including denoising, dereverberation, and declipping -- demonstrating the effectiveness of active, targeted modulation in challenging acoustic environments.","authors":["Ofir Yaish","Yehuda Mishaly","Eliya Nachmani"],"url":"https://arxiv.org/abs/2505.16911"}
{"created":"2025-05-23","title":"TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation","abstract":"A reliable uncertainty estimation method is the foundation of many modern out-of-distribution (OOD) detectors, which are critical for safe deployments of deep learning models in the open world. In this work, we propose TULiP, a theoretically-driven post-hoc uncertainty estimator for OOD detection. Our approach considers a hypothetical perturbation applied to the network before convergence. Based on linearized training dynamics, we bound the effect of such perturbation, resulting in an uncertainty score computable by perturbing model parameters. Ultimately, our approach computes uncertainty from a set of sampled predictions. We visualize our bound on synthetic regression and classification datasets. Furthermore, we demonstrate the effectiveness of TULiP using large-scale OOD detection benchmarks for image classification. Our method exhibits state-of-the-art performance, particularly for near-distribution samples.","authors":["Yuhui Zhang","Dongshen Wu","Yuichiro Wada","Takafumi Kanamori"],"url":"https://arxiv.org/abs/2505.16923"}
{"created":"2025-05-23","title":"Horospherically Convex Optimization on Hadamard Manifolds Part I: Analysis and Algorithms","abstract":"Geodesic convexity (g-convexity) is a natural generalization of convexity to Riemannian manifolds. However, g-convexity lacks many desirable properties satisfied by Euclidean convexity. For instance, the natural notions of half-spaces and affine functions are themselves not g-convex. Moreover, recent studies have shown that the oracle complexity of geodesically convex optimization necessarily depends on the curvature of the manifold (Criscitiello and Boumal, 2022; Criscitiello and Boumal, 2023; Hamilton and Moitra, 2021), a computational bottleneck for several problems, e.g., tensor scaling. Recently, Lewis et al. (2024) addressed this challenge by proving curvature-independent convergence of subgradient descent, assuming horospherical convexity of the objective's sublevel sets. Using a similar idea, we introduce a generalization of convex functions to Hadamard manifolds, utilizing horoballs and Busemann functions as building blocks (as proxies for half-spaces and affine functions). We refer to this new notion as horospherical convexity (h-convexity). We provide algorithms for both nonsmooth and smooth h-convex optimization, which have curvature-independent guarantees exactly matching those from Euclidean space; this includes generalizations of subgradient descent and Nesterov's accelerated method. Motivated by applications, we extend these algorithms and their convergence rates to minimizing a sum of horospherically convex functions, assuming access to a weighted-Fr\\'echet-mean oracle.","authors":["Christopher Criscitiello","Jungbin Kim"],"url":"https://arxiv.org/abs/2505.16970"}
{"created":"2025-05-23","title":"Critical Points of Random Neural Networks","abstract":"This work investigates the expected number of critical points of random neural networks with different activation functions as the depth increases in the infinite-width limit. Under suitable regularity conditions, we derive precise asymptotic formulas for the expected number of critical points of fixed index and those exceeding a given threshold. Our analysis reveals three distinct regimes depending on the value of the first derivative of the covariance evaluated at 1: the expected number of critical points may converge, grow polynomially, or grow exponentially with depth. The theoretical predictions are supported by numerical experiments. Moreover, we provide numerical evidence suggesting that, when the regularity condition is not satisfied (e.g. for neural networks with ReLU as activation function), the number of critical points increases as the map resolution increases, indicating a potential divergence in the number of critical points.","authors":["Simmaco Di Lillo"],"url":"https://arxiv.org/abs/2505.17000"}
{"created":"2025-05-23","title":"Sufficient conditions for offline reactivation in recurrent neural networks","abstract":"During periods of quiescence, such as sleep, neural activity in many brain circuits resembles that observed during periods of task engagement. However, the precise conditions under which task-optimized networks can autonomously reactivate the same network states responsible for online behavior is poorly understood. In this study, we develop a mathematical framework that outlines sufficient conditions for the emergence of neural reactivation in circuits that encode features of smoothly varying stimuli. We demonstrate mathematically that noisy recurrent networks optimized to track environmental state variables using change-based sensory information naturally develop denoising dynamics, which, in the absence of input, cause the network to revisit state configurations observed during periods of online activity. We validate our findings using numerical experiments on two canonical neuroscience tasks: spatial position estimation based on self-motion cues, and head direction estimation based on angular velocity cues. Overall, our work provides theoretical support for modeling offline reactivation as an emergent consequence of task optimization in noisy neural circuits.","authors":["Nanda H. Krishna","Colin Bredenberg","Daniel Levenstein","Blake A. Richards","Guillaume Lajoie"],"url":"https://arxiv.org/abs/2505.17003"}
{"created":"2025-05-23","title":"iMLCA: Machine Learning-powered Iterative Combinatorial Auctions with Interval Bidding","abstract":"Preference elicitation is a major challenge in large combinatorial auctions because the bundle space grows exponentially in the number of items. Recent work has used machine learning (ML) algorithms to identify a small set of bundles to query from each bidder. However, a shortcoming of this prior work is that bidders must submit exact values for the queried bundles, which can be quite costly. To address this, we propose iMLCA, a new ML-powered iterative combinatorial auction with interval bidding (i.e., where bidders submit upper and lower bounds instead of exact values). To steer the auction towards an efficient allocation, we introduce a price-based activity rule, asking bidders to tighten bounds on relevant bundles only. In our experiments, iMLCA achieves the same allocative efficiency as the prior ML-based auction that uses exact bidding. Moreover, it outperforms the well-known combinatorial clock auction in a realistically-sized domain.","authors":["Benjamin Lubin","Manuel Beyeler","Gianluca Brero","Sven Seuken"],"url":"https://arxiv.org/abs/2009.13605"}
{"created":"2025-05-23","title":"Gaze-based dual resolution deep imitation learning for high-precision dexterous robot manipulation","abstract":"A high-precision manipulation task, such as needle threading, is challenging. Physiological studies have proposed connecting low-resolution peripheral vision and fast movement to transport the hand into the vicinity of an object, and using high-resolution foveated vision to achieve the accurate homing of the hand to the object. The results of this study demonstrate that a deep imitation learning based method, inspired by the gaze-based dual resolution visuomotor control system in humans, can solve the needle threading task. First, we recorded the gaze movements of a human operator who was teleoperating a robot. Then, we used only a high-resolution image around the gaze to precisely control the thread position when it was close to the target. We used a low-resolution peripheral image to reach the vicinity of the target. The experimental results obtained in this study demonstrate that the proposed method enables precise manipulation tasks using a general-purpose robot manipulator and improves computational efficiency. Data from this and related works are available at: https://sites.google.com/view/multi-task-fine.","authors":["Heecheol Kim","Yoshiyuki Ohmura","Yasuo Kuniyoshi"],"url":"https://arxiv.org/abs/2102.01295"}
{"created":"2025-05-23","title":"Intersection Types for a Computational Lambda-Calculus with Global State","abstract":"We study the semantics of an untyped lambda-calculus equipped with operators representing read and write operations from and to a global store. We adopt the monadic approach to model side-effects and treat read and write as algebraic operations over a monad. We introduce operational and denotational semantics and a type assignment system of intersection types and prove that types are invariant under the reduction and expansion of term and state configurations. Finally, we characterize convergent terms via their typings.","authors":["Ugo de'Liguoro","Riccardo Treglia"],"url":"https://arxiv.org/abs/2104.01358"}
{"created":"2025-05-23","title":"Transformer-based deep imitation learning for dual-arm robot manipulation","abstract":"Deep imitation learning is promising for solving dexterous manipulation tasks because it does not require an environment model and pre-programmed robot behavior. However, its application to dual-arm manipulation tasks remains challenging. In a dual-arm manipulation setup, the increased number of state dimensions caused by the additional robot manipulators causes distractions and results in poor performance of the neural networks. We address this issue using a self-attention mechanism that computes dependencies between elements in a sequential input and focuses on important elements. A Transformer, a variant of self-attention architecture, is applied to deep imitation learning to solve dual-arm manipulation tasks in the real world. The proposed method has been tested on dual-arm manipulation tasks using a real robot. The experimental results demonstrated that the Transformer-based deep imitation learning architecture can attend to the important features among the sensory inputs, therefore reducing distractions and improving manipulation performance when compared with the baseline architecture without the self-attention mechanisms. Data from this and related works are available at: https://sites.google.com/view/multi-task-fine.","authors":["Heecheol Kim","Yoshiyuki Ohmura","Yasuo Kuniyoshi"],"url":"https://arxiv.org/abs/2108.00385"}
{"created":"2025-05-23","title":"An Operator Splitting View of Federated Learning","abstract":"Over the past few years, the federated learning ($\\texttt{FL}$) community has witnessed a proliferation of new $\\texttt{FL}$ algorithms. However, our understating of the theory of $\\texttt{FL}$ is still fragmented, and a thorough, formal comparison of these algorithms remains elusive. Motivated by this gap, we show that many of the existing $\\texttt{FL}$ algorithms can be understood from an operator splitting point of view. This unification allows us to compare different algorithms with ease, to refine previous convergence results and to uncover new algorithmic variants. In particular, our analysis reveals the vital role played by the step size in $\\texttt{FL}$ algorithms. The unification also leads to a streamlined and economic way to accelerate $\\texttt{FL}$ algorithms, without incurring any communication overhead. We perform numerical experiments on both convex and nonconvex models to validate our findings.","authors":["Saber Malekmohammadi","Kiarash Shaloudegi","Zeou Hu","Yaoliang Yu"],"url":"https://arxiv.org/abs/2108.05974"}
{"created":"2025-05-23","title":"Goal-conditioned dual-action imitation learning for dexterous dual-arm robot manipulation","abstract":"Long-horizon dexterous robot manipulation of deformable objects, such as banana peeling, is a problematic task because of the difficulties in object modeling and a lack of knowledge about stable and dexterous manipulation skills. This paper presents a goal-conditioned dual-action (GC-DA) deep imitation learning (DIL) approach that can learn dexterous manipulation skills using human demonstration data. Previous DIL methods map the current sensory input and reactive action, which often fails because of compounding errors in imitation learning caused by the recurrent computation of actions. The method predicts reactive action only when the precise manipulation of the target object is required (local action) and generates the entire trajectory when precise manipulation is not required (global action). This dual-action formulation effectively prevents compounding error in the imitation learning using the trajectory-based global action while responding to unexpected changes in the target object during the reactive local action. The proposed method was tested in a real dual-arm robot and successfully accomplished the banana-peeling task. Data from this and related works are available at: https://sites.google.com/view/multi-task-fine.","authors":["Heecheol Kim","Yoshiyuki Ohmura","Yasuo Kuniyoshi"],"url":"https://arxiv.org/abs/2203.09749"}
{"created":"2025-05-23","title":"Communication-Efficient Federated Learning With Data and Client Heterogeneity","abstract":"Federated Learning (FL) enables large-scale distributed training of machine learning models, while still allowing individual nodes to maintain data locally. However, executing FL at scale comes with inherent practical challenges: 1) heterogeneity of the local node data distributions, 2) heterogeneity of node computational speeds (asynchrony), but also 3) constraints in the amount of communication between the clients and the server. In this work, we present the first variant of the classic federated averaging (FedAvg) algorithm which, at the same time, supports data heterogeneity, partial client asynchrony, and communication compression. Our algorithm comes with a novel, rigorous analysis showing that, in spite of these system relaxations, it can provide similar convergence to FedAvg in interesting parameter regimes. Experimental results in the rigorous LEAF benchmark on setups of up to 300 nodes show that our algorithm ensures fast convergence for standard federated tasks, improving upon prior quantized and asynchronous approaches.","authors":["Hossein Zakerinia","Shayan Talaei","Giorgi Nadiradze","Dan Alistarh"],"url":"https://arxiv.org/abs/2206.10032"}
{"created":"2025-05-23","title":"What is Cognitive Computing? An Architecture and State of The Art","abstract":"Cognitive Computing (COC) aims to build highly cognitive machines with low computational resources that respond in real-time. However, scholarly literature shows varying research areas and various interpretations of COC. This calls for a cohesive architecture that delineates the nature of COC. We argue that if Herbert Simon considered the design science is the science of artificial, cognitive systems are the products of cognitive science or 'the newest science of the artificial'. Therefore, building a conceptual basis for COC is an essential step into prospective cognitive computing-based systems. This paper proposes an architecture of COC through analyzing the literature on COC using a myriad of statistical analysis methods. Then, we compare the statistical analysis results with previous qualitative analysis results to confirm our findings. The study also comprehensively surveys the recent research on COC to identify the state of the art and connect the advances in varied research disciplines in COC. The study found that there are three underlaying computing paradigms, Von-Neuman, Neuromorphic Engineering and Quantum Computing, that comprehensively complement the structure of cognitive computation. The research discuss possible applications and open research directions under the COC umbrella.","authors":["Samaa Elnagar","Manoj A. Thomas","Kweku-Muata Osei-Bryson"],"url":"https://arxiv.org/abs/2301.00882"}
{"created":"2025-05-23","title":"LABO: Towards Learning Optimal Label Regularization via Bi-level Optimization","abstract":"Regularization techniques are crucial to improving the generalization performance and training efficiency of deep neural networks. Many deep learning algorithms rely on weight decay, dropout, batch/layer normalization to converge faster and generalize. Label Smoothing (LS) is another simple, versatile and efficient regularization which can be applied to various supervised classification tasks. Conventional LS, however, regardless of the training instance assumes that each non-target class is equally likely. In this work, we present a general framework for training with label regularization, which includes conventional LS but can also model instance-specific variants. Based on this formulation, we propose an efficient way of learning LAbel regularization by devising a Bi-level Optimization (LABO) problem. We derive a deterministic and interpretable solution of the inner loop as the optimal label smoothing without the need to store the parameters or the output of a trained model. Finally, we conduct extensive experiments and demonstrate our LABO consistently yields improvement over conventional label regularization on various fields, including seven machine translation and three image classification tasks across various","authors":["Peng Lu","Ahmad Rashid","Ivan Kobyzev","Mehdi Rezagholizadeh","Philippe Langlais"],"url":"https://arxiv.org/abs/2305.04971"}
{"created":"2025-05-23","title":"Compressing Neural Networks Using Tensor Networks with Exponentially Fewer Variational Parameters","abstract":"Neural network (NN) designed for challenging machine learning tasks is in general a highly nonlinear mapping that contains massive variational parameters. High complexity of NN, if unbounded or unconstrained, might unpredictably cause severe issues including \\R{overfitting}, loss of generalization power, and unbearable cost of hardware. In this work, we propose a general compression scheme that significantly reduces the variational parameters of NN's, despite of their specific types (linear, convolutional, \\textit{etc}), by encoding them to deep \\R{automatically differentiable} tensor network (ADTN) that contains exponentially-fewer free parameters. Superior compression performance of our scheme is demonstrated on several widely-recognized NN's (FC-2, LeNet-5, AlextNet, ZFNet and VGG-16) and datasets (MNIST, CIFAR-10 and CIFAR-100). For instance, we compress two linear layers in VGG-16 with approximately $10^{7}$ parameters to two ADTN's with just 424 parameters, improving the testing accuracy on CIFAR-10 from $90.17\\%$ to $91.74\\%$. We argue that the deep structure of ADTN is an essential reason for the remarkable compression performance of ADTN, compared to existing compression schemes that are mainly based on tensor decompositions/factorization and shallow tensor networks. Our work suggests deep TN as an exceptionally efficient mathematical structure for representing the variational parameters of NN's, which exhibits superior compressibility over the commonly-used matrices and multi-way arrays.","authors":["Yong Qing","Ke Li","Peng-Fei Zhou","Shi-Ju Ran"],"url":"https://arxiv.org/abs/2305.06058"}
{"created":"2025-05-23","title":"Optimal Control of Nonlinear Systems with Unknown Dynamics","abstract":"This paper presents a data-driven method for finding a closed-loop optimal controller, which minimizes a specified infinite-horizon cost function for systems with unknown dynamics given any arbitrary initial state. Suppose the closed-loop optimal controller can be parameterized by a given class of functions, hereafter referred to as the policy. The proposed method introduces a novel gradient estimation framework, which approximates the gradient of the cost function with respect to the policy parameters via integrating the Koopman operator with the classical concept of actor-critic. This enables the policy parameters to be tuned iteratively using gradient descent to achieve an optimal controller, leveraging the linearity of the Koopman operator. The convergence analysis of the proposed framework is provided. The effectiveness of the method is demonstrated through comparisons with a model-free reinforcement learning approach, and its control performance is further evaluated through simulations against model-based optimal control methods that solve the same optimal control problem utilizing the exact system dynamics.","authors":["Wenjian Hao","Paulo C. Heredia","Shaoshuai Mou"],"url":"https://arxiv.org/abs/2305.15188"}
{"created":"2025-05-23","title":"Investigating the Effects of Fairness Interventions Using Pointwise Representational Similarity","abstract":"Machine learning (ML) algorithms can often exhibit discriminatory behavior, negatively affecting certain populations across protected groups. To address this, numerous debiasing methods, and consequently evaluation measures, have been proposed. Current evaluation measures for debiasing methods suffer from two main limitations: (1) they primarily provide a global estimate of unfairness, failing to provide a more fine-grained analysis, and (2) they predominantly analyze the model output on a specific task, failing to generalize the findings to other tasks. In this work, we introduce Pointwise Normalized Kernel Alignment (PNKA), a pointwise representational similarity measure that addresses these limitations by measuring how debiasing measures affect the intermediate representations of individuals. On tabular data, the use of PNKA reveals previously unknown insights: while group fairness predominantly influences a small subset of the population, maintaining high representational similarity for the majority, individual fairness constraints uniformly impact representations across the entire population, altering nearly every data point. We show that by evaluating representations using PNKA, we can reliably predict the behavior of ML models trained on these representations. Moreover, applying PNKA to language embeddings shows that existing debiasing methods may not perform as intended, failing to remove biases from stereotypical words and sentences. Our findings suggest that current evaluation measures for debiasing methods are insufficient, highlighting the need for a deeper understanding of the effects of debiasing methods, and show how pointwise representational similarity metrics can help with fairness audits.","authors":["Camila Kolling","Till Speicher","Vedant Nanda","Mariya Toneva","Krishna P. Gummadi"],"url":"https://arxiv.org/abs/2305.19294"}
{"created":"2025-05-23","title":"On the Clean Generalization and Robust Overfitting in Adversarial Training from Two Theoretical Views: Representation Complexity and Training Dynamics","abstract":"Similar to surprising performance in the standard deep learning, deep nets trained by adversarial training also generalize well for unseen clean data (natural data). However, despite adversarial training can achieve low robust training error, there exists a significant robust generalization gap. We call this phenomenon the Clean Generalization and Robust Overfitting (CGRO). In this work, we study the CGRO phenomenon in adversarial training from two views: representation complexity and training dynamics. Specifically, we consider a binary classification setting with $N$ separated training data points. First, we prove that, based on the assumption that we assume there is $\\operatorname{poly}(D)$-size clean classifier (where $D$ is the data dimension), ReLU net with only $O(N D)$ extra parameters is able to leverages robust memorization to achieve the CGRO, while robust classifier still requires exponential representation complexity in worst case. Next, we focus on a structured-data case to analyze training dynamics, where we train a two-layer convolutional network with $O(N D)$ width against adversarial perturbation. We then show that a three-stage phase transition occurs during learning process and the network provably converges to robust memorization regime, which thereby results in the CGRO. Besides, we also empirically verify our theoretical analysis by experiments in real-image recognition datasets.","authors":["Binghui Li","Yuanzhi Li"],"url":"https://arxiv.org/abs/2306.01271"}
{"created":"2025-05-23","title":"A Deep Unrolling Model with Hybrid Optimization Structure for Hyperspectral Image Deconvolution","abstract":"In recent literature there are plenty of works that combine handcrafted and learnable regularizers to solve inverse imaging problems. While this hybrid approach has demonstrated promising results, the motivation for combining handcrafted and learnable regularizers remains largely underexplored. This work aims to justify this combination, by demonstrating that the incorporation of proper handcrafted regularizers alongside learnable regularizers not only reduces the complexity of the learnable prior, but also the performance is notably enhanced. To analyze the impact of this synergy, we introduce the notion of residual structure, to refer to the structure of the solution that cannot be modeled by the handcrafted regularizers per se. Motivated by these, we propose a novel optimization framework for the hyperspectral deconvolution problem, called DeepMix. Based on the proposed optimization framework, an interpretable model is developed using the deep unrolling strategy, which consists of three distinct modules, namely, a data consistency module, a module that enforces the effect of the handcrafted regularizers, and a denoising module. Recognizing the collaborative nature of these modules, this work proposes a context aware denoising module designed to sustain the advancements achieved by the cooperative efforts of the other modules. This is facilitated through the incorporation of a proper skip connection, ensuring that essential details and structures identified by other modules are effectively retained and not lost during denoising. Extensive experimental results across simulated and real-world datasets demonstrate that DeepMix is notable for surpassing existing methodologies, offering marked improvements in both image quality and computational efficiency.","authors":["Alexandros Gkillas","Dimitris Ampeliotis","Kostas Berberidis"],"url":"https://arxiv.org/abs/2306.06378"}
{"created":"2025-05-23","title":"Differential approximation of the Gaussian by short cosine sums with exponential error decay","abstract":"In this paper, we propose a method to approximate the Gaussian function on ${\\mathbb R}$ by a short cosine sum. We generalise and extend the differential approximation method proposed in [4, 40] to approximate $\\mathrm{e}^{-t^{2}/2\\sigma}$ in the weighted space $L^{2}({\\mathbb R}, \\mathrm{e}^{-t^{2}/2\\rho})$ where $\\sigma, \\, \\rho >0$. We prove that the optimal frequency parameters $\\lambda_1, \\ldots , \\lambda_{N}$ for this method in the approximation problem $ \\min\\limits_{\\lambda_{1},\\ldots, \\lambda_{N}, \\gamma_{1}, \\ldots, \\gamma_{N}}\\|\\mathrm{e}^{-\\cdot^{2}/2\\sigma} - \\sum_{j=1}^{N} \\gamma_{j} \\, {\\mathrm e}^{\\lambda_{j} \\cdot}\\|_{L^{2}({\\mathbb R}, \\mathrm{e}^{-t^{2}/2\\rho})}$, are zeros of a scaled Hermite polynomial. This observation leads us to a numerically stable approximation method with low computational cost of ${\\mathcal O}(N^{3})$ operations. We derive a direct algorithm to solve this approximation problem based on a matrix pencil method for a special structured matrix. The entries of this matrix are determined by hypergeometric functions. For the weighted $L^{2}$-norm, we prove that the approximation error decays exponentially with respect to the length $N$ of the sum. An exponentially decaying error in the (unweighted) $L^{2}$-norm is achieved using a truncated cosine sum. Our new convergence result for approximation of Gaussian functions by exponential sums of length $N$ shows that exponential error decay rates $e^{-cN}$ are not only achievable for complete monotone functions.","authors":["Nadiia Derevianko","Gerlind Plonka"],"url":"https://arxiv.org/abs/2307.13587"}
{"created":"2025-05-23","title":"SegMatch: A semi-supervised learning method for surgical instrument segmentation","abstract":"Surgical instrument segmentation is recognised as a key enabler in providing advanced surgical assistance and improving computer-assisted interventions. In this work, we propose SegMatch, a semi-supervised learning method to reduce the need for expensive annotation for laparoscopic and robotic surgical images. SegMatch builds on FixMatch, a widespread semi supervised classification pipeline combining consistency regularization and pseudo-labelling, and adapts it for the purpose of segmentation. In our proposed SegMatch, the unlabelled images are first weakly augmented and fed to the segmentation model to generate pseudo-labels. In parallel, images are fed to a strong augmentation branch and consistency between the branches is used as an unsupervised loss. To increase the relevance of our strong augmentations, we depart from using only handcrafted augmentations and introduce a trainable adversarial augmentation strategy. Our FixMatch adaptation for segmentation tasks further includes carefully considering the equivariance and invariance properties of the augmentation functions we rely on. For binary segmentation tasks, our algorithm was evaluated on the MICCAI Instrument Segmentation Challenge datasets, Robust-MIS 2019 and EndoVis 2017. For multi-class segmentation tasks, we relied on the recent CholecInstanceSeg dataset. Our results show that SegMatch outperforms fully-supervised approaches by incorporating unlabelled data, and surpasses a range of state-of-the-art semi-supervised models across different labelled to unlabelled data ratios.","authors":["Meng Wei","Charlie Budd","Luis C. Garcia-Peraza-Herrera","Reuben Dorent","Miaojing Shi","Tom Vercauteren"],"url":"https://arxiv.org/abs/2308.05232"}
{"created":"2025-05-23","title":"Neural Influence Estimator: Towards Real-time Solutions to Influence Blocking Maximization","abstract":"Real-time solutions to the influence blocking maximization (IBM) problems are crucial for promptly containing the spread of misinformation. However, achieving this goal is non-trivial, mainly because assessing the blocked influence of an IBM problem solution typically requires plenty of expensive Monte Carlo simulations (MCSs). This work presents a novel approach that enables solving IBM problems with hundreds of thousands of nodes and edges in seconds. The key idea is to construct a fast-to-evaluate surrogate model called neural influence estimator (NIE) offline as a substitute for the time-intensive MCSs, and then combine it with optimization algorithms to address IBM problems online. To this end, a learning problem is formulated to build the NIE that takes the false-and-true information instance as input, extracts features describing the topology and inter-relationship between two seed sets, and predicts the blocked influence. A well-trained NIE can generalize across different IBM problems given a social network, and can be readily combined with existing IBM optimization algorithms. The experiments on 25 IBM problems with up to millions of edges show that the NIE-based optimization method can be up to four orders of magnitude faster than MCSs-based optimization method to achieve the same optimization quality. Moreover, given a one-minute limit, the NIE-based method can solve IBM problems with up to hundreds of thousands of nodes, which is at least one order of magnitude larger than what can be solved by existing methods.","authors":["Wenjie Chen","Shengcai Liu","Yew-Soon Ong","Zhuang Li","Ke Tang"],"url":"https://arxiv.org/abs/2308.14012"}
{"created":"2025-05-23","title":"Homotopy-Aware Multi-Agent Path Planning on Plane","abstract":"We propose an efficient framework using Dynnikov coordinates for homotopy-aware multi-agent path planning in planar domains that may contain obstacles. We developed a method for generating multiple homotopically distinct solutions for the multi-agent path planning problem in planar domains by combining our framework with revised prioritized planning and proved its completeness under specific assumptions. Experimentally, we demonstrated that our method is significantly faster than a method without Dynnikov coordinates. We also confirmed experimentally that homotopy-aware planning contributes to avoiding locally optimal solutions when searching for low-cost trajectories for a swarm of agents in a continuous environment.","authors":["Kazumi Kasaura"],"url":"https://arxiv.org/abs/2310.01945"}
{"created":"2025-05-23","title":"Language Models are Universal Embedders","abstract":"In the large language model (LLM) revolution, embedding is a key component of various systems, such as retrieving knowledge or memories for LLMs or building content moderation filters. As such cases span from English to other natural or programming languages, from retrieval to classification and beyond, it is advantageous to build a unified embedding model rather than dedicated ones for each scenario. In this context, the pre-trained multilingual decoder-only large language models, e.g., BLOOM, emerge as a viable backbone option. To assess their potential, we propose straightforward strategies for constructing embedders and introduce a universal evaluation benchmark. Experimental results show that our trained model is proficient at generating good embeddings across languages and tasks, even extending to languages and tasks for which no finetuning/pretraining data is available. We also present detailed analyses and additional evaluations. We hope that this work could encourage the development of more robust open-source universal embedders.","authors":["Xin Zhang","Zehan Li","Yanzhao Zhang","Dingkun Long","Pengjun Xie","Meishan Zhang","Min Zhang"],"url":"https://arxiv.org/abs/2310.08232"}
{"created":"2025-05-23","title":"Unsupervised Log Anomaly Detection with Few Unique Tokens","abstract":"This article introduces a novel method for detecting anomalies within log data from control system nodes at the European XFEL accelerator. Effective anomaly detection is crucial for providing operators with a clear understanding of each node's availability, status, and potential problems, thereby ensuring smooth accelerator operation. Traditional and learning-based anomaly detection methods face significant limitations due to the sequential nature of these logs and the lack of a rich, node-specific text corpus. To address this, we propose an approach utilizing word embeddings to represent log entries and a Hidden Markov Model (HMM) to model the typical sequential patterns of these embeddings for individual nodes. Anomalies are identified by scoring individual log entries based on a probability ratio: this ratio compares the likelihood of the log sequence including the new entry against its likelihood without it, effectively measuring how well the new entry fits the established pattern. High scores indicate potential anomalies that deviate from the node's routine behavior. This method functions as a warning system, alerting operators to irregular log events that may signify underlying issues, thereby facilitating proactive intervention.","authors":["Antonin Sulc","Annika Eichler","Tim Wilksen"],"url":"https://arxiv.org/abs/2310.08951"}
{"created":"2025-05-23","title":"Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination","abstract":"Over the past decade, deep learning has proven to be a highly effective tool for learning meaningful features from raw data. However, it remains an open question how deep networks perform hierarchical feature learning across layers. In this work, we attempt to unveil this mystery by investigating the structures of intermediate features. Motivated by our empirical findings that linear layers mimic the roles of deep layers in nonlinear networks for feature learning, we explore how deep linear networks transform input data into output by investigating the output (i.e., features) of each layer after training in the context of multi-class classification problems. Toward this goal, we first define metrics to measure within-class compression and between-class discrimination of intermediate features, respectively. Through theoretical analysis of these two metrics, we show that the evolution of features follows a simple and quantitative pattern from shallow to deep layers when the input data is nearly orthogonal and the network weights are minimum-norm, balanced, and approximate low-rank: Each layer of the linear network progressively compresses within-class features at a geometric rate and discriminates between-class features at a linear rate with respect to the number of layers that data have passed through. To the best of our knowledge, this is the first quantitative characterization of feature evolution in hierarchical representations of deep linear networks. Empirically, our extensive experiments not only validate our theoretical results numerically but also reveal a similar pattern in deep nonlinear networks which aligns well with recent empirical studies. Moreover, we demonstrate the practical implications of our results in transfer learning. Our code is available at https://github.com/Heimine/PNC_DLN.","authors":["Peng Wang","Xiao Li","Can Yaras","Zhihui Zhu","Laura Balzano","Wei Hu","Qing Qu"],"url":"https://arxiv.org/abs/2311.02960"}
{"created":"2025-05-23","title":"Maximizing Discrimination Capability of Knowledge Distillation with Energy Function","abstract":"To apply the latest computer vision techniques that require a large computational cost in real industrial applications, knowledge distillation methods (KDs) are essential. Existing logit-based KDs apply the constant temperature scaling to all samples in dataset, limiting the utilization of knowledge inherent in each sample individually. In our approach, we classify the dataset into two categories (i.e., low energy and high energy samples) based on their energy score. Through experiments, we have confirmed that low energy samples exhibit high confidence scores, indicating certain predictions, while high energy samples yield low confidence scores, meaning uncertain predictions. To distill optimal knowledge by adjusting non-target class predictions, we apply a higher temperature to low energy samples to create smoother distributions and a lower temperature to high energy samples to achieve sharper distributions. When compared to previous logit-based and feature-based methods, our energy-based KD (Energy KD) achieves better performance on various datasets. Especially, Energy KD shows significant improvements on CIFAR-100-LT and ImageNet datasets, which contain many challenging samples. Furthermore, we propose high energy-based data augmentation (HE-DA) for further improving the performance. We demonstrate that higher performance improvement could be achieved by augmenting only a portion of the dataset rather than the entire dataset, suggesting that it can be employed on resource-limited devices. To the best of our knowledge, this paper represents the first attempt to make use of energy function in knowledge distillation and data augmentation, and we believe it will greatly contribute to future research.","authors":["Seonghak Kim","Gyeongdo Ham","Suin Lee","Donggon Jang","Daeshik Kim"],"url":"https://arxiv.org/abs/2311.14334"}
{"created":"2025-05-23","title":"A Survey on Design Methodologies for Accelerating Deep Learning on Heterogeneous Architectures","abstract":"Given their increasing size and complexity, the need for efficient execution of deep neural networks has become increasingly pressing in the design of heterogeneous High-Performance Computing (HPC) and edge platforms, leading to a wide variety of proposals for specialized deep learning architectures and hardware accelerators. The design of such architectures and accelerators requires a multidisciplinary approach combining expertise from several areas, from machine learning to computer architecture, low-level hardware design, and approximate computing. Several methodologies and tools have been proposed to improve the process of designing accelerators for deep learning, aimed at maximizing parallelism and minimizing data movement to achieve high performance and energy efficiency. This paper critically reviews influential tools and design methodologies for Deep Learning accelerators, offering a wide perspective in this rapidly evolving field. This work complements surveys on architectures and accelerators by covering hardware-software co-design, automated synthesis, domain-specific compilers, design space exploration, modeling, and simulation, providing insights into technical challenges and open research directions.","authors":["Serena Curzel","Fabrizio Ferrandi","Leandro Fiorin","Daniele Ielmini","Cristina Silvano","Francesco Conti","Luca Bompani","Luca Benini","Enrico Calore","Sebastiano Fabio Schifano","Cristian Zambelli","Maurizio Palesi","Giuseppe Ascia","Enrico Russo","Valeria Cardellini","Salvatore Filippone","Francesco Lo Presti","Stefania Perri"],"url":"https://arxiv.org/abs/2311.17815"}
{"created":"2025-05-23","title":"Large Language Models are Miscalibrated In-Context Learners","abstract":"When adapting ICL with or without fine-tuning, we are curious about whether the instruction-tuned language model is able to achieve well-calibrated results without suffering from the problem of overconfidence (i.e., miscalibration) considering its strong instruction following ability, especially in such limited data setups. In this work, we deliver an in-depth analysis of the behavior across different choices of learning methods from the perspective of both performance and calibration. Through extensive controlled experiments, we observe that the miscalibration problem exists across all learning methods in low-resource setups. To achieve simultaneous gain for both in-task performance and calibration, we then study the potential of self-ensembling applied at different modeling stages (e.g., variations of in-context examples or variations in prompts or different ensembling strategies) to make the predictions more calibrated and have comparable or even better performance. We find that self-ensembling with max probability produces robust and calibrated predictions. Our work reveals the potential calibration problem of using ICL despite the improvements in task performance and sheds light on which learning paradigm to choose. We also provide practical guidelines for choosing learning paradigms depending on whether the data has been seen by the model before and a worthwhile solution via self-ensembling on how to enhance both task performance and calibration of LMs, which we hope could encourage further study.","authors":["Chengzu Li","Han Zhou","Goran Glava\\v{s}","Anna Korhonen","Ivan Vuli\\'c"],"url":"https://arxiv.org/abs/2312.13772"}
{"created":"2025-05-23","title":"Leveraging Habitat Information for Fine-grained Bird Identification","abstract":"Traditional bird classifiers mostly rely on the visual characteristics of birds. Some prior works even train classifiers to be invariant to the background, completely discarding the living environment of birds. Instead, we are the first to explore integrating habitat information, one of the four major cues for identifying birds by ornithologists, into modern bird classifiers. We focus on two leading model types: (1) CNNs and ViTs trained on the downstream bird datasets; and (2) original, multi-modal CLIP. Training CNNs and ViTs with habitat-augmented data results in an improvement of up to +0.83 and +0.23 points on NABirds and CUB-200, respectively. Similarly, adding habitat descriptors to the prompts for CLIP yields a substantial accuracy boost of up to +0.99 and +1.1 points on NABirds and CUB-200, respectively. We find consistent accuracy improvement after integrating habitat features into the image augmentation process and into the textual descriptors of vision-language CLIP classifiers. Code is available at: https://anonymous.4open.science/r/reasoning-8B7E/.","authors":["Tin Nguyen","Peijie Chen","Anh Totti Nguyen"],"url":"https://arxiv.org/abs/2312.14999"}
{"created":"2025-05-23","title":"Combining SNNs with Filtering for Efficient Neural Decoding in Implantable Brain-Machine Interfaces","abstract":"While it is important to make implantable brain-machine interfaces (iBMI) wireless to increase patient comfort and safety, the trend of increased channel count in recent neural probes poses a challenge due to the concomitant increase in the data rate. Extracting information from raw data at the source by using edge computing is a promising solution to this problem, with integrated intention decoders providing the best compression ratio. Recent benchmarking efforts have shown recurrent neural networks to be the best solution. Spiking Neural Networks (SNN) emerge as a promising solution for resource efficient neural decoding while Long Short Term Memory (LSTM) networks achieve the best accuracy. In this work, we show that combining traditional signal processing techniques, namely signal filtering, with SNNs improve their decoding performance significantly for regression tasks, closing the gap with LSTMs, at little added cost. Results with different filters are shown with Bessel filters providing best performance. Two block-bidirectional Bessel filters have been used--one for low latency and another for high accuracy. Adding the high accuracy variant of the Bessel filters to the output of ANN, SNN and variants provided statistically significant benefits with maximum gains of $\\approx 5\\%$ and $8\\%$ in $R^2$ for two SNN topologies (SNN\\_Streaming and SNN\\_3D). Our work presents state of the art results for this dataset and paves the way for decoder-integrated-implants of the future.","authors":["Biyan Zhou","Pao-Sheng Vincent Sun","Arindam Basu"],"url":"https://arxiv.org/abs/2312.15889"}
{"created":"2025-05-23","title":"Fast Sampling Through The Reuse Of Attention Maps In Diffusion Models","abstract":"Text-to-image diffusion models have demonstrated unprecedented capabilities for flexible and realistic image synthesis. Nevertheless, these models rely on a time-consuming sampling procedure, which has motivated attempts to reduce their latency. When improving efficiency, researchers often use the original diffusion model to train an additional network designed specifically for fast image generation. In contrast, our approach seeks to reduce latency directly, without any retraining, fine-tuning, or knowledge distillation. In particular, we find the repeated calculation of attention maps to be costly yet redundant, and instead suggest reusing them during sampling. Our specific reuse strategies are based on ODE theory, which implies that the later a map is reused, the smaller the distortion in the final image. We empirically compare our reuse strategies with few-step sampling procedures of comparable latency, finding that reuse generates images that are closer to those produced by the original high-latency diffusion model.","authors":["Rosco Hunter","{\\L}ukasz Dudziak","Mohamed S. Abdelfattah","Abhinav Mehrotra","Sourav Bhattacharya","Hongkai Wen"],"url":"https://arxiv.org/abs/2401.01008"}
{"created":"2025-05-23","title":"Accelerating Maximal Biclique Enumeration on GPUs","abstract":"Maximal Biclique Enumeration (MBE) holds critical importance in graph theory with applications extending across fields such as bioinformatics, social networks, and recommendation systems. However, its computational complexity presents barriers for efficiently scaling to large graphs. To address these challenges, we introduce cuMBE, a GPU-optimized parallel algorithm for MBE. Utilizing a unique data structure, called compact array, cuMBE eradicates the need for recursion, thereby significantly minimizing dynamic memory requirements and computational overhead. The algorithm utilizes a hybrid parallelism approach, in which GPU thread blocks handle coarse-grained tasks associated with part of the search process. Besides, we implement three fine-grained optimizations within each thread block to enhance performance. Further, we integrate a work-stealing mechanism to mitigate workload imbalances among thread blocks. Our experiments reveal that cuMBE achieves an geometric mean speedup of 4.02x and 4.13x compared to the state-of-the-art serial algorithm and parallel CPU-based algorithm on both common and real-world datasets, respectively.","authors":["Chou-Ying Hsieh","Chia-Ming Chang","Po-Hsiu Cheng","Sy-Yen Kuo"],"url":"https://arxiv.org/abs/2401.05039"}
{"created":"2025-05-23","title":"Demystifying Variational Diffusion Models","abstract":"Despite the growing interest in diffusion models, gaining a deep understanding of the model class remains an elusive endeavour, particularly for the uninitiated in non-equilibrium statistical physics. Thanks to the rapid rate of progress in the field, most existing work on diffusion models focuses on either applications or theoretical contributions. Unfortunately, the theoretical material is often inaccessible to practitioners and new researchers, leading to a risk of superficial understanding in ongoing research. Given that diffusion models are now an indispensable tool, a clear and consolidating perspective on the model class is needed to properly contextualize recent advances in generative modelling and lower the barrier to entry for new researchers. To that end, we revisit predecessors to diffusion models like hierarchical latent variable models and synthesize a holistic perspective using only directed graphical modelling and variational inference principles. The resulting narrative is easier to follow as it imposes fewer prerequisites on the average reader relative to the view from non-equilibrium thermodynamics or stochastic differential equations.","authors":["Fabio De Sousa Ribeiro","Ben Glocker"],"url":"https://arxiv.org/abs/2401.06281"}
{"created":"2025-05-23","title":"Multilevel lattice codes from Hurwitz quaternion integers","abstract":"This work presents an extension of the Construction $\\pi_A$ lattices proposed in \\cite{huang2017construction}, to Hurwitz quaternion integers. This construction is provided by using an isomorphism from a version of the Chinese remainder theorem applied to maximal orders in contrast to natural orders in prior works. Exploiting this map, we analyze the performance of the resulting multilevel lattice codes, highlight via computer simulations their notably reduced computational complexity provided by the multistage decoding. Moreover it is shown that this construction effectively attain the Poltyrev-limit.","authors":["Juliana G. F. Souza","Sueli I. R. Costa","Cong Ling"],"url":"https://arxiv.org/abs/2401.10773"}
{"created":"2025-05-23","title":"EntGPT: Entity Linking with Generative Large Language Models","abstract":"Entity Linking in natural language processing seeks to match text entities to their corresponding entries in a dictionary or knowledge base. Traditional approaches rely on contextual models, which can be complex, hard to train, and have limited transferability across different domains. Generative large language models like GPT offer a promising alternative but often underperform with naive prompts. In this study, we introduce EntGPT, employing advanced prompt engineering to enhance EL tasks. Our three-step hard-prompting method (EntGPT-P) significantly boosts the micro-F_1 score by up to 36% over vanilla prompts, achieving competitive performance across 10 datasets without supervised fine-tuning. Additionally, our instruction tuning method (EntGPT-I) improves micro-F_1 scores by 2.1% on average in supervised EL tasks and outperforms several baseline models in six Question Answering tasks. Our methods are compatible with both open-source and proprietary LLMs. All data and code are available on GitHub at https://github.com/yifding/In_Context_EL.","authors":["Yifan Ding","Amrit Poudel","Qingkai Zeng","Tim Weninger","Balaji Veeramani","Sanmitra Bhattacharya"],"url":"https://arxiv.org/abs/2402.06738"}
{"created":"2025-05-23","title":"Reading Rational Univariate Representations on lexicographic Groebner bases","abstract":"In this contribution, we consider a zero-dimensional polynomial system in $n$ variables defined over a field $\\mathbb{K}$. In the context of computing a Rational Univariate Representation (RUR) of its solutions, we address the problem of certifying a separating linear form and, once certified, calculating the RUR that comes from it, without any condition on the ideal else than being zero-dimensional. Our key result is that the RUR can be read (closed formula) from lexicographic Groebner bases of bivariate elimination ideals, even in the case where the original ideal that is not in shape position, so that one can use the same core as the well known FGLM method to propose a simple algorithm. Our first experiments, either with a very short code (300 lines) written in Maple or with a Julia code using straightforward implementations performing only classical Gaussian reductions in addition to Groebner bases for the degree reverse lexicographic ordering, show that this new method is already competitive with sophisticated state of the art implementations which do not certify the parameterizations.","authors":["Alexander Demin","Fabrice Rouillier","Joao Ruiz"],"url":"https://arxiv.org/abs/2402.07141"}
{"created":"2025-05-23","title":"DePLOI: Applying NL2SQL to Synthesize and Audit Database Access Control","abstract":"In every enterprise database, administrators must define an access control policy that specifies which users have access to which tables. Access control straddles two worlds: policy (organization-level principles that define who should have access) and process (database-level primitives that actually implement the policy). Assessing and enforcing process compliance with a policy is a manual and ad-hoc task. This paper introduces a new access control model called Intent-Based Access Control for Databases (IBAC-DB). In IBAC-DB, access control policies are expressed using abstractions that scale to high numbers of database objects, and are traceable with respect to implementations. This paper proposes DePLOI (Deployment Policy Linter for Organization Intents), a LLM-backed system leveraging access control-specific task decompositions to accurately synthesize and audit access control implementation from IBAC-DB abstractions. As DePLOI is the first system of its kind to our knowledge, this paper further proposes IBACBench, the first benchmark for evaluating the synthesis and auditing capabilities of DePLOI. IBACBench leverages a combination of current NL2SQL benchmarks, real-world role hierarchies and access control policies, and LLM-generated data. We find that DePLOI achieves high synthesis accuracies and auditing F1 scores overall, and greatly outperforms other LLM prompting strategies (e.g., by 10 F1 points).","authors":["Pranav Subramaniam","Sanjay Krishnan"],"url":"https://arxiv.org/abs/2402.07332"}
{"created":"2025-05-23","title":"CodeMind: Evaluating Large Language Models for Code Reasoning","abstract":"Large Language Models (LLMs) have been widely used to automate programming tasks. Their capabilities have been evaluated by assessing the quality of generated code through tests or proofs. The extent to which they can reason about code is a critical question revealing important insights about their true capabilities. This paper introduces CodeMind, a framework designed to gauge the code reasoning abilities of LLMs through the following explicit and implicit code reasoning tasks: Independent Execution Reasoning (IER), Specification Reasoning (SR) and Dynamic Semantics Reasoning (DSR). The first evaluates the abilities of LLMs to simulate the execution of given inputs to a code and predict the output (IER). The second assesses the abilities of LLMs to incorporate the simulation of test data in the specification into code generation (SR). Finally, CodeMind evaluates LLMs' abilities to understand overall code semantics only given a specific input/output (DSR). Our extensive evaluation of ten LLMs across four widely used benchmarks using CodeMind shows that LLMs, depending on their size and training strategy, can reason about some dynamic aspects of code. However, their performance drops for code with higher complexity, non-trivial logical and arithmetic operators, non-primitive types, and API calls. We show that these reasoning tasks evaluate LLMs differently, and a comprehensive evaluation of code reasoning requires them all. Finally, we show that the performance of LLMs in bug repair is not correlated with any of the code reasoning tasks, and except for advanced frontier models, other LLMs do not incorporate code reasoning when performing bug repair.","authors":["Changshu Liu","Yang Chen","Reyhaneh Jabbarvand"],"url":"https://arxiv.org/abs/2402.09664"}
{"created":"2025-05-23","title":"Non-Adaptive Multi-Stage Algorithm and Bounds for Group Testing with Prior Statistics","abstract":"In this paper, we propose an efficient multi-stage algorithm for non-adaptive Group Testing (GT) with general correlated prior statistics. The proposed solution can be applied to any correlated statistical prior represented in trellis, e.g., finite state machines and Markov processes. We introduce a variation of List Viterbi Algorithm (LVA) to enable accurate recovery using much fewer tests than objectives, which efficiently gains from the correlated prior statistics structure. We also provide a sufficiency bound to the number of pooled tests required by any Maximum A Posteriori (MAP) decoder with an arbitrary correlation between infected items. Our numerical results demonstrate that the proposed Multi-Stage GT (MSGT) algorithm can obtain the optimal MAP performance with feasible complexity in practical regimes, such as with COVID-19 and sparse signal recovery applications, and reduce in the scenarios tested the number of pooled tests by at least 25% compared to existing classical low complexity GT algorithms. Moreover, we analytically characterize the complexity of the proposed MSGT algorithm that guarantees its efficiency.","authors":["Ayelet C. Portnoy","Amit Solomon","Alejandro Cohen"],"url":"https://arxiv.org/abs/2402.10018"}
{"created":"2025-05-23","title":"Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning","abstract":"Instruction tuning for large language models (LLMs) can drive them to produce results consistent with human goals in specific downstream tasks. However, the process of continual instruction tuning (CIT) for LLMs may bring about the catastrophic forgetting (CF) problem, where previously learned abilities are degraded. Recent methods try to alleviate the CF problem by modifying models or replaying data, which may only remember the surface-level pattern of instructions and get confused on held-out tasks. In this paper, we propose a novel continual instruction tuning method based on Key-part Information Gain (KPIG). Our method computes the information gain on masked parts to dynamically replay data and refine the training objective, which enables LLMs to capture task-aware information relevant to the correct response and alleviate overfitting to general descriptions in instructions. In addition, we propose two metrics, P-score and V-score, to measure the generalization and instruction-following abilities of LLMs. Experiments demonstrate our method achieves superior performance on both seen and held-out tasks.","authors":["Yongquan He","Wenyuan Zhang","Xuancheng Huang","Peng Zhang"],"url":"https://arxiv.org/abs/2403.10056"}
{"created":"2025-05-23","title":"FairSIN: Achieving Fairness in Graph Neural Networks through Sensitive Information Neutralization","abstract":"Despite the remarkable success of graph neural networks (GNNs) in modeling graph-structured data, like other machine learning models, GNNs are also susceptible to making biased predictions based on sensitive attributes, such as race and gender. For fairness consideration, recent state-of-the-art (SOTA) methods propose to filter out sensitive information from inputs or representations, e.g., edge dropping or feature masking. However, we argue that such filtering-based strategies may also filter out some non-sensitive feature information, leading to a sub-optimal trade-off between predictive performance and fairness. To address this issue, we unveil an innovative neutralization-based paradigm, where additional Fairness-facilitating Features (F3) are incorporated into node features or representations before message passing. The F3 are expected to statistically neutralize the sensitive bias in node representations and provide additional nonsensitive information. We also provide theoretical explanations for our rationale, concluding that F3 can be realized by emphasizing the features of each node's heterogeneous neighbors (neighbors with different sensitive attributes). We name our method as FairSIN, and present three implementation variants from both data-centric and model-centric perspectives. Experimental results on five benchmark datasets with three different GNN backbones show that FairSIN significantly improves fairness metrics while maintaining high prediction accuracies.","authors":["Cheng Yang","Jixi Liu","Yunhe Yan","Chuan Shi"],"url":"https://arxiv.org/abs/2403.12474"}
{"created":"2025-05-23","title":"OSVAuto: automatic proofs about functional specifications in OS verification","abstract":"We present OSVAuto for automatic proofs about functional specifications that commonly arise when verifying operating system kernels. The algorithm behind OSVAuto is designed to support natively those data types that commonly occur in OS verification, including sequences, maps, structures and enumerations. Propositions about these data are encoded into a form that is suitable for SMT solving. For quantifier instantiation, we propose an extension of recent work for automatic proofs about sequences. We evaluate the algorithm on proof obligations adapted from existing verification of the uC-OS/II kernel in Coq, demonstrating that a large number of proof obligations can be solved automatically, significantly reducing the proof effort on the functional side.","authors":["Yulun Wu","Bican Xia","Jiale Xu","Bohua Zhan","Tianqi Zhao"],"url":"https://arxiv.org/abs/2403.13457"}
{"created":"2025-05-23","title":"Initialisation and Network Effects in Decentralised Federated Learning","abstract":"Fully decentralised federated learning enables collaborative training of individual machine learning models on a distributed network of communicating devices while keeping the training data localised on each node. This approach avoids central coordination, enhances data privacy and eliminates the risk of a single point of failure. Our research highlights that the effectiveness of decentralised federated learning is significantly influenced by the network topology of connected devices and the learning models' initial conditions. We propose a strategy for uncoordinated initialisation of the artificial neural networks based on the distribution of eigenvector centralities of the underlying communication network, leading to a radically improved training efficiency. Additionally, our study explores the scaling behaviour and the choice of environmental parameters under our proposed initialisation strategy. This work paves the way for more efficient and scalable artificial neural network training in a distributed and uncoordinated environment, offering a deeper understanding of the intertwining roles of network structure and learning dynamics.","authors":["Arash Badie-Modiri","Chiara Boldrini","Lorenzo Valerio","J\\'anos Kert\\'esz","M\\'arton Karsai"],"url":"https://arxiv.org/abs/2403.15855"}
{"created":"2025-05-23","title":"Missing Pieces: How Do Designs that Expose Uncertainty Longitudinally Impact Trust in AI Decision Aids? An In Situ Study of Gig Drivers","abstract":"Decision aids based on artificial intelligence (AI) induce a wide range of outcomes when they are deployed in uncertain environments. In this paper, we investigate how users' trust in recommendations from an AI decision aid is impacted over time by designs that expose uncertainty in predicted outcomes. Unlike previous work, we focus on gig driving - a real-world, repeated decision-making context. We report on a longitudinal mixed-methods study ($n=51$) where we measured gig drivers' trust as they interacted with an AI-based schedule recommendation tool. Our results show that participants' trust in the tool was shaped by both their first impressions of its accuracy and their longitudinal interactions with it; and that task-aligned framings of uncertainty improved trust by allowing participants to incorporate uncertainty into their decision-making processes. Additionally, we observed that trust depended on their characteristics as drivers, underscoring the need for more in situ studies of AI decision aids.","authors":["Rex Chen","Ruiyi Wang","Fei Fang","Norman Sadeh"],"url":"https://arxiv.org/abs/2404.06432"}
{"created":"2025-05-23","title":"Causal Deconfounding via Confounder Disentanglement for Dual-Target Cross-Domain Recommendation","abstract":"In recent years, dual-target Cross-Domain Recommendation (CDR) has been proposed to capture comprehensive user preferences in order to ultimately enhance the recommendation accuracy in both data-richer and data-sparser domains simultaneously. However, in addition to users' true preferences, the user-item interactions might also be affected by confounders (e.g., free shipping, sales promotion). As a result, dual-target CDR has to meet two challenges: (1) how to effectively decouple observed confounders, including single-domain confounders and cross-domain confounders, and (2) how to preserve the positive effects of observed confounders on predicted interactions, while eliminating their negative effects on capturing comprehensive user preferences. To address the above two challenges, we propose a Causal Deconfounding framework via Confounder Disentanglement for dual-target Cross-Domain Recommendation, called CD2CDR. In CD2CDR, we first propose a confounder disentanglement module to effectively decouple observed single-domain and cross-domain confounders. We then propose a causal deconfounding module to preserve the positive effects of such observed confounders and eliminate their negative effects via backdoor adjustment, thereby enhancing the recommendation accuracy in each domain. Extensive experiments conducted on seven real-world datasets demonstrate that CD2CDR significantly outperforms the state-of-the-art methods.","authors":["Jiajie Zhu","Yan Wang","Feng Zhu","Zhu Sun"],"url":"https://arxiv.org/abs/2404.11180"}
{"created":"2025-05-23","title":"Reachability in temporal graphs under perturbation","abstract":"Reachability and other path-based measures on temporal graphs can be used to understand spread of infection, information, and people in modelled systems. Due to delays and errors in reporting, temporal graphs derived from data are unlikely to perfectly reflect reality, especially with respect to the precise times at which edges appear. To reflect this uncertainty, we consider a model in which some number $\\zeta$ of edge appearances may have their timestamps perturbed by $\\pm\\delta$ for some $\\delta$. Within this model, we investigate temporal reachability and consider the problem of determining the maximum number of vertices any vertex can reach under these perturbations. We show that this problem is intractable in general but is efficiently solvable when $\\zeta$ is sufficiently large. We also give algorithms which solve this problem in several restricted settings. We complement this with some contrasting results concerning the complexity of related temporal eccentricity problems under perturbation.","authors":["Jessica Enright","Laura Larios-Jones","Kitty Meeks","William Pettersson"],"url":"https://arxiv.org/abs/2404.19479"}
{"created":"2025-05-23","title":"ReinWiFi: Application-Layer QoS Optimization of WiFi Networks with Reinforcement Learning","abstract":"The enhanced distributed channel access (EDCA) mechanism is used in current wireless fidelity (WiFi) networks to support priority requirements of heterogeneous applications. However, the EDCA mechanism can not adapt to particular quality-of-service (QoS) objective, network topology, and interference level. In this paper, a novel reinforcement-learning-based scheduling framework is proposed and implemented to optimize the application-layer quality-of-service (QoS) of a WiFi network with commercial adapters and unknown interference. Particularly, application-layer tasks of file delivery and delay-sensitive communication are jointly scheduled by adjusting the contention window sizes and application-layer throughput limitation, such that the throughput of the former and the round trip time of the latter can be optimized. Due to the unknown interference and vendor-dependent implementation of the WiFi adapters, the relation between the scheduling policy and the system QoS is unknown. Hence, a reinforcement learning method is proposed, in which a novel Q-network is trained to map from the historical scheduling parameters and QoS observations to the current scheduling action. It is demonstrated on a testbed that the proposed framework can achieve a significantly better performance than the EDCA mechanism.","authors":["Qianren Li","Bojie Lv","Yuncong Hong","Rui Wang"],"url":"https://arxiv.org/abs/2405.03526"}
{"created":"2025-05-23","title":"Red-Teaming for Inducing Societal Bias in Large Language Models","abstract":"Ensuring the safe deployment of AI systems is critical in industry settings where biased outputs can lead to significant operational, reputational, and regulatory risks. Thorough evaluation before deployment is essential to prevent these hazards. Red-teaming addresses this need by employing adversarial attacks to develop guardrails that detect and reject biased or harmful queries, enabling models to be retrained or steered away from harmful outputs. However, most red-teaming efforts focus on harmful or unethical instructions rather than addressing social bias, leaving this critical area under-explored despite its significant real-world impact, especially in customer-facing systems. We propose two bias-specific red-teaming methods, Emotional Bias Probe (EBP) and BiasKG, to evaluate how standard safety measures for harmful content affect bias. For BiasKG, we refactor natural language stereotypes into a knowledge graph. We use these attacking strategies to induce biased responses from several open- and closed-source language models. Unlike prior work, these methods specifically target social bias. We find our method increases bias in all models, even those trained with safety guardrails. Our work emphasizes uncovering societal bias in LLMs through rigorous evaluation, and recommends measures ensure AI safety in high-stakes industry deployments.","authors":["Chu Fei Luo","Ahmad Ghawanmeh","Bharat Bhimshetty","Kashyap Murali","Murli Jadhav","Xiaodan Zhu","Faiza Khan Khattak"],"url":"https://arxiv.org/abs/2405.04756"}
{"created":"2025-05-23","title":"A categorical account of composition methods in logic (extended version)","abstract":"We present a categorical theory of the composition methods in finite model theory -- a key technique enabling modular reasoning about complex structures by building them out of simpler components. The crucial results required by the composition methods are Feferman--Vaught--Mostowski (FVM) type theorems, which characterize how logical equivalence behaves under composition and transformation of models.","authors":["Tom\\'a\\v{s} Jakl","Dan Marsden","Nihil Shah"],"url":"https://arxiv.org/abs/2405.06664"}
{"created":"2025-05-23","title":"FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering","abstract":"Large Language Models (LLMs) are often challenged by generating erroneous or hallucinated responses, especially in complex reasoning tasks. Leveraging Knowledge Graphs (KGs) as external knowledge sources has emerged as a viable solution. However, existing KG-enhanced methods, either retrieval-based or agent-based, encounter difficulties in accurately retrieving knowledge and efficiently traversing KGs at scale. In this paper, we propose a unified framework, FiDeLiS, designed to improve the factuality of LLM responses by anchoring answers to verifiable reasoning steps retrieved from KGs. To achieve this, we leverage step-wise beam search with a deductive scoring function, allowing the LLM to validate reasoning process step by step, and halt the search once the question is deducible. In addition, we propose a Path-RAG module to pre-select a smaller candidate set for each beam search step, reducing computational costs by narrowing the search space. Extensive experiments show that our method, as a training-free framework, not only improve the performance but also enhance the factuality and interpretability across different benchmarks. Code is released at https://github.com/Y-Sui/FiDeLiS.","authors":["Yuan Sui","Yufei He","Nian Liu","Xiaoxin He","Kun Wang","Bryan Hooi"],"url":"https://arxiv.org/abs/2405.13873"}
{"created":"2025-05-23","title":"A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP","abstract":"We consider the inverse optimization problem of estimating the weights of the objective function such that the given solution is an optimal solution for a mixed integer linear program (MILP). In this inverse optimization problem, the known methods exhibit inefficient convergence. Specifically, if $d$ denotes the dimension of the weights and $k$ the number of iterations, then the error of the weights is bounded by $O(k^{-1/(d-1)})$, leading to slow convergence as $d$ increases.We propose a projected subgradient method with a step size of $k^{-1/2}$ based on suboptimality loss. We theoretically show and demonstrate that the proposed method efficiently learns the weights. In particular, we show that there exists a constant $\\gamma > 0$ such that the distance between the learned and true weights is bounded by $ O\\left(k^{-1/(1+\\gamma)} \\exp\\left(-\\frac{\\gamma k^{1/2}}{2+\\gamma}\\right)\\right), $ or the optimal solution is exactly recovered. Furthermore, experiments demonstrate that the proposed method solves the inverse optimization problems of MILP using fewer than $1/7$ the number of MILP calls required by known methods, and converges within a finite number of iterations.","authors":["Akira Kitaoka"],"url":"https://arxiv.org/abs/2405.14273"}
{"created":"2025-05-23","title":"NeCGS: Neural Compression for 3D Geometry Sets","abstract":"We present NeCGS, the first neural compression paradigm, which can compress a geometry set encompassing thousands of detailed and diverse 3D mesh models by up to 900 times with high accuracy and preservation of detailed geometric structures. Specifically, we first propose TSDF-Def, a new implicit representation that is capable of \\textbf{accurately} representing irregular 3D mesh models with various structures into regular 4D tensors of \\textbf{uniform} and \\textbf{compact} size, where 3D surfaces can be extracted through the deformable marching cubes. Then we construct a quantization-aware auto-decoder network architecture to regress these 4D tensors to explore the local geometric similarity within each shape and across different shapes for redundancy removal, resulting in more compact representations, including an embedded feature of a smaller size associated with each 3D model and a network parameter shared by all models. We finally encode the resulting features and network parameters into bitstreams through entropy coding. Besides, our NeCGS can handle the dynamic scenario well, where new 3D models are constantly added to a compressed set. Extensive experiments and ablation studies demonstrate the significant advantages of our NeCGS over state-of-the-art methods both quantitatively and qualitatively. The source code is available at https://github.com/rsy6318/NeCGS.","authors":["Siyu Ren","Junhui Hou","Weiyao Lin","Wenping Wang"],"url":"https://arxiv.org/abs/2405.15034"}
{"created":"2025-05-23","title":"Deep Koopman Learning using Noisy Data","abstract":"This paper proposes a data-driven framework to learn a finite-dimensional approximation of a Koopman operator for approximating the state evolution of a dynamical system under noisy observations. To this end, our proposed solution has two main advantages. First, the proposed method only requires the measurement noise to be bounded. Second, the proposed method modifies the existing deep Koopman operator formulations by characterizing the effect of the measurement noise on the Koopman operator learning and then mitigating it by updating the tunable parameter of the observable functions of the Koopman operator, making it easy to implement. The performance of the proposed method is demonstrated on several standard benchmarks. We then compare the presented method with similar methods proposed in the latest literature on Koopman learning.","authors":["Wenjian Hao","Devesh Upadhyay","Shaoshuai Mou"],"url":"https://arxiv.org/abs/2405.16649"}
{"created":"2025-05-23","title":"COOKIEGUARD: Characterizing and Isolating the First-Party Cookie Jar","abstract":"As third-party cookies are being phased out or restricted by major browsers, first-party cookies are increasingly repurposed for tracking. Prior work has shown that third-party scripts embedded in the main frame can access and exfiltrate first-party cookies, including those set by other third-party scripts. However, existing browser security mechanisms, such as the Same-Origin Policy, Content Security Policy, and third-party storage partitioning, do not prevent this type of cross-domain interaction within the main frame. While recent studies have begun to highlight this issue, there remains a lack of comprehensive measurement and practical defenses.","authors":["Pouneh Nikkhah Bahrami","Aurore Fass","Zubair Shafiq"],"url":"https://arxiv.org/abs/2406.05310"}
{"created":"2025-05-23","title":"BlockPruner: Fine-grained Pruning for Large Language Models","abstract":"With the rapid growth in the size and complexity of large language models (LLMs), the costs associated with their training and inference have escalated significantly. Research indicates that certain layers in LLMs harbor substantial redundancy, and pruning these layers has minimal impact on the overall performance. While various layer pruning methods have been developed based on this insight, they generally overlook the finer-grained redundancies within the layers themselves. In this paper, we delve deeper into the architecture of LLMs and demonstrate that finer-grained pruning can be achieved by targeting redundancies in multi-head attention (MHA) and multi-layer perceptron (MLP) blocks. We propose a novel, training-free structured pruning approach called BlockPruner. Unlike existing layer pruning methods, BlockPruner segments each Transformer layer into MHA and MLP blocks. It then assesses the importance of these blocks using perplexity measures and applies a heuristic search for iterative pruning. We applied BlockPruner to LLMs of various sizes and architectures and validated its performance across a wide range of downstream tasks. Experimental results show that BlockPruner achieves more granular and effective pruning compared to state-of-the-art baselines.","authors":["Longguang Zhong","Fanqi Wan","Ruijun Chen","Xiaojun Quan","Liangzhi Li"],"url":"https://arxiv.org/abs/2406.10594"}
{"created":"2025-05-23","title":"Projection Methods for Operator Learning and Universal Approximation","abstract":"We obtain a new universal approximation theorem for continuous (possibly nonlinear) operators on arbitrary Banach spaces using the Leray-Schauder mapping. Moreover, we introduce and study a method for operator learning in Banach spaces $L^p$ of functions with multiple variables, based on orthogonal projections on polynomial bases. We derive a universal approximation result for operators where we learn a linear projection and a finite dimensional mapping under some additional assumptions. For the case of $p=2$, we give some sufficient conditions for the approximation results to hold. This article serves as the theoretical framework for a deep learning methodology in operator learning.","authors":["Emanuele Zappala"],"url":"https://arxiv.org/abs/2406.12264"}
{"created":"2025-05-23","title":"ESBMC v7.6: Enhanced Model Checking of C++ Programs with Clang AST","abstract":"This paper presents Efficient SMT-Based Context-Bounded Model Checker (ESBMC) v7.6, an extended version based on previous work on ESBMC v7.3 by K. Song et al. The v7.3 introduced a new Clang-based C++ front-end to address the challenges posed by modern C++ programs. Although the new front-end has demonstrated significant potential in previous studies, it remains in the developmental stage and lacks several essential features. ESBMC v7.6 further enhanced this foundation by adding and extending features based on the Clang AST, such as 1) exception handling, 2) extended memory management and memory safety verification, including dangling pointers, duplicate deallocation, memory leaks and rvalue references and 3) new operational models for STL updating the outdated C++ operational models. Our extensive experiments demonstrate that ESBMC v7.6 can handle a significantly broader range of C++ features introduced in recent versions of the C++ standard.","authors":["Xianzhiyu Li","Kunjian Song","Mikhail R. Gadelha","Franz Brau{\\ss}e","Rafael S. Menezes","Konstantin Korovin","Lucas C. Cordeiro"],"url":"https://arxiv.org/abs/2406.17862"}
{"created":"2025-05-23","title":"Analysis of Channel Uncertainty in Trusted Wireless Services via Repeated Interactions","abstract":"The coexistence of heterogeneous sub-networks in 6G poses new security and trust concerns and thus calls for a perimeterless-security model. Blockchain radio access network (B-RAN) provides a trust-building approach via repeated interactions rather than relying on pre-established trust or central authentication. Such a trust-building process naturally supports dynamic trusted services across various service providers (SP) without the need for perimeter-based authentications; however, it remains vulnerable to environmental and system unreliability such as wireless channel uncertainty. In this study, we investigate channel unreliability in the trust-building framework based on repeated interactions for secure wireless services. We derive specific requirements for achieving cooperation between SPs and clients via a repeated game model and illustrate the implications of channel unreliability on sustaining trusted wireless services. We consider the framework design and optimization to guarantee SP-client cooperation, given the worst channel condition and/or the least cooperation willingness. Furthermore, we explore the maximum cooperation area to enhance service resilience and reveal the trade-off relationship between transmission efficiency, security integrity, and cooperative margin. Finally, we present simulations to demonstrate the system performance over fading channels and verify our results.","authors":["Bingwen Chen","Xintong Ling","Weihang Cao","Jiaheng Wang","Zhi Ding"],"url":"https://arxiv.org/abs/2406.18204"}
{"created":"2025-05-23","title":"Distribution System Reconfiguration to Mitigate Load Altering Attacks via Stackelberg Games","abstract":"The integration of IoT-controllable devices in power systems (such as smart electric vehicle charging stations, heat pumps, etc.), despite their benefits, raises novel cybersecurity concerns. Vulnerabilities in these devices can be leveraged to launch load-altering attacks (LAAs) that can potentially compromise the safety of power systems. In this paper, we analyze the impact of LAAs on the voltage profile of distribution networks (DNs). We first derive closed-form expressions to quantify the attacks' impact. Using the insights derived from this analysis, we then propose a reactive defense method to mitigate LAAs based on reconfiguring the DNs. We also study optimal defense strategies that are robust to LAAs by exploiting non-cooperative sequential game theory. The proposed solution takes into account the potential uncertainties in the attack localization. Furthermore, we propose a Bayesian optimization (BO) approach to compute the equilibrium of the game, which reduces the computational burden. Our results show that attacks launched on the deepest nodes in the DN have the most detrimental effect on the grid voltage profile. Furthermore, the proposed game-theoretic strategy successfully mitigates the effect of the attack while ensuring minimum system reconfiguration.","authors":["Sajjad Maleki","E. Veronica Belmaga","Charalambos Konstantinou","Subhash Lakshminarayana"],"url":"https://arxiv.org/abs/2407.07065"}
{"created":"2025-05-23","title":"How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities","abstract":"Long sequences occur in abundance within real-world scenarios, hence properly modelling them opens numerous down-stream use-cases. Deep neural networks, however, have often struggled with these for a variety of reasons. Recent advances, both in system engineering as well as model design, have enabled the scaling up of model that are purported to support extended context length. In particular, the state-space and linear recurrent neural network families of models hypothetically can entend to infinite sequence lenth. However, is this too good to be true? We conduct an evaluation to show that while such claims may be sound theoretically, there remain large practical gaps that are empirically observed. In particular, recurrent models still suffer in the same settings as long-context LLMs with attention. We further show that different inductive biases have inconsistent extrapolation capabilities, highlighting the need to further study such paradigms and investigate why long-context models seemingly fail to behave as one might expect.","authors":["Jerry Huang"],"url":"https://arxiv.org/abs/2407.08112"}
{"created":"2025-05-23","title":"ImPORTance: Machine Learning-Driven Analysis of Global Port Significance and Network Dynamics for Improved Operational Efficiency","abstract":"Seaports play a crucial role in the global economy, and researchers have sought to understand their significance through various studies. In this paper, we aim to explore the common characteristics shared by important ports by analyzing the network of connections formed by vessel movement among them. To accomplish this task, we adopt a bottom-up network construction approach that combines three years' worth of AIS (Automatic Identification System) data from around the world, constructing a Ports Network that represents the connections between different ports. Through this representation, we utilize machine learning to assess the relative significance of various port features. Our model examined such features and revealed that geographical characteristics and the port's depth are indicators of a port's importance to the Ports Network. Accordingly, this study employs a data-driven approach and utilizes machine learning to provide a comprehensive understanding of the factors contributing to the extent of ports. Our work aims to inform decision-making processes related to port development, resource allocation, and infrastructure planning within the industry.","authors":["Emanuele Carlini","Domenico Di Gangi","Vinicius Monteiro de Lira","Hanna Kavalionak","Amilcar Soares","Gabriel Spadon"],"url":"https://arxiv.org/abs/2407.09571"}
{"created":"2025-05-23","title":"Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion","abstract":"Can we generate a control policy for an agent using just one demonstration of desired behaviors as a prompt, as effortlessly as creating an image from a textual description? In this paper, we present Make-An-Agent, a novel policy parameter generator that leverages the power of conditional diffusion models for behavior-to-policy generation. Guided by behavior embeddings that encode trajectory information, our policy generator synthesizes latent parameter representations, which can then be decoded into policy networks. Trained on policy network checkpoints and their corresponding trajectories, our generation model demonstrates remarkable versatility and scalability on multiple tasks and has a strong generalization ability on unseen tasks to output well-performed policies with only few-shot demonstrations as inputs. We showcase its efficacy and efficiency on various domains and tasks, including varying objectives, behaviors, and even across different robot manipulators. Beyond simulation, we directly deploy policies generated by Make-An-Agent onto real-world robots on locomotion tasks. Project page: https://cheryyunl.github.io/make-an-agent/","authors":["Yongyuan Liang","Tingqiang Xu","Kaizhe Hu","Guangqi Jiang","Furong Huang","Huazhe Xu"],"url":"https://arxiv.org/abs/2407.10973"}
{"created":"2025-05-23","title":"VITAL: Interactive Few-Shot Imitation Learning via Visual Human-in-the-Loop Corrections","abstract":"Imitation Learning (IL) has emerged as a powerful approach in robotics, allowing robots to acquire new skills by mimicking human actions. Despite its potential, the data collection process for IL remains a significant challenge due to the logistical difficulties and high costs associated with obtaining high-quality demonstrations. To address these issues, we propose a large-scale data generation from a handful of demonstrations through data augmentation in simulation. Our approach leverages affordable hardware and visual processing techniques to collect demonstrations, which are then augmented to create extensive training datasets for imitation learning. By utilizing both real and simulated environments, along with human-in-the-loop corrections, we enhance the generalizability and robustness of the learned policies. We evaluated our method through several rounds of experiments in both simulated and real-robot settings, focusing on tasks of varying complexity, including bottle collecting, stacking objects, and hammering. Our experimental results validate the effectiveness of our approach in learning robust robot policies from simulated data, significantly improved by human-in-the-loop corrections and real-world data integration. Additionally, we demonstrate the framework's capability to generalize to new tasks, such as setting a drink tray, showcasing its adaptability and potential for handling a wide range of real-world manipulation tasks. A video of the experiments can be found at: https://youtu.be/YeVAMRqRe64?si=R179xDlEGc7nPu8i","authors":["Hamidreza Kasaei","Mohammadreza Kasaei"],"url":"https://arxiv.org/abs/2407.21244"}
{"created":"2025-05-23","title":"Asynchronous Latency and Fast Atomic Snapshot","abstract":"This paper introduces a novel, fast atomic-snapshot protocol for asynchronous message-passing systems. In the process of defining what ``fast'' means exactly, we spot a few interesting issues that arise when conventional time metrics are applied to long-lived asynchronous algorithms. We reveal some gaps in latency claims made in earlier work on snapshot algorithms, which hamper their comparative time-complexity analysis. We then come up with a new unifying time-complexity metric that captures the latency of an operation in an asynchronous, long-lived implementation. This allows us to formally grasp latency improvements of our atomic-snapshot algorithm with respect to the state-of-the-art protocols: optimal latency in fault-free runs without contention, short constant latency in fault-free runs with contention, the worst-case latency proportional to the number of active concurrent failures, and constant, close to optimal, amortized latency.","authors":["Jo\\~ao Paulo Bezerra","Luciano Freitas","Petr Kuznetsov"],"url":"https://arxiv.org/abs/2408.02562"}
{"created":"2025-05-23","title":"Longest Common Extensions with Wildcards: Trade-off and Applications","abstract":"We study the Longest Common Extension (LCE) problem in a string containing wildcards. Wildcards (also called \"don't cares\" or \"holes\") are special characters that match any other character in the alphabet, similar to the character \"?\" in Unix commands or \".\" in regular expression engines.","authors":["Gabriel Bathie","Itai Boneh","Panagiotis Charalampopoulos","Jonas Ellert","Tatiana Starikovskaya"],"url":"https://arxiv.org/abs/2408.03610"}
{"created":"2025-05-23","title":"A Review of Pseudo-Labeling for Computer Vision","abstract":"Deep neural models have achieved state of the art performance on a wide range of problems in computer science, especially in computer vision. However, deep neural networks often require large datasets of labeled samples to generalize effectively, and an important area of active research is semi-supervised learning, which attempts to instead utilize large quantities of (easily acquired) unlabeled samples. One family of methods in this space is pseudo-labeling, a class of algorithms that use model outputs to assign labels to unlabeled samples which are then used as labeled samples during training. Such assigned labels, called pseudo-labels, are most commonly associated with the field of semi-supervised learning. In this work we explore a broader interpretation of pseudo-labels within both self-supervised and unsupervised methods. By drawing the connection between these areas we identify new directions when advancements in one area would likely benefit others, such as curriculum learning and self-supervised regularization.","authors":["Patrick Kage","Jay C. Rothenberger","Pavlos Andreadis","Dimitrios I. Diochnos"],"url":"https://arxiv.org/abs/2408.07221"}
{"created":"2025-05-23","title":"The high resolution sampling methods for acoustic sources from multi-frequency far field patterns at sparse observation directions","abstract":"This work is dedicated to novel uniqueness results and high resolution sampling methods for source support from multi-frequency sparse far field patterns. With a single pair of observation directions $\\pm\\hat{x}$, we prove that the lines $\\{z\\in\\mathbb R^2|\\, \\hat{x}\\cdot z = \\hat{x}\\cdot y, \\,y\\in A_{\\hat{x}}\\}$ can be determined by multi-frequency far field patterns at the directions $\\pm\\hat{x}$, where $A_{\\hat{x}}$ denotes a set containing the corners of the boundary and points whose normal vector to the boundary is parallel to $\\hat{x}$. Furthermore, if the source support is composed of polygons and annuluses, then we prove that the support can be determined by multi-frequency far field patterns at sparse directions. Precisely, the lowest number of the observation directions is given in terms of the number of the corners and the annuluses. Inspired by the uniqueness arguments, we introduce two novel indicators to determine the source support. Numerical examples in two dimensions are presented to show the validity and robustness of the two indicators for reconstructing the boundaries of the source support with a high resolution. The second indicator also shows its powerful ability to determine the unknown source function.","authors":["Xiaodong Liu","Qingxiang Shi"],"url":"https://arxiv.org/abs/2408.10829"}
{"created":"2025-05-23","title":"Depth-Weighted Detection of Behaviours of Risk in People with Dementia using Cameras","abstract":"The behavioural and psychological symptoms of dementia, such as agitation and aggression, present a significant health and safety risk in residential care settings. Many care facilities have video cameras in place for digital monitoring of public spaces, which can be leveraged to develop an automated behaviours of risk detection system that can alert the staff to enable timely intervention and prevent the situation from escalating. However, one of the challenges in our previous study was the presence of false alarms due to disparate importance of events based on distance. To address this issue, we proposed a novel depth-weighted loss to enforce equivalent importance to the events happening both near and far from the cameras; thus, helping to reduce false alarms. We further propose to utilize the training outliers to determine the anomaly threshold. The data from nine dementia participants across three cameras in a specialized dementia unit were used for training. The proposed approach obtained the best area under receiver operating characteristic curve performance of 0.852, 0.81 and 0.768, respectively, for the three cameras. Ablation analysis was conducted for the individual components of the proposed approach and effect of frame size and frame rate. The performance of the proposed approach was investigated for cross-camera, participant-specific and sex-specific behaviours of risk detection. The proposed approach performed reasonably well in reducing false alarms. This motivates further research to make the system more suitable for deployment in care facilities.","authors":["Pratik K. Mishra","Irene Ballester","Andrea Iaboni","Bing Ye","Kristine Newman","Alex Mihailidis","Shehroz S. Khan"],"url":"https://arxiv.org/abs/2408.15519"}
{"created":"2025-05-23","title":"More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding","abstract":"Enabling Large Language Models (LLMs) to comprehend the 3D physical world remains a significant challenge. Due to the lack of large-scale 3D-text pair datasets, the success of LLMs has yet to be replicated in 3D understanding. In this paper, we rethink this issue and propose a new task: 3D Data-Efficient Point-Language Understanding. The goal is to enable LLMs to achieve robust 3D object understanding with minimal 3D point cloud and text data pairs. To address this task, we introduce GreenPLM, which leverages more text data to compensate for the lack of 3D data. First, inspired by using CLIP to align images and text, we utilize a pre-trained point cloud-text encoder to map the 3D point cloud space to the text space. This mapping leaves us to seamlessly connect the text space with LLMs. Once the point-text-LLM connection is established, we further enhance text-LLM alignment by expanding the intermediate text space, thereby reducing the reliance on 3D point cloud data. Specifically, we generate 6M free-text descriptions of 3D objects, and design a three-stage training strategy to help LLMs better explore the intrinsic connections between different modalities. To achieve efficient modality alignment, we design a zero-parameter cross-attention module for token pooling. Extensive experimental results show that GreenPLM requires only 12% of the 3D training data used by existing state-of-the-art models to achieve superior 3D understanding. Remarkably, GreenPLM also achieves competitive performance using text-only data. The code and weights are available at: https://github.com/TangYuan96/GreenPLM.","authors":["Yuan Tang","Xu Han","Xianzhi Li","Qiao Yu","Jinfeng Xu","Yixue Hao","Long Hu","Min Chen"],"url":"https://arxiv.org/abs/2408.15966"}
{"created":"2025-05-23","title":"Logit Scaling for Out-of-Distribution Detection","abstract":"The safe deployment of machine learning and AI models in open-world settings hinges critically on the ability to detect out-of-distribution (OOD) data accurately, data samples that contrast vastly from what the model was trained with. Current approaches to OOD detection often require further training the model, and/or statistics about the training data which may no longer be accessible. Additionally, many existing OOD detection methods struggle to maintain performance when transferred across different architectures. Our research tackles these issues by proposing a simple, post-hoc method that does not require access to the training data distribution, keeps a trained network intact, and holds strong performance across a variety of architectures. Our method, Logit Scaling (LTS), as the name suggests, simply scales the logits in a manner that effectively distinguishes between in-distribution (ID) and OOD samples. We tested our method on benchmarks across various scales, including CIFAR-10, CIFAR-100, ImageNet and OpenOOD. The experiments cover 3 ID and 14 OOD datasets, as well as 9 model architectures. Overall, we demonstrate state-of-the-art performance, robustness and adaptability across different architectures, paving the way towards a universally applicable solution for advanced OOD detection.","authors":["Andrija Djurisic","Rosanne Liu","Mladen Nikolic"],"url":"https://arxiv.org/abs/2409.01175"}
{"created":"2025-05-23","title":"Determination of language families using deep learning","abstract":"We use a c-GAN (convolutional generative adversarial) neural network to analyze transliterated text fragments of extant, dead comprehensible, and one dead non-deciphered (Cypro-Minoan) language to establish linguistic affinities. The paper is agnostic with respect to translation and/or deciphering. However, there is hope that the proposed approach can be useful for decipherment with more sophisticated neural network techniques.","authors":["Peter B. Lerner"],"url":"https://arxiv.org/abs/2409.02393"}
{"created":"2025-05-23","title":"MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark","abstract":"This paper introduces MMMU-Pro, a robust version of the Massive Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark. MMMU-Pro rigorously assesses multimodal models' true understanding and reasoning capabilities through a three-step process based on MMMU: (1) filtering out questions answerable by text-only models, (2) augmenting candidate options, and (3) introducing a vision-only input setting where questions are embedded within images. This setting challenges AI to truly \"see\" and \"read\" simultaneously, testing a fundamental human cognitive skill of seamlessly integrating visual and textual information. Results show that model performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8% to 26.9% across models. We explore the impact of OCR prompts and Chain of Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT generally improves performance. MMMU-Pro provides a more rigorous evaluation tool, closely mimicking real-world scenarios and offering valuable directions for future research in multimodal AI.","authors":["Xiang Yue","Tianyu Zheng","Yuansheng Ni","Yubo Wang","Kai Zhang","Shengbang Tong","Yuxuan Sun","Botao Yu","Ge Zhang","Huan Sun","Yu Su","Wenhu Chen","Graham Neubig"],"url":"https://arxiv.org/abs/2409.02813"}
{"created":"2025-05-23","title":"Normal forms in Virus Machines","abstract":"In the present work, we further study the computational power of virus machines (VMs in short).VMs provide a computing paradigm inspired by the transmission and replication networks of viruses.VMs consist of process units (called hosts) structured by a directed graph whose arcs are called channels and an instruction graph that controls the transmissions of virus objects among hosts. The present work complements our understanding of the computing power of VMs by introducing normal forms; these expressions restrict the features in a given computing model.Some of the features that we restrict in our normal forms include (a) the number of hosts, (b) the number of instructions, and (c) the number of virus objects in each host. After we recall some known results on the computing power of VMs we give our series of normal forms, such as the size of the loops in the network, proving new characterisations of family of sets, such as finite sets, semilinear sets, or recursively enumerable sets (NRE).","authors":["A. Ram\\'irez-de-Arellano","F. G. C. Cabarle","D. Orellana-Mart\\'in","M. J. P\\'erez-Jim\\'enez"],"url":"https://arxiv.org/abs/2409.03327"}
{"created":"2025-05-23","title":"Algorithm Configuration for Structured Pfaffian Settings","abstract":"Data-driven algorithm design automatically adapts algorithms to specific application domains, achieving better performance. In the context of parameterized algorithms, this approach involves tuning the algorithm's hyperparameters using problem instances drawn from the problem distribution of the target application domain. This can be achieved by maximizing empirical utilities that measure the algorithms' performance as a function of their hyperparameters, using problem instances. While empirical evidence supports the effectiveness of data-driven algorithm design, providing theoretical guarantees for several parameterized families remains challenging. This is due to the intricate behaviors of their corresponding utility functions, which typically admit piecewise discontinuous structures. In this work, we present refined frameworks for providing learning guarantees for parameterized data-driven algorithm design problems in both distributional and online learning settings. For the distributional learning setting, we introduce the \\textit{Pfaffian GJ framework}, an extension of the classical \\textit{GJ framework}, that is capable of providing learning guarantees for function classes for which the computation involves Pfaffian functions. Unlike the GJ framework, which is limited to function classes with computation characterized by rational functions, our proposed framework can deal with function classes involving Pfaffian functions, which are much more general and widely applicable. We then show that for many parameterized algorithms of interest, their utility function possesses a \\textit{refined piecewise structure}, which automatically translates to learning guarantees using our proposed framework.","authors":["Maria-Florina Balcan","Anh Tuan Nguyen","Dravyansh Sharma"],"url":"https://arxiv.org/abs/2409.04367"}
{"created":"2025-05-23","title":"Anonymity Unveiled: A Practical Framework for Auditing Data Use in Deep Learning Models","abstract":"The rise of deep learning (DL) has led to a surging demand for training data, which incentivizes the creators of DL models to trawl through the Internet for training materials. Meanwhile, users often have limited control over whether their data (e.g., facial images) are used to train DL models without their consent, which has engendered pressing concerns.","authors":["Zitao Chen","Karthik Pattabiraman"],"url":"https://arxiv.org/abs/2409.06280"}
{"created":"2025-05-23","title":"ReAugment: Model Zoo-Guided RL for Few-Shot Time Series Augmentation and Forecasting","abstract":"Time series forecasting, particularly in few-shot learning scenarios, is challenging due to the limited availability of high-quality training data. To address this, we present a pilot study on using reinforcement learning (RL) for time series data augmentation. Our method, ReAugment, tackles three critical questions: which parts of the training set should be augmented, how the augmentation should be performed, and what advantages RL brings to the process. Specifically, our approach maintains a forecasting model zoo, and by measuring prediction diversity across the models, we identify samples with higher probabilities for overfitting and use them as the anchor points for augmentation. Leveraging RL, our method adaptively transforms the overfit-prone samples into new data that not only enhances training set diversity but also directs the augmented data to target regions where the forecasting models are prone to overfitting. We validate the effectiveness of ReAugment across a wide range of base models, showing its advantages in both standard time series forecasting and few-shot learning tasks.","authors":["Haochen Yuan","Yutong Wang","Yihong Chen","Yunbo Wang","Xiaokang Yang"],"url":"https://arxiv.org/abs/2409.06282"}
{"created":"2025-05-23","title":"Robo-Platform: A Robotic System for Recording Sensors and Controlling Robots","abstract":"Mobile smartphones compactly provide sensors such as cameras, IMUs, GNSS measurement units, and wireless and wired communication channels required for robotics projects. They are affordable, portable, and programmable, which makes them ideal for testing, data acquisition, controlling mobile robots, and many other robotic applications. A robotic system is proposed in this paper, consisting of an Android phone, a microcontroller board attached to the phone via USB, and a remote wireless controller station. In the data acquisition mode, the Android device can record a dataset of a diverse configuration of multiple cameras, IMUs, GNSS units, and external USB ADC channels in the rawest format used for, but not limited to, pose estimation and scene reconstruction applications. In robot control mode, the Android phone, a microcontroller board, and other peripherals constitute the mobile or stationary robotic system. This system is controlled using a remote server connected over Wi-Fi or Bluetooth. Experiments show that although the SLAM and AR applications can utilize the acquired data, the proposed system can pave the way for more advanced algorithms for processing these noisy and sporadic measurements. Moreover, the characteristics of the communication media are studied, and two example robotic projects, which involve controlling a toy car and a quadcopter, are included.","authors":["Masoud Dayani Najafabadi","Khoshnam Shojaei"],"url":"https://arxiv.org/abs/2409.16595"}
{"created":"2025-05-23","title":"Judgment-of-Thought Prompting: A Courtroom-Inspired Framework for Binary Logical Reasoning with Large Language Models","abstract":"This paper proposes a novel prompting approach, Judgment of Thought (JoT), specifically tailored for binary logical reasoning tasks. Despite advances in prompt engineering, existing approaches still face limitations in handling complex logical reasoning tasks. To address these issues, JoT introduces a multi-agent approach with three specialized roles$\\unicode{x2010}$$\\unicode{x2010}$$\\unicode{x2010}$lawyer, prosecutor, and judge$\\unicode{x2010}$$\\unicode{x2010}$$\\unicode{x2010}$where a high-level model acts as the judge, and lower-level models serve as lawyer and prosecutor to systematically debate and evaluate arguments. Experimental evaluations on benchmarks such as BigBenchHard and Winogrande demonstrate JoT's superior performance compared to existing prompting approaches, achieving notable improvements, including 98\\% accuracy in Boolean expressions. Also, our ablation studies validate the critical contribution of each role, iterative refinement loops, and feedback mechanisms. Consequently, JoT significantly enhances accuracy, reliability, and consistency in binary reasoning tasks and shows potential for practical applications.","authors":["Sungjune Park","Heehwan Kim","Haehyun Cho","Daeseon Choi"],"url":"https://arxiv.org/abs/2409.16635"}
{"created":"2025-05-23","title":"GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design","abstract":"We provide a dataset for enabling Deep Generative Models (DGMs) in engineering design and propose methods to automate data labeling by utilizing large-scale foundation models. GeoBiked is curated to contain 4 355 bicycle images, annotated with structural and technical features and is used to investigate two automated labeling techniques: The utilization of consolidated latent features (Hyperfeatures) from image-generation models to detect geometric correspondences (e.g. the position of the wheel center) in structural images and the generation of diverse text descriptions for structural images. GPT-4o, a vision-language-model (VLM), is instructed to analyze images and produce diverse descriptions aligned with the system-prompt. By representing technical images as Diffusion-Hyperfeatures, drawing geometric correspondences between them is possible. The detection accuracy of geometric points in unseen samples is improved by presenting multiple annotated source images. GPT-4o has sufficient capabilities to generate accurate descriptions of technical images. Grounding the generation only on images leads to diverse descriptions but causes hallucinations, while grounding it on categorical labels restricts the diversity. Using both as input balances creativity and accuracy. Successfully using Hyperfeatures for geometric correspondence suggests that this approach can be used for general point-detection and annotation tasks in technical images. Labeling such images with text descriptions using VLMs is possible, but dependent on the models detection capabilities, careful prompt-engineering and the selection of input information. Applying foundation models in engineering design is largely unexplored. We aim to bridge this gap with a dataset to explore training, finetuning and conditioning DGMs in this field and suggesting approaches to bootstrap foundation models to process technical images.","authors":["Phillip Mueller","Sebastian Mueller","Lars Mikelsons"],"url":"https://arxiv.org/abs/2409.17045"}
{"created":"2025-05-23","title":"LangSAMP: Language-Script Aware Multilingual Pretraining","abstract":"Recent multilingual pretrained language models (mPLMs) often avoid using language embeddings -- learnable vectors assigned to individual languages. However, this places a significant burden on token representations to encode all language-specific information, which may hinder language neutrality. To address this limitation, we propose Language-Script Aware Multilingual Pretraining (LangSAMP), a method that incorporates both language and script embeddings to enhance representation learning. Specifically, we integrate these embeddings into the output of the Transformer blocks before passing the final representations to the language modeling head for prediction. We apply LangSAMP to the continual pretraining of XLM-R on a highly multilingual corpus covering more than 500 languages. The resulting model consistently outperforms the baseline in zero-shot crosslingual transfer across diverse downstream tasks. Extensive analysis reveals that language and script embeddings capture language- and script-specific nuances, which benefits more language-neutral representations, proven by improved pairwise cosine similarity. In our case study, we also show that language and script embeddings can be used to select better source languages for crosslingual transfer. We make our code and models publicly available at https://github.com/cisnlp/LangSAMP.","authors":["Yihong Liu","Haotian Ye","Chunlan Ma","Mingyang Wang","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2409.18199"}
{"created":"2025-05-23","title":"Statistical inference on black-box generative models in the data kernel perspective space","abstract":"Generative models are capable of producing human-expert level content across a variety of topics and domains. As the impact of generative models grows, it is necessary to develop statistical methods to understand collections of available models. These methods are particularly important in settings where the user may not have access to information related to a model's pre-training data, weights, or other relevant model-level covariates. In this paper we extend recent results on representations of black-box generative models to model-level statistical inference tasks. We demonstrate that the model-level representations are effective for multiple inference tasks.","authors":["Hayden Helm","Aranyak Acharyya","Brandon Duderstadt","Youngser Park","Carey E. Priebe"],"url":"https://arxiv.org/abs/2410.01106"}
{"created":"2025-05-23","title":"Fair Class-Incremental Learning using Sample Weighting","abstract":"Model fairness is becoming important in class-incremental learning for Trustworthy AI. While accuracy has been a central focus in class-incremental learning, fairness has been relatively understudied. However, naively using all the samples of the current task for training results in unfair catastrophic forgetting for certain sensitive groups including classes. We theoretically analyze that forgetting occurs if the average gradient vector of the current task data is in an \"opposite direction\" compared to the average gradient vector of a sensitive group, which means their inner products are negative. We then propose a fair class-incremental learning framework that adjusts the training weights of current task samples to change the direction of the average gradient vector and thus reduce the forgetting of underperforming groups and achieve fairness. For various group fairness measures, we formulate optimization problems to minimize the overall losses of sensitive groups while minimizing the disparities among them. We also show the problems can be solved with linear programming and propose an efficient Fairness-aware Sample Weighting (FSW) algorithm. Experiments show that FSW achieves better accuracy-fairness tradeoff results than state-of-the-art approaches on real datasets.","authors":["Jaeyoung Park","Minsu Kim","Steven Euijong Whang"],"url":"https://arxiv.org/abs/2410.01324"}
{"created":"2025-05-23","title":"Discovering Spoofing Attempts on Language Model Watermarks","abstract":"LLM watermarks stand out as a promising way to attribute ownership of LLM-generated text. One threat to watermark credibility comes from spoofing attacks, where an unauthorized third party forges the watermark, enabling it to falsely attribute arbitrary texts to a particular LLM. Despite recent work demonstrating that state-of-the-art schemes are, in fact, vulnerable to spoofing, no prior work has focused on post-hoc methods to discover spoofing attempts. In this work, we for the first time propose a reliable statistical method to distinguish spoofed from genuinely watermarked text, suggesting that current spoofing attacks are less effective than previously thought. In particular, we show that regardless of their underlying approach, all current learning-based spoofing methods consistently leave observable artifacts in spoofed texts, indicative of watermark forgery. We build upon these findings to propose rigorous statistical tests that reliably reveal the presence of such artifacts and thus demonstrate that a watermark has been spoofed. Our experimental evaluation shows high test power across all learning-based spoofing methods, providing insights into their fundamental limitations and suggesting a way to mitigate this threat. We make all our code available at https://github.com/eth-sri/watermark-spoofing-detection .","authors":["Thibaud Gloaguen","Nikola Jovanovi\\'c","Robin Staab","Martin Vechev"],"url":"https://arxiv.org/abs/2410.02693"}
{"created":"2025-05-23","title":"Permissive Information-Flow Analysis for Large Language Models","abstract":"Large Language Models (LLMs) are rapidly becoming commodity components of larger software systems. This poses natural security and privacy problems: poisoned data retrieved from one component can change the model's behavior and compromise the entire system, including coercing the model to spread confidential data to untrusted components. One promising approach is to tackle this problem at the system level via dynamic information flow (aka taint) tracking. Unfortunately, this approach of propagating the most restrictive input label to the output is too conservative for applications where LLMs operate on inputs retrieved from diverse sources. In this paper, we propose a novel, more permissive approach to propagate information flow labels through LLM queries. The key idea behind our approach is to propagate only the labels of the samples that were influential in generating the model output and to eliminate the labels of unnecessary inputs. We implement and investigate the effectiveness of two variations of this approach, based on (i) prompt-based retrieval augmentation, and (ii) a $k$-nearest-neighbors language model. We compare these with a baseline that uses introspection to predict the output label. Our experimental results in an LLM agent setting show that the permissive label propagator improves over the baseline in more than 85% of the cases, which underscores the practicality of our approach.","authors":["Shoaib Ahmed Siddiqui","Radhika Gaonkar","Boris K\\\"opf","David Krueger","Andrew Paverd","Ahmed Salem","Shruti Tople","Lukas Wutschitz","Menglin Xia","Santiago Zanella-B\\'eguelin"],"url":"https://arxiv.org/abs/2410.03055"}
{"created":"2025-05-23","title":"MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents","abstract":"MLLM agents demonstrate potential for complex embodied tasks by retrieving multimodal task-relevant trajectory data. However, current retrieval methods primarily focus on surface-level similarities of textual or visual cues in trajectories, neglecting their effectiveness for the specific task at hand. To address this issue, we propose a novel method, MLLM As ReTriever (MART), which enhances the performance of embodied agents by utilizing interaction data to fine-tune an MLLM retriever based on preference learning, such that the retriever fully considers the effectiveness of trajectories and prioritizes them for unseen tasks. We also introduce Trajectory Abstraction, a mechanism that leverages MLLMs' summarization capabilities to represent trajectories with fewer tokens while preserving key information, enabling agents to better comprehend milestones in the trajectory. Experimental results across various environments demonstrate our method significantly improves task success rates in unseen scenes compared to baseline methods. This work presents a new paradigm for multimodal retrieval in embodied agents, by fine-tuning a general-purpose MLLM as the retriever to assess trajectory effectiveness. All the code for benchmark tasks, simulator modifications, and the MLLM retriever is available at https://github.com/PKU-RL/MART.","authors":["Junpeng Yue","Xinrun Xu","B\\\"orje F. Karlsson","Zongqing Lu"],"url":"https://arxiv.org/abs/2410.03450"}
{"created":"2025-05-23","title":"Exploration Implies Data Augmentation: Reachability and Generalisation in Contextual MDPs","abstract":"In the zero-shot policy transfer (ZSPT) setting for contextual Markov decision processes (MDP), agents train on a fixed set of contexts and must generalise to new ones. Recent work has argued and demonstrated that increased exploration can improve this generalisation, by training on more states in the training contexts. In this paper, we demonstrate that training on more states can indeed improve generalisation, but can come at a cost of reducing the accuracy of the learned value function which should not benefit generalisation. We hypothesise and demonstrate that using exploration to increase the agent's coverage while also increasing the accuracy improves generalisation even more. Inspired by this, we propose a method Explore-Go that implements an exploration phase at the beginning of each episode, which can be combined with existing on- and off-policy RL algorithms and significantly improves generalisation even in partially observable MDPs. We demonstrate the effectiveness of Explore-Go when combined with several popular algorithms and show an increase in generalisation performance across several environments. With this, we hope to provide practitioners with a simple modification that can improve the generalisation of their agents.","authors":["Max Weltevrede","Caroline Horsch","Matthijs T. J. Spaan","Wendelin B\\\"ohmer"],"url":"https://arxiv.org/abs/2410.03565"}
{"created":"2025-05-23","title":"Robust Offline Imitation Learning from Diverse Auxiliary Data","abstract":"Offline imitation learning enables learning a policy solely from a set of expert demonstrations, without any environment interaction. To alleviate the issue of distribution shift arising due to the small amount of expert data, recent works incorporate large numbers of auxiliary demonstrations alongside the expert data. However, the performance of these approaches rely on assumptions about the quality and composition of the auxiliary data, and they are rarely successful when those assumptions do not hold. To address this limitation, we propose Robust Offline Imitation from Diverse Auxiliary Data (ROIDA). ROIDA first identifies high-quality transitions from the entire auxiliary dataset using a learned reward function. These high-reward samples are combined with the expert demonstrations for weighted behavioral cloning. For lower-quality samples, ROIDA applies temporal difference learning to steer the policy towards high-reward states, improving long-term returns. This two-pronged approach enables our framework to effectively leverage both high and low-quality data without any assumptions. Extensive experiments validate that ROIDA achieves robust and consistent performance across multiple auxiliary datasets with diverse ratios of expert and non-expert demonstrations. ROIDA effectively leverages unlabeled auxiliary data, outperforming prior methods reliant on specific data assumptions. Our code is available at https://github.com/uditaghosh/roida.","authors":["Udita Ghosh","Dripta S. Raychaudhuri","Jiachen Li","Konstantinos Karydis","Amit K. Roy-Chowdhury"],"url":"https://arxiv.org/abs/2410.03626"}
{"created":"2025-05-23","title":"Domain-Oriented Time Series Inference Agents for Reasoning and Automated Analysis","abstract":"Real-world time series inference requires more than point forecasting. It demands multi-step reasoning, constraint handling, domain knowledge incorporation, and domain-specific workflow assembly. Existing time series foundation models are limited to narrow tasks and lack flexibility to generalize across diverse scenarios. On the other hand, large language models (LLMs) struggle with numerical precision. To address these limitations, we introduce TS-Reasoner, a Domain-Oriented Time Series Agent that integrates natural language reasoning with precise numerical execution. TS-Reasoner decomposes natural language instructions into structured workflows composed of statistical, logical, and domain-specific operators, and incorporates a self-refinement mechanism for adaptive execution. We evaluate its capabilities through two axes: basic time series understanding and complex multi-step inference, using the TimeSeriesExam benchmark and a newly constructed dataset. Experimental results show that TS-Reasoner significantly outperforms general-purpose LLMs, highlighting the promise of domain-specialized agents for robust and interpretable time series reasoning.","authors":["Wen Ye","Wei Yang","Defu Cao","Yizhou Zhang","Lumingyuan Tang","Jie Cai","Yan Liu"],"url":"https://arxiv.org/abs/2410.04047"}
{"created":"2025-05-23","title":"GLEE: A Unified Framework and Benchmark for Language-based Economic Environments","abstract":"Large Language Models (LLMs) show significant potential in economic and strategic interactions, where communication via natural language is often prevalent. This raises key questions: Do LLMs behave rationally? How do they perform compared to humans? Do they tend to reach an efficient and fair outcome? What is the role of natural language in strategic interaction? How do characteristics of the economic environment influence these dynamics? These questions become crucial concerning the economic and societal implications of integrating LLM-based agents into real-world data-driven systems, such as online retail platforms and recommender systems. To answer these questions, we introduce a benchmark for standardizing research on two-player, sequential, language-based games. Inspired by the economic literature, we define three base families of games with consistent parameterization, degrees of freedom and economic measures to evaluate agents' performance (self-gain), as well as the game outcome (efficiency and fairness). We develop an open-source framework for interaction simulation and analysis, and utilize it to collect a dataset of LLM vs. LLM interactions across numerous game configurations and an additional dataset of human vs. LLM interactions. Through extensive experimentation, we demonstrate how our framework and dataset can be used to: (i) compare the behavior of LLM-based agents in various economic contexts; (ii) evaluate agents in both individual and collective performance measures; and (iii) quantify the effect of the economic characteristics of the environments on the behavior of agents. Our results suggest that the market parameters, as well as the choice of the LLMs, tend to have complex and interdependent effects on the economic outcome, which calls for careful design and analysis of the language-based economic ecosystem.","authors":["Eilam Shapira","Omer Madmon","Itamar Reinman","Samuel Joseph Amouyal","Roi Reichart","Moshe Tennenholtz"],"url":"https://arxiv.org/abs/2410.05254"}
{"created":"2025-05-23","title":"Synthesizing Efficient and Permissive Programmatic Runtime Shields for Neural Policies","abstract":"With the increasing use of neural policies in control systems, ensuring their safety and reliability has become a critical software engineering task. One prevalent approach to ensuring the safety of neural policies is to deploy programmatic runtime shields alongside them to correct their unsafe commands. However, the programmatic runtime shields synthesized by existing methods are either computationally expensive or insufficiently permissive, resulting in high overhead and unnecessary interventions on the system. To address these challenges, we propose Aegis, a novel framework that synthesizes lightweight and permissive programmatic runtime shields for neural policies. Aegis achieves this by formulating the seeking of a runtime shield as a sketch-based program synthesis problem and proposing a novel method that leverages counterexample-guided inductive synthesis and Bayesian optimization to solve it. To evaluate Aegis and its synthesized shields, we use eight representative control systems and compare Aegis with the current state-of-the-art. Our results show that the programmatic runtime shields synthesized by Aegis can correct all unsafe commands from neural policies, ensuring that the systems do not violate any desired safety properties at all times. Compared to the current state-of-the-art, Aegis's shields exhibit a 2.2$\\times$ reduction in time overhead and a 3.9$\\times$ reduction in memory usage, suggesting that they are much more lightweight. Moreover, Aegis's shields incur an average of 1.5$\\times$ fewer interventions than other shields, showing better permissiveness.","authors":["Jieke Shi","Junda He","Zhou Yang","{\\DJ}or{\\dj}e \\v{Z}ikeli\\'c","David Lo"],"url":"https://arxiv.org/abs/2410.05641"}
{"created":"2025-05-23","title":"Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering","abstract":"Recent works integrating Knowledge Graphs (KGs) have shown promising improvements in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing benchmarks primarily focus on closed-ended tasks, leaving a gap in evaluating performance on more complex, real-world scenarios. This limitation also hinders a thorough assessment of KGs' potential to reduce hallucinations in LLMs. To address this, we introduce OKGQA, a new benchmark specifically designed to evaluate LLMs augmented with KGs in open-ended, real-world question answering settings. OKGQA reflects practical complexities through diverse question types and incorporates metrics to quantify both hallucination rates and reasoning improvements in LLM+KG models. To consider the scenarios in which KGs may contain varying levels of errors, we propose a benchmark variant, OKGQA-P, to assess model performance when the semantics and structure of KGs are deliberately perturbed and contaminated. In this paper, we aims to (1) explore whether KGs can make LLMs more trustworthy in an open-ended setting, and (2) conduct a comparative analysis to shed light on method design. We believe this study can facilitate a more complete performance comparison and encourages continuous improvement in integrating KGs with LLMs to mitigate hallucination, and make LLMs more trustworthy. Code and data are released at https://github.com/Y-Sui/OKGQA.","authors":["Yuan Sui","Yufei He","Zifeng Ding","Bryan Hooi"],"url":"https://arxiv.org/abs/2410.08085"}
{"created":"2025-05-23","title":"Keys to Robust Edits: from Theoretical Insights to Practical Advances","abstract":"Large language models (LLMs) struggle with maintaining accurate knowledge due to conflicting/outdated parametric memories. While locate-and-edit methods address this, their reliance on models' internal representations leads to robustness failures in long-context reasoning and paraphrased queries. We identify a fundamental limitation of locate-and-edit methods: existing semantic keys (for memory localization) cannot simultaneously satisfy robustness (context-invariant activation) and specificity (precise knowledge discrimination). Through theoretical error-bound analysis, we establish formal criteria for effective editing. Our solution introduces \\textit{Robust Edit Pathway (REP)}, a plug-and-play module that: (1) disentangles editing keys from native model representations; (2) dynamically adjusts keys via contrastive learning to achieve robustness-specificity balance. Extensive experiments across various editing methods (ROME/MEMIT/R-ROME/EMMET), existing LLMs (LLaMA2, QWen, Mistral), and datasets (CounterFact, ZsRE) show that REP improves success rate over robustness tests by up-to 66.4\\% while maintaining the success rate unaffected. Our code can be found at https://github.com/ElliottYan/RobustKeyEdit .","authors":["Jianhao Yan","Futing Wang","Yun Luo","Yafu Li","Yue Zhang"],"url":"https://arxiv.org/abs/2410.09338"}
{"created":"2025-05-23","title":"The Epochal Sawtooth Effect: Unveiling Training Loss Oscillations in Adam and Other Optimizers","abstract":"In this paper, we identify and analyze a recurring training loss pattern, which we term the \\textit{Epochal Sawtooth Effect (ESE)}, commonly observed during training with adaptive gradient-based optimizers, particularly Adam optimizer. This pattern is characterized by a sharp drop in loss at the beginning of each epoch, followed by a gradual increase, resulting in a sawtooth-shaped loss curve. Through empirical observations, we demonstrate that while this effect is most pronounced with Adam, it persists, although less severely, with other optimizers such as RMSProp.","authors":["Qi Liu","Wanjing Ma"],"url":"https://arxiv.org/abs/2410.10056"}
{"created":"2025-05-23","title":"A Unified Approach to Routing and Cascading for LLMs","abstract":"The availability of a wide range of large language models (LLMs) embedded in various agentic systems has significantly increased the potential of model selection strategies to improve the cost-performance tradeoff. Existing strategies involve either routing, where a single model is chosen per query, or cascading, which sequentially runs increasingly larger models until a satisfactory answer is found. However, current approaches face three key limitations: they (1) lack formal proofs of optimality, (2) fail to identify the conditions under which these strategies are most effective to improve the cost-performance tradeoff, and (3) are unable to combine both paradigms for further improvements. To address these issues, we first derive a novel optimal strategy for cascading and prove the optimality of an existing routing strategy. Further, we propose cascade routing, a unified framework that integrates routing and cascading into a theoretically optimal strategy. Through our analysis, we identify good quality estimators as the critical factor for the success of model selection paradigms. Finally, in our experiments, we show that cascade routing consistently outperforms the individual approaches by a large margin and we analyze quality estimators to determine when routing and/or cascading are useful paradigms for model selection.","authors":["Jasper Dekoninck","Maximilian Baader","Martin Vechev"],"url":"https://arxiv.org/abs/2410.10347"}
{"created":"2025-05-23","title":"Model-based Large Language Model Customization as Service","abstract":"Prominent Large Language Model (LLM) services from providers like OpenAI and Google excel at general tasks but often underperform on domain-specific applications. Current customization services for these LLMs typically require users to upload data for fine-tuning, posing significant privacy risks. While differentially private (DP) data synthesis presents a potential alternative, its application commonly results in low effectiveness due to the introduction of excessive noise on data for DP. To overcome this, we introduce Llamdex, a novel framework that facilitates LLM customization as a service, where the client uploads pre-trained domain-specific models rather than data. This client-uploaded model, optionally protected by DP with much lower noise, is inserted into the base LLM via connection modules. Significantly, these connecting modules are trained without requiring sensitive domain data, enabling clients to customize LLM services while preserving data privacy. Experiments demonstrate that Llamdex improves domain-specific accuracy by up to 26\\% over state-of-the-art private data synthesis methods under identical privacy constraints and, by obviating the need for users to provide domain context within queries, maintains inference efficiency comparable to the original LLM service.","authors":["Zhaomin Wu","Jizhou Guo","Junyi Hou","Bingsheng He","Lixin Fan","Qiang Yang"],"url":"https://arxiv.org/abs/2410.10481"}
{"created":"2025-05-23","title":"Multi-Agent Corridor Generating Algorithm","abstract":"In this paper, we propose the Multi-Agent Corridor Generating Algorithm (MACGA) for solving the Multi-agent Pathfinding (MAPF) problem, where a group of agents need to find non-colliding paths to their target locations. Existing approaches struggle to solve dense MAPF instances. In MACGA, the agents build \\emph{corridors}, which are sequences of connected vertices, from current locations towards agents' goals, and evacuate other agents out of the corridors to avoid collisions and deadlocks. We also present the MACGA+PIBT algorithm, which integrates the well-known rule-based PIBT algorithm into MACGA to improve runtime and solution quality. The proposed algorithms run in polynomial time and have a reachability property, i.e., every agent is guaranteed to reach its goal location at some point. We demonstrate experimentally that MACGA and MACGA+PIBT outperform baseline algorithms in terms of success rate, runtime, and makespan across diverse MAPF benchmark grids.","authors":["Arseniy Pertzovsky","Roni Stern","Roie Zivan","Ariel Felner"],"url":"https://arxiv.org/abs/2410.12397"}
{"created":"2025-05-23","title":"Bias Amplification: Large Language Models as Increasingly Biased Media","abstract":"Model collapse, a phenomenon characterized by performance degradation due to iterative training on synthetic data, has been widely studied. However, its implications for bias amplification, the progressive intensification of pre-existing societal biases in Large Language Models (LLMs), remain significantly underexplored, despite the growing influence of LLMs in shaping online discourse. In this paper, we introduce a open, generational, and long-context benchmark specifically designed to measure political bias amplification in LLMs, leveraging sentence continuation tasks derived from a comprehensive dataset of U.S. political news. Our empirical study using GPT-2 reveals consistent and substantial political bias intensification (e.g., right-leaning amplification) over iterative synthetic training cycles. We evaluate three mitigation strategies, Overfitting, Preservation, and Accumulation, and demonstrate that bias amplification persists independently of model collapse, even when the latter is effectively controlled. Furthermore, we propose a mechanistic analysis approach that identifies neurons correlated with specific phenomena during inference through regression and statistical tests. This analysis uncovers largely distinct neuron populations driving bias amplification and model collapse, underscoring fundamentally different underlying mechanisms. Finally, we supplement our empirical findings with theoretical intuition that explains the separate origins of these phenomena, guiding targeted strategies for bias mitigation.","authors":["Ze Wang","Zekun Wu","Jeremy Zhang","Xin Guan","Navya Jain","Skylar Lu","Saloni Gupta","Adriano Koshiyama"],"url":"https://arxiv.org/abs/2410.15234"}
{"created":"2025-05-23","title":"When LLMs Learn to be Students: The SOEI Framework for Modeling and Evaluating Virtual Student Agents in Educational Interaction","abstract":"Recent advances in large language models (LLMs) have enabled intelligent tutoring systems, yet the development of LLM-based Virtual Student Agents (LVSAs) remains underexplored. Such agents are essential for teacher-facing applications, where simulating diverse learner traits can support adaptive instruction and pedagogical skill development. However, current methods lack principled personality modeling, scalable evaluation of behavioral consistency, and empirical validation in interactive teaching settings. We propose the SOEI framework, a structured pipeline comprising Scene, Object, Evaluation, and Interaction, for constructing and evaluating personality-aligned LVSAs in classroom scenarios. Leveraging Chinese language instruction as a cognitively and emotionally rich testbed, we generate five LVSAs based on Big Five traits through LoRA fine-tuning and expert-informed prompt design. Their behavioral realism and personality coherence are assessed using a hybrid human & GPT-4 evaluation and a multi-dimensional annotation protocol. Through controlled experiments with real pre-service teachers, we demonstrate that LVSAs can elicit adaptive teaching strategies and maintain trait-consistent behavior across multi-turn dialogues. Our results provide: (1) an educationally and psychologically grounded generation pipeline for LLM-based student agents; (2) a hybrid, scalable evaluation framework for behavioral realism; and (3) empirical insights into the pedagogical utility of LVSAs in shaping instructional adaptation. By embedding LVSAs into both generative modeling and human-in-the-loop teaching, SOEI bridges AI for Education (AI4Edu) and Education for AI (Edu4AI), positioning classroom interaction as a rigorous testbed for controllability, personality alignment, and human-likeness in large language models.","authors":["Yiping Ma","Shiyu Hu","Xuchen Li","Yipei Wang","Yuqing Chen","Shiqing Liu","Kang Hao Cheong"],"url":"https://arxiv.org/abs/2410.15701"}
{"created":"2025-05-23","title":"Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination","abstract":"The growth in prominence of large language models (LLMs) in everyday life can be largely attributed to their generative abilities, yet some of this is also owed to the risks and costs associated with their use. On one front is their tendency to hallucinate false or misleading information, limiting their reliability. On another is the increasing focus on the computational limitations associated with traditional self-attention based LLMs, which has brought about new alternatives, in particular recurrent models, meant to overcome them. Yet it remains uncommon to consider these two concerns simultaneously. Do changes in architecture exacerbate/alleviate existing concerns about hallucinations? Do they affect how and where they occur? Through an extensive evaluation, we study how these architecture-based inductive biases affect the propensity to hallucinate. While hallucination remains a general phenomenon not limited to specific architectures, the situations in which they occur and the ease with which specific types of hallucinations can be induced can significantly differ based on the model architecture. These findings highlight the need for better understanding both these problems in conjunction with each other, as well as consider how to design more universal techniques for handling hallucinations.","authors":["Jerry Huang","Prasanna Parthasarathi","Mehdi Rezagholizadeh","Boxing Chen","Sarath Chandar"],"url":"https://arxiv.org/abs/2410.17477"}
{"created":"2025-05-23","title":"SHAP zero Explains Biological Sequence Models with Near-zero Marginal Cost for Future Queries","abstract":"The growing adoption of machine learning models for biological sequences has intensified the need for interpretable predictions, with Shapley values emerging as a theoretically grounded standard for model explanation. While effective for local explanations of individual input sequences, scaling Shapley-based interpretability to extract global biological insights requires evaluating thousands of sequences--incurring exponential computational cost per query. We introduce SHAP zero, a novel algorithm that amortizes the cost of Shapley value computation across large-scale biological datasets. After a one-time model sketching step, SHAP zero enables near-zero marginal cost for future queries by uncovering an underexplored connection between Shapley values, high-order feature interactions, and the sparse Fourier transform of the model. Applied to models of guide RNA efficacy, DNA repair outcomes, and protein fitness, SHAP zero explains predictions orders of magnitude faster than existing methods, recovering rich combinatorial interactions previously inaccessible at scale. This work opens the door to principled, efficient, and scalable interpretability for black-box sequence models in biology.","authors":["Darin Tsui","Aryan Musharaf","Yigit Efe Erginbas","Justin Singh Kang","Amirali Aghazadeh"],"url":"https://arxiv.org/abs/2410.19236"}
{"created":"2025-05-23","title":"GeoLLaVA: Efficient Fine-Tuned Vision-Language Models for Temporal Change Detection in Remote Sensing","abstract":"Detecting temporal changes in geographical landscapes is critical for applications like environmental monitoring and urban planning. While remote sensing data is abundant, existing vision-language models (VLMs) often fail to capture temporal dynamics effectively. This paper addresses these limitations by introducing an annotated dataset of video frame pairs to track evolving geographical patterns over time. Using fine-tuning techniques like Low-Rank Adaptation (LoRA), quantized LoRA (QLoRA), and model pruning on models such as Video-LLaVA and LLaVA-NeXT-Video, we significantly enhance VLM performance in processing remote sensing temporal changes. Results show significant improvements, with the best performance achieving a BERT score of 0.864 and ROUGE-1 score of 0.576, demonstrating superior accuracy in describing land-use transformations.","authors":["Hosam Elgendy","Ahmed Sharshar","Ahmed Aboeitta","Yasser Ashraf","Mohsen Guizani"],"url":"https://arxiv.org/abs/2410.19552"}
{"created":"2025-05-23","title":"Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites","abstract":"Machine learning (ML) models benefit from large datasets. Collecting data in biomedical domains is costly and challenging, hence, combining datasets has become a common practice. However, datasets obtained under different conditions could present undesired site-specific variability. Data harmonization methods aim to remove site-specific variance while retaining biologically relevant information. This study evaluates the effectiveness of popularly used ComBat-based methods for harmonizing data in scenarios where the class balance is not equal across sites. We find that these methods struggle with data leakage issues. To overcome this problem, we propose a novel approach PrettYharmonize, designed to harmonize data by pretending the target labels. We validate our approach using controlled datasets designed to benchmark the utility of harmonization. Finally, using real-world MRI and clinical data, we compare leakage-prone methods with PrettYharmonize and show that it achieves comparable performance while avoiding data leakage, particularly in site-target-dependence scenarios.","authors":["Nicol\\'as Nieto","Simon B. Eickhoff","Christian Jung","Martin Reuter","Kersten Diers","Malte Kelm","Artur Lichtenberg","Federico Raimondo","Kaustubh R. Patil"],"url":"https://arxiv.org/abs/2410.19643"}
{"created":"2025-05-23","title":"Understanding Synthetic Context Extension via Retrieval Heads","abstract":"Long-context LLMs are increasingly in demand for applications such as retrieval-augmented generation. To defray the cost of pretraining LLMs over long contexts, recent work takes an approach of synthetic context extension: fine-tuning LLMs with synthetically generated long-context data in a post-training stage. However, it remains unclear how and why this synthetic context extension imparts abilities for downstream long-context tasks. In this paper, we investigate fine-tuning on synthetic data for three long-context tasks that require retrieval and reasoning. We vary the realism of \"needle\" concepts to be retrieved and diversity of the surrounding \"haystack\" context, from using LLMs to construct synthetic documents to using templated relations and creating symbolic datasets. We find that models trained on synthetic data fall short of the real data, but surprisingly, the mismatch can be interpreted and even predicted in terms of a special set of attention heads that are responsible for retrieval over long context, retrieval heads (Wu et al., 2024). The retrieval heads learned on synthetic data have high overlap with retrieval heads learned on real data, and there is a strong correlation between the recall of heads learned and the downstream performance of a model. Furthermore, with attention knockout and activation patching, we mechanistically show that retrieval heads are necessary and explain model performance, although they are not totally sufficient. Our results shed light on how to interpret synthetic data fine-tuning performance and how to approach creating better data for learning real-world capabilities over long contexts.","authors":["Xinyu Zhao","Fangcong Yin","Greg Durrett"],"url":"https://arxiv.org/abs/2410.22316"}
{"created":"2025-05-23","title":"AAAR-1.0: Assessing AI's Potential to Assist Research","abstract":"Numerous studies have assessed the proficiency of AI systems, particularly large language models (LLMs), in facilitating everyday tasks such as email writing, question answering, and creative content generation. However, researchers face unique challenges and opportunities in leveraging LLMs for their own work, such as brainstorming research ideas, designing experiments, and writing or reviewing papers. In this study, we introduce AAAR-1.0, a benchmark dataset designed to evaluate LLM performance in three fundamental, expertise-intensive research tasks: (i) EquationInference, assessing the correctness of equations based on the contextual information in paper submissions; (ii) ExperimentDesign, designing experiments to validate research ideas and solutions; (iii) PaperWeakness, identifying weaknesses in paper submissions; and (iv) REVIEWCRITIQUE, identifying each segment in human reviews is deficient or not. AAAR-1.0 differs from prior benchmarks in two key ways: first, it is explicitly research-oriented, with tasks requiring deep domain expertise; second, it is researcher-oriented, mirroring the primary activities that researchers engage in on a daily basis. An evaluation of both open-source and proprietary LLMs reveals their potential as well as limitations in conducting sophisticated research tasks. We will keep iterating AAAR-1.0 to new versions.","authors":["Renze Lou","Hanzi Xu","Sijia Wang","Jiangshu Du","Ryo Kamoi","Xiaoxin Lu","Jian Xie","Yuxuan Sun","Yusen Zhang","Jihyun Janice Ahn","Hongchao Fang","Zhuoyang Zou","Wenchao Ma","Xi Li","Kai Zhang","Congying Xia","Lifu Huang","Wenpeng Yin"],"url":"https://arxiv.org/abs/2410.22394"}
{"created":"2025-05-23","title":"KAN-AD: Time Series Anomaly Detection with Kolmogorov-Arnold Networks","abstract":"Time series anomaly detection (TSAD) underpins real-time monitoring in cloud services and web systems, allowing rapid identification of anomalies to prevent costly failures. Most TSAD methods driven by forecasting models tend to overfit by emphasizing minor fluctuations. Our analysis reveals that effective TSAD should focus on modeling \"normal\" behavior through smooth local patterns. To achieve this, we reformulate time series modeling as approximating the series with smooth univariate functions. The local smoothness of each univariate function ensures that the fitted time series remains resilient against local disturbances. However, a direct KAN implementation proves susceptible to these disturbances due to the inherently localized characteristics of B-spline functions. We thus propose KAN-AD, replacing B-splines with truncated Fourier expansions and introducing a novel lightweight learning mechanism that emphasizes global patterns while staying robust to local disturbances. On four popular TSAD benchmarks, KAN-AD achieves an average 15% improvement in detection accuracy (with peaks exceeding 27%) over state-of-the-art baselines. Remarkably, it requires fewer than 1,000 trainable parameters, resulting in a 50% faster inference speed compared to the original KAN, demonstrating the approach's efficiency and practical viability.","authors":["Quan Zhou","Changhua Pei","Fei Sun","Jing Han","Zhengwei Gao","Dan Pei","Haiming Zhang","Gaogang Xie","Jianhui Li"],"url":"https://arxiv.org/abs/2411.00278"}
{"created":"2025-05-23","title":"Quantum Rationale-Aware Graph Contrastive Learning for Jet Discrimination","abstract":"In high-energy physics, particle jet tagging plays a pivotal role in distinguishing quark from gluon jets using data from collider experiments. While graph-based deep learning methods have advanced this task beyond traditional feature-engineered approaches, the complex data structure and limited labeled samples present ongoing challenges. However, existing contrastive learning (CL) frameworks struggle to leverage rationale-aware augmentations effectively, often lacking supervision signals that guide the extraction of salient features and facing computational efficiency issues such as high parameter counts. In this study, we demonstrate that integrating a quantum rationale generator (QRG) within our proposed Quantum Rationale-aware Graph Contrastive Learning (QRGCL) framework significantly enhances jet discrimination performance, reducing reliance on labeled data and capturing discriminative features. Evaluated on the quark-gluon jet dataset, QRGCL achieves an AUC score of $77.53\\%$ while maintaining a compact architecture of only 45 QRG parameters, outperforming classical, quantum, and hybrid GCL and GNN benchmarks. These results highlight QRGCL's potential to advance jet tagging and other complex classification tasks in high-energy physics, where computational efficiency and feature extraction limitations persist.","authors":["Md Abrar Jahin","Md. Akmol Masud","M. F. Mridha","Nilanjan Dey","Zeyar Aung"],"url":"https://arxiv.org/abs/2411.01642"}
{"created":"2025-05-23","title":"Enhancing the Influence of Labels on Unlabeled Nodes in Graph Convolutional Networks","abstract":"The message-passing mechanism of graph convolutional networks (i.e., GCNs) enables label information to reach more unlabeled neighbors, thereby increasing the utilization of labels. However, the additional label information does not always contribute positively to the GCN. To address this issue, we propose a new two-step framework called ELU-GCN. In the first stage, ELU-GCN conducts graph learning to learn a new graph structure (i.e., ELU-graph), which allows the additional label information to positively influence the predictions of GCN. In the second stage, we design a new graph contrastive learning on the GCN framework for representation learning by exploring the consistency and mutually exclusive information between the learned ELU graph and the original graph. Moreover, we theoretically demonstrate that the proposed method can ensure the generalization ability of GCNs. Extensive experiments validate the superiority of our method.","authors":["Jincheng Huang","Yujie Mo","Xiaoshuang Shi","Lei Feng","Xiaofeng Zhu"],"url":"https://arxiv.org/abs/2411.02279"}
{"created":"2025-05-23","title":"Graph-based Confidence Calibration for Large Language Models","abstract":"Reliable confidence estimation is essential for enhancing the trustworthiness of large language models (LLMs), especially in high-stakes scenarios. Despite its importance, accurately estimating confidence in LLM responses remains a significant challenge. In this work, we propose using an auxiliary learning model to assess response correctness based on the self-consistency of multiple outputs generated by the LLM. Our method builds a consistency graph to represent the agreement among multiple responses and uses a graph neural network (GNN) to estimate the likelihood that each response is correct. Experiments demonstrate that this method has strong calibration performance on various benchmark datasets and generalizes well to out-of-domain cases.","authors":["Yukun Li","Sijia Wang","Lifu Huang","Li-Ping Liu"],"url":"https://arxiv.org/abs/2411.02454"}
{"created":"2025-05-23","title":"Feature Map Similarity Reduction in Convolutional Neural Networks","abstract":"It has been observed that Convolutional Neural Networks (CNNs) suffer from redundancy in feature maps, leading to inefficient capacity utilization. Efforts to address this issue have largely focused on kernel orthogonality method. In this work, we theoretically and empirically demonstrate that kernel orthogonality does not necessarily lead to a reduction in feature map redundancy. Based on this analysis, we propose the Convolutional Similarity method to reduce feature map similarity, independently of the CNN's input. The Convolutional Similarity can be minimized as either a regularization term or an iterative initialization method. Experimental results show that minimizing Convolutional Similarity not only improves classification accuracy but also accelerates convergence. Furthermore, our method enables the use of significantly smaller models to achieve the same level of performance, promoting a more efficient use of model capacity. Future work will focus on coupling the iterative initialization method with the optimization momentum term and examining the method's impact on generative frameworks.","authors":["Zakariae Belmekki","Jun Li","Patrick Reuter","David Antonio G\\'omez J\\'auregui","Karl Jenkins"],"url":"https://arxiv.org/abs/2411.03226"}
{"created":"2025-05-23","title":"Long-Form Text-to-Music Generation with Adaptive Prompts: A Case Study in Tabletop Role-Playing Games Soundtracks","abstract":"This paper investigates the capabilities of text-to-audio music generation models in producing long-form music with prompts that change over time, focusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We introduce Babel Bardo, a system that uses Large Language Models (LLMs) to transform speech transcriptions into music descriptions for controlling a text-to-music model. Four versions of Babel Bardo were compared in two TRPG campaigns: a baseline using direct speech transcriptions, and three LLM-based versions with varying approaches to music description generation. Evaluations considered audio quality, story alignment, and transition smoothness. Results indicate that detailed music descriptions improve audio quality while maintaining consistency across consecutive descriptions enhances story alignment and transition smoothness.","authors":["Felipe Marra","Lucas N. Ferreira"],"url":"https://arxiv.org/abs/2411.03948"}
{"created":"2025-05-23","title":"Differential Privacy in Continual Learning: Which Labels to Update?","abstract":"The goal of continual learning (CL) is to retain knowledge across tasks, but this conflicts with strict privacy required for sensitive training data that prevents storing or memorising individual samples. To address that, we combine CL and differential privacy (DP). We highlight that failing to account for privacy leakage through the set of labels a model can output can break the privacy of otherwise valid DP algorithms. This is especially relevant in CL. We show that mitigating the issue with a data-independent overly large label space can have minimal negative impact on utility when fine-tuning a pre-trained model under DP, while learning the labels with a separate DP mechanism risks losing small classes.","authors":["Marlon Tobaben","Talal Alrawajfeh","Marcus Klasson","Mikko Heikkil\\\"a","Arno Solin","Antti Honkela"],"url":"https://arxiv.org/abs/2411.04680"}
{"created":"2025-05-23","title":"Prompt-Guided Internal States for Hallucination Detection of Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities across a variety of tasks in different domains. However, they sometimes generate responses that are logically coherent but factually incorrect or misleading, which is known as LLM hallucinations. Data-driven supervised methods train hallucination detectors by leveraging the internal states of LLMs, but detectors trained on specific domains often struggle to generalize well to other domains. In this paper, we aim to enhance the cross-domain performance of supervised detectors with only in-domain data. We propose a novel framework, prompt-guided internal states for hallucination detection of LLMs, namely PRISM. By utilizing appropriate prompts to guide changes to the structure related to text truthfulness in LLMs' internal states, we make this structure more salient and consistent across texts from different domains. We integrated our framework with existing hallucination detection methods and conducted experiments on datasets from different domains. The experimental results indicate that our framework significantly enhances the cross-domain generalization of existing hallucination detection methods.","authors":["Fujie Zhang","Peiqi Yu","Biao Yi","Baolei Zhang","Tong Li","Zheli Liu"],"url":"https://arxiv.org/abs/2411.04847"}
{"created":"2025-05-23","title":"TRACE: Transformer-based Risk Assessment for Clinical Evaluation","abstract":"We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation), a novel method for clinical risk assessment based on clinical data, leveraging the self-attention mechanism for enhanced feature interaction and result interpretation. Our approach is able to handle different data modalities, including continuous, categorical and multiple-choice (checkbox) attributes. The proposed architecture features a shared representation of the clinical data obtained by integrating specialized embeddings of each data modality, enabling the detection of high-risk individuals using Transformer encoder layers. To assess the effectiveness of the proposed method, a strong baseline based on non-negative multi-layer perceptrons (MLPs) is introduced. The proposed method outperforms various baselines widely used in the domain of clinical risk assessment, while effectively handling missing values. In terms of explainability, our Transformer-based method offers easily interpretable results via attention weights, further enhancing the clinicians' decision-making process.","authors":["Dionysis Christopoulos","Sotiris Spanos","Valsamis Ntouskos","Konstantinos Karantzalos"],"url":"https://arxiv.org/abs/2411.08701"}
{"created":"2025-05-23","title":"SmoothCache: A Universal Inference Acceleration Technique for Diffusion Transformers","abstract":"Diffusion Transformers (DiT) have emerged as powerful generative models for various tasks, including image, video, and speech synthesis. However, their inference process remains computationally expensive due to the repeated evaluation of resource-intensive attention and feed-forward modules. To address this, we introduce SmoothCache, a model-agnostic inference acceleration technique for DiT architectures. SmoothCache leverages the observed high similarity between layer outputs across adjacent diffusion timesteps. By analyzing layer-wise representation errors from a small calibration set, SmoothCache adaptively caches and reuses key features during inference. Our experiments demonstrate that SmoothCache achieves 8% to 71% speed up while maintaining or even improving generation quality across diverse modalities. We showcase its effectiveness on DiT-XL for image generation, Open-Sora for text-to-video, and Stable Audio Open for text-to-audio, highlighting its potential to enable real-time applications and broaden the accessibility of powerful DiT models.","authors":["Joseph Liu","Joshua Geddes","Ziyu Guo","Haomiao Jiang","Mahesh Kumar Nandwana"],"url":"https://arxiv.org/abs/2411.10510"}
{"created":"2025-05-23","title":"Quantifying Haptic Affection of Car Door through Data-Driven Analysis of Force Profile","abstract":"Haptic affection plays a crucial role in user experience, particularly in the automotive industry where the tactile quality of components can influence customer satisfaction. This study aims to accurately predict the affective property of a car door by only watching the force or torque profile of it when opening. To this end, a deep learning model is designed to capture the underlying relationships between force profiles and user-defined adjective ratings, providing insights into the door-opening experience. The dataset employed in this research includes force profiles and user adjective ratings collected from six distinct car models, reflecting a diverse set of door-opening characteristics and tactile feedback. The model's performance is assessed using Leave-One-Out Cross-Validation, a method that measures its generalization capability on unseen data. The results demonstrate that the proposed model achieves a high level of prediction accuracy, indicating its potential in various applications related to haptic affection and design optimization in the automotive industry.","authors":["Mudassir Ibrahim Awan","Ahsan Raza","Waseem Hassan","Ki-Uk Kyung","Seokhee Jeon"],"url":"https://arxiv.org/abs/2411.11382"}
{"created":"2025-05-23","title":"KAN-Mamba FusionNet: Redefining Medical Image Segmentation with Non-Linear Modeling","abstract":"Medical image segmentation is essential for applications like robotic surgeries, disease diagnosis, and treatment planning. Recently, various deep-learning models have been proposed to enhance medical image segmentation. One promising approach utilizes Kolmogorov-Arnold Networks (KANs), which better capture non-linearity in input data. However, they are unable to effectively capture long-range dependencies, which are required to accurately segment complex medical images and, by that, improve diagnostic accuracy in clinical settings. Neural networks such as Mamba can handle long-range dependencies. However, they have a limited ability to accurately capture non-linearities in the images as compared to KANs. Thus, we propose a novel architecture, the KAN-Mamba FusionNet, which improves segmentation accuracy by effectively capturing the non-linearities from input and handling long-range dependencies with the newly proposed KAMBA block. We evaluated the proposed KAN-Mamba FusionNet on three distinct medical image segmentation datasets: BUSI, Kvasir-Seg, and GlaS - and found it consistently outperforms state-of-the-art methods in IoU and F1 scores. Further, we examined the effects of various components and assessed their contributions to the overall model performance via ablation studies. The findings highlight the effectiveness of this methodology for reliable medical image segmentation, providing a unique approach to address intricate visual data issues in healthcare.","authors":["Akansh Agrawal","Akshan Agrawal","Shashwat Gupta","Priyanka Bagade"],"url":"https://arxiv.org/abs/2411.11926"}
{"created":"2025-05-23","title":"Neural Internal Model Control: Learning a Robust Control Policy via Predictive Error Feedback","abstract":"Accurate motion control in the face of disturbances within complex environments remains a major challenge in robotics. Classical model-based approaches often struggle with nonlinearities and unstructured disturbances, while RL-based methods can be fragile when encountering unseen scenarios. In this paper, we propose a novel framework, Neural Internal Model Control, which integrates model-based control with RL-based control to enhance robustness. Our framework streamlines the predictive model by applying Newton-Euler equations for rigid-body dynamics, eliminating the need to capture complex high-dimensional nonlinearities. This internal model combines model-free RL algorithms with predictive error feedback. Such a design enables a closed-loop control structure to enhance the robustness and generalizability of the control system. We demonstrate the effectiveness of our framework on both quadrotors and quadrupedal robots, achieving superior performance compared to state-of-the-art methods. Furthermore, real-world deployment on a quadrotor with rope-suspended payloads highlights the framework's robustness in sim-to-real transfer. Our code is released at https://github.com/thu-uav/NeuralIMC.","authors":["Feng Gao","Chao Yu","Yu Wang","Yi Wu"],"url":"https://arxiv.org/abs/2411.13079"}
{"created":"2025-05-23","title":"Transforming the Hybrid Cloud for Emerging AI Workloads","abstract":"This white paper, developed through close collaboration between IBM Research and UIUC researchers within the IIDAI Institute, envisions transforming hybrid cloud systems to meet the growing complexity of AI workloads through innovative, full-stack co-design approaches, emphasizing usability, manageability, affordability, adaptability, efficiency, and scalability. By integrating cutting-edge technologies such as generative and agentic AI, cross-layer automation and optimization, unified control plane, and composable and adaptive system architecture, the proposed framework addresses critical challenges in energy efficiency, performance, and cost-effectiveness. Incorporating quantum computing as it matures will enable quantum-accelerated simulations for materials science, climate modeling, and other high-impact domains. Collaborative efforts between academia and industry are central to this vision, driving advancements in foundation models for material design and climate solutions, scalable multimodal data processing, and enhanced physics-based AI emulators for applications like weather forecasting and carbon sequestration. Research priorities include advancing AI agentic systems, LLM as an Abstraction (LLMaaA), AI model optimization and unified abstractions across heterogeneous infrastructure, end-to-end edge-cloud transformation, efficient programming model, middleware and platform, secure infrastructure, application-adaptive cloud systems, and new quantum-classical collaborative workflows. These ideas and solutions encompass both theoretical and practical research questions, requiring coordinated input and support from the research community. This joint initiative aims to establish hybrid clouds as secure, efficient, and sustainable platforms, fostering breakthroughs in AI-driven applications and scientific discovery across academia, industry, and society.","authors":["Deming Chen","Alaa Youssef","Ruchi Pendse","Andr\\'e Schleife","Bryan K. Clark","Hendrik Hamann","Jingrui He","Teodoro Laino","Lav Varshney","Yuxiong Wang","Avirup Sil","Reyhaneh Jabbarvand","Tianyin Xu","Volodymyr Kindratenko","Carlos Costa","Sarita Adve","Charith Mendis","Minjia Zhang","Santiago N\\'u\\~nez-Corrales","Raghu Ganti","Mudhakar Srivatsa","Nam Sung Kim","Josep Torrellas","Jian Huang","Seetharami Seelam","Klara Nahrstedt","Tarek Abdelzaher","Tamar Eilam","Huimin Zhao","Matteo Manica","Ravishankar Iyer","Martin Hirzel","Vikram Adve","Darko Marinov","Hubertus Franke","Hanghang Tong","Elizabeth Ainsworth","Han Zhao","Deepak Vasisht","Minh Do","Sahil Suneja","Fabio Oliveira","Giovanni Pacifici","Ruchir Puri","Priya Nagpurkar"],"url":"https://arxiv.org/abs/2411.13239"}
{"created":"2025-05-23","title":"Breaking Information Cocoons: A Hyperbolic Graph-LLM Framework for Exploration and Exploitation in Recommender Systems","abstract":"Modern recommender systems often create information cocoons, restricting users' exposure to diverse content. A key challenge lies in balancing content exploration and exploitation while allowing users to adjust their recommendation preferences. Intuitively, this balance can be modeled as a tree-structured representation, where depth search facilitates exploitation and breadth search enables exploration. However, existing approaches face two fundamental limitations: Euclidean methods struggle to capture hierarchical structures, while hyperbolic methods, despite their superior hierarchical modeling, lack semantic understanding of user and item profiles and fail to provide a principled mechanism for balancing exploration and exploitation. To address these challenges, we propose HERec, a hyperbolic graph-LLM framework that effectively balances exploration and exploitation in recommender systems. Our framework introduces two key innovations: (1) a semantic-enhanced hierarchical mechanism that aligns rich textual descriptions processed by large language models (LLMs) with collaborative information directly in hyperbolic space, allowing for more nuanced updates that respect the underlying hierarchical structure in user-item profiles; (2) an automatic hierarchical representation by optimizing Dasgupta's cost, which discovers hierarchical structures without requiring predefined hyperparameters, enabling user-adjustable exploration-exploitation trade-offs. Extensive experiments demonstrate that HERec consistently outperforms both Euclidean and hyperbolic baselines, achieving up to 5.49% improvement in utility metrics and 11.39% increase in diversity metrics, effectively mitigating information cocoons. We open-source our model implementation at https://github.com/Martin-qyma/HERec.","authors":["Qiyao Ma","Menglin Yang","Mingxuan Ju","Tong Zhao","Neil Shah","Rex Ying"],"url":"https://arxiv.org/abs/2411.13865"}
{"created":"2025-05-23","title":"VisionPAD: A Vision-Centric Pre-training Paradigm for Autonomous Driving","abstract":"This paper introduces VisionPAD, a novel self-supervised pre-training paradigm designed for vision-centric algorithms in autonomous driving. In contrast to previous approaches that employ neural rendering with explicit depth supervision, VisionPAD utilizes more efficient 3D Gaussian Splatting to reconstruct multi-view representations using only images as supervision. Specifically, we introduce a self-supervised method for voxel velocity estimation. By warping voxels to adjacent frames and supervising the rendered outputs, the model effectively learns motion cues in the sequential data. Furthermore, we adopt a multi-frame photometric consistency approach to enhance geometric perception. It projects adjacent frames to the current frame based on rendered depths and relative poses, boosting the 3D geometric representation through pure image supervision. Extensive experiments on autonomous driving datasets demonstrate that VisionPAD significantly improves performance in 3D object detection, occupancy prediction and map segmentation, surpassing state-of-the-art pre-training strategies by a considerable margin.","authors":["Haiming Zhang","Wending Zhou","Yiyao Zhu","Xu Yan","Jiantao Gao","Dongfeng Bai","Yingjie Cai","Bingbing Liu","Shuguang Cui","Zhen Li"],"url":"https://arxiv.org/abs/2411.14716"}
{"created":"2025-05-23","title":"A Primer on AP Power Save in Wi-Fi 8: Overview, Analysis, and Open Challenges","abstract":"Wi-Fi facilitates the Internet connectivity of billions of devices worldwide, making it an indispensable technology for modern life. Wi-Fi networks are becoming significantly denser, making energy consumption and its effects on operational costs and environmental sustainability crucial considerations. Wi-Fi has already introduced several mechanisms to enhance the energy efficiency of non-Access Point (non-AP) stations (STAs). However, the reduction of energy consumption of APs has never been a priority. Always-on APs operating at their highest capabilities consume significant power, which affects the energy costs of the infrastructure owner, aggravates the environmental impact, and decreases the lifetime of battery-powered APs. IEEE 802.11bn, which will be the basis of Wi-Fi 8, makes a big leap forward by introducing the AP Power Save (PS) framework. In this article, we describe and analyze the main proposals discussed in the IEEE 802.11bn Task Group (TGbn), such as Scheduled Power Save, (Semi-)Dynamic Power Save, and Cross-Link Power Save. We also consider other proposals that are being discussed in TGbn, namely the integration of Wake-up Radios (WuRs) and STA offloading. We then showcase the potential benefits of AP PS in several scenarios, including a deployment of 470 real APs in a university campus. Our numerical analysis reveals that AP power consumption can be decreased on average by up to 28 percent, with further improvement potential. Finally, we outline the open challenges that need to be addressed to optimally integrate AP PS in Wi-Fi and ensure its compatibility with legacy devices.","authors":["Roger Sanchez-Vital","Andrey Belogaev","Carles Gomez","Jeroen Famaey","Eduard Garcia-Villegas"],"url":"https://arxiv.org/abs/2411.17424"}
{"created":"2025-05-23","title":"Data-Driven Prescriptive Analytics Applications: A Comprehensive Survey","abstract":"Prescriptive Analytics (PSA), an emerging business analytics field suggesting concrete options for solving business problems, has seen an increasing amount of interest after more than a decade of multidisciplinary research. This paper is a comprehensive survey of existing applications within PSA in terms of their use cases, methodologies, and possible future research directions. To ensure a manageable scope, we focus on PSA applications that develop data-driven, automatic workflows, i.e., Data-Driven PSA (DPSA). Following a systematic methodology, we identify and include 104 papers in our survey. As our key contributions, we derive a number of novel taxonomies of the field and use them to analyse the field's temporal development. In terms of use cases, we derive 10 application domains for DPSA, from Healthcare to Manufacturing, and subsumed problem types within each. In terms of individual method usage, we derive 5 method types and map them to a comprehensive taxonomy of method usage within DPSA applications, covering mathematical optimization, data mining and machine learning, probabilistic modelling, domain expertise, as well as simulations. As for combined method usage, we provide a statistical overview of how different method usage combinations are distributed and derive 2 generic workflow patterns along with subsumed workflow patterns, combining methods by either sequential or simultaneous relationships. Finally, we derive 5 possible research directions based on frequently recurring issues among surveyed papers, suggesting new frontiers in terms of methods, tools, and use cases.","authors":["Martin Moesmann","Torben Bach Pedersen"],"url":"https://arxiv.org/abs/2412.00034"}
{"created":"2025-05-23","title":"Seismocardiography for Emotion Recognition: A Study on EmoWear with Insights from DEAP","abstract":"Emotions have a profound impact on our daily lives, influencing our thoughts, behaviors, and interactions, but also our physiological reactions. Recent advances in wearable technology have facilitated studying emotions through cardio-respiratory signals. Accelerometers offer a non-invasive, convenient, and cost-effective method for capturing heart- and pulmonary-induced vibrations on the chest wall, specifically Seismocardiography (SCG) and Accelerometry-Derived Respiration (ADR). Their affordability, wide availability, and ability to provide rich contextual data make accelerometers ideal for everyday use. While accelerometers have been used as part of broader modality fusions for Emotion Recognition (ER), their stand-alone potential via SCG and ADR remains unexplored. Bridging this gap could significantly help the embedding of ER into real-world applications, minimizing the hardware, and increasing contextual integration potentials. To address this gap, we introduce SCG and ADR as novel modalities for ER and evaluate their performance using the EmoWear dataset. First, we replicate the single-trial emotion classification pipeline from the DEAP dataset study, achieving similar results. Then we use our validated pipeline to train models that predict affective valence-arousal states using SCG and compare them against established cardiac signals, Electrocardiography (ECG) and Blood Volume Pulse (BVP). Results show that SCG is a viable modality for ER, achieving similar performance to ECG and BVP. By combining ADR with SCG, we achieved a working ER framework that only requires a single chest-worn accelerometer. These findings pave the way for integrating ER into real-world, enabling seamless affective computing in everyday life.","authors":["Mohammad Hasan Rahmani","Rafael Berkvens","Maarten Weyn"],"url":"https://arxiv.org/abs/2412.00411"}
{"created":"2025-05-23","title":"Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings","abstract":"Several evaluation metrics have been developed recently to automatically assess the quality of generative AI reports for chest radiographs based only on textual information using lexical, semantic, or clinical named entity recognition methods. In this paper, we develop a new method of report quality evaluation by first extracting fine-grained finding patterns capturing the location, laterality, and severity of a large number of clinical findings. We then performed phrasal grounding to localize their associated anatomical regions on chest radiograph images. The textual and visual measures are then combined to rate the quality of the generated reports. We present results that compare this evaluation metric with other textual metrics on a gold standard dataset derived from the MIMIC collection and show its robustness and sensitivity to factual errors.","authors":["Razi Mahmood","Pingkun Yan","Diego Machado Reyes","Ge Wang","Mannudeep K. Kalra","Parisa Kaviani","Joy T. Wu","Tanveer Syeda-Mahmood"],"url":"https://arxiv.org/abs/2412.01031"}
{"created":"2025-05-23","title":"Remote Sensing Spatio-Temporal Vision-Language Models: A Comprehensive Survey","abstract":"The interpretation of multi-temporal remote sensing imagery is critical for monitoring Earth's dynamic processes-yet previous change detection methods, which produce binary or semantic masks, fall short of providing human-readable insights into changes. Recent advances in Vision-Language Models (VLMs) have opened a new frontier by fusing visual and linguistic modalities, enabling spatio-temporal vision-language understanding: models that not only capture spatial and temporal dependencies to recognize changes but also provide a richer interactive semantic analysis of temporal images (e.g., generate descriptive captions and answer natural-language queries). In this survey, we present the first comprehensive review of RS-STVLMs. The survey covers the evolution of models from early task-specific models to recent general foundation models that leverage powerful large language models. We discuss progress in representative tasks, such as change captioning, change question answering, and change grounding. Moreover, we systematically dissect the fundamental components and key technologies underlying these models, and review the datasets and evaluation metrics that have driven the field. By synthesizing task-level insights with a deep dive into shared architectural patterns, we aim to illuminate current achievements and chart promising directions for future research in spatio-temporal vision-language understanding for remote sensing. We will keep tracing related works at https://github.com/Chen-Yang-Liu/Awesome-RS-SpatioTemporal-VLMs","authors":["Chenyang Liu","Jiafan Zhang","Keyan Chen","Man Wang","Zhengxia Zou","Zhenwei Shi"],"url":"https://arxiv.org/abs/2412.02573"}
{"created":"2025-05-23","title":"Copy-Move Forgery Detection and Question Answering for Remote Sensing Image","abstract":"Driven by practical demands in land resource monitoring and national defense security, this paper introduces the Remote Sensing Copy-Move Question Answering (RSCMQA) task. Unlike traditional Remote Sensing Visual Question Answering (RSVQA), RSCMQA focuses on interpreting complex tampering scenarios and inferring relationships between objects. We present a suite of global RSCMQA datasets, comprising images from 29 different regions across 14 countries. Specifically, we propose five distinct datasets, including the basic dataset RS-CMQA, the category-balanced dataset RS-CMQA-B, the high-authenticity dataset Real-RSCM, the extended dataset RS-TQA, and the extended category-balanced dataset RS-TQA-B. These datasets fill a critical gap in the field while ensuring comprehensiveness, balance, and challenge. Furthermore, we introduce a region-discrimination-guided multimodal copy-move forgery perception framework (CMFPF), which enhances the accuracy of answering questions about tampered images by leveraging prompt about the differences and connections between the source and tampered domains. Extensive experiments demonstrate that our method provides a stronger benchmark for RSCMQA compared to general VQA and RSVQA models. Our datasets and code are publicly available at https://github.com/shenyedepisa/RSCMQA.","authors":["Ze Zhang","Enyuan Zhao","Di Niu","Jie Nie","Xinyue Liang","Lei Huang"],"url":"https://arxiv.org/abs/2412.02575"}
{"created":"2025-05-23","title":"Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction","abstract":"In smart mobility, large networks of geographically distributed sensors produce vast amounts of high-frequency spatio-temporal data that must be processed in real time to avoid major disruptions. Traditional centralized approaches are increasingly unsuitable to this task, as they struggle to scale with expanding sensor networks, and reliability issues in central components can easily affect the whole deployment. To address these challenges, we explore and adapt semi-decentralized training techniques for Spatio-Temporal Graph Neural Networks (ST-GNNs) in smart mobility domain. We implement a simulation framework where sensors are grouped by proximity into multiple cloudlets, each handling a subgraph of the traffic graph, fetching node features from other cloudlets to train its own local ST-GNN model, and exchanging model updates with other cloudlets to ensure consistency, enhancing scalability and removing reliance on a centralized aggregator. We perform extensive comparative evaluation of four different ST-GNN training setups -- centralized, traditional FL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the METR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed predictions. Experimental results show that semi-decentralized setups are comparable to centralized approaches in performance metrics, while offering advantages in terms of scalability and fault tolerance. In addition, we highlight often overlooked issues in existing literature for distributed ST-GNNs, such as the variation in model performance across different geographical areas due to region-specific traffic patterns, and the significant communication overhead and computational costs that arise from the large receptive field of GNNs, leading to substantial data transfers and increased computation of partial embeddings.","authors":["Ivan Kralj","Lodovico Giaretta","Gordan Je\\v{z}i\\'c","Ivana Podnar \\v{Z}arko","\\v{S}ar\\=unas Girdzijauskas"],"url":"https://arxiv.org/abs/2412.03188"}
{"created":"2025-05-23","title":"Mask of truth: model sensitivity to unexpected regions of medical images","abstract":"The development of larger models for medical image analysis has led to increased performance. However, it also affected our ability to explain and validate model decisions. Models can use non-relevant parts of images, also called spurious correlations or shortcuts, to obtain high performance on benchmark datasets but fail in real-world scenarios. In this work, we challenge the capacity of convolutional neural networks (CNN) to classify chest X-rays and eye fundus images while masking out clinically relevant parts of the image. We show that all models trained on the PadChest dataset, irrespective of the masking strategy, are able to obtain an Area Under the Curve (AUC) above random. Moreover, the models trained on full images obtain good performance on images without the region of interest (ROI), even superior to the one obtained on images only containing the ROI. We also reveal a possible spurious correlation in the Chaksu dataset while the performances are more aligned with the expectation of an unbiased model. We go beyond the performance analysis with the usage of the explainability method SHAP and the analysis of embeddings. We asked a radiology resident to interpret chest X-rays under different masking to complement our findings with clinical knowledge. Our code is available at https://github.com/TheoSourget/MMC_Masking and https://github.com/TheoSourget/MMC_Masking_EyeFundus","authors":["Th\\'eo Sourget","Michelle Hestbek-M{\\o}ller","Amelia Jim\\'enez-S\\'anchez","Jack Junchi Xu","Veronika Cheplygina"],"url":"https://arxiv.org/abs/2412.04030"}
{"created":"2025-05-23","title":"On the Lack of Robustness of Binary Function Similarity Systems","abstract":"Binary function similarity, which often relies on learning-based algorithms to identify what functions in a pool are most similar to a given query function, is a sought-after topic in different communities, including machine learning, software engineering, and security. Its importance stems from the impact it has in facilitating several crucial tasks, from reverse engineering and malware analysis to automated vulnerability detection. Whereas recent work cast light around performance on this long-studied problem, the research landscape remains largely lackluster in understanding the resiliency of the state-of-the-art machine learning models against adversarial attacks. As security requires to reason about adversaries, in this work we assess the robustness of such models through a simple yet effective black-box greedy attack, which modifies the topology and the content of the control flow of the attacked functions. We demonstrate that this attack is successful in compromising all the models, achieving average attack success rates of 57.06% and 95.81% depending on the problem settings (targeted and untargeted attacks). Our findings are insightful: top performance on clean data does not necessarily relate to top robustness properties, which explicitly highlights performance-robustness trade-offs one should consider when deploying such models, calling for further research.","authors":["Gianluca Capozzi","Tong Tang","Jie Wan","Ziqi Yang","Daniele Cono D'Elia","Giuseppe Antonio Di Luna","Lorenzo Cavallaro","Leonardo Querzoni"],"url":"https://arxiv.org/abs/2412.04163"}
{"created":"2025-05-23","title":"HyperMARL: Adaptive Hypernetworks for Multi-Agent RL","abstract":"Adaptability to specialised or homogeneous behaviours is critical in cooperative multi-agent reinforcement learning (MARL). Parameter sharing (PS) techniques, common for efficient adaptation, often limit behavioural diversity due to cross-agent gradient interference, which we show can be exacerbated by the coupling of observations and agent IDs. Current remedies typically add complexity through altered objectives, manual preset diversity levels, or sequential updates. We ask: can shared policies adapt without these complexities? We propose HyperMARL, a PS approach using hypernetworks for dynamic agent-specific parameters, without altering the RL objective or requiring preset diversity levels. HyperMARL's explicit decoupling of observation- and agent-conditioned gradients empirically reduces policy gradient variance, facilitates shared-policy adaptation (including specialisation), and helps mitigate cross-agent interference. Across diverse MARL benchmarks (up to 20 agents), requiring homogeneous, heterogeneous, or mixed behaviours, HyperMARL achieves competitive performance against key baselines -- fully shared, non-parameter sharing, and three diversity-promoting methods -- while preserving behavioural diversity comparable to non-parameter sharing. These findings establish HyperMARL as a versatile approach for adaptive MARL. The code is publicly available at https://github.com/KaleabTessera/HyperMARL.","authors":["Kale-ab Abebe Tessera","Arrasy Rahman","Amos Storkey","Stefano V. Albrecht"],"url":"https://arxiv.org/abs/2412.04233"}
{"created":"2025-05-23","title":"Extractive Structures Learned in Pretraining Enable Generalization on Finetuned Facts","abstract":"Pretrained language models (LMs) can generalize to implications of facts that they are finetuned on. For example, if finetuned on ``John Doe lives in Tokyo,\" LMs can correctly answer ``What language do the people in John Doe's city speak?'' with ``Japanese''. However, little is known about the mechanisms that enable this generalization or how they are learned during pretraining. We introduce extractive structures as a framework for describing how components in LMs (e.g., MLPs or attention heads) coordinate to enable this generalization. The structures consist of informative components that store training facts as weight changes, and upstream and downstream extractive components that query and process the stored information to produce the correct implication. We hypothesize that extractive structures are learned during pretraining when encountering implications of previously known facts. This yields two predictions: a data ordering effect where extractive structures can be learned only if facts precede their implications, and a weight grafting effect where extractive structures can be transferred to predict counterfactual implications. We empirically demonstrate these phenomena in the OLMo-7b, Llama 3-8b, Gemma 2-9b, and Qwen 2-7b models. Of independent interest, our results also indicate that fact learning can occur at both early and late layers, which lead to different forms of generalization.","authors":["Jiahai Feng","Stuart Russell","Jacob Steinhardt"],"url":"https://arxiv.org/abs/2412.04614"}
{"created":"2025-05-23","title":"Evaluating LLM-based Approaches to Legal Citation Prediction: Domain-specific Pre-training, Fine-tuning, or RAG? A Benchmark and an Australian Law Case Study","abstract":"Large Language Models (LLMs) have demonstrated strong potential across legal tasks, yet the problem of legal citation prediction remains under-explored. At its core, this task demands fine-grained contextual understanding and precise identification of relevant legislation or precedent. We introduce the AusLaw Citation Benchmark, a real-world dataset comprising 55k Australian legal instances and 18,677 unique citations which to the best of our knowledge is the first of its scale and scope. We then conduct a systematic benchmarking across a range of solutions: (i) standard prompting of both general and law-specialised LLMs, (ii) retrieval-only pipelines with both generic and domain-specific embeddings, (iii) supervised fine-tuning, and (iv) several hybrid strategies that combine LLMs with retrieval augmentation through query expansion, voting ensembles, or re-ranking. Results show that neither general nor law-specific LLMs suffice as stand-alone solutions, with performance near zero. Instruction tuning (of even a generic open-source LLM) on task-specific dataset is among the best performing solutions. We highlight that database granularity along with the type of embeddings play a critical role in retrieval-based approaches, with hybrid methods which utilise a trained re-ranker delivering the best results. Despite this, a performance gap of nearly 50% remains, underscoring the value of this challenging benchmark as a rigorous test-bed for future research in legal-domain.","authors":["Jiuzhou Han","Paul Burgess","Ehsan Shareghi"],"url":"https://arxiv.org/abs/2412.06272"}
{"created":"2025-05-23","title":"My Words Imply Your Opinion: Reader Agent-based Propagation Enhancement for Personalized Implicit Emotion Analysis","abstract":"The subtlety of emotional expressions makes implicit emotion analysis (IEA) particularly sensitive to user-specific characteristics. Current studies personalize emotion analysis by focusing on the author but neglect the impact of the intended reader on implicit emotional feedback. In this paper, we introduce Personalized IEA (PIEA) and present the RAPPIE model, which addresses subjective variability by incorporating reader feedback. In particular, (1) we create reader agents based on large language models to simulate reader feedback, overcoming the issue of ``spiral of silence effect'' and data incompleteness of real reader reaction. (2) We develop a role-aware multi-view graph learning to model the emotion interactive propagation process in scenarios with sparse reader information. (3) We construct two new PIEA datasets covering English and Chinese social media with detailed user metadata, addressing the text-centric limitation of existing datasets. Extensive experiments show that RAPPIE significantly outperforms state-of-the-art baselines, demonstrating the value of incorporating reader feedback in PIEA.","authors":["Jian Liao","Yu Feng","Yujin Zheng","Jun Zhao","Suge Wang","Jianxing Zheng"],"url":"https://arxiv.org/abs/2412.07367"}
{"created":"2025-05-23","title":"Motion by Queries: Identity-Motion Trade-offs in Text-to-Video Generation","abstract":"Text-to-video diffusion models have shown remarkable progress in generating coherent video clips from textual descriptions. However, the interplay between motion, structure, and identity representations in these models remains under-explored. Here, we investigate how self-attention query (Q) features simultaneously govern motion, structure, and identity and examine the challenges arising when these representations interact. Our analysis reveals that Q affects not only layout, but that during denoising Q also has a strong effect on subject identity, making it hard to transfer motion without the side-effect of transferring identity. Understanding this dual role enabled us to control query feature injection (Q injection) and demonstrate two applications: (1) a zero-shot motion transfer method - implemented with VideoCrafter2 and WAN 2.1 - that is 10 times more efficient than existing approaches, and (2) a training-free technique for consistent multi-shot video generation, where characters maintain identity across multiple video shots while Q injection enhances motion fidelity.","authors":["Yuval Atzmon","Rinon Gal","Yoad Tewel","Yoni Kasten","Gal Chechik"],"url":"https://arxiv.org/abs/2412.07750"}
{"created":"2025-05-23","title":"AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era","abstract":"Animation has gained significant interest in the recent film and TV industry. Despite the success of advanced video generation models like Sora, Kling, and CogVideoX in generating natural videos, they lack the same effectiveness in handling animation videos. Evaluating animation video generation is also a great challenge due to its unique artist styles, violating the laws of physics and exaggerated motions. In this paper, we present a comprehensive system, AniSora, designed for animation video generation, which includes a data processing pipeline, a controllable generation model, and an evaluation benchmark. Supported by the data processing pipeline with over 10M high-quality data, the generation model incorporates a spatiotemporal mask module to facilitate key animation production functions such as image-to-video generation, frame interpolation, and localized image-guided animation. We also collect an evaluation benchmark of 948 various animation videos, with specifically developed metrics for animation video generation. Our entire project is publicly available on https://github.com/bilibili/Index-anisora/tree/main.","authors":["Yudong Jiang","Baohan Xu","Siqian Yang","Mingyu Yin","Jing Liu","Chao Xu","Siqi Wang","Yidi Wu","Bingwen Zhu","Xinwen Zhang","Xingyu Zheng","Jixuan Xu","Yue Zhang","Jinlong Hou","Huyang Sun"],"url":"https://arxiv.org/abs/2412.10255"}
{"created":"2025-05-23","title":"What Matters in Learning A Zero-Shot Sim-to-Real RL Policy for Quadrotor Control? A Comprehensive Study","abstract":"Executing precise and agile flight maneuvers is critical for quadrotors in various applications. Traditional quadrotor control approaches are limited by their reliance on flat trajectories or time-consuming optimization, which restricts their flexibility. Recently, RL-based policy has emerged as a promising alternative due to its ability to directly map observations to actions, reducing the need for detailed system knowledge and actuation constraints. However, a significant challenge remains in bridging the sim-to-real gap, where RL-based policies often experience instability when deployed in real world. In this paper, we investigate key factors for learning robust RL-based control policies that are capable of zero-shot deployment in real-world quadrotors. We identify five critical factors and we develop a PPO-based training framework named SimpleFlight, which integrates these five techniques. We validate the efficacy of SimpleFlight on Crazyflie quadrotor, demonstrating that it achieves more than a 50% reduction in trajectory tracking error compared to state-of-the-art RL baselines. The policy derived by SimpleFlight consistently excels across both smooth polynominal trajectories and challenging infeasible zigzag trajectories on small thrust-to-weight quadrotors. In contrast, baseline methods struggle with high-speed or infeasible trajectories. To support further research and reproducibility, we integrate SimpleFlight into a GPU-based simulator Omnidrones and provide open-source access to the code and model checkpoints. We hope SimpleFlight will offer valuable insights for advancing RL-based quadrotor control. For more details, visit our project website at https://sites.google.com/view/simpleflight/.","authors":["Jiayu Chen","Chao Yu","Yuqing Xie","Feng Gao","Yinuo Chen","Shu'ang Yu","Wenhao Tang","Shilong Ji","Mo Mu","Yi Wu","Huazhong Yang","Yu Wang"],"url":"https://arxiv.org/abs/2412.11764"}
{"created":"2025-05-23","title":"LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework","abstract":"Topic modeling is widely used for uncovering thematic structures within text corpora, yet traditional models often struggle with specificity and coherence in domain-focused applications. Guided approaches, such as SeededLDA and CorEx, incorporate user-provided seed words to improve relevance but remain labor-intensive and static. Large language models (LLMs) offer potential for dynamic topic refinement and discovery, yet their application often incurs high API costs. To address these challenges, we propose the LLM-assisted Iterative Topic Augmentation framework (LITA), an LLM-assisted approach that integrates user-provided seeds with embedding-based clustering and iterative refinement. LITA identifies a small number of ambiguous documents and employs an LLM to reassign them to existing or new topics, minimizing API costs while enhancing topic quality. Experiments on two datasets across topic quality and clustering performance metrics demonstrate that LITA outperforms five baseline models, including LDA, SeededLDA, CorEx, BERTopic, and PromptTopic. Our work offers an efficient and adaptable framework for advancing topic modeling and text clustering.","authors":["Chia-Hsuan Chang","Jui-Tse Tsai","Yi-Hang Tsai","San-Yih Hwang"],"url":"https://arxiv.org/abs/2412.12459"}
{"created":"2025-05-23","title":"DocFusion: A Unified Framework for Document Parsing Tasks","abstract":"Document parsing is essential for analyzing complex document structures and extracting fine-grained information, supporting numerous downstream applications. However, existing methods often require integrating multiple independent models to handle various parsing tasks, leading to high complexity and maintenance overhead. To address this, we propose DocFusion, a lightweight generative model with only 0.28B parameters. It unifies task representations and achieves collaborative training through an improved objective function. Experiments reveal and leverage the mutually beneficial interaction among recognition tasks, and integrating recognition data significantly enhances detection performance. The final results demonstrate that DocFusion achieves state-of-the-art (SOTA) performance across four key tasks.","authors":["Mingxu Chai","Ziyu Shen","Chong Zhang","Yue Zhang","Xiao Wang","Shihan Dou","Jihua Kang","Jiazheng Zhang","Qi Zhang"],"url":"https://arxiv.org/abs/2412.12505"}
{"created":"2025-05-23","title":"Detection of Aerial Spoofing Attacks to LEO Satellite Systems via Deep Learning","abstract":"Detecting spoofing attacks to Low-Earth-Orbit (LEO) satellite systems is a cornerstone to assessing the authenticity of the received information and guaranteeing robust service delivery in several application domains. The solutions available today for spoofing detection either rely on additional communication systems, receivers, and antennas, or require mobile deployments. Detection systems working at the Physical (PHY) layer of the satellite communication link also require time-consuming and energy-hungry training processes on all satellites of the constellation, and rely on the availability of spoofed data, which are often challenging to collect. Moreover, none of such contributions investigate the feasibility of aerial spoofing attacks launched via drones operating at various altitudes. In this paper, we propose a new spoofing detection technique for LEO satellite constellation systems, applying anomaly detection on the received PHY signal via autoencoders. We validate our solution through an extensive measurement campaign involving the deployment of an actual spoofer (Software-Defined Radio) installed on a drone and injecting rogue IRIDIUM messages while flying at different altitudes with various movement patterns. Our results demonstrate that the proposed technique can reliably detect LEO spoofing attacks launched at different altitudes, while state-of-the-art competing approaches simply fail. We also release the collected data as open source, fostering further research on satellite security.","authors":["Jos Wigchert","Savio Sciancalepore","Gabriele Oligeri"],"url":"https://arxiv.org/abs/2412.16008"}
{"created":"2025-05-23","title":"Divide and Conquer: A Hybrid Strategy Defeats Multimodal Large Language Models","abstract":"Large language models (LLMs) are widely applied in various fields of society due to their powerful reasoning, understanding, and generation capabilities. However, the security issues associated with these models are becoming increasingly severe. Jailbreaking attacks, as an important method for detecting vulnerabilities in LLMs, have been explored by researchers who attempt to induce these models to generate harmful content through various attack methods. Nevertheless, existing jailbreaking methods face numerous limitations, such as excessive query counts, limited coverage of jailbreak modalities, low attack success rates, and simplistic evaluation methods. To overcome these constraints, this paper proposes a multimodal jailbreaking method: JMLLM. This method integrates multiple strategies to perform comprehensive jailbreak attacks across text, visual, and auditory modalities. Additionally, we contribute a new and comprehensive dataset for multimodal jailbreaking research: TriJail, which includes jailbreak prompts for all three modalities. Experiments on the TriJail dataset and the benchmark dataset AdvBench, conducted on 13 popular LLMs, demonstrate advanced attack success rates and significant reduction in time overhead.","authors":["Yanxu Mao","Peipei Liu","Tiehan Cui","Zhaoteng Yan","Congying Liu","Datao You"],"url":"https://arxiv.org/abs/2412.16555"}
{"created":"2025-05-23","title":"ErasableMask: A Robust and Erasable Privacy Protection Scheme against Black-box Face Recognition Models","abstract":"While face recognition (FR) models have brought remarkable convenience in face verification and identification, they also pose substantial privacy risks to the public. Existing facial privacy protection schemes usually adopt adversarial examples to disrupt face verification of FR models. However, these schemes often suffer from weak transferability against black-box FR models and permanently damage the identifiable information that cannot fulfill the requirements of authorized operations such as forensics and authentication. To address these limitations, we propose ErasableMask, a robust and erasable privacy protection scheme against black-box FR models. Specifically, via rethinking the inherent relationship between surrogate FR models, ErasableMask introduces a novel meta-auxiliary attack, which boosts black-box transferability by learning more general features in a stable and balancing optimization strategy. It also offers a perturbation erasion mechanism that supports the erasion of semantic perturbations in protected face without degrading image quality. To further improve performance, ErasableMask employs a curriculum learning strategy to mitigate optimization conflicts between adversarial attack and perturbation erasion. Extensive experiments on the CelebA-HQ and FFHQ datasets demonstrate that ErasableMask achieves the state-of-the-art performance in transferability, achieving over 72% confidence on average in commercial FR systems. Moreover, ErasableMask also exhibits outstanding perturbation erasion performance, achieving over 90% erasion success rate.","authors":["Sipeng Shen","Yunming Zhang","Dengpan Ye","Xiuwen Shi","Long Tang","Haoran Duan","Yueyun Shang","Zhihong Tian"],"url":"https://arxiv.org/abs/2412.17038"}
{"created":"2025-05-23","title":"Refining CNN-based Heatmap Regression with Gradient-based Corner Points for Electrode Localization","abstract":"We propose a method for detecting the electrode positions in lithium-ion batteries. The process begins by identifying the region of interest (ROI) in the battery's X-ray image through corner point detection. A convolutional neural network is then used to regress the pole positions within this ROI. Finally, the regressed positions are optimized and corrected using corner point priors, significantly mitigating the loss of localization accuracy caused by operations such as feature map down-sampling and padding during network training. Our findings show that combining traditional pixel gradient analysis with CNN-based heatmap regression for keypoint extraction enhances both accuracy and efficiency, resulting in significant performance improvements.","authors":["Lin Wu"],"url":"https://arxiv.org/abs/2412.17105"}
{"created":"2025-05-23","title":"Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey","abstract":"Facial expressions convey human emotions and can be categorized into macro-expressions (MaEs) and micro-expressions (MiEs) based on duration and intensity. While MaEs are voluntary and easily recognized, MiEs are involuntary, rapid, and can reveal concealed emotions. The integration of facial expression analysis with Internet-of-Thing (IoT) systems has significant potential across diverse scenarios. IoT-enhanced MaE analysis enables real-time monitoring of patient emotions, facilitating improved mental health care in smart healthcare. Similarly, IoT-based MiE detection enhances surveillance accuracy and threat detection in smart security. Our work aims to provide a comprehensive overview of research progress in facial expression analysis and explores its potential integration with IoT systems. We discuss the distinctions between our work and existing surveys, elaborate on advancements in MaE and MiE analysis techniques across various learning paradigms, and examine their potential applications in IoT. We highlight challenges and future directions for the convergence of facial expression-based technologies and IoT systems, aiming to foster innovation in this domain. By presenting recent developments and practical applications, our work offers a systematic understanding of the ways of facial expression analysis to enhance IoT systems in healthcare, security, and beyond.","authors":["Zixuan Shanggua","Yanjie Dong","Song Guo","Victor C. M. Leung","M. Jamal Deen","Xiping Hu"],"url":"https://arxiv.org/abs/2412.17616"}
{"created":"2025-05-23","title":"BenCzechMark : A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism","abstract":"We present BenCzechMark (BCM), the first comprehensive Czech language benchmark designed for large language models, offering diverse tasks, multiple task formats, and multiple evaluation metrics. Its duel scoring system is grounded in statistical significance theory and uses aggregation across tasks inspired by social preference theory. Our benchmark encompasses 50 challenging tasks, with corresponding test datasets, primarily in native Czech, with 14 newly collected ones. These tasks span 8 categories and cover diverse domains, including historical Czech news, essays from pupils or language learners, and spoken word. Furthermore, we collect and clean BUT-Large Czech Collection, the largest publicly available clean Czech language corpus, and use it for (i) contamination analysis and (ii) continuous pretraining of the first Czech-centric 7B language model with Czech-specific tokenization. We use our model as a baseline for comparison with publicly available multilingual models. Lastly, we release and maintain a leaderboard with existing 50 model submissions, where new model submissions can be made at https://huggingface.co/spaces/CZLC/BenCzechMark.","authors":["Martin Fajcik","Martin Docekal","Jan Dolezal","Karel Ondrej","Karel Bene\\v{s}","Jan Kapsa","Pavel Smrz","Alexander Polok","Michal Hradis","Zuzana Neverilova","Ales Horak","Radoslav Sabol","Michal Stefanik","Adam Jirkovsky","David Adamczyk","Petr Hyner","Jan Hula","Hynek Kydlicek"],"url":"https://arxiv.org/abs/2412.17933"}
{"created":"2025-05-23","title":"Enhancing Multi-Robot Semantic Navigation Through Multimodal Chain-of-Thought Score Collaboration","abstract":"Understanding how humans cooperatively utilize semantic knowledge to explore unfamiliar environments and decide on navigation directions is critical for house service multi-robot systems. Previous methods primarily focused on single-robot centralized planning strategies, which severely limited exploration efficiency. Recent research has considered decentralized planning strategies for multiple robots, assigning separate planning models to each robot, but these approaches often overlook communication costs. In this work, we propose Multimodal Chain-of-Thought Co-Navigation (MCoCoNav), a modular approach that utilizes multimodal Chain-of-Thought to plan collaborative semantic navigation for multiple robots. MCoCoNav combines visual perception with Vision Language Models (VLMs) to evaluate exploration value through probabilistic scoring, thus reducing time costs and achieving stable outputs. Additionally, a global semantic map is used as a communication bridge, minimizing communication overhead while integrating observational results. Guided by scores that reflect exploration trends, robots utilize this map to assess whether to explore new frontier points or revisit history nodes. Experiments on HM3D_v0.2 and MP3D demonstrate the effectiveness of our approach. Our code is available at https://github.com/FrankZxShen/MCoCoNav.git.","authors":["Zhixuan Shen","Haonan Luo","Kexun Chen","Fengmao Lv","Tianrui Li"],"url":"https://arxiv.org/abs/2412.18292"}
{"created":"2025-05-23","title":"Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot Quantization in Edge Computing","abstract":"We introduce AKT (Advanced Knowledge Transfer), a novel method to enhance the training ability of low-bit quantized (Q) models in the field of zero-shot quantization (ZSQ). Existing research in ZSQ has focused on generating high-quality data from full-precision (FP) models. However, these approaches struggle with reduced learning ability in low-bit quantization due to its limited information capacity. To overcome this limitation, we propose effective training strategy compared to data generation. Particularly, we analyzed that refining feature maps in the feature distillation process is an effective way to transfer knowledge to the Q model. Based on this analysis, AKT efficiently transfer core information from the FP model to the Q model. AKT is the first approach to utilize both spatial and channel attention information in feature distillation in ZSQ. Our method addresses the fundamental gradient exploding problem in low-bit Q models. Experiments on CIFAR-10 and CIFAR-100 datasets demonstrated the effectiveness of the AKT. Our method led to significant performance enhancement in existing generative models. Notably, AKT achieved significant accuracy improvements in low-bit Q models, achieving state-of-the-art in the 3,5bit scenarios on CIFAR-10. The code is available at https://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer.","authors":["Inpyo Hong","Youngwan Jo","Hyojeong Lee","Sunghyun Ahn","Sanghyun Park"],"url":"https://arxiv.org/abs/2412.19125"}
{"created":"2025-05-23","title":"UniRestorer: Universal Image Restoration via Adaptively Estimating Image Degradation at Proper Granularity","abstract":"Recently, considerable progress has been made in all-in-one image restoration. Generally, existing methods can be degradation-agnostic or degradation-aware. However, the former are limited in leveraging degradation-specific restoration, and the latter suffer from the inevitable error in degradation estimation. Consequently, the performance of existing methods has a large gap compared to specific single-task models. In this work, we make a step forward in this topic, and present our UniRestorer with improved restoration performance. Specifically, we perform hierarchical clustering on degradation space, and train a multi-granularity mixture-of-experts (MoE) restoration model. Then, UniRestorer adopts both degradation and granularity estimation to adaptively select an appropriate expert for image restoration. In contrast to existing degradation-agnostic and -aware methods, UniRestorer can leverage degradation estimation to benefit degradation specific restoration, and use granularity estimation to make the model robust to degradation estimation error. Experimental results show that our UniRestorer outperforms state-of-the-art all-in-one methods by a large margin, and is promising in closing the performance gap to specific single task models.","authors":["Jingbo Lin","Zhilu Zhang","Wenbo Li","Renjing Pei","Hang Xu","Hongzhi Zhang","Wangmeng Zuo"],"url":"https://arxiv.org/abs/2412.20157"}
{"created":"2025-05-23","title":"Reconciling Privacy and Explainability in High-Stakes: A Systematic Inquiry","abstract":"Deep learning's preponderance across scientific domains has reshaped high-stakes decision-making, making it essential to follow rigorous operational frameworks that include both Right-to-Privacy (RTP) and Right-to-Explanation (RTE). This paper examines the complexities of combining these two requirements. For RTP, we focus on `Differential privacy` (DP), which is considered the current gold standard for privacy-preserving machine learning due to its strong quantitative guarantee of privacy. For RTE, we focus on post-hoc explainers: they are the go-to option for model auditing as they operate independently of model training. We formally investigate DP models and various commonly-used post-hoc explainers: how to evaluate these explainers subject to RTP, and analyze the intrinsic interactions between DP models and these explainers. Furthermore, our work throws light on how RTP and RTE can be effectively combined in high-stakes applications. Our study concludes by outlining an industrial software pipeline, with the example of a wildly used use-case, that respects both RTP and RTE requirements.","authors":["Supriya Manna","Niladri Sett"],"url":"https://arxiv.org/abs/2412.20798"}
{"created":"2025-05-23","title":"SGLDBench: A Benchmark Suite for Stress-Guided Lightweight 3D Designs","abstract":"We introduce the Stress-Guided Lightweight Design Benchmark (SGLDBench), a comprehensive benchmark suite for applying and evaluating material layout strategies to generate stiff, lightweight designs in 3D domains. SGLDBench provides a seamlessly integrated simulation and analysis framework, including six reference strategies and a scalable multigrid elasticity solver to efficiently execute these strategies and validate the stiffness of their results. This facilitates the systematic analysis and comparison of design strategies based on the mechanical properties they achieve. SGLDBench enables the evaluation of diverse load conditions and, through the tight integration of the solver, supports high-resolution designs and stiffness analysis. Additionally, SGLDBench emphasizes visual analysis to explore the relationship between the geometric structure of a design and the distribution of stresses, offering insights into the specific properties and behaviors of different design strategies. SGLDBench's specific features are highlighted through several experiments, comparing the results of reference strategies with respect to geometric and mechanical properties.","authors":["Junpeng Wang","Dennis R. Bukenberger","Simon Niedermayr","Christoph Neuhauser","Jun Wu","R\\\"udiger Westermann"],"url":"https://arxiv.org/abs/2501.03068"}
{"created":"2025-05-23","title":"Joint Hierarchical Representation Learning of Samples and Features via Informed Tree-Wasserstein Distance","abstract":"High-dimensional data often exhibit hierarchical structures in both modes: samples and features. Yet, most existing approaches for hierarchical representation learning consider only one mode at a time. In this work, we propose an unsupervised method for jointly learning hierarchical representations of samples and features via Tree-Wasserstein Distance (TWD). Our method alternates between the two data modes. It first constructs a tree for one mode, then computes a TWD for the other mode based on that tree, and finally uses the resulting TWD to build the second mode's tree. By repeatedly alternating through these steps, the method gradually refines both trees and the corresponding TWDs, capturing meaningful hierarchical representations of the data. We provide a theoretical analysis showing that our method converges. We show that our method can be integrated into hyperbolic graph convolutional networks as a pre-processing technique, improving performance in link prediction and node classification tasks. In addition, our method outperforms baselines in sparse approximation and unsupervised Wasserstein distance learning tasks on word-document and single-cell RNA-sequencing datasets.","authors":["Ya-Wei Eileen Lin","Ronald R. Coifman","Gal Mishne","Ronen Talmon"],"url":"https://arxiv.org/abs/2501.03627"}
{"created":"2025-05-23","title":"A New Fick-Jacobs Derivation with Applications to Computational Branched Diffusion Networks","abstract":"The Fick-Jacobs equation is a classical model reduction of 3-dimensional diffusion in a tube of varying radius to a 1-dimensional problem with radially scaled derivatives. This model has been shown to be unstable when the radial gradient is too steep. In this work, we present a new derivation of the Fick-Jacobs equation that results in the addition of higher order spatial derivative terms that provide additional stability in a wide variety of cases and improved solution convergence. We also derive new numerical schemes for branched nodes within networks and provide stability conditions for these schemes. The computational accuracy, efficiency, and stability of our method is demonstrated through a variety of numerical examples.","authors":["Zachary M. Miksis","Gillian Queisser"],"url":"https://arxiv.org/abs/2501.08247"}
{"created":"2025-05-23","title":"GOTPR: General Outdoor Text-based Place Recognition Using Scene Graph Retrieval with OpenStreetMap","abstract":"We propose GOTPR, a robust place recognition method designed for outdoor environments where GPS signals are unavailable. Unlike existing approaches that use point cloud maps, which are large and difficult to store, GOTPR leverages scene graphs generated from text descriptions and maps for place recognition. This method improves scalability by replacing point clouds with compact data structures, allowing robots to efficiently store and utilize extensive map data. In addition, GOTPR eliminates the need for custom map creation by using publicly available OpenStreetMap data, which provides global spatial information. We evaluated its performance using the KITTI360Pose dataset with corresponding OpenStreetMap data, comparing it to existing point cloud-based place recognition methods. The results show that GOTPR achieves comparable accuracy while significantly reducing storage requirements. In city-scale tests, it completed processing within a few seconds, making it highly practical for real-world robotics applications. More information can be found at https://donghwijung.github.io/GOTPR_page/.","authors":["Donghwi Jung","Keonwoo Kim","Seong-Woo Kim"],"url":"https://arxiv.org/abs/2501.08575"}
{"created":"2025-05-23","title":"Small Decision Trees for MDPs with Deductive Synthesis","abstract":"Markov decision processes (MDPs) describe sequential decision-making processes; MDP policies return for every state in that process an advised action. Classical algorithms can efficiently compute policies that are optimal with respect to, e.g., reachability probabilities. However, these policies are then given in a tabular format. A longstanding challenge is to represent optimal or almost-optimal policies concisely, e.g., as decision trees. This paper makes two contributions towards this challenge: first, an SMT-based approach to encode a given (optimal) policy as a small decision tree, and second, an abstraction-refinement loop that searches for policies that are optimal within the set of policies that can be represented with a small tree. Technically, the latter combines the SMT encoding with verification approaches for families of Markov chains. The empirical evaluation demonstrates the feasibility of these approaches and shows how they can outperform the state-of-the-art on various benchmarks, yielding up to 20 times smaller trees representing (almost) optimal policies for models with up to 10k states and 19 variables.","authors":["Roman Andriushchenko","Milan \\v{C}e\\v{s}ka","Sebastian Junges","Filip Mac\\'ak"],"url":"https://arxiv.org/abs/2501.10126"}
{"created":"2025-05-23","title":"Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian","abstract":"Software engineers spend a significant amount of time reading code during the software development process. This trend is amplified by the emergence of large language models (LLMs) that automatically generate code. However, little is known about the readability of the LLM-generated code and whether it is still important from practitioners' perspectives in this new era. In this paper, we conduct a survey to explore the practitioners' perspectives on code readability in the age of LLMs and investigate the readability of our LLM-based software development agents framework, HULA, by comparing its generated code with human-written code in real-world scenarios. Overall, the findings underscore that (1) readability remains a critical aspect of software development; (2) the readability of our LLM-generated code is comparable to human-written code, fostering the establishment of appropriate trust and driving the broad adoption of our LLM-powered software development platform.","authors":["Wannita Takerngsaksiri","Micheal Fu","Chakkrit Tantithamthavorn","Jirat Pasuksmit","Kun Chen","Ming Wu"],"url":"https://arxiv.org/abs/2501.11264"}
{"created":"2025-05-23","title":"Auto-Prompting SAM for Weakly Supervised Landslide Extraction","abstract":"Weakly supervised landslide extraction aims to identify landslide regions from remote sensing data using models trained with weak labels, particularly image-level labels. However, it is often challenged by the imprecise boundaries of the extracted objects due to the lack of pixel-wise supervision and the properties of landslide objects. To tackle these issues, we propose a simple yet effective method by auto-prompting the Segment Anything Model (SAM), i.e., APSAM. Instead of depending on high-quality class activation maps (CAMs) for pseudo-labeling or fine-tuning SAM, our method directly yields fine-grained segmentation masks from SAM inference through prompt engineering. Specifically, it adaptively generates hybrid prompts from the CAMs obtained by an object localization network. To provide sufficient information for SAM prompting, an adaptive prompt generation (APG) algorithm is designed to fully leverage the visual patterns of CAMs, enabling the efficient generation of pseudo-masks for landslide extraction. These informative prompts are able to identify the extent of landslide areas (box prompts) and denote the centers of landslide objects (point prompts), guiding SAM in landslide segmentation. Experimental results on high-resolution aerial and satellite datasets demonstrate the effectiveness of our method, achieving improvements of at least 3.0\\% in F1 score and 3.69\\% in IoU compared to other state-of-the-art methods. The source codes and datasets will be available at https://github.com/zxk688.","authors":["Jian Wang","Xiaokang Zhang","Xianping Ma","Weikang Yu","Pedram Ghamisi"],"url":"https://arxiv.org/abs/2501.13426"}
{"created":"2025-05-23","title":"OCSU: Optical Chemical Structure Understanding for Molecule-centric Scientific Discovery","abstract":"Understanding the chemical structure from a graphical representation of a molecule is a challenging image caption task that would greatly benefit molecule-centric scientific discovery. Variations in molecular images and caption subtasks pose a significant challenge in both image representation learning and task modeling. Yet, existing methods only focus on a specific caption task that translates a molecular image into its graph structure, i.e., OCSR. In this paper, we propose the Optical Chemical Structure Understanding (OCSU) task, which extends low-level recognition to multilevel understanding and aims to translate chemical structure diagrams into readable strings for both machine and chemist. To facilitate the development of OCSU technology, we explore both OCSR-based and OCSR-free paradigms. We propose DoubleCheck to enhance OCSR performance via attentive feature enhancement for local ambiguous atoms. It can be cascaded with existing SMILES-based molecule understanding methods to achieve OCSU. Meanwhile, Mol-VL is a vision-language model end-to-end optimized for OCSU. We also construct Vis-CheBI20, the first large-scale OCSU dataset. Through comprehensive experiments, we demonstrate the proposed approaches excel at providing chemist-readable caption for chemical structure diagrams, which provide solid baselines for further research. Our code, model, and data are open-sourced at https://github.com/PharMolix/OCSU.","authors":["Siqi Fan","Yuguang Xie","Bowen Cai","Ailin Xie","Gaochao Liu","Mu Qiao","Jie Xing","Zaiqing Nie"],"url":"https://arxiv.org/abs/2501.15415"}
{"created":"2025-05-23","title":"Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity","abstract":"Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstone method for parallelizing learning in distributed machine learning. However, its performance suffers under arbitrarily heterogeneous computation times across workers, leading to suboptimal time complexity and inefficiency as the number of workers scales. While several Asynchronous SGD variants have been proposed, recent findings by Tyurin & Richt\\'arik (NeurIPS 2023) reveal that none achieve optimal time complexity, leaving a significant gap in the literature. In this paper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed to address these limitations and tame the inherent challenges of Asynchronous SGD. We establish, through rigorous theoretical analysis, that Ringmaster ASGD achieves optimal time complexity under arbitrarily heterogeneous and dynamically fluctuating worker computation times. This makes it the first Asynchronous SGD method to meet the theoretical lower bounds for time complexity in such scenarios.","authors":["Artavazd Maranjyan","Alexander Tyurin","Peter Richt\\'arik"],"url":"https://arxiv.org/abs/2501.16168"}
{"created":"2025-05-23","title":"Efficient Feature Fusion for UAV Object Detection","abstract":"Object detection in unmanned aerial vehicle (UAV) remote sensing images poses significant challenges due to unstable image quality, small object sizes, complex backgrounds, and environmental occlusions. Small objects, in particular, occupy small portions of images, making their accurate detection highly difficult. Existing multi-scale feature fusion methods address these challenges to some extent by aggregating features across different resolutions. However, they often fail to effectively balance the classification and localization performance for small objects, primarily due to insufficient feature representation and imbalanced network information flow. In this paper, we propose a novel feature fusion framework specifically designed for UAV object detection tasks to enhance both localization accuracy and classification performance. The proposed framework integrates hybrid upsampling and downsampling modules, enabling feature maps from different network depths to be flexibly adjusted to arbitrary resolutions. This design facilitates cross-layer connections and multi-scale feature fusion, ensuring improved representation of small objects. Our approach leverages hybrid downsampling to enhance fine-grained feature representation, improving spatial localization of small targets, even under complex conditions. Simultaneously, the upsampling module aggregates global contextual information, optimizing feature consistency across scales and enhancing classification robustness in cluttered scenes. Experimental results on two public UAV datasets demonstrate the effectiveness of the proposed framework. Integrated into the YOLO-v10 model, our method achieves a 2% improvement in average precision (AP) compared to the baseline YOLO-v10 model, while maintaining the same number of parameters. These results highlight the potential of our framework for accurate and efficient UAV object detection.","authors":["Xudong Wang","Yaxin Peng","Chaomin Shen"],"url":"https://arxiv.org/abs/2501.17983"}
{"created":"2025-05-23","title":"Joint Pricing and Resource Allocation: An Optimal Online-Learning Approach","abstract":"We study an online learning problem on dynamic pricing and resource allocation, where we make joint pricing and inventory decisions to maximize the overall net profit. We consider the stochastic dependence of demands on the price, which complicates the resource allocation process and introduces significant non-convexity and non-smoothness to the problem. To solve this problem, we develop an efficient algorithm that utilizes a \"Lower-Confidence Bound (LCB)\" meta-strategy over multiple OCO agents. Our algorithm achieves $\\tilde{O}(\\sqrt{Tmn})$ regret (for $m$ suppliers and $n$ consumers), which is optimal with respect to the time horizon $T$. Our results illustrate an effective integration of statistical learning methodologies with complex operations research problems.","authors":["Jianyu Xu","Xuan Wang","Yu-Xiang Wang","Jiashuo Jiang"],"url":"https://arxiv.org/abs/2501.18049"}
{"created":"2025-05-23","title":"SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders","abstract":"Diffusion models, while powerful, can inadvertently generate harmful or undesirable content, raising significant ethical and safety concerns. Recent machine unlearning approaches offer potential solutions but often lack transparency, making it difficult to understand the changes they introduce to the base model. In this work, we introduce SAeUron, a novel method leveraging features learned by sparse autoencoders (SAEs) to remove unwanted concepts in text-to-image diffusion models. First, we demonstrate that SAEs, trained in an unsupervised manner on activations from multiple denoising timesteps of the diffusion model, capture sparse and interpretable features corresponding to specific concepts. Building on this, we propose a feature selection method that enables precise interventions on model activations to block targeted content while preserving overall performance. Our evaluation shows that SAeUron outperforms existing approaches on the UnlearnCanvas benchmark for concepts and style unlearning, and effectively eliminates nudity when evaluated with I2P. Moreover, we show that with a single SAE, we can remove multiple concepts simultaneously and that in contrast to other methods, SAeUron mitigates the possibility of generating unwanted content under adversarial attack. Code and checkpoints are available at https://github.com/cywinski/SAeUron.","authors":["Bartosz Cywi\\'nski","Kamil Deja"],"url":"https://arxiv.org/abs/2501.18052"}
{"created":"2025-05-23","title":"Diverse Preference Optimization","abstract":"Post-training of language models, either through reinforcement learning, preference optimization or supervised finetuning, tends to sharpen the output probability distribution and reduce the diversity of generated responses. This is particularly a problem for creative generative tasks where varied responses are desired. In this work we introduce Diverse Preference Optimization (DivPO), an optimization method which learns to generate much more diverse responses than standard pipelines, while maintaining the quality of the generations. In DivPO, preference pairs are selected by first considering a pool of responses, and a measure of diversity among them, and selecting chosen examples as being more rare but high quality, while rejected examples are more common, but low quality. DivPO results in generating 45.6% more diverse persona attributes, and a 74.6% increase in story diversity, while maintaining similar win rates as standard baselines. On general instruction following, DivPO results in a 46.2% increase in diversity, and a 2.4% winrate improvement compared to DPO.","authors":["Jack Lanchantin","Angelica Chen","Shehzaad Dhuliawala","Ping Yu","Jason Weston","Sainbayar Sukhbaatar","Ilia Kulikov"],"url":"https://arxiv.org/abs/2501.18101"}
{"created":"2025-05-23","title":"Strengthening Generative Robot Policies through Predictive World Modeling","abstract":"We present generative predictive control (GPC), a learning control framework that (i) clones a generative diffusion-based policy from expert demonstrations, (ii) trains a predictive action-conditioned world model from both expert demonstrations and random explorations, and (iii) synthesizes an online planner that ranks and optimizes the action proposals from (i) by looking ahead into the future using the world model from (ii). Across a variety of robotic manipulation tasks, we demonstrate that GPC consistently outperforms behavior cloning in both state-based and vision-based settings, in simulation and in the real world.","authors":["Han Qi","Haocheng Yin","Aris Zhu","Yilun Du","Heng Yang"],"url":"https://arxiv.org/abs/2502.00622"}
{"created":"2025-05-23","title":"ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Consensus Enforcement, and Column Exploration","abstract":"We present ReFoRCE, a Text-to-SQL agent that tops the Spider 2.0 leaderboard--a challenging benchmark reflecting complex, real-world Text-to-SQL scenarios. While Text-to-SQL systems enable natural language queries over structured databases, deploying them in enterprise environments remains difficult due to large, complex schemas (with over 1,000 columns), diverse SQL dialects (e.g., BigQuery, Snowflake), and sophisticated query requirements (e.g., transformations and analytics). ReFoRCE addresses these challenges through: (a) database information compression via pattern-based table grouping and LLM-guided schema linking to alleviate long-context issues; (b) self-refinement to iteratively correct syntax and semantic errors across dialects; (c) majority-vote consensus to select high-confidence candidates while deferring ambiguous cases arising from sophisticated queries; and (d) iterative column exploration guided by execution feedback to resolve those deferred cases. ReFoRCE achieves new state-of-the-art results, with scores of 35.83 on Spider 2.0-Snow and 36.56 on Spider 2.0-Lite.","authors":["Minghang Deng","Ashwin Ramachandran","Canwen Xu","Lanxiang Hu","Zhewei Yao","Anupam Datta","Hao Zhang"],"url":"https://arxiv.org/abs/2502.00675"}
{"created":"2025-05-23","title":"To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization","abstract":"Recent advances in mathematical problem-solving with language models (LMs) integrate chain-of-thought (CoT) reasoning and code execution to harness their complementary strengths. However, existing hybrid frameworks exhibit a critical limitation: they depend on externally dictated instructions or rigid code-integration templates, lacking metacognitive awareness -- the capacity to dynamically evaluate intrinsic capabilities and autonomously determine when and how to integrate tools. This rigidity motivates our study of autonomous code integration, enabling models to adapt tool-usage strategies as their reasoning abilities evolve during training.","authors":["Haozhe Wang","Long Li","Chao Qu","Fengming Zhu","Weidi Xu","Wei Chu","Fangzhen Lin"],"url":"https://arxiv.org/abs/2502.00691"}
{"created":"2025-05-23","title":"FIRE: Flexible Integration of Data Quality Ratings for Effective Pre-Training","abstract":"Selecting high-quality data can improve the pretraining efficiency of large language models (LLMs). Existing methods generally rely on heuristic techniques or single quality signals, limiting their ability to evaluate data quality comprehensively. In this work, we propose FIRE, a flexible and scalable framework for integrating multiple data quality raters, which allows for a comprehensive assessment of data quality across various dimensions. FIRE aligns multiple quality signals into a unified space, and integrates diverse data quality raters to provide a comprehensive quality signal for each data point. Further, we introduce a progressive data selection scheme based on FIRE that iteratively refines the selection of high-quality data points. Extensive experiments show that FIRE outperforms other data selection methods and significantly boosts pretrained model performance across a wide range of downstream tasks, while requiring less than 37.5\\% of the training data needed by the Random baseline to reach the target performance.","authors":["Liangyu Xu","Xuemiao Zhang","Feiyu Duan","Sirui Wang","Rongxiang Weng","Jingang Wang","Xunliang Cai"],"url":"https://arxiv.org/abs/2502.00761"}
{"created":"2025-05-23","title":"ATA: Adaptive Task Allocation for Efficient Resource Management in Distributed Machine Learning","abstract":"Asynchronous methods are fundamental for parallelizing computations in distributed machine learning. They aim to accelerate training by fully utilizing all available resources. However, their greedy approach can lead to inefficiencies using more computation than required, especially when computation times vary across devices. If the computation times were known in advance, training could be fast and resource-efficient by assigning more tasks to faster workers. The challenge lies in achieving this optimal allocation without prior knowledge of the computation time distributions. In this paper, we propose ATA (Adaptive Task Allocation), a method that adapts to heterogeneous and random distributions of worker computation times. Through rigorous theoretical analysis, we show that ATA identifies the optimal task allocation and performs comparably to methods with prior knowledge of computation times. Experimental results further demonstrate that ATA is resource-efficient, significantly reducing costs compared to the greedy approach, which can be arbitrarily expensive depending on the number of workers.","authors":["Artavazd Maranjyan","El Mehdi Saad","Peter Richt\\'arik","Francesco Orabona"],"url":"https://arxiv.org/abs/2502.00775"}
{"created":"2025-05-23","title":"Efficient and Scalable Density Functional Theory Hamiltonian Prediction through Adaptive Sparsity","abstract":"Hamiltonian matrix prediction is pivotal in computational chemistry, serving as the foundation for determining a wide range of molecular properties. While SE(3) equivariant graph neural networks have achieved remarkable success in this domain, their substantial computational cost--driven by high-order tensor product (TP) operations--restricts their scalability to large molecular systems with extensive basis sets. To address this challenge, we introduce SPHNet, an efficient and scalable equivariant network, that incorporates adaptive SParsity into Hamiltonian prediction. SPHNet employs two innovative sparse gates to selectively constrain non-critical interaction combinations, significantly reducing tensor product computations while maintaining accuracy. To optimize the sparse representation, we develop a Three-phase Sparsity Scheduler, ensuring stable convergence and achieving high performance at sparsity rates of up to 70%. Extensive evaluations on QH9 and PubchemQH datasets demonstrate that SPHNet achieves state-of-the-art accuracy while providing up to a 7x speedup over existing models. Beyond Hamiltonian prediction, the proposed sparsification techniques also hold significant potential for improving the efficiency and scalability of other SE(3) equivariant networks, further broadening their applicability and impact. Our code can be found at https://github.com/microsoft/SPHNet.","authors":["Erpai Luo","Xinran Wei","Lin Huang","Yunyang Li","Han Yang","Zaishuo Xia","Zun Wang","Chang Liu","Bin Shao","Jia Zhang"],"url":"https://arxiv.org/abs/2502.01171"}
{"created":"2025-05-23","title":"Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents","abstract":"Pre-training vision-language representations on human action videos has emerged as a promising approach to reduce reliance on large-scale expert demonstrations for training embodied agents. However, prior methods often employ time contrastive learning based on goal-reaching heuristics, progressively aligning language instructions from the initial to the final frame. This overemphasis on future frames can result in erroneous vision-language associations, as actions may terminate early or include irrelevant moments in the end. To address this issue, we propose Action Temporal Coherence Learning (AcTOL) to learn ordered and continuous vision-language representations without rigid goal-based constraint. AcTOL treats a video as a continuous trajectory where it (1) contrasts semantic differences between frames to reflect their natural ordering, and (2) imposes a local Brownian bridge constraint to ensure smooth transitions across intermediate frames. Extensive imitation learning experiments on both simulated and real robots show that the pretrained features significantly enhance downstream manipulation tasks with high robustness to different linguistic styles of instructions, offering a viable pathway toward generalized embodied agents.","authors":["Zhizhen Zhang","Lei Zhu","Zhen Fang","Zi Huang","Yadan Luo"],"url":"https://arxiv.org/abs/2502.01218"}
{"created":"2025-05-23","title":"Firewalls to Secure Dynamic LLM Agentic Networks","abstract":"LLM agents will likely communicate on behalf of users with other entity-representing agents on tasks involving long-horizon plans with interdependent goals. Current work neglects these agentic networks and their challenges. We identify required properties for agent communication: proactivity, adaptability, privacy (sharing only task-necessary information), and security (preserving integrity and utility against selfish entities). After demonstrating communication vulnerabilities, we propose a practical design and protocol inspired by network security principles. Our framework automatically derives task-specific rules from prior conversations to build firewalls. These firewalls construct a closed language that is completely controlled by the developer. They transform any personal data to the allowed degree of permissibility entailed by the task. Both operations are completely quarantined from external attackers, disabling the potential for prompt injections, jailbreaks, or manipulation. By incorporating rules learned from their previous mistakes, agents rewrite their instructions and self-correct during communication. Evaluations on diverse attacks demonstrate our framework significantly reduces privacy and security vulnerabilities while allowing adaptability.","authors":["Sahar Abdelnabi","Amr Gomaa","Eugene Bagdasarian","Per Ola Kristensson","Reza Shokri"],"url":"https://arxiv.org/abs/2502.01822"}
{"created":"2025-05-23","title":"Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data","abstract":"Fine-tuning large language models (LLMs) using diverse datasets is crucial for enhancing their overall performance across various domains. In practical scenarios, existing methods based on modeling the mixture proportions of data composition often struggle with data whose domain labels are missing, imprecise or non-normalized, while methods based on data selection usually encounter difficulties in balancing multi-domain performance. To address these challenges, in this work, we investigate the role of data diversity in enhancing the overall abilities of LLMs by empirically constructing contrastive data pools and theoretically deriving explanations. Building upon the insights gained, we propose a new method that gives the LLM a dual identity: an output model to cognitively probe and select data based on diversity reward, as well as an input model to be tuned with the selected data. Extensive experiments show that the proposed method notably boosts performance across domain-undetermined data and a series of foundational downstream tasks when applied to various advanced LLMs. We release our code and hope this study can shed light on the understanding of data diversity and advance feedback-driven data-model co-design for LLMs.","authors":["Zhenqing Ling","Daoyuan Chen","Liuyi Yao","Qianli Shen","Yaliang Li","Ying Shen"],"url":"https://arxiv.org/abs/2502.04380"}
{"created":"2025-05-23","title":"Infinite State Model Checking by Learning Transitive Relations","abstract":"We propose a new approach for proving safety of infinite state systems. It extends the analyzed system by transitive relations until its diameter D becomes finite, i.e., until constantly many steps suffice to cover all reachable states, irrespective of the initial state. Then we can prove safety by checking that no error state is reachable in D steps. To deduce transitive relations, we use recurrence analysis. While recurrence analyses can usually find conjunctive relations only, our approach also discovers disjunctive relations by combining recurrence analysis with projections. An empirical evaluation of the implementation of our approach in our tool LoAT shows that it is highly competitive with the state of the art.","authors":["Florian Frohn","J\\\"urgen Giesl"],"url":"https://arxiv.org/abs/2502.04761"}
{"created":"2025-05-23","title":"Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension","abstract":"Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a strong (large) student model is trained on pseudo-labels generated by a weak teacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to understand this phenomenon through the observation that FT often occurs in intrinsically low-dimensional spaces. Leveraging the low intrinsic dimensionality of FT, we analyze W2S in the ridgeless regression setting from a variance reduction perspective. For a strong student-weak teacher pair with sufficiently expressive low-dimensional feature subspaces $\\mathcal{V}_s, \\mathcal{V}_w$, we provide an exact characterization of the variance that dominates the generalization error of W2S. This unveils a virtue of discrepancy between the strong and weak models in W2S: the variance of the weak teacher is inherited by the strong student in $\\mathcal{V}_s \\cap \\mathcal{V}_w$, while reduced by a factor of $\\dim(\\mathcal{V}_s)/N$ in the subspace of discrepancy $\\mathcal{V}_w \\setminus \\mathcal{V}_s$ with $N$ pseudo-labels for W2S. Our analysis further casts light on the sample complexities and the scaling of performance gap recovery in W2S. The analysis is supported by experiments on synthetic regression problems, as well as real vision and NLP tasks.","authors":["Yijun Dong","Yicheng Li","Yunai Li","Jason D. Lee","Qi Lei"],"url":"https://arxiv.org/abs/2502.05075"}
{"created":"2025-05-23","title":"Position: We Need An Adaptive Interpretation of Helpful, Honest, and Harmless Principles","abstract":"The Helpful, Honest, and Harmless (HHH) principle is a foundational framework for aligning AI systems with human values. However, existing interpretations of the HHH principle often overlook contextual variability and conflicting requirements across applications. In this paper, we argue for an adaptive interpretation of the HHH principle and propose a reference framework for its adaptation to diverse scenarios. We first examine the principle's foundational significance and identify ambiguities and conflicts through case studies of its dimensions. To address these challenges, we introduce the concept of priority order, which provides a structured approach for balancing trade-offs among helpfulness, honesty, and harmlessness. Further, we explore the interrelationships between these dimensions, demonstrating how harmlessness and helpfulness can be jointly enhanced and analyzing their interdependencies in high-risk evaluations. Building on these insights, we propose a reference framework that integrates context definition, value prioritization, risk assessment, and benchmarking standards to guide the adaptive application of the HHH principle. This work offers practical insights for improving AI alignment, ensuring that HHH principles remain both ethically grounded and operationally effective in real-world AI deployment.","authors":["Yue Huang","Chujie Gao","Yujun Zhou","Kehan Guo","Xiangqi Wang","Or Cohen-Sasson","Max Lamparth","Dawn Song","Xiangliang Zhang"],"url":"https://arxiv.org/abs/2502.06059"}
{"created":"2025-05-23","title":"Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type","abstract":"Conceptual combination is a cognitive process that merges basic concepts, enabling the creation of complex expressions. During this process, the properties of combination (e.g., the whiteness of a peeled apple) can be inherited from basic concepts, newly emerge, or be canceled. However, previous studies have evaluated a limited set of properties and have not examined the generative process. To address this gap, we introduce the Conceptual Combination with Property Type dataset (CCPT), which consists of 12.3K annotated triplets of noun phrases, properties, and property types. Using CCPT, we establish three types of tasks to evaluate LLMs for conceptual combination thoroughly. Our key findings are threefold: (1) Our automatic metric grading property emergence and cancellation closely corresponds with human judgments. (2) LLMs, including OpenAI's o1, struggle to generate noun phrases which possess given emergent properties. (3) Our proposed method, inspired by cognitive psychology model that explains how relationships between concepts are formed, improves performances in all generative tasks. The dataset and experimental code are available at https://github.com/seokwon99/CCPT.git.","authors":["Seokwon Song","Taehyun Lee","Jaewoo Ahn","Jae Hyuk Sung","Gunhee Kim"],"url":"https://arxiv.org/abs/2502.06086"}
{"created":"2025-05-23","title":"LCIRC: A Recurrent Compression Approach for Efficient Long-form Context and Query Dependent Modeling in LLMs","abstract":"While large language models (LLMs) excel in generating coherent and contextually rich outputs, their capacity to efficiently handle long-form contexts is limited by fixed-length position embeddings. Additionally, the computational cost of processing long sequences increases quadratically, making it challenging to extend context length. To address these challenges, we propose Long-form Context Injection with Recurrent Compression (LCIRC), a method that enables the efficient processing long-form sequences beyond the model's length limit through recurrent compression without retraining the entire model. We further introduce query dependent context modeling, which selectively compresses query-relevant information, ensuring that the model retains the most pertinent content. Our empirical results demonstrate that Query Dependent LCIRC (QD-LCIRC) significantly improves LLM's ability to manage extended contexts, making it well-suited for tasks that require both comprehensive context understanding and query relevance.","authors":["Sumin An","Junyoung Sung","Wonpyo Park","Chanjun Park","Paul Hongsuck Seo"],"url":"https://arxiv.org/abs/2502.06139"}
{"created":"2025-05-23","title":"C-3PO: Compact Plug-and-Play Proxy Optimization to Achieve Human-like Retrieval-Augmented Generation","abstract":"Retrieval-augmented generation (RAG) systems face a fundamental challenge in aligning independently developed retrievers and large language models (LLMs). Existing approaches typically involve modifying either component or introducing simple intermediate modules, resulting in practical limitations and sub-optimal performance. Inspired by human search behavior -- typically involving a back-and-forth process of proposing search queries and reviewing documents, we propose C-3PO, a proxy-centric framework that facilitates communication between retrievers and LLMs through a lightweight multi-agent system. Our framework implements three specialized agents that collaboratively optimize the entire RAG pipeline without altering the retriever and LLMs. These agents work together to assess the need for retrieval, generate effective queries, and select information suitable for the LLMs. To enable effective multi-agent coordination, we develop a tree-structured rollout approach for reward credit assignment in reinforcement learning. Extensive experiments in both in-domain and out-of-distribution scenarios demonstrate that C-3PO significantly enhances RAG performance while maintaining plug-and-play flexibility and superior generalization capabilities.","authors":["Guoxin Chen","Minpeng Liao","Peiying Yu","Dingmin Wang","Zile Qiao","Chao Yang","Xin Zhao","Kai Fan"],"url":"https://arxiv.org/abs/2502.06205"}
{"created":"2025-05-23","title":"Network Intrusion Datasets: A Survey, Limitations, and Recommendations","abstract":"Data-driven cyberthreat detection has become a crucial defense technique in modern cybersecurity. Network defense, supported by Network Intrusion Detection Systems (NIDSs), has also increasingly adopted data-driven approaches, leading to greater reliance on data. Despite the importance of data, its scarcity has long been recognized as a major obstacle in NIDS research. In response, the community has published many new datasets recently. However, many of them remain largely unknown and unanalyzed, leaving researchers uncertain about their suitability for specific use cases.","authors":["Patrik Goldschmidt","Daniela Chud\\'a"],"url":"https://arxiv.org/abs/2502.06688"}
{"created":"2025-05-23","title":"InSTA: Towards Internet-Scale Training For Agents","abstract":"The predominant approach for training web navigation agents is to gather human demonstrations for a set of popular websites and hand-written tasks, but it is becoming clear that human data is an inefficient resource. We develop a pipeline to facilitate internet-scale training for agents without laborious human annotations. In the first stage, an LLM annotates 150k sites with agentic tasks. In the next stage, LLM agents complete tasks and produce trajectories. In the final stage, an LLM filters trajectories by judging their success. Language models are powerful data curation tools, identifying harmful content with an accuracy of 97%, judging successful trajectories with an accuracy of 82.6%, and producing effective data. We train agents based on Qwen 3 1.7B that are competitive with frontier LLMs as web agents, while being smaller and faster. Our top agent reaches a success rate of 56.9%, outperforming the data collection policy Qwen 3 235B, a 235 times larger Llama 4 Maverick, and reaching 94.7% of the performance of Gemini 2.5 Flash. We are releasing code, models and data at: https://data-for-agents.github.io.","authors":["Brandon Trabucco","Gunnar Sigurdsson","Robinson Piramuthu","Ruslan Salakhutdinov"],"url":"https://arxiv.org/abs/2502.06776"}
{"created":"2025-05-23","title":"Prot2Chat: Protein LLM with Early-Fusion of Text, Sequence and Structure","abstract":"Motivation: Proteins are of great significance in living organisms. However, understanding their functions encounters numerous challenges, such as insufficient integration of multimodal information, a large number of training parameters, limited flexibility of classification-based methods, and the lack of systematic evaluation metrics for protein Q&amp;A systems. To tackle these issues, we propose the Prot2Chat framework. Results: We modified ProteinMPNN to encode protein sequence and structural information in a unified way. We used a large language model (LLM) to encode questions into vectors and developed a protein-text adapter to compress protein information into virtual tokens based on these vectors, achieving the early fusion of text and protein information. Finally, the same LLM reads the virtual tokens and the questions to generate answers. To optimize training efficiency, we froze the encoder and employed Low-Rank Adaptation (LoRA) techniques for the LLM. Experiments on two datasets show that both automated metrics and expert evaluations demonstrate the superior performance of our model, and zero-shot prediction results highlight its generalization ability. The models and codes are available at https://github.com/ wangzc1233/Prot2Chat. Contact: zqcao@suda.edu.cn or wangzc025@163.com Key words: Protein Q&amp;A, Early-Fusion, LLM","authors":["Zhicong Wang","Zicheng Ma","Ziqiang Cao","Changlong Zhou","Jun Zhang","Yiqin Gao"],"url":"https://arxiv.org/abs/2502.06846"}
{"created":"2025-05-23","title":"Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion","abstract":"Recent diffusion-based talking face generation models have demonstrated impressive potential in synthesizing videos that accurately match a speech audio clip with a given reference identity. However, existing approaches still encounter significant challenges due to uncontrollable factors, such as inaccurate lip-sync, inappropriate head posture and the lack of fine-grained control over facial expressions. In order to introduce more face-guided conditions beyond speech audio clips, a novel two-stage training framework Playmate is proposed to generate more lifelike facial expressions and talking faces. In the first stage, we introduce a decoupled implicit 3D representation along with a meticulously designed motion-decoupled module to facilitate more accurate attribute disentanglement and generate expressive talking videos directly from audio cues. Then, in the second stage, we introduce an emotion-control module to encode emotion control information into the latent space, enabling fine-grained control over emotions and thereby achieving the ability to generate talking videos with desired emotion. Extensive experiments demonstrate that Playmate not only outperforms existing state-of-the-art methods in terms of video quality, but also exhibits strong competitiveness in lip synchronization while offering improved flexibility in controlling emotion and head pose. The code will be available at https://github.com/Playmate111/Playmate.","authors":["Xingpei Ma","Jiaran Cai","Yuansheng Guan","Shenneng Huang","Qiang Zhang","Shunsi Zhang"],"url":"https://arxiv.org/abs/2502.07203"}
{"created":"2025-05-23","title":"Beyond Benign Overfitting in Nadaraya-Watson Interpolators","abstract":"In recent years, there has been much interest in understanding the generalization behavior of interpolating predictors, which overfit on noisy training data. Whereas standard analyses are concerned with whether a method is consistent or not, recent observations have shown that even inconsistent predictors can generalize well. In this work, we revisit the classic interpolating Nadaraya-Watson (NW) estimator (also known as Shepard's method), and study its generalization capabilities through this modern viewpoint. In particular, by varying a single bandwidth-like hyperparameter, we prove the existence of multiple overfitting behaviors, ranging non-monotonically from catastrophic, through benign, to tempered. Our results highlight how even classical interpolating methods can exhibit intricate generalization behaviors. In addition, for the purpose of tuning the hyperparameter, the results suggest that over-estimating the intrinsic dimension of the data is less harmful than under-estimating it. Numerical experiments complement our theory, demonstrating the same phenomena.","authors":["Daniel Barzilai","Guy Kornowski","Ohad Shamir"],"url":"https://arxiv.org/abs/2502.07480"}
{"created":"2025-05-23","title":"Scaling Off-Policy Reinforcement Learning with Batch and Weight Normalization","abstract":"Reinforcement learning has achieved significant milestones, but sample efficiency remains a bottleneck for real-world applications. Recently, CrossQ has demonstrated state-of-the-art sample efficiency with a low update-to-data (UTD) ratio of 1. In this work, we explore CrossQ's scaling behavior with higher UTD ratios. We identify challenges in the training dynamics, which are emphasized by higher UTD ratios. To address these, we integrate weight normalization into the CrossQ framework, a solution that stabilizes training, has been shown to prevent potential loss of plasticity and keeps the effective learning rate constant. Our proposed approach reliably scales with increasing UTD ratios, achieving competitive performance across 25 challenging continuous control tasks on the DeepMind Control Suite and Myosuite benchmarks, notably the complex dog and humanoid environments. This work eliminates the need for drastic interventions, such as network resets, and offers a simple yet robust pathway for improving sample efficiency and scalability in model-free reinforcement learning.","authors":["Daniel Palenicek","Florian Vogt","Joe Watson","Jan Peters"],"url":"https://arxiv.org/abs/2502.07523"}
{"created":"2025-05-23","title":"Classifier-Free Guidance: From High-Dimensional Analysis to Generalized Guidance Forms","abstract":"Classifier-Free Guidance (CFG) is a widely adopted technique in diffusion and flow-based generative models, enabling high-quality conditional generation. A key theoretical challenge is characterizing the distribution induced by CFG, particularly in high-dimensional settings relevant to real-world data. Previous works have shown that CFG modifies the target distribution, steering it towards a distribution sharper than the target one, more shifted towards the boundary of the class. In this work, we provide a high-dimensional analysis of CFG, showing that these distortions vanish as the data dimension grows. We present a blessing-of-dimensionality result demonstrating that in sufficiently high and infinite dimensions, CFG accurately reproduces the target distribution. Using our high-dimensional theory, we show that there is a large family of guidances enjoying this property, in particular non-linear CFG generalizations. We study a simple non-linear power-law version, for which we demonstrate improved robustness, sample fidelity and diversity. Our findings are validated with experiments on class-conditional and text-to-image generation using state-of-the-art diffusion and flow-matching models.","authors":["Krunoslav Lehman Pavasovic","Jakob Verbeek","Giulio Biroli","Marc Mezard"],"url":"https://arxiv.org/abs/2502.07849"}
{"created":"2025-05-23","title":"What is a Sketch-and-Precondition Derivation for Low-Rank Approximation? Inverse Power Error or Inverse Power Estimation?","abstract":"Randomized sketching accelerates large-scale numerical linear algebra by reducing computational complexity. While the traditional sketch-and-solve approach reduces the problem size directly through sketching, the sketch-and-precondition method leverages sketching to construct a computational friendly preconditioner. This preconditioner improves the convergence speed of iterative solvers applied to the original problem, maintaining accuracy in the full space. Furthermore, the convergence rate of the solver improves at least linearly with the sketch size. Despite its potential, developing a sketch-and-precondition framework for randomized algorithms in low-rank matrix approximation remains an open challenge. We introduce the Error-Powered Sketched Inverse Iteration (EPSI) Method via run sketched Newton iteration for the Lagrange form as a sketch-and-precondition variant for randomized low-rank approximation. Our method achieves theoretical guarantees, including a convergence rate that improves at least linearly with the sketch size.","authors":["Ruihan Xu","Yiping Lu"],"url":"https://arxiv.org/abs/2502.07993"}
{"created":"2025-05-23","title":"No Need for Explanations: LLMs can implicitly learn from mistakes in-context","abstract":"Showing incorrect answers to Large Language Models (LLMs) is a popular strategy to improve their performance in reasoning-intensive tasks. It is widely assumed that, in order to be helpful, the incorrect answers must be accompanied by comprehensive rationales, explicitly detailing where the mistakes are and how to correct them. However, in this work we present a counterintuitive finding: we observe that LLMs perform better in math reasoning tasks when these rationales are eliminated from the context and models are left to infer on their own what makes an incorrect answer flawed. This approach also substantially outperforms chain-of-thought prompting in our evaluations. These results are consistent across LLMs of different sizes and varying reasoning abilities. To gain an understanding of why LLMs learn from mistakes more effectively without explicit corrective rationales, we perform a thorough analysis, investigating changes in context length and answer diversity between different prompting strategies, and their effect on performance. We also examine evidence of overfitting to the in-context rationales when these are provided, and study the extent to which LLMs are able to autonomously infer high-quality corrective rationales given only incorrect answers as input. We find evidence that, while incorrect answers are more beneficial for LLM learning than additional diverse correct answers, explicit corrective rationales over-constrain the model, thus limiting those benefits.","authors":["Lisa Alazraki","Maximilian Mozes","Jon Ander Campos","Tan Yi-Chern","Marek Rei","Max Bartolo"],"url":"https://arxiv.org/abs/2502.08550"}
{"created":"2025-05-23","title":"Compositional Taylor expansion in cartesian differential categories","abstract":"This paper provides a compositional approach to Taylor expansion, in the setting of cartesian differential categories. Taylor expansion is captured here by a functor that generalizes the tangent bundle functor to higher order derivatives. The fundamental properties of Taylor expansion then boils down to naturality equations that turns this functor into a monad. This monad provides a categorical approach to higher order dual numbers and the jet bundle construction used in automated differentiation.","authors":["Aymeric Walch (IRIF)"],"url":"https://arxiv.org/abs/2502.09066"}
{"created":"2025-05-23","title":"SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models","abstract":"We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses. Instead of only relying on costly and labor-intensive annotations, SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response. This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations. The effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks. The source code is available at https://github.com/facebookresearch/SelfCite","authors":["Yung-Sung Chuang","Benjamin Cohen-Wang","Shannon Zejiang Shen","Zhaofeng Wu","Hu Xu","Xi Victoria Lin","James Glass","Shang-Wen Li","Wen-tau Yih"],"url":"https://arxiv.org/abs/2502.09604"}
{"created":"2025-05-23","title":"The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Analysis of Orthogonal Safety Directions","abstract":"Large Language Models' safety-aligned behaviors, such as refusing harmful queries, can be represented by linear directions in activation space. Previous research modeled safety behavior with a single direction, limiting mechanistic understanding to an isolated safety feature. In this work, we discover that safety-aligned behavior is jointly controlled by multi-dimensional directions. Namely, we study the vector space of representation shifts during safety fine-tuning on Llama 3 8B for refusing jailbreaks. By studying orthogonal directions in the space, we first find that a dominant direction governs the model's refusal behavior, while multiple smaller directions represent distinct and interpretable features like hypothetical narrative and role-playing. We then measure how different directions promote or suppress the dominant direction, showing the important role of secondary directions in shaping the model's refusal representation. Finally, we demonstrate that removing certain trigger tokens in harmful queries can mitigate these directions to bypass the learned safety capability, providing new insights on understanding safety alignment vulnerability from a multi-dimensional perspective. Code and artifacts are available at https://github.com/BMPixel/safety-residual-space.","authors":["Wenbo Pan","Zhichao Liu","Qiguang Chen","Xiangyang Zhou","Haining Yu","Xiaohua Jia"],"url":"https://arxiv.org/abs/2502.09674"}
{"created":"2025-05-23","title":"Knowledge Integration Strategies in Autonomous Vehicle Prediction and Planning: A Comprehensive Survey","abstract":"This comprehensive survey examines the integration of knowledge-based approaches in autonomous driving systems, specifically focusing on trajectory prediction and planning. We extensively analyze various methodologies for incorporating domain knowledge, traffic rules, and commonsense reasoning into autonomous driving systems. The survey categorizes and analyzes approaches based on their knowledge representation and integration methods, ranging from purely symbolic to hybrid neuro-symbolic architectures. We examine recent developments in logic programming, foundation models for knowledge representation, reinforcement learning frameworks, and other emerging technologies incorporating domain knowledge. This work systematically reviews recent approaches, identifying key challenges, opportunities, and future research directions in knowledge-enhanced autonomous driving systems. Our analysis reveals emerging trends in the field, including the increasing importance of interpretable AI, the role of formal verification in safety-critical systems, and the potential of hybrid approaches that combine traditional knowledge representation with modern machine learning techniques.","authors":["Kumar Manas","Adrian Paschke"],"url":"https://arxiv.org/abs/2502.10477"}
{"created":"2025-05-23","title":"GRIFFIN: Effective Token Alignment for Faster Speculative Decoding","abstract":"Speculative decoding accelerates inference in large language models (LLMs) by generating multiple draft tokens simultaneously. However, existing methods often struggle with token misalignment between the training and decoding phases, limiting their performance. To address this, we propose GRIFFIN, a novel framework that incorporates a token-alignable training strategy and a token-alignable draft model to mitigate misalignment. The training strategy employs a loss masking mechanism to exclude highly misaligned tokens during training, preventing them from negatively impacting the draft model's optimization. The token-alignable draft model introduces input tokens to correct inconsistencies in generated features. Experiments on LLaMA, Vicuna, Qwen and Mixtral models demonstrate that GRIFFIN achieves an average acceptance length improvement of over 8% and a speedup ratio exceeding 7%, outperforming current speculative decoding state-of-the-art methods. Our code and GRIFFIN's draft models are released publicly in https://github.com/hsj576/GRIFFIN.","authors":["Shijing Hu","Jingyang Li","Xingyu Xie","Zhihui Lu","Kim-Chuan Toh","Pan Zhou"],"url":"https://arxiv.org/abs/2502.11018"}
{"created":"2025-05-23","title":"SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL","abstract":"Text-to-SQL aims to convert natural language questions into executable SQL queries. While previous approaches, such as skeleton-masked selection, have demonstrated strong performance by retrieving similar training examples to guide large language models (LLMs), they struggle in real-world scenarios where such examples are unavailable. To overcome this limitation, we propose Self-Augmentation in-context learning with Fine-grained Example selection for Text-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by generating and filtering self-augmented examples. SAFE-SQL first prompts an LLM to generate multiple Text-to-SQL examples relevant to the test input. Then SAFE-SQL filters these examples through three relevance assessments, constructing high-quality in-context learning examples. Using self-generated examples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL frameworks, achieving higher execution accuracy. Notably, our approach provides additional performance gains in extra hard and unseen scenarios, where conventional methods often fail.","authors":["Jimin Lee","Ingeol Baek","Byeongjeong Kim","Hyunkyung Bae","Hwanhee Lee"],"url":"https://arxiv.org/abs/2502.11438"}
{"created":"2025-05-23","title":"FineFilter: A Fine-grained Noise Filtering Mechanism for Retrieval-Augmented Large Language Models","abstract":"Retrieved documents containing noise will hinder Retrieval-Augmented Generation (RAG) from detecting answer clues, necessitating noise filtering mechanisms to enhance accuracy. Existing methods use reranking or summarization to identify the most relevant sentences, but directly and accurately locating answer clues from these large-scale and complex documents remains challenging. Unlike these document-level operations, we treat noise filtering as a sentence-level MinMax optimization problem: first identifying potential clues from multiple documents, then ranking them by relevance, and finally retaining the minimum number of clues through truncation. In this paper, we propose FineFilter, a novel fine-grained noise filtering mechanism for RAG, consisting of a clue extractor, a reranker, and a truncator. We optimize each module to tackle complex reasoning challenges: (1) The clue extractor first uses sentences containing the answer and similar ones as fine-tuning targets, aiming to extract sufficient potential clues; (2) The reranker is trained to prioritize effective clues based on the real feedback from the generation module, with clues capable of generating correct answers as positive samples and others as negative; (3) The truncator takes the minimum number of clues needed to answer the question (truncation point) as fine-tuning targets, and performs truncation on the reranked clues to achieve fine-grained noise filtering. Experiments on three QA datasets demonstrate that FineFilter significantly improves QA performance over baselines on both LLaMA3 and Mistral. Further analysis confirms its effectiveness in complex reasoning, robustness to unreliable retrieval, and generalization to different scenarios.","authors":["Qianchi Zhang","Hainan Zhang","Liang Pang","Ziwei Wang","Hongwei Zheng","Yongxin Tong","Zhiming Zheng"],"url":"https://arxiv.org/abs/2502.11811"}
{"created":"2025-05-23","title":"M-ABSA: A Multilingual Dataset for Aspect-Based Sentiment Analysis","abstract":"Aspect-based sentiment analysis (ABSA) is a crucial task in information extraction and sentiment analysis, aiming to identify aspects with associated sentiment elements in text. However, existing ABSA datasets are predominantly English-centric, limiting the scope for multilingual evaluation and research. To bridge this gap, we present M-ABSA, a comprehensive dataset spanning 7 domains and 21 languages, making it the most extensive multilingual parallel dataset for ABSA to date. Our primary focus is on triplet extraction, which involves identifying aspect terms, aspect categories, and sentiment polarities. The dataset is constructed through an automatic translation process with human review to ensure quality. We perform extensive experiments using various baselines to assess performance and compatibility on M-ABSA. Our empirical findings highlight that the dataset enables diverse evaluation tasks, such as multilingual and multi-domain transfer learning, and large language model evaluation, underscoring its inclusivity and its potential to drive advancements in multilingual ABSA research.","authors":["Chengyan Wu","Bolei Ma","Yihong Liu","Zheyu Zhang","Ningyuan Deng","Yanshu Li","Baolan Chen","Yi Zhang","Yun Xue","Barbara Plank"],"url":"https://arxiv.org/abs/2502.11824"}
{"created":"2025-05-23","title":"Infinitary Refinement Types for Temporal Properties in Scott Domains","abstract":"We discuss an infinitary refinement type system for input-output temporal specifications of functions that handle infinite objects like streams or infinite trees. Our system is based on a reformulation of Bonsangue and Kok's infinitary extension of Abramsky's Domain Theory in Logical Form to saturated properties. We show that in an interesting range of cases, our system is complete without the need of an infinitary rule introduced by Bonsangue and Kok to reflect the well-filteredness of Scott domains.","authors":["Colin Riba","Alexandre Kejikian"],"url":"https://arxiv.org/abs/2502.11917"}
{"created":"2025-05-23","title":"Robust 6DoF Pose Tracking Considering Contour and Interior Correspondence Uncertainty for AR Assembly Guidance","abstract":"Augmented reality assembly guidance is essential for intelligent manufacturing and medical applications, requiring continuous measurement of the 6DoF poses of manipulated objects. Although current tracking methods have made significant advancements in accuracy and efficiency, they still face challenges in robustness when dealing with cluttered backgrounds, rotationally symmetric objects, and noisy sequences. In this paper, we first propose a robust contour-based pose tracking method that addresses error-prone contour correspondences and improves noise tolerance. It utilizes a fan-shaped search strategy to refine correspondences and models local contour shape and noise uncertainty as mixed probability distribution, resulting in a highly robust contour energy function. Secondly, we introduce a CPU-only strategy to better track rotationally symmetric objects and assist the contour-based method in overcoming local minima by exploring sparse interior correspondences. This is achieved by pre-sampling interior points from sparse viewpoint templates offline and using the DIS optical flow algorithm to compute their correspondences during tracking. Finally, we formulate a unified energy function to fuse contour and interior information, which is solvable using a re-weighted least squares algorithm. Experiments on public datasets and real scenarios demonstrate that our method significantly outperforms state-of-the-art monocular tracking methods and can achieve more than 100 FPS using only a CPU.","authors":["Jixiang Chen","Jing Chen","Kai Liu","Haochen Chang","Shanfeng Fu","Jian Yang"],"url":"https://arxiv.org/abs/2502.11971"}
{"created":"2025-05-23","title":"Blank Space: Adaptive Causal Coding for Streaming Communications Over Multi-Hop Networks","abstract":"In this work, we introduce Blank Space AC-RLNC (BS), a novel Adaptive and Causal Network Coding (AC-RLNC) solution designed to mitigate the triplet trade-off between throughput-delay-efficiency in multi-hop networks. BS leverages the network's physical limitations considering the bottleneck from each node to the destination. In particular, BS introduces a light-computational re-encoding algorithm, called Network AC-RLNC (NET), implemented independently at intermediate nodes. NET adaptively adjusts the Forward Error Correction (FEC) rates and schedules idle periods. It incorporates two distinct suspension mechanisms: 1) Blank Space Period, accounting for the forward-channels bottleneck, and 2) No-New No-FEC approach, based on data availability. The experimental results achieve significant improvements in resource efficiency, demonstrating a 20% reduction in channel usage compared to baseline RLNC solutions. Notably, these efficiency gains are achieved while maintaining competitive throughput and delay performance, ensuring improved resource utilization does not compromise network performance.","authors":["Adina Waxman","Shai Ginzach","Aviel Glam","Alejandro Cohen"],"url":"https://arxiv.org/abs/2502.11984"}
{"created":"2025-05-23","title":"DivIL: Unveiling and Addressing Over-Invariance for Out-of- Distribution Generalization","abstract":"Out-of-distribution generalization is a common problem that expects the model to perform well in the different distributions even far from the train data. A popular approach to addressing this issue is invariant learning (IL), in which the model is compiled to focus on invariant features instead of spurious features by adding strong constraints during training. However, there are some potential pitfalls of strong invariant constraints. Due to the limited number of diverse environments and over-regularization in the feature space, it may lead to a loss of important details in the invariant features while alleviating the spurious correlations, namely the over-invariance, which can also degrade the generalization performance. We theoretically define the over-invariance and observe that this issue occurs in various classic IL methods. To alleviate this issue, we propose a simple approach Diverse Invariant Learning (DivIL) by adding the unsupervised contrastive learning and the random masking mechanism compensatory for the invariant constraints, which can be applied to various IL methods. Furthermore, we conduct experiments across multiple modalities across 12 datasets and 6 classic models, verifying our over-invariance insight and the effectiveness of our DivIL framework. Our code is available at https://github.com/kokolerk/DivIL.","authors":["Jiaqi Wang","Yuhang Zhou","Zhixiong Zhang","Qiguang Chen","Yongqiang Chen","James Cheng"],"url":"https://arxiv.org/abs/2502.12413"}
{"created":"2025-05-23","title":"CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space","abstract":"Embodied Question Answering (EQA) has primarily focused on indoor environments, leaving the complexities of urban settings-spanning environment, action, and perception-largely unexplored. To bridge this gap, we introduce CityEQA, a new task where an embodied agent answers open-vocabulary questions through active exploration in dynamic city spaces. To support this task, we present CityEQA-EC, the first benchmark dataset featuring 1,412 human-annotated tasks across six categories, grounded in a realistic 3D urban simulator. Moreover, we propose Planner-Manager-Actor (PMA), a novel agent tailored for CityEQA. PMA enables long-horizon planning and hierarchical task execution: the Planner breaks down the question answering into sub-tasks, the Manager maintains an object-centric cognitive map for spatial reasoning during the process control, and the specialized Actors handle navigation, exploration, and collection sub-tasks. Experiments demonstrate that PMA achieves 60.7% of human-level answering accuracy, significantly outperforming competitive baselines. While promising, the performance gap compared to humans highlights the need for enhanced visual reasoning in CityEQA. This work paves the way for future advancements in urban spatial intelligence. Dataset and code are available at https://github.com/BiluYong/CityEQA.git.","authors":["Yong Zhao","Kai Xu","Zhengqiu Zhu","Yue Hu","Zhiheng Zheng","Yingfeng Chen","Yatai Ji","Chen Gao","Yong Li","Jincai Huang"],"url":"https://arxiv.org/abs/2502.12532"}
{"created":"2025-05-23","title":"Whose story is it? Personalizing story generation by inferring author styles","abstract":"Personalization is critical for improving user experience in interactive writing and educational applications, yet remains understudied in story generation. We study the task of personalizing story generation, where our goal is to mimic an author's writing style, given other stories written by them. We collect Mythos, a dataset of 3.6k stories from 112 authors, with an average of 16 stories per author, across five distinct sources reflecting diverse story-writing settings. We propose a two-stage pipeline for personalized story generation: first, we infer authors' implicit writing characteristics and organize them into an Author Writing Sheet, which is validated by humans to be of high quality; second, we simulate the author's persona using tailored persona descriptions and personalized story rules. We find that stories personalized using the Author Writing Sheet outperform a non-personalized baseline, achieving a 78% win-rate in capturing authors' past style and 59% in similarity to ground-truth author stories. Human evaluation supports these findings and further highlights trends, such as Reddit stories being easier to personalize, and the Creativity and Language Use aspects of stories being easier to personalize than the Plot.","authors":["Nischal Ashok Kumar","Chau Minh Pham","Mohit Iyyer","Andrew Lan"],"url":"https://arxiv.org/abs/2502.13028"}
{"created":"2025-05-23","title":"Transferring Textual Preferences to Vision-Language Understanding through Model Merging","abstract":"Large vision-language models (LVLMs) perform outstandingly across various multimodal tasks. However, their ability to evaluate generated content remains limited, and training vision-language reward models (VLRMs) with preference data is computationally expensive. This paper explores a training-free alternative by merging text-based reward models (RMs) with LVLMs to create VLRMs. Our approach shows that integrating these models leads to improved performance over LVLMs' scoring and text-based RMs, offering an efficient method for incorporating textual preferences into LVLMs.","authors":["Chen-An Li","Tzu-Han Lin","Yun-Nung Chen","Hung-yi Lee"],"url":"https://arxiv.org/abs/2502.13487"}
{"created":"2025-05-23","title":"Agentic AI Software Engineers: Programming with Trust","abstract":"Large Language Models (LLMs) have shown surprising proficiency in generating code snippets, promising to automate large parts of software engineering via artificial intelligence (AI). We argue that successfully deploying AI software engineers requires a level of trust equal to or even greater than the trust established by human-driven software engineering practices. The recent trend toward LLM agents offers a path toward integrating the power of LLMs to create new code with the power of analysis tools to increase trust in the code. This opinion piece comments on whether LLM agents could dominate software engineering workflows in the future and whether the focus of programming will shift from programming at scale to programming with trust.","authors":["Abhik Roychoudhury","Corina Pasareanu","Michael Pradel","Baishakhi Ray"],"url":"https://arxiv.org/abs/2502.13767"}
{"created":"2025-05-23","title":"CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations","abstract":"We introduce CoT-ICL Lab, a framework and methodology to generate synthetic tokenized datasets and systematically study chain-of-thought (CoT) in-context learning (ICL) in language models. CoT-ICL Lab allows fine grained control over the complexity of in-context examples by decoupling (1) the causal structure involved in chain token generation from (2) the underlying token processing functions. We train decoder-only transformers (up to 700M parameters) on these datasets and show that CoT accelerates the accuracy transition to higher values across model sizes. In particular, we find that model depth is crucial for leveraging CoT with limited in-context examples, while more examples help shallow models match deeper model performance. Additionally, limiting the diversity of token processing functions throughout training improves causal structure learning via ICL. We also interpret these transitions by analyzing transformer embeddings and attention maps. Overall, CoT-ICL Lab serves as a simple yet powerful testbed for theoretical and empirical insights into ICL and CoT in language models.","authors":["Vignesh Kothapalli","Hamed Firooz","Maziar Sanjabi"],"url":"https://arxiv.org/abs/2502.15132"}
{"created":"2025-05-23","title":"Slamming: Training a Speech Language Model on One GPU in a Day","abstract":"We introduce Slam, a recipe for training high-quality Speech Language Models (SLMs) on a single academic GPU in 24 hours. We do so through empirical analysis of model initialisation and architecture, synthetic training data, preference optimisation with synthetic data and tweaking all other components. We empirically demonstrate that this training recipe also scales well with more compute getting results on par with leading SLMs in a fraction of the compute cost. We hope these insights will make SLM training and research more accessible. In the context of SLM scaling laws, our results far outperform predicted compute optimal performance, giving an optimistic view to SLM feasibility. See code, data, models, samples at - https://pages.cs.huji.ac.il/adiyoss-lab/slamming .","authors":["Gallil Maimon","Avishai Elmakies","Yossi Adi"],"url":"https://arxiv.org/abs/2502.15814"}
{"created":"2025-05-23","title":"KVLink: Accelerating Large Language Models via Efficient KV Cache Reuse","abstract":"We describe KVLink, an approach for efficient key-value (KV) cache reuse in large language models (LLMs). In many LLM applications, different inputs can share overlapping context, such as the same retrieved document appearing in multiple queries. However, the LLMs still need to encode the entire context for each query, leading to redundant computation. In this paper, we investigate a new strategy to eliminate such inefficiency, where the KV cache of each document is precomputed independently. During inference, the KV caches of retrieved documents are concatenated, allowing the model to reuse cached representations instead of recomputing them. To mitigate the performance degradation when using KV caches computed independently for each document, KVLink introduces two key techniques: adjusting positional embeddings of the KV cache at inference to match the global position after concatenation, and using trainable special tokens to restore self-attention across independently encoded documents. Experiments across 7 datasets demonstrate that KVLink improves question answering accuracy by an average of 4% over state-of-the-art methods. Furthermore, by leveraging precomputed KV caches, our approach reduces time-to-first-token by up to 96% compared to standard LLM inference, making it a scalable and efficient solution for context reuse. Additionally, KVLink can be combined with KV cache compression to further save cache loading and storage overhead while outperforming the baselines.","authors":["Jingbo Yang","Bairu Hou","Wei Wei","Yujia Bao","Shiyu Chang"],"url":"https://arxiv.org/abs/2502.16002"}
{"created":"2025-05-23","title":"Worse than Zero-shot? A Fact-Checking Dataset for Evaluating the Robustness of RAG Against Misleading Retrievals","abstract":"Retrieval-augmented generation (RAG) has shown impressive capabilities in mitigating hallucinations in large language models (LLMs). However, LLMs struggle to handle misleading retrievals and often fail to maintain their own reasoning when exposed to conflicting or selectively-framed evidence, making them vulnerable to real-world misinformation. In such real-world retrieval scenarios, misleading and conflicting information is rampant, particularly in the political domain, where evidence is often selectively framed, incomplete, or polarized. However, existing RAG benchmarks largely assume a clean retrieval setting, where models succeed by accurately retrieving and generating answers from gold-standard documents. This assumption fails to align with real-world conditions, leading to an overestimation of RAG system performance. To bridge this gap, we introduce RAGuard, a fact-checking dataset designed to evaluate the robustness of RAG systems against misleading retrievals. Unlike prior benchmarks that rely on synthetic noise, our dataset constructs its retrieval corpus from Reddit discussions, capturing naturally occurring misinformation. It categorizes retrieved evidence into three types: supporting, misleading, and irrelevant, providing a realistic and challenging testbed for assessing how well RAG systems navigate different retrieval information. Our benchmark experiments reveal that when exposed to misleading retrievals, all tested LLM-powered RAG systems perform worse than their zero-shot baselines (i.e., no retrieval at all), highlighting their susceptibility to noisy environments. To the best of our knowledge, RAGuard is the first benchmark to systematically assess RAG robustness against misleading evidence. We expect this benchmark will drive future research toward improving RAG systems beyond idealized datasets, making them more reliable for real-world applications.","authors":["Linda Zeng","Rithwik Gupta","Divij Motwani","Diji Yang","Yi Zhang"],"url":"https://arxiv.org/abs/2502.16101"}
{"created":"2025-05-23","title":"Model-Based Exploration in Truthful Monitored Markov Decision Processes","abstract":"A tenet of reinforcement learning is that the agent always observes rewards. However, this is not true in many realistic settings, e.g., a human observer may not always be available to provide rewards, sensors may be limited or malfunctioning, or rewards may be inaccessible during deployment. Monitored Markov decision processes (Mon-MDPs) have recently been proposed to model such settings. However, existing Mon-MDP algorithms have several limitations: they do not fully exploit the problem structure, cannot leverage a known monitor, lack worst-case guarantees for 'unsolvable' Mon-MDPs without specific initialization, and offer only asymptotic convergence proofs. This paper makes three contributions. First, we introduce a model-based algorithm for Mon-MDPs that addresses these shortcomings. The algorithm employs two instances of model-based interval estimation: one to ensure that observable rewards are reliably captured, and another to learn the minimax-optimal policy. Second, we empirically demonstrate the advantages. We show faster convergence than prior algorithms in over four dozen benchmarks, and even more dramatic improvement when the monitoring process is known. Third, we present the first finite-sample bound on performance. We show convergence to a minimax-optimal policy even when some rewards are never observable.","authors":["Alireza Kazemipour","Simone Parisi","Matthew E. Taylor","Michael Bowling"],"url":"https://arxiv.org/abs/2502.16772"}
{"created":"2025-05-23","title":"The Challenges and Benefits of Bringing Religious Values Into Design","abstract":"HCI is increasingly taking inspiration from religious traditions as a basis for ethical technology designs. Such ethically-inspired designs can be especially important for social communications technologies, which are associated with numerous societal concerns. If religious values are to be incorporated into real-world designs, there may be challenges when designers work with values unfamiliar to them. Therefore, we investigate the difference in interpretations of values when they are translated to technology designs. To do so we studied design patterns that embody Catholic Social Teaching (CST). We interviewed 24 technologists and 7 CST scholars to assess how their understanding of how those values would manifest in social media designs. We found that for the most part the technologists responded similarly to the CST scholars. However, CST scholars had a better understanding of the principle of subsidiarity, and they believed moderation upheld human dignity more than the technologists did. We discuss the implications of our findings on the designs of social technologies and design processes at large.","authors":["Louisa Conwill","Megan K. Levis","Karla Badillo-Urquiola","Walter J. Scheirer"],"url":"https://arxiv.org/abs/2502.17293"}
{"created":"2025-05-23","title":"FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks","abstract":"Spatial reasoning is a fundamental aspect of human intelligence. One key concept in spatial cognition is the Frame of Reference (FoR), which identifies the perspective of spatial expressions. Despite its significance, FoR has received limited attention in AI models that need spatial intelligence. There is a lack of dedicated benchmarks and in-depth evaluation of large language models (LLMs) in this area. To address this issue, we introduce the Frame of Reference Evaluation in Spatial Reasoning Tasks (FoREST) benchmark, designed to assess FoR comprehension in LLMs. We evaluate LLMs on answering questions that require FoR comprehension and layout generation in text-to-image models using FoREST. Our results reveal a notable performance gap across different FoR classes in various LLMs, affecting their ability to generate accurate layouts for text-to-image generation. This highlights critical shortcomings in FoR comprehension. To improve FoR understanding, we propose Spatial-Guided prompting, which improves LLMs ability to extract essential spatial concepts. Our proposed method improves overall performance across spatial reasoning tasks.","authors":["Tanawan Premsri","Parisa Kordjamshidi"],"url":"https://arxiv.org/abs/2502.17775"}
{"created":"2025-05-23","title":"Towards Better Understanding of Program-of-Thought Reasoning in Cross-Lingual and Multilingual Environments","abstract":"Multi-step reasoning is essential for large language models (LLMs), yet multilingual performance remains challenging. While Chain-of-Thought (CoT) prompting improves reasoning, it struggles with non-English languages due to the entanglement of reasoning and execution. Program-of-Thought (PoT) prompting separates reasoning from execution, offering a promising alternative but shifting the challenge to generating programs from non-English questions. We propose a framework to evaluate PoT by separating multilingual reasoning from code execution to examine (i) the impact of fine-tuning on question-reasoning alignment and (ii) how reasoning quality affects answer correctness. Our findings demonstrate that PoT fine-tuning substantially enhances multilingual reasoning, outperforming CoT fine-tuned models. We further demonstrate a strong correlation between reasoning quality (measured through code quality) and answer accuracy, highlighting its potential as a test-time performance improvement heuristic.","authors":["Patomporn Payoungkhamdee","Pume Tuchinda","Jinheon Baek","Samuel Cahyawijaya","Can Udomcharoenchaikit","Potsawee Manakul","Peerat Limkonchotiwat","Ekapol Chuangsuwanich","Sarana Nutanong"],"url":"https://arxiv.org/abs/2502.17956"}
{"created":"2025-05-23","title":"Progressive Local Alignment for Medical Multimodal Pre-training","abstract":"Local alignment between medical images and text is essential for accurate diagnosis, though it remains challenging due to the absence of natural local pairings and the limitations of rigid region recognition methods. Traditional approaches rely on hard boundaries, which introduce uncertainty, whereas medical imaging demands flexible soft region recognition to handle irregular structures. To overcome these challenges, we propose the Progressive Local Alignment Network (PLAN), which designs a novel contrastive learning-based approach for local alignment to establish meaningful word-pixel relationships and introduces a progressive learning strategy to iteratively refine these relationships, enhancing alignment precision and robustness. By combining these techniques, PLAN effectively improves soft region recognition while suppressing noise interference. Extensive experiments on multiple medical datasets demonstrate that PLAN surpasses state-of-the-art methods in phrase grounding, image-text retrieval, object detection, and zero-shot classification, setting a new benchmark for medical image-text alignment.","authors":["Huimin Yan","Xian Yang","Liang Bai","Jiye Liang"],"url":"https://arxiv.org/abs/2502.18047"}
{"created":"2025-05-23","title":"Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models","abstract":"Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce Meta-Reasoner, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to \\enquote{think about how to think.} Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs contextual multi-armed bandits to iteratively evaluate reasoning progress and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks.","authors":["Yuan Sui","Yufei He","Tri Cao","Simeng Han","Yulin Chen","Bryan Hooi"],"url":"https://arxiv.org/abs/2502.19918"}
{"created":"2025-05-23","title":"Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents","abstract":"Large language models (LLMs) based agent systems have made great strides in real-world applications beyond traditional NLP tasks. This paper proposes a new LLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on the popular Overcooked-AI game with more applicable and challenging tasks in interactive environments. Collab-Overcooked extends existing benchmarks from two novel perspectives. First, it provides a multi-agent framework supporting diverse tasks and objectives and encourages collaboration through natural language communication. Second, it introduces a spectrum of process-oriented evaluation metrics to assess the fine-grained collaboration capabilities of different LLM agents, a dimension often overlooked in prior work. We conduct extensive experiments over 11 popular LLMs and show that, while the LLMs present a strong ability in goal interpretation, there is a significant discrepancy in active collaboration and continuous adaptation which are critical for efficiently fulfilling complicated tasks. Notably, we highlight the strengths and weaknesses in LLM-MAS and provide insights for improving and evaluating LLM-MAS on a unified and open-sourced benchmark. The environments, 30 open-ended tasks, and the evaluation package are publicly available at https://github.com/YusaeMeow/Collab-Overcooked.","authors":["Haochen Sun","Shuwen Zhang","Lujie Niu","Lei Ren","Hao Xu","Hao Fu","Fangkun Zhao","Caixia Yuan","Xiaojie Wang"],"url":"https://arxiv.org/abs/2502.20073"}
{"created":"2025-05-23","title":"Similarity-Distance-Magnitude Universal Verification","abstract":"We address the neural network robustness problem by adding Similarity (i.e., correctly predicted depth-matches into training)-awareness and Distance-to-training-distribution-awareness to the existing output Magnitude (i.e., decision-boundary)-awareness of the softmax function. The resulting SDM activation function provides strong signals of the relative epistemic (reducible) predictive uncertainty. We use this novel behavior to further address the complementary HCI problem of mapping the output to human-interpretable summary statistics over relevant partitions of a held-out calibration set. Estimates of prediction-conditional uncertainty are obtained via a parsimonious learned transform over the class-conditional empirical CDFs of the output of a final-layer SDM activation function. For decision-making and as an intrinsic model check, estimates of class-conditional accuracy are obtained by further partitioning the high-probability regions of this calibrated output into class-conditional, region-specific CDFs. The uncertainty estimates from SDM calibration are remarkably robust to test-time distribution shifts and out-of-distribution inputs; incorporate awareness of the effective sample size; provide estimates of uncertainty from the learning and data splitting processes; and are well-suited for selective classification and conditional branching for additional test-time compute based on the predictive uncertainty, as for selective LLM generation, routing, and composition over multiple models and retrieval. Finally, we construct SDM networks, LLMs with uncertainty-aware verification and interpretability-by-exemplar as intrinsic properties. We provide open-source software implementing these results.","authors":["Allen Schmaltz"],"url":"https://arxiv.org/abs/2502.20167"}
{"created":"2025-05-23","title":"DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping","abstract":"Dexterous grasping remains a fundamental yet challenging problem in robotics. A general-purpose robot must be capable of grasping diverse objects in arbitrary scenarios. However, existing research typically relies on restrictive assumptions, such as single-object settings or limited environments, leading to constrained generalization. We present DexGraspVLA, a hierarchical framework for general dexterous grasping in cluttered scenes based on RGB image perception and language instructions. It utilizes a pre-trained Vision-Language model as the high-level task planner and learns a diffusion-based policy as the low-level Action controller. The key insight to achieve robust generalization lies in iteratively transforming diverse language and visual inputs into domain-invariant representations via foundation models, where imitation learning can be effectively applied due to the alleviation of domain shift. Notably, our method achieves a 90+% success rate under thousands of unseen object, lighting, and background combinations in a \"zero-shot\" environment. Empirical analysis confirms the consistency of internal model behavior across environmental variations, thereby validating our design and explaining its generalization performance. DexGraspVLA also demonstrates free-form long-horizon prompt execution, robustness to adversarial objects and human disturbance, and failure recovery, which are rarely achieved simultaneously in prior work. Extended application to nonprehensile object grasping further proves its generality. Code, model, and video are available at dexgraspvla.github.io.","authors":["Yifan Zhong","Xuchuan Huang","Ruochong Li","Ceyao Zhang","Yitao Liang","Yaodong Yang","Yuanpei Chen"],"url":"https://arxiv.org/abs/2502.20900"}
{"created":"2025-05-23","title":"Remasking Discrete Diffusion Models with Inference-Time Scaling","abstract":"Part of the success of diffusion models stems from their ability to perform iterative refinement, i.e., repeatedly correcting outputs during generation. However, modern masked discrete diffusion lacks this capability: when a token is generated, it cannot be updated again, even when it introduces an error. Here, we address this limitation by introducing the remasking diffusion model (ReMDM) sampler, a method that can be applied to pretrained masked diffusion models in a principled way and that is derived from a discrete diffusion model with a custom remasking backward process. Most interestingly, ReMDM endows discrete diffusion with a form of inference-time compute scaling. By increasing the number of sampling steps, ReMDM generates natural language outputs that approach the quality of autoregressive models, whereas when the computation budget is limited, ReMDM better maintains quality. ReMDM also improves sample quality of masked diffusion models for discretized images, and in scientific domains such as molecule design, ReMDM facilitates diffusion guidance and pushes the Pareto frontier of controllability relative to classical masking and uniform noise diffusion. We provide the code along with a blog post on the project page: https://remdm.github.io","authors":["Guanghan Wang","Yair Schiff","Subham Sekhar Sahoo","Volodymyr Kuleshov"],"url":"https://arxiv.org/abs/2503.00307"}
{"created":"2025-05-23","title":"Split Gibbs Discrete Diffusion Posterior Sampling","abstract":"We study the problem of posterior sampling in discrete-state spaces using discrete diffusion models. While posterior sampling methods for continuous diffusion models have achieved remarkable progress, analogous methods for discrete diffusion models remain challenging. In this work, we introduce a principled plug-and-play discrete diffusion posterior sampling algorithm based on split Gibbs sampling, which we call SGDD. Our algorithm enables reward-guided generation and solving inverse problems in discrete-state spaces. We demonstrate the convergence of SGDD to the target posterior distribution and verify this through controlled experiments on synthetic benchmarks. Our method enjoys state-of-the-art posterior sampling performance on a range of benchmarks for discrete data, including DNA sequence design, discrete image inverse problems, and music infilling, achieving more than 30% improved performance compared to existing baselines.","authors":["Wenda Chu","Zihui Wu","Yifan Chen","Yang Song","Yisong Yue"],"url":"https://arxiv.org/abs/2503.01161"}
{"created":"2025-05-23","title":"Retrieval-Augmented Perception: High-Resolution Image Perception Meets Visual RAG","abstract":"High-resolution (HR) image perception remains a key challenge in multimodal large language models (MLLMs). To overcome the limitations of existing methods, this paper shifts away from prior dedicated heuristic approaches and revisits the most fundamental idea to HR perception by enhancing the long-context capability of MLLMs, driven by recent advances in long-context techniques like retrieval-augmented generation (RAG) for general LLMs. Towards this end, this paper presents the first study exploring the use of RAG to address HR perception challenges. Specifically, we propose Retrieval-Augmented Perception (RAP), a training-free framework that retrieves and fuses relevant image crops while preserving spatial context using the proposed Spatial-Awareness Layout. To accommodate different tasks, the proposed Retrieved-Exploration Search (RE-Search) dynamically selects the optimal number of crops based on model confidence and retrieval scores. Experimental results on HR benchmarks demonstrate the significant effectiveness of RAP, with LLaVA-v1.5-13B achieving a 43% improvement on $V^*$ Bench and 19% on HR-Bench.","authors":["Wenbin Wang","Yongcheng Jing","Liang Ding","Yingjie Wang","Li Shen","Yong Luo","Bo Du","Dacheng Tao"],"url":"https://arxiv.org/abs/2503.01222"}
{"created":"2025-05-23","title":"POPGym Arcade: Parallel Pixelated POMDPs","abstract":"We present the POPGym Arcade, a collection of hardware-accelerated, pixel-based environments with shared observation and action spaces. Each environment includes fully and partially observable variants, enabling counterfactual studies on partial observability. We also introduce mathematical tools for analyzing policies under partial observability, which reveal how agents recall past information to make decisions. Our analysis shows (1) that controlling for partial observability is critical and (2) that agents with long-term memory learn brittle policies that struggle to generalize. Finally, we demonstrate that recurrent policies can be \"poisoned\" by old, out-of-distribution observations, with implications for sim-to-real transfer, imitation learning, and offline reinforcement learning.","authors":["Zekang Wang","Zhe He","Borong Zhang","Edan Toledo","Steven Morad"],"url":"https://arxiv.org/abs/2503.01450"}
{"created":"2025-05-23","title":"Steer LLM Latents for Hallucination Detection","abstract":"Hallucinations in LLMs pose a significant concern to their safe deployment in real-world applications. Recent approaches have leveraged the latent space of LLMs for hallucination detection, but their embeddings, optimized for linguistic coherence rather than factual accuracy, often fail to clearly separate truthful and hallucinated content. To this end, we propose the Truthfulness Separator Vector (TSV), a lightweight and flexible steering vector that reshapes the LLM's representation space during inference to enhance the separation between truthful and hallucinated outputs, without altering model parameters. Our two-stage framework first trains TSV on a small set of labeled exemplars to form compact and well-separated clusters. It then augments the exemplar set with unlabeled LLM generations, employing an optimal transport-based algorithm for pseudo-labeling combined with a confidence-based filtering process. Extensive experiments demonstrate that TSV achieves state-of-the-art performance with minimal labeled data, exhibiting strong generalization across datasets and providing a practical solution for real-world LLM applications.","authors":["Seongheon Park","Xuefeng Du","Min-Hsuan Yeh","Haobo Wang","Yixuan Li"],"url":"https://arxiv.org/abs/2503.01917"}
{"created":"2025-05-23","title":"Adaptive Traffic Signal Control based on Multi-Agent Reinforcement Learning. Case Study on a simulated real-world corridor","abstract":"Previous studies that have formulated multi-agent reinforcement learning (RL) algorithms for adaptive traffic signal control have primarily used value-based RL methods. However, recent literature has shown that policy-based methods may perform better in partially observable environments. Additionally, RL methods remain largely untested for real-world normally signal timing plans because of the simplifying assumptions common in the literature. The current study attempts to address these gaps and formulates a multi-agent proximal policy optimization (MA-PPO) algorithm to implement adaptive and coordinated traffic control along an arterial corridor. The formulated MA-PPO has a centralized-critic architecture under a centralized training and decentralized execution framework. Agents are designed to allow selection and implementation of up to eight signal phases, as commonly implemented in field controllers. The formulated algorithm is tested on a simulated real-world seven intersection corridor. The speed of convergence for each agent was found to depend on the size of the action space, which depends on the number and sequence of signal phases. The performance of the formulated MA-PPO adaptive control algorithm is compared with the field implemented actuated-coordinated signal control (ASC), modeled using PTV-Vissim-MaxTime software in the loop simulation (SILs). The trained MA-PPO performed significantly better than the ASC for all movements. Compared to ASC the MA-PPO showed 2% and 24% improvements in travel time in the primary and secondary coordination directions, respectively. For cross streets movements MA-PPO also showed significant crossing time reductions. Volume sensitivity experiments revealed that the formulated MA-PPO demonstrated good stability, robustness, and adaptability to changes in traffic demand.","authors":["Dickness Kakitahi Kwesiga","Angshuman Guin","Michael Hunter"],"url":"https://arxiv.org/abs/2503.02189"}
{"created":"2025-05-23","title":"Transformers for molecular property prediction: Domain adaptation efficiently improves performance","abstract":"Over the past six years, molecular transformer models have become key tools in drug discovery. Most existing models are pre-trained on large, unlabeled datasets such as ZINC or ChEMBL. However, the extent to which large-scale pre-training improves molecular property prediction remains unclear. This study evaluates transformer models for this task while addressing their limitations. We explore how pre-training dataset size and chemically informed objectives impact performance. Our results show that increasing the dataset beyond approximately 400K to 800K molecules from large-scale unlabeled databases does not enhance performance across seven datasets covering five ADME endpoints: lipophilicity, permeability, solubility (two datasets), microsomal stability (two datasets), and plasma protein binding. In contrast, domain adaptation on a small, domain-specific dataset (less than or equal 4K molecules) using multi-task regression of physicochemical properties significantly boosts performance (P-value less than 0.001). A model pre-trained on 400K molecules and adapted with domain-specific data outperforms larger models such as MolFormer and performs comparably to MolBERT. Benchmarks against Random Forest (RF) baselines using descriptors and Morgan fingerprints show that chemically and physically informed features consistently yield better performance across model types. While RF remains a strong baseline, we identify concrete practices to enhance transformer performance. Aligning pre-training and adaptation with chemically meaningful tasks and domain-relevant data presents a promising direction for molecular property prediction. Our models are available on HuggingFace for easy use and adaptation.","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Dietrich Klakow","Andrea Volkamer"],"url":"https://arxiv.org/abs/2503.03360"}
{"created":"2025-05-23","title":"L2RDaS: Synthesizing 4D Radar Tensors for Model Generalization via Dataset Expansion","abstract":"4-dimensional (4D) radar is increasingly adopted in autonomous driving for perception tasks, owing to its robustness under adverse weather conditions. To better utilize the spatial information inherent in 4D radar data, recent deep learning methods have transitioned from using sparse point cloud to 4D radar tensors. However, the scarcity of publicly available 4D radar tensor datasets limits model generalization across diverse driving scenarios. Previous methods addressed this by synthesizing radar data, but the outputs did not fully exploit the spatial information characteristic of 4D radar. To overcome these limitations, we propose LiDAR-to-4D radar data synthesis (L2RDaS), a framework that synthesizes spatially informative 4D radar tensors from LiDAR data available in existing autonomous driving datasets. L2RDaS integrates a modified U-Net architecture to effectively capture spatial information and an object information supplement (OBIS) module to enhance reflection fidelity. This framework enables the synthesis of radar tensors across diverse driving scenarios without additional sensor deployment or data collection. L2RDaS improves model generalization by expanding real datasets with synthetic radar tensors, achieving an average increase of 4.25\\% in ${{AP}_{BEV}}$ and 2.87\\% in ${{AP}_{3D}}$ across three detection models. Additionally, L2RDaS supports ground-truth augmentation (GT-Aug) by embedding annotated objects into LiDAR data and synthesizing them into radar tensors, resulting in further average increases of 3.75\\% in ${{AP}_{BEV}}$ and 4.03\\% in ${{AP}_{3D}}$. The implementation will be available at https://github.com/kaist-avelab/K-Radar.","authors":["Woo-Jin Jung","Dong-Hee Paek","Seung-Hyun Kong"],"url":"https://arxiv.org/abs/2503.03637"}
{"created":"2025-05-23","title":"DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating Semantic Understanding of Dongba Pictograms","abstract":"Dongba pictographic is the only pictographic script still in use in the world. Its pictorial ideographic features carry rich cultural and contextual information. However, due to the lack of relevant datasets, research on semantic understanding of Dongba hieroglyphs has progressed slowly. To this end, we constructed \\textbf{DongbaMIE} - the first dataset focusing on multimodal information extraction of Dongba pictographs. The dataset consists of images of Dongba hieroglyphic characters and their corresponding semantic annotations in Chinese. It contains 23,530 sentence-level and 2,539 paragraph-level high-quality text-image pairs. The annotations cover four semantic dimensions: object, action, relation and attribute. Systematic evaluation of mainstream multimodal large language models shows that the models are difficult to perform information extraction of Dongba hieroglyphs efficiently under zero-shot and few-shot learning. Although supervised fine-tuning can improve the performance, accurate extraction of complex semantics is still a great challenge at present.","authors":["Xiaojun Bi","Shuo Li","Junyao Xing","Ziyue Wang","Fuwen Luo","Weizheng Qiao","Lu Han","Ziwei Sun","Peng Li","Yang Liu"],"url":"https://arxiv.org/abs/2503.03644"}
{"created":"2025-05-23","title":"All-atom Diffusion Transformers: Unified generative modelling of molecules and materials","abstract":"Diffusion models are the standard toolkit for generative modelling of 3D atomic systems. However, for different types of atomic systems -- such as molecules and materials -- the generative processes are usually highly specific to the target system despite the underlying physics being the same. We introduce the All-atom Diffusion Transformer (ADiT), a unified latent diffusion framework for jointly generating both periodic materials and non-periodic molecular systems using the same model: (1) An autoencoder maps a unified, all-atom representations of molecules and materials to a shared latent embedding space; and (2) A diffusion model is trained to generate new latent embeddings that the autoencoder can decode to sample new molecules or materials. Experiments on MP20, QM9 and GEOM-DRUGS datasets demonstrate that jointly trained ADiT generates realistic and valid molecules as well as materials, obtaining state-of-the-art results on par with molecule and crystal-specific models. ADiT uses standard Transformers with minimal inductive biases for both the autoencoder and diffusion model, resulting in significant speedups during training and inference compared to equivariant diffusion models. Scaling ADiT up to half a billion parameters predictably improves performance, representing a step towards broadly generalizable foundation models for generative chemistry. Open source code: https://github.com/facebookresearch/all-atom-diffusion-transformer","authors":["Chaitanya K. Joshi","Xiang Fu","Yi-Lun Liao","Vahe Gharakhanyan","Benjamin Kurt Miller","Anuroop Sriram","Zachary W. Ulissi"],"url":"https://arxiv.org/abs/2503.03965"}
{"created":"2025-05-23","title":"Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association","abstract":"Secure aggregation is motivated by federated learning (FL) where a cloud server aims to compute an averaged model (i.e., weights of deep neural networks) of the locally-trained models of numerous clients, while adhering to data security requirements. Hierarchical secure aggregation (HSA) extends this concept to a three-layer network, where clustered users communicate with the server through an intermediate layer of relays. In HSA, beyond conventional server security, relay security is also enforced to ensure that the relays remain oblivious to the users' inputs (an abstraction of the local models in FL). Existing study on HSA assumes that each user is associated with only one relay, limiting opportunities for coding across inter-cluster users to achieve efficient communication and key generation. In this paper, we consider HSA with a cyclic association pattern where each user is connected to $B$ consecutive relays in a wrap-around manner. We propose an efficient aggregation scheme which includes a message design for the inputs inspired by gradient coding-a well-known technique for efficient communication in distributed computing-along with a highly nontrivial security key design. We also derive novel converse bounds on the minimum achievable communication and key rates using information-theoretic arguments.","authors":["Xiang Zhang","Zhou Li","Kai Wan","Hua Sun","Mingyue Ji","Giuseppe Caire"],"url":"https://arxiv.org/abs/2503.04564"}
{"created":"2025-05-23","title":"HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization","abstract":"Transformers have become the de facto architecture for a wide range of machine learning tasks, particularly in large language models (LLMs). Despite their remarkable performance, challenges remain in training deep transformer networks, especially regarding the position of layer normalization. While Pre-Norm structures facilitate more stable training owing to their stronger identity path, they often lead to suboptimal performance compared to Post-Norm. In this paper, we propose $\\textbf{HybridNorm}$, a simple yet effective hybrid normalization strategy that integrates the advantages of both Pre-Norm and Post-Norm. Specifically, HybridNorm employs QKV normalization within the attention mechanism and Post-Norm in the feed-forward network (FFN) of each transformer block. We provide both theoretical insights and empirical evidence demonstrating that HybridNorm improves gradient flow and model robustness. Extensive experiments on large-scale transformer models, including both dense and sparse variants, show that HybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches across multiple benchmarks. These findings highlight the potential of HybridNorm as a more stable and effective technique for improving the training and performance of deep transformer models. Code is available at https://github.com/BryceZhuo/HybridNorm.","authors":["Zhijian Zhuo","Yutao Zeng","Ya Wang","Sijun Zhang","Jian Yang","Xiaoqing Li","Xun Zhou","Jinwen Ma"],"url":"https://arxiv.org/abs/2503.04598"}
{"created":"2025-05-23","title":"Leveraging Large Language Models For Scalable Vector Graphics Processing: A Review","abstract":"In recent years, rapid advances in computer vision have significantly improved the processing and generation of raster images. However, vector graphics, which is essential in digital design, due to its scalability and ease of editing, have been relatively understudied. Traditional vectorization techniques, which are often used in vector generation, suffer from long processing times and excessive output complexity, limiting their usability in practical applications. The advent of large language models (LLMs) has opened new possibilities for the generation, editing, and analysis of vector graphics, particularly in the SVG format, which is inherently text-based and well-suited for integration with LLMs.","authors":["Boris Malashenko","Ivan Jarsky","Valeria Efimova"],"url":"https://arxiv.org/abs/2503.04983"}
{"created":"2025-05-23","title":"Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts","abstract":"The Mixture of Experts (MoE) is an effective architecture for scaling large language models by leveraging sparse expert activation, optimizing the trade-off between performance and efficiency. However, under expert parallelism, MoE suffers from inference inefficiencies due to imbalanced token-to-expert assignment, where some experts are overloaded while others remain underutilized. This imbalance leads to poor resource utilization and increased latency, as the most burdened expert dictates the overall delay, a phenomenon we define as the \\textbf{\\textit{Straggler Effect}}. To mitigate this, we propose Capacity-Aware Inference, including two key techniques: (1) \\textbf{\\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens to regulate the maximum latency of MoE, and (2) \\textbf{\\textit{Capacity-Aware Token Reroute}}, which reallocates overflowed tokens to underutilized experts, balancing the token distribution. These techniques collectively optimize both high-load and low-load expert utilization, leading to a more efficient MoE inference pipeline. Extensive experiments demonstrate the effectiveness of our methods, showing significant improvements in inference efficiency, e.g., 0.2\\% average performance increase and a 1.94$\\times$ inference speedup on Mixtral-8$\\times$7B-Instruct.","authors":["Shwai He","Weilin Cai","Jiayi Huang","Ang Li"],"url":"https://arxiv.org/abs/2503.05066"}
{"created":"2025-05-23","title":"EDM: Efficient Deep Feature Matching","abstract":"Recent feature matching methods have achieved remarkable performance but lack efficiency consideration. In this paper, we revisit the mainstream detector-free matching pipeline and improve all its stages considering both accuracy and efficiency. We propose an Efficient Deep feature Matching network, EDM. We first adopt a deeper CNN with fewer dimensions to extract multi-level features. Then we present a Correlation Injection Module that conducts feature transformation on high-level deep features, and progressively injects feature correlations from global to local for efficient multi-scale feature aggregation, improving both speed and performance. In the refinement stage, a novel lightweight bidirectional axis-based regression head is designed to directly predict subpixel-level correspondences from latent features, avoiding the significant computational cost of explicitly locating keypoints on high-resolution local feature heatmaps. Moreover, effective selection strategies are introduced to enhance matching accuracy. Extensive experiments show that our EDM achieves competitive matching accuracy on various benchmarks and exhibits excellent efficiency, offering valuable best practices for real-world applications. The code is available at https://github.com/chicleee/EDM.","authors":["Xi Li","Tong Rao","Cihui Pan"],"url":"https://arxiv.org/abs/2503.05122"}
{"created":"2025-05-23","title":"A Modified Hermite Radial Basis Function for Accurate Interpolation","abstract":"Accurate interpolation of functions and derivatives is crucial in solving partial differential equations (PDEs). The Radial Basis Function (RBF) method has become an extremely popular and robust approach for interpolation on scattered data. Hermite Radial Basis Function (HRBF) methods are an extension of the RBF and improve the overall accuracy by incorporating both function and derivative information. Infinitely smooth kernels, such as the Gaussian, use a shape-parameter to describe the width of support and are widely used due to their excellent approximation accuracy and ability to capture fine-scale details. Unfortunately, the use of infinitely smooth kernels suffers from ill-conditioning at low to moderate shape parameters, which affects the accuracy. This work proposes a Modified HRBF (MHRBF) method that introduces an additional polynomial term to balance kernel behavior, improving accuracy while maintaining or lowering computational cost. Using standard double-precision mathematics, the results indicate that compared to the HRBF method, the MHRBF method achieves lower error for all values of the shape parameter and domain size. The MHRBF is also able to achieve low errors at a lower computational cost as compared to the standard HRBF method.","authors":["Amirhossein Fashamiha","David Salac"],"url":"https://arxiv.org/abs/2503.05752"}
{"created":"2025-05-23","title":"Multi-layer Motion Planning with Kinodynamic and Spatio-Temporal Constraints","abstract":"We propose a novel, multi-layered planning approach for computing paths that satisfy both kinodynamic and spatiotemporal constraints. Our three-part framework first establishes potential sequences to meet spatial constraints, using them to calculate a geometric lead path. This path then guides an asymptotically optimal sampling-based kinodynamic planner, which minimizes an STL-robustness cost to jointly satisfy spatiotemporal and kinodynamic constraints. In our experiments, we test our method with a velocity-controlled Ackerman-car model and demonstrate significant efficiency gains compared to prior art. Additionally, our method is able to generate complex path maneuvers, such as crossovers, something that previous methods had not demonstrated.","authors":["Jeel Chatrola","Abhiroop Ajith","Kevin Leahy","Constantinos Chamzas"],"url":"https://arxiv.org/abs/2503.07762"}
{"created":"2025-05-23","title":"ExMAG: Learning of Maximally Ancestral Graphs","abstract":"In mixed graphs, there are both directed and undirected edges. An extension of acyclicity to this mixed-graph setting is known as maximally ancestral graphs. This extension is of considerable interest in causal learning in the presence of confounders. There, directed edges represent a clear direction of causality, while undirected edges represent confounding. We propose a score-based branch-and-cut algorithm for learning maximally ancestral graphs. The algorithm produces more accurate results than state-of-the-art methods, while being faster to run on small and medium-sized synthetic instances.","authors":["Petr Ry\\v{s}av\\'y","Pavel Ryt\\'i\\v{r}","Xiaoyu He","Georgios Korpas","Jakub Mare\\v{c}ek"],"url":"https://arxiv.org/abs/2503.08245"}
{"created":"2025-05-23","title":"ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews","abstract":"Academic paper review is a critical yet time-consuming task within the research community. With the increasing volume of academic publications, automating the review process has become a significant challenge. The primary issue lies in generating comprehensive, accurate, and reasoning-consistent review comments that align with human reviewers' judgments. In this paper, we address this challenge by proposing ReviewAgents, a framework that leverages large language models (LLMs) to generate academic paper reviews. We first introduce a novel dataset, Review-CoT, consisting of 142k review comments, designed for training LLM agents. This dataset emulates the structured reasoning process of human reviewers-summarizing the paper, referencing relevant works, identifying strengths and weaknesses, and generating a review conclusion. Building upon this, we train LLM reviewer agents capable of structured reasoning using a relevant-paper-aware training method. Furthermore, we construct ReviewAgents, a multi-role, multi-LLM agent review framework, to enhance the review comment generation process. Additionally, we propose ReviewBench, a benchmark for evaluating the review comments generated by LLMs. Our experimental results on ReviewBench demonstrate that while existing LLMs exhibit a certain degree of potential for automating the review process, there remains a gap when compared to human-generated reviews. Moreover, our ReviewAgents framework further narrows this gap, outperforming advanced LLMs in generating review comments.","authors":["Xian Gao","Jiacheng Ruan","Jingsheng Gao","Ting Liu","Yuzhuo Fu"],"url":"https://arxiv.org/abs/2503.08506"}
{"created":"2025-05-23","title":"MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?","abstract":"Large foundation models face challenges in acquiring transferable, structured thinking abilities, especially when supervised with rigid templates or crowd-annotated instruction datasets. Unlike prior approaches, we focus on a thinking-centric data synthesis paradigm that enables models to evolve through self-generated, cognitively guided data. We propose MindGYM, a structured and scalable framework for question synthesis, composed of: (1) Cognitive Thinking Process Injection, which infuses high-level reasoning objectives to shape the model's synthesis behavior; (2) Seed Single-Hop Question Synthesis, generating atomic questions from diverse semantic types to encourage broader thinking; and (3) Challenging Multi-Hop QA Synthesis, composing more complex multi-hop questions based on QA seeds for deeper reasoning. Detailed analysis shows that synthetic data generated by our method achieves 16.7% higher average quality and 67.91% lower quality variance compared to baseline sources, highlighting that both high-quality and self-contained data are essential for effective, thinking-oriented fine-tuning. MindGYM improves performance on six reasoning benchmarks, achieving gains of up to 16% on MathVision using only 400 data samples, and generalizable improvements across different model sizes and architectures. MindGYM underscores the viability of self-challenging mechanisms in refining large model capabilities while minimizing human intervention and resource demands. Code and data are released to promote data-centric research into self-evolving foundation models driven by their internal reasoning capabilities.","authors":["Zhe Xu","Daoyuan Chen","Zhenqing Ling","Yaliang Li","Ying Shen"],"url":"https://arxiv.org/abs/2503.09499"}
{"created":"2025-05-23","title":"ASMA-Tune: Unlocking LLMs' Assembly Code Comprehension via Structural-Semantic Instruction Tuning","abstract":"Assembly code analysis and comprehension play critical roles in applications like reverse engineering, yet they face substantial challenges due to low information density and a lack of explicit syntactic structures. While traditional masked language modeling (MLM) approaches do not explicitly focus on natural language interaction, emerging decoder-focused large language models (LLMs) demonstrate partial success in binary analysis yet remain underexplored for holistic comprehension. We present Assembly Augmented Tuning, an end-to-end structural-semantic instruction tuning framework that synergizes encoder architecture with decoder-based LLMs through a projector module, where the assembly encoder extracts hardware-level structural features, the projector bridges representations with the semantic space, and the instruction-tuned LLM preserves natural language capabilities. Experimental results demonstrate three key advantages: (1) State-of-the-art performance in assembly comprehension with +39.7% Recall@1 and +17.8% MRR improvements over GPT-4-Turbo, (2) Consistent enhancements across base models (24.6-107.4% Recall@1 and 15.2-106.3% MRR on Qwen2.5-Coder, Deepseek-Coder and CodeLlama variants), and (3) Superior instruction-following capabilities (41.5%-118% improvements) with controlled code generation degradation (-8.9% to -35% across architectures).","authors":["Xinyi Wang","Jiashui Wang","Jinbo Su","Ke Wang","Peng Chen","Yanming Liu","Long Liu","Xiang Li","Yangdong Wang","Qiyuan Chen","Rongze Chen","Chunfu Jia"],"url":"https://arxiv.org/abs/2503.11617"}
{"created":"2025-05-23","title":"ECLARE: Efficient cross-planar learning for anisotropic resolution enhancement","abstract":"In clinical imaging, magnetic resonance (MR) image volumes are often acquired as stacks of 2D slices with decreased scan times, improved signal-to-noise ratio, and image contrasts unique to 2D MR pulse sequences. While this is sufficient for clinical evaluation, automated algorithms designed for 3D analysis perform poorly on multi-slice 2D MR volumes, especially those with thick slices and gaps between slices. Super-resolution (SR) methods aim to address this problem, but previous methods do not address all of the following: slice profile shape estimation, slice gap, domain shift, and non-integer or arbitrary upsampling factors. In this paper, we propose ECLARE (Efficient Cross-planar Learning for Anisotropic Resolution Enhancement), a self-SR method that addresses each of these factors. ECLARE uses a slice profile estimated from the multi-slice 2D MR volume, trains a network to learn the mapping from low-resolution to high-resolution in-plane patches from the same volume, and performs SR with anti-aliasing. We compared ECLARE to cubic B-spline interpolation, SMORE, and other contemporary SR methods. We used realistic and representative simulations so that quantitative performance against ground truth can be computed, and ECLARE outperformed all other methods in both signal recovery and downstream tasks. Importantly, as ECLARE does not use external training data it cannot suffer from domain shift between training and testing. Our code is open-source and available at https://www.github.com/sremedios/eclare.","authors":["Samuel W. Remedios","Shuwen Wei","Shuo Han","Jinwei Zhang","Aaron Carass","Kurt G. Schilling","Dzung L. Pham","Jerry L. Prince","Blake E. Dewey"],"url":"https://arxiv.org/abs/2503.11787"}
{"created":"2025-05-23","title":"Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence","abstract":"As large language models (LLMs) are increasingly used for factual question-answering, it becomes more important for LLMs to have the capability to communicate the likelihood that their answer is correct. For these verbalized expressions of uncertainty to be meaningful, they should reflect the error rates at the expressed level of confidence. However, when prompted to express confidence, the error rates of current LLMs are inconsistent with their communicated confidences, highlighting the need for uncertainty quantification methods. Many prior methods calculate lexical uncertainty, estimating a model's confidence in the specific string it generated. In some cases, however, it may be more useful to estimate semantic uncertainty, or the model's confidence in the answer regardless of how it is verbalized. We propose a simple procedure, uncertainty distillation, to teach an LLM to verbalize calibrated semantic confidences. Using held-out data to map initial uncertainty estimates to meaningful probabilities, we create examples annotated with verbalized probabilities for supervised fine-tuning. We compare uncertainty distillation to several strong baselines, and find that our method yields verbalized confidences that correlate well with observed error rates.","authors":["Sophia Hager","David Mueller","Kevin Duh","Nicholas Andrews"],"url":"https://arxiv.org/abs/2503.14749"}
{"created":"2025-05-23","title":"From 1,000,000 Users to Every User: Scaling Up Personalized Preference for User-level Alignment","abstract":"Large language models (LLMs) have traditionally been aligned through one-size-fits-all approaches that assume uniform human preferences, fundamentally overlooking the diversity in user values and needs. This paper introduces a comprehensive framework for scalable personalized alignment of LLMs. We establish a systematic preference space characterizing psychological and behavioral dimensions, alongside diverse persona representations for robust preference inference in real-world scenarios. Building upon this foundation, we introduce \\textsc{AlignX}, a large-scale dataset of over 1.3 million personalized preference examples, and develop two complementary alignment approaches: \\textit{in-context alignment} directly conditioning on persona representations and \\textit{preference-bridged alignment} modeling intermediate preference distributions. Extensive experiments demonstrate substantial improvements over existing methods, with an average 17.06\\% accuracy gain across four benchmarks while exhibiting a strong adaptation capability to novel preferences, robustness to limited user data, and precise preference controllability. These results validate our approach toward user-adaptive AI systems.","authors":["Jia-Nan Li","Jian Guan","Songhao Wu","Wei Wu","Rui Yan"],"url":"https://arxiv.org/abs/2503.15463"}
{"created":"2025-05-23","title":"Development of a magnetorheological hand exoskeleton featuring a high force-to-power ratio for enhanced grip endurance","abstract":"Hand exoskeletons have significant potential in labor-intensive fields by mitigating hand grip fatigue, enhancing hand strength, and preventing injuries. However, most of the traditional hand exoskeletons are driven by motors, whose output force is limited in the constrained installation conditions. Besides, they also come with the disadvantages of high power consumption, complex and bulky assistive systems, and high instability. In this work, we develop a novel hand exoskeleton integrated with magnetorheological (MR) clutches that offers a high force-to-power ratio to improve grip endurance. The clutch features an enhanced structure design, a micro roller enhancing structure, which can significantly boost output forces. The experimental data demonstrate that the clutch can deliver a peak holding force of 380 N with a 1.48 W consumption, yielding a force-to-power ratio of 256.75N/W, which is 2.35 times higher than the best-reported actuator used for hand exoskeletons. This capability enables the designed MRHE to provide approximately 419.79 N support force for gripping. The designed MR hand exoskeleton is highly integrated, comprising an exoskeleton frame, MR clutches, a control unit, and a battery. Evaluations through static grip endurance tests and dynamic carrying and lifting tests confirm that the MR hand exoskeleton can effectively reduce muscle fatigue, extend grip endurance, and minimize injuries. These findings highlight its strong potential for practical applications in repetitive tasks such as carrying and lifting in industrial settings.","authors":["Wenbo Li","Xianlong Mai","Ying Li","Weihua Li","Shiwu Zhang","Lei Deng","Shuaishuai Sun"],"url":"https://arxiv.org/abs/2503.15915"}
{"created":"2025-05-23","title":"Through the LLM Looking Glass: A Socratic Probing of Donkeys, Elephants, and Markets","abstract":"While detecting and avoiding bias in LLM-generated text is becoming increasingly important, media bias often remains subtle and subjective, making it particularly difficult to identify and mitigate. In this study, we assess media bias in LLM-generated content and LLMs' ability to detect subtle ideological bias. We conduct this evaluation using two datasets, PoliGen and EconoLex, covering political and economic discourse, respectively. We evaluate seven widely used LLMs by prompting them to generate articles and analyze their ideological preferences via Socratic probing. By using our self-contained Socratic approach, the study aims to directly measure the models' biases rather than relying on external interpretations, thereby minimizing subjective judgments about media bias. Our results reveal a consistent preference of Democratic over Republican positions across all models. Conversely, in economic topics, biases vary among Western LLMs, while those developed in China lean more strongly toward socialism.","authors":["Molly Kennedy","Ayyoob Imani","Timo Spinde","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2503.16674"}
{"created":"2025-05-23","title":"Praxis-VLM: Vision-Grounded Decision Making via Text-Driven Reinforcement Learning","abstract":"Vision Language Models exhibited immense potential for embodied AI, yet they often lack the sophisticated situational reasoning required for complex decision-making. This paper shows that VLMs can achieve surprisingly strong decision-making performance when visual scenes are represented merely as text-only descriptions, suggesting foundational reasoning can be effectively learned from language. Motivated by this insight, we propose Praxis-VLM, a reasoning VLM for vision-grounded decision-making. Praxis-VLM employs the GRPO algorithm on textual scenarios to instill robust reasoning capabilities, where models learn to evaluate actions and their consequences. These reasoning skills, acquired purely from text, successfully transfer to multimodal inference with visual inputs, significantly reducing reliance on scarce paired image-text training data. Experiments across diverse decision-making benchmarks demonstrate that Praxis-VLM substantially outperforms standard supervised fine-tuning, exhibiting superior performance and generalizability. Further analysis confirms that our models engage in explicit and effective reasoning, underpinning their enhanced performance and adaptability.","authors":["Zhe Hu","Jing Li","Zhongzhu Pu","Hou Pong Chan","Yu Yin"],"url":"https://arxiv.org/abs/2503.16965"}
{"created":"2025-05-23","title":"FastCuRL: Curriculum Reinforcement Learning with Stage-wise Context Scaling for Efficient Training R1-like Reasoning Models","abstract":"Improving training efficiency continues to be one of the primary challenges in large-scale Reinforcement Learning (RL). In this paper, we investigate how context length and the complexity of training data influence the RL scaling training process of R1-distilled small reasoning models, e.g., DeepSeek-R1-Distill-Qwen-1.5B. Our experimental results reveal that: (1) simply controlling the context length and curating the training data based on the input prompt length can effectively improve the training efficiency of scaling RL, achieving better performance with more concise CoT; (2) properly scaling the context length helps mitigate entropy collapse; and (3) choosing an optimal context length can improve the efficiency of model training and incentivize the model's chain-of-thought reasoning capabilities. Inspired by these insights, we propose FastCuRL, a curriculum RL framework with stage-wise context scaling to achieve efficient training and concise CoT reasoning. Experiment results demonstrate that FastCuRL-1.5B-V3 significantly outperforms state-of-the-art reasoning models on five competition-level benchmarks and achieves 49.6\\% accuracy on AIME 2024. Furthermore, FastCuRL-1.5B-Preview surpasses DeepScaleR-1.5B-Preview on five benchmarks while only using a single node with 8 GPUs and a total of 50\\% of training steps. %The code, training data, and models will be publicly released.","authors":["Mingyang Song","Mao Zheng","Zheng Li","Wenjie Yang","Xuan Luo","Yue Pan","Feng Zhang"],"url":"https://arxiv.org/abs/2503.17287"}
{"created":"2025-05-23","title":"Safe RLHF-V: Safe Reinforcement Learning from Multi-modal Human Feedback","abstract":"Multimodal large language models (MLLMs) are essential for building general-purpose AI assistants; however, they pose increasing safety risks. How can we ensure safety alignment of MLLMs to prevent undesired behaviors? Going further, it is critical to explore how to fine-tune MLLMs to preserve capabilities while meeting safety constraints. Fundamentally, this challenge can be formulated as a min-max optimization problem. However, existing datasets have not yet disentangled single preference signals into explicit safety constraints, hindering systematic investigation in this direction. Moreover, it remains an open question whether such constraints can be effectively incorporated into the optimization process for multi-modal models. In this work, we present the first exploration of the Safe RLHF-V -- the first multimodal safety alignment framework. The framework consists of: $\\mathbf{(I)}$ BeaverTails-V, the first open-source dataset featuring dual preference annotations for helpfulness and safety, supplemented with multi-level safety labels (minor, moderate, severe); $\\mathbf{(II)}$ Beaver-Guard-V, a multi-level guardrail system to proactively defend against unsafe queries and adversarial attacks. Applying the guard model over five rounds of filtering and regeneration significantly enhances the precursor model's overall safety by an average of 40.9%. $\\mathbf{(III)}$ Based on dual preference, we initiate the first exploration of multi-modal safety alignment within a constrained optimization. Experimental results demonstrate that Safe RLHF effectively improves both model helpfulness and safety. Specifically, Safe RLHF-V enhances model safety by 34.2% and helpfulness by 34.3%.","authors":["Jiaming Ji","Xinyu Chen","Rui Pan","Conghui Zhang","Han Zhu","Jiahao Li","Donghai Hong","Boyuan Chen","Jiayi Zhou","Kaile Wang","Juntao Dai","Chi-Min Chan","Yida Tang","Sirui Han","Yike Guo","Yaodong Yang"],"url":"https://arxiv.org/abs/2503.17682"}
{"created":"2025-05-23","title":"Choose Wisely: Data-driven Predictive Control for Nonlinear Systems Using Online Data Selection","abstract":"This paper proposes Select-Data-driven Predictive Control (Select-DPC), a new method for controlling nonlinear systems using output-feedback for which data are available but an explicit model is not. At each timestep, Select-DPC employs only the most relevant data to implicitly linearize the dynamics in \"trajectory space\". Then, taking user-defined output constraints into account, it makes control decisions using a convex optimization. This optimal control is applied in a receding-horizon manner. As the online data-selection is the core of Select-DPC, we propose and verify both norm-based and manifold-embedding-based selection methods. We evaluate Select-DPC on three benchmark nonlinear system simulators -- rocket-landing, a robotic arm and cart-pole inverted pendulum swing-up -- comparing them with standard Data-enabled Predictive Control (DeePC) and Time-Windowed DeePC methods, and find that Select-DPC outperforms both methods.","authors":["Joshua N\\\"af","Keith Moffat","Jaap Eising","Florian D\\\"orfler"],"url":"https://arxiv.org/abs/2503.18845"}
{"created":"2025-05-23","title":"MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow","abstract":"In modern medicine, clinical diagnosis relies on the comprehensive analysis of primarily textual and visual data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in large Vision-Language Models (VLMs) and agent-based methods hold great potential for medical diagnosis, thanks to the ability to effectively integrate multi-modal patient data. However, they often provide direct answers and draw empirical-driven conclusions without quantitative analysis, which reduces their reliability and clinical usability. We propose MedAgent-Pro, a new agentic reasoning paradigm that follows the diagnosis principle in modern medicine, to decouple the process into sequential components for step-by-step, evidence-based reasoning. Our MedAgent-Pro workflow presents a hierarchical diagnostic structure to mirror this principle, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, an RAG-based agent is designed to retrieve medical guidelines to ensure alignment with clinical standards. For patient-level reasoning, we propose to integrate professional tools such as visual models to enable quantitative assessments. Meanwhile, we propose to verify the reliability of each step to achieve evidence-based diagnosis, enforcing rigorous logical reasoning and a well-founded conclusion. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro to mainstream VLMs, agentic systems and state-of-the-art expert models. Ablation studies and human evaluation by clinical experts further validate its robustness and clinical relevance. Code is available at https://github.com/jinlab-imvr/MedAgent-Pro.","authors":["Ziyue Wang","Junde Wu","Linghan Cai","Chang Han Low","Xihong Yang","Qiaxuan Li","Yueming Jin"],"url":"https://arxiv.org/abs/2503.18968"}
{"created":"2025-05-23","title":"DomainCQA: Crafting Expert-Level QA from Domain-Specific Charts","abstract":"Chart Question Answering (CQA) benchmarks are essential for evaluating the capability of Multimodal Large Language Models (MLLMs) to interpret visual data. However, current benchmarks focus primarily on the evaluation of general-purpose CQA but fail to adequately capture domain-specific challenges. We introduce DomainCQA, a systematic methodology for constructing domain-specific CQA benchmarks, and demonstrate its effectiveness by developing AstroChart, a CQA benchmark in the field of astronomy. Our evaluation shows that current MLLMs face fundamental challenges in vision-language alignment and domain adaptation, highlighting a critical gap in current benchmarks. By providing a scalable and rigorous framework, DomainCQA enables more precise assessment and improvement of MLLMs for domain-specific applications.","authors":["Ling Zhong","Yujing Lu","Jing Yang","Weiming Li","Peng Wei","Yongheng Wang","Manni Duan","Qing Zhang"],"url":"https://arxiv.org/abs/2503.19498"}
{"created":"2025-05-23","title":"Universal Cross-Tokenizer Distillation via Approximate Likelihood Matching","abstract":"Distillation has shown remarkable success in transferring knowledge from a Large Language Model (LLM) teacher to a student LLM. However, current distillation methods require similar tokenizers between the teacher and the student, restricting their applicability to only a small subset of teacher-student pairs. In this work, we develop a principled cross-tokenizer distillation method to solve this crucial deficiency. Our method is the first to enable effective distillation across fundamentally different tokenizers, while also substantially outperforming prior methods in all other cases. We verify the efficacy of our method on three distinct use cases. First, we show that viewing tokenizer transfer as self-distillation enables unprecedentedly effective transfer across tokenizers, including rapid transfer of subword models to the byte-level. Transferring different models to the same tokenizer also enables ensembling to boost performance. Secondly, we distil a large maths-specialised LLM into a small general-purpose model with a different tokenizer, achieving competitive maths problem-solving performance. Thirdly, we use our method to train state-of-the-art embedding prediction hypernetworks for training-free tokenizer transfer. Our results unlock an expanded range of teacher-student pairs for distillation, enabling new ways to adapt and enhance interaction between LLMs.","authors":["Benjamin Minixhofer","Ivan Vuli\\'c","Edoardo Maria Ponti"],"url":"https://arxiv.org/abs/2503.20083"}
{"created":"2025-05-23","title":"Optimizing Case-Based Reasoning System for Functional Test Script Generation with Large Language Models","abstract":"In this work, we explore the potential of large language models (LLMs) for generating functional test scripts, which necessitates understanding the dynamically evolving code structure of the target software. To achieve this, we propose a case-based reasoning (CBR) system utilizing a 4R cycle (i.e., retrieve, reuse, revise, and retain), which maintains and leverages a case bank of test intent descriptions and corresponding test scripts to facilitate LLMs for test script generation. To improve user experience further, we introduce Re4, an optimization method for the CBR system, comprising reranking-based retrieval finetuning and reinforced reuse finetuning. Specifically, we first identify positive examples with high semantic and script similarity, providing reliable pseudo-labels for finetuning the retriever model without costly labeling. Then, we apply supervised finetuning, followed by a reinforcement learning finetuning stage, to align LLMs with our production scenarios, ensuring the faithful reuse of retrieved cases. Extensive experimental results on two product development units from Huawei Datacom demonstrate the superiority of the proposed CBR+Re4. Notably, we also show that the proposed Re4 method can help alleviate the repetitive generation issues with LLMs.","authors":["Siyuan Guo","Huiwu Liu","Xiaolong Chen","Yuming Xie","Liang Zhang","Tao Han","Hechang Chen","Yi Chang","Jun Wang"],"url":"https://arxiv.org/abs/2503.20576"}
{"created":"2025-05-23","title":"HyperGraphRAG: Retrieval-Augmented Generation via Hypergraph-Structured Knowledge Representation","abstract":"Standard Retrieval-Augmented Generation (RAG) relies on chunk-based retrieval, whereas GraphRAG advances this approach by graph-based knowledge representation. However, existing graph-based RAG approaches are constrained by binary relations, as each edge in an ordinary graph connects only two entities, limiting their ability to represent the n-ary relations (n >= 2) in real-world knowledge. In this work, we propose HyperGraphRAG, a novel hypergraph-based RAG method that represents n-ary relational facts via hyperedges, and consists of knowledge hypergraph construction, retrieval, and generation. Experiments across medicine, agriculture, computer science, and law demonstrate that HyperGraphRAG outperforms both standard RAG and previous graph-based RAG methods in answer accuracy, retrieval efficiency, and generation quality.","authors":["Haoran Luo","Haihong E","Guanting Chen","Yandan Zheng","Xiaobao Wu","Yikai Guo","Qika Lin","Yu Feng","Zemin Kuang","Meina Song","Yifan Zhu","Luu Anh Tuan"],"url":"https://arxiv.org/abs/2503.21322"}
{"created":"2025-05-23","title":"Physics-Informed Neural Network-Based Control for Grid-Forming Converter's Stability Under Overload Conditions","abstract":"Grid-forming converters (GFCs) are crucial for frequency and voltage stability in modern power systems. However, their performance under overload conditions remains a challenge. This paper highlights the limitations of existing approaches in managing DC source saturation and AC current limits, emphasizing the need for improved control strategies to ensure system stability. This paper proposes a control strategy based on a physics-informed neural network (PINN) to improve GFC performance under overloaded conditions, effectively preventing switch failures and mitigating DC source saturation. This approach outperforms conventional methods by maintaining stable voltage and frequency, even under significant load increase where traditional droop control alone proves inadequate. The post-disturbance operating point of GFCs remains unchanged using PINN-based control with an improvement of 0.245 Hz in frequency and 0.03 p.u. in active power when compared to an already existing current limitation strategy. Additionally, it reduces peak voltage deviations during transients by 24.14\\%, lowers the rate of change of frequency (ROCOF) from 0.02 Hz/s to 0.005 Hz/s, and improves the rate of change of voltage (ROCOV), keeping both within acceptable limits. These improvements significantly enhance system resilience, especially in inertia-less power networks.","authors":["Abhay Kumar","Dushyant Sharma","Mayukha Pal"],"url":"https://arxiv.org/abs/2503.21529"}
{"created":"2025-05-23","title":"A Hybrid Systems Model of Feedback Optimization for Linear Systems","abstract":"Feedback optimization algorithms compute inputs to a system in real time, which helps mitigate the effects of unknown disturbances. However, existing work models both system dynamics and computations in either discrete or continuous time, which does not faithfully model some applications. In this work, we model linear system dynamics in continuous time, and we model the computations of inputs in discrete time. Therefore, we present a novel hybrid systems framework for modeling feedback optimization of linear time-invariant systems that are subject to unknown, constant disturbances. For this setup, we first establish the well-posedness of the hybrid model and establish completeness of solutions while ruling out Zeno behavior. Then, our main result derives a convergence rate and an error bound for the full hybrid computation-in-theloop system and shows that it converges exponentially towards a ball of known radius about a desired fixed point. Simulation results show that this approach successfully mitigates the effects of disturbances, with the magnitude of steady-state error being 81% less than the magnitude of the disturbances in the system.","authors":["Oscar Jed Chuy","Matthew Hale","Ricardo Sanfelice"],"url":"https://arxiv.org/abs/2504.00321"}
{"created":"2025-05-23","title":"Stroke Disease Classification Using Machine Learning with Feature Selection Techniques","abstract":"Heart disease remains a leading cause of mortality and morbidity worldwide, necessitating the development of accurate and reliable predictive models to facilitate early detection and intervention. While state of the art work has focused on various machine learning approaches for predicting heart disease, but they could not able to achieve remarkable accuracy. In response to this need, we applied nine machine learning algorithms XGBoost, logistic regression, decision tree, random forest, k-nearest neighbors (KNN), support vector machine (SVM), gaussian na\\\"ive bayes (NB gaussian), adaptive boosting, and linear regression to predict heart disease based on a range of physiological indicators. Our approach involved feature selection techniques to identify the most relevant predictors, aimed at refining the models to enhance both performance and interpretability. The models were trained, incorporating processes such as grid search hyperparameter tuning, and cross-validation to minimize overfitting. Additionally, we have developed a novel voting system with feature selection techniques to advance heart disease classification. Furthermore, we have evaluated the models using key performance metrics including accuracy, precision, recall, F1-score, and the area under the receiver operating characteristic curve (ROC AUC). Among the models, XGBoost demonstrated exceptional performance, achieving 99% accuracy, precision, F1-Score, 98% recall, and 100% ROC AUC. This study offers a promising approach to early heart disease diagnosis and preventive healthcare.","authors":["Mahade Hasan","Farhana Yasmin","Xue Yu"],"url":"https://arxiv.org/abs/2504.00485"}
{"created":"2025-05-23","title":"PrediHealth: Telemedicine and Predictive Algorithms for the Care and Prevention of Patients with Chronic Heart Failure","abstract":"The management of chronic heart failure presents significant challenges in modern healthcare, requiring continuous monitoring, early detection of exacerbations, and personalized treatment strategies. This paper presents the preliminary results of the PrediHealth research project conducted in this context. Specifically, it aims to address the challenges above by integrating telemedicine, mobile health solutions, and predictive analytics into a unified digital healthcare platform. We leveraged a web-based IoT platform, a telemonitoring kit with medical devices and environmental sensors, and AI-driven predictive models to support clinical decision-making. The project follows a structured methodology comprising research on emerging CPS/IoT technologies, system prototyping, predictive model development, and empirical validation.","authors":["Pietro Cassieri","Giuseppe De Filippo","Simranjit Singh","Gianpiero Sisto","Marco Mazzotta","Gianvito Mitrano","Claudio Pascarelli","Gianluca Fimiani","Simone Romano","Mariangela Lazoi","Marina Garofano","Alessia Bramanti","Giuseppe Scanniello"],"url":"https://arxiv.org/abs/2504.03737"}
{"created":"2025-05-23","title":"COHESION: Composite Graph Convolutional Network with Dual-Stage Fusion for Multimodal Recommendation","abstract":"Recent works in multimodal recommendations, which leverage diverse modal information to address data sparsity and enhance recommendation accuracy, have garnered considerable interest. Two key processes in multimodal recommendations are modality fusion and representation learning. Previous approaches in modality fusion often employ simplistic attentive or pre-defined strategies at early or late stages, failing to effectively handle irrelevant information among modalities. In representation learning, prior research has constructed heterogeneous and homogeneous graph structures encapsulating user-item, user-user, and item-item relationships to better capture user interests and item profiles. Modality fusion and representation learning were considered as two independent processes in previous work. In this paper, we reveal that these two processes are complementary and can support each other. Specifically, powerful representation learning enhances modality fusion, while effective fusion improves representation quality. Stemming from these two processes, we introduce a COmposite grapH convolutional nEtwork with dual-stage fuSION for the multimodal recommendation, named COHESION. Specifically, it introduces a dual-stage fusion strategy to reduce the impact of irrelevant information, refining all modalities using ID embedding in the early stage and fusing their representations at the late stage. It also proposes a composite graph convolutional network that utilizes user-item, user-user, and item-item graphs to extract heterogeneous and homogeneous latent relationships within users and items. Besides, it introduces a novel adaptive optimization to ensure balanced and reasonable representations across modalities. Extensive experiments on three widely used datasets demonstrate the significant superiority of COHESION over various competitive baselines.","authors":["Jinfeng Xu","Zheyu Chen","Wei Wang","Xiping Hu","Sang-Wook Kim","Edith C. H. Ngai"],"url":"https://arxiv.org/abs/2504.04452"}
{"created":"2025-05-23","title":"Dion: Distributed Orthonormalized Updates","abstract":"Recent work has shown that orthonormal matrix updates speed up neural network optimization, improve training stability, and offer better hyperparameter transfer across model sizes. Applying these updates efficiently when model weights and optimizer states are sharded across a large-scale distributed LLM training system remains a major challenge. We introduce Dion (DIstributed OrthoNormalization), a scalable and communication-efficient orthonormalizing optimizer. Dion leverages low-rank approximation and decoupled momentum buffers, eliminating the need for full gradient synchronization while producing numerically equivalent results. It is compatible with simultaneous DDP, FSDP, and TP parallelism, and it computes an orthonormalized update without unsharding a full parameter matrix on any single device. We evaluate Dion on language models from 120M to 3B parameters and find that its benefits improve with increasing model size and batch size.","authors":["Kwangjun Ahn","Byron Xu","Natalie Abreu","John Langford"],"url":"https://arxiv.org/abs/2504.05295"}
{"created":"2025-05-23","title":"TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning","abstract":"Episodic tasks in Reinforcement Learning (RL) often pose challenges due to sparse reward signals and high-dimensional state spaces, which hinder efficient learning. Additionally, these tasks often feature hidden \"trap states\" -- irreversible failures that prevent task completion but do not provide explicit negative rewards to guide agents away from repeated errors. To address these issues, we propose Time-Weighted Contrastive Reward Learning (TW-CRL), an Inverse Reinforcement Learning (IRL) framework that leverages both successful and failed demonstrations. By incorporating temporal information, TW-CRL learns a dense reward function that identifies critical states associated with success or failure. This approach not only enables agents to avoid trap states but also encourages meaningful exploration beyond simple imitation of expert trajectories. Empirical evaluations on navigation tasks and robotic manipulation benchmarks demonstrate that TW-CRL surpasses state-of-the-art methods, achieving improved efficiency and robustness.","authors":["Yuxuan Li","Yicheng Gao","Ning Yang","Stephen Xia"],"url":"https://arxiv.org/abs/2504.05585"}
{"created":"2025-05-23","title":"Architecture independent generalization bounds for overparametrized deep ReLU networks","abstract":"We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove that the generalization error is independent of the network architecture.","authors":["Thomas Chen","Chun-Kai Kevin Chien","Patricia Mu\\~noz Ewald","Andrew G. Moore"],"url":"https://arxiv.org/abs/2504.05695"}
{"created":"2025-05-23","title":"Linear-space LCS enumeration with quadratic-time delay for two strings","abstract":"Suppose we want to seek the longest common subsequences (LCSs) of two strings as informative patterns that explain the relationship between the strings. The dynamic programming algorithm gives us a table from which all LCSs can be extracted by traceback. However, the need for quadratic space to hold this table can be an obstacle when dealing with long strings. A question that naturally arises in this situation would be whether it is possible to exhaustively search for all LCSs one by one in a time-efficient manner using only a space linear in the LCS length, where we treat read-only memory for storing the strings as excluded from the space consumed. As a part of the answer to this question, we propose an $O(L)$-space algorithm that outputs all distinct LCSs of the strings one by one each in $O(n^2)$ time, where the strings are both of length $n$ and $L$ is the LCS length of the strings.","authors":["Yoshifumi Sakai"],"url":"https://arxiv.org/abs/2504.05742"}
{"created":"2025-05-23","title":"Unifying Search and Recommendation: A Generative Paradigm Inspired by Information Theory","abstract":"Recommender systems and search engines serve as foundational elements of online platforms, with the former delivering information proactively and the latter enabling users to seek information actively. Unifying both tasks in a shared model is promising since it can enhance user modeling and item understanding. Previous approaches mainly follow a discriminative paradigm, utilizing shared encoders to process input features and task-specific heads to perform each task. However, this paradigm encounters two key challenges: gradient conflict and manual design complexity. From the information theory perspective, these challenges potentially both stem from the same issue -- low mutual information between the input features and task-specific outputs during the optimization process.","authors":["Jujia Zhao","Wenjie Wang","Chen Xu","Xiuying Chen","Zhaochun Ren","Suzan Verberne"],"url":"https://arxiv.org/abs/2504.06714"}
{"created":"2025-05-23","title":"TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling","abstract":"Recent efforts target spoken language models (SLMs) that not only listen but also speak for more natural human-LLM interaction. Joint speech-text modeling is a promising direction to achieve this. However, the effectiveness of recent speech tokens for joint modeling remains underexplored. To address this, we introduce Text-Aligned Speech Tokenization and Embedding (TASTE), a method that directly addresses the modality gap by aligning speech token with the corresponding text transcription during the tokenization stage. We propose a method that can achieve this through a attention-based aggregation mechanism and with speech reconstruction as the training objective. We conduct extensive experiments and show that TASTE can preserve essential paralinguistic information while dramatically reducing the token sequence length. With TASTE, we perform straightforward joint spoken language modeling by using Low-Rank Adaptation on the pre-trained text LLM. Experimental results show that TASTE-based SLMs perform comparable to previous work on SALMON and StoryCloze; while significantly outperform other pre-trained SLMs on speech continuation across subjective and objective evaluations. To our knowledge, TASTE is the first end-to-end approach that utilizes a reconstruction objective to automatically learn a text-aligned speech tokenization and embedding suitable for spoken language modeling. Our demo, code, and model are available at https://mtkresearch.github.io/TASTE-SpokenLM.github.io.","authors":["Liang-Hsuan Tseng","Yi-Chang Chen","Kuan-Yi Lee","Da-Shan Shiu","Hung-yi Lee"],"url":"https://arxiv.org/abs/2504.07053"}
{"created":"2025-05-23","title":"DRIP: DRop unImportant data Points -- Enhancing Machine Learning Efficiency with Grad-CAM-Based Real-Time Data Prioritization for On-Device Training","abstract":"Selecting data points for model training is critical in machine learning. Effective selection methods can reduce the labeling effort, optimize on-device training for embedded systems with limited data storage, and enhance the model performance. This paper introduces a novel algorithm that uses Grad-CAM to make online decisions about retaining or discarding data points. Optimized for embedded devices, the algorithm computes a unique DRIP Score to quantify the importance of each data point. This enables dynamic decision-making on whether a data point should be stored for potential retraining or discarded without compromising model performance. Experimental evaluations on four benchmark datasets demonstrate that our approach can match or even surpass the accuracy of models trained on the entire dataset, all while achieving storage savings of up to 39\\%. To our knowledge, this is the first algorithm that makes online decisions about data point retention without requiring access to the entire dataset.","authors":["Marcus R\\\"ub","Daniel Konegen","Patrick Selle","Axel Sikora","Daniel Mueller-Gritschneder"],"url":"https://arxiv.org/abs/2504.08364"}
{"created":"2025-05-23","title":"DynaServe: Unified and Elastic Execution for Dynamic Disaggregated LLM Serving","abstract":"LLM inference must meet strict latency SLOs (e.g., 100 ms P99 time-between-tokens) while maximizing goodput. Yet, real-world variability in prompt and response lengths skews compute-intensive prefill and memory-bound decode phases, making both colocated (even with chunked prefill) and disaggregated deployments unable to simultaneously deliver low tail latency and high throughput.","authors":["Chaoyi Ruan","Yinhe Chen","Dongqi Tian","Yandong Shi","Yongji Wu","Jialin Li","Cheng Li"],"url":"https://arxiv.org/abs/2504.09285"}
{"created":"2025-05-23","title":"Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance","abstract":"Large Language Models (LLMs) have shown remarkable capabilities, but their development has primarily focused on English and other high-resource languages, leaving many languages underserved. We present our latest Hindi-English bi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark scores over both languages, outperforming models twice its size. Using a curated dataset composed of English and Hindi instruction data of 485K samples, we instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve performance over both English and Hindi. Our experiments encompassing seven different LLMs of varying parameter sizes and over 140 training attempts with varying English-Hindi training data ratios demonstrated that it is possible to significantly improve multilingual performance without compromising native performance. Further, our approach avoids resource-intensive techniques like vocabulary expansion or architectural modifications, thus keeping the model size small. Our results indicate that modest fine-tuning with culturally and locally informed data can bridge performance gaps without incurring significant computational overhead. We release our training code, datasets, and models under mit and apache licenses to aid further research towards under-represented and low-resource languages.","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Siddhant Gupta","Drishti Sharma","Jebish Purbey","Kanwal Mehreen","Muhammad Arham","Hamza Farooq"],"url":"https://arxiv.org/abs/2504.09753"}
{"created":"2025-05-23","title":"Hallucination Detection in LLMs with Topological Divergence on Attention Graphs","abstract":"Hallucination, i.e., generating factually incorrect content, remains a critical challenge for large language models (LLMs). We introduce TOHA, a TOpology-based HAllucination detector in the RAG setting, which leverages a topological divergence metric to quantify the structural properties of graphs induced by attention matrices. Examining the topological divergence between prompt and response subgraphs reveals consistent patterns: higher divergence values in specific attention heads correlate with hallucinated outputs, independent of the dataset. Extensive experiments - including evaluation on question answering and summarization tasks - show that our approach achieves state-of-the-art or competitive results on several benchmarks while requiring minimal annotated data and computational resources. Our findings suggest that analyzing the topological structure of attention matrices can serve as an efficient and robust indicator of factual reliability in LLMs.","authors":["Alexandra Bazarova","Aleksandr Yugay","Andrey Shulga","Alina Ermilova","Andrei Volodichev","Konstantin Polev","Julia Belikova","Rauf Parchiev","Dmitry Simakov","Maxim Savchenko","Andrey Savchenko","Serguei Barannikov","Alexey Zaytsev"],"url":"https://arxiv.org/abs/2504.10063"}
{"created":"2025-05-23","title":"Energy Matching: Unifying Flow Matching and Energy-Based Models for Generative Modeling","abstract":"The most widely used generative models map noise and data distributions by matching flows or scores. However, they struggle to incorporate partial observations and additional priors--something energy-based models (EBMs) handle elegantly by simply adding corresponding scalar energy terms. We address this issue by proposing Energy Matching, a framework that endows flow-based approaches with the flexibility of EBMs. Far from the data manifold, samples move along curl-free, optimal transport paths from noise to data. As they approach the data manifold, an entropic energy term guides the system into a Boltzmann equilibrium distribution, explicitly capturing the underlying likelihood structure of the data. We parameterize this dynamic with a single time-independent scalar field, which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems. Our method substantially outperforms existing EBMs on CIFAR-10 and ImageNet generation in terms of fidelity, while retaining simulation-free training of transport-based approaches away from the data manifold. Furthermore, we leverage the method's flexibility to introduce an interaction energy that supports diverse mode exploration, which we demonstrate in a controlled protein-generation setting. Our approach focuses on learning a scalar potential energy--without time-conditioning, auxiliary generators, or additional networks--which marks a significant departure from recent EBM methods. We believe that this simplified framework significantly advances EBMs capabilities and paves the way for their wider adoption in generative modeling across diverse domains.","authors":["Michal Balcerak","Tamaz Amiranashvili","Antonio Terpin","Suprosanna Shit","Lea Bogensperger","Sebastian Kaltenbach","Petros Koumoutsakos","Bjoern Menze"],"url":"https://arxiv.org/abs/2504.10612"}
{"created":"2025-05-23","title":"Harnessing the Computation Redundancy in ViTs to Boost Adversarial Transferability","abstract":"Vision Transformers (ViTs) have demonstrated impressive performance across a range of applications, including many safety-critical tasks. However, their unique architectural properties raise new challenges and opportunities in adversarial robustness. In particular, we observe that adversarial examples crafted on ViTs exhibit higher transferability compared to those crafted on CNNs, suggesting that ViTs contain structural characteristics favorable for transferable attacks. In this work, we investigate the role of computational redundancy in ViTs and its impact on adversarial transferability. Unlike prior studies that aim to reduce computation for efficiency, we propose to exploit this redundancy to improve the quality and transferability of adversarial examples. Through a detailed analysis, we identify two forms of redundancy, including the data-level and model-level, that can be harnessed to amplify attack effectiveness. Building on this insight, we design a suite of techniques, including attention sparsity manipulation, attention head permutation, clean token regularization, ghost MoE diversification, and test-time adversarial training. Extensive experiments on the ImageNet-1k dataset validate the effectiveness of our approach, showing that our methods significantly outperform existing baselines in both transferability and generality across diverse model architectures.","authors":["Jiani Liu","Zhiyuan Wang","Zeliang Zhang","Chao Huang","Susan Liang","Yunlong Tang","Chenliang Xu"],"url":"https://arxiv.org/abs/2504.10804"}
{"created":"2025-05-23","title":"Maximum bound principle for Q-tensor gradient flow with low regularity integrators","abstract":"We investigate low-regularity integrator (LRI) methods for the Q-tensor model governing nematic liquid-crystalline semilinear parabolic equation. First- and second-order temporal discretizations are developed using Duhamel's formula, and we rigorously prove that both schemes preserve the maximum bound principle (MBP) and energy dissipation under minimal regularity requirements. Optimal convergence rates are established for the proposed methods. Numerical experiments validate the theoretical findings, demonstrating that the eigenvalues of Q remain strictly confined within the physical range (-1/3},2/3).","authors":["Wenshuai Hu","Guanghua Ji"],"url":"https://arxiv.org/abs/2504.11676"}
{"created":"2025-05-23","title":"Robust and Fine-Grained Detection of AI Generated Texts","abstract":"An ideal detection system for machine generated content is supposed to work well on any generator as many more advanced LLMs come into existence day by day. Existing systems often struggle with accurately identifying AI-generated content over shorter texts. Further, not all texts might be entirely authored by a human or LLM, hence we focused more over partial cases i.e human-LLM co-authored texts. Our paper introduces a set of models built for the task of token classification which are trained on an extensive collection of human-machine co-authored texts, which performed well over texts of unseen domains, unseen generators, texts by non-native speakers and those with adversarial inputs. We also introduce a new dataset of over 2.4M such texts mostly co-authored by several popular proprietary LLMs over 23 languages. We also present findings of our models' performance over each texts of each domain and generator. Additional findings include comparison of performance against each adversarial method, length of input texts and characteristics of generated texts compared to the original human authored texts.","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Kanwal Mehreen","Drishti Sharma","Siddhant Gupta","Jebish Purbey","Ashay Srivastava","Subhasya TippaReddy","Arvind Reddy Bobbili","Suraj Telugara Chandrashekhar","Modabbir Adeeb","Srinadh Vura","Hamza Farooq"],"url":"https://arxiv.org/abs/2504.11952"}
{"created":"2025-05-23","title":"Branching Bisimulation Learning","abstract":"We introduce a bisimulation learning algorithm for non-deterministic transition systems. We generalise bisimulation learning to systems with bounded branching and extend its applicability to model checking branching-time temporal logic, while previously it was limited to deterministic systems and model checking linear-time properties. Our method computes a finite stutter-insensitive bisimulation quotient of the system under analysis, represented as a decision tree. We adapt the proof rule for well-founded bisimulations to an iterative procedure that trains candidate decision trees from sample transitions of the system, and checks their validity over the entire transition relation using SMT solving. This results in a new technology for model checking CTL* without the next-time operator. Our technique is sound, entirely automated, and yields abstractions that are succinct and effective for formal verification and system diagnostics. We demonstrate the efficacy of our method on diverse benchmarks comprising concurrent software, communication protocols and robotic scenarios. Our method performs comparably to mature tools in the special case of LTL model checking, and outperforms the state of the art in CTL and CTL* model checking for systems with very large and countably infinite state space.","authors":["Alessandro Abate","Mirco Giacobbe","Christian Micheletti","Yannik Schnitzer"],"url":"https://arxiv.org/abs/2504.12246"}
{"created":"2025-05-23","title":"SMARTe: Slot-based Method for Accountable Relational Triple extraction","abstract":"Relational Triple Extraction (RTE) is a fundamental task in Natural Language Processing (NLP). However, prior research has primarily focused on optimizing model performance, with limited efforts to understand the internal mechanisms driving these models. Many existing methods rely on complex preprocessing to induce specific interactions, often resulting in opaque systems that may not fully align with their theoretical foundations. To address these limitations, we propose SMARTe: a Slot-based Method for Accountable Relational Triple extraction. SMARTe introduces intrinsic interpretability through a slot attention mechanism and frames the task as a set prediction problem. Slot attention consolidates relevant information into distinct slots, ensuring all predictions can be explicitly traced to learned slot representations and the tokens contributing to each predicted relational triple. While emphasizing interpretability, SMARTe achieves performance comparable to state-of-the-art models. Evaluations on the NYT and WebNLG datasets demonstrate that adding interpretability does not compromise performance. Furthermore, we conducted qualitative assessments to showcase the explanations provided by SMARTe, using attention heatmaps that map to their respective tokens. We conclude with a discussion of our findings and propose directions for future research.","authors":["Xue Wen Tan","Stanley Kok"],"url":"https://arxiv.org/abs/2504.12816"}
{"created":"2025-05-23","title":"QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?","abstract":"Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \\textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.","authors":["Zhouyang Jiang","Bin Zhang","Airong Wei","Zhiwei Xu"],"url":"https://arxiv.org/abs/2504.12961"}
{"created":"2025-05-23","title":"Complexity at Scale: A Quantitative Analysis of an Alibaba Microservice Deployment","abstract":"Recent studies have begun to explore the characteristics of real-world large-scale microservice deployments. However, their operational complexities, and the degree to which these complexities are consistent across different deployments, remains under explored. In this paper, we analyse a microservice deployment dataset released by Alibaba to understand its scale, heterogeneity, and dynamicity, and compare our results to previous large-scale deployments to begin to understand their commonalities. We identify tens of thousands of microservices, that support an even broader array of front-end functionality. Moreover, our analysis shows wide-spread long-tailed distributions of characteristics between microservices, such as share of workload and dependencies, highlighting inequality. This diversity is also reflected in call graphs, with front-end service functionalities producing dominant and rarer, non-dominant, call graphs that can involve dissimilar microservice calls. We find that dependencies within the deployment at runtime can be different from the static view of the system, and that the deployment undergoes daily changes. We discuss the implications of our findings for state-of-the-art research in microservice management and research testbed realism.","authors":["Giles Winchester","George Parisis","Guoyao Xu","Luc Berthouze"],"url":"https://arxiv.org/abs/2504.13141"}
{"created":"2025-05-23","title":"Supervising 3D Talking Head Avatars with Analysis-by-Audio-Synthesis","abstract":"In order to be widely applicable, speech-driven 3D head avatars must articulate their lips in accordance with speech, while also conveying the appropriate emotions with dynamically changing facial expressions. The key problem is that deterministic models produce high-quality lip-sync but without rich expressions, whereas stochastic models generate diverse expressions but with lower lip-sync quality. To get the best of both, we seek a stochastic model with accurate lip-sync. To that end, we develop a new approach based on the following observation: if a method generates realistic 3D lip motions, it should be possible to infer the spoken audio from the lip motion. The inferred speech should match the original input audio, and erroneous predictions create a novel supervision signal for training 3D talking head avatars with accurate lip-sync. To demonstrate this effect, we propose THUNDER (Talking Heads Under Neural Differentiable Elocution Reconstruction), a 3D talking head avatar framework that introduces a novel supervision mechanism via differentiable sound production. First, we train a novel mesh-to-speech model that regresses audio from facial animation. Then, we incorporate this model into a diffusion-based talking avatar framework. During training, the mesh-to-speech model takes the generated animation and produces a sound that is compared to the input speech, creating a differentiable analysis-by-audio-synthesis supervision loop. Our extensive qualitative and quantitative experiments demonstrate that THUNDER significantly improves the quality of the lip-sync of talking head avatars while still allowing for generation of diverse, high-quality, expressive facial animations. The code and models will be available at https://thunder.is.tue.mpg.de/","authors":["Radek Dan\\v{e}\\v{c}ek","Carolin Schmitt","Senya Polikovsky","Michael J. Black"],"url":"https://arxiv.org/abs/2504.13386"}
{"created":"2025-05-23","title":"Learning Joint ID-Textual Representation for ID-Preserving Image Synthesis","abstract":"We propose a novel framework for ID-preserving generation using a multi-modal encoding strategy rather than injecting identity features via adapters into pre-trained models. Our method treats identity and text as a unified conditioning input. To achieve this, we introduce FaceCLIP, a multi-modal encoder that learns a joint embedding space for both identity and textual semantics. Given a reference face and a text prompt, FaceCLIP produces a unified representation that encodes both identity and text, which conditions a base diffusion model to generate images that are identity-consistent and text-aligned. We also present a multi-modal alignment algorithm to train FaceCLIP, using a loss that aligns its joint representation with face, text, and image embedding spaces. We then build FaceCLIP-SDXL, an ID-preserving image synthesis pipeline by integrating FaceCLIP with Stable Diffusion XL (SDXL). Compared to prior methods, FaceCLIP-SDXL enables photorealistic portrait generation with better identity preservation and textual relevance. Extensive experiments demonstrate its quantitative and qualitative superiority.","authors":["Zichuan Liu","Liming Jiang","Qing Yan","Yumin Jia","Hao Kang","Xin Lu"],"url":"https://arxiv.org/abs/2504.14202"}
{"created":"2025-05-23","title":"How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?","abstract":"Publicly available biomedical videos, such as those on YouTube, serve as valuable educational resources for medical students. Unlike standard machine learning datasets, these videos are designed for human learners, often mixing medical imagery with narration, explanatory diagrams, and contextual framing. In this work, we investigate whether such pedagogically rich, yet non-standardized and heterogeneous videos can effectively teach general-domain vision-language models biomedical knowledge. To this end, we introduce OpenBiomedVi, a biomedical video instruction tuning dataset comprising 1031 hours of video-caption and Q/A pairs, curated through a multi-step human-in-the-loop pipeline. Diverse biomedical video datasets are rare, and OpenBiomedVid fills an important gap by providing instruction-style supervision grounded in real-world educational content. Surprisingly, despite the informal and heterogeneous nature of these videos, the fine-tuned Qwen-2-VL models exhibit substantial performance improvements across most benchmarks. The 2B model achieves gains of 98.7% on video tasks, 71.2% on image tasks, and 0.2% on text tasks. The 7B model shows improvements of 37.09% on video and 11.2% on image tasks, with a slight degradation of 2.7% on text tasks compared to their respective base models. To address the lack of standardized biomedical video evaluation datasets, we also introduce two new expert curated benchmarks, MIMICEchoQA and SurgeryVideoQA. On these benchmarks, the 2B model achieves gains of 99.1% and 98.1%, while the 7B model shows gains of 22.5% and 52.1%, respectively, demonstrating the models' ability to generalize and perform biomedical video understanding on cleaner and more standardized datasets than those seen during training. These results suggest that educational videos created for human learning offer a surprisingly effective training signal for biomedical VLMs.","authors":["Rahul Thapa","Andrew Li","Qingyang Wu","Bryan He","Yuki Sahashi","Christina Binder","Angela Zhang","Ben Athiwaratkun","Shuaiwen Leon Song","David Ouyang","James Zou"],"url":"https://arxiv.org/abs/2504.14391"}
{"created":"2025-05-23","title":"Relation-R1: Progressively Cognitive Chain-of-Thought Guided Reinforcement Learning for Unified Relation Comprehension","abstract":"Recent advances in multi-modal large language models (MLLMs) have significantly improved object-level grounding and region captioning. However, they remain limited in visual relation understanding, struggling even with binary relation detection, let alone \\textit{N}-ary relations involving multiple semantic roles. The core reason is the lack of modeling for \\textit{structural semantic dependencies} among multi-entities, leading to unreliable outputs, hallucinations, and over-reliance on language priors (\\eg, defaulting to ``person drinks a milk'' if a person is merely holding it). To this end, we propose Relation-R1, the \\textit{first unified} relation comprehension framework that explicitly integrates cognitive chain-of-thought (CoT)-guided supervised fine-tuning (SFT) and group relative policy optimization (GRPO) within a reinforcement learning (RL) paradigm. Specifically, we first establish foundational reasoning capabilities via SFT, enforcing structured outputs with thinking processes. Then, GRPO is utilized to refine these outputs via multi-rewards optimization, prioritizing visual-semantic grounding over language-induced biases, thereby improving generalization capability. Furthermore, we investigate the impact of various CoT strategies within this framework, demonstrating that a specific-to-general progressive approach in CoT guidance further improves generalization, especially in capturing synonymous \\textit{N}-ary relations. Extensive experiments on widely-used PSG and SWiG datasets demonstrate that Relation-R1 achieves state-of-the-art performance in both binary and \\textit{N}-ary relation understanding.","authors":["Lin Li","Wei Chen","Jiahui Li","Kwang-Ting Cheng","Long Chen"],"url":"https://arxiv.org/abs/2504.14642"}
{"created":"2025-05-23","title":"DC4CR: When Cloud Removal Meets Diffusion Control in Remote Sensing","abstract":"Cloud occlusion significantly hinders remote sensing applications by obstructing surface information and complicating analysis. To address this, we propose DC4CR (Diffusion Control for Cloud Removal), a novel multimodal diffusion-based framework for cloud removal in remote sensing imagery. Our method introduces prompt-driven control, allowing selective removal of thin and thick clouds without relying on pre-generated cloud masks, thereby enhancing preprocessing efficiency and model adaptability. Additionally, we integrate low-rank adaptation for computational efficiency, subject-driven generation for improved generalization, and grouped learning to enhance performance on small datasets. Designed as a plug-and-play module, DC4CR seamlessly integrates into existing cloud removal models, providing a scalable and robust solution. Extensive experiments on the RICE and CUHK-CR datasets demonstrate state-of-the-art performance, achieving superior cloud removal across diverse conditions. This work presents a practical and efficient approach for remote sensing image processing with broad real-world applications.","authors":["Zhenyu Yu","Mohd Yamani Idna Idris","Pei Wang"],"url":"https://arxiv.org/abs/2504.14785"}
{"created":"2025-05-23","title":"TWIG: Two-Step Image Generation using Segmentation Masks in Diffusion Models","abstract":"In today's age of social media and marketing, copyright issues can be a major roadblock to the free sharing of images. Generative AI models have made it possible to create high-quality images, but concerns about copyright infringement are a hindrance to their abundant use. As these models use data from training images to generate new ones, it is often a daunting task to ensure they do not violate intellectual property rights. Some AI models have even been noted to directly copy copyrighted images, a problem often referred to as source copying. Traditional copyright protection measures such as watermarks and metadata have also proven to be futile in this regard. To address this issue, we propose a novel two-step image generation model inspired by the conditional diffusion model. The first step involves creating an image segmentation mask for some prompt-based generated images. This mask embodies the shape of the image. Thereafter, the diffusion model is asked to generate the image anew while avoiding the shape in question. This approach shows a decrease in structural similarity from the training image, i.e. we are able to avoid the source copying problem using this approach without expensive retraining of the model or user-centered prompt generation techniques. This makes our approach the most computationally inexpensive approach to avoiding both copyright infringement and source copying for diffusion model-based image generation.","authors":["Mazharul Islam Rakib","Showrin Rahman","Joyanta Jyoti Mondal","Xi Xiao","David Lewis","Alessandra Mileo","Meem Arafat Manab"],"url":"https://arxiv.org/abs/2504.14933"}
{"created":"2025-05-23","title":"Evaluating Judges as Evaluators: The JETTS Benchmark of LLM-as-Judges as Test-Time Scaling Evaluators","abstract":"Scaling test-time computation, or affording a generator large language model (LLM) extra compute during inference, typically employs the help of external non-generative evaluators (i.e., reward models). Concurrently, LLM-judges, models trained to generate evaluations and critiques (explanations) in natural language, are becoming increasingly popular in automatic evaluation. Despite judge empirical successes, their effectiveness as evaluators in test-time scaling settings is largely unknown. In this paper, we introduce the Judge Evaluation for Test-Time Scaling (JETTS) benchmark, which evaluates judge performance in three domains (math reasoning, code generation, and instruction following) under three task settings: response reranking, step-level beam search, and critique-based response refinement. We evaluate 10 different judge models (7B-70B parameters) for 8 different base generator models (6.7B-72B parameters). Our benchmark shows that while judges are competitive with outcome reward models in reranking, they are consistently worse than process reward models in beam search procedures. Furthermore, though unique to LLM-judges, their natural language critiques are currently ineffective in guiding the generator towards better responses.","authors":["Yilun Zhou","Austin Xu","Peifeng Wang","Caiming Xiong","Shafiq Joty"],"url":"https://arxiv.org/abs/2504.15253"}
{"created":"2025-05-23","title":"ORION Grounded in Context: Retrieval-Based Method for Hallucination Detection","abstract":"Despite advancements in grounded content generation, production Large Language Models (LLMs) based applications still suffer from hallucinated answers. We present \"Grounded in Context\" - a member of Deepchecks' ORION (Output Reasoning-based InspectiON) family of lightweight evaluation models. It is our framework for hallucination detection, designed for production-scale long-context data and tailored to diverse use cases, including summarization, data extraction, and RAG. Inspired by RAG architecture, our method integrates retrieval and Natural Language Inference (NLI) models to predict factual consistency between premises and hypotheses using an encoder-based model with only a 512-token context window. Our framework identifies unsupported claims with an F1 score of 0.83 in RAGTruth's response-level classification task, matching methods that trained on the dataset, and outperforming all comparable frameworks using similar-sized models.","authors":["Assaf Gerner","Netta Madvil","Nadav Barak","Alex Zaikman","Jonatan Liberman","Liron Hamra","Rotem Brazilay","Shay Tsadok","Yaron Friedman","Neal Harow","Noam Bressler","Shir Chorev","Philip Tannor"],"url":"https://arxiv.org/abs/2504.15771"}
{"created":"2025-05-23","title":"TTRL: Test-Time Reinforcement Learning","abstract":"This paper investigates Reinforcement Learning (RL) on data without explicit labels for reasoning tasks in Large Language Models (LLMs). The core challenge of the problem is reward estimation during inference while not having access to ground-truth information. While this setting appears elusive, we find that common practices in Test-Time Scaling (TTS), such as majority voting, yield surprisingly effective rewards suitable for driving RL training. In this work, we introduce Test-Time Reinforcement Learning (TTRL), a novel method for training LLMs using RL on unlabeled data. TTRL enables self-evolution of LLMs by utilizing the priors in the pre-trained models. Our experiments demonstrate that TTRL consistently improves performance across a variety of tasks and models. Notably, TTRL boosts the pass@1 performance of Qwen-2.5-Math-7B by approximately 211% on the AIME 2024 with only unlabeled test data. Furthermore, although TTRL is only supervised by the maj@n metric, TTRL has demonstrated performance to consistently surpass the upper limit of the initial model maj@n, and approach the performance of models trained directly on test data with ground-truth labels. Our experimental findings validate the general effectiveness of TTRL across various tasks and highlight TTRL's potential for broader tasks and domains. GitHub: https://github.com/PRIME-RL/TTRL","authors":["Yuxin Zuo","Kaiyan Zhang","Li Sheng","Shang Qu","Ganqu Cui","Xuekai Zhu","Haozhan Li","Yuchen Zhang","Xinwei Long","Ermo Hua","Biqing Qi","Youbang Sun","Zhiyuan Ma","Lifan Yuan","Ning Ding","Bowen Zhou"],"url":"https://arxiv.org/abs/2504.16084"}
{"created":"2025-05-23","title":"Persistence-based Hough Transform for Line Detection","abstract":"The Hough transform is a popular and classical technique in computer vision for the detection of lines (or more general objects). It maps a pixel into a dual space -- the Hough space: each pixel is mapped to the set of lines through this pixel, which forms a curve in Hough space. The detection of lines then becomes a voting process to find those lines that received many votes by pixels. However, this voting is done by thresholding, which is susceptible to noise and other artifacts.","authors":["Johannes Ferner","Stefan Huber","Saverio Messineo","Angel Pop","Martin Uray"],"url":"https://arxiv.org/abs/2504.16114"}
{"created":"2025-05-23","title":"Privacy-Preserving Personalized Federated Learning for Distributed Photovoltaic Disaggregation under Statistical Heterogeneity","abstract":"The rapid expansion of distributed photovoltaic (PV) installations worldwide, many being behind-the-meter systems, has significantly challenged energy management and grid operations, as unobservable PV generation further complicates the supply-demand balance. Therefore, estimating this generation from net load, known as PV disaggregation, is critical. Given privacy concerns and the need for large training datasets, federated learning becomes a promising approach, but statistical heterogeneity, arising from geographical and behavioral variations among prosumers, poses new challenges to PV disaggregation. To overcome these challenges, a privacy-preserving distributed PV disaggregation framework is proposed using Personalized Federated Learning (PFL). The proposed method employs a two-level framework that combines local and global modeling. At the local level, a transformer-based PV disaggregation model is designed to generate solar irradiance embeddings for representing local PV conditions. A novel adaptive local aggregation mechanism is adopted to mitigate the impact of statistical heterogeneity on the local model, extracting a portion of global information that benefits the local model. At the global level, a central server aggregates information uploaded from multiple data centers, preserving privacy while enabling cross-center knowledge sharing. Experiments on real-world data demonstrate the effectiveness of this proposed framework, showing improved accuracy and robustness compared to benchmark methods.","authors":["Xiaolu Chen","Chenghao Huang","Yanru Zhang","Hao Wang"],"url":"https://arxiv.org/abs/2504.18078"}
{"created":"2025-05-23","title":"APE-Bench I: Towards File-level Automated Proof Engineering of Formal Math Libraries","abstract":"Recent progress in large language models (LLMs) has shown promise in formal theorem proving, yet existing benchmarks remain limited to isolated, static proof tasks, failing to capture the iterative, engineering-intensive workflows of real-world formal mathematics libraries. Motivated by analogous advances in software engineering, we introduce the paradigm of Automated Proof Engineering (APE), which aims to automate proof engineering tasks such as feature addition, proof refactoring, and bug fixing using LLMs. To facilitate research in this direction, we present APE-Bench I, the first realistic benchmark built from real-world commit histories of Mathlib4, featuring diverse file-level tasks described in natural language and verified via a hybrid approach combining the Lean compiler and LLM-as-a-Judge. We further develop Eleanstic, a scalable parallel verification infrastructure optimized for proof checking across multiple versions of Mathlib. Empirical results on state-of-the-art LLMs demonstrate strong performance on localized edits but substantial degradation on handling complex proof engineering. This work lays the foundation for developing agentic workflows in proof engineering, with future benchmarks targeting multi-file coordination, project-scale verification, and autonomous agents capable of planning, editing, and repairing formal libraries.","authors":["Huajian Xin","Luming Li","Xiaoran Jin","Jacques Fleuriot","Wenda Li"],"url":"https://arxiv.org/abs/2504.19110"}
{"created":"2025-05-23","title":"Spark: A System for Scientifically Creative Idea Generation","abstract":"Recently, large language models (LLMs) have shown promising abilities to generate novel research ideas in science, a direction which coincides with many foundational principles in computational creativity (CC). In light of these developments, we present an idea generation system named Spark that couples retrieval-augmented idea generation using LLMs with a reviewer model named Judge trained on 600K scientific reviews from OpenReview. Our work is both a system demonstration and intended to inspire other CC researchers to explore grounding the generation and evaluation of scientific ideas within foundational CC principles. To this end, we release the annotated dataset used to train Judge, inviting other researchers to explore the use of LLMs for idea generation and creative evaluations.","authors":["Aishik Sanyal","Samuel Schapiro","Sumuk Shashidhar","Royce Moon","Lav R. Varshney","Dilek Hakkani-Tur"],"url":"https://arxiv.org/abs/2504.20090"}
{"created":"2025-05-23","title":"How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues","abstract":"The growing adoption of synthetic data in healthcare is driven by privacy concerns, limited access to real-world data, and the high cost of annotation. This work explores the use of synthetic Prolonged Exposure (PE) therapeutic conversations for Post-Traumatic Stress Disorder (PTSD) as a scalable alternative for training and evaluating clinical models. We systematically compare real and synthetic dialogues using linguistic, structural, and protocol-specific metrics, including turn-taking patterns and treatment fidelity. We also introduce and evaluate PE-specific metrics derived from linguistic analysis and semantic modeling, offering a novel framework for assessing clinical fidelity beyond surface fluency. Our findings show that although synthetic data holds promise for mitigating data scarcity and protecting patient privacy, it can struggle to capture the subtle dynamics of therapeutic interactions. Synthetic therapy dialogues closely match structural features of real-world conversations (e.g., speaker switch ratio: 0.98 vs. 0.99); however, they may not adequately reflect key fidelity markers (e.g., distress monitoring). We highlight gaps in existing evaluation frameworks and advocate for fidelity-aware metrics that go beyond surface fluency to uncover clinically significant failures. Our findings clarify where synthetic data can effectively complement real-world datasets -- and where critical limitations remain.","authors":["Suhas BN","Dominik Mattioli","Saeed Abdullah","Rosa I. Arriaga","Chris W. Wiese","Andrew M. Sherrill"],"url":"https://arxiv.org/abs/2504.21800"}
{"created":"2025-05-23","title":"GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling","abstract":"The rapid advancement of multimodal large language models (MLLMs) has profoundly impacted the document domain, creating a wide array of application scenarios. This progress highlights the need for a comprehensive benchmark to evaluate these models' capabilities across various document-specific tasks. However, existing benchmarks often fail to locate specific model weaknesses or guide systematic improvements. To bridge this gap, we introduce a General Document Intelligence Benchmark (GDI-Bench), featuring 2.3k images across 9 key scenarios and 19 document-specific tasks. By decoupling visual complexity and reasoning complexity, the GDI-Bench structures graded tasks that allow performance assessment by difficulty, aiding in model weakness identification and optimization guidance. We evaluate various open-source and closed-source models on GDI-Bench, conducting decoupled analyses in the visual and reasoning domains, revealing their strengths and weaknesses. To address the diverse tasks and domains in the GDI-Bench, we propose a GDI-Model that mitigates catastrophic forgetting during the supervised fine-tuning (SFT) process through an intelligence-preserving training strategy, thereby reinforcing the inherent weaknesses of the base model. Our model achieves state-of-the-art performance on previous benchmarks and the GDI-Bench. Both our benchmark and models are or will be open-sourced on https://huggingface.co/GDIBench.","authors":["Siqi Li","Yufan Shen","Xiangnan Chen","Jiayi Chen","Hengwei Ju","Haodong Duan","Song Mao","Hongbin Zhou","Bo Zhang","Bin Fu","Pinlong Cai","Licheng Wen","Botian Shi","Yong Liu","Xinyu Cai","Yu Qiao"],"url":"https://arxiv.org/abs/2505.00063"}
{"created":"2025-05-23","title":"Adaptive Thinking via Mode Policy Optimization for Social Language Agents","abstract":"Effective social intelligence simulation requires language agents to dynamically adjust reasoning depth, a capability notably absent in current studies. Existing methods either lack this kind of reasoning capability or enforce Long Chain-of-Thought reasoning uniformly across all scenarios, resulting in excessive token usage and inflexible social simulation. To address this, we propose an $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{L}$earning ($\\textbf{AML}$) framework in this paper, aiming to improve the adaptive thinking ability of language agents in dynamic social interactions. To this end, we first identify hierarchical thinking modes ranging from intuitive response to deep deliberation based on the cognitive control theory. We then develop the $\\textbf{A}$daptive $\\textbf{M}$ode $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{AMPO}$) algorithm to optimize the context-aware mode switching and reasoning. Our framework advances existing research in three key aspects: (1) Multi-granular thinking mode design, (2) Context-aware mode switching across social interaction, and (3) Token-efficient reasoning via depth-adaptive processing. Extensive experiments on social intelligence benchmarks verify that AML achieves 15.6% higher task performance than GPT-4o. Notably, our AMPO outperforms GRPO by 7.0% with 32.8% shorter reasoning chains, demonstrating the advantage of adaptive thinking mode selection and optimization mechanism in AMPO over GRPO's fixed-depth solution.","authors":["Minzheng Wang","Yongbin Li","Haobo Wang","Xinghua Zhang","Nan Xu","Bingli Wu","Fei Huang","Haiyang Yu","Wenji Mao"],"url":"https://arxiv.org/abs/2505.02156"}
{"created":"2025-05-23","title":"Identifying Legal Holdings with LLMs: A Systematic Study of Performance, Scale, and Memorization","abstract":"As large language models (LLMs) continue to advance in capabilities, it is essential to assess how they perform on established benchmarks. In this study, we present a suite of experiments to assess the performance of modern LLMs (ranging from 3B to 90B+ parameters) on CaseHOLD, a legal benchmark dataset for identifying case holdings. Our experiments demonstrate ``scaling effects'' - performance on this task improves with model size, with more capable models like GPT4o and AmazonNovaPro achieving macro F1 scores of 0.744 and 0.720 respectively. These scores are competitive with the best published results on this dataset, and do not require any technically sophisticated model training, fine-tuning or few-shot prompting. To ensure that these strong results are not due to memorization of judicial opinions contained in the training data, we develop and utilize a novel citation anonymization test that preserves semantic meaning while ensuring case names and citations are fictitious. Models maintain strong performance under these conditions (macro F1 of 0.728), suggesting the performance is not due to rote memorization. These findings demonstrate both the promise and current limitations of LLMs for legal tasks with important implications for the development and measurement of automated legal analytics and legal benchmarks.","authors":["Chuck Arvin"],"url":"https://arxiv.org/abs/2505.02172"}
{"created":"2025-05-23","title":"An End-to-End Model For Logits Based Large Language Models Watermarking","abstract":"The rise of LLMs has increased concerns over source tracing and copyright protection for AIGC, highlighting the need for advanced detection technologies. Passive detection methods usually face high false positives, while active watermarking techniques using logits or sampling manipulation offer more effective protection. Existing LLM watermarking methods, though effective on unaltered content, suffer significant performance drops when the text is modified and could introduce biases that degrade LLM performance in downstream tasks. These methods fail to achieve an optimal tradeoff between text quality and robustness, particularly due to the lack of end-to-end optimization of the encoder and decoder. In this paper, we introduce a novel end-to-end logits perturbation method for watermarking LLM-generated text. By jointly optimization, our approach achieves a better balance between quality and robustness. To address non-differentiable operations in the end-to-end training pipeline, we introduce an online prompting technique that leverages the on-the-fly LLM as a differentiable surrogate. Our method achieves superior robustness, outperforming distortion-free methods by 37-39% under paraphrasing and 17.2% on average, while maintaining text quality on par with these distortion-free methods in terms of text perplexity and downstream tasks. Our method can be easily generalized to different LLMs. Code is available at https://github.com/KAHIMWONG/E2E_LLM_WM.","authors":["Kahim Wong","Jicheng Zhou","Jiantao Zhou","Yain-Whar Si"],"url":"https://arxiv.org/abs/2505.02344"}
{"created":"2025-05-23","title":"A New Approach to Backtracking Counterfactual Explanations: A Unified Causal Framework for Efficient Model Interpretability","abstract":"Counterfactual explanations enhance interpretability by identifying alternative inputs that produce different outputs, offering localized insights into model decisions. However, traditional methods often neglect causal relationships, leading to unrealistic examples. While newer approaches integrate causality, they are computationally expensive. To address these challenges, we propose an efficient method called BRACE based on backtracking counterfactuals that incorporates causal reasoning to generate actionable explanations. We first examine the limitations of existing methods and then introduce our novel approach and its features. We also explore the relationship between our method and previous techniques, demonstrating that it generalizes them in specific scenarios. Finally, experiments show that our method provides deeper insights into model outputs.","authors":["Pouria Fatemi","Ehsan Sharifian","Mohammad Hossein Yassaee"],"url":"https://arxiv.org/abs/2505.02435"}
{"created":"2025-05-23","title":"Unified Multimodal Understanding and Generation Models: Advances, Challenges, and Opportunities","abstract":"Recent years have seen remarkable progress in both multimodal understanding models and image generation models. Despite their respective successes, these two domains have evolved independently, leading to distinct architectural paradigms: While autoregressive-based architectures have dominated multimodal understanding, diffusion-based models have become the cornerstone of image generation. Recently, there has been growing interest in developing unified frameworks that integrate these tasks. The emergence of GPT-4o's new capabilities exemplifies this trend, highlighting the potential for unification. However, the architectural differences between the two domains pose significant challenges. To provide a clear overview of current efforts toward unification, we present a comprehensive survey aimed at guiding future research. First, we introduce the foundational concepts and recent advancements in multimodal understanding and text-to-image generation models. Next, we review existing unified models, categorizing them into three main architectural paradigms: diffusion-based, autoregressive-based, and hybrid approaches that fuse autoregressive and diffusion mechanisms. For each category, we analyze the structural designs and innovations introduced by related works. Additionally, we compile datasets and benchmarks tailored for unified models, offering resources for future exploration. Finally, we discuss the key challenges facing this nascent field, including tokenization strategy, cross-modal attention, and data. As this area is still in its early stages, we anticipate rapid advancements and will regularly update this survey. Our goal is to inspire further research and provide a valuable reference for the community. The references associated with this survey are available on GitHub (https://github.com/AIDC-AI/Awesome-Unified-Multimodal-Models).","authors":["Xinjie Zhang","Jintao Guo","Shanshan Zhao","Minghao Fu","Lunhao Duan","Guo-Hua Wang","Qing-Guo Chen","Zhao Xu","Weihua Luo","Kaifu Zhang"],"url":"https://arxiv.org/abs/2505.02567"}
{"created":"2025-05-23","title":"seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models","abstract":"Current self-supervised algorithms commonly rely on transformations such as data augmentation and masking to learn visual representations. This is achieved by enforcing invariance or equivariance with respect to these transformations after encoding two views of an image. This dominant two-view paradigm often limits the flexibility of learned representations for downstream adaptation by creating performance trade-offs between high-level invariance-demanding tasks such as image classification and more fine-grained equivariance-related tasks. In this work, we proposes \\emph{seq-JEPA}, a world modeling framework that introduces architectural inductive biases into joint-embedding predictive architectures to resolve this trade-off. Without relying on dual equivariance predictors or loss terms, seq-JEPA simultaneously learns two architecturally segregated representations: one equivariant to specified transformations and another invariant to them. To do so, our model processes short sequences of different views (observations) of inputs. Each encoded view is concatenated with an embedding of the relative transformation (action) that produces the next observation in the sequence. These view-action pairs are passed through a transformer encoder that outputs an aggregate representation. A predictor head then conditions this aggregate representation on the upcoming action to predict the representation of the next observation. Empirically, seq-JEPA demonstrates strong performance on both equivariant and invariant benchmarks without sacrificing one for the other. Furthermore, it excels at tasks that inherently require aggregating a sequence of observations, such as path integration across actions and predictive learning across eye movements.","authors":["Hafez Ghaemi","Eilif Muller","Shahab Bakhtiari"],"url":"https://arxiv.org/abs/2505.03176"}
{"created":"2025-05-23","title":"Say It Another Way: Auditing LLMs with a User-Grounded Automated Paraphrasing Framework","abstract":"Large language models (LLMs) are sensitive to subtle changes in prompt phrasing, complicating efforts to audit them reliably. Prior approaches often rely on arbitrary or ungrounded prompt variations, which may miss key linguistic and demographic factors in real-world usage. We introduce AUGMENT (Automated User-Grounded Modeling and Evaluation of Natural Language Transformations), a framework for systematically generating and evaluating controlled, realistic prompt paraphrases based on linguistic structure and user demographics. AUGMENT ensures paraphrase quality through a combination of semantic, stylistic, and instruction-following criteria. In a case study on the BBQ dataset, we show that user-grounded paraphrasing leads to significant shifts in LLM performance and bias metrics across nine models. Our findings highlight the need for more representative and structured approaches to prompt variation in LLM auditing.","authors":["Cl\\'ea Chataigner","Rebecca Ma","Prakhar Ganesh","Afaf Ta\\\"ik","Elliot Creager","Golnoosh Farnadi"],"url":"https://arxiv.org/abs/2505.03563"}
{"created":"2025-05-23","title":"In-Context Adaptation to Concept Drift for Learned Database Operations","abstract":"Machine learning has demonstrated transformative potential for database operations, such as query optimization and in-database data analytics. However, dynamic database environments, characterized by frequent updates and evolving data distributions, introduce concept drift, which leads to performance degradation for learned models and limits their practical applicability. Addressing this challenge requires efficient frameworks capable of adapting to shifting concepts while minimizing the overhead of retraining or fine-tuning.","authors":["Jiaqi Zhu","Shaofeng Cai","Yanyan Shen","Gang Chen","Fang Deng","Beng Chin Ooi"],"url":"https://arxiv.org/abs/2505.04404"}
{"created":"2025-05-23","title":"Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation","abstract":"Backpropagation (BP) is the cornerstone of deep learning, but its reliance on global gradient synchronization limits scalability and imposes significant memory overhead. We propose Stochastic Variational Propagation (SVP), a scalable alternative that reframes training as hierarchical variational inference. SVP treats layer activations as latent variables and optimizes local Evidence Lower Bounds (ELBOs), enabling independent, local updates while preserving global coherence. However, directly applying KL divergence in layer-wise ELBOs risks inter-layer's representation collapse due to excessive compression. To prevent this, SVP projects activations into low-dimensional spaces via fixed random matrices, ensuring information preservation and representational diversity. Combined with a feature alignment loss for inter-layer consistency, SVP achieves competitive accuracy with BP across diverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to ImageNet), reduces memory usage by up to 4x, and significantly improves scalability. More broadly, SVP introduces a probabilistic perspective to deep representation learning, opening pathways toward more modular and interpretable neural network design.","authors":["Bojian Yin","Federico Corradi"],"url":"https://arxiv.org/abs/2505.05181"}
{"created":"2025-05-23","title":"Bounds on $k$-hash distances and rates of linear codes","abstract":"In this paper, we bound the rate of linear codes in $\\mathbb{F}_q^n$ with the property that any $k\\leq q$ codewords are all simultaneously distinct in at least $d_k$ coordinates. For the particular case $d_k=1$, this leads to bounds on the rate of linear $q$-ary $k$-hash codes which generalize, with a simpler proof, results recently obtained for the case $q=k=3$ by Pohoata and Zakharov and by Bishnoi, D'haeseleer, Gijswijt and Potukuchi. We finally discuss some related open problems on the list-decoding zero-error capacity of discrete memoryless channels.","authors":["Stefano Della Fiore","Marco Dalai"],"url":"https://arxiv.org/abs/2505.05239"}
{"created":"2025-05-23","title":"Timestamp Manipulation: Timestamp-based Nakamoto-style Blockchains are Vulnerable","abstract":"Nakamoto consensus are the most widely adopted decentralized consensus mechanism in cryptocurrency systems. Since it was proposed in 2008, many studies have focused on analyzing its security. Most of them focus on maximizing the profit of the adversary. Examples include the selfish mining attack [FC '14] and the recent riskless uncle maker (RUM) attack [CCS '23]. In this work, we introduce the Staircase-Unrestricted Uncle Maker (SUUM), the first block withholding attack targeting the timestamp-based Nakamoto-style blockchain. Through block withholding, timestamp manipulation, and difficulty risk control, SUUM adversaries are capable of launching persistent attacks with zero cost and minimal difficulty risk characteristics, indefinitely exploiting rewards from honest participants. This creates a self-reinforcing cycle that threatens the security of blockchains. We conduct a comprehensive and systematic evaluation of SUUM, including the attack conditions, its impact on blockchains, and the difficulty risks. Finally, we further discuss four feasible mitigation measures against SUUM.","authors":["Junjie Hu","Na Ruan","Sisi Duan"],"url":"https://arxiv.org/abs/2505.05328"}
{"created":"2025-05-23","title":"LiTransProQA: an LLM-based Literary Translation evaluation metric with Professional Question Answering","abstract":"The impact of Large Language Models (LLMs) has extended into literary domains. However, existing evaluation metrics prioritize mechanical accuracy over artistic expression and tend to overrate machine translation as being superior to human translation from experienced professionals. In the long run, this bias could result in an irreversible decline in translation quality and cultural authenticity. In response to the urgent need for a specialized literary evaluation metric, we introduce LiTransProQA, a novel, reference-free, LLM-based question-answering framework designed for literary translation evaluation. LiTransProQA uniquely integrates insights from professional literary translators and researchers, focusing on critical elements in literary quality assessment such as literary devices, cultural understanding, and authorial voice. Our extensive evaluation shows that while literary-finetuned XCOMET-XL yields marginal gains, LiTransProQA substantially outperforms current metrics, achieving up to 0.07 gain in correlation and surpassing the best state-of-the-art metrics by over 15 points in adequacy assessments. Incorporating professional translator insights as weights further improves performance, highlighting the value of translator inputs. Notably, LiTransProQA reaches human-level evaluation performance comparable to trained student evaluators. It shows broad applicability to open-source models like LLaMa3.3-70b and Qwen2.5-32b, indicating its potential as an accessible and training-free tool for evaluating literary translations that require local processing due to copyright or ethical considerations. The code and datasets are available under: https://github.com/zhangr2021/TransProQA.","authors":["Ran Zhang","Wei Zhao","Lieve Macken","Steffen Eger"],"url":"https://arxiv.org/abs/2505.05423"}
{"created":"2025-05-23","title":"Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models","abstract":"Achieving deep alignment between vision and language remains a central challenge for Multimodal Large Language Models (MLLMs). These models often fail to fully leverage visual input, defaulting to strong language priors. Our approach first provides insights into how MLLMs internally build visual understanding of image regions and then introduces techniques to amplify this capability. Specifically, we explore techniques designed both to deepen the model's understanding of visual content and to ensure that these visual insights actively guide language generation. We demonstrate the superior multimodal understanding of our resultant model through a detailed upstream analysis quantifying its ability to predict visually-dependent tokens as well as 10 pt boost on visually challenging tasks.","authors":["Aarti Ghatkesar","Uddeshya Upadhyay","Ganesh Venkatesh"],"url":"https://arxiv.org/abs/2505.05626"}
{"created":"2025-05-23","title":"LLMs Outperform Experts on Challenging Biology Benchmarks","abstract":"This study systematically evaluates 27 frontier Large Language Models on eight biology benchmarks spanning molecular biology, genetics, cloning, virology, and biosecurity. Models from major AI developers released between November 2022 and April 2025 were assessed through ten independent runs per benchmark. The findings reveal dramatic improvements in biological capabilities. Top model performance increased more than 4-fold on the challenging text-only subset of the Virology Capabilities Test over the study period, with OpenAI's o3 now performing twice as well as expert virologists. Several models now match or exceed expert-level performance on other challenging benchmarks, including the biology subsets of GPQA and WMDP and LAB-Bench CloningScenarios. Contrary to expectations, chain-of-thought did not substantially improve performance over zero-shot evaluation, while extended reasoning features in o3-mini and Claude 3.7 Sonnet typically improved performance as predicted by inference scaling. Benchmarks such as PubMedQA and the MMLU and WMDP biology subsets exhibited performance plateaus well below 100%, suggesting benchmark saturation and errors in the underlying benchmark data. The analysis highlights the need for more sophisticated evaluation methodologies as AI systems continue to advance.","authors":["Lennart Justen"],"url":"https://arxiv.org/abs/2505.06108"}
{"created":"2025-05-23","title":"A New DAPO Algorithm for Stock Trading","abstract":"Recent advances in reinforcement learning, such as Dynamic Sampling Policy Optimization (DAPO), show strong performance when paired with large language models (LLMs). Motivated by this success, we ask whether similar gains can be realized in financial trading. We design a trading agent that combines an improved Group Relative Policy Optimization (GRPO) algorithm, augmented with ideas from DAPO, with LLM-based risk and sentiment signals extracted from financial news. On the NASDAQ-100 index (FNSPID dataset), our agent attains a cumulative return of 230.49 percent and an information ratio of 0.37, outperforming the CPPO-DeepSeek baseline. It also cuts training time from about 8 hours to 2.5 hours over 100 epochs while markedly reducing RAM usage. The proposed RL-LLM framework offers a scalable path toward data-efficient trading agents. Code: https://github.com/Ruijian-Zha/FinRL-DAPO-SR/","authors":["Ruijian Zha","Bojun Liu"],"url":"https://arxiv.org/abs/2505.06408"}
{"created":"2025-05-23","title":"Generative Pre-trained Autoregressive Diffusion Transformer","abstract":"In this work, we present GPDiT, a Generative Pre-trained Autoregressive Diffusion Transformer that unifies the strengths of diffusion and autoregressive modeling for long-range video synthesis, within a continuous latent space. Instead of predicting discrete tokens, GPDiT autoregressively predicts future latent frames using a diffusion loss, enabling natural modeling of motion dynamics and semantic consistency across frames. This continuous autoregressive framework not only enhances generation quality but also endows the model with representation capabilities. Additionally, we introduce a lightweight causal attention variant and a parameter-free rotation-based time-conditioning mechanism, improving both the training and inference efficiency. Extensive experiments demonstrate that GPDiT achieves strong performance in video generation quality, video representation ability, and few-shot learning tasks, highlighting its potential as an effective framework for video modeling in continuous space.","authors":["Yuan Zhang","Jiacheng Jiang","Guoqing Ma","Zhiying Lu","Haoyang Huang","Jianlong Yuan","Nan Duan"],"url":"https://arxiv.org/abs/2505.07344"}
{"created":"2025-05-23","title":"YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models","abstract":"Leveraging large language model (LLM) based agents to simulate human social behaviors has recently gained significant attention. In this paper, we introduce a novel social simulator called YuLan-OneSim. Compared to previous works, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free scenario construction: Users can simply describe and refine their simulation scenarios through natural language interactions with our simulator. All simulation code is automatically generated, significantly reducing the need for programming expertise. (2) Comprehensive default scenarios: We implement 50 default simulation scenarios spanning 8 domains, including economics, sociology, politics, psychology, organization, demographics, law, and communication, broadening access for a diverse range of social researchers. (3) Evolvable simulation: Our simulator is capable of receiving external feedback and automatically fine-tuning the backbone LLMs, significantly enhancing the simulation quality. (4) Large-scale simulation: By developing a fully responsive agent framework and a distributed simulation architecture, our simulator can handle up to 100,000 agents, ensuring more stable and reliable simulation results. (5) AI social researcher: Leveraging the above features, we develop an AI social researcher. Users only need to propose a research topic, and the AI researcher will automatically analyze the input, construct simulation environments, summarize results, generate technical reports, review and refine the reports--completing the social science research loop. To demonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate the quality of the automatically generated scenarios, the reliability, efficiency, and scalability of the simulation process, as well as the performance of the AI social researcher.","authors":["Lei Wang","Heyang Gao","Xiaohe Bo","Xu Chen","Ji-Rong Wen"],"url":"https://arxiv.org/abs/2505.07581"}
{"created":"2025-05-23","title":"One Bad NOFO? AI Governance in Federal Grantmaking","abstract":"Much scholarship considers how U.S. federal agencies govern artificial intelligence (AI) through rulemaking and their own internal use policies. But agencies have an overlooked AI governance role: setting discretionary grant policy when directing billions of dollars in federal financial assistance. These dollars enable state and local entities to study, create, and use AI. This funding not only goes to dedicated AI programs, but also to grantees using AI in the course of meeting their routine grant objectives. As discretionary grantmakers, agencies guide and restrict what grant winners do -- a hidden lever for AI governance. Agencies pull this lever by setting program objectives, judging criteria, and restrictions for AI use. Using a novel dataset of over 40,000 non-defense federal grant notices of funding opportunity (NOFOs) posted to the U.S. federal grants website between 2009 and 2024, we analyze how agencies regulate the use of AI by grantees. We select records mentioning AI and review their stated goals and requirements. We find agencies promoting AI in notice narratives, shaping adoption in ways other records of grant policy might fail to capture. Of the grant opportunities that mention AI, we find only a handful of AI-specific judging criteria or restrictions. This silence holds even when agencies fund AI uses in contexts affecting people's rights and which, under an analogous federal procurement regime, would result in extra oversight. These findings recast grant notices as a site of AI policymaking -- albeit one that is developing out of step with other regulatory efforts and incomplete in its consideration of transparency, accountability, and privacy protections. The paper concludes by drawing lessons from AI procurement scholarship, while identifying distinct challenges in grantmaking that invite further study.","authors":["Dan Bateyko","Karen Levy"],"url":"https://arxiv.org/abs/2505.08133"}
{"created":"2025-05-23","title":"LiDDA: Data Driven Attribution at LinkedIn","abstract":"Data Driven Attribution, which assigns conversion credits to marketing interactions based on causal patterns learned from data, is the foundation of modern marketing intelligence and vital to any marketing businesses and advertising platform. In this paper, we introduce a unified transformer-based attribution approach that can handle member-level data, aggregate-level data, and integration of external macro factors. We detail the large scale implementation of the approach at LinkedIn, showcasing significant impact. We also share learning and insights that are broadly applicable to the marketing and ad tech fields.","authors":["John Bencina","Erkut Aykutlug","Yue Chen","Zerui Zhang","Stephanie Sorenson","Shao Tang","Changshuai Wei"],"url":"https://arxiv.org/abs/2505.09861"}
{"created":"2025-05-23","title":"Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field","abstract":"Dynamic scene representation and reconstruction have undergone transformative advances in recent years, catalyzed by breakthroughs in neural radiance fields and 3D Gaussian splatting techniques. While initially developed for static environments, these methodologies have rapidly evolved to address the complexities inherent in 4D dynamic scenes through an expansive body of research. Coupled with innovations in differentiable volumetric rendering, these approaches have significantly enhanced the quality of motion representation and dynamic scene reconstruction, thereby garnering substantial attention from the computer vision and graphics communities. This survey presents a systematic analysis of over 200 papers focused on dynamic scene representation using radiance field, spanning the spectrum from implicit neural representations to explicit Gaussian primitives. We categorize and evaluate these works through multiple critical lenses: motion representation paradigms, reconstruction techniques for varied scene dynamics, auxiliary information integration strategies, and regularization approaches that ensure temporal consistency and physical plausibility. We organize diverse methodological approaches under a unified representational framework, concluding with a critical examination of persistent challenges and promising research directions. By providing this comprehensive overview, we aim to establish a definitive reference for researchers entering this rapidly evolving field while offering experienced practitioners a systematic understanding of both conceptual principles and practical frontiers in dynamic scene reconstruction.","authors":["Jinlong Fan","Xuepu Zeng","Jing Zhang","Mingming Gong","Yuxiang Yang","Dacheng Tao"],"url":"https://arxiv.org/abs/2505.10049"}
{"created":"2025-05-23","title":"ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization","abstract":"Human mesh recovery (HMR) from a single image is inherently ill-posed due to depth ambiguity and occlusions. Probabilistic methods have tried to solve this by generating numerous plausible 3D human mesh predictions, but they often exhibit misalignment with 2D image observations and weak robustness to in-the-wild images. To address these issues, we propose ADHMR, a framework that Aligns a Diffusion-based HMR model in a preference optimization manner. First, we train a human mesh prediction assessment model, HMR-Scorer, capable of evaluating predictions even for in-the-wild images without 3D annotations. We then use HMR-Scorer to create a preference dataset, where each input image has a pair of winner and loser mesh predictions. This dataset is used to finetune the base model using direct preference optimization. Moreover, HMR-Scorer also helps improve existing HMR models by data cleaning, even with fewer training samples. Extensive experiments show that ADHMR outperforms current state-of-the-art methods. Code is available at: https://github.com/shenwenhao01/ADHMR.","authors":["Wenhao Shen","Wanqi Yin","Xiaofeng Yang","Cheng Chen","Chaoyue Song","Zhongang Cai","Lei Yang","Hao Wang","Guosheng Lin"],"url":"https://arxiv.org/abs/2505.10250"}
{"created":"2025-05-23","title":"Are Sparse Autoencoders Useful for Java Function Bug Detection?","abstract":"Software vulnerabilities such as buffer overflows and SQL injections are a major source of security breaches. Traditional methods for vulnerability detection remain essential but are limited by high false positive rates, scalability issues, and reliance on manual effort. These constraints have driven interest in AI-based approaches to automated vulnerability detection and secure code generation. While Large Language Models (LLMs) have opened new avenues for classification tasks, their complexity and opacity pose challenges for interpretability and deployment. Sparse Autoencoder offer a promising solution to this problem. We explore whether SAEs can serve as a lightweight, interpretable alternative for bug detection in Java functions. We evaluate the effectiveness of SAEs when applied to representations from GPT-2 Small and Gemma 2B, examining their capacity to highlight buggy behaviour without fine-tuning the underlying LLMs. We found that SAE-derived features enable bug detection with an F1 score of up to 89%, consistently outperforming fine-tuned transformer encoder baselines. Our work provides the first empirical evidence that SAEs can be used to detect software bugs directly from the internal representations of pretrained LLMs, without any fine-tuning or task-specific supervision.","authors":["Rui Melo","Claudia Mamede","Andre Catarino","Rui Abreu","Henrique Lopes Cardoso"],"url":"https://arxiv.org/abs/2505.10375"}
{"created":"2025-05-23","title":"Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting","abstract":"To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks to minimize the number of Gaussians used while preserving high rendering quality, introducing an inherent trade-off between Gaussian quantity and rendering quality. Existing methods strive for better quantity-quality performance, but lack the ability for users to intuitively adjust this trade-off to suit practical needs such as model deployment under diverse hardware and communication constraints. Here, we present ControlGS, a 3DGS optimization method that achieves semantically meaningful and cross-scene consistent quantity-quality control. Through a single training run using a fixed setup and a user-specified hyperparameter reflecting quantity-quality preference, ControlGS can automatically find desirable quantity-quality trade-off points across diverse scenes, from compact objects to large outdoor scenes. It also outperforms baselines by achieving higher rendering quality with fewer Gaussians, and supports a broad adjustment range with stepless control over the trade-off. Project page: https://zhang-fengdi.github.io/ControlGS/","authors":["Fengdi Zhang","Hongkun Cao","Ruqi Huang"],"url":"https://arxiv.org/abs/2505.10473"}
{"created":"2025-05-23","title":"Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization","abstract":"Optimizing Large Language Model (LLM) performance requires well-crafted prompts, but manual prompt engineering is labor-intensive and often ineffective. Automated prompt optimization techniques address this challenge but the majority of them rely on randomly selected evaluation subsets, which fail to represent the full dataset, leading to unreliable evaluations and suboptimal prompts. Existing coreset selection methods, designed for LLM benchmarking, are unsuitable for prompt optimization due to challenges in clustering similar samples, high data collection costs, and the unavailability of performance data for new or private datasets. To overcome these issues, we propose IPOMP, an Iterative evaluation data selection for effective Prompt Optimization using real-time Model Performance. IPOMP is a two-stage approach that selects representative and diverse samples using semantic clustering and boundary analysis, followed by iterative refinement with real-time model performance data to replace redundant samples. Evaluations on the BIG-bench dataset show that IPOMP improves effectiveness by 1.6% to 5.3% and stability by at least 57% compared with SOTA baselines, with minimal computational overhead below 1%. Furthermore, the results demonstrate that our real-time performance-guided refinement approach can be universally applied to enhance existing coreset selection methods.","authors":["Ximing Dong","Shaowei Wang","Dayi Lin","Ahmed E. Hassan"],"url":"https://arxiv.org/abs/2505.10736"}
{"created":"2025-05-23","title":"Bandwidth vs BFS Width in Matrix Reordering, Graph Reconstruction, and Graph Drawing","abstract":"We provide the first approximation quality guarantees for the Cuthull-McKee heuristic for reordering symmetric matrices to have low bandwidth, and we provide an algorithm for reconstructing bounded-bandwidth graphs from distance oracles with near-linear query complexity. To prove these results we introduce a new width parameter, BFS width, and we prove polylogarithmic upper and lower bounds on the BFS width of graphs of bounded bandwidth. Unlike other width parameters, such as bandwidth, pathwidth, and treewidth, BFS width can easily be computed in polynomial time. Bounded BFS width implies bounded bandwidth, pathwidth, and treewidth, which in turn imply fixed-parameter tractable algorithms for many problems that are NP-hard for general graphs. In addition to their applications to matrix ordering, we also provide applications of BFS width to graph reconstruction, to reconstruct graphs from distance queries, and graph drawing, to construct arc diagrams of small height.","authors":["David Eppstein","Michael T. Goodrich","Songyu Liu"],"url":"https://arxiv.org/abs/2505.10789"}
{"created":"2025-05-23","title":"PoE-World: Compositional World Modeling with Products of Programmatic Experts","abstract":"Learning how the world works is central to building AI agents that can adapt to complex environments. Traditional world models based on deep learning demand vast amounts of training data, and do not flexibly update their knowledge from sparse observations. Recent advances in program synthesis using Large Language Models (LLMs) give an alternate approach which learns world models represented as source code, supporting strong generalization from little data. To date, application of program-structured world models remains limited to natural language and grid-world domains. We introduce a novel program synthesis method for effectively modeling complex, non-gridworld domains by representing a world model as an exponentially-weighted product of programmatic experts (PoE-World) synthesized by LLMs. We show that this approach can learn complex, stochastic world models from just a few observations. We evaluate the learned world models by embedding them in a model-based planning agent, demonstrating efficient performance and generalization to unseen levels on Atari's Pong and Montezuma's Revenge. We release our code and display the learned world models and videos of the agent's gameplay at https://topwasu.github.io/poe-world.","authors":["Wasu Top Piriyakulkij","Yichao Liang","Hao Tang","Adrian Weller","Marta Kryven","Kevin Ellis"],"url":"https://arxiv.org/abs/2505.10819"}
{"created":"2025-05-23","title":"Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer","abstract":"Large Language Models (LLMs) increasingly incorporate multilingual capabilities, fueling the demand to transfer them into target language-specific models. However, most approaches, which blend the source model's embedding by replacing the source vocabulary with the target language-specific vocabulary, may constrain expressive capacity in the target language since the source model is predominantly trained on English data. In this paper, we propose Semantic Aware Linear Transfer (SALT), a novel cross-lingual transfer technique that recycles embeddings from target language Pre-trained Language Models (PLMs) to transmit the deep representational strengths of PLM-derived embedding to LLMs. SALT derives unique regression lines based on the similarity in the overlap of the source and target vocabularies, to handle each non-overlapping token's embedding space. Our extensive experiments show that SALT significantly outperforms other transfer methods and achieves lower loss with accelerating faster convergence during language adaptation. Notably, SALT obtains remarkable performance in cross-lingual understanding setups compared to other methods. Furthermore, we highlight the scalable use of PLMs to enhance the functionality of contemporary LLMs by conducting experiments with varying architectures.","authors":["Seungyoon Lee","Seongtae Hong","Hyeonseok Moon","Heuiseok Lim"],"url":"https://arxiv.org/abs/2505.10945"}
{"created":"2025-05-23","title":"Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning","abstract":"Large-scale Transformer language models (LMs) trained solely on next-token prediction with web-scale data can solve a wide range of tasks after seeing just a few examples. The mechanism behind this capability, known as in-context learning (ICL), remains both controversial and poorly understood. Some studies argue that it is merely the result of memorizing vast amounts of data, while others contend that it reflects a fundamental, symbolic algorithmic development in LMs. In this work, we introduce a suite of investigative tasks and a novel method to systematically investigate ICL by leveraging the full Pythia scaling suite, including interim checkpoints that capture progressively larger amount of training data. By carefully exploring ICL performance on downstream tasks and simultaneously conducting a mechanistic analysis of the residual stream's subspace, we demonstrate that ICL extends beyond mere \"memorization\" of the training corpus, yet does not amount to the implementation of an independent symbolic algorithm. Our results also clarify several aspects of ICL, including the influence of training dynamics, model capabilities, and elements of mechanistic interpretability. Overall, our work advances the understanding of ICL and its implications, offering model developers insights into potential improvements and providing AI security practitioners with a basis for more informed guidelines.","authors":["Jingcheng Niu","Subhabrata Dutta","Ahmed Elshabrawy","Harish Tayyar Madabushi","Iryna Gurevych"],"url":"https://arxiv.org/abs/2505.11004"}
{"created":"2025-05-23","title":"Evolutionary training-free guidance in diffusion model for 3D multi-objective molecular generation","abstract":"Discovering novel 3D molecular structures that simultaneously satisfy multiple property targets remains a central challenge in materials and drug design. Although recent diffusion-based models can generate 3D conformations, they require expensive retraining for each new property or property-combination and lack flexibility in enforcing structural constraints. We introduce EGD (Evolutionary Guidance in Diffusion), a training-free framework that embeds evolutionary operators directly into the diffusion sampling process. By performing crossover on noise-perturbed samples and then denoising them with a pretrained Unconditional diffusion model, EGD seamlessly blends structural fragments and steers generation toward user-specified objectives without any additional model updates. On both single- and multi-target 3D conditional generation tasks-and on multi-objective optimization of quantum properties EGD outperforms state-of-the-art conditional diffusion methods in accuracy and runs up to five times faster per generation. In the single-objective optimization of protein ligands, EGD enables customized ligand generation. Moreover, EGD can embed arbitrary 3D fragments into the generated molecules while optimizing multiple conflicting properties in one unified process. This combination of efficiency, flexibility, and controllable structure makes EGD a powerful tool for rapid, guided exploration of chemical space.","authors":["Ruiqing Sun","Dawei Feng","Sen Yang","Yijie Wang","Huaimin Wang"],"url":"https://arxiv.org/abs/2505.11037"}
{"created":"2025-05-23","title":"Fractal Graph Contrastive Learning","abstract":"While Graph Contrastive Learning (GCL) has attracted considerable attention in the field of graph self-supervised learning, its performance heavily relies on data augmentations that are expected to generate semantically consistent positive pairs. Existing strategies typically resort to random perturbations or local structure preservation, yet lack explicit control over global structural consistency between augmented views. To address this limitation, we propose Fractal Graph Contrastive Learning (FractalGCL), a theory-driven framework that leverages fractal self-similarity to enforce global topological coherence. FractalGCL introduces two key innovations: a renormalisation-based augmentation that generates structurally aligned positive views via box coverings; and a fractal-dimension-aware contrastive loss that aligns graph embeddings according to their fractal dimensions. While combining the two innovations markedly boosts graph-representation quality, it also adds non-trivial computational overhead. To mitigate the computational overhead of fractal dimension estimation, we derive a one-shot estimator by proving that the dimension discrepancy between original and renormalised graphs converges weakly to a centred Gaussian distribution. This theoretical insight enables a reduction in dimension computation cost by an order of magnitude, cutting overall training time by approximately 61%. The experiments show that FractalGCL not only delivers state-of-the-art results on standard benchmarks but also outperforms traditional baselines on traffic networks by an average margin of about remarkably 7%. Codes are available at (https://anonymous.4open.science/r/FractalGCL-0511).","authors":["Nero Z. Li","Xuehao Zhai","Zhichao Shi","Boshen Shi","Xuhui Jiang"],"url":"https://arxiv.org/abs/2505.11356"}
{"created":"2025-05-23","title":"Critique-Guided Distillation: Improving Supervised Fine-tuning via Better Distillation","abstract":"Supervised fine-tuning (SFT) using expert demonstrations often suffer from the imitation problem, where the model learns to reproduce the correct responses without understanding the underlying rationale. To address this limitation, we propose Critique-Guided Distillation (CGD), a novel multi-stage framework that integrates teacher model generated explanatory critiques and refined responses into the SFT process. A student model is then trained to map the triplet of prompt, teacher critique, and its own initial response to the corresponding refined teacher response, thereby learning both what to imitate and why. Using entropy-based analysis, we show that CGD reduces refinement uncertainty and can be interpreted as a Bayesian posterior update. We perform extensive empirical evaluation of CGD, on variety of benchmark tasks, and demonstrate significant gains on both math (AMC23 +17.5%) and language understanding tasks (MMLU-Pro +6.3%), while successfully mitigating the format drift issues observed in previous critique fine-tuning (CFT) techniques.","authors":["Berkcan Kapusuzoglu","Supriyo Chakraborty","Chia-Hsuan Lee","Sambit Sahu"],"url":"https://arxiv.org/abs/2505.11628"}
{"created":"2025-05-23","title":"OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration","abstract":"Agents powered by advanced large language models (LLMs) have demonstrated impressive capabilities across diverse complex applications. Recently, Multi-Agent Systems (MAS), wherein multiple agents collaborate and communicate with each other, have exhibited enhanced capabilities in complex tasks, such as high-quality code generation and arithmetic reasoning. However, the development of such systems often relies on handcrafted methods, and the literature on systematic design and optimization of LLM-based MAS remains limited.","authors":["Shijun Li","Hilaf Hasson","Joydeep Ghosh"],"url":"https://arxiv.org/abs/2505.11765"}
{"created":"2025-05-23","title":"PRS-Med: Position Reasoning Segmentation with Vision-Language Model in Medical Imaging","abstract":"Recent advancements in prompt-based medical image segmentation have enabled clinicians to identify tumors using simple input like bounding boxes or text prompts. However, existing methods face challenges when doctors need to interact through natural language or when position reasoning is required - understanding spatial relationships between anatomical structures and pathologies. We present PRS-Med, a framework that integrates vision-language models with segmentation capabilities to generate both accurate segmentation masks and corresponding spatial reasoning outputs. Additionally, we introduce the MMRS dataset (Multimodal Medical in Positional Reasoning Segmentation), which provides diverse, spatially-grounded question-answer pairs to address the lack of position reasoning data in medical imaging. PRS-Med demonstrates superior performance across six imaging modalities (CT, MRI, X-ray, ultrasound, endoscopy, RGB), significantly outperforming state-of-the-art methods in both segmentation accuracy and position reasoning. Our approach enables intuitive doctor-system interaction through natural language, facilitating more efficient diagnoses. Our dataset pipeline, model, and codebase will be released to foster further research in spatially-aware multimodal reasoning for medical applications.","authors":["Quoc-Huy Trinh","Minh-Van Nguyen","Jung Peng","Ulas Bagci","Debesh Jha"],"url":"https://arxiv.org/abs/2505.11872"}
{"created":"2025-05-23","title":"Top-Down Compression: Revisit Efficient Vision Token Projection for Visual Instruction Tuning","abstract":"Visual instruction tuning aims to enable large language models to comprehend the visual world, with a pivotal challenge lying in establishing an effective vision-to-language projection. However, existing methods often grapple with the intractable trade-off between accuracy and efficiency. In this paper, we present LLaVA-Meteor, a novel approach designed to break this deadlock, equipped with a novel Top-Down Compression paradigm that strategically compresses visual tokens without compromising core information. Specifically, we construct a trainable Flash Global Fusion module based on efficient selective state space operators, which aligns the feature space while enabling each token to perceive holistic visual context and instruction preference at low cost. Furthermore, a local-to-single scanning manner is employed to effectively capture local dependencies, thereby enhancing the model's capability in vision modeling. To alleviate computational overhead, we explore a Visual-Native Selection mechanism that independently assesses token significance by both the visual and native experts, followed by aggregation to retain the most critical subset. Extensive experiments show that our approach reduces visual tokens by 75--95% while achieving comparable or superior performance across 12 benchmarks, significantly improving efficiency.","authors":["Bonan li","Zicheng Zhang","Songhua Liu","Weihao Yu","Xinchao Wang"],"url":"https://arxiv.org/abs/2505.11945"}
{"created":"2025-05-23","title":"Multi-modal Collaborative Optimization and Expansion Network for Event-assisted Single-eye Expression Recognition","abstract":"In this paper, we proposed a Multi-modal Collaborative Optimization and Expansion Network (MCO-E Net), to use event modalities to resist challenges such as low light, high exposure, and high dynamic range in single-eye expression recognition tasks. The MCO-E Net introduces two innovative designs: Multi-modal Collaborative Optimization Mamba (MCO-Mamba) and Heterogeneous Collaborative and Expansion Mixture-of-Experts (HCE-MoE). MCO-Mamba, building upon Mamba, leverages dual-modal information to jointly optimize the model, facilitating collaborative interaction and fusion of modal semantics. This approach encourages the model to balance the learning of both modalities and harness their respective strengths. HCE-MoE, on the other hand, employs a dynamic routing mechanism to distribute structurally varied experts (deep, attention, and focal), fostering collaborative learning of complementary semantics. This heterogeneous architecture systematically integrates diverse feature extraction paradigms to comprehensively capture expression semantics. Extensive experiments demonstrate that our proposed network achieves competitive performance in the task of single-eye expression recognition, especially under poor lighting conditions.","authors":["Runduo Han","Xiuping Liu","Shangxuan Yi","Yi Zhang","Hongchen Tan"],"url":"https://arxiv.org/abs/2505.12007"}
{"created":"2025-05-23","title":"Do different prompting methods yield a common task representation in language models?","abstract":"Demonstrations and instructions are two primary approaches for prompting language models to perform in-context learning (ICL) tasks. Do identical tasks elicited in different ways result in similar representations of the task? An improved understanding of task representation mechanisms would offer interpretability insights and may aid in steering models. We study this through \\textit{function vectors} (FVs), recently proposed as a mechanism to extract few-shot ICL task representations. We generalize FVs to alternative task presentations, focusing on short textual instruction prompts, and successfully extract instruction function vectors that promote zero-shot task accuracy. We find evidence that demonstration- and instruction-based function vectors leverage different model components, and offer several controls to dissociate their contributions to task performance. Our results suggest that different task promptings forms do not induce a common task representation through FVs but elicit different, partly overlapping mechanisms. Our findings offer principled support to the practice of combining instructions and task demonstrations, imply challenges in universally monitoring task inference across presentation forms, and encourage further examinations of LLM task inference mechanisms.","authors":["Guy Davidson","Todd M. Gureckis","Brenden M. Lake","Adina Williams"],"url":"https://arxiv.org/abs/2505.12075"}
{"created":"2025-05-23","title":"Model Merging in Pre-training of Large Language Models","abstract":"Model merging has emerged as a promising technique for enhancing large language models, though its application in large-scale pre-training remains relatively unexplored. In this paper, we present a comprehensive investigation of model merging techniques during the pre-training process. Through extensive experiments with both dense and Mixture-of-Experts (MoE) architectures ranging from millions to over 100 billion parameters, we demonstrate that merging checkpoints trained with constant learning rates not only achieves significant performance improvements but also enables accurate prediction of annealing behavior. These improvements lead to both more efficient model development and significantly lower training costs. Our detailed ablation studies on merging strategies and hyperparameters provide new insights into the underlying mechanisms while uncovering novel applications. Through comprehensive experimental analysis, we offer the open-source community practical pre-training guidelines for effective model merging.","authors":["Yunshui Li","Yiyuan Ma","Shen Yan","Chaoyi Zhang","Jing Liu","Jianqiao Lu","Ziwen Xu","Mengzhao Chen","Minrui Wang","Shiyi Zhan","Jin Ma","Xunhao Lai","Deyi Liu","Yao Luo","Xingyan Bin","Hongbin Ren","Mingji Han","Wenhao Hao","Bairen Yi","LingJun Liu","Bole Ma","Xiaoying Jia","Xun Zhou","Siyuan Qiao","Liang Xiang","Yonghui Wu"],"url":"https://arxiv.org/abs/2505.12082"}
{"created":"2025-05-23","title":"Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning","abstract":"Fine-tuning large language models (LLMs) on task-specific data is essential for their effective deployment. As dataset sizes grow, efficiently selecting optimal subsets for training becomes crucial to balancing performance and computational costs. Traditional data selection methods often require fine-tuning a scoring model on the target dataset, which is time-consuming and resource-intensive, or rely on heuristics that fail to fully leverage the model's predictive capabilities. To address these challenges, we propose Data Whisperer, an efficient, training-free, attention-based method that leverages few-shot in-context learning with the model to be fine-tuned. Comprehensive evaluations were conducted on both raw and synthetic datasets across diverse tasks and models. Notably, Data Whisperer achieves superior performance compared to the full GSM8K dataset on the Llama-3-8B-Instruct model, using just 10% of the data, and outperforms existing methods with a 3.1-point improvement and a 7.4$\\times$ speedup.","authors":["Shaobo Wang","Xiangqi Jin","Ziming Wang","Jize Wang","Jiajun Zhang","Kaixin Li","Zichen Wen","Zhong Li","Conghui He","Xuming Hu","Linfeng Zhang"],"url":"https://arxiv.org/abs/2505.12212"}
{"created":"2025-05-23","title":"Compile-Time Fully Homomorphic Encryption of Vectors: Eliminating Online Encryption via Algebraic Basis Synthesis","abstract":"We propose a framework for compile-time ciphertext synthesis in fully homomorphic encryption (FHE) systems, where ciphertexts are constructed from precomputed encrypted basis vectors combined with a runtime-scaled encryption of zero. This design eliminates online encryption and instead relies solely on ciphertext-level additions and scalar multiplications, enabling efficient data ingestion and algebraic reuse. We formalize the method as a randomized $\\mathbb{Z}_t$-module morphism and prove that it satisfies IND-CPA security under standard assumptions. The proof uses a hybrid game reduction, showing that adversarial advantage in distinguishing synthesized ciphertexts is negligible if the underlying FHE scheme is IND-CPA secure. Unlike prior designs that require a pool of random encryptions of zero, our construction achieves equivalent security using a single zero ciphertext multiplied by a fresh scalar at runtime, reducing memory overhead while preserving ciphertext randomness. The resulting primitive supports efficient integration with standard FHE APIs and maintains compatibility with batching, rotation, and aggregation, making it well-suited for encrypted databases, streaming pipelines, and secure compiler backends.","authors":["Dongfang Zhao"],"url":"https://arxiv.org/abs/2505.12582"}
{"created":"2025-05-23","title":"A Few Large Shifts: Layer-Inconsistency Based Minimal Overhead Adversarial Example Detection","abstract":"Deep neural networks (DNNs) are highly susceptible to adversarial examples--subtle, imperceptible perturbations that can lead to incorrect predictions. While detection-based defenses offer a practical alternative to adversarial training, many existing methods depend on external models, complex architectures, heavy augmentations, or adversarial data, limiting their efficiency and generalizability. We introduce a lightweight, plug-in detection framework that leverages internal layer-wise inconsistencies within the target model itself, requiring only benign data for calibration. Our approach is grounded in the A Few Large Shifts Assumption, which posits that adversarial perturbations typically induce large representation shifts in a small subset of layers. Building on this, we propose two complementary strategies--Recovery Testing (RT) and Logit-layer Testing (LT)--to expose internal disruptions caused by adversaries. Evaluated on CIFAR-10, CIFAR-100, and ImageNet under both standard and adaptive threat models, our method achieves state-of-the-art detection performance with negligible computational overhead and no compromise to clean accuracy. The code is available here: https://github.com/c0510gy/AFLS-AED.","authors":["Sanggeon Yun","Ryozo Masukawa","Hyunwoo Oh","Nathaniel D. Bastian","Mohsen Imani"],"url":"https://arxiv.org/abs/2505.12586"}
{"created":"2025-05-23","title":"LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple Object Tracking","abstract":"Multi-object tracking from LiDAR point clouds presents unique challenges due to the sparse and irregular nature of the data, compounded by the need for temporal coherence across frames. Traditional tracking systems often rely on hand-crafted features and motion models, which can struggle to maintain consistent object identities in crowded or fast-moving scenes. We present a lidar-based two-staged DETR inspired transformer; a smoother and tracker. The smoother stage refines lidar object detections, from any off-the-shelf detector, across a moving temporal window. The tracker stage uses a DETR-based attention block to maintain tracks across time by associating tracked objects with the refined detections using the point cloud as context. The model is trained on the datasets nuScenes and KITTI in both online and offline (forward peeking) modes demonstrating strong performance across metrics such as ID-switch and multiple object tracking accuracy (MOTA). The numerical results indicate that the online mode outperforms the lidar-only baseline and SOTA models on the nuScenes dataset, with an aMOTA of 0.722 and an aMOTP of 0.475, while the offline mode provides an additional 3 pp aMOTP.","authors":["Martha Teiko Teye","Ori Maoz","Matthias Rottmann"],"url":"https://arxiv.org/abs/2505.12753"}
{"created":"2025-05-23","title":"Emergent Specialization: Rare Token Neurons in Language Models","abstract":"Large language models struggle with representing and generating rare tokens despite their importance in specialized domains. In this study, we identify neuron structures with exceptionally strong influence on language model's prediction of rare tokens, termed as rare token neurons, and investigate the mechanism for their emergence and behavior. These neurons exhibit a characteristic three-phase organization (plateau, power-law, and rapid decay) that emerges dynamically during training, evolving from a homogeneous initial state to a functionally differentiated architecture. In the activation space, rare token neurons form a coordinated subnetwork that selectively co-activates while avoiding co-activation with other neurons. This functional specialization potentially correlates with the development of heavy-tailed weight distributions, suggesting a statistical mechanical basis for emergent specialization.","authors":["Jing Liu","Haozheng Wang","Yueheng Li"],"url":"https://arxiv.org/abs/2505.12822"}
{"created":"2025-05-23","title":"Regularized Model Predictive Control","abstract":"In model predictive control (MPC), the choice of cost-weighting matrices and designing the Hessian matrix directly affects the trade-off between rapid state regulation and minimizing the control effort. However, traditional MPC in quadratic programming relies on fixed design matrices across the entire horizon, which can lead to suboptimal performance. This letter presents a Riccati equation-based method for adjusting the design matrix within the MPC framework, which enhances real-time performance. We employ a penalized least-squares (PLS) approach to derive a quadratic cost function for a discrete-time linear system over a finite prediction horizon. Using the method of weighting and enforcing the constraint equation by introducing a large penalty parameter, we solve the constrained optimization problem and generate control inputs for forward-shifted horizons. This process yields a recursive PLS-based Riccati equation that updates the design matrix as a regularization term in each shift, forming the foundation of the regularized MPC (Re-MPC) algorithm. To accomplish this, we provide a convergence and stability analysis of the developed algorithm. Numerical analysis demonstrates its superiority over traditional methods by allowing Riccati equation-based adjustments.","authors":["Komeil Nosrati","Juri Belikov","Aleksei Tepljakov","Eduard Petlenkov"],"url":"https://arxiv.org/abs/2505.12977"}
{"created":"2025-05-23","title":"Treatment Effect Estimation for Optimal Decision-Making","abstract":"Decision-making across various fields, such as medicine, heavily relies on conditional average treatment effects (CATEs). Practitioners commonly make decisions by checking whether the estimated CATE is positive, even though the decision-making performance of modern CATE estimators is poorly understood from a theoretical perspective. In this paper, we study optimal decision-making based on two-stage CATE estimators (e.g., DR-learner), which are considered state-of-the-art and widely used in practice. We prove that, while such estimators may be optimal for estimating CATE, they can be suboptimal when used for decision-making. Intuitively, this occurs because such estimators prioritize CATE accuracy in regions far away from the decision boundary, which is ultimately irrelevant to decision-making. As a remedy, we propose a novel two-stage learning objective that retargets the CATE to balance CATE estimation error and decision performance. We then propose a neural method that optimizes an adaptively-smoothed approximation of our learning objective. Finally, we confirm the effectiveness of our method both empirically and theoretically. In sum, our work is the first to show how two-stage CATE estimators can be adapted for optimal decision-making.","authors":["Dennis Frauen","Valentyn Melnychuk","Jonas Schweisthal","Mihaela van der Schaar","Stefan Feuerriegel"],"url":"https://arxiv.org/abs/2505.13092"}
{"created":"2025-05-23","title":"ToolSpectrum : Towards Personalized Tool Utilization for Large Language Models","abstract":"While integrating external tools into large language models (LLMs) enhances their ability to access real-time information and domain-specific services, existing approaches focus narrowly on functional tool selection following user instructions, overlooking the context-aware personalization in tool selection. This oversight leads to suboptimal user satisfaction and inefficient tool utilization, particularly when overlapping toolsets require nuanced selection based on contextual factors. To bridge this gap, we introduce ToolSpectrum, a benchmark designed to evaluate LLMs' capabilities in personalized tool utilization. Specifically, we formalize two key dimensions of personalization, user profile and environmental factors, and analyze their individual and synergistic impacts on tool utilization. Through extensive experiments on ToolSpectrum, we demonstrate that personalized tool utilization significantly improves user experience across diverse scenarios. However, even state-of-the-art LLMs exhibit the limited ability to reason jointly about user profiles and environmental factors, often prioritizing one dimension at the expense of the other. Our findings underscore the necessity of context-aware personalization in tool-augmented LLMs and reveal critical limitations for current models. Our data and code are available at https://github.com/Chengziha0/ToolSpectrum.","authors":["Zihao Cheng","Hongru Wang","Zeming Liu","Yuhang Guo","Yuanfang Guo","Yunhong Wang","Haifeng Wang"],"url":"https://arxiv.org/abs/2505.13176"}
{"created":"2025-05-23","title":"Policy Contrastive Decoding for Robotic Foundation Models","abstract":"Robotic foundation models, or generalist robot policies, hold immense potential to enable flexible, general-purpose and dexterous robotic systems. Despite their advancements, our empirical experiments reveal that existing robot policies are prone to learning spurious correlations from pre-training trajectories, adversely affecting their generalization capabilities beyond the training data. To tackle this, we propose a novel Policy Contrastive Decoding (PCD) approach, which redirects the robot policy's focus toward object-relevant visual clues by contrasting action probability distributions derived from original and object-masked visual inputs. As a training-free method, our PCD can be used as a plugin to improve different types of robot policies without needing to finetune or access model weights. We conduct extensive experiments on top of three open-source robot policies, including the autoregressive policy OpenVLA and the diffusion-based policies Octo and $\\pi_0$. The obtained results in both simulation and real-world environments prove PCD's flexibility and effectiveness, e.g., PCD enhances the state-of-the-art policy $\\pi_0$ by 8% in the simulation environment and by 108% in the real-world environment. Code and demos are publicly available at: https://Koorye.github.io/proj/PCD.","authors":["Shihan Wu","Ji Zhang","Xu Luo","Junlin Xie","Jingkuan Song","Heng Tao Shen","Lianli Gao"],"url":"https://arxiv.org/abs/2505.13255"}
{"created":"2025-05-23","title":"GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation","abstract":"We present GrasMolmo, a generalizable open-vocabulary task-oriented grasping (TOG) model. GraspMolmo predicts semantically appropriate, stable grasps conditioned on a natural language instruction and a single RGB-D frame. For instance, given \"pour me some tea\", GraspMolmo selects a grasp on a teapot handle rather than its body. Unlike prior TOG methods, which are limited by small datasets, simplistic language, and uncluttered scenes, GraspMolmo learns from PRISM, a novel large-scale synthetic dataset of 379k samples featuring cluttered environments and diverse, realistic task descriptions. We fine-tune the Molmo visual-language model on this data, enabling GraspMolmo to generalize to novel open-vocabulary instructions and objects. In challenging real-world evaluations, GraspMolmo achieves state-of-the-art results, with a 70% prediction success on complex tasks, compared to the 35% achieved by the next best alternative. GraspMolmo also successfully demonstrates the ability to predict semantically correct bimanual grasps zero-shot. We release our synthetic dataset, code, model, and benchmarks to accelerate research in task-semantic robotic manipulation, which, along with videos, are available at https://abhaybd.github.io/GraspMolmo/.","authors":["Abhay Deshpande","Yuquan Deng","Arijit Ray","Jordi Salvador","Winson Han","Jiafei Duan","Kuo-Hao Zeng","Yuke Zhu","Ranjay Krishna","Rose Hendrix"],"url":"https://arxiv.org/abs/2505.13441"}
{"created":"2025-05-23","title":"PandaGuard: Systematic Evaluation of LLM Safety against Jailbreaking Attacks","abstract":"Large language models (LLMs) have achieved remarkable capabilities but remain vulnerable to adversarial prompts known as jailbreaks, which can bypass safety alignment and elicit harmful outputs. Despite growing efforts in LLM safety research, existing evaluations are often fragmented, focused on isolated attack or defense techniques, and lack systematic, reproducible analysis. In this work, we introduce PandaGuard, a unified and modular framework that models LLM jailbreak safety as a multi-agent system comprising attackers, defenders, and judges. Our framework implements 19 attack methods and 12 defense mechanisms, along with multiple judgment strategies, all within a flexible plugin architecture supporting diverse LLM interfaces, multiple interaction modes, and configuration-driven experimentation that enhances reproducibility and practical deployment. Built on this framework, we develop PandaBench, a comprehensive benchmark that evaluates the interactions between these attack/defense methods across 49 LLMs and various judgment approaches, requiring over 3 billion tokens to execute. Our extensive evaluation reveals key insights into model vulnerabilities, defense cost-performance trade-offs, and judge consistency. We find that no single defense is optimal across all dimensions and that judge disagreement introduces nontrivial variance in safety assessments. We release the code, configurations, and evaluation results to support transparent and reproducible research in LLM safety.","authors":["Guobin Shen","Dongcheng Zhao","Linghao Feng","Xiang He","Jihang Wang","Sicheng Shen","Haibo Tong","Yiting Dong","Jindong Li","Xiang Zheng","Yi Zeng"],"url":"https://arxiv.org/abs/2505.13862"}
{"created":"2025-05-23","title":"InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning","abstract":"Leveraging pretrained Vision-Language Models (VLMs) to map language instruction and visual observations to raw low-level actions, Vision-Language-Action models (VLAs) hold great promise for achieving general-purpose robotic systems. Despite their advancements, existing VLAs tend to spuriously correlate task-irrelevant visual features with actions, limiting their generalization capacity beyond the training data. To tackle this challenge, we propose Intrinsic Spatial Reasoning (InSpire), a simple yet effective approach that mitigates the adverse effects of spurious correlations by boosting the spatial reasoning ability of VLAs. Specifically, InSpire redirects the VLA's attention to task-relevant factors by prepending the question \"In which direction is the [object] relative to the robot?\" to the language instruction and aligning the answer \"right/left/up/down/front/back/grasped\" and predicted actions with the ground-truth. Notably, InSpire can be used as a plugin to enhance existing autoregressive VLAs, requiring no extra training data or interaction with other large models. Extensive experimental results in both simulation and real-world environments demonstrate the effectiveness and flexibility of our approach. Our code, pretrained models and demos are publicly available at: https://Koorye.github.io/proj/Inspire.","authors":["Ji Zhang","Shihan Wu","Xu Luo","Hao Wu","Lianli Gao","Heng Tao Shen","Jingkuan Song"],"url":"https://arxiv.org/abs/2505.13888"}
{"created":"2025-05-23","title":"Convergence Guarantees for Gradient-Based Training of Neural PDE Solvers: From Linear to Nonlinear PDEs","abstract":"We present a unified convergence theory for gradient-based training of neural network methods for partial differential equations (PDEs), covering both physics-informed neural networks (PINNs) and the Deep Ritz method. For linear PDEs, we extend the neural tangent kernel (NTK) framework for PINNs to establish global convergence guarantees for a broad class of linear operators. For nonlinear PDEs, we prove convergence to critical points via the \\L{}ojasiewicz inequality under the random feature model, eliminating the need for strong over-parameterization and encompassing both gradient flow and implicit gradient descent dynamics. Our results further reveal that the random feature model exhibits an implicit regularization effect, preventing parameter divergence to infinity. Theoretical findings are corroborated by numerical experiments, providing new insights into the training dynamics and robustness of neural network PDE solvers.","authors":["Wei Zhao","Tao Luo"],"url":"https://arxiv.org/abs/2505.14002"}
{"created":"2025-05-23","title":"Partition-wise Graph Filtering: A Unified Perspective Through the Lens of Graph Coarsening","abstract":"Filtering-based graph neural networks (GNNs) constitute a distinct class of GNNs that employ graph filters to handle graph-structured data, achieving notable success in various graph-related tasks. Conventional methods adopt a graph-wise filtering paradigm, imposing a uniform filter across all nodes, yet recent findings suggest that this rigid paradigm struggles with heterophilic graphs. To overcome this, recent works have introduced node-wise filtering, which assigns distinct filters to individual nodes, offering enhanced adaptability. However, a fundamental gap remains: a comprehensive framework unifying these two strategies is still absent, limiting theoretical insights into the filtering paradigms. Moreover, through the lens of Contextual Stochastic Block Model, we reveal that a synthesis of graph-wise and node-wise filtering provides a sufficient solution for classification on graphs exhibiting both homophily and heterophily, suggesting the risk of excessive parameterization and potential overfitting with node-wise filtering. To address the limitations, this paper introduces Coarsening-guided Partition-wise Filtering (CPF). CPF innovates by performing filtering on node partitions. The method begins with structure-aware partition-wise filtering, which filters node partitions obtained via graph coarsening algorithms, and then performs feature-aware partition-wise filtering, refining node embeddings via filtering on clusters produced by $k$-means clustering over features. In-depth analysis is conducted for each phase of CPF, showing its superiority over other paradigms. Finally, benchmark node classification experiments, along with a real-world graph anomaly detection application, validate CPF's efficacy and practical utility.","authors":["Guoming Li","Jian Yang","Yifan Chen"],"url":"https://arxiv.org/abs/2505.14033"}
{"created":"2025-05-23","title":"Place Recognition: A Comprehensive Review, Current Challenges and Future Directions","abstract":"Place recognition is a cornerstone of vehicle navigation and mapping, which is pivotal in enabling systems to determine whether a location has been previously visited. This capability is critical for tasks such as loop closure in Simultaneous Localization and Mapping (SLAM) and long-term navigation under varying environmental conditions. In this survey, we comprehensively review recent advancements in place recognition, emphasizing three representative methodological paradigms: Convolutional Neural Network (CNN)-based approaches, Transformer-based frameworks, and cross-modal strategies. We begin by elucidating the significance of place recognition within the broader context of autonomous systems. Subsequently, we trace the evolution of CNN-based methods, highlighting their contributions to robust visual descriptor learning and scalability in large-scale environments. We then examine the emerging class of Transformer-based models, which leverage self-attention mechanisms to capture global dependencies and offer improved generalization across diverse scenes. Furthermore, we discuss cross-modal approaches that integrate heterogeneous data sources such as Lidar, vision, and text description, thereby enhancing resilience to viewpoint, illumination, and seasonal variations. We also summarize standard datasets and evaluation metrics widely adopted in the literature. Finally, we identify current research challenges and outline prospective directions, including domain adaptation, real-time performance, and lifelong learning, to inspire future advancements in this domain. The unified framework of leading-edge place recognition methods, i.e., code library, and the results of their experimental evaluations are available at https://github.com/CV4RA/SOTA-Place-Recognitioner.","authors":["Zhenyu Li","Tianyi Shang","Pengjie Xu","Zhaojun Deng"],"url":"https://arxiv.org/abs/2505.14068"}
{"created":"2025-05-23","title":"Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning","abstract":"Retrieval-augmented generation (RAG) enhances the text generation capabilities of large language models (LLMs) by integrating external knowledge and up-to-date information. However, traditional RAG systems are limited by static workflows and lack the adaptability required for multistep reasoning and complex task management. To address these limitations, agentic RAG systems (e.g., DeepResearch) have been proposed, enabling dynamic retrieval strategies, iterative context refinement, and adaptive workflows for handling complex search queries beyond the capabilities of conventional RAG. Recent advances, such as Search-R1, have demonstrated promising gains using outcome-based reinforcement learning, where the correctness of the final answer serves as the reward signal. Nevertheless, such outcome-supervised agentic RAG methods face challenges including low exploration efficiency, gradient conflict, and sparse reward signals. To overcome these challenges, we propose to utilize fine-grained, process-level rewards to improve training stability, reduce computational costs, and enhance efficiency. Specifically, we introduce a novel method ReasonRAG that automatically constructs RAG-ProGuide, a high-quality dataset providing process-level rewards for (i) query generation, (ii) evidence extraction, and (iii) answer generation, thereby enhancing model inherent capabilities via process-supervised reinforcement learning. With the process-level policy optimization, the proposed framework empowers LLMs to autonomously invoke search, generate queries, extract relevant evidence, and produce final answers. Compared to existing approaches such as Search-R1 and traditional RAG systems, ReasonRAG, leveraging RAG-ProGuide, achieves superior performance on five benchmark datasets using only 5k training instances, significantly fewer than the 90k training instances required by Search-R1.","authors":["Wenlin Zhang","Xiangyang Li","Kuicai Dong","Yichao Wang","Pengyue Jia","Xiaopeng Li","Yingyi Zhang","Derong Xu","Zhaocheng Du","Huifeng Guo","Ruiming Tang","Xiangyu Zhao"],"url":"https://arxiv.org/abs/2505.14069"}
{"created":"2025-05-23","title":"BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks","abstract":"Large language model (LLM) based agents have shown great potential in following human instructions and automatically completing various tasks. To complete a task, the agent needs to decompose it into easily executed steps by planning. Existing studies mainly conduct the planning by inferring what steps should be executed next starting from the agent's initial state. However, this forward reasoning paradigm doesn't work well for complex tasks. We propose to study this issue in Minecraft, a virtual environment that simulates complex tasks based on real-world scenarios. We believe that the failure of forward reasoning is caused by the big perception gap between the agent's initial state and task goal. To this end, we leverage backward reasoning and make the planning starting from the terminal state, which can directly achieve the task goal in one step. Specifically, we design a BAckward Reasoning based agent (BAR). It is equipped with a recursive goal decomposition module, a state consistency maintaining module and a stage memory module to make robust, consistent, and efficient planning starting from the terminal state. Experimental results demonstrate the superiority of BAR over existing methods and the effectiveness of proposed modules.","authors":["Weihong Du","Wenrui Liao","Binyu Yan","Hongru Liang","Anthony G. Cohn","Wenqiang Lei"],"url":"https://arxiv.org/abs/2505.14079"}
{"created":"2025-05-23","title":"Regularized least squares learning with heavy-tailed noise is minimax optimal","abstract":"This paper examines the performance of ridge regression in reproducing kernel Hilbert spaces in the presence of noise that exhibits a finite number of higher moments. We establish excess risk bounds consisting of subgaussian and polynomial terms based on the well known integral operator framework. The dominant subgaussian component allows to achieve convergence rates that have previously only been derived under subexponential noise - a prevalent assumption in related work from the last two decades. These rates are optimal under standard eigenvalue decay conditions, demonstrating the asymptotic robustness of regularized least squares against heavy-tailed noise. Our derivations are based on a Fuk-Nagaev inequality for Hilbert-space valued random variables.","authors":["Mattes Mollenhauer","Nicole M\\\"ucke","Dimitri Meunier","Arthur Gretton"],"url":"https://arxiv.org/abs/2505.14214"}
{"created":"2025-05-23","title":"Not All Correct Answers Are Equal: Why Your Distillation Source Matters","abstract":"Distillation has emerged as a practical and effective approach to enhance the reasoning capabilities of open-source language models. In this work, we conduct a large-scale empirical study on reasoning data distillation by collecting verified outputs from three state-of-the-art teacher models-AM-Thinking-v1, Qwen3-235B-A22B, and DeepSeek-R1-on a shared corpus of 1.89 million queries. We construct three parallel datasets and analyze their distributions, revealing that AM-Thinking-v1-distilled data exhibits greater token length diversity and lower perplexity. Student models trained on each dataset are evaluated on reasoning benchmarks including AIME2024, AIME2025, MATH500, and LiveCodeBench. The model distilled from AM-Thinking-v1 consistently achieves the best performance (e.g., 84.3 on AIME2024, 72.2 on AIME2025, 98.4 on MATH500, and 65.9 on LiveCodeBench) and demonstrates adaptive output behavior-producing longer responses for harder tasks and shorter ones for simpler tasks. These findings highlight the value of high-quality, verified reasoning traces. We release the AM-Thinking-v1 and Qwen3-235B-A22B distilled datasets to support future research on open and high-performing reasoning-oriented language models. The datasets are publicly available on Hugging Face\\footnote{Datasets are available on Hugging Face: \\href{https://huggingface.co/datasets/a-m-team/AM-Thinking-v1-Distilled}{AM-Thinking-v1-Distilled}, \\href{https://huggingface.co/datasets/a-m-team/AM-Qwen3-Distilled}{AM-Qwen3-Distilled}.}.","authors":["Xiaoyu Tian","Yunjie Ji","Haotian Wang","Shuaiting Chen","Sitong Zhao","Yiping Peng","Han Zhao","Xiangang Li"],"url":"https://arxiv.org/abs/2505.14464"}
{"created":"2025-05-23","title":"BACON: A fully explainable AI model with graded logic for decision making problems","abstract":"As machine learning models and autonomous agents are increasingly deployed in high-stakes, real-world domains such as healthcare, security, finance, and robotics, the need for transparent and trustworthy explanations has become critical. To ensure end-to-end transparency of AI decisions, we need models that are not only accurate but also fully explainable and human-tunable. We introduce BACON, a novel framework for automatically training explainable AI models for decision making problems using graded logic. BACON achieves high predictive accuracy while offering full structural transparency and precise, logic-based symbolic explanations, enabling effective human-AI collaboration and expert-guided refinement. We evaluate BACON with a diverse set of scenarios: classic Boolean approximation, Iris flower classification, house purchasing decisions and breast cancer diagnosis. In each case, BACON provides high-performance models while producing compact, human-verifiable decision logic. These results demonstrate BACON's potential as a practical and principled approach for delivering crisp, trustworthy explainable AI.","authors":["Haishi Bai","Jozo Dujmovic","Jianwu Wang"],"url":"https://arxiv.org/abs/2505.14510"}
{"created":"2025-05-23","title":"Guarded Query Routing for Large Language Models","abstract":"Query routing, the task to route user queries to different large language model (LLM) endpoints, can be considered as a text classification problem. However, out-of-distribution queries must be handled properly, as those could be questions about unrelated domains, queries in other languages, or even contain unsafe text. Here, we thus study a guarded query routing problem, for which we first introduce the Guarded Query Routing Benchmark (GQR-Bench), which covers three exemplary target domains (law, finance, and healthcare), and seven datasets to test robustness against out-of-distribution queries. We then use GQR-Bench to contrast the effectiveness and efficiency of LLM-based routing mechanisms (GPT-4o-mini, Llama-3.2-3B, and Llama-3.1-8B), standard LLM-based guardrail approaches (LlamaGuard and NVIDIA NeMo Guardrails), continuous bag-of-words classifiers (WideMLP, fastText), and traditional machine learning models (SVM, XGBoost). Our results show that WideMLP, enhanced with out-of-domain detection capabilities, yields the best trade-off between accuracy (88%) and speed (<4ms). The embedding-based fastText excels at speed (<1ms) with acceptable accuracy (80%), whereas LLMs yield the highest accuracy (91%) but are comparatively slow (62ms for local Llama-3.1:8B and 669ms for remote GPT-4o-mini calls). Our findings challenge the automatic reliance on LLMs for (guarded) query routing and provide concrete recommendations for practical applications. GQR-Bench will be released as a Python package -- gqr.","authors":["Richard \\v{S}l\\'eher","William Brach","Tibor Sloboda","Kristi\\'an Ko\\v{s}\\v{t}\\'al","Lukas Galke"],"url":"https://arxiv.org/abs/2505.14524"}
{"created":"2025-05-23","title":"TinyV: Reducing False Negatives in Verification Improves RL for LLM Reasoning","abstract":"Reinforcement Learning (RL) has become a powerful tool for enhancing the reasoning abilities of large language models (LLMs) by optimizing their policies with reward signals. Yet, RL's success relies on the reliability of rewards, which are provided by verifiers. In this paper, we expose and analyze a widespread problem--false negatives--where verifiers wrongly reject correct model outputs. Our in-depth study of the Big-Math-RL-Verified dataset reveals that over 38% of model-generated responses suffer from false negatives, where the verifier fails to recognize correct answers. We show, both empirically and theoretically, that these false negatives severely impair RL training by depriving the model of informative gradient signals and slowing convergence. To mitigate this, we propose tinyV, a lightweight LLM-based verifier that augments existing rule-based methods, which dynamically identifies potential false negatives and recovers valid responses to produce more accurate reward estimates. Across multiple math-reasoning benchmarks, integrating TinyV boosts pass rates by up to 10% and accelerates convergence relative to the baseline. Our findings highlight the critical importance of addressing verifier false negatives and offer a practical approach to improve RL-based fine-tuning of LLMs. Our code is available at https://github.com/uw-nsl/TinyV.","authors":["Zhangchen Xu","Yuetai Li","Fengqing Jiang","Bhaskar Ramasubramanian","Luyao Niu","Bill Yuchen Lin","Radha Poovendran"],"url":"https://arxiv.org/abs/2505.14625"}
{"created":"2025-05-23","title":"General-Reasoner: Advancing LLM Reasoning Across All Domains","abstract":"Reinforcement learning (RL) has recently demonstrated strong potential in enhancing the reasoning capabilities of large language models (LLMs). Particularly, the \"Zero\" reinforcement learning introduced by Deepseek-R1-Zero, enables direct RL training of base LLMs without relying on an intermediate supervised fine-tuning stage. Despite these advancements, current works for LLM reasoning mainly focus on mathematical and coding domains, largely due to data abundance and the ease of answer verification. This limits the applicability and generalization of such models to broader domains, where questions often have diverse answer representations, and data is more scarce. In this paper, we propose General-Reasoner, a novel training paradigm designed to enhance LLM reasoning capabilities across diverse domains. Our key contributions include: (1) constructing a large-scale, high-quality dataset of questions with verifiable answers curated by web crawling, covering a wide range of disciplines; and (2) developing a generative model-based answer verifier, which replaces traditional rule-based verification with the capability of chain-of-thought and context-awareness. We train a series of models and evaluate them on a wide range of datasets covering wide domains like physics, chemistry, finance, electronics etc. Our comprehensive evaluation across these 12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC) demonstrates that General-Reasoner outperforms existing baseline methods, achieving robust and generalizable reasoning performance while maintaining superior effectiveness in mathematical reasoning tasks.","authors":["Xueguang Ma","Qian Liu","Dongfu Jiang","Ge Zhang","Zejun Ma","Wenhu Chen"],"url":"https://arxiv.org/abs/2505.14652"}
{"created":"2025-05-23","title":"UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens","abstract":"Personalized models have demonstrated remarkable success in understanding and generating concepts provided by users. However, existing methods use separate concept tokens for understanding and generation, treating these tasks in isolation. This may result in limitations for generating images with complex prompts. For example, given the concept $\\langle bo\\rangle$, generating \"$\\langle bo\\rangle$ wearing its hat\" without additional textual descriptions of its hat. We call this kind of generation personalized knowledge-driven generation. To address the limitation, we present UniCTokens, a novel framework that effectively integrates personalized information into a unified vision language model (VLM) for understanding and generation. UniCTokens trains a set of unified concept tokens to leverage complementary semantics, boosting two personalized tasks. Moreover, we propose a progressive training strategy with three stages: understanding warm-up, bootstrapping generation from understanding, and deepening understanding from generation to enhance mutual benefits between both tasks. To quantitatively evaluate the unified VLM personalization, we present UnifyBench, the first benchmark for assessing concept understanding, concept generation, and knowledge-driven generation. Experimental results on UnifyBench indicate that UniCTokens shows competitive performance compared to leading methods in concept understanding, concept generation, and achieving state-of-the-art results in personalized knowledge-driven generation. Our research demonstrates that enhanced understanding improves generation, and the generation process can yield valuable insights into understanding. Our code and dataset will be released at: \\href{https://github.com/arctanxarc/UniCTokens}{https://github.com/arctanxarc/UniCTokens}.","authors":["Ruichuan An","Sihan Yang","Renrui Zhang","Zijun Shen","Ming Lu","Gaole Dai","Hao Liang","Ziyu Guo","Shilin Yan","Yulin Luo","Bocheng Zou","Chaoqun Yang","Wentao Zhang"],"url":"https://arxiv.org/abs/2505.14671"}
{"created":"2025-05-23","title":"Harnessing On-Device Large Language Model: Empirical Results and Implications for AI PC","abstract":"The increasing deployment of Large Language Models (LLMs) on edge devices, driven by model advancements and hardware improvements, offers significant privacy benefits. However, these on-device LLMs inherently face performance limitations due to reduced model capacity and necessary compression techniques. To address this, we introduce a systematic methodology -- encompassing model capability, development efficiency, and system resources -- for evaluating on-device LLMs. Our comprehensive evaluation, encompassing models from 0.5B to 14B parameters and seven post-training quantization (PTQ) methods on commodity laptops, yields several critical insights: 1) System-level metrics exhibit near-linear scaling with effective bits-per-weight (BPW). 2) A practical threshold exists around $\\sim$3.5 effective BPW, larger models subjected to low-bit quantization consistently outperform smaller models utilizing higher bit-precision. 3) Quantization with low BPW incurs marginal accuracy loss but significant memory savings. 4) Determined by low-level implementation specifics power consumption on CPU, where computation-intensive operations spend more power than memory-intensive ones. These findings offer crucial insights and practical guidelines for the efficient deployment and optimized configuration of LLMs on resource-constrained edge devices. Our codebase is available at https://github.com/simmonssong/LLMOnDevice.","authors":["Qingyu Song","Peiyu Liao","Wenqian Zhao","Yiwen Wang","Shoubo Hu","Hui-Ling Zhen","Ning Jiang","Mingxuan Yuan"],"url":"https://arxiv.org/abs/2505.15030"}
{"created":"2025-05-23","title":"Big Ramsey degrees using parameter spaces","abstract":"We show that the universal homogeneous partial order has finite big Ramsey degrees and discuss several corollaries. Our proof relies on parameter spaces and the Carlson-Simpson theorem rather than on (a strengthening of) the Halpern-L\\\"auchli theorem and the Milliken tree theorem, which are typically used to bound big Ramsey degrees in the existing literature (originating from the work of Laver and Milliken).","authors":["Jan Hubi\\v{c}ka"],"url":"https://arxiv.org/abs/2009.00967"}
{"created":"2025-05-23","title":"On the Keevash-Knox-Mycroft Conjecture","abstract":"Given $1\\le \\ell  1-(1-1/k)^{k-\\ell}$ and verified the case $\\ell=k-1$.","authors":["Luyining Gan","Jie Han"],"url":"https://arxiv.org/abs/2202.04246"}
{"created":"2025-05-23","title":"A deep solver for BSDEs with jumps","abstract":"The aim of this work is to propose an extension of the deep solver by Han, Jentzen, E (2018) to the case of forward backward stochastic differential equations (FBSDEs) with jumps. As in the aforementioned solver, starting from a discretized version of the FBSDE and parametrizing the (high dimensional) control processes by means of a family of artificial neural networks (ANNs), the FBSDE is viewed as a model-based reinforcement learning problem and the ANN parameters are fitted so as to minimize a prescribed loss function. We take into account both finite and infinite jump activity by introducing, in the latter case, an approximation with finitely many jumps of the forward process. We successfully apply our algorithm to option pricing problems in low and high dimension and discuss the applicability in the context of counterparty credit risk.","authors":["Kristoffer Andersson","Alessandro Gnoatto","Marco Patacca","Athena Picarelli"],"url":"https://arxiv.org/abs/2211.04349"}
{"created":"2025-05-23","title":"Relative-Interior Solution for the (Incomplete) Linear Assignment Problem with Applications to the Quadratic Assignment Problem","abstract":"We study the set of optimal solutions of the dual linear programming formulation of the linear assignment problem (LAP) to propose a method for computing a solution from the relative interior of this set. Assuming that an arbitrary dual-optimal solution and an optimal assignment are available (for which many efficient algorithms already exist), our method computes a relative-interior solution in linear time. Since the LAP occurs as a subproblem in the linear programming (LP) relaxation of the quadratic assignment problem (QAP), we employ our method as a new component in the family of dual-ascent algorithms that provide bounds on the optimal value of the QAP. To make our results applicable to the incomplete QAP, which is of interest in practical use-cases, we also provide a linear-time reduction from the incomplete LAP to the complete LAP along with a mapping that preserves optimality and membership in the relative interior. Our experiments on publicly available benchmarks indicate that our approach with relative-interior solution can frequently provide bounds near the optimum of the LP relaxation and its runtime is much lower when compared to a commercial LP solver.","authors":["Tom\\'a\\v{s} Dlask","Bogdan Savchynskyy"],"url":"https://arxiv.org/abs/2301.11201"}
{"created":"2025-05-23","title":"Label propagation on binomial random graphs","abstract":"We study the behavior of a label propagation algorithm (LPA) on the Erd\\H{o}s-R\\'enyi random graph $\\mathcal{G}(n,p)$. Initially, given a network, each vertex starts with a random label in the interval $[0,1]$. Then, in each round of LPA, every vertex switches its label to the majority label in its neighborhood (including its own label). At the first round, ties are broken towards smaller labels, while at each of the next rounds, ties are broken uniformly at random. The algorithm terminates once all labels stay the same in two consecutive iterations. LPA is successfully used in practice for detecting communities in networks (corresponding to vertex sets with the same label after termination of the algorithm). Perhaps surprisingly, LPA's performance on dense random graphs is hard to analyze, and so far convergence to consensus was known only when $np\\ge n^{3/4+\\varepsilon}$, where LPA converges in three rounds. By defining an alternative label attribution procedure which converges to the label propagation algorithm after three rounds, a careful multi-stage exposure of the edges allows us to break the $n^{3/4+\\varepsilon}$ barrier and show that, when $np \\ge n^{5/8+\\varepsilon}$, a.a.s.\\ the algorithm terminates with a single label. Moreover, we show that, if $np\\gg n^{2/3}$, a.a.s.\\ this label is the smallest one, whereas if $n^{5/8+\\varepsilon}\\le np\\ll n^{2/3}$, the surviving label is a.a.s.\\ not the smallest one. En passant, we show a presumably new monotonicity lemma for Binomial random variables that might be of independent interest.","authors":["Marcos Kiwi","Lyuben Lichev","Dieter Mitsche","Pawe{\\l} Pra{\\l}at"],"url":"https://arxiv.org/abs/2302.03569"}
{"created":"2025-05-23","title":"Estimate-Then-Optimize versus Integrated-Estimation-Optimization versus Sample Average Approximation: A Stochastic Dominance Perspective","abstract":"In data-driven stochastic optimization, model parameters of the underlying distribution need to be estimated from data in addition to the optimization task. Recent literature considers integrating the estimation and optimization processes by selecting model parameters that lead to the best empirical objective performance. This integrated approach, which we call integrated-estimation-optimization (IEO), can be readily shown to outperform simple estimate-then-optimize (ETO) when the model is misspecified. In this paper, we show that a reverse behavior appears when the model class is well-specified and there is sufficient data. Specifically, for a general class of nonlinear stochastic optimization problems, we show that simple ETO outperforms IEO asymptotically when the model class covers the ground truth, in the strong sense of stochastic dominance of the regret. Namely, the entire distribution of the regret, not only its mean or other moments, is always better for ETO compared to IEO. Our results also apply to constrained, contextual optimization problems where the decision depends on observed features. Whenever applicable, we also demonstrate how standard sample average approximation (SAA) performs the worst when the model class is well-specified in terms of regret, and best when it is misspecified. Finally, we provide experimental results to support our theoretical comparisons and illustrate when our insights hold in finite-sample regimes and under various degrees of misspecification.","authors":["Adam N. Elmachtoub","Henry Lam","Haofeng Zhang","Yunfan Zhao"],"url":"https://arxiv.org/abs/2304.06833"}
{"created":"2025-05-23","title":"Artificial intelligence in digital pathology: a systematic review and meta-analysis of diagnostic test accuracy","abstract":"Ensuring diagnostic performance of AI models before clinical use is key to the safe and successful adoption of these technologies. Studies reporting AI applied to digital pathology images for diagnostic purposes have rapidly increased in number in recent years. The aim of this work is to provide an overview of the diagnostic accuracy of AI in digital pathology images from all areas of pathology. This systematic review and meta-analysis included diagnostic accuracy studies using any type of artificial intelligence applied to whole slide images (WSIs) in any disease type. The reference standard was diagnosis through histopathological assessment and / or immunohistochemistry. Searches were conducted in PubMed, EMBASE and CENTRAL in June 2022. We identified 2976 studies, of which 100 were included in the review and 48 in the full meta-analysis. Risk of bias and concerns of applicability were assessed using the QUADAS-2 tool. Data extraction was conducted by two investigators and meta-analysis was performed using a bivariate random effects model. 100 studies were identified for inclusion, equating to over 152,000 whole slide images (WSIs) and representing many disease types. Of these, 48 studies were included in the meta-analysis. These studies reported a mean sensitivity of 96.3% (CI 94.1-97.7) and mean specificity of 93.3% (CI 90.5-95.4) for AI. There was substantial heterogeneity in study design and all 100 studies identified for inclusion had at least one area at high or unclear risk of bias. This review provides a broad overview of AI performance across applications in whole slide imaging. However, there is huge variability in study design and available performance data, with details around the conduct of the study and make up of the datasets frequently missing. Overall, AI offers good accuracy when applied to WSIs but requires more rigorous evaluation of its performance.","authors":["Clare McGenity","Emily L Clarke","Charlotte Jennings","Gillian Matthews","Caroline Cartlidge","Henschel Freduah-Agyemang","Deborah D Stocken","Darren Treanor"],"url":"https://arxiv.org/abs/2306.07999"}
{"created":"2025-05-23","title":"A Fourier Neural Operator Approach for Modelling Exciton-Polariton Condensate Systems","abstract":"A plethora of next-generation all-optical devices based on exciton-polaritons have been proposed in latest years, including prototypes of transistors, switches, analogue quantum simulators and others. However, for such systems consisting of multiple polariton condensates, it is still challenging to predict their properties in a fast and accurate manner. The condensate physics is conventionally described by Gross-Pitaevskii equations (GPEs). While GPU-based solvers currently exist, we propose a significantly more efficient machine-learning-based Fourier neural operator approach to find the solution to the GPE coupled with exciton rate equations, trained on both numerical and experimental datasets. The proposed method predicts solutions almost three orders of magnitude faster than CUDA-based solvers in numerical studies, maintaining the high degree of accuracy. Our method not only accelerates simulations but also opens the door to faster, more scalable designs for all-optical chips and devices, offering profound implications for quantum computing, neuromorphic systems, and beyond.","authors":["Yuan Wang","Surya T. Sathujoda","Krzysztof Sawicki","Kanishk Gandhi","Angelica I Aviles-Rivero","Pavlos G. Lagoudakis"],"url":"https://arxiv.org/abs/2309.15593"}
{"created":"2025-05-23","title":"Generalization error property of infoGAN for two-layer neural network","abstract":"Information Maximizing Generative Adversarial Network (infoGAN) can be understood as a minimax problem involving two neural networks: discriminators and generators with mutual information functions. The infoGAN incorporates various components, including latent variables, mutual information, and objective function. This research demonstrates the Generalization error property of infoGAN as the discriminator and generator sample size approaches infinity. This research explores the generalization error property of InfoGAN as the sample sizes of the discriminator and generator approach infinity. To establish this property, the study considers the difference between the empirical and population versions of the objective function. The error bound is derived from the Rademacher complexity of the discriminator and generator function classes. Additionally, the bound is proven for a two-layer network, where both the discriminator and generator utilize Lipschitz and non-decreasing activation functions.","authors":["Mahmud Hasan","Mathias Muia"],"url":"https://arxiv.org/abs/2310.00443"}
{"created":"2025-05-23","title":"Do we need rebalancing strategies? A theoretical and empirical study around SMOTE and its variants","abstract":"Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced tabular data sets. However, few works analyze SMOTE theoretically. In this paper, we derive several non-asymptotic upper bound on SMOTE density. From these results, we prove that SMOTE (with default parameter) tends to copy the original minority samples asymptotically. We confirm and illustrate empirically this first theoretical behavior on a real-world data-set.bFurthermore, we prove that SMOTE density vanishes near the boundary of the support of the minority class distribution. We then adapt SMOTE based on our theoretical findings to introduce two new variants. These strategies are compared on 13 tabular data sets with 10 state-of-the-art rebalancing procedures, including deep generative and diffusion models. One of our key findings is that, for most data sets, applying no rebalancing strategy is competitive in terms of predictive performances, would it be with LightGBM, tuned random forests or logistic regression. However, when the imbalance ratio is artificially augmented, one of our two modifications of SMOTE leads to promising predictive performances compared to SMOTE and other state-of-the-art strategies.","authors":["Abdoulaye Sakho (LPSM)","Emmanuel Malherbe (LPSM)","Erwan Scornet (LPSM)"],"url":"https://arxiv.org/abs/2402.03819"}
{"created":"2025-05-23","title":"Bounded-Confidence Models of Opinion Dynamics with Neighborhood Effects","abstract":"We generalize bounded-confidence models (BCMs) of opinion dynamics by incorporating neighborhood effects. In a BCM, interacting agents influence each other through dyadic influence if their opinions are sufficiently similar to each other. In our \"neighborhood BCMs\" (NBCMs), interacting agents are influenced both by each other's opinions and by the opinions of the agents in each other's neighborhoods. Our NBCMs thus include both the usual dyadic influence between agents and a \"transitive influence\", which encodes the influence of an agent's neighbors, when determining whether or not an interaction changes the opinions of agents. In this transitive influence, an individual's opinion is influenced by a neighbor when, on average, the opinions of the neighbor's neighbors are sufficiently similar to its own opinion. We formulate both neighborhood Deffuant--Weisbuch (NDW) and neighborhood Hegselmann--Krause (NHK) BCMs.","authors":["Sanjukta Krishnagopal","Mason A. Porter"],"url":"https://arxiv.org/abs/2402.05368"}
{"created":"2025-05-23","title":"QFNN-FFD: Quantum Federated Neural Network for Financial Fraud Detection","abstract":"This study introduces the Quantum Federated Neural Network for Financial Fraud Detection (QFNN-FFD), a cutting-edge framework merging Quantum Machine Learning (QML) and quantum computing with Federated Learning (FL) for financial fraud detection. Using quantum technologies' computational power and the robust data privacy protections offered by FL, QFNN-FFD emerges as a secure and efficient method for identifying fraudulent transactions within the financial sector. Implementing a dual-phase training model across distributed clients enhances data integrity and enables superior performance metrics, achieving precision rates consistently above 95%. Additionally, QFNN-FFD demonstrates exceptional resilience by maintaining an impressive 80% accuracy, highlighting its robustness and readiness for real-world applications. This combination of high performance, security, and robustness against noise positions QFNN-FFD as a transformative advancement in financial technology solutions and establishes it as a new benchmark for privacy-focused fraud detection systems. This framework facilitates the broader adoption of secure, quantum-enhanced financial services and inspires future innovations that could use QML to tackle complex challenges in other areas requiring high confidentiality and accuracy.","authors":["Nouhaila Innan","Alberto Marchisio","Mohamed Bennai","Muhammad Shafique"],"url":"https://arxiv.org/abs/2404.02595"}
{"created":"2025-05-23","title":"Causality Pursuit from Heterogeneous Environments via Neural Adversarial Invariance Learning","abstract":"Pursuing causality from data is a fundamental problem in scientific discovery, treatment intervention, and transfer learning. This paper introduces a novel algorithmic method for addressing nonparametric invariance and causality learning in regression models across multiple environments, where the joint distribution of response variables and covariates varies, but the conditional expectations of outcome given an unknown set of quasi-causal variables are invariant. The challenge of finding such an unknown set of quasi-causal or invariant variables is compounded by the presence of endogenous variables that have heterogeneous effects across different environments. The proposed Focused Adversarial Invariant Regularization (FAIR) framework utilizes an innovative minimax optimization approach that drives regression models toward prediction-invariant solutions through adversarial testing. Leveraging the representation power of neural networks, FAIR neural networks (FAIR-NN) are introduced for causality pursuit. It is shown that FAIR-NN can find the invariant variables and quasi-causal variables under a minimal identification condition and that the resulting procedure is adaptive to low-dimensional composition structures in a non-asymptotic analysis. Under a structural causal model, variables identified by FAIR-NN represent pragmatic causality and provably align with exact causal mechanisms under conditions of sufficient heterogeneity. Computationally, FAIR-NN employs a novel Gumbel approximation with decreased temperature and a stochastic gradient descent ascent algorithm. The procedures are demonstrated using simulated and real-data examples.","authors":["Yihong Gu","Cong Fang","Peter B\\\"uhlmann","Jianqing Fan"],"url":"https://arxiv.org/abs/2405.04715"}
{"created":"2025-05-23","title":"Analysis of clinical, dosimetric and radiomic features for predicting local failure after stereotactic radiotherapy of brain metastases in malignant melanoma","abstract":"Background: This study aimed to predict lesion-specific outcomes after stereotactic radiotherapy (SRT) in patients with brain metastases from malignant melanoma (MBM), using clinical, dosimetric pretherapeutic MRI data. Methods: In this multicenter retrospective study, 517 MBM from 130 patients treated with single-fraction or hypofractionated SRT across three centers were analyzed. From contrast-enhanced T1-weighted MRI, 1576 radiomic features (RF) were extracted per lesion - 788 from the gross tumor volume (GTV), 788 from a 3 mm peritumoral margin. Clinical data, radiation dose and RF from one center were used for feature selection and model development via nested cross-validation; external validation was performed using the other two centers. Results: Local failure occurred in 72 of 517 lesions (13.9%). Predictive models based on clinical data (model 1), RF (model 2), or both (model 3) achieved c-indices of 0.60 +/- 0.15, 0.65 +/- 0.11, and 0.65 +/- 0.12. RF-based models outperformed the clinical model, while dosimetric data alone were not predictive. Most predictive RF came from the peritumoral margin (92%) vs. GTV (76%). On the first external dataset, all models performed similarly (c-index: 0.60-0.63), but showed poor generalization on the second (c-index < 0.50), likely due to differences in patient characteristics and imaging protocols. Conclusions: Information extracted from pretherapeutic MRI, particularly from the peritumoral area, can support accurate prediction of lesion-specific outcomes after SRT in MBM. When combined with clinical data, these imaging-derived markers offer valuable prognostic insights. However, generalizability remains challenging by heterogeneity in patient populations and MRI protocols.","authors":["Nanna E. Hartong","Ilias Sachpazidis","Oliver Blanck","Lucas Etzel","Jan C. Peeken","Stephanie E. Combs","Horst Urbach","Maxim Zaitsev","Dimos Baltas","Ilinca Popp","Anca-Ligia Grosu","Tobias Fechter"],"url":"https://arxiv.org/abs/2405.20825"}
{"created":"2025-05-23","title":"A Discrete Exterior Calculus of Bundle-valued Forms","abstract":"The discretization of Cartan's exterior calculus of differential forms has been fruitful in a variety of theoretical and practical endeavors: from computational electromagnetics to the development of Finite-Element Exterior Calculus, the development of structure-preserving numerical tools satisfying exact discrete equivalents to Stokes' theorem or the de Rham complex for the exterior derivative have found numerous applications in computational physics. However, there has been a dearth of effort in establishing a more general discrete calculus, this time for differential forms with values in vector bundles over a combinatorial manifold equipped with a connection. In this work, we propose a discretization of the exterior covariant derivative of bundle-valued differential forms. We demonstrate that our discrete operator mimics its continuous counterpart, satisfies the Bianchi identities on simplicial cells, and contrary to previous attempts at its discretization, ensures numerical convergence to its exact evaluation with mesh refinement under mild assumptions.","authors":["Theo Braune","Yiying Tong","Fran\\c{c}ois Gay-Balmaz","Mathieu Desbrun"],"url":"https://arxiv.org/abs/2406.05383"}
{"created":"2025-05-23","title":"Bayesian Bandit Algorithms with Approximate Inference in Stochastic Linear Bandits","abstract":"Bayesian bandit algorithms with approximate Bayesian inference have been widely used in real-world applications. Despite the superior practical performance, their theoretical justification is less investigated in the literature, especially for contextual bandit problems. To fill this gap, we propose a theoretical framework to analyze the impact of approximate inference in stochastic linear bandits and conduct frequentist regret analysis on two Bayesian bandit algorithms, Linear Thompson Sampling (LinTS) and the extension of Bayesian Upper Confidence Bound, namely Linear Bayesian Upper Confidence Bound (LinBUCB). We demonstrate that when applied in approximate inference settings, LinTS and LinBUCB can universally preserve their original rates of regret upper bound but with a sacrifice of larger constant terms. These results hold for general Bayesian inference approaches, assuming the inference error measured by two different $\\alpha$-divergences is bounded. Additionally, by introducing a new definition of well-behaved distributions, we show that LinBUCB expedites the regret rate of LinTS from $\\tilde{O}(d^{3/2}\\sqrt{T})$ to $\\tilde{O}(d\\sqrt{T})$, matching the minimax optimal rate. To our knowledge, this work provides the first regret bounds in the setting of stochastic linear bandits with bounded approximate inference errors.","authors":["Ziyi Huang","Henry Lam","Haofeng Zhang"],"url":"https://arxiv.org/abs/2406.14071"}
{"created":"2025-05-23","title":"Clusterpath Gaussian Graphical Modeling","abstract":"Graphical models serve as effective tools for visualizing conditional dependencies between variables. However, as the number of variables grows, interpretation becomes increasingly difficult, and estimation uncertainty increases due to the large number of parameters relative to the number of observations. To address these challenges, we introduce the Clusterpath estimator of the Gaussian Graphical Model (CGGM) that encourages variable clustering in the graphical model in a data-driven way. Through the use of an aggregation penalty, we group variables together, which in turn results in a block-structured precision matrix whose block structure remains preserved in the covariance matrix. The CGGM estimator is formulated as the solution to a convex optimization problem, making it easy to incorporate other popular penalization schemes which we illustrate through the combination of an aggregation and sparsity penalty. We present a computationally efficient implementation of the CGGM estimator by using a cyclic block coordinate descent algorithm. In simulations, we show that CGGM not only matches, but oftentimes outperforms other state-of-the-art methods for variable clustering in graphical models. We also demonstrate CGGM's practical advantages and versatility on a diverse collection of empirical applications.","authors":["D. J. W. Touw","A. Alfons","P. J. F. Groenen","I. Wilms"],"url":"https://arxiv.org/abs/2407.00644"}
{"created":"2025-05-23","title":"Information-Theoretic Foundations for Machine Learning","abstract":"The progress of machine learning over the past decade is undeniable. In retrospect, it is both remarkable and unsettling that this progress was achievable with little to no rigorous theory to guide experimentation. Despite this fact, practitioners have been able to guide their future experimentation via observations from previous large-scale empirical investigations. In this work, we propose a theoretical framework which attempts to provide rigor to existing practices in machine learning. To the theorist, we provide a framework which is mathematically rigorous and leaves open many interesting ideas for future exploration. To the practitioner, we provide a framework whose results are simple, and provide intuition to guide future investigations across a wide range of learning paradigms. Concretely, we provide a theoretical framework rooted in Bayesian statistics and Shannon's information theory which is general enough to unify the analysis of many phenomena in machine learning. Our framework characterizes the performance of an optimal Bayesian learner as it learns from a stream of experience. Unlike existing analyses that weaken with increasing data complexity, our theoretical tools provide accurate insights across diverse machine learning settings. Throughout this work, we derive theoretical results and demonstrate their generality by apply them to derive insights specific to settings. These settings range from learning from data which is independently and identically distributed under an unknown distribution, to data which is sequential, to data which exhibits hierarchical structure amenable to meta-learning, and finally to data which is not fully explainable under the learner's beliefs (misspecification). These results are particularly relevant as we strive to understand and overcome increasingly difficult machine learning challenges in this endlessly complex world.","authors":["Hong Jun Jeon","Benjamin Van Roy"],"url":"https://arxiv.org/abs/2407.12288"}
{"created":"2025-05-23","title":"Gender differences in collaboration and career progression in physics","abstract":"We examine gender differences in collaboration networks and academic career progression in physics. We use the likelihood and time to become a principal investigator (PI) and the length of an author's career to measure career progression. Utilising logistic regression and accelerated failure time models, we examine whether the effect of collaboration behaviour varies by gender. We find that, controlling for the number of publications, the relationship between collaborative behaviour and career progression is almost the same for men and women. Specifically, we find that those who eventually reach principal investigator (PI) status, tend to have published with more unique collaborators. In contrast, publishing repeatedly with the same highly interconnected collaborators and/or larger number of co-authors per publication is characteristic of shorter career lengths and not attaining PI status. We observe that women tend to collaborate in more tightly connected and larger groups than men. Finally, we observe that women are less likely to attain the status of PI throughout their careers and have a lower survival probability compared to men, which calls for policies to close this crucial gap.","authors":["Mingrong She","Jan Bachmann","Fariba Karimi","Leto Peel"],"url":"https://arxiv.org/abs/2408.02482"}
{"created":"2025-05-23","title":"Distributed alternating gradient descent for convex semi-infinite programs over a network","abstract":"This paper presents a first-order distributed algorithm for solving a convex semi-infinite program (SIP) over a time-varying network. In this setting, the objective function associated with the optimization problem is a summation of a set of functions, each held by one node in a network. The semi-infinite constraint, on the other hand, is known to all agents. The nodes collectively aim to solve the problem using local data about the objective and limited communication capabilities depending on the network topology. Our algorithm is built on three key ingredients: consensus step, gradient descent in the local objective, and local gradient descent iterations in the constraint at a node when the estimate violates the semi-infinite constraint. The algorithm is constructed, and its parameters are prescribed in such a way that the iterates held by each agent provably converge to an optimizer. That is, as the algorithm progresses, the estimates achieve consensus, and the constraint violation and the error in the optimal value are bounded above by vanishing terms. Simulation examples illustrate our results.","authors":["Ashwin Aravind","Debasish Chatterjee","Ashish Cherukuri"],"url":"https://arxiv.org/abs/2408.11937"}
{"created":"2025-05-23","title":"VAE-QWGAN: Addressing Mode Collapse in Quantum GANs via Autoencoding Priors","abstract":"Recent proposals for quantum generative adversarial networks (GANs) suffer from the issue of mode collapse, analogous to classical GANs, wherein the distribution learnt by the GAN fails to capture the high mode complexities of the target distribution. Mode collapse can arise due to the use of uninformed prior distributions in the generative learning task. To alleviate the issue of mode collapse for quantum GANs, this work presents a novel \\textbf{hybrid quantum-classical generative model}, the VAE-QWGAN, which combines the strengths of a classical Variational AutoEncoder (VAE) with a hybrid Quantum Wasserstein GAN (QWGAN). The VAE-QWGAN fuses the VAE decoder and QWGAN generator into a single quantum model, and utilizes the VAE encoder for data-dependant latent vector sampling during training. This in turn, enhances the diversity and quality of generated images. To generate new data from the trained model at inference, we sample from a Gaussian mixture model (GMM) prior that is learnt on the latent vectors generated during training. We conduct extensive experiments for image generation QGANs on MNIST/Fashion-MNIST datasets and compute a range of metrics that measure the diversity and quality of generated samples. We show that VAE-QWGAN demonstrates significant improvement over existing QGAN approaches.","authors":["Aaron Mark Thomas","Harry Youel","Sharu Theresa Jose"],"url":"https://arxiv.org/abs/2409.10339"}
{"created":"2025-05-23","title":"The Benefit of Being Bayesian in Online Conformal Prediction","abstract":"Based on the framework of Conformal Prediction (CP), we study the online construction of confidence sets given a black-box machine learning model. By converting the target confidence levels into quantile levels, the problem can be reduced to predicting the quantiles (in hindsight) of a sequentially revealed data sequence. Two very different approaches have been studied previously: (i) Assuming the data sequence is iid or exchangeable, one could maintain the empirical distribution of the observed data as an algorithmic belief, and directly predict its quantiles. (ii) Due to the fragility of statistical assumptions, a recent trend is to consider the non-distributional, adversarial setting and apply first-order online optimization algorithms to moving quantile losses. However, it requires the oracle knowledge of the target quantile level, and suffers from a previously overlooked monotonicity issue due to the associated loss linearization.","authors":["Zhiyu Zhang","Zhou Lu","Heng Yang"],"url":"https://arxiv.org/abs/2410.02561"}
{"created":"2025-05-23","title":"WGFormer: An SE(3)-Transformer Driven by Wasserstein Gradient Flows for Molecular Ground-State Conformation Prediction","abstract":"Predicting molecular ground-state conformation (i.e., energy-minimized conformation) is crucial for many chemical applications such as molecular docking and property prediction. Classic energy-based simulation is time-consuming when solving this problem, while existing learning-based methods have advantages in computational efficiency but sacrifice accuracy and interpretability. In this work, we propose a novel and effective method to bridge the energy-based simulation and the learning-based strategy, which designs and learns a Wasserstein gradient flow-driven SE(3)-Transformer, called WGFormer, for ground-state conformation prediction. Specifically, our method tackles this task within an auto-encoding framework, which encodes low-quality conformations by the proposed WGFormer and decodes corresponding ground-state conformations by an MLP. The architecture of WGFormer corresponds to Wasserstein gradient flows -- it optimizes conformations by minimizing an energy function defined on the latent mixture models of atoms, thereby significantly improving performance and interpretability. Extensive experiments demonstrate that our method consistently outperforms state-of-the-art competitors, providing a new and insightful paradigm to predict ground-state conformation.","authors":["Fanmeng Wang","Minjie Cheng","Hongteng Xu"],"url":"https://arxiv.org/abs/2410.09795"}
{"created":"2025-05-23","title":"Scalable Implicit Graphon Learning","abstract":"Graphons are continuous models that represent the structure of graphs and allow the generation of graphs of varying sizes. We propose Scalable Implicit Graphon Learning (SIGL), a scalable method that combines implicit neural representations (INRs) and graph neural networks (GNNs) to estimate a graphon from observed graphs. Unlike existing methods, which face important limitations like fixed resolution and scalability issues, SIGL learns a continuous graphon at arbitrary resolutions. GNNs are used to determine the correct node ordering, improving graph alignment. Furthermore, we characterize the asymptotic consistency of our estimator, showing that more expressive INRs and GNNs lead to consistent estimators. We evaluate SIGL in synthetic and real-world graphs, showing that it outperforms existing methods and scales effectively to larger graphs, making it ideal for tasks like graph data augmentation.","authors":["Ali Azizpour","Nicolas Zilberstein","Santiago Segarra"],"url":"https://arxiv.org/abs/2410.17464"}
{"created":"2025-05-23","title":"Isotropic Q-fractional Brownian motion on the sphere: regularity and fast simulation","abstract":"As an extension of isotropic Gaussian random fields and Q-Wiener processes on d-dimensional spheres, isotropic Q-fractional Brownian motion is introduced and sample H\\\"older regularity in space-time is shown depending on the regularity of the spatial covariance operator Q and the Hurst parameter H. The processes are approximated by a spectral method in space for which strong and almost sure convergence are shown. The underlying sample paths of fractional Brownian motion are simulated by circulant embedding or conditionalized random midpoint displacement. Temporal accuracy and computational complexity are numerically tested, the latter matching the complexity of simulating a Q-Wiener process if allowing for a temporal error.","authors":["Annika Lang","Bj\\\"orn M\\\"uller"],"url":"https://arxiv.org/abs/2410.19649"}
{"created":"2025-05-23","title":"Bridging the Gap between Reactivity, Contraction, and Finite-Time Lyapunov Exponents","abstract":"Reactivity, contractivity, and Lyapunov exponents are powerful tools for studying the stability properties of dynamical systems and have been extensively investigated in the literature for decades. In this paper, we review and extend the concepts of reactivity, contractivity, and finite-time Lyapunov exponents for discrete-time dynamical systems and establish connections among them. We focus on time-invariant maps, time-varying linear maps, and certain classes of time-varying nonlinear maps. In particular, we show that if the corresponding $p$-iteration systems (with p > 1) are contractive, then the original systems admit stable attractors such as fixed points or limit cycles. We demonstrate the application of these results to the analysis of synchronization stability in coupled networks and discuss how p-iteration systems can serve as a useful framework for studying network synchronization.","authors":["Amirhossein Nazerian","Francesco Sorrentino","Zahra Aminzare"],"url":"https://arxiv.org/abs/2410.23435"}
{"created":"2025-05-23","title":"A Stochastic Dynamic Network Model of the Space Environment","abstract":"This work proposes to model the space environment as a stochastic dynamic network where each node is a group of objects of a given class, or species, and their relationship is represented by stochastic links. A set of stochastic dynamic equations, governing the evolution of the network, are derived from the network structure and topology. It will be shown that the proposed system of stochastic dynamic equations well reproduces existing results on the evolution of the space environment. The analysis of the structure of the network and relationships among node can help to understand which species of objects and orbit regimes are more critical and affect the most the future evolution of the space environment. In analogy with ecological networks, we develop a theory of the carrying capacity of space based on the stability of equilibria of the network dynamics. Some examples are presented starting from the current population of resident objects and different launch traffic forecast models. It will be shown how the proposed network model can be used to study the effect of the adoption of different policies on the execution of collision avoidance and post mission disposal manoeuvres.","authors":["Yirui Wang","Pietro De Marchi","Massimiliano Vasile"],"url":"https://arxiv.org/abs/2411.03173"}
{"created":"2025-05-23","title":"SimSort: A Data-Driven Framework for Spike Sorting by Large-Scale Electrophysiology Simulation","abstract":"Spike sorting is an essential process in neural recording, which identifies and separates electrical signals from individual neurons recorded by electrodes in the brain, enabling researchers to study how specific neurons communicate and process information. Although there exist a number of spike sorting methods which have contributed to significant neuroscientific breakthroughs, many are heuristically designed, making it challenging to verify their correctness due to the difficulty of obtaining ground truth labels from real-world neural recordings. In this work, we explore a data-driven, deep learning-based approach. We begin by creating a large-scale dataset through electrophysiology simulations using biologically realistic computational models. We then present SimSort, a pretraining framework for spike sorting. Trained solely on simulated data, SimSort demonstrates zero-shot generalizability to real-world spike sorting tasks, yielding consistent improvements over existing methods across multiple benchmarks. These results highlight the potential of simulation-driven pretraining to enhance the robustness and scalability of spike sorting in experimental neuroscience.","authors":["Yimu Zhang","Dongqi Han","Yansen Wang","Zhenning Lv","Yu Gu","Dongsheng Li"],"url":"https://arxiv.org/abs/2502.03198"}
{"created":"2025-05-23","title":"ShiftySpeech: A Large-Scale Synthetic Speech Dataset with Distribution Shifts","abstract":"The problem of synthetic speech detection has enjoyed considerable attention, with recent methods achieving low error rates across several established benchmarks. However, to what extent can low error rates on academic benchmarks translate to more realistic conditions? In practice, while the training set is fixed at one point in time, test-time conditions may exhibit distribution shifts relative to the training conditions, such as changes in speaker characteristics, emotional expressiveness, language and acoustic conditions, and the emergence of novel synthesis methods. Although some existing datasets target subsets of these distribution shifts, systematic analysis remains difficult due to inconsistencies between source data and synthesis systems across datasets. This difficulty is further exacerbated by the rapid development of new text-to-speech (TTS) and vocoder systems, which continually expand the diversity of synthetic speech. To enable systematic benchmarking of model performance under distribution shifts, we introduce ShiftySpeech, a large-scale benchmark comprising over 3,000 hours of synthetic speech across 7 source domains, 6 TTS systems, 12 vocoders, and 3 languages. ShiftySpeech is specifically designed to evaluate model generalization under controlled distribution shifts while ensuring broad coverage of modern synthetic speech generation techniques. It fills a key gap in current benchmarks by supporting fine-grained, controlled analysis of generalization robustness. All tested distribution shifts significantly degrade detection performance of state-of-the-art detection approaches based on self-supervised features. Overall, our findings suggest that reliance on synthetic speech detection methods in production environments should be carefully evaluated based on anticipated distribution shifts.","authors":["Ashi Garg","Zexin Cai","Lin Zhang","Henry Li Xinyuan","Leibny Paola Garc\\'ia-Perera","Kevin Duh","Sanjeev Khudanpur","Matthew Wiesner","Nicholas Andrews"],"url":"https://arxiv.org/abs/2502.05674"}
{"created":"2025-05-23","title":"Quantitative analysis of the value of investment in research facilities, with examples from cyberinfrastructure","abstract":"Purpose: How much to invest in research facilities has long been a question in higher education and research policy. We present established and recently developed techniques for assessing the quantitative value created or received as a result of investments in research facilities. This discussion is timely. Financial challenges in higher education may soon force difficult decisions regarding investment in research facilities at some institutions. Clear quantitative analysis will be necessary for such strategic decision-making. Further, institutions of higher education in the USA are currently being called on to justify their value to society. The analyses presented here are extendable to research enterprises as a whole. Results: We present methods developed primarily for analyses of cyberinfrastructure. Most analyses comparing investment in university-based cyberinfrastructure facilities with purchasing services from commercial sources demonstrate positive results for economic and scientific research. A recent assessment, based on a comprehensive accounting approach, has shown that for one large publicly funded cyberinfrastructure project the value delivered to the USA economy and society exceeded the cost to USA taxpayers. Conclusions: Quantitative analyses of the benefits of investment in research and research facilities create a fact-based foundation for discussing the value of research and higher education. These methods enable a quantitative assessment of the relationship between investment in specific research facilities or research projects and economic, societal, and educational outcomes. These methods are of value in quantifying the economic benefit of higher education and in managing investments within such institutions.","authors":["Winona G. Snapp-Childs","David Y. Hancock","Preston M. Smith","John Towns","Craig A. Stewart"],"url":"https://arxiv.org/abs/2502.07833"}
{"created":"2025-05-23","title":"Finite-Sample Analysis of Policy Evaluation for Robust Average Reward Reinforcement Learning","abstract":"We present the first finite-sample analysis for policy evaluation in robust average-reward Markov Decision Processes (MDPs). Prior works in this setting have established only asymptotic convergence guarantees, leaving open the question of sample complexity. In this work, we address this gap by establishing that the robust Bellman operator is a contraction under the span semi-norm, and developing a stochastic approximation framework with controlled bias. Our approach builds upon Multi-Level Monte Carlo (MLMC) techniques to estimate the robust Bellman operator efficiently. To overcome the infinite expected sample complexity inherent in standard MLMC, we introduce a truncation mechanism based on a geometric distribution, ensuring a finite constant sample complexity while maintaining a small bias that decays exponentially with the truncation level. Our method achieves the order-optimal sample complexity of $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ for robust policy evaluation and robust average reward estimation, marking a significant advancement in robust reinforcement learning theory.","authors":["Yang Xu","Washim Uddin Mondal","Vaneet Aggarwal"],"url":"https://arxiv.org/abs/2502.16816"}
{"created":"2025-05-23","title":"Function-Space Learning Rates","abstract":"We consider layerwise function-space learning rates, which measure the magnitude of the change in a neural network's output function in response to an update to a parameter tensor. This contrasts with traditional learning rates, which describe the magnitude of changes in parameter space. We develop efficient methods to measure and set function-space learning rates in arbitrary neural networks, requiring only minimal computational overhead through a few additional backward passes that can be performed at the start of, or periodically during, training. We demonstrate two key applications: (1) analysing the dynamics of standard neural network optimisers in function space, rather than parameter space, and (2) introducing FLeRM (Function-space Learning Rate Matching), a novel approach to hyperparameter transfer across model scales. FLeRM records function-space learning rates while training a small, cheap base model, then automatically adjusts parameter-space layerwise learning rates when training larger models to maintain consistent function-space updates. FLeRM gives hyperparameter transfer across model width, depth, initialisation scale, and LoRA rank in various architectures including MLPs with residual connections and transformers with different layer normalisation schemes.","authors":["Edward Milsom","Ben Anson","Laurence Aitchison"],"url":"https://arxiv.org/abs/2502.17405"}
{"created":"2025-05-23","title":"FLARE: A Framework for Stellar Flare Forecasting using Stellar Physical Properties and Historical Records","abstract":"Stellar flare events are critical observational samples for astronomical research; however, recorded flare events remain limited. Stellar flare forecasting can provide additional flare event samples to support research efforts. Despite this potential, no specialized models for stellar flare forecasting have been proposed to date. In this paper, we present extensive experimental evidence demonstrating that both stellar physical properties and historical flare records are valuable inputs for flare forecasting tasks. We then introduce FLARE (Forecasting Light-curve-based Astronomical Records via features Ensemble), the first-of-its-kind large model specifically designed for stellar flare forecasting. FLARE integrates stellar physical properties and historical flare records through a novel Soft Prompt Module and Residual Record Fusion Module. Our experiments on the publicly available Kepler light curve dataset demonstrate that FLARE achieves superior performance compared to other methods across all evaluation metrics. Finally, we validate the forecast capability of our model through a comprehensive case study.","authors":["Bingke Zhu","Xiaoxiao Wang","Minghui Jia","Yihan Tao","Xiao Kong","Ali Luo","Yingying Chen","Ming Tang","Jinqiao Wang"],"url":"https://arxiv.org/abs/2502.18218"}
{"created":"2025-05-23","title":"Liver Cirrhosis Stage Estimation from MRI with Deep Learning","abstract":"We present an end-to-end deep learning framework for automated liver cirrhosis stage estimation from multi-sequence MRI. Cirrhosis is the severe scarring (fibrosis) of the liver and a common endpoint of various chronic liver diseases. Early diagnosis is vital to prevent complications such as decompensation and cancer, which significantly decreases life expectancy. However, diagnosing cirrhosis in its early stages is challenging, and patients often present with life-threatening complications. Our approach integrates multi-scale feature learning with sequence-specific attention mechanisms to capture subtle tissue variations across cirrhosis progression stages. Using CirrMRI600+, a large-scale publicly available dataset of 628 high-resolution MRI scans from 339 patients, we demonstrate state-of-the-art performance in three-stage cirrhosis classification. Our best model achieves 72.8% accuracy on T1W and 63.8% on T2W sequences, significantly outperforming traditional radiomics-based approaches. Through extensive ablation studies, we show that our architecture effectively learns stage-specific imaging biomarkers. We establish new benchmarks for automated cirrhosis staging and provide insights for developing clinically applicable deep learning systems. The source code will be available at https://github.com/JunZengz/CirrhosisStage.","authors":["Jun Zeng","Debesh Jha","Ertugrul Aktas","Elif Keles","Alpay Medetalibeyoglu","Matthew Antalek","Federica Proietto Salanitri","Amir A. Borhani","Daniela P. Ladner","Gorkem Durak","Ulas Bagci"],"url":"https://arxiv.org/abs/2502.18225"}
{"created":"2025-05-23","title":"Fast computation of the TGOSPA metric for multiple target tracking via unbalanced optimal transport","abstract":"In multiple target tracking, it is important to be able to evaluate the performance of different tracking algorithms. The trajectory generalized optimal sub-pattern assignment metric (TGOSPA) is a recently proposed metric for such evaluations. The TGOSPA metric is computed as the solution to an optimization problem, but for large tracking scenarios, solving this problem becomes computationally demanding. In this paper, we present an approximation algorithm for evaluating the TGOSPA metric, based on casting the TGOSPA problem as an unbalanced multimarginal optimal transport problem. Following recent advances in computational optimal transport, we introduce an entropy regularization and derive an iterative scheme for solving the Lagrangian dual of the regularized problem. Numerical results suggest that our proposed algorithm is more computationally efficient than the alternative of computing the exact metric using a linear programming solver, while still providing an adequate approximation of the metric.","authors":["Viktor Nevelius Wernholm","Alfred W\\\"arns\\\"ater","Axel Ringh"],"url":"https://arxiv.org/abs/2503.09449"}
{"created":"2025-05-23","title":"Interacting Twisted Bilayer Graphene with Systematic Modeling of Structural Relaxation","abstract":"Twisted bilayer graphene (TBG) has drawn significant interest due to recent experiments which show that TBG can exhibit strongly correlated behavior such as the superconducting and correlated insulator phases. Much of the theoretical work on TBG has been based on analysis of the Bistritzer-MacDonald model which includes a phenomenological parameter to account for lattice relaxation. In this work, we use a newly developed continuum model which systematically accounts for the effects of structural relaxation. In particular, we model structural relaxation by coupling linear elasticity to a stacking energy that penalizes disregistry. We compare the impact of the two relaxation models on the corresponding many-body model by defining an interacting model projected to the flat bands. We perform tests at charge neutrality at both the Hartree-Fock and Coupled Cluster Singles and Doubles (CCSD) level of theory and find the systematic relaxation model gives quantitative differences from the simplified relaxation model.","authors":["Tianyu Kong","Alexander B. Watson","Mitchell Luskin","Kevin D. Stubbs"],"url":"https://arxiv.org/abs/2504.03479"}
{"created":"2025-05-23","title":"PolyConf: Unlocking Polymer Conformation Generation through Hierarchical Generative Models","abstract":"Polymer conformation generation is a critical task that enables atomic-level studies of diverse polymer materials. While significant advances have been made in designing conformation generation methods for small molecules and proteins, these methods struggle to generate polymer conformations due to their unique structural characteristics. Meanwhile, the scarcity of polymer conformation datasets further limits the progress, making this important area largely unexplored. In this work, we propose PolyConf, a pioneering tailored polymer conformation generation method that leverages hierarchical generative models to unlock new possibilities. Specifically, we decompose the polymer conformation into a series of local conformations (i.e., the conformations of its repeating units), generating these local conformations through an autoregressive model, and then generating their orientation transformations via a diffusion model to assemble them into the complete polymer conformation. Moreover, we develop the first benchmark with a high-quality polymer conformation dataset derived from molecular dynamics simulations to boost related research in this area. The comprehensive evaluation demonstrates that PolyConf consistently outperforms existing conformation generation methods, thus facilitating advancements in polymer modeling and simulation.","authors":["Fanmeng Wang","Wentao Guo","Qi Ou","Hongshuai Wang","Haitao Lin","Hongteng Xu","Zhifeng Gao"],"url":"https://arxiv.org/abs/2504.08859"}
{"created":"2025-05-23","title":"Estimation of discrete distributions in relative entropy, and the deviations of the missing mass","abstract":"We study the problem of estimating a distribution over a finite alphabet from an i.i.d. sample, with accuracy measured in relative entropy (Kullback-Leibler divergence). While optimal expected risk bounds are known, high-probability guarantees remain less well-understood. First, we analyze the classical Laplace (add-one) estimator, obtaining matching upper and lower bounds on its performance and showing its optimality among confidence-independent estimators. We then characterize the minimax-optimal high-probability risk, which is attained via a simple confidence-dependent smoothing technique. Interestingly, the optimal non-asymptotic risk exhibits an additional logarithmic factor over the ideal asymptotic risk. Next, motivated by scenarios where the alphabet exceeds the sample size, we investigate methods that adapt to the sparsity of the distribution at hand. We introduce an estimator using data-dependent smoothing, for which we establish a high-probability risk bound depending on two effective sparsity parameters. As part of the analysis, we also derive a sharp high-probability upper bound on the missing mass.","authors":["Jaouad Mourtada"],"url":"https://arxiv.org/abs/2504.21787"}
{"created":"2025-05-23","title":"SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction","abstract":"Recent advances in machine learning have demonstrated an enormous utility of deep learning approaches, particularly Graph Neural Networks (GNNs) for materials science. These methods have emerged as powerful tools for high-throughput prediction of material properties, offering a compelling enhancement and alternative to traditional first-principles calculations. While the community has predominantly focused on developing increasingly complex and universal models to enhance predictive accuracy, such approaches often lack physical interpretability and insights into materials behavior. Here, we introduce a novel computational paradigm, Self-Adaptable Graph Attention Networks integrated with Symbolic Regression (SA-GAT-SR), that synergistically combines the predictive capability of GNNs with the interpretative power of symbolic regression. Our framework employs a self-adaptable encoding algorithm that automatically identifies and adjust attention weights so as to screen critical features from an expansive 180-dimensional feature space while maintaining O(n) computational scaling. The integrated SR module subsequently distills these features into compact analytical expressions that explicitly reveal quantum-mechanically meaningful relationships, achieving 23 times acceleration compared to conventional SR implementations that heavily rely on first principle calculations-derived features as input. This work suggests a new framework in computational materials science, bridging the gap between predictive accuracy and physical interpretability, offering valuable physical insights into material behavior.","authors":["Junchi Liu","Ying Tang","Sergei Tretiak","Wenhui Duan","Liujiang Zhou"],"url":"https://arxiv.org/abs/2505.00625"}
{"created":"2025-05-23","title":"Temporal Robustness in Discrete Time Linear Dynamical Systems","abstract":"Discrete time linear dynamical systems, including Markov chains, have found many applications. However, in some problems, there is uncertainty about the time horizon for which the system runs. This creates uncertainty about the cost (or reward) incurred based on the state distribution when the system stops. Given past data samples of how long a system ran, we propose to theoretically analyze a distributional robust cost estimation task in a Wasserstein ambiguity set, instead of learning a probability distribution from a few samples. Towards this, we show an equivalence between a discrete time Markov Chain on a probability simplex and a global asymptotic stable (GAS) discrete time linear dynamical system, allowing us to base our study on a GAS system only. Then, we provide various polynomial time algorithms and hardness results for different cases in our theoretical study, including a fundamental result about Wasserstein distance based polytope.","authors":["Nilava Metya","Arunesh Sinha"],"url":"https://arxiv.org/abs/2505.02347"}
{"created":"2025-05-23","title":"Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection","abstract":"Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to learn robust representations from large-scale natural image datasets, enhancing their generalization across domains. In retinal imaging, foundation models pretrained on either natural or ophthalmic data have shown promise, but the benefits of in-domain pretraining remain uncertain. To investigate this, we benchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets totaling 70,000 expert-annotated images for the task of moderate-to-late age-related macular degeneration (AMD) identification. Our results show that iBOT pretrained on natural images achieves the highest out-of-distribution generalization, with AUROCs of 0.80-0.97, outperforming domain-specific models, which achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining, which achieved AUROCs of 0.68-0.91. These findings highlight the value of foundation models in improving AMD identification and challenge the assumption that in-domain pretraining is necessary. Furthermore, we release BRAMD, an open-access dataset (n=587) of DFIs with AMD labels from Brazil.","authors":["Benjamin A. Cohen","Jonathan Fhima","Meishar Meisel","Baskin Meital","Luis Filipe Nakayama","Eran Berkowitz","Joachim A. Behar"],"url":"https://arxiv.org/abs/2505.05291"}
{"created":"2025-05-23","title":"Robust Online Learning with Private Information","abstract":"This paper investigates the robustness of online learning algorithms when learners possess private information. No-external-regret algorithms, prevalent in machine learning, are vulnerable to strategic manipulation, allowing an adaptive opponent to extract full surplus. Even standard no-weak-external-regret algorithms, designed for optimal learning in stationary environments, exhibit similar vulnerabilities. This raises a fundamental question: can a learner simultaneously prevent full surplus extraction by adaptive opponents while maintaining optimal performance in well-behaved environments? To address this, we model the problem as a two-player repeated game, where the learner with private information plays against the environment, facing ambiguity about the environment's types: stationary or adaptive. We introduce \\emph{partial safety} as a key design criterion for online learning algorithms to prevent full surplus extraction. We then propose the \\emph{Explore-Exploit-Punish} (\\textsf{EEP}) algorithm and prove that it satisfies partial safety while achieving optimal learning in stationary environments, and has a variant that delivers improved welfare performance. Our findings highlight the risks of applying standard online learning algorithms in strategic settings with adverse selection. We advocate for a shift toward online learning algorithms that explicitly incorporate safeguards against strategic manipulation while ensuring strong learning performance.","authors":["Kyohei Okumura"],"url":"https://arxiv.org/abs/2505.05341"}
{"created":"2025-05-23","title":"FlowHFT: Imitation Learning via Flow Matching Policy for Optimal High-Frequency Trading under Diverse Market Conditions","abstract":"High-frequency trading (HFT) is an investing strategy that continuously monitors market states and places bid and ask orders at millisecond speeds. Traditional HFT approaches fit models with historical data and assume that future market states follow similar patterns. This limits the effectiveness of any single model to the specific conditions it was trained for. Additionally, these models achieve optimal solutions only under specific market conditions, such as assumptions about stock price's stochastic process, stable order flow, and the absence of sudden volatility. Real-world markets, however, are dynamic, diverse, and frequently volatile. To address these challenges, we propose the FlowHFT, a novel imitation learning framework based on flow matching policy. FlowHFT simultaneously learns strategies from numerous expert models, each proficient in particular market scenarios. As a result, our framework can adaptively adjust investment decisions according to the prevailing market state. Furthermore, FlowHFT incorporates a grid-search fine-tuning mechanism. This allows it to refine strategies and achieve superior performance even in complex or extreme market scenarios where expert strategies may be suboptimal. We test FlowHFT in multiple market environments. We first show that flow matching policy is applicable in stochastic market environments, thus enabling FlowHFT to learn trading strategies under different market conditions. Notably, our single framework consistently achieves performance superior to the best expert for each market condition.","authors":["Yang Li","Zhi Chen","Steve Yang"],"url":"https://arxiv.org/abs/2505.05784"}
{"created":"2025-05-23","title":"Constrained Online Decision-Making: A Unified Framework","abstract":"Contextual online decision-making problems with constraints appear in a wide range of real-world applications, such as adaptive experimental design under safety constraints, personalized recommendation with resource limits, and dynamic pricing under fairness requirements. In this paper, we investigate a general formulation of sequential decision-making with stage-wise feasibility constraints, where at each round, the learner must select an action based on observed context while ensuring that a problem-specific feasibility criterion is satisfied. We propose a unified algorithmic framework that captures many existing constrained learning problems, including constrained bandits, active learning with label budgets, online hypothesis testing with Type I error control, and model calibration. Central to our approach is the concept of upper counterfactual confidence bounds, which enables the design of practically efficient online algorithms with strong theoretical guarantees using any offline conditional density estimation oracle. To handle feasibility constraints in complex environments, we introduce a generalized notion of the eluder dimension, extending it from the classical setting based on square loss to a broader class of metric-like probability divergences. This allows us to capture the complexity of various density function classes and characterize the utility regret incurred due to feasibility constraint uncertainty. Our result offers a principled foundation for constrained sequential decision-making in both theory and practice.","authors":["Haichen Hu","David Simchi-Levi","Navid Azizan"],"url":"https://arxiv.org/abs/2505.07101"}
{"created":"2025-05-23","title":"Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification","abstract":"The management of chronic Heart Failure (HF) presents significant challenges in modern healthcare, requiring continuous monitoring, early detection of exacerbations, and personalized treatment strategies. In this paper, we present a predictive model founded on Machine Learning (ML) techniques to identify patients at HF risk. This model is an ensemble learning approach, a modified stacking technique, that uses two specialized models leveraging clinical and echocardiographic features and then a meta-model to combine the predictions of these two models. We initially assess the model on a real dataset and the obtained results suggest that it performs well in the stratification of patients at HR risk. Specifically, we obtained high sensitivity (95\\%), ensuring that nearly all high-risk patients are identified. As for accuracy, we obtained 84\\%, which can be considered moderate in some ML contexts. However, it is acceptable given our priority of identifying patients at risk of HF because they will be asked to participate in the telemonitoring program of the PrediHealth research project on which some of the authors of this paper are working. The initial findings also suggest that ML-based risk stratification models can serve as valuable decision-support tools not only in the PrediHealth project but also for healthcare professionals, aiding in early intervention and personalized patient management. To have a better understanding of the value and of potentiality of our predictive model, we also contrasted its results with those obtained by using three baseline models. The preliminary results indicate that our predictive model outperforms these baselines that flatly consider features, \\ie not grouping them in clinical and echocardiographic features.","authors":["Pietro Cassieri","Aiman Faiz","Anna Maria De Roberto","Claudio Pascarelli","Gianvito Mitrano","Gianluca Fimiani","Marina Garofano","Genoveffa Tortora","Mariangela Lazoi","Claudio Passino","Alessia Bramanti","Giuseppe Scanniello"],"url":"https://arxiv.org/abs/2505.09619"}
{"created":"2025-05-23","title":"Supervised Models Can Generalize Also When Trained on Random Labels","abstract":"The success of unsupervised learning raises the question of whether also supervised models can be trained without using the information in the output $y$. In this paper, we demonstrate that this is indeed possible. The key step is to formulate the model as a smoother, i.e. on the form $\\hat{f}=Sy$, and to construct the smoother matrix $S$ independently of $y$, e.g. by training on random labels. We present a simple model selection criterion based on the distribution of the out-of-sample predictions and show that, in contrast to cross-validation, this criterion can be used also without access to $y$. We demonstrate on real and synthetic data that $y$-free trained versions of linear and kernel ridge regression, smoothing splines, and neural networks perform similarly to their standard, $y$-based, versions and, most importantly, significantly better than random guessing.","authors":["Oskar Allerbo","Thomas B. Sch\\\"on"],"url":"https://arxiv.org/abs/2505.11006"}
{"created":"2025-05-23","title":"Vague Knowledge: Evidence from Analyst Reports","abstract":"People in the real world often possess vague knowledge of future payoffs, for which quantification is not feasible or desirable. We argue that language, with differing ability to convey vague information, plays an important but less known-role in representing subjective expectations. Empirically, we find that in their reports, analysts include useful information in linguistic expressions but not numerical forecasts. Specifically, the textual tone of analyst reports has predictive power for forecast errors and subsequent revisions in numerical forecasts, and this relation becomes stronger when analyst's language is vaguer, when uncertainty is higher, and when analysts are busier. Overall, our theory and evidence suggest that some useful information is vaguely known and only communicated through language.","authors":["Kerry Xiao","Amy Zang"],"url":"https://arxiv.org/abs/2505.12269"}
{"created":"2025-05-23","title":"Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising","abstract":"Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend to preserve the acoustic environment of the audio prompt, leading to degradation in synthesized speech quality when the audio prompt contains noise. In this paper, we propose a novel neural codec-based speech denoiser and integrate it with the advanced LLM-based TTS model, LauraTTS, to achieve noise-robust zero-shot TTS. The proposed codec denoiser consists of an audio codec, a token denoiser, and an embedding refiner. The token denoiser predicts the first two groups of clean acoustic tokens from the noisy ones, which can serve as the acoustic prompt for LauraTTS to synthesize high-quality personalized speech or be converted to clean speech waveforms through the embedding refiner and codec decoder. Experimental results show that our proposed codec denoiser outperforms state-of-the-art speech enhancement (SE) methods, and the proposed noise-robust LauraTTS surpasses the approach using additional SE models.","authors":["Ye-Xin Lu","Hui-Peng Du","Fei Liu","Yang Ai","Zhen-Hua Ling"],"url":"https://arxiv.org/abs/2505.13830"}
{"created":"2025-05-23","title":"A Probabilistic Perspective on Model Collapse","abstract":"In recent years, model collapse has become a critical issue in language model training, making it essential to understand the underlying mechanisms driving this phenomenon. In this paper, we investigate recursive parametric model training from a probabilistic perspective, aiming to characterize the conditions under which model collapse occurs and, crucially, how it can be mitigated. We conceptualize the recursive training process as a random walk of the model estimate, highlighting how the sample size influences the step size and how the estimation procedure determines the direction and potential bias of the random walk. Under mild conditions, we rigorously show that progressively increasing the sample size at each training step is necessary to prevent model collapse. In particular, when the estimation is unbiased, the required growth rate follows a superlinear pattern. This rate needs to be accelerated even further in the presence of substantial estimation bias. Building on this probabilistic framework, we also investigate the probability that recursive training on synthetic data yields models that outperform those trained solely on real data. Moreover, we extend these results to general parametric model family in an asymptotic regime. Finally, we validate our theoretical results through extensive simulations and a real-world dataset.","authors":["Shirong Xu","Hengzhi He","Guang Cheng"],"url":"https://arxiv.org/abs/2505.13947"}
