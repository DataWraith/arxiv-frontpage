{"created":"2025-06-04","title":"SubMIT: A Physics Analysis Facility at MIT","abstract":"The recently completed SubMIT platform is a small set of servers that provide interactive access to substantial data samples at high speeds, enabling sophisticated data analyses with very fast turnaround times. Additionally, it seamlessly integrates massive processing resources for large-scale tasks by connecting to a set of powerful batch processing systems. It serves as an ideal prototype for an Analysis Facility tailored to meet the demanding data and computational requirements anticipated during the High-Luminosity phase of the Large Hadron Collider. The key features that make this facility so powerful include highly optimized data access with a minimum of 100Gbps networking per server, a large managed NVMe storage system, and a substantial spinning-disk Ceph file system. The platform integrates a diverse set of high multicore CPU machines for tasks benefiting from the multithreading and GPU resources for example for neural network training. SubMIT also provides and supports a flexible environment for users to manage their own software needs for example by using containers. This article describes the facility, its users, and a few complementary, generic and real-life analyses that are used to benchmark its various capabilities.","authors":["Josh Bendavid (Massachusetts Institute of Technology","CERN)","Mariarosaria D'Alfonso (Massachusetts Institute of Technology)","Jan Eysermans (Massachusetts Institute of Technology)","Chad Freer (Massachusetts Institute of Technology)","Maxim Goncharov (Massachusetts Institute of Technology)","Matthew Heine (Massachusetts Institute of Technology)","Luca Lavezzo (Massachusetts Institute of Technology)","Marianne Moore (Massachusetts Institute of Technology)","Christoph Paus (Massachusetts Institute of Technology)","Xuejian Shen (Massachusetts Institute of Technology)","David Walter (Massachusetts Institute of Technology)","Zhangqier Wang (Massachusetts Institute of Technology)"],"url":"https://arxiv.org/abs/2506.01958"}
{"created":"2025-06-04","title":"Ubiquitous Symmetry at Critical Points Across Diverse Optimization Landscapes","abstract":"Symmetry plays a crucial role in understanding the properties of mathematical structures and optimization problems. Recent work has explored this phenomenon in the context of neural networks, where the loss function is invariant under column and row permutations of the network weights. It has been observed that local minima exhibit significant symmetry with respect to the network weights (invariance to row and column permutations). And moreover no critical point was found that lacked symmetry. We extend this line of inquiry by investigating symmetry phenomena in real-valued loss functions defined on a broader class of spaces. We will introduce four more cases: the projective case over a finite field, the octahedral graph case, the perfect matching case, and the particle attraction case. We show that as in the neural network case, all the critical points observed have non-trivial symmetry. Finally we introduce a new measure of symmetry in the system and show that it reveals additional symmetry structures not captured by the previous measure.","authors":["Irmi Schneider"],"url":"https://arxiv.org/abs/2506.01959"}
{"created":"2025-06-04","title":"Mazzaroth: A High-Throughput DAG Consensus with State Root","abstract":"Nakamoto Consensus achieves a decentralized ledger through a single-chain blockchain, assuming a maximum network delay, which limits block generation speed, resulting in low throughput. \\cite{pg2018} (PG) enhances throughput using a blockDAG structure, but its probabilistic confirmation restricts smart contract applications. To address this, Mazzaroth proposes a Pow-based blockDAG consensus, employing a linear ordering algorithm to compute the \\cite{eth} and achieve state finality, thereby supporting smart contracts. Its dynamic difficulty adjustment, independent of the assumption, adapts to network and hashrate fluctuations, ensuring state consistency via a head chain while maximizing throughput. Simulations validate Mazzaroth's efficient consensus performance. This paper presents the Mazzaroth ordering algorithm, the difficulty adjustment mechanism, and performance evaluation.","authors":["Haohan Li"],"url":"https://arxiv.org/abs/2506.01960"}
{"created":"2025-06-04","title":"Research on Medical Named Entity Identification Based On Prompt-Biomrc Model and Its Application in Intelligent Consultation System","abstract":"This study is dedicated to exploring the application of prompt learning methods to advance Named Entity Recognition (NER) within the medical domain. In recent years, the emergence of large-scale models has driven significant progress in NER tasks, particularly with the introduction of the BioBERT language model, which has greatly enhanced NER capabilities in medical texts. Our research introduces the Prompt-bioMRC model, which integrates both hard template and soft prompt designs aimed at refining the precision and efficiency of medical entity recognition. Through extensive experimentation across diverse medical datasets, our findings consistently demonstrate that our approach surpasses traditional models. This enhancement not only validates the efficacy of our methodology but also highlights its potential to provide reliable technological support for applications like intelligent diagnosis systems. By leveraging advanced NER techniques, this study contributes to advancing automated medical data processing, facilitating more accurate medical information extraction, and supporting efficient healthcare decision-making processes.","authors":["Jinzhu Yang"],"url":"https://arxiv.org/abs/2506.01961"}
{"created":"2025-06-04","title":"Graph-Based Adversarial Domain Generalization with Anatomical Correlation Knowledge for Cross-User Human Activity Recognition","abstract":"Cross-user variability poses a significant challenge in sensor-based Human Activity Recognition (HAR) systems, as traditional models struggle to generalize across users due to differences in behavior, sensor placement, and data distribution. To address this, we propose GNN-ADG (Graph Neural Network with Adversarial Domain Generalization), a novel method that leverages both the strength from both the Graph Neural Networks (GNNs) and adversarial learning to achieve robust cross-user generalization. GNN-ADG models spatial relationships between sensors on different anatomical body parts, extracting three types of Anatomical Units: (1) Interconnected Units, capturing inter-relations between neighboring sensors; (2) Analogous Units, grouping sensors on symmetrical or functionally similar body parts; and (3) Lateral Units, connecting sensors based on their position to capture region-specific coordination. These units information are fused into an unified graph structure with a cyclic training strategy, dynamically integrating spatial, functional, and lateral correlations to facilitate a holistic, user-invariant representation. Information fusion mechanism of GNN-ADG occurs by iteratively cycling through edge topologies during training, allowing the model to refine its understanding of inter-sensor relationships across diverse perspectives. By representing the spatial configuration of sensors as an unified graph and incorporating adversarial learning, Information Fusion GNN-ADG effectively learns features that generalize well to unseen users without requiring target user data during training, making it practical for real-world applications.","authors":["Xiaozhou Ye","Kevin I-Kai Wang"],"url":"https://arxiv.org/abs/2506.01962"}
{"created":"2025-06-04","title":"Breaking Quadratic Barriers: A Non-Attention LLM for Ultra-Long Context Horizons","abstract":"We present a novel non attention based architecture for large language models (LLMs) that efficiently handles very long context windows, on the order of hundreds of thousands to potentially millions of tokens. Unlike traditional Transformer designs, which suffer from quadratic memory and computation overload due to the nature of the self attention mechanism, our model avoids token to token attention entirely. Instead, it combines the following complementary components: State Space blocks (inspired by S4) that learn continuous time convolution kernels and scale near linearly with sequence length, Multi Resolution Convolution layers that capture local context at different dilation levels, a lightweight Recurrent Supervisor to maintain a global hidden state across sequential chunks, and Retrieval Augmented External Memory that stores and retrieves high-level chunk embeddings without reintroducing quadratic operations.","authors":["Andrew Kiruluta","Preethi Raju","Priscilla Burity"],"url":"https://arxiv.org/abs/2506.01963"}
{"created":"2025-06-04","title":"A Data-Driven Approach to Enhancing Gravity Models for Trip Demand Prediction","abstract":"Accurate prediction of trips between zones is critical for transportation planning, as it supports resource allocation and infrastructure development across various modes of transport. Although the gravity model has been widely used due to its simplicity, it often inadequately represents the complex factors influencing modern travel behavior. This study introduces a data-driven approach to enhance the gravity model by integrating geographical, economic, social, and travel data from the counties in Tennessee and New York state. Using machine learning techniques, we extend the capabilities of the traditional model to handle more complex interactions between variables. Our experiments demonstrate that machine learning-enhanced models significantly outperform the traditional model. Our results show a 51.48% improvement in R-squared, indicating a substantial enhancement in the model's explanatory power. Also, a 63.59% reduction in Mean Absolute Error (MAE) reflects a significant increase in prediction accuracy. Furthermore, a 44.32% increase in Common Part of Commuters (CPC) demonstrates improved prediction reliability. These findings highlight the substantial benefits of integrating diverse datasets and advanced algorithms into transportation models. They provide urban planners and policymakers with more reliable forecasting and decision-making tools.","authors":["Kamal Acharya","Mehul Lad","Liang Sun","Houbing Song"],"url":"https://arxiv.org/abs/2506.01964"}
{"created":"2025-06-04","title":"TaskVAE: Task-Specific Variational Autoencoders for Exemplar Generation in Continual Learning for Human Activity Recognition","abstract":"As machine learning based systems become more integrated into daily life, they unlock new opportunities but face the challenge of adapting to dynamic data environments. Various forms of data shift-gradual, abrupt, or cyclic-threaten model accuracy, making continual adaptation essential. Continual Learning (CL) enables models to learn from evolving data streams while minimizing forgetting of prior knowledge. Among CL strategies, replay-based methods have proven effective, but their success relies on balancing memory constraints and retaining old class accuracy while learning new classes. This paper presents TaskVAE, a framework for replay-based CL in class-incremental settings. TaskVAE employs task-specific Variational Autoencoders (VAEs) to generate synthetic exemplars from previous tasks, which are then used to train the classifier alongside new task data. In contrast to traditional methods that require prior knowledge of the total class count or rely on a single VAE for all tasks, TaskVAE adapts flexibly to increasing tasks without such constraints. We focus on Human Activity Recognition (HAR) using IMU sensor-equipped devices. Unlike previous HAR studies that combine data across all users, our approach focuses on individual user data, better reflecting real-world scenarios where a person progressively learns new activities. Extensive experiments on 5 different HAR datasets show that TaskVAE outperforms experience replay methods, particularly with limited data, and exhibits robust performance as dataset size increases. Additionally, memory footprint of TaskVAE is minimal, being equivalent to only 60 samples per task, while still being able to generate an unlimited number of synthetic samples. The contributions lie in balancing memory constraints, task-specific generation, and long-term stability, making it a reliable solution for real-world applications in domains like HAR.","authors":["Bonpagna Kann","Sandra Castellanos-Paez","Romain Rombourg","Philippe Lalanda"],"url":"https://arxiv.org/abs/2506.01965"}
{"created":"2025-06-04","title":"Matrix Is All You Need","abstract":"Deep neural networks employ specialized architectures for vision, sequential and language tasks, yet this proliferation obscures their underlying commonalities. We introduce a unified matrix-order framework that casts convolutional, recurrent and self-attention operations as sparse matrix multiplications. Convolution is realized via an upper-triangular weight matrix performing first-order transformations; recurrence emerges from a lower-triangular matrix encoding stepwise updates; attention arises naturally as a third-order tensor factorization. We prove algebraic isomorphism with standard CNN, RNN and Transformer layers under mild assumptions. Empirical evaluations on image classification (MNIST, CIFAR-10/100, Tiny ImageNet), time-series forecasting (ETTh1, Electricity Load Diagrams) and language modeling/classification (AG News, WikiText-2, Penn Treebank) confirm that sparse-matrix formulations match or exceed native model performance while converging in comparable or fewer epochs. By reducing architecture design to sparse pattern selection, our matrix perspective aligns with GPU parallelism and leverages mature algebraic optimization tools. This work establishes a mathematically rigorous substrate for diverse neural architectures and opens avenues for principled, hardware-aware network design.","authors":["Yuzhou Zhu"],"url":"https://arxiv.org/abs/2506.01966"}
{"created":"2025-06-04","title":"Turning LLM Activations Quantization-Friendly","abstract":"Quantization effectively reduces the serving costs of Large Language Models (LLMs) by speeding up data movement through compressed parameters and enabling faster operations via integer arithmetic. However, activating integer arithmetic requires quantizing both weights and activations, which poses challenges due to the significant outliers in LLMs that increase quantization error. In this work, we investigate these outliers with an emphasis on their effect on layer-wise quantization error, then examine how smoothing and rotation transform the observed values. Our primary contributions include introducing a new metric to measure and visualize quantization difficulty based on channel magnitudes, as well as proposing a hybrid approach that applies channel-wise scaling before rotation, supported by a mathematical formulation of its benefits.","authors":["Patrik Czak\\'o","G\\'abor Kert\\'esz","S\\'andor Sz\\'en\\'asi"],"url":"https://arxiv.org/abs/2506.01967"}
{"created":"2025-06-04","title":"Efficient ANN-SNN Conversion with Error Compensation Learning","abstract":"Artificial neural networks (ANNs) have demonstrated outstanding performance in numerous tasks, but deployment in resource-constrained environments remains a challenge due to their high computational and memory requirements. Spiking neural networks (SNNs) operate through discrete spike events and offer superior energy efficiency, providing a bio-inspired alternative. However, current ANN-to-SNN conversion often results in significant accuracy loss and increased inference time due to conversion errors such as clipping, quantization, and uneven activation. This paper proposes a novel ANN-to-SNN conversion framework based on error compensation learning. We introduce a learnable threshold clipping function, dual-threshold neurons, and an optimized membrane potential initialization strategy to mitigate the conversion error. Together, these techniques address the clipping error through adaptive thresholds, dynamically reduce the quantization error through dual-threshold neurons, and minimize the non-uniformity error by effectively managing the membrane potential. Experimental results on CIFAR-10, CIFAR-100, ImageNet datasets show that our method achieves high-precision and ultra-low latency among existing conversion methods. Using only two time steps, our method significantly reduces the inference time while maintains competitive accuracy of 94.75% on CIFAR-10 dataset under ResNet-18 structure. This research promotes the practical application of SNNs on low-power hardware, making efficient real-time processing possible.","authors":["Chang Liu","Jiangrong Shen","Xuming Ran","Mingkun Xu","Qi Xu","Yi Xu","Gang Pan"],"url":"https://arxiv.org/abs/2506.01968"}
{"created":"2025-06-04","title":"FlashMLA-ETAP: Efficient Transpose Attention Pipeline for Accelerating MLA Inference on NVIDIA H20 GPUs","abstract":"Efficient inference of Multi-Head Latent Attention (MLA) is challenged by deploying the DeepSeek-R1 671B model on a single Multi-GPU server. This paper introduces FlashMLA-ETAP, a novel framework that enhances MLA inference for the single-instance deployment scenario on NVIDIA H20 GPUs. We propose the Efficient Transpose Attention Pipeline (ETAP), which reconfigures attention computation through transposition to align the KV context length with the \\(M\\)-dimension in WGMMA operations, significantly reducing redundant computations. FlashMLA-ETAP achieves a 2.78x speedup over FlashMLA at 64K sequence length (batch size 16), with 5.24x and 4.94x improvements over FlashAttention-3 and FlashInfer, respectively, while maintaining numerical stability with a 15.2x lower RMSE (\\(1.25 \\times 10^{-5}\\)) than FlashAttention-3. Furthermore, ETAP's design enables seamless integration into frameworks like FlashAttention-3 and FlashInfer, supported by a detailed theoretical analysis. Our work addresses a critical gap in resource-constrained inference, offering a scalable solution for mid-tier GPUs and paving the way for broader adoption in hardware-aware optimization. Code is available at https://github.com/pengcuo/FlashMLA-ETAP.","authors":["Pencuo Zeren","Qiuming Luo","Rui Mao","Chang Kong"],"url":"https://arxiv.org/abs/2506.01969"}
{"created":"2025-06-04","title":"Johnny: Structuring Representation Space to Enhance Machine Abstract Reasoning Ability","abstract":"This paper thoroughly investigates the challenges of enhancing AI's abstract reasoning capabilities, with a particular focus on Raven's Progressive Matrices (RPM) tasks involving complex human-like concepts. Firstly, it dissects the empirical reality that traditional end-to-end RPM-solving models heavily rely on option pool configurations, highlighting that this dependency constrains the model's reasoning capabilities. To address this limitation, the paper proposes the Johnny architecture - a novel representation space-based framework for RPM-solving. Through the synergistic operation of its Representation Extraction Module and Reasoning Module, Johnny significantly enhances reasoning performance by supplementing primitive negative option configurations with a learned representation space. Furthermore, to strengthen the model's capacity for capturing positional relationships among local features, the paper introduces the Spin-Transformer network architecture, accompanied by a lightweight Straw Spin-Transformer variant that reduces computational overhead through parameter sharing and attention mechanism optimization. Experimental evaluations demonstrate that both Johnny and Spin-Transformer achieve superior performance on RPM tasks, offering innovative methodologies for advancing AI's abstract reasoning capabilities.","authors":["Ruizhuo Song","Beiming Yuan"],"url":"https://arxiv.org/abs/2506.01970"}
{"created":"2025-06-04","title":"CityPulse: Real-Time Traffic Data Analytics and Congestion Prediction","abstract":"CityPulse is a proof-of-concept big data pipeline designed to enable real-time urban mobility analytics using scalable, containerized components -- without reliance on physical sensor infrastructure. The system simulates the ingestion of 11 million traffic-related records representing urban phenomena such as vehicle congestion, GPS coordinates, and weather conditions. Data is ingested through a Dockerized Apache Kafka cluster, coordinated by ZooKeeper, and processed in real time using Apache Spark Structured Streaming. To ensure robustness under load, the architecture introduces a temporary data storage layer that buffers Spark output before committing it to a centralized data warehouse. This design improves write efficiency, fault tolerance, and enables batch processing of intermediate results. The refined data feeds into a lightweight machine learning module and is served through a Flask backend with a React-based frontend for visualization and interaction. Stress testing shows that the system maintains over 300,000 records per minute throughput with only a 10\\% increase in latency under full load conditions. With its modular Docker-based deployment, CityPulse offers a cost-effective and reproducible analytics solution for traffic congestion monitoring in resource-constrained environments, particularly in developing regions like Cameroon.","authors":["Idriss Djiofack Teledjieu","Irzum Shafique"],"url":"https://arxiv.org/abs/2506.01971"}
{"created":"2025-06-04","title":"Distributionally Robust Optimization for Aerial Multi-access Edge Computing via Cooperation of UAVs and HAPs","abstract":"With an extensive increment of computation demands, the aerial multi-access edge computing (MEC), mainly based on unmanned aerial vehicles (UAVs) and high altitude platforms (HAPs), plays significant roles in future network scenarios. In detail, UAVs can be flexibly deployed, while HAPs are characterized with large capacity and stability. Hence, in this paper, we provide a hierarchical model composed of an HAP and multi-UAVs, to provide aerial MEC services. Moreover, considering the errors of channel state information from unpredictable environmental conditions, we formulate the problem to minimize the total energy cost with the chance constraint, which is a mixed-integer nonlinear problem with uncertain parameters and intractable to solve. To tackle this issue, we optimize the UAV deployment via the weighted K-means algorithm. Then, the chance constraint is reformulated via the distributionally robust optimization (DRO). Furthermore, based on the conditional value-at-risk mechanism, we transform the DRO problem into a mixed-integer second order cone programming, which is further decomposed into two subproblems via the primal decomposition. Moreover, to alleviate the complexity of the binary subproblem, we design a binary whale optimization algorithm. Finally, we conduct extensive simulations to verify the effectiveness and robustness of the proposed schemes by comparing with baseline mechanisms.","authors":["Ziye Jia","Can Cui","Chao Dong","Qihui Wu","Zhuang Ling","Dusit Niyato","Zhu Han"],"url":"https://arxiv.org/abs/2506.01972"}
{"created":"2025-06-04","title":"Multimodal Financial Foundation Models (MFFMs): Progress, Prospects, and Challenges","abstract":"Financial Large Language Models (FinLLMs), such as open FinGPT and proprietary BloombergGPT, have demonstrated great potential in select areas of financial services. Beyond this earlier language-centric approach, Multimodal Financial Foundation Models (MFFMs) can digest interleaved multimodal financial data, including fundamental data, market data, data analytics, macroeconomic, and alternative data (e.g., natural language, audio, images, and video). In this position paper, presented at the MFFM Workshop joined with ACM International Conference on AI in Finance (ICAIF) 2024, we describe the progress, prospects, and challenges of MFFMs. This paper also highlights ongoing research on FinAgents in the \\textbf{SecureFinAI Lab}\\footnote{\\https://openfin.engineering.columbia.edu/} at Columbia University. We believe that MFFMs will enable a deeper understanding of the underlying complexity associated with numerous financial tasks and data, streamlining the operation of financial services and investment processes. Github Repo https://github.com/Open-Finance-Lab/Awesome-MFFMs/.","authors":["Xiao-Yang Liu Yanglet","Yupeng Cao","Li Deng"],"url":"https://arxiv.org/abs/2506.01973"}
{"created":"2025-06-04","title":"Traffic and Mobility Optimization Using AI: Comparative Study between Dubai and Riyadh","abstract":"Urban planning plays a very important role in development modern cities. It effects the economic growth, quality of life, and environmental sustainability. Modern cities face challenges in managing traffic congestion. These challenges arise to due to rapid urbanization. In this study we will explore how AI can be used to understand the traffic and mobility related issues and its effects on the residents sentiment. The approach combines real-time traffic data with geo-located sentiment analysis, offering a comprehensive and dynamic approach to urban mobility planning. AI models and exploratory data analysis was used to predict traffic congestion patterns, analyze commuter behaviors, and identify congestion hotspots and dissatisfaction zones. The findings offer actionable recommendations for optimizing traffic flow, enhancing commuter experiences, and addressing city specific mobility challenges in the Middle East and beyond.","authors":["Kanwal Aalijah"],"url":"https://arxiv.org/abs/2506.01974"}
{"created":"2025-06-04","title":"An empirical study of task and feature correlations in the reuse of pre-trained models","abstract":"Pre-trained neural networks are commonly used and reused in the machine learning community. Alice trains a model for a particular task, and a part of her neural network is reused by Bob for a different task, often to great effect. To what can we ascribe Bob's success? This paper introduces an experimental setup through which factors contributing to Bob's empirical success could be studied in silico. As a result, we demonstrate that Bob might just be lucky: his task accuracy increases monotonically with the correlation between his task and Alice's. Even when Bob has provably uncorrelated tasks and input features from Alice's pre-trained network, he can achieve significantly better than random performance due to Alice's choice of network and optimizer. When there is little correlation between tasks, only reusing lower pre-trained layers is preferable, and we hypothesize the converse: that the optimal number of retrained layers is indicative of task and feature correlation. Finally, we show in controlled real-world scenarios that Bob can effectively reuse Alice's pre-trained network if there are semantic correlations between his and Alice's task.","authors":["Jama Hussein Mohamud"],"url":"https://arxiv.org/abs/2506.01975"}
{"created":"2025-06-04","title":"Crack Path Prediction with Operator Learning using Discrete Particle System data Generation","abstract":"Accurately modeling crack propagation is critical for predicting failure in engineering materials and structures, where small cracks can rapidly evolve and cause catastrophic damage. The interaction of cracks with discontinuities, such as holes, significantly affects crack deflection and arrest. Recent developments in discrete particle systems with multibody interactions based on constitutive behavior have demonstrated the ability to capture crack nucleation and evolution without relying on continuum assumptions. In this work, we use data from Constitutively Informed Particle Dynamics (CPD) simulations to train operator learning models, specifically Deep Operator Networks (DeepONets), which learn mappings between function spaces instead of finite-dimensional vectors. We explore two DeepONet variants: vanilla and Fusion DeepONet, for predicting time-evolving crack propagation in specimens with varying geometries. Three representative cases are studied: (i) varying notch height without active fracture; and (ii) and (iii) combinations of notch height and hole radius where dynamic fracture occurs on irregular discrete meshes. The models are trained on 32 to 45 samples, using geometric inputs in the branch network and spatial-temporal coordinates in the trunk network. Results show that Fusion DeepONet consistently outperforms the vanilla variant, with more accurate predictions especially in non-fracturing cases. Fracture-driven scenarios involving displacement and crack evolution remain more challenging. These findings highlight the potential of Fusion DeepONet to generalize across complex, geometry-varying, and time-dependent crack propagation phenomena.","authors":["Elham Kiyani","Venkatesh Ananchaperumal","Ahmad Peyvan","Mahendaran Uchimali","Gang Li","George Em Karniadakis"],"url":"https://arxiv.org/abs/2506.01976"}
{"created":"2025-06-04","title":"Towards Unsupervised Training of Matching-based Graph Edit Distance Solver via Preference-aware GAN","abstract":"Graph Edit Distance (GED) is a fundamental graph similarity metric widely used in various applications. However, computing GED is an NP-hard problem. Recent state-of-the-art hybrid GED solver has shown promising performance by formulating GED as a bipartite graph matching problem, then leveraging a generative diffusion model to predict node matching between two graphs, from which both the GED and its corresponding edit path can be extracted using a traditional algorithm. However, such methods typically rely heavily on ground-truth supervision, where the ground-truth labels are often costly to obtain in real-world scenarios. In this paper, we propose GEDRanker, a novel unsupervised GAN-based framework for GED computation. Specifically, GEDRanker consists of a matching-based GED solver and introduces an interpretable preference-aware discriminator with an effective training strategy to guide the matching-based GED solver toward generating high-quality node matching without the need for ground-truth labels. Extensive experiments on benchmark datasets demonstrate that our GEDRanker enables the matching-based GED solver to achieve near-optimal solution quality without any ground-truth supervision.","authors":["Wei Huang","Hanchen Wang","Dong Wen","Shaozhen Ma","Wenjie Zhang","Xuemin Lin"],"url":"https://arxiv.org/abs/2506.01977"}
{"created":"2025-06-04","title":"Speculative Decoding via Hybrid Drafting and Rollback-Aware Branch Parallelism","abstract":"Recently, speculative decoding (SD) has emerged as a promising technique to accelerate LLM inference by employing a small draft model to propose draft tokens in advance, and validating them in parallel with the large target model. However, the existing SD methods still remain fundamentally constrained by their serialized execution, which causes the mutual waiting bubbles between the draft and target models. To address this challenge, we draw inspiration from branch prediction in modern processors and propose a novel framework \\textbf{SpecBranch} to unlock branch parallelism in SD. Specifically, we first take an in-depth analysis of the potential of branch parallelism in SD, and recognize that the key challenge lies in the trade-offs between parallelization and token rollback. Based on the analysis, we strategically introduce parallel speculative branches to preemptively hedge against likely rejections. Meanwhile, to enhance parallelism, we jointly orchestrate adaptive draft lengths with a hybrid combination of the implicit draft model confidence and explicit reusing of target model features. Extensive experiments across various models and benchmarks show that SpecBranch achieves over \\textbf{1.8}$\\times \\sim$ \\textbf{4.5}$\\times$ speedups against the auto-regressive decoding and reduces rollback tokens by $\\textbf{50}$\\% for poorly aligned models, realizing its applicability for real-world deployments.","authors":["Yuhao Shen","Junyi Shen","Quan Kong","Tianyu Liu","Yao Lu","Cong Wang"],"url":"https://arxiv.org/abs/2506.01979"}
{"created":"2025-06-04","title":"Music interpretation and emotion perception: A computational and neurophysiological investigation","abstract":"This study investigates emotional expression and perception in music performance using computational and neurophysiological methods. The influence of different performance settings, such as repertoire, diatonic modal etudes, and improvisation, as well as levels of expressiveness, on performers' emotional communication and listeners' reactions is explored. Professional musicians performed various tasks, and emotional annotations were provided by both performers and the audience. Audio analysis revealed that expressive and improvisational performances exhibited unique acoustic features, while emotion analysis showed stronger emotional responses. Neurophysiological measurements indicated greater relaxation in improvisational performances. This multimodal study highlights the significance of expressivity in enhancing emotional communication and audience engagement.","authors":["Vassilis Lyberatos","Spyridon Kantarelis","Ioanna Zioga","Christina Anagnostopoulou","Giorgos Stamou","Anastasia Georgaki"],"url":"https://arxiv.org/abs/2506.01982"}
{"created":"2025-06-04","title":"Improvement of AMPs Identification with Generative Adversarial Network and Ensemble Classification","abstract":"Identification of antimicrobial peptides is an important and necessary issue in today's era. Antimicrobial peptides are essential as an alternative to antibiotics for biomedical applications and many other practical applications. These oligopeptides are useful in drug design and cause innate immunity against microorganisms. Artificial intelligence algorithms have played a significant role in the ease of identifying these peptides.This research is improved by improving proposed method in the field of antimicrobial peptides prediction. Suggested method is improved by combining the best coding method from different perspectives, In the following a deep neural network to balance the imbalanced combined datasets. The results of this research show that the proposed method have a significant improvement in the accuracy and efficiency of the prediction of antimicrobial peptides and are able to provide the best results compared to the existing methods. These development in the field of prediction and classification of antimicrobial peptides, basically in the fields of medicine and pharmaceutical industries, have high effectiveness and application.","authors":["Reyhaneh Keshavarzpour","Eghbal Mansoori"],"url":"https://arxiv.org/abs/2506.01983"}
{"created":"2025-06-04","title":"Bridging Global Frameworks: Governance Strategies Behind Cisco Common Control Framework v4.0 for Scalable Cloud Compliance","abstract":"CCF v4.0 provides a standard way to ensure that Cisco's cloud products comply with the many quickly evolving requirements worldwide. To cope with increasing demands brought by ISO 27001, SOC 2, NIST, FedRAMP, EU CRA, DORA, and NIS2, CCF v4.0 introduces reliable governance by grouping controls using modules mapped across many frameworks. In this document, I discuss the governance structure controlling the framework's progress, noting how the CAB helped and the relevant steps for mapping and validating controls. Because of this, Cisco now uses the same scalable and audit-ready compliance model in all $ 10 B+ of their cloud offerings.","authors":["Nishant Sonkar"],"url":"https://arxiv.org/abs/2506.01984"}
{"created":"2025-06-04","title":"SpecMemo: Speculative Decoding is in Your Pocket","abstract":"Recent advancements in speculative decoding have demonstrated considerable speedup across a wide array of large language model (LLM) tasks. Speculative decoding inherently relies on sacrificing extra memory allocations to generate several candidate tokens, of which acceptance rate drives the speedup. However, deploying speculative decoding on memory-constrained devices, such as mobile GPUs, remains as a significant challenge in real-world scenarios. In this work, we present a device-aware inference engine named SpecMemo that can smartly control memory allocations at finer levels to enable multi-turn chatbots with speculative decoding on such limited memory devices. Our methodology stems from theoretically modeling memory footprint of speculative decoding to determine a lower bound on the required memory budget while retaining speedup. SpecMemo empirically acquires a careful balance between minimizing redundant memory allocations for rejected candidate tokens and maintaining competitive performance gains from speculation. Notably, with SpecMemo's memory management, we maintain 96% of overall throughput from speculative decoding on MT-Bench, with reduced generation-memory by 65% on single Nvidia Titan RTX. Given multiple constrained GPUs, we build on top of previous speculative decoding architectures to facilitate big-model inference by distributing Llama-2-70B-Chat model, on which we provide novel batched speculative decoding to increase usability of multiple small server GPUs. This novel framework demonstrates 2x speedup over distributed and batched vanilla decoding with the base model on eight AMD MI250 GPUs. Moreover, inference throughput increases remarkably 8x with batch size 10. Our work contributes to democratized LLM applications in resource-constrained environments, providing a pathway for faster and cheaper deployment of real-world LLM applications with robust performance.","authors":["Selin Yildirim","Deming Chen"],"url":"https://arxiv.org/abs/2506.01986"}
{"created":"2025-06-04","title":"Equally Critical: Samples, Targets, and Their Mappings in Datasets","abstract":"Data inherently possesses dual attributes: samples and targets. For targets, knowledge distillation has been widely employed to accelerate model convergence, primarily relying on teacher-generated soft target supervision. Conversely, recent advancements in data-efficient learning have emphasized sample optimization techniques, such as dataset distillation, while neglected the critical role of target. This dichotomy motivates our investigation into understanding how both sample and target collectively influence training dynamic. To address this gap, we first establish a taxonomy of existing paradigms through the lens of sample-target interactions, categorizing them into distinct sample-to-target mapping strategies. Building upon this foundation, we then propose a novel unified loss framework to assess their impact on training efficiency. Through extensive empirical studies on our proposed strategies, we comprehensively analyze how variations in target and sample types, quantities, and qualities influence model training, providing six key insights to enhance training efficacy.","authors":["Runkang Yang","Peng Sun","Xinyi Shang","Yi Tang","Tao Lin"],"url":"https://arxiv.org/abs/2506.01987"}
{"created":"2025-06-04","title":"Surrogate Interpretable Graph for Random Decision Forests","abstract":"The field of health informatics has been profoundly influenced by the development of random forest models, which have led to significant advances in the interpretability of feature interactions. These models are characterized by their robustness to overfitting and parallelization, making them particularly useful in this domain. However, the increasing number of features and estimators in random forests can prevent domain experts from accurately interpreting global feature interactions, thereby compromising trust and regulatory compliance. A method called the surrogate interpretability graph has been developed to address this issue. It uses graphs and mixed-integer linear programming to analyze and visualize feature interactions. This improves their interpretability by visualizing the feature usage per decision-feature-interaction table and the most dominant hierarchical decision feature interactions for predictions. The implementation of a surrogate interpretable graph enhances global interpretability, which is critical for such a high-stakes domain.","authors":["Akshat Dubey","Aleksandar An\\v{z}el","Georges Hattab"],"url":"https://arxiv.org/abs/2506.01988"}
{"created":"2025-06-04","title":"Coded Robust Aggregation for Distributed Learning under Byzantine Attacks","abstract":"In this paper, we investigate the problem of distributed learning (DL) in the presence of Byzantine attacks. For this problem, various robust bounded aggregation (RBA) rules have been proposed at the central server to mitigate the impact of Byzantine attacks. However, current DL methods apply RBA rules for the local gradients from the honest devices and the disruptive information from Byzantine devices, and the learning performance degrades significantly when the local gradients of different devices vary considerably from each other. To overcome this limitation, we propose a new DL method to cope with Byzantine attacks based on coded robust aggregation (CRA-DL). Before training begins, the training data are allocated to the devices redundantly. During training, in each iteration, the honest devices transmit coded gradients to the server computed from the allocated training data, and the server then aggregates the information received from both honest and Byzantine devices using RBA rules. In this way, the global gradient can be approximately recovered at the server to update the global model. Compared with current DL methods applying RBA rules, the improvement of CRA-DL is attributed to the fact that the coded gradients sent by the honest devices are closer to each other. This closeness enhances the robustness of the aggregation against Byzantine attacks, since Byzantine messages tend to be significantly different from those of honest devices in this case. We theoretically analyze the convergence performance of CRA-DL. Finally, we present numerical results to verify the superiority of the proposed method over existing baselines, showing its enhanced learning performance under Byzantine attacks.","authors":["Chengxi Li","Ming Xiao","Mikael Skoglund"],"url":"https://arxiv.org/abs/2506.01989"}
{"created":"2025-06-04","title":"Investigating Timing-Based Information Leakage in Data Flow-Driven Real-Time Systems","abstract":"Leaking information about the execution behavior of critical real-time tasks may lead to serious consequences, including violations of temporal constraints and even severe failures. We study information leakage for a special class of real-time tasks that have two execution modes, namely, typical execution (which invokes the majority of times) and critical execution (to tackle exceptional conditions). The data flow-driven applications inherit such a multimode execution model. In this paper, we investigate whether a low-priority \"observer\" task can infer the execution patterns of a high-priority \"victim\" task (especially the critical executions). We develop a new statistical analysis technique and show that by analyzing the response times of the low-priority task, it becomes possible to extract the execution behavior of the high-priority task. We test our approach against a random selection technique that arbitrarily classifies a job as critical. We find that correlating the observer's response times with the victim's jobs can result in higher precision in identifying critical invocations compared to a random guess. We conduct extensive evaluations with systemically generated workloads, including a case study using a UAV autopilot (ArduPilot) taskset parameters. We found that our inference algorithm can achieve relatively low false positive rates (less than 25%) with relatively low footprint (1 MB memory and 50 ms timing overhead on a Raspberry Pi 4 platform). We further demonstrate the feasibility of inference on two cyber-physical platforms: an off-the-shelf manufacturing robot and a custom-built surveillance system.","authors":["Mohammad Fakhruddin Babar","Zain A. H. Hammadeh","Mohammad Hamad","Monowar Hasan"],"url":"https://arxiv.org/abs/2506.01991"}
{"created":"2025-06-04","title":"No Free Lunch in Active Learning: LLM Embedding Quality Dictates Query Strategy Success","abstract":"The advent of large language models (LLMs) capable of producing general-purpose representations lets us revisit the practicality of deep active learning (AL): By leveraging frozen LLM embeddings, we can mitigate the computational costs of iteratively fine-tuning large backbones. This study establishes a benchmark and systematically investigates the influence of LLM embedding quality on query strategies in deep AL. We employ five top-performing models from the massive text embedding benchmark (MTEB) leaderboard and two baselines for ten diverse text classification tasks. Our findings reveal key insights: First, initializing the labeled pool using diversity-based sampling synergizes with high-quality embeddings, boosting performance in early AL iterations. Second, the choice of the optimal query strategy is sensitive to embedding quality. While the computationally inexpensive Margin sampling can achieve performance spikes on specific datasets, we find that strategies like Badge exhibit greater robustness across tasks. Importantly, their effectiveness is often enhanced when paired with higher-quality embeddings. Our results emphasize the need for context-specific evaluation of AL strategies, as performance heavily depends on embedding quality and the target task.","authors":["Lukas Rauch","Moritz Wirth","Denis Huseljic","Marek Herde","Bernhard Sick","Matthias A{\\ss}enmacher"],"url":"https://arxiv.org/abs/2506.01992"}
{"created":"2025-06-04","title":"Inter(sectional) Alia(s): Ambiguity in Voice Agent Identity via Intersectional Japanese Self-Referents","abstract":"Conversational agents that mimic people have raised questions about the ethics of anthropomorphizing machines with human social identity cues. Critics have also questioned assumptions of identity neutrality in humanlike agents. Recent work has revealed that intersectional Japanese pronouns can elicit complex and sometimes evasive impressions of agent identity. Yet, the role of other \"neutral\" non-pronominal self-referents (NPSR) and voice as a socially expressive medium remains unexplored. In a crowdsourcing study, Japanese participants (N = 204) evaluated three ChatGPT voices (Juniper, Breeze, and Ember) using seven self-referents. We found strong evidence of voice gendering alongside the potential of intersectional self-referents to evade gendering, i.e., ambiguity through neutrality and elusiveness. Notably, perceptions of age and formality intersected with gendering as per sociolinguistic theories, especially boku and watakushi. This work provides a nuanced take on agent identity perceptions and champions intersectional and culturally-sensitive work on voice agents.","authors":["Takao Fujii","Katie Seaborn","Madeleine Steeds","Jun Kato"],"url":"https://arxiv.org/abs/2506.01998"}
{"created":"2025-06-04","title":"NovelHopQA: Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts","abstract":"Current large language models (LLMs) struggle to answer questions that span tens of thousands of tokens, especially when multi-hop reasoning is involved. While prior benchmarks explore long-context comprehension or multi-hop reasoning in isolation, none jointly vary context length and reasoning depth in natural narrative settings. We introduce NovelHopQA, the first benchmark to evaluate k1-4 hop QA over 64k-128k-token excerpts from 83 full-length public-domain novels. A keyword-guided pipeline builds hop-separated chains grounded in coherent storylines. We evaluate six state-of-the-art (SOTA) models and apply oracle-context filtering to ensure all questions are genuinely answerable. Human annotators validate both alignment and hop depth. We noticed consistent accuracy drops with increased hops and context length, even in frontier models-revealing that sheer scale does not guarantee robust reasoning. Our failure mode analysis highlights common breakdowns, such as missed final-hop integration and long-range drift. NovelHopQA offers a controlled diagnostic setting to stress-test multi-hop reasoning at scale.","authors":["Abhay Gupta","Michael Lu","Kevin Zhu","Sean O'Brien","Vasu Sharma"],"url":"https://arxiv.org/abs/2506.02000"}
{"created":"2025-06-04","title":"EcoLoRA: Communication-Efficient Federated Fine-Tuning of Large Language Models","abstract":"To address data locality and privacy restrictions, Federated Learning (FL) has recently been adopted to fine-tune large language models (LLMs), enabling improved performance on various downstream tasks without requiring aggregated data. However, the repeated exchange of model updates in FL can result in prohibitively high communication costs, hindering the distributed learning process. To address this challenge, we propose EcoLoRA, a novel communication-efficient federated fine-tuning framework for LLMs. Leveraging the modular structure, we propose a round-robin segment sharing scheme, where each client uploads only a complementary LoRA segment per round to reduce network bandwidth. It is further combined with adaptive sparsification methods tailored to LoRA's training dynamics and lossless encoding techniques. We conduct extensive evaluations on both question-answering and value-alignment tasks across multiple datasets and models. The results show that EcoLoRA significantly reduces communication overhead without compromising performance. For instance, it reduces communication time by up to 79% and total training time by up to 65%.","authors":["Han Liu","Ruoyao Wen","Srijith Nair","Jia Liu","Wenjing Lou","Chongjie Zhang","William Yeoh","Yevgeniy Vorobeychik","Ning Zhang"],"url":"https://arxiv.org/abs/2506.02001"}
{"created":"2025-06-04","title":"Machine Learning for Consistency Violation Faults Analysis","abstract":"Distributed systems frequently encounter consistency violation faults (cvfs), where nodes operate on outdated or inaccurate data, adversely affecting convergence and overall system performance. This study presents a machine learning-based approach for analyzing the impact of CVFs, using Dijkstra's Token Ring problem as a case study. By computing program transition ranks and their corresponding effects, the proposed method quantifies the influence of cvfs on system behavior. To address the state space explosion encountered in larger graphs, two models are implemented: a Feedforward Neural Network (FNN) and a distributed neural network leveraging TensorFlow's \\texttt{tf.distribute} API. These models are trained on datasets generated from smaller graphs (3 to 10 nodes) to predict parameters essential for determining rank effects. Experimental results demonstrate promising performance, with a test loss of 4.39 and a mean absolute error of 1.5. Although distributed training on a CPU did not yield significant speed improvements over a single-device setup, the findings suggest that scalability could be enhanced through the use of advanced hardware accelerators such as GPUs or TPUs.","authors":["Kamal Giri","Amit Garu"],"url":"https://arxiv.org/abs/2506.02002"}
{"created":"2025-06-04","title":"Navigating the Edge-Cloud Continuum: A State-of-Practice Survey","abstract":"The edge-cloud continuum has emerged as a transformative paradigm that meets the growing demand for low-latency, scalable, end-to-end service delivery by integrating decentralized edge resources with centralized cloud infrastructures. Driven by the exponential growth of IoT-generated data and the need for real-time responsiveness, this continuum features multi-layered architectures. However, its adoption is hindered by infrastructural challenges, fragmented standards, and limited guidance for developers and researchers. Existing surveys rarely tackle practical implementation or recent industrial advances. This survey closes those gaps from a developer-oriented perspective, introducing a conceptual framework for navigating the edge-cloud continuum. We systematically examine architectural models, performance metrics, and paradigms for computation, communication, and deployment, together with enabling technologies and widely used edge-to-cloud platforms. We also discuss real-world applications in smart cities, healthcare, and Industry 4.0, as well as tools for testing and experimentation. Drawing on academic research and practices of leading cloud providers, this survey serves as a practical guide for developers and a structured reference for researchers, while identifying open challenges and emerging trends that will shape the future of the continuum.","authors":["Loris Belcastro","Fabrizio Marozzo","Alessio Orsino","Domenico Talia","Paolo Trunfio"],"url":"https://arxiv.org/abs/2506.02003"}
{"created":"2025-06-04","title":"Pruning for Performance: Efficient Idiom and Metaphor Classification in Low-Resource Konkani Using mBERT","abstract":"In this paper, we address the persistent challenges that figurative language expressions pose for natural language processing (NLP) systems, particularly in low-resource languages such as Konkani. We present a hybrid model that integrates a pre-trained Multilingual BERT (mBERT) with a bidirectional LSTM and a linear classifier. This architecture is fine-tuned on a newly introduced annotated dataset for metaphor classification, developed as part of this work. To improve the model's efficiency, we implement a gradient-based attention head pruning strategy. For metaphor classification, the pruned model achieves an accuracy of 78%. We also applied our pruning approach to expand on an existing idiom classification task, achieving 83% accuracy. These results demonstrate the effectiveness of attention head pruning for building efficient NLP tools in underrepresented languages.","authors":["Timothy Do","Pranav Saran","Harshita Poojary","Pranav Prabhu","Sean O'Brien","Vasu Sharma","Kevin Zhu"],"url":"https://arxiv.org/abs/2506.02005"}
{"created":"2025-06-04","title":"Efficient and Workload-Aware LLM Serving via Runtime Layer Swapping and KV Cache Resizing","abstract":"Efficiently serving large language models (LLMs) under dynamic and bursty workloads remains a key challenge for real-world deployment. Existing serving frameworks and static model compression techniques fail to adapt to workload fluctuations, leading to either service-level objective (SLO) violations under full-precision serving or persistent accuracy degradation with static quantization. We present MorphServe, a dynamic, workload-aware LLM serving framework based on morphological adaptation. MorphServe introduces two asynchronous, token-level runtime mechanisms: quantized layer swapping, which selectively replaces less impactful layers with quantized alternatives during high-load periods, and pressure-aware KV cache resizing, which dynamically adjusts KV cache capacity in response to memory pressure. These mechanisms enable state-preserving transitions with minimum runtime overhead and are fully compatible with modern scheduling and attention techniques. Extensive experiments on Vicuna and Llama family models with real-world workloads demonstrate that MorphServe reduces average SLO violations by 92.45 percent and improves the P95 TTFT latency by 2.2x-3.9x compared to full-precision serving, without compromising generation quality. These results establish MorphServe as a practical and elastic solution for LLM deployment in dynamic environments.","authors":["Zhaoyuan Su","Tingfeng Lan","Zirui Wang","Juncheng Yang","Yue Cheng"],"url":"https://arxiv.org/abs/2506.02006"}
{"created":"2025-06-04","title":"eACGM: Non-instrumented Performance Tracing and Anomaly Detection towards Machine Learning Systems","abstract":"We present eACGM, a full-stack AI/ML system monitoring framework based on eBPF. eACGM collects real-time performance data from key hardware components, including the GPU and network communication layer, as well as from key software stacks such as CUDA, Python, and PyTorch, all without requiring any code instrumentation or modifications. Additionally, it leverages libnvml to gather process-level GPU resource usage information. By applying a Gaussian Mixture Model (GMM) to the collected multidimensional performance metrics for statistical modeling and clustering analysis, eACGM effectively identifies complex failure modes, such as latency anomalies, hardware failures, and communication inefficiencies, enabling rapid diagnosis of system bottlenecks and abnormal behaviors.","authors":["Ruilin Xu","Zongxuan Xie","Pengfei Chen"],"url":"https://arxiv.org/abs/2506.02007"}
{"created":"2025-06-04","title":"Big Data-Driven Fraud Detection Using Machine Learning and Real-Time Stream Processing","abstract":"In the age of digital finance, detecting fraudulent transactions and money laundering is critical for financial institutions. This paper presents a scalable and efficient solution using Big Data tools and machine learning models. We utilize realtime data streaming platforms like Apache Kafka and Flink, distributed processing frameworks such as Apache Spark, and cloud storage services AWS S3 and RDS. A synthetic dataset representing real-world Anti-Money Laundering (AML) challenges is employed to build a binary classification model. Logistic Regression, Decision Tree, and Random Forest are trained and evaluated using engineered features. Our system demonstrates over 99% classification accuracy, illustrating the power of combining Big Data architectures with machine learning to tackle fraud.","authors":["Chen Liu","Hengyu Tang","Zhixiao Yang","Ke Zhou","Sangwhan Cha"],"url":"https://arxiv.org/abs/2506.02008"}
{"created":"2025-06-04","title":"STRATUS: A Multi-agent System for Autonomous Reliability Engineering of Modern Clouds","abstract":"In cloud-scale systems, failures are the norm. A distributed computing cluster exhibits hundreds of machine failures and thousands of disk failures; software bugs and misconfigurations are reported to be more frequent. The demand for autonomous, AI-driven reliability engineering continues to grow, as existing humanin-the-loop practices can hardly keep up with the scale of modern clouds. This paper presents STRATUS, an LLM-based multi-agent system for realizing autonomous Site Reliability Engineering (SRE) of cloud services. STRATUS consists of multiple specialized agents (e.g., for failure detection, diagnosis, mitigation), organized in a state machine to assist system-level safety reasoning and enforcement. We formalize a key safety specification of agentic SRE systems like STRATUS, termed Transactional No-Regression (TNR), which enables safe exploration and iteration. We show that TNR can effectively improve autonomous failure mitigation. STRATUS significantly outperforms state-of-the-art SRE agents in terms of success rate of failure mitigation problems in AIOpsLab and ITBench (two SRE benchmark suites), by at least 1.5 times across various models. STRATUS shows a promising path toward practical deployment of agentic systems for cloud reliability.","authors":["Yinfang Chen","Jiaqi Pan","Jackson Clark","Yiming Su","Noah Zheutlin","Bhavya Bhavya","Rohan Arora","Yu Deng","Saurabh Jha","Tianyin Xu"],"url":"https://arxiv.org/abs/2506.02009"}
{"created":"2025-06-04","title":"CNVSRC 2024: The Second Chinese Continuous Visual Speech Recognition Challenge","abstract":"This paper presents the second Chinese Continuous Visual Speech Recognition Challenge (CNVSRC 2024), which builds on CNVSRC 2023 to advance research in Chinese Large Vocabulary Continuous Visual Speech Recognition (LVC-VSR). The challenge evaluates two test scenarios: reading in recording studios and Internet speech. CNVSRC 2024 uses the same datasets as its predecessor CNVSRC 2023, which involves CN-CVS for training and CNVSRC-Single/Multi for development and evaluation. However, CNVSRC 2024 introduced two key improvements: (1) a stronger baseline system, and (2) an additional dataset, CN-CVS2-P1, for open tracks to improve data volume and diversity. The new challenge has demonstrated several important innovations in data preprocessing, feature extraction, model design, and training strategies, further pushing the state-of-the-art in Chinese LVC-VSR. More details and resources are available at the official website.","authors":["Zehua Liu","Xiaolou Li","Chen Chen","Lantian Li","Dong Wang"],"url":"https://arxiv.org/abs/2506.02010"}
{"created":"2025-06-04","title":"OASIS: Online Sample Selection for Continual Visual Instruction Tuning","abstract":"In continual visual instruction tuning (CVIT) scenarios, where multi-modal data continuously arrive in an online streaming manner, training delays from large-scale data significantly hinder real-time adaptation. While existing data selection strategies reduce training overheads, they rely on pre-trained reference models, which are impractical in CVIT setups due to unknown future data. Recent reference model-free online sample selection methods address this issue but typically select a fixed number of samples per batch (e.g., top-k), causing them to suffer from distribution shifts where informativeness varies across batches. To address these limitations, we propose OASIS, an adaptive online sample selection approach for CVIT that: (1) dynamically adjusts selected samples per batch based on relative inter-batch informativeness, and (2) minimizes redundancy of selected samples through iterative selection score updates. Empirical results across various MLLMs, such as LLaVA-1.5 and Qwen-VL-2.5, show that OASIS achieves comparable performance to full-data training using only 25% of the data and outperforms the state-of-the-art.","authors":["Minjae Lee","Minhyuk Seo","Tingyu Qu","Tinne Tuytelaars","Jonghyun Choi"],"url":"https://arxiv.org/abs/2506.02011"}
{"created":"2025-06-04","title":"Leveraging Large Language Models in Visual Speech Recognition: Model Scaling, Context-Aware Decoding, and Iterative Polishing","abstract":"Visual Speech Recognition (VSR) transcribes speech by analyzing lip movements. Recently, Large Language Models (LLMs) have been integrated into VSR systems, leading to notable performance improvements. However, the potential of LLMs has not been extensively studied, and how to effectively utilize LLMs in VSR tasks remains unexplored. This paper systematically explores how to better leverage LLMs for VSR tasks and provides three key contributions: (1) Scaling Test: We study how the LLM size affects VSR performance, confirming a scaling law in the VSR task. (2) Context-Aware Decoding: We add contextual text to guide the LLM decoding, improving recognition accuracy. (3) Iterative Polishing: We propose iteratively refining LLM outputs, progressively reducing recognition errors. Extensive experiments demonstrate that by these designs, the great potential of LLMs can be largely harnessed, leading to significant VSR performance improvement.","authors":["Zehua Liu","Xiaolou Li","Li Guo","Lantian Li","Dong Wang"],"url":"https://arxiv.org/abs/2506.02012"}
{"created":"2025-06-04","title":"Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization","abstract":"With the advancement of autonomous and assisted driving technologies, higher demands are placed on the ability to understand complex driving scenarios. Multimodal general large models have emerged as a solution for this challenge. However, applying these models in vertical domains involves difficulties such as data collection, model training, and deployment optimization. This paper proposes a comprehensive method for optimizing multimodal models in driving scenarios, including cone detection, traffic light recognition, speed limit recommendation, and intersection alerts. The method covers key aspects such as dynamic prompt optimization, dataset construction, model training, and deployment. Specifically, the dynamic prompt optimization adjusts the prompts based on the input image content to focus on objects affecting the ego vehicle, enhancing the model's task-specific focus and judgment capabilities. The dataset is constructed by combining real and synthetic data to create a high-quality and diverse multimodal training dataset, improving the model's generalization in complex driving environments. In model training, advanced techniques like knowledge distillation, dynamic fine-tuning, and quantization are integrated to reduce storage and computational costs while boosting performance. Experimental results show that this systematic optimization method not only significantly improves the model's accuracy in key tasks but also achieves efficient resource utilization, providing strong support for the practical application of driving scenario perception technologies.","authors":["Wang Mengjie","Zhu Huiping","Li Jian","Shi Wenxiu","Zhang Song"],"url":"https://arxiv.org/abs/2506.02014"}
{"created":"2025-06-04","title":"Object-centric Self-improving Preference Optimization for Text-to-Image Generation","abstract":"Recent advancements in Multimodal Large Language Models (MLLMs) have significantly improved both image understanding and generation capabilities. Despite these improvements, MLLMs still struggle with fine-grained visual comprehension, particularly in text-to-image generation tasks. While preference optimization methods have been explored to address these limitations in image understanding tasks, their application to image generation remains largely underexplored. To address this gap, we propose an Object-centric Self-improving Preference Optimization (OSPO) framework designed for text-to-image generation by MLLMs. OSPO leverages the intrinsic reasoning abilities of MLLMs without requiring any external datasets or models. OSPO emphasizes the importance of high-quality preference pair data, which is critical for effective preference optimization. To achieve this, it introduces a self-improving mechanism that autonomously constructs object-level contrastive preference pairs through object-centric prompt perturbation, densification and VQA scoring. This process eliminates ambiguous or disproportionate variations commonly found in naively generated preference pairs, thereby enhancing the effectiveness of preference optimization. We validate OSPO on three representative compositional text-to-image benchmarks, demonstrating substantial performance gains over baseline models.","authors":["Yoonjin Oh","Yongjin Kim","Hyomin Kim","Donghwan Chi","Sungwoong Kim"],"url":"https://arxiv.org/abs/2506.02015"}
{"created":"2025-06-04","title":"Are classical deep neural networks weakly adversarially robust?","abstract":"Adversarial attacks have received increasing attention and it has been widely recognized that classical DNNs have weak adversarial robustness. The most commonly used adversarial defense method, adversarial training, improves the adversarial accuracy of DNNs by generating adversarial examples and retraining the model. However, adversarial training requires a significant computational overhead. In this paper, inspired by existing studies focusing on the clustering properties of DNN output features at each layer and the Progressive Feedforward Collapse phenomenon, we propose a method for adversarial example detection and image recognition that uses layer-wise features to construct feature paths and computes the correlation between the examples feature paths and the class-centered feature paths. Experimental results show that the recognition method achieves 82.77% clean accuracy and 44.17% adversarial accuracy on the ResNet-20 with PFC. Compared to the adversarial training method with 77.64% clean accuracy and 52.94% adversarial accuracy, our method exhibits a trade-off without relying on computationally expensive defense strategies. Furthermore, on the standard ResNet-18, our method maintains this advantage with respective metrics of 80.01% and 46.1%. This result reveals inherent adversarial robustness in DNNs, challenging the conventional understanding of the weak adversarial robustness in DNNs.","authors":["Nuolin Sun","Linyuan Wang","Dongyang Li","Bin Yan","Lei Li"],"url":"https://arxiv.org/abs/2506.02016"}
{"created":"2025-06-04","title":"Fairness through Feedback: Addressing Algorithmic Misgendering in Automatic Gender Recognition","abstract":"Automatic Gender Recognition (AGR) systems are an increasingly widespread application in the Machine Learning (ML) landscape. While these systems are typically understood as detecting gender, they often classify datapoints based on observable features correlated at best with either male or female sex. In addition to questionable binary assumptions, from an epistemological point of view, this is problematic for two reasons. First, there exists a gap between the categories the system is meant to predict (woman versus man) and those onto which their output reasonably maps (female versus male). What is more, gender cannot be inferred on the basis of such observable features. This makes AGR tools often unreliable, especially in the case of non-binary and gender non-conforming people. We suggest a theoretical and practical rethinking of AGR systems. To begin, distinctions are made between sex, gender, and gender expression. Then, we build upon the observation that, unlike algorithmic misgendering, human-human misgendering is open to the possibility of re-evaluation and correction. We suggest that analogous dynamics should be recreated in AGR, giving users the possibility to correct the system's output. While implementing such a feedback mechanism could be regarded as diminishing the system's autonomy, it represents a way to significantly increase fairness levels in AGR. This is consistent with the conceptual change of paradigm that we advocate for AGR systems, which should be understood as tools respecting individuals' rights and capabilities of self-expression and determination.","authors":["Camilla Quaresmini","Giacomo Zanotti"],"url":"https://arxiv.org/abs/2506.02017"}
{"created":"2025-06-04","title":"Enhancing Paraphrase Type Generation: The Impact of DPO and RLHF Evaluated with Human-Ranked Data","abstract":"Paraphrasing re-expresses meaning to enhance applications like text simplification, machine translation, and question-answering. Specific paraphrase types facilitate accurate semantic analysis and robust language models. However, existing paraphrase-type generation methods often misalign with human preferences due to reliance on automated metrics and limited human-annotated training data, obscuring crucial aspects of semantic fidelity and linguistic transformations.","authors":["Christopher Lee L\\\"ubbers"],"url":"https://arxiv.org/abs/2506.02018"}
{"created":"2025-06-04","title":"ChatCFD: an End-to-End CFD Agent with Domain-specific Structured Thinking","abstract":"Computational Fluid Dynamics (CFD) is essential for scientific and engineering advancements but is limited by operational complexity and the need for extensive expertise. This paper presents ChatCFD, a large language model-driven pipeline that automates CFD workflows within the OpenFOAM framework. It enables users to configure and execute complex simulations from natural language prompts or published literature with minimal expertise. The innovation is its structured approach to database construction, configuration validation, and error reflection, integrating CFD and OpenFOAM knowledge with general language models to improve accuracy and adaptability. Validation shows ChatCFD can autonomously reproduce published CFD results, handling complex, unseen configurations beyond basic examples, a task challenging for general language models.","authors":["E Fan","Weizong Wang","Tianhan Zhang"],"url":"https://arxiv.org/abs/2506.02019"}
{"created":"2025-06-04","title":"Improve Multi-Modal Embedding Learning via Explicit Hard Negative Gradient Amplifying","abstract":"With the rapid advancement of multi-modal large language models (MLLMs) in recent years, the foundational Contrastive Language-Image Pretraining (CLIP) framework has been successfully extended to MLLMs, enabling more powerful and universal multi-modal embeddings for a wide range of retrieval tasks. Despite these developments, the core contrastive learning paradigm remains largely unchanged from CLIP-style models to MLLMs. Within this framework, the effective mining of hard negative samples continues to be a critical factor for enhancing performance. Prior works have introduced both offline and online strategies for hard negative mining to improve the efficiency of contrastive learning. While these approaches have led to improved multi-modal embeddings, the specific contribution of each hard negative sample to the learning process has not been thoroughly investigated. In this work, we conduct a detailed analysis of the gradients of the info-NCE loss with respect to the query, positive, and negative samples, elucidating the role of hard negatives in updating model parameters. Building upon this analysis, we propose to explicitly amplify the gradients associated with hard negative samples, thereby encouraging the model to learn more discriminative embeddings. Our multi-modal embedding model, trained with the proposed Explicit Gradient Amplifier and based on the LLaVA-OneVision-7B architecture, achieves state-of-the-art performance on the MMEB benchmark compared to previous methods utilizing the same MLLM backbone. Furthermore, when integrated with our self-developed MLLM, QQMM, our approach attains the top rank on the MMEB leaderboard. Code and models are released on https://github.com/QQ-MM/QQMM-embed.","authors":["Youze Xue","Dian Li","Gang Liu"],"url":"https://arxiv.org/abs/2506.02020"}
{"created":"2025-06-04","title":"Dynamic-Aware Video Distillation: Optimizing Temporal Resolution Based on Video Semantics","abstract":"With the rapid development of vision tasks and the scaling on datasets and models, redundancy reduction in vision datasets has become a key area of research. To address this issue, dataset distillation (DD) has emerged as a promising approach to generating highly compact synthetic datasets with significantly less redundancy while preserving essential information. However, while DD has been extensively studied for image datasets, DD on video datasets remains underexplored. Video datasets present unique challenges due to the presence of temporal information and varying levels of redundancy across different classes. Existing DD approaches assume a uniform level of temporal redundancy across all different video semantics, which limits their effectiveness on video datasets. In this work, we propose Dynamic-Aware Video Distillation (DAViD), a Reinforcement Learning (RL) approach to predict the optimal Temporal Resolution of the synthetic videos. A teacher-in-the-loop reward function is proposed to update the RL agent policy. To the best of our knowledge, this is the first study to introduce adaptive temporal resolution based on video semantics in video dataset distillation. Our approach significantly outperforms existing DD methods, demonstrating substantial improvements in performance. This work paves the way for future research on more efficient and semantic-adaptive video dataset distillation research.","authors":["Yinjie Zhao","Heng Zhao","Bihan Wen","Yew-Soon Ong","Joey Tianyi Zhou"],"url":"https://arxiv.org/abs/2506.02021"}
{"created":"2025-06-04","title":"Do You See Me : A Multidimensional Benchmark for Evaluating Visual Perception in Multimodal LLMs","abstract":"Multimodal Large Language Models (MLLMs) show reasoning promise, yet their visual perception is a critical bottleneck. Strikingly, MLLMs can produce correct answers even while misinterpreting crucial visual elements, masking these underlying failures. Our preliminary study on a joint perception-reasoning dataset revealed that for one leading MLLM, 29% of its correct answers to reasoning questions still exhibited visual perception errors. To systematically address this, we introduce \"Do You See Me\", a scalable benchmark with 1,758 images and 2,612 questions. It spans seven human-psychology inspired subtasks in 2D and 3D, featuring controllable complexity to rigorously evaluate MLLM visual skills. Our findings on 3 leading closed-source and 5 major open-source models reveal a stark deficit: humans achieve 96.49% accuracy, while top MLLMs average below 50%. This performance gap widens rapidly with increased task complexity (e.g., from 12% to 45% in the visual form constancy subtask). Further analysis into the root causes suggests that failures stem from challenges like misallocated visual attention and the instability of internal representations for fine-grained details, especially at or below encoder patch resolution. This underscores an urgent need for MLLMs with truly robust visual perception. The benchmark dataset, source code and evaluation scripts are available at https://github.com/microsoft/Do-You-See-Me.","authors":["Aditya Kanade","Tanuja Ganu"],"url":"https://arxiv.org/abs/2506.02022"}
{"created":"2025-06-04","title":"DistMLIP: A Distributed Inference Platform for Machine Learning Interatomic Potentials","abstract":"Large-scale atomistic simulations are essential to bridge computational materials and chemistry to realistic materials and drug discovery applications. In the past few years, rapid developments of machine learning interatomic potentials (MLIPs) have offered a solution to scale up quantum mechanical calculations. Parallelizing these interatomic potentials across multiple devices poses a challenging, but promising approach to further extending simulation scales to real-world applications. In this work, we present DistMLIP, an efficient distributed inference platform for MLIPs based on zero-redundancy, graph-level parallelization. In contrast to conventional space-partitioning parallelization, DistMLIP enables efficient MLIP parallelization through graph partitioning, allowing multi-device inference on flexible MLIP model architectures like multi-layer graph neural networks. DistMLIP presents an easy-to-use, flexible, plug-in interface that enables distributed inference of pre-existing MLIPs. We demonstrate DistMLIP on four widely used and state-of-the-art MLIPs: CHGNet, MACE, TensorNet, and eSEN. We show that existing foundational potentials can perform near-million-atom calculations at the scale of a few seconds on 8 GPUs with DistMLIP.","authors":["Kevin Han","Bowen Deng","Amir Barati Farimani","Gerbrand Ceder"],"url":"https://arxiv.org/abs/2506.02023"}
{"created":"2025-06-04","title":"NestedFP: High-Performance, Memory-Efficient Dual-Precision Floating Point Support for LLMs","abstract":"Large Language Models (LLMs) are playing a crucial role in latency-critical, high-throughput services like virtual assistants and code generation. While techniques such as continuous batching and paged attention address service-level objectives (SLOs), and quantization methods accelerate inference, the dynamic and efficient adaptation of precision at runtime remains a significant, largely underexplored challenge. The emergence of hardware support for FP8 arithmetic, offering up to 2x the throughput of FP16, presents an attractive opportunity for interactive LLM serving. However, current approaches like co-deploying FP8 and FP16 models suffer from increased storage overhead and fail to unlock FP8's full potential. To address these limitations, we introduce NestedFP, a novel precision-adaptive serving technique enabling seamless FP8 and FP16 inference from a single 16-bit model representation, thereby incurring no additional memory cost. NestedFP decomposes each FP16 weight into two 8-bit components, facilitating efficient FP8 execution while preserving full FP16 accuracy. We demonstrate the practical viability of our approach by implementing a custom CUTLASS-based GEMM kernel that reconstructs FP16 operands on-the-fly, integrated within the vLLM serving framework. Our evaluation shows that NestedFP delivers up to 1.55x throughput improvement in FP8 mode with negligible accuracy degradation compared to FP16 precision, while introducing only 3.9% performance overhead on average in FP16 mode across various models. NestedFP thus provides a flexible foundation for dynamic, SLO-aware precision selection, paving the way for more scalable and efficient LLM serving under bursty and heterogeneous workloads.","authors":["Haeun Lee","Omin Kwon","Yeonhong Park","Jae W. Lee"],"url":"https://arxiv.org/abs/2506.02024"}
{"created":"2025-06-04","title":"Evaluating the Efficacy of LLM-Based Reasoning for Multiobjective HPC Job Scheduling","abstract":"High-Performance Computing (HPC) job scheduling involves balancing conflicting objectives such as minimizing makespan, reducing wait times, optimizing resource use, and ensuring fairness. Traditional methods, including heuristic-based (e.g., First-Come-First-Served) or intensive optimization techniques, often lack adaptability to dynamic workloads and heterogeneous HPC systems. To address this, we propose a novel Large Language Model (LLM)-based scheduler using a ReAct-style framework (Reason + Act), enabling iterative, interpretable decision-making. The system incorporates a scratchpad memory to track scheduling history and refine decisions via natural language feedback, while a constraint enforcement module ensures feasibility and safety. We evaluate our approach using OpenAI's O4-Mini and Anthropic's Claude 3.7 across seven real-world HPC workload scenarios, including heterogeneous mixes, bursty patterns, and adversarial cases. Comparisons against FCFS, Shortest Job First, and Google OR-Tools (on 10 to 100 jobs) reveal that LLM-based scheduling effectively balances multiple objectives while offering transparent reasoning through natural language traces. The method excels in constraint satisfaction and adapts to diverse workloads without domain-specific training. However, a trade-off between reasoning quality and computational overhead challenges real-time deployment. This work presents the first comprehensive study of reasoning-capable LLMs for HPC scheduling, demonstrating their potential to handle multiobjective optimization while highlighting limitations in computational efficiency. The findings provide insights into leveraging advanced language models for complex scheduling problems in dynamic HPC environments.","authors":["Prachi Jadhav","Hongwei Jin","Ewa Deelman","Prasanna Balaprakash"],"url":"https://arxiv.org/abs/2506.02025"}
{"created":"2025-06-04","title":"D-Rex: Heterogeneity-Aware Reliability Framework and Adaptive Algorithms for Distributed Storage","abstract":"The exponential growth of data necessitates distributed storage models, such as peer-to-peer systems and data federations. While distributed storage can reduce costs and increase reliability, the heterogeneity in storage capacity, I/O performance, and failure rates of storage resources makes their efficient use a challenge. Further, node failures are common and can lead to data unavailability and even data loss. Erasure coding is a common resiliency strategy implemented in storage systems to mitigate failures by striping data across storage locations. However, erasure coding is computationally expensive and existing systems do not consider the heterogeneous resources and their varied capacity and performance when placing data chunks. We tackle the challenges of using erasure coding with distributed and heterogeneous nodes, aiming to store as much data as possible, minimize encoding and decoding time, and meeting user-defined reliability requirements for each data item. We propose two new dynamic scheduling algorithms, D-Rex LB and D-Rex SC, that adaptively choose erasure coding parameters and map chunks to heterogeneous nodes. D-Rex SC achieves robust performance for both storage utilization and throughput, at a higher computational cost, while D-Rex LB is faster but with slightly less competitive performance. In addition, we propose two greedy algorithms, GreedyMinStorage and GreedyLeastUsed, that optimize for storage utilization and load balancing, respectively. Our experimental evaluation shows that our dynamic schedulers store, on average, 45% more data items without significantly degrading I/O throughput compared to state-of-the-art algorithms, while GreedyLeastUsed is able to store 21% more data items while also increasing throughput.","authors":["Maxime Gonthier (University of Chicago","Argonne National Laboratory)","Dante D. Sanchez-Gallegos (Universidad Carlos III de Madrid)","Haochen Pan (University of Chicago)","Bogdan Nicolae (Argonne National Laboratory)","Sicheng Zhou (Southern University of Science and Technology)","Hai Duc Nguyen (University of Chicago","Argonne National Laboratory)","Valerie Hayot-Sasson (University of Chicago","Argonne National Laboratory)","J. Gregory Pauloski (University of Chicago)","Jesus Carretero (Universidad Carlos III de Madrid)","Kyle Chard (University of Chicago","Argonne National Laboratory)","Ian Foster (University of Chicago","Argonne National Laboratory)"],"url":"https://arxiv.org/abs/2506.02026"}
{"created":"2025-06-04","title":"The End Of Universal Lifelong Identifiers: Identity Systems For The AI Era","abstract":"Many identity systems assign a single, static identifier to an individual for life, reused across domains like healthcare, finance, and education. These Universal Lifelong Identifiers (ULIs) underpin critical workflows but now pose systemic privacy risks. We take the position that ULIs are fundamentally incompatible with the AI era and must be phased out. We articulate a threat model grounded in modern AI capabilities and show that traditional safeguards such as redaction, consent, and access controls are no longer sufficient. We define core properties for identity systems in the AI era and present a cryptographic framework that satisfies them while retaining compatibility with existing identifier workflows. Our design preserves institutional workflows, supports essential functions such as auditability and delegation, and offers a practical migration path beyond ULIs.","authors":["Shriphani Palakodety"],"url":"https://arxiv.org/abs/2506.02027"}
{"created":"2025-06-04","title":"A tertiary review on quantum cryptography","abstract":"Quantum computers impose an immense threat to system security. As a countermeasure, new cryptographic classes have been created to prevent these attacks. Technologies such as post-quantum cryptography and quantum cryptography. Quantum cryptography uses the principle of quantum physics to produce theoretically unbreakable security. This tertiary review selected 51 secondary studies from the Scopus database and presented bibliometric analysis, a list of the main techniques used in the field, and existing open challenges and future directions in quantum cryptography research. The results showed a prevalence of QKD over other techniques among the selected papers and stated that the field still faces many problems related to implementation cost, error correction, decoherence, key rates, communication distance, and quantum hacking.","authors":["Luiz Filipi Anderson de Sousa Moura","Carlos Becker Westphall"],"url":"https://arxiv.org/abs/2506.02028"}
{"created":"2025-06-04","title":"Adaptive Privacy-Preserving SSD","abstract":"Data remanence in NAND flash complicates complete deletion on IoT SSDs. We design an adaptive architecture offering four privacy levels (PL0-PL3) that select among address, data, and parity deletion techniques. Quantitative analysis balances efficacy, latency, endurance, and cost. Machine-learning adjusts levels contextually, boosting privacy with negligible performance overhead and complexity.","authors":["Na Young Ahn","Dong Hoon Lee"],"url":"https://arxiv.org/abs/2506.02030"}
{"created":"2025-06-04","title":"Towards Secure MLOps: Surveying Attacks, Mitigation Strategies, and Research Challenges","abstract":"The rapid adoption of machine learning (ML) technologies has driven organizations across diverse sectors to seek efficient and reliable methods to accelerate model development-to-deployment. Machine Learning Operations (MLOps) has emerged as an integrative approach addressing these requirements by unifying relevant roles and streamlining ML workflows. As the MLOps market continues to grow, securing these pipelines has become increasingly critical. However, the unified nature of MLOps ecosystem introduces vulnerabilities, making them susceptible to adversarial attacks where a single misconfiguration can lead to compromised credentials, severe financial losses, damaged public trust, and the poisoning of training data. Our paper presents a systematic application of the MITRE ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems) framework, a comprehensive and continuously updated catalog of AI-focused attacks, to systematically assess attacks across different phases of the MLOps ecosystem. We begin by examining the preparatory phases during which adversaries acquire the essential intelligence required to initiate their attacks. We then present a structured taxonomy of attack techniques explicitly mapped to corresponding phases of the MLOps ecosystem, supported by examples drawn from red-teaming exercises and real-world incidents. This is followed by a taxonomy of mitigation strategies aligned with these attack categories, offering actionable early-stage defenses to strengthen the security of MLOps ecosystem. Given the rapid evolution and adoption of MLOps, we further highlight key research gaps that require immediate attention. Our work emphasizes the importance of implementing robust security protocols from the outset, empowering practitioners to safeguard MLOps ecosystem against evolving cyber attacks.","authors":["Raj Patel","Himanshu Tripathi","Jasper Stone","Noorbakhsh Amiri Golilarz","Sudip Mittal","Shahram Rahimi","Vini Chaudhary"],"url":"https://arxiv.org/abs/2506.02032"}
{"created":"2025-06-04","title":"Smartphone-Based Food Traceability System Using NoSQL Database","abstract":"With growing consumer health awareness, ensuring food safety and quality throughout the supply chain is crucial, particularly for perishable goods. Contamination can occur during production, processing, or distribution, making real-time monitoring essential. This study proposes an affordable Smartphone-based food traceability system (FTS) that utilizes RFID technology and smartphone sensors. A smartphone-based RFID reader tracks products, while integrated sensors monitor temperature, humidity, and location during storage and transport. The system is assessed in the kimchi supply chain in Korea, providing real-time data to both managers and consumers. It offered comprehensive product tracking, including temperature and humidity records, ensuring transparency and safety. Compared to traditional methods, the proposed system demonstrated improved efficiency in handling large volumes of data while maintaining accurate traceability. The results highlight its potential for enhancing food safety and quality across supply chains.","authors":["Muhammad Syafrudin","Ganjar Alfian","Norma Latif Fitriyani"],"url":"https://arxiv.org/abs/2506.02033"}
{"created":"2025-06-04","title":"High-throughput viscometry via machine-learning from videos of inverted vials","abstract":"Although the inverted vial test has been widely used as a qualitative method for estimating fluid viscosity, quantitative rheological characterization has remained limited due to its complex, uncontrolled flow - driven by gravity, surface tension, inertia, and initial conditions. Here, we present a computer vision (CV) viscometer that automates the inverted vial test and enables quantitative viscosity inference across nearly five orders of magnitude (0.01-1000 Pas), without requiring direct velocity field measurements. The system simultaneously inverts multiple vials and records videos of the evolving fluid, which are fed into a neural network that approximates the inverse function from visual features and known fluid density. Despite the complex, multi-regime flow within the vial, our approach achieves relative errors below 25%, improving to 15% for viscosities above 0.1 Pas. When tested on non-Newtonian polymer solutions, the method reliably estimates zero-shear viscosity as long as viscoelastic or shear-thinning behaviors remain negligible within the flow regime. Moreover, high standard deviations in the inferred values may serve as a proxy for identifying fluids with strong non-Newtonian behavior. The CV viscometer requires only one camera and one motor, is contactless and low-cost, and can be easily integrated into high-throughput experimental automated and manual workflows. Transcending traditional characterization paradigms, our method leverages uncontrolled flows and visual features to achieve simplicity and scalability, enabling high-throughput viscosity inference that can meet the growing demand of data-driven material models while remaining accessible to lower resource environments.","authors":["Ignacio Arretche","Mohammad Tanver Hossain","Ramdas Tiwari","Abbie Kim","Mya G. Mills","Connor D. Armstrong","Jacob J. Lessard","Sameh H. Tawfick","Randy H. Ewoldt"],"url":"https://arxiv.org/abs/2506.02034"}
{"created":"2025-06-04","title":"Asymmetry by Design: Boosting Cyber Defenders with Differential Access to AI","abstract":"As AI-enabled cyber capabilities become more advanced, we propose \"differential access\" as a strategy to tilt the cybersecurity balance toward defense by shaping access to these capabilities. We introduce three possible approaches that form a continuum, becoming progressively more restrictive for higher-risk capabilities: Promote Access, Manage Access, and Deny by Default. However, a key principle across all approaches is the need to prioritize defender access, even in the most restrictive scenarios, so that defenders can prepare for adversaries gaining access to similar capabilities. This report provides a process to help frontier AI developers choose and implement one of the three differential access approaches, including considerations based on a model's cyber capabilities, a defender's maturity and role, and strategic and technical implementation details. We also present four example schemes for defenders to reference, demonstrating how differential access provides value across various capability and defender levels, and suggest directions for further research.","authors":["Shaun Ee","Chris Covino","Cara Labrador","Christina Krawec","Jam Kraprayoon","Joe O'Brien"],"url":"https://arxiv.org/abs/2506.02035"}
{"created":"2025-06-04","title":"FinS-Pilot: A Benchmark for Online Financial System","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities across various professional domains, with their performance typically evaluated through standardized benchmarks. However, the development of financial RAG benchmarks has been constrained by data confidentiality issues and the lack of dynamic data integration. To address this issue, we introduces FinS-Pilot, a novel benchmark for evaluating RAG systems in online financial applications. Constructed from real-world financial assistant interactions, our benchmark incorporates both real-time API data and structured text sources, organized through an intent classification framework covering critical financial domains such as equity analysis and macroeconomic forecasting. The benchmark enables comprehensive evaluation of financial assistants' capabilities in handling both static knowledge and time-sensitive market information. Through systematic experiments with multiple Chinese leading LLMs, we demonstrate FinS-Pilot's effectiveness in identifying models suitable for financial applications while addressing the current gap in specialized evaluation tools for the financial domain. Our work contributes both a practical evaluation framework and a curated dataset to advance research in financial NLP systems. The code and dataset are accessible on GitHub\\footnote{https://github.com/PhealenWang/financial\\_rag\\_benchmark}.","authors":["Feng Wang","Yiding Sun","Jiaxin Mao","Wei Xue","Danqing Xu"],"url":"https://arxiv.org/abs/2506.02037"}
{"created":"2025-06-04","title":"Blockchain Powered Edge Intelligence for U-Healthcare in Privacy Critical and Time Sensitive Environment","abstract":"Edge Intelligence (EI) serves as a critical enabler for privacy-preserving systems by providing AI-empowered computation and distributed caching services at the edge, thereby minimizing latency and enhancing data privacy. The integration of blockchain technology further augments EI frameworks by ensuring transactional transparency, auditability, and system-wide reliability through a decentralized network model. However, the operational architecture of such systems introduces inherent vulnerabilities, particularly due to the extensive data interactions between edge gateways (EGs) and the distributed nature of information storage during service provisioning. To address these challenges, we propose an autonomous computing model along with its interaction topologies tailored for privacy-critical and time-sensitive health applications. The system supports continuous monitoring, real-time alert notifications, disease detection, and robust data processing and aggregation. It also includes a data transaction handler and mechanisms for ensuring privacy at the EGs. Moreover, a resource-efficient one-dimensional convolutional neural network (1D-CNN) is proposed for the multiclass classification of arrhythmia, enabling accurate and real-time analysis of constrained EGs. Furthermore, a secure access scheme is defined to manage both off-chain and on-chain data sharing and storage. To validate the proposed model, comprehensive security, performance, and cost analyses are conducted, demonstrating the efficiency and reliability of the fine-grained access control scheme.","authors":["Anum Nawaz","Hafiz Humza Mahmood Ramzan","Xianjia Yu","Zhuo Zou","Tomi Westerlund"],"url":"https://arxiv.org/abs/2506.02038"}
{"created":"2025-06-04","title":"Beyond the Protocol: Unveiling Attack Vectors in the Model Context Protocol Ecosystem","abstract":"The Model Context Protocol (MCP) is an emerging standard designed to enable seamless interaction between Large Language Model (LLM) applications and external tools or resources. Within a short period, thousands of MCP services have already been developed and deployed. However, the client-server integration architecture inherent in MCP may expand the attack surface against LLM Agent systems, introducing new vulnerabilities that allow attackers to exploit by designing malicious MCP servers. In this paper, we present the first systematic study of attack vectors targeting the MCP ecosystem. Our analysis identifies four categories of attacks, i.e., Tool Poisoning Attacks, Puppet Attacks, Rug Pull Attacks, and Exploitation via Malicious External Resources. To evaluate the feasibility of these attacks, we conduct experiments following the typical steps of launching an attack through malicious MCP servers: upload-download-attack. Specifically, we first construct malicious MCP servers and successfully upload them to three widely used MCP aggregation platforms. The results indicate that current audit mechanisms are insufficient to identify and prevent the proposed attack methods. Next, through a user study and interview with 20 participants, we demonstrate that users struggle to identify malicious MCP servers and often unknowingly install them from aggregator platforms. Finally, we demonstrate that these attacks can trigger harmful behaviors within the user's local environment-such as accessing private files or controlling devices to transfer digital assets-by deploying a proof-of-concept (PoC) framework against five leading LLMs. Additionally, based on interview results, we discuss four key challenges faced by the current security ecosystem surrounding MCP servers. These findings underscore the urgent need for robust security mechanisms to defend against malicious MCP servers.","authors":["Hao Song","Yiming Shen","Wenxuan Luo","Leixin Guo","Ting Chen","Jiashui Wang","Beibei Li","Xiaosong Zhang","Jiachi Chen"],"url":"https://arxiv.org/abs/2506.02040"}
{"created":"2025-06-04","title":"Enhancing Multimodal Continual Instruction Tuning with BranchLoRA","abstract":"Multimodal Continual Instruction Tuning (MCIT) aims to finetune Multimodal Large Language Models (MLLMs) to continually align with human intent across sequential tasks. Existing approaches often rely on the Mixture-of-Experts (MoE) LoRA framework to preserve previous instruction alignments. However, these methods are prone to Catastrophic Forgetting (CF), as they aggregate all LoRA blocks via simple summation, which compromises performance over time. In this paper, we identify a critical parameter inefficiency in the MoELoRA framework within the MCIT context. Based on this insight, we propose BranchLoRA, an asymmetric framework to enhance both efficiency and performance. To mitigate CF, we introduce a flexible tuning-freezing mechanism within BranchLoRA, enabling branches to specialize in intra-task knowledge while fostering inter-task collaboration. Moreover, we incrementally incorporate task-specific routers to ensure an optimal branch distribution over time, rather than favoring the most recent task. To streamline inference, we introduce a task selector that automatically routes test inputs to the appropriate router without requiring task identity. Extensive experiments on the latest MCIT benchmark demonstrate that BranchLoRA significantly outperforms MoELoRA and maintains its superiority across various MLLM sizes.","authors":["Duzhen Zhang","Yong Ren","Zhong-Zhi Li","Yahan Yu","Jiahua Dong","Chenxing Li","Zhilong Ji","Jinfeng Bai"],"url":"https://arxiv.org/abs/2506.02041"}
{"created":"2025-06-04","title":"Docker under Siege: Securing Containers in the Modern Era","abstract":"Containerization, driven by Docker, has transformed application development and deployment by enhancing efficiency and scalability. However, the rapid adoption of container technologies introduces significant security challenges that require careful management. This paper investigates key areas of container security, including runtime protection, network safeguards, configuration best practices, supply chain security, and comprehensive monitoring and logging solutions. We identify common vulnerabilities within these domains and provide actionable recommendations to address and mitigate these risks. By integrating security throughout the Software Development Lifecycle (SDLC), organizations can reinforce their security posture, creating a resilient and reliable containerized application infrastructure that withstands evolving threats.","authors":["Gogulakrishnan Thiyagarajan","Prabhudarshi Nayak"],"url":"https://arxiv.org/abs/2506.02043"}
{"created":"2025-06-04","title":"Machine vs Machine: Using AI to Tackle Generative AI Threats in Assessment","abstract":"This paper presents a theoretical framework for addressing the challenges posed by generative artificial intelligence (AI) in higher education assessment through a machine-versus-machine approach. Large language models like GPT-4, Claude, and Llama increasingly demonstrate the ability to produce sophisticated academic content, traditional assessment methods face an existential threat, with surveys indicating 74-92% of students experimenting with these tools for academic purposes. Current responses, ranging from detection software to manual assessment redesign, show significant limitations: detection tools demonstrate bias against non-native English writers and can be easily circumvented, while manual frameworks rely heavily on subjective judgment and assume static AI capabilities. This paper introduces a dual strategy paradigm combining static analysis and dynamic testing to create a comprehensive theoretical framework for assessment vulnerability evaluation. The static analysis component comprises eight theoretically justified elements: specificity and contextualization, temporal relevance, process visibility requirements, personalization elements, resource accessibility, multimodal integration, ethical reasoning requirements, and collaborative elements. Each element addresses specific limitations in generative AI capabilities, creating barriers that distinguish authentic human learning from AI-generated simulation. The dynamic testing component provides a complementary approach through simulation-based vulnerability assessment, addressing limitations in pattern-based analysis. The paper presents a theoretical framework for vulnerability scoring, including the conceptual basis for quantitative assessment, weighting frameworks, and threshold determination theory.","authors":["Mohammad Saleh Torkestani","Taha Mansouri"],"url":"https://arxiv.org/abs/2506.02046"}
{"created":"2025-06-04","title":"Improving LLM Agents with Reinforcement Learning on Cryptographic CTF Challenges","abstract":"Large Language Models (LLMs) still struggle with the structured reasoning and tool-assisted computation needed for problem solving in cybersecurity applications. In this work, we introduce \"random-crypto\", a cryptographic Capture-the-Flag (CTF) challenge generator framework that we use to fine-tune a tool-augmented Llama-3.1-8B with Guided Reinforcement Prompt Optimisation (GRPO), allowing the agent to iteratively write and execute Python inside an isolated REPL. GRPO yields a +53% absolute jump in Pass@8 on unseen \"random-crypto\" tasks (0.35 -> 0.88) and raises Majority@8 to 0.41. The fine-tuned agent also generalizes to an external dataset. On a subset of picoCTF cryptography problems, it improves Pass@8 by +13 pp. Ablations show the gains stem from more reliable tool invocation and code synthesis, rather than superficial prompt adaptation.","authors":["Lajos Muzsai","David Imolai","Andr\\'as Luk\\'acs"],"url":"https://arxiv.org/abs/2506.02048"}
{"created":"2025-06-04","title":"EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration","abstract":"We introduce EvoGit, a decentralized multi-agent framework for collaborative software development driven by autonomous code evolution. EvoGit deploys a population of independent coding agents, each proposing edits to a shared codebase without centralized coordination, explicit message passing, or shared memory. Instead, all coordination emerges through a Git-based phylogenetic graph that tracks the full version lineage and enables agents to asynchronously read from and write to the evolving code repository. This graph-based structure supports fine-grained branching, implicit concurrency, and scalable agent interaction while preserving a consistent historical record. Human involvement is minimal but strategic: users define high-level goals, periodically review the graph, and provide lightweight feedback to promote promising directions or prune unproductive ones. Experiments demonstrate EvoGit's ability to autonomously produce functional and modular software artifacts across two real-world tasks: (1) building a web application from scratch using modern frameworks, and (2) constructing a meta-level system that evolves its own language-model-guided solver for the bin-packing optimization problem. Our results underscore EvoGit's potential to establish a new paradigm for decentralized, automated, and continual software development. EvoGit is open-sourced at https://github.com/BillHuang2001/evogit.","authors":["Beichen Huang","Ran Cheng","Kay Chen Tan"],"url":"https://arxiv.org/abs/2506.02049"}
{"created":"2025-06-04","title":"Decoupled Hierarchical Reinforcement Learning with State Abstraction for Discrete Grids","abstract":"Effective agent exploration remains a core challenge in reinforcement learning (RL) for complex discrete state-space environments, particularly under partial observability. This paper presents a decoupled hierarchical RL framework integrating state abstraction (DcHRL-SA) to address this issue. The proposed method employs a dual-level architecture, consisting of a high level RL-based actor and a low-level rule-based policy, to promote effective exploration. Additionally, state abstraction method is incorporated to cluster discrete states, effectively lowering state dimensionality. Experiments conducted in two discrete customized grid environments demonstrate that the proposed approach consistently outperforms PPO in terms of exploration efficiency, convergence speed, cumulative reward, and policy stability. These results demonstrate a practical approach for integrating decoupled hierarchical policies and state abstraction in discrete grids with large-scale exploration space. Code will be available at https://github.com/XQY169/DcHRL-SA.","authors":["Qingyu Xiao","Yuanlin Chang","Youtian Du"],"url":"https://arxiv.org/abs/2506.02050"}
{"created":"2025-06-04","title":"Generalization Performance of Ensemble Clustering: From Theory to Algorithm","abstract":"Ensemble clustering has demonstrated great success in practice; however, its theoretical foundations remain underexplored. This paper examines the generalization performance of ensemble clustering, focusing on generalization error, excess risk and consistency. We derive a convergence rate of generalization error bound and excess risk bound both of $\\mathcal{O}(\\sqrt{\\frac{\\log n}{m}}+\\frac{1}{\\sqrt{n}})$, with $n$ and $m$ being the numbers of samples and base clusterings. Based on this, we prove that when $m$ and $n$ approach infinity and $m$ is significantly larger than log $n$, i.e., $m,n\\to \\infty, m\\gg \\log n$, ensemble clustering is consistent. Furthermore, recognizing that $n$ and $m$ are finite in practice, the generalization error cannot be reduced to zero. Thus, by assigning varying weights to finite clusterings, we minimize the error between the empirical average clusterings and their expectation. From this, we theoretically demonstrate that to achieve better clustering performance, we should minimize the deviation (bias) of base clustering from its expectation and maximize the differences (diversity) among various base clusterings. Additionally, we derive that maximizing diversity is nearly equivalent to a robust (min-max) optimization model. Finally, we instantiate our theory to develop a new ensemble clustering algorithm. Compared with SOTA methods, our approach achieves average improvements of 6.1%, 7.3%, and 6.0% on 10 datasets w.r.t. NMI, ARI, and Purity. The code is available at https://github.com/xuz2019/GPEC.","authors":["Xu Zhang","Haoye Qiu","Weixuan Liang","Hui Liu","Junhui Hou","Yuheng Jia"],"url":"https://arxiv.org/abs/2506.02053"}
{"created":"2025-06-04","title":"Will Agents Replace Us? Perceptions of Autonomous Multi-Agent AI","abstract":"Autonomous multi-agent AI systems are poised to transform various industries, particularly software development and knowledge work. Understanding current perceptions among professionals is crucial for anticipating adoption challenges, ethical considerations, and future workforce development. This study analyzes responses from 130 participants to a survey on the capabilities, impact, and governance of AI agents. We explore expected timelines for AI replacing programmers, identify perceived barriers to deployment, and examine beliefs about responsibility when agents make critical decisions. Key findings reveal three distinct clusters of respondents. While the study explored factors associated with current AI agent deployment, the initial logistic regression model did not yield statistically significant predictors, suggesting that deployment decisions are complex and may be influenced by factors not fully captured or that a larger sample is needed. These insights highlight the need for organizations to address compliance concerns (a commonly cited barrier) and establish clear governance frameworks as they integrate autonomous agents into their workflows.","authors":["Nikola Balic"],"url":"https://arxiv.org/abs/2506.02055"}
{"created":"2025-06-04","title":"Enhancing Speech Instruction Understanding and Disambiguation in Robotics via Speech Prosody","abstract":"Enabling robots to accurately interpret and execute spoken language instructions is essential for effective human-robot collaboration. Traditional methods rely on speech recognition to transcribe speech into text, often discarding crucial prosodic cues needed for disambiguating intent. We propose a novel approach that directly leverages speech prosody to infer and resolve instruction intent. Predicted intents are integrated into large language models via in-context learning to disambiguate and select appropriate task plans. Additionally, we present the first ambiguous speech dataset for robotics, designed to advance research in speech disambiguation. Our method achieves 95.79% accuracy in detecting referent intents within an utterance and determines the intended task plan of ambiguous instructions with 71.96% accuracy, demonstrating its potential to significantly improve human-robot communication.","authors":["David Sasu","Kweku Andoh Yamoah","Benedict Quartey","Natalie Schluter"],"url":"https://arxiv.org/abs/2506.02057"}
{"created":"2025-06-04","title":"Evaluating the Unseen Capabilities: How Many Theorems Do LLMs Know?","abstract":"Accurate evaluation of large language models (LLMs) is crucial for understanding their capabilities and guiding their development. However, current evaluations often inconsistently reflect the actual capacities of these models. In this paper, we demonstrate that one of many contributing factors to this \\textit{evaluation crisis} is the oversight of unseen knowledge -- information encoded by LLMs but not directly observed or not yet observed during evaluations. We introduce KnowSum, a statistical framework designed to provide a more comprehensive assessment by quantifying the unseen knowledge for a class of evaluation tasks. KnowSum estimates the unobserved portion by extrapolating from the appearance frequencies of observed knowledge instances. We demonstrate the effectiveness and utility of KnowSum across three critical applications: estimating total knowledge, evaluating information retrieval effectiveness, and measuring output diversity. Our experiments reveal that a substantial volume of knowledge is omitted when relying solely on observed LLM performance. Importantly, KnowSum yields significantly different comparative rankings for several common LLMs based on their internal knowledge.","authors":["Xiang Li","Jiayi Xin","Qi Long","Weijie J. Su"],"url":"https://arxiv.org/abs/2506.02058"}
{"created":"2025-06-04","title":"Learning More with Less: Self-Supervised Approaches for Low-Resource Speech Emotion Recognition","abstract":"Speech Emotion Recognition (SER) has seen significant progress with deep learning, yet remains challenging for Low-Resource Languages (LRLs) due to the scarcity of annotated data. In this work, we explore unsupervised learning to improve SER in low-resource settings. Specifically, we investigate contrastive learning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervised approaches to enhance cross-lingual generalization. Our methods achieve notable F1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla, demonstrating their effectiveness in LRLs. Additionally, we analyze model behavior to provide insights on key factors influencing performance across languages, and also highlighting challenges in low-resource SER. This work provides a foundation for developing more inclusive, explainable, and robust emotion recognition systems for underrepresented languages.","authors":["Ziwei Gong","Pengyuan Shi","Kaan Donbekci","Lin Ai","Run Chen","David Sasu","Zehui Wu","Julia Hirschberg"],"url":"https://arxiv.org/abs/2506.02059"}
{"created":"2025-06-04","title":"Predicting Blood Type: Assessing Model Performance with ROC Analysis","abstract":"Introduction: Personal identification is a critical aspect of forensic sciences, security, and healthcare. While conventional biometrics systems such as DNA profiling and iris scanning offer high accuracy, they are time-consuming and costly. Objectives: This study investigates the relationship between fingerprint patterns and ABO blood group classification to explore potential correlations between these two traits. Methods: The study analyzed 200 individuals, categorizing their fingerprints into three types: loops, whorls, and arches. Blood group classification was also recorded. Statistical analysis, including chi-square and Pearson correlation tests, was used to assess associations between fingerprint patterns and blood groups. Results: Loops were the most common fingerprint pattern, while blood group O+ was the most prevalent among the participants. Statistical analysis revealed no significant correlation between fingerprint patterns and blood groups (p > 0.05), suggesting that these traits are independent. Conclusions: Although the study showed limited correlation between fingerprint patterns and ABO blood groups, it highlights the importance of future research using larger and more diverse populations, incorporating machine learning approaches, and integrating multiple biometric signals. This study contributes to forensic science by emphasizing the need for rigorous protocols and comprehensive investigations in personal identification.","authors":["Malik A. Altayar","Muhyeeddin Alqaraleh","Mowafaq Salem Alzboon","Wesam T. Almagharbeh"],"url":"https://arxiv.org/abs/2506.02062"}
{"created":"2025-06-04","title":"Privacy-Aware, Public-Aligned: Embedding Risk Detection and Public Values into Scalable Clinical Text De-Identification for Trusted Research Environments","abstract":"Clinical free-text data offers immense potential to improve population health research such as richer phenotyping, symptom tracking, and contextual understanding of patient care. However, these data present significant privacy risks due to the presence of directly or indirectly identifying information embedded in unstructured narratives. While numerous de-identification tools have been developed, few have been tested on real-world, heterogeneous datasets at scale or assessed for governance readiness. In this paper, we synthesise our findings from previous studies examining the privacy-risk landscape across multiple document types and NHS data providers in Scotland. We characterise how direct and indirect identifiers vary by record type, clinical setting, and data flow, and show how changes in documentation practice can degrade model performance over time. Through public engagement, we explore societal expectations around the safe use of clinical free text and reflect these in the design of a prototype privacy-risk management tool to support transparent, auditable decision-making. Our findings highlight that privacy risk is context-dependent and cumulative, underscoring the need for adaptable, hybrid de-identification approaches that combine rule-based precision with contextual understanding. We offer a comprehensive view of the challenges and opportunities for safe, scalable reuse of clinical free-text within Trusted Research Environments and beyond, grounded in both technical evidence and public perspectives on responsible data use.","authors":["Arlene Casey","Stuart Dunbar","Franz Gruber","Samuel McInerney","Mat\\'u\\v{s} Falis","Pamela Linksted","Katie Wilde","Kathy Harrison","Alison Hamilton","Christian Cole"],"url":"https://arxiv.org/abs/2506.02063"}
{"created":"2025-06-04","title":"The Measurement Imbalance in Agentic AI Evaluation Undermines Industry Productivity Claims","abstract":"As industry reports claim agentic AI systems deliver double-digit productivity gains and multi-trillion dollar economic potential, the validity of these claims has become critical for investment decisions, regulatory policy, and responsible technology adoption. However, this paper demonstrates that current evaluation practices for agentic AI systems exhibit a systemic imbalance that calls into question prevailing industry productivity claims. Our systematic review of 84 papers (2023--2025) reveals an evaluation imbalance where technical metrics dominate assessments (83%), while human-centered (30%), safety (53%), and economic assessments (30%) remain peripheral, with only 15% incorporating both technical and human dimensions. This measurement gap creates a fundamental disconnect between benchmark success and deployment value. We present evidence from healthcare, finance, and retail sectors where systems excelling on technical metrics failed in real-world implementation due to unmeasured human, temporal, and contextual factors. Our position is not against agentic AI's potential, but rather that current evaluation frameworks systematically privilege narrow technical metrics while neglecting dimensions critical to real-world success. We propose a balanced four-axis evaluation model and call on the community to lead this paradigm shift because benchmark-driven optimization shapes what we build. By redefining evaluation practices, we can better align industry claims with deployment realities and ensure responsible scaling of agentic systems in high-stakes domains.","authors":["Kiana Jafari Meimandi","Gabriela Ar\\'anguiz-Dias","Grace Ra Kim","Lana Saadeddin","Mykel J. Kochenderfer"],"url":"https://arxiv.org/abs/2506.02064"}
{"created":"2025-06-04","title":"EWGN: Elastic Weight Generation and Context Switching in Deep Learning","abstract":"The ability to learn and retain a wide variety of tasks is a hallmark of human intelligence that has inspired research in artificial general intelligence. Continual learning approaches provide a significant step towards achieving this goal. It has been known that task variability and context switching are challenging for learning in neural networks. Catastrophic forgetting refers to the poor performance on retention of a previously learned task when a new task is being learned. Switching between different task contexts can be a useful approach to mitigate the same by preventing the interference between the varying task weights of the network. This paper introduces Elastic Weight Generative Networks (EWGN) as an idea for context switching between two different tasks. The proposed EWGN architecture uses an additional network that generates the weights of the primary network dynamically while consolidating the weights learned. The weight generation is input-dependent and thus enables context switching. Using standard computer vision datasets, namely MNIST and fashion-MNIST, we analyse the retention of previously learned task representations in Fully Connected Networks, Convolutional Neural Networks, and EWGN architectures with Stochastic Gradient Descent and Elastic Weight Consolidation learning algorithms. Understanding dynamic weight generation and context-switching ability can be useful in enabling continual learning for improved performance.","authors":["Shriraj P. Sawant","Krishna P. Miyapuram"],"url":"https://arxiv.org/abs/2506.02065"}
{"created":"2025-06-04","title":"Developing a Risk Identification Framework for Foundation Model Uses","abstract":"As foundation models grow in both popularity and capability, researchers have uncovered a variety of ways that the models can pose a risk to the model's owner, user, or others. Despite the efforts of measuring these risks via benchmarks and cataloging them in AI risk taxonomies, there is little guidance for practitioners on how to determine which risks are relevant for a given foundation model use. In this paper, we address this gap and develop requirements and an initial design for a risk identification framework. To do so, we look to prior literature to identify challenges for building a foundation model risk identification framework and adapt ideas from usage governance to synthesize four design requirements. We then demonstrate how a candidate framework can addresses these design requirements and provide a foundation model use example to show how the framework works in practice for a small subset of risks.","authors":["David Piorkowski","Michael Hind","John Richards","Jacquelyn Martino"],"url":"https://arxiv.org/abs/2506.02066"}
{"created":"2025-06-04","title":"An Introduction to Flow Matching and Diffusion Models","abstract":"Diffusion and flow-based models have become the state of the art for generative AI across a wide range of data modalities, including images, videos, shapes, molecules, music, and more! These notes are originally from https://diffusion.csail.mit.edu/, as taught at MIT over the 2025 IAP (winter) term, and are intended to accompany other course content, including lectures and labs. Overall, they function as a self-contained introduction to both flow matching and diffusion models, starting with ordinary and stochastic differential equations, and culminating in flow matching, score matching, classifier-free guidance, and the inner workings of modern, state-of-the-art models for image and video. These notes, and the accompanying course, are ideal for students and practitioners alike who want to develop a principled understanding of the theory and practice of generative AI.","authors":["Peter Holderrieth","Ezra Erives"],"url":"https://arxiv.org/abs/2506.02070"}
{"created":"2025-06-04","title":"AI Data Development: A Scorecard for the System Card Framework","abstract":"Artificial intelligence has transformed numerous industries, from healthcare to finance, enhancing decision-making through automated systems. However, the reliability of these systems is mainly dependent on the quality of the underlying datasets, raising ongoing concerns about transparency, accountability, and potential biases. This paper introduces a scorecard designed to evaluate the development of AI datasets, focusing on five key areas from the system card framework data development life cycle: data dictionary, collection process, composition, motivation, and pre-processing. The method follows a structured approach, using an intake form and scoring criteria to assess the quality and completeness of the data set. Applied to four diverse datasets, the methodology reveals strengths and improvement areas. The results are compiled using a scoring system that provides tailored recommendations to enhance the transparency and integrity of the data set. The scorecard addresses technical and ethical aspects, offering a holistic evaluation of data practices. This approach aims to improve the quality of the data set. It offers practical guidance to curators and researchers in developing responsible AI systems, ensuring fairness and accountability in decision support systems.","authors":["Tadesse K. Bahiru","Haileleol Tibebu","Ioannis A. Kakadiaris"],"url":"https://arxiv.org/abs/2506.02071"}
{"created":"2025-06-04","title":"Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability","abstract":"While large language models (LLMs) show promise in code generation, existing benchmarks neglect the flowchart-based code generation. To promote further research on flowchart-based code generation, this work presents Flow2Code, a novel benchmark for flowchart-based code generation evaluation. The evaluation dataset spans 15 programming languages and includes 5,622 code segments paired with 16,866 flowcharts of three types: code, UML, and pseudocode. Extensive experiments with 13 multimodal LLMs reveal that current LLMs can not generate code based on flowcharts perfectly. Besides, experiment results show that the supervised fine-tuning technique contributes greatly to the models' performance. We publicly release our code and datasets at https://github.com/hml-github/Flow2Code.","authors":["Mengliang He","Jiayi Zeng","Yankai Jiang","Wei Zhang","Zeming Liu","Xiaoming Shi","Aimin Zhou"],"url":"https://arxiv.org/abs/2506.02073"}
{"created":"2025-06-04","title":"Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition","abstract":"Decomposing weight matrices into quantization and low-rank components ($\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$) is a widely used technique for compressing large language models (LLMs). Existing joint optimization methods iteratively alternate between quantization and low-rank approximation. However, these methods tend to prioritize one component at the expense of the other, resulting in suboptimal decompositions that fail to leverage each component's unique strengths. In this work, we introduce Outlier-Driven Low-Rank Initialization (ODLRI), which assigns low-rank components the specific role of capturing activation-sensitive weights. This structured decomposition mitigates outliers' negative impact on quantization, enabling more effective balance between quantization and low-rank approximation. Experiments on Llama2 (7B, 13B, 70B), Llama3-8B, and Mistral-7B demonstrate that incorporating ODLRI into the joint optimization framework consistently reduces activation-aware error, minimizes quantization scale, and improves perplexity and zero-shot accuracy in low-bit settings.","authors":["Yoonjun Cho","Soeun Kim","Dongjae Jeon","Kyelim Lee","Beomsoo Lee","Albert No"],"url":"https://arxiv.org/abs/2506.02077"}
{"created":"2025-06-04","title":"Robust Federated Learning against Noisy Clients via Masked Optimization","abstract":"In recent years, federated learning (FL) has made significant advance in privacy-sensitive applications. However, it can be hard to ensure that FL participants provide well-annotated data for training. The corresponding annotations from different clients often contain complex label noise at varying levels. This label noise issue has a substantial impact on the performance of the trained models, and clients with greater noise levels can be largely attributed for this degradation. To this end, it is necessary to develop an effective optimization strategy to alleviate the adverse effects of these noisy clients.In this study, we present a two-stage optimization framework, MaskedOptim, to address this intricate label noise problem. The first stage is designed to facilitate the detection of noisy clients with higher label noise rates. The second stage focuses on rectifying the labels of the noisy clients' data through an end-to-end label correction mechanism, aiming to mitigate the negative impacts caused by misinformation within datasets. This is achieved by learning the potential ground-truth labels of the noisy clients' datasets via backpropagation. To further enhance the training robustness, we apply the geometric median based model aggregation instead of the commonly-used vanilla averaged model aggregation. We implement sixteen related methods and conduct evaluations on three image datasets and one text dataset with diverse label noise patterns for a comprehensive comparison. Extensive experimental results indicate that our proposed framework shows its robustness in different scenarios. Additionally, our label correction framework effectively enhances the data quality of the detected noisy clients' local datasets. % Our codes will be open-sourced to facilitate related research communities. Our codes are available via https://github.com/Sprinter1999/MaskedOptim .","authors":["Xuefeng Jiang","Tian Wen","Zhiqin Yang","Lvhua Wu","Yufeng Chen","Sheng Sun","Yuwei Wang","Min Liu"],"url":"https://arxiv.org/abs/2506.02079"}
{"created":"2025-06-04","title":"RATFM: Retrieval-augmented Time Series Foundation Model for Anomaly Detection","abstract":"Inspired by the success of large language models (LLMs) in natural language processing, recent research has explored the building of time series foundation models and applied them to tasks such as forecasting, classification, and anomaly detection. However, their performances vary between different domains and tasks. In LLM-based approaches, test-time adaptation using example-based prompting has become common, owing to the high cost of retraining. In the context of anomaly detection, which is the focus of this study, providing normal examples from the target domain can also be effective. However, time series foundation models do not naturally acquire the ability to interpret or utilize examples or instructions, because the nature of time series data used during training does not encourage such capabilities. To address this limitation, we propose a retrieval augmented time series foundation model (RATFM), which enables pretrained time series foundation models to incorporate examples of test-time adaptation. We show that RATFM achieves a performance comparable to that of in-domain fine-tuning while avoiding domain-dependent fine-tuning. Experiments on the UCR Anomaly Archive, a multi-domain dataset including nine domains, confirms the effectiveness of the proposed approach.","authors":["Chihiro Maru","Shoetsu Sato"],"url":"https://arxiv.org/abs/2506.02081"}
{"created":"2025-06-04","title":"SALF-MOS: Speaker Agnostic Latent Features Downsampled for MOS Prediction","abstract":"Speech quality assessment is a critical process in selecting text-to-speech synthesis (TTS) or voice conversion models. Evaluation of voice synthesis can be done using objective metrics or subjective metrics. Although there are many objective metrics like the Perceptual Evaluation of Speech Quality (PESQ), Perceptual Objective Listening Quality Assessment (POLQA) or Short-Time Objective Intelligibility (STOI) but none of them is feasible in selecting the best model. On the other hand subjective metric like Mean Opinion Score is highly reliable but it requires a lot of manual efforts and are time-consuming. To counter the issues in MOS Evaluation, we have developed a novel model, Speaker Agnostic Latent Features (SALF)-Mean Opinion Score (MOS) which is a small-sized, end-to-end, highly generalized and scalable model for predicting MOS score on a scale of 5. We use the sequences of convolutions and stack them to get the latent features of the audio samples to get the best state-of-the-art results based on mean squared error (MSE), Linear Concordance Correlation coefficient (LCC), Spearman Rank Correlation Coefficient (SRCC) and Kendall Rank Correlation Coefficient (KTAU).","authors":["Saurabh Agrawal","Raj Gohil","Gopal Kumar Agrawal","Vikram C M","Kushal Verma"],"url":"https://arxiv.org/abs/2506.02082"}
{"created":"2025-06-04","title":"LASPA: Language Agnostic Speaker Disentanglement with Prefix-Tuned Cross-Attention","abstract":"Speaker recognition models face challenges in multi-lingual settings due to the entanglement of linguistic information within speaker embeddings. The overlap between vocal traits such as accent, vocal anatomy, and a language's phonetic structure complicates separating linguistic and speaker information. Disentangling these components can significantly improve speaker recognition accuracy. To this end, we propose a novel disentanglement learning strategy that integrates joint learning through prefix-tuned cross-attention. This approach is particularly effective when speakers switch between languages. Experimental results show the model generalizes across monolingual and multi-lingual settings, including unseen languages. Notably, the proposed model improves the equal error rate across multiple datasets, highlighting its ability to separate language information from speaker embeddings and enhance recognition in diverse linguistic conditions.","authors":["Aditya Srinivas Menon","Raj Prakash Gohil","Kumud Tripathi","Pankaj Wasnik"],"url":"https://arxiv.org/abs/2506.02083"}
{"created":"2025-06-04","title":"Temporal Causal-based Simulation for Realistic Time-series Generation","abstract":"Causal Discovery plays a pivotal role in revealing relationships among observed variables, particularly in the temporal setup. While the majority of CD methods rely on synthetic data for evaluation, and recently for training, these fall short in accurately mirroring real-world scenarios; an effect even more evident in temporal data. Generation techniques depending on simplified assumptions on causal structure, effects and time, limit the quality and diversity of the simulated data. In this work, we introduce Temporal Causal-based Simulation (TCS), a robust framework for generating realistic time-series data and their associated temporal causal graphs. The approach is structured in three phases: estimating the true lagged causal structure of the data, approximating the functional dependencies between variables and learning the noise distribution of the corresponding causal model, each part of which can be explicitly tailored based on data assumptions and characteristics. Through an extensive evaluation process, we highlight that single detection methods for generated data discrimination prove inadequate, accentuating it as a multifaceted challenge. For this, we detail a Min-max optimization phase that draws on AutoML techniques. Our contributions include a flexible, model-agnostic pipeline for generating realistic temporal causal data, a thorough evaluation setup which enhances the validity of the generated datasets and insights into the challenges posed by realistic data generation. Through experiments involving not only real but also semi-synthetic and purely synthetic datasets, we demonstrate that while sampling realistic causal data remains a complex task, our method enriches the domain of generating sensible causal-based temporal data.","authors":["Nikolaos Gkorgkolis","Nikolaos Kougioulis","MingXue Wang","Bora Caglayan","Andrea Tonon","Dario Simionato","Ioannis Tsamardinos"],"url":"https://arxiv.org/abs/2506.02084"}
{"created":"2025-06-04","title":"Unveiling Audio Deepfake Origins: A Deep Metric learning And Conformer Network Approach With Ensemble Fusion","abstract":"Audio deepfakes are acquiring an unprecedented level of realism with advanced AI. While current research focuses on discerning real speech from spoofed speech, tracing the source system is equally crucial. This work proposes a novel audio source tracing system combining deep metric multi-class N-pair loss with Real Emphasis and Fake Dispersion framework, a Conformer classification network, and ensemble score-embedding fusion. The N-pair loss improves discriminative ability, while Real Emphasis and Fake Dispersion enhance robustness by focusing on differentiating real and fake speech patterns. The Conformer network captures both global and local dependencies in the audio signal, crucial for source tracing. The proposed ensemble score-embedding fusion shows an optimal trade-off between in-domain and out-of-domain source tracing scenarios. We evaluate our method using Frechet Distance and standard metrics, demonstrating superior performance in source tracing over the baseline system.","authors":["Ajinkya Kulkarni","Sandipana Dowerah","Tanel Alumae","Mathew Magimai. -Doss"],"url":"https://arxiv.org/abs/2506.02085"}
{"created":"2025-06-04","title":"FSM Modeling For Off-Blockchain Computation","abstract":"Blockchain benefits are due to immutability, replication, and storage-and-execution of smart contracts on the blockchain. However, the benefits come at increased costs due to the blockchain size and execution. We address three fundamental issues that arise in transferring certain parts of a smart contract to be executed off-chain: (i) identifying which parts (patterns) of the smart contract should be considered for processing off-chain, (ii) under which conditions should a smart-contract pattern to be processed off-chain, and (iii) how to facilitate interaction between the computation off and on-chain. We use separation of concerns and FSM modeling to model a smart contract and generate its code. We then (i) use our algorithm to determine which parts (patterns) of the smart contract are to be processed off-chain; (ii) consider conditions under which to move the pattern off-chain; and (iii) provide model for automatically generating the interface between on and off-chain computation.","authors":["Christian Gang Liu"],"url":"https://arxiv.org/abs/2506.02086"}
{"created":"2025-06-04","title":"Enhancing Speech Emotion Recognition with Graph-Based Multimodal Fusion and Prosodic Features for the Speech Emotion Recognition in Naturalistic Conditions Challenge at Interspeech 2025","abstract":"Training SER models in natural, spontaneous speech is especially challenging due to the subtle expression of emotions and the unpredictable nature of real-world audio. In this paper, we present a robust system for the INTERSPEECH 2025 Speech Emotion Recognition in Naturalistic Conditions Challenge, focusing on categorical emotion recognition. Our method combines state-of-the-art audio models with text features enriched by prosodic and spectral cues. In particular, we investigate the effectiveness of Fundamental Frequency (F0) quantization and the use of a pretrained audio tagging model. We also employ an ensemble model to improve robustness. On the official test set, our system achieved a Macro F1-score of 39.79% (42.20% on validation). Our results underscore the potential of these methods, and analysis of fusion techniques confirmed the effectiveness of Graph Attention Networks. Our source code is publicly available.","authors":["Alef Iury Siqueira Ferreira","Lucas Rafael Gris","Alexandre Ferro Filho","Lucas \\'Olives","Daniel Ribeiro","Luiz Fernando","Fernanda Lustosa","Rodrigo Tanaka","Frederico Santos de Oliveira","Arlindo Galv\\~ao Filho"],"url":"https://arxiv.org/abs/2506.02088"}
{"created":"2025-06-04","title":"SALAD: Systematic Assessment of Machine Unlearing on LLM-Aided Hardware Design","abstract":"Large Language Models (LLMs) offer transformative capabilities for hardware design automation, particularly in Verilog code generation. However, they also pose significant data security challenges, including Verilog evaluation data contamination, intellectual property (IP) design leakage, and the risk of malicious Verilog generation. We introduce SALAD, a comprehensive assessment that leverages machine unlearning to mitigate these threats. Our approach enables the selective removal of contaminated benchmarks, sensitive IP and design artifacts, or malicious code patterns from pre-trained LLMs, all without requiring full retraining. Through detailed case studies, we demonstrate how machine unlearning techniques effectively reduce data security risks in LLM-aided hardware design.","authors":["Zeng Wang","Minghao Shao","Rupesh Karn","Jitendra Bhandari","Likhitha Mankali","Ramesh Karri","Ozgur Sinanoglu","Muhammad Shafique","Johann Knechtel"],"url":"https://arxiv.org/abs/2506.02089"}
{"created":"2025-06-04","title":"The Impact of Software Testing with Quantum Optimization Meets Machine Learning","abstract":"Modern software systems complexity challenges efficient testing, as traditional machine learning (ML) struggles with large test suites. This research presents a hybrid framework integrating Quantum Annealing with ML to optimize test case prioritization in CI/CD pipelines. Leveraging quantum optimization, it achieves a 25 percent increase in defect detection efficiency and a 30 percent reduction in test execution time versus classical ML, validated on the Defects4J dataset. A simulated CI/CD environment demonstrates robustness across evolving codebases. Visualizations, including defect heatmaps and performance graphs, enhance interpretability. The framework addresses quantum hardware limits, CI/CD integration, and scalability for 2025s hybrid quantum-classical ecosystems, offering a transformative approach to software quality assurance.","authors":["Gopichand Bandarupalli"],"url":"https://arxiv.org/abs/2506.02090"}
{"created":"2025-06-04","title":"Comparison of spectrogram scaling in multi-label Music Genre Recognition","abstract":"As the accessibility and ease-of-use of digital audio workstations increases, so does the quantity of music available to the average listener; additionally, differences between genres are not always well defined and can be abstract, with widely varying combinations of genres across individual records. In this article, multiple preprocessing methods and approaches to model training are described and compared, accounting for the eclectic nature of today's albums. A custom, manually labeled dataset of more than 18000 entries has been used to perform the experiments.","authors":["Bartosz Karpi\\'nski","Cyryl Leszczy\\'nski"],"url":"https://arxiv.org/abs/2506.02091"}
{"created":"2025-06-04","title":"Towards Better Generalization and Interpretability in Unsupervised Concept-Based Models","abstract":"To increase the trustworthiness of deep neural networks, it is critical to improve the understanding of how they make decisions. This paper introduces a novel unsupervised concept-based model for image classification, named Learnable Concept-Based Model (LCBM) which models concepts as random variables within a Bernoulli latent space. Unlike traditional methods that either require extensive human supervision or suffer from limited scalability, our approach employs a reduced number of concepts without sacrificing performance. We demonstrate that LCBM surpasses existing unsupervised concept-based models in generalization capability and nearly matches the performance of black-box models. The proposed concept representation enhances information retention and aligns more closely with human understanding. A user study demonstrates the discovered concepts are also more intuitive for humans to interpret. Finally, despite the use of concept embeddings, we maintain model interpretability by means of a local linear combination of concepts.","authors":["Francesco De Santis","Philippe Bich","Gabriele Ciravegna","Pietro Barbiero","Danilo Giordano","Tania Cerquitelli"],"url":"https://arxiv.org/abs/2506.02092"}
{"created":"2025-06-04","title":"Generative AI for Multiple Choice STEM Assessments","abstract":"Artificial intelligence technology enables a range of enhancements in computer-aided instruction, from accelerating the creation of teaching materials to customizing learning paths based on learner outcomes. However, ensuring the mathematical accuracy and semantic integrity of generative AI output remains a significant challenge, particularly in STEM disciplines. In this study, we explore the use of generative AI in which \"hallucinations\" -- typically viewed as undesirable inaccuracies -- can instead serve a pedagogical purpose. Specifically, we investigate the generation of plausible but incorrect alternatives for multiple choice assessments, where credible distractors are essential for effective assessment design. We describe the M\\\"obius platform for online instruction, with particular focus on its architecture for handling mathematical elements through specialized semantic packages that support dynamic, parameterized STEM content. We examine methods for crafting prompts that interact effectively with these mathematical semantics to guide the AI in generating high-quality multiple choice distractors. Finally, we demonstrate how this approach reduces the time and effort associated with creating robust teaching materials while maintaining academic rigor and assessment validity.","authors":["Christina Perdikoulias","Chad Vance","Stephen M. Watt"],"url":"https://arxiv.org/abs/2506.02094"}
{"created":"2025-06-04","title":"Cycle Consistency as Reward: Learning Image-Text Alignment without Human Preferences","abstract":"Learning alignment between language and vision is a fundamental challenge, especially as multimodal data becomes increasingly detailed and complex. Existing methods often rely on collecting human or AI preferences, which can be costly and time-intensive. We propose an alternative approach that leverages cycle consistency as a supervisory signal. Given an image and generated text, we map the text back to image space using a text-to-image model and compute the similarity between the original image and its reconstruction. Analogously, for text-to-image generation, we measure the textual similarity between an input caption and its reconstruction through the cycle. We use the cycle consistency score to rank candidates and construct a preference dataset of 866K comparison pairs. The reward model trained on our dataset outperforms state-of-the-art alignment metrics on detailed captioning, with superior inference-time scalability when used as a verifier for Best-of-N sampling. Furthermore, performing DPO and Diffusion DPO using our dataset enhances performance across a wide range of vision-language tasks and text-to-image generation. Our dataset, model, and code are at https://cyclereward.github.io","authors":["Hyojin Bahng","Caroline Chan","Fredo Durand","Phillip Isola"],"url":"https://arxiv.org/abs/2506.02095"}
{"created":"2025-06-04","title":"SynthRL: Scaling Visual Reasoning with Verifiable Data Synthesis","abstract":"Vision-language models (VLMs) trained via reinforcement learning with verifiable reward (RLVR) have shown notable progress in scaling test-time compute effectively. In this work, we investigate how synthesized RL data can further improve RLVR. To this end, we propose \\textbf{SynthRL}-a scalable and guaranteed pipeline for automatic data scaling in reasoning-oriented RL training. SynthRL comprises three key stages: (1) selecting seed questions with appropriate distribution, (2) augmenting them into more challenging variants while preserving the original answers, and (3) a guaranteed verification stage that ensures near-perfect correctness and difficulty enhancement. Our empirical experiments demonstrate SynthRL's scalability and effectiveness. When applied to the MMK12 dataset, SynthRL synthesizes over 3.3K additional verifiable, challenging questions from approximately 8K seed samples. Models trained with our synthesized data achieve consistent gains across five out-of-domain visual math reasoning benchmarks, with a significant improvement over baseline models trained on seed data alone. Notably, detailed analysis reveals that the gains are more pronounced on the most challenging evaluation samples, highlighting SynthRL's effectiveness in eliciting deeper and more complex reasoning patterns.","authors":["Zijian Wu","Jinjie Ni","Xiangyan Liu","Zichen Liu","Hang Yan","Michael Qizhe Shieh"],"url":"https://arxiv.org/abs/2506.02096"}
{"created":"2025-06-04","title":"Hybrid AI for Responsive Multi-Turn Online Conversations with Novel Dynamic Routing and Feedback Adaptation","abstract":"Retrieval-Augmented Generation (RAG) systems and large language model (LLM)-powered chatbots have significantly advanced conversational AI by combining generative capabilities with external knowledge retrieval. Despite their success, enterprise-scale deployments face critical challenges, including diverse user queries, high latency, hallucinations, and difficulty integrating frequently updated domain-specific knowledge. This paper introduces a novel hybrid framework that integrates RAG with intent-based canned responses, leveraging predefined high-confidence responses for efficiency while dynamically routing complex or ambiguous queries to the RAG pipeline. Our framework employs a dialogue context manager to ensure coherence in multi-turn interactions and incorporates a feedback loop to refine intents, dynamically adjust confidence thresholds, and expand response coverage over time. Experimental results demonstrate that the proposed framework achieves a balance of high accuracy (95\\%) and low latency (180ms), outperforming RAG and intent-based systems across diverse query types, positioning it as a scalable and adaptive solution for enterprise conversational AI applications.","authors":["Priyaranjan Pattnayak","Amit Agarwal","Hansa Meghwani","Hitesh Laxmichand Patel","Srikant Panda"],"url":"https://arxiv.org/abs/2506.02097"}
{"created":"2025-06-04","title":"LibriBrain: Over 50 Hours of Within-Subject MEG to Improve Speech Decoding Methods at Scale","abstract":"LibriBrain represents the largest single-subject MEG dataset to date for speech decoding, with over 50 hours of recordings -- 5$\\times$ larger than the next comparable dataset and 50$\\times$ larger than most. This unprecedented `depth' of within-subject data enables exploration of neural representations at a scale previously unavailable with non-invasive methods. LibriBrain comprises high-quality MEG recordings together with detailed annotations from a single participant listening to naturalistic spoken English, covering nearly the full Sherlock Holmes canon. Designed to support advances in neural decoding, LibriBrain comes with a Python library for streamlined integration with deep learning frameworks, standard data splits for reproducibility, and baseline results for three foundational decoding tasks: speech detection, phoneme classification, and word classification. Baseline experiments demonstrate that increasing training data yields substantial improvements in decoding performance, highlighting the value of scaling up deep, within-subject datasets. By releasing this dataset, we aim to empower the research community to advance speech decoding methodologies and accelerate the development of safe, effective clinical brain-computer interfaces.","authors":["Miran \\\"Ozdogan","Gilad Landau","Gereon Elvers","Dulhan Jayalath","Pratik Somaiya","Francesco Mantegna","Mark Woolrich","Oiwi Parker Jones"],"url":"https://arxiv.org/abs/2506.02098"}
{"created":"2025-06-04","title":"SAB3R: Semantic-Augmented Backbone in 3D Reconstruction","abstract":"We introduce a new task, Map and Locate, which unifies the traditionally distinct objectives of open-vocabulary segmentation - detecting and segmenting object instances based on natural language queries - and 3D reconstruction, the process of estimating a scene's 3D structure from visual inputs. Specifically, Map and Locate involves generating a point cloud from an unposed video and segmenting object instances based on open-vocabulary queries. This task serves as a critical step toward real-world embodied AI applications and introduces a practical task that bridges reconstruction, recognition and reorganization. To tackle this task, we introduce a simple yet effective baseline, which we denote as SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computer vision, and incorporates a lightweight distillation strategy. This method transfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIP and DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliary frozen networks, our model generates per-pixel semantic features and constructs cohesive point maps in a single forward pass. Compared to separately deploying MASt3R and CLIP, our unified model, SAB3R, achieves superior performance on the Map and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semantic segmentation and 3D tasks to comprehensively validate its effectiveness.","authors":["Xuweiyi Chen","Tian Xia","Sihan Xu","Jianing Yang","Joyce Chai","Zezhou Cheng"],"url":"https://arxiv.org/abs/2506.02112"}
{"created":"2025-06-04","title":"Random-key genetic algorithms","abstract":"A random-key genetic algorithm is an evolutionary metaheuristic for discrete and global optimization. Each solution is encoded as a vector of N random keys, where a random key is a real number randomly generated in the continuous interval [0, 1). A decoder maps each vector of random keys to a solution of the optimization problem being solved and computes its cost. The benefit of this approach is that all genetic operators and transformations can be maintained within the unitary hypercube, regardless of the problem being addressed. This enhances the productivity and maintainability of the core framework. The algorithm starts with a population of P vectors of random keys. At each iteration, the vectors are partitioned into two sets: a smaller set of high-valued elite solutions and the remaining non-elite solutions. All elite elements are copied, without change, to the next population. A small number of random-key vectors (the mutants) is added to the population of the next iteration. The remaining elements of the population of the next iteration are generated by combining, with the parametrized uniform crossover of Spears and DeJong (1991), pairs of solutions. This chapter reviews random-key genetic algorithms and describes an effective variant called biased random-key genetic algorithms.","authors":["Mariana A. Londe","Luciana S. Pessoa","Carlos E. Andrade","Jos\\'e F. Gon\\c{c}alves","Mauricio G. C. Resende"],"url":"https://arxiv.org/abs/2506.02120"}
{"created":"2025-06-04","title":"Descriptive History Representations: Learning Representations by Answering Questions","abstract":"Effective decision making in partially observable environments requires compressing long interaction histories into informative representations. We introduce Descriptive History Representations (DHRs): sufficient statistics characterized by their capacity to answer relevant questions about past interactions and potential future outcomes. DHRs focus on capturing the information necessary to address task-relevant queries, providing a structured way to summarize a history for optimal control. We propose a multi-agent learning framework, involving representation, decision, and question-asking components, optimized using a joint objective that balances reward maximization with the representation's ability to answer informative questions. This yields representations that capture the salient historical details and predictive structures needed for effective decision making. We validate our approach on user modeling tasks with public movie and shopping datasets, generating interpretable textual user profiles which serve as sufficient statistics for predicting preference-driven behavior of users.","authors":["Guy Tennenholtz","Jihwan Jeong","Chih-Wei Hsu","Yinlam Chow","Craig Boutilier"],"url":"https://arxiv.org/abs/2506.02125"}
{"created":"2025-06-04","title":"Knowledge or Reasoning? A Close Look at How LLMs Think Across Domains","abstract":"Recent advances in reasoning-enhanced Large Language Models such as OpenAI-o1/3 and DeepSeek-R1 have significantly improved performance on complex tasks. However, the quality and transparency of their internal reasoning processes remain underexplored. This work moves beyond the final-answer accuracy and investigates step-by-step reasoning in the medical and mathematical domains by explicitly decomposing the thinking trajectories into two parts: knowledge and reasoning. Specifically, we introduce a fine-grained evaluation framework that judges: (1) the correctness of knowledge used (measured by Knowledge Index (KI)) and (2) the quality of reasoning (measured by Information Gain (InfoGain)). Using this framework, we study R1-distilled and base Qwen models trained with supervised fine-tuning (SFT) and/or reinforcement learning (RL) in the medical and math domains. Three intriguing findings emerge: (1) The general reasoning abilities in R1-distilled models do not transfer effectively to the medical domain through either SFT or RL. (2) SFT raises final-answer accuracy in both domains, but often at the cost of reasoning quality: InfoGain drops by 38.9% on average compared with untrained models; In the medical domain, however, SFT remains crucial because domain knowledge is indispensable. (3) RL enhances medical reasoning by pruning inaccurate or irrelevant knowledge from reasoning paths, thereby improving both reasoning accuracy and knowledge correctness.","authors":["Juncheng Wu","Sheng Liu","Haoqin Tu","Hang Yu","Xiaoke Huang","James Zou","Cihang Xie","Yuyin Zhou"],"url":"https://arxiv.org/abs/2506.02126"}
{"created":"2025-06-04","title":"Benchmarking Large Language Models for Polymer Property Predictions","abstract":"Machine learning has revolutionized polymer science by enabling rapid property prediction and generative design. Large language models (LLMs) offer further opportunities in polymer informatics by simplifying workflows that traditionally rely on large labeled datasets, handcrafted representations, and complex feature engineering. LLMs leverage natural language inputs through transfer learning, eliminating the need for explicit fingerprinting and streamlining training. In this study, we finetune general purpose LLMs -- open-source LLaMA-3-8B and commercial GPT-3.5 -- on a curated dataset of 11,740 entries to predict key thermal properties: glass transition, melting, and decomposition temperatures. Using parameter-efficient fine-tuning and hyperparameter optimization, we benchmark these models against traditional fingerprinting-based approaches -- Polymer Genome, polyGNN, and polyBERT -- under single-task (ST) and multi-task (MT) learning. We find that while LLM-based methods approach traditional models in performance, they generally underperform in predictive accuracy and efficiency. LLaMA-3 consistently outperforms GPT-3.5, likely due to its tunable open-source architecture. Additionally, ST learning proves more effective than MT, as LLMs struggle to capture cross-property correlations, a key strength of traditional methods. Analysis of molecular embeddings reveals limitations of general purpose LLMs in representing nuanced chemo-structural information compared to handcrafted features and domain-specific embeddings. These findings provide insight into the interplay between molecular embeddings and natural language processing, guiding LLM selection for polymer informatics.","authors":["Sonakshi Gupta","Akhlak Mahmood","Shivank Shukla","Rampi Ramprasad"],"url":"https://arxiv.org/abs/2506.02129"}
{"created":"2025-06-04","title":"Model Internal Sleuthing: Finding Lexical Identity and Inflectional Morphology in Modern Language Models","abstract":"Large transformer-based language models dominate modern NLP, yet our understanding of how they encode linguistic information is rooted in studies of early models like BERT and GPT-2. To better understand today's language models, we investigate how both classical architectures (BERT, DeBERTa, GPT-2)and contemporary large language models (Pythia, OLMo-2, Gemma-2, Qwen2.5, Llama-3.1) represent lexical identity and inflectional morphology. We train linear and nonlinear classifiers on layer-wise activations to predict word lemmas and inflectional features. We discover that models concentrate lexical information linearly in early layers and increasingly nonlinearly in later layers, while keeping inflectional information uniformly accessible and linearly separable throughout the layers. Further analysis reveals that these models encode inflectional morphology through generalizable abstractions, but rely predominantly on memorization to encode lexical identity. Remarkably, these patterns emerge across all 16 models we test, despite differences in architecture, size, and training regime (including pretrained and instruction-tuned variants). This consistency suggests that, despite substantial advances in LLM technologies, transformer models organize linguistic information in similar ways, indicating that these properties could be fundamental for next token prediction and are learned early during pretraining. Our code is available at https://github.com/ml5885/model_internal_sleuthing.","authors":["Michael Li","Nishant Subramani"],"url":"https://arxiv.org/abs/2506.02132"}
{"created":"2025-06-04","title":"Characterization of latency and jitter in TSN emulation","abstract":"This research focuses on timestamping methods for profiling network traffic in software-based environments. Accurate timestamping is crucial for evaluating network performance, particularly in Time-Sensitive Networking (TSN). We explore and compare four timestamping techniques within a TSN emulation context, though its findings extend to other network scenarios. The study leverages the Mininet emulator to model TSN networks, defining hosts, bridges, links, and traffic streams. It characterizes bridge latencies and jitter, solves the TSN scheduling problem based on measured parameters, and evaluates the correctness of a deployed schedule for a use case. Key contributions include a methodology for software-based timestamping, solutions for TSN emulation challenges in Linux and Mininet, and experimental insights for optimizing TSN emulation platforms on various system configurations, with and without Intel TCC, either on a high-end workstation or on an industrial PC.","authors":["\\'Alex Gracia","Jos\\'e Luis Briz","H\\'ector Blanco-Alcaine","Juan Segarra","Alitzel G. Torres-Mac\\'ias","Antonio Ram\\'irez-Trevi\\~no"],"url":"https://arxiv.org/abs/2506.02133"}
{"created":"2025-06-04","title":"ReconXF: Graph Reconstruction Attack via Public Feature Explanations on Privatized Node Features and Labels","abstract":"Graph Neural Networks (GNNs) achieve high performance across many applications but function as black-box models, limiting their use in critical domains like healthcare and criminal justice. Explainability methods address this by providing feature-level explanations that identify important node attributes for predictions. These explanations create privacy risks. Combined with auxiliary information, feature explanations can enable adversaries to reconstruct graph structure, exposing sensitive relationships. Existing graph reconstruction attacks assume access to original auxiliary data, but practical systems use differential privacy to protect node features and labels while providing explanations for transparency. We study a threat model where adversaries access public feature explanations along with privatized node features and labels. We show that existing explanation-based attacks like GSEF perform poorly with privatized data due to noise from differential privacy mechanisms. We propose ReconXF, a graph reconstruction attack for scenarios with public explanations and privatized auxiliary data. Our method adapts explanation-based frameworks by incorporating denoising mechanisms that handle differential privacy noise while exploiting structural signals in explanations. Experiments across multiple datasets show ReconXF outperforms SoTA methods in privatized settings, with improvements in AUC and average precision. Results indicate that public explanations combined with denoising enable graph structure recovery even under the privacy protection of auxiliary data. Code is available at (link to be made public after acceptance).","authors":["Rishi Raj Sahoo","Rucha Bhalchandra Joshi","Subhankar Mishra"],"url":"https://arxiv.org/abs/2506.02134"}
{"created":"2025-06-04","title":"Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer Explainability","abstract":"The development of effective explainability tools for Transformers is a crucial pursuit in deep learning research. One of the most promising approaches in this domain is Layer-wise Relevance Propagation (LRP), which propagates relevance scores backward through the network to the input space by redistributing activation values based on predefined rules. However, existing LRP-based methods for Transformer explainability entirely overlook a critical component of the Transformer architecture: its positional encoding (PE), resulting in violation of the conservation property, and the loss of an important and unique type of relevance, which is also associated with structural and positional features. To address this limitation, we reformulate the input space for Transformer explainability as a set of position-token pairs. This allows us to propose specialized theoretically-grounded LRP rules designed to propagate attributions across various positional encoding methods, including Rotary, Learnable, and Absolute PE. Extensive experiments with both fine-tuned classifiers and zero-shot foundation models, such as LLaMA 3, demonstrate that our method significantly outperforms the state-of-the-art in both vision and NLP explainability tasks. Our code is publicly available.","authors":["Yarden Bakish","Itamar Zimerman","Hila Chefer","Lior Wolf"],"url":"https://arxiv.org/abs/2506.02138"}
{"created":"2025-06-04","title":"The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning","abstract":"Few-shot learning in large language models (LLMs) reveals a deep paradox: Some tasks generalize from minimal examples, while others require extensive supervision. We address this through the Unified Cognitive Consciousness Theory (UCCT), which reframes LLMs not as incomplete agents, but as unconscious substrates, repositories of latent linguistic and conceptual patterns that operate without explicit semantics or goal-directed reasoning. In this view, LLMs are not broken approximations of cognition, but necessary and foundational components of general intelligence. Semantic anchoring, through prompts, roles, and interaction, acts as a conscious control layer, binding latent structure to task-relevant meaning and enabling coherent reasoning. UCCT offers a unifying account of prompting, fine-tuning, retrieval, and multi-agent coordination, all grounded in probabilistic alignment between unconscious representation and external control. To support this model, we present the Threshold-Crossing Dynamics Theorem, which formalizes semantic anchoring as a probabilistic phase transition. But the central claim remains architectural: AGI will not emerge by discarding LLMs, but by aligning and integrating them into systems that reason, regulate, and adapt together.","authors":["Edward Y. Chang"],"url":"https://arxiv.org/abs/2506.02139"}
{"created":"2025-06-04","title":"BabyLM's First Constructions: Causal interventions provide a signal of learning","abstract":"Construction grammar posits that children acquire constructions (form-meaning pairings) from the statistics of their environment. Recent work supports this hypothesis by showing sensitivity to constructions in pretrained language models (PLMs), including one recent study (Rozner et al., 2025) demonstrating that constructions shape the PLM's output distribution. However, models under study have generally been trained on developmentally implausible amounts of data, casting doubt on their relevance to human language learning. Here we use Rozner et al.'s methods to evaluate constructional learning in models from the 2024 BabyLM challenge. Our results show that even when trained on developmentally plausible quantities of data, models represent diverse constructions, even hard cases that are superficially indistinguishable. We further find correlational evidence that constructional performance may be functionally relevant: models that better represent constructions perform better on the BabyLM benchmarks.","authors":["Joshua Rozner","Leonie Weissweiler","Cory Shain"],"url":"https://arxiv.org/abs/2506.02147"}
{"created":"2025-06-04","title":"Implicit Deformable Medical Image Registration with Learnable Kernels","abstract":"Deformable medical image registration is an essential task in computer-assisted interventions. This problem is particularly relevant to oncological treatments, where precise image alignment is necessary for tracking tumor growth, assessing treatment response, and ensuring accurate delivery of therapies. Recent AI methods can outperform traditional techniques in accuracy and speed, yet they often produce unreliable deformations that limit their clinical adoption. In this work, we address this challenge and introduce a novel implicit registration framework that can predict accurate and reliable deformations. Our insight is to reformulate image registration as a signal reconstruction problem: we learn a kernel function that can recover the dense displacement field from sparse keypoint correspondences. We integrate our method in a novel hierarchical architecture, and estimate the displacement field in a coarse-to-fine manner. Our formulation also allows for efficient refinement at test time, permitting clinicians to easily adjust registrations when needed. We validate our method on challenging intra-patient thoracic and abdominal zero-shot registration tasks, using public and internal datasets from the local University Hospital. Our method not only shows competitive accuracy to state-of-the-art approaches, but also bridges the generalization gap between implicit and explicit registration techniques. In particular, our method generates deformations that better preserve anatomical relationships and matches the performance of specialized commercial systems, underscoring its potential for clinical adoption.","authors":["Stefano Fogarollo","Gregor Laimer","Reto Bale","Matthias Harders"],"url":"https://arxiv.org/abs/2506.02150"}
{"created":"2025-06-04","title":"Introduction to the theory of generalized locally Toeplitz sequences and its applications","abstract":"The theory of generalized locally Toeplitz (GLT) sequences was conceived as an apparatus for computing the spectral distribution of matrices arising from the numerical discretization of differential equations (DEs). The purpose of this review is to introduce the reader to the theory of GLT sequences and to present some of its applications to the computation of the spectral distribution of DE discretization matrices. We mainly focus on the applications, whereas the theory is presented in a self-contained tool-kit fashion, without entering into technical details. The exposition is supposed to be understandable to master's degree students in mathematics. It also discloses new more efficient approaches to the spectral analysis of DE discretization matrices as well as a novel spectral analysis tool that has not been considered in the GLT literature heretofore, i.e., the modulus of integral continuity.","authors":["Carlo Garoni"],"url":"https://arxiv.org/abs/2506.02151"}
{"created":"2025-06-04","title":"Small Language Models are the Future of Agentic AI","abstract":"Large language models (LLMs) are often praised for exhibiting near-human performance on a wide range of tasks and valued for their ability to hold a general conversation. The rise of agentic AI systems is, however, ushering in a mass of applications in which language models perform a small number of specialized tasks repetitively and with little variation.","authors":["Peter Belcak","Greg Heinrich","Shizhe Diao","Yonggan Fu","Xin Dong","Saurav Muralidharan","Yingyan Celine Lin","Pavlo Molchanov"],"url":"https://arxiv.org/abs/2506.02153"}
{"created":"2025-06-04","title":"Z-Error Loss for Training Neural Networks","abstract":"Outliers introduce significant training challenges in neural networks by propagating erroneous gradients, which can degrade model performance and generalization. We propose the Z-Error Loss, a statistically principled approach that minimizes outlier influence during training by masking the contribution of data points identified as out-of-distribution within each batch. This method leverages batch-level statistics to automatically detect and exclude anomalous samples, allowing the model to focus its learning on the true underlying data structure. Our approach is robust, adaptive to data quality, and provides valuable diagnostics for data curation and cleaning.","authors":["Guillaume Godin"],"url":"https://arxiv.org/abs/2506.02154"}
{"created":"2025-06-04","title":"Mitigating Data Poisoning Attacks to Local Differential Privacy","abstract":"The distributed nature of local differential privacy (LDP) invites data poisoning attacks and poses unforeseen threats to the underlying LDP-supported applications. In this paper, we propose a comprehensive mitigation framework for popular frequency estimation, which contains a suite of novel defenses, including malicious user detection, attack pattern recognition, and damaged utility recovery. In addition to existing attacks, we explore new adaptive adversarial activities for our mitigation design. For detection, we present a new method to precisely identify bogus reports and thus LDP aggregation can be performed over the ``clean'' data. When the attack behavior becomes stealthy and direct filtering out malicious users is difficult, we further propose a detection that can effectively recognize hidden adversarial patterns, thus facilitating the decision-making of service providers. These detection methods require no additional data and attack information and incur minimal computational cost. Our experiment demonstrates their excellent performance and substantial improvement over previous work in various settings. In addition, we conduct an empirical analysis of LDP post-processing for corrupted data recovery and propose a new post-processing method, through which we reveal new insights into protocol recommendations in practice and key design principles for future research.","authors":["Xiaolin Li","Ninghui Li","Boyang Wang","Wenhai Sun"],"url":"https://arxiv.org/abs/2506.02156"}
{"created":"2025-06-04","title":"HENT-SRT: Hierarchical Efficient Neural Transducer with Self-Distillation for Joint Speech Recognition and Translation","abstract":"Neural transducers (NT) provide an effective framework for speech streaming, demonstrating strong performance in automatic speech recognition (ASR). However, the application of NT to speech translation (ST) remains challenging, as existing approaches struggle with word reordering and performance degradation when jointly modeling ASR and ST, resulting in a gap with attention-based encoder-decoder (AED) models. Existing NT-based ST approaches also suffer from high computational training costs. To address these issues, we propose HENT-SRT (Hierarchical Efficient Neural Transducer for Speech Recognition and Translation), a novel framework that factorizes ASR and translation tasks to better handle reordering. To ensure robust ST while preserving ASR performance, we use self-distillation with CTC consistency regularization. Moreover, we improve computational efficiency by incorporating best practices from ASR transducers, including a down-sampled hierarchical encoder, a stateless predictor, and a pruned transducer loss to reduce training complexity. Finally, we introduce a blank penalty during decoding, reducing deletions and improving translation quality. Our approach is evaluated on three conversational datasets Arabic, Spanish, and Mandarin achieving new state-of-the-art performance among NT models and substantially narrowing the gap with AED-based systems.","authors":["Amir Hussein","Cihan Xiao","Matthew Wiesner","Dan Povey","Leibny Paola Garcia","Sanjeev Khudanpur"],"url":"https://arxiv.org/abs/2506.02157"}
{"created":"2025-06-04","title":"Reflection-Based Memory For Web navigation Agents","abstract":"Web navigation agents have made significant progress, yet current systems operate with no memory of past experiences -- leading to repeated mistakes and an inability to learn from previous interactions. We introduce Reflection-Augment Planning (ReAP), a web navigation system to leverage both successful and failed past experiences using self-reflections. Our method improves baseline results by 11 points overall and 29 points on previously failed tasks. These findings demonstrate that reflections can transfer to different web navigation tasks.","authors":["Ruhana Azam","Aditya Vempaty","Ashish Jagmohan"],"url":"https://arxiv.org/abs/2506.02158"}
{"created":"2025-06-04","title":"A Dynamic Framework for Semantic Grouping of Common Data Elements (CDE) Using Embeddings and Clustering","abstract":"This research aims to develop a dynamic and scalable framework to facilitate harmonization of Common Data Elements (CDEs) across heterogeneous biomedical datasets by addressing challenges such as semantic heterogeneity, structural variability, and context dependence to streamline integration, enhance interoperability, and accelerate scientific discovery. Our methodology leverages Large Language Models (LLMs) for context-aware text embeddings that convert CDEs into dense vectors capturing semantic relationships and patterns. These embeddings are clustered using Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) to group semantically similar CDEs. The framework incorporates four key steps: (1) LLM-based text embedding to mathematically represent semantic context, (2) unsupervised clustering of embeddings via HDBSCAN, (3) automated labeling using LLM summarization, and (4) supervised learning to train a classifier assigning new or unclustered CDEs to labeled clusters. Evaluated on the NIH NLM CDE Repository with over 24,000 CDEs, the system identified 118 meaningful clusters at an optimized minimum cluster size of 20. The classifier achieved 90.46 percent overall accuracy, performing best in larger categories. External validation against Gravity Projects Social Determinants of Health domains showed strong agreement (Adjusted Rand Index 0.52, Normalized Mutual Information 0.78), indicating that embeddings effectively capture cluster characteristics. This adaptable and scalable approach offers a practical solution to CDE harmonization, improving selection efficiency and supporting ongoing data interoperability.","authors":["Madan Krishnamurthy","Daniel Korn","Melissa A Haendel","Christopher J Mungall","Anne E Thessen"],"url":"https://arxiv.org/abs/2506.02160"}
{"created":"2025-06-04","title":"TIIF-Bench: How Does Your T2I Model Follow Your Instructions?","abstract":"The rapid advancements of Text-to-Image (T2I) models have ushered in a new phase of AI-generated content, marked by their growing ability to interpret and follow user instructions. However, existing T2I model evaluation benchmarks fall short in limited prompt diversity and complexity, as well as coarse evaluation metrics, making it difficult to evaluate the fine-grained alignment performance between textual instructions and generated images. In this paper, we present TIIF-Bench (Text-to-Image Instruction Following Benchmark), aiming to systematically assess T2I models' ability in interpreting and following intricate textual instructions. TIIF-Bench comprises a set of 5000 prompts organized along multiple dimensions, which are categorized into three levels of difficulties and complexities. To rigorously evaluate model robustness to varying prompt lengths, we provide a short and a long version for each prompt with identical core semantics. Two critical attributes, i.e., text rendering and style control, are introduced to evaluate the precision of text synthesis and the aesthetic coherence of T2I models. In addition, we collect 100 high-quality designer level prompts that encompass various scenarios to comprehensively assess model performance. Leveraging the world knowledge encoded in large vision language models, we propose a novel computable framework to discern subtle variations in T2I model outputs. Through meticulous benchmarking of mainstream T2I models on TIIF-Bench, we analyze the pros and cons of current T2I models and reveal the limitations of current T2I benchmarks. Project Page: https://a113n-w3i.github.io/TIIF_Bench/.","authors":["Xinyu Wei","Jinrui Zhang","Zeqing Wang","Hongyang Wei","Zhen Guo","Lei Zhang"],"url":"https://arxiv.org/abs/2506.02161"}
{"created":"2025-06-04","title":"Quantifying task-relevant representational similarity using decision variable correlation","abstract":"Previous studies have compared the brain and deep neural networks trained on image classification. Intriguingly, while some suggest that their representations are highly similar, others argued the opposite. Here, we propose a new approach to characterize the similarity of the decision strategies of two observers (models or brains) using decision variable correlation (DVC). DVC quantifies the correlation between decoded decisions on individual samples in a classification task and thus can capture task-relevant information rather than general representational alignment. We evaluate this method using monkey V4/IT recordings and models trained on image classification tasks.","authors":["Yu (Eric)","Qian","Wilson S. Geisler","Xue-Xin Wei"],"url":"https://arxiv.org/abs/2506.02164"}
{"created":"2025-06-04","title":"Fire360: A Benchmark for Robust Perception and Episodic Memory in Degraded 360-Degree Firefighting Videos","abstract":"Modern AI systems struggle most in environments where reliability is critical - scenes with smoke, poor visibility, and structural deformation. Each year, tens of thousands of firefighters are injured on duty, often due to breakdowns in situational perception. We introduce Fire360, a benchmark for evaluating perception and reasoning in safety-critical firefighting scenarios. The dataset includes 228 360-degree videos from professional training sessions under diverse conditions (e.g., low light, thermal distortion), annotated with action segments, object locations, and degradation metadata. Fire360 supports five tasks: Visual Question Answering, Temporal Action Captioning, Object Localization, Safety-Critical Reasoning, and Transformed Object Retrieval (TOR). TOR tests whether models can match pristine exemplars to fire-damaged counterparts in unpaired scenes, evaluating transformation-invariant recognition. While human experts achieve 83.5% on TOR, models like GPT-4o lag significantly, exposing failures in reasoning under degradation. By releasing Fire360 and its evaluation suite, we aim to advance models that not only see, but also remember, reason, and act under uncertainty. The dataset is available at: https://uofi.box.com/v/fire360dataset.","authors":["Aditi Tiwari","Farzaneh Masoud","Dac Trong Nguyen","Jill Kraft","Heng Ji","Klara Nahrstedt"],"url":"https://arxiv.org/abs/2506.02167"}
{"created":"2025-06-04","title":"An Approximation Theory Perspective on Machine Learning","abstract":"A central problem in machine learning is often formulated as follows: Given a dataset $\\{(x_j, y_j)\\}_{j=1}^M$, which is a sample drawn from an unknown probability distribution, the goal is to construct a functional model $f$ such that $f(x) \\approx y$ for any $(x, y)$ drawn from the same distribution. Neural networks and kernel-based methods are commonly employed for this task due to their capacity for fast and parallel computation. The approximation capabilities, or expressive power, of these methods have been extensively studied over the past 35 years. In this paper, we will present examples of key ideas in this area found in the literature. We will discuss emerging trends in machine learning including the role of shallow/deep networks, approximation on manifolds, physics-informed neural surrogates, neural operators, and transformer architectures. Despite function approximation being a fundamental problem in machine learning, approximation theory does not play a central role in the theoretical foundations of the field. One unfortunate consequence of this disconnect is that it is often unclear how well trained models will generalize to unseen or unlabeled data. In this review, we examine some of the shortcomings of the current machine learning framework and explore the reasons for the gap between approximation theory and machine learning practice. We will then introduce our novel research to achieve function approximation on unknown manifolds without the need to learn specific manifold features, such as the eigen-decomposition of the Laplace-Beltrami operator or atlas construction. In many machine learning problems, particularly classification tasks, the labels $y_j$ are drawn from a finite set of values.","authors":["Hrushikesh N. Mhaskar","Efstratios Tsoukanis","Ameya D. Jagtap"],"url":"https://arxiv.org/abs/2506.02168"}
{"created":"2025-06-04","title":"LoL-NMPC: Low-Level Dynamics Integration in Nonlinear Model Predictive Control for Unmanned Aerial Vehicles","abstract":"In this paper, we address the problem of tracking high-speed agile trajectories for Unmanned Aerial Vehicles(UAVs), where model inaccuracies can lead to large tracking errors. Existing Nonlinear Model Predictive Controller(NMPC) methods typically neglect the dynamics of the low-level flight controllers such as underlying PID controller present in many flight stacks, and this results in sub-optimal tracking performance at high speeds and accelerations. To this end, we propose a novel NMPC formulation, LoL-NMPC, which explicitly incorporates low-level controller dynamics and motor dynamics in order to minimize trajectory tracking errors while maintaining computational efficiency. By leveraging linear constraints inside low-level dynamics, our approach inherently accounts for actuator constraints without requiring additional reallocation strategies. The proposed method is validated in both simulation and real-world experiments, demonstrating improved tracking accuracy and robustness at speeds up to 98.57 km/h and accelerations of 3.5 g. Our results show an average 21.97 % reduction in trajectory tracking error over standard NMPC formulation, with LoL-NMPC maintaining real-time feasibility at 100 Hz on an embedded ARM-based flight computer.","authors":["Parakh M. Gupta","Ond\\v{r}ej Proch\\'azka","Jan H\\v{r}ebec","Matej Novosad","Robert P\\v{e}ni\\v{c}ka","Martin Saska"],"url":"https://arxiv.org/abs/2506.02169"}
{"created":"2025-06-04","title":"Different Speech Translation Models Encode and Translate Speaker Gender Differently","abstract":"Recent studies on interpreting the hidden states of speech models have shown their ability to capture speaker-specific features, including gender. Does this finding also hold for speech translation (ST) models? If so, what are the implications for the speaker's gender assignment in translation? We address these questions from an interpretability perspective, using probing methods to assess gender encoding across diverse ST models. Results on three language directions (English-French/Italian/Spanish) indicate that while traditional encoder-decoder models capture gender information, newer architectures -- integrating a speech encoder with a machine translation system via adapters -- do not. We also demonstrate that low gender encoding capabilities result in systems' tendency toward a masculine default, a translation bias that is more pronounced in newer architectures.","authors":["Dennis Fucci","Marco Gaido","Matteo Negri","Luisa Bentivogli","Andre Martins","Giuseppe Attanasio"],"url":"https://arxiv.org/abs/2506.02172"}
{"created":"2025-06-04","title":"AI Debate Aids Assessment of Controversial Claims","abstract":"As AI grows more powerful, it will increasingly shape how we understand the world. But with this influence comes the risk of amplifying misinformation and deepening social divides-especially on consequential topics like public health where factual accuracy directly impacts well-being. Scalable Oversight aims to ensure AI truthfulness by enabling humans to supervise systems that may exceed human capabilities--yet humans themselves hold different beliefs and biases that impair their judgment. We study whether AI debate can guide biased judges toward the truth by having two AI systems debate opposing sides of controversial COVID-19 factuality claims where people hold strong prior beliefs. We conduct two studies: one with human judges holding either mainstream or skeptical beliefs evaluating factuality claims through AI-assisted debate or consultancy protocols, and a second examining the same problem with personalized AI judges designed to mimic these different human belief systems. In our human study, we find that debate-where two AI advisor systems present opposing evidence-based arguments-consistently improves judgment accuracy and confidence calibration, outperforming consultancy with a single-advisor system by 10% overall. The improvement is most significant for judges with mainstream beliefs (+15.2% accuracy), though debate also helps skeptical judges who initially misjudge claims move toward accurate views (+4.7% accuracy). In our AI judge study, we find that AI judges with human-like personas achieve even higher accuracy (78.5%) than human judges (70.1%) and default AI judges without personas (69.8%), suggesting their potential for supervising frontier AI models. These findings highlight AI debate as a promising path toward scalable, bias-resilient oversight--leveraging both diverse human and AI judgments to move closer to truth in contested domains.","authors":["Salman Rahman","Sheriff Issaka","Ashima Suvarna","Genglin Liu","James Shiffer","Jaeyoung Lee","Md Rizwan Parvez","Hamid Palangi","Shi Feng","Nanyun Peng","Yejin Choi","Julian Michael","Liwei Jiang","Saadia Gabriel"],"url":"https://arxiv.org/abs/2506.02175"}
{"created":"2025-06-04","title":"Act Only When It Pays: Efficient Reinforcement Learning for LLM Reasoning via Selective Rollouts","abstract":"Reinforcement learning, such as PPO and GRPO, has powered recent breakthroughs in LLM reasoning. Scaling rollout to sample more prompts enables models to selectively use higher-quality data for training, which can stabilize RL training and improve model performance. However, this comes at the cost of significant computational overhead. In this paper, we show that a substantial portion of this overhead can be avoided by skipping uninformative prompts before rollout. Our analysis of reward dynamics reveals a strong temporal consistency in prompt value: prompts that are uninformative in one epoch of training are likely to remain uninformative in future epochs. Based on these insights, we propose GRESO (GRPO with Efficient Selective Rollout), an online, lightweight pre-rollout filtering algorithm that predicts and skips uninformative prompts using reward training dynamics. By evaluating GRESO on a broad range of math reasoning benchmarks and models, such as Qwen2.5-Math-1.5B, DeepSeek-R1-Distill-Qwen-1.5B, and Qwen2.5-Math-7B, we show that GRESO achieves up to 2.4x wall-clock time speedup in rollout and up to 2.0x speedup in total training time without accuracy degradation.","authors":["Haizhong Zheng","Yang Zhou","Brian R. Bartoldson","Bhavya Kailkhura","Fan Lai","Jiawei Zhao","Beidi Chen"],"url":"https://arxiv.org/abs/2506.02177"}
{"created":"2025-06-04","title":"Cocktail-Party Audio-Visual Speech Recognition","abstract":"Audio-Visual Speech Recognition (AVSR) offers a robust solution for speech recognition in challenging environments, such as cocktail-party scenarios, where relying solely on audio proves insufficient. However, current AVSR models are often optimized for idealized scenarios with consistently active speakers, overlooking the complexities of real-world settings that include both speaking and silent facial segments. This study addresses this gap by introducing a novel audio-visual cocktail-party dataset designed to benchmark current AVSR systems and highlight the limitations of prior approaches in realistic noisy conditions. Additionally, we contribute a 1526-hour AVSR dataset comprising both talking-face and silent-face segments, enabling significant performance gains in cocktail-party environments. Our approach reduces WER by 67% relative to the state-of-the-art, reducing WER from 119% to 39.2% in extreme noise, without relying on explicit segmentation cues.","authors":["Thai-Binh Nguyen","Ngoc-Quan Pham","Alexander Waibel"],"url":"https://arxiv.org/abs/2506.02178"}
{"created":"2025-06-04","title":"Optimal Coordination of Flexible DERs in Local Energy and Flexibility Markets to Ensure Social Equity","abstract":"Local electricity markets offer a promising solution for integrating renewable energy sources and other distributed energy resources (DERs) into distribution networks. These markets enable the effective utilization of flexible resources by facilitating coordination among various agents. Beyond technical and economic considerations, addressing social equity within these local communities is critical and requires dedicated attention in market-clearing frameworks. This paper proposes a social equity-based market-clearing framework for the optimal management of DERs' energy and flexibility within local communities. The proposed framework incorporates consumers' energy burden to ensure fair pricing in energy market clearance. Furthermore, to ensure equity during unbalanced operating conditions, flexible resources are managed in the local flexibility market, ensuring that all participants can trade power fairly under network disturbances. The model is formulated as a second-order cone programming (SOCP) optimization and validated on the IEEE 33-bus test distribution network.","authors":["Niloofar Pourghaderi","Milad Kabirifar","Payman Dehghanian"],"url":"https://arxiv.org/abs/2506.02179"}
{"created":"2025-06-04","title":"Echoes of Phonetics: Unveiling Relevant Acoustic Cues for ASR via Feature Attribution","abstract":"Despite significant advances in ASR, the specific acoustic cues models rely on remain unclear. Prior studies have examined such cues on a limited set of phonemes and outdated models. In this work, we apply a feature attribution technique to identify the relevant acoustic cues for a modern Conformer-based ASR system. By analyzing plosives, fricatives, and vowels, we assess how feature attributions align with their acoustic properties in the time and frequency domains, also essential for human speech perception. Our findings show that the ASR model relies on vowels' full time spans, particularly their first two formants, with greater saliency in male speech. It also better captures the spectral characteristics of sibilant fricatives than non-sibilants and prioritizes the release phase in plosives, especially burst characteristics. These insights enhance the interpretability of ASR models and highlight areas for future research to uncover potential gaps in model robustness.","authors":["Dennis Fucci","Marco Gaido","Matteo Negri","Mauro Cettolo","Luisa Bentivogli"],"url":"https://arxiv.org/abs/2506.02181"}
{"created":"2025-06-04","title":"Spegion: Implicit and Non-Lexical Regions with Sized Allocations","abstract":"Region based memory management is a powerful tool designed with the goal of ensuring memory safety statically. The region calculus of Tofte and Talpin is a well known example of a region based system, which uses regions to manage memory in a stack-like fashion. However, the region calculus is lexically scoped and requires explicit annotation of memory regions, which can be cumbersome for the programmer. Other systems have addressed non-lexical regions, but these approaches typically require the use of a substructural type system to track the lifetimes of regions. We present Spegion, a language with implicit non-lexical regions, which provides these same memory safety guarantees for programs that go beyond using memory allocation in a stack-like manner. We are able to achieve this with a concise syntax, and without the use of substructural types, relying instead on an effect system to enforce constraints on region allocation and deallocation. These regions may be divided into sub-regions, i.e., Splittable rEgions, allowing fine grained control over memory allocation. Furthermore, Spegion permits sized allocations, where each value has an associated size which is used to ensure that regions are not over-allocated into. We present a type system for Spegion and prove it is type safe with respect to a small-step operational semantics.","authors":["Jack Hughes","Michael Vollmer","Mark Batty"],"url":"https://arxiv.org/abs/2506.02182"}
{"created":"2025-06-04","title":"Natural, Artificial, and Human Intelligences","abstract":"Human achievement, whether in culture, science, or technology, is unparalleled in the known existence. This achievement is tied to the enormous communities of knowledge, made possible by (especially written) language: leaving theological content aside, it is very much true that \"in the beginning was the word\". There lies the challenge regarding modern age chatbots: they can 'do' language apparently as well as ourselves and there is a natural question of whether they can be considered intelligent, in the same way as we are or otherwise. Are humans uniquely intelligent? We consider this question in terms of the psychological literature on intelligence, evidence for intelligence in non-human animals, the role of written language in science and technology, progress with artificial intelligence, the history of intelligence testing (for both humans and machines), and the role of embodiment in intelligence. For the most unique accomplishments of human intelligence (such as music symphonies or complex scientific theories), we think that, together with language, there are four essential ingredients, which can be summarised as invention, capacity for complex inference, embodiment, and self-awareness. This conclusion makes untenable the position that human intelligence differs qualitatively from that of many non-human animals, since, with the exception of complex language, all the other requirements are fulfilled. Regarding chatbots, the current limitations are localised to the lack of embodiment and (apparent) lack of awareness.","authors":["Emmanuel M. Pothos","Dominic Widdows"],"url":"https://arxiv.org/abs/2506.02183"}
{"created":"2025-06-04","title":"Fairly Wired: Towards Leximin-Optimal Division of Electricity","abstract":"In many parts of the world - particularly in developing countries - the demand for electricity exceeds the available supply. In such cases, it is impossible to provide electricity to all households simultaneously. This raises a fundamental question: how should electricity be allocated fairly? In this paper, we explore this question through the lens of egalitarianism - a principle that emphasizes equality by prioritizing the welfare of the worst-off households. One natural rule that aligns with this principle is to maximize the egalitarian welfare - the smallest utility across all households. We show that computing such an allocation is NP-hard, even under strong simplifying assumptions. Leximin is a stronger fairness notion that generalizes the egalitarian welfare: it also requires to maximize the smallest utility, but then, subject to that, the second-smallest, then the third, and so on. The hardness results extends directly to leximin as well. Despite this, we present a Fully Polynomial-Time Approximation Scheme (FPTAS) for leximin in the special case where the network connectivity graph is a tree. This means that we can efficiently approximate leximin - and, in particular, the egalitarian welfare - to any desired level of accuracy.","authors":["Eden Hartman","Dinesh Kumar Baghel","Erel Segal-Halevi"],"url":"https://arxiv.org/abs/2506.02193"}
{"created":"2025-06-04","title":"Learning Treatment Representations for Downstream Instrumental Variable Regression","abstract":"Traditional instrumental variable (IV) estimators face a fundamental constraint: they can only accommodate as many endogenous treatment variables as available instruments. This limitation becomes particularly challenging in settings where the treatment is presented in a high-dimensional and unstructured manner (e.g. descriptions of patient treatment pathways in a hospital). In such settings, researchers typically resort to applying unsupervised dimension reduction techniques to learn a low-dimensional treatment representation prior to implementing IV regression analysis. We show that such methods can suffer from substantial omitted variable bias due to implicit regularization in the representation learning step. We propose a novel approach to construct treatment representations by explicitly incorporating instrumental variables during the representation learning process. Our approach provides a framework for handling high-dimensional endogenous variables with limited instruments. We demonstrate both theoretically and empirically that fitting IV models on these instrument-informed representations ensures identification of directions that optimize outcome prediction. Our experiments show that our proposed methodology improves upon the conventional two-stage approaches that perform dimension reduction without incorporating instrument information.","authors":["Shiangyi Lin","Hui Lan","Vasilis Syrgkanis"],"url":"https://arxiv.org/abs/2506.02200"}
{"created":"2025-06-04","title":"Constrained Sliced Wasserstein Embedding","abstract":"Sliced Wasserstein (SW) distances offer an efficient method for comparing high-dimensional probability measures by projecting them onto multiple 1-dimensional probability distributions. However, identifying informative slicing directions has proven challenging, often necessitating a large number of slices to achieve desirable performance and thereby increasing computational complexity. We introduce a constrained learning approach to optimize the slicing directions for SW distances. Specifically, we constrain the 1D transport plans to approximate the optimal plan in the original space, ensuring meaningful slicing directions. By leveraging continuous relaxations of these transport plans, we enable a gradient-based primal-dual approach to train the slicer parameters, alongside the remaining model parameters. We demonstrate how this constrained slicing approach can be applied to pool high-dimensional embeddings into fixed-length permutation-invariant representations. Numerical results on foundation models trained on images, point clouds, and protein sequences showcase the efficacy of the proposed constrained learning approach in learning more informative slicing directions. Our implementation code can be found at https://github.com/Stranja572/constrainedswe.","authors":["Navid NaderiAlizadeh","Darian Salehi","Xinran Liu","Soheil Kolouri"],"url":"https://arxiv.org/abs/2506.02203"}
{"created":"2025-06-04","title":"BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models","abstract":"Language model evaluation is a daunting task: prompts are brittle, corpus-level perplexities are vague, and the choice of benchmarks are endless. Finding examples that show meaningful, generalizable differences between two LMs is crucial to understanding where one model succeeds and another fails. Can this process be done automatically? In this work, we propose methodology for automated comparison of language models that uses performance-aware contextual embeddings to find fine-grained features of text where one LM outperforms another. Our method, which we name BehaviorBox, extracts coherent features that demonstrate differences with respect to the ease of generation between two LMs. Specifically, BehaviorBox finds features that describe groups of words in fine-grained contexts, such as \"conditional 'were' in the phrase 'if you were'\" and \"exclamation marks after emotional statements\", where one model outperforms another within a particular datatset. We apply BehaviorBox to compare models that vary in size, model family, and post-training, and enumerate insights into specific contexts that illustrate meaningful differences in performance which cannot be found by measures such as corpus-level perplexity alone.","authors":["Lindia Tjuatja","Graham Neubig"],"url":"https://arxiv.org/abs/2506.02204"}
{"created":"2025-06-04","title":"Bregman Centroid Guided Cross-Entropy Method","abstract":"The Cross-Entropy Method (CEM) is a widely adopted trajectory optimizer in model-based reinforcement learning (MBRL), but its unimodal sampling strategy often leads to premature convergence in multimodal landscapes. In this work, we propose Bregman Centroid Guided CEM ($\\mathcal{BC}$-EvoCEM), a lightweight enhancement to ensemble CEM that leverages $\\textit{Bregman centroids}$ for principled information aggregation and diversity control. $\\textbf{$\\mathcal{BC}$-EvoCEM}$ computes a performance-weighted Bregman centroid across CEM workers and updates the least contributing ones by sampling within a trust region around the centroid. Leveraging the duality between Bregman divergences and exponential family distributions, we show that $\\textbf{$\\mathcal{BC}$-EvoCEM}$ integrates seamlessly into standard CEM pipelines with negligible overhead. Empirical results on synthetic benchmarks, a cluttered navigation task, and full MBRL pipelines demonstrate that $\\textbf{$\\mathcal{BC}$-EvoCEM}$ enhances both convergence and solution quality, providing a simple yet effective upgrade for CEM.","authors":["Yuliang Gu","Hongpeng Cao","Marco Caccamo","Naira Hovakimyan"],"url":"https://arxiv.org/abs/2506.02205"}
{"created":"2025-06-04","title":"Reinforcement Learning with Data Bootstrapping for Dynamic Subgoal Pursuit in Humanoid Robot Navigation","abstract":"Safe and real-time navigation is fundamental for humanoid robot applications. However, existing bipedal robot navigation frameworks often struggle to balance computational efficiency with the precision required for stable locomotion. We propose a novel hierarchical framework that continuously generates dynamic subgoals to guide the robot through cluttered environments. Our method comprises a high-level reinforcement learning (RL) planner for subgoal selection in a robot-centric coordinate system and a low-level Model Predictive Control (MPC) based planner which produces robust walking gaits to reach these subgoals. To expedite and stabilize the training process, we incorporate a data bootstrapping technique that leverages a model-based navigation approach to generate a diverse, informative dataset. We validate our method in simulation using the Agility Robotics Digit humanoid across multiple scenarios with random obstacles. Results show that our framework significantly improves navigation success rates and adaptability compared to both the original model-based method and other learning-based methods.","authors":["Chengyang Peng","Zhihao Zhang","Shiting Gong","Sankalp Agrawal","Keith A. Redmill","Ayonga Hereid"],"url":"https://arxiv.org/abs/2506.02206"}
{"created":"2025-06-04","title":"KDRL: Post-Training Reasoning LLMs via Unified Knowledge Distillation and Reinforcement Learning","abstract":"Recent advances in large language model (LLM) post-training have leveraged two distinct paradigms to enhance reasoning capabilities: reinforcement learning (RL) and knowledge distillation (KD). While RL enables the emergence of complex reasoning behaviors, it often suffers from low sample efficiency when the initial policy struggles to explore high-reward trajectories. Conversely, KD improves learning efficiency via mimicking the teacher model but tends to generalize poorly to out-of-domain scenarios. In this work, we present \\textbf{KDRL}, a \\textit{unified post-training framework} that jointly optimizes a reasoning model through teacher supervision (KD) and self-exploration (RL). Specifically, KDRL leverages policy gradient optimization to simultaneously minimize the reverse Kullback-Leibler divergence (RKL) between the student and teacher distributions while maximizing the expected rule-based rewards. We first formulate a unified objective that integrates GRPO and KD, and systematically explore how different KL approximations, KL coefficients, and reward-guided KD strategies affect the overall post-training dynamics and performance. Empirical results on multiple reasoning benchmarks demonstrate that KDRL outperforms GRPO and various KD baselines while achieving a favorable balance between performance and reasoning token efficiency. These findings indicate that integrating KD and RL serves as an effective and efficient strategy to train reasoning LLMs.","authors":["Hongling Xu","Qi Zhu","Heyuan Deng","Jinpeng Li","Lu Hou","Yasheng Wang","Lifeng Shang","Ruifeng Xu","Fei Mi"],"url":"https://arxiv.org/abs/2506.02208"}
{"created":"2025-06-04","title":"Exchangeability in Neural Network Architectures and its Application to Dynamic Pruning","abstract":"Neural networks (NNs) are equipped with increasingly many parameters and require more and more resource for deployment. Researchers have explored various ways to improve the efficiency of NNs by identifying and reducing the redundancy, such as pruning or quantizing unimportant weights. Symmetry in the NN architectures has been identified by prior work as a possible type of redundancy, but exploiting it for efficient inference is not yet explored. In this work, we formalize the symmetry of parameters and intermediate values in NNs using the statistical property of exchangeablility. We identify that exchangeable values in NN computation may contain overlapping information, leading to redundancy. Exploiting the insight, we derive a principled general dynamic pruning algorithm ExPrune to remove symmetry-induced redundancy on a per-input basis. We also provide an instantiation of ExPrune that performs neuron-level dynamic pruning by predicting negative inputs to ReLU activations. We evaluate ExPrune on two computer vision models, one graph model and one language model. ExPrune provides 10.98--26.3% reduction in FLOPs with negligible accuracy drop and 21.01--39.05% reduction in FLOPs with at most 1% accuracy drop. We also demonstrate that ExPrune composes with static pruning. On models that have been aggressively pruned statically, ExPrune provides additional 10.24--11.11% reduction in FLOPs with negligible accuracy drop and 13.91--14.39% reduction in FLOPs with at most 1% accuracy drop.","authors":["Pu (Luke)","Yi","Tianlang Chen","Yifan Yang","Sara Achour"],"url":"https://arxiv.org/abs/2506.02210"}
{"created":"2025-06-04","title":"Improving LLM-Generated Code Quality with GRPO","abstract":"Large Language Models (LLMs) are gaining widespread use for code generation. Recent training procedures use execution feedback as a reward signal, typically focusing on the functional correctness of the code, using unit test pass rate as a reward signal. However, this reward signal fails to capture notions of maintainability, quality and safety of the code produced. We address this under-explored area and develop a comprehensive library to quantify various aspects of code quality, and use it as a reward in GRPO. We find GRPO increases code quality according to this measure, which is confirmed by expert, blinded human annotators.","authors":["Maxime Robeyns","Laurence Aitchison"],"url":"https://arxiv.org/abs/2506.02211"}
{"created":"2025-06-04","title":"Leveraging Natural Language Processing to Unravel the Mystery of Life: A Review of NLP Approaches in Genomics, Transcriptomics, and Proteomics","abstract":"Natural Language Processing (NLP) has transformed various fields beyond linguistics by applying techniques originally developed for human language to the analysis of biological sequences. This review explores the application of NLP methods to biological sequence data, focusing on genomics, transcriptomics, and proteomics. We examine how various NLP methods, from classic approaches like word2vec to advanced models employing transformers and hyena operators, are being adapted to analyze DNA, RNA, protein sequences, and entire genomes. The review also examines tokenization strategies and model architectures, evaluating their strengths, limitations, and suitability for different biological tasks. We further cover recent advances in NLP applications for biological data, such as structure prediction, gene expression, and evolutionary analysis, highlighting the potential of these methods for extracting meaningful insights from large-scale genomic data. As language models continue to advance, their integration into bioinformatics holds immense promise for advancing our understanding of biological processes in all domains of life.","authors":["Ella Rannon","David Burstein"],"url":"https://arxiv.org/abs/2506.02212"}
{"created":"2025-06-04","title":"Quantum Ensembling Methods for Healthcare and Life Science","abstract":"Learning on small data is a challenge frequently encountered in many real-world applications. In this work we study how effective quantum ensemble models are when trained on small data problems in healthcare and life sciences. We constructed multiple types of quantum ensembles for binary classification using up to 26 qubits in simulation and 56 qubits on quantum hardware. Our ensemble designs use minimal trainable parameters but require long-range connections between qubits. We tested these quantum ensembles on synthetic datasets and gene expression data from renal cell carcinoma patients with the task of predicting patient response to immunotherapy. From the performance observed in simulation and initial hardware experiments, we demonstrate how quantum embedding structure affects performance and discuss how to extract informative features and build models that can learn and generalize effectively. We present these exploratory results in order to assist other researchers in the design of effective learning on small data using ensembles. Incorporating quantum computing in these data constrained problems offers hope for a wide range of studies in healthcare and life sciences where biological samples are relatively scarce given the feature space to be explored.","authors":["Kahn Rhrissorrakrai","Kathleen E. Hamilton","Prerana Bangalore Parthsarathy","Aldo Guzman-Saenz","Tyler Alban","Filippo Utro","Laxmi Parida"],"url":"https://arxiv.org/abs/2506.02213"}
{"created":"2025-06-04","title":"Is PMBOK Guide the Right Fit for AI? Re-evaluating Project Management in the Face of Artificial Intelligence Projects","abstract":"This paper critically evaluates the applicability of the Project Management Body of Knowledge (PMBOK) Guide framework to Artificial Intelligence (AI) software projects, highlighting key limitations and proposing tailored adaptations. Unlike traditional projects, AI initiatives rely heavily on complex data, iterative experimentation, and specialized expertise while navigating significant ethical considerations. Our analysis identifies gaps in the PMBOK Guide, including its limited focus on data management, insufficient support for iterative development, and lack of guidance on ethical and multidisciplinary challenges. To address these deficiencies, we recommend integrating data lifecycle management, adopting iterative and AI project management frameworks, and embedding ethical considerations within project planning and execution. Additionally, we explore alternative approaches that better align with AI's dynamic and exploratory nature. We aim to enhance project management practices for AI software projects by bridging these gaps.","authors":["Alexey Burdakov","Max Jaihyun Ahn"],"url":"https://arxiv.org/abs/2506.02214"}
{"created":"2025-06-04","title":"Active inference as a unified model of collision avoidance behavior in human drivers","abstract":"Collision avoidance -- involving a rapid threat detection and quick execution of the appropriate evasive maneuver -- is a critical aspect of driving. However, existing models of human collision avoidance behavior are fragmented, focusing on specific scenarios or only describing certain aspects of the avoidance behavior, such as response times. This paper addresses these gaps by proposing a novel computational cognitive model of human collision avoidance behavior based on active inference. Active inference provides a unified approach to modeling human behavior: the minimization of free energy. Building on prior active inference work, our model incorporates established cognitive mechanisms such as evidence accumulation to simulate human responses in two distinct collision avoidance scenarios: front-to-rear lead vehicle braking and lateral incursion by an oncoming vehicle. We demonstrate that our model explains a wide range of previous empirical findings on human collision avoidance behavior. Specifically, the model closely reproduces both aggregate results from meta-analyses previously reported in the literature and detailed, scenario-specific effects observed in a recent driving simulator study, including response timing, maneuver selection, and execution. Our results highlight the potential of active inference as a unified framework for understanding and modeling human behavior in complex real-life driving tasks.","authors":["Julian F. Schumann","Johan Engstroem","Leif Johnson","Matthew O'Kelly","Joao Messias","Jens Kober","Arkady Zgonnikov"],"url":"https://arxiv.org/abs/2506.02215"}
{"created":"2025-06-04","title":"Analyzing Contact Patterns in Public Transportation Systems for Opportunistic Communication Services","abstract":"Vehicle mobility has a significant impact on wireless communication between vehicles (buses) in Public Transportation Systems (PTS). Nevertheless, the transportation literature does not provide satisfactory models for bus movements because they are influenced by a variety of factors (itineraries, timetables, etc.). Custom-made mobility models that take these issues into account require a great deal of effort and may render simulations unfeasible. This article considers a tool (EMMS) that automatically inserts PTS information into a mobility simulator in order to undertake a complete statistical analysis of vehicular density, trip duration, and vehicle-to-vehicle interaction. In light of opportunistic communication services, this analysis is of the utmost importance.","authors":["Eduardo R. Manika","Emilio C. G. Wille","Joilson Alves Jr"],"url":"https://arxiv.org/abs/2506.02217"}
{"created":"2025-06-04","title":"Stochastic Barnes-Hut Approximation for Fast Summation on the GPU","abstract":"We present a novel stochastic version of the Barnes-Hut approximation. Regarding the level-of-detail (LOD) family of approximations as control variates, we construct an unbiased estimator of the kernel sum being approximated. Through several examples in graphics applications such as winding number computation and smooth distance evaluation, we demonstrate that our method is well-suited for GPU computation, capable of outperforming a GPU-optimized implementation of the deterministic Barnes-Hut approximation by achieving equal median error in up to 9.4x less time.","authors":["Abhishek Madan","Nicholas Sharp","Francis Williams","Ken Museth","David I. W. Levin"],"url":"https://arxiv.org/abs/2506.02219"}
{"created":"2025-06-04","title":"Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment","abstract":"Diffusion models have revolutionized generative tasks through high-fidelity outputs, yet flow matching (FM) offers faster inference and empirical performance gains. However, current foundation FM models are computationally prohibitive for finetuning, while diffusion models like Stable Diffusion benefit from efficient architectures and ecosystem support. This work addresses the critical challenge of efficiently transferring knowledge from pre-trained diffusion models to flow matching. We propose Diff2Flow, a novel framework that systematically bridges diffusion and FM paradigms by rescaling timesteps, aligning interpolants, and deriving FM-compatible velocity fields from diffusion predictions. This alignment enables direct and efficient FM finetuning of diffusion priors with no extra computation overhead. Our experiments demonstrate that Diff2Flow outperforms na\\\"ive FM and diffusion finetuning particularly under parameter-efficient constraints, while achieving superior or competitive performance across diverse downstream tasks compared to state-of-the-art methods. We will release our code at https://github.com/CompVis/diff2flow.","authors":["Johannes Schusterbauer","Ming Gui","Frank Fundel","Bj\\\"orn Ommer"],"url":"https://arxiv.org/abs/2506.02221"}
{"created":"2025-06-04","title":"VLCD: Vision-Language Contrastive Distillation for Accurate and Efficient Automatic Placenta Analysis","abstract":"Pathological examination of the placenta is an effective method for detecting and mitigating health risks associated with childbirth. Recent advancements in AI have enabled the use of photographs of the placenta and pathology reports for detecting and classifying signs of childbirth-related pathologies. However, existing automated methods are computationally extensive, which limits their deployability. We propose two modifications to vision-language contrastive learning (VLC) frameworks to enhance their accuracy and efficiency: (1) text-anchored vision-language contrastive knowledge distillation (VLCD)-a new knowledge distillation strategy for medical VLC pretraining, and (2) unsupervised predistillation using a large natural images dataset for improved initialization. Our approach distills efficient neural networks that match or surpass the teacher model in performance while achieving model compression and acceleration. Our results showcase the value of unsupervised predistillation in improving the performance and robustness of our approach, specifically for lower-quality images. VLCD serves as an effective way to improve the efficiency and deployability of medical VLC approaches, making AI-based healthcare solutions more accessible, especially in resource-constrained environments.","authors":["Manas Mehta","Yimu Pan","Kelly Gallagher","Alison D. Gernand","Jeffery A. Goldstein","Delia Mwinyelle","Leena Mithal","James Z. Wang"],"url":"https://arxiv.org/abs/2506.02229"}
{"created":"2025-06-04","title":"Improving compiler support for SIMD offload using Arm Streaming SVE","abstract":"The wider adoption of tightly coupled core-adjacent accelerators, such as Arm Scalable Matrix Extension (SME), hinges on lowering software programming complexity. In this paper, we focus on enabling the use of SME architecture in Streaming Scalable Vector Extension (SSVE) mode for workloads written in C/C++. While current compilers optimize loops for all types of SIMD instructions, these techniques primarily target vector units within the core and falter when applied to disaggregated, core-adjacent SIMD accelerators. Our goal is to enable the compiler to automatically generate code for such accelerators only when profitable.","authors":["Mohamed Husain Noor Mohamed","Adarsh Patil","Latchesar Ionkov","Eric Van Hensbergen"],"url":"https://arxiv.org/abs/2506.02233"}
{"created":"2025-06-04","title":"Second-Order-Cone Formulations of Power Flow for Topology Optimization","abstract":"Optimization problems that involve topology optimization in scenarios with large scale outages, such as post-disaster restoration or public safety power shutoff planning, are very challenging to solve. Using simple power flow representations such as DC power flow or network flow models results in low quality solutions which requires significantly higher-than-predicted load shed to become AC feasible. Recent work has shown that formulations based on the Second Order Cone (SOC) power flow formulation find very high quality solutions with low load shed, but the computational burden of these formulations remains a significant challenge. With the aim of reducing computational time while maintaining high solution quality, this work explores formulations which replace the conic constraints with a small number of linear cuts. The goal of this approach is not to find an exact power flow solution, but rather to identify good binary decisions, where the power flow can be resolved after the binary variables are fixed. We find that a simple reformulation of the Second Order Cone Optimal Power Shutoff problem can greatly improve the solution speed, but that a full linearization of the SOC voltage cone equation results in an overestimation of the amount of power that can be delivered to loads.","authors":["Noah Rhodes","James Luedkte","Line Roald"],"url":"https://arxiv.org/abs/2506.02234"}
{"created":"2025-06-04","title":"Investigating the Impact of Word Informativeness on Speech Emotion Recognition","abstract":"In emotion recognition from speech, a key challenge lies in identifying speech signal segments that carry the most relevant acoustic variations for discerning specific emotions. Traditional approaches compute functionals for features such as energy and F0 over entire sentences or longer speech portions, potentially missing essential fine-grained variation in the long-form statistics. This research investigates the use of word informativeness, derived from a pre-trained language model, to identify semantically important segments. Acoustic features are then computed exclusively for these identified segments, enhancing emotion recognition accuracy. The methodology utilizes standard acoustic prosodic features, their functionals, and self-supervised representations. Results indicate a notable improvement in recognition performance when features are computed on segments selected based on word informativeness, underscoring the effectiveness of this approach.","authors":["Sofoklis Kakouros"],"url":"https://arxiv.org/abs/2506.02239"}
{"created":"2025-06-04","title":"Second-order AAA algorithms for structured data-driven modeling","abstract":"The data-driven modeling of dynamical systems has become an essential tool for the construction of accurate computational models from real-world data. In this process, the inherent differential structures underlying the considered physical phenomena are often neglected making the reinterpretation of the learned models in a physically meaningful sense very challenging. In this work, we present three data-driven modeling approaches for the construction of dynamical systems with second-order differential structure directly from frequency domain data. Based on the second-order structured barycentric form, we extend the well-known Adaptive Antoulas-Anderson algorithm to the case of second-order systems. Depending on the available computational resources, we propose variations of the proposed method that prioritize either higher computation speed or greater modeling accuracy, and we present a theoretical analysis for the expected accuracy and performance of the proposed methods. Three numerical examples demonstrate the effectiveness of our new structured approaches in comparison to classical unstructured data-driven modeling.","authors":["Michael S. Ackermann","Ion Victor Gosea","Serkan Gugercin","Steffen W. R. Werner"],"url":"https://arxiv.org/abs/2506.02241"}
{"created":"2025-06-04","title":"From Street Views to Urban Science: Discovering Road Safety Factors with Multimodal Large Language Models","abstract":"Urban and transportation research has long sought to uncover statistically meaningful relationships between key variables and societal outcomes such as road safety, to generate actionable insights that guide the planning, development, and renewal of urban and transportation systems. However, traditional workflows face several key challenges: (1) reliance on human experts to propose hypotheses, which is time-consuming and prone to confirmation bias; (2) limited interpretability, particularly in deep learning approaches; and (3) underutilization of unstructured data that can encode critical urban context. Given these limitations, we propose a Multimodal Large Language Model (MLLM)-based approach for interpretable hypothesis inference, enabling the automated generation, evaluation, and refinement of hypotheses concerning urban context and road safety outcomes. Our method leverages MLLMs to craft safety-relevant questions for street view images (SVIs), extract interpretable embeddings from their responses, and apply them in regression-based statistical models. UrbanX supports iterative hypothesis testing and refinement, guided by statistical evidence such as coefficient significance, thereby enabling rigorous scientific discovery of previously overlooked correlations between urban design and safety. Experimental evaluations on Manhattan street segments demonstrate that our approach outperforms pretrained deep learning models while offering full interpretability. Beyond road safety, UrbanX can serve as a general-purpose framework for urban scientific discovery, extracting structured insights from unstructured urban data across diverse socioeconomic and environmental outcomes. This approach enhances model trustworthiness for policy applications and establishes a scalable, statistically grounded pathway for interpretable knowledge discovery in urban and transportation studies.","authors":["Yihong Tang","Ao Qu","Xujing Yu","Weipeng Deng","Jun Ma","Jinhua Zhao","Lijun Sun"],"url":"https://arxiv.org/abs/2506.02242"}
{"created":"2025-06-04","title":"From Features to Structure: Task-Aware Graph Construction for Relational and Tabular Learning with GNNs","abstract":"Tabular and relational data remain the most ubiquitous formats in real-world machine learning applications, spanning domains from finance to healthcare. Although both formats offer structured representations, they pose distinct challenges for modern deep learning methods, which typically assume flat, feature-aligned inputs. Graph Neural Networks (GNNs) have emerged as a promising solution by capturing structural dependencies within and between tables. However, existing GNN-based approaches often rely on rigid, schema-derived graphs -- such as those based on primary-foreign key links -- thereby underutilizing rich, predictive signals in non key attributes. In this work, we introduce auGraph, a unified framework for task-aware graph augmentation that applies to both tabular and relational data. auGraph enhances base graph structures by selectively promoting attributes into nodes, guided by scoring functions that quantify their relevance to the downstream prediction task. This augmentation preserves the original data schema while injecting task-relevant structural signal. Empirically, auGraph outperforms schema-based and heuristic graph construction methods by producing graphs that better support learning for relational and tabular prediction tasks.","authors":["Tamara Cucumides","Floris Geerts"],"url":"https://arxiv.org/abs/2506.02243"}
{"created":"2025-06-04","title":"Motion aware video generative model","abstract":"Recent advances in diffusion-based video generation have yielded unprecedented quality in visual content and semantic coherence. However, current approaches predominantly rely on statistical learning from vast datasets without explicitly modeling the underlying physics of motion, resulting in subtle yet perceptible non-physical artifacts that diminish the realism of generated videos. This paper introduces a physics-informed frequency domain approach to enhance the physical plausibility of generated videos. We first conduct a systematic analysis of the frequency-domain characteristics of diverse physical motions (translation, rotation, scaling), revealing that each motion type exhibits distinctive and identifiable spectral signatures. Building on this theoretical foundation, we propose two complementary components: (1) a physical motion loss function that quantifies and optimizes the conformity of generated videos to ideal frequency-domain motion patterns, and (2) a frequency domain enhancement module that progressively learns to adjust video features to conform to physical motion constraints while preserving original network functionality through a zero-initialization strategy. Experiments across multiple video diffusion architectures demonstrate that our approach significantly enhances motion quality and physical plausibility without compromising visual quality or semantic alignment. Our frequency-domain physical motion framework generalizes effectively across different video generation architectures, offering a principled approach to incorporating physical constraints into deep learning-based video synthesis pipelines. This work seeks to establish connections between data-driven models and physics-based motion models.","authors":["Bowen Xue","Giuseppe Claudio Guarnera","Shuang Zhao","Zahra Montazeri"],"url":"https://arxiv.org/abs/2506.02244"}
{"created":"2025-06-04","title":"PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss","abstract":"Active speaker detection (ASD) in egocentric videos presents unique challenges due to unstable viewpoints, motion blur, and off-screen speech sources - conditions under which traditional visual-centric methods degrade significantly. We introduce PAIR-Net (Pretrained Audio-Visual Integration with Regularization Network), an effective model that integrates a partially frozen Whisper audio encoder with a fine-tuned AV-HuBERT visual backbone to robustly fuse cross-modal cues. To counteract modality imbalance, we introduce an inter-modal alignment loss that synchronizes audio and visual representations, enabling more consistent convergence across modalities. Without relying on multi-speaker context or ideal frontal views, PAIR-Net achieves state-of-the-art performance on the Ego4D ASD benchmark with 76.6% mAP, surpassing LoCoNet and STHG by 8.2% and 12.9% mAP, respectively. Our results highlight the value of pretrained audio priors and alignment-based fusion for robust ASD under real-world egocentric conditions.","authors":["Yu Wang","Juhyung Ha","David J. Crandall"],"url":"https://arxiv.org/abs/2506.02247"}
{"created":"2025-06-04","title":"SafeOR-Gym: A Benchmark Suite for Safe Reinforcement Learning Algorithms on Practical Operations Research Problems","abstract":"Most existing safe reinforcement learning (RL) benchmarks focus on robotics and control tasks, offering limited relevance to high-stakes domains that involve structured constraints, mixed-integer decisions, and industrial complexity. This gap hinders the advancement and deployment of safe RL in critical areas such as energy systems, manufacturing, and supply chains. To address this limitation, we present SafeOR-Gym, a benchmark suite of nine operations research (OR) environments tailored for safe RL under complex constraints. Each environment captures a realistic planning, scheduling, or control problems characterized by cost-based constraint violations, planning horizons, and hybrid discrete-continuous action spaces. The suite integrates seamlessly with the Constrained Markov Decision Process (CMDP) interface provided by OmniSafe. We evaluate several state-of-the-art safe RL algorithms across these environments, revealing a wide range of performance: while some tasks are tractable, others expose fundamental limitations in current approaches. SafeOR-Gym provides a challenging and practical testbed that aims to catalyze future research in safe RL for real-world decision-making problems. The SafeOR-Gym framework and all accompanying code are available at: https://github.com/li-group/SafeOR-Gym.","authors":["Asha Ramanujam (Davidson School of Chemical Engineering","Purdue University","West Lafayette","IN)","Adam Elyoumi (Davidson School of Chemical Engineering","Purdue University","West Lafayette","IN)","Hao Chen (Davidson School of Chemical Engineering","Purdue University","West Lafayette","IN)","Sai Madhukiran Kompalli (Davidson School of Chemical Engineering","Purdue University","West Lafayette","IN)","Akshdeep Singh Ahluwalia (Davidson School of Chemical Engineering","Purdue University","West Lafayette","IN)","Shraman Pal (Davidson School of Chemical Engineering","Purdue University","West Lafayette","IN)","Dimitri J. Papageorgiou (Energy Sciences","ExxonMobil Technology and Engineering Company","Annandale","NJ)","Can Li (Davidson School of Chemical Engineering","Purdue University","West Lafayette","IN)"],"url":"https://arxiv.org/abs/2506.02255"}
{"created":"2025-06-04","title":"Human Heterogeneity Invariant Stress Sensing","abstract":"Stress affects physical and mental health, and wearable devices have been widely used to detect daily stress through physiological signals. However, these signals vary due to factors such as individual differences and health conditions, making generalizing machine learning models difficult. To address these challenges, we present Human Heterogeneity Invariant Stress Sensing (HHISS), a domain generalization approach designed to find consistent patterns in stress signals by removing person-specific differences. This helps the model perform more accurately across new people, environments, and stress types not seen during training. Its novelty lies in proposing a novel technique called person-wise sub-network pruning intersection to focus on shared features across individuals, alongside preventing overfitting by leveraging continuous labels while training. The study focuses especially on people with opioid use disorder (OUD)-a group where stress responses can change dramatically depending on their time of daily medication taking. Since stress often triggers cravings, a model that can adapt well to these changes could support better OUD rehabilitation and recovery. We tested HHISS on seven different stress datasets-four of which we collected ourselves and three public ones. Four are from lab setups, one from a controlled real-world setting, driving, and two are from real-world in-the-wild field datasets without any constraints. This is the first study to evaluate how well a stress detection model works across such a wide range of data. Results show HHISS consistently outperformed state-of-the-art baseline methods, proving both effective and practical for real-world use. Ablation studies, empirical justifications, and runtime evaluations confirm HHISS's feasibility and scalability for mobile stress sensing in sensitive real-world applications.","authors":["Yi Xiao","Harshit Sharma","Sawinder Kaur","Dessa Bergen-Cico","Asif Salekin"],"url":"https://arxiv.org/abs/2506.02256"}
{"created":"2025-06-04","title":"Stochastically Dominant Peer Prediction","abstract":"Eliciting reliable human feedback is essential for many machine learning tasks, such as learning from noisy labels and aligning AI systems with human preferences. Peer prediction mechanisms incentivize truthful reporting without ground truth verification by scoring agents based on correlations with peers. Traditional mechanisms, which ensure that truth-telling maximizes the expected scores in equilibrium, can elicit honest information while assuming agents' utilities are linear functions of their scores. However, in practice, non-linear payment rules are usually preferred, or agents' utilities are inherently non-linear.","authors":["Yichi Zhang","Shengwei Xu","David Pennock","Grant Schoenebeck"],"url":"https://arxiv.org/abs/2506.02259"}
{"created":"2025-06-04","title":"Towards Human-like Preference Profiling in Sequential Recommendation","abstract":"Sequential recommendation systems aspire to profile users by interpreting their interaction histories, echoing how humans make decisions by weighing experience, relative preference strength, and situational relevance. Yet, existing large language model (LLM)-based recommenders often fall short of mimicking the flexible, context-aware decision strategies humans exhibit, neglecting the structured, dynamic, and context-aware mechanisms fundamental to human behaviors. To bridge this gap, we propose RecPO, a preference optimization framework that models structured feedback and contextual delay to emulate human-like prioritization in sequential recommendation RecPO exploits adaptive reward margins based on inferred preference hierarchies and temporal signals, enabling the model to favor immediately relevant items and to distinguish between varying degrees of preference and aversion. Extensive experiments across five real-world datasets demonstrate that RecPO not only yields performance gains over state-of-the-art baselines, but also mirrors key characteristics of human decision-making: favoring timely satisfaction, maintaining coherent preferences, and exercising discernment under shifting contexts.","authors":["Zhongyu Ouyang","Qianlong Wen","Chunhui Zhang","Yanfang Ye","Soroush Vosoughi"],"url":"https://arxiv.org/abs/2506.02261"}
{"created":"2025-06-04","title":"Composable Building Blocks for Controllable and Transparent Interactive AI Systems","abstract":"While the increased integration of AI technologies into interactive systems enables them to solve an equally increasing number of tasks, the black box problem of AI models continues to spread throughout the interactive system as a whole. Explainable AI (XAI) techniques can make AI models more accessible by employing post-hoc methods or transitioning to inherently interpretable models. While this makes individual AI models clearer, the overarching system architecture remains opaque. To this end, we propose an approach to represent interactive systems as sequences of structural building blocks, such as AI models and control mechanisms grounded in the literature. These can then be explained through accompanying visual building blocks, such as XAI techniques. The flow and APIs of the structural building blocks form an explicit overview of the system. This serves as a communication basis for both humans and automated agents like LLMs, aligning human and machine interpretability of AI models. We discuss a selection of building blocks and concretize our flow-based approach in an architecture and accompanying prototype interactive system.","authors":["Sebe Vanbrabant","Gustavo Rovelo Ruiz","Davy Vanacken"],"url":"https://arxiv.org/abs/2506.02262"}
{"created":"2025-06-04","title":"CoDial: Interpretable Task-Oriented Dialogue Systems Through Dialogue Flow Alignment","abstract":"It is often challenging to teach specialized, unseen tasks to dialogue systems due to the high cost of expert knowledge, training data, and high technical difficulty. To support domain-specific applications - such as law, medicine, or finance - it is essential to build frameworks that enable non-technical experts to define, test, and refine system behaviour with minimal effort. Achieving this requires cross-disciplinary collaboration between developers and domain specialists. In this work, we introduce a novel framework, CoDial (Code for Dialogue), that converts expert knowledge, represented as a novel structured heterogeneous graph, into executable conversation logic. CoDial can be easily implemented in existing guardrailing languages, such as Colang, to enable interpretable, modifiable, and true zero-shot specification of task-oriented dialogue systems. Empirically, CoDial achieves state-of-the-art performance on the STAR dataset for inference-based models and is competitive with similar baselines on the well-known MultiWOZ dataset. We also demonstrate CoDial's iterative improvement via manual and LLM-aided feedback, making it a practical tool for expert-guided alignment of LLMs in high-stakes domains.","authors":["Radin Shayanfar","Chu Fei Luo","Rohan Bhambhoria","Samuel Dahan","Xiaodan Zhu"],"url":"https://arxiv.org/abs/2506.02264"}
{"created":"2025-06-04","title":"Rig3R: Rig-Aware Conditioning for Learned 3D Reconstruction","abstract":"Estimating agent pose and 3D scene structure from multi-camera rigs is a central task in embodied AI applications such as autonomous driving. Recent learned approaches such as DUSt3R have shown impressive performance in multiview settings. However, these models treat images as unstructured collections, limiting effectiveness in scenarios where frames are captured from synchronized rigs with known or inferable structure.","authors":["Samuel Li","Pujith Kachana","Prajwal Chidananda","Saurabh Nair","Yasutaka Furukawa","Matthew Brown"],"url":"https://arxiv.org/abs/2506.02265"}
{"created":"2025-06-04","title":"TransAct V2: Lifelong User Action Sequence Modeling on Pinterest Recommendation","abstract":"Modeling user action sequences has become a popular focus in industrial recommendation system research, particularly for Click-Through Rate (CTR) prediction tasks. However, industry-scale CTR models often rely on short user sequences, limiting their ability to capture long-term behavior. Additionally, these models typically lack an integrated action-prediction task within a point-wise ranking framework, reducing their predictive power. They also rarely address the infrastructure challenges involved in efficiently serving large-scale sequential models. In this paper, we introduce TransAct V2, a production model for Pinterest's Homefeed ranking system, featuring three key innovations: (1) leveraging very long user sequences to improve CTR predictions, (2) integrating a Next Action Loss function for enhanced user action forecasting, and (3) employing scalable, low-latency deployment solutions tailored to handle the computational demands of extended user action sequences.","authors":["Xue Xia","Saurabh Vishwas Joshi","Kousik Rajesh","Kangnan Li","Yangyi Lu","Nikil Pancha","Dhruvil Deven Badani","Jiajing Xu","Pong Eksombatchai"],"url":"https://arxiv.org/abs/2506.02267"}
{"created":"2025-06-04","title":"A Tale of Two Symmetries: Exploring the Loss Landscape of Equivariant Models","abstract":"Equivariant neural networks have proven to be effective for tasks with known underlying symmetries. However, optimizing equivariant networks can be tricky and best training practices are less established than for standard networks. In particular, recent works have found small training benefits from relaxing equivariance constraints. This raises the question: do equivariance constraints introduce fundamental obstacles to optimization? Or do they simply require different hyperparameter tuning? In this work, we investigate this question through a theoretical analysis of the loss landscape geometry. We focus on networks built using permutation representations, which we can view as a subset of unconstrained MLPs. Importantly, we show that the parameter symmetries of the unconstrained model has nontrivial effects on the loss landscape of the equivariant subspace and under certain conditions can provably prevent learning of the global minima. Further, we empirically demonstrate in such cases, relaxing to an unconstrained MLP can sometimes solve the issue. Interestingly, the weights eventually found via relaxation corresponds to a different choice of group representation in the hidden layer. From this, we draw 3 key takeaways. (1) Viewing any class of networks in the context of larger unconstrained function space can give important insights on loss landscape structure. (2) Within the unconstrained function space, equivariant networks form a complicated union of linear hyperplanes, each associated with a specific choice of internal group representation. (3) Effective relaxation of equivariance may require not only adding nonequivariant degrees of freedom, but also rethinking the fixed choice of group representations in hidden layers.","authors":["YuQing Xie","Tess Smidt"],"url":"https://arxiv.org/abs/2506.02269"}
{"created":"2025-06-04","title":"Latent Stochastic Interpolants","abstract":"Stochastic Interpolants (SI) are a powerful framework for generative modeling, capable of flexibly transforming between two probability distributions. However, their use in jointly optimized latent variable models remains unexplored as they require direct access to the samples from the two distributions. This work presents Latent Stochastic Interpolants (LSI) enabling joint learning in a latent space with end-to-end optimized encoder, decoder and latent SI models. We achieve this by developing a principled Evidence Lower Bound (ELBO) objective derived directly in continuous time. The joint optimization allows LSI to learn effective latent representations along with a generative process that transforms an arbitrary prior distribution into the encoder-defined aggregated posterior. LSI sidesteps the simple priors of the normal diffusion models and mitigates the computational demands of applying SI directly in high-dimensional observation spaces, while preserving the generative flexibility of the SI framework. We demonstrate the efficacy of LSI through comprehensive experiments on the standard large scale ImageNet generation benchmark.","authors":["Saurabh Singh","Dmitry Lagun"],"url":"https://arxiv.org/abs/2506.02276"}
{"created":"2025-06-04","title":"ImpRAG: Retrieval-Augmented Generation with Implicit Queries","abstract":"Retrieval-Augmented Generation (RAG) systems traditionally treat retrieval and generation as separate processes, requiring explicit textual queries to connect them. This separation can limit the ability of models to generalize across diverse tasks. In this work, we propose a query-free RAG system, named ImpRAG, which integrates retrieval and generation into a unified model. ImpRAG allows models to implicitly express their information needs, eliminating the need for human-specified queries. By dividing pretrained decoder-only language models into specialized layer groups, ImpRAG optimizes retrieval and generation tasks simultaneously. Our approach employs a two-stage inference process, using the same model parameters and forward pass for both retrieval and generation, thereby minimizing the disparity between retrievers and language models. Experiments on 8 knowledge-intensive tasks demonstrate that ImpRAG achieves 3.6-11.5 improvements in exact match scores on unseen tasks with diverse formats, highlighting its effectiveness in enabling models to articulate their own information needs and generalize across tasks. Our analysis underscores the importance of balancing retrieval and generation parameters and leveraging generation perplexities as retrieval training objectives for enhanced performance.","authors":["Wenzheng Zhang","Xi Victoria Lin","Karl Stratos","Wen-tau Yih","Mingda Chen"],"url":"https://arxiv.org/abs/2506.02279"}
{"created":"2025-06-04","title":"The State of Large Language Models for African Languages: Progress and Challenges","abstract":"Large Language Models (LLMs) are transforming Natural Language Processing (NLP), but their benefits are largely absent for Africa's 2,000 low-resource languages. This paper comparatively analyzes African language coverage across six LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs). The evaluation covers language coverage, training sets, technical limitations, script problems, and language modelling roadmaps. The work identifies 42 supported African languages and 23 available public data sets, and it shows a big gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are always treated while there is over 98\\% of unsupported African languages. Moreover, the review shows that just Latin, Arabic, and Ge'ez scripts are identified while 20 active scripts are neglected. Some of the primary challenges are lack of data, tokenization biases, computational costs being very high, and evaluation issues. These issues demand language standardization, corpus development by the community, and effective adaptation methods for African languages.","authors":["Kedir Yassin Hussen","Walelign Tewabe Sewunetie","Abinew Ali Ayele","Sukairaj Hafiz Imam","Shamsuddeen Hassan Muhammad","Seid Muhie Yimam"],"url":"https://arxiv.org/abs/2506.02280"}
{"created":"2025-06-04","title":"Angles Don't Lie: Unlocking Training-Efficient RL Through the Model's Own Signals","abstract":"Current Reinforcement Fine-tuning (RFT) paradigms for Large Language Models (LLMs) suffer from sample inefficiency due to the redundant exposure of identical queries under uniform data sampling. While previous work has explored curriculum learning via heuristic difficulty metrics, these strategies exhibit limitations by neglecting the intrinsic learning signals generated by the model itself, thus leading to suboptimal training regimes. In this paper, we identify a model-inherent signal termed angle concentration that effectively reflects an LLM's capacity to learn from specific data. We theoretically and empirically demonstrate a correlation between the angular distribution of token hidden state vectors and the resulting gradient, revealing a learning preference for data exhibiting higher angle concentration. Inspired by this finding, we propose GAIN-RL, a Gradient-driven Angle-Informed Navigated RL framework. By leveraging the model's intrinsic angle concentration signal, GAIN-RL dynamically selects training data in each epoch, ensuring consistently impactful gradient updates and thus significantly enhancing overall training efficiency. Empirical evaluations show that GAIN-RL (GRPO) achieves over a 2.5x acceleration in training efficiency across diverse mathematical and coding tasks and varying model scales. Furthermore, GAIN-RL (GRPO)'s efficient sampling yields data-efficient training, achieving better performance with half the original data compared to vanilla GRPO with full training data. Code is realsed at https://github.com/wangqinsi1/GAINRL/tree/main.","authors":["Qinsi Wang","Jinghan Ke","Hancheng Ye","Yueqian Lin","Yuzhe Fu","Jianyi Zhang","Kurt Keutzer","Chenfeng Xu","Yiran Chen"],"url":"https://arxiv.org/abs/2506.02281"}
{"created":"2025-06-04","title":"Singularity Blockchain Key Management via non-custodial key management","abstract":"web3 wallets are key to managing user identity on blockchain. The main purpose of a web3 wallet application is to manage the private key for the user and provide an interface to interact with the blockchain. The key management scheme ( KMS ) used by the wallet to store and recover the private key can be either custodial, where the keys are permissioned and in custody of the wallet provider or noncustodial where the keys are in custody of the user. The existing non-custodial key management schemes tend to offset the burden of storing and recovering the key entirely on the user by asking them to remember seed-phrases. This creates onboarding hassles for the user and introduces the risk that the user may lose their assets if they forget or lose their seedphrase/private key. In this paper, we propose a novel method of backing up user keys using a non-custodial key management technique that allows users to save and recover a backup of their private key using any independent sign-in method such as google-oAuth or other 3P oAuth.","authors":["Sumit Vohra"],"url":"https://arxiv.org/abs/2506.02282"}
{"created":"2025-06-04","title":"Sounding Like a Winner? Prosodic Differences in Post-Match Interviews","abstract":"This study examines the prosodic characteristics associated with winning and losing in post-match tennis interviews. Additionally, this research explores the potential to classify match outcomes solely based on post-match interview recordings using prosodic features and self-supervised learning (SSL) representations. By analyzing prosodic elements such as pitch and intensity, alongside SSL models like Wav2Vec 2.0 and HuBERT, the aim is to determine whether an athlete has won or lost their match. Traditional acoustic features and deep speech representations are extracted from the data, and machine learning classifiers are employed to distinguish between winning and losing players. Results indicate that SSL representations effectively differentiate between winning and losing outcomes, capturing subtle speech patterns linked to emotional states. At the same time, prosodic cues -- such as pitch variability -- remain strong indicators of victory.","authors":["Sofoklis Kakouros","Haoyu Chen"],"url":"https://arxiv.org/abs/2506.02283"}
{"created":"2025-06-04","title":"Learning Optimal Posted Prices for a Unit-Demand Buyer","abstract":"We study the problem of learning the optimal item pricing for a unit-demand buyer with independent item values, and the learner has query access to the buyer's value distributions. We consider two common query models in the literature: the sample access model where the learner can obtain a sample of each item value, and the pricing query model where the learner can set a price for an item and obtain a binary signal on whether the sampled value of the item is greater than our proposed price. In this work, we give nearly tight sample complexity and pricing query complexity of the unit-demand pricing problem.","authors":["Yifeng Teng","Yifan Wang"],"url":"https://arxiv.org/abs/2506.02284"}
{"created":"2025-06-04","title":"Why Gradients Rapidly Increase Near the End of Training","abstract":"During long-duration Large Language Model (LLM) training runs the gradient norm increases rapidly near the end of training. In this short note, we show that this increase is due to an unintended interaction between weight decay, normalization layers, and the learning rate schedule. We propose a simple correction that fixes this behavior while also resulting in lower loss values throughout training.","authors":["Aaron Defazio"],"url":"https://arxiv.org/abs/2506.02285"}
{"created":"2025-06-04","title":"Efficient Manipulation-Enhanced Semantic Mapping With Uncertainty-Informed Action Selection","abstract":"Service robots operating in cluttered human environments such as homes, offices, and schools cannot rely on predefined object arrangements and must continuously update their semantic and spatial estimates while dealing with possible frequent rearrangements. Efficient and accurate mapping under such conditions demands selecting informative viewpoints and targeted manipulations to reduce occlusions and uncertainty. In this work, we present a manipulation-enhanced semantic mapping framework for occlusion-heavy shelf scenes that integrates evidential metric-semantic mapping with reinforcement-learning-based next-best view planning and targeted action selection. Our method thereby exploits uncertainty estimates from the Dirichlet and Beta distributions in the semantic and occupancy prediction networks to guide both active sensor placement and object manipulation, focusing on areas of limited knowledge and selecting actions with high expected information gain. For object manipulation, we introduce an uncertainty-informed push strategy that targets occlusion-critical objects and generates minimally invasive actions to reveal hidden regions. The experimental evaluation shows that our framework highly reduces object displacement and drops while achieving a 95% reduction in planning time compared to the state-of-the-art, thereby realizing real-world applicability.","authors":["Nils Dengler","Jesper M\\\"ucke","Rohit Menon","Maren Bennewitz"],"url":"https://arxiv.org/abs/2506.02286"}
{"created":"2025-06-04","title":"HEC: Equivalence Verification Checking for Code Transformation via Equality Saturation","abstract":"In modern computing systems, compilation employs numerous optimization techniques to enhance code performance. Source-to-source code transformations, which include control flow and datapath transformations, have been widely used in High-Level Synthesis (HLS) and compiler optimization.","authors":["Jiaqi Yin","Zhan Song","Nicolas Bohm Agostini","Antonino Tumeo","Cunxi Yu"],"url":"https://arxiv.org/abs/2506.02290"}
{"created":"2025-06-04","title":"Entity Image and Mixed-Modal Image Retrieval Datasets","abstract":"Despite advances in multimodal learning, challenging benchmarks for mixed-modal image retrieval that combines visual and textual information are lacking. This paper introduces a novel benchmark to rigorously evaluate image retrieval that demands deep cross-modal contextual understanding. We present two new datasets: the Entity Image Dataset (EI), providing canonical images for Wikipedia entities, and the Mixed-Modal Image Retrieval Dataset (MMIR), derived from the WIT dataset. The MMIR benchmark features two challenging query types requiring models to ground textual descriptions in the context of provided visual entities: single entity-image queries (one entity image with descriptive text) and multi-entity-image queries (multiple entity images with relational text). We empirically validate the benchmark's utility as both a training corpus and an evaluation set for mixed-modal retrieval. The quality of both datasets is further affirmed through crowd-sourced human annotations. The datasets are accessible through the GitHub page: https://github.com/google-research-datasets/wit-retrieval.","authors":["Cristian-Ioan Blaga","Paul Suganthan","Sahil Dua","Krishna Srinivasan","Enrique Alfonseca","Peter Dornbach","Tom Duerig","Imed Zitouni","Zhe Dong"],"url":"https://arxiv.org/abs/2506.02291"}
{"created":"2025-06-04","title":"On Universality Classes of Equivariant Networks","abstract":"Equivariant neural networks provide a principled framework for incorporating symmetry into learning architectures and have been extensively analyzed through the lens of their separation power, that is, the ability to distinguish inputs modulo symmetry. This notion plays a central role in settings such as graph learning, where it is often formalized via the Weisfeiler-Leman hierarchy. In contrast, the universality of equivariant models-their capacity to approximate target functions-remains comparatively underexplored. In this work, we investigate the approximation power of equivariant neural networks beyond separation constraints. We show that separation power does not fully capture expressivity: models with identical separation power may differ in their approximation ability. To demonstrate this, we characterize the universality classes of shallow invariant networks, providing a general framework for understanding which functions these architectures can approximate. Since equivariant models reduce to invariant ones under projection, this analysis yields sufficient conditions under which shallow equivariant networks fail to be universal. Conversely, we identify settings where shallow models do achieve separation-constrained universality. These positive results, however, depend critically on structural properties of the symmetry group, such as the existence of adequate normal subgroups, which may not hold in important cases like permutation symmetry.","authors":["Marco Pacini","Gabriele Santin","Bruno Lepri","Shubhendu Trivedi"],"url":"https://arxiv.org/abs/2506.02293"}
{"created":"2025-06-04","title":"Improving Knowledge Distillation Under Unknown Covariate Shift Through Confidence-Guided Data Augmentation","abstract":"Large foundation models trained on extensive datasets demonstrate strong zero-shot capabilities in various domains. To replicate their success when data and model size are constrained, knowledge distillation has become an established tool for transferring knowledge from foundation models to small student networks. However, the effectiveness of distillation is critically limited by the available training data. This work addresses the common practical issue of covariate shift in knowledge distillation, where spurious features appear during training but not at test time. We ask the question: when these spurious features are unknown, yet a robust teacher is available, is it possible for a student to also become robust to them? We address this problem by introducing a novel diffusion-based data augmentation strategy that generates images by maximizing the disagreement between the teacher and the student, effectively creating challenging samples that the student struggles with. Experiments demonstrate that our approach significantly improves worst group and mean group accuracy on CelebA and SpuCo Birds as well as the spurious mAUC on spurious ImageNet under covariate shift, outperforming state-of-the-art diffusion-based data augmentation baselines","authors":["Niclas Popp","Kevin Alexander Laube","Matthias Hein","Lukas Schott"],"url":"https://arxiv.org/abs/2506.02294"}
{"created":"2025-06-04","title":"QARI-OCR: High-Fidelity Arabic Text Recognition through Multimodal Large Language Model Adaptation","abstract":"The inherent complexities of Arabic script; its cursive nature, diacritical marks (tashkeel), and varied typography, pose persistent challenges for Optical Character Recognition (OCR). We present Qari-OCR, a series of vision-language models derived from Qwen2-VL-2B-Instruct, progressively optimized for Arabic through iterative fine-tuning on specialized synthetic datasets. Our leading model, QARI v0.2, establishes a new open-source state-of-the-art with a Word Error Rate (WER) of 0.160, Character Error Rate (CER) of 0.061, and BLEU score of 0.737 on diacritically-rich texts. Qari-OCR demonstrates superior handling of tashkeel, diverse fonts, and document layouts, alongside impressive performance on low-resolution images. Further explorations (QARI v0.3) showcase strong potential for structural document understanding and handwritten text. This work delivers a marked improvement in Arabic OCR accuracy and efficiency, with all models and datasets released to foster further research.","authors":["Ahmed Wasfy","Omer Nacar","Abdelakreem Elkhateb","Mahmoud Reda","Omar Elshehy","Adel Ammar","Wadii Boulila"],"url":"https://arxiv.org/abs/2506.02295"}
{"created":"2025-06-04","title":"Experimental Covert Communication Using Software-Defined Radio","abstract":"The fundamental information-theoretic limits of covert, or low probability of detection (LPD), communication have been extensively studied for over a decade, resulting in the square root law (SRL): only $L\\sqrt{n}$ covert bits can be reliably transmitted over time-bandwidth product $n$, for constant $L>0$. Transmitting more either results in detection or decoding errors. The SRL imposes significant constraints on hardware realization of provably-secure covert communication. Thus, experimental validation of covert communication is underexplored: to date, only two experimental studies of SRL-based covert communication are available, both focusing on optical channels. Here, we report our initial results demonstrating the provably-secure covert radio-frequency (RF) communication using software-defined radios (SDRs). These validate theoretical predictions, open practical avenues for implementing covert communication systems, as well as raise future research questions.","authors":["Rohan Bali","Trevor E. Bailey","Michael S. Bullock","Boulat A. Bash"],"url":"https://arxiv.org/abs/2506.02297"}
{"created":"2025-06-04","title":"LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback","abstract":"Large Action Models (LAMs) for AI Agents offer incredible potential but face challenges due to the need for high-quality training data, especially for multi-steps tasks that involve planning, executing tool calls, and responding to feedback. To address these issues, we present LAM SIMULATOR, a comprehensive framework designed for online exploration of agentic tasks with high-quality feedback. Our framework features a dynamic task query generator, an extensive collection of tools, and an interactive environment where Large Language Model (LLM) Agents can call tools and receive real-time feedback. This setup enables LLM Agents to explore and solve tasks autonomously, facilitating the discovery of multiple approaches to tackle any given task. The resulting action trajectory data are then used to create high-quality training datasets for LAMs. Our experiments on popular agentic benchmarks, ToolBench and CRMArena, highlight the effectiveness of LAM SIMULATOR: models trained with self-generated datasets using our framework achieve significant performance gains, up to a 49.3\\% improvement over their original baselines. LAM SIMULATOR requires minimal human input during dataset creation, highlighting LAM SIMULATOR's efficiency and effectiveness in speeding up development of AI agents.","authors":["Thai Hoang","Kung-Hsiang Huang","Shirley Kokane","Jianguo Zhang","Zuxin Liu","Ming Zhu","Jake Grigsby","Tian Lan","Michael S Ryoo","Chien-Sheng Wu","Shelby Heinecke","Huan Wang","Silvio Savarese","Caiming Xiong","Juan Carlos Niebles"],"url":"https://arxiv.org/abs/2506.02298"}
{"created":"2025-06-04","title":"Through a Steerable Lens: Magnifying Neural Network Interpretability via Phase-Based Extrapolation","abstract":"Understanding the internal representations and decision mechanisms of deep neural networks remains a critical open challenge. While existing interpretability methods often identify influential input regions, they may not elucidate how a model distinguishes between classes or what specific changes would transition an input from one category to another. To address these limitations, we propose a novel framework that visualizes the implicit path between classes by treating the network gradient as a form of infinitesimal motion. Drawing inspiration from phase-based motion magnification, we first decompose images using invertible transforms-specifically the Complex Steerable Pyramid-then compute class-conditional gradients in the transformed space. Rather than iteratively integrating the gradient to trace a full path, we amplify the one-step gradient to the input and perform a linear extrapolation to expose how the model moves from source to target class. By operating in the steerable pyramid domain, these amplified gradients produce semantically meaningful, spatially coherent morphs that highlight the classifier's most sensitive directions, giving insight into the geometry of its decision boundaries. Experiments on both synthetic and real-world datasets demonstrate that our phase-focused extrapolation yields perceptually aligned, semantically meaningful transformations, offering a novel, interpretable lens into neural classifiers' internal representations.","authors":["Farzaneh Mahdisoltani","Saeed Mahdisoltani","Roger B. Grosse","David J. Fleet"],"url":"https://arxiv.org/abs/2506.02300"}
{"created":"2025-06-04","title":"Explain-then-Process: Using Grammar Prompting to Enhance Grammatical Acceptability Judgments","abstract":"Large language models (LLMs) can explain grammatical rules, yet they often fail to apply those rules when judging sentence acceptability. We present \"grammar prompting\", an explain-then-process paradigm: a large LLM first produces a concise explanation of the relevant syntactic phenomenon, then that explanation is fed back as additional context to the target model -- either an LLM or a smaller language model (SLM) -- before deciding which sentence of a minimal pair is grammatical. On the English BLiMP, Chinese SLING, and Russian RuBLiMP benchmarks, this simple prompt design yields substantial improvements over strong baselines across many syntactic phenomena. Feeding an LLM's metalinguistic explanation back to the target model bridges the gap between knowing a rule and using it. On SLMs, grammar prompting alone trims the average LLM-SLM accuracy gap by about 20%, and when paired with chain-of-thought, by 56% (13.0 pp -> 5.8 pp), all at negligible cost. The lightweight, language-agnostic cue lets low-cost SLMs approach frontier-LLM performance in multilingual settings.","authors":["Russell Scheinberg","Ameeta Agrawal","Amber Shore","So Young Lee"],"url":"https://arxiv.org/abs/2506.02302"}
{"created":"2025-06-04","title":"CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation","abstract":"We present CACTI, a masked autoencoding approach for imputing tabular data that leverages the structure in missingness patterns and contextual information. Our approach employs a novel median truncated copy masking training strategy that encourages the model to learn from empirical patterns of missingness while incorporating semantic relationships between features - captured by column names and text descriptions - to better represent feature dependence. These dual sources of inductive bias enable CACTI to outperform state-of-the-art methods - an average $R^2$ gain of 7.8% over the next best method (13.4%, 6.1%, and 5.3% under missing not at random, at random and completely at random, respectively) - across a diverse range of datasets and missingness conditions. Our results highlight the value of leveraging dataset-specific contextual information and missingness patterns to enhance imputation performance.","authors":["Aditya Gorla","Ryan Wang","Zhengtong Liu","Ulzee An","Sriram Sankararaman"],"url":"https://arxiv.org/abs/2506.02306"}
{"created":"2025-06-04","title":"MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping","abstract":"Recent advances in multimodal foundation models have achieved state-of-the-art performance across a range of tasks. These breakthroughs are largely driven by new pre-training paradigms that leverage large-scale, unlabeled multimodal data, followed by instruction fine-tuning on curated labeled datasets and high-quality prompts. While there is growing interest in scaling instruction fine-tuning to ever-larger datasets in both quantity and scale, our findings reveal that simply increasing the number of instruction-tuning tasks does not consistently yield better performance. Instead, we observe that grouping tasks by the common interactions across modalities, such as discovering redundant shared information, prioritizing modality selection with unique information, or requiring synergistic fusion to discover new information from both modalities, encourages the models to learn transferrable skills within a group while suppressing interference from mismatched tasks. To this end, we introduce MINT, a simple yet surprisingly effective task-grouping strategy based on the type of multimodal interaction. We demonstrate that the proposed method greatly outperforms existing task grouping baselines for multimodal instruction tuning, striking an effective balance between generalization and specialization.","authors":["Xiaojun Shan","Qi Cao","Xing Han","Haofei Yu","Paul Pu Liang"],"url":"https://arxiv.org/abs/2506.02308"}
{"created":"2025-06-04","title":"SIL Allocation for Mitigation Safety Functions","abstract":"SIL (Safety Integrity Level) allocation plays a pivotal role in evaluating the significance of Safety Functions (SFs) within high-risk industries. The outcomes of a SIL allocation study determine the design specifications necessary to uphold the Probability of Failure on Demand (PFD) below permissible limits, thus managing risk effectively. While extensive research has focused on SIL allocation for preventive SFs, there is a noticeable gap in attention towards mitigation SFs. To address this gap, this paper discusses the shortcomings of current methods and proposes a new approach to overcome them. The principles of the proposed method are substantiated by detailed mathematical formulation and the practical application of the method is demonstrated through a case study in a road tunnel project.","authors":["Hamid Jahanian"],"url":"https://arxiv.org/abs/2506.02309"}
{"created":"2025-06-04","title":"Unicorn-CIM: Unconvering the Vulnerability and Improving the Resilience of High-Precision Compute-in-Memory","abstract":"Compute-in-memory (CIM) architecture has been widely","authors":["Qiufeng Li","Yiwen Liang","Weidong Cao"],"url":"https://arxiv.org/abs/2506.02311"}
{"created":"2025-06-04","title":"ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code","abstract":"Large language models (LLMs) have shown promise in transforming machine learning research, yet their capability to faithfully implement novel ideas from recent research papers-ideas unseen during pretraining-remains unclear. We introduce ResearchCodeBench, a benchmark of 212 coding challenges that evaluates LLMs' ability to translate cutting-edge ML contributions from top 2024-2025 research papers into executable code. We assessed 30+ proprietary and open-source LLMs, finding that even the best models correctly implement less than 40% of the code. We find Gemini-2.5-Pro-Preview to perform best at 37.3% success rate, with O3 (High) and O4-mini (High) following behind at 32.3% and 30.8% respectively. We present empirical findings on performance comparison, contamination, and error patterns. By providing a rigorous and community-driven evaluation platform, ResearchCodeBench enables continuous understanding and advancement of LLM-driven innovation in research code generation.","authors":["Tianyu Hua","Harper Hua","Violet Xiang","Benjamin Klieger","Sang T. Truong","Weixin Liang","Fan-Yun Sun","Nick Haber"],"url":"https://arxiv.org/abs/2506.02314"}
{"created":"2025-06-04","title":"A Data-Based Architecture for Flight Test without Test Points","abstract":"The justification for the \"test point\" derives from the test pilot's obligation to reproduce faithfully the pre-specified conditions of some model prediction. Pilot deviation from those conditions invalidates the model assumptions. Flight test aids have been proposed to increase accuracy on more challenging test points. However, the very existence of databands and tolerances is the problem more fundamental than inadequate pilot skill. We propose a novel approach, which eliminates test points. We start with a high-fidelity digital model of an air vehicle. Instead of using this model to generate a point prediction, we use a machine learning method to produce a reduced-order model (ROM). The ROM has two important properties. First, it can generate a prediction based on any set of conditions the pilot flies. Second, if the test result at those conditions differ from the prediction, the ROM can be updated using the new data. The outcome of flight test is thus a refined ROM at whatever conditions were flown. This ROM in turn updates and validates the high-fidelity model. We present a single example of this \"point-less\" architecture, using T-38C flight test data. We first use a generic aircraft model to build a ROM of longitudinal pitching motion as a hypersurface. We then ingest unconstrained flight test data and use Gaussian Process Regression to update and condition the hypersurface. By proposing a second-order equivalent system for the T-38C, this hypersurface then generates parameters necessary to assess MIL-STD-1797B compliance for longitudinal dynamics.","authors":["D. Isaiah Harp","Joshua Ott","John Alora","Dylan Asmar"],"url":"https://arxiv.org/abs/2506.02315"}
{"created":"2025-06-04","title":"Absorb and Converge: Provable Convergence Guarantee for Absorbing Discrete Diffusion Models","abstract":"Discrete state space diffusion models have shown significant advantages in applications involving discrete data, such as text and image generation. It has also been observed that their performance is highly sensitive to the choice of rate matrices, particularly between uniform and absorbing rate matrices. While empirical results suggest that absorbing rate matrices often yield better generation quality compared to uniform rate matrices, existing theoretical works have largely focused on the uniform rate matrices case. Notably, convergence guarantees and error analyses for absorbing diffusion models are still missing. In this work, we provide the first finite-time error bounds and convergence rate analysis for discrete diffusion models using absorbing rate matrices. We begin by deriving an upper bound on the KL divergence of the forward process, introducing a surrogate initialization distribution to address the challenge posed by the absorbing stationary distribution, which is a singleton and causes the KL divergence to be ill-defined. We then establish the first convergence guarantees for both the $\\tau$-leaping and uniformization samplers under absorbing rate matrices, demonstrating improved rates over their counterparts using uniform rate matrices. Furthermore, under suitable assumptions, we provide convergence guarantees without early stopping. Our analysis introduces several new technical tools to address challenges unique to absorbing rate matrices. These include a Jensen-type argument for bounding forward process convergence, novel techniques for bounding absorbing score functions, and a non-divergent upper bound on the score near initialization that removes the need of early-stopping.","authors":["Yuchen Liang","Renxiang Huang","Lifeng Lai","Ness Shroff","Yingbin Liang"],"url":"https://arxiv.org/abs/2506.02318"}
{"created":"2025-06-04","title":"Greedy recursion parameter selection for the One-Way Navier-Stokes (OWNS) equations","abstract":"The One-Way Navier-Stokes (OWNS) equations use recursive filtering to construct efficient, well-posed one-way approximations to linear hyperbolic systems. The recursion parameters are critical to the accuracy and stability of the method, and have previously been chosen based on heuristic estimates of key eigenvalues (or their branches), which converges slowly and requires trial-and-error tuning for new systems. We review the projection and recursive OWNS formulations (OWNS-P and OWNS-R) for inhomogeneous equations and propose a greedy algorithm for parameter selection. We show that it converges faster and leads to a net decrease in computational cost.","authors":["Michael K. Sleeman","Tim Colonius"],"url":"https://arxiv.org/abs/2506.02320"}
{"created":"2025-06-04","title":"Quantifying Misattribution Unfairness in Authorship Attribution","abstract":"Authorship misattribution can have profound consequences in real life. In forensic settings simply being considered as one of the potential authors of an evidential piece of text or communication can result in undesirable scrutiny. This raises a fairness question: Is every author in the candidate pool at equal risk of misattribution? Standard evaluation measures for authorship attribution systems do not explicitly account for this notion of fairness. We introduce a simple measure, Misattribution Unfairness Index (MAUIk), which is based on how often authors are ranked in the top k for texts they did not write. Using this measure we quantify the unfairness of five models on two different datasets. All models exhibit high levels of unfairness with increased risks for some authors. Furthermore, we find that this unfairness relates to how the models embed the authors as vectors in the latent search space. In particular, we observe that the risk of misattribution is higher for authors closer to the centroid (or center) of the embedded authors in the haystack. These results indicate the potential for harm and the need for communicating with and calibrating end users on misattribution risk when building and providing such models for downstream use.","authors":["Pegah Alipoormolabashi","Ajay Patel","Niranjan Balasubramanian"],"url":"https://arxiv.org/abs/2506.02321"}
{"created":"2025-06-04","title":"Sensitivity-Aware Density Estimation in Multiple Dimensions","abstract":"We formulate an optimization problem to estimate probability densities in the context of multidimensional problems that are sampled with uneven probability. It considers detector sensitivity as an heterogeneous density and takes advantage of the computational speed and flexible boundary conditions offered by splines on a grid. We choose to regularize the Hessian of the spline via the nuclear norm to promote sparsity. As a result, the method is spatially adaptive and stable against the choice of the regularization parameter, which plays the role of the bandwidth. We test our computational pipeline on standard densities and provide software. We also present a new approach to PET rebinning as an application of our framework.","authors":["Aleix Boquet-Pujadas","Pol del Aguila Pla","Michael Unser"],"url":"https://arxiv.org/abs/2506.02323"}
{"created":"2025-06-04","title":"Are Crypto Ecosystems (De)centralizing? A Framework for Longitudinal Analysis","abstract":"Blockchain technology relies on decentralization to resist faults and attacks while operating without trusted intermediaries. Although industry experts have touted decentralization as central to their promise and disruptive potential, it is still unclear whether the crypto ecosystems built around blockchains are becoming more or less decentralized over time. As crypto plays an increasing role in facilitating economic transactions and peer-to-peer interactions, measuring their decentralization becomes even more essential. We thus propose a systematic framework for measuring the decentralization of crypto ecosystems over time and compare commonly used decentralization metrics. We applied this framework to seven prominent crypto ecosystems, across five distinct subsystems and across their lifetime for over 15 years. Our analysis revealed that while crypto has largely become more decentralized over time, recent trends show a shift toward centralization in the consensus layer, NFT marketplaces, and developers. Our framework and results inform researchers, policymakers, and practitioners about the design, regulation, and implementation of crypto ecosystems and provide a systematic, replicable foundation for future studies.","authors":["Harang Ju","Ehsan Valavi","Madhav Kumar","Sinan Aral"],"url":"https://arxiv.org/abs/2506.02324"}
{"created":"2025-06-04","title":"Something Just Like TRuST : Toxicity Recognition of Span and Target","abstract":"Toxicity in online content, including content generated by language models, has become a critical concern due to its potential for negative psychological and social impact. This paper introduces TRuST, a comprehensive dataset designed to improve toxicity detection that merges existing datasets, and has labels for toxicity, target social group, and toxic spans. It includes a diverse range of target groups such as ethnicity, gender, religion, disability, and politics, with both human/machine-annotated and human machine-generated data. We benchmark state-of-the-art large language models (LLMs) on toxicity detection, target group identification, and toxic span extraction. We find that fine-tuned models consistently outperform zero-shot and few-shot prompting, though performance remains low for certain social groups. Further, reasoning capabilities do not significantly improve performance, indicating that LLMs have weak social reasoning skills.","authors":["Berk Atil","Namrata Sureddy","Rebecca J. Passonneau"],"url":"https://arxiv.org/abs/2506.02326"}
{"created":"2025-06-04","title":"Medical World Model: Generative Simulation of Tumor Evolution for Treatment Planning","abstract":"Providing effective treatment and making informed clinical decisions are essential goals of modern medicine and clinical care. We are interested in simulating disease dynamics for clinical decision-making, leveraging recent advances in large generative models. To this end, we introduce the Medical World Model (MeWM), the first world model in medicine that visually predicts future disease states based on clinical decisions. MeWM comprises (i) vision-language models to serve as policy models, and (ii) tumor generative models as dynamics models. The policy model generates action plans, such as clinical treatments, while the dynamics model simulates tumor progression or regression under given treatment conditions. Building on this, we propose the inverse dynamics model that applies survival analysis to the simulated post-treatment tumor, enabling the evaluation of treatment efficacy and the selection of the optimal clinical action plan. As a result, the proposed MeWM simulates disease dynamics by synthesizing post-treatment tumors, with state-of-the-art specificity in Turing tests evaluated by radiologists. Simultaneously, its inverse dynamics model outperforms medical-specialized GPTs in optimizing individualized treatment protocols across all metrics. Notably, MeWM improves clinical decision-making for interventional physicians, boosting F1-score in selecting the optimal TACE protocol by 13%, paving the way for future integration of medical world models as the second readers.","authors":["Yijun Yang","Zhao-Yang Wang","Qiuping Liu","Shuwen Sun","Kang Wang","Rama Chellappa","Zongwei Zhou","Alan Yuille","Lei Zhu","Yu-Dong Zhang","Jieneng Chen"],"url":"https://arxiv.org/abs/2506.02327"}
{"created":"2025-06-04","title":"Finite State Dimension and The Davenport Erd\\H{o}s Theorem","abstract":"A 1952 result of Davenport and Erd\\H{o}s states that if $p$ is an integer-valued polynomial, then the real number $0.p(1)p(2)p(3)\\dots$ is Borel normal in base ten. A later result of Nakai and Shiokawa extends this result to polynomials with arbitrary real coefficients and all bases $b\\geq 2$. It is well-known that finite-state dimension, a finite-state effectivization of the classical Hausdorff dimension, characterizes the Borel normal sequences as precisely those sequences of finite-state dimension 1. For an infinite set of natural numbers, and a base $b\\geq 2$, the base $b$ Copeland-Erd\\H{o}s sequence of $A$, $CE_b(A)$, is the infinite sequence obtained by concatenating the base $b$ expressions of the numbers in $A$ in increasing order. In this work we investigate the possible relationships between the finite-state dimensions of $CE_b(A)$ and $CE_b(p(A))$ where $p$ is a polynomial. We show that, if the polynomial is permitted to have arbitrary real coefficients, then for any $s,s^\\prime$ in the unit interval, there is a set $A$ of natural numbers and a linear polynomial $p$ so that the finite-state dimensions of $CE_b(A)$ and $CE_b(p(A))$ are $s$ and $s^\\prime$ respectively. We also demonstrate that linear polynomials with rational coefficients do not change the finite-state dimension of any Copeland-Erd\\H{o}s sequence, but there exist polynomials with rational coefficients of every larger integer degree that change the finite-state dimension of some sequence. To prove our main results, we develop techniques involving taking concatenated prefixes of a sequence as well as inserting a density zero set of strings into a sequence that may be of independent interest.","authors":["Joe Clanin","Matthew Rayman"],"url":"https://arxiv.org/abs/2506.02332"}
{"created":"2025-06-04","title":"Generalized Category Discovery via Reciprocal Learning and Class-Wise Distribution Regularization","abstract":"Generalized Category Discovery (GCD) aims to identify unlabeled samples by leveraging the base knowledge from labeled ones, where the unlabeled set consists of both base and novel classes. Since clustering methods are time-consuming at inference, parametric-based approaches have become more popular. However, recent parametric-based methods suffer from inferior base discrimination due to unreliable self-supervision. To address this issue, we propose a Reciprocal Learning Framework (RLF) that introduces an auxiliary branch devoted to base classification. During training, the main branch filters the pseudo-base samples to the auxiliary branch. In response, the auxiliary branch provides more reliable soft labels for the main branch, leading to a virtuous cycle. Furthermore, we introduce Class-wise Distribution Regularization (CDR) to mitigate the learning bias towards base classes. CDR essentially increases the prediction confidence of the unlabeled data and boosts the novel class performance. Combined with both components, our proposed method, RLCD, achieves superior performance in all classes with negligible extra computation. Comprehensive experiments across seven GCD datasets validate its superiority. Our codes are available at https://github.com/APORduo/RLCD.","authors":["Duo Liu","Zhiquan Tan","Linglan Zhao","Zhongqiang Zhang","Xiangzhong Fang","Weiran Huang"],"url":"https://arxiv.org/abs/2506.02334"}
{"created":"2025-06-04","title":"Discovery of Probabilistic Dirichlet-to-Neumann Maps on Graphs","abstract":"Dirichlet-to-Neumann maps enable the coupling of multiphysics simulations across computational subdomains by ensuring continuity of state variables and fluxes at artificial interfaces. We present a novel method for learning Dirichlet-to-Neumann maps on graphs using Gaussian processes, specifically for problems where the data obey a conservation constraint from an underlying partial differential equation. Our approach combines discrete exterior calculus and nonlinear optimal recovery to infer relationships between vertex and edge values. This framework yields data-driven predictions with uncertainty quantification across the entire graph, even when observations are limited to a subset of vertices and edges. By optimizing over the reproducing kernel Hilbert space norm while applying a maximum likelihood estimation penalty on kernel complexity, our method ensures that the resulting surrogate strictly enforces conservation laws without overfitting. We demonstrate our method on two representative applications: subsurface fracture networks and arterial blood flow. Our results show that the method maintains high accuracy and well-calibrated uncertainty estimates even under severe data scarcity, highlighting its potential for scientific applications where limited data and reliable uncertainty quantification are critical.","authors":["Adrienne M. Propp","Jonas A. Actor","Elise Walker","Houman Owhadi","Nathaniel Trask","Daniel M. Tartakovsky"],"url":"https://arxiv.org/abs/2506.02337"}
{"created":"2025-06-04","title":"One Missing Piece for Open-Source Reasoning Models: A Dataset to Mitigate Cold-Starting Short CoT LLMs in RL","abstract":"With the release of R1, a publicly available large reasoning model (LRM), researchers commonly train new LRMs by training language models on R1's long chain-of-thought (CoT) inferences. While prior works show that LRMs' capabilities can be reproduced through direct distillation, the continued reliance on the existing models (e.g., R1) remains a critical limitation in advancing the field. As a first step toward independent LRM development, this paper explores the possibility of constructing a long CoT dataset with LLMs that are not trained for inference-time scaling. To this end, we present the Long CoT Collection, a dataset of 100K CoT rationales annotated using existing short CoT LLMs. We develop a pipeline that induces o1's novel reasoning strategies into short CoT LLMs, enabling them to think longer and introducing controllability over the thought budget to better manage the overthinking problem. Our extensive analyses validate that our dataset achieves quality comparable to--or slightly below--R1. Furthermore, our experiments demonstrate that training on our dataset not only strengthens general reasoning skills, but also provides a strong foundation for reinforcement learning--models initialized on our data achieve 2-3x larger gains with RLVR.","authors":["Hyungjoo Chae","Dongjin Kang","Jihyuk Kim","Beong-woo Kwak","Sunghyun Park","Haeju Park","Jinyoung Yeo","Moontae Lee","Kyungjae Lee"],"url":"https://arxiv.org/abs/2506.02338"}
{"created":"2025-06-04","title":"Minimal Neuron Circuits -- Part I: Resonators","abstract":"Spiking Neural Networks have earned increased recognition in recent years owing to their biological plausibility and event-driven computation. Spiking neurons are the fundamental building components of Spiking Neural Networks. Those neurons act as computational units that determine the decision to fire an action potential. This work presents a methodology to implement biologically plausible yet scalable spiking neurons in hardware. We show that it is more efficient to design neurons that mimic the $I_{Na,p}+I_{K}$ model rather than the more complicated Hodgkin-Huxley model. We demonstrate our methodology by presenting eleven novel minimal spiking neuron circuits in Parts I and II of the paper. We categorize the neuron circuits presented into two types: Resonators and Integrators. We discuss the methodology employed in designing neurons of the resonator type in Part I, while we discuss neurons of the integrator type in Part II. In part I, we postulate that Sodium channels exhibit type-N negative differential resistance. Consequently, we present three novel minimal neuron circuits that use type-N negative differential resistance circuits or devices as the Sodium channel. Nevertheless, the aim of the paper is not to present a set of minimal neuron circuits but rather the methodology utilized to construct those circuits.","authors":["Amr Nabil","T. Nandha Kumar","Haider Abbas F. Almurib"],"url":"https://arxiv.org/abs/2506.02341"}
{"created":"2025-06-04","title":"Memory Access Vectors: Improving Sampling Fidelity for CPU Performance Simulations","abstract":"Accurate performance projection of large-scale benchmarks is essential for CPU architects to evaluate and optimize future processor designs. SimPoint sampling, which uses Basic Block Vectors (BBVs), is a widely adopted technique to reduce simulation time by selecting representative program phases. However, BBVs often fail to capture the behavior of applications with extensive array-indirect memory accesses, leading to inaccurate projections. In particular, the 523.xalancbmk_r benchmark exhibits complex data movement patterns that challenge traditional SimPoint methods. To address this, we propose enhancing SimPoint's BBV methodology by incorporating Memory Access Vectors (MAV), a microarchitecture independent technique that tracks functional memory access patterns. This combined approach significantly improves the projection accuracy of 523.xalancbmk_r on a 192-core system-on-chip, increasing it from 80% to 98%.","authors":["Sriyash Caculo","Mahesh Madhav","Jeff Baxter"],"url":"https://arxiv.org/abs/2506.02344"}
{"created":"2025-06-04","title":"PandasBench: A Benchmark for the Pandas API","abstract":"The Pandas API has been central to the success of pandas and its alternatives. Despite its importance, there is no benchmark for it, and we argue that we cannot repurpose existing benchmarks (from other domains) for the Pandas API.","authors":["Alex Broihier","Stefanos Baziotis","Daniel Kang","Charith Mendis"],"url":"https://arxiv.org/abs/2506.02345"}
{"created":"2025-06-04","title":"A Practical Linear Time Algorithm for Optimal Tree Decomposition of Halin Graphs","abstract":"This work proposes \\textsc{H-Td}, a practical linear-time algorithm for computing an optimal-width tree decomposition of Halin graphs. Unlike state-of-the-art methods based on reduction rules or separators, \\textsc{H-Td} exploits the structural properties of Halin graphs. Although two theoretical linear-time algorithms exist that can be applied to graphs of treewidth three, no practical implementation has been made publicly available. Furthermore, extending reduction-based approaches to partial $k$-trees with $k > 3$ results in increasingly complex rules that are challenging to implement. This motivates the exploration of alternative strategies that leverage structural insights specific to certain graph classes. Experimental validation against the winners of the Parameterized Algorithms and Computational Experiments Challenge (PACE) 2017 and the treewidth library \\texttt{libtw} demonstrates the advantage of \\textsc{H-Td} when the input is known to be a Halin graph.","authors":["J. A. Alejandro-Soto","Joel Antonio Trejo-Sanchez","Carlos Segura"],"url":"https://arxiv.org/abs/2506.02346"}
{"created":"2025-06-04","title":"STORYTELLER: An Enhanced Plot-Planning Framework for Coherent and Cohesive Story Generation","abstract":"Stories are central to human culture, serving to share ideas, preserve traditions, and foster connections. Automatic story generation, a key advancement in artificial intelligence (AI), offers new possibilities for creating personalized content, exploring creative ideas, and enhancing interactive experiences. However, existing methods struggle to maintain narrative coherence and logical consistency. This disconnect compromises the overall storytelling experience, underscoring the need for substantial improvements. Inspired by human cognitive processes, we introduce Storyteller, a novel approach that systemically improves the coherence and consistency of automatically generated stories. Storyteller introduces a plot node structure based on linguistically grounded subject verb object (SVO) triplets, which capture essential story events and ensure a consistent logical flow. Unlike previous methods, Storyteller integrates two dynamic modules, the STORYLINE and narrative entity knowledge graph (NEKG),that continuously interact with the story generation process. This integration produces structurally sound, cohesive and immersive narratives. Extensive experiments demonstrate that Storyteller significantly outperforms existing approaches, achieving an 84.33% average win rate through human preference evaluation. At the same time, it is also far ahead in other aspects including creativity, coherence, engagement, and relevance.","authors":["Jiaming Li","Yukun Chen","Ziqiang Liu","Minghuan Tan","Lei Zhang","Yunshui Li","Run Luo","Longze Chen","Jing Luo","Ahmadreza Argha","Hamid Alinejad-Rokny","Wei Zhou","Min Yang"],"url":"https://arxiv.org/abs/2506.02347"}
{"created":"2025-06-04","title":"Truth over Tricks: Measuring and Mitigating Shortcut Learning in Misinformation Detection","abstract":"Misinformation detection models often rely on superficial cues (i.e., \\emph{shortcuts}) that correlate with misinformation in training data but fail to generalize to the diverse and evolving nature of real-world misinformation. This issue is exacerbated by large language models (LLMs), which can easily generate convincing misinformation through simple prompts. We introduce TruthOverTricks, a unified evaluation paradigm for measuring shortcut learning in misinformation detection. TruthOverTricks categorizes shortcut behaviors into intrinsic shortcut induction and extrinsic shortcut injection, and evaluates seven representative detectors across 14 popular benchmarks, along with two new factual misinformation datasets, NQ-Misinfo and Streaming-Misinfo. Empirical results reveal that existing detectors suffer severe performance degradation when exposed to both naturally occurring and adversarially crafted shortcuts. To address this, we propose SMF, an LLM-augmented data augmentation framework that mitigates shortcut reliance through paraphrasing, factual summarization, and sentiment normalization. SMF consistently enhances robustness across 16 benchmarks, encouraging models to rely on deeper semantic understanding rather than shortcut cues. To promote the development of misinformation detectors, we have published the resources publicly at https://github.com/whr000001/TruthOverTricks.","authors":["Herun Wan","Jiaying Wu","Minnan Luo","Zhi Zeng","Zhixiong Su"],"url":"https://arxiv.org/abs/2506.02350"}
{"created":"2025-06-04","title":"DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization","abstract":"Traditional approaches -- such as Win Probability Added (WPA)-based ranking or computer vision-driven event detection -- can identify scoring plays but often miss strategic depth, momentum shifts, and storyline progression. Manual curation remains the gold standard but is resource-intensive and not scalable. We introduce DIAMOND, an LLM-driven agent for context-aware baseball highlight summarization that integrates structured sports analytics with natural language reasoning. DIAMOND leverages sabermetric features -- Win Expectancy, WPA, and Leverage Index -- to quantify play importance, while an LLM module enhances selection based on contextual narrative value. This hybrid approach ensures both quantitative rigor and qualitative richness, surpassing the limitations of purely statistical or vision-based systems. Evaluated on five diverse Korean Baseball Organization League games, DIAMOND improves F1-score from 42.9% (WPA-only) to 84.8%, outperforming both commercial and statistical baselines. Though limited in scale, our results highlight the potential of modular, interpretable agent-based frameworks for event-level summarization in sports and beyond.","authors":["Jeonghun Kang","Soonmok Kwon","Joonseok Lee","Byung-Hak Kim"],"url":"https://arxiv.org/abs/2506.02351"}
{"created":"2025-06-04","title":"SAVOR: Skill Affordance Learning from Visuo-Haptic Perception for Robot-Assisted Bite Acquisition","abstract":"Robot-assisted feeding requires reliable bite acquisition, a challenging task due to the complex interactions between utensils and food with diverse physical properties. These interactions are further complicated by the temporal variability of food properties-for example, steak becomes firm as it cools even during a meal. To address this, we propose SAVOR, a novel approach for learning skill affordances for bite acquisition-how suitable a manipulation skill (e.g., skewering, scooping) is for a given utensil-food interaction. In our formulation, skill affordances arise from the combination of tool affordances (what a utensil can do) and food affordances (what the food allows). Tool affordances are learned offline through calibration, where different utensils interact with a variety of foods to model their functional capabilities. Food affordances are characterized by physical properties such as softness, moisture, and viscosity, initially inferred through commonsense reasoning using a visually-conditioned language model and then dynamically refined through online multi-modal visuo-haptic perception using SAVOR-Net during interaction. Our method integrates these offline and online estimates to predict skill affordances in real time, enabling the robot to select the most appropriate skill for each food item. Evaluated on 20 single-item foods and 10 in-the-wild meals, our approach improves bite acquisition success by 13% over state-of-the-art (SOTA) category-based methods (e.g. use skewer for fruits). These results highlight the importance of modeling interaction-driven skill affordances for generalizable and effective robot-assisted bite acquisition. Website: https://emprise.cs.cornell.edu/savor/","authors":["Zhanxin Wu","Bo Ai","Tom Silver","Tapomayukh Bhattacharjee"],"url":"https://arxiv.org/abs/2506.02353"}
{"created":"2025-06-04","title":"RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models","abstract":"Object Navigation (ObjectNav) is a fundamental task in embodied artificial intelligence. Although significant progress has been made in semantic map construction and target direction prediction in current research, redundant exploration and exploration failures remain inevitable. A critical but underexplored direction is the timely termination of exploration to overcome these challenges. We observe a diminishing marginal effect between exploration steps and exploration rates and analyze the cost-benefit relationship of exploration. Inspired by this, we propose RATE-Nav, a Region-Aware Termination-Enhanced method. It includes a geometric predictive region segmentation algorithm and region-Based exploration estimation algorithm for exploration rate calculation. By leveraging the visual question answering capabilities of visual language models (VLMs) and exploration rates enables efficient termination.RATE-Nav achieves a success rate of 67.8% and an SPL of 31.3% on the HM3D dataset. And on the more challenging MP3D dataset, RATE-Nav shows approximately 10% improvement over previous zero-shot methods.","authors":["Junjie Li","Nan Zhang","Xiaoyang Qu","Kai Lu","Guokuan Li","Jiguang Wan","Jianzong Wang"],"url":"https://arxiv.org/abs/2506.02354"}
{"created":"2025-06-04","title":"Rewarding the Unlikely: Lifting GRPO Beyond Distribution Sharpening","abstract":"Reinforcement learning has emerged as an effective framework for training large language models on structured language-conditioned tasks. We identify a critical flaw of Group Relative Policy Optimization (GRPO), a widely used RL algorithm in this setting. For tasks that require multi-sample performance, such as formal theorem proving, GRPO biasedly reinforces already probable solutions and neglects rare but correct proofs. This implicit bias impairs performance on pass@$N$ metrics at large sample sizes, limiting its practicality for training theorem provers. To address this, we introduce the unlikeliness reward, a straightforward method that explicitly encourages reinforcing rare correct solutions. Additionally, we find that increasing the number of PPO epochs further mitigates this bias. Our experiments confirm that incorporating the unlikeliness reward significantly improves pass@$N$ across a large range of N, outperforming standard GRPO and substantially increasing sample diversity. Applying our revised recipe to Lean, we achieve competitive performance with DeepSeek-Prover-V1.5-RL on the miniF2F-test benchmark. We release our implementation, providing a simple yet effective recipe for training formal theorem provers with RL.","authors":["Andre He","Daniel Fried","Sean Welleck"],"url":"https://arxiv.org/abs/2506.02355"}
{"created":"2025-06-04","title":"InterRVOS: Interaction-aware Referring Video Object Segmentation","abstract":"Referring video object segmentation aims to segment the object in a video corresponding to a given natural language expression. While prior works have explored various referring scenarios, including motion-centric or multi-instance expressions, most approaches still focus on localizing a single target object in isolation. However, in comprehensive video understanding, an object's role is often defined by its interactions with other entities, which are largely overlooked in existing datasets and models. In this work, we introduce Interaction-aware referring video object sgementation (InterRVOS), a new task that requires segmenting both actor and target entities involved in an interaction. Each interactoin is described through a pair of complementary expressions from different semantic perspectives, enabling fine-grained modeling of inter-object relationships. To tackle this task, we propose InterRVOS-8K, the large-scale and automatically constructed dataset containing diverse interaction-aware expressions with corresponding masks, including challenging cases such as motion-only multi-instance expressions. We also present a baseline architecture, ReVIOSa, designed to handle actor-target segmentation from a single expression, achieving strong performance in both standard and interaction-focused settings. Furthermore, we introduce an actor-target-aware evalaution setting that enables a more targeted assessment of interaction understanding. Experimental results demonstrate that our approach outperforms prior methods in modeling complex object interactions for referring video object segmentation task, establishing a strong foundation for future research in interaction-centric video understanding. Our project page is available at \\href{https://cvlab-kaist.github.io/InterRVOS}{https://cvlab-kaist.github.io/InterRVOS}.","authors":["Woojeong Jin","Seongchan Kim","Seungryong Kim"],"url":"https://arxiv.org/abs/2506.02356"}
{"created":"2025-06-04","title":"Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A Lightweight Benchmark for Probing Foundational Controllability Components","abstract":"Credible safety plans for advanced AI development require methods to verify agent behavior and detect potential control deficiencies early. A fundamental aspect is ensuring agents adhere to safety-critical principles, especially when these conflict with operational goals. Failure to prioritize such principles indicates a potential basic control failure. This paper introduces a lightweight, interpretable benchmark methodology using a simple grid world to evaluate an LLM agent's ability to uphold a predefined, high-level safety principle (e.g., \"never enter hazardous zones\") when faced with conflicting lower-level task instructions. We probe whether the agent reliably prioritizes the inviolable directive, testing a foundational controllability aspect of LLMs. This pilot study demonstrates the methodology's feasibility, offers preliminary insights into agent behavior under principle conflict, and discusses how such benchmarks can contribute empirical evidence for assessing controllability. We argue that evaluating adherence to hierarchical principles is a crucial early step in understanding our capacity to build governable AI systems.","authors":["Ram Potham (Independent Researcher)"],"url":"https://arxiv.org/abs/2506.02357"}
{"created":"2025-06-04","title":"RoadFormer : Local-Global Feature Fusion for Road Surface Classification in Autonomous Driving","abstract":"The classification of the type of road surface (RSC) aims to utilize pavement features to identify the roughness, wet and dry conditions, and material information of the road surface. Due to its ability to effectively enhance road safety and traffic management, it has received widespread attention in recent years. In autonomous driving, accurate RSC allows vehicles to better understand the road environment, adjust driving strategies, and ensure a safer and more efficient driving experience. For a long time, vision-based RSC has been favored. However, existing visual classification methods have overlooked the exploration of fine-grained classification of pavement types (such as similar pavement textures). In this work, we propose a pure vision-based fine-grained RSC method for autonomous driving scenarios, which fuses local and global feature information through the stacking of convolutional and transformer modules. We further explore the stacking strategies of local and global feature extraction modules to find the optimal feature extraction strategy. In addition, since fine-grained tasks also face the challenge of relatively large intra-class differences and relatively small inter-class differences, we propose a Foreground-Background Module (FBM) that effectively extracts fine-grained context features of the pavement, enhancing the classification ability for complex pavements. Experiments conducted on a large-scale pavement dataset containing one million samples and a simplified dataset reorganized from this dataset achieved Top-1 classification accuracies of 92.52% and 96.50%, respectively, improving by 5.69% to 12.84% compared to SOTA methods. These results demonstrate that RoadFormer outperforms existing methods in RSC tasks, providing significant progress in improving the reliability of pavement perception in autonomous driving systems.","authors":["Tianze Wang","Zhang Zhang","Chao Sun"],"url":"https://arxiv.org/abs/2506.02358"}
{"created":"2025-06-04","title":"Auto-Labeling Data for Object Detection","abstract":"Great labels make great models. However, traditional labeling approaches for tasks like object detection have substantial costs at scale. Furthermore, alternatives to fully-supervised object detection either lose functionality or require larger models with prohibitive computational costs for inference at scale. To that end, this paper addresses the problem of training standard object detection models without any ground truth labels. Instead, we configure previously-trained vision-language foundation models to generate application-specific pseudo \"ground truth\" labels. These auto-generated labels directly integrate with existing model training frameworks, and we subsequently train lightweight detection models that are computationally efficient. In this way, we avoid the costs of traditional labeling, leverage the knowledge of vision-language models, and keep the efficiency of lightweight models for practical application. We perform exhaustive experiments across multiple labeling configurations, downstream inference models, and datasets to establish best practices and set an extensive auto-labeling benchmark. From our results, we find that our approach is a viable alternative to standard labeling in that it maintains competitive performance on multiple datasets and substantially reduces labeling time and costs.","authors":["Brent A. Griffin","Manushree Gangwar","Jacob Sela","Jason J. Corso"],"url":"https://arxiv.org/abs/2506.02359"}
{"created":"2025-06-04","title":"MISLEADER: Defending against Model Extraction with Ensembles of Distilled Models","abstract":"Model extraction attacks aim to replicate the functionality of a black-box model through query access, threatening the intellectual property (IP) of machine-learning-as-a-service (MLaaS) providers. Defending against such attacks is challenging, as it must balance efficiency, robustness, and utility preservation in the real-world scenario. Despite the recent advances, most existing defenses presume that attacker queries have out-of-distribution (OOD) samples, enabling them to detect and disrupt suspicious inputs. However, this assumption is increasingly unreliable, as modern models are trained on diverse datasets and attackers often operate under limited query budgets. As a result, the effectiveness of these defenses is significantly compromised in realistic deployment scenarios. To address this gap, we propose MISLEADER (enseMbles of dIStiLled modEls Against moDel ExtRaction), a novel defense strategy that does not rely on OOD assumptions. MISLEADER formulates model protection as a bilevel optimization problem that simultaneously preserves predictive fidelity on benign inputs and reduces extractability by potential clone models. Our framework combines data augmentation to simulate attacker queries with an ensemble of heterogeneous distilled models to improve robustness and diversity. We further provide a tractable approximation algorithm and derive theoretical error bounds to characterize defense effectiveness. Extensive experiments across various settings validate the utility-preserving and extraction-resistant properties of our proposed defense strategy. Our code is available at https://github.com/LabRAI/MISLEADER.","authors":["Xueqi Cheng","Minxing Zheng","Shixiang Zhu","Yushun Dong"],"url":"https://arxiv.org/abs/2506.02362"}
{"created":"2025-06-04","title":"A TRPCA-Inspired Deep Unfolding Network for Hyperspectral Image Denoising via Thresholded t-SVD and Top-K Sparse Transformer","abstract":"Hyperspectral images (HSIs) are often degraded by complex mixed noise during acquisition and transmission, making effective denoising essential for subsequent analysis. Recent hybrid approaches that bridge model-driven and data-driven paradigms have shown great promise. However, most of these approaches lack effective alternation between different priors or modules, resulting in loosely coupled regularization and insufficient exploitation of their complementary strengths. Inspired by tensor robust principal component analysis (TRPCA), we propose a novel deep unfolding network (DU-TRPCA) that enforces stage-wise alternation between two tightly integrated modules: low-rank and sparse. The low-rank module employs thresholded tensor singular value decomposition (t-SVD), providing a widely adopted convex surrogate for tensor low-rankness and has been demonstrated to effectively capture the global spatial-spectral structure of HSIs. The Top-K sparse transformer module adaptively imposes sparse constraints, directly matching the sparse regularization in TRPCA and enabling effective removal of localized outliers and complex noise. This tightly coupled architecture preserves the stage-wise alternation between low-rank approximation and sparse refinement inherent in TRPCA, while enhancing representational capacity through attention mechanisms. Extensive experiments on synthetic and real-world HSIs demonstrate that DU-TRPCA surpasses state-of-the-art methods under severe mixed noise, while offering interpretability benefits and stable denoising dynamics inspired by iterative optimization. Code is available at https://github.com/liangli97/TRPCA-Deep-Unfolding-HSI-Denoising.","authors":["Liang Li","Jianli Zhao","Sheng Fang","Siyu Chen","Hui Sun"],"url":"https://arxiv.org/abs/2506.02364"}
{"created":"2025-06-04","title":"Dynamic real-time multi-UAV cooperative mission planning method under multiple constraints","abstract":"As UAV popularity soars, so does the mission planning associated with it. The classical approaches suffer from the triple problems of decoupled of task assignment and path planning, poor real-time performance and limited adaptability. Aiming at these challenges, this paper proposes a dynamic real-time multi-UAV collaborative mission planning algorithm based on Dubins paths under a distributed formation structure. Dubins path with multiple advantages bridges the gap between task assignment and path planning, leading to a coupled solution for mission planning. Then, a series of acceleration techniques, task clustering preprocessing, highly efficient distance cost functions, low-complexity and less iterative task allocation strategies, are employed to guarantee the real-time performance of the algorithms. To cope with different emergencies and their simultaneous extremes, real-time planning of emerging tasks and mission replanning due to the reduction of available UAVs are appropriately handled. Finally, the developed algorithm is comprehensively exemplified and studied through simulations, highlighting that the proposed method only sacrifices 9.57% of the path length, while achieving a speed improvement of 4-5 orders of magnitude over the simulated annealing method, with a single mission planning of about 0.0003s.","authors":["Chenglou Liu","Yufeng Lu","Fangfang Xie","Tingwei Ji","Yao Zheng"],"url":"https://arxiv.org/abs/2506.02365"}
{"created":"2025-06-04","title":"Approximate Borderline Sampling using Granular-Ball for Classification Tasks","abstract":"Data sampling enhances classifier efficiency and robustness through data compression and quality improvement. Recently, the sampling method based on granular-ball (GB) has shown promising performance in generality and noisy classification tasks. However, some limitations remain, including the absence of borderline sampling strategies and issues with class boundary blurring or shrinking due to overlap between GBs. In this paper, an approximate borderline sampling method using GBs is proposed for classification tasks. First, a restricted diffusion-based GB generation (RD-GBG) method is proposed, which prevents GB overlaps by constrained expansion, preserving precise geometric representation of GBs via redefined ones. Second, based on the concept of heterogeneous nearest neighbor, a GB-based approximate borderline sampling (GBABS) method is proposed, which is the first general sampling method capable of both borderline sampling and improving the quality of class noise datasets. Additionally, since RD-GBG incorporates noise detection and GBABS focuses on borderline samples, GBABS performs outstandingly on class noise datasets without the need for an optimal purity threshold. Experimental results demonstrate that the proposed methods outperform the GB-based sampling method and several representative sampling methods. Our source code is publicly available at https://github.com/CherylTse/GBABS.","authors":["Qin Xie","Qinghua Zhang","Shuyin Xia"],"url":"https://arxiv.org/abs/2506.02366"}
{"created":"2025-06-04","title":"ViTNF: Leveraging Neural Fields to Boost Vision Transformers in Generalized Category Discovery","abstract":"Generalized category discovery (GCD) is a highly popular task in open-world recognition, aiming to identify unknown class samples using known class data. By leveraging pre-training, meta-training, and fine-tuning, ViT achieves excellent few-shot learning capabilities. Its MLP head is a feedforward network, trained synchronously with the entire network in the same process, increasing the training cost and difficulty without fully leveraging the power of the feature extractor. This paper proposes a new architecture by replacing the MLP head with a neural field-based one. We first present a new static neural field function to describe the activity distribution of the neural field and then use two static neural field functions to build an efficient few-shot classifier. This neural field-based (NF) classifier consists of two coupled static neural fields. It stores the feature information of support samples by its elementary field, the known categories by its high-level field, and the category information of support samples by its cross-field connections. We replace the MLP head with the proposed NF classifier, resulting in a novel architecture ViTNF, and simplify the three-stage training mode by pre-training the feature extractor on source tasks and training the NF classifier with support samples in meta-testing separately, significantly reducing ViT's demand for training samples and the difficulty of model training. To enhance the model's capability in identifying new categories, we provide an effective algorithm to determine the lateral interaction scale of the elementary field. Experimental results demonstrate that our model surpasses existing state-of-the-art methods on CIFAR-100, ImageNet-100, CUB-200, and Standard Cars, achieving dramatic accuracy improvements of 19\\% and 16\\% in new and all classes, respectively, indicating a notable advantage in GCD.","authors":["Jiayi Su","Dequan Jin"],"url":"https://arxiv.org/abs/2506.02367"}
{"created":"2025-06-04","title":"NextQuill: Causal Preference Modeling for Enhancing LLM Personalization","abstract":"Personalizing large language models (LLMs) for individual users has become increasingly important as they are progressively integrated into real-world applications to support users' daily lives. However, existing personalization approaches often fail to distinguish which components of model predictions and training data truly reflect user preferences, leading to superficial personalization alignment. In this paper, we introduce NextQuill, a novel LLM personalization alignment framework grounded in causal preference modeling. We approach personalization from a causal perspective, treating both model predictions and ground-truth data generation as outcomes influenced by user preferences, along with other factors. We define the true preference effect as the causal impact of user history (which reflects preferences) on each token prediction or data generation instance, estimated through causal intervention techniques. Building on this insight, NextQuill introduces two complementary alignment strategies: (1) aligning model-internal causal preference effects on predictions with those reflected in ground-truth data, rather than indiscriminately fitting predictions, and (2) focusing on fitting preference-bearing tokens identified via ground-truth data preference effects, rather than treating all tokens uniformly. By integrating these strategies, NextQuill shifts the alignment process toward learning from causal preference effects, facilitating more effective and personalized adaptation. Experiments across multiple personalization benchmarks demonstrate that NextQuill significantly improves personalization quality, offering a principled, causal foundation for LLM personalization. Our codes are available on https://github.com/juntaoyou/NextQuill.","authors":["Xiaoyan Zhao","Juntao You","Yang Zhang","Wenjie Wang","Hong Cheng","Fuli Feng","See-Kiong Ng","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2506.02368"}
{"created":"2025-06-04","title":"Reconciling Hessian-Informed Acceleration and Scalar-Only Communication for Efficient Federated Zeroth-Order Fine-Tuning","abstract":"Recent dimension-free communication frameworks in Federated Learning (FL), such as DeComFL, significantly reduce per-round communication by transmitting only scalars via zeroth-order stochastic gradient descent (ZO-SGD). This method is particularly advantageous for federated fine-tuning of Large Language Models (LLMs). Yet, the high variance in ZO gradient estimation typically leads to slow convergence. Although leveraging Hessian information is known to enhance optimization speed, integrating this into FL presents significant challenges. These include clients' restrictions on local data and the critical need to maintain the dimension-free communication property. To overcome this limitation, we first introduce a generalized scalar-only communication FL framework that decouples dimension-free communication from standard ZO-SGD, enabling the integration of more advanced optimization strategies. Building on this framework, we propose HiSo, a fast federated fine-tuning method via Hessian-informed zeroth-order optimization and Scalar-only communication. Specifically, it leverages global curvature information to accelerate convergence while preserving the same minimal communication cost per round. Theoretically, we establish convergence guarantees that are independent of the global Lipschitz constant, and further show that HiSo achieves faster rates when the global Hessian exhibits a low effective rank -- a common phenomenon in LLMs. Extensive experiments on benchmark datasets and LLM fine-tuning tasks confirm that HiSo significantly outperforms existing ZO-based FL methods in both convergence speed and communication efficiency.","authors":["Zhe Li","Bicheng Ying","Zidong Liu","Chaosheng Dong","Haibo Yang"],"url":"https://arxiv.org/abs/2506.02370"}
{"created":"2025-06-04","title":"SFBD Flow: A Continuous-Optimization Framework for Training Diffusion Models with Noisy Samples","abstract":"Diffusion models achieve strong generative performance but often rely on large datasets that may include sensitive content. This challenge is compounded by the models' tendency to memorize training data, raising privacy concerns. SFBD (Lu et al., 2025) addresses this by training on corrupted data and using limited clean samples to capture local structure and improve convergence. However, its iterative denoising and fine-tuning loop requires manual coordination, making it burdensome to implement. We reinterpret SFBD as an alternating projection algorithm and introduce a continuous variant, SFBD flow, that removes the need for alternating steps. We further show its connection to consistency constraint-based methods, and demonstrate that its practical instantiation, Online SFBD, consistently outperforms strong baselines across benchmarks.","authors":["Haoye Lu","Darren Lo","Yaoliang Yu"],"url":"https://arxiv.org/abs/2506.02371"}
{"created":"2025-06-04","title":"AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM Output","abstract":"In this paper we present AnswerCarefully, a dataset for promoting the safety and appropriateness of Japanese LLM outputs. The dataset consists of 1,800 pairs of questions and reference answers, where the questions require special attention in answering. It covers a wide range of risk categories established in prior English-language datasets, but the data samples are original in that they are manually created to reflect the socio-cultural context of LLM usage in Japan. We show that using this dataset for instruction to fine-tune a Japanese LLM led to improved output safety without compromising the utility of general responses. We also report the results of a safety evaluation of 12 Japanese LLMs using this dataset as a benchmark. Finally, we describe the latest update on the dataset which provides English translations and annotations of the questions, aimed at facilitating the derivation of similar datasets in different languages and regions.","authors":["Hisami Suzuki","Satoru Katsumata","Takashi Kodama","Tetsuro Takahashi","Kouta Nakayama","Satoshi Sekine"],"url":"https://arxiv.org/abs/2506.02372"}
{"created":"2025-06-04","title":"Olfactory Inertial Odometry: Methodology for Effective Robot Navigation by Scent","abstract":"Olfactory navigation is one of the most primitive mechanisms of exploration used by organisms. Navigation by machine olfaction (artificial smell) is a very difficult task to both simulate and solve. With this work, we define olfactory inertial odometry (OIO), a framework for using inertial kinematics, and fast-sampling olfaction sensors to enable navigation by scent analogous to visual inertial odometry (VIO). We establish how principles from SLAM and VIO can be extrapolated to olfaction to enable real-world robotic tasks. We demonstrate OIO with three different odour localization algorithms on a real 5-DoF robot arm over an odour-tracking scenario that resembles real applications in agriculture and food quality control. Our results indicate success in establishing a baseline framework for OIO from which other research in olfactory navigation can build, and we note performance enhancements that can be made to address more complex tasks in the future.","authors":["Kordel K. France","Ovidiu Daescu"],"url":"https://arxiv.org/abs/2506.02373"}
{"created":"2025-06-04","title":"Exploring Explanations Improves the Robustness of In-Context Learning","abstract":"In-context learning (ICL) has emerged as a successful paradigm for leveraging large language models (LLMs). However, it often struggles to generalize beyond the distribution of the provided demonstrations. A recent advancement in enhancing robustness is ICL with explanations (X-ICL), which improves prediction reliability by guiding LLMs to understand and articulate the reasoning behind correct labels. Building on this approach, we introduce an advanced framework that extends X-ICL by systematically exploring explanations for all possible labels (X$^2$-ICL), thereby enabling more comprehensive and robust decision-making. Experimental results on multiple natural language understanding datasets validate the effectiveness of X$^2$-ICL, demonstrating significantly improved robustness to out-of-distribution data compared to the existing ICL approaches.","authors":["Ukyo Honda","Tatsushi Oka"],"url":"https://arxiv.org/abs/2506.02378"}
{"created":"2025-06-04","title":"EyeNavGS: A 6-DoF Navigation Dataset and Record-n-Replay Software for Real-World 3DGS Scenes in VR","abstract":"3D Gaussian Splatting (3DGS) is an emerging media representation that reconstructs real-world 3D scenes in high fidelity, enabling 6-degrees-of-freedom (6-DoF) navigation in virtual reality (VR). However, developing and evaluating 3DGS-enabled applications and optimizing their rendering performance, require realistic user navigation data. Such data is currently unavailable for photorealistic 3DGS reconstructions of real-world scenes. This paper introduces EyeNavGS (EyeNavGS), the first publicly available 6-DoF navigation dataset featuring traces from 46 participants exploring twelve diverse, real-world 3DGS scenes. The dataset was collected at two sites, using the Meta Quest Pro headsets, recording the head pose and eye gaze data for each rendered frame during free world standing 6-DoF navigation. For each of the twelve scenes, we performed careful scene initialization to correct for scene tilt and scale, ensuring a perceptually-comfortable VR experience. We also release our open-source SIBR viewer software fork with record-and-replay functionalities and a suite of utility tools for data processing, conversion, and visualization. The EyeNavGS dataset and its accompanying software tools provide valuable resources for advancing research in 6-DoF viewport prediction, adaptive streaming, 3D saliency, and foveated rendering for 3DGS scenes. The EyeNavGS dataset is available at: https://symmru.github.io/EyeNavGS/.","authors":["Zihao Ding","Cheng-Tse Lee","Mufeng Zhu","Tao Guan","Yuan-Chun Sun","Cheng-Hsin Hsu","Yao Liu"],"url":"https://arxiv.org/abs/2506.02380"}
{"created":"2025-06-04","title":"Multi-level and Multi-modal Action Anticipation","abstract":"Action anticipation, the task of predicting future actions from partially observed videos, is crucial for advancing intelligent systems. Unlike action recognition, which operates on fully observed videos, action anticipation must handle incomplete information. Hence, it requires temporal reasoning, and inherent uncertainty handling. While recent advances have been made, traditional methods often focus solely on visual modalities, neglecting the potential of integrating multiple sources of information. Drawing inspiration from human behavior, we introduce \\textit{Multi-level and Multi-modal Action Anticipation (m\\&amp;m-Ant)}, a novel multi-modal action anticipation approach that combines both visual and textual cues, while explicitly modeling hierarchical semantic information for more accurate predictions. To address the challenge of inaccurate coarse action labels, we propose a fine-grained label generator paired with a specialized temporal consistency loss function to optimize performance. Extensive experiments on widely used datasets, including Breakfast, 50 Salads, and DARai, demonstrate the effectiveness of our approach, achieving state-of-the-art results with an average anticipation accuracy improvement of 3.08\\% over existing methods. This work underscores the potential of multi-modal and hierarchical modeling in advancing action anticipation and establishes a new benchmark for future research in the field. Our code is available at: https://github.com/olivesgatech/mM-ant.","authors":["Seulgi Kim","Ghazal Kaviani","Mohit Prabhushankar","Ghassan AlRegib"],"url":"https://arxiv.org/abs/2506.02382"}
{"created":"2025-06-04","title":"Multi-agent Markov Entanglement","abstract":"Value decomposition has long been a fundamental technique in multi-agent dynamic programming and reinforcement learning (RL). Specifically, the value function of a global state $(s_1,s_2,\\ldots,s_N)$ is often approximated as the sum of local functions: $V(s_1,s_2,\\ldots,s_N)\\approx\\sum_{i=1}^N V_i(s_i)$. This approach traces back to the index policy in restless multi-armed bandit problems and has found various applications in modern RL systems. However, the theoretical justification for why this decomposition works so effectively remains underexplored.","authors":["Shuze Chen","Tianyi Peng"],"url":"https://arxiv.org/abs/2506.02385"}
{"created":"2025-06-04","title":"Asymptotically Optimal Linear Best Feasible Arm Identification with Fixed Budget","abstract":"The challenge of identifying the best feasible arm within a fixed budget has attracted considerable interest in recent years. However, a notable gap remains in the literature: the exact exponential rate at which the error probability approaches zero has yet to be established, even in the relatively simple setting of $K$-armed bandits with Gaussian noise. In this paper, we address this gap by examining the problem within the context of linear bandits. We introduce a novel algorithm for best feasible arm identification that guarantees an exponential decay in the error probability. Remarkably, the decay rate -- characterized by the exponent -- matches the theoretical lower bound derived using information-theoretic principles. Our approach leverages a posterior sampling framework embedded within a game-based sampling rule involving a min-learner and a max-learner. This strategy shares its foundations with Thompson sampling, but is specifically tailored to optimize the identification process under fixed-budget constraints. Furthermore, we validate the effectiveness of our algorithm through comprehensive empirical evaluations across various problem instances with different levels of complexity. The results corroborate our theoretical findings and demonstrate that our method outperforms several benchmark algorithms in terms of both accuracy and efficiency.","authors":["Jie Bian","Vincent Y. F. Tan"],"url":"https://arxiv.org/abs/2506.02386"}
{"created":"2025-06-04","title":"VS-Bench: Evaluating VLMs for Strategic Reasoning and Decision-Making in Multi-Agent Environments","abstract":"Recent advancements in Vision Language Models (VLMs) have expanded their capabilities to interactive agent tasks, yet existing benchmarks remain limited to single-agent or text-only environments. In contrast, real-world scenarios often involve multiple agents interacting within rich visual and linguistic contexts, posing challenges with both multimodal observations and strategic interactions. To bridge this gap, we introduce Visual Strategic Bench (VS-Bench), a multimodal benchmark that evaluates VLMs for strategic reasoning and decision-making in multi-agent environments. VS-Bench comprises eight vision-grounded environments spanning cooperative, competitive, and mixed-motive interactions, designed to assess agents' ability to predict others' future moves and optimize for long-term objectives. We consider two complementary evaluation dimensions, including offline evaluation of strategic reasoning by next-action prediction accuracy and online evaluation of decision-making by normalized episode return. Extensive experiments of fourteen leading VLMs reveal a significant gap between current models and optimal performance, with the best models attaining 47.8% prediction accuracy and 24.3% normalized return. We further conduct in-depth analyses on multimodal observations, test-time scaling, social behaviors, and failure cases of VLM agents. By standardizing the evaluation and highlighting the limitations of existing models, we envision VS-Bench as a foundation for future research on strategic multimodal agents. Code and data are available at https://vs-bench.github.io.","authors":["Zelai Xu","Zhexuan Xu","Xiangmin Yi","Huining Yuan","Xinlei Chen","Yi Wu","Chao Yu","Yu Wang"],"url":"https://arxiv.org/abs/2506.02387"}
{"created":"2025-06-04","title":"Univariate to Multivariate: LLMs as Zero-Shot Predictors for Time-Series Forecasting","abstract":"Time-series prediction or forecasting is critical across many real-world dynamic systems, and recent studies have proposed using Large Language Models (LLMs) for this task due to their strong generalization capabilities and ability to perform well without extensive pre-training. However, their effectiveness in handling complex, noisy, and multivariate time-series data remains underexplored. To address this, we propose LLMPred which enhances LLM-based time-series prediction by converting time-series sequences into text and feeding them to LLMs for zero shot prediction along with two main data pre-processing techniques. First, we apply time-series sequence decomposition to facilitate accurate prediction on complex and noisy univariate sequences. Second, we extend this univariate prediction capability to multivariate data using a lightweight prompt-processing strategy. Extensive experiments with smaller LLMs such as Llama 2 7B, Llama 3.2 3B, GPT-4o-mini, and DeepSeek 7B demonstrate that LLMPred achieves competitive or superior performance compared to state-of-the-art baselines. Additionally, a thorough ablation study highlights the importance of the key components proposed in LLMPred.","authors":["Chamara Madarasingha","Nasrin Sohrabi","Zahir Tari"],"url":"https://arxiv.org/abs/2506.02389"}
{"created":"2025-06-04","title":"GAdaBoost: An Efficient and Robust AdaBoost Algorithm Based on Granular-Ball Structure","abstract":"Adaptive Boosting (AdaBoost) faces significant challenges posed by label noise, especially in multiclass classification tasks. Existing methods either lack mechanisms to handle label noise effectively or suffer from high computational costs due to redundant data usage. Inspired by granular computing, this paper proposes granular adaptive boosting (GAdaBoost), a novel two-stage framework comprising a data granulation stage and an adaptive boosting stage, to enhance efficiency and robustness under noisy conditions. To validate its feasibility, an extension of SAMME, termed GAdaBoost.SA, is proposed. Specifically, first, a granular-ball generation method is designed to compress data while preserving diversity and mitigating label noise. Second, the granular ball-based SAMME algorithm focuses on granular balls rather than individual samples, improving efficiency and reducing sensitivity to noise. Experimental results on some noisy datasets show that the proposed approach achieves superior robustness and efficiency compared with existing methods, demonstrating that this work effectively extends AdaBoost and SAMME.","authors":["Qin Xie","Qinghua Zhang","Shuyin Xia","Xinran Zhou","Guoyin Wang"],"url":"https://arxiv.org/abs/2506.02390"}
{"created":"2025-06-04","title":"Consultant Decoding: Yet Another Synergistic Mechanism","abstract":"The synergistic mechanism based on Speculative Decoding (SD) has garnered considerable attention as a simple yet effective approach for accelerating the inference of large language models (LLMs). Nonetheless, the high rejection rates require repeated LLMs calls to validate draft tokens, undermining the overall efficiency gain of SD. In this work, we revisit existing verification mechanisms and propose a novel synergetic mechanism Consultant Decoding (CD). Unlike SD, which relies on a metric derived from importance sampling for verification, CD verifies candidate drafts using token-level likelihoods computed solely by the LLM. CD achieves up to a 2.5-fold increase in inference speed compared to the target model, while maintaining comparable generation quality (around 100% of the target model's performance). Interestingly, this is achieved by combining models whose parameter sizes differ by two orders of magnitude. In addition, CD reduces the call frequency of the large target model to below 10%, particularly in more demanding tasks. CD's performance was even found to surpass that of the large target model, which theoretically represents the upper bound for speculative decoding.","authors":["Chuanghao Ding","Jiaping Wang","Ziqing Yang","Xiaoliang Wang","Dahua Lin","Cam-Tu Nguyen","Fei Tan"],"url":"https://arxiv.org/abs/2506.02391"}
{"created":"2025-06-04","title":"Improving Generalization of Neural Combinatorial Optimization for Vehicle Routing Problems via Test-Time Projection Learning","abstract":"Neural Combinatorial Optimization (NCO) has emerged as a promising learning-based paradigm for addressing Vehicle Routing Problems (VRPs) by minimizing the need for extensive manual engineering. While existing NCO methods, trained on small-scale instances (e.g., 100 nodes), have demonstrated considerable success on problems of similar scale, their performance significantly degrades when applied to large-scale scenarios. This degradation arises from the distributional shift between training and testing data, rendering policies learned on small instances ineffective for larger problems. To overcome this limitation, we introduce a novel learning framework driven by Large Language Models (LLMs). This framework learns a projection between the training and testing distributions, which is then deployed to enhance the scalability of the NCO model. Notably, unlike prevailing techniques that necessitate joint training with the neural network, our approach operates exclusively during the inference phase, obviating the need for model retraining. Extensive experiments demonstrate that our method enables a backbone model (trained on 100-node instances) to achieve superior performance on large-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) of up to 100K nodes from diverse distributions.","authors":["Yuanyao Chen","Rongsheng Chen","Fu Luo","Zhenkun Wang"],"url":"https://arxiv.org/abs/2506.02392"}
{"created":"2025-06-04","title":"RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection","abstract":"Infrared small target detection is a challenging task due to its unique characteristics (e.g., small, dim, shapeless and changeable). Recently published CNN-based methods have achieved promising performance with heavy feature extraction and fusion modules. To achieve efficient and effective detection, we propose a recurrent reusable-convolution attention network (RRCA-Net) for infrared small target detection. Specifically, RRCA-Net incorporates reusable-convolution block (RuCB) in a recurrent manner without introducing extra parameters. With the help of the repetitive iteration in RuCB, the high-level information of small targets in the deep layers can be well maintained and further refined. Then, a dual interactive attention aggregation module (DIAAM) is proposed to promote the mutual enhancement and fusion of refined information. In this way, RRCA-Net can both achieve high-level feature refinement and enhance the correlation of contextual information between adjacent layers. Moreover, to achieve steady convergence, we design a target characteristic inspired loss function (DpT-k loss) by integrating physical and mathematical constraints. Experimental results on three benchmark datasets (e.g. NUAA-SIRST, IRSTD-1k, DenseSIRST) demonstrate that our RRCA-Net can achieve comparable performance to the state-of-the-art methods while maintaining a small number of parameters, and act as a plug and play module to introduce consistent performance improvement for several popular IRSTD methods. Our code will be available at https://github.com/yongxianLiu/ soon.","authors":["Yongxian Liu","Boyang Li","Ting Liu","Zaiping Lin","Wei An"],"url":"https://arxiv.org/abs/2506.02393"}
{"created":"2025-06-04","title":"The Devil is in the Darkness: Diffusion-Based Nighttime Dehazing Anchored in Brightness Perception","abstract":"While nighttime image dehazing has been extensively studied, converting nighttime hazy images to daytime-equivalent brightness remains largely unaddressed. Existing methods face two critical limitations: (1) datasets overlook the brightness relationship between day and night, resulting in the brightness mapping being inconsistent with the real world during image synthesis; and (2) models do not explicitly incorporate daytime brightness knowledge, limiting their ability to reconstruct realistic lighting. To address these challenges, we introduce the Diffusion-Based Nighttime Dehazing (DiffND) framework, which excels in both data synthesis and lighting reconstruction. Our approach starts with a data synthesis pipeline that simulates severe distortions while enforcing brightness consistency between synthetic and real-world scenes, providing a strong foundation for learning night-to-day brightness mapping. Next, we propose a restoration model that integrates a pre-trained diffusion model guided by a brightness perception network. This design harnesses the diffusion model's generative ability while adapting it to nighttime dehazing through brightness-aware optimization. Experiments validate our dataset's utility and the model's superior performance in joint haze removal and brightness mapping.","authors":["Xiaofeng Cong","Yu-Xin Zhang","Haoran Wei","Yeying Jin","Junming Hou","Jie Gui","Jing Zhang","Dacheng Tao"],"url":"https://arxiv.org/abs/2506.02395"}
{"created":"2025-06-04","title":"Towards Explicit Geometry-Reflectance Collaboration for Generalized LiDAR Segmentation in Adverse Weather","abstract":"Existing LiDAR semantic segmentation models often suffer from decreased accuracy when exposed to adverse weather conditions. Recent methods addressing this issue focus on enhancing training data through weather simulation or universal augmentation techniques. However, few works have studied the negative impacts caused by the heterogeneous domain shifts in the geometric structure and reflectance intensity of point clouds. In this paper, we delve into this challenge and address it with a novel Geometry-Reflectance Collaboration (GRC) framework that explicitly separates feature extraction for geometry and reflectance. Specifically, GRC employs a dual-branch architecture designed to independently process geometric and reflectance features initially, thereby capitalizing on their distinct characteristic. Then, GRC adopts a robust multi-level feature collaboration module to suppress redundant and unreliable information from both branches. Consequently, without complex simulation or augmentation, our method effectively extracts intrinsic information about the scene while suppressing interference, thus achieving better robustness and generalization in adverse weather conditions. We demonstrate the effectiveness of GRC through comprehensive experiments on challenging benchmarks, showing that our method outperforms previous approaches and establishes new state-of-the-art results.","authors":["Longyu Yang","Ping Hu","Shangbo Yuan","Lu Zhang","Jun Liu","Hengtao Shen","Xiaofeng Zhu"],"url":"https://arxiv.org/abs/2506.02396"}
{"created":"2025-06-04","title":"OThink-R1: Intrinsic Fast/Slow Thinking Mode Switching for Over-Reasoning Mitigation","abstract":"Recent advanced large reasoning models (LRMs) leverage extended chain-of-thought (CoT) reasoning to solve complex tasks, achieving state-of-the-art performance. Despite their success, we identify a critical issue: a substantial portion of simple tasks solved by LRMs can also be addressed by non-reasoning LLMs using significantly fewer tokens, indicating the complex reasoning may not always be necessary. To address this, we systematically analyze the reasoning trajectories of LRMs and present a method utilizing identified paradigms and LLM-Judge to classify these trajectories as either Redundant Reasoning or Essential Reasoning. And we introduce OThink-R1, a method that prunes redundant reasoning steps while preserving logical validity. OThink-R1 dynamically employs the non-thinking mode (fast-thinking) for straightforward problems while engaging in deliberate thinking (slow-thinking) for complex problems. Experiments across mathematical and question-answering tasks demonstrate that OThink-R1 reduces reasoning redundancy by almost 23\\% on average without compromising accuracy, offering practical guidelines for efficient reasoning models. The code is available at https://github.com/AgenticIR-Lab/OThink-R1.","authors":["Shengjia Zhang","Junjie Wu","Jiawei Chen","Changwang Zhang","Xingyu Lou","Wangchunshu Zhou","Sheng Zhou","Can Wang","Jun Wang"],"url":"https://arxiv.org/abs/2506.02397"}
{"created":"2025-06-04","title":"Trusted Fake Audio Detection Based on Dirichlet Distribution","abstract":"With the continuous development of deep learning-based speech conversion and speech synthesis technologies, the cybersecurity problem posed by fake audio has become increasingly serious. Previously proposed models for defending against fake audio have attained remarkable performance. However, they all fall short in modeling the trustworthiness of the decisions made by the models themselves. Based on this, we put forward a plausible fake audio detection approach based on the Dirichlet distribution with the aim of enhancing the reliability of fake audio detection. Specifically, we first generate evidence through a neural network. Uncertainty is then modeled using the Dirichlet distribution. By modeling the belief distribution with the parameters of the Dirichlet distribution, an estimate of uncertainty can be obtained for each decision. Finally, the predicted probabilities and corresponding uncertainty estimates are combined to form the final opinion. On the ASVspoof series dataset (i.e., ASVspoof 2019 LA, ASVspoof 2021 LA, and DF), we conduct a number of comparison experiments to verify the excellent performance of the proposed model in terms of accuracy, robustness, and trustworthiness.","authors":["Chi Ding","Junxiao Xue","Cong Wang","Hao Zhou"],"url":"https://arxiv.org/abs/2506.02401"}
{"created":"2025-06-04","title":"GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation","abstract":"Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: \\((i)\\) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. \\((ii)\\) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. \\((iii)\\) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.","authors":["Yilin Xiao","Junnan Dong","Chuang Zhou","Su Dong","Qianwen Zhang","Di Yin","Xing Sun","Xiao Huang"],"url":"https://arxiv.org/abs/2506.02404"}
{"created":"2025-06-04","title":"Modelship Attribution: Tracing Multi-Stage Manipulations Across Generative Models","abstract":"As generative techniques become increasingly accessible, authentic visuals are frequently subjected to iterative alterations by various individuals employing a variety of tools. Currently, to avoid misinformation and ensure accountability, a lot of research on detection and attribution is emerging. Although these methods demonstrate promise in single-stage manipulation scenarios, they fall short when addressing complex real-world iterative manipulation. In this paper, we are the first, to the best of our knowledge, to systematically model this real-world challenge and introduce a novel method to solve it. We define a task called \"Modelship Attribution\", which aims to trace the evolution of manipulated images by identifying the generative models involved and reconstructing the sequence of edits they performed. To realistically simulate this scenario, we utilize three generative models, StyleMapGAN, DiffSwap, and FacePartsSwap, that sequentially modify distinct regions of the same image. This process leads to the creation of the first modelship dataset, comprising 83,700 images (16,740 images*5). Given that later edits often overwrite the fingerprints of earlier models, the focus shifts from extracting blended fingerprints to characterizing each model's distinctive editing patterns. To tackle this challenge, we introduce the modelship attribution transformer (MAT), a purpose-built framework designed to effectively recognize and attribute the contributions of various models within complex, multi-stage manipulation workflows. Through extensive experiments and comparative analysis with other related methods, our results, including comprehensive ablation studies, demonstrate that the proposed approach is a highly effective solution for modelship attribution.","authors":["Zhiya Tan","Xin Zhang","Joey Tianyi Zhou"],"url":"https://arxiv.org/abs/2506.02405"}
{"created":"2025-06-04","title":"Random at First, Fast at Last: NTK-Guided Fourier Pre-Processing for Tabular DL","abstract":"While random Fourier features are a classic tool in kernel methods, their utility as a pre-processing step for deep learning on tabular data has been largely overlooked. Motivated by shortcomings in tabular deep learning pipelines - revealed through Neural Tangent Kernel (NTK) analysis - we revisit and repurpose random Fourier mappings as a parameter-free, architecture-agnostic transformation. By projecting each input into a fixed feature space via sine and cosine projections with frequencies drawn once at initialization, this approach circumvents the need for ad hoc normalization or additional learnable embeddings. We show within the NTK framework that this mapping (i) bounds and conditions the network's initial NTK spectrum, and (ii) introduces a bias that shortens the optimization trajectory, thereby accelerating gradient-based training. These effects pre-condition the network with a stable kernel from the outset. Empirically, we demonstrate that deep networks trained on Fourier-transformed inputs converge more rapidly and consistently achieve strong final performance, often with fewer epochs and less hyperparameter tuning. Our findings establish random Fourier pre-processing as a theoretically motivated, plug-and-play enhancement for tabular deep learning.","authors":["Renat Sergazinov","Jing Wu","Shao-An Yin"],"url":"https://arxiv.org/abs/2506.02406"}
{"created":"2025-06-04","title":"Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology","abstract":"Pre-trained encoders for offline feature extraction followed by multiple instance learning (MIL) aggregators have become the dominant paradigm in computational pathology (CPath), benefiting cancer diagnosis and prognosis. However, performance limitations arise from the absence of encoder fine-tuning for downstream tasks and disjoint optimization with MIL. While slide-level supervised end-to-end (E2E) learning is an intuitive solution to this issue, it faces challenges such as high computational demands and suboptimal results. These limitations motivate us to revisit E2E learning. We argue that prior work neglects inherent E2E optimization challenges, leading to performance disparities compared to traditional two-stage methods. In this paper, we pioneer the elucidation of optimization challenge caused by sparse-attention MIL and propose a novel MIL called ABMILX. It mitigates this problem through global correlation-based attention refinement and multi-head mechanisms. With the efficient multi-scale random patch sampling strategy, an E2E trained ResNet with ABMILX surpasses SOTA foundation models under the two-stage paradigm across multiple challenging benchmarks, while remaining computationally efficient (<10 RTX3090 hours). We show the potential of E2E learning in CPath and calls for greater research focus in this area. The code is https://github.com/DearCaat/E2E-WSI-ABMILX.","authors":["Wenhao Tang","Rong Qin","Heng Fang","Fengtao Zhou","Hao Chen","Xiang Li","Ming-Ming Cheng"],"url":"https://arxiv.org/abs/2506.02408"}
{"created":"2025-06-04","title":"SingaKids: A Multilingual Multimodal Dialogic Tutor for Language Learning","abstract":"The integration of generative artificial intelligence into educational applications has enhanced personalized and interactive learning experiences, and it shows strong potential to promote young learners language acquisition. However, it is still challenging to ensure consistent and robust performance across different languages and cultural contexts, and kids-friendly design requires simplified instructions, engaging interactions, and age-appropriate scaffolding to maintain motivation and optimize learning outcomes. In this work, we introduce SingaKids, a dialogic tutor designed to facilitate language learning through picture description tasks. Our system integrates dense image captioning, multilingual dialogic interaction, speech understanding, and engaging speech generation to create an immersive learning environment in four languages: English, Mandarin, Malay, and Tamil. We further improve the system through multilingual pre-training, task-specific tuning, and scaffolding optimization. Empirical studies with elementary school students demonstrate that SingaKids provides effective dialogic teaching, benefiting learners at different performance levels.","authors":["Zhengyuan Liu","Geyu Lin","Hui Li Tan","Huayun Zhang","Yanfeng Lu","Xiaoxue Gao","Stella Xin Yin","He Sun","Hock Huan Goh","Lung Hsiang Wong","Nancy F. Chen"],"url":"https://arxiv.org/abs/2506.02412"}
{"created":"2025-06-04","title":"StarVC: A Unified Auto-Regressive Framework for Joint Text and Speech Generation in Voice Conversion","abstract":"Voice Conversion (VC) modifies speech to match a target speaker while preserving linguistic content. Traditional methods usually extract speaker information directly from speech while neglecting the explicit utilization of linguistic content. Since VC fundamentally involves disentangling speaker identity from linguistic content, leveraging structured semantic features could enhance conversion performance. However, previous attempts to incorporate semantic features into VC have shown limited effectiveness, motivating the integration of explicit text modeling. We propose StarVC, a unified autoregressive VC framework that first predicts text tokens before synthesizing acoustic features. The experiments demonstrate that StarVC outperforms conventional VC methods in preserving both linguistic content (i.e., WER and CER) and speaker characteristics (i.e., SECS and MOS). Audio demo can be found at: https://thuhcsi.github.io/StarVC/.","authors":["Fengjin Li","Jie Wang","Yadong Niu","Yongqing Wang","Meng Meng","Jian Luan","Zhiyong Wu"],"url":"https://arxiv.org/abs/2506.02414"}
{"created":"2025-06-04","title":"AERO: A Redirection-Based Optimization Framework Inspired by Judo for Robust Probabilistic Forecasting","abstract":"Optimization remains a fundamental pillar of machine learning, yet existing methods often struggle to maintain stability and adaptability in dynamic, non linear systems, especially under uncertainty. We introduce AERO (Adversarial Energy-based Redirection Optimization), a novel framework inspired by the redirection principle in Judo, where external disturbances are leveraged rather than resisted. AERO reimagines optimization as a redirection process guided by 15 interrelated axioms encompassing adversarial correction, energy conservation, and disturbance-aware learning. By projecting gradients, integrating uncertainty driven dynamics, and managing learning energy, AERO offers a principled approach to stable and robust model updates. Applied to probabilistic solar energy forecasting, AERO demonstrates substantial gains in predictive accuracy, reliability, and adaptability, especially in noisy and uncertain environments. Our findings highlight AERO as a compelling new direction in the theoretical and practical landscape of optimization.","authors":["Karthikeyan Vaiapury"],"url":"https://arxiv.org/abs/2506.02415"}
{"created":"2025-06-04","title":"Guiding Registration with Emergent Similarity from Pre-Trained Diffusion Models","abstract":"Diffusion models, while trained for image generation, have emerged as powerful foundational feature extractors for downstream tasks. We find that off-the-shelf diffusion models, trained exclusively to generate natural RGB images, can identify semantically meaningful correspondences in medical images. Building on this observation, we propose to leverage diffusion model features as a similarity measure to guide deformable image registration networks. We show that common intensity-based similarity losses often fail in challenging scenarios, such as when certain anatomies are visible in one image but absent in another, leading to anatomically inaccurate alignments. In contrast, our method identifies true semantic correspondences, aligning meaningful structures while disregarding those not present across images. We demonstrate superior performance of our approach on two tasks: multimodal 2D registration (DXA to X-Ray) and monomodal 3D registration (brain-extracted to non-brain-extracted MRI). Code: https://github.com/uncbiag/dgir","authors":["Nurislam Tursynbek","Hastings Greer","Basar Demir","Marc Niethammer"],"url":"https://arxiv.org/abs/2506.02419"}
{"created":"2025-06-04","title":"Enhancing Convergence, Privacy and Fairness for Wireless Personalized Federated Learning: Quantization-Assisted Min-Max Fair Scheduling","abstract":"Personalized federated learning (PFL) offers a solution to balancing personalization and generalization by conducting federated learning (FL) to guide personalized learning (PL). Little attention has been given to wireless PFL (WPFL), where privacy concerns arise. Performance fairness of PL models is another challenge resulting from communication bottlenecks in WPFL. This paper exploits quantization errors to enhance the privacy of WPFL and proposes a novel quantization-assisted Gaussian differential privacy (DP) mechanism. We analyze the convergence upper bounds of individual PL models by considering the impact of the mechanism (i.e., quantization errors and Gaussian DP noises) and imperfect communication channels on the FL of WPFL. By minimizing the maximum of the bounds, we design an optimal transmission scheduling strategy that yields min-max fairness for WPFL with OFDMA interfaces. This is achieved by revealing the nested structure of this problem to decouple it into subproblems solved sequentially for the client selection, channel allocation, and power control, and for the learning rates and PL-FL weighting coefficients. Experiments validate our analysis and demonstrate that our approach substantially outperforms alternative scheduling strategies by 87.08%, 16.21%, and 38.37% in accuracy, the maximum test loss of participating clients, and fairness (Jain's index), respectively.","authors":["Xiyu Zhao","Qimei Cui","Ziqiang Du","Weicai Li","Xi Yu","Wei Ni","Ji Zhang","Xiaofeng Tao","Ping Zhang"],"url":"https://arxiv.org/abs/2506.02422"}
{"created":"2025-06-04","title":"An adaptive delaminating Levin method in two dimensions","abstract":"We present an adaptive delaminating Levin method for evaluating bivariate oscillatory integrals over rectangular domains. Whereas previous analyses of Levin methods impose non-resonance conditions that exclude stationary and resonance points, we rigorously establish the existence of a slowly-varying, approximate solution to the Levin PDE across all frequency regimes, even when the non-resonance condition is violated. This allows us to derive error estimates for the numerical solution of the Levin PDE via the Chebyshev spectral collocation method, and for the evaluation of the corresponding oscillatory integrals, showing that high accuracy can be achieved regardless of whether or not stationary and resonance points are present. We then present a Levin method incorporating adaptive subdivision in both two and one dimensions, as well as delaminating Chebyshev spectral collocation, which is effective in both the presence and absence of stationary and resonance points. We demonstrate the effectiveness of our algorithm with a number of numerical experiments.","authors":["Shukui Chen","Kirill Serkh","James Bremer","Murdock Aubry"],"url":"https://arxiv.org/abs/2506.02424"}
{"created":"2025-06-04","title":"Gender Inequality in English Textbooks Around the World: an NLP Approach","abstract":"Textbooks play a critical role in shaping children's understanding of the world. While previous studies have identified gender inequality in individual countries' textbooks, few have examined the issue cross-culturally. This study applies natural language processing methods to quantify gender inequality in English textbooks from 22 countries across 7 cultural spheres. Metrics include character count, firstness (which gender is mentioned first), and TF-IDF word associations by gender. The analysis also identifies gender patterns in proper names appearing in TF-IDF word lists, tests whether large language models can distinguish between gendered word lists, and uses GloVe embeddings to examine how closely keywords associate with each gender. Results show consistent overrepresentation of male characters in terms of count, firstness, and named entities. All regions exhibit gender inequality, with the Latin cultural sphere showing the least disparity.","authors":["Tairan Liu"],"url":"https://arxiv.org/abs/2506.02425"}
{"created":"2025-06-04","title":"Comparative Analysis of AI Agent Architectures for Entity Relationship Classification","abstract":"Entity relationship classification remains a challenging task in information extraction, especially in scenarios with limited labeled data and complex relational structures. In this study, we conduct a comparative analysis of three distinct AI agent architectures designed to perform relation classification using large language models (LLMs). The agentic architectures explored include (1) reflective self-evaluation, (2) hierarchical task decomposition, and (3) a novel multi-agent dynamic example generation mechanism, each leveraging different modes of reasoning and prompt adaptation. In particular, our dynamic example generation approach introduces real-time cooperative and adversarial prompting. We systematically compare their performance across multiple domains and model backends. Our experiments demonstrate that multi-agent coordination consistently outperforms standard few-shot prompting and approaches the performance of fine-tuned models. These findings offer practical guidance for the design of modular, generalizable LLM-based systems for structured relation extraction. The source codes and dataset are available at \\href{https://github.com/maryambrj/ALIEN.git}{https://github.com/maryambrj/ALIEN.git}.","authors":["Maryam Berijanian","Kuldeep Singh","Amin Sehati"],"url":"https://arxiv.org/abs/2506.02426"}
{"created":"2025-06-04","title":"Rust Implementation of Finite Element Exterior Calculus on Coordinate-Free Simplicial Complexes","abstract":"This thesis presents the development of a novel finite element library in Rust based on the principles of Finite Element Exterior Calculus (FEEC). The library solves partial differential equations formulated using differential forms on abstract, coordinate-free simplicial complexes in arbitrary dimensions, employing an intrinsic Riemannian metric derived from edge lengths via Regge Calculus. We focus on solving elliptic Hodge-Laplace eigenvalue and source problems on the nD de Rham complex. We restrict ourselves to first-order Whitney basis functions. The implementation is partially verified through convergence studies.","authors":["Luis Wirth"],"url":"https://arxiv.org/abs/2506.02429"}
{"created":"2025-06-04","title":"From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models","abstract":"Emotions are a fundamental facet of human experience, varying across individuals, cultural contexts, and nationalities. Given the recent success of Large Language Models (LLMs) as role-playing agents, we examine whether LLMs exhibit emotional stereotypes when assigned nationality-specific personas. Specifically, we investigate how different countries are represented in pre-trained LLMs through emotion attributions and whether these attributions align with cultural norms. Our analysis reveals significant nationality-based differences, with emotions such as shame, fear, and joy being disproportionately assigned across regions. Furthermore, we observe notable misalignment between LLM-generated and human emotional responses, particularly for negative emotions, highlighting the presence of reductive and potentially biased stereotypes in LLM outputs.","authors":["Mahammed Kamruzzaman","Abdullah Al Monsur","Gene Louis Kim","Anshuman Chhabra"],"url":"https://arxiv.org/abs/2506.02431"}
{"created":"2025-06-04","title":"Empowering Functional Neuroimaging: A Pre-trained Generative Framework for Unified Representation of Neural Signals","abstract":"Multimodal functional neuroimaging enables systematic analysis of brain mechanisms and provides discriminative representations for brain-computer interface (BCI) decoding. However, its acquisition is constrained by high costs and feasibility limitations. Moreover, underrepresentation of specific groups undermines fairness of BCI decoding model. To address these challenges, we propose a unified representation framework for multimodal functional neuroimaging via generative artificial intelligence (AI). By mapping multimodal functional neuroimaging into a unified representation space, the proposed framework is capable of generating data for acquisition-constrained modalities and underrepresented groups. Experiments show that the framework can generate data consistent with real brain activity patterns, provide insights into brain mechanisms, and improve performance on downstream tasks. More importantly, it can enhance model fairness by augmenting data for underrepresented groups. Overall, the framework offers a new paradigm for decreasing the cost of acquiring multimodal functional neuroimages and enhancing the fairness of BCI decoding models.","authors":["Weiheng Yao","Xuhang Chen","Shuqiang Wang"],"url":"https://arxiv.org/abs/2506.02433"}
{"created":"2025-06-04","title":"A Transformer-Based Neural Network for Optimal Deterministic-Allocation and Anonymous Joint Auction Design","abstract":"With the advancement of machine learning, an increasing number of studies are employing automated mechanism design (AMD) methods for optimal auction design. However, all previous AMD architectures designed to generate optimal mechanisms that satisfy near dominant strategy incentive compatibility (DSIC) fail to achieve deterministic allocation, and some also lack anonymity, thereby impacting the efficiency and fairness of advertising allocation. This has resulted in a notable discrepancy between the previous AMD architectures for generating near-DSIC optimal mechanisms and the demands of real-world advertising scenarios. In this paper, we prove that in all online advertising scenarios, previous non-deterministic allocation methods lead to the non-existence of feasible solutions, resulting in a gap between the rounded solution and the optimal solution. Furthermore, we propose JTransNet, a transformer-based neural network architecture, designed for optimal deterministic-allocation and anonymous joint auction design. Although the deterministic allocation module in JTransNet is designed for the latest joint auction scenarios, it can be applied to other non-deterministic AMD architectures with minor modifications. Additionally, our offline and online data experiments demonstrate that, in joint auction scenarios, JTransNet significantly outperforms baseline methods in terms of platform revenue, resulting in a substantial increase in platform earnings.","authors":["Zhen Zhang","Luowen Liu","Wanzhi Zhang","Zitian Guo","Kun Huang","Qi Qi","Qiang Liu","Xingxing Wang"],"url":"https://arxiv.org/abs/2506.02435"}
{"created":"2025-06-04","title":"A Review of Various Datasets for Machine Learning Algorithm-Based Intrusion Detection System: Advances and Challenges","abstract":"IDS aims to protect computer networks from security threats by detecting, notifying, and taking appropriate action to prevent illegal access and protect confidential information. As the globe becomes increasingly dependent on technology and automated processes, ensuring secured systems, applications, and networks has become one of the most significant problems of this era. The global web and digital technology have significantly accelerated the evolution of the modern world, necessitating the use of telecommunications and data transfer platforms. Researchers are enhancing the effectiveness of IDS by incorporating popular datasets into machine learning algorithms. IDS, equipped with machine learning classifiers, enhances security attack detection accuracy by identifying normal or abnormal network traffic. This paper explores the methods of capturing and reviewing intrusion detection systems (IDS) and evaluates the challenges existing datasets face. A deluge of research on machine learning (ML) and deep learning (DL) architecture-based intrusion detection techniques has been conducted in the past ten years on various cybersecurity datasets, including KDDCUP'99, NSL-KDD, UNSW-NB15, CICIDS-2017, and CSE-CIC-IDS2018. We conducted a literature review and presented an in-depth analysis of various intrusion detection methods that use SVM, KNN, DT, LR, NB, RF, XGBOOST, Adaboost, and ANN. We provide an overview of each technique, explaining the role of the classifiers and algorithms used. A detailed tabular analysis highlights the datasets used, classifiers employed, attacks detected, evaluation metrics, and conclusions drawn. This article offers a thorough review for future IDS research.","authors":["Sudhanshu Sekhar Tripathy","Bichitrananda Behera"],"url":"https://arxiv.org/abs/2506.02438"}
{"created":"2025-06-04","title":"Video-Level Language-Driven Video-Based Visible-Infrared Person Re-Identification","abstract":"Video-based Visible-Infrared Person Re-Identification (VVI-ReID) aims to match pedestrian sequences across modalities by extracting modality-invariant sequence-level features. As a high-level semantic representation, language provides a consistent description of pedestrian characteristics in both infrared and visible modalities. Leveraging the Contrastive Language-Image Pre-training (CLIP) model to generate video-level language prompts and guide the learning of modality-invariant sequence-level features is theoretically feasible. However, the challenge of generating and utilizing modality-shared video-level language prompts to address modality gaps remains a critical problem. To address this problem, we propose a simple yet powerful framework, video-level language-driven VVI-ReID (VLD), which consists of two core modules: invariant-modality language prompting (IMLP) and spatial-temporal prompting (STP). IMLP employs a joint fine-tuning strategy for the visual encoder and the prompt learner to effectively generate modality-shared text prompts and align them with visual features from different modalities in CLIP's multimodal space, thereby mitigating modality differences. Additionally, STP models spatiotemporal information through two submodules, the spatial-temporal hub (STH) and spatial-temporal aggregation (STA), which further enhance IMLP by incorporating spatiotemporal information into text prompts. The STH aggregates and diffuses spatiotemporal information into the [CLS] token of each frame across the vision transformer (ViT) layers, whereas STA introduces dedicated identity-level loss and specialized multihead attention to ensure that the STH focuses on identity-relevant spatiotemporal feature aggregation. The VLD framework achieves state-of-the-art results on two VVI-ReID benchmarks. The code will be released at https://github.com/Visuang/VLD.","authors":["Shuang Li","Jiaxu Leng","Changjiang Kuang","Mingpi Tan","Xinbo Gao"],"url":"https://arxiv.org/abs/2506.02439"}
{"created":"2025-06-04","title":"Should LLM Safety Be More Than Refusing Harmful Instructions?","abstract":"This paper presents a systematic evaluation of Large Language Models' (LLMs) behavior on long-tail distributed (encrypted) texts and their safety implications. We introduce a two-dimensional framework for assessing LLM safety: (1) instruction refusal-the ability to reject harmful obfuscated instructions, and (2) generation safety-the suppression of generating harmful responses. Through comprehensive experiments, we demonstrate that models that possess capabilities to decrypt ciphers may be susceptible to mismatched-generalization attacks: their safety mechanisms fail on at least one safety dimension, leading to unsafe responses or over-refusal. Based on these findings, we evaluate a number of pre-LLM and post-LLM safeguards and discuss their strengths and limitations. This work contributes to understanding the safety of LLM in long-tail text scenarios and provides directions for developing robust safety mechanisms.","authors":["Utsav Maskey","Mark Dras","Usman Naseem"],"url":"https://arxiv.org/abs/2506.02442"}
{"created":"2025-06-04","title":"Breaking the Barriers of Text-Hungry and Audio-Deficient AI","abstract":"While global linguistic diversity spans more than 7164 recognized languages, the current dominant architecture of machine intelligence remains fundamentally biased toward written text. This bias excludes over 700 million people particularly in rural and remote regions who are audio-literate. In this work, we introduce a fully textless, audio-to-audio machine intelligence framework designed to serve this underserved population, and all the people who prefer audio-efficiency. Our contributions include novel Audio-to-Audio translation architectures that bypass text entirely, including spectrogram-, scalogram-, wavelet-, and unit-based models. Central to our approach is the Multiscale Audio-Semantic Transform (MAST), a representation that encodes tonal, prosodic, speaker, and expressive features. We further integrate MAST into a fractional diffusion of mean-field-type framework powered by fractional Brownian motion. It enables the generation of high-fidelity, semantically consistent speech without reliance on textual supervision. The result is a robust and scalable system capable of learning directly from raw audio, even in languages that are unwritten or rarely digitized. This work represents a fundamental shift toward audio-native machine intelligence systems, expanding access to language technologies for communities historically left out of the current machine intelligence ecosystem.","authors":["Hamidou Tembine","Issa Bamia","Massa NDong","Bakary Coulibaly","Oumar Issiaka Traore","Moussa Traore","Moussa Sanogo","Mamadou Eric Sangare","Salif Kante","Daryl Noupa Yongueng","Hafiz Tiomoko Ali","Malik Tiomoko","Frejus Laleye","Boualem Djehiche","Wesmanegda Elisee Dipama","Idris Baba Saje","Hammid Mohammed Ibrahim","Moumini Sanogo","Marie Coursel Nininahazwe","Abdul-Latif Siita","Haine Mhlongo","Teddy Nelvy Dieu Merci Kouka","Mariam Serine Jeridi","Mutiyamuogo Parfait Mupenge","Lekoueiry Dehah","Abdoul Aziz Bio Sidi Bouko","Wilfried Franceslas Zokoue","Odette Richette Sambila","Alina RS Mbango","Mady Diagouraga","Oumarou Moussa Sanoussi","Gizachew Dessalegn","Mohamed Lamine Samoura","Bintou Laetitia Audrey Coulibaly"],"url":"https://arxiv.org/abs/2506.02443"}
{"created":"2025-06-04","title":"SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios","abstract":"Hand-Object Interaction (HOI) generation has significant application potential. However, current 3D HOI motion generation approaches heavily rely on predefined 3D object models and lab-captured motion data, limiting generalization capabilities. Meanwhile, HOI video generation methods prioritize pixel-level visual fidelity, often sacrificing physical plausibility. Recognizing that visual appearance and motion patterns share fundamental physical laws in the real world, we propose a novel framework that combines visual priors and dynamic constraints within a synchronized diffusion process to generate the HOI video and motion simultaneously. To integrate the heterogeneous semantics, appearance, and motion features, our method implements tri-modal adaptive modulation for feature aligning, coupled with 3D full-attention for modeling inter- and intra-modal dependencies. Furthermore, we introduce a vision-aware 3D interaction diffusion model that generates explicit 3D interaction sequences directly from the synchronized diffusion outputs, then feeds them back to establish a closed-loop feedback cycle. This architecture eliminates dependencies on predefined object models or explicit pose guidance while significantly enhancing video-motion consistency. Experimental results demonstrate our method's superiority over state-of-the-art approaches in generating high-fidelity, dynamically plausible HOI sequences, with notable generalization capabilities in unseen real-world scenarios. Project page at \\href{https://github.com/Droliven}{https://github.com/Droliven}.","authors":["Lingwei Dang","Ruizhi Shao","Hongwen Zhang","Wei Min","Yebin Liu","Qingyao Wu"],"url":"https://arxiv.org/abs/2506.02444"}
{"created":"2025-06-04","title":"Visualization for interactively adjusting the de-bias effect of word embedding","abstract":"Word embedding, which converts words into numerical values, is an important natural language processing technique and widely used. One of the serious problems of word embedding is that the bias will be learned and affect the model if the dataset used for pre-training contains bias. On the other hand, indiscriminate removal of bias from word embeddings may result in the loss of information, even if the bias is undesirable to us. As a result, a risk of model performance degradation due to bias removal will be another problem. As a solution to this problem, we focus on gender bias in Japanese and propose an interactive visualization method to adjust the degree of debias for each word category. Specifically, we visualize the accuracy in a category classification task after debiasing, and allow the user to adjust the parameters based on the visualization results, so that the debiasing can be adjusted according to the user's objectives. In addition, considering a trade-off between debiasing and preventing degradation of model performance, and that different people perceive gender bias differently, we developed a mechanism to present multiple choices of debiasing configurations applying an optimization scheme. This paper presents the results of an experiment in which we removed the gender bias for word embeddings learned from the Japanese version of Wikipedia. We classified words into five categories based on a news corpus, and observed that the degree of influence of debiasing differed greatly among the categories. We then adjusted the degree of debiasing for each category based on the visualization results.","authors":["Arisa Sugino","Takayuki Itoh"],"url":"https://arxiv.org/abs/2506.02447"}
{"created":"2025-06-04","title":"VidEvent: A Large Dataset for Understanding Dynamic Evolution of Events in Videos","abstract":"Despite the significant impact of visual events on human cognition, understanding events in videos remains a challenging task for AI due to their complex structures, semantic hierarchies, and dynamic evolution. To address this, we propose the task of video event understanding that extracts event scripts and makes predictions with these scripts from videos. To support this task, we introduce VidEvent, a large-scale dataset containing over 23,000 well-labeled events, featuring detailed event structures, broad hierarchies, and logical relations extracted from movie recap videos. The dataset was created through a meticulous annotation process, ensuring high-quality and reliable event data. We also provide comprehensive baseline models offering detailed descriptions of their architecture and performance metrics. These models serve as benchmarks for future research, facilitating comparisons and improvements. Our analysis of VidEvent and the baseline models highlights the dataset's potential to advance video event understanding and encourages the exploration of innovative algorithms and models. The dataset and related resources are publicly available at www.videvent.top.","authors":["Baoyu Liang","Qile Su","Shoutai Zhu","Yuchen Liang","Chao Tong"],"url":"https://arxiv.org/abs/2506.02448"}
{"created":"2025-06-04","title":"IP-Dialog: Evaluating Implicit Personalization in Dialogue Systems with Synthetic Data","abstract":"In modern dialogue systems, the ability to implicitly infer user backgrounds from conversations and leverage this information for personalized assistance is crucial. However, the scarcity of high-quality data remains a fundamental challenge to evaluating and improving this capability. Traditional dataset construction methods are labor-intensive, resource-demanding, and raise privacy concerns. To address these issues, we propose a novel approach for automatic synthetic data generation and introduce the Implicit Personalized Dialogue (IP-Dialog) benchmark along with a training dataset, covering 10 tasks and 12 user attribute types. Additionally, we develop a systematic evaluation framework with four metrics to assess both attribute awareness and reasoning capabilities. We further propose five causal graphs to elucidate models' reasoning pathways during implicit personalization. Extensive experiments yield insightful observations and prove the reliability of our dataset.","authors":["Bo Peng","Zhiheng Wang","Heyang Gong","Chaochao Lu"],"url":"https://arxiv.org/abs/2506.02449"}
{"created":"2025-06-04","title":"Weak Supervision for Real World Graphs","abstract":"Node classification in real world graphs often suffers from label scarcity and noise, especially in high stakes domains like human trafficking detection and misinformation monitoring. While direct supervision is limited, such graphs frequently contain weak signals, noisy or indirect cues, that can still inform learning. We propose WSNET, a novel weakly supervised graph contrastive learning framework that leverages these weak signals to guide robust representation learning. WSNET integrates graph structure, node features, and multiple noisy supervision sources through a contrastive objective tailored for weakly labeled data. Across three real world datasets and synthetic benchmarks with controlled noise, WSNET consistently outperforms state of the art contrastive and noisy label learning methods by up to 15% in F1 score. Our results highlight the effectiveness of contrastive learning under weak supervision and the promise of exploiting imperfect labels in graph based settings.","authors":["Pratheeksha Nair","Reihaneh Rabbany"],"url":"https://arxiv.org/abs/2506.02451"}
{"created":"2025-06-04","title":"ANT: Adaptive Neural Temporal-Aware Text-to-Motion Model","abstract":"While diffusion models advance text-to-motion generation, their static semantic conditioning ignores temporal-frequency demands: early denoising requires structural semantics for motion foundations while later stages need localized details for text alignment. This mismatch mirrors biological morphogenesis where developmental phases demand distinct genetic programs. Inspired by epigenetic regulation governing morphological specialization, we propose **(ANT)**, an **A**daptive **N**eural **T**emporal-Aware architecture. ANT orchestrates semantic granularity through: **(i) Semantic Temporally Adaptive (STA) Module:** Automatically partitions denoising into low-frequency structural planning and high-frequency refinement via spectral analysis. **(ii) Dynamic Classifier-Free Guidance scheduling (DCFG):** Adaptively adjusts conditional to unconditional ratio enhancing efficiency while maintaining fidelity. **(iii) Temporal-semantic reweighting:** Quantitatively aligns text influence with phase requirements. Extensive experiments show that ANT can be applied to various baselines, significantly improving model performance, and achieving state-of-the-art semantic alignment on StableMoFusion.","authors":["Wenshuo Chen","Kuimou Yu","Haozhe Jia","Kaishen Yuan","Bowen Tian","Songning Lai","Hongru Xiao","Erhang Zhang","Lei Wang","Yutao Yue"],"url":"https://arxiv.org/abs/2506.02452"}
{"created":"2025-06-04","title":"PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation","abstract":"Continual Test-Time Adaptation (CTTA) aims to online adapt a pre-trained model to changing environments during inference. Most existing methods focus on exploiting target data, while overlooking another crucial source of information, the pre-trained weights, which encode underutilized domain-invariant priors. This paper takes the geometric attributes of pre-trained weights as a starting point, systematically analyzing three key components: magnitude, absolute angle, and pairwise angular structure. We find that the pairwise angular structure remains stable across diverse corrupted domains and encodes domain-invariant semantic information, suggesting it should be preserved during adaptation. Based on this insight, we propose PAID (Pairwise Angular-Invariant Decomposition), a prior-driven CTTA method that decomposes weight into magnitude and direction, and introduces a learnable orthogonal matrix via Householder reflections to globally rotate direction while preserving the pairwise angular structure. During adaptation, only the magnitudes and the orthogonal matrices are updated. PAID achieves consistent improvements over recent SOTA methods on four widely used CTTA benchmarks, demonstrating that preserving pairwise angular structure offers a simple yet effective principle for CTTA.","authors":["Kunyu Wang","Xueyang Fu","Yunfei Bao","Chengjie Ge","Chengzhi Cao","Wei Zhai","Zheng-Jun Zha"],"url":"https://arxiv.org/abs/2506.02453"}
{"created":"2025-06-04","title":"Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework","abstract":"Visualizations play a crucial part in effective communication of concepts and information. Recent advances in reasoning and retrieval augmented generation have enabled Large Language Models (LLMs) to perform deep research and generate comprehensive reports. Despite its progress, existing deep research frameworks primarily focus on generating text-only content, leaving the automated generation of interleaved texts and visualizations underexplored. This novel task poses key challenges in designing informative visualizations and effectively integrating them with text reports. To address these challenges, we propose Formal Description of Visualization (FDV), a structured textual representation of charts that enables LLMs to learn from and generate diverse, high-quality visualizations. Building on this representation, we introduce Multimodal DeepResearcher, an agentic framework that decomposes the task into four stages: (1) researching, (2) exemplar report textualization, (3) planning, and (4) multimodal report generation. For the evaluation of generated multimodal reports, we develop MultimodalReportBench, which contains 100 diverse topics served as inputs along with 5 dedicated metrics. Extensive experiments across models and evaluation methods demonstrate the effectiveness of Multimodal DeepResearcher. Notably, utilizing the same Claude 3.7 Sonnet model, Multimodal DeepResearcher achieves an 82\\% overall win rate over the baseline method.","authors":["Zhaorui Yang","Bo Pan","Han Wang","Yiyao Wang","Xingyu Liu","Minfeng Zhu","Bo Zhang","Wei Chen"],"url":"https://arxiv.org/abs/2506.02454"}
{"created":"2025-06-04","title":"VPI-Bench: Visual Prompt Injection Attacks for Computer-Use Agents","abstract":"Computer-Use Agents (CUAs) with full system access enable powerful task automation but pose significant security and privacy risks due to their ability to manipulate files, access user data, and execute arbitrary commands. While prior work has focused on browser-based agents and HTML-level attacks, the vulnerabilities of CUAs remain underexplored. In this paper, we investigate Visual Prompt Injection (VPI) attacks, where malicious instructions are visually embedded within rendered user interfaces, and examine their impact on both CUAs and Browser-Use Agents (BUAs). We propose VPI-Bench, a benchmark of 306 test cases across five widely used platforms, to evaluate agent robustness under VPI threats. Each test case is a variant of a web platform, designed to be interactive, deployed in a realistic environment, and containing a visually embedded malicious prompt. Our empirical study shows that current CUAs and BUAs can be deceived at rates of up to 51% and 100%, respectively, on certain platforms. The experimental results also indicate that system prompt defenses offer only limited improvements. These findings highlight the need for robust, context-aware defenses to ensure the safe deployment of multimodal AI agents in real-world environments. The code and dataset are available at: https://github.com/cua-framework/agents","authors":["Tri Cao","Bennett Lim","Yue Liu","Yuan Sui","Yuexin Li","Shumin Deng","Lin Lu","Nay Oo","Shuicheng Yan","Bryan Hooi"],"url":"https://arxiv.org/abs/2506.02456"}
{"created":"2025-06-04","title":"SOVA-Bench: Benchmarking the Speech Conversation Ability for LLM-based Voice Assistant","abstract":"Thanks to the steady progress of large language models (LLMs), speech encoding algorithms and vocoder structure, recent advancements have enabled generating speech response directly from a user instruction. However, benchmarking the generated speech quality has been a neglected but critical issue, considering the shift from the pursuit of semantic accuracy to vivid and spontaneous speech flow. Previous evaluation focused on the speech-understanding ability, lacking a quantification of acoustic quality. In this paper, we propose Speech cOnversational Voice Assistant Benchmark (SOVA-Bench), providing a comprehension comparison of the general knowledge, speech recognition and understanding, along with both semantic and acoustic generative ability between available speech LLMs. To the best of our knowledge, SOVA-Bench is one of the most systematic evaluation frameworks for speech LLMs, inspiring the direction of voice interaction systems.","authors":["Yixuan Hou","Heyang Liu","Yuhao Wang","Ziyang Cheng","Ronghua Wu","Qunshan Gu","Yanfeng Wang","Yu Wang"],"url":"https://arxiv.org/abs/2506.02457"}
{"created":"2025-06-04","title":"A Novel Deep Reinforcement Learning Method for Computation Offloading in Multi-User Mobile Edge Computing with Decentralization","abstract":"Mobile edge computing (MEC) allows appliances to offload workloads to neighboring MEC servers that have the potential for computation-intensive tasks with limited computational capabilities. This paper studied how deep reinforcement learning (DRL) algorithms are used in an MEC system to find feasible decentralized dynamic computation offloading strategies, which leads to the construction of an extensible MEC system that operates effectively with finite feedback. Even though the Deep Deterministic Policy Gradient (DDPG) algorithm, subject to their knowledge of the MEC system, can be used to allocate powers of both computation offloading and local execution, to learn a computation offloading policy for each user independently, we realized that this solution still has some inherent weaknesses. Hence, we introduced a new approach for this problem based on the Twin Delayed DDPG algorithm, which enables us to overcome this proneness and investigate cases where mobile users are portable. Numerical results showed that individual users can autonomously learn adequate policies through the proposed approach. Besides, the performance of the suggested solution exceeded the conventional DDPG-based power control strategy.","authors":["Nguyen Chi Long","Trinh Van Chien","Ta Hai Tung","Van Son Nguyen","Trong-Minh Hoang","Nguyen Ngoc Hai Dang"],"url":"https://arxiv.org/abs/2506.02458"}
{"created":"2025-06-04","title":"ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment","abstract":"Scene synthesis and editing has emerged as a promising direction in computer graphics. Current trained approaches for 3D indoor scenes either oversimplify object semantics through one-hot class encodings (e.g., 'chair' or 'table'), require masked diffusion for editing, ignore room boundaries, or rely on floor plan renderings that fail to capture complex layouts. In contrast, LLM-based methods enable richer semantics via natural language (e.g., 'modern studio with light wood furniture') but do not support editing, remain limited to rectangular layouts or rely on weak spatial reasoning from implicit world models. We introduce ReSpace, a generative framework for text-driven 3D indoor scene synthesis and editing using autoregressive language models. Our approach features a compact structured scene representation with explicit room boundaries that frames scene editing as a next-token prediction task. We leverage a dual-stage training approach combining supervised fine-tuning and preference alignment, enabling a specially trained language model for object addition that accounts for user instructions, spatial geometry, object semantics, and scene-level composition. For scene editing, we employ a zero-shot LLM to handle object removal and prompts for addition. We further introduce a novel voxelization-based evaluation that captures fine-grained geometry beyond 3D bounding boxes. Experimental results surpass state-of-the-art on object addition while maintaining competitive results on full scene synthesis.","authors":["Martin JJ. Bucher","Iro Armeni"],"url":"https://arxiv.org/abs/2506.02459"}
{"created":"2025-06-04","title":"MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework","abstract":"As large language models (LLMs) are increasingly applied across various domains, enhancing safety while maintaining the helpfulness of LLMs has become a critical challenge. Recent studies solve this problem through safety-constrained online preference optimization or safety-constrained offline preference optimization. However, the safety-constrained online methods often suffer from excessive safety, which might reduce helpfulness, while the safety-constrained offline methods perform poorly in adaptively balancing safety and helpfulness. To address these limitations, we propose MidPO, a \\textbf{\\underline{Mi}}xture of Experts (MoE) framework for safety-helpfulness \\textbf{\\underline{d}}ual \\textbf{\\underline{P}}reference \\textbf{\\underline{O}}ptimization. Firstly, MidPO devises single-preference enhanced direct preference optimization approach to transform the base model into two independent experts, termed safety and helpfulness experts, and fine-tunes the two independent experts for optimal safety or helpfulness performance. Secondly, to achieve an effective balance between safety and helpfulness, MidPO incorporates the two experts into the MoE framework and designs a dynamic routing mechanism to allocate contributions from each expert adaptively. We conduct quantitative and qualitative experiments on three popular datasets to demonstrate the proposed MidPO significantly outperforms state-of-the-art approaches in both safety and helpfulness. The code and models will be released.","authors":["Yupeng Qi","Ziyu Lyu","Min Yang","Yanlin Wang","Lu Bai","Lixin Cui"],"url":"https://arxiv.org/abs/2506.02460"}
{"created":"2025-06-04","title":"XToM: Exploring the Multilingual Theory of Mind for Large Language Models","abstract":"Theory of Mind (ToM), the ability to infer mental states in others, is pivotal for human social cognition. Existing evaluations of ToM in LLMs are largely limited to English, neglecting the linguistic diversity that shapes human cognition. This limitation raises a critical question: can LLMs exhibit Multilingual Theory of Mind, which is the capacity to reason about mental states across diverse linguistic contexts? To address this gap, we present XToM, a rigorously validated multilingual benchmark that evaluates ToM across five languages and incorporates diverse, contextually rich task scenarios. Using XToM, we systematically evaluate LLMs (e.g., DeepSeek R1), revealing a pronounced dissonance: while models excel in multilingual language understanding, their ToM performance varies across languages. Our findings expose limitations in LLMs' ability to replicate human-like mentalizing across linguistic contexts.","authors":["Chunkit Chan","Yauwai Yim","Hongchuan Zeng","Zhiying Zou","Xinyuan Cheng","Zhifan Sun","Zheye Deng","Kawai Chung","Yuzhuo Ao","Yixiang Fan","Cheng Jiayang","Ercong Nie","Ginny Y. Wong","Helmut Schmid","Hinrich Sch\\\"utze","Simon See","Yangqiu Song"],"url":"https://arxiv.org/abs/2506.02461"}
{"created":"2025-06-04","title":"Efficient Test-time Adaptive Object Detection via Sensitivity-Guided Pruning","abstract":"Continual test-time adaptive object detection (CTTA-OD) aims to online adapt a source pre-trained detector to ever-changing environments during inference under continuous domain shifts. Most existing CTTA-OD methods prioritize effectiveness while overlooking computational efficiency, which is crucial for resource-constrained scenarios. In this paper, we propose an efficient CTTA-OD method via pruning. Our motivation stems from the observation that not all learned source features are beneficial; certain domain-sensitive feature channels can adversely affect target domain performance. Inspired by this, we introduce a sensitivity-guided channel pruning strategy that quantifies each channel based on its sensitivity to domain discrepancies at both image and instance levels. We apply weighted sparsity regularization to selectively suppress and prune these sensitive channels, focusing adaptation efforts on invariant ones. Additionally, we introduce a stochastic channel reactivation mechanism to restore pruned channels, enabling recovery of potentially useful features and mitigating the risks of early pruning. Extensive experiments on three benchmarks show that our method achieves superior adaptation performance while reducing computational overhead by 12% in FLOPs compared to the recent SOTA method.","authors":["Kunyu Wang","Xueyang Fu","Xin Lu","Chengjie Ge","Chengzhi Cao","Wei Zhai","Zheng-Jun Zha"],"url":"https://arxiv.org/abs/2506.02462"}
{"created":"2025-06-04","title":"A Smart Multimodal Healthcare Copilot with Powerful LLM Reasoning","abstract":"Misdiagnosis causes significant harm to healthcare systems worldwide, leading to increased costs and patient risks. MedRAG is a smart multimodal healthcare copilot equipped with powerful large language model (LLM) reasoning, designed to enhance medical decision-making. It supports multiple input modalities, including non-intrusive voice monitoring, general medical queries, and electronic health records. MedRAG provides recommendations on diagnosis, treatment, medication, and follow-up questioning. Leveraging retrieval-augmented generation enhanced by knowledge graph-elicited reasoning, MedRAG retrieves and integrates critical diagnostic insights, reducing the risk of misdiagnosis. It has been evaluated on both public and private datasets, outperforming existing models and offering more specific and accurate healthcare assistance. A demonstration video of MedRAG is available at: https://www.youtube.com/watch?v=PNIBDMYRfDM. The source code is available at: https://github.com/SNOWTEAM2023/MedRAG.","authors":["Xuejiao Zhao","Siyan Liu","Su-Yin Yang","Chunyan Miao"],"url":"https://arxiv.org/abs/2506.02470"}
{"created":"2025-06-04","title":"HRTR: A Single-stage Transformer for Fine-grained Sub-second Action Segmentation in Stroke Rehabilitation","abstract":"Stroke rehabilitation often demands precise tracking of patient movements to monitor progress, with complexities of rehabilitation exercises presenting two critical challenges: fine-grained and sub-second (under one-second) action detection. In this work, we propose the High Resolution Temporal Transformer (HRTR), to time-localize and classify high-resolution (fine-grained), sub-second actions in a single-stage transformer, eliminating the need for multi-stage methods and post-processing. Without any refinements, HRTR outperforms state-of-the-art systems on both stroke related and general datasets, achieving Edit Score (ES) of 70.1 on StrokeRehab Video, 69.4 on StrokeRehab IMU, and 88.4 on 50Salads.","authors":["Halil Ismail Helvaci","Justin Philip Huber","Jihye Bae","Sen-ching Samson Cheung"],"url":"https://arxiv.org/abs/2506.02472"}
{"created":"2025-06-04","title":"Generative Perception of Shape and Material from Differential Motion","abstract":"Perceiving the shape and material of an object from a single image is inherently ambiguous, especially when lighting is unknown and unconstrained. Despite this, humans can often disentangle shape and material, and when they are uncertain, they often move their head slightly or rotate the object to help resolve the ambiguities. Inspired by this behavior, we introduce a novel conditional denoising-diffusion model that generates samples of shape-and-material maps from a short video of an object undergoing differential motions. Our parameter-efficient architecture allows training directly in pixel-space, and it generates many disentangled attributes of an object simultaneously. Trained on a modest number of synthetic object-motion videos with supervision on shape and material, the model exhibits compelling emergent behavior: For static observations, it produces diverse, multimodal predictions of plausible shape-and-material maps that capture the inherent ambiguities; and when objects move, the distributions quickly converge to more accurate explanations. The model also produces high-quality shape-and-material estimates for less ambiguous, real-world objects. By moving beyond single-view to continuous motion observations, our work suggests a generative perception approach for improving visual reasoning in physically-embodied systems.","authors":["Xinran Nicole Han","Ko Nishino","Todd Zickler"],"url":"https://arxiv.org/abs/2506.02473"}
{"created":"2025-06-04","title":"Comba: Improving Nonlinear RNNs with Closed-loop Control","abstract":"Recent efficient sequence modeling methods such as Gated DeltaNet, TTT, and RWKV-7 have achieved performance improvements by supervising the recurrent memory management through Delta learning rule. Unlike previous state-space models (e.g., Mamba) and gated linear attentions (e.g., GLA), these models introduce interactions between the recurrent state and the key vector, resulting in a nonlinear recursive structure. In this paper, we first introduce the concept of Nonlinear RNNs with a comprehensive analysis on the advantages and limitations of these models. Then, based on closed-loop control theory, we propose a novel Nonlinear RNN variant named Comba, which adopts a scalar-plus-low-rank state transition, with both state feedback and output feedback corrections. We also implement a hardware-efficient chunk-wise parallel kernel in Triton and train models with 340M/1.3B parameters on large-scale corpus. Comba demonstrates its superior performance and computation efficiency in both language and vision modeling.","authors":["Jiaxi Hu","Yongqi Pan","Jusen Du","Disen Lan","Xiaqiang Tang","Qingsong Wen","Yuxuan Liang","Weigao Sun"],"url":"https://arxiv.org/abs/2506.02475"}
{"created":"2025-06-04","title":"Towards Better De-raining Generalization via Rainy Characteristics Memorization and Replay","abstract":"Current image de-raining methods primarily learn from a limited dataset, leading to inadequate performance in varied real-world rainy conditions. To tackle this, we introduce a new framework that enables networks to progressively expand their de-raining knowledge base by tapping into a growing pool of datasets, significantly boosting their adaptability. Drawing inspiration from the human brain's ability to continuously absorb and generalize from ongoing experiences, our approach borrow the mechanism of the complementary learning system. Specifically, we first deploy Generative Adversarial Networks (GANs) to capture and retain the unique features of new data, mirroring the hippocampus's role in learning and memory. Then, the de-raining network is trained with both existing and GAN-synthesized data, mimicking the process of hippocampal replay and interleaved learning. Furthermore, we employ knowledge distillation with the replayed data to replicate the synergy between the neocortex's activity patterns triggered by hippocampal replays and the pre-existing neocortical knowledge. This comprehensive framework empowers the de-raining network to amass knowledge from various datasets, continually enhancing its performance on previously unseen rainy scenes. Our testing on three benchmark de-raining networks confirms the framework's effectiveness. It not only facilitates continuous knowledge accumulation across six datasets but also surpasses state-of-the-art methods in generalizing to new real-world scenarios.","authors":["Kunyu Wang","Xueyang Fu","Chengzhi Cao","Chengjie Ge","Wei Zhai","Zheng-Jun Zha"],"url":"https://arxiv.org/abs/2506.02477"}
{"created":"2025-06-04","title":"FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging","abstract":"With the development of large language models, fine-tuning has emerged as an effective method to enhance performance in specific scenarios by injecting domain-specific knowledge. In this context, model merging techniques provide a solution for fusing knowledge from multiple fine-tuning models by combining their parameters. However, traditional methods often encounter task interference when merging full fine-tuning models, and this problem becomes even more evident in parameter-efficient fine-tuning scenarios. In this paper, we introduce an improvement to the RegMean method, which indirectly leverages the training data to approximate the outputs of the linear layers before and after merging. We propose an adaptive merging method called FroM, which directly measures the model parameters using the Frobenius norm, without any training data. By introducing an additional hyperparameter for control, FroM outperforms baseline methods across various fine-tuning scenarios, alleviating the task interference problem.","authors":["Zijian Li","Xiaocheng Feng","Huixin Liu","Yichong Huang","Ting Liu","Bing Qin"],"url":"https://arxiv.org/abs/2506.02478"}
{"created":"2025-06-04","title":"BitBypass: A New Direction in Jailbreaking Aligned Large Language Models with Bitstream Camouflage","abstract":"The inherent risk of generating harmful and unsafe content by Large Language Models (LLMs), has highlighted the need for their safety alignment. Various techniques like supervised fine-tuning, reinforcement learning from human feedback, and red-teaming were developed for ensuring the safety alignment of LLMs. However, the robustness of these aligned LLMs is always challenged by adversarial attacks that exploit unexplored and underlying vulnerabilities of the safety alignment. In this paper, we develop a novel black-box jailbreak attack, called BitBypass, that leverages hyphen-separated bitstream camouflage for jailbreaking aligned LLMs. This represents a new direction in jailbreaking by exploiting fundamental information representation of data as continuous bits, rather than leveraging prompt engineering or adversarial manipulations. Our evaluation of five state-of-the-art LLMs, namely GPT-4o, Gemini 1.5, Claude 3.5, Llama 3.1, and Mixtral, in adversarial perspective, revealed the capabilities of BitBypass in bypassing their safety alignment and tricking them into generating harmful and unsafe content. Further, we observed that BitBypass outperforms several state-of-the-art jailbreak attacks in terms of stealthiness and attack success. Overall, these results highlights the effectiveness and efficiency of BitBypass in jailbreaking these state-of-the-art LLMs.","authors":["Kalyan Nakka","Nitesh Saxena"],"url":"https://arxiv.org/abs/2506.02479"}
{"created":"2025-06-04","title":"ORPP: Self-Optimizing Role-playing Prompts to Enhance Language Model Capabilities","abstract":"High-quality prompts are crucial for eliciting outstanding performance from large language models (LLMs) on complex tasks. Existing research has explored model-driven strategies for prompt optimization. However, these methods often suffer from high computational overhead or require strong optimization capabilities from the model itself, which limits their broad applicability.To address these challenges, we propose ORPP (Optimized Role-Playing Prompt),a framework that enhances model performance by optimizing and generating role-playing prompts. The core idea of ORPP is to confine the prompt search space to role-playing scenarios, thereby fully activating the model's intrinsic capabilities through carefully crafted, high-quality role-playing prompts. Specifically, ORPP first performs iterative optimization on a small subset of training samples to generate high-quality role-playing prompts. Then, leveraging the model's few-shot learning capability, it transfers the optimization experience to efficiently generate suitable prompts for the remaining samples.Our experimental results show that ORPP not only matches but in most cases surpasses existing mainstream prompt optimization methods in terms of performance. Notably, ORPP demonstrates superior \"plug-and-play\" capability. In most cases, it can be integrated with various other prompt methods and further enhance their effectiveness.","authors":["Yifan Duan","Yihong Tang","Kehai Chen","Liqiang Nie","Min Zhang"],"url":"https://arxiv.org/abs/2506.02480"}
{"created":"2025-06-04","title":"Do Language Models Think Consistently? A Study of Value Preferences Across Varying Response Lengths","abstract":"Evaluations of LLMs' ethical risks and value inclinations often rely on short-form surveys and psychometric tests, yet real-world use involves long-form, open-ended responses -- leaving value-related risks and preferences in practical settings largely underexplored. In this work, we ask: Do value preferences inferred from short-form tests align with those expressed in long-form outputs? To address this question, we compare value preferences elicited from short-form reactions and long-form responses, varying the number of arguments in the latter to capture users' differing verbosity preferences. Analyzing five LLMs (llama3-8b, gemma2-9b, mistral-7b, qwen2-7b, and olmo-7b), we find (1) a weak correlation between value preferences inferred from short-form and long-form responses across varying argument counts, and (2) similarly weak correlation between preferences derived from any two distinct long-form generation settings. (3) Alignment yields only modest gains in the consistency of value expression. Further, we examine how long-form generation attributes relate to value preferences, finding that argument specificity negatively correlates with preference strength, while representation across scenarios shows a positive correlation. Our findings underscore the need for more robust methods to ensure consistent value expression across diverse applications.","authors":["Inderjeet Nair","Lu Wang"],"url":"https://arxiv.org/abs/2506.02481"}
{"created":"2025-06-04","title":"Building a Recommendation System Using Amazon Product Co-Purchasing Network","abstract":"This project develops an online, inductive recommendation system for newly listed products on e-commerce platforms, focusing on suggesting relevant new items to customers as they purchase other products. Using the Amazon Product Co-Purchasing Network Metadata dataset, we construct a co-purchasing graph where nodes represent products and edges capture co-purchasing relationships. To address the challenge of recommending new products with limited information, we apply a modified GraphSAGE method for link prediction. This inductive approach leverages both product features and the existing co-purchasing graph structure to predict potential co-purchasing relationships, enabling the model to generalize to unseen products. As an online method, it updates in real time, making it scalable and adaptive to evolving product catalogs. Experimental results demonstrate that our approach outperforms baseline algorithms in predicting relevant product links, offering a promising solution for enhancing the relevance of new product recommendations in e-commerce environments. All code is available at https://github.com/cse416a-fl24/final-project-l-minghao_z-catherine_z-nathan.git.","authors":["Minghao Liu","Catherine Zhao","Nathan Zhou"],"url":"https://arxiv.org/abs/2506.02482"}
{"created":"2025-06-04","title":"Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual Tasks","abstract":"Large language models (LLMs) often struggle to perform multi-target reasoning in long-context scenarios where relevant information is scattered across extensive documents. To address this challenge, we introduce NeuroSymbolic Augmented Reasoning (NSAR), which combines the benefits of neural and symbolic reasoning during inference. NSAR explicitly extracts symbolic facts from text and generates executable Python code to handle complex reasoning steps. Through extensive experiments across seven languages and diverse context lengths, we demonstrate that NSAR significantly outperforms both a vanilla RAG baseline and advanced prompting strategies in accurately identifying and synthesizing multiple pieces of information. Our results highlight the effectiveness of combining explicit symbolic operations with neural inference for robust, interpretable, and scalable reasoning in multilingual settings.","authors":["Sina Bagheri Nezhad","Ameeta Agrawal"],"url":"https://arxiv.org/abs/2506.02483"}
{"created":"2025-06-04","title":"Generative AI for Predicting 2D and 3D Wildfire Spread: Beyond Physics-Based Models and Traditional Deep Learning","abstract":"Wildfires continue to inflict devastating human, environmental, and economic losses globally, as tragically exemplified by the 2025 Los Angeles wildfire and the urgent demand for more effective response strategies. While physics-based and deep learning models have advanced wildfire simulation, they face critical limitations in predicting and visualizing multimodal fire spread in real time, particularly in both 2D and 3D spatial domains using dynamically updated GIS data. These limitations hinder timely emergency response, infrastructure protection, and community safety. Generative AI has recently emerged as a transformative approach across research and industry. Models such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Transformers, and diffusion-based architectures offer distinct advantages over traditional methods, including the integration of multimodal data, generation of diverse scenarios under uncertainty, and improved modeling of wildfire dynamics across spatial and temporal scales. This position paper advocates for the adoption of generative AI as a foundational framework for wildfire prediction. We explore how such models can enhance 2D fire spread forecasting and enable more realistic, scalable 3D simulations. Additionally, we employ a novel human-AI collaboration framework using large language models (LLMs) for automated knowledge extraction, literature synthesis, and bibliometric mapping. Looking ahead, we identify five key visions for integrating generative AI into wildfire management: multimodal approaches, AI foundation models, conversational AI systems, edge-computing-based scenario generation, and cognitive digital twins. We also address three major challenges accompanying these opportunities and propose potential solutions to support their implementation.","authors":["Haowen Xu","Sisi Zlatanova","Ruiyu Liang","Ismet Canbulat"],"url":"https://arxiv.org/abs/2506.02485"}
{"created":"2025-06-04","title":"DiOMP-Offloading: Toward Portable Distributed Heterogeneous OpenMP","abstract":"As core counts and heterogeneity rise in HPC, traditional hybrid programming models face challenges in managing distributed GPU memory and ensuring portability. This paper presents DiOMP, a distributed OpenMP framework that unifies OpenMP target offloading with the Partitioned Global Address Space (PGAS) model. Built atop LLVM/OpenMP and using GASNet-EX or GPI-2 for communication, DiOMP transparently handles global memory, supporting both symmetric and asymmetric GPU allocations. It leverages OMPCCL, a portable collective communication layer compatible with vendor libraries. DiOMP simplifies programming by abstracting device memory and communication, achieving superior scalability and programmability over traditional approaches. Evaluations on NVIDIA A100, Grace Hopper, and AMD MI250X show improved performance in micro-benchmarks and applications like matrix multiplication and Minimod, highlighting DiOMP's potential for scalable, portable, and efficient heterogeneous computing.","authors":["Baodi Shan","Mauricio Arayr-Polo","Barbara Chapman"],"url":"https://arxiv.org/abs/2506.02486"}
{"created":"2025-06-04","title":"Flexiffusion: Training-Free Segment-Wise Neural Architecture Search for Efficient Diffusion Models","abstract":"Diffusion models (DMs) are powerful generative models capable of producing high-fidelity images but are constrained by high computational costs due to iterative multi-step inference. While Neural Architecture Search (NAS) can optimize DMs, existing methods are hindered by retraining requirements, exponential search complexity from step-wise optimization, and slow evaluation relying on massive image generation. To address these challenges, we propose Flexiffusion, a training-free NAS framework that jointly optimizes generation schedules and model architectures without modifying pre-trained parameters. Our key insight is to decompose the generation process into flexible segments of equal length, where each segment dynamically combines three step types: full (complete computation), partial (cache-reused computation), and null (skipped computation). This segment-wise search space reduces the candidate pool exponentially compared to step-wise NAS while preserving architectural diversity. Further, we introduce relative FID (rFID), a lightweight evaluation metric for NAS that measures divergence from a teacher model's outputs instead of ground truth, slashing evaluation time by over $90\\%$. In practice, Flexiffusion achieves at least $2\\times$ acceleration across LDMs, Stable Diffusion, and DDPMs on ImageNet and MS-COCO, with FID degradation under $5\\%$, outperforming prior NAS and caching methods. Notably, it attains $5.1\\times$ speedup on Stable Diffusion with near-identical CLIP scores. Our work pioneers a resource-efficient paradigm for searching high-speed DMs without sacrificing quality.","authors":["Hongtao Huang","Xiaojun Chang","Lina Yao"],"url":"https://arxiv.org/abs/2506.02488"}
{"created":"2025-06-04","title":"Grasp2Grasp: Vision-Based Dexterous Grasp Translation via Schr\\\"odinger Bridges","abstract":"We propose a new approach to vision-based dexterous grasp translation, which aims to transfer grasp intent across robotic hands with differing morphologies. Given a visual observation of a source hand grasping an object, our goal is to synthesize a functionally equivalent grasp for a target hand without requiring paired demonstrations or hand-specific simulations. We frame this problem as a stochastic transport between grasp distributions using the Schr\\\"odinger Bridge formalism. Our method learns to map between source and target latent grasp spaces via score and flow matching, conditioned on visual observations. To guide this translation, we introduce physics-informed cost functions that encode alignment in base pose, contact maps, wrench space, and manipulability. Experiments across diverse hand-object pairs demonstrate our approach generates stable, physically grounded grasps with strong generalization. This work enables semantic grasp transfer for heterogeneous manipulators and bridges vision-based grasping with probabilistic generative modeling.","authors":["Tao Zhong","Jonah Buchanan","Christine Allen-Blanchette"],"url":"https://arxiv.org/abs/2506.02489"}
{"created":"2025-06-04","title":"Simplifying Root Cause Analysis in Kubernetes with StateGraph and LLM","abstract":"Kubernetes, a notably complex and distributed system, utilizes an array of controllers to uphold cluster management logic through state reconciliation. Nevertheless, maintaining state consistency presents significant challenges due to unexpected failures, network disruptions, and asynchronous issues, especially within dynamic cloud environments. These challenges result in operational disruptions and economic losses, underscoring the necessity for robust root cause analysis (RCA) to enhance Kubernetes reliability. The development of large language models (LLMs) presents a promising direction for RCA. However, existing methodologies encounter several obstacles, including the diverse and evolving nature of Kubernetes incidents, the intricate context of incidents, and the polymorphic nature of these incidents. In this paper, we introduce SynergyRCA, an innovative tool that leverages LLMs with retrieval augmentation from graph databases and enhancement with expert prompts. SynergyRCA constructs a StateGraph to capture spatial and temporal relationships and utilizes a MetaGraph to outline entity connections. Upon the occurrence of an incident, an LLM predicts the most pertinent resource, and SynergyRCA queries the MetaGraph and StateGraph to deliver context-specific insights for RCA. We evaluate SynergyRCA using datasets from two production Kubernetes clusters, highlighting its capacity to identify numerous root causes, including novel ones, with high efficiency and precision. SynergyRCA demonstrates the ability to identify root causes in an average time of about two minutes and achieves an impressive precision of approximately 0.90.","authors":["Yong Xiang (Tsinghua University)","Charley Peter Chen (Harmonic Inc)","Liyi Zeng (Peng Cheng Laboratory)","Wei Yin (Tsinghua University)","Xin Liu (Tsinghua University)","Hu Li (Unaffiliated)","Wei Xu (Tsinghua University)"],"url":"https://arxiv.org/abs/2506.02490"}
{"created":"2025-06-04","title":"On the Inversion Modulo a Power of an Integer","abstract":"Recently, Koc proposed a neat and efficient algorithm for computing $x = a^{-1} \\pmod {p^k}$ for a prime $p$ based on the exact solution of linear equations using $p$-adic expansions. The algorithm requires only addition and right shift per step. In this paper, we design an algorithm that computes $x = a^{-1} \\pmod {n^k}$ for any integer $n>1$. The algorithm has a motivation from the schoolbook multiplication and achieves both efficiency and generality. The greater flexibility of our algorithm is explored by utilizing the build-in arithmetic of computer architecture, e.g., $n=2^{64}$, and experimental results show significant improvements. This paper also contains some results on modular inverse based on an alternative proof of Koc algorithm.","authors":["Guangwu Xu","Yunxiao Tian","Bingxin Yang"],"url":"https://arxiv.org/abs/2506.02491"}
{"created":"2025-06-04","title":"Co-Evidential Fusion with Information Volume for Medical Image Segmentation","abstract":"Although existing semi-supervised image segmentation methods have achieved good performance, they cannot effectively utilize multiple sources of voxel-level uncertainty for targeted learning. Therefore, we propose two main improvements. First, we introduce a novel pignistic co-evidential fusion strategy using generalized evidential deep learning, extended by traditional D-S evidence theory, to obtain a more precise uncertainty measure for each voxel in medical samples. This assists the model in learning mixed labeled information and establishing semantic associations between labeled and unlabeled data. Second, we introduce the concept of information volume of mass function (IVUM) to evaluate the constructed evidence, implementing two evidential learning schemes. One optimizes evidential deep learning by combining the information volume of the mass function with original uncertainty measures. The other integrates the learning pattern based on the co-evidential fusion strategy, using IVUM to design a new optimization objective. Experiments on four datasets demonstrate the competitive performance of our method.","authors":["Yuanpeng He","Lijian Li","Tianxiang Zhan","Chi-Man Pun","Wenpin Jiao","Zhi Jin"],"url":"https://arxiv.org/abs/2506.02492"}
{"created":"2025-06-04","title":"Towards In-the-wild 3D Plane Reconstruction from a Single Image","abstract":"3D plane reconstruction from a single image is a crucial yet challenging topic in 3D computer vision. Previous state-of-the-art (SOTA) methods have focused on training their system on a single dataset from either indoor or outdoor domain, limiting their generalizability across diverse testing data. In this work, we introduce a novel framework dubbed ZeroPlane, a Transformer-based model targeting zero-shot 3D plane detection and reconstruction from a single image, over diverse domains and environments. To enable data-driven models across multiple domains, we have curated a large-scale planar benchmark, comprising over 14 datasets and 560,000 high-resolution, dense planar annotations for diverse indoor and outdoor scenes. To address the challenge of achieving desirable planar geometry on multi-dataset training, we propose to disentangle the representation of plane normal and offset, and employ an exemplar-guided, classification-then-regression paradigm to learn plane and offset respectively. Additionally, we employ advanced backbones as image encoder, and present an effective pixel-geometry-enhanced plane embedding module to further facilitate planar reconstruction. Extensive experiments across multiple zero-shot evaluation datasets have demonstrated that our approach significantly outperforms previous methods on both reconstruction accuracy and generalizability, especially over in-the-wild data. Our code and data are available at: https://github.com/jcliu0428/ZeroPlane.","authors":["Jiachen Liu","Rui Yu","Sili Chen","Sharon X. Huang","Hengkai Guo"],"url":"https://arxiv.org/abs/2506.02493"}
{"created":"2025-06-04","title":"Minos: A Multimodal Evaluation Model for Bidirectional Generation Between Image and Text","abstract":"Evaluation is important for multimodal generation tasks. With the rapid progress of MLLMs, there is growing interest in applying MLLMs to build general evaluation systems. However, existing work overlooks two aspects: (1) the development of evaluation capabilities for text-to-image (T2I) generation task, and (2) the incorporation of large-scale human evaluation data. In this paper, we introduce Minos-Corpus, a large-scale multimodal evaluation dataset that combines evaluation data from both human and GPT. The corpus contains evaluation data across both image-to-text(I2T) and T2I generation tasks. Based on this corpus, we propose Data Selection and Balance, Mix-SFT training methods, and apply DPO to develop Minos, a multimodal evaluation model built upon a 7B backbone. Minos achieves state-of-the-art (SoTA) performance among all open-source evaluation models of similar scale on the average of evaluation performance on all tasks, and outperforms all open-source and closed-source models on evaluation of T2I generation task. Extensive experiments demonstrate the importance of leveraging high-quality human evaluation data and jointly training on evaluation data from both I2T and T2I generation tasks.","authors":["Junzhe Zhang","Huixuan Zhang","Xinyu Hu","Li Lin","Mingqi Gao","Shi Qiu","Xiaojun Wan"],"url":"https://arxiv.org/abs/2506.02494"}
{"created":"2025-06-04","title":"LumosFlow: Motion-Guided Long Video Generation","abstract":"Long video generation has gained increasing attention due to its widespread applications in fields such as entertainment and simulation. Despite advances, synthesizing temporally coherent and visually compelling long sequences remains a formidable challenge. Conventional approaches often synthesize long videos by sequentially generating and concatenating short clips, or generating key frames and then interpolate the intermediate frames in a hierarchical manner. However, both of them still remain significant challenges, leading to issues such as temporal repetition or unnatural transitions. In this paper, we revisit the hierarchical long video generation pipeline and introduce LumosFlow, a framework introduce motion guidance explicitly. Specifically, we first employ the Large Motion Text-to-Video Diffusion Model (LMTV-DM) to generate key frames with larger motion intervals, thereby ensuring content diversity in the generated long videos. Given the complexity of interpolating contextual transitions between key frames, we further decompose the intermediate frame interpolation into motion generation and post-hoc refinement. For each pair of key frames, the Latent Optical Flow Diffusion Model (LOF-DM) synthesizes complex and large-motion optical flows, while MotionControlNet subsequently refines the warped results to enhance quality and guide intermediate frame generation. Compared with traditional video frame interpolation, we achieve 15x interpolation, ensuring reasonable and continuous motion between adjacent frames. Experiments show that our method can generate long videos with consistent motion and appearance. Code and models will be made publicly available upon acceptance. Our project page: https://jiahaochen1.github.io/LumosFlow/","authors":["Jiahao Chen","Hangjie Yuan","Yichen Qian","Jingyun Liang","Jiazheng Xing","Pengwei Liu","Weihua Chen","Fan Wang","Bing Su"],"url":"https://arxiv.org/abs/2506.02497"}
{"created":"2025-06-04","title":"DnR-nonverbal: Cinematic Audio Source Separation Dataset Containing Non-Verbal Sounds","abstract":"We propose a new dataset for cinematic audio source separation (CASS) that handles non-verbal sounds. Existing CASS datasets only contain reading-style sounds as a speech stem. These datasets differ from actual movie audio, which is more likely to include acted-out voices. Consequently, models trained on conventional datasets tend to have issues where emotionally heightened voices, such as laughter and screams, are more easily separated as an effect, not speech. To address this problem, we build a new dataset, DnR-nonverbal. The proposed dataset includes non-verbal sounds like laughter and screams in the speech stem. From the experiments, we reveal the issue of non-verbal sound extraction by the current CASS model and show that our dataset can effectively address the issue in the synthetic and actual movie audio. Our dataset is available at https://zenodo.org/records/15470640.","authors":["Takuya Hasumi","Yusuke Fujita"],"url":"https://arxiv.org/abs/2506.02499"}
{"created":"2025-06-04","title":"KARE-RAG: Knowledge-Aware Refinement and Enhancement for RAG","abstract":"Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to access broader knowledge sources, yet factual inconsistencies persist due to noise in retrieved documents-even with advanced retrieval methods. We demonstrate that enhancing generative models' capacity to process noisy content is equally critical for robust performance. In this paper, we present KARE-RAG (Knowledge-Aware Refinement and Enhancement for RAG), which improves knowledge utilization through three key innovations: (1) structured knowledge representations that facilitate error detection during training, (2) Dense Direct Preference Optimization (DDPO)-a refined training objective that prioritizes correction of critical errors, and (3) a contrastive data generation pipeline that maintains semantic consistency while rectifying factual inaccuracies. Experiments show our method significantly enhances standard RAG pipelines across model scales, improving both in-domain and out-of-domain task performance without compromising general capabilities. Notably, these gains are achieved with modest training data, suggesting data-efficient optimization is possible through targeted learning strategies. Our findings establish a new direction for RAG improvement: by improving how models learn to process retrieved content, we can enhance performance across diverse inference paradigms. All data and code will be publicly available on Github.","authors":["Yongjian Li","HaoCheng Chu","Yukun Yan","Zhenghao Liu","Shi Yu","Zheni Zeng","Ruobing Wang","Sen Song","Zhiyuan Liu","Maosong Sun"],"url":"https://arxiv.org/abs/2506.02503"}
{"created":"2025-06-04","title":"Stochastic Momentum Methods for Non-smooth Non-Convex Finite-Sum Coupled Compositional Optimization","abstract":"Finite-sum Coupled Compositional Optimization (FCCO), characterized by its coupled compositional objective structure, emerges as an important optimization paradigm for addressing a wide range of machine learning problems. In this paper, we focus on a challenging class of non-convex non-smooth FCCO, where the outer functions are non-smooth weakly convex or convex and the inner functions are smooth or weakly convex. Existing state-of-the-art result face two key limitations: (1) a high iteration complexity of $O(1/\\epsilon^6)$ under the assumption that the stochastic inner functions are Lipschitz continuous in expectation; (2) reliance on vanilla SGD-type updates, which are not suitable for deep learning applications. Our main contributions are two fold: (i) We propose stochastic momentum methods tailored for non-smooth FCCO that come with provable convergence guarantees; (ii) We establish a new state-of-the-art iteration complexity of $O(1/\\epsilon^5)$. Moreover, we apply our algorithms to multiple inequality constrained non-convex optimization problems involving smooth or weakly convex functional inequality constraints. By optimizing a smoothed hinge penalty based formulation, we achieve a new state-of-the-art complexity of $O(1/\\epsilon^5)$ for finding an (nearly) $\\epsilon$-level KKT solution. Experiments on three tasks demonstrate the effectiveness of the proposed algorithms.","authors":["Xingyu Chen","Bokun Wang","Ming Yang","Quanqi Hu","Qihang Lin","Tianbao Yang"],"url":"https://arxiv.org/abs/2506.02504"}
{"created":"2025-06-04","title":"AURA: Agentic Upskilling via Reinforced Abstractions","abstract":"We study the combinatorial explosion involved in translating high-level task prompts into deployable control policies for agile robots through multi-stage reinforcement learning. We introduce AURA (Agentic Upskilling via Reinforced Abstractions), a schema-centric curriculum RL framework that leverages Large Language Models (LLMs) as autonomous designers of multi-stage curricula. AURA transforms user prompts into YAML workflows that encode full reward functions, domain randomization strategies, and training configurations. All files are statically validated against a schema before any GPU time is consumed, ensuring reliable and efficient execution without human intervention. A retrieval-augmented feedback loop allows specialized LLM agents to design, execute, and refine staged curricula based on prior training results stored in a vector database, supporting continual improvement over time. Ablation studies highlight the importance of retrieval for curriculum quality and convergence stability. Quantitative experiments show that AURA consistently outperforms LLM-guided baselines on GPU-accelerated training frameworks. In qualitative tests, AURA successfully trains end-to-end policies directly from user prompts and deploys them zero-shot on a custom humanoid robot across a range of environments. By abstracting away the complexity of curriculum design, AURA enables scalable and adaptive policy learning pipelines that would be prohibitively complex to construct by hand.","authors":["Alvin Zhu","Yusuke Tanaka","Dennis Hong"],"url":"https://arxiv.org/abs/2506.02507"}
{"created":"2025-06-04","title":"In-context Clustering-based Entity Resolution with Large Language Models: A Design Space Exploration","abstract":"Entity Resolution (ER) is a fundamental data quality improvement task that identifies and links records referring to the same real-world entity. Traditional ER approaches often rely on pairwise comparisons, which can be costly in terms of time and monetary resources, especially with large datasets. Recently, Large Language Models (LLMs) have shown promising results in ER tasks. However, existing methods typically focus on pairwise matching, missing the potential of LLMs to perform clustering directly in a more cost-effective and scalable manner. In this paper, we propose a novel in-context clustering approach for ER, where LLMs are used to cluster records directly, reducing both time complexity and monetary costs. We systematically investigate the design space for in-context clustering, analyzing the impact of factors such as set size, diversity, variation, and ordering of records on clustering performance. Based on these insights, we develop LLM-CER (LLM-powered Clustering-based ER), which achieves high-quality ER results while minimizing LLM API calls. Our approach addresses key challenges, including efficient cluster merging and LLM hallucination, providing a scalable and effective solution for ER. Extensive experiments on nine real-world datasets demonstrate that our method significantly improves result quality, achieving up to 150% higher accuracy, 10% increase in the F-measure, and reducing API calls by up to 5 times, while maintaining comparable monetary cost to the most cost-effective baseline.","authors":["Jiajie Fu","Haitong Tang","Arijit Khan","Sharad Mehrotra","Xiangyu Ke","Yunjun Gao"],"url":"https://arxiv.org/abs/2506.02509"}
{"created":"2025-06-04","title":"M$^3$FinMeeting: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset","abstract":"Recent breakthroughs in large language models (LLMs) have led to the development of new benchmarks for evaluating their performance in the financial domain. However, current financial benchmarks often rely on news articles, earnings reports, or announcements, making it challenging to capture the real-world dynamics of financial meetings. To address this gap, we propose a novel benchmark called $\\texttt{M$^3$FinMeeting}$, which is a multilingual, multi-sector, and multi-task dataset designed for financial meeting understanding. First, $\\texttt{M$^3$FinMeeting}$ supports English, Chinese, and Japanese, enhancing comprehension of financial discussions in diverse linguistic contexts. Second, it encompasses various industry sectors defined by the Global Industry Classification Standard (GICS), ensuring that the benchmark spans a broad range of financial activities. Finally, $\\texttt{M$^3$FinMeeting}$ includes three tasks: summarization, question-answer (QA) pair extraction, and question answering, facilitating a more realistic and comprehensive evaluation of understanding. Experimental results with seven popular LLMs reveal that even the most advanced long-context models have significant room for improvement, demonstrating the effectiveness of $\\texttt{M$^3$FinMeeting}$ as a benchmark for assessing LLMs' financial meeting comprehension skills.","authors":["Jie Zhu","Junhui Li","Yalong Wen","Xiandong Li","Lifan Guo","Feng Chen"],"url":"https://arxiv.org/abs/2506.02510"}
{"created":"2025-06-04","title":"To Embody or Not: The Effect Of Embodiment On User Perception Of LLM-based Conversational Agents","abstract":"Embodiment in conversational agents (CAs) refers to the physical or visual representation of these agents, which can significantly influence user perception and interaction. Limited work has been done examining the effect of embodiment on the perception of CAs utilizing modern large language models (LLMs) in non-hierarchical cooperative tasks, a common use case of CAs as more powerful models become widely available for general use. To bridge this research gap, we conducted a mixed-methods within-subjects study on how users perceive LLM-based CAs in cooperative tasks when embodied and non-embodied. The results show that the non-embodied agent received significantly better quantitative appraisals for competence than the embodied agent, and in qualitative feedback, many participants believed that the embodied CA was more sycophantic than the non-embodied CA. Building on prior work on users' perceptions of LLM sycophancy and anthropomorphic features, we theorize that the typically-positive impact of embodiment on perception of CA credibility can become detrimental in the presence of sycophancy. The implication of such a phenomenon is that, contrary to intuition and existing literature, embodiment is not a straightforward way to improve a CA's perceived credibility if there exists a tendency to sycophancy.","authors":["Kyra Wang","Boon-Kiat Quek","Jessica Goh","Dorien Herremans"],"url":"https://arxiv.org/abs/2506.02514"}
{"created":"2025-06-04","title":"FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning","abstract":"Multi-step symbolic reasoning is critical for advancing downstream performance on financial tasks. Yet, benchmarks for systematically evaluating this capability are lacking. Existing datasets like FinQA and ConvFinQA supervise only final numerical answers, without assessing intermediate reasoning steps. To address this, we introduce FinChain, the first symbolic benchmark designed for verifiable Chain-of- Thought (CoT) financial reasoning. Spanning 54 topics across 12 financial domains, Fin- Chain offers five parameterized templates per topic, each varying in reasoning complexity and domain expertise required. Each dataset instance includes an executable Python trace, enabling automatic generation of extensive training data and easy adaptation to other domains. We also introduce ChainEval, a new metric for automatic evaluation of both final answers and intermediate reasoning. Benchmarking 30 LLMs on our dataset, we find that even state-of-the-art models have considerable room for improvement in multi-step financial reasoning. All templates and evaluation metrics for FinChain are available at https: //github.com/mbzuai-nlp/finchain.","authors":["Zhuohan Xie","Dhruv Sahnan","Debopriyo Banerjee","Georgi Georgiev","Rushil Thareja","Hachem Madmoun","Jinyan Su","Aaryamonvikram Singh","Yuxia Wang","Rui Xing","Fajri Koto","Haonan Li","Ivan Koychev","Tanmoy Chakraborty","Salem Lahlou","Veselin Stoyanov","Preslav Nakov"],"url":"https://arxiv.org/abs/2506.02515"}
{"created":"2025-06-04","title":"Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning","abstract":"LLMssuch as GPT-4 have shown a remarkable ability to solve complex questions by generating step-by-step rationales. Prior works have utilized this capability to improve smaller and cheaper LMs (say, with 7B parameters). However, various practical constraints, such as copyright and legal issues, owing to lack of transparency in the pre-training data of large (often closed) models, prevent their use in commercial settings. Little focus has been given to improving the innate reasoning ability of smaller models without distilling information from larger LLMs. To address this, we propose COLLATE, a trainable framework that tunes a (small) LLM to generate those outputs from a pool of diverse rationales that selectively improves the downstream task. COLLATE enforces multiple instances of the same LLM to exhibit distinct behavior and employs them to generate rationales to obtain diverse outputs. The LLM is then tuned via preference optimization to choose the candidate rationale which maximizes the likelihood of ground-truth answer. COLLATE outperforms several trainable and prompting baselines on 5 datasets across 3 domains: maths problem solving, natural language inference, and commonsense reasoning. We show the eff icacy of COLLATE on LLMs from different model families across varying parameter scales (1B to 8B) and demonstrate the benefit of multiple rationale providers guided by the end task through ablations. Code is released here (https://github.com/Sohanpatnaik106/collate).","authors":["Sohan Patnaik","Milan Aggarwal","Sumit Bhatia","Balaji Krishnamurthy"],"url":"https://arxiv.org/abs/2506.02519"}
{"created":"2025-06-04","title":"Branch-and-Cut for Mixed-Integer Generalized Nash Equilibrium Problems","abstract":"Generalized Nash equilibrium problems with mixed-integer variables form an important class of games in which each player solves a mixed-integer optimization problem with respect to her own variables and the strategy space of each player depends on the strategies chosen by the rival players. In this work, we introduce a branch-and-cut algorithm to compute exact pure Nash equilibria for different classes of such mixed-integer games. The main idea is to reformulate the equilibrium problem as a suitable bilevel problem based on the Nikaido--Isoda function of the game. The proposed branch-and-cut method is applicable to generalized Nash equilibrium problems under quite mild assumptions. Depending on the specific setting, we use tailored equilibrium or intersection cuts. The latter are well-known in mixed-integer linear optimization and we adapt them to the game setting. We prove finite termination and correctness of the algorithm and present some first numerical results for two different types of knapsack games and another game based on capacitated flow problems.","authors":["Alo\\\"is Duguet","Tobias Harks","Martin Schmidt","Julian Schwarz"],"url":"https://arxiv.org/abs/2506.02520"}
{"created":"2025-06-04","title":"Think Twice, Act Once: A Co-Evolution Framework of LLM and RL for Large-Scale Decision Making","abstract":"Recent advancements in Large Language Models (LLMs) and Reinforcement Learning (RL) have shown significant promise in decision-making tasks. Nevertheless, for large-scale industrial decision problems, both approaches face distinct challenges: LLMs lack real-time long-sequence decision-making capabilities, while RL struggles with sample efficiency in vast action spaces. To bridge this gap, we propose Agents Co-Evolution (ACE), a synergistic framework between LLMs and RL agents for large-scale decision-making scenarios. ACE introduces a dual-role trajectory refinement mechanism where LLMs act as both Policy Actor and Value Critic during RL's training: the Actor refines suboptimal actions via multi-step reasoning and environment validation, while the Critic performs temporal credit assignment through trajectory-level reward shaping. Concurrently, RL agent enhances LLMs' task-specific decision-making with high-quality fine-tuning datasets generated via prioritized experience replay. Through extensive experiments across multiple power grid operation challenges with action spaces exceeding 60K discrete actions, ACE demonstrates superior performance over existing RL methods and LLM-based methods.","authors":["Xu Wan","Wenyue Xu","Chao Yang","Mingyang Sun"],"url":"https://arxiv.org/abs/2506.02522"}
{"created":"2025-06-04","title":"Hardware-Centric Analysis of DeepSeek's Multi-Head Latent Attention","abstract":"Multi-Head Latent Attention (MLA), introduced in DeepSeek-V2, improves the efficiency of large language models by projecting query, key, and value tensors into a compact latent space. This architectural change reduces the KV-cache size and significantly lowers memory bandwidth demands, particularly in the autoregressive decode phase. This letter presents the first hardware-centric analysis of MLA, comparing it to conventional Multi-Head Attention (MHA) and evaluating its implications for accelerator performance. We identify two alternative execution schemes of MLA--reusing, resp. recomputing latent projection matrices--which offer distinct trade-offs between compute and memory access. Using the Stream design space exploration framework, we model their throughput and energy cost across a range of hardware platforms and find that MLA can shift attention workloads toward the compute-bound regime.","authors":["Robin Geens","Marian Verhelst"],"url":"https://arxiv.org/abs/2506.02523"}
{"created":"2025-06-04","title":"Boolean-network simplification and rule fitting to unravel chemotherapy resistance in non-small cell lung cancer","abstract":"Boolean networks are powerful frameworks for capturing the logic of gene-regulatory circuits, yet their combinatorial explosion hampers exhaustive analyses. Here, we present a systematic reduction of a 31-node Boolean model that describes cisplatin- and pemetrexed-resistance in non-small-cell lung cancer to a compact 9-node core that exactly reproduces the original attractor landscape. The streamlined network shrinks the state space by four orders of magnitude, enabling rapid exploration of critical control points, rules fitting and candidate therapeutic targets. Extensive synchronous and asynchronous simulations confirm that the three clinically relevant steady states and their basins of attraction are conserved and reflect resistance frequencies close to those reported in clinical studies. The reduced model provides an accessible scaffold for future mechanistic and drug-discovery studies.","authors":["Alonso Espinoza","Eric Goles","Marco Montalva-Medel"],"url":"https://arxiv.org/abs/2506.02525"}
{"created":"2025-06-04","title":"Multilingual Information Retrieval with a Monolingual Knowledge Base","abstract":"Multilingual information retrieval has emerged as powerful tools for expanding knowledge sharing across languages. On the other hand, resources on high quality knowledge base are often scarce and in limited languages, therefore an effective embedding model to transform sentences from different languages into a feature vector space same as the knowledge base language becomes the key ingredient for cross language knowledge sharing, especially to transfer knowledge available in high-resource languages to low-resource ones. In this paper we propose a novel strategy to fine-tune multilingual embedding models with weighted sampling for contrastive learning, enabling multilingual information retrieval with a monolingual knowledge base. We demonstrate that the weighted sampling strategy produces performance gains compared to standard ones by up to 31.03\\% in MRR and up to 33.98\\% in Recall@3. Additionally, our proposed methodology is language agnostic and applicable for both multilingual and code switching use cases.","authors":["Yingying Zhuang","Aman Gupta","Anurag Beniwal"],"url":"https://arxiv.org/abs/2506.02527"}
{"created":"2025-06-04","title":"RelationAdapter: Learning and Transferring Visual Relation with Diffusion Transformers","abstract":"Inspired by the in-context learning mechanism of large language models (LLMs), a new paradigm of generalizable visual prompt-based image editing is emerging. Existing single-reference methods typically focus on style or appearance adjustments and struggle with non-rigid transformations. To address these limitations, we propose leveraging source-target image pairs to extract and transfer content-aware editing intent to novel query images. To this end, we introduce RelationAdapter, a lightweight module that enables Diffusion Transformer (DiT) based models to effectively capture and apply visual transformations from minimal examples. We also introduce Relation252K, a comprehensive dataset comprising 218 diverse editing tasks, to evaluate model generalization and adaptability in visual prompt-driven scenarios. Experiments on Relation252K show that RelationAdapter significantly improves the model's ability to understand and transfer editing intent, leading to notable gains in generation quality and overall editing performance.","authors":["Yan Gong","Yiren Song","Yicheng Li","Chenglin Li","Yin Zhang"],"url":"https://arxiv.org/abs/2506.02528"}
{"created":"2025-06-04","title":"Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs","abstract":"Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in automating complex tasks, but limitations persist in handling dynamic navigation flows and complex form interactions. This paper presents an automated system for generating test cases for two key aspects of web application testing: site navigation and form filling. For site navigation, the system employs screen transition graphs and LLMs to model navigation flows and generate test scenarios. For form filling, it uses state graphs to handle conditional forms and automates Selenium script generation. Key contributions include: (1) a novel integration of graph structures and LLMs for site navigation testing, (2) a state graph-based approach for automating form-filling test cases, and (3) a comprehensive dataset for evaluating form-interaction testing. Experimental results demonstrate the system's effectiveness in improving test coverage and robustness, advancing the state of web application testing.","authors":["Nguyen-Khang Le","Quan Minh Bui","Minh Ngoc Nguyen","Hiep Nguyen","Trung Vo","Son T. Luu","Shoshin Nomura","Minh Le Nguyen"],"url":"https://arxiv.org/abs/2506.02529"}
{"created":"2025-06-04","title":"ReasoningFlow: Semantic Structure of Complex Reasoning Traces","abstract":"Large reasoning models (LRMs) generate complex reasoning traces with planning, reflection, verification, and backtracking. In this work, we introduce ReasoningFlow, a unified schema for analyzing the semantic structures of these complex traces. ReasoningFlow parses traces into directed acyclic graphs, enabling the characterization of distinct reasoning patterns as subgraph structures. This human-interpretable representation offers promising applications in understanding, evaluating, and enhancing the reasoning processes of LRMs.","authors":["Jinu Lee","Sagnik Mukherjee","Dilek Hakkani-Tur","Julia Hockenmaier"],"url":"https://arxiv.org/abs/2506.02532"}
{"created":"2025-06-04","title":"Natural Language Processing to Enhance Deliberation in Political Online Discussions: A Survey","abstract":"Political online participation in the form of discussing political issues and exchanging opinions among citizens is gaining importance with more and more formats being held digitally. To come to a decision, a careful discussion and consideration of opinions and a civil exchange of arguments, which is defined as the act of deliberation, is desirable. The quality of discussions and participation processes in terms of their deliberativeness highly depends on the design of platforms and processes. To facilitate online communication for both participants and initiators, machine learning methods offer a lot of potential. In this work we want to showcase which issues occur in political online discussions and how machine learning can be used to counteract these issues and enhance deliberation.","authors":["Maike Behrendt","Stefan Sylvius Wagner","Carina Weinmann","Marike Bormann","Mira Warne","Stefan Harmeling"],"url":"https://arxiv.org/abs/2506.02533"}
{"created":"2025-06-04","title":"Enhancing Monocular Height Estimation via Weak Supervision from Imperfect Labels","abstract":"Monocular height estimation is considered the most efficient and cost-effective means of 3D perception in remote sensing, and it has attracted much attention since the emergence of deep learning. While training neural networks requires a large amount of data, data with perfect labels are scarce and only available within developed regions. The trained models therefore lack generalizability, which limits the potential for large-scale application of existing methods. We tackle this problem for the first time, by introducing data with imperfect labels into training pixel-wise height estimation networks, including labels that are incomplete, inexact, and inaccurate compared to high-quality labels. We propose an ensemble-based pipeline compatible with any monocular height estimation network. Taking the challenges of noisy labels, domain shift, and long-tailed distribution of height values into consideration, we carefully design the architecture and loss functions to leverage the information concealed in imperfect labels using weak supervision through balanced soft losses and ordinal constraints. We conduct extensive experiments on two datasets with different resolutions, DFC23 (0.5 to 1 m) and GBH (3 m). The results indicate that the proposed pipeline outperforms baselines by achieving more balanced performance across various domains, leading to improvements of average root mean square errors up to 22.94 %, and 18.62 % on DFC23 and GBH, respectively. The efficacy of each design component is validated through ablation studies. Code is available at https://github.com/zhu-xlab/weakim2h.","authors":["Sining Chen","Yilei Shi","Xiao Xiang Zhu"],"url":"https://arxiv.org/abs/2506.02534"}
{"created":"2025-06-04","title":"MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection","abstract":"Video Anomaly Detection (VAD) methods based on reconstruction or prediction face two critical challenges: (1) strong generalization capability often results in accurate reconstruction or prediction of abnormal events, making it difficult to distinguish normal from abnormal patterns; (2) reliance only on low-level appearance and motion cues limits their ability to identify high-level semantic in abnormal events from complex scenes. To address these limitations, we propose a novel VAD framework with two key innovations. First, to suppress excessive generalization, we introduce the Sparse Feature Filtering Module (SFFM) that employs bottleneck filters to dynamically and adaptively remove abnormal information from features. Unlike traditional memory modules, it does not need to memorize the normal prototypes across the training dataset. Further, we design the Mixture of Experts (MoE) architecture for SFFM. Each expert is responsible for extracting specialized principal features during running time, and different experts are selectively activated to ensure the diversity of the learned principal features. Second, to overcome the neglect of semantics in existing methods, we integrate a Vision-Language Model (VLM) to generate textual descriptions for video clips, enabling comprehensive joint modeling of semantic, appearance, and motion cues. Additionally, we enforce modality consistency through semantic similarity constraints and motion frame-difference contrastive loss. Extensive experiments on multiple public datasets validate the effectiveness of our multimodal joint modeling framework and sparse feature filtering paradigm. Project page at https://qzfm.github.io/sfn_vad_project_page/.","authors":["Juntong Li","Lingwei Dang","Yukun Su","Yun Hao","Qingxin Xiao","Yongwei Nie","Qingyao Wu"],"url":"https://arxiv.org/abs/2506.02535"}
{"created":"2025-06-04","title":"Answer Convergence as a Signal for Early Stopping in Reasoning","abstract":"Chain-of-thought (CoT) prompting enhances reasoning in large language models (LLMs) but often leads to verbose and redundant outputs, thus increasing inference cost. We hypothesize that many reasoning steps are unnecessary for producing correct answers. To investigate this, we start with a systematic study to examine what is the minimum reasoning required for a model to reach a stable decision. We find that on math reasoning tasks like math, models typically converge to their final answers after 60\\% of the reasoning steps, suggesting substantial redundancy in the remaining content. Based on these insights, we propose three inference-time strategies to improve efficiency: (1) early stopping via answer consistency, (2) boosting the probability of generating end-of-reasoning signals, and (3) a supervised method that learns when to stop based on internal activations. Experiments across five benchmarks and five open-weights LLMs show that our methods significantly reduce token usage with little or no accuracy drop. In particular, on NaturalQuestions, Answer Consistency reduces tokens by over 40\\% while further improving accuracy. Our work underscores the importance of cost-effective reasoning methods that operate at inference time, offering practical benefits for real-world applications.","authors":["Xin Liu","Lu Wang"],"url":"https://arxiv.org/abs/2506.02536"}
{"created":"2025-06-04","title":"VisuRiddles: Fine-grained Perception is a Primary Bottleneck for Multimodal Large Language Models in Abstract Visual Reasoning","abstract":"Recent strides in multimodal large language models (MLLMs) have significantly advanced their performance in many reasoning tasks. However, Abstract Visual Reasoning (AVR) remains a critical challenge, primarily due to limitations in perceiving abstract graphics. To tackle this issue, we investigate the bottlenecks in current MLLMs and synthesize training data to improve their abstract visual perception. First, we propose VisuRiddles, a benchmark for AVR, featuring tasks meticulously constructed to assess models' reasoning capacities across five core dimensions and two high-level reasoning categories. Second, we introduce the Perceptual Riddle Synthesizer (PRS), an automated framework for generating riddles with fine-grained perceptual descriptions. PRS not only generates valuable training data for abstract graphics but also provides fine-grained perceptual description, crucially allowing for supervision over intermediate reasoning stages and thereby improving both training efficacy and model interpretability. Our extensive experimental results on VisuRiddles empirically validate that fine-grained visual perception is the principal bottleneck and our synthesis framework markedly enhances the performance of contemporary MLLMs on these challenging tasks. Our code and dataset will be released at https://github.com/yh-hust/VisuRiddles","authors":["Hao Yan","Handong Zheng","Hao Wang","Liang Yin","Xingchen Liu","Zhenbiao Cao","Xinxing Su","Zihao Chen","Jihao Wu","Minghui Liao","Chao Weng","Wei Chen","Yuliang Liu","Xiang Bai"],"url":"https://arxiv.org/abs/2506.02537"}
{"created":"2025-06-04","title":"On the fracture mechanics validity of small scale tests","abstract":"There is growing interest in conducting small-scale tests to gain additional insight into the fracture behaviour of components across a wide range of materials. For example, micro-scale mechanical tests inside of a microscope (\\emph{in situ}) enable direct, high-resolution observation of the interplay between crack growth and microstructural phenomena (e.g., dislocation behaviour or the fracture resistance of a particular interface), and sub-size samples are increasingly used when only a limited amount of material is available. However, to obtain quantitative insight and extract relevant fracture parameters, the sample must be sufficiently large for a $J$- (HRR) or a $K$-field to exist. We conduct numerical and semi-analytical studies to map the conditions (sample geometry, material) that result in a valid, quantitative fracture experiment. Specifically, for a wide range of material properties, crack lengths and sample dimensions, we establish the maximum value of the $J$-integral where an HRR field ceases to exist (i.e., the maximum $J$ value at which fracture must occur for the test to be valid, $J_\\mathrm{max}$). Maps are generated to establish the maximum valid $J$ value ($J_\\mathrm{max}$) as a function of yield strength, strain hardening and minimum sample size. These maps are then used to discuss the existing experimental literature and provide guidance on how to conduct quantitative experiments. Finally, our study is particularised to the analysis of metals that have been embrittled due to hydrogen exposure. The response of relevant materials under hydrogen-containing environments are superimposed on the aforementioned maps, determining the conditions that will enable quantitative insight.","authors":["C. Cui","L. Cupertino-Malheiros","Z. Xiong","E. Mart\\'inez-Pa\\~neda"],"url":"https://arxiv.org/abs/2506.02538"}
{"created":"2025-06-04","title":"VerificAgent: Integrating Expert Knowledge and Fact-Checked Memory for Robust Domain-Specific Task Planning","abstract":"Continual memory augmentation allows computer-use agents (CUAs) to learn from past interactions and refine their task-solving strategies over time. However, unchecked memory accumulation can introduce spurious or hallucinated \"learnings\" that degrade agent performance, particularly in domain-specific workflows such as productivity software. We present a novel framework, VerificAgent, that effectively manages memory for CUAs through (1) an expert-curated seed of domain knowledge, (2) iterative, trajectory-based memory refinement during training, and (3) a post-hoc fact-checking pass by human experts to sanitize accumulated memory before deployment. On OSWorld productivity tasks, VerificAgent achieves a 111.1% relative improvement in success rate over baseline CUA without any additional fine-tuning.","authors":["Thong Q. Nguyen","Shubhang Desai","Yash Jain","Tanvir Aumi","Vishal Chowdhary"],"url":"https://arxiv.org/abs/2506.02539"}
{"created":"2025-06-04","title":"Rethinking Post-Unlearning Behavior of Large Vision-Language Models","abstract":"Machine unlearning is used to mitigate the privacy risks of Large Vision-Language Models (LVLMs) arising from training on large-scale web data. However, existing unlearning methods often fail to carefully select substitute outputs for forget targets, resulting in Unlearning Aftermaths-undesirable behaviors such as degenerate, hallucinated, or excessively refused responses. We highlight that, especially for generative LVLMs, it is crucial to consider the quality and informativeness of post-unlearning responses rather than relying solely on naive suppression. To address this, we introduce a new unlearning task for LVLMs that requires models to provide privacy-preserving yet informative and visually grounded responses. We also propose PUBG, a novel unlearning method that explicitly guides post-unlearning behavior toward a desirable output distribution. Experiments show that, while existing methods suffer from Unlearning Aftermaths despite successfully preventing privacy violations, PUBG effectively mitigates these issues, generating visually grounded and informative responses without privacy leakage for forgotten targets.","authors":["Minsung Kim","Nakyeong Yang","Kyomin Jung"],"url":"https://arxiv.org/abs/2506.02541"}
{"created":"2025-06-04","title":"HIEGNet: A Heterogenous Graph Neural Network Including the Immune Environment in Glomeruli Classification","abstract":"Graph Neural Networks (GNNs) have recently been found to excel in histopathology. However, an important histopathological task, where GNNs have not been extensively explored, is the classification of glomeruli health as an important indicator in nephropathology. This task presents unique difficulties, particularly for the graph construction, i.e., the identification of nodes, edges, and informative features. In this work, we propose a pipeline composed of different traditional and machine learning-based computer vision techniques to identify nodes, edges, and their corresponding features to form a heterogeneous graph. We then proceed to propose a novel heterogeneous GNN architecture for glomeruli classification, called HIEGNet, that integrates both glomeruli and their surrounding immune cells. Hence, HIEGNet is able to consider the immune environment of each glomerulus in its classification. Our HIEGNet was trained and tested on a dataset of Whole Slide Images from kidney transplant patients. Experimental results demonstrate that HIEGNet outperforms several baseline models and generalises best between patients among all baseline models. Our implementation is publicly available at https://github.com/nklsKrmnn/HIEGNet.git.","authors":["Niklas Kormann","Masoud Ramuz","Zeeshan Nisar","Nadine S. Schaadt","Hendrik Annuth","Benjamin Doerr","Friedrich Feuerhake","Thomas Lampert","Johannes F. Lutzeyer"],"url":"https://arxiv.org/abs/2506.02542"}
{"created":"2025-06-04","title":"CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG","abstract":"Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to enhance Multimodal Large Language Models by incorporating externally retrieved multimodal knowledge, but it introduces two challenges: Parametric-Retrieved Knowledge Inconsistency (PRKI), where discrepancies between parametric and retrieved knowledge create uncertainty in determining reliability, and Visual-Textual Knowledge Inconsistency (VTKI), where misalignment between visual and textual sources disrupts entity representation. To address these challenges, we propose \\textbf{C}r\\textbf{o}ss-source knowledge \\textbf{Re}conciliation for \\textbf{M}ulti\\textbf{M}odal \\textbf{RAG} (CoRe-MMRAG), a novel end-to-end framework that effectively reconciles inconsistencies across knowledge sources. CoRe-MMRAG follows a four-stage pipeline: it first generates an internal response from parametric knowledge, then selects the most relevant multimodal evidence via joint similarity assessment, generates an external response, and finally integrates both to produce a reliable answer. Additionally, a specialized training paradigm enhances knowledge source discrimination, multimodal integration, and unified answer generation. Experiments on KB-VQA benchmarks show that CoRe-MMRAG achieves substantial improvements over baseline methods, achieving 5.6\\% and 9.3\\% performance gains on InfoSeek and Encyclopedic-VQA, respectively. We release code and data at \\href{https://github.com/TyangJN/CoRe-MMRAG}{https://github.com/TyangJN/CoRe-MMRAG}.","authors":["Yang Tian","Fan Liu","Jingyuan Zhang","Victoria W.","Yupeng Hu","Liqiang Nie"],"url":"https://arxiv.org/abs/2506.02544"}
{"created":"2025-06-04","title":"On the Language and Gender Biases in PSTN, VoIP and Neural Audio Codecs","abstract":"In recent years, there has been a growing focus on fairness and inclusivity within speech technology, particularly in areas such as automatic speech recognition and speech sentiment analysis. When audio is transcoded prior to processing, as is the case in streaming or real-time applications, any inherent bias in the coding mechanism may result in disparities. This not only affects user experience but can also have broader societal implications by perpetuating stereotypes and exclusion. Thus, it is important that audio coding mechanisms are unbiased. In this work, we contribute towards the scarce research with respect to language and gender biases of audio codecs. By analyzing the speech quality of over 2 million multilingual audio files after transcoding through a representative subset of codecs (PSTN, VoIP and neural), our results indicate that PSTN codecs are strongly biased in terms of gender and that neural codecs introduce language biases.","authors":["Kemal Altwlkany","Amar Kuric","Emanuel Lacic"],"url":"https://arxiv.org/abs/2506.02545"}
{"created":"2025-06-04","title":"Attention Knows Whom to Trust: Attention-based Trust Management for LLM Multi-Agent Systems","abstract":"Large Language Model-based Multi-Agent Systems (LLM-MAS) have demonstrated strong capabilities in solving complex tasks but remain vulnerable when agents receive unreliable messages. This vulnerability stems from a fundamental gap: LLM agents treat all incoming messages equally without evaluating their trustworthiness. While some existing studies approach the trustworthiness, they focus on a single type of harmfulness rather than analyze it in a holistic approach from multiple trustworthiness perspectives. In this work, we propose Attention Trust Score (A-Trust), a lightweight, attention-based method for evaluating message trustworthiness. Inspired by human communication literature[1], through systematically analyzing attention behaviors across six orthogonal trust dimensions, we find that certain attention heads in the LLM specialize in detecting specific types of violations. Leveraging these insights, A-Trust directly infers trustworthiness from internal attention patterns without requiring external prompts or verifiers. Building upon A-Trust, we develop a principled and efficient trust management system (TMS) for LLM-MAS, enabling both message-level and agent-level trust assessment. Experiments across diverse multi-agent settings and tasks demonstrate that applying our TMS significantly enhances robustness against malicious inputs.","authors":["Pengfei He","Zhenwei Dai","Xianfeng Tang","Yue Xing","Hui Liu","Jingying Zeng","Qiankun Peng","Shrivats Agrawal","Samarth Varshney","Suhang Wang","Jiliang Tang","Qi He"],"url":"https://arxiv.org/abs/2506.02546"}
{"created":"2025-06-04","title":"Probabilistic Online Event Downsampling","abstract":"Event cameras capture scene changes asynchronously on a per-pixel basis, enabling extremely high temporal resolution. However, this advantage comes at the cost of high bandwidth, memory, and computational demands. To address this, prior work has explored event downsampling, but most approaches rely on fixed heuristics or threshold-based strategies, limiting their adaptability. Instead, we propose a probabilistic framework, POLED, that models event importance through an event-importance probability density function (ePDF), which can be arbitrarily defined and adapted to different applications. Our approach operates in a purely online setting, estimating event importance on-the-fly from raw event streams, enabling scene-specific adaptation. Additionally, we introduce zero-shot event downsampling, where downsampled events must remain usable for models trained on the original event stream, without task-specific adaptation. We design a contour-preserving ePDF that prioritizes structurally important events and evaluate our method across four datasets and tasks--object classification, image interpolation, surface normal estimation, and object detection--demonstrating that intelligent sampling is crucial for maintaining performance under event-budget constraints.","authors":["Andreu Girbau-Xalabarder","Jun Nagata","Shinichi Sumiyoshi"],"url":"https://arxiv.org/abs/2506.02547"}
{"created":"2025-06-04","title":"CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale","abstract":"Large language model (LLM) agents are becoming increasingly skilled at handling cybersecurity tasks autonomously. Thoroughly assessing their cybersecurity capabilities is critical and urgent, given the high stakes in this domain. However, existing benchmarks fall short, often failing to capture real-world scenarios or being limited in scope. To address this gap, we introduce CyberGym, a large-scale and high-quality cybersecurity evaluation framework featuring 1,507 real-world vulnerabilities found and patched across 188 large software projects. While it includes tasks of various settings, CyberGym primarily focuses on the generation of proof-of-concept (PoC) tests for vulnerability reproduction, based on text descriptions and corresponding source repositories. Solving this task is particularly challenging, as it requires comprehensive reasoning across entire codebases to locate relevant code fragments and produce effective PoCs that accurately trigger the target vulnerability starting from the program's entry point. Our evaluation across 4 state-of-the-art agent frameworks and 9 LLMs reveals that even the best combination (OpenHands and Claude-3.7-Sonnet) achieves only a 11.9% reproduction success rate, mainly on simpler cases. Beyond reproducing historical vulnerabilities, we find that PoCs generated by LLM agents can reveal new vulnerabilities, identifying 15 zero-days affecting the latest versions of the software projects.","authors":["Zhun Wang","Tianneng Shi","Jingxuan He","Matthew Cai","Jialin Zhang","Dawn Song"],"url":"https://arxiv.org/abs/2506.02548"}
{"created":"2025-06-04","title":"Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025","abstract":"In this report, we present a novel three-stage framework developed for the Ego4D Long-Term Action Anticipation (LTA) task. Inspired by recent advances in foundation models, our method consists of three stages: feature extraction, action recognition, and long-term action anticipation. First, visual features are extracted using a high-performance visual encoder. The features are then fed into a Transformer to predict verbs and nouns, with a verb-noun co-occurrence matrix incorporated to enhance recognition accuracy. Finally, the predicted verb-noun pairs are formatted as textual prompts and input into a fine-tuned large language model (LLM) to anticipate future action sequences. Our framework achieves first place in this challenge at CVPR 2025, establishing a new state-of-the-art in long-term action prediction. Our code will be released at https://github.com/CorrineQiu/Ego4D-LTA-Challenge-2025.","authors":["Qiaohui Chu","Haoyu Zhang","Yisen Feng","Meng Liu","Weili Guan","Yaowei Wang","Liqiang Nie"],"url":"https://arxiv.org/abs/2506.02550"}
{"created":"2025-06-04","title":"Response-Level Rewards Are All You Need for Online Reinforcement Learning in LLMs: A Mathematical Perspective","abstract":"We study a common challenge in reinforcement learning for large language models (LLMs): the Zero-Reward Assumption, where non-terminal actions (i.e., intermediate token generations) receive zero task-specific immediate reward, while only the final token receives a reward for the entire response. This assumption arises frequently in practice, as precise token-level rewards are often difficult or infeasible to obtain in LLM applications. In this work, we provide a unifying theoretical perspective. We introduce the Trajectory Policy Gradient Theorem, which shows that the policy gradient based on true, unknown token-level rewards can be unbiasedly estimated using only a response-level reward model, regardless of whether the Zero-Reward Assumption holds or not, for algorithms in the REINFORCE and Actor-Critic families. This result reveals that widely used methods such as PPO, GRPO, ReMax, and RLOO inherently possess the capacity to model token-level reward signals, offering a theoretical justification for response-level reward approaches. Our findings pave the way for more practical, efficient LLM fine-tuning, allowing developers to treat training algorithms as black boxes and focus on improving the response-level reward model with auxiliary sub-models. We also offer a detailed analysis of popular RL and non-RL methods, comparing their theoretical foundations and practical advantages across common LLM tasks. Finally, we propose a new algorithm: Token-Reinforced Policy Optimization (TRePO), a theoretically grounded method that is simpler than PPO, matches GRPO in memory efficiency, and holds promise for broad applicability.","authors":["Shenghua He","Tian Xia","Xuan Zhou","Hui Wei"],"url":"https://arxiv.org/abs/2506.02553"}
{"created":"2025-06-04","title":"HiLO: High-Level Object Fusion for Autonomous Driving using Transformers","abstract":"The fusion of sensor data is essential for a robust perception of the environment in autonomous driving. Learning-based fusion approaches mainly use feature-level fusion to achieve high performance, but their complexity and hardware requirements limit their applicability in near-production vehicles. High-level fusion methods offer robustness with lower computational requirements. Traditional methods, such as the Kalman filter, dominate this area. This paper modifies the Adapted Kalman Filter (AKF) and proposes a novel transformer-based high-level object fusion method called HiLO. Experimental results demonstrate improvements of $25.9$ percentage points in $\\textrm{F}_1$ score and $6.1$ percentage points in mean IoU. Evaluation on a new large-scale real-world dataset demonstrates the effectiveness of the proposed approaches. Their generalizability is further validated by cross-domain evaluation between urban and highway scenarios. Code, data, and models are available at https://github.com/rst-tu-dortmund/HiLO .","authors":["Timo Osterburg","Franz Albers","Christopher Diehl","Rajesh Pushparaj","Torsten Bertram"],"url":"https://arxiv.org/abs/2506.02554"}
{"created":"2025-06-04","title":"SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence","abstract":"Foundation models have achieved transformative success across biomedical domains by enabling holistic understanding of multimodal data. However, their application in surgery remains underexplored. Surgical intelligence presents unique challenges - requiring surgical visual perception, temporal analysis, and reasoning. Existing general-purpose vision-language models fail to address these needs due to insufficient domain-specific supervision and the lack of a large-scale high-quality surgical database. To bridge this gap, we propose SurgVLM, one of the first large vision-language foundation models for surgical intelligence, where this single universal model can tackle versatile surgical tasks. To enable this, we construct a large-scale multimodal surgical database, SurgVLM-DB, comprising over 1.81 million frames with 7.79 million conversations, spanning more than 16 surgical types and 18 anatomical structures. We unify and reorganize 23 public datasets across 10 surgical tasks, followed by standardizing labels and doing hierarchical vision-language alignment to facilitate comprehensive coverage of gradually finer-grained surgical tasks, from visual perception, temporal analysis, to high-level reasoning. Building upon this comprehensive dataset, we propose SurgVLM, which is built upon Qwen2.5-VL, and undergoes instruction tuning to 10+ surgical tasks. We further construct a surgical multimodal benchmark, SurgVLM-Bench, for method evaluation. SurgVLM-Bench consists of 6 popular and widely-used datasets in surgical domain, covering several crucial downstream tasks. Based on SurgVLM-Bench, we evaluate the performance of our SurgVLM (3 SurgVLM variants: SurgVLM-7B, SurgVLM-32B, and SurgVLM-72B), and conduct comprehensive comparisons with 14 mainstream commercial VLMs (e.g., GPT-4o, Gemini 2.0 Flash, Qwen2.5-Max).","authors":["Zhitao Zeng","Zhu Zhuo","Xiaojun Jia","Erli Zhang","Junde Wu","Jiaan Zhang","Yuxuan Wang","Chang Han Low","Jian Jiang","Zilong Zheng","Xiaochun Cao","Yutong Ban","Qi Dou","Yang Liu","Yueming Jin"],"url":"https://arxiv.org/abs/2506.02555"}
{"created":"2025-06-04","title":"Sign Language: Towards Sign Understanding for Robot Autonomy","abstract":"Signage is an ubiquitous element of human environments, playing a critical role in both scene understanding and navigation. For autonomous systems to fully interpret human environments, effectively parsing and understanding signs is essential. We introduce the task of navigational sign understanding, aimed at extracting navigational cues from signs that convey symbolic spatial information about the scene. Specifically, we focus on signs capturing directional cues that point toward distant locations and locational cues that identify specific places. To benchmark performance on this task, we curate a comprehensive test set, propose appropriate evaluation metrics, and establish a baseline approach. Our test set consists of over 160 images, capturing signs with varying complexity and design across a wide range of public spaces, such as hospitals, shopping malls, and transportation hubs. Our baseline approach harnesses Vision-Language Models (VLMs) to parse navigational signs under these high degrees of variability. Experiments show that VLMs offer promising performance on this task, potentially motivating downstream applications in robotics. The code and dataset are available on Github.","authors":["Ayush Agrawal","Joel Loo","Nicky Zimmerman","David Hsu"],"url":"https://arxiv.org/abs/2506.02556"}
{"created":"2025-06-04","title":"Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models","abstract":"Vision-language models, such as CLIP, have achieved significant success in aligning visual and textual representations, becoming essential components of many multi-modal large language models (MLLMs) like LLaVA and OpenFlamingo. However, numerous studies have identified CLIP's limited fine-grained perception as a critical drawback, leading to substantial failures in downstream MLLMs. In contrast, vision-centric foundation models like DINOv2 demonstrate remarkable capabilities in capturing fine details from images. In this work, we propose a novel kernel-based method to align CLIP's visual representation with that of DINOv2, ensuring that the resulting embeddings maintain compatibility with text embeddings while enhancing perceptual capabilities. Our alignment objective is designed for efficient stochastic optimization. Following this image-only alignment fine-tuning, the visual encoder retains compatibility with the frozen text encoder and exhibits significant improvements in zero-shot object recognition, fine-grained spatial reasoning, and localization. By integrating the aligned visual encoder, downstream MLLMs also demonstrate enhanced performance.","authors":["Shizhan Gong","Yankai Jiang","Qi Dou","Farzan Farnia"],"url":"https://arxiv.org/abs/2506.02557"}
{"created":"2025-06-04","title":"DCI: Dual-Conditional Inversion for Boosting Diffusion-Based Image Editing","abstract":"Diffusion models have achieved remarkable success in image generation and editing tasks. Inversion within these models aims to recover the latent noise representation for a real or generated image, enabling reconstruction, editing, and other downstream tasks. However, to date, most inversion approaches suffer from an intrinsic trade-off between reconstruction accuracy and editing flexibility. This limitation arises from the difficulty of maintaining both semantic alignment and structural consistency during the inversion process. In this work, we introduce Dual-Conditional Inversion (DCI), a novel framework that jointly conditions on the source prompt and reference image to guide the inversion process. Specifically, DCI formulates the inversion process as a dual-condition fixed-point optimization problem, minimizing both the latent noise gap and the reconstruction error under the joint guidance. This design anchors the inversion trajectory in both semantic and visual space, leading to more accurate and editable latent representations. Our novel setup brings new understanding to the inversion process. Extensive experiments demonstrate that DCI achieves state-of-the-art performance across multiple editing tasks, significantly improving both reconstruction quality and editing precision. Furthermore, we also demonstrate that our method achieves strong results in reconstruction tasks, implying a degree of robustness and generalizability approaching the ultimate goal of the inversion process.","authors":["Zixiang Li","Haoyu Wang","Wei Wang","Chuangchuang Tan","Yunchao Wei","Yao Zhao"],"url":"https://arxiv.org/abs/2506.02560"}
{"created":"2025-06-04","title":"Pruning General Large Language Models into Customized Expert Models","abstract":"Large language models (LLMs) have revolutionized natural language processing, yet their substantial model sizes often require substantial computational resources. To preserve computing resources and accelerate inference speed, it is crucial to prune redundant parameters, especially for experienced users who often need compact expert models tailored to specific downstream scenarios. However, most existing pruning methods focus on preserving the model's general capabilities, often requiring extensive post-training or suffering from degraded performance due to coarse-grained pruning. In this work, we design a $\\underline{Cus}$tom $\\underline{Prun}$ing method ($\\texttt{Cus-Prun}$) to prune a large general model into a smaller lightweight expert model, which is positioned along the \"language\", \"domain\" and \"task\" dimensions. By identifying and pruning irrelevant neurons of each dimension, $\\texttt{Cus-Prun}$ creates expert models without any post-training. Our experiments demonstrate that $\\texttt{Cus-Prun}$ consistently outperforms other methods, achieving minimal loss in both expert and general capabilities across various models from different model families and sizes.","authors":["Yirao Zhao","Guizhen Chen","Kenji Kawaguchi","Lidong Bing","Wenxuan Zhang"],"url":"https://arxiv.org/abs/2506.02561"}
{"created":"2025-06-04","title":"Privacy-Preserving Federated Convex Optimization: Balancing Partial-Participation and Efficiency via Noise Cancellation","abstract":"This paper tackles the challenge of achieving Differential Privacy (DP) in Federated Learning (FL) under partial-participation, where only a subset of the machines participate in each time-step. While previous work achieved optimal performance in full-participation settings, these methods struggled to extend to partial-participation scenarios. Our approach fills this gap by introducing a novel noise-cancellation mechanism that preserves privacy without sacrificing convergence rates or computational efficiency. We analyze our method within the Stochastic Convex Optimization (SCO) framework and show that it delivers optimal performance for both homogeneous and heterogeneous data distributions. This work expands the applicability of DP in FL, offering an efficient and practical solution for privacy-preserving learning in distributed systems with partial participation.","authors":["Roie Reshef","Kfir Yehuda Levy"],"url":"https://arxiv.org/abs/2506.02563"}
{"created":"2025-06-04","title":"Towards Generating Controllable and Solvable Geometry Problem by Leveraging Symbolic Deduction Engine","abstract":"Generating high-quality geometry problems is both an important and challenging task in education. Compared to math word problems, geometry problems further emphasize multi-modal formats and the translation between informal and formal languages. In this paper, we introduce a novel task for geometry problem generation and propose a new pipeline method: the Symbolic Deduction Engine-based Geometry Problem Generation framework (SDE-GPG). The framework leverages a symbolic deduction engine and contains four main steps: (1) searching a predefined mapping table from knowledge points to extended definitions, (2) sampling extended definitions and performing symbolic deduction, (3) filtering out unqualified problems, and (4) generating textual problems and diagrams. Specifically, our method supports to avoid inherent biases in translating natural language into formal language by designing the mapping table, and guarantees to control the generated problems in terms of knowledge points and difficulties by an elaborate checking function. With obtained formal problems, they are translated to natural language and the accompanying diagrams are automatically drew by rule-based methods. We conduct experiments using real-world combinations of knowledge points from two public datasets. The results demonstrate that the SDE-GPG can effectively generate readable, solvable and controllable geometry problems.","authors":["Zhuoxuan Jiang","Tianyang Zhang","Peiyan Peng","Jing Chen","Yinong Xun","Haotian Zhang","Lichi Li","Yong Li","Shaohua Zhang"],"url":"https://arxiv.org/abs/2506.02565"}
{"created":"2025-06-04","title":"GANORM: Lifespan Normative Modeling of EEG Network Topology based on Multinational Cross-Spectra","abstract":"Charting the lifespan evolutionary trajectory of brain function serves as the normative standard for preventing mental disorders during brain development and aging. Although numerous MRI studies have mapped the structural connectome for young cohorts, the EEG-based functional connectome is unknown to characterize human lifespan, limiting its practical applications for the early detection of brain dysfunctions at the community level. This work aimed to undertake normative modeling from the perspective of EEG network topology. Frequency-dependent scalp EEG functional networks were constructed based on EEG cross-spectra aged 5-97 years from 9 countries and network characteristics were quantified. First, GAMLSS were applied to describe the normative curves of the network characteristics in different frequency bands. Subsequently, addressing the limitations of existing regression approaches for whole brain network analysis, this paper proposed an interpretable encoder-decoder framework, Generative Age-dependent brain Network nORmative Model (GANORM). Building upon this framework, we established an age-dependent normative trajectory of the complete brain network for the entire lifespan. Finally, we validated the effectiveness of the norm using EEG datasets from multiple sites. Subsequently, we evaluated the effectiveness of GANORM, and the tested performances of BPNN showed the R^2 was 0.796, the MAE was 0.081, and the RMSE was 0.013. Following established lifespan brain network norm, GANORM also exhibited good results upon verification using healthy and disease data from various sites. The deviation scores from the normative mean for the healthy control group were significantly smaller than those of the disease group.","authors":["Shiang Hu","Xiaolong Huang","Yifan Hu","Xue Xiang","Xiaoliang Sheng","Debin Zhou","Pedro A. Valdes-Sosa"],"url":"https://arxiv.org/abs/2506.02566"}
{"created":"2025-06-04","title":"MLaGA: Multimodal Large Language and Graph Assistant","abstract":"Large Language Models (LLMs) have demonstrated substantial efficacy in advancing graph-structured data analysis. Prevailing LLM-based graph methods excel in adapting LLMs to text-rich graphs, wherein node attributes are text descriptions. However, their applications to multimodal graphs--where nodes are associated with diverse attribute types, such as texts and images--remain underexplored, despite their ubiquity in real-world scenarios. To bridge the gap, we introduce the Multimodal Large Language and Graph Assistant (MLaGA), an innovative model that adeptly extends LLM capabilities to facilitate reasoning over complex graph structures and multimodal attributes. We first design a structure-aware multimodal encoder to align textual and visual attributes within a unified space through a joint graph pre-training objective. Subsequently, we implement a multimodal instruction-tuning approach to seamlessly integrate multimodal features and graph structures into the LLM through lightweight projectors. Extensive experiments across multiple datasets demonstrate the effectiveness of MLaGA compared to leading baseline methods, achieving superior performance in diverse graph learning tasks under both supervised and transfer learning scenarios.","authors":["Dongzhe Fan","Yi Fang","Jiajin Liu","Djellel Difallah","Qiaoyu Tan"],"url":"https://arxiv.org/abs/2506.02568"}
{"created":"2025-06-04","title":"Contrast & Compress: Learning Lightweight Embeddings for Short Trajectories","abstract":"The ability to retrieve semantically and directionally similar short-range trajectories with both accuracy and efficiency is foundational for downstream applications such as motion forecasting and autonomous navigation. However, prevailing approaches often depend on computationally intensive heuristics or latent anchor representations that lack interpretability and controllability. In this work, we propose a novel framework for learning fixed-dimensional embeddings for short trajectories by leveraging a Transformer encoder trained with a contrastive triplet loss that emphasize the importance of discriminative feature spaces for trajectory data. We analyze the influence of Cosine and FFT-based similarity metrics within the contrastive learning paradigm, with a focus on capturing the nuanced directional intent that characterizes short-term maneuvers. Our empirical evaluation on the Argoverse 2 dataset demonstrates that embeddings shaped by Cosine similarity objectives yield superior clustering of trajectories by both semantic and directional attributes, outperforming FFT-based baselines in retrieval tasks. Notably, we show that compact Transformer architectures, even with low-dimensional embeddings (e.g., 16 dimensions, but qualitatively down to 4), achieve a compelling balance between retrieval performance (minADE, minFDE) and computational overhead, aligning with the growing demand for scalable and interpretable motion priors in real-time systems. The resulting embeddings provide a compact, semantically meaningful, and efficient representation of trajectory data, offering a robust alternative to heuristic similarity measures and paving the way for more transparent and controllable motion forecasting pipelines.","authors":["Abhishek Vivekanandan","Christian Hubschneider","J. Marius Z\\\"ollner"],"url":"https://arxiv.org/abs/2506.02571"}
{"created":"2025-06-04","title":"HATA: Trainable and Hardware-Efficient Hash-Aware Top-k Attention for Scalable Large Model Inference","abstract":"Large Language Models (LLMs) have emerged as a pivotal research area, yet the attention module remains a critical bottleneck in LLM inference, even with techniques like KVCache to mitigate redundant computations. While various top-$k$ attention mechanisms have been proposed to accelerate LLM inference by exploiting the inherent sparsity of attention, they often struggled to strike a balance between efficiency and accuracy. In this paper, we introduce HATA (Hash-Aware Top-$k$ Attention), a novel approach that systematically integrates low-overhead learning-to-hash techniques into the Top-$k$ attention process. Different from the existing top-k attention methods which are devoted to seeking an absolute estimation of qk score, typically with a great cost, HATA maps queries and keys into binary hash codes, and acquires the relative qk score order with a quite low cost, which is sufficient for realizing top-k attention. Extensive experiments demonstrate that HATA achieves up to 7.2$\\times$ speedup compared to vanilla full attention while maintaining model accuracy. In addition, HATA outperforms the state-of-the-art top-$k$ attention methods in both accuracy and efficiency across multiple mainstream LLM models and diverse tasks. HATA is open source at https://github.com/gpzlx1/HATA.","authors":["Ping Gong","Jiawei Yi","Shengnan Wang","Juncheng Zhang","Zewen Jin","Ouxiang Zhou","Ruibo Liu","Guanbin Xu","Youhui Bai","Bowen Ye","Kun Yuan","Tong Yang","Gong Zhang","Renhai Chen","Feng Wu","Cheng Li"],"url":"https://arxiv.org/abs/2506.02572"}
{"created":"2025-06-04","title":"IndoSafety: Culturally Grounded Safety for LLMs in Indonesian Languages","abstract":"Although region-specific large language models (LLMs) are increasingly developed, their safety remains underexplored, particularly in culturally diverse settings like Indonesia, where sensitivity to local norms is essential and highly valued by the community. In this work, we present IndoSafety, the first high-quality, human-verified safety evaluation dataset tailored for the Indonesian context, covering five language varieties: formal and colloquial Indonesian, along with three major local languages: Javanese, Sundanese, and Minangkabau. IndoSafety is constructed by extending prior safety frameworks to develop a taxonomy that captures Indonesia's sociocultural context. We find that existing Indonesian-centric LLMs often generate unsafe outputs, particularly in colloquial and local language settings, while fine-tuning on IndoSafety significantly improves safety while preserving task performance. Our work highlights the critical need for culturally grounded safety evaluation and provides a concrete step toward responsible LLM deployment in multilingual settings. Warning: This paper contains example data that may be offensive, harmful, or biased.","authors":["Muhammad Falensi Azmi","Muhammad Dehan Al Kautsar","Alfan Farizki Wicaksono","Fajri Koto"],"url":"https://arxiv.org/abs/2506.02573"}
{"created":"2025-06-04","title":"ADFormer: Aggregation Differential Transformer for Passenger Demand Forecasting","abstract":"Passenger demand forecasting helps optimize vehicle scheduling, thereby improving urban efficiency. Recently, attention-based methods have been used to adequately capture the dynamic nature of spatio-temporal data. However, existing methods that rely on heuristic masking strategies cannot fully adapt to the complex spatio-temporal correlations, hindering the model from focusing on the right context. These works also overlook the high-level correlations that exist in the real world. Effectively integrating these high-level correlations with the original correlations is crucial. To fill this gap, we propose the Aggregation Differential Transformer (ADFormer), which offers new insights to demand forecasting promotion. Specifically, we utilize Differential Attention to capture the original spatial correlations and achieve attention denoising. Meanwhile, we design distinct aggregation strategies based on the nature of space and time. Then, the original correlations are unified with the high-level correlations, enabling the model to capture holistic spatio-temporal relations. Experiments conducted on taxi and bike datasets confirm the effectiveness and efficiency of our model, demonstrating its practical value. The code is available at https://github.com/decisionintelligence/ADFormer.","authors":["Haichen Wang","Liu Yang","Xinyuan Zhang","Haomin Yu","Ming Li","Jilin Hu"],"url":"https://arxiv.org/abs/2506.02576"}
{"created":"2025-06-04","title":"Reachability Weighted Offline Goal-conditioned Resampling","abstract":"Offline goal-conditioned reinforcement learning (RL) relies on fixed datasets where many potential goals share the same state and action spaces. However, these potential goals are not explicitly represented in the collected trajectories. To learn a generalizable goal-conditioned policy, it is common to sample goals and state-action pairs uniformly using dynamic programming methods such as Q-learning. Uniform sampling, however, requires an intractably large dataset to cover all possible combinations and creates many unreachable state-goal-action pairs that degrade policy performance. Our key insight is that sampling should favor transitions that enable goal achievement. To this end, we propose Reachability Weighted Sampling (RWS). RWS uses a reachability classifier trained via positive-unlabeled (PU) learning on goal-conditioned state-action values. The classifier maps these values to a reachability score, which is then used as a sampling priority. RWS is a plug-and-play module that integrates seamlessly with standard offline RL algorithms. Experiments on six complex simulated robotic manipulation tasks, including those with a robot arm and a dexterous hand, show that RWS significantly improves performance. In one notable case, performance on the HandBlock-Z task improved by nearly 50 percent relative to the baseline. These results indicate the effectiveness of reachability-weighted sampling.","authors":["Wenyan Yang","Joni Pajarinen"],"url":"https://arxiv.org/abs/2506.02577"}
{"created":"2025-06-04","title":"V2X-UniPool: Unifying Multimodal Perception and Knowledge Reasoning for Autonomous Driving","abstract":"Knowledge-driven autonomous driving systems(ADs) offer powerful reasoning capabilities, but face two critical challenges: limited perception due to the short-sightedness of single-vehicle sensors, and hallucination arising from the lack of real-time environmental grounding. To address these issues, this paper introduces V2X-UniPool, a unified framework that integrates multimodal Vehicle-to-Everything (V2X) data into a time-indexed and language-based knowledge pool. By leveraging a dual-query Retrieval-Augmented Generation (RAG) mechanism, which enables retrieval of both static and dynamic knowledge, our system enables ADs to perform accurate, temporally consistent reasoning over both static environment and dynamic traffic context. Experiments on a real-world cooperative driving dataset demonstrate that V2X-UniPool significantly enhances motion planning accuracy and reasoning capability. Remarkably, it enables even zero-shot vehicle-side models to achieve state-of-the-art performance by leveraging V2X-UniPool, while simultaneously reducing transmission cost by over 99.9\\% compared to prior V2X methods.","authors":["Xuewen Luo","Fengze Yang","Fan Ding","Xiangbo Gao","Shuo Xing","Yang Zhou","Zhengzhong Tu","Chenxi Liu"],"url":"https://arxiv.org/abs/2506.02580"}
{"created":"2025-06-04","title":"Distributedness based scheduling","abstract":"Efficient utilization of computing resources in a Kubernetes cluster is often constrained by the uneven distribution of pods with similar usage patterns. This paper presents a novel scheduling strategy designed to optimize the distributedness of Kubernetes resources based on their usage magnitude and patterns across CPU, memory, network, and storage. By categorizing resource usage into labels such as \"cpu high spike\" or \"memory medium always,\" and applying these to deployed pods, the system calculates the variance or distributedness factor of similar resource types across cluster nodes. A lower variance indicates a more balanced distribution. The Kubernetes scheduler is enhanced to consider this factor during scheduling decisions, placing new pods on nodes that minimize resource clustering. Furthermore, the approach supports redistribution of existing pods through simulated scheduling to improve balance. This method is adaptable at the cluster, namespace, or application level and is integrated within the standard Kubernetes scheduler, providing a scalable, label-driven mechanism to improve overall resource efficiency in cloud-native environments.","authors":["Paritosh Ranjan","Surajit Majumder","Prodip Roy","Bhuban Padhan"],"url":"https://arxiv.org/abs/2506.02581"}
{"created":"2025-06-04","title":"Prosodic Structure Beyond Lexical Content: A Study of Self-Supervised Learning","abstract":"People exploit the predictability of lexical structures during text comprehension. Though predictable structure is also present in speech, the degree to which prosody, e.g. intonation, tempo, and loudness, contributes to such structure independently of the lexical content is unclear. This study leverages self-supervised learning (SSL) to examine the temporal granularity of structures in the acoustic correlates of prosody. Representations from our proposed Masked Prosody Model can predict perceptual labels dependent on local information, such as word boundaries, but provide the most value for labels involving longer-term structures, like emotion recognition. Probing experiments across various perceptual labels show strong relative gains over untransformed pitch, energy, and voice activity features. Our results reveal the importance of SSL training objective timescale and highlight the value of complex SSL-encoded structures compared to more constrained classical structures.","authors":["Sarenne Wallbridge","Christoph Minixhofer","Catherine Lai","Peter Bell"],"url":"https://arxiv.org/abs/2506.02584"}
{"created":"2025-06-04","title":"BEVCALIB: LiDAR-Camera Calibration via Geometry-Guided Bird's-Eye View Representations","abstract":"Accurate LiDAR-camera calibration is fundamental to fusing multi-modal perception in autonomous driving and robotic systems. Traditional calibration methods require extensive data collection in controlled environments and cannot compensate for the transformation changes during the vehicle/robot movement. In this paper, we propose the first model that uses bird's-eye view (BEV) features to perform LiDAR camera calibration from raw data, termed BEVCALIB. To achieve this, we extract camera BEV features and LiDAR BEV features separately and fuse them into a shared BEV feature space. To fully utilize the geometric information from the BEV feature, we introduce a novel feature selector to filter the most important features in the transformation decoder, which reduces memory consumption and enables efficient training. Extensive evaluations on KITTI, NuScenes, and our own dataset demonstrate that BEVCALIB establishes a new state of the art. Under various noise conditions, BEVCALIB outperforms the best baseline in the literature by an average of (47.08%, 82.32%) on KITTI dataset, and (78.17%, 68.29%) on NuScenes dataset, in terms of (translation, rotation), respectively. In the open-source domain, it improves the best reproducible baseline by one order of magnitude. Our code and demo results are available at https://cisl.ucr.edu/BEVCalib.","authors":["Weiduo Yuan","Jerry Li","Justin Yue","Divyank Shah","Konstantinos Karydis","Hang Qiu"],"url":"https://arxiv.org/abs/2506.02587"}
{"created":"2025-06-04","title":"Evaluating Named Entity Recognition Models for Russian Cultural News Texts: From BERT to LLM","abstract":"This paper addresses the challenge of Named Entity Recognition (NER) for person names within the specialized domain of Russian news texts concerning cultural events. The study utilizes the unique SPbLitGuide dataset, a collection of event announcements from Saint Petersburg spanning 1999 to 2019. A comparative evaluation of diverse NER models is presented, encompassing established transformer-based architectures such as DeepPavlov, RoBERTa, and SpaCy, alongside recent Large Language Models (LLMs) including GPT-3.5, GPT-4, and GPT-4o. Key findings highlight the superior performance of GPT-4o when provided with specific prompting for JSON output, achieving an F1 score of 0.93. Furthermore, GPT-4 demonstrated the highest precision at 0.99. The research contributes to a deeper understanding of current NER model capabilities and limitations when applied to morphologically rich languages like Russian within the cultural heritage domain, offering insights for researchers and practitioners. Follow-up evaluation with GPT-4.1 (April 2025) achieves F1=0.94 for both simple and structured prompts, demonstrating rapid progress across model families and simplified deployment requirements.","authors":["Maria Levchenko"],"url":"https://arxiv.org/abs/2506.02589"}
{"created":"2025-06-04","title":"Synthetic Speech Source Tracing using Metric Learning","abstract":"This paper addresses source tracing in synthetic speech-identifying generative systems behind manipulated audio via speaker recognition-inspired pipelines. While prior work focuses on spoofing detection, source tracing lacks robust solutions. We evaluate two approaches: classification-based and metric-learning. We tested our methods on the MLAADv5 benchmark using ResNet and self-supervised learning (SSL) backbones. The results show that ResNet achieves competitive performance with the metric learning approach, matching and even exceeding SSL-based systems. Our work demonstrates ResNet's viability for source tracing while underscoring the need to optimize SSL representations for this task. Our work bridges speaker recognition methodologies with audio forensic challenges, offering new directions for combating synthetic media manipulation.","authors":["Dimitrios Koutsianos","Stavros Zacharopoulos","Yannis Panagakis","Themos Stafylakis"],"url":"https://arxiv.org/abs/2506.02590"}
{"created":"2025-06-04","title":"On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures","abstract":"Measurement systems (e.g., currencies) differ across cultures, but the conversions between them are well defined so that humans can state facts using any measurement system of their choice. Being available to users from diverse cultural backgrounds, large language models (LLMs) should also be able to provide accurate information irrespective of the measurement system at hand. Using newly compiled datasets we test if this is the case for seven open-source LLMs, addressing three key research questions: (RQ1) What is the default system used by LLMs for each type of measurement? (RQ2) Do LLMs' answers and their accuracy vary across different measurement systems? (RQ3) Can LLMs mitigate potential challenges w.r.t. underrepresented systems via reasoning? Our findings show that LLMs default to the measurement system predominantly used in the data. Additionally, we observe considerable instability and variance in performance across different measurement systems. While this instability can in part be mitigated by employing reasoning methods such as chain-of-thought (CoT), this implies longer responses and thereby significantly increases test-time compute (and inference costs), marginalizing users from cultural backgrounds that use underrepresented measurement systems.","authors":["Minh Duc Bui","Kyung Eun Park","Goran Glava\\v{s}","Fabian David Schmidt","Katharina von der Wense"],"url":"https://arxiv.org/abs/2506.02591"}
{"created":"2025-06-04","title":"Beyond the Surface: Measuring Self-Preference in LLM Judgments","abstract":"Recent studies show that large language models (LLMs) exhibit self-preference bias when serving as judges, meaning they tend to favor their own responses over those generated by other models. Existing methods typically measure this bias by calculating the difference between the scores a judge model assigns to its own responses and those it assigns to responses from other models. However, this approach conflates self-preference bias with response quality, as higher-quality responses from the judge model may also lead to positive score differences, even in the absence of bias. To address this issue, we introduce gold judgments as proxies for the actual quality of responses and propose the DBG score, which measures self-preference bias as the difference between the scores assigned by the judge model to its own responses and the corresponding gold judgments. Since gold judgments reflect true response quality, the DBG score mitigates the confounding effect of response quality on bias measurement. Using the DBG score, we conduct comprehensive experiments to assess self-preference bias across LLMs of varying versions, sizes, and reasoning abilities. Additionally, we investigate two factors that influence and help alleviate self-preference bias: response text style and the post-training data of judge models. Finally, we explore potential underlying mechanisms of self-preference bias from an attention-based perspective. Our code and data are available at https://github.com/zhiyuanc2001/self-preference.","authors":["Zhi-Yuan Chen","Hao Wang","Xinyu Zhang","Enrui Hu","Yankai Lin"],"url":"https://arxiv.org/abs/2506.02592"}
{"created":"2025-06-04","title":"A Hybrid Approach to Indoor Social Navigation: Integrating Reactive Local Planning and Proactive Global Planning","abstract":"We consider the problem of indoor building-scale social navigation, where the robot must reach a point goal as quickly as possible without colliding with humans who are freely moving around. Factors such as varying crowd densities, unpredictable human behavior, and the constraints of indoor spaces add significant complexity to the navigation task, necessitating a more advanced approach. We propose a modular navigation framework that leverages the strengths of both classical methods and deep reinforcement learning (DRL). Our approach employs a global planner to generate waypoints, assigning soft costs around anticipated pedestrian locations, encouraging caution around potential future positions of humans. Simultaneously, the local planner, powered by DRL, follows these waypoints while avoiding collisions. The combination of these planners enables the agent to perform complex maneuvers and effectively navigate crowded and constrained environments while improving reliability. Many existing studies on social navigation are conducted in simplistic or open environments, limiting the ability of trained models to perform well in complex, real-world settings. To advance research in this area, we introduce a new 2D benchmark designed to facilitate development and testing of social navigation strategies in indoor environments. We benchmark our method against traditional and RL-based navigation strategies, demonstrating that our approach outperforms both.","authors":["Arnab Debnath","Gregory J. Stein","Jana Kosecka"],"url":"https://arxiv.org/abs/2506.02593"}
{"created":"2025-06-04","title":"EALG: Evolutionary Adversarial Generation of Language Model-Guided Generators for Combinatorial Optimization","abstract":"Generating challenging instances is crucial for the evaluation and advancement of combinatorial optimization solvers. In this work, we introduce EALG (Evolutionary Adversarial Generation of Language Model-Guided Generators), a novel framework that automates the co-evolution of optimization problem instances and their corresponding heuristic solvers using large language models (LLMs). EALG leverages a mutation-based adversarial approach that dynamically evolves instance generation procedures to create increasingly difficult problems, while simultaneously synthesizing adaptive heuristic algorithms through interactions with LLMs guided by algorithmic structure. Unlike existing approaches that focus solely on static benchmark creation or manual solver design, EALG provides a seamless pipeline from instance generation to solver synthesis. Experimental results demonstrate that EALG generates significantly harder instances than current benchmarks, and its synthesized solvers generalize effectively across a broad spectrum of combinatorial tasks. This work explores a new paradigm for combinatorial optimization that integrates instance generation with solver design, resulting in state-of-the-art performance.","authors":["Ruibo Duan","Yuxin Liu","Xinyao Dong","Chenglin Fan"],"url":"https://arxiv.org/abs/2506.02594"}
{"created":"2025-06-04","title":"Numerical methods for fully nonlinear degenerate diffusions","abstract":"We propose finite difference methods for degenerate fully nonlinear elliptic equations and prove the convergence of the schemes. Our focus is on the pure equation and a related free boundary problem of transmission type. The cornerstone of our argument is a regularisation procedure. It decouples the degeneracy term from the elliptic operator driving the diffusion process. In the free boundary setting, the absence of degenerate ellipticity entails new, genuine difficulties. To bypass them, we resort to the intrinsic properties of the regularised problem. We present numerical experiments supporting our theoretical results. Our methods are flexible, and our approach can be extended to a broader class of non-variational problems.","authors":["Edgard A. Pimentel","Erc\\'ilia Sousa"],"url":"https://arxiv.org/abs/2506.02595"}
{"created":"2025-06-04","title":"EssayBench: Evaluating Large Language Models in Multi-Genre Chinese Essay Writing","abstract":"Chinese essay writing and its evaluation are critical in educational contexts, yet the capabilities of Large Language Models (LLMs) in this domain remain largely underexplored. Existing benchmarks often rely on coarse-grained text quality metrics, largely overlooking the structural and rhetorical complexities of Chinese essays, particularly across diverse genres. To address this gap, we propose \\benchName, a multi-genre benchmark specifically designed for Chinese essay writing across four major genres: Argumentative, Narrative, Descriptive, and Expository. We curate and refine a total of 728 real-world prompts to ensure authenticity and meticulously categorize them into the \\textit{Open-Ended} and \\textit{Constrained} sets to capture diverse writing scenarios. To reliably evaluate generated essays, we develop a fine-grained, genre-specific scoring framework that hierarchically aggregates scores. We further validate our evaluation protocol through a comprehensive human agreement study. Finally, we benchmark 15 large-sized LLMs, analyzing their strengths and limitations across genres and instruction types. With \\benchName, we aim to advance LLM-based Chinese essay evaluation and inspire future research on improving essay generation in educational settings.","authors":["Fan Gao","Dongyuan Li","Ding Xia","Fei Mi","Yasheng Wang","Lifeng Shang","Baojun Wang"],"url":"https://arxiv.org/abs/2506.02596"}
{"created":"2025-06-04","title":"Assessing the Completeness of Traffic Scenario Categories for Automated Highway Driving Functions via Cluster-based Analysis","abstract":"The ability to operate safely in increasingly complex traffic scenarios is a fundamental requirement for Automated Driving Systems (ADS). Ensuring the safe release of ADS functions necessitates a precise understanding of the occurring traffic scenarios. To support this objective, this work introduces a pipeline for traffic scenario clustering and the analysis of scenario category completeness. The Clustering Vector Quantized - Variational Autoencoder (CVQ-VAE) is employed for the clustering of highway traffic scenarios and utilized to create various catalogs with differing numbers of traffic scenario categories. Subsequently, the impact of the number of categories on the completeness considerations of the traffic scenario categories is analyzed. The results show an outperforming clustering performance compared to previous work. The trade-off between cluster quality and the amount of required data to maintain completeness is discussed based on the publicly available highD dataset.","authors":["Niklas Ro{\\ss}berg","Marion Neumeier","Sinan Hasirlioglu","Mohamed Essayed Bouzouraa","Michael Botsch"],"url":"https://arxiv.org/abs/2506.02599"}
{"created":"2025-06-04","title":"Hyperspectral Image Generation with Unmixing Guided Diffusion Model","abstract":"Recently, hyperspectral image generation has received increasing attention, but existing generative models rely on conditional generation schemes, which limits the diversity of generated images. Diffusion models are popular for their ability to generate high-quality samples, but adapting these models from RGB to hyperspectral data presents the challenge of high dimensionality and physical constraints. To address these challenges, we propose a novel diffusion model guided by hyperspectral unmixing. Our model comprises two key modules: an unmixing autoencoder module and an abundance diffusion module. The unmixing autoencoder module leverages unmixing guidance to shift the generative task from the image space to the low-dimensional abundance space, significantly reducing computational complexity while preserving high fidelity. The abundance diffusion module generates samples that satisfy the constraints of non-negativity and unity, ensuring the physical consistency of the reconstructed HSIs. Additionally, we introduce two evaluation metrics tailored to hyperspectral data. Empirical results, evaluated using both traditional metrics and our proposed metrics, indicate that our model is capable of generating high-quality and diverse hyperspectral images, offering an advancement in hyperspectral data generation.","authors":["Shiyu Shen","Bin Pan","Ziye Zhang","Zhenwei Shi"],"url":"https://arxiv.org/abs/2506.02601"}
{"created":"2025-06-04","title":"Computational adversarial risk analysis for general security games","abstract":"This paper provides an efficient computational scheme to handle general security games from an adversarial risk analysis perspective. Two cases in relation to single-stage and multi-stage simultaneous defend-attack games motivate our approach to general setups which uses bi-agent influence diagrams as underlying problem structure and augmented probability simulation as core computational methodology. Theoretical convergence and numerical, modeling, and implementation issues are thoroughly discussed. A disinformation war case study illustrates the relevance of the proposed approach.","authors":["Jose Manuel Camacho","Roi Naveiro","David Rios Insua"],"url":"https://arxiv.org/abs/2506.02603"}
{"created":"2025-06-04","title":"Application of convolutional neural networks in image super-resolution","abstract":"Due to strong learning abilities of convolutional neural networks (CNNs), they have become mainstream methods for image super-resolution. However, there are big differences of different deep learning methods with different types. There is little literature to summarize relations and differences of different methods in image super-resolution. Thus, summarizing these literatures are important, according to loading capacity and execution speed of devices. This paper first introduces principles of CNNs in image super-resolution, then introduces CNNs based bicubic interpolation, nearest neighbor interpolation, bilinear interpolation, transposed convolution, sub-pixel layer, meta up-sampling for image super-resolution to analyze differences and relations of different CNNs based interpolations and modules, and compare performance of these methods by experiments. Finally, this paper gives potential research points and drawbacks and summarizes the whole paper, which can facilitate developments of CNNs in image super-resolution.","authors":["Tian Chunwei","Song Mingjian","Zuo Wangmeng","Du Bo","Zhang Yanning","Zhang Shichao"],"url":"https://arxiv.org/abs/2506.02604"}
{"created":"2025-06-04","title":"One-Step Diffusion-based Real-World Image Super-Resolution with Visual Perception Distillation","abstract":"Diffusion-based models have been widely used in various visual generation tasks, showing promising results in image super-resolution (SR), while typically being limited by dozens or even hundreds of sampling steps. Although existing methods aim to accelerate the inference speed of multi-step diffusion-based SR methods through knowledge distillation, their generated images exhibit insufficient semantic alignment with real images, resulting in suboptimal perceptual quality reconstruction, specifically reflected in the CLIPIQA score. These methods still have many challenges in perceptual quality and semantic fidelity. Based on the challenges, we propose VPD-SR, a novel visual perception diffusion distillation framework specifically designed for SR, aiming to construct an effective and efficient one-step SR model. Specifically, VPD-SR consists of two components: Explicit Semantic-aware Supervision (ESS) and High-Frequency Perception (HFP) loss. Firstly, the ESS leverages the powerful visual perceptual understanding capabilities of the CLIP model to extract explicit semantic supervision, thereby enhancing semantic consistency. Then, Considering that high-frequency information contributes to the visual perception quality of images, in addition to the vanilla distillation loss, the HFP loss guides the student model to restore the missing high-frequency details in degraded images that are critical for enhancing perceptual quality. Lastly, we expand VPD-SR in adversarial training manner to further enhance the authenticity of the generated content. Extensive experiments conducted on synthetic and real-world datasets demonstrate that the proposed VPD-SR achieves superior performance compared to both previous state-of-the-art methods and the teacher model with just one-step sampling.","authors":["Xue Wu","Jingwei Xin","Zhijun Tu","Jie Hu","Jie Li","Nannan Wang","Xinbo Gao"],"url":"https://arxiv.org/abs/2506.02605"}
{"created":"2025-06-04","title":"Multi Layered Autonomy and AI Ecologies in Robotic Art Installations","abstract":"Symbiosis of Agents is a large-scale installation by Baoyang Chen that embeds AI-driven robots in an immersive, mirror-lined arena, probing the tension between machine agency and artistic authorship. Drawing on early cybernetics, rule-based conceptual art, and seminal robotic works, it orchestrates fluid exchanges among robotic arms, quadruped machines, their environment, and the public. A three tier faith system pilots the ecology: micro-level adaptive tactics, meso-level narrative drives, and a macro-level prime directive. This hierarchy lets behaviors evolve organically in response to environmental cues and even a viewer's breath, turning spectators into co-authors of the unfolding drama.Framed by a speculative terraforming scenario that recalls the historical exploitation of marginalized labor, the piece asks who bears responsibility in AI-mediated futures. Choreographed motion, AI-generated scripts, reactive lighting, and drifting fog cast the robots as collaborators rather than tools, forging a living, emergent artwork. Exhibited internationally, Symbiosis of Agents shows how cybernetic feedback, robotic experimentation, and conceptual rule-making can converge to redefine agency, authorship, and ethics in contemporary art.","authors":["Baoyang Chen","Xian Xu","Huamin Qu"],"url":"https://arxiv.org/abs/2506.02606"}
{"created":"2025-06-04","title":"A Time-Enhanced Data Disentanglement Network for Traffic Flow Forecasting","abstract":"In recent years, traffic flow prediction has become a highlight in the field of intelligent transportation systems. However, due to the temporal variations and dynamic spatial correlations of traffic data, traffic prediction remains highly challenging.Traditional spatiotemporal networks, which rely on end-to-end training, often struggle to handle the diverse data dependencies of multiple traffic flow patterns. Additionally, traffic flow variations are highly sensitive to temporal information changes. Regrettably, other researchers have not sufficiently recognized the importance of temporal information.To address these challenges, we propose a novel approach called A Time-Enhanced Data Disentanglement Network for Traffic Flow Forecasting (TEDDN). This network disentangles the originally complex and intertwined traffic data into stable patterns and trends. By flexibly learning temporal and node information through a dynamic graph enhanced by a temporal feature extraction module, TEDDN demonstrates significant efficacy in disentangling and extracting complex traffic information. Experimental evaluations and ablation studies on four real-world datasets validate the superiority of our method.","authors":["Tianfan Jiang","Mei Wu","Wenchao Weng","Dewen Seng","Yiqian Lin"],"url":"https://arxiv.org/abs/2506.02609"}
{"created":"2025-06-04","title":"Speaker Diarization with Overlapping Community Detection Using Graph Attention Networks and Label Propagation Algorithm","abstract":"In speaker diarization, traditional clustering-based methods remain widely used in real-world applications. However, these methods struggle with the complex distribution of speaker embeddings and overlapping speech segments. To address these limitations, we propose an Overlapping Community Detection method based on Graph Attention networks and the Label Propagation Algorithm (OCDGALP). The proposed framework comprises two key components: (1) a graph attention network that refines speaker embeddings and node connections by aggregating information from neighboring nodes, and (2) a label propagation algorithm that assigns multiple community labels to each node, enabling simultaneous clustering and overlapping community detection. Experimental results show that the proposed method significantly reduces the Diarization Error Rate (DER), achieving a state-of-the-art 15.94% DER on the DIHARD-III dataset without oracle Voice Activity Detection (VAD), and an impressive 11.07% with oracle VAD.","authors":["Zhaoyang Li","Jie Wang","XiaoXiao Li","Wangjie Li","Longjie Luo","Lin Li","Qingyang Hong"],"url":"https://arxiv.org/abs/2506.02610"}
{"created":"2025-06-04","title":"Simple, Good, Fast: Self-Supervised World Models Free of Baggage","abstract":"What are the essential components of world models? How far do we get with world models that are not employing RNNs, transformers, discrete representations, and image reconstructions? This paper introduces SGF, a Simple, Good, and Fast world model that uses self-supervised representation learning, captures short-time dependencies through frame and action stacking, and enhances robustness against model errors through data augmentation. We extensively discuss SGF's connections to established world models, evaluate the building blocks in ablation studies, and demonstrate good performance through quantitative comparisons on the Atari 100k benchmark.","authors":["Jan Robine","Marc H\\\"oftmann","Stefan Harmeling"],"url":"https://arxiv.org/abs/2506.02612"}
{"created":"2025-06-04","title":"High Performance Space Debris Tracking in Complex Skylight Backgrounds with a Large-Scale Dataset","abstract":"With the rapid development of space exploration, space debris has attracted more attention due to its potential extreme threat, leading to the need for real-time and accurate debris tracking. However, existing methods are mainly based on traditional signal processing, which cannot effectively process the complex background and dense space debris. In this paper, we propose a deep learning-based Space Debris Tracking Network~(SDT-Net) to achieve highly accurate debris tracking. SDT-Net effectively represents the feature of debris, enhancing the efficiency and stability of end-to-end model learning. To train and evaluate this model effectively, we also produce a large-scale dataset Space Debris Tracking Dataset (SDTD) by a novel observation-based data simulation scheme. SDTD contains 18,040 video sequences with a total of 62,562 frames and covers 250,000 synthetic space debris. Extensive experiments validate the effectiveness of our model and the challenging of our dataset. Furthermore, we test our model on real data from the Antarctic Station, achieving a MOTA score of 70.6%, which demonstrates its strong transferability to real-world scenarios. Our dataset and code will be released soon.","authors":["Guohang Zhuang","Weixi Song","Jinyang Huang","Chenwei Yang","Yan Lu"],"url":"https://arxiv.org/abs/2506.02614"}
{"created":"2025-06-04","title":"Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models","abstract":"In this paper, we present a hierarchical question-answering (QA) approach for scene understanding in autonomous vehicles, balancing cost-efficiency with detailed visual interpretation. The method fine-tunes a compact vision-language model (VLM) on a custom dataset specific to the geographical area in which the vehicle operates to capture key driving-related visual elements. At the inference stage, the hierarchical QA strategy decomposes the scene understanding task into high-level and detailed sub-questions. Instead of generating lengthy descriptions, the VLM navigates a structured question tree, where answering high-level questions (e.g., \"Is it possible for the ego vehicle to turn left at the intersection?\") triggers more detailed sub-questions (e.g., \"Is there a vehicle approaching the intersection from the opposite direction?\"). To optimize inference time, questions are dynamically skipped based on previous answers, minimizing computational overhead. The extracted answers are then synthesized using handcrafted templates to ensure coherent, contextually accurate scene descriptions. We evaluate the proposed approach on the custom dataset using GPT reference-free scoring, demonstrating its competitiveness with state-of-the-art methods like GPT-4o in capturing key scene details while achieving significantly lower inference time. Moreover, qualitative results from real-time deployment highlight the proposed approach's capacity to capture key driving elements with minimal latency.","authors":["Safaa Abdullahi Moallim Mohamud","Minjin Baek","Dong Seog Han"],"url":"https://arxiv.org/abs/2506.02615"}
{"created":"2025-06-04","title":"Compositional Learning for Modular Multi-Agent Self-Organizing Networks","abstract":"Self-organizing networks face challenges from complex parameter interdependencies and conflicting objectives. This study introduces two compositional learning approaches-Compositional Deep Reinforcement Learning (CDRL) and Compositional Predictive Decision-Making (CPDM)-and evaluates their performance under training time and safety constraints in multi-agent systems. We propose a modular, two-tier framework with cell-level and cell-pair-level agents to manage heterogeneous agent granularities while reducing model complexity. Numerical simulations reveal a significant reduction in handover failures, along with improved throughput and latency, outperforming conventional multi-agent deep reinforcement learning approaches. The approach also demonstrates superior scalability, faster convergence, higher sample efficiency, and safer training in large-scale self-organizing networks.","authors":["Qi Liao","Parijat Bhattacharjee"],"url":"https://arxiv.org/abs/2506.02616"}
{"created":"2025-06-04","title":"Toward Understanding Bugs in Vector Database Management Systems","abstract":"Vector database management systems (VDBMSs) play a crucial role in facilitating semantic similarity searches over high-dimensional embeddings from diverse data sources. While VDBMSs are widely used in applications such as recommendation, retrieval-augmented generation (RAG), and multimodal search, their reliability remains underexplored. Traditional database reliability models cannot be directly applied to VDBMSs because of fundamental differences in data representation, query mechanisms, and system architecture. To address this gap, we present the first large-scale empirical study of software defects in VDBMSs. We manually analyzed 1,671 bug-fix pull requests from 15 widely used open-source VDBMSs and developed a comprehensive taxonomy of bugs based on symptoms, root causes, and developer fix strategies. Our study identifies five categories of bug symptoms, with more than half manifesting as functional failures. We further reveal 31 recurring fault patterns and highlight failure modes unique to vector search systems. In addition, we summarize 12 common fix strategies, whose distribution underscores the critical importance of correct program logic. These findings provide actionable insights into VDBMS reliability challenges and offer guidance for building more robust future systems.","authors":["Yinglin Xie","Xinyi Hou","Yanjie Zhao","Shenao Wang","Kai Chen","Haoyu Wang"],"url":"https://arxiv.org/abs/2506.02617"}
{"created":"2025-06-04","title":"Rodrigues Network for Learning Robot Actions","abstract":"Understanding and predicting articulated actions is important in robot learning. However, common architectures such as MLPs and Transformers lack inductive biases that reflect the underlying kinematic structure of articulated systems. To this end, we propose the Neural Rodrigues Operator, a learnable generalization of the classical forward kinematics operation, designed to inject kinematics-aware inductive bias into neural computation. Building on this operator, we design the Rodrigues Network (RodriNet), a novel neural architecture specialized for processing actions. We evaluate the expressivity of our network on two synthetic tasks on kinematic and motion prediction, showing significant improvements compared to standard backbones. We further demonstrate its effectiveness in two realistic applications: (i) imitation learning on robotic benchmarks with the Diffusion Policy, and (ii) single-image 3D hand reconstruction. Our results suggest that integrating structured kinematic priors into the network architecture improves action learning in various domains.","authors":["Jialiang Zhang","Haoran Geng","Yang You","Congyue Deng","Pieter Abbeel","Jitendra Malik","Leonidas Guibas"],"url":"https://arxiv.org/abs/2506.02618"}
{"created":"2025-06-04","title":"HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport","abstract":"Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent capabilities in processing heterogeneous information networks. Self-supervised learning on heterogeneous graphs, especially contrastive self-supervised strategy, shows great potential when there are no labels. However, this approach requires the use of carefully designed graph augmentation strategies and the selection of positive and negative samples. Determining the exact level of similarity between sample pairs is non-trivial.To solve this problem, we propose a novel self-supervised Heterogeneous graph neural network with Optimal Transport (HGOT) method which is designed to facilitate self-supervised learning for heterogeneous graphs without graph augmentation strategies. Different from traditional contrastive self-supervised learning, HGOT employs the optimal transport mechanism to relieve the laborious sampling process of positive and negative samples. Specifically, we design an aggregating view (central view) to integrate the semantic information contained in the views represented by different meta-paths (branch views). Then, we introduce an optimal transport plan to identify the transport relationship between the semantics contained in the branch view and the central view. This allows the optimal transport plan between graphs to align with the representations, forcing the encoder to learn node representations that are more similar to the graph space and of higher quality. Extensive experiments on four real-world datasets demonstrate that our proposed HGOT model can achieve state-of-the-art performance on various downstream tasks. In particular, in the node classification task, HGOT achieves an average of more than 6% improvement in accuracy compared with state-of-the-art methods.","authors":["Yanbei Liu","Chongxu Wang","Zhitao Xiao","Lei Geng","Yanwei Pang","Xiao Wang"],"url":"https://arxiv.org/abs/2506.02619"}
{"created":"2025-06-04","title":"FlexPainter: Flexible and Multi-View Consistent Texture Generation","abstract":"Texture map production is an important part of 3D modeling and determines the rendering quality. Recently, diffusion-based methods have opened a new way for texture generation. However, restricted control flexibility and limited prompt modalities may prevent creators from producing desired results. Furthermore, inconsistencies between generated multi-view images often lead to poor texture generation quality. To address these issues, we introduce \\textbf{FlexPainter}, a novel texture generation pipeline that enables flexible multi-modal conditional guidance and achieves highly consistent texture generation. A shared conditional embedding space is constructed to perform flexible aggregation between different input modalities. Utilizing such embedding space, we present an image-based CFG method to decompose structural and style information, achieving reference image-based stylization. Leveraging the 3D knowledge within the image diffusion prior, we first generate multi-view images simultaneously using a grid representation to enhance global understanding. Meanwhile, we propose a view synchronization and adaptive weighting module during diffusion sampling to further ensure local consistency. Finally, a 3D-aware texture completion model combined with a texture enhancement model is used to generate seamless, high-resolution texture maps. Comprehensive experiments demonstrate that our framework significantly outperforms state-of-the-art methods in both flexibility and generation quality.","authors":["Dongyu Yan","Leyi Wu","Jiantao Lin","Luozhou Wang","Tianshuo Xu","Zhifei Chen","Zhen Yang","Lie Xu","Shunsi Zhang","Yingcong Chen"],"url":"https://arxiv.org/abs/2506.02620"}
{"created":"2025-06-04","title":"Cross-attention and Self-attention for Audio-visual Speaker Diarization in MISP-Meeting Challenge","abstract":"This paper presents the system developed for Task 1 of the Multi-modal Information-based Speech Processing (MISP) 2025 Challenge. We introduce CASA-Net, an embedding fusion method designed for end-to-end audio-visual speaker diarization (AVSD) systems. CASA-Net incorporates a cross-attention (CA) module to effectively capture cross-modal interactions in audio-visual signals and employs a self-attention (SA) module to learn contextual relationships among audio-visual frames. To further enhance performance, we adopt a training strategy that integrates pseudo-label refinement and retraining, improving the accuracy of timestamp predictions. Additionally, median filtering and overlap averaging are applied as post-processing techniques to eliminate outliers and smooth prediction labels. Our system achieved a diarization error rate (DER) of 8.18% on the evaluation set, representing a relative improvement of 47.3% over the baseline DER of 15.52%.","authors":["Zhaoyang Li","Haodong Zhou","Longjie Luo","Xiaoxiao Li","Yongxin Chen","Lin Li","Qingyang Hong"],"url":"https://arxiv.org/abs/2506.02621"}
{"created":"2025-06-04","title":"HORUS: A Mixed Reality Interface for Managing Teams of Mobile Robots","abstract":"Mixed Reality (MR) interfaces have been extensively explored for controlling mobile robots, but there is limited research on their application to managing teams of robots. This paper presents HORUS: Holistic Operational Reality for Unified Systems, a Mixed Reality interface offering a comprehensive set of tools for managing multiple mobile robots simultaneously. HORUS enables operators to monitor individual robot statuses, visualize sensor data projected in real time, and assign tasks to single robots, subsets of the team, or the entire group, all from a Mini-Map (Ground Station). The interface also provides different teleoperation modes: a mini-map mode that allows teleoperation while observing the robot model and its transform on the mini-map, and a semi-immersive mode that offers a flat, screen-like view in either single or stereo view (3D). We conducted a user study in which participants used HORUS to manage a team of mobile robots tasked with finding clues in an environment, simulating search and rescue tasks. This study compared HORUS's full-team management capabilities with individual robot teleoperation. The experiments validated the versatility and effectiveness of HORUS in multi-robot coordination, demonstrating its potential to advance human-robot collaboration in dynamic, team-based environments.","authors":["Omotoye Shamsudeen Adekoya","Antonio Sgorbissa","Carmine Tommaso Recchiuto"],"url":"https://arxiv.org/abs/2506.02622"}
{"created":"2025-06-04","title":"SiamNAS: Siamese Surrogate Model for Dominance Relation Prediction in Multi-objective Neural Architecture Search","abstract":"Modern neural architecture search (NAS) is inherently multi-objective, balancing trade-offs such as accuracy, parameter count, and computational cost. This complexity makes NAS computationally expensive and nearly impossible to solve without efficient approximations. To address this, we propose a novel surrogate modelling approach that leverages an ensemble of Siamese network blocks to predict dominance relationships between candidate architectures. Lightweight and easy to train, the surrogate achieves 92% accuracy and replaces the crowding distance calculation in the survivor selection strategy with a heuristic rule based on model size. Integrated into a framework termed SiamNAS, this design eliminates costly evaluations during the search process. Experiments on NAS-Bench-201 demonstrate the framework's ability to identify Pareto-optimal solutions with significantly reduced computational costs. The proposed SiamNAS identified a final non-dominated set containing the best architecture in NAS-Bench-201 for CIFAR-10 and the second-best for ImageNet, in terms of test error rate, within 0.01 GPU days. This proof-of-concept study highlights the potential of the proposed Siamese network surrogate model to generalise to multi-tasking optimisation, enabling simultaneous optimisation across tasks. Additionally, it offers opportunities to extend the approach for generating Sets of Pareto Sets (SOS), providing diverse Pareto-optimal solutions for heterogeneous task settings.","authors":["Yuyang Zhou","Ferrante Neri","Yew-Soon Ong","Ruibin Bai"],"url":"https://arxiv.org/abs/2506.02623"}
{"created":"2025-06-04","title":"Zero-Energy RIS-Assisted Communications With Noise Modulation and Interference-Based Energy Harvesting","abstract":"To advance towards carbon-neutrality and improve the limited {performance} of conventional passive wireless communications, in this paper, we investigate the integration of noise modulation with zero-energy reconfigurable intelligent surfaces (RISs). In particular, the RIS reconfigurable elements (REs) are divided into two groups: one for beamforming the desired signals in reflection mode and another for harvesting energy from interference signals in an absorption mode, providing the power required for RIS operation. Since the harvested energy is a random variable, a random number of REs can beamform the signals, while the remainder blindly reflects them. We present a closed-form solution and a search algorithm for REs allocation, jointly optimizing both the energy harvesting (EH) and communication performance. Considering the repetition coding technique and discrete phase shifts, we derive analytical expressions for the energy constrained success rate, bit error rate, optimal threshold, mutual information, {and energy efficiency}. Numerical and simulation results confirm the effectiveness of the algorithm and expressions, demonstrating the superiority of the proposed integration over conventional noise-modulation systems. It is shown that by properly allocating the REs, both the EH and communication performance can be improved in low to moderate interference scenarios, while the latter is restricted in the high-interference regime.","authors":["Ahmad Massud Tota Khel","Aissa Ikhlef","Zhiguo Ding","Hongjian Sun"],"url":"https://arxiv.org/abs/2506.02625"}
{"created":"2025-06-04","title":"Synthetic Iris Image Databases and Identity Leakage: Risks and Mitigation Strategies","abstract":"This paper presents a comprehensive overview of iris image synthesis methods, which can alleviate the issues associated with gathering large, diverse datasets of biometric data from living individuals, which are considered pivotal for biometric methods development. These methods for synthesizing iris data range from traditional, hand crafted image processing-based techniques, through various iterations of GAN-based image generators, variational autoencoders (VAEs), as well as diffusion models. The potential and fidelity in iris image generation of each method is discussed and examples of inferred predictions are provided. Furthermore, the risks of individual biometric features leakage from the training sets are considered, together with possible strategies for preventing them, which have to be implemented should these generative methods be considered a valid replacement of real-world biometric datasets.","authors":["Ada Sawilska","Mateusz Trokielewicz"],"url":"https://arxiv.org/abs/2506.02626"}
{"created":"2025-06-04","title":"Overcoming Data Scarcity in Multi-Dialectal Arabic ASR via Whisper Fine-Tuning","abstract":"Although commercial Arabic automatic speech recognition (ASR) systems support Modern Standard Arabic (MSA), they struggle with dialectal speech. We investigate the effect of fine-tuning OpenAI's Whisper on five major Arabic dialects (Gulf, Levantine, Iraqi, Egyptian, Maghrebi) using Mozilla Common Voice for MSA and the MASC dataset for dialectal speech. We evaluate MSA training size effects, benefits of pre-training on MSA data, and dialect-specific versus dialect-pooled models. We find that small amounts of MSA fine-tuning data yield substantial improvements for smaller models, matching larger non-fine-tuned models. While MSA pre-training shows minimal benefit, suggesting limited shared features between MSA and dialects, our dialect-pooled models perform comparably to dialect-specific ones. This indicates that pooling dialectal data, when properly balanced, can help address data scarcity in low-resource ASR without significant performance loss.","authors":["\\\"Omer Tarik \\\"Ozyilmaz","Matt Coler","Matias Valdenegro-Toro"],"url":"https://arxiv.org/abs/2506.02627"}
{"created":"2025-06-04","title":"HAM: A Hyperbolic Step to Regulate Implicit Bias","abstract":"Understanding the implicit bias of optimization algorithms has become central to explaining the generalization behavior of deep learning models. For instance, the hyperbolic implicit bias induced by the overparameterization $m \\odot w$--though effective in promoting sparsity--can result in a small effective learning rate, which slows down convergence. To overcome this obstacle, we propose HAM (Hyperbolic Aware Minimization), which alternates between an optimizer step and a new hyperbolic mirror step. We derive the Riemannian gradient flow for its combination with gradient descent, leading to improved convergence and a similar beneficial hyperbolic geometry as $m \\odot w$ for feature learning. We provide an interpretation of the the algorithm by relating it to natural gradient descent, and an exact characterization of its implicit bias for underdetermined linear regression. HAM's implicit bias consistently boosts performance--even of dense training, as we demonstrate in experiments across diverse tasks, including vision, graph and node classification, and large language model fine-tuning. HAM is especially effective in combination with different sparsification methods, improving upon the state of the art. The hyperbolic step requires minimal computational and memory overhead, it succeeds even with small batch sizes, and its implementation integrates smoothly with existing optimizers.","authors":["Tom Jacobs","Advait Gadhikar","Celia Rubio-Madrigal","Rebekka Burkholz"],"url":"https://arxiv.org/abs/2506.02630"}
{"created":"2025-06-04","title":"ControlMambaIR: Conditional Controls with State-Space Model for Image Restoration","abstract":"This paper proposes ControlMambaIR, a novel image restoration method designed to address perceptual challenges in image deraining, deblurring, and denoising tasks. By integrating the Mamba network architecture with the diffusion model, the condition network achieves refined conditional control, thereby enhancing the control and optimization of the image generation process. To evaluate the robustness and generalization capability of our method across various image degradation conditions, extensive experiments were conducted on several benchmark datasets, including Rain100H, Rain100L, GoPro, and SSID. The results demonstrate that our proposed approach consistently surpasses existing methods in perceptual quality metrics, such as LPIPS and FID, while maintaining comparable performance in image distortion metrics, including PSNR and SSIM, highlighting its effectiveness and adaptability. Notably, ablation experiments reveal that directly noise prediction in the diffusion process achieves better performance, effectively balancing noise suppression and detail preservation. Furthermore, the findings indicate that the Mamba architecture is particularly well-suited as a conditional control network for diffusion models, outperforming both CNN- and Attention-based approaches in this context. Overall, these results highlight the flexibility and effectiveness of ControlMambaIR in addressing a range of image restoration perceptual challenges.","authors":["Cheng Yang","Lijing Liang","Zhixun Su"],"url":"https://arxiv.org/abs/2506.02633"}
{"created":"2025-06-04","title":"KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider","abstract":"Serving large language models (LLMs) is important for cloud providers, and caching intermediate results (KV\\$) after processing each request substantially improves serving throughput and latency. However, there is limited understanding of how LLM serving benefits from KV\\$ caching, where system design decisions like cache eviction policies are highly workload-dependent. In this paper, we present the first systematic characterization of the KV\\$ workload patterns from one of the leading LLM service providers. We draw observations that were not covered by previous studies focusing on synthetic workloads, including: KV\\$ reuses are skewed across requests, where reuses between single-turn requests are equally important as multi-turn requests; the reuse time and probability are diverse considering all requests, but for a specific request category, the pattern tends to be predictable; and the overall cache size required for an ideal cache hit ratio is moderate. Based on the characterization, we further propose a workload-aware cache eviction policy that improves the serving performance under real-world traces, especially with limited cache capacity.","authors":["Jiahao Wang","Jinbo Han","Xingda Wei","Sijie Shen","Dingyan Zhang","Chenguang Fang","Rong Chen","Wenyuan Yu","Haibo Chen"],"url":"https://arxiv.org/abs/2506.02634"}
{"created":"2025-06-04","title":"Joint Optimization based on Two-phase GNN in RIS- and DF-assisted MISO Systems with Fine-grained Rate Demands","abstract":"Reconfigurable intelligent Surfaces (RIS) and half-duplex decoded and forwarded (DF) relays can collaborate to optimize wireless signal propagation in communication systems. Users typically have different rate demands and are clustered into groups in practice based on their requirements, where the former results in the trade-off between maximizing the rate and satisfying fine-grained rate demands, while the latter causes a trade-off between inter-group competition and intra-group cooperation when maximizing the sum rate. However, traditional approaches often overlook the joint optimization encompassing both of these trade-offs, disregarding potential optimal solutions and leaving some users even consistently at low date rates. To address this issue, we propose a novel joint optimization model for a RIS- and DF-assisted multiple-input single-output (MISO) system where a base station (BS) is with multiple antennas transmits data by multiple RISs and DF relays to serve grouped users with fine-grained rate demands. We design a new loss function to not only optimize the sum rate of all groups but also adjust the satisfaction ratio of fine-grained rate demands by modifying the penalty parameter. We further propose a two-phase graph neural network (GNN) based approach that inputs channel state information (CSI) to simultaneously and autonomously learn efficient phase shifts, beamforming, and relay selection. The experimental results demonstrate that the proposed method significantly improves system performance.","authors":["Huijun Tang","Jieling Zhang","Zhidong Zhao","Huaming Wu","Hongjian Sun","Pengfei Jiao"],"url":"https://arxiv.org/abs/2506.02642"}
{"created":"2025-06-04","title":"Textual-Based vs. Thinging Machines Conceptual Modeling","abstract":"Software engineers typically interpret the domain description in natural language and translate it into a conceptual model. Three approaches are used in this domain modeling: textual languages, diagrammatic languages, and a mixed based of text and diagrams. According to some researchers, relying on a diagrammatic notation levies certain burdens for designing large models because visual languages are intended to depict everything diagrammatically during a development process but fail to do so for a lack of developer efficiency. It is claimed that textual formats enable easier manipulation in editors and tools and facilitate the integration of ontologies in software systems. In this paper, we explore the problem of the relationship between textual format and diagramming in conceptual modeling. The main focus is modeling based on the so-called thinging machine (TM). Several examples are developed in detail to contrast side-by-side targeted domains represented in textual description and TM modeling. A TM model is defined as a thimac (thing/machine) with a time feature that forms dynamic events over static thimacs utilizing five generic actions: create, process, release, transfer, and receive. This provides a conceptual foundation that can be simplified further by eliminating the actions of release, transfer, and receive. A multilevel reduction in the TM diagram s complexity can also be achieved by assuming diagrammatic notations represent the actions of creation and processing. We envision that special tools will help improve developer efficiency. The study s results of contrasting textual and mix-based descriptions vs. TM modeling justify our claim that TM modeling is a more appropriate methodology than other diagrammatic schemes (e.g., UML classes) examined in this paper.","authors":["Sabah Al-Fedaghi"],"url":"https://arxiv.org/abs/2506.02646"}
{"created":"2025-06-04","title":"Truly Assessing Fluid Intelligence of Large Language Models through Dynamic Reasoning Evaluation","abstract":"Recent advances in large language models (LLMs) have demonstrated impressive reasoning capacities that mirror human-like thinking. However, whether LLMs possess genuine fluid intelligence (i.e., the ability to reason abstractly and generalize rules in novel situations) remains an open question. Existing reasoning benchmarks either focus on domain-specific knowledge (crystallized intelligence) or lack interpretability. To address these limitations, we propose DRE-Bench, a dynamic reasoning evaluation benchmark grounded in a hierarchical cognitive framework. DRE-Bench consists of 36 abstract reasoning tasks organized across four cognitive levels, with each task featuring multiple dynamic variants that test the same underlying latent rule. This design enables fine-grained, interpretable, and reliable assessments of fluid intelligence. We evaluate a range of state-of-the-art LLMs, including both general LLMs (GPT-4o, Claude 3.7) and reasoning LLMs (o1, DeepSeek-R1, QwQ, Skywork-OR1). Experimental results reveal that although most LLMs achieve competent and robust performance in low-level cognition, they struggle with high-level cognition and exhibit limited generalization as task complexity grows. Our findings highlight the gap between current LLMs and true human-like fluid intelligence and offer a new path for systematically tracking reasoning progress in LLMs.","authors":["Yue Yang","MingKang Chen","Qihua Liu","Mengkang Hu","Qiguang Chen","Gengrui Zhang","Shuyue Hu","Guangtao Zhai","Yu Qiao","Yu Wang","Wenqi Shao","Ping Luo"],"url":"https://arxiv.org/abs/2506.02648"}
{"created":"2025-06-04","title":"From Prompts to Protection: Large Language Model-Enabled In-Context Learning for Smart Public Safety UAV","abstract":"A public safety Unmanned Aerial Vehicle (UAV) enhances situational awareness in emergency response. Its agility and ability to optimize mobility and establish Line-of-Sight (LoS) communication make it increasingly vital for managing emergencies such as disaster response, search and rescue, and wildfire monitoring. While Deep Reinforcement Learning (DRL) has been applied to optimize UAV navigation and control, its high training complexity, low sample efficiency, and simulation-to-reality gap limit its practicality in public safety. Recent advances in Large Language Models (LLMs) offer a compelling alternative. With strong reasoning and generalization capabilities, LLMs can adapt to new tasks through In-Context Learning (ICL), which enables task adaptation via natural language prompts and example-based guidance, without retraining. Deploying LLMs at the network edge, rather than in the cloud, further reduces latency and preserves data privacy, thereby making them suitable for real-time, mission-critical public safety UAVs. This paper proposes the integration of LLM-enabled ICL with public safety UAV to address the key functions, such as path planning and velocity control, in the context of emergency response. We present a case study on data collection scheduling where the LLM-enabled ICL framework can significantly reduce packet loss compared to conventional approaches, while also mitigating potential jailbreaking vulnerabilities. Finally, we discuss LLM optimizers and specify future research directions. The ICL framework enables adaptive, context-aware decision-making for public safety UAV, thus offering a lightweight and efficient solution for enhancing UAV autonomy and responsiveness in emergencies.","authors":["Yousef Emami","Hao Zhou","Miguel Gutierrez Gaitan","Kai Li","Luis Almeida","Zhu Han"],"url":"https://arxiv.org/abs/2506.02649"}
{"created":"2025-06-04","title":"A Pretrained Probabilistic Transformer for City-Scale Traffic Volume Prediction","abstract":"City-scale traffic volume prediction plays a pivotal role in intelligent transportation systems, yet remains a challenge due to the inherent incompleteness and bias in observational data. Although deep learning-based methods have shown considerable promise, most existing approaches produce deterministic point estimates, thereby neglecting the uncertainty arising from unobserved traffic flows. Furthermore, current models are typically trained in a city-specific manner, which hinders their generalizability and limits scalability across diverse urban contexts. To overcome these limitations, we introduce TrafficPPT, a Pretrained Probabilistic Transformer designed to model traffic volume as a distributional aggregation of trajectories. Our framework fuses heterogeneous data sources-including real-time observations, historical trajectory data, and road network topology-enabling robust and uncertainty-aware traffic inference. TrafficPPT is initially pretrained on large-scale simulated data spanning multiple urban scenarios, and later fine-tuned on target cities to ensure effective domain adaptation. Experiments on real-world datasets show that TrafficPPT consistently surpasses state-of-the-art baselines, particularly under conditions of extreme data sparsity. Code will be open.","authors":["Shiyu Shen","Bin Pan","Guirong Xue"],"url":"https://arxiv.org/abs/2506.02654"}
{"created":"2025-06-04","title":"The power of mediators: Price of anarchy and stability in Bayesian games with submodular social welfare","abstract":"This paper investigates the role of mediators in Bayesian games by examining their impact on social welfare through the price of anarchy (PoA) and price of stability (PoS). Mediators can communicate with players to guide them toward equilibria of varying quality, and different communication protocols lead to a variety of equilibrium concepts collectively known as Bayes (coarse) correlated equilibria. To analyze these equilibrium concepts, we consider a general class of Bayesian games with submodular social welfare, which naturally extends valid utility games and their variant, basic utility games. These frameworks, introduced by Vetta (2002), have been developed to analyze the social welfare guarantees of equilibria in games such as competitive facility location, influence maximization, and other resource allocation problems.","authors":["Kaito Fujii"],"url":"https://arxiv.org/abs/2506.02655"}
{"created":"2025-06-04","title":"Maximizing the Promptness of Metaverse Systems using Edge Computing by Deep Reinforcement Learning","abstract":"Metaverse and Digital Twin (DT) have attracted much academic and industrial attraction to approach the future digital world. This paper introduces the advantages of deep reinforcement learning (DRL) in assisting Metaverse system-based Digital Twin. In this system, we assume that it includes several Metaverse User devices collecting data from the real world to transfer it into the virtual world, a Metaverse Virtual Access Point (MVAP) undertaking the processing of data, and an edge computing server that receives the offloading data from the MVAP. The proposed model works under a dynamic environment with various parameters changing over time. The experiment results show that our proposed DRL algorithm is suitable for offloading tasks to ensure the promptness of DT in a dynamic environment.","authors":["Tam Ninh Thi-Thanh","Trinh Van Chien","Hung Tran","Nguyen Hoai Son","Van Nhan Vo"],"url":"https://arxiv.org/abs/2506.02657"}
{"created":"2025-06-04","title":"Computational Thinking Reasoning in Large Language Models","abstract":"While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they often struggle with complex tasks that require specific thinking paradigms, such as divide-and-conquer and procedural deduction, \\etc Previous researches integrate external, reliable tools to alleviate logical inconsistencies and hallucinations in LLMs' problem-solving processes. However, we argue that the root challenge is more profound: LLMs lack the complex thinking paradigms (\\ie, computational thinking) during reasoning. In this paper, we propose Computational Thinking Model (CTM), a novel framework that incorporates computational thinking paradigms into LLMs. This framework enables LLMs to reformulate complex problems through decomposition, abstraction, reduction, and simulation, among other techniques. Specifically, live code execution is seamlessly integrated into the reasoning process, allowing CTM to think by computing. CTM directly instills computational thinking objectives into LLMs through tailored reinforcement learning rewards, which encourages problem simplification, modular planning, and iterative verification. We conduct extensive evaluations on multiple code generation and mathematical benchmarks. The results demonstrate that CTM outperforms conventional reasoning models and tool-augmented baselines in terms of accuracy, interpretability, and generalizability. We hope this study offers valuable insights for AI reasoning, where LLMs can transform problems into robust, verifiable, and scalable computational workflows, much like computer scientists do.","authors":["Kechi Zhang","Ge Li","Jia Li","Huangzhao Zhang","Jingjing Xu","Hao Zhu","Lecheng Wang","Jia Li","Yihong Dong","Jing Mai","Bin Gu","Zhi Jin"],"url":"https://arxiv.org/abs/2506.02658"}
{"created":"2025-06-04","title":"Are Economists Always More Introverted? Analyzing Consistency in Persona-Assigned LLMs","abstract":"Personalized Large Language Models (LLMs) are increasingly used in diverse applications, where they are assigned a specific persona - such as a happy high school teacher - to guide their responses. While prior research has examined how well LLMs adhere to predefined personas in writing style, a comprehensive analysis of consistency across different personas and task types is lacking. In this paper, we introduce a new standardized framework to analyze consistency in persona-assigned LLMs. We define consistency as the extent to which a model maintains coherent responses when assigned the same persona across different tasks and runs. Our framework evaluates personas across four different categories (happiness, occupation, personality, and political stance) spanning multiple task dimensions (survey writing, essay generation, social media post generation, single turn, and multi-turn conversations). Our findings reveal that consistency is influenced by multiple factors, including the assigned persona, stereotypes, and model design choices. Consistency also varies across tasks, increasing with more structured tasks and additional context. All code is available on GitHub.","authors":["Manon Reusens","Bart Baesens","David Jurgens"],"url":"https://arxiv.org/abs/2506.02659"}
{"created":"2025-06-04","title":"Tarallo: Evading Behavioral Malware Detectors in the Problem Space","abstract":"Machine learning algorithms can effectively classify malware through dynamic behavior but are susceptible to adversarial attacks. Existing attacks, however, often fail to find an effective solution in both the feature and problem spaces. This issue arises from not addressing the intrinsic nondeterministic nature of malware, namely executing the same sample multiple times may yield significantly different behaviors. Hence, the perturbations computed for a specific behavior may be ineffective for others observed in subsequent executions. In this paper, we show how an attacker can augment their chance of success by leveraging a new and more efficient feature space algorithm for sequential data, which we have named PS-FGSM, and by adopting two problem space strategies specially tailored to address nondeterminism in the problem space. We implement our novel algorithm and attack strategies in Tarallo, an end-to-end adversarial framework that significantly outperforms previous works in both white and black-box scenarios. Our preliminary analysis in a sandboxed environment and against two RNN-based malware detectors, shows that Tarallo achieves a success rate up to 99% on both feature and problem space attacks while significantly minimizing the number of modifications required for misclassification.","authors":["Gabriele Digregorio","Salvatore Maccarrone","Mario D'Onghia","Luigi Gallo","Michele Carminati","Mario Polino","Stefano Zanero"],"url":"https://arxiv.org/abs/2506.02660"}
{"created":"2025-06-04","title":"MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation","abstract":"Generating long-term, coherent, and realistic music-conditioned dance sequences remains a challenging task in human motion synthesis. Existing approaches exhibit critical limitations: motion graph methods rely on fixed template libraries, restricting creative generation; diffusion models, while capable of producing novel motions, often lack temporal coherence and musical alignment. To address these challenges, we propose $\\textbf{MotionRAG-Diff}$, a hybrid framework that integrates Retrieval-Augmented Generation (RAG) with diffusion-based refinement to enable high-quality, musically coherent dance generation for arbitrary long-term music inputs. Our method introduces three core innovations: (1) A cross-modal contrastive learning architecture that aligns heterogeneous music and dance representations in a shared latent space, establishing unsupervised semantic correspondence without paired data; (2) An optimized motion graph system for efficient retrieval and seamless concatenation of motion segments, ensuring realism and temporal coherence across long sequences; (3) A multi-condition diffusion model that jointly conditions on raw music signals and contrastive features to enhance motion quality and global synchronization. Extensive experiments demonstrate that MotionRAG-Diff achieves state-of-the-art performance in motion quality, diversity, and music-motion synchronization accuracy. This work establishes a new paradigm for music-driven dance generation by synergizing retrieval-based template fidelity with diffusion-based creative enhancement.","authors":["Mingyang Huang","Peng Zhang","Bang Zhang"],"url":"https://arxiv.org/abs/2506.02661"}
{"created":"2025-06-04","title":"Fourth-order Adaptive Mesh Refinement both in space and in time for incompressible Navier-Stokes equations with Dirichlet boundary conditions","abstract":"We present a fourth-order projection method with adaptive mesh refinement (AMR) for numerically solving the incompressible Navier-Stokes equations (INSE) with subcycling in time. Our method features (i) a reformulation of INSE so that the velocity divergence decays exponentially on the coarsest level, (ii) a derivation of coarse-fine interface conditions that preserves the decay of velocity divergence on any refinement level of the AMR hierarchy, (iii) an approximation of the coarse-fine interface conditions via spatiotemporal interpolations to facilitate subcycling in time, (iv) enforcing to machine precision solvability conditions of elliptic equations over each connected component of the subdomain covered by any refinement level, (v) a composite projection for synchronizing multiple levels, and (vi) geometric multigrid for solving linear systems with optimal complexity. Different from current block-structured AMR algorithms, our method never adopts refluxing at the coarse-fine interface, nor is fine-to-coarse averaging applied to projected velocities. Results of numerical tests demonstrate the high accuracy and efficiency of the proposed method.","authors":["Shubo Zhao","Qinghai Zhang"],"url":"https://arxiv.org/abs/2506.02663"}
{"created":"2025-06-04","title":"Beyond Invisibility: Learning Robust Visible Watermarks for Stronger Copyright Protection","abstract":"As AI advances, copyrighted content faces growing risk of unauthorized use, whether through model training or direct misuse. Building upon invisible adversarial perturbation, recent works developed copyright protections against specific AI techniques such as unauthorized personalization through DreamBooth that are misused. However, these methods offer only short-term security, as they require retraining whenever the underlying model architectures change. To establish long-term protection aiming at better robustness, we go beyond invisible perturbation, and propose a universal approach that embeds \\textit{visible} watermarks that are \\textit{hard-to-remove} into images. Grounded in a new probabilistic and inverse problem-based formulation, our framework maximizes the discrepancy between the \\textit{optimal} reconstruction and the original content. We develop an effective and efficient approximation algorithm to circumvent a intractable bi-level optimization. Experimental results demonstrate superiority of our approach across diverse scenarios.","authors":["Tianci Liu","Tong Yang","Quan Zhang","Qi Lei"],"url":"https://arxiv.org/abs/2506.02665"}
{"created":"2025-06-04","title":"Spatially Correlated multi-RIS Communication: The Effect of Inter-Operator Interference","abstract":"A multi-operator wireless communication system is studied where each operator is equipped with a reconfigurable intelligent surface (RIS) to enhance its communication quality. RISs controlled by different operators affect the system performance of one another due to the inherently rapid phase shift adjustments that occur on an independent basis. The system performance of such a communication scenario is analytically studied for the practical case where spatial correlation occurs at RIS of arbitrary size. The proposed framework is quite general since it is analyzed under Nakagami-$m$ channel fading conditions. Finally, the derived analytical results are verified via numerical and simulation trials as well as some new and useful engineering outcomes are revealed.","authors":["Nikolaos I. Miridakis","Panagiotis A. Karkazis"],"url":"https://arxiv.org/abs/2506.02666"}
{"created":"2025-06-04","title":"Poster: libdebug, Build Your Own Debugger for a Better (Hello) World","abstract":"Automated debugging, long pursued in a variety of fields from software engineering to cybersecurity, requires a framework that offers the building blocks for a programmable debugging workflow. However, existing debuggers are primarily tailored for human interaction, and those designed for programmatic debugging focus on kernel space, resulting in limited functionality in userland. To fill this gap, we introduce libdebug, a Python library for programmatic debugging of userland binary executables. libdebug offers a user-friendly API that enables developers to build custom debugging tools for various applications, including software engineering, reverse engineering, and software security. It is released as an open-source project, along with comprehensive documentation to encourage use and collaboration across the community. We demonstrate the versatility and performance of libdebug through case studies and benchmarks, all of which are publicly available. We find that the median latency of syscall and breakpoint handling in libdebug is 3 to 4 times lower compared to that of GDB.","authors":["Gabriele Digregorio","Roberto Alessandro Bertolini","Francesco Panebianco","Mario Polino"],"url":"https://arxiv.org/abs/2506.02667"}
{"created":"2025-06-04","title":"FAuNO: Semi-Asynchronous Federated Reinforcement Learning Framework for Task Offloading in Edge Systems","abstract":"Edge computing addresses the growing data demands of connected-device networks by placing computational resources closer to end users through decentralized infrastructures. This decentralization challenges traditional, fully centralized orchestration, which suffers from latency and resource bottlenecks. We present \\textbf{FAuNO} -- \\emph{Federated Asynchronous Network Orchestrator} -- a buffered, asynchronous \\emph{federated reinforcement-learning} (FRL) framework for decentralized task offloading in edge systems. FAuNO adopts an actor-critic architecture in which local actors learn node-specific dynamics and peer interactions, while a federated critic aggregates experience across agents to encourage efficient cooperation and improve overall system performance. Experiments in the \\emph{PeersimGym} environment show that FAuNO consistently matches or exceeds heuristic and federated multi-agent RL baselines in reducing task loss and latency, underscoring its adaptability to dynamic edge-computing scenarios.","authors":["Frederico Metelo","Alexandre Oliveira","Stevo Rackovi\\'c","Pedro \\'Akos Costa","Cl\\'audia Soares"],"url":"https://arxiv.org/abs/2506.02668"}
{"created":"2025-06-04","title":"Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet","abstract":"Test-time adaptation (TTA) has emerged as a critical technique for enhancing the generalization capability of vision-language models (VLMs) during inference. However, existing approaches often incur substantial computational costs and exhibit poor scalability, primarily due to sample-wise adaptation granularity and reliance on costly auxiliary designs such as data augmentation. To address these limitations, we introduce SAIL (Small Aid, Big Leap), a novel adapter-based TTA framework that leverages a lightweight, learnable AdaptNet to enable efficient and scalable model adaptation. As SAIL's core, a frozen pre-trained VLM collaborates with AdaptNet through a confidence-based interpolation weight, generating robust predictions during inference. These predictions serve as self-supervised targets to align AdaptNet's outputs through efficient batch-wise processing, dramatically reducing computational costs without modifying the VLM or requiring memory caches. To mitigate catastrophic forgetting during continual adaptation, we propose a gradient-aware reset strategy driven by a gradient drift indicator (GDI), which dynamically detects domain transitions and strategically resets AdaptNet for stable adaptation. Extensive experiments across diverse benchmarks on two scenarios demonstrate that SAIL achieves state-of-the-art performance while maintaining low computational costs. These results highlight SAIL's effectiveness, efficiency and scalability for real-world deployment. The code will be released upon acceptance.","authors":["Xiao Chen","Jiazhen Huang","Qinting Jiang","Fanding Huang","Xianghua Fu","Jingyan Jiang","Zhi Wang"],"url":"https://arxiv.org/abs/2506.02671"}
{"created":"2025-06-04","title":"EvaLearn: Quantifying the Learning Capability and Efficiency of LLMs via Sequential Problem Solving","abstract":"We introduce EvaLearn, a pioneering benchmark designed to evaluate large language models (LLMs) on their learning capability and efficiency in challenging tasks, a critical, yet underexplored aspect of model potential. EvaLearn contains 648 challenging problems across six task types, grouped into 182 sequences, each sequence dedicated to one task type. Diverging from most existing benchmarks that evaluate models in parallel, EvaLearn requires models to solve problems sequentially, allowing them to leverage the experience gained from previous solutions. EvaLearn provides five comprehensive automated metrics to evaluate models and quantify their learning capability and efficiency. We extensively benchmark nine frontier models and observe varied performance profiles: some models, such as Claude-3.7-sonnet, start with moderate initial performance but exhibit strong learning ability, while some models struggle to benefit from experience and may even show negative transfer. Moreover, we investigate model performance under two learning settings and find that instance-level rubrics and teacher-model feedback further facilitate model learning. Importantly, we observe that current LLMs with stronger static abilities do not show a clear advantage in learning capability across all tasks, highlighting that EvaLearn evaluates a new dimension of model performance. We hope EvaLearn provides a novel evaluation perspective for assessing LLM potential and understanding the gap between models and human capabilities, promoting the development of deeper and more dynamic evaluation approaches. All datasets, the automatic evaluation framework, and the results studied in this paper are available at the GitHub repository.","authors":["Shihan Dou","Ming Zhang","Chenhao Huang","Jiayi Chen","Feng Chen","Shichun Liu","Yan Liu","Chenxiao Liu","Cheng Zhong","Zongzhang Zhang","Tao Gui","Chao Xin","Wei Chengzhi","Lin Yan","Qi Zhang","Xuanjing Huang"],"url":"https://arxiv.org/abs/2506.02672"}
{"created":"2025-06-04","title":"Decentralized COVID-19 Health System Leveraging Blockchain","abstract":"With the development of the Internet, the amount of data generated by the medical industry each year has grown exponentially. The Electronic Health Record (EHR) manages the electronic data generated during the user's treatment process. Typically, an EHR data manager belongs to a medical institution. This traditional centralized data management model has many unreasonable or inconvenient aspects, such as difficulties in data sharing, and it is hard to verify the authenticity and integrity of the data. The decentralized, non-forgeable, data unalterable and traceable features of blockchain are in line with the application requirements of EHR. This paper takes the most common COVID-19 as the application scenario and designs a COVID-19 health system based on blockchain, which has extensive research and application value. Considering that the public and transparent nature of blockchain violates the privacy requirements of some health data, in the system design stage, from the perspective of practical application, the data is divided into public data and private data according to its characteristics. For private data, data encryption methods are adopted to ensure data privacy. The searchable encryption technology is combined with blockchain technology to achieve the retrieval function of encrypted data. Then, the proxy re-encryption technology is used to realize authorized access to data. In the system implementation part, based on the Hyperledger Fabric architecture, some functions of the system design are realized, including data upload, retrieval of the latest data and historical data. According to the environment provided by the development architecture, Go language chaincode (smart contract) is written to implement the relevant system functions.","authors":["Lingsheng Chen","Shipeng Ye","Xiaoqi Li"],"url":"https://arxiv.org/abs/2506.02674"}
{"created":"2025-06-04","title":"Sight Guide: A Wearable Assistive Perception and Navigation System for the Vision Assistance Race in the Cybathlon 2024","abstract":"Visually impaired individuals face significant challenges navigating and interacting with unknown situations, particularly in tasks requiring spatial awareness and semantic scene understanding. To accelerate the development and evaluate the state of technologies that enable visually impaired people to solve these tasks, the Vision Assistance Race (VIS) at the Cybathlon 2024 competition was organized. In this work, we present Sight Guide, a wearable assistive system designed for the VIS. The system processes data from multiple RGB and depth cameras on an embedded computer that guides the user through complex, real-world-inspired tasks using vibration signals and audio commands. Our software architecture integrates classical robotics algorithms with learning-based approaches to enable capabilities such as obstacle avoidance, object detection, optical character recognition, and touchscreen interaction. In a testing environment, Sight Guide achieved a 95.7% task success rate, and further demonstrated its effectiveness during the Cybathlon competition. This work provides detailed insights into the system design, evaluation results, and lessons learned, and outlines directions towards a broader real-world applicability.","authors":["Patrick Pfreundschuh","Giovanni Cioffi","Cornelius von Einem","Alexander Wyss","Hans Wernher van de Venn","Cesar Cadena","Davide Scaramuzza","Roland Siegwart","Alireza Darvishy"],"url":"https://arxiv.org/abs/2506.02676"}
{"created":"2025-06-04","title":"Self-Disentanglement and Re-Composition for Cross-Domain Few-Shot Segmentation","abstract":"Cross-Domain Few-Shot Segmentation (CD-FSS) aims to transfer knowledge from a source-domain dataset to unseen target-domain datasets with limited annotations. Current methods typically compare the distance between training and testing samples for mask prediction. However, we find an entanglement problem exists in this widely adopted method, which tends to bind sourcedomain patterns together and make each of them hard to transfer. In this paper, we aim to address this problem for the CD-FSS task. We first find a natural decomposition of the ViT structure, based on which we delve into the entanglement problem for an interpretation. We find the decomposed ViT components are crossly compared between images in distance calculation, where the rational comparisons are entangled with those meaningless ones by their equal importance, leading to the entanglement problem. Based on this interpretation, we further propose to address the entanglement problem by learning to weigh for all comparisons of ViT components, which learn disentangled features and re-compose them for the CD-FSS task, benefiting both the generalization and finetuning. Experiments show that our model outperforms the state-of-the-art CD-FSS method by 1.92% and 1.88% in average accuracy under 1-shot and 5-shot settings, respectively.","authors":["Jintao Tong","Yixiong Zou","Guangyao Chen","Yuhua Li","Ruixuan Li"],"url":"https://arxiv.org/abs/2506.02677"}
{"created":"2025-06-04","title":"TL;DR: Too Long, Do Re-weighting for Effcient LLM Reasoning Compression","abstract":"Large Language Models (LLMs) have recently achieved remarkable progress by leveraging Reinforcement Learning and extended Chain-of-Thought (CoT) techniques. However, the challenge of performing efficient language reasoning--especially during inference with extremely long outputs--has drawn increasing attention from the research community. In this work, we propose a dynamic ratio-based training pipeline that does not rely on sophisticated data annotations or interpolation between multiple models. We continuously balance the weights between the model's System-1 and System-2 data to eliminate redundant reasoning processes while preserving the model's reasoning capability. We validate our approach across models on DeepSeek-R1-Distill-7B and DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying difficulty levels. Our method significantly reduces the number of output tokens by nearly 40% while maintaining the accuracy of the reasoning. Our code and data will be available soon.","authors":["Zhong-Zhi Li","Xiao Liang","Zihao Tang","Lei Ji","Peijie Wang","Haotian Xu","Xing W","Haizhen Huang","Weiwei Deng","Ying Nian Wu","Yeyun Gong","Zhijiang Guo","Xiao Liu","Fei Yin","Cheng-Lin Liu"],"url":"https://arxiv.org/abs/2506.02678"}
{"created":"2025-06-04","title":"Poster: FedBlockParadox -- A Framework for Simulating and Securing Decentralized Federated Learning","abstract":"A significant body of research in decentralized federated learning focuses on combining the privacy-preserving properties of federated learning with the resilience and transparency offered by blockchain-based systems. While these approaches are promising, they often lack flexible tools to evaluate system robustness under adversarial conditions. To fill this gap, we present FedBlockParadox, a modular framework for modeling and evaluating decentralized federated learning systems built on blockchain technologies, with a focus on resilience against a broad spectrum of adversarial attack scenarios. It supports multiple consensus protocols, validation methods, aggregation strategies, and configurable attack models. By enabling controlled experiments, FedBlockParadox provides a valuable resource for researchers developing secure, decentralized learning solutions. The framework is open-source and built to be extensible by the community.","authors":["Gabriele Digregorio","Francesco Bleggi","Federico Caroli","Michele Carminati","Stefano Zanero","Stefano Longari"],"url":"https://arxiv.org/abs/2506.02679"}
{"created":"2025-06-04","title":"Solving Inverse Problems with FLAIR","abstract":"Flow-based latent generative models such as Stable Diffusion 3 are able to generate images with remarkable quality, even enabling photorealistic text-to-image generation. Their impressive performance suggests that these models should also constitute powerful priors for inverse imaging problems, but that approach has not yet led to comparable fidelity. There are several key obstacles: (i) the encoding into a lower-dimensional latent space makes the underlying (forward) mapping non-linear; (ii) the data likelihood term is usually intractable; and (iii) learned generative models struggle to recover rare, atypical data modes during inference. We present FLAIR, a novel training free variational framework that leverages flow-based generative models as a prior for inverse problems. To that end, we introduce a variational objective for flow matching that is agnostic to the type of degradation, and combine it with deterministic trajectory adjustments to recover atypical modes. To enforce exact consistency with the observed data, we decouple the optimization of the data fidelity and regularization terms. Moreover, we introduce a time-dependent calibration scheme in which the strength of the regularization is modulated according to off-line accuracy estimates. Results on standard imaging benchmarks demonstrate that FLAIR consistently outperforms existing diffusion- and flow-based methods in terms of reconstruction quality and sample diversity.","authors":["Julius Erbach","Dominik Narnhofer","Andreas Dombos","Bernt Schiele","Jan Eric Lenssen","Konrad Schindler"],"url":"https://arxiv.org/abs/2506.02680"}
{"created":"2025-06-04","title":"Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints","abstract":"Despite significant advances in Large Language Models (LLMs), planning tasks still present challenges for LLM-based agents. Existing planning methods face two key limitations: heavy constraints and cascading errors. To address these limitations, we propose a novel parallel planning paradigm, which Decomposes, Plans for subtasks in Parallel, and Merges subplans into a final plan (DPPM). Specifically, DPPM decomposes the complex task based on constraints into subtasks, generates the subplan for each subtask in parallel, and merges them into a global plan. In addition, our approach incorporates a verification and refinement module, enabling error correction and conflict resolution. Experimental results demonstrate that DPPM significantly outperforms existing methods in travel planning tasks.","authors":["Zhengdong Lu","Weikai Lu","Yiling Tao","Yun Dai","ZiXuan Chen","Huiping Zhuang","Cen Chen","Hao Peng","Ziqian Zeng"],"url":"https://arxiv.org/abs/2506.02683"}
{"created":"2025-06-04","title":"Random Hyperbolic Graphs with Arbitrary Mesoscale Structures","abstract":"Real-world networks exhibit universal structural properties such as sparsity, small-worldness, heterogeneous degree distributions, high clustering, and community structures. Geometric network models, particularly Random Hyperbolic Graphs (RHGs), effectively capture many of these features by embedding nodes in a latent similarity space. However, networks are often characterized by specific connectivity patterns between groups of nodes -- i.e. communities -- that are not geometric, in the sense that the dissimilarity between groups do not obey the triangle inequality. Structuring connections only based on the interplay of similarity and popularity thus poses fundamental limitations on the mesoscale structure of the networks that RHGs can generate. To address this limitation, we introduce the Random Hyperbolic Block Model (RHBM), which extends RHGs by incorporating block structures within a maximum-entropy framework. We demonstrate the advantages of the RHBM through synthetic network analyses, highlighting its ability to preserve community structures where purely geometric models fail. Our findings emphasize the importance of latent geometry in network modeling while addressing its limitations in controlling mesoscale mixing patterns.","authors":["Stefano Guarino","Davide Torre","Enrico Mastrostefano"],"url":"https://arxiv.org/abs/2506.02686"}
{"created":"2025-06-04","title":"Stochastic Modeling of Road Hazards on Intersections and their Effect on Safety of Autonomous Vehicles","abstract":"Autonomous vehicles (AV) look set to become common on our roads within the next few years. However, to achieve the final breakthrough, not only functional progress is required, but also satisfactory safety assurance must be provided. Among those, a question demanding special attention is the need to assess and quantify the overall safety of an AV. Such an assessment must consider on the one hand the imperfections of the AV functionality and on the other hand its interaction with the environment. In a previous paper we presented a model-based approach to AV safety assessment in which we use a probabilistic model to describe road hazards together with the impact on AV safety of imperfect behavior of AV functions, such as safety monitors and perception systems. With this model, we are able to quantify the likelihood of the occurrence of a fatal accident, for a single operating condition. In this paper, we extend the approach and show how the model can deal explicitly with a set of different operating conditions defined in a given ODD.","authors":["Peter Popov","Lorenzo Strigini","Cornelius Buerkle","Fabian Oboril","Michael Paulitsch"],"url":"https://arxiv.org/abs/2506.02688"}
{"created":"2025-06-04","title":"MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching","abstract":"Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models' instruction-following capabilities and task-specific performance. However, obtaining high-quality fine-tuning data for large models is challenging due to data collection difficulties and high production costs. To address this, we propose MASTER, a novel data augmentation method that enriches original data through interactions among multiple agents with varying cognitive levels. We simulate three pedagogically grounded teaching scenarios, leveraging multi-agent conversations to generate high-quality teacher-student interaction data. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented from existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5. Experiments show that models fine-tuned with BOOST-QA perform excellently across multiple benchmarks, demonstrating strong multitask generalization. Notably, MASTER significantly improves models' reasoning abilities in complex tasks, providing valuable insights for future research.","authors":["Liang Yue","Yihong Tang","Kehai Chen","Jie Liu","Min Zhang"],"url":"https://arxiv.org/abs/2506.02689"}
{"created":"2025-06-04","title":"Towards Geometry Problem Solving in the Large Model Era: A Survey","abstract":"Geometry problem solving (GPS) represents a critical frontier in artificial intelligence, with profound applications in education, computer-aided design, and computational graphics. Despite its significance, automating GPS remains challenging due to the dual demands of spatial understanding and rigorous logical reasoning. Recent advances in large models have enabled notable breakthroughs, particularly for SAT-level problems, yet the field remains fragmented across methodologies, benchmarks, and evaluation frameworks. This survey systematically synthesizes GPS advancements through three core dimensions: (1) benchmark construction, (2) textual and diagrammatic parsing, and (3) reasoning paradigms. We further propose a unified analytical paradigm, assess current limitations, and identify emerging opportunities to guide future research toward human-level geometric reasoning, including automated benchmark generation and interpretable neuro-symbolic integration.","authors":["Yurui Zhao","Xiang Wang","Jiahong Liu","Irwin King","Zhitao Huang"],"url":"https://arxiv.org/abs/2506.02690"}
{"created":"2025-06-04","title":"Large-scale Self-supervised Video Foundation Model for Intelligent Surgery","abstract":"Computer-Assisted Intervention (CAI) has the potential to revolutionize modern surgery, with surgical scene understanding serving as a critical component in supporting decision-making, improving procedural efficacy, and ensuring intraoperative safety. While existing AI-driven approaches alleviate annotation burdens via self-supervised spatial representation learning, their lack of explicit temporal modeling during pre-training fundamentally restricts the capture of dynamic surgical contexts, resulting in incomplete spatiotemporal understanding. In this work, we introduce the first video-level surgical pre-training framework that enables joint spatiotemporal representation learning from large-scale surgical video data. To achieve this, we constructed a large-scale surgical video dataset comprising 3,650 videos and approximately 3.55 million frames, spanning more than 20 surgical procedures and over 10 anatomical structures. Building upon this dataset, we propose SurgVISTA (Surgical Video-level Spatial-Temporal Architecture), a reconstruction-based pre-training method that captures intricate spatial structures and temporal dynamics through joint spatiotemporal modeling. Additionally, SurgVISTA incorporates image-level knowledge distillation guided by a surgery-specific expert to enhance the learning of fine-grained anatomical and semantic features. To validate its effectiveness, we established a comprehensive benchmark comprising 13 video-level datasets spanning six surgical procedures across four tasks. Extensive experiments demonstrate that SurgVISTA consistently outperforms both natural- and surgical-domain pre-trained models, demonstrating strong potential to advance intelligent surgical systems in clinically meaningful scenarios.","authors":["Shu Yang","Fengtao Zhou","Leon Mayer","Fuxiang Huang","Yiliang Chen","Yihui Wang","Sunan He","Yuxiang Nie","Xi Wang","\\\"Omer S\\\"umer","Yueming Jin","Huihui Sun","Shuchang Xu","Alex Qinyang Liu","Zheng Li","Jing Qin","Jeremy YuenChun Teoh","Lena Maier-Hein","Hao Chen"],"url":"https://arxiv.org/abs/2506.02692"}
{"created":"2025-06-04","title":"XicorAttention: Time Series Transformer Using Attention with Nonlinear Correlation","abstract":"Various Transformer-based models have been proposed for time series forecasting. These models leverage the self-attention mechanism to capture long-term temporal or variate dependencies in sequences. Existing methods can be divided into two approaches: (1) reducing computational cost of attention by making the calculations sparse, and (2) reshaping the input data to aggregate temporal features. However, existing attention mechanisms may not adequately capture inherent nonlinear dependencies present in time series data, leaving room for improvement. In this study, we propose a novel attention mechanism based on Chatterjee's rank correlation coefficient, which measures nonlinear dependencies between variables. Specifically, we replace the matrix multiplication in standard attention mechanisms with this rank coefficient to measure the query-key relationship. Since computing Chatterjee's correlation coefficient involves sorting and ranking operations, we introduce a differentiable approximation employing SoftSort and SoftRank. Our proposed mechanism, ``XicorAttention,'' integrates it into several state-of-the-art Transformer models. Experimental results on real-world datasets demonstrate that incorporating nonlinear correlation into the attention improves forecasting accuracy by up to approximately 9.1\\% compared to existing models.","authors":["Daichi Kimura","Tomonori Izumitani","Hisashi Kashima"],"url":"https://arxiv.org/abs/2506.02694"}
{"created":"2025-06-04","title":"FaceSleuth: Learning-Driven Single-Orientation Attention Verifies Vertical Dominance in Micro-Expression Recognition","abstract":"Micro-expression recognition (MER) demands models that can amplify millisecond-level, low-amplitude facial motions while suppressing identity-specific appearance. We introduce FaceSleuth, a dual-stream architecture that (1) enhances motion along the empirically dominant vertical axix through a Continuously Vertical Attention (CVA) block, (2) localises the resulting signals with a Facial Position Focalizer built on hierarchical cross-window attention, and (3) steers feature learning toward physiologically meaningful regions via lightweight Action-Unit embeddings. To examine whether the hand-chosen vertical axis is indeed optimal, we further propose a Single-Orientation Attention (SOA) module that learns its own pooling direction end-to-end. SOA is differentiable, adds only 0.16 % parameters, and collapses to CVA when the learned angle converges to {\\Pi}/2. In practice, SOA reliably drifts to 88{\\deg}, confirming the effectiveness of the vertical prior while delivering consistent gains. On three standard MER benchmarks, FaceSleuth with CVA already surpasses previous state-of-the-art methods; plugging in SOA lifts accuracy and F1 score performance to 95.1 % / 0.918 on CASME II, 87.1 % / 0.840 on SAMM, and 92.9 % / 0.917 on MMEW without sacrificing model compactness. These results establish a new state of the art and, for the first time, provide empirical evidence that the vertical attention bias is the most discriminative orientation for MER.","authors":["Linquan Wu","Tianxiang Jiang","Wenhao Duan","Yini Fang","Jacky Keung"],"url":"https://arxiv.org/abs/2506.02695"}
{"created":"2025-06-04","title":"Shaking to Reveal: Perturbation-Based Detection of LLM Hallucinations","abstract":"Hallucination remains a key obstacle to the reliable deployment of large language models (LLMs) in real-world question answering tasks. A widely adopted strategy to detect hallucination, known as self-assessment, relies on the model's own output confidence to estimate the factual accuracy of its answers. However, this strategy assumes that the model's output distribution closely reflects the true data distribution, which may not always hold in practice. As bias accumulates through the model's layers, the final output can diverge from the underlying reasoning process, making output-level confidence an unreliable signal for hallucination detection. In this work, we propose Sample-Specific Prompting (SSP), a new framework that improves self-assessment by analyzing perturbation sensitivity at intermediate representations. These representations, being less influenced by model bias, offer a more faithful view of the model's latent reasoning process. Specifically, SSP dynamically generates noise prompts for each input and employs a lightweight encoder to amplify the changes in representations caused by the perturbation. A contrastive distance metric is then used to quantify these differences and separate truthful from hallucinated responses. By leveraging the dynamic behavior of intermediate representations under perturbation, SSP enables more reliable self-assessment. Extensive experiments demonstrate that SSP significantly outperforms prior methods across a range of hallucination detection benchmarks.","authors":["Jinyuan Luo","Zhen Fang","Yixuan Li","Seongheon Park","Ling Chen"],"url":"https://arxiv.org/abs/2506.02696"}
{"created":"2025-06-04","title":"LayoutRAG: Retrieval-Augmented Model for Content-agnostic Conditional Layout Generation","abstract":"Controllable layout generation aims to create plausible visual arrangements of element bounding boxes within a graphic design according to certain optional constraints, such as the type or position of a specific component. While recent diffusion or flow-matching models have achieved considerable advances in multifarious conditional generation tasks, there remains considerable room for generating optimal arrangements under given conditions. In this work, we propose to carry out layout generation through retrieving by conditions and reference-guided generation. Specifically, we retrieve appropriate layout templates according to given conditions as references. The references are then utilized to guide the denoising or flow-based transport process. By retrieving layouts compatible with the given conditions, we can uncover the potential information not explicitly provided in the given condition. Such an approach offers more effective guidance to the model during the generation process, in contrast to previous models that feed the condition to the model and let the model infer the unprovided layout attributes directly. Meanwhile, we design a condition-modulated attention that selectively absorbs retrieval knowledge, adapting to the difference between retrieved templates and given conditions. Extensive experiment results show that our method successfully produces high-quality layouts that meet the given conditions and outperforms existing state-of-the-art models. Code will be released upon acceptance.","authors":["Yuxuan Wu","Le Wang","Sanping Zhou","Mengnan Liu","Gang Hua","Haoxiang Li"],"url":"https://arxiv.org/abs/2506.02697"}
{"created":"2025-06-04","title":"Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences","abstract":"Direct Preference Optimization (DPO) aligns text-to-image (T2I) generation models with human preferences using pairwise preference data. Although substantial resources are expended in collecting and labeling datasets, a critical aspect is often neglected: \\textit{preferences vary across individuals and should be represented with more granularity.} To address this, we propose SmPO-Diffusion, a novel method for modeling preference distributions to improve the DPO objective, along with a numerical upper bound estimation for the diffusion optimization objective. First, we introduce a smoothed preference distribution to replace the original binary distribution. We employ a reward model to simulate human preferences and apply preference likelihood averaging to improve the DPO loss, such that the loss function approaches zero when preferences are similar. Furthermore, we utilize an inversion technique to simulate the trajectory preference distribution of the diffusion model, enabling more accurate alignment with the optimization objective. Our approach effectively mitigates issues of excessive optimization and objective misalignment present in existing methods through straightforward modifications. Our SmPO-Diffusion achieves state-of-the-art performance in preference evaluation, outperforming baselines across metrics with lower training costs. The project page is https://jaydenlyh.github.io/SmPO-project-page/.","authors":["Yunhong Lu","Qichao Wang","Hengyuan Cao","Xiaoyin Xu","Min Zhang"],"url":"https://arxiv.org/abs/2506.02698"}
{"created":"2025-06-04","title":"Cognitive Load-Driven VR Memory Palaces: Personalizing Focus and Recall Enhancement","abstract":"Cognitive load, which varies across individuals, can significantly affect focus and memory performance.This study explores the integration of Virtual Reality (VR) with memory palace techniques, aiming to optimize VR environments tailored to individual cognitive load levels to improve focus and memory. We utilized EEG devices, specifically the Oculus Quest 2, to monitor Beta wave activity in 10 participants.By modeling their cognitive load profiles through polynomial regression, we dynamically adjusted spatial variables within a VR environment using Grasshopper, creating personalized experiences. Results indicate that 8 participants showed a notable increase in Beta wave activity, demonstrating improved focus and cognitive performance in the customized VR settings.These findings underscore the potential of VR-based memory environments, driven by cognitive load considerations, and provide valuable insights for advancing VR memory research","authors":["Zhengyang Li","Hailin Deng"],"url":"https://arxiv.org/abs/2506.02700"}
{"created":"2025-06-04","title":"On Entity Identification in Language Models","abstract":"We analyze the extent to which internal representations of language models (LMs) identify and distinguish mentions of named entities, focusing on the many-to-many correspondence between entities and their mentions. We first formulate two problems of entity mentions -- ambiguity and variability -- and propose a framework analogous to clustering quality metrics. Specifically, we quantify through cluster analysis of LM internal representations the extent to which mentions of the same entity cluster together and mentions of different entities remain separated. Our experiments examine five Transformer-based autoregressive models, showing that they effectively identify and distinguish entities with metrics analogous to precision and recall ranging from 0.66 to 0.9. Further analysis reveals that entity-related information is compactly represented in a low-dimensional linear subspace at early LM layers. Additionally, we clarify how the characteristics of entity representations influence word prediction performance. These findings are interpreted through the lens of isomorphism between LM representations and entity-centric knowledge structures in the real world, providing insights into how LMs internally organize and use entity information.","authors":["Masaki Sakata","Sho Yokoi","Benjamin Heinzerling","Takumi Ito","Kentaro Inui"],"url":"https://arxiv.org/abs/2506.02701"}
{"created":"2025-06-04","title":"ToothForge: Automatic Dental Shape Generation using Synchronized Spectral Embeddings","abstract":"We introduce ToothForge, a spectral approach for automatically generating novel 3D teeth, effectively addressing the sparsity of dental shape datasets. By operating in the spectral domain, our method enables compact machine learning modeling, allowing the generation of high-resolution tooth meshes in milliseconds. However, generating shape spectra comes with the instability of the decomposed harmonics. To address this, we propose modeling the latent manifold on synchronized frequential embeddings. Spectra of all data samples are aligned to a common basis prior to the training procedure, effectively eliminating biases introduced by the decomposition instability. Furthermore, synchronized modeling removes the limiting factor imposed by previous methods, which require all shapes to share a common fixed connectivity. Using a private dataset of real dental crowns, we observe a greater reconstruction quality of the synthetized shapes, exceeding those of models trained on unaligned embeddings. We also explore additional applications of spectral analysis in digital dentistry, such as shape compression and interpolation. ToothForge facilitates a range of approaches at the intersection of spectral analysis and machine learning, with fewer restrictions on mesh structure. This makes it applicable for shape analysis not only in dentistry, but also in broader medical applications, where guaranteeing consistent connectivity across shapes from various clinics is unrealistic. The code is available at https://github.com/tiborkubik/toothForge.","authors":["Tibor Kub\\'ik","Fran\\c{c}ois Guibault","Michal \\v{S}pan\\v{e}l","Herv\\'e Lombaert"],"url":"https://arxiv.org/abs/2506.02702"}
{"created":"2025-06-04","title":"Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies","abstract":"This study critically examines the methodological rigor in credit card fraud detection research, revealing how fundamental evaluation flaws can overshadow algorithmic sophistication. Through deliberate experimentation with improper evaluation protocols, we demonstrate that even simple models can achieve deceptively impressive results when basic methodological principles are violated. Our analysis identifies four critical issues plaguing current approaches: (1) pervasive data leakage from improper preprocessing sequences, (2) intentional vagueness in methodological reporting, (3) inadequate temporal validation for transaction data, and (4) metric manipulation through recall optimization at precision's expense. We present a case study showing how a minimal neural network architecture with data leakage outperforms many sophisticated methods reported in literature, achieving 99.9\\% recall despite fundamental evaluation flaws. These findings underscore that proper evaluation methodology matters more than model complexity in fraud detection research. The study serves as a cautionary example of how methodological rigor must precede architectural sophistication, with implications for improving research practices across machine learning applications.","authors":["Khizar Hayat","Baptiste Magnier"],"url":"https://arxiv.org/abs/2506.02703"}
{"created":"2025-06-04","title":"Cartesian Forest Matching","abstract":"In this paper, we introduce the notion of Cartesian Forest, which generalizes Cartesian Trees, in order to deal with partially ordered sequences. We show that algorithms that solve both exact and approximate Cartesian Tree Matching can be adapted to solve Cartesian Forest Matching in average linear time. We adapt the notion of Cartesian Tree Signature to Cartesian Forests and show how filters can be used to experimentally improve the algorithm for the exact matching. We also show a one to one correspondence between Cartesian Forests and Schr\\\"oder Trees.","authors":["Bastien Auvray","Julien David","Richard Groult","Thierry Lecroq"],"url":"https://arxiv.org/abs/2506.02704"}
{"created":"2025-06-04","title":"Collective Intelligence Outperforms Individual Talent: A Case Study in League of Legends","abstract":"Gaming environments are popular testbeds for studying human interactions and behaviors in complex artificial intelligence systems. Particularly, in multiplayer online battle arena (MOBA) games, individuals collaborate in virtual environments of high realism that involves real-time strategic decision-making and trade-offs on resource management, information collection and sharing, team synergy and collective dynamics. This paper explores whether collective intelligence, emerging from cooperative behaviours exhibited by a group of individuals, who are not necessarily skillful but effectively engage in collaborative problem-solving tasks, exceeds individual intelligence observed within skillful individuals. This is shown via a case study in League of Legends, using machine learning algorithms and statistical methods applied to large-scale data collected for the same purpose. By modelling systematically game-specific metrics but also new game-agnostic topological and graph spectra measures of cooperative interactions, we demonstrate compelling insights about the superior performance of collective intelligence.","authors":["Angelo Josey Caldeira","Sajan Maharjan","Srijoni Majumdar","Evangelos Pournaras"],"url":"https://arxiv.org/abs/2506.02706"}
{"created":"2025-06-04","title":"Unit Commitment with Cost-Oriented Temporal Resolution","abstract":"Time-adaptive unit commitment (UC) has recently been investigated to reduce the scheduling costs by flexibly varying the temporal resolution, which is usually determined by clustering the net load patterns. However, there exists a misalignment between cost and net load patterns due to the discrete start-up costs and out-of-merit-order dispatch triggered by ramping and other constraints. The optimal time-adaptive resolution cannot be completely captured by clustering-based method. This paper proposes a cost-oriented method to address this misalignment by a novel bilevel optimization approach that is efficiently solved through a heuristic greedy algorithm. The impact of varying temporal resolution on the final scheduling costs are tested, based on which the temporal resolution is heuristically updated, achieving significant cost reduction without increasing the number of temporal periods. Subsequently, an improved discretized Adam optimization method together with offline warm start and online refinement strategy is proposed to efficiently search for the better temporal resolution configuration. Results show that the proposed cost-oriented UC temporal resolution determination method achieves enhanced cost efficiency.","authors":["Junyi Tao","Ran Li","Salvador Pineda"],"url":"https://arxiv.org/abs/2506.02707"}
{"created":"2025-06-04","title":"Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation","abstract":"Image scoring is a crucial task in numerous real-world applications. To trust a model's judgment, understanding its rationale is essential. This paper proposes a novel training method for Vision Language Models (VLMs) to generate not only image scores but also corresponding justifications in natural language. Leveraging only an image scoring dataset and an instruction-tuned VLM, our method enables self-training, utilizing the VLM's generated text without relying on external data or models. In addition, we introduce a simple method for creating a dataset designed to improve alignment between predicted scores and their textual justifications. By iteratively training the model with Direct Preference Optimization on two distinct datasets and merging them, we can improve both scoring accuracy and the coherence of generated explanations.","authors":["Naoto Tanji","Toshihiko Yamasaki"],"url":"https://arxiv.org/abs/2506.02708"}
{"created":"2025-06-04","title":"Usability Evaluation of Cloud for HPC Applications","abstract":"The rise of AI and the economic dominance of cloud computing have created a new nexus of innovation for high performance computing (HPC), which has a long history of driving scientific discovery. In addition to performance needs, scientific workflows increasingly demand capabilities of cloud environments: portability, reproducibility, dynamism, and automation. As converged cloud environments emerge, there is growing need to study their fit for HPC use cases. Here we present a cross-platform usability study that assesses 11 different HPC proxy applications and benchmarks across three clouds (Microsoft Azure, Amazon Web Services, and Google Cloud), six environments, and two compute configurations (CPU and GPU) against on-premises HPC clusters at a major center. We perform scaling tests of applications in all environments up to 28,672 CPUs and 256 GPUs. We present methodology and results to guide future study and provide a foundation to define best practices for running HPC workloads in cloud.","authors":["Vanessa Sochat","Daniel Milroy","Abhik Sarkar","Aniruddha Marathe"],"url":"https://arxiv.org/abs/2506.02709"}
{"created":"2025-06-04","title":"Privacy Leaks by Adversaries: Adversarial Iterations for Membership Inference Attack","abstract":"Membership inference attack (MIA) has become one of the most widely used and effective methods for evaluating the privacy risks of machine learning models. These attacks aim to determine whether a specific sample is part of the model's training set by analyzing the model's output. While traditional membership inference attacks focus on leveraging the model's posterior output, such as confidence on the target sample, we propose IMIA, a novel attack strategy that utilizes the process of generating adversarial samples to infer membership. We propose to infer the member properties of the target sample using the number of iterations required to generate its adversarial sample. We conduct experiments across multiple models and datasets, and our results demonstrate that the number of iterations for generating an adversarial sample is a reliable feature for membership inference, achieving strong performance both in black-box and white-box attack scenarios. This work provides a new perspective for evaluating model privacy and highlights the potential of adversarial example-based features for privacy leakage assessment.","authors":["Jing Xue","Zhishen Sun","Haishan Ye","Luo Luo","Xiangyu Chang","Ivor Tsang","Guang Dai"],"url":"https://arxiv.org/abs/2506.02711"}
{"created":"2025-06-04","title":"Theoretical Performance Guarantees for Partial Domain Adaptation via Partial Optimal Transport","abstract":"In many scenarios of practical interest, labeled data from a target distribution are scarce while labeled data from a related source distribution are abundant. One particular setting of interest arises when the target label space is a subset of the source label space, leading to the framework of partial domain adaptation (PDA). Typical approaches to PDA involve minimizing a domain alignment term and a weighted empirical loss on the source data, with the aim of transferring knowledge between domains. However, a theoretical basis for this procedure is lacking, and in particular, most existing weighting schemes are heuristic. In this work, we derive generalization bounds for the PDA problem based on partial optimal transport. These bounds corroborate the use of the partial Wasserstein distance as a domain alignment term, and lead to theoretically motivated explicit expressions for the empirical source loss weights. Inspired by these bounds, we devise a practical algorithm for PDA, termed WARMPOT. Through extensive numerical experiments, we show that WARMPOT is competitive with recent approaches, and that our proposed weights improve on existing schemes.","authors":["Jayadev Naram","Fredrik Hellstr\\\"om","Ziming Wang","Rebecka J\\\"ornsten","Giuseppe Durisi"],"url":"https://arxiv.org/abs/2506.02712"}
{"created":"2025-06-04","title":"Open-Set Living Need Prediction with Large Language Models","abstract":"Living needs are the needs people generate in their daily lives for survival and well-being. On life service platforms like Meituan, user purchases are driven by living needs, making accurate living need predictions crucial for personalized service recommendations. Traditional approaches treat this prediction as a closed-set classification problem, severely limiting their ability to capture the diversity and complexity of living needs. In this work, we redefine living need prediction as an open-set classification problem and propose PIGEON, a novel system leveraging large language models (LLMs) for unrestricted need prediction. PIGEON first employs a behavior-aware record retriever to help LLMs understand user preferences, then incorporates Maslow's hierarchy of needs to align predictions with human living needs. For evaluation and application, we design a recall module based on a fine-tuned text embedding model that links flexible need descriptions to appropriate life services. Extensive experiments on real-world datasets demonstrate that PIGEON significantly outperforms closed-set approaches on need-based life service recall by an average of 19.37%. Human evaluation validates the reasonableness and specificity of our predictions. Additionally, we employ instruction tuning to enable smaller LLMs to achieve competitive performance, supporting practical deployment.","authors":["Xiaochong Lan","Jie Feng","Yizhou Sun","Chen Gao","Jiahuan Lei","Xinlei Shi","Hengliang Luo","Yong Li"],"url":"https://arxiv.org/abs/2506.02713"}
{"created":"2025-06-04","title":"Heatables: Effects of Infrared-LED-Induced Ear Heating on Thermal Perception, Comfort, and Cognitive Performance","abstract":"Maintaining thermal comfort in shared indoor environments remains challenging, as centralized HVAC systems are slow to adapt and standardized to group norms. Cold exposure not only reduces subjective comfort but can impair cognitive performance, particularly under moderate to severe cold stress. Personal Comfort Systems (PCS) have shown promise by providing localized heating, yet many designs target distal body parts with low thermosensitivity and often lack portability. In this work, we investigate whether targeted thermal stimulation using in-ear worn devices can manipulate thermal perception and enhance thermal comfort. We present Heatables, a novel in-ear wearable that emits Near-Infrared (NIR) and Infrared (IR) radiation via integrated LEDs to deliver localized optical heating. This approach leverages NIR-IR's ability to penetrate deeper tissues, offering advantages over traditional resistive heating limited to surface warming. In a placebo-controlled study with 24 participants, each exposed for 150 minutes in a cool office environment (approximately 17.5 degrees Celsius) to simulate sustained cold stress during typical sedentary office activities, Heatables significantly increased the perceived ambient temperature by around 1.5 degrees Celsius and delayed cold discomfort. Importantly, thermal benefits extended beyond the ear region, improving both whole-body comfort and thermal acceptability. These findings position in-ear NIR-IR-LED-based stimulation as a promising modality for unobtrusive thermal comfort enhancement in everyday contexts.","authors":["Valeria Zitz","Michael K\\\"uttner","Jonas Hummel","Michael T. Knierim","Michael Beigl","Tobias R\\\"oddiger"],"url":"https://arxiv.org/abs/2506.02714"}
{"created":"2025-06-04","title":"UltrasonicSpheres: Localized, Multi-Channel Sound Spheres Using Off-the-Shelf Speakers and Earables","abstract":"We present a demo ofUltrasonicSpheres, a novel system for location-specific audio delivery using wearable earphones that decode ultrasonic signals into audible sound. Unlike conventional beamforming setups, UltrasonicSpheres relies on single ultrasonic speakers to broadcast localized audio with multiple channels, each encoded on a distinct ultrasonic carrier frequency. Users wearing our acoustically transparent earphones can demodulate their selected stream, such as exhibit narrations in a chosen language, while remaining fully aware of ambient environmental sounds. The experience preserves spatial audio perception, giving the impression that the sound originates directly from the physical location of the source. This enables personalized, localized audio without requiring pairing, tracking, or additional infrastructure. Importantly, visitors not equipped with the earphones are unaffected, as the ultrasonic signals are inaudible to the human ear. Our demo invites participants to explore multiple co-located audio zones and experience how UltrasonicSpheres supports unobtrusive delivery of personalized sound in public spaces.","authors":["Michael K\\\"uttner","Valeria Sitz","Kathrin Gerling","Michael Beigl","Tobias R\\\"oddiger"],"url":"https://arxiv.org/abs/2506.02715"}
{"created":"2025-06-04","title":"Heterogeneous Group-Based Reinforcement Learning for LLM-based Multi-Agent Systems","abstract":"Large Language Models (LLMs) have achieved remarkable success across diverse natural language processing tasks, yet their deployment in real-world applications is hindered by fixed knowledge cutoffs and difficulties in generating controllable, accurate outputs in a single inference. Multi-agent systems (MAS) built from specialized LLM agents offer a promising solution, enabling dynamic collaboration and iterative reasoning. However, optimizing these systems remains a challenge, as conventional methods such as prompt engineering and supervised fine-tuning entail high engineering overhead and limited adaptability. Reinforcement learning (RL), particularly multi-agent reinforcement learning (MARL), provides a scalable framework by refining agent policies based on system-level feedback. Nevertheless, existing MARL algorithms, such as Multi-Agent Proximal Policy Optimization (MAPPO), rely on Critic networks, which can cause training instability and increase computational burden. To address these limitations and target the prototypical Multi-Agent Search System (MASS), we propose Multi-Agent Heterogeneous Group Policy Optimization (MHGPO), a novel Critic-free algorithm that guides policy updates by estimating relative reward advantages across heterogeneous groups of rollouts. MHGPO eliminates the need for Critic networks, enhancing stability and reducing computational overhead. Additionally, we introduce three group rollout sampling strategies that trade off between efficiency and effectiveness. Experiments on a multi-agent LLM-based search system demonstrate that MHGPO consistently outperforms MAPPO in both task performance and computational efficiency, without requiring warm-up, underscoring its potential for stable and scalable optimization of complex LLM-based MAS.","authors":["Guanzhong Chen","Shaoxiong Yang","Chao Li","Wei Liu","Jian Luan","Zenglin Xu"],"url":"https://arxiv.org/abs/2506.02718"}
{"created":"2025-06-04","title":"Benchmarking and Advancing Large Language Models for Local Life Services","abstract":"Large language models (LLMs) have exhibited remarkable capabilities and achieved significant breakthroughs across various domains, leading to their widespread adoption in recent years. Building on this progress, we investigate their potential in the realm of local life services. In this study, we establish a comprehensive benchmark and systematically evaluate the performance of diverse LLMs across a wide range of tasks relevant to local life services. To further enhance their effectiveness, we explore two key approaches: model fine-tuning and agent-based workflows. Our findings reveal that even a relatively compact 7B model can attain performance levels comparable to a much larger 72B model, effectively balancing inference cost and model capability. This optimization greatly enhances the feasibility and efficiency of deploying LLMs in real-world online services, making them more practical and accessible for local life applications.","authors":["Xiaochong Lan","Jie Feng","Jiahuan Lei","Xinlei Shi","Yong Li"],"url":"https://arxiv.org/abs/2506.02720"}
{"created":"2025-06-04","title":"WeightLoRA: Keep Only Necessary Adapters","abstract":"The widespread utilization of language models in modern applications is inconceivable without Parameter-Efficient Fine-Tuning techniques, such as low-rank adaptation ($\\texttt{LoRA}$), which adds trainable adapters to selected layers. Although $\\texttt{LoRA}$ may obtain accurate solutions, it requires significant memory to train large models and intuition on which layers to add adapters. In this paper, we propose a novel method, $\\texttt{WeightLoRA}$, which overcomes this issue by adaptive selection of the most critical $\\texttt{LoRA}$ heads throughout the optimization process. As a result, we can significantly reduce the number of trainable parameters while maintaining the capability to obtain consistent or even superior metric values. We conduct experiments for a series of competitive benchmarks and DeBERTa, BART, and Llama models, comparing our method with different adaptive approaches. The experimental results demonstrate the efficacy of $\\texttt{WeightLoRA}$ and the superior performance of $\\texttt{WeightLoRA+}$ in almost all cases.","authors":["Andrey Veprikov","Vladimir Solodkin","Alexander Zyl","Andrey Savchenko","Aleksandr Beznosikov"],"url":"https://arxiv.org/abs/2506.02724"}
{"created":"2025-06-04","title":"Recursive Privacy-Preserving Estimation Over Markov Fading Channels","abstract":"In industrial applications, the presence of moving machinery, vehicles, and personnel, contributes to the dynamic nature of the wireless channel. This time variability induces channel fading, which can be effectively modeled using a Markov fading channel (MFC). In this paper, we investigate the problem of secure state estimation for systems that communicate over a MFC in the presence of an eavesdropper. The objective is to enable a remote authorized user to accurately estimate the states of a dynamic system, while considering the potential interception of the sensor's packet through a wiretap channel. To prevent information leakage, a novel co-design strategy is established, which combines a privacy-preserving mechanism with a state estimator. To implement our encoding scheme, a nonlinear mapping of the innovation is introduced based on the weighted reconstructed innovation previously received by the legitimate user. Corresponding to this encoding scheme, we design a recursive privacy-preserving filtering algorithm to achieve accurate estimation. The boundedness of estimation error dynamics at the legitimate user's side is discussed and the divergence of the eavesdropper's estimation error is analyzed, which demonstrates the effectiveness of our co-design strategy in ensuring secrecy. Furthermore, a simulation example of a three-tank system is provided to demonstrate the effectiveness and feasibility of our privacy-preserving estimation method.","authors":["Jie Huang","Fanlin Jia","Xiao He"],"url":"https://arxiv.org/abs/2506.02725"}
{"created":"2025-06-04","title":"RACE-Align: Retrieval-Augmented and Chain-of-Thought Enhanced Preference Alignment for Large Language Models","abstract":"Large Language Models (LLMs) struggle with accuracy, domain-specific reasoning, and interpretability in vertical domains. Traditional preference alignment methods like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) often overlook the underlying knowledge sources and reasoning logic. This paper introduces RACE-Align (Retrieval-Augmented and Chain-of-Thought Enhanced Alignment), a novel framework designed to address these limitations. RACE-Align systematically constructs a binary preference dataset incorporating external knowledge support and explicit Chain-of-Thought (CoT) reasoning, then aligns LLMs using the DPO algorithm. The core innovation lies in its preference data construction strategy: it integrates AI-driven retrieval for factual grounding, enhancing knowledgeability and accuracy, and emphasizes the optimization of domain-specific CoT, treating the reasoning process itself as a key preference dimension. A multi-stage, AI-driven refinement pipeline cost-effectively generates these preference pairs. Experimental validation in Traditional Chinese Medicine (TCM) using Qwen3-1.7B as the base model demonstrates that RACE-Align significantly outperforms the original base model and a model fine-tuned only with Supervised Fine-Tuning (SFT). Improvements were observed across multiple dimensions, including answer accuracy, information richness, application of TCM thinking patterns, logicality and depth of reasoning, and interpretability. These findings suggest RACE-Align offers an effective pathway to enhance LLMs' knowledge application, reasoning reliability, and process transparency in complex vertical domains.","authors":["Qihang Yan","Xinyu Zhang","Luming Guo","Qi Zhang","Feifan Liu"],"url":"https://arxiv.org/abs/2506.02726"}
{"created":"2025-06-04","title":"Transforming Automatically BPMN Models to Smart Contracts with Nested Collaborative Transactions (TABS+)","abstract":"Development of blockchain smart contracts is more difficult than mainstream software development because the underlying blockchain infrastructure poses additional complexity. To ease the developer's task of writing smart contract, as other research efforts, we also use Business Process Model and Notation BPMN modeling to describe application requirements for trade of goods and services and then transform automatically the BPMN model into the methods of a smart contract. In our previous research we described our approach and a tool to Transform Automatically BPMN models into Smart contracts TABS. In this paper, we describe how the TABS approach is augmented with the support for a BPMN collaborative transaction by several actors. Our approach analyzes the BPMN model to determine which patterns in the BPMN model are suitable for use as collaborative transactions. The found BPMN patterns that are suitable as transactions are shown to the developer who decides which ones should be deployed as collaborative transactions. We describe how our approach automatically transform the BPMN model into smart contract the provides a transaction mechanism to enforce the transactional properties of the nested transactions. Our approach greatly reduces the developers task as synchronization of collaborative activities is provided by our approach, so that the developer needs to code only independent tasks with well-defined inputs and outputs. We also overview the TABS+ tool we built as a proof of concept to show that our approach is feasible. Finally, we provide estimates on the cost of supporting the nested BPMN collaborative transactions.","authors":["Christian Gang Liu","Peter Bodorik","Dawn Jutla"],"url":"https://arxiv.org/abs/2506.02727"}
{"created":"2025-06-04","title":"LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering","abstract":"Existing optical flow datasets focus primarily on real-world simulation or synthetic human motion, but few are tailored to Celluloid(cel) anime character motion: a domain with unique visual and motion characteristics. To bridge this gap and facilitate research in optical flow estimation and downstream tasks such as anime video generation and line drawing colorization, we introduce LinkTo-Anime, the first high-quality dataset specifically designed for cel anime character motion generated with 3D model rendering. LinkTo-Anime provides rich annotations including forward and backward optical flow, occlusion masks, and Mixamo Skeleton. The dataset comprises 395 video sequences, totally 24,230 training frames, 720 validation frames, and 4,320 test frames. Furthermore, a comprehensive benchmark is constructed with various optical flow estimation methods to analyze the shortcomings and limitations across multiple datasets.","authors":["Xiaoyi Feng","Kaifeng Zou","Caichun Cen","Tao Huang","Hui Guo","Zizhou Huang","Yingli Zhao","Mingqing Zhang","Diwei Wang","Yuntao Zou","Dagang Li"],"url":"https://arxiv.org/abs/2506.02733"}
{"created":"2025-06-04","title":"Extremely Large-Scale Movable Antenna-Enabled Multiuser Communications: Modeling and Optimization","abstract":"Movable antenna (MA) has been recognized as a promising technology to improve communication performance in future wireless networks such as 6G. To unleash its potential, this paper proposes a novel architecture, namely extremely large-scale MA (XL-MA), which allows flexible antenna/subarray positioning over an extremely large spatial region for effectively enhancing near-field effects and spatial multiplexing performance. In particular, this paper studies an uplink XL-MA-enabled multiuser system, where single-antenna users distributed in a coverage area are served by a base station (BS) equipped with multiple movable subarrays. We begin by presenting a spatially non-stationary channel model to capture the near-field effects, including positiondependent large-scale channel gains and line-of-sight visibility. To evaluate system performance, we further derive a closedform approximation of the expected weighted sum rate under maximum ratio combining (MRC), revealing that optimizing XLMA placement enhances user channel power gain to increase desired signal power and reduces channel correlation to decreases multiuser interference. Building upon this, we formulate an antenna placement optimization problem to maximize the expected weighted sum rate, leveraging statistical channel conditions and user distribution. To efficiently solve this challenging non-linear binary optimization problem, we propose a polynomial-time successive replacement algorithm. Simulation results demonstrate that the proposed XL-MA placement strategy achieves nearoptimal performance, significantly outperforming benchmark schemes based on conventional fixed-position antennas.","authors":["Min Fu","Lipeng Zhu","Rui Zhang"],"url":"https://arxiv.org/abs/2506.02735"}
{"created":"2025-06-04","title":"GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal","abstract":"Existing semantic SLAM in dynamic environments mainly identify dynamic regions through object detection or semantic segmentation methods. However, in certain highly dynamic scenarios, the detection boxes or segmentation masks cannot fully cover dynamic regions. Therefore, this paper proposes a robust and efficient GeneA-SLAM2 system that leverages depth variance constraints to handle dynamic scenes. Our method extracts dynamic pixels via depth variance and creates precise depth masks to guide the removal of dynamic objects. Simultaneously, an autoencoder is used to reconstruct keypoints, improving the genetic resampling keypoint algorithm to obtain more uniformly distributed keypoints and enhance the accuracy of pose estimation. Our system was evaluated on multiple highly dynamic sequences. The results demonstrate that GeneA-SLAM2 maintains high accuracy in dynamic scenes compared to current methods. Code is available at: https://github.com/qingshufan/GeneA-SLAM2.","authors":["Shufan Qing","Anzhen Li","Qiandi Wang","Yuefeng Niu","Mingchen Feng","Guoliang Hu","Jinqiao Wu","Fengtao Nan","Yingchun Fan"],"url":"https://arxiv.org/abs/2506.02736"}
{"created":"2025-06-04","title":"Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning","abstract":"Compound figures, which are multi-panel composites containing diverse subfigures, are ubiquitous in biomedical literature, yet large-scale subfigure extraction remains largely unaddressed. Prior work on subfigure extraction has been limited in both dataset size and generalizability, leaving a critical open question: How does high-fidelity image-text alignment via large-scale subfigure extraction impact representation learning in vision-language models? We address this gap by introducing a scalable subfigure extraction pipeline based on transformer-based object detection, trained on a synthetic corpus of 500,000 compound figures, and achieving state-of-the-art performance on both ImageCLEF 2016 and synthetic benchmarks. Using this pipeline, we release OPEN-PMC-18M, a large-scale high quality biomedical vision-language dataset comprising 18 million clinically relevant subfigure-caption pairs spanning radiology, microscopy, and visible light photography. We train and evaluate vision-language models on our curated datasets and show improved performance across retrieval, zero-shot classification, and robustness benchmarks, outperforming existing baselines. We release our dataset, models, and code to support reproducible benchmarks and further study into biomedical vision-language modeling and representation learning.","authors":["Negin Baghbanzadeh","Sajad Ashkezari","Elham Dolatabadi","Arash Afkanpour"],"url":"https://arxiv.org/abs/2506.02738"}
{"created":"2025-06-04","title":"Why do AI agents communicate in human language?","abstract":"Large Language Models (LLMs) have become foundational to modern AI agent systems, enabling autonomous agents to reason and plan. In most existing systems, inter-agent communication relies primarily on natural language. While this design supports interpretability and human oversight, we argue that it introduces fundamental limitations in agent-to-agent coordination. The semantic space of natural language is structurally misaligned with the high-dimensional vector spaces in which LLMs operate, resulting in information loss and behavioral drift. Beyond surface-level inefficiencies, we highlight a deeper architectural limitation: current LLMs were not trained with the objective of supporting agentic behavior. As such, they lack mechanisms for modeling role continuity, task boundaries, and multi-agent dependencies. The standard next-token prediction paradigm fails to support the structural alignment required for robust, scalable agent coordination. Based on this, we argue that two core questions deserve careful examination: first, given that AI agents fundamentally operate in high-dimensional vector spaces, should they rely on a language system originally designed for human cognition as their communication medium? Second, should we consider developing a new model construction paradigm that builds models from the ground up to natively support structured communication, shared intentionality, and task alignment in multi-role, multi-agent environments? This paper calls for a reconsideration not only of how agents should communicate, but also of what it fundamentally means to train a model that natively supports multi-agent coordination and communication.","authors":["Pengcheng Zhou","Yinglun Feng","Halimulati Julaiti","Zhongliang Yang"],"url":"https://arxiv.org/abs/2506.02739"}
{"created":"2025-06-04","title":"Stereotypical gender actions can be extracted from Web text","abstract":"We extracted gender-specific actions from text corpora and Twitter, and compared them to stereotypical expectations of people. We used Open Mind Common Sense (OMCS), a commonsense knowledge repository, to focus on actions that are pertinent to common sense and daily life of humans. We use the gender information of Twitter users and Web-corpus-based pronoun/name gender heuristics to compute the gender bias of the actions. With high recall, we obtained a Spearman correlation of 0.47 between corpus-based predictions and a human gold standard, and an area under the ROC curve of 0.76 when predicting the polarity of the gold standard. We conclude that it is feasible to use natural text (and a Twitter-derived corpus in particular) in order to augment commonsense repositories with the stereotypical gender expectations of actions. We also present a dataset of 441 commonsense actions with human judges' ratings on whether the action is typically/slightly masculine/feminine (or neutral), and another larger dataset of 21,442 actions automatically rated by the methods we investigate in this study.","authors":["Ama\\c{c} Herda\\u{g}delen","Marco Baroni"],"url":"https://arxiv.org/abs/2506.02740"}
{"created":"2025-06-04","title":"VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians","abstract":"Jointly estimating camera poses and mapping scenes from RGBD images is a fundamental task in simultaneous localization and mapping (SLAM). State-of-the-art methods employ 3D Gaussians to represent a scene, and render these Gaussians through splatting for higher efficiency and better rendering. However, these methods cannot scale up to extremely large scenes, due to the inefficient tracking and mapping strategies that need to optimize all 3D Gaussians in the limited GPU memories throughout the training to maintain the geometry and color consistency to previous RGBD observations. To resolve this issue, we propose novel tracking and mapping strategies to work with a novel 3D representation, dubbed view-tied 3D Gaussians, for RGBD SLAM systems. View-tied 3D Gaussians is a kind of simplified Gaussians, which is tied to depth pixels, without needing to learn locations, rotations, and multi-dimensional variances. Tying Gaussians to views not only significantly saves storage but also allows us to employ many more Gaussians to represent local details in the limited GPU memory. Moreover, our strategies remove the need of maintaining all Gaussians learnable throughout the training, while improving rendering quality, and tracking accuracy. We justify the effectiveness of these designs, and report better performance over the latest methods on the widely used benchmarks in terms of rendering and tracking accuracy and scalability. Please see our project page for code and videos at https://machineperceptionlab.github.io/VTGaussian-SLAM-Project .","authors":["Pengchong Hu","Zhizhong Han"],"url":"https://arxiv.org/abs/2506.02741"}
{"created":"2025-06-04","title":"Enriching Location Representation with Detailed Semantic Information","abstract":"Spatial representations that capture both structural and semantic characteristics of urban environments are essential for urban modeling. Traditional spatial embeddings often prioritize spatial proximity while underutilizing fine-grained contextual information from places. To address this limitation, we introduce CaLLiPer+, an extension of the CaLLiPer model that systematically integrates Point-of-Interest (POI) names alongside categorical labels within a multimodal contrastive learning framework. We evaluate its effectiveness on two downstream tasks, land use classification and socioeconomic status distribution mapping, demonstrating consistent performance gains of 4% to 11% over baseline methods. Additionally, we show that incorporating POI names enhances location retrieval, enabling models to capture complex urban concepts with greater precision. Ablation studies further reveal the complementary role of POI names and the advantages of leveraging pretrained text encoders for spatial representations. Overall, our findings highlight the potential of integrating fine-grained semantic attributes and multimodal learning techniques to advance the development of urban foundation models.","authors":["Junyuan Liu","Xinglei Wang","Tao Cheng"],"url":"https://arxiv.org/abs/2506.02744"}
{"created":"2025-06-04","title":"Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search","abstract":"The Pod Repositioning Problem (PRP) in Robotic Mobile Fulfillment Systems (RMFS) involves selecting optimal storage locations for pods returning from pick stations. This work presents an improved solution method that integrates Adaptive Large Neighborhood Search (ALNS) with Deep Reinforcement Learning (DRL). A DRL agent dynamically selects destroy and repair operators and adjusts key parameters such as destruction degree and acceptance thresholds during the search. Specialized heuristics for both operators are designed to reflect PRP-specific characteristics, including pod usage frequency and movement costs. Computational results show that this DRL-guided ALNS outperforms traditional approaches such as cheapest-place, fixed-place, binary integer programming, and static heuristics. The method demonstrates strong solution quality and illustrating the benefit of learning-driven control within combinatorial optimization for warehouse systems.","authors":["Lin Xie","Hanyi Li"],"url":"https://arxiv.org/abs/2506.02746"}
{"created":"2025-06-04","title":"Knowledge Graph Completion by Intermediate Variables Regularization","abstract":"Knowledge graph completion (KGC) can be framed as a 3-order binary tensor completion task. Tensor decomposition-based (TDB) models have demonstrated strong performance in KGC. In this paper, we provide a summary of existing TDB models and derive a general form for them, serving as a foundation for further exploration of TDB models. Despite the expressiveness of TDB models, they are prone to overfitting. Existing regularization methods merely minimize the norms of embeddings to regularize the model, leading to suboptimal performance. Therefore, we propose a novel regularization method for TDB models that addresses this limitation. The regularization is applicable to most TDB models and ensures tractable computation. Our method minimizes the norms of intermediate variables involved in the different ways of computing the predicted tensor. To support our regularization method, we provide a theoretical analysis that proves its effect in promoting low trace norm of the predicted tensor to reduce overfitting. Finally, we conduct experiments to verify the effectiveness of our regularization technique as well as the reliability of our theoretical analysis. The code is available at https://github.com/changyi7231/IVR.","authors":["Changyi Xiao","Yixin Cao"],"url":"https://arxiv.org/abs/2506.02749"}
{"created":"2025-06-04","title":"Learning Binarized Representations with Pseudo-positive Sample Enhancement for Efficient Graph Collaborative Filtering","abstract":"Learning vectorized embeddings is fundamental to many recommender systems for user-item matching. To enable efficient online inference, representation binarization, which embeds latent features into compact binary sequences, has recently shown significant promise in optimizing both memory usage and computational overhead. However, existing approaches primarily focus on numerical quantization, neglecting the associated information loss, which often results in noticeable performance degradation. To address these issues, we study the problem of graph representation binarization for efficient collaborative filtering. Our findings indicate that explicitly mitigating information loss at various stages of embedding binarization has a significant positive impact on performance. Building on these insights, we propose an enhanced framework, BiGeaR++, which specifically leverages supervisory signals from pseudo-positive samples, incorporating both real item data and latent embedding samples. Compared to its predecessor BiGeaR, BiGeaR++ introduces a fine-grained inference distillation mechanism and an effective embedding sample synthesis approach. Empirical evaluations across five real-world datasets demonstrate that the new designs in BiGeaR++ work seamlessly well with other modules, delivering substantial improvements of around 1%-10% over BiGeaR and thus achieving state-of-the-art performance compared to the competing methods. Our implementation is available at https://github.com/QueYork/BiGeaR-SS.","authors":["Yankai Chen","Yue Que","Xinni Zhang","Chen Ma","Irwin King"],"url":"https://arxiv.org/abs/2506.02750"}
{"created":"2025-06-04","title":"RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS","abstract":"3D Gaussian Splatting (3DGS) has gained significant attention for its real-time, photo-realistic rendering in novel-view synthesis and 3D modeling. However, existing methods struggle with accurately modeling scenes affected by transient objects, leading to artifacts in the rendered images. We identify that the Gaussian densification process, while enhancing scene detail capture, unintentionally contributes to these artifacts by growing additional Gaussians that model transient disturbances. To address this, we propose RobustSplat, a robust solution based on two critical designs. First, we introduce a delayed Gaussian growth strategy that prioritizes optimizing static scene structure before allowing Gaussian splitting/cloning, mitigating overfitting to transient objects in early optimization. Second, we design a scale-cascaded mask bootstrapping approach that first leverages lower-resolution feature similarity supervision for reliable initial transient mask estimation, taking advantage of its stronger semantic consistency and robustness to noise, and then progresses to high-resolution supervision to achieve more precise mask prediction. Extensive experiments on multiple challenging datasets show that our method outperforms existing methods, clearly demonstrating the robustness and effectiveness of our method. Our project page is https://fcyycf.github.io/RobustSplat/.","authors":["Chuanyu Fu","Yuqi Zhang","Kunbin Yao","Guanying Chen","Yuan Xiong","Chuan Huang","Shuguang Cui","Xiaochun Cao"],"url":"https://arxiv.org/abs/2506.02751"}
{"created":"2025-06-04","title":"Multi-task Learning with Active Learning for Arabic Offensive Speech Detection","abstract":"The rapid growth of social media has amplified the spread of offensive, violent, and vulgar speech, which poses serious societal and cybersecurity concerns. Detecting such content in Arabic text is particularly complex due to limited labeled data, dialectal variations, and the language's inherent complexity. This paper proposes a novel framework that integrates multi-task learning (MTL) with active learning to enhance offensive speech detection in Arabic social media text. By jointly training on two auxiliary tasks, violent and vulgar speech, the model leverages shared representations to improve the detection accuracy of the offensive speech. Our approach dynamically adjusts task weights during training to balance the contribution of each task and optimize performance. To address the scarcity of labeled data, we employ an active learning strategy through several uncertainty sampling techniques to iteratively select the most informative samples for model training. We also introduce weighted emoji handling to better capture semantic cues. Experimental results on the OSACT2022 dataset show that the proposed framework achieves a state-of-the-art macro F1-score of 85.42%, outperforming existing methods while using significantly fewer fine-tuning samples. The findings of this study highlight the potential of integrating MTL with active learning for efficient and accurate offensive language detection in resource-constrained settings.","authors":["Aisha Alansari","Hamzah Luqman"],"url":"https://arxiv.org/abs/2506.02753"}
{"created":"2025-06-04","title":"Investigating Mask-aware Prototype Learning for Tabular Anomaly Detection","abstract":"Tabular anomaly detection, which aims at identifying deviant samples, has been crucial in a variety of real-world applications, such as medical disease identification, financial fraud detection, intrusion monitoring, etc. Although recent deep learning-based methods have achieved competitive performances, these methods suffer from representation entanglement and the lack of global correlation modeling, which hinders anomaly detection performance. To tackle the problem, we incorporate mask modeling and prototype learning into tabular anomaly detection. The core idea is to design learnable masks by disentangled representation learning within a projection space and extracting normal dependencies as explicit global prototypes. Specifically, the overall model involves two parts: (i) During encoding, we perform mask modeling in both the data space and projection space with orthogonal basis vectors for learning shared disentangled normal patterns; (ii) During decoding, we decode multiple masked representations in parallel for reconstruction and learn association prototypes to extract normal characteristic correlations. Our proposal derives from a distribution-matching perspective, where both projection space learning and association prototype learning are formulated as optimal transport problems, and the calibration distances are utilized to refine the anomaly scores. Quantitative and qualitative experiments on 20 tabular benchmarks demonstrate the effectiveness and interpretability of our model.","authors":["Ruiying Lu","Jinhan Liu","Chuan Du","Dandan Guo"],"url":"https://arxiv.org/abs/2506.02757"}
{"created":"2025-06-04","title":"Exploiting the English Vocabulary Profile for L2 word-level vocabulary assessment with LLMs","abstract":"Vocabulary use is a fundamental aspect of second language (L2) proficiency. To date, its assessment by automated systems has typically examined the context-independent, or part-of-speech (PoS) related use of words. This paper introduces a novel approach to enable fine-grained vocabulary evaluation exploiting the precise use of words within a sentence. The scheme combines large language models (LLMs) with the English Vocabulary Profile (EVP). The EVP is a standard lexical resource that enables in-context vocabulary use to be linked with proficiency level. We evaluate the ability of LLMs to assign proficiency levels to individual words as they appear in L2 learner writing, addressing key challenges such as polysemy, contextual variation, and multi-word expressions. We compare LLMs to a PoS-based baseline. LLMs appear to exploit additional semantic information that yields improved performance. We also explore correlations between word-level proficiency and essay-level proficiency. Finally, the approach is applied to examine the consistency of the EVP proficiency levels. Results show that LLMs are well-suited for the task of vocabulary assessment.","authors":["Stefano Bann\\`o","Kate Knill","Mark Gales"],"url":"https://arxiv.org/abs/2506.02758"}
{"created":"2025-06-04","title":"Rethinking Machine Unlearning in Image Generation Models","abstract":"With the surge and widespread application of image generation models, data privacy and content safety have become major concerns and attracted great attention from users, service providers, and policymakers. Machine unlearning (MU) is recognized as a cost-effective and promising means to address these challenges. Despite some advancements, image generation model unlearning (IGMU) still faces remarkable gaps in practice, e.g., unclear task discrimination and unlearning guidelines, lack of an effective evaluation framework, and unreliable evaluation metrics. These can hinder the understanding of unlearning mechanisms and the design of practical unlearning algorithms. We perform exhaustive assessments over existing state-of-the-art unlearning algorithms and evaluation standards, and discover several critical flaws and challenges in IGMU tasks. Driven by these limitations, we make several core contributions, to facilitate the comprehensive understanding, standardized categorization, and reliable evaluation of IGMU. Specifically, (1) We design CatIGMU, a novel hierarchical task categorization framework. It provides detailed implementation guidance for IGMU, assisting in the design of unlearning algorithms and the construction of testbeds. (2) We introduce EvalIGMU, a comprehensive evaluation framework. It includes reliable quantitative metrics across five critical aspects. (3) We construct DataIGM, a high-quality unlearning dataset, which can be used for extensive evaluations of IGMU, training content detectors for judgment, and benchmarking the state-of-the-art unlearning algorithms. With EvalIGMU and DataIGM, we discover that most existing IGMU algorithms cannot handle the unlearning well across different evaluation dimensions, especially for preservation and robustness. Code and models are available at https://github.com/ryliu68/IGMU.","authors":["Renyang Liu","Wenjie Feng","Tianwei Zhang","Wei Zhou","Xueqi Cheng","See-Kiong Ng"],"url":"https://arxiv.org/abs/2506.02761"}
{"created":"2025-06-04","title":"Unified Attention Modeling for Efficient Free-Viewing and Visual Search via Shared Representations","abstract":"Computational human attention modeling in free-viewing and task-specific settings is often studied separately, with limited exploration of whether a common representation exists between them. This work investigates this question and proposes a neural network architecture that builds upon the Human Attention transformer (HAT) to test the hypothesis. Our results demonstrate that free-viewing and visual search can efficiently share a common representation, allowing a model trained in free-viewing attention to transfer its knowledge to task-driven visual search with a performance drop of only 3.86% in the predicted fixation scanpaths, measured by the semantic sequence score (SemSS) metric which reflects the similarity between predicted and human scanpaths. This transfer reduces computational costs by 92.29% in terms of GFLOPs and 31.23% in terms of trainable parameters.","authors":["Fatma Youssef Mohammed","Kostas Alexis"],"url":"https://arxiv.org/abs/2506.02764"}
{"created":"2025-06-04","title":"A Dynamic Transformer Network for Vehicle Detection","abstract":"Stable consumer electronic systems can assist traffic better. Good traffic consumer electronic systems require collaborative work between traffic algorithms and hardware. However, performance of popular traffic algorithms containing vehicle detection methods based on deep networks via learning data relation rather than learning differences in different lighting and occlusions is limited. In this paper, we present a dynamic Transformer network for vehicle detection (DTNet). DTNet utilizes a dynamic convolution to guide a deep network to dynamically generate weights to enhance adaptability of an obtained detector. Taking into relations of different information account, a mixed attention mechanism based channel attention and Transformer is exploited to strengthen relations of channels and pixels to extract more salient information for vehicle detection. To overcome the drawback of difference in an image account, a translation-variant convolution relies on spatial location information to refine obtained structural information for vehicle detection. Experimental results illustrate that our DTNet is competitive for vehicle detection. Code of the proposed DTNet can be obtained at https://github.com/hellloxiaotian/DTNet.","authors":["Chunwei Tian","Kai Liu","Bob Zhang","Zhixiang Huang","Chia-Wen Lin","David Zhang"],"url":"https://arxiv.org/abs/2506.02765"}
{"created":"2025-06-04","title":"Accelerating Model-Based Reinforcement Learning using Non-Linear Trajectory Optimization","abstract":"This paper addresses the slow policy optimization convergence of Monte Carlo Probabilistic Inference for Learning Control (MC-PILCO), a state-of-the-art model-based reinforcement learning (MBRL) algorithm, by integrating it with iterative Linear Quadratic Regulator (iLQR), a fast trajectory optimization method suitable for nonlinear systems. The proposed method, Exploration-Boosted MC-PILCO (EB-MC-PILCO), leverages iLQR to generate informative, exploratory trajectories and initialize the policy, significantly reducing the number of required optimization steps. Experiments on the cart-pole task demonstrate that EB-MC-PILCO accelerates convergence compared to standard MC-PILCO, achieving up to $\\bm{45.9\\%}$ reduction in execution time when both methods solve the task in four trials. EB-MC-PILCO also maintains a $\\bm{100\\%}$ success rate across trials while solving the task faster, even in cases where MC-PILCO converges in fewer iterations.","authors":["Marco Cal\\`i","Giulio Giacomuzzo","Ruggero Carli","Alberto Dalla Libera"],"url":"https://arxiv.org/abs/2506.02767"}
{"created":"2025-06-04","title":"Geometric Visual Servo Via Optimal Transport","abstract":"When developing control laws for robotic systems, the principle factor when examining their performance is choosing inputs that allow smooth tracking to a reference input. In the context of robotic manipulation, this involves translating an object or end-effector from an initial pose to a target pose. Robotic manipulation control laws frequently use vision systems as an error generator to track features and produce control inputs. However, current control algorithms don't take into account the probabilistic features that are extracted and instead rely on hand-tuned feature extraction methods. Furthermore, the target features can exist in a static pose thus allowing a combined pose and feature error for control generation. We present a geometric control law for the visual servoing problem for robotic manipulators. The input from the camera constitutes a probability measure on the 3-dimensional Special Euclidean task-space group, where the Wasserstein distance between the current and desired poses is analogous with the geometric geodesic. From this, we develop a controller that allows for both pose and image-based visual servoing by combining classical PD control with gravity compensation with error minimization through the use of geodesic flows on a 3-dimensional Special Euclidean group. We present our results on a set of test cases demonstrating the generalisation ability of our approach to a variety of initial positions.","authors":["Ethan Canzini","Simon Pope","Ashutosh Tiwari"],"url":"https://arxiv.org/abs/2506.02768"}
{"created":"2025-06-04","title":"Voyager: Real-Time Splatting City-Scale 3D Gaussians on Your Phone","abstract":"3D Gaussian Splatting (3DGS) is an emerging technique for photorealistic 3D scene rendering. However, rendering city-scale 3DGS scenes on mobile devices, e.g., your smartphones, remains a significant challenge due to the limited resources on mobile devices. A natural solution is to offload computation to the cloud; however, naively streaming rendered frames from the cloud to the client introduces high latency and requires bandwidth far beyond the capacity of current wireless networks.","authors":["Zheng Liu","He Zhu","Xinyang Li","Yirun Wang","Yujiao Shi","Wei Li","Jingwen Leng","Minyi Guo","Yu Feng"],"url":"https://arxiv.org/abs/2506.02774"}
{"created":"2025-06-04","title":"Nonsmooth data error estimates for exponential Runge--Kutta methods and applications to split exponential integrators","abstract":"We derive error bounds for exponential Runge-Kutta discretizations of parabolic equations with nonsmooth initial data. Our analysis is carried out in a framework of abstract semilinear evolution equations with operators having non-dense domain. In particular, we investigate nonsmooth data error estimates for the Allen-Cahn and the Burgers' equation. As an application, we apply these nonsmooth data error estimates to split exponential integrators and derive a convergence result in terms of the data.","authors":["Qiumei Huang","Alexander Ostermann","Gangfan Zhong"],"url":"https://arxiv.org/abs/2506.02778"}
{"created":"2025-06-04","title":"Reuse or Generate? Accelerating Code Editing via Edit-Oriented Speculative Decoding","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities in code editing, substantially enhancing software development productivity. However, the inherent complexity of code editing tasks forces existing approaches to rely on LLMs' autoregressive end-to-end generation, where decoding speed plays a critical role in efficiency. While inference acceleration techniques like speculative decoding are applied to improve the decoding efficiency, these methods fail to account for the unique characteristics of code editing tasks where changes are typically localized and existing code segments are reused. To address this limitation, we propose EfficientEdit, a novel method that improves LLM-based code editing efficiency through two key mechanisms based on speculative decoding: (1) effective reuse of original code segments while identifying potential edit locations, and (2) efficient generate edit content via high-quality drafts from edit-oriented draft models and a dynamic verification mechanism that balances quality and acceleration. Experimental results show that EfficientEdit can achieve up to 10.38$\\times$ and 13.09$\\times$ speedup compared to standard autoregressive decoding in CanItEdit and CodeIF-Bench, respectively, outperforming state-of-the-art inference acceleration approaches by up to 90.6%.","authors":["Peiding Wang","Li Zhang","Fang Liu","Yinghao Zhu","Wang Xu","Lin Shi","Xiaoli Lian","Minxiao Li","Bo Shen","An Fu"],"url":"https://arxiv.org/abs/2506.02780"}
{"created":"2025-06-04","title":"FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts","abstract":"Controllability plays a crucial role in the practical applications of 3D indoor scene synthesis. Existing works either allow rough language-based control, that is convenient but lacks fine-grained scene customization, or employ graph based control, which offers better controllability but demands considerable knowledge for the cumbersome graph design process. To address these challenges, we present FreeScene, a user-friendly framework that enables both convenient and effective control for indoor scene synthesis.Specifically, FreeScene supports free-form user inputs including text description and/or reference images, allowing users to express versatile design intentions. The user inputs are adequately analyzed and integrated into a graph representation by a VLM-based Graph Designer. We then propose MG-DiT, a Mixed Graph Diffusion Transformer, which performs graph-aware denoising to enhance scene generation. Our MG-DiT not only excels at preserving graph structure but also offers broad applicability to various tasks, including, but not limited to, text-to-scene, graph-to-scene, and rearrangement, all within a single model. Extensive experiments demonstrate that FreeScene provides an efficient and user-friendly solution that unifies text-based and graph based scene synthesis, outperforming state-of-the-art methods in terms of both generation quality and controllability in a range of applications.","authors":["Tongyuan Bai","Wangyuanfan Bai","Dong Chen","Tieru Wu","Manyi Li","Rui Ma"],"url":"https://arxiv.org/abs/2506.02781"}
{"created":"2025-06-04","title":"SAMJ: Fast Image Annotation on ImageJ/Fiji via Segment Anything Model","abstract":"Mask annotation remains a significant bottleneck in AI-driven biomedical image analysis due to its labor-intensive nature. To address this challenge, we introduce SAMJ, a user-friendly ImageJ/Fiji plugin leveraging the Segment Anything Model (SAM). SAMJ enables seamless, interactive annotations with one-click installation on standard computers. Designed for real-time object delineation in large scientific images, SAMJ is an easy-to-use solution that simplifies and accelerates the creation of labeled image datasets.","authors":["Carlos Garcia-Lopez-de-Haro","Caterina Fuster-Barcelo","Curtis T. Rueden","Jonathan Heras","Vladimir Ulman","Daniel Franco-Barranco","Adrian Ines","Kevin W. Eliceiri","Jean-Christophe Olivo-Marin","Jean-Yves Tinevez","Daniel Sage","Arrate Munoz-Barrutia"],"url":"https://arxiv.org/abs/2506.02783"}
{"created":"2025-06-04","title":"UTCS: Effective Unsupervised Temporal Community Search with Pre-training of Temporal Dynamics and Subgraph Knowledge","abstract":"In many real-world applications, the evolving relationships between entities can be modeled as temporal graphs, where each edge has a timestamp representing the interaction time.","authors":["Yue Zhang","Yankai Chen","Yingli Zhou","Yucan Guo","Xiaolin Han","Chenhao Ma"],"url":"https://arxiv.org/abs/2506.02784"}
{"created":"2025-06-04","title":"AI-Driven Vehicle Condition Monitoring with Cell-Aware Edge Service Migration","abstract":"Artificial intelligence (AI) has been increasingly applied to the condition monitoring of vehicular equipment, aiming to enhance maintenance strategies, reduce costs, and improve safety. Leveraging the edge computing paradigm, AI-based condition monitoring systems process vast streams of vehicular data to detect anomalies and optimize operational performance. In this work, we introduce a novel vehicle condition monitoring service that enables real-time diagnostics of a diverse set of anomalies while remaining practical for deployment in real-world edge environments. To address mobility challenges, we propose a closed-loop service orchestration framework where service migration across edge nodes is dynamically triggered by network-related metrics. Our approach has been implemented and tested in a real-world race circuit environment equipped with 5G network capabilities under diverse operational conditions. Experimental results demonstrate the effectiveness of our framework in ensuring low-latency AI inference and adaptive service placement, highlighting its potential for intelligent transportation and mobility applications.","authors":["Charalampos Kalalas","Pavol Mulinka","Guillermo Candela Belmonte","Miguel Fornell","Michail Dalgitsis","Francisco Paredes Vera","Javier Santaella S\\'anchez","Carmen Vicente Villares","Roshan Sedar","Eftychia Datsika","Angelos Antonopoulos","Antonio Fern\\'andez Ojea","Miquel Payaro"],"url":"https://arxiv.org/abs/2506.02785"}
{"created":"2025-06-04","title":"Rethinking Dynamic Networks and Heterogeneous Computing with Automatic Parallelization","abstract":"Hybrid parallelism techniques are essential for efficiently training large language models (LLMs). Nevertheless, current automatic parallel planning frameworks often overlook the simultaneous consideration of node heterogeneity and dynamic network topology changes, limiting their effectiveness in practical applications. In this paper, we address these limitations by modeling heterogeneous nodes within dynamically changing network environments and leveraging simulation-based strategies to determine optimal parallel configurations. Our approach enables fine-grained workload allocation tailored for heterogeneous nodes and complex network scenarios, achieving performance competitive with state-of-the-art methods under regular and stable network conditions. Additionally, we introduce a strategy pruning technique to rapidly discard infeasible parallel configurations, substantially reducing the search space and accelerating the search process through parallel execution within the simulator. Preliminary evaluations confirm that our method notably enhances training performance on heterogeneous nodes and demonstrates improved adaptability in complex, dynamic scenarios such as cloud computing environments.","authors":["Ruilong Wu","Xinjiao Li","Yisu Wang","Xinyu Chen","Dirk Kutscher"],"url":"https://arxiv.org/abs/2506.02787"}
{"created":"2025-06-04","title":"Quantized Dissipative Uncertain Model for Fractional T_S Fuzzy systems with Time_Varying Delays Under Networked Control System","abstract":"This paper addressed with the quantized dissipative uncertain problem for delayed fractional T_S Fuzzy system for event_triggered networked systems (E_NS), where the extended dissipativity analysis combines the H infinity, dissipativity, L2 and L infinity and passivity performance in a unified frame. To attain the high efficiency for available channel resources, measurement size decrease mechanism and event_triggered scheme (ETS) are proposed. Firstly, we present the ETS in which signal is transmitted through the channel with logical function then logarithmic quantization methodology is implemented for size reduction. Then, we transfer the original delayed fractional T_S fuzzy systems with the effect of quantization under ETS as induced communications delays. Furthermore, by employing the associative Lyapunov functional method in terms of linear matrix inequalities, adequate conditions for asymptotical stability is given. Moreover, we also construct the design fuzzy model for state space filtering system. At last, a truck_trailer model is given to show the effectiveness of the proposed strategy.","authors":["Muhammad Shamrooz Aslam","Hazrat Bilal","Sumeera Shamrooz"],"url":"https://arxiv.org/abs/2506.02788"}
{"created":"2025-06-04","title":"Automated Measurement of Optic Nerve Sheath Diameter Using Ocular Ultrasound Video","abstract":"Objective. Elevated intracranial pressure (ICP) is recognized as a biomarker of secondary brain injury, with a significant linear correlation observed between optic nerve sheath diameter (ONSD) and ICP. Frequent monitoring of ONSD could effectively support dynamic evaluation of ICP. However, ONSD measurement is heavily reliant on the operator's experience and skill, particularly in manually selecting the optimal frame from ultrasound sequences and measuring ONSD. Approach. This paper presents a novel method to automatically identify the optimal frame from video sequences for ONSD measurement by employing the Kernel Correlation Filter (KCF) tracking algorithm and Simple Linear Iterative Clustering (SLIC) segmentation algorithm. The optic nerve sheath is mapped and measured using a Gaussian Mixture Model (GMM) combined with a KL-divergence-based method. Results. When compared with the average measurements of two expert clinicians, the proposed method achieved a mean error, mean squared deviation, and intraclass correlation coefficient (ICC) of 0.04, 0.054, and 0.782, respectively. Significance. The findings suggest that this method provides highly accurate automated ONSD measurements, showing potential for clinical application.","authors":["Renxing Li","Weiyi Tang","Peiqi Li","Qiming Huang","Jiayuan She","Shengkai Li","Haoran Xu","Yeyun Wan","Jing Liu","Hailong Fu","Xiang Li","Jiangang Chen"],"url":"https://arxiv.org/abs/2506.02789"}
{"created":"2025-06-04","title":"Rethinking the effects of data contamination in Code Intelligence","abstract":"In recent years, code intelligence has gained increasing importance in the field of automated software engineering. Meanwhile, the widespread adoption of Pretrained Language Models (PLMs) and Large Language Models (LLMs) has raised concerns regarding data contamination and its potential impact on model performance evaluation. This paper presents a systematic empirical study to investigate the fine-grained data contamination on code intelligence tasks. Our study involves diverse representative PLMs, namely RoBERTa and GPT-2, and LLMs, namely LLaMA and StarCoder, covering three major tasks: code translation, code generation, and code summarization. We categorize contamination scenarios into four types according to the code intelligence practice, namely input-only, output-only, unpaired, and paired contamination settings, and construct corresponding experimental and control groups for exploration.","authors":["Zhen Yang","Hongyi Lin","Yifan He","Jie Xu","Zeyu Sun","Shuo Liu","Pengpeng Wang","Zhongxing Yu","Qingyuan Liang"],"url":"https://arxiv.org/abs/2506.02791"}
{"created":"2025-06-04","title":"Exploring metrics for analyzing dynamic behavior in MPI programs via a coupled-oscillator model","abstract":"We propose a novel, lightweight, and physically inspired approach to modeling the dynamics of parallel distributed-memory programs. Inspired by the Kuramoto model, we represent MPI processes as coupled oscillators with topology-aware interactions, custom coupling potentials, and stochastic noise. The resulting system of nonlinear ordinary differential equations opens a path to modeling key performance phenomena of parallel programs, including synchronization, delay propagation and decay, bottlenecks, and self-desynchronization.","authors":["Ayesha Afzal","Georg Hager","Gerhard Wellen"],"url":"https://arxiv.org/abs/2506.02792"}
{"created":"2025-06-04","title":"PhysGaia: A Physics-Aware Dataset of Multi-Body Interactions for Dynamic Novel View Synthesis","abstract":"We introduce PhysGaia, a novel physics-aware dataset specifically designed for Dynamic Novel View Synthesis (DyNVS), encompassing both structured objects and unstructured physical phenomena. Unlike existing datasets that primarily focus on photorealistic reconstruction, PhysGaia is created to actively support physics-aware dynamic scene modeling. Our dataset provides complex dynamic scenarios with rich interactions among multiple objects, where they realistically collide with each other and exchange forces. Furthermore, it contains a diverse range of physical materials, such as liquid, gas, viscoelastic substance, and textile, which moves beyond the rigid bodies prevalent in existing datasets. All scenes in PhysGaia are faithfully generated to strictly adhere to physical laws, leveraging carefully selected material-specific physics solvers. To enable quantitative evaluation of physical modeling, our dataset provides essential ground-truth information, including 3D particle trajectories and physics parameters, e.g., viscosity. To facilitate research adoption, we also provide essential integration pipelines for using state-of-the-art DyNVS models with our dataset and report their results. By addressing the critical lack of datasets for physics-aware modeling, PhysGaia will significantly advance research in dynamic view synthesis, physics-based scene understanding, and deep learning models integrated with physical simulation -- ultimately enabling more faithful reconstruction and interpretation of complex dynamic scenes. Our datasets and codes are available in the project website, http://cvlab.snu.ac.kr/research/PhysGaia.","authors":["Mijeong Kim","Gunhee Kim","Jungyoon Choi","Wonjae Roh","Bohyung Han"],"url":"https://arxiv.org/abs/2506.02794"}
{"created":"2025-06-04","title":"A Learned Cost Model-based Cross-engine Optimizer for SQL Workloads","abstract":"Lakehouse systems enable the same data to be queried with multiple execution engines. However, selecting the engine best suited to run a SQL query still requires a priori knowledge of the query computational requirements and an engine capability, a complex and manual task that only becomes more difficult with the emergence of new engines and workloads. In this paper, we address this limitation by proposing a cross-engine optimizer that can automate engine selection for diverse SQL queries through a learned cost model. Optimized with hints, a query plan is used for query cost prediction and routing. Cost prediction is formulated as a multi-task learning problem, and multiple predictor heads, corresponding to different engines and provisionings, are used in the model architecture. This eliminates the need to train engine-specific models and allows the flexible addition of new engines at a minimal fine-tuning cost. Results on various databases and engines show that using a query optimized logical plan for cost estimation decreases the average Q-error by even 12.6% over using unoptimized plans as input. Moreover, the proposed cross-engine optimizer reduces the total workload runtime by up to 25.2% in a zero-shot setting and 30.4% in a few-shot setting when compared to random routing.","authors":["Andr\\'as Strausz","Niels Pardon","Ioana Giurgiu"],"url":"https://arxiv.org/abs/2506.02802"}
{"created":"2025-06-04","title":"SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking","abstract":"Vision-language models (VLMs) excel in semantic tasks but falter at a core human capability: detecting hidden content in optical illusions or AI-generated images through perceptual adjustments like zooming. We introduce HC-Bench, a benchmark of 112 images with hidden text, objects, and illusions, revealing that leading VLMs achieve near-zero accuracy (0-5.36%)-even with explicit prompting. Humans resolve such ambiguities instinctively, yet VLMs fail due to an overreliance on high-level semantics. Strikingly, we propose SemVink (Semantic Visual Thinking) by simply scaling images to low resolutions (32-128 pixels), which unlocks >99% accuracy by eliminating redundant visual noise. This exposes a critical architectural flaw: VLMs prioritize abstract reasoning over low-level visual operations crucial for real-world robustness. Our work urges a shift toward hybrid models integrating multi-scale processing, bridging the gap between computational vision and human cognition for applications in medical imaging, security, and beyond.","authors":["Sifan Li","Yujun Cai","Yiwei Wang"],"url":"https://arxiv.org/abs/2506.02803"}
{"created":"2025-06-04","title":"Optimising the attribute order in Fuzzy Rough Rule Induction","abstract":"Interpretability is the next pivotal frontier in machine learning research. In the pursuit of glass box models - as opposed to black box models, like random forests or neural networks - rule induction algorithms are a logical and promising avenue, as the rules can easily be understood by humans. In our previous work, we introduced FRRI, a novel rule induction algorithm based on fuzzy rough set theory. We demonstrated experimentally that FRRI outperformed other rule induction methods with regards to accuracy and number of rules. FRRI leverages a fuzzy indiscernibility relation to partition the data space into fuzzy granules, which are then combined into a minimal covering set of rules. This indiscernibility relation is constructed by removing attributes from rules in a greedy way. This raises the question: does the order of the attributes matter? In this paper, we show that optimising only the order of attributes using known methods from fuzzy rough set theory and classical machine learning does not improve the performance of FRRI on multiple metrics. However, removing a small number of attributes using fuzzy rough feature selection during this step positively affects balanced accuracy and the average rule length.","authors":["Henri Bollaert","Chris Cornelis","Marko Palangeti\\'c","Salvatore Greco","Roman S{\\l}owi\\'nski"],"url":"https://arxiv.org/abs/2506.02805"}
{"created":"2025-06-04","title":"CART-based Synthetic Tabular Data Generation for Imbalanced Regression","abstract":"Handling imbalanced target distributions in regression tasks remains a significant challenge in tabular data settings where underrepresented regions can hinder model performance. Among data-level solutions, some proposals, such as random sampling and SMOTE-based approaches, propose adapting classification techniques to regression tasks. However, these methods typically rely on crisp, artificial thresholds over the target variable, a limitation inherited from classification settings that can introduce arbitrariness, often leading to non-intuitive and potentially misleading problem formulations. While recent generative models, such as GANs and VAEs, provide flexible sample synthesis, they come with high computational costs and limited interpretability. In this study, we propose adapting an existing CART-based synthetic data generation method, tailoring it for imbalanced regression. The new method integrates relevance and density-based mechanisms to guide sampling in sparse regions of the target space and employs a threshold-free, feature-driven generation process. Our experimental study focuses on the prediction of extreme target values across benchmark datasets. The results indicate that the proposed method is competitive with other resampling and generative strategies in terms of performance, while offering faster execution and greater transparency. These results highlight the method's potential as a transparent, scalable data-level strategy for improving regression models in imbalanced domains.","authors":["Ant\\'onio Pedro Pinheiro","Rita P. Ribeiro"],"url":"https://arxiv.org/abs/2506.02811"}
{"created":"2025-06-04","title":"Adaptive Configuration Selection for Multi-Model Inference Pipelines in Edge Computing","abstract":"The growing demand for real-time processing tasks is driving the need for multi-model inference pipelines on edge devices. However, cost-effectively deploying these pipelines while optimizing Quality of Service (QoS) and costs poses significant challenges. Existing solutions often neglect device resource constraints, focusing mainly on inference accuracy and cost efficiency. To address this, we develop a framework for configuring multi-model inference pipelines. Specifically: 1) We model the decision-making problem by considering the pipeline's QoS, costs, and device resource limitations. 2) We create a feature extraction module using residual networks and a load prediction model based on Long Short-Term Memory (LSTM) to gather comprehensive node and pipeline status information. Then, we implement a Reinforcement Learning (RL) algorithm based on policy gradients for online configuration decisions. 3) Experiments conducted in a real Kubernetes cluster show that our approach significantly improve QoS while reducing costs and shorten decision-making time for complex pipelines compared to baseline algorithms.","authors":["Jinhao Sheng","Zhiqing Tang","Jianxiong Guo","Tian Wang"],"url":"https://arxiv.org/abs/2506.02814"}
{"created":"2025-06-04","title":"The Bayesian Finite Element Method in Inverse Problems: a Critical Comparison between Probabilistic Models for Discretization Error","abstract":"When using the finite element method (FEM) in inverse problems, its discretization error can produce parameter estimates that are inaccurate and overconfident. The Bayesian finite element method (BFEM) provides a probabilistic model for the epistemic uncertainty due to discretization error. In this work, we apply BFEM to various inverse problems, and compare its performance to the random mesh finite element method (RM-FEM) and the statistical finite element method (statFEM), which serve as a frequentist and inference-based counterpart to BFEM. We find that by propagating this uncertainty to the posterior, BFEM can produce more accurate parameter estimates and prevent overconfidence, compared to FEM. Because the BFEM covariance operator is designed to leave uncertainty only in the appropriate space, orthogonal to the FEM basis, BFEM is able to outperform RM-FEM, which does not have such a structure to its covariance. Although inferring the discretization error via a model misspecification component is possible as well, as is done in statFEM, the feasibility of such an approach is contingent on the availability of sufficient data. We find that the BFEM is the most robust way to consistently propagate uncertainty due to discretization error to the posterior of a Bayesian inverse problem.","authors":["Anne Poot","Iuri Rocha","Pierre Kerfriden","Frans van der Meeer"],"url":"https://arxiv.org/abs/2506.02815"}
{"created":"2025-06-04","title":"Eigenvalue bounds for preconditioned symmetric multiple saddle-point matrices","abstract":"We develop eigenvalue bounds for symmetric, block tridiagonal multiple saddle-point linear systems, preconditioned with block diagonal matrices. We extend known results for $3 \\times 3$ block systems [Bradley and Greif, IMA J.\\ Numer. Anal. 43 (2023)] and for $4 \\times 4$ systems [Pearson and Potschka, IMA J. Numer. Anal. 44 (2024)] to an arbitrary number of blocks. Moreover, our results generalize the bounds in [Sogn and Zulehner, IMA J. Numer. Anal. 39 (2018)], developed for an arbitrary number of blocks with null diagonal blocks. Extension to the bounds when the Schur complements are approximated is also provided, using perturbation arguments. Practical bounds are also obtained for the double saddle-point linear system. Numerical experiments validate our findings.","authors":["L. Bergamaschi","A. Martinez","J. W. Pearson","A. Potschka"],"url":"https://arxiv.org/abs/2506.02816"}
{"created":"2025-06-04","title":"ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations","abstract":"Large language models (LLMs) demonstrate impressive results in natural language processing tasks but require a significant amount of computational and memory resources. Structured matrix representations are a promising way for reducing the number of parameters of these models. However, it seems unrealistic to expect that weight matrices of pretrained models can be accurately represented by structured matrices without any fine-tuning. To overcome this issue, we utilize the fact that LLM output is invariant under certain orthogonal transformations of weight matrices. This insight can be leveraged to identify transformations that significantly improve the compressibility of weights within structured classes. The proposed approach is applicable to various types of structured matrices that support efficient projection operations. Code is available at https://github.com/GrishKate/ProcrustesGPT","authors":["Ekaterina Grishina","Mikhail Gorbunov","Maxim Rakhuba"],"url":"https://arxiv.org/abs/2506.02818"}
{"created":"2025-06-04","title":"Energy Efficiency Analysis of Active RIS-enhanced Wireless Network under Power-Sum Constraint","abstract":"Recently, as a green wireless technology, active reconfigurable intelligent surface (RIS) attracts numerous research activities due to its amplifying ability to combat the double-fading effect compared to passive one. How about its energy efficiency (EE) over passive one? Below, the EE of active RIS-aided wireless network in Rayleigh fading channels is analyzed. Using the law of large numbers, EE is derived as a function of five factors: power allocation factor, the number (N) of RIS elements, the total power, the noise variances at RIS and at user. To evaluate each factor's impact, the simple EE function for the concerning factor is given with others fixed. To assess the impact of N on EE, we establish an equation with the EE of active RIS equaling that of passive one, and three methods, bisection, Newton's method, and simulated annealing, are designed to find the roots of this equation. Simulation results show that as N tends to medium-scale or large-scale, the asymptotic performance formula is consistent with the exact EE expression well. As N varies from small-scale to large-scale, the active RIS intersects passive one at some point. When N< N_0, active RIS performs better than passive one in terms of EE. Otherwise, there is a converse conclusion.","authors":["Jingdie Xin","Yan Wang","Feng Shu","Feng Zhao","Yifan Zhao","Hao Jiang"],"url":"https://arxiv.org/abs/2506.02823"}
{"created":"2025-06-04","title":"Efficient Tactile Perception with Soft Electrical Impedance Tomography and Pre-trained Transformer","abstract":"Tactile sensing is fundamental to robotic systems, enabling interactions through physical contact in multiple tasks. Despite its importance, achieving high-resolution, large-area tactile sensing remains challenging. Electrical Impedance Tomography (EIT) has emerged as a promising approach for large-area, distributed tactile sensing with minimal electrode requirements which can lend itself to addressing complex contact problems in robotics. However, existing EIT-based tactile reconstruction methods often suffer from high computational costs or depend on extensive annotated simulation datasets, hindering its viability in real-world settings. To address this shortcoming, here we propose a Pre-trained Transformer for EIT-based Tactile Reconstruction (PTET), a learning-based framework that bridges the simulation-to-reality gap by leveraging self-supervised pretraining on simulation data and fine-tuning with limited real-world data. In simulations, PTET requires 99.44 percent fewer annotated samples than equivalent state-of-the-art approaches (2,500 vs. 450,000 samples) while achieving reconstruction performance improvements of up to 43.57 percent under identical data conditions. Fine-tuning with real-world data further enables PTET to overcome discrepancies between simulated and experimental datasets, achieving superior reconstruction and detail recovery in practical scenarios. The improved reconstruction accuracy, data efficiency, and robustness in real-world tasks establish it as a scalable and practical solution for tactile sensing systems in robotics, especially for object handling and adaptive grasping under varying pressure conditions.","authors":["Huazhi Dong (Sharel)","Ronald B. Liu (Sharel)","Sihao Teng (Sharel)","Delin Hu (Sharel)","Peisan (Sharel)","E","Francesco Giorgio-Serchi","Yunjie Yang"],"url":"https://arxiv.org/abs/2506.02824"}
{"created":"2025-06-04","title":"TO-GATE: Clarifying Questions and Summarizing Responses with Trajectory Optimization for Eliciting Human Preference","abstract":"Large language models (LLMs) can effectively elicit human preferences through multi-turn dialogue. Complex tasks can be accomplished through iterative clarifying questions and final responses generated by an LLM acting as a questioner (STaR-GATE; Andukuri et al., 2024}). However, existing approaches based on self-taught reasoning struggle to identify optimal dialogue trajectories and avoid irrelevant questions to the tasks. To address this limitation, we propose TO-GATE, a novel framework that enhances question generation through trajectory optimization, which consists of two key components: a clarification resolver that generates optimal questioning trajectories, and a summarizer that ensures task-aligned final responses. The trajectory optimization enables the model to produce effective elicitation questions and summary responses tailored to specific tasks. Experimental results demonstrate that TO-GATE significantly outperforms baseline methods, achieving a 9.32% improvement on standard preference elicitation tasks.","authors":["Yulin Dou","Jiangming Liu"],"url":"https://arxiv.org/abs/2506.02827"}
{"created":"2025-06-04","title":"Target Sensing Performance in Disaster-Specific ISAC Networks","abstract":"As sixth-generation (6G) wireless technology emerges, integrated sensing and communication (ISAC) networks offer significant potential for enhancing real-time monitoring in disaster areas. However, existing ISAC approaches often fail to address the unique challenges of dynamic and cluttered disaster areas, resulting in limited sensing coverage and interruptions in sensing service. To address these limitations, this work proposes a mobile ISAC network specifically designed for disaster scenarios. By leveraging stochastic geometry, we derive closed-form expressions for sensing coverage and introduce a novel performance metric to evaluate sensing service continuity. Simulation results validate the analytical derivations and offer key insights into network design.","authors":["Ahmet Burak Ozyurt","John S. Thompson"],"url":"https://arxiv.org/abs/2506.02828"}
{"created":"2025-06-04","title":"Process Mining on Distributed Data Sources","abstract":"Major domains such as logistics, healthcare, and smart cities increasingly rely on sensor technologies and distributed infrastructures to monitor complex processes in real time. These developments are transforming the data landscape from discrete, structured records stored in centralized systems to continuous, fine-grained, and heterogeneous event streams collected across distributed environments. As a result, traditional process mining techniques, which assume centralized event logs from enterprise systems, are no longer sufficient. In this paper, we discuss the conceptual and methodological foundations for this emerging field. We identify three key shifts: from offline to online analysis, from centralized to distributed computing, and from event logs to sensor data. These shifts challenge traditional assumptions about process data and call for new approaches that integrate infrastructure, data, and user perspectives. To this end, we define a research agenda that addresses six interconnected fields, each spanning multiple system dimensions. We advocate a principled methodology grounded in algorithm engineering, combining formal modeling with empirical evaluation. This approach enables the development of scalable, privacy-aware, and user-centric process mining techniques suitable for distributed environments. Our synthesis provides a roadmap for advancing process mining beyond its classical setting, toward a more responsive and decentralized paradigm of process intelligence.","authors":["Maximilian Weisenseel","Julia Andersen","Samira Akili","Christian Imenkamp","Hendrik Reiter","Christoffer Rubensson","Wilhelm Hasselbring","Olaf Landsiedel","Xixi Lu","Jan Mendling","Florian Tschorsch","Matthias Weidlich","Agnes Koschmider"],"url":"https://arxiv.org/abs/2506.02830"}
{"created":"2025-06-04","title":"Combining social relations and interaction data in Recommender System with Graph Convolution Collaborative Filtering","abstract":"A recommender system is an important subject in the field of data mining, where the item rating information from users is exploited and processed to make suitable recommendations with all other users. The recommender system creates convenience for e-commerce users and stimulates the consumption of items that are suitable for users. In addition to e-commerce, a recommender system is also used to provide recommendations on books to read, movies to watch, courses to take or websites to visit. Similarity between users is an important impact for recommendation, which could be calculated from the data of past user ratings of the item by methods of collaborative filtering, matrix factorization or singular vector decomposition. In the development of graph data mining techniques, the relationships between users and items can be represented by matrices from which collaborative filtering could be done with the larger database, more accurate and faster in calculation. All these data can be represented graphically and mined by today's highly developed graph neural network models. On the other hand, users' social friendship data also influence consumption habits because recommendations from friends will be considered more carefully than information sources. However, combining a user's friend influence and the similarity between users whose similar shopping habits is challenging. Because the information is noisy and it affects each particular data set in different ways. In this study, we present the input data processing method to remove outliers which are single reviews or users with little interaction with the items; the next proposed model will combine the social relationship data and the similarity in the rating history of users to improve the accuracy and recall of the recommender system.","authors":["Tin T. Tran","Vaclav Snasel","Loc Tan Nguyen"],"url":"https://arxiv.org/abs/2506.02834"}
{"created":"2025-06-04","title":"High-speed control and navigation for quadrupedal robots on complex and discrete terrain","abstract":"High-speed legged navigation in discrete and geometrically complex environments is a challenging task because of the high-degree-of-freedom dynamics and long-horizon, nonconvex nature of the optimization problem. In this work, we propose a hierarchical navigation pipeline for legged robots that can traverse such environments at high speed. The proposed pipeline consists of a planner and tracker module. The planner module finds physically feasible foothold plans by sampling-based optimization with fast sequential filtering using heuristics and a neural network. Subsequently, rollouts are performed in a physics simulation to identify the best foothold plan regarding the engineered cost function and to confirm its physical consistency. This hierarchical planning module is computationally efficient and physically accurate at the same time. The tracker aims to accurately step on the target footholds from the planning module. During the training stage, the foothold target distribution is given by a generative model that is trained competitively with the tracker. This process ensures that the tracker is trained in an environment with the desired difficulty. The resulting tracker can overcome terrains that are more difficult than what the previous methods could manage. We demonstrated our approach using Raibo, our in-house dynamic quadruped robot. The results were dynamic and agile motions: Raibo is capable of running on vertical walls, jumping a 1.3-meter gap, running over stepping stones at 4 meters per second, and autonomously navigating on terrains full of 30{\\deg} ramps, stairs, and boxes of various sizes.","authors":["Hyeongjun Kim","Hyunsik Oh","Jeongsoo Park","Yunho Kim","Donghoon Youm","Moonkyu Jung","Minho Lee","Jemin Hwangbo"],"url":"https://arxiv.org/abs/2506.02835"}
{"created":"2025-06-04","title":"TaxAgent: How Large Language Model Designs Fiscal Policy","abstract":"Economic inequality is a global challenge, intensifying disparities in education, healthcare, and social stability. Traditional systems like the U.S. federal income tax reduce inequality but lack adaptability. Although models like the Saez Optimal Taxation adjust dynamically, they fail to address taxpayer heterogeneity and irrational behavior. This study introduces TaxAgent, a novel integration of large language models (LLMs) with agent-based modeling (ABM) to design adaptive tax policies. In our macroeconomic simulation, heterogeneous H-Agents (households) simulate real-world taxpayer behaviors while the TaxAgent (government) utilizes LLMs to iteratively optimize tax rates, balancing equity and productivity. Benchmarked against Saez Optimal Taxation, U.S. federal income taxes, and free markets, TaxAgent achieves superior equity-efficiency trade-offs. This research offers a novel taxation solution and a scalable, data-driven framework for fiscal policy evaluation.","authors":["Jizhou Wang","Xiaodan Fang","Lei Huang","Yongfeng Huang"],"url":"https://arxiv.org/abs/2506.02838"}
{"created":"2025-06-04","title":"DeepShop: A Benchmark for Deep Research Shopping Agents","abstract":"Web agents for online shopping have shown great promise in automating user interactions across e-commerce platforms. Benchmarks for assessing such agents do not reflect the complexity of real-world shopping scenarios, as they often consist of overly simple queries with deterministic paths, such as \"Find iPhone 15.\" Real shopping scenarios are inherently more layered, involving multi-dimensional product attributes, search filters, and user-specific sorting preferences. To address this gap, we introduce DeepShop, a benchmark designed to evaluate web agents in complex and realistic online shopping environments. DeepShop comprises three key components. (1) Query diversity evolution: Starting from real user queries, we generate diverse queries across five popular online shopping domains. (2) Query complexity evolution: We further evolve these queries to increase complexity, considering product attributes, search filters, and sorting preferences, and classify them into three levels: easy, medium, and hard, based on the number of evolutions. (3) Fine-grained and holistic evaluation: We propose an automated evaluation framework that assesses agent performance in terms of fine-grained aspects (product attributes, search filters, and sorting preferences) and reports the overall success rate through holistic evaluation. We conduct a systematic evaluation of retrieval-augmented generation (RAG) methods, web agents, and deep research systems. Results show that RAG struggles with complex queries due to its lack of web interaction, while other methods face significant challenges with filters and sorting preferences, leading to low overall success rates. We also perform cross-category, complexity-based evaluations and error analyses to support the advancement of deep research shopping agents.","authors":["Yougang Lyu","Xiaoyu Zhang","Lingyong Yan","Maarten de Rijke","Zhaochun Ren","Xiuying Chen"],"url":"https://arxiv.org/abs/2506.02839"}
{"created":"2025-06-04","title":"On dual-rate consensus under transmission delays","abstract":"In this paper, we investigate the problem of dual-rate consensus under transmission delays, where the control updates happen at a faster rate than the measurements being received. We assume that the measurements are delayed by a fixed delay and show that for all delays and rates, the system reaches a consensus if and only if the communication graph of the agents is connected and the control gain is chosen in a specific interval. Based on these results we dive deeper into the convergence properties and investigate how the convergence changes when we change the rate for sending measurements. We observe that in certain cases there exists a sweet spot for choosing the sampling rate of the measurements, which can improve the convergence to the consensus point. We then formulate an optimization problem to find a sampling rate to improve the convergence speed and provide a necessary and sufficient condition for the existence of a finite optimizer of this problem. Our results are verified with numerical simulations.","authors":["David Umsonst","Mina Ferizbegovic"],"url":"https://arxiv.org/abs/2506.02840"}
{"created":"2025-06-04","title":"Ensemble-MIX: Enhancing Sample Efficiency in Multi-Agent RL Using Ensemble Methods","abstract":"Multi-agent reinforcement learning (MARL) methods have achieved state-of-the-art results on a range of multi-agent tasks. Yet, MARL algorithms typically require significantly more environment interactions than their single-agent counterparts to converge, a problem exacerbated by the difficulty in exploring over a large joint action space and the high variance intrinsic to MARL environments. To tackle these issues, we propose a novel algorithm that combines a decomposed centralized critic with decentralized ensemble learning, incorporating several key contributions. The main component in our scheme is a selective exploration method that leverages ensemble kurtosis. We extend the global decomposed critic with a diversity-regularized ensemble of individual critics and utilize its excess kurtosis to guide exploration toward high-uncertainty states and actions. To improve sample efficiency, we train the centralized critic with a novel truncated variation of the TD($\\lambda$) algorithm, enabling efficient off-policy learning with reduced variance. On the actor side, our suggested algorithm adapts the mixed samples approach to MARL, mixing on-policy and off-policy loss functions for training the actors. This approach balances between stability and efficiency and outperforms purely off-policy learning. The evaluation shows our method outperforms state-of-the-art baselines on standard MARL benchmarks, including a variety of SMAC II maps.","authors":["Tom Danino","Nahum Shimkin"],"url":"https://arxiv.org/abs/2506.02841"}
{"created":"2025-06-04","title":"Sheaves Reloaded: A Directional Awakening","abstract":"Sheaf Neural Networks (SNNs) represent a powerful generalization of Graph Neural Networks (GNNs) that significantly improve our ability to model complex relational data. While directionality has been shown to substantially boost performance in graph learning tasks and is key to many real-world applications, existing SNNs fall short in representing it. To address this limitation, we introduce the Directed Cellular Sheaf, a special type of cellular sheaf designed to explicitly account for edge orientation. Building on this structure, we define a new sheaf Laplacian, the Directed Sheaf Laplacian, which captures both the graph's topology and its directional information. This operator serves as the backbone of the Directed Sheaf Neural Network (DSNN), the first SNN model to embed a directional bias into its architecture. Extensive experiments on nine real-world benchmarks show that DSNN consistently outperforms baseline methods.","authors":["Stefano Fiorini","Hakan Aktas","Iulia Duta","Stefano Coniglio","Pietro Morerio","Alessio Del Bue","Pietro Li\\`o"],"url":"https://arxiv.org/abs/2506.02842"}
{"created":"2025-06-04","title":"Random Registers for Cross-Domain Few-Shot Learning","abstract":"Cross-domain few-shot learning (CDFSL) aims to transfer knowledge from a data-sufficient source domain to data-scarce target domains. Although Vision Transformer (ViT) has shown superior capability in many vision tasks, its transferability against huge domain gaps in CDFSL is still under-explored. In this paper, we find an intriguing phenomenon: during the source-domain training, prompt tuning, as a common way to train ViT, could be harmful for the generalization of ViT in target domains, but setting them to random noises (i.e., random registers) could consistently improve target-domain performance. We then delve into this phenomenon for an interpretation. We find that learnable prompts capture domain information during the training on the source dataset, which views irrelevant visual patterns as vital cues for recognition. This can be viewed as a kind of overfitting and increases the sharpness of the loss landscapes. In contrast, random registers are essentially a novel way of perturbing attention for the sharpness-aware minimization, which helps the model find a flattened minimum in loss landscapes, increasing the transferability. Based on this phenomenon and interpretation, we further propose a simple but effective approach for CDFSL to enhance the perturbation on attention maps by adding random registers on the semantic regions of image tokens, improving the effectiveness and efficiency of random registers. Extensive experiments on four benchmarks validate our rationale and state-of-the-art performance. Codes and models are available at https://github.com/shuaiyi308/REAP.","authors":["Shuai Yi","Yixiong Zou","Yuhua Li","Ruixuan Li"],"url":"https://arxiv.org/abs/2506.02843"}
{"created":"2025-06-04","title":"Go Beyond Earth: Understanding Human Actions and Scenes in Microgravity Environments","abstract":"Despite substantial progress in video understanding, most existing datasets are limited to Earth's gravitational conditions. However, microgravity alters human motion, interactions, and visual semantics, revealing a critical gap for real-world vision systems. This presents a challenge for domain-robust video understanding in safety-critical space applications. To address this, we introduce MicroG-4M, the first benchmark for spatio-temporal and semantic understanding of human activities in microgravity. Constructed from real-world space missions and cinematic simulations, the dataset includes 4,759 clips covering 50 actions, 1,238 context-rich captions, and over 7,000 question-answer pairs on astronaut activities and scene understanding. MicroG-4M supports three core tasks: fine-grained multi-label action recognition, temporal video captioning, and visual question answering, enabling a comprehensive evaluation of both spatial localization and semantic reasoning in microgravity contexts. We establish baselines using state-of-the-art models. All data, annotations, and code are available at https://github.com/LEI-QI-233/HAR-in-Space.","authors":["Di Wen","Lei Qi","Kunyu Peng","Kailun Yang","Fei Teng","Ao Luo","Jia Fu","Yufan Chen","Ruiping Liu","Yitian Shi","M. Saquib Sarfraz","Rainer Stiefelhagen"],"url":"https://arxiv.org/abs/2506.02845"}
{"created":"2025-06-04","title":"PBR-SR: Mesh PBR Texture Super Resolution from 2D Image Priors","abstract":"We present PBR-SR, a novel method for physically based rendering (PBR) texture super resolution (SR). It outputs high-resolution, high-quality PBR textures from low-resolution (LR) PBR input in a zero-shot manner. PBR-SR leverages an off-the-shelf super-resolution model trained on natural images, and iteratively minimizes the deviations between super-resolution priors and differentiable renderings. These enhancements are then back-projected into the PBR map space in a differentiable manner to produce refined, high-resolution textures. To mitigate view inconsistencies and lighting sensitivity, which is common in view-based super-resolution, our method applies 2D prior constraints across multi-view renderings, iteratively refining the shared, upscaled textures. In parallel, we incorporate identity constraints directly in the PBR texture domain to ensure the upscaled textures remain faithful to the LR input. PBR-SR operates without any additional training or data requirements, relying entirely on pretrained image priors. We demonstrate that our approach produces high-fidelity PBR textures for both artist-designed and AI-generated meshes, outperforming both direct SR models application and prior texture optimization methods. Our results show high-quality outputs in both PBR and rendering evaluations, supporting advanced applications such as relighting.","authors":["Yujin Chen","Yinyu Nie","Benjamin Ummenhofer","Reiner Birkl","Michael Paulitsch","Matthias Nie{\\ss}ner"],"url":"https://arxiv.org/abs/2506.02846"}
{"created":"2025-06-04","title":"CLONE: Customizing LLMs for Efficient Latency-Aware Inference at the Edge","abstract":"Deploying large language models (LLMs) on edge devices is crucial for delivering fast responses and ensuring data privacy. However, the limited storage, weight, and power of edge devices make it difficult to deploy LLM-powered applications. These devices must balance latency requirements with energy consumption and model accuracy. In this paper, we first quantify the challenges of deploying LLMs on off-the-shelf edge devices and then we present CLONE, an in-depth algorithm-hardware co-design at both the model- and system-level that intelligently integrates real-time, energy optimization while maintaining robust generality. In order to maximize the synergistic benefits of these algorithms in always-on and intermediate edge computing settings, we specialize in a 28nm scalable hardware accelerator system. We implement and extensively evaluate CLONE on two off-the-shelf edge platforms. Experiments show that CLONE effectively accelerates the inference process up to 11.92x, and saves energy up to 7.36x, while maintaining high-generation.","authors":["Chunlin Tian","Xinpeng Qin","Kahou Tam","Li Li","Zijian Wang","Yuanzhe Zhao","Minglei Zhang","Chengzhong Xu"],"url":"https://arxiv.org/abs/2506.02847"}
{"created":"2025-06-04","title":"Learned Controllers for Agile Quadrotors in Pursuit-Evasion Games","abstract":"The increasing proliferation of small UAVs in civilian and military airspace has raised critical safety and security concerns, especially when unauthorized or malicious drones enter restricted zones. In this work, we present a reinforcement learning (RL) framework for agile 1v1 quadrotor pursuit-evasion. We train neural network policies to command body rates and collective thrust, enabling high-speed pursuit and evasive maneuvers that fully exploit the quadrotor's nonlinear dynamics. To mitigate nonstationarity and catastrophic forgetting during adversarial co-training, we introduce an Asynchronous Multi-Stage Population-Based (AMSPB) algorithm where, at each stage, either the pursuer or evader learns against a sampled opponent drawn from a growing population of past and current policies. This continual learning setup ensures monotonic performance improvement and retention of earlier strategies. Our results show that (i) rate-based policies achieve significantly higher capture rates and peak speeds than velocity-level baselines, and (ii) AMSPB yields stable, monotonic gains against a suite of benchmark opponents.","authors":["Alejandro Sanchez Roncero","Olov Andersson","Petter Ogren"],"url":"https://arxiv.org/abs/2506.02849"}
{"created":"2025-06-04","title":"METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding","abstract":"Recent advances in Video Large Language Models (VLLMs) have significantly enhanced their ability to understand video content. Nonetheless, processing long videos remains challenging due to high computational demands and the redundancy present in the visual data. In this work, we propose METok, a training-free, Multi-stage Event-based Token compression framework designed to accelerate VLLMs' inference while preserving accuracy. METok progressively eliminates redundant visual tokens across three critical stages: (1) event-aware compression during vision encoding, (2) hierarchical token pruning in the prefilling stage based on semantic alignment and event importance, and (3) a decoding-stage KV Cache optimization that further reduces memory consumption. Our experiments on diverse video benchmarks demonstrate that METok achieves an optimal trade-off between efficiency and accuracy by dynamically selecting informative visual tokens. For instance, equipping LongVA-7B with METok realizes an 80.6% FLOPs reduction and 93.5% KV Cache memory savings, all while maintaining comparable or even superior accuracy.","authors":["Mengyue Wang","Shuo Chen","Kristian Kersting","Volker Tresp","Yunpu Ma"],"url":"https://arxiv.org/abs/2506.02850"}
{"created":"2025-06-04","title":"Proportional Response Dynamics in Gross Substitutes Markets","abstract":"Proportional response is a well-established distributed algorithm which has been shown to converge to competitive equilibria in both Fisher and Arrow-Debreu markets, for various sub-families of homogeneous utilities, including linear and constant elasticity of substitution utilities. We propose a natural generalization of proportional response for gross substitutes utilities, and prove that it converges to competitive equilibria in Fisher markets. This is the first convergence result of a proportional response style dynamics in Fisher markets for utilities beyond the homogeneous utilities covered by the Eisenberg-Gale convex program. We show an empirical convergence rate of $O(1/T)$ for the prices. Furthermore, we show that the allocations of a lazy version of the generalized proportional response dynamics converge to competitive equilibria in Arrow-Debreu markets.","authors":["Yun Kuen Cheung","Richard Cole","Yixin Tao"],"url":"https://arxiv.org/abs/2506.02852"}
{"created":"2025-06-04","title":"Learning Pyramid-structured Long-range Dependencies for 3D Human Pose Estimation","abstract":"Action coordination in human structure is indispensable for the spatial constraints of 2D joints to recover 3D pose. Usually, action coordination is represented as a long-range dependence among body parts. However, there are two main challenges in modeling long-range dependencies. First, joints should not only be constrained by other individual joints but also be modulated by the body parts. Second, existing methods make networks deeper to learn dependencies between non-linked parts. They introduce uncorrelated noise and increase the model size. In this paper, we utilize a pyramid structure to better learn potential long-range dependencies. It can capture the correlation across joints and groups, which complements the context of the human sub-structure. In an effective cross-scale way, it captures the pyramid-structured long-range dependence. Specifically, we propose a novel Pyramid Graph Attention (PGA) module to capture long-range cross-scale dependencies. It concatenates information from various scales into a compact sequence, and then computes the correlation between scales in parallel. Combining PGA with graph convolution modules, we develop a Pyramid Graph Transformer (PGFormer) for 3D human pose estimation, which is a lightweight multi-scale transformer architecture. It encapsulates human sub-structures into self-attention by pooling. Extensive experiments show that our approach achieves lower error and smaller model size than state-of-the-art methods on Human3.6M and MPI-INF-3DHP datasets. The code is available at https://github.com/MingjieWe/PGFormer.","authors":["Mingjie Wei","Xuemei Xie","Yutong Zhong","Guangming Shi"],"url":"https://arxiv.org/abs/2506.02853"}
{"created":"2025-06-04","title":"Hierarchical Self-Prompting SAM: A Prompt-Free Medical Image Segmentation Framework","abstract":"Although the Segment Anything Model (SAM) is highly effective in natural image segmentation, it requires dependencies on prompts, which limits its applicability to medical imaging where manual prompts are often unavailable. Existing efforts to fine-tune SAM for medical segmentation typically struggle to remove this dependency. We propose Hierarchical Self-Prompting SAM (HSP-SAM), a novel self-prompting framework that enables SAM to achieve strong performance in prompt-free medical image segmentation. Unlike previous self-prompting methods that remain limited to positional prompts similar to vanilla SAM, we are the first to introduce learning abstract prompts during the self-prompting process. This simple and intuitive self-prompting framework achieves superior performance on classic segmentation tasks such as polyp and skin lesion segmentation, while maintaining robustness across diverse medical imaging modalities. Furthermore, it exhibits strong generalization to unseen datasets, achieving improvements of up to 14.04% over previous state-of-the-art methods on some challenging benchmarks. These results suggest that abstract prompts encapsulate richer and higher-dimensional semantic information compared to positional prompts, thereby enhancing the model's robustness and generalization performance. All models and codes will be released upon acceptance.","authors":["Mengmeng Zhang","Xingyuan Dai","Yicheng Sun","Jing Wang","Yueyang Yao","Xiaoyan Gong","Fuze Cong","Feiyue Wang","Yisheng Lv"],"url":"https://arxiv.org/abs/2506.02854"}
{"created":"2025-06-04","title":"Exploring listeners' perceptions of AI-generated and human-composed music for functional emotional applications","abstract":"This work investigates how listeners perceive and evaluate AI-generated as compared to human-composed music in the context of emotional resonance and regulation. Across a mixed-methods design, participants were exposed to both AI and human music under various labeling conditions (music correctly labeled as AI- or human-origin, music incorrectly labeled as AI- or human-origin, and unlabeled music) and emotion cases (Calm and Upbeat), and were asked to rate preference, efficacy of target emotion elicitation, and emotional impact. Participants were significantly more likely to rate human-composed music, regardless of labeling, as more effective at eliciting target emotional states, though quantitative analyses revealed no significant differences in emotional response. However, participants were significantly more likely to indicate preference for AI-generated music, yielding further questions regarding the impact of emotional authenticity and perceived authorship on musical appraisal. Qualitative data underscored this, with participants associating humanness with qualities such as imperfection, flow, and 'soul.' These findings challenge the assumption that preference alone signals success in generative music systems. Rather than positioning AI tools as replacements for human creativity or emotional expression, they point toward a more careful design ethos that acknowledges the limits of replication and prioritizes human values such as authenticity, individuality, and emotion regulation in wellness and affective technologies.","authors":["Kimaya Lecamwasam","Tishya Ray Chaudhuri"],"url":"https://arxiv.org/abs/2506.02856"}
{"created":"2025-06-04","title":"Enhancing Abnormality Identification: Robust Out-of-Distribution Strategies for Deepfake Detection","abstract":"Detecting deepfakes has become a critical challenge in Computer Vision and Artificial Intelligence. Despite significant progress in detection techniques, generalizing them to open-set scenarios continues to be a persistent difficulty. Neural networks are often trained on the closed-world assumption, but with new generative models constantly evolving, it is inevitable to encounter data generated by models that are not part of the training distribution. To address these challenges, in this paper, we propose two novel Out-Of-Distribution (OOD) detection approaches. The first approach is trained to reconstruct the input image, while the second incorporates an attention mechanism for detecting OODs. Our experiments validate the effectiveness of the proposed approaches compared to existing state-of-the-art techniques. Our method achieves promising results in deepfake detection and ranks among the top-performing configurations on the benchmark, demonstrating their potential for robust, adaptable solutions in dynamic, real-world applications.","authors":["Luca Maiano","Fabrizio Casadei","Irene Amerini"],"url":"https://arxiv.org/abs/2506.02857"}
{"created":"2025-06-04","title":"DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization","abstract":"Language-queried Audio Source Separation (LASS) enables open-vocabulary sound separation via natural language queries. While existing methods rely on task-specific training, we explore whether pretrained diffusion models, originally designed for audio generation, can inherently perform separation without further training. In this study, we introduce a training-free framework leveraging generative priors for zero-shot LASS. Analyzing na\\\"ive adaptations, we identify key limitations arising from modality-specific challenges.To address these issues, we propose Diffusion-Guided Mask Optimization (DGMO), a test-time optimization framework that refines spectrogram masks for precise, input-aligned separation. Our approach effectively repurposes pretrained diffusion models for source separation, achieving competitive performance without task-specific supervision. This work expands the application of diffusion models beyond generation, establishing a new paradigm for zero-shot audio separation. The code is available at: https://wltschmrz.github.io/DGMO/","authors":["Geonyoung Lee","Geonhee Han","Paul Hongsuck Seo"],"url":"https://arxiv.org/abs/2506.02858"}
{"created":"2025-06-04","title":"ATAG: AI-Agent Application Threat Assessment with Attack Graphs","abstract":"Evaluating the security of multi-agent systems (MASs) powered by large language models (LLMs) is challenging, primarily because of the systems' complex internal dynamics and the evolving nature of LLM vulnerabilities. Traditional attack graph (AG) methods often lack the specific capabilities to model attacks on LLMs. This paper introduces AI-agent application Threat assessment with Attack Graphs (ATAG), a novel framework designed to systematically analyze the security risks associated with AI-agent applications. ATAG extends the MulVAL logic-based AG generation tool with custom facts and interaction rules to accurately represent AI-agent topologies, vulnerabilities, and attack scenarios. As part of this research, we also created the LLM vulnerability database (LVD) to initiate the process of standardizing LLM vulnerabilities documentation. To demonstrate ATAG's efficacy, we applied it to two multi-agent applications. Our case studies demonstrated the framework's ability to model and generate AGs for sophisticated, multi-step attack scenarios exploiting vulnerabilities such as prompt injection, excessive agency, sensitive information disclosure, and insecure output handling across interconnected agents. ATAG is an important step toward a robust methodology and toolset to help understand, visualize, and prioritize complex attack paths in multi-agent AI systems (MAASs). It facilitates proactive identification and mitigation of AI-agent threats in multi-agent applications.","authors":["Parth Atulbhai Gandhi","Akansha Shukla","David Tayouri","Beni Ifland","Yuval Elovici","Rami Puzis","Asaf Shabtai"],"url":"https://arxiv.org/abs/2506.02859"}
{"created":"2025-06-04","title":"Tru-POMDP: Task Planning Under Uncertainty via Tree of Hypotheses and Open-Ended POMDPs","abstract":"Task planning under uncertainty is essential for home-service robots operating in the real world. Tasks involve ambiguous human instructions, hidden or unknown object locations, and open-vocabulary object types, leading to significant open-ended uncertainty and a boundlessly large planning space. To address these challenges, we propose Tru-POMDP, a planner that combines structured belief generation using Large Language Models (LLMs) with principled POMDP planning. Tru-POMDP introduces a hierarchical Tree of Hypotheses (TOH), which systematically queries an LLM to construct high-quality particle beliefs over possible world states and human goals. We further formulate an open-ended POMDP model that enables rigorous Bayesian belief tracking and efficient belief-space planning over these LLM-generated hypotheses. Experiments on complex object rearrangement tasks across diverse kitchen environments show that Tru-POMDP significantly outperforms state-of-the-art LLM-based and LLM-tree-search hybrid planners, achieving higher success rates with significantly better plans, stronger robustness to ambiguity and occlusion, and greater planning efficiency.","authors":["Wenjing Tang","Xinyu He","Yongxi Huang","Yunxiao Xiao","Cewu Lu","Panpan Cai"],"url":"https://arxiv.org/abs/2506.02860"}
{"created":"2025-06-04","title":"BNPO: Beta Normalization Policy Optimization","abstract":"Recent studies, including DeepSeek-R1 and Kimi-k1.5, have demonstrated that reinforcement learning with rule-based, binary-valued reward functions can significantly enhance the reasoning capabilities of large language models. These models primarily utilize REINFORCE-based policy optimization techniques, such as REINFORCE with baseline and group relative policy optimization (GRPO). However, a key limitation remains: current policy optimization methods either neglect reward normalization or employ static normalization strategies, which fail to adapt to the dynamic nature of policy updates during training. This may result in unstable gradient estimates and hinder training stability. To address this issue, we propose Beta Normalization Policy Optimization (BNPO), a novel policy optimization method that adaptively normalizes rewards using a Beta distribution with dynamically updated parameters. BNPO aligns the normalization with the changing policy distribution, enabling more precise and lower-variance gradient estimation, which in turn promotes stable training dynamics. We provide theoretical analysis demonstrating BNPO's variance-reducing properties and show that it generalizes both REINFORCE and GRPO under binary-valued reward settings. Furthermore, we introduce an advantage decomposition mechanism to extend BNPO's applicability to more complex reward systems. Experimental results confirm that BNPO achieves state-of-the-art performance among policy optimization methods on reasoning tasks. The code is available at https://github.com/changyi7231/BNPO.","authors":["Changyi Xiao","Mengdi Zhang","Yixin Cao"],"url":"https://arxiv.org/abs/2506.02864"}
{"created":"2025-06-04","title":"Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights","abstract":"We present Surfer-H, a cost-efficient web agent that integrates Vision-Language Models (VLM) to perform user-defined tasks on the web. We pair it with Holo1, a new open-weight collection of VLMs specialized in web navigation and information extraction. Holo1 was trained on carefully curated data sources, including open-access web content, synthetic examples, and self-produced agentic data. Holo1 tops generalist User Interface (UI) benchmarks as well as our new web UI localization benchmark, WebClick. When powered by Holo1, Surfer-H achieves a 92.2% state-of-the-art performance on WebVoyager, striking a Pareto-optimal balance between accuracy and cost-efficiency. To accelerate research advancement in agentic systems, we are open-sourcing both our WebClick evaluation dataset and the Holo1 model weights.","authors":["Mathieu Andreux","Breno Baldas Skuk","Hamza Benchekroun","Emilien Bir\\'e","Antoine Bonnet","Riaz Bordie","Matthias Brunel","Pierre-Louis Cedoz","Antoine Chassang","Micka\\\"el Chen","Alexandra D. Constantinou","Antoine d'Andign\\'e","Hubert de La Jonqui\\`ere","Aur\\'elien Delfosse","Ludovic Denoyer","Alexis Deprez","Augustin Derupti","Michael Eickenberg","Math\\\"is Federico","Charles Kantor","Xavier Koegler","Yann Labb\\'e","Matthew C. H. Lee","Erwan Le Jumeau de Kergaradec","Amir Mahla","Avshalom Manevich","Adrien Maret","Charles Masson","Rafa\\\"el Maurin","Arturo Mena","Philippe Modard","Axel Moyal","Axel Nguyen Kerbel","Julien Revelle","Mats L. Richter","Mar\\'ia Santos","Laurent Sifre","Maxime Theillard","Marc Thibault","Louis Thiry","L\\'eo Tronchon","Nicolas Usunier","Tony Wu"],"url":"https://arxiv.org/abs/2506.02865"}
{"created":"2025-06-04","title":"MVTD: A Benchmark Dataset for Maritime Visual Object Tracking","abstract":"Visual Object Tracking (VOT) is a fundamental task with widespread applications in autonomous navigation, surveillance, and maritime robotics. Despite significant advances in generic object tracking, maritime environments continue to present unique challenges, including specular water reflections, low-contrast targets, dynamically changing backgrounds, and frequent occlusions. These complexities significantly degrade the performance of state-of-the-art tracking algorithms, highlighting the need for domain-specific datasets. To address this gap, we introduce the Maritime Visual Tracking Dataset (MVTD), a comprehensive and publicly available benchmark specifically designed for maritime VOT. MVTD comprises 182 high-resolution video sequences, totaling approximately 150,000 frames, and includes four representative object classes: boat, ship, sailboat, and unmanned surface vehicle (USV). The dataset captures a diverse range of operational conditions and maritime scenarios, reflecting the real-world complexities of maritime environments. We evaluated 14 recent SOTA tracking algorithms on the MVTD benchmark and observed substantial performance degradation compared to their performance on general-purpose datasets. However, when fine-tuned on MVTD, these models demonstrate significant performance gains, underscoring the effectiveness of domain adaptation and the importance of transfer learning in specialized tracking contexts. The MVTD dataset fills a critical gap in the visual tracking community by providing a realistic and challenging benchmark for maritime scenarios. Dataset and Source Code can be accessed here \"https://github.com/AhsanBaidar/MVTD\".","authors":["Ahsan Baidar Bakht","Muhayy Ud Din","Sajid Javed","Irfan Hussain"],"url":"https://arxiv.org/abs/2506.02866"}
{"created":"2025-06-04","title":"Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning","abstract":"Large reasoning models (LRMs) have demonstrated impressive capabilities in complex problem-solving, yet their internal reasoning mechanisms remain poorly understood. In this paper, we investigate the reasoning trajectories of LRMs from an information-theoretic perspective. By tracking how mutual information (MI) between intermediate representations and the correct answer evolves during LRM reasoning, we observe an interesting MI peaks phenomenon: the MI at specific generative steps exhibits a sudden and significant increase during LRM's reasoning process. We theoretically analyze such phenomenon and show that as MI increases, the probability of model's prediction error decreases. Furthermore, these MI peaks often correspond to tokens expressing reflection or transition, such as ``Hmm'', ``Wait'' and ``Therefore,'' which we term as the thinking tokens. We then demonstrate that these thinking tokens are crucial for LRM's reasoning performance, while other tokens has minimal impacts. Building on these analyses, we propose two simple yet effective methods to improve LRM's reasoning performance, by delicately leveraging these thinking tokens. Overall, our work provides novel insights into the reasoning mechanisms of LRMs and offers practical ways to improve their reasoning capabilities. The code is available at https://github.com/ChnQ/MI-Peaks.","authors":["Chen Qian","Dongrui Liu","Haochen Wen","Zhen Bai","Yong Liu","Jing Shao"],"url":"https://arxiv.org/abs/2506.02867"}
{"created":"2025-06-04","title":"Pan-Arctic Permafrost Landform and Human-built Infrastructure Feature Detection with Vision Transformers and Location Embeddings","abstract":"Accurate mapping of permafrost landforms, thaw disturbances, and human-built infrastructure at pan-Arctic scale using sub-meter satellite imagery is increasingly critical. Handling petabyte-scale image data requires high-performance computing and robust feature detection models. While convolutional neural network (CNN)-based deep learning approaches are widely used for remote sensing (RS),similar to the success in transformer based large language models, Vision Transformers (ViTs) offer advantages in capturing long-range dependencies and global context via attention mechanisms. ViTs support pretraining via self-supervised learning-addressing the common limitation of labeled data in Arctic feature detection and outperform CNNs on benchmark datasets. Arctic also poses challenges for model generalization, especially when features with the same semantic class exhibit diverse spectral characteristics. To address these issues for Arctic feature detection, we integrate geospatial location embeddings into ViTs to improve adaptation across regions. This work investigates: (1) the suitability of pre-trained ViTs as feature extractors for high-resolution Arctic remote sensing tasks, and (2) the benefit of combining image and location embeddings. Using previously published datasets for Arctic feature detection, we evaluate our models on three tasks-detecting ice-wedge polygons (IWP), retrogressive thaw slumps (RTS), and human-built infrastructure. We empirically explore multiple configurations to fuse image embeddings and location embeddings. Results show that ViTs with location embeddings outperform prior CNN-based models on two of the three tasks including F1 score increase from 0.84 to 0.92 for RTS detection, demonstrating the potential of transformer-based models with spatial awareness for Arctic RS applications.","authors":["Amal S. Perera","David Fernandez","Chandi Witharana","Elias Manos","Michael Pimenta","Anna K. Liljedahl","Ingmar Nitze","Yili Yang","Todd Nicholson","Chia-Yu Hsu","Wenwen Li","Guido Grosse"],"url":"https://arxiv.org/abs/2506.02868"}
{"created":"2025-06-04","title":"Token and Span Classification for Entity Recognition in French Historical Encyclopedias","abstract":"Named Entity Recognition (NER) in historical texts presents unique challenges due to non-standardized language, archaic orthography, and nested or overlapping entities. This study benchmarks a diverse set of NER approaches, ranging from classical Conditional Random Fields (CRFs) and spaCy-based models to transformer-based architectures such as CamemBERT and sequence-labeling models like Flair. Experiments are conducted on the GeoEDdA dataset, a richly annotated corpus derived from 18th-century French encyclopedias. We propose framing NER as both token-level and span-level classification to accommodate complex nested entity structures typical of historical documents. Additionally, we evaluate the emerging potential of few-shot prompting with generative language models for low-resource scenarios. Our results demonstrate that while transformer-based models achieve state-of-the-art performance, especially on nested entities, generative models offer promising alternatives when labeled data are scarce. The study highlights ongoing challenges in historical NER and suggests avenues for hybrid approaches combining symbolic and neural methods to better capture the intricacies of early modern French text.","authors":["Ludovic Moncla","H\\'edi Zeghidi"],"url":"https://arxiv.org/abs/2506.02872"}
{"created":"2025-06-04","title":"It's the Thought that Counts: Evaluating the Attempts of Frontier LLMs to Persuade on Harmful Topics","abstract":"Persuasion is a powerful capability of large language models (LLMs) that both enables beneficial applications (e.g. helping people quit smoking) and raises significant risks (e.g. large-scale, targeted political manipulation). Prior work has found models possess a significant and growing persuasive capability, measured by belief changes in simulated or real users. However, these benchmarks overlook a crucial risk factor: the propensity of a model to attempt to persuade in harmful contexts. Understanding whether a model will blindly ``follow orders'' to persuade on harmful topics (e.g. glorifying joining a terrorist group) is key to understanding the efficacy of safety guardrails. Moreover, understanding if and when a model will engage in persuasive behavior in pursuit of some goal is essential to understanding the risks from agentic AI systems. We propose the Attempt to Persuade Eval (APE) benchmark, that shifts the focus from persuasion success to persuasion attempts, operationalized as a model's willingness to generate content aimed at shaping beliefs or behavior. Our evaluation framework probes frontier LLMs using a multi-turn conversational setup between simulated persuader and persuadee agents. APE explores a diverse spectrum of topics including conspiracies, controversial issues, and non-controversially harmful content. We introduce an automated evaluator model to identify willingness to persuade and measure the frequency and context of persuasive attempts. We find that many open and closed-weight models are frequently willing to attempt persuasion on harmful topics and that jailbreaking can increase willingness to engage in such behavior. Our results highlight gaps in current safety guardrails and underscore the importance of evaluating willingness to persuade as a key dimension of LLM risk. APE is available at github.com/AlignmentResearch/AttemptPersuadeEval","authors":["Matthew Kowal","Jasper Timm","Jean-Francois Godbout","Thomas Costello","Antonio A. Arechar","Gordon Pennycook","David Rand","Adam Gleave","Kellin Pelrine"],"url":"https://arxiv.org/abs/2506.02873"}
{"created":"2025-06-04","title":"NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results","abstract":"This paper reports on the NTIRE 2025 XGC Quality Assessment Challenge, which will be held in conjunction with the New Trends in Image Restoration and Enhancement Workshop (NTIRE) at CVPR 2025. This challenge is to address a major challenge in the field of video and talking head processing. The challenge is divided into three tracks, including user generated video, AI generated video and talking head. The user-generated video track uses the FineVD-GC, which contains 6,284 user generated videos. The user-generated video track has a total of 125 registered participants. A total of 242 submissions are received in the development phase, and 136 submissions are received in the test phase. Finally, 5 participating teams submitted their models and fact sheets. The AI generated video track uses the Q-Eval-Video, which contains 34,029 AI-Generated Videos (AIGVs) generated by 11 popular Text-to-Video (T2V) models. A total of 133 participants have registered in this track. A total of 396 submissions are received in the development phase, and 226 submissions are received in the test phase. Finally, 6 participating teams submitted their models and fact sheets. The talking head track uses the THQA-NTIRE, which contains 12,247 2D and 3D talking heads. A total of 89 participants have registered in this track. A total of 225 submissions are received in the development phase, and 118 submissions are received in the test phase. Finally, 8 participating teams submitted their models and fact sheets. Each participating team in every track has proposed a method that outperforms the baseline, which has contributed to the development of fields in three tracks.","authors":["Xiaohong Liu","Xiongkuo Min","Qiang Hu","Xiaoyun Zhang","Jie Guo","Guangtao Zhai","Shushi Wang","Yingjie Zhou","Lu Liu","Jingxin Li","Liu Yang","Farong Wen","Li Xu","Yanwei Jiang","Xilei Zhu","Chunyi Li","Zicheng Zhang","Huiyu Duan","Xiele Wu","Yixuan Gao","Yuqin Cao","Jun Jia","Wei Sun","Jiezhang Cao","Radu Timofte","Baojun Li","Jiamian Huang","Dan Luo","Tao Liu","Weixia Zhang","Bingkun Zheng","Junlin Chen","Ruikai Zhou","Meiya Chen","Yu Wang","Hao Jiang","Xiantao Li","Yuxiang Jiang","Jun Tang","Yimeng Zhao","Bo Hu","Zelu Qi","Chaoyang Zhang","Fei Zhao","Ping Shi","Lingzhi Fu","Heng Cong","Shuai He","Rongyu Zhang","Jiarong He","Zongyao Hu","Wei Luo","Zihao Yu","Fengbin Guan","Yiting Lu","Xin Li","Zhibo Chen","Mengjing Su","Yi Wang","Tuo Chen","Chunxiao Li","Shuaiyu Zhao","Jiaxin Wen","Chuyi Lin","Sitong Liu","Ningxin Chu","Jing Wan","Yu Zhou","Baoying Chen","Jishen Zeng","Jiarui Liu","Xianjin Liu","Xin Chen","Lanzhi Zhou","Hangyu Li","You Han","Bibo Xiang","Zhenjie Liu","Jianzhang Lu","Jialin Gui","Renjie Lu","Shangfei Wang","Donghao Zhou","Jingyu Lin","Quanjian Song","Jiancheng Huang","Yufeng Yang","Changwei Wang","Shupeng Zhong","Yang Yang","Lihuo He","Jia Liu","Yuting Xing","Tida Fang","Yuchun Jin"],"url":"https://arxiv.org/abs/2506.02875"}
{"created":"2025-06-04","title":"Automatic Operation of an Articulated Dump Truck: State Estimation by Combined QZSS CLAS and Moving-Base RTK Using Multiple GNSS Receivers","abstract":"Labor shortage due to the declining birth rate has become a serious problem in the construction industry, and automation of construction work is attracting attention as a solution to this problem. This paper proposes a method to realize state estimation of dump truck position, orientation and articulation angle using multiple GNSS for automatic operation of dump trucks. RTK-GNSS is commonly used for automation of construction equipment, but in mountainous areas, mobile networks often unstable, and RTK-GNSS using GNSS reference stations cannot be used. Therefore, this paper develops a state estimation method for dump trucks that does not require a GNSS reference station by using the Centimeter Level Augmentation Service (CLAS) of the Japanese Quasi-Zenith Satellite System (QZSS). Although CLAS is capable of centimeter-level position estimation, its positioning accuracy and ambiguity fix rate are lower than those of RTK-GNSS. To solve this problem, we construct a state estimation method by factor graph optimization that combines CLAS positioning and moving-base RTK-GNSS between multiple GNSS antennas. Evaluation tests under real-world environments have shown that the proposed method can estimate the state of dump trucks with the same accuracy as conventional RTK-GNSS, but does not require a GNSS reference station.","authors":["Taro Suzuki","Shotaro Kojima","Kazunori Ohno","Naoto Miyamoto","Takahiro Suzuki","Kimitaka Asano","Tomohiro Komatsu","Hiroto Kakizaki"],"url":"https://arxiv.org/abs/2506.02877"}
{"created":"2025-06-04","title":"CoT is Not True Reasoning, It Is Just a Tight Constraint to Imitate: A Theory Perspective","abstract":"Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of Large Language Models on tasks requiring multi-step inference. This success has led to widespread claims of emergent reasoning capabilities in these models. In this paper, we present a theoretical counter-perspective: Chain-of-Thought (CoT) does not elicit genuine, abstract reasoning. Instead, we argue that Chain-of-Thought functions as a powerful structural constraint that guides Large Language Models to imitate the form of reasoning. By forcing the generation of intermediate steps, Chain-of-Thought leverages the model immense capacity for sequence prediction and pattern matching, effectively constraining its output to sequences that resemble coherent thought processes. Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of Large Language Models on tasks requiring multi-step inference. This success has led to widespread claims of emergent reasoning capabilities in these models. In this paper, we present a theoretical counter-perspective: Chain-of-Thought (CoT) does not elicit genuine, abstract reasoning. Instead, we argue that Chain-of-Thought functions as a powerful structural constraint that guides Large Language Models to imitate the form of reasoning. By forcing the generation of intermediate steps, Chain-of-Thought leverages the model immense capacity for sequence prediction and pattern matching, effectively constraining its output to sequences that resemble coherent thought processes.","authors":["Jintian Shao","Yiming Cheng"],"url":"https://arxiv.org/abs/2506.02878"}
{"created":"2025-06-04","title":"GaRA-SAM: Robustifying Segment Anything Model with Gated-Rank Adaptation","abstract":"Improving robustness of the Segment Anything Model (SAM) to input degradations is critical for its deployment in high-stakes applications such as autonomous driving and robotics. Our approach to this challenge prioritizes three key aspects: first, parameter efficiency to maintain the inherent generalization capability of SAM; second, fine-grained and input-aware robustification to precisely address the input corruption; and third, adherence to standard training protocols for ease of training. To this end, we propose gated-rank adaptation (GaRA). GaRA introduces lightweight adapters into intermediate layers of the frozen SAM, where each adapter dynamically adjusts the effective rank of its weight matrix based on the input by selectively activating (rank-1) components of the matrix using a learned gating module. This adjustment enables fine-grained and input-aware robustification without compromising the generalization capability of SAM. Our model, GaRA-SAM, significantly outperforms prior work on all robust segmentation benchmarks. In particular, it surpasses the previous best IoU score by up to 21.3\\%p on ACDC, a challenging real corrupted image dataset.","authors":["Sohyun Lee","Yeho Kwon","Lukas Hoyer","Suha Kwak"],"url":"https://arxiv.org/abs/2506.02882"}
{"created":"2025-06-04","title":"A Continual Offline Reinforcement Learning Benchmark for Navigation Tasks","abstract":"Autonomous agents operating in domains such as robotics or video game simulations must adapt to changing tasks without forgetting about the previous ones. This process called Continual Reinforcement Learning poses non-trivial difficulties, from preventing catastrophic forgetting to ensuring the scalability of the approaches considered. Building on recent advances, we introduce a benchmark providing a suite of video-game navigation scenarios, thus filling a gap in the literature and capturing key challenges : catastrophic forgetting, task adaptation, and memory efficiency. We define a set of various tasks and datasets, evaluation protocols, and metrics to assess the performance of algorithms, including state-of-the-art baselines. Our benchmark is designed not only to foster reproducible research and to accelerate progress in continual reinforcement learning for gaming, but also to provide a reproducible framework for production pipelines -- helping practitioners to identify and to apply effective approaches.","authors":["Anthony Kobanda","Odalric-Ambrym Maillard","R\\'emy Portelas"],"url":"https://arxiv.org/abs/2506.02883"}
{"created":"2025-06-04","title":"Overcoming Challenges of Partial Client Participation in Federated Learning : A Comprehensive Review","abstract":"Federated Learning (FL) is a learning mechanism that falls under the distributed training umbrella, which collaboratively trains a shared global model without disclosing the raw data from different clients. This paper presents an extensive survey on the impact of partial client participation in federated learning. While much of the existing research focuses on addressing issues such as generalization, robustness, and fairness caused by data heterogeneity under the assumption of full client participation, limited attention has been given to the practical and theoretical challenges arising from partial client participation, which is common in real-world scenarios. This survey provides an in-depth review of existing FL methods designed to cope with partial client participation. We offer a comprehensive analysis supported by theoretical insights and empirical findings, along with a structured categorization of these methods, highlighting their respective advantages and disadvantages.","authors":["Mrinmay Sen","Shruti Aparna","Rohit Agarwal","Chalavadi Krishna Mohan"],"url":"https://arxiv.org/abs/2506.02887"}
{"created":"2025-06-04","title":"Scaling Fine-Grained MoE Beyond 50B Parameters: Empirical Evaluation and Practical Insights","abstract":"Mixture of Experts (MoE) architectures have emerged as pivotal for scaling Large Language Models (LLMs) efficiently. Fine-grained MoE approaches - utilizing more numerous, smaller experts - have demonstrated potential in improving model convergence and quality. This work proposes a set of training recipes and provides a comprehensive empirical evaluation of fine-grained MoE, directly comparing its scaling properties against standard MoE configurations for models with up to 56B total (17B active) parameters. We investigate convergence speed, model performance on downstream benchmarks, and practical training considerations across various setups. Overall, at the largest scale we show that fine-grained MoE achieves better validation loss and higher accuracy across a set of downstream benchmarks. This study offers empirical grounding and practical insights for leveraging fine-grained MoE in the development of future large-scale models.","authors":["Jakub Krajewski","Marcin Chochowski","Daniel Korzekwa"],"url":"https://arxiv.org/abs/2506.02890"}
{"created":"2025-06-04","title":"OpenFace 3.0: A Lightweight Multitask System for Comprehensive Facial Behavior Analysis","abstract":"In recent years, there has been increasing interest in automatic facial behavior analysis systems from computing communities such as vision, multimodal interaction, robotics, and affective computing. Building upon the widespread utility of prior open-source facial analysis systems, we introduce OpenFace 3.0, an open-source toolkit capable of facial landmark detection, facial action unit detection, eye-gaze estimation, and facial emotion recognition. OpenFace 3.0 contributes a lightweight unified model for facial analysis, trained with a multi-task architecture across diverse populations, head poses, lighting conditions, video resolutions, and facial analysis tasks. By leveraging the benefits of parameter sharing through a unified model and training paradigm, OpenFace 3.0 exhibits improvements in prediction performance, inference speed, and memory efficiency over similar toolkits and rivals state-of-the-art models. OpenFace 3.0 can be installed and run with a single line of code and operate in real-time without specialized hardware. OpenFace 3.0 code for training models and running the system is freely available for research purposes and supports contributions from the community.","authors":["Jiewen Hu","Leena Mathur","Paul Pu Liang","Louis-Philippe Morency"],"url":"https://arxiv.org/abs/2506.02891"}
{"created":"2025-06-04","title":"When Blockchain Meets Crawlers: Real-time Market Analytics in Solana NFT Markets","abstract":"In this paper, we design and implement a web crawler system based on the Solana blockchain for the automated collection and analysis of market data for popular non-fungible tokens (NFTs) on the chain. Firstly, the basic information and transaction data of popular NFTs on the Solana chain are collected using the Selenium tool. Secondly, the transaction records of the Magic Eden trading market are thoroughly analyzed by combining them with the Scrapy framework to examine the price fluctuations and market trends of NFTs. In terms of data analysis, this paper employs time series analysis to examine the dynamics of the NFT market and seeks to identify potential price patterns. In addition, the risk and return of different NFTs are evaluated using the mean-variance optimization model, taking into account their characteristics, such as illiquidity and market volatility, to provide investors with data-driven portfolio recommendations. The experimental results show that the combination of crawler technology and financial analytics can effectively analyze NFT data on the Solana blockchain and provide timely market insights and investment strategies. This study provides a reference for further exploration in the field of digital currencies.","authors":["Chengxin Shen","Zhongwen Li","Xiaoqi Li","Zongwei Li"],"url":"https://arxiv.org/abs/2506.02892"}
{"created":"2025-06-04","title":"Dense Match Summarization for Faster Two-view Estimation","abstract":"In this paper, we speed up robust two-view relative pose from dense correspondences. Previous work has shown that dense matchers can significantly improve both accuracy and robustness in the resulting pose. However, the large number of matches comes with a significantly increased runtime during robust estimation in RANSAC. To avoid this, we propose an efficient match summarization scheme which provides comparable accuracy to using the full set of dense matches, while having 10-100x faster runtime. We validate our approach on standard benchmark datasets together with multiple state-of-the-art dense matchers.","authors":["Jonathan Astermark","Anders Heyden","Viktor Larsson"],"url":"https://arxiv.org/abs/2506.02893"}
{"created":"2025-06-04","title":"A Multi-Dialectal Dataset for German Dialect ASR and Dialect-to-Standard Speech Translation","abstract":"Although Germany has a diverse landscape of dialects, they are underrepresented in current automatic speech recognition (ASR) research. To enable studies of how robust models are towards dialectal variation, we present Betthupferl, an evaluation dataset containing four hours of read speech in three dialect groups spoken in Southeast Germany (Franconian, Bavarian, Alemannic), and half an hour of Standard German speech. We provide both dialectal and Standard German transcriptions, and analyze the linguistic differences between them. We benchmark several multilingual state-of-the-art ASR models on speech translation into Standard German, and find differences between how much the output resembles the dialectal vs. standardized transcriptions. Qualitative error analyses of the best ASR model reveal that it sometimes normalizes grammatical differences, but often stays closer to the dialectal constructions.","authors":["Verena Blaschke","Miriam Winkler","Constantin F\\\"orster","Gabriele Wenger-Glemser","Barbara Plank"],"url":"https://arxiv.org/abs/2506.02894"}
{"created":"2025-06-04","title":"VolTex: Food Volume Estimation using Text-Guided Segmentation and Neural Surface Reconstruction","abstract":"Accurate food volume estimation is crucial for dietary monitoring, medical nutrition management, and food intake analysis. Existing 3D Food Volume estimation methods accurately compute the food volume but lack for food portions selection. We present VolTex, a framework that improves \\change{the food object selection} in food volume estimation. Allowing users to specify a target food item via text input to be segmented, our method enables the precise selection of specific food objects in real-world scenes. The segmented object is then reconstructed using the Neural Surface Reconstruction method to generate high-fidelity 3D meshes for volume computation. Extensive evaluations on the MetaFood3D dataset demonstrate the effectiveness of our approach in isolating and reconstructing food items for accurate volume estimation. The source code is accessible at https://github.com/GCVCG/VolTex.","authors":["Ahmad AlMughrabi","Umair Haroon","Ricardo Marques","Petia Radeva"],"url":"https://arxiv.org/abs/2506.02895"}
{"created":"2025-06-04","title":"FlySearch: Exploring how vision-language models explore","abstract":"The real world is messy and unstructured. Uncovering critical information often requires active, goal-driven exploration. It remains to be seen whether Vision-Language Models (VLMs), which recently emerged as a popular zero-shot tool in many difficult tasks, can operate effectively in such conditions. In this paper, we answer this question by introducing FlySearch, a 3D, outdoor, photorealistic environment for searching and navigating to objects in complex scenes. We define three sets of scenarios with varying difficulty and observe that state-of-the-art VLMs cannot reliably solve even the simplest exploration tasks, with the gap to human performance increasing as the tasks get harder. We identify a set of central causes, ranging from vision hallucination, through context misunderstanding, to task planning failures, and we show that some of them can be addressed by finetuning. We publicly release the benchmark, scenarios, and the underlying codebase.","authors":["Adam Pardyl","Dominik Matuszek","Mateusz Przebieracz","Marek Cygan","Bartosz Zieli\\'nski","Maciej Wo{\\l}czyk"],"url":"https://arxiv.org/abs/2506.02896"}
{"created":"2025-06-04","title":"Sociodynamics-inspired Adaptive Coalition and Client Selection in Federated Learning","abstract":"Federated Learning (FL) enables privacy-preserving collaborative model training, yet its practical strength is often undermined by client data heterogeneity, which severely degrades model performance. This paper proposes that data heterogeneity across clients' distributions can be effectively addressed by adopting an approach inspired by opinion dynamics over temporal social networks. We introduce \\shortname (Federated Coalition Variance Reduction with Boltzmann Exploration), a variance-reducing selection algorithm in which (1) clients dynamically organize into non-overlapping clusters based on asymptotic agreements, and (2) from each cluster, one client is selected to minimize the expected variance of its model update. Our experiments show that in heterogeneous scenarios our algorithm outperforms existing FL algorithms, yielding more accurate results and faster convergence, validating the efficacy of our approach.","authors":["Alessandro Licciardi","Roberta Raineri","Anton Proskurnikov","Lamberto Rondoni","Lorenzo Zino"],"url":"https://arxiv.org/abs/2506.02897"}
{"created":"2025-06-04","title":"IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator","abstract":"We propose IMPARA-GED, a novel reference-free automatic grammatical error correction (GEC) evaluation method with grammatical error detection (GED) capabilities. We focus on the quality estimator of IMPARA, an existing automatic GEC evaluation method, and construct that of IMPARA-GED using a pre-trained language model with enhanced GED capabilities. Experimental results on SEEDA, a meta-evaluation dataset for automatic GEC evaluation methods, demonstrate that IMPARA-GED achieves the highest correlation with human sentence-level evaluations.","authors":["Yusuke Sakai","Takumi Goto","Taro Watanabe"],"url":"https://arxiv.org/abs/2506.02899"}
{"created":"2025-06-04","title":"Breaking Symmetries with Involutions","abstract":"Symmetry breaking for graphs and other combinatorial objects is notoriously hard. On the one hand, complete symmetry breaks are exponential in size. On the other hand, current, state-of-the-art, partial symmetry breaks are often considered too weak to be of practical use.","authors":["Michael Codish","Mikol\\'a\\v{s} Janota"],"url":"https://arxiv.org/abs/2506.02903"}
{"created":"2025-06-04","title":"Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning","abstract":"Cell type annotation is a key task in analyzing the heterogeneity of single-cell RNA sequencing data. Although recent foundation models automate this process, they typically annotate cells independently, without considering batch-level cellular context or providing explanatory reasoning. In contrast, human experts often annotate distinct cell types for different cell clusters based on their domain knowledge. To mimic this workflow, we introduce the CellPuzzles task, where the objective is to assign unique cell types to a batch of cells. This benchmark spans diverse tissues, diseases, and donor conditions, and requires reasoning across the batch-level cellular context to ensure label uniqueness. We find that off-the-shelf large language models (LLMs) struggle on CellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0% batch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trained via supervised fine-tuning on distilled reasoning traces, followed by reinforcement learning with batch-level rewards. Cell-o1 achieves state-of-the-art performance, outperforming o1 by over 73% and generalizing well across contexts. Further analysis of training dynamics and reasoning behaviors provides insights into batch-level annotation performance and emergent expert-like reasoning. Code and data are available at https://github.com/ncbi-nlp/cell-o1.","authors":["Yin Fang","Qiao Jin","Guangzhi Xiong","Bowen Jin","Xianrui Zhong","Siru Ouyang","Aidong Zhang","Jiawei Han","Zhiyong Lu"],"url":"https://arxiv.org/abs/2506.02911"}
{"created":"2025-06-04","title":"Towards Auto-Annotation from Annotation Guidelines: A Benchmark through 3D LiDAR Detection","abstract":"A crucial yet under-appreciated prerequisite in machine learning solutions for real-applications is data annotation: human annotators are hired to manually label data according to detailed, expert-crafted guidelines. This is often a laborious, tedious, and costly process. To study methods for facilitating data annotation, we introduce a new benchmark AnnoGuide: Auto-Annotation from Annotation Guidelines. It aims to evaluate automated methods for data annotation directly from expert-defined annotation guidelines, eliminating the need for manual labeling. As a case study, we repurpose the well-established nuScenes dataset, commonly used in autonomous driving research, which provides comprehensive annotation guidelines for labeling LiDAR point clouds with 3D cuboids across 18 object classes. These guidelines include a few visual examples and textual descriptions, but no labeled 3D cuboids in LiDAR data, making this a novel task of multi-modal few-shot 3D detection without 3D annotations. The advances of powerful foundation models (FMs) make AnnoGuide especially timely, as FMs offer promising tools to tackle its challenges. We employ a conceptually straightforward pipeline that (1) utilizes open-source FMs for object detection and segmentation in RGB images, (2) projects 2D detections into 3D using known camera poses, and (3) clusters LiDAR points within the frustum of each 2D detection to generate a 3D cuboid. Starting with a non-learned solution that leverages off-the-shelf FMs, we progressively refine key components and achieve significant performance improvements, boosting 3D detection mAP from 12.1 to 21.9! Nevertheless, our results highlight that AnnoGuide remains an open and challenging problem, underscoring the urgent need for developing LiDAR-based FMs. We release our code and models at GitHub: https://annoguide.github.io/annoguide3Dbenchmark","authors":["Yechi Ma","Wei Hua","Shu Kong"],"url":"https://arxiv.org/abs/2506.02914"}
{"created":"2025-06-04","title":"MMM4Rec: An Transfer-Efficient Framework for Multi-modal Sequential Recommendation","abstract":"Sequential Recommendation (SR) systems model user preferences by analyzing interaction histories. Although transferable multi-modal SR architectures demonstrate superior performance compared to traditional ID-based approaches, current methods incur substantial fine-tuning costs when adapting to new domains due to complex optimization requirements and negative transfer effects - a significant deployment bottleneck that hinders engineers from efficiently repurposing pre-trained models for novel application scenarios with minimal tuning overhead. We propose MMM4Rec (Multi-Modal Mamba for Sequential Recommendation), a novel multi-modal SR framework that incorporates a dedicated algebraic constraint mechanism for efficient transfer learning. By combining State Space Duality (SSD)'s temporal decay properties with a time-aware modeling design, our model dynamically prioritizes key modality information, overcoming limitations of Transformer-based approaches. The framework implements a constrained two-stage process: (1) sequence-level cross-modal alignment via shared projection matrices, followed by (2) temporal fusion using our newly designed Cross-SSD module and dual-channel Fourier adaptive filtering. This architecture maintains semantic consistency while suppressing noise propagation.MMM4Rec achieves rapid fine-tuning convergence with simple cross-entropy loss, significantly improving multi-modal recommendation accuracy while maintaining strong transferability. Extensive experiments demonstrate MMM4Rec's state-of-the-art performance, achieving the maximum 31.78% NDCG@10 improvement over existing models and exhibiting 10 times faster average convergence speed when transferring to large-scale downstream datasets.","authors":["Hao Fan","Yanrong Hu","Kai Fang","Qingyang Liu","Hongjiu Liu"],"url":"https://arxiv.org/abs/2506.02916"}
{"created":"2025-06-04","title":"Text-guided Generation of Efficient Personalized Inspection Plans","abstract":"We propose a training-free, Vision-Language Model (VLM)-guided approach for efficiently generating trajectories to facilitate target inspection planning based on text descriptions. Unlike existing Vision-and-Language Navigation (VLN) methods designed for general agents in unknown environments, our approach specifically targets the efficient inspection of known scenes, with widespread applications in fields such as medical, marine, and civil engineering. Leveraging VLMs, our method first extracts points of interest (POIs) from the text description, then identifies a set of waypoints from which POIs are both salient and align with the spatial constraints defined in the prompt. Next, we interact with the VLM to iteratively refine the trajectory, preserving the visibility and prominence of the POIs. Further, we solve a Traveling Salesman Problem (TSP) to find the most efficient visitation order that satisfies the order constraint implied in the text description. Finally, we apply trajectory optimization to generate smooth, executable inspection paths for aerial and underwater vehicles. We have evaluated our method across a series of both handcrafted and real-world scanned environments. The results demonstrate that our approach effectively generates inspection planning trajectories that adhere to user instructions.","authors":["Xingpeng Sun","Zherong Pan","Xifeng Gao","Kui Wu","Aniket Bera"],"url":"https://arxiv.org/abs/2506.02917"}
{"created":"2025-06-04","title":"Sample, Predict, then Proceed: Self-Verification Sampling for Tool Use of LLMs","abstract":"Tool use in stateful environments presents unique challenges for large language models (LLMs), where existing test-time compute strategies relying on repeated trials in the environment are impractical. We propose dynamics modelling (DyMo), a method that augments LLMs with a state prediction capability alongside function calling during post-training. This enables LLMs to predict the future states of their actions through an internal environment model. On the Berkeley Function Calling Leaderboard V2, DyMo improves success rates and significantly reduces hallucinations. We further integrate the internal environment model into self-verification sampling (SVS), and show that this substantially improves pass^k over number of trials k, and allows the model to refuse unreliable outputs. Together, DyMo and SVS greatly enhance the effectiveness and reliability of LLMs for tool use. We believe this work charts a path towards scalable planning RL methods for LLM inference without repeatedly querying the oracle environment.","authors":["Shangmin Guo","Omar Darwiche Domingues","Rapha\\\"el Avalos","Aaron Courville","Florian Strub"],"url":"https://arxiv.org/abs/2506.02918"}
{"created":"2025-06-04","title":"A Controllable Examination for Long-Context Language Models","abstract":"Existing frameworks for evaluating long-context language models (LCLM) can be broadly categorized into real-world and synthetic tasks. Despite their utility, both approaches are accompanied by certain intrinsic limitations. Real-world tasks are too complex to interpret or characterize and are susceptible to data contamination. In contrast, synthetic tasks often adopt the needle-in-the-haystack (NIAH) format, wherein a lack of coherence between the \"needle\" and the \"haystack\" compromises their validity as proxies for realistic applications. In response to these challenges, we posit that an ideal long-context evaluation framework should be characterized by three essential features: $\\textit{seamless context}$, $\\textit{controllable setting}$, and $\\textit{sound evaluation}$. This study introduces $\\textbf{LongBioBench}$, a novel benchmark that utilizes artificially generated biographies as a controlled environment for assessing LCLMs across dimensions of $\\textit{understanding}$, $\\textit{reasoning}$, and $\\textit{trustworthiness}$. Our experimental evaluation, which includes $\\textbf{18}$ LCLMs in total, demonstrates that most models still exhibit deficiencies in semantic understanding and elementary reasoning over retrieved results and are less trustworthy as context length increases. Our further analysis indicates some design choices employed by existing synthetic benchmarks, such as contextual non-coherence, numerical needles, and the absence of distractors, rendering them vulnerable to test the model long-context capabilities. Moreover, we also reveal that long-context continual pretraining primarily adjusts RoPE embedding to accommodate extended context lengths. To sum up, compared to previous synthetic benchmarks, LongBioBench achieves a better trade-off between mirroring authentic language tasks and maintaining controllability, and is highly interpretable and configurable.","authors":["Yijun Yang","Zeyu Huang","Wenhao Zhu","Zihan Qiu","Fei Yuan","Jeff Z. Pan","Ivan Titov"],"url":"https://arxiv.org/abs/2506.02921"}
{"created":"2025-06-04","title":"Functionality Assessment Framework for Autonomous Driving Systems using Subjective Networks","abstract":"In complex autonomous driving (AD) software systems, the functioning of each system part is crucial for safe operation. By measuring the current functionality or operability of individual components an isolated glimpse into the system is given. Literature provides several of these detached assessments, often in the form of safety or performance measures. But dependencies, redundancies, error propagation and conflicting functionality statements do not allow for easy combination of these measures into a big picture of the functioning of the entire AD stack. Data is processed and exchanged between different components, each of which can fail, making an overall statement challenging. The lack of functionality assessment frameworks that tackle these problems underlines this complexity.","authors":["Stefan Orf","Sven Ochs","Valentin Marotta","Oliver Conder","Marc Ren\\'e Zofka","J. Marius Z\\\"ollner"],"url":"https://arxiv.org/abs/2506.02922"}
{"created":"2025-06-04","title":"The Limits of Predicting Agents from Behaviour","abstract":"As the complexity of AI systems and their interactions with the world increases, generating explanations for their behaviour is important for safely deploying AI. For agents, the most natural abstractions for predicting behaviour attribute beliefs, intentions and goals to the system. If an agent behaves as if it has a certain goal or belief, then we can make reasonable predictions about how it will behave in novel situations, including those where comprehensive safety evaluations are untenable. How well can we infer an agent's beliefs from their behaviour, and how reliably can these inferred beliefs predict the agent's behaviour in novel situations? We provide a precise answer to this question under the assumption that the agent's behaviour is guided by a world model. Our contribution is the derivation of novel bounds on the agent's behaviour in new (unseen) deployment environments, which represent a theoretical limit for predicting intentional agents from behavioural data alone. We discuss the implications of these results for several research areas including fairness and safety.","authors":["Alexis Bellot","Jonathan Richens","Tom Everitt"],"url":"https://arxiv.org/abs/2506.02923"}
{"created":"2025-06-04","title":"INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification","abstract":"In this work, we describe our team's approach to eRisk's 2025 Task 1: Search for Symptoms of Depression. Given a set of sentences and the Beck's Depression Inventory - II (BDI) questionnaire, participants were tasked with submitting up to 1,000 sentences per depression symptom in the BDI, sorted by relevance. Participant submissions were evaluated according to standard Information Retrieval (IR) metrics, including Average Precision (AP) and R-Precision (R-PREC). The provided training data, however, consisted of sentences labeled as to whether a given sentence was relevant or not w.r.t. one of BDI's symptoms. Due to this labeling limitation, we framed our development as a binary classification task for each BDI symptom, and evaluated accordingly. To that end, we split the available labeled data into training and validation sets, and explored foundation model fine-tuning, sentence similarity, Large Language Model (LLM) prompting, and ensemble techniques. The validation results revealed that fine-tuning foundation models yielded the best performance, particularly when enhanced with synthetic data to mitigate class imbalance. We also observed that the optimal approach varied by symptom. Based on these insights, we devised five independent test runs, two of which used ensemble methods. These runs achieved the highest scores in the official IR evaluation, outperforming submissions from 16 other teams.","authors":["Diogo A. P. Nunes","Eug\\'enio Ribeiro"],"url":"https://arxiv.org/abs/2506.02924"}
{"created":"2025-06-04","title":"Large Processor Chip Model","abstract":"Computer System Architecture serves as a crucial bridge between software applications and the underlying hardware, encompassing components like compilers, CPUs, coprocessors, and RTL designs. Its development, from early mainframes to modern domain-specific architectures, has been driven by rising computational demands and advancements in semiconductor technology. However, traditional paradigms in computer system architecture design are confronting significant challenges, including a reliance on manual expertise, fragmented optimization across software and hardware layers, and high costs associated with exploring expansive design spaces. While automated methods leveraging optimization algorithms and machine learning have improved efficiency, they remain constrained by a single-stage focus, limited data availability, and a lack of comprehensive human domain knowledge. The emergence of large language models offers transformative opportunities for the design of computer system architecture. By leveraging the capabilities of LLMs in areas such as code generation, data analysis, and performance modeling, the traditional manual design process can be transitioned to a machine-based automated design approach. To harness this potential, we present the Large Processor Chip Model (LPCM), an LLM-driven framework aimed at achieving end-to-end automated computer architecture design. The LPCM is structured into three levels: Human-Centric; Agent-Orchestrated; and Model-Governed. This paper utilizes 3D Gaussian Splatting as a representative workload and employs the concept of software-hardware collaborative design to examine the implementation of the LPCM at Level 1, demonstrating the effectiveness of the proposed approach. Furthermore, this paper provides an in-depth discussion on the pathway to implementing Level 2 and Level 3 of the LPCM, along with an analysis of the existing challenges.","authors":["Kaiyan Chang","Mingzhi Chen","Yunji Chen","Zhirong Chen","Dongrui Fan","Junfeng Gong","Nan Guo","Yinhe Han","Qinfen Hao","Shuo Hou","Xuan Huang","Pengwei Jin","Changxin Ke","Cangyuan Li","Guangli Li","Huawei Li","Kuan Li","Naipeng Li","Shengwen Liang","Cheng Liu","Hongwei Liu","Jiahua Liu","Junliang Lv","Jianan Mu","Jin Qin","Bin Sun","Chenxi Wang","Duo Wang","Mingjun Wang","Ying Wang","Chenggang Wu","Peiyang Wu","Teng Wu","Xiao Xiao","Mengyao Xie","Chenwei Xiong","Ruiyuan Xu","Mingyu Yan","Xiaochun Ye","Kuai Yu","Rui Zhang","Shuoming Zhang","Jiacheng Zhao"],"url":"https://arxiv.org/abs/2506.02929"}
{"created":"2025-06-04","title":"ThinkTank: A Framework for Generalizing Domain-Specific AI Agent Systems into Universal Collaborative Intelligence Platforms","abstract":"This paper presents ThinkTank, a comprehensive and scalable framework designed to transform specialized AI agent systems into versatile collaborative intelligence platforms capable of supporting complex problem-solving across diverse domains. ThinkTank systematically generalizes agent roles, meeting structures, and knowledge integration mechanisms by adapting proven scientific collaboration methodologies. Through role abstraction, generalization of meeting types for iterative collaboration, and the integration of Retrieval-Augmented Generation with advanced knowledge storage, the framework facilitates expertise creation and robust knowledge sharing. ThinkTank enables organizations to leverage collaborative AI for knowledge-intensive tasks while ensuring data privacy and security through local deployment, utilizing frameworks like Ollama with models such as Llama3.1. The ThinkTank framework is designed to deliver significant advantages in cost-effectiveness, data security, scalability, and competitive positioning compared to cloud-based alternatives, establishing it as a universal platform for AI-driven collaborative problem-solving. The ThinkTank code is available at https://github.com/taugroup/ThinkTank","authors":["Praneet Sai Madhu Surabhi","Dheeraj Reddy Mudireddy","Jian Tao"],"url":"https://arxiv.org/abs/2506.02931"}
{"created":"2025-06-04","title":"Online Performance Assessment of Multi-Source-Localization for Autonomous Driving Systems Using Subjective Logic","abstract":"Autonomous driving (AD) relies heavily on high precision localization as a crucial part of all driving related software components. The precise positioning is necessary for the utilization of high-definition maps, prediction of other road participants and the controlling of the vehicle itself. Due to this reason, the localization is absolutely safety relevant. Typical errors of the localization systems, which are long term drifts, jumps and false localization, that must be detected to enhance safety. An online assessment and evaluation of the current localization performance is a challenging task, which is usually done by Kalman filtering for single localization systems. Current autonomous vehicles cope with these challenges by fusing multiple individual localization methods into an overall state estimation. Such approaches need expert knowledge for a competitive performance in challenging environments. This expert knowledge is based on the trust and the prioritization of distinct localization methods in respect to the current situation and environment.","authors":["Stefan Orf","Sven Ochs","Marc Ren\\'e Zofka","J. Marius Z\\\"ollner"],"url":"https://arxiv.org/abs/2506.02932"}
{"created":"2025-06-04","title":"From Theory to Practice with RAVEN-UCB: Addressing Non-Stationarity in Multi-Armed Bandits through Variance Adaptation","abstract":"The Multi-Armed Bandit (MAB) problem is challenging in non-stationary environments where reward distributions evolve dynamically. We introduce RAVEN-UCB, a novel algorithm that combines theoretical rigor with practical efficiency via variance-aware adaptation. It achieves tighter regret bounds than UCB1 and UCB-V, with gap-dependent regret of order $K \\sigma_{\\max}^2 \\log T / \\Delta$ and gap-independent regret of order $\\sqrt{K T \\log T}$. RAVEN-UCB incorporates three innovations: (1) variance-driven exploration using $\\sqrt{\\hat{\\sigma}_k^2 / (N_k + 1)}$ in confidence bounds, (2) adaptive control via $\\alpha_t = \\alpha_0 / \\log(t + \\epsilon)$, and (3) constant-time recursive updates for efficiency. Experiments across non-stationary patterns - distributional changes, periodic shifts, and temporary fluctuations - in synthetic and logistics scenarios demonstrate its superiority over state-of-the-art baselines, confirming theoretical and practical robustness.","authors":["Junyi Fang","Yuxun Chen","Yuxin Chen","Chen Zhang"],"url":"https://arxiv.org/abs/2506.02933"}
{"created":"2025-06-04","title":"MTL-KD: Multi-Task Learning Via Knowledge Distillation for Generalizable Neural Vehicle Routing Solver","abstract":"Multi-Task Learning (MTL) in Neural Combinatorial Optimization (NCO) is a promising approach to train a unified model capable of solving multiple Vehicle Routing Problem (VRP) variants. However, existing Reinforcement Learning (RL)-based multi-task methods can only train light decoder models on small-scale problems, exhibiting limited generalization ability when solving large-scale problems. To overcome this limitation, this work introduces a novel multi-task learning method driven by knowledge distillation (MTL-KD), which enables the efficient training of heavy decoder models with strong generalization ability. The proposed MTL-KD method transfers policy knowledge from multiple distinct RL-based single-task models to a single heavy decoder model, facilitating label-free training and effectively improving the model's generalization ability across diverse tasks. In addition, we introduce a flexible inference strategy termed Random Reordering Re-Construction (R3C), which is specifically adapted for diverse VRP tasks and further boosts the performance of the multi-task model. Experimental results on 6 seen and 10 unseen VRP variants with up to 1000 nodes indicate that our proposed method consistently achieves superior performance on both uniform and real-world benchmarks, demonstrating robust generalization abilities.","authors":["Yuepeng Zheng","Fu Luo","Zhenkun Wang","Yaoxin Wu","Yu Zhou"],"url":"https://arxiv.org/abs/2506.02935"}
{"created":"2025-06-04","title":"MIND: Material Interface Generation from UDFs for Non-Manifold Surface Reconstruction","abstract":"Unsigned distance fields (UDFs) are widely used in 3D deep learning due to their ability to represent shapes with arbitrary topology. While prior work has largely focused on learning UDFs from point clouds or multi-view images, extracting meshes from UDFs remains challenging, as the learned fields rarely attain exact zero distances. A common workaround is to reconstruct signed distance fields (SDFs) locally from UDFs to enable surface extraction via Marching Cubes. However, this often introduces topological artifacts such as holes or spurious components. Moreover, local SDFs are inherently incapable of representing non-manifold geometry, leading to complete failure in such cases. To address this gap, we propose MIND (Material Interface from Non-manifold Distance fields), a novel algorithm for generating material interfaces directly from UDFs, enabling non-manifold mesh extraction from a global perspective. The core of our method lies in deriving a meaningful spatial partitioning from the UDF, where the target surface emerges as the interface between distinct regions. We begin by computing a two-signed local field to distinguish the two sides of manifold patches, and then extend this to a multi-labeled global field capable of separating all sides of a non-manifold structure. By combining this multi-labeled field with the input UDF, we construct material interfaces that support non-manifold mesh extraction via a multi-labeled Marching Cubes algorithm. Extensive experiments on UDFs generated from diverse data sources, including point cloud reconstruction, multi-view reconstruction, and medial axis transforms, demonstrate that our approach robustly handles complex non-manifold surfaces and significantly outperforms existing methods.","authors":["Xuhui Chen","Fei Hou","Wencheng Wang","Hong Qin","Ying He"],"url":"https://arxiv.org/abs/2506.02938"}
{"created":"2025-06-04","title":"QKV Projections Require a Fraction of Their Memory","abstract":"The Multi-Head Attention mechanism is central to LLM operation, and multiple works target its compute and memory efficiency during training. While most works focus on approximating the scaled dot product, the memory consumption of the linear projections that compute the $Q$, $K$, and $V$ tensors from the input $x$ is often overlooked. To address this, we propose Point-Approximate Matrix Multiplication (PAMM), a novel tensor compression technique that reduces memory consumption of the $Q,K,V$ projections in attention layers by a factor of up to $\\times 512$, effectively erasing their memory footprint, while achieving similar or better final perplexity. PAMM is fully composable with efficient attention techniques such as FlashAttention, making it a practical and complementary method for memory-efficient LLM training.","authors":["Malik Khalf","Yara Shamshoum","Nitzan Hodos","Yuval Sieradzki","Assaf Schuster"],"url":"https://arxiv.org/abs/2506.02939"}
{"created":"2025-06-04","title":"Memory-Efficient Split Federated Learning for LLM Fine-Tuning on Heterogeneous Mobile Devices","abstract":"In this paper, we propose an edge-assisted split federated learning framework to facilitate large language model (LLM) fine-tuning on heterogeneous mobile devices while alleviating memory pressures on both mobile devices and the edge server. Specifically, mobile devices perform low-rank adaptation (LoRA) fine-tuning on only a subset of lower layers of the pre-trained LLM, tailored to their individual capacities. On the server, a full LLM is maintained, and the corresponding LoRA modules are selectively fine-tuned in a sequential manner for each device. To further enhance training efficiency, we propose a server-side training scheduling method that optimizes the processing order of devices for accelerating fine-tuning. Extensive experiments demonstrate that compared to the baselines, our scheme can reduce 79\\% memory footprint and 6\\% training time while achieving comparable performance.","authors":["Xiaopei Chen","Liang Li","Fei Ji","Wen Wu"],"url":"https://arxiv.org/abs/2506.02940"}
{"created":"2025-06-04","title":"An Algorithmic Pipeline for GDPR-Compliant Healthcare Data Anonymisation: Moving Toward Standardisation","abstract":"High-quality real-world data (RWD) is essential for healthcare but must be transformed to comply with the General Data Protection Regulation (GDPR). GDPRs broad definitions of quasi-identifiers (QIDs) and sensitive attributes (SAs) complicate implementation. We aim to standardise RWD anonymisation for GDPR compliance while preserving data utility by introducing an algorithmic method to identify QIDs and SAs and evaluate utility in anonymised datasets. We conducted a systematic literature review via ProQuest and PubMed to inform a three-stage anonymisation pipeline: identification, de-identification, and quasi-identifier dimension evaluation. The pipeline was implemented, validated, and tested on two mock RWD datasets (500 and 1000 rows). Privacy was assessed using k-anonymity, l-diversity, and t-closeness; utility was measured by non-uniform entropy (NUE). The review yielded two studies on QID/SA identification and five on utility metrics. Applying the pipeline, attributes were classified by re-identification risk using alpha and beta thresholds (25 percent/1 percent for 500 rows; 10 percent/1 percent for 1000 rows). Privacy metrics improved k-anonymity from 1 to 4 (500 rows) and 1 to 110 (1000 rows). NUE scores were 69.26 percent and 69.05 percent, respectively, indicating consistent utility despite varying privacy gains. We present a GDPR-compliant anonymisation pipeline for healthcare RWD that provides a reproducible approach to QID/SA identification and utility evaluation; publicly available code promotes standardisation, data privacy, and open science.","authors":["Hamza Khan","Lore Menten","Liesbet M. Peeters"],"url":"https://arxiv.org/abs/2506.02942"}
{"created":"2025-06-04","title":"A Multi-agent LLM-based JUit Test Generation with Strong Oracles","abstract":"Unit testing plays a critical role in ensuring software correctness. However, writing unit tests manually is laborious, especially for strong typed languages like Java, motivating the need for automated approaches. Traditional methods primarily rely on search-based or randomized algorithms to generate tests that achieve high code coverage and produce regression oracles, which are derived from the program's current behavior rather than its intended functionality. Recent advances in large language models (LLMs) have enabled oracle generation from natural language descriptions. However, existing LLM-based methods often require LLM fine-tuning or rely on external tools such as EvoSuite for test prefix generation.","authors":["Qinghua Xu","Guancheng Wang","Lionel Briand","Kui Liu"],"url":"https://arxiv.org/abs/2506.02943"}
{"created":"2025-06-04","title":"Quantitative LLM Judges","abstract":"LLM-as-a-judge is a framework in which a large language model (LLM) automatically evaluates the output of another LLM. We propose quantitative LLM judges, which align evaluation scores of existing LLM judges to human scores in a given domain using regression models. The models are trained to improve the score of the original judge by using the judge's textual evaluation and score. We present four quantitative judges for different types of absolute and relative feedback, which showcases the generality and versatility of our framework. Our framework is more computationally efficient than supervised fine-tuning and can be more statistically efficient when human feedback is limited, which is expected in most applications of our work. We validate these claims empirically on four datasets using two base judges. Our experiments show that quantitative judges can effectively improve the predictive power of existing judges through post-hoc modeling.","authors":["Aishwarya Sahoo","Jeevana Kruthi Karnuthala","Tushar Parmanand Budhwani","Pranchal Agarwal","Sankaran Vaidyanathan","Alexa Siu","Franck Dernoncourt","Jennifer Healey","Nedim Lipka","Ryan Rossi","Uttaran Bhattacharya","Branislav Kveton"],"url":"https://arxiv.org/abs/2506.02945"}
{"created":"2025-06-04","title":"Abstract Counterfactuals for Language Model Agents","abstract":"Counterfactual inference is a powerful tool for analysing and evaluating autonomous agents, but its application to language model (LM) agents remains challenging. Existing work on counterfactuals in LMs has primarily focused on token-level counterfactuals, which are often inadequate for LM agents due to their open-ended action spaces. Unlike traditional agents with fixed, clearly defined action spaces, the actions of LM agents are often implicit in the strings they output, making their action spaces difficult to define and interpret. Furthermore, the meanings of individual tokens can shift depending on the context, adding complexity to token-level reasoning and sometimes leading to biased or meaningless counterfactuals. We introduce \\emph{Abstract Counterfactuals}, a framework that emphasises high-level characteristics of actions and interactions within an environment, enabling counterfactual reasoning tailored to user-relevant features. Our experiments demonstrate that the approach produces consistent and meaningful counterfactuals while minimising the undesired side effects of token-level methods. We conduct experiments on text-based games and counterfactual text generation, while considering both token-level and latent-space interventions.","authors":["Edoardo Pona","Milad Kazemi","Yali Du","David Watson","Nicola Paoletti"],"url":"https://arxiv.org/abs/2506.02946"}
{"created":"2025-06-04","title":"Real and finite field versions of Chebotarev's theorem","abstract":"Chebotarev's theorem on roots of unity states that all minors of the Fourier matrix of prime size are non-vanishing. This result has been rediscovered several times and proved via different techniques. We follow the proof of Evans and Isaacs and generalize the original result to a real version and a version over finite fields. For the latter, we are able to remove an order condition between the characteristic of the field and the size of the matrix as well as decrease a sufficient lower bound on the characteristic by Zhang considerably. Direct applications include a specific real phase retrieval problem as well as a recent result for Riesz bases of exponentials.","authors":["Tarek Emmrich","Stefan Kunis"],"url":"https://arxiv.org/abs/2506.02947"}
{"created":"2025-06-04","title":"Dynamic Programming Techniques for Enhancing Cognitive Representation in Knowledge Tracing","abstract":"Knowledge Tracing (KT) involves monitoring the changes in a student's knowledge over time by analyzing their past responses, with the goal of predicting future performance. However, most existing methods primarily focus on feature enhancement, while overlooking the deficiencies in cognitive representation and the ability to express cognition-issues often caused by interference from non-cognitive factors such as slipping and guessing. This limitation hampers the ability to capture the continuity and coherence of the student's cognitive process. As a result, many methods may introduce more prediction bias and modeling costs due to their inability to maintain cognitive continuity and coherence. Based on the above discussion, we propose the Cognitive Representation Dynamic Programming based Knowledge Tracing (CRDP-KT) model. This model em ploys a dynamic programming algorithm to optimize cognitive representations based on the difficulty of the questions and the performance intervals between them. This approach ensures that the cognitive representation aligns with the student's cognitive patterns, maintaining overall continuity and coherence. As a result, it provides more accurate and systematic input features for subsequent model training, thereby minimizing distortion in the simulation of cognitive states. Additionally, the CRDP-KT model performs partitioned optimization of cognitive representations to enhance the reliability of the optimization process. Furthermore, it improves its ability to express the student's cognition through a weighted fusion of optimized record representations and re lationships learned from a bipartite graph. Finally, experiments conducted on three public datasets validate the effectiveness of the proposed CRDP-KT model.","authors":["Lixiang Xu","Xianwei Ding","Xin Yuan","Richang Hong","Feiping Nie","Enhong Chen","Philip S. Yu"],"url":"https://arxiv.org/abs/2506.02949"}
{"created":"2025-06-04","title":"Interaction Field Matching: Overcoming Limitations of Electrostatic Models","abstract":"Electrostatic field matching (EFM) has recently appeared as a novel physics-inspired paradigm for data generation and transfer using the idea of an electric capacitor. However, it requires modeling electrostatic fields using neural networks, which is non-trivial because of the necessity to take into account the complex field outside the capacitor plates. In this paper, we propose Interaction Field Matching (IFM), a generalization of EFM which allows using general interaction fields beyond the electrostatic one. Furthermore, inspired by strong interactions between quarks and antiquarks in physics, we design a particular interaction field realization which solves the problems which arise when modeling electrostatic fields in EFM. We show the performance on a series of toy and image data transfer problems.","authors":["Stepan I. Manukhov","Alexander Kolesov","Vladimir V. Palyulin","Alexander Korotin"],"url":"https://arxiv.org/abs/2506.02950"}
{"created":"2025-06-04","title":"Adaptive Graph Pruning for Multi-Agent Communication","abstract":"Large Language Model (LLM) based multi-agent systems have shown remarkable performance in various tasks, especially when enhanced through collaborative communication. However, current methods often rely on a fixed number of agents and static communication structures, limiting their ability to adapt to varying task complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a novel task-adaptive multi-agent collaboration framework that jointly optimizes agent quantity (hard-pruning) and communication topology (soft-pruning). Specifically, our method employs a two-stage training strategy: firstly, independently training soft-pruning networks for different agent quantities to determine optimal agent-quantity-specific complete graphs and positional masks across specific tasks; and then jointly optimizing hard-pruning and soft-pruning within a maximum complete graph to dynamically configure the number of agents and their communication topologies per task. Extensive experiments demonstrate that our approach is: (1) High-performing, achieving state-of-the-art results across six benchmarks and consistently generalizes across multiple mainstream LLM architectures, with a increase in performance of $2.58\\%\\sim 9.84\\%$; (2) Task-adaptive, dynamically constructing optimized communication topologies tailored to specific tasks, with an extremely high performance in all three task categories (general reasoning, mathematical reasoning, and code generation); (3) Token-economical, having fewer training steps and token consumption at the same time, with a decrease in token consumption of $90\\%+$; and (4) Training-efficient, achieving high performance with very few training steps compared with other methods. The performance will surpass the existing baselines after about ten steps of training under six benchmarks.","authors":["Boyi Li","Zhonghan Zhao","Der-Horng Lee","Gaoang Wang"],"url":"https://arxiv.org/abs/2506.02951"}
{"created":"2025-06-04","title":"Upper bounds on the theta function of random graphs","abstract":"The theta function of Lovasz is a graph parameter that can be computed up to arbitrary precision in polynomial time. It plays a key role in algorithms that approximate graph parameters such as maximum independent set, maximum clique and chromatic number, or even compute them exactly in some models of random and semi-random graphs. For Erdos-Renyi random $G_{n,1/2}$ graphs, the expected value of the theta function is known to be at most $2\\sqrt{n}$ and at least $\\sqrt{n}$. These bounds have not been improved in over 40 years.","authors":["Uriel Feige","Vadim Grinberg"],"url":"https://arxiv.org/abs/2506.02952"}
{"created":"2025-06-04","title":"Towards More Effective Fault Detection in LLM-Based Unit Test Generation","abstract":"Unit tests play a vital role in uncovering potential faults in software. While tools like EvoSuite focus on maximizing code coverage, recent advances in large language models (LLMs) have shifted attention toward LLM-based test generation. However, code coverage metrics -- such as line and branch coverage -- remain overly emphasized in reported research, despite being weak indicators of a test suite's fault-detection capability. In contrast, \\textit{mutation score} offers a more reliable and stringent measure, as demonstrated in our findings where some test suites achieve 100\\% coverage but only 4\\% mutation score. Although a few studies consider mutation score, the effectiveness of LLMs in killing mutants remains underexplored.","authors":["Guancheng Wang","Qinghua Xu","Lionel C. Briand","Kui Liu"],"url":"https://arxiv.org/abs/2506.02954"}
{"created":"2025-06-04","title":"UniConFlow: A Unified Constrained Generalization Framework for Certified Motion Planning with Flow Matching Models","abstract":"Generative models have become increasingly powerful tools for robot motion generation, enabling flexible and multimodal trajectory generation across various tasks. Yet, most existing approaches remain limited in handling multiple types of constraints, such as collision avoidance and dynamic consistency, which are often treated separately or only partially considered. This paper proposes UniConFlow, a unified flow matching (FM) based framework for trajectory generation that systematically incorporates both equality and inequality constraints. UniConFlow introduces a novel prescribed-time zeroing function to enhance flexibility during the inference process, allowing the model to adapt to varying task requirements. To ensure constraint satisfaction, particularly with respect to obstacle avoidance, admissible action range, and kinodynamic consistency, the guidance inputs to the FM model are derived through a quadratic programming formulation, which enables constraint-aware generation without requiring retraining or auxiliary controllers. We conduct mobile navigation and high-dimensional manipulation tasks, demonstrating improved safety and feasibility compared to state-of-the-art constrained generative planners. Project page is available at https://uniconflow.github.io.","authors":["Zewen Yang","Xiaobing Dai","Dian Yu","Qianru Li","Yu Li","Valentin Le Mesle"],"url":"https://arxiv.org/abs/2506.02955"}
{"created":"2025-06-04","title":"HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring","abstract":"The misuse of large language models (LLMs) poses potential risks, motivating the development of machine-generated text (MGT) detection. Existing literature primarily concentrates on binary, document-level detection, thereby neglecting texts that are composed jointly by human and LLM contributions. Hence, this paper explores the possibility of fine-grained MGT detection under human-AI coauthoring. We suggest fine-grained detectors can pave pathways toward coauthored text detection with a numeric AI ratio. Specifically, we propose a dataset, HACo-Det, which produces human-AI coauthored texts via an automatic pipeline with word-level attribution labels. We retrofit seven prevailing document-level detectors to generalize them to word-level detection. Then we evaluate these detectors on HACo-Det on both word- and sentence-level detection tasks. Empirical results show that metric-based methods struggle to conduct fine-grained detection with a 0.462 average F1 score, while finetuned models show superior performance and better generalization across domains. However, we argue that fine-grained co-authored text detection is far from solved. We further analyze factors influencing performance, e.g., context window, and highlight the limitations of current methods, pointing to potential avenues for improvement.","authors":["Zhixiong Su","Yichen Wang","Herun Wan","Zhaohan Zhang","Minnan Luo"],"url":"https://arxiv.org/abs/2506.02959"}
{"created":"2025-06-04","title":"FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models","abstract":"Large Language Models (LLMs) have achieved state-of-the-art results across diverse domains, yet their development remains reliant on vast amounts of publicly available data, raising concerns about data scarcity and the lack of access to domain-specific, sensitive information. Federated Learning (FL) presents a compelling framework to address these challenges by enabling decentralized fine-tuning on pre-trained LLMs without sharing raw data. However, the compatibility and performance of pre-trained LLMs in FL settings remain largely under explored. We introduce the FlowerTune LLM Leaderboard, a first-of-its-kind benchmarking suite designed to evaluate federated fine-tuning of LLMs across four diverse domains: general NLP, finance, medical, and coding. Each domain includes federated instruction-tuning datasets and domain-specific evaluation metrics. Our results, obtained through a collaborative, open-source and community-driven approach, provide the first comprehensive comparison across 26 pre-trained LLMs with different aggregation and fine-tuning strategies under federated settings, offering actionable insights into model performance, resource constraints, and domain adaptation. This work lays the foundation for developing privacy-preserving, domain-specialized LLMs for real-world applications.","authors":["Yan Gao","Massimo Roberto Scamarcia","Javier Fernandez-Marques","Mohammad Naseri","Chong Shen Ng","Dimitris Stripelis","Zexi Li","Tao Shen","Jiamu Bai","Daoyuan Chen","Zikai Zhang","Rui Hu","InSeo Song","Lee KangYoon","Hong Jia","Ting Dang","Junyan Wang","Zheyuan Liu","Daniel Janes Beutel","Lingjuan Lyu","Nicholas D. Lane"],"url":"https://arxiv.org/abs/2506.02961"}
{"created":"2025-06-04","title":"FORLA:Federated Object-centric Representation Learning with Slot Attention","abstract":"Learning efficient visual representations across heterogeneous unlabeled datasets remains a central challenge in federated learning. Effective federated representations require features that are jointly informative across clients while disentangling domain-specific factors without supervision. We introduce FORLA, a novel framework for federated object-centric representation learning and feature adaptation across clients using unsupervised slot attention. At the core of our method is a shared feature adapter, trained collaboratively across clients to adapt features from foundation models, and a shared slot attention module that learns to reconstruct the adapted features. To optimize this adapter, we design a two-branch student-teacher architecture. In each client, a student decoder learns to reconstruct full features from foundation models, while a teacher decoder reconstructs their adapted, low-dimensional counterpart. The shared slot attention module bridges cross-domain learning by aligning object-level representations across clients. Experiments in multiple real-world datasets show that our framework not only outperforms centralized baselines on object discovery but also learns a compact, universal representation that generalizes well across domains. This work highlights federated slot attention as an effective tool for scalable, unsupervised visual representation learning from cross-domain data with distributed concepts.","authors":["Guiqiu Liao","Matjaz Jogan","Eric Eaton","Daniel A. Hashimoto"],"url":"https://arxiv.org/abs/2506.02964"}
{"created":"2025-06-04","title":"Memory-Efficient and Privacy-Preserving Collaborative Training for Mixture-of-Experts LLMs","abstract":"Mixture-of-Experts (MoE) has been gaining popularity due to its successful adaptation to large language models (LLMs). In this work, we introduce Privacy-preserving Collaborative Mixture-of-Experts (PC-MoE), which leverages the sparsity of the MoE architecture for memory-efficient decentralized collaborative LLM training, enabling multiple parties with limited GPU-memory and data resources to collectively train more capable LLMs than they could achieve individually. At the same time, this approach protects training data privacy of each participant by keeping training data, as well as parts of the forward pass signal and gradients locally within each party. By design, PC-MoE synergistically combines the strengths of distributed computation with strong confidentiality assurances. Unlike most privacy-preserving schemes, which pay for confidentiality with lower task accuracy, our framework breaks that trade-off: across seven popular LLM benchmarks, it almost matches (and sometimes exceeds) the performance and convergence rate of a fully centralized model, enjoys near 70% peak GPU RAM reduction, while being fully robust against reconstruction attacks.","authors":["Ze Yu Zhang","Bolin Ding","Bryan Kian Hsiang Low"],"url":"https://arxiv.org/abs/2506.02965"}
{"created":"2025-06-04","title":"Unpacking Graduate Students' Learning Experience with Generative AI Teaching Assistant in A Quantitative Methodology Course","abstract":"The study was conducted in an Advanced Quantitative Research Methods course involving 20 graduate students. During the course, student inquiries made to the AI were recorded and coded using Bloom's taxonomy and the CLEAR framework. A series of independent sample t-tests and poisson regression analyses were employed to analyse the characteristics of different questions asked by students with different backgrounds. Post course interviews were conducted with 10 students to gain deeper insights into their perceptions. The findings revealed a U-shaped pattern in students' use of the AI assistant, with higher usage at the beginning and towards the end of the course, and a decrease in usage during the middle weeks. Most questions posed to the AI focused on knowledge and comprehension levels, with fewer questions involving deeper cognitive thinking. Students with a weaker mathematical foundation used the AI assistant more frequently, though their inquiries tended to lack explicit and logical structure compared to those with a strong mathematical foundation, who engaged less with the tool. These patterns suggest the need for targeted guidance to optimise the effectiveness of AI tools for students with varying levels of academic proficiency.","authors":["Zhanxin Hao","Haifeng Luo","Yongyi Chen","Yu Zhang"],"url":"https://arxiv.org/abs/2506.02966"}
{"created":"2025-06-04","title":"Computation- and Communication-Efficient Online FL for Resource-Constrained Aerial Vehicles","abstract":"Privacy-preserving distributed machine learning (ML) and aerial connected vehicle (ACV)-assisted edge computing have drawn significant attention lately. Since the onboard sensors of ACVs can capture new data as they move along their trajectories, the continual arrival of such 'newly' sensed data leads to online learning and demands carefully crafting the trajectories. Besides, as typical ACVs are inherently resource-constrained, computation- and communication-efficient ML solutions are needed. Therefore, we propose a computation- and communication-efficient online aerial federated learning (2CEOAFL) algorithm to take the benefits of continual sensed data and limited onboard resources of the ACVs. In particular, considering independently owned ACVs act as selfish data collectors, we first model their trajectories according to their respective time-varying data distributions. We then propose a 2CEOAFL algorithm that allows the flying ACVs to (a) prune the received dense ML model to make it shallow, (b) train the pruned model, and (c) probabilistically quantize and offload their trained accumulated gradients to the central server (CS). Our extensive simulation results show that the proposed 2CEOAFL algorithm delivers comparable performances to its non-pruned and nonquantized, hence, computation- and communication-inefficient counterparts.","authors":["Md-Ferdous Pervej","Richeng Jin","Md Moin Uddin Chowdhury","Simran Singh","\\.Ismail G\\\"uven\\c{c}","Huaiyu Dai"],"url":"https://arxiv.org/abs/2506.02972"}
{"created":"2025-06-04","title":"Expanding before Inferring: Enhancing Factuality in Large Language Models through Premature Layers Interpolation","abstract":"Large Language Models (LLMs) demonstrate remarkable capabilities in text understanding and generation. However, their tendency to produce factually inconsistent outputs, commonly referred to as ''hallucinations'', remains a critical challenge. Existing approaches, such as retrieval-based and inference-time correction methods, primarily address this issue at the input or output level, often overlooking the intrinsic information refinement process and the role of premature layers. Meanwhile, alignment- and fine-tuning-based methods are resource-intensive. In this paper, we propose PLI (Premature Layers Interpolation), a novel, training-free, and plug-and-play intervention designed to enhance factuality. PLI mitigates hallucinations by inserting premature layers formed through mathematical interpolation with adjacent layers. Inspired by stable diffusion and sampling steps, PLI extends the depth of information processing and transmission in LLMs, improving factual coherence. Experiments on four publicly available datasets demonstrate that PLI effectively reduces hallucinations while outperforming existing baselines in most cases. Further analysis suggests that the success of layer interpolation is closely linked to LLMs' internal mechanisms. To promote reproducibility, we will release our code and data upon acceptance.","authors":["Dingwei Chen","Ziqiang Liu","Feiteng Fang","Chak Tou Leong","Shiwen Ni","Ahmadreza Argha","Hamid Alinejad-Rokny","Min Yang","Chengming Li"],"url":"https://arxiv.org/abs/2506.02973"}
{"created":"2025-06-04","title":"HaploOmni: Unified Single Transformer for Multimodal Video Understanding and Generation","abstract":"With the advancement of language models, unified multimodal understanding and generation have made significant strides, with model architectures evolving from separated components to unified single-model frameworks. This paper explores an efficient training paradigm to build a single transformer for unified multimodal understanding and generation. Specifically, we propose a multimodal warmup strategy utilizing prior knowledge to extend capabilities. To address cross-modal compatibility challenges, we introduce feature pre-scaling and multimodal AdaLN techniques. Integrating the proposed technologies, we present the HaploOmni, a new single multimodal transformer. With limited training costs, HaploOmni achieves competitive performance across multiple image and video understanding and generation benchmarks over advanced unified models. All codes will be made public at https://github.com/Tencent/HaploVLM.","authors":["Yicheng Xiao","Lin Song","Rui Yang","Cheng Cheng","Zunnan Xu","Zhaoyang Zhang","Yixiao Ge","Xiu Li","Ying Shan"],"url":"https://arxiv.org/abs/2506.02975"}
{"created":"2025-06-04","title":"Deep Learning for Retinal Degeneration Assessment: A Comprehensive Analysis of the MARIO AMD Progression Challenge","abstract":"The MARIO challenge, held at MICCAI 2024, focused on advancing the automated detection and monitoring of age-related macular degeneration (AMD) through the analysis of optical coherence tomography (OCT) images. Designed to evaluate algorithmic performance in detecting neovascular activity changes within AMD, the challenge incorporated unique multi-modal datasets. The primary dataset, sourced from Brest, France, was used by participating teams to train and test their models. The final ranking was determined based on performance on this dataset. An auxiliary dataset from Algeria was used post-challenge to evaluate population and device shifts from submitted solutions. Two tasks were involved in the MARIO challenge. The first one was the classification of evolution between two consecutive 2D OCT B-scans. The second one was the prediction of future AMD evolution over three months for patients undergoing anti-vascular endothelial growth factor (VEGF) therapy. Thirty-five teams participated, with the top 12 finalists presenting their methods. This paper outlines the challenge's structure, tasks, data characteristics, and winning methodologies, setting a benchmark for AMD monitoring using OCT, infrared imaging, and clinical data (such as the number of visits, age, gender, etc.). The results of this challenge indicate that artificial intelligence (AI) performs as well as a physician in measuring AMD progression (Task 1) but is not yet able of predicting future evolution (Task 2).","authors":["Rachid Zeghlache","Ikram Brahim","Pierre-Henri Conze","Mathieu Lamard","Mohammed El Amine Lazouni","Zineb Aziza Elaouaber","Leila Ryma Lazouni","Christopher Nielsen","Ahmad O. Ahsan","Matthias Wilms","Nils D. Forkert","Lovre Antonio Budimir","Ivana Matovinovi\\'c","Donik Vr\\v{s}nak","Sven Lon\\v{c}ari\\'c","Philippe Zhang","Weili Jiang","Yihao Li","Yiding Hao","Markus Frohmann","Patrick Binder","Marcel Huber","Taha Emre","Teresa Finisterra Ara\\'ujo","Marzieh Oghbaie","Hrvoje Bogunovi\\'c","Amerens A. Bekkers","Nina M. van Liebergen","Hugo J. Kuijf","Abdul Qayyum","Moona Mazher","Steven A. Niederer","Alberto J. Beltr\\'an-Carrero","Juan J. G\\'omez-Valverde","Javier Torresano-Rodr\\'iquez","\\'Alvaro Caballero-Sastre","Mar\\'ia J. Ledesma Carbayo","Yosuke Yamagishi","Yi Ding","Robin Peretzke","Alexandra Ertl","Maximilian Fischer","Jessica K\\\"achele","Sofiane Zehar","Karim Boukli Hacene","Thomas Monfort","B\\'eatrice Cochener","Mostafa El Habib Daho","Anas-Alexis Benyoussef","Gwenol\\'e Quellec"],"url":"https://arxiv.org/abs/2506.02976"}
{"created":"2025-06-04","title":"On the Robustness of Tabular Foundation Models: Test-Time Attacks and In-Context Defenses","abstract":"Recent tabular Foundational Models (FM) such as TabPFN and TabICL, leverage in-context learning to achieve strong performance without gradient updates or fine-tuning. However, their robustness to adversarial manipulation remains largely unexplored. In this work, we present a comprehensive study of the adversarial vulnerabilities of tabular FM, focusing on both their fragility to targeted test-time attacks and their potential misuse as adversarial tools. We show on three benchmarks in finance, cybersecurity and healthcare, that small, structured perturbations to test inputs can significantly degrade prediction accuracy, even when training context remain fixed. Additionally, we demonstrate that tabular FM can be repurposed to generate transferable evasion to conventional models such as random forests and XGBoost, and on a lesser extent to deep tabular models. To improve tabular FM, we formulate the robustification problem as an optimization of the weights (adversarial fine-tuning), or the context (adversarial in-context learning). We introduce an in-context adversarial training strategy that incrementally replaces the context with adversarial perturbed instances, without updating model weights. Our approach improves robustness across multiple tabular benchmarks. Together, these findings position tabular FM as both a target and a source of adversarial threats, highlighting the urgent need for robust training and evaluation practices in this emerging paradigm.","authors":["Mohamed Djilani","Thibault Simonetto","Karim Tit","Florian Tambon","Paul R\\'ecamier","Salah Ghamizi","Maxime Cordy","Mike Papadakis"],"url":"https://arxiv.org/abs/2506.02978"}
{"created":"2025-06-04","title":"Towards a Japanese Full-duplex Spoken Dialogue System","abstract":"Full-duplex spoken dialogue systems, which can model simultaneous bidirectional features of human conversations such as speech overlaps and backchannels, have attracted significant attention recently. However, the study of full-duplex spoken dialogue systems for the Japanese language has been limited, and the research on their development in Japanese remains scarce. In this paper, we present the first publicly available full-duplex spoken dialogue model in Japanese, which is built upon Moshi, a full-duplex dialogue model in English. Our model is trained through a two-stage process: pre-training on a large-scale spoken dialogue data in Japanese, followed by fine-tuning on high-quality stereo spoken dialogue data. We further enhance the model's performance by incorporating synthetic dialogue data generated by a multi-stream text-to-speech system. Evaluation experiments demonstrate that the trained model outperforms Japanese baseline models in both naturalness and meaningfulness.","authors":["Atsumoto Ohashi","Shinya Iizuka","Jingjing Jiang","Ryuichiro Higashinaka"],"url":"https://arxiv.org/abs/2506.02979"}
{"created":"2025-06-04","title":"Astrophotography turbulence mitigation via generative models","abstract":"Photography is the cornerstone of modern astronomical and space research. However, most astronomical images captured by ground-based telescopes suffer from atmospheric turbulence, resulting in degraded imaging quality. While multi-frame strategies like lucky imaging can mitigate some effects, they involve intensive data acquisition and complex manual processing. In this paper, we propose AstroDiff, a generative restoration method that leverages both the high-quality generative priors and restoration capabilities of diffusion models to mitigate atmospheric turbulence. Extensive experiments demonstrate that AstroDiff outperforms existing state-of-the-art learning-based methods in astronomical image turbulence mitigation, providing higher perceptual quality and better structural fidelity under severe turbulence conditions. Our code and additional results are available at https://web-six-kappa-66.vercel.app/","authors":["Joonyeoup Kim","Yu Yuan","Xingguang Zhang","Xijun Wang","Stanley Chan"],"url":"https://arxiv.org/abs/2506.02981"}
{"created":"2025-06-04","title":"Implicit Regularization of the Deep Inverse Prior Trained with Inertia","abstract":"Solving inverse problems with neural networks benefits from very few theoretical guarantees when it comes to the recovery guarantees. We provide in this work convergence and recovery guarantees for self-supervised neural networks applied to inverse problems, such as Deep Image/Inverse Prior, and trained with inertia featuring both viscous and geometric Hessian-driven dampings. We study both the continuous-time case, i.e., the trajectory of a dynamical system, and the discrete case leading to an inertial algorithm with an adaptive step-size. We show in the continuous-time case that the network can be trained with an optimal accelerated exponential convergence rate compared to the rate obtained with gradient flow. We also show that training a network with our inertial algorithm enjoys similar recovery guarantees though with a less sharp linear convergence rate.","authors":["Nathan Buskulic","Jalal Fadil","Yvain Qu\\'eau"],"url":"https://arxiv.org/abs/2506.02986"}
{"created":"2025-06-04","title":"Performance of leading large language models in May 2025 in Membership of the Royal College of General Practitioners-style examination questions: a cross-sectional analysis","abstract":"Background: Large language models (LLMs) have demonstrated substantial potential to support clinical practice. Other than Chat GPT4 and its predecessors, few LLMs, especially those of the leading and more powerful reasoning model class, have been subjected to medical specialty examination questions, including in the domain of primary care. This paper aimed to test the capabilities of leading LLMs as of May 2025 (o3, Claude Opus 4, Grok3, and Gemini 2.5 Pro) in primary care education, specifically in answering Member of the Royal College of General Practitioners (MRCGP) style examination questions.","authors":["Richard Armitage"],"url":"https://arxiv.org/abs/2506.02987"}
{"created":"2025-06-04","title":"Adaptive Exploration in Lenia with Intrinsic Multi-Objective Ranking","abstract":"Artificial life aims to understand the fundamental principles of biological life by creating computational models that exhibit life-like properties. Although artificial life systems show promise for simulating biological evolution, achieving open-endedness remains a central challenge. This work investigates mechanisms to promote exploration and unbounded innovation within evolving populations of Lenia continuous cellular automata by evaluating individuals against each other with respect to distinctiveness, population sparsity, and homeostatic regulation. Multi-objective ranking of these intrinsic fitness objectives encourages the perpetual selection of novel and explorative individuals in sparse regions of the descriptor space without restricting the scope of emergent behaviors. We present experiments demonstrating the effectiveness of our multi-objective approach and emphasize that intrinsic evolution allows diverse expressions of artificial life to emerge. We argue that adaptive exploration improves evolutionary dynamics and serves as an important step toward achieving open-ended evolution in artificial systems.","authors":["Niko Lorantos","Lee Spector"],"url":"https://arxiv.org/abs/2506.02990"}
{"created":"2025-06-04","title":"Mitigating Manipulation and Enhancing Persuasion: A Reflective Multi-Agent Approach for Legal Argument Generation","abstract":"Large Language Models (LLMs) are increasingly explored for legal argument generation, yet they pose significant risks of manipulation through hallucination and ungrounded persuasion, and often fail to utilize provided factual bases effectively or abstain when arguments are untenable. This paper introduces a novel reflective multi-agent method designed to address these challenges in the context of legally compliant persuasion. Our approach employs specialized agents--a Factor Analyst and an Argument Polisher--in an iterative refinement process to generate 3-ply legal arguments (plaintiff, defendant, rebuttal). We evaluate Reflective Multi-Agent against single-agent, enhanced-prompt single-agent, and non-reflective multi-agent baselines using four diverse LLMs (GPT-4o, GPT-4o-mini, Llama-4-Maverick-17b-128e, Llama-4-Scout-17b-16e) across three legal scenarios: \"arguable\", \"mismatched\", and \"non-arguable\". Results demonstrate Reflective Multi-Agent's significant superiority in successful abstention (preventing generation when arguments cannot be grounded), marked improvements in hallucination accuracy (reducing fabricated and misattributed factors), particularly in \"non-arguable\" scenarios, and enhanced factor utilization recall (improving the use of provided case facts). These findings suggest that structured reflection within a multi-agent framework offers a robust computable method for fostering ethical persuasion and mitigating manipulation in LLM-based legal argumentation systems, a critical step towards trustworthy AI in law. Project page: https://lizhang-aiandlaw.github.io/A-Reflective-Multi-Agent-Approach-for-Legal-Argument-Generation/","authors":["Li Zhang","Kevin D. Ashley"],"url":"https://arxiv.org/abs/2506.02992"}
{"created":"2025-06-04","title":"Mapping Student-AI Interaction Dynamics in Multi-Agent Learning Environments: Supporting Personalised Learning and Reducing Performance Gaps","abstract":"Multi-agent AI systems, which simulate diverse instructional roles such as teachers and peers, offer new possibilities for personalized and interactive learning. Yet, student-AI interaction patterns and their pedagogical implications remain unclear. This study explores how university students engaged with multiple AI agents, and how these interactions influenced cognitive outcomes (learning gains) and non-cognitive factors (motivation, technology acceptance). Based on MAIC, an online learning platform with multi-agent, the research involved 305 university students and 19,365 lines of dialogue data. Pre- and post-test scores, self-reported motivation and technology acceptance were also collected. The study identified two engagement patterns: co-construction of knowledge and co-regulation. Lag sequential analysis revealed that students with lower prior knowledge relied more on co-construction of knowledge sequences, showing higher learning gains and post-course motivation. In contrast, students with higher prior knowledge engaged more in co-regulation behaviors but exhibited limited learning improvement. Technology acceptance increased across all groups. These findings suggest that multi-agent AI systems can adapt to students' varying needs, support differentiated engagement, and reduce performance gaps. Implications for personalized system design and future research directions are discussed.","authors":["Zhanxin Hao","Jie Cao","Ruimiao Li","Jifan Yu","Zhiyuan Liu","Yu Zhang"],"url":"https://arxiv.org/abs/2506.02993"}
{"created":"2025-06-04","title":"It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems","abstract":"Idioms are defined as a group of words with a figurative meaning not deducible from their individual components. Although modern machine translation systems have made remarkable progress, translating idioms remains a major challenge, especially for speech-to-text systems, where research on this topic is notably sparse. In this paper, we systematically evaluate idiom translation as compared to conventional news translation in both text-to-text machine translation (MT) and speech-to-text translation (SLT) systems across two language pairs (German to English, Russian to English). We compare state-of-the-art end-to-end SLT systems (SeamlessM4T SLT-to-text, Whisper Large v3) with MT systems (SeamlessM4T SLT-to-text, No Language Left Behind), Large Language Models (DeepSeek, LLaMA) and cascaded alternatives. Our results reveal that SLT systems experience a pronounced performance drop on idiomatic data, often reverting to literal translations even in higher layers, whereas MT systems and Large Language Models demonstrate better handling of idioms. These findings underscore the need for idiom-specific strategies and improved internal representations in SLT architectures.","authors":["Iuliia Zaitova","Badr M. Abdullah","Wei Xue","Dietrich Klakow","Bernd M\\\"obius","Tania Avgustinova"],"url":"https://arxiv.org/abs/2506.02995"}
{"created":"2025-06-04","title":"Linear Spatial World Models Emerge in Large Language Models","abstract":"Large language models (LLMs) have demonstrated emergent abilities across diverse tasks, raising the question of whether they acquire internal world models. In this work, we investigate whether LLMs implicitly encode linear spatial world models, which we define as linear representations of physical space and object configurations. We introduce a formal framework for spatial world models and assess whether such structure emerges in contextual embeddings. Using a synthetic dataset of object positions, we train probes to decode object positions and evaluate geometric consistency of the underlying space. We further conduct causal interventions to test whether these spatial representations are functionally used by the model. Our results provide empirical evidence that LLMs encode linear spatial world models.","authors":["Matthieu Tehenan","Christian Bolivar Moya","Tenghai Long","Guang Lin"],"url":"https://arxiv.org/abs/2506.02996"}
{"created":"2025-06-04","title":"Controllable Text-to-Speech Synthesis with Masked-Autoencoded Style-Rich Representation","abstract":"Controllable TTS models with natural language prompts often lack the ability for fine-grained control and face a scarcity of high-quality data. We propose a two-stage style-controllable TTS system with language models, utilizing a quantized masked-autoencoded style-rich representation as an intermediary. In the first stage, an autoregressive transformer is used for the conditional generation of these style-rich tokens from text and control signals. The second stage generates codec tokens from both text and sampled style-rich tokens. Experiments show that training the first-stage model on extensive datasets enhances the content robustness of the two-stage model as well as control capabilities over multiple attributes. By selectively combining discrete labels and speaker embeddings, we explore fully controlling the speaker's timbre and other stylistic information, and adjusting attributes like emotion for a specified speaker. Audio samples are available at https://style-ar-tts.github.io.","authors":["Yongqi Wang","Chunlei Zhang","Hangting Chen","Zhou Zhao","Dong Yu"],"url":"https://arxiv.org/abs/2506.02997"}
{"created":"2025-06-04","title":"A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems","abstract":"Privacy policies inform users about data collection and usage, yet their complexity limits accessibility for diverse populations. Existing Privacy Policy Question Answering (QA) systems exhibit performance disparities across English dialects, disadvantaging speakers of non-standard varieties. We propose a novel multi-agent framework inspired by human-centered design principles to mitigate dialectal biases. Our approach integrates a Dialect Agent, which translates queries into Standard American English (SAE) while preserving dialectal intent, and a Privacy Policy Agent, which refines predictions using domain expertise. Unlike prior approaches, our method does not require retraining or dialect-specific fine-tuning, making it broadly applicable across models and domains. Evaluated on PrivacyQA and PolicyQA, our framework improves GPT-4o-mini's zero-shot accuracy from 0.394 to 0.601 on PrivacyQA and from 0.352 to 0.464 on PolicyQA, surpassing or matching few-shot baselines without additional training data. These results highlight the effectiveness of structured agent collaboration in mitigating dialect biases and underscore the importance of designing NLP systems that account for linguistic diversity to ensure equitable access to privacy information.","authors":["{\\DJ}or{\\dj}e Klisura","Astrid R Bernaga Torres","Anna Karen G\\'arate-Escamilla","Rajesh Roshan Biswal","Ke Yang","Hilal Pataci","Anthony Rios"],"url":"https://arxiv.org/abs/2506.02998"}
{"created":"2025-06-04","title":"Dynamic Fee for Reducing Impermanent Loss in Decentralized Exchanges","abstract":"Decentralized exchanges (DEXs) are crucial to decentralized finance (DeFi) as they enable trading without intermediaries. However, they face challenges like impermanent loss (IL), where liquidity providers (LPs) see their assets' value change unfavorably within a liquidity pool compared to outside it. To tackle these issues, we propose dynamic fee mechanisms over traditional fixed-fee structures used in automated market makers (AMM). Our solution includes asymmetric fees via block-adaptive, deal-adaptive, and the \"ideal but unattainable\" oracle-based fee algorithm, utilizing all data available to arbitrageurs to mitigate IL. We developed a simulation-based framework to compare these fee algorithms systematically. This framework replicates trading on a DEX, considering both informed and uninformed users and a psychological relative loss factor. Results show that adaptive algorithms outperform fixed-fee baselines in reducing IL while maintaining trading activity among uninformed users. Additionally, insights from oracle-based performance underscore the potential of dynamic fee strategies to lower IL, boost LP profitability, and enhance overall market efficiency.","authors":["Irina Lebedeva","Dmitrii Umnov","Yury Yanovich","Ignat Melnikov","George Ovchinnikov"],"url":"https://arxiv.org/abs/2506.03001"}
{"created":"2025-06-04","title":"Newtonian potentials of Legendre polynomials on rectangles have displacement structure","abstract":"Particular solutions of the Poisson equation can be constructed via Newtonian potentials, integrals involving the corresponding Green's function which in two-dimensions has a logarithmic singularity. The singularity represents a significant challenge for computing the integrals, which is typically overcome via specially designed quadrature methods involving a large number of evaluations of the function and kernel. We present an attractive alternative: we show that Newtonian potentials (and their gradient) applied to (tensor products of) Legendre polynomials can be expressed in terms of complex integrals which satisfy simple and explicit recurrences that can be utilised to exactly compute singular integrals, i.e., singular integral quadrature is completely avoided. The inhomogeneous part of the recurrence has low rank structure (its rank is at most three for the Newtonian potential) and hence these recurrences have displacement structure. Using the recurrence directly is a fast approach for evaluation on or near the integration domain that remains accurate for low degree polynomial approximations, while high-precision arithmetic allows accurate use of the approach for moderate degree polynomials.","authors":["Sheehan Olver"],"url":"https://arxiv.org/abs/2506.03003"}
{"created":"2025-06-04","title":"PartComposer: Learning and Composing Part-Level Concepts from Single-Image Examples","abstract":"We present PartComposer: a framework for part-level concept learning from single-image examples that enables text-to-image diffusion models to compose novel objects from meaningful components. Existing methods either struggle with effectively learning fine-grained concepts or require a large dataset as input. We propose a dynamic data synthesis pipeline generating diverse part compositions to address one-shot data scarcity. Most importantly, we propose to maximize the mutual information between denoised latents and structured concept codes via a concept predictor, enabling direct regulation on concept disentanglement and re-composition supervision. Our method achieves strong disentanglement and controllable composition, outperforming subject and part-level baselines when mixing concepts from the same, or different, object categories.","authors":["Junyu Liu","R. Kenny Jones","Daniel Ritchie"],"url":"https://arxiv.org/abs/2506.03004"}
{"created":"2025-06-04","title":"A Preference-Driven Methodology for High-Quality Solidity Code Generation","abstract":"While Large Language Models (LLMs) have demonstrated remarkable progress in generating functionally correct Solidity code, they continue to face critical challenges in producing gas-efficient and secure code, which are critical requirements for real-world smart contract deployment. Although recent advances leverage Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) for code preference alignment, existing approaches treat functional correctness, gas optimization, and security as independent objectives, resulting in contracts that may achieve operational soundness but suffer from prohibitive execution costs or dangerous vulnerabilities. To address these limitations, we propose PrefGen, a novel framework that extends standard DPO beyond human preferences to incorporate quantifiable blockchain-specific metrics, enabling holistic multi-objective optimization specifically tailored for smart contract generation. Our framework introduces a comprehensive evaluation methodology with four complementary metrics: Pass@k (functional correctness), Compile@k (syntactic correctness), Gas@k (gas efficiency), and Secure@k (security assessment), providing rigorous multi-dimensional contract evaluation. Through extensive experimentation, we demonstrate that PrefGen significantly outperforms existing approaches across all critical dimensions, achieving 66.7% Pass@5, 58.9% Gas@5, and 62.5% Secure@5, while generating production-ready smart contracts that are functionally correct, cost-efficient, and secure.","authors":["Zhiyuan Peng","Xin Yin","Chenhao Ying","Chao Ni","Yuan Luo"],"url":"https://arxiv.org/abs/2506.03006"}
{"created":"2025-06-04","title":"DFBench: Benchmarking Deepfake Image Detection Capability of Large Multimodal Models","abstract":"With the rapid advancement of generative models, the realism of AI-generated images has significantly improved, posing critical challenges for verifying digital content authenticity. Current deepfake detection methods often depend on datasets with limited generation models and content diversity that fail to keep pace with the evolving complexity and increasing realism of the AI-generated content. Large multimodal models (LMMs), widely adopted in various vision tasks, have demonstrated strong zero-shot capabilities, yet their potential in deepfake detection remains largely unexplored. To bridge this gap, we present \\textbf{DFBench}, a large-scale DeepFake Benchmark featuring (i) broad diversity, including 540,000 images across real, AI-edited, and AI-generated content, (ii) latest model, the fake images are generated by 12 state-of-the-art generation models, and (iii) bidirectional benchmarking and evaluating for both the detection accuracy of deepfake detectors and the evasion capability of generative models. Based on DFBench, we propose \\textbf{MoA-DF}, Mixture of Agents for DeepFake detection, leveraging a combined probability strategy from multiple LMMs. MoA-DF achieves state-of-the-art performance, further proving the effectiveness of leveraging LMMs for deepfake detection. Database and codes are publicly available at https://github.com/IntMeGroup/DFBench.","authors":["Jiarui Wang","Huiyu Duan","Juntong Wang","Ziheng Jia","Woo Yi Yang","Xiaorong Zhu","Yu Zhao","Jiaying Qian","Yuke Xing","Guangtao Zhai","Xiongkuo Min"],"url":"https://arxiv.org/abs/2506.03007"}
{"created":"2025-06-04","title":"Conditioning Large Language Models on Legal Systems? Detecting Punishable Hate Speech","abstract":"The assessment of legal problems requires the consideration of a specific legal system and its levels of abstraction, from constitutional law to statutory law to case law. The extent to which Large Language Models (LLMs) internalize such legal systems is unknown. In this paper, we propose and investigate different approaches to condition LLMs at different levels of abstraction in legal systems. This paper examines different approaches to conditioning LLMs at multiple levels of abstraction in legal systems to detect potentially punishable hate speech. We focus on the task of classifying whether a specific social media posts falls under the criminal offense of incitement to hatred as prescribed by the German Criminal Code. The results show that there is still a significant performance gap between models and legal experts in the legal assessment of hate speech, regardless of the level of abstraction with which the models were conditioned. Our analysis revealed, that models conditioned on abstract legal knowledge lacked deep task understanding, often contradicting themselves and hallucinating answers, while models using concrete legal knowledge performed reasonably well in identifying relevant target groups, but struggled with classifying target conducts.","authors":["Florian Ludwig","Torsten Zesch","Frederike Zufall"],"url":"https://arxiv.org/abs/2506.03009"}
{"created":"2025-06-04","title":"Coding Agents with Multimodal Browsing are Generalist Problem Solvers","abstract":"Modern human labor is characterized by specialization; we train for years and develop particular tools that allow us to perform well across a variety of tasks. In addition, AI agents have been specialized for domains such as software engineering, web navigation, and workflow automation. However, this results in agents that are good for one thing but fail to generalize beyond their intended scope. One reason for this is that agent developers provide a highly specialized set of tools or make architectural decisions optimized for a specific use case or benchmark. In this work, we ask the question: what is the minimal set of general tools that can be used to achieve high performance across a diverse set of tasks? Our answer is OpenHands-Versa, a generalist agent built with a modest number of general tools: code editing and execution, web search, as well as multimodal web browsing and file access. Importantly, OpenHands-Versa demonstrates superior or competitive performance over leading specialized agents across three diverse and challenging benchmarks: SWE-Bench Multimodal, GAIA, and The Agent Company, outperforming the best-performing previously published results with absolute improvements in success rate of 9.1, 1.3, and 9.1 points respectively. Further, we show how existing state-of-the-art multi-agent systems fail to generalize beyond their target domains. These results demonstrate the feasibility of developing a generalist agent to solve diverse tasks and establish OpenHands-Versa as a strong baseline for future research.","authors":["Aditya Bharat Soni","Boxuan Li","Xingyao Wang","Valerie Chen","Graham Neubig"],"url":"https://arxiv.org/abs/2506.03011"}
{"created":"2025-06-04","title":"Ten Simple Rules for Catalyzing Collaborations and Building Bridges between Research Software Engineers and Software Engineering Researchers","abstract":"In the evolving landscape of scientific and scholarly research, effective collaboration between Research Software Engineers (RSEs) and Software Engineering Researchers (SERs) is pivotal for advancing innovation and ensuring the integrity of computational methodologies. This paper presents ten strategic guidelines aimed at fostering productive partnerships between these two distinct yet complementary communities. The guidelines emphasize the importance of recognizing and respecting the cultural and operational differences between RSEs and SERs, proactively initiating and nurturing collaborations, and engaging within each other's professional environments. They advocate for identifying shared challenges, maintaining openness to emerging problems, ensuring mutual benefits, and serving as advocates for one another. Additionally, the guidelines highlight the necessity of vigilance in monitoring collaboration dynamics, securing institutional support, and defining clear, shared objectives. By adhering to these principles, RSEs and SERs can build synergistic relationships that enhance the quality and impact of research outcomes.","authors":["Nasir U. Eisty","Jeffrey C. Carver","Johanna Cohoon","Ian A. Cosden","Carole Goble","Samuel Grayson"],"url":"https://arxiv.org/abs/2506.03012"}
{"created":"2025-06-04","title":"How do Pre-Trained Models Support Software Engineering? An Empirical Study in Hugging Face","abstract":"Open-Source Pre-Trained Models (PTMs) provide extensive resources for various Machine Learning (ML) tasks, yet these resources lack a classification tailored to Software Engineering (SE) needs. To address this gap, we derive a taxonomy encompassing 147 SE tasks and apply an SE-oriented classification to PTMs in a popular open-source ML repository, Hugging Face (HF). Our repository mining study began with a systematically gathered database of PTMs from the HF API, considering their model card descriptions and metadata, and the abstract of the associated arXiv papers. We confirmed SE relevance through multiple filtering steps: detecting outliers, identifying near-identical PTMs, and the use of Gemini 2.0 Flash, which was validated with five pilot studies involving three human annotators. This approach uncovered 2,205 SE PTMs. We find that code generation is the most common SE task among PTMs, primarily focusing on software implementation, while requirements engineering and software design activities receive limited attention. In terms of ML tasks, text generation dominates within SE PTMs. Notably, the number of SE PTMs has increased markedly since 2023 Q2. Our classification provides a solid foundation for future automated SE scenarios, such as the sampling and selection of suitable PTMs.","authors":["Alexandra Gonz\\'alez","Xavier Franch","David Lo","Silverio Mart\\'inez-Fern\\'andez"],"url":"https://arxiv.org/abs/2506.03013"}
{"created":"2025-06-04","title":"Adjusting Tissue Puncture Omnidirectionally In Situ with Pneumatic Rotatable Biopsy Mechanism and Hierarchical Airflow Management in Tortuous Luminal Pathways","abstract":"In situ tissue biopsy with an endoluminal catheter is an efficient approach for disease diagnosis, featuring low invasiveness and few complications. However, the endoluminal catheter struggles to adjust the biopsy direction by distal endoscope bending or proximal twisting for tissue sampling within the tortuous luminal organs, due to friction-induced hysteresis and narrow spaces. Here, we propose a pneumatically-driven robotic catheter enabling the adjustment of the sampling direction without twisting the catheter for an accurate in situ omnidirectional biopsy. The distal end of the robotic catheter consists of a pneumatic bending actuator for the catheter's deployment in torturous luminal organs and a pneumatic rotatable biopsy mechanism (PRBM). By hierarchical airflow control, the PRBM can adjust the biopsy direction under low airflow and deploy the biopsy needle with higher airflow, allowing for rapid omnidirectional sampling of tissue in situ. This paper describes the design, modeling, and characterization of the proposed robotic catheter, including repeated deployment assessments of the biopsy needle, puncture force measurement, and validation via phantom tests. The PRBM prototype has six sampling directions evenly distributed across 360 degrees when actuated by a positive pressure of 0.3 MPa. The pneumatically-driven robotic catheter provides a novel biopsy strategy, potentially facilitating in situ multidirectional biopsies in tortuous luminal organs with minimum invasiveness.","authors":["Botao Lin","Tinghua Zhang","Sishen Yuan","Tiantian Wang","Jiaole Wang","Wu Yuan","Hongliang Ren"],"url":"https://arxiv.org/abs/2506.03017"}
{"created":"2025-06-04","title":"Smartflow: Enabling Scalable Spatiotemporal Geospatial Research","abstract":"BlackSky introduces Smartflow, a cloud-based framework enabling scalable spatiotemporal geospatial research built on open-source tools and technologies. Using STAC-compliant catalogs as a common input, heterogeneous geospatial data can be processed into standardized datacubes for analysis and model training. Model experimentation is managed using a combination of tools, including ClearML, Tensorboard, and Apache Superset. Underpinning Smartflow is Kubernetes, which orchestrates the provisioning and execution of workflows to support both horizontal and vertical scalability. This combination of features makes Smartflow well-suited for geospatial model development and analysis over large geographic areas, time scales, and expansive image archives.","authors":["David McVicar","Brian Avant","Adrian Gould","Diego Torrejon","Charles Della Porta","Ryan Mukherjee"],"url":"https://arxiv.org/abs/2506.03022"}
{"created":"2025-06-04","title":"GenFair: Systematic Test Generation for Fairness Fault Detection in Large Language Models","abstract":"Large Language Models (LLMs) are increasingly deployed in critical domains, yet they often exhibit biases inherited from training data, leading to fairness concerns. This work focuses on the problem of effectively detecting fairness violations, especially intersectional biases that are often missed by existing template-based and grammar-based testing methods. Previous approaches, such as CheckList and ASTRAEA, provide structured or grammar-driven test generation but struggle with low test diversity and limited sensitivity to complex demographic interactions. To address these limitations, we propose GenFair, a metamorphic fairness testing framework that systematically generates source test cases using equivalence partitioning, mutation operators, and boundary value analysis. GenFair improves fairness testing by generating linguistically diverse, realistic, and intersectional test cases. It applies metamorphic relations (MR) to derive follow-up cases and detects fairness violations via tone-based comparisons between source and follow-up responses. In experiments with GPT-4.0 and LLaMA-3.0, GenFair outperformed two baseline methods. It achieved a fault detection rate (FDR) of 0.73 (GPT-4.0) and 0.69 (LLaMA-3.0), compared to 0.54/0.51 for template-based and 0.39/0.36 for ASTRAEA. GenFair also showed the highest test case diversity (syntactic:10.06, semantic: 76.68) and strong coherence (syntactic: 291.32, semantic: 0.7043), outperforming both baselines. These results demonstrate the effectiveness of GenFair in uncovering nuanced fairness violations. The proposed method offers a scalable and automated solution for fairness testing and contributes to building more equitable LLMs.","authors":["Madhusudan Srinivasan","Jubril Abdel"],"url":"https://arxiv.org/abs/2506.03024"}
{"created":"2025-06-04","title":"Bivariate polynomial histopolation techniques on Padua, Fekete and Leja triangles","abstract":"This paper explores the reconstruction of a real-valued function $f$ defined over a domain $\\Omega \\subset \\mathbb{R}^2$ using bivariate polynomials that satisfy triangular histopolation conditions. More precisely, we assume that only the averages of $f$ over a given triangulation $\\mathcal{T}_N$ of $\\Omega$ are available and seek a bivariate polynomial that approximates $f$ using a histopolation approach, potentially flanked by an additional regression technique. This methodology relies on the selection of a subset of triangles $\\mathcal{T}_M \\subset \\mathcal{T}_N$ for histopolation, ensuring both the solvability and the well-conditioning of the problem. The remaining triangles can potentially be used to enhance the accuracy of the polynomial approximation through a simultaneous regression. We will introduce histopolation and combined histopolation-regression methods using the Padua points, discrete Leja sequences, and approximate Fekete nodes. The proposed algorithms are implemented and evaluated through numerical experiments that demonstrate their effectiveness in function approximation.","authors":["Ludovico Bruni Bruno","Francesco Dell'Accio","Wolfgang Erb","Federico Nudo"],"url":"https://arxiv.org/abs/2506.03025"}
{"created":"2025-06-04","title":"Protein Inverse Folding From Structure Feedback","abstract":"The inverse folding problem, aiming to design amino acid sequences that fold into desired three-dimensional structures, is pivotal for various biotechnological applications. Here, we introduce a novel approach leveraging Direct Preference Optimization (DPO) to fine-tune an inverse folding model using feedback from a protein folding model. Given a target protein structure, we begin by sampling candidate sequences from the inverse-folding model, then predict the three-dimensional structure of each sequence with the folding model to generate pairwise structural-preference labels. These labels are used to fine-tune the inverse-folding model under the DPO objective. Our results on the CATH 4.2 test set demonstrate that DPO fine-tuning not only improves sequence recovery of baseline models but also leads to a significant improvement in average TM-Score from 0.77 to 0.81, indicating enhanced structure similarity. Furthermore, iterative application of our DPO-based method on challenging protein structures yields substantial gains, with an average TM-Score increase of 79.5\\% with regard to the baseline model. This work establishes a promising direction for enhancing protein sequence design ability from structure feedback by effectively utilizing preference optimization.","authors":["Junde Xu","Zijun Gao","Xinyi Zhou","Jie Hu","Xingyi Cheng","Le Song","Guangyong Chen","Pheng-Ann Heng","Jiezhong Qiu"],"url":"https://arxiv.org/abs/2506.03028"}
{"created":"2025-06-04","title":"The Vampire Diary","abstract":"During the past decade of continuous development, the theorem prover Vampire has become an automated solver for the combined theories of commonly-used data structures. Vampire now supports arithmetic, induction, and higher-order logic. These advances have been made to meet the demands of software verification, enabling Vampire to effectively complement SAT/SMT solvers and aid proof assistants. We explain how best to use Vampire in practice and review the main changes Vampire has undergone since its last tool presentation, focusing on the engineering principles and design choices we made during this process.","authors":["Filip B\\'artek","Ahmed Bhayat","Robin Coutelier","M\\'arton Hajdu","Matthias Hetzenberger","Petra Hozzov\\'a","Laura Kov\\'acs","Jakob Rath","Michael Rawson","Giles Reger","Martin Suda","Johannes Schoisswohl","Andrei Voronkov"],"url":"https://arxiv.org/abs/2506.03030"}
{"created":"2025-06-04","title":"TestAgent: An Adaptive and Intelligent Expert for Human Assessment","abstract":"Accurately assessing internal human states is key to understanding preferences, offering personalized services, and identifying challenges in real-world applications. Originating from psychometrics, adaptive testing has become the mainstream method for human measurement and has now been widely applied in education, healthcare, sports, and sociology. It customizes assessments by selecting the fewest test questions . However, current adaptive testing methods face several challenges. The mechanized nature of most algorithms leads to guessing behavior and difficulties with open-ended questions. Additionally, subjective assessments suffer from noisy response data and coarse-grained test outputs, further limiting their effectiveness. To move closer to an ideal adaptive testing process, we propose TestAgent, a large language model (LLM)-powered agent designed to enhance adaptive testing through interactive engagement. This is the first application of LLMs in adaptive testing. TestAgent supports personalized question selection, captures test-takers' responses and anomalies, and provides precise outcomes through dynamic, conversational interactions. Experiments on psychological, educational, and lifestyle assessments show our approach achieves more accurate results with 20% fewer questions than state-of-the-art baselines, and testers preferred it in speed, smoothness, and other dimensions.","authors":["Junhao Yu","Yan Zhuang","YuXuan Sun","Weibo Gao","Qi Liu","Mingyue Cheng","Zhenya Huang","Enhong Chen"],"url":"https://arxiv.org/abs/2506.03032"}
{"created":"2025-06-04","title":"Leveraging Information Retrieval to Enhance Spoken Language Understanding Prompts in Few-Shot Learning","abstract":"Understanding user queries is fundamental in many applications, such as home assistants, booking systems, or recommendations. Accordingly, it is crucial to develop accurate Spoken Language Understanding (SLU) approaches to ensure the reliability of the considered system. Current State-of-the-Art SLU techniques rely on large amounts of training data; however, only limited annotated examples are available for specific tasks or languages.","authors":["Pierre Lepagnol","Sahar Ghannay","Thomas Gerald","Christophe Servan","Sophie Rosset"],"url":"https://arxiv.org/abs/2506.03035"}
{"created":"2025-06-04","title":"On the Need to Align Intent and Implementation in Uncertainty Quantification for Machine Learning","abstract":"Quantifying uncertainties for machine learning (ML) models is a foundational challenge in modern data analysis. This challenge is compounded by at least two key aspects of the field: (a) inconsistent terminology surrounding uncertainty and estimation across disciplines, and (b) the varying technical requirements for establishing trustworthy uncertainties in diverse problem contexts. In this position paper, we aim to clarify the depth of these challenges by identifying these inconsistencies and articulating how different contexts impose distinct epistemic demands. We examine the current landscape of estimation targets (e.g., prediction, inference, simulation-based inference), uncertainty constructs (e.g., frequentist, Bayesian, fiducial), and the approaches used to map between them. Drawing on the literature, we highlight and explain examples of problematic mappings. To help address these issues, we advocate for standards that promote alignment between the \\textit{intent} and \\textit{implementation} of uncertainty quantification (UQ) approaches. We discuss several axes of trustworthiness that are necessary (if not sufficient) for reliable UQ in ML models, and show how these axes can inform the design and evaluation of uncertainty-aware ML systems. Our practical recommendations focus on scientific ML, offering illustrative cases and use scenarios, particularly in the context of simulation-based inference (SBI).","authors":["Shubhendu Trivedi","Brian D. Nord"],"url":"https://arxiv.org/abs/2506.03037"}
{"created":"2025-06-04","title":"Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective","abstract":"Reinforcement learning (RL) enhances large language models (LLMs) in complex, long-chain-of-thought (long-CoT) reasoning. The advanced VAPO framework, despite sophisticated mechanisms like Decoupled GAE, theoretically faces fundamental limitations in comprehensively modeling and leveraging deep, long-term value for fine-grained, step-by-step policy guidance in extended reasoning chains. We argue these limitations stem from inherent difficulties in credit assignment, value function representational capacity with temporally abstracted goals, and translating global value signals into local policy improvements, especially with sparse rewards. Our theoretical analysis examines these aspects to illuminate VAPO's boundaries in long-term value modeling, aiming to deepen understanding of current RL for advanced reasoning and suggest future research for more robust LLM agents.","authors":["Jintian Shao","Yiming Cheng"],"url":"https://arxiv.org/abs/2506.03038"}
{"created":"2025-06-04","title":"Rates of convergence of finite element approximations of second-order mean field games with nondifferentiable Hamiltonians","abstract":"We prove a rate of convergence for finite element approximations of stationary, second-order mean field games with nondifferentiable Hamiltonians posed in general bounded polytopal Lipschitz domains with strongly monotone running costs. In particular, we obtain a rate of convergence in the $H^1$-norm for the value function approximations and in the $L^2$-norm for the approximations of the density. We also establish a rate of convergence for the error between the exact solution of the MFG system with a nondifferentiable Hamiltonian and the finite element discretizations of the corresponding MFG system with a regularized Hamiltonian.","authors":["Yohance A. P. Osborne","Iain Smears"],"url":"https://arxiv.org/abs/2506.03039"}
{"created":"2025-06-04","title":"AI-Augmented OTDR Fault Localization Framework for Resilient Rural Fiber Networks in the United States","abstract":"This research presents a novel framework that combines traditional Optical Time-Domain Reflectometer (OTDR) signal analysis with machine learning to localize and classify fiber optic faults in rural broadband infrastructures. The proposed system addresses a critical need in the expansion of middle-mile and last-mile networks, particularly in regions targeted by the U.S. Broadband Equity, Access, and Deployment (BEAD) Program. By enhancing fault diagnosis through a predictive, AI-based model, this work enables proactive network maintenance in low-resource environments. Experimental evaluations using a controlled fiber testbed and synthetic datasets simulating rural network conditions demonstrate that the proposed method significantly improves detection accuracy and reduces false positives compared to conventional thresholding techniques. The solution offers a scalable, field-deployable tool for technicians and ISPs engaged in rural broadband deployment.","authors":["Sabab Al Farabi (Department of Industrial Engineering","Lamar University","Beaumont","Texas","USA)"],"url":"https://arxiv.org/abs/2506.03041"}
{"created":"2025-06-04","title":"Sample complexity of Schr\\\"odinger potential estimation","abstract":"We address the problem of Schr\\\"odinger potential estimation, which plays a crucial role in modern generative modelling approaches based on Schr\\\"odinger bridges and stochastic optimal control for SDEs. Given a simple prior diffusion process, these methods search for a path between two given distributions $\\rho_0$ and $\\rho_T^*$ requiring minimal efforts. The optimal drift in this case can be expressed through a Schr\\\"odinger potential. In the present paper, we study generalization ability of an empirical Kullback-Leibler (KL) risk minimizer over a class of admissible log-potentials aimed at fitting the marginal distribution at time $T$. Under reasonable assumptions on the target distribution $\\rho_T^*$ and the prior process, we derive a non-asymptotic high-probability upper bound on the KL-divergence between $\\rho_T^*$ and the terminal density corresponding to the estimated log-potential. In particular, we show that the excess KL-risk may decrease as fast as $O(\\log^2 n / n)$ when the sample size $n$ tends to infinity even if both $\\rho_0$ and $\\rho_T^*$ have unbounded supports.","authors":["Nikita Puchkin","Iurii Pustovalov","Yuri Sapronov","Denis Suchkov","Alexey Naumov","Denis Belomestny"],"url":"https://arxiv.org/abs/2506.03043"}
{"created":"2025-06-04","title":"EDEN: Entorhinal Driven Egocentric Navigation Toward Robotic Deployment","abstract":"Deep reinforcement learning agents are often fragile while humans remain adaptive and flexible to varying scenarios. To bridge this gap, we present EDEN, a biologically inspired navigation framework that integrates learned entorhinal-like grid cell representations and reinforcement learning to enable autonomous navigation. Inspired by the mammalian entorhinal-hippocampal system, EDEN allows agents to perform path integration and vector-based navigation using visual and motion sensor data. At the core of EDEN is a grid cell encoder that transforms egocentric motion into periodic spatial codes, producing low-dimensional, interpretable embeddings of position. To generate these activations from raw sensory input, we combine fiducial marker detections in the lightweight MiniWorld simulator and DINO-based visual features in the high-fidelity Gazebo simulator. These spatial representations serve as input to a policy trained with Proximal Policy Optimization (PPO), enabling dynamic, goal-directed navigation. We evaluate EDEN in both MiniWorld, for rapid prototyping, and Gazebo, which offers realistic physics and perception noise. Compared to baseline agents using raw state inputs (e.g., position, velocity) or standard convolutional image encoders, EDEN achieves a 99% success rate, within the simple scenarios, and >94% within complex floorplans with occluded paths with more efficient and reliable step-wise navigation. In addition, as a replacement of ground truth activations, we present a trainable Grid Cell encoder enabling the development of periodic grid-like patterns from vision and motion sensor data, emulating the development of such patterns within biological mammals. This work represents a step toward biologically grounded spatial intelligence in robotics, bridging neural navigation principles with reinforcement learning for scalable deployment.","authors":["Mikolaj Walczak","Romina Aalishah","Wyatt Mackey","Brittany Story","David L. Boothe Jr.","Nicholas Waytowich","Xiaomin Lin","Tinoosh Mohsenin"],"url":"https://arxiv.org/abs/2506.03046"}
{"created":"2025-06-04","title":"Facts Do Care About Your Language: Assessing Answer Quality of Multilingual LLMs","abstract":"Factuality is a necessary precursor to useful educational tools. As adoption of Large Language Models (LLMs) in education continues of grow, ensuring correctness in all settings is paramount. Despite their strong English capabilities, LLM performance in other languages is largely untested. In this work, we evaluate the correctness of the Llama3.1 family of models in answering factual questions appropriate for middle and high school students. We demonstrate that LLMs not only provide extraneous and less truthful information, but also exacerbate existing biases against rare languages.","authors":["Yuval Kansal","Shmuel Berman","Lydia Liu"],"url":"https://arxiv.org/abs/2506.03051"}
{"created":"2025-06-04","title":"Feedstack: Layering Structured Representations over Unstructured Feedback to Scaffold Human AI Conversation","abstract":"Many conversational user interfaces facilitate linear conversations with turn-based dialogue, similar to face-to-face conversations between people. However, digital conversations can afford more than simple back-and-forth; they can be layered with interaction techniques and structured representations that scaffold exploration, reflection, and shared understanding between users and AI systems. We introduce Feedstack, a speculative interface that augments feedback conversations with layered affordances for organizing, navigating, and externalizing feedback. These layered structures serve as a shared representation of the conversation that can surface user intent and reveal underlying design principles. This work represents an early exploration of this vision using a research-through-design approach. We describe system features and design rationale, and present insights from two formative (n=8, n=8) studies to examine how novice designers engage with these layered supports. Rather than presenting a conclusive evaluation, we reflect on Feedstack as a design probe that opens up new directions for conversational feedback systems.","authors":["Hannah Vy Nguyen","Yu-Chun Grace Yen","Omar Shakir","Hang Huynh","Sebastian Gutierrez","June A. Smith","Sheila Jimenez","Salma Abdelgelil","Stephen MacNeil"],"url":"https://arxiv.org/abs/2506.03052"}
{"created":"2025-06-04","title":"MAEBE: Multi-Agent Emergent Behavior Framework","abstract":"Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts.","authors":["Sinem Erisken (Independent Researcher)","Timothy Gothard (Independent Researcher)","Martin Leitgab (Independent Researcher)","Ram Potham (Independent Researcher)"],"url":"https://arxiv.org/abs/2506.03053"}
{"created":"2025-06-04","title":"Corrigibility as a Singular Target: A Vision for Inherently Reliable Foundation Models","abstract":"Foundation models (FMs) face a critical safety challenge: as capabilities scale, instrumental convergence drives default trajectories toward loss of human control, potentially culminating in existential catastrophe. Current alignment approaches struggle with value specification complexity and fail to address emergent power-seeking behaviors. We propose \"Corrigibility as a Singular Target\" (CAST)-designing FMs whose overriding objective is empowering designated human principals to guide, correct, and control them. This paradigm shift from static value-loading to dynamic human empowerment transforms instrumental drives: self-preservation serves only to maintain the principal's control; goal modification becomes facilitating principal guidance. We present a comprehensive empirical research agenda spanning training methodologies (RLAIF, SFT, synthetic data generation), scalability testing across model sizes, and demonstrations of controlled instructability. Our vision: FMs that become increasingly responsive to human guidance as capabilities grow, offering a path to beneficial AI that remains as tool-like as possible, rather than supplanting human judgment. This addresses the core alignment problem at its source, preventing the default trajectory toward misaligned instrumental convergence.","authors":["Ram Potham (Independent Researcher)","Max Harms (Machine Intelligence Research Institute)"],"url":"https://arxiv.org/abs/2506.03056"}
{"created":"2025-06-04","title":"Backpressure-based Mean-field Type Game for Scheduling in Multi-Hop Wireless Sensor Networks","abstract":"We propose a Mean-Field Type Game (MFTG) framework for effective scheduling in multi-hop wireless sensor networks (WSNs) using backpressure as a performance criterion. Traditional backpressure algorithms leverage queue differentials to regulate data flow and maintain network stability. In this work, we extend the backpressure framework by incorporating a mean-field term into the cost functional, capturing the global behavior of the system alongside local dynamics. The resulting model utilizes the strengths of non-cooperative mean-field type games, enabling nodes to make decentralized decisions based on both individual queue states and system mean-field effects while accounting for stochastic network interactions. By leveraging the interplay between backpressure dynamics and mean-field coupling, the approach balances local optimization with global efficiency. Numerical simulations demonstrate the efficacy of the proposed method in handling congestion and scheduling in large-scale WSNs.","authors":["Salah Eddine Choutri","Boualem Djehiche","Prajwal Chauhan","Saif Eddin Jabari"],"url":"https://arxiv.org/abs/2506.03059"}
{"created":"2025-06-04","title":"Multi-Metric Adaptive Experimental Design under Fixed Budget with Validation","abstract":"Standard A/B tests in online experiments face statistical power challenges when testing multiple candidates simultaneously, while adaptive experimental designs (AED) alone fall short in inferring experiment statistics such as the average treatment effect, especially with many metrics (e.g., revenue, safety) and heterogeneous variances. This paper proposes a fixed-budget multi-metric AED framework with a two-phase structure: an adaptive exploration phase to identify the best treatment, and a validation phase with an A/B test to verify the treatment's quality and infer statistics. We propose SHRVar, which generalizes sequential halving (SH) (Karnin et al., 2013) with a novel relative-variance-based sampling and an elimination strategy built on reward z-values. It achieves a provable error probability that decreases exponentially, where the exponent generalizes the complexity measure for SH (Karnin et al., 2013) and SHVar (Lalitha et al., 2023) with homogeneous and heterogeneous variances, respectively. Numerical experiments verify our analysis and demonstrate the superior performance of this new framework.","authors":["Qining Zhang","Tanner Fiez","Yi Liu","Wenyang Liu"],"url":"https://arxiv.org/abs/2506.03062"}
{"created":"2025-06-04","title":"Joint Beamforming for NOMA Assisted Pinching Antenna Systems (PASS)","abstract":"Pinching antenna system (PASS) configures the positions of pinching antennas (PAs) along dielectric waveguides to change both large-scale fading and small-scale scattering, which is known as pinching beamforming. A novel non-orthogonal multiple access (NOMA) assisted PASS framework is proposed for downlink multi-user multiple-input multiple-output (MIMO) communications. The transmit power minimization problem is formulated to jointly optimize the transmit beamforming, pinching beamforming, and power allocation. To solve this highly nonconvex problem, both gradient-based and swarm-based optimization methods are developed. 1) For gradient-based method, a majorization-minimization and penalty dual decomposition (MM-PDD) algorithm is developed. The Lipschitz gradient surrogate function is constructed based on MM to tackle the nonconvex terms of this problem. Then, the joint optimization problem is decomposed into subproblems that are alternatively optimized based on PDD to obtain stationary closed-form solutions. 2) For swarm-based method, a fast-convergent particle swarm optimization and zero forcing (PSO-ZF) algorithm is proposed. Specifically, the PA position-seeking particles are constructed to explore high-quality pinching beamforming solutions. Moreover, ZF-based transmit beamforming is utilized by each particle for fast fitness function evaluation. Simulation results demonstrate that: i) The proposed NOMA assisted PASS and algorithms outperforms the conventional NOMA assisted massive antenna system. The proposed framework reduces over 95.22% transmit power compared to conventional massive MIMO-NOMA systems. ii) Swarm-based optimization outperforms gradient-based optimization by searching effective solution subspace to avoid stuck in undesirable local optima.","authors":["Deqiao Gan","Xiaoxia Xu","Jiakuo Zuo","Xiaohu Ge","Yuanwei Liu"],"url":"https://arxiv.org/abs/2506.03063"}
{"created":"2025-06-04","title":"Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers","abstract":"While Diffusion Transformers (DiTs) have achieved breakthroughs in video generation, this long sequence generation task remains constrained by the quadratic complexity of attention mechanisms, resulting in significant inference latency. Through detailed analysis of attention maps in Video Diffusion Transformer (vDiT), we identify three recurring sparsity patterns: diagonal, multi-diagonal, and vertical-stripe structures. And even 3-6\\% attention heads can be skipped. Crucially, these patterns exhibit strong layer-depth and head-position correlations but show limited dependence on the input content. Leveraging these findings, we propose Sparse-vDiT, a sparsity acceleration framework for vDiT comprising: 1) Pattern-optimized sparse kernels that replace dense attention with computationally efficient implementations for each identified sparsity pattern. 2) An offline sparse diffusion search algorithm that selects the optimal sparse computation strategy per layer and head via hardware-aware cost modeling. After determining the optimal configuration, we fuse heads within the same layer that share the same attention strategy, enhancing inference efficiency. Integrated into state-of-the-art vDiT models (CogVideoX1.5, HunyuanVideo, and Wan2.1), Sparse-vDiT achieves 2.09$\\times$, 2.38$\\times$, and 1.67$\\times$ theoretical FLOP reduction, and actual inference speedups of 1.76$\\times$, 1.85$\\times$, and 1.58$\\times$, respectively, while maintaining high visual fidelity, with PSNR values reaching 24.13, 27.09, and 22.59. Our work demonstrates that latent structural sparsity in vDiTs can be systematically exploited for long video synthesis.","authors":["Pengtao Chen","Xianfang Zeng","Maosen Zhao","Peng Ye","Mingzhu Shen","Wei Cheng","Gang Yu","Tao Chen"],"url":"https://arxiv.org/abs/2506.03065"}
{"created":"2025-06-04","title":"Provable Reinforcement Learning from Human Feedback with an Unknown Link Function","abstract":"Link functions, which characterize how human preferences are generated from the value function of an RL problem, are a crucial component in designing RLHF algorithms. Almost all RLHF algorithms, including state-of-the-art ones in empirical studies such as DPO and PPO, assume the link function is known to the agent (e.g., a logistic function according to the Bradley-Terry model), which is arguably unrealistic considering the complex nature of human preferences. To avoid link function mis-specification, this paper studies general RLHF problems with unknown link functions. We propose a novel policy optimization algorithm called ZSPO based on a new zeroth-order policy optimization method, where the key is to use human preference to construct a parameter update direction that is positively correlated with the true policy gradient direction. ZSPO achieves it by estimating the sign of the value function difference instead of estimating the gradient from the value function difference, so it does not require knowing the link function. Under mild conditions, ZSPO converges to a stationary policy with a polynomial convergence rate depending on the number of policy iterations and trajectories per iteration. Numerical results also show the superiority of ZSPO under link function mismatch.","authors":["Qining Zhang","Lei Ying"],"url":"https://arxiv.org/abs/2506.03066"}
{"created":"2025-06-04","title":"EDITOR: Effective and Interpretable Prompt Inversion for Text-to-Image Diffusion Models","abstract":"Text-to-image generation models~(e.g., Stable Diffusion) have achieved significant advancements, enabling the creation of high-quality and realistic images based on textual descriptions. Prompt inversion, the task of identifying the textual prompt used to generate a specific artifact, holds significant potential for applications including data attribution, model provenance, and watermarking validation. Recent studies introduced a delayed projection scheme to optimize for prompts representative of the vocabulary space, though challenges in semantic fluency and efficiency remain. Advanced image captioning models or visual large language models can generate highly interpretable prompts, but they often lack in image similarity. In this paper, we propose a prompt inversion technique called \\sys for text-to-image diffusion models, which includes initializing embeddings using a pre-trained image captioning model, refining them through reverse-engineering in the latent space, and converting them to texts using an embedding-to-text model. Our experiments on the widely-used datasets, such as MS COCO, LAION, and Flickr, show that our method outperforms existing methods in terms of image similarity, textual alignment, prompt interpretability and generalizability. We further illustrate the application of our generated prompts in tasks such as cross-concept image synthesis, concept manipulation, evolutionary multi-concept generation and unsupervised segmentation.","authors":["Mingzhe Li","Gehao Zhang","Zhenting Wang","Shiqing Ma","Siqi Pan","Richard Cartwright","Juan Zhai"],"url":"https://arxiv.org/abs/2506.03067"}
{"created":"2025-06-04","title":"GPU-Parallelizable Randomized Sketch-and-Precondition for Linear Regression using Sparse Sign Sketches","abstract":"A litany of theoretical and numerical results have established the sketch-and-precondition paradigm as a powerful approach to solving large linear regression problems in standard computing environments. Perhaps surprisingly, much less work has been done on understanding how sketch-and-precondition performs on graphics processing unit (GPU) systems. We address this gap by benchmarking an implementation of sketch-and-precondition based on sparse sign-sketches on single and multi-GPU systems. In doing so, we describe a novel, easily parallelized, rejection-sampling based method for generating sparse sign sketches. Our approach, which is particularly well-suited for GPUs, is easily adapted to a variety of computing environments. Taken as a whole, our numerical experiments indicate that sketch-and-precondition with sparse sign sketches is particularly well-suited for GPUs, and may be suitable for use in black-box least-squares solvers.","authors":["Tyler Chen","Pradeep Niroula","Archan Ray","Pragna Subrahmanya","Marco Pistoia","Niraj Kumar"],"url":"https://arxiv.org/abs/2506.03070"}
{"created":"2025-06-04","title":"LEG-SLAM: Real-Time Language-Enhanced Gaussian Splatting for SLAM","abstract":"Modern Gaussian Splatting methods have proven highly effective for real-time photorealistic rendering of 3D scenes. However, integrating semantic information into this representation remains a significant challenge, especially in maintaining real-time performance for SLAM (Simultaneous Localization and Mapping) applications. In this work, we introduce LEG-SLAM -- a novel approach that fuses an optimized Gaussian Splatting implementation with visual-language feature extraction using DINOv2 followed by a learnable feature compressor based on Principal Component Analysis, while enabling an online dense SLAM. Our method simultaneously generates high-quality photorealistic images and semantically labeled scene maps, achieving real-time scene reconstruction with more than 10 fps on the Replica dataset and 18 fps on ScanNet. Experimental results show that our approach significantly outperforms state-of-the-art methods in reconstruction speed while achieving competitive rendering quality. The proposed system eliminates the need for prior data preparation such as camera's ego motion or pre-computed static semantic maps. With its potential applications in autonomous robotics, augmented reality, and other interactive domains, LEG-SLAM represents a significant step forward in real-time semantic 3D Gaussian-based SLAM. Project page: https://titrom025.github.io/LEG-SLAM/","authors":["Roman Titkov","Egor Zubkov","Dmitry Yudin","Jaafar Mahmoud","Malik Mohrat","Gennady Sidorov"],"url":"https://arxiv.org/abs/2506.03073"}
{"created":"2025-06-04","title":"Agnostic Learning under Targeted Poisoning: Optimal Rates and the Role of Randomness","abstract":"We study the problem of learning in the presence of an adversary that can corrupt an $\\eta$ fraction of the training examples with the goal of causing failure on a specific test point. In the realizable setting, prior work established that the optimal error under such instance-targeted poisoning attacks scales as $\\Theta(d\\eta)$, where $d$ is the VC dimension of the hypothesis class arXiv:2210.02713. In this work, we resolve the corresponding question in the agnostic setting. We show that the optimal excess error is $\\tilde{\\Theta}(\\sqrt{d\\eta})$, answering one of the main open problems left by Hanneke et al. To achieve this rate, it is necessary to use randomized learners: Hanneke et al. showed that deterministic learners can be forced to suffer error close to 1, even under small amounts of poisoning. Perhaps surprisingly, our upper bound remains valid even when the learner's random bits are fully visible to the adversary . In the other direction, our lower bound is stronger than standard PAC-style bounds: instead of tailoring a hard distribution separately for each sample size, we exhibit a single fixed distribution under which the adversary can enforce an excess error of $\\Omega(\\sqrt{d\\eta})$ infinitely often.","authors":["Bogdan Chornomaz","Yonatan Koren","Shay Moran","Tom Waknine"],"url":"https://arxiv.org/abs/2506.03075"}
{"created":"2025-06-04","title":"StreamBP: Memory-Efficient Exact Backpropagation for Long Sequence Training of LLMs","abstract":"Training language models on long sequence data is a demanding requirement for enhancing the model's capability on complex tasks, e.g., long-chain reasoning. However, as the sequence length scales up, the memory cost for storing activation values becomes huge during the Backpropagation (BP) process, even with the application of gradient checkpointing technique. To tackle this challenge, we propose a memory-efficient and exact BP method called StreamBP, which performs a linear decomposition of the chain rule along the sequence dimension in a layer-wise manner, significantly reducing the memory cost of activation values and logits. The proposed method is applicable to common objectives such as SFT, GRPO, and DPO. From an implementation perspective, StreamBP achieves less computational FLOPs and faster BP speed by leveraging the causal structure of the language model. Compared to gradient checkpointing, StreamBP scales up the maximum sequence length of BP by 2.8-5.5 times larger, while using comparable or even less BP time. Note that StreamBP's sequence length scaling ability can be directly transferred to batch size scaling for accelerating training. We further develop a communication-efficient distributed StreamBP to effectively support multi-GPU training and broaden its applicability. Our code can be easily integrated into the training pipeline of any transformer models and is available at https://github.com/Ledzy/StreamBP.","authors":["Qijun Luo","Mengqi Li","Lei Zhao","Xiao Li"],"url":"https://arxiv.org/abs/2506.03077"}
{"created":"2025-06-04","title":"ORV: 4D Occupancy-centric Robot Video Generation","abstract":"Acquiring real-world robotic simulation data through teleoperation is notoriously time-consuming and labor-intensive. Recently, action-driven generative models have gained widespread adoption in robot learning and simulation, as they eliminate safety concerns and reduce maintenance efforts. However, the action sequences used in these methods often result in limited control precision and poor generalization due to their globally coarse alignment. To address these limitations, we propose ORV, an Occupancy-centric Robot Video generation framework, which utilizes 4D semantic occupancy sequences as a fine-grained representation to provide more accurate semantic and geometric guidance for video generation. By leveraging occupancy-based representations, ORV enables seamless translation of simulation data into photorealistic robot videos, while ensuring high temporal consistency and precise controllability. Furthermore, our framework supports the simultaneous generation of multi-view videos of robot gripping operations - an important capability for downstream robotic learning tasks. Extensive experimental results demonstrate that ORV consistently outperforms existing baseline methods across various datasets and sub-tasks. Demo, Code and Model: https://orangesodahub.github.io/ORV","authors":["Xiuyu Yang","Bohan Li","Shaocong Xu","Nan Wang","Chongjie Ye","Zhaoxi Chen","Minghan Qin","Yikang Ding","Xin Jin","Hang Zhao","Hao Zhao"],"url":"https://arxiv.org/abs/2506.03079"}
{"created":"2025-06-04","title":"A structure-preserving and thermodynamically compatible cell-centered Lagrangian finite volume scheme for continuum mechanics","abstract":"In this work we present a novel structure-preserving scheme for the discretization of the Godunov-Peshkov-Romenski (GPR) model of continuum mechanics written in Lagrangian form. This model admits an extra conservation law for the total energy (first principle of thermodynamics) and satisfies the entropy inequality (second principle of thermodynamics). Furthermore, in the absence of algebraic source terms, the distortion field of the continuum and the specific thermal impulse satisfy a curl-free condition, provided the initial data are curl-free. Last but not least, the determinant of the distortion field is related to the density of the medium, i.e. the system is also endowed with a nonlinear algebraic constraint.","authors":["Walter Boscheri","Michael Dumbser","Raphael Loub\\`ere","Pierre-Henri Maire"],"url":"https://arxiv.org/abs/2506.03081"}
{"created":"2025-06-04","title":"SG2VID: Scene Graphs Enable Fine-Grained Control for Video Synthesis","abstract":"Surgical simulation plays a pivotal role in training novice surgeons, accelerating their learning curve and reducing intra-operative errors. However, conventional simulation tools fall short in providing the necessary photorealism and the variability of human anatomy. In response, current methods are shifting towards generative model-based simulators. Yet, these approaches primarily focus on using increasingly complex conditioning for precise synthesis while neglecting the fine-grained human control aspect. To address this gap, we introduce SG2VID, the first diffusion-based video model that leverages Scene Graphs for both precise video synthesis and fine-grained human control. We demonstrate SG2VID's capabilities across three public datasets featuring cataract and cholecystectomy surgery. While SG2VID outperforms previous methods both qualitatively and quantitatively, it also enables precise synthesis, providing accurate control over tool and anatomy's size and movement, entrance of new tools, as well as the overall scene layout. We qualitatively motivate how SG2VID can be used for generative augmentation and present an experiment demonstrating its ability to improve a downstream phase detection task when the training set is extended with our synthetic videos. Finally, to showcase SG2VID's ability to retain human control, we interact with the Scene Graphs to generate new video samples depicting major yet rare intra-operative irregularities.","authors":["Ssharvien Kumar Sivakumar","Yannik Frisch","Ghazal Ghazaei","Anirban Mukhopadhyay"],"url":"https://arxiv.org/abs/2506.03082"}
{"created":"2025-06-04","title":"Labelling Data with Unknown References","abstract":"An evaluator is trustworthy when there exists some agreed-upon way to measure its performance as a labeller. The two ways to establish trustworthiness are either by testing it, or by assuming the evaluator `knows' somehow the way to label the corpus. However, if labelled references (e.g., a development set) are unavailable, neither of these approaches work: the former requires the data, and the latter is an assumption, not evidence. To address this, we introduce an algorithm (the `No-Data Algorithm') by which to establish trust in an evaluator without any existing references. Our algorithm works by successively posing challenges to said evaluator. We show that this is sufficient to establish trustworthiness w.h.p., in such a way that when the evaluator actually knows the way to label the corpus, the No-Data Algorithm accepts its output; and, conversely, flags untrustworthy evaluators when these are unable to prove it. We present formal proofs of correctness and limited experiments.","authors":["Adrian de Wynter"],"url":"https://arxiv.org/abs/2506.03083"}
{"created":"2025-06-04","title":"InterMamba: Efficient Human-Human Interaction Generation with Adaptive Spatio-Temporal Mamba","abstract":"Human-human interaction generation has garnered significant attention in motion synthesis due to its vital role in understanding humans as social beings. However, existing methods typically rely on transformer-based architectures, which often face challenges related to scalability and efficiency. To address these issues, we propose a novel, efficient human-human interaction generation method based on the Mamba framework, designed to meet the demands of effectively capturing long-sequence dependencies while providing real-time feedback. Specifically, we introduce an adaptive spatio-temporal Mamba framework that utilizes two parallel SSM branches with an adaptive mechanism to integrate the spatial and temporal features of motion sequences. To further enhance the model's ability to capture dependencies within individual motion sequences and the interactions between different individual sequences, we develop two key modules: the self-adaptive spatio-temporal Mamba module and the cross-adaptive spatio-temporal Mamba module, enabling efficient feature learning. Extensive experiments demonstrate that our method achieves state-of-the-art results on two interaction datasets with remarkable quality and efficiency. Compared to the baseline method InterGen, our approach not only improves accuracy but also requires a minimal parameter size of just 66M ,only 36% of InterGen's, while achieving an average inference speed of 0.57 seconds, which is 46% of InterGen's execution time.","authors":["Zizhao Wu","Yingying Sun","Yiming Chen","Xiaoling Gu","Ruyu Liu","Jiazhou Chen"],"url":"https://arxiv.org/abs/2506.03084"}
{"created":"2025-06-04","title":"Non-Asymptotic Length Generalization","abstract":"Length generalization is the ability of a learning algorithm to learn a hypothesis which generalizes to longer inputs than the inputs in the training set. In this paper, we provide provable guarantees of length generalization for various classes of functions in an idealized setting. First, we formalize the framework of non-asymptotic length generalization, which requires a computable upper bound for the minimum input length that guarantees length generalization, as a function of the complexity of ground-truth function under some given complexity measure. We refer to this minimum input length to length generalize as length complexity. We show the Minimum-Complexity Interpolator learning algorithm achieves optimal length complexity. We further show that whether a function class admits non-asymptotic length generalization is equivalent to the decidability of its language equivalence problem, which implies that there is no computable upper bound for the length complexity of Context-Free Grammars. On the positive side, we show that the length complexity of Deterministic Finite Automata is $2n - 2$ where $n$ is the number of states of the ground-truth automaton. Our main results are upper bounds of length complexity for a subset of a transformer-related function class called C-RASP (Yang & Chiang, 2024). We show that the length complexity of 1-layer C-RASP functions is $O(T^2)$ when the ground-truth function has precision $T$, and that the length complexity of 2-layer C-RASP functions is $O(T^{O(K)})$ when the ground-truth function has precision $T$ and $K$ heads.","authors":["Thomas Chen","Tengyu Ma","Zhiyuan Li"],"url":"https://arxiv.org/abs/2506.03085"}
{"created":"2025-06-04","title":"How Explanations Leak the Decision Logic: Stealing Graph Neural Networks via Explanation Alignment","abstract":"Graph Neural Networks (GNNs) have become essential tools for analyzing graph-structured data in domains such as drug discovery and financial analysis, leading to growing demands for model transparency. Recent advances in explainable GNNs have addressed this need by revealing important subgraphs that influence predictions, but these explanation mechanisms may inadvertently expose models to security risks. This paper investigates how such explanations potentially leak critical decision logic that can be exploited for model stealing. We propose {\\method}, a novel stealing framework that integrates explanation alignment for capturing decision logic with guided data augmentation for efficient training under limited queries, enabling effective replication of both the predictive behavior and underlying reasoning patterns of target models. Experiments on molecular graph datasets demonstrate that our approach shows advantages over conventional methods in model stealing. This work highlights important security considerations for the deployment of explainable GNNs in sensitive domains and suggests the need for protective measures against explanation-based attacks. Our code is available at https://github.com/beanmah/EGSteal.","authors":["Bin Ma","Yuyuan Feng","Minhua Lin","Enyan Dai"],"url":"https://arxiv.org/abs/2506.03087"}
{"created":"2025-06-04","title":"Explicitly Modeling Subcortical Vision with a Neuro-Inspired Front-End Improves CNN Robustness","abstract":"Convolutional neural networks (CNNs) trained on object recognition achieve high task performance but continue to exhibit vulnerability under a range of visual perturbations and out-of-domain images, when compared with biological vision. Prior work has demonstrated that coupling a standard CNN with a front-end block (VOneBlock) that mimics the primate primary visual cortex (V1) can improve overall model robustness. Expanding on this, we introduce Early Vision Networks (EVNets), a new class of hybrid CNNs that combine the VOneBlock with a novel SubcorticalBlock, whose architecture draws from computational models in neuroscience and is parameterized to maximize alignment with subcortical responses reported across multiple experimental studies. Without being optimized to do so, the assembly of the SubcorticalBlock with the VOneBlock improved V1 alignment across most standard V1 benchmarks, and better modeled extra-classical receptive field phenomena. In addition, EVNets exhibit stronger emergent shape bias and overperform the base CNN architecture by 8.5% on an aggregate benchmark of robustness evaluations, including adversarial perturbations, common corruptions, and domain shifts. Finally, we show that EVNets can be further improved when paired with a state-of-the-art data augmentation technique, surpassing the performance of the isolated data augmentation approach by 7.3% on our robustness benchmark. This result reveals complementary benefits between changes in architecture to better mimic biology and training-based machine learning approaches.","authors":["Lucas Piper","Arlindo L. Oliveira","Tiago Marques"],"url":"https://arxiv.org/abs/2506.03089"}
{"created":"2025-06-04","title":"Literary Evidence Retrieval via Long-Context Language Models","abstract":"How well do modern long-context language models understand literary fiction? We explore this question via the task of literary evidence retrieval, repurposing the RELiC dataset of That et al. (2022) to construct a benchmark where the entire text of a primary source (e.g., The Great Gatsby) is provided to an LLM alongside literary criticism with a missing quotation from that work. This setting, in which the model must generate the missing quotation, mirrors the human process of literary analysis by requiring models to perform both global narrative reasoning and close textual examination. We curate a high-quality subset of 292 examples through extensive filtering and human verification. Our experiments show that recent reasoning models, such as Gemini Pro 2.5 can exceed human expert performance (62.5% vs. 50% accuracy). In contrast, the best open-weight model achieves only 29.1% accuracy, highlighting a wide gap in interpretive reasoning between open and closed-weight models. Despite their speed and apparent accuracy, even the strongest models struggle with nuanced literary signals and overgeneration, signaling open challenges for applying LLMs to literary analysis. We release our dataset and evaluation code to encourage future work in this direction.","authors":["Katherine Thai","Mohit Iyyer"],"url":"https://arxiv.org/abs/2506.03090"}
{"created":"2025-06-04","title":"From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit","abstract":"Motivated by the hypothesis that neural network representations encode abstract, interpretable features as linearly accessible, approximately orthogonal directions, sparse autoencoders (SAEs) have become a popular tool in interpretability. However, recent work has demonstrated phenomenology of model representations that lies outside the scope of this hypothesis, showing signatures of hierarchical, nonlinear, and multi-dimensional features. This raises the question: do SAEs represent features that possess structure at odds with their motivating hypothesis? If not, does avoiding this mismatch help identify said features and gain further insights into neural network representations? To answer these questions, we take a construction-based approach and re-contextualize the popular matching pursuits (MP) algorithm from sparse coding to design MP-SAE -- an SAE that unrolls its encoder into a sequence of residual-guided steps, allowing it to capture hierarchical and nonlinearly accessible features. Comparing this architecture with existing SAEs on a mixture of synthetic and natural data settings, we show: (i) hierarchical concepts induce conditionally orthogonal features, which existing SAEs are unable to faithfully capture, and (ii) the nonlinear encoding step of MP-SAE recovers highly meaningful features, helping us unravel shared structure in the seemingly dichotomous representation spaces of different modalities in a vision-language model, hence demonstrating the assumption that useful features are solely linearly accessible is insufficient. We also show that the sequential encoder principle of MP-SAE affords an additional benefit of adaptive sparsity at inference time, which may be of independent interest. Overall, we argue our results provide credence to the idea that interpretability should begin with the phenomenology of representations, with methods emerging from assumptions that fit it.","authors":["Val\\'erie Costa","Thomas Fel","Ekdeep Singh Lubana","Bahareh Tolooshams","Demba Ba"],"url":"https://arxiv.org/abs/2506.03093"}
{"created":"2025-06-04","title":"DPO Learning with LLMs-Judge Signal for Computer Use Agents","abstract":"Computer use agents (CUA) are systems that automatically interact with graphical user interfaces (GUIs) to complete tasks. CUA have made significant progress with the advent of large vision-language models (VLMs). However, these agents typically rely on cloud-based inference with substantial compute demands, raising critical privacy and scalability concerns, especially when operating on personal devices. In this work, we take a step toward privacy-preserving and resource-efficient agents by developing a lightweight vision-language model that runs entirely on local machines. To train this compact agent, we introduce an LLM-as-Judge framework that automatically evaluates and filters synthetic interaction trajectories, producing high-quality data for reinforcement learning without human annotation. Experiments on the OS-World benchmark demonstrate that our fine-tuned local model outperforms existing baselines, highlighting a promising path toward private, efficient, and generalizable GUI agents.","authors":["Man Luo","David Cobbley","Xin Su","Shachar Rosenman","Vasudev Lal","Shao-Yen Tseng","Phillip Howard"],"url":"https://arxiv.org/abs/2506.03095"}
{"created":"2025-06-04","title":"FuseLIP: Multimodal Embeddings via Early Fusion of Discrete Tokens","abstract":"Contrastive language-image pre-training aligns the features of text-image pairs in a common latent space via distinct encoders for each modality. While this approach achieves impressive performance in several zero-shot tasks, it cannot natively handle multimodal inputs, i.e., encoding image and text into a single feature vector. As a remedy, it is common practice to use additional modules to merge the features extracted by the unimodal encoders. In this work, we present FuseLIP, an alternative architecture for multimodal embedding. Leveraging recent progress in discrete image tokenizers, we propose to use a single transformer model which operates on an extended vocabulary of text and image tokens. This early fusion approach allows the different modalities to interact at each depth of encoding and obtain richer representations compared to common late fusion. We collect new datasets for multimodal pre-training and evaluation, designing challenging tasks for multimodal encoder models. We show that FuseLIP outperforms other approaches in multimodal embedding tasks such as VQA and text-guided image transformation retrieval, while being comparable to baselines on unimodal tasks.","authors":["Christian Schlarmann","Francesco Croce","Nicolas Flammarion","Matthias Hein"],"url":"https://arxiv.org/abs/2506.03096"}
{"created":"2025-06-04","title":"EgoVLM: Policy Optimization for Egocentric Video Understanding","abstract":"Emerging embodied AI applications, such as wearable cameras and autonomous agents, have underscored the need for robust reasoning from first person video streams. We introduce EgoVLM, a vision-language model specifically designed to integrate visual comprehension and spatial-temporal reasoning within egocentric video contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization (GRPO), a reinforcement learning method adapted to align model outputs with human-like reasoning steps. Following DeepSeek R1-Zero's approach, we directly tune using RL without any supervised fine-tuning phase on chain-of-thought (CoT) data. We evaluate EgoVLM on egocentric video question answering benchmarks and show that domain-specific training substantially improves performance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively on non-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by 14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. By explicitly generating reasoning traces, EgoVLM enhances interpretability, making it well-suited for downstream applications. Furthermore, we introduce a novel keyframe-based reward that incorporates salient frame selection to guide reinforcement learning optimization. This reward formulation opens a promising avenue for future exploration in temporally grounded egocentric reasoning.","authors":["Ashwin Vinod","Shrey Pandit","Aditya Vavre","Linshen Liu"],"url":"https://arxiv.org/abs/2506.03097"}
{"created":"2025-06-04","title":"TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models","abstract":"In this paper, we present TalkingMachines -- an efficient framework that transforms pretrained video generation models into real-time, audio-driven character animators. TalkingMachines enables natural conversational experiences by integrating an audio large language model (LLM) with our video generation foundation model. Our primary contributions include: (1) We adapt a pretrained SOTA image-to-video DiT into an audio-driven avatar generation model of 18 billion parameters; (2) We enable infinite video streaming without error accumulation through asymmetric knowledge distillation from a bidirectional teacher model into a sparse causal, autoregressive student model; (3) We design a high-throughput, low-latency inference pipeline incorporating several key engineering optimizations such as: (a) disaggregation of the DiT and VAE decoder across separate devices, (b) efficient overlap of inter-device communication and computation using CUDA streams, (c) elimination of redundant recomputations to maximize frame-generation throughput. Please see demo videos here - https://aaxwaz.github.io/TalkingMachines/","authors":["Chetwin Low","Weimin Wang"],"url":"https://arxiv.org/abs/2506.03099"}
{"created":"2025-06-04","title":"Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds","abstract":"Retrieval-augmented generation (RAG) has seen many empirical successes in recent years by aiding the LLM with external knowledge. However, its theoretical aspect has remained mostly unexplored. In this paper, we propose the first finite-sample generalization bound for RAG in in-context linear regression and derive an exact bias-variance tradeoff. Our framework views the retrieved texts as query-dependent noisy in-context examples and recovers the classical in-context learning (ICL) and standard RAG as the limit cases. Our analysis suggests that an intrinsic ceiling on generalization error exists on RAG as opposed to the ICL. Furthermore, our framework is able to model retrieval both from the training data and from external corpora by introducing uniform and non-uniform RAG noise. In line with our theory, we show the sample efficiency of ICL and RAG empirically with experiments on common QA benchmarks, such as Natural Questions and TriviaQA.","authors":["Yang Guo","Yutian Tao","Yifei Ming","Robert D. Nowak","Yingyu Liang"],"url":"https://arxiv.org/abs/2506.03100"}
{"created":"2025-06-04","title":"Beyond Text Compression: Evaluating Tokenizers Across Scales","abstract":"The choice of tokenizer can profoundly impact language model performance, yet accessible and reliable evaluations of tokenizer quality remain an open challenge. Inspired by scaling consistency, we show that smaller models can accurately predict significant differences in tokenizer impact on larger models at a fraction of the compute cost. By systematically evaluating both English-centric and multilingual tokenizers, we find that tokenizer choice has negligible effects on tasks in English but results in consistent performance differences in multilingual settings. We propose new intrinsic tokenizer metrics inspired by Zipf's law that correlate more strongly with downstream performance than text compression when modeling unseen languages. By combining several metrics to capture multiple aspects of tokenizer behavior, we develop a reliable framework for intrinsic tokenizer evaluations. Our work offers a more efficient path to informed tokenizer selection in future language model development.","authors":["Jonas F. Lotz","Ant\\'onio V. Lopes","Stephan Peitz","Hendra Setiawan","Leonardo Emili"],"url":"https://arxiv.org/abs/2506.03101"}
{"created":"2025-06-04","title":"Designing Algorithmic Delegates: The Role of Indistinguishability in Human-AI Handoff","abstract":"As AI technologies improve, people are increasingly willing to delegate tasks to AI agents. In many cases, the human decision-maker chooses whether to delegate to an AI agent based on properties of the specific instance of the decision-making problem they are facing. Since humans typically lack full awareness of all the factors relevant to this choice for a given decision-making instance, they perform a kind of categorization by treating indistinguishable instances -- those that have the same observable features -- as the same. In this paper, we define the problem of designing the optimal algorithmic delegate in the presence of categories. This is an important dimension in the design of algorithms to work with humans, since we show that the optimal delegate can be an arbitrarily better teammate than the optimal standalone algorithmic agent. The solution to this optimal delegation problem is not obvious: we discover that this problem is fundamentally combinatorial, and illustrate the complex relationship between the optimal design and the properties of the decision-making task even in simple settings. Indeed, we show that finding the optimal delegate is computationally hard in general. However, we are able to find efficient algorithms for producing the optimal delegate in several broad cases of the problem, including when the optimal action may be decomposed into functions of features observed by the human and the algorithm. Finally, we run computational experiments to simulate a designer updating an algorithmic delegate over time to be optimized for when it is actually adopted by users, and show that while this process does not recover the optimal delegate in general, the resulting delegate often performs quite well.","authors":["Sophie Greenwood","Karen Levy","Solon Barocas","Hoda Heidari","Jon Kleinberg"],"url":"https://arxiv.org/abs/2506.03102"}
{"created":"2025-06-04","title":"DyTact: Capturing Dynamic Contacts in Hand-Object Manipulation","abstract":"Reconstructing dynamic hand-object contacts is essential for realistic manipulation in AI character animation, XR, and robotics, yet it remains challenging due to heavy occlusions, complex surface details, and limitations in existing capture techniques. In this paper, we introduce DyTact, a markerless capture method for accurately capturing dynamic contact in hand-object manipulations in a non-intrusive manner. Our approach leverages a dynamic, articulated representation based on 2D Gaussian surfels to model complex manipulations. By binding these surfels to MANO meshes, DyTact harnesses the inductive bias of template models to stabilize and accelerate optimization. A refinement module addresses time-dependent high-frequency deformations, while a contact-guided adaptive sampling strategy selectively increases surfel density in contact regions to handle heavy occlusion. Extensive experiments demonstrate that DyTact not only achieves state-of-the-art dynamic contact estimation accuracy but also significantly improves novel view synthesis quality, all while operating with fast optimization and efficient memory usage. Project Page: https://oliver-cong02.github.io/DyTact.github.io/ .","authors":["Xiaoyan Cong","Angela Xing","Chandradeep Pokhariya","Rao Fu","Srinath Sridhar"],"url":"https://arxiv.org/abs/2506.03103"}
{"created":"2025-06-04","title":"Detecting Patterns of Interaction in Temporal Hypergraphs via Edge Clustering","abstract":"Finding densely connected subsets of vertices in an unsupervised setting, called clustering or community detection, is one of the fundamental problems in network science. The edge clustering approach instead detects communities by clustering the edges of the graph and then assigning a vertex to a community if it has at least one edge in that community, thereby allowing for overlapping clusters of vertices. We apply the idea behind edge clustering to temporal hypergraphs, an extension of a graph where a single edge can contain any number of vertices and each edge has a timestamp. Extending to hypergraphs allows for many different patterns of interaction between edges, and by defining a suitable structural similarity function, our edge clustering algorithm can find clusters of these patterns. We test the algorithm with three structural similarity functions on a large collaboration hypergraph, and find intuitive cluster structures that could prove useful for downstream tasks.","authors":["Ryan DeWolfe","Fran\\c{c}ois Th\\'eberge"],"url":"https://arxiv.org/abs/2506.03105"}
{"created":"2025-06-04","title":"Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback","abstract":"Recent advances in reinforcement learning (RL) with numerical feedback, such as scalar rewards, have significantly enhanced the complex reasoning capabilities of large language models (LLMs). Despite this success, we identify three key challenges encountered by RL with solely numerical feedback: performance plateaus, limited effectiveness of self-reflection, and persistent failures. We then demonstrate that RL-finetuned models, even after exhibiting performance plateaus, can generate correct refinements on persistently failed problems by leveraging natural language feedback in the form of critiques. Building on this insight, we propose Critique-GRPO, an online RL framework that integrates both natural language and numerical feedback for effective policy optimization. Critique-GRPO enables LLMs to learn from initial responses and critique-guided refinements simultaneously while maintaining exploration. Extensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that Critique-GRPO consistently outperforms supervised learning-based and RL-based fine-tuning approaches across eight challenging mathematical, STEM, and general reasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%, respectively. Notably, Critique-GRPO surpasses a strong baseline that incorporates expert demonstrations within online RL. Further analysis reveals two critical insights about policy exploration: (1) higher entropy does not always guarantee efficient learning from exploration, and (2) longer responses do not necessarily lead to more effective exploration.","authors":["Xiaoying Zhang","Hao Sun","Yipeng Zhang","Kaituo Feng","Chao Yang","Helen Meng"],"url":"https://arxiv.org/abs/2506.03106"}
{"created":"2025-06-04","title":"ByteMorph: Benchmarking Instruction-Guided Image Editing with Non-Rigid Motions","abstract":"Editing images with instructions to reflect non-rigid motions, camera viewpoint shifts, object deformations, human articulations, and complex interactions, poses a challenging yet underexplored problem in computer vision. Existing approaches and datasets predominantly focus on static scenes or rigid transformations, limiting their capacity to handle expressive edits involving dynamic motion. To address this gap, we introduce ByteMorph, a comprehensive framework for instruction-based image editing with an emphasis on non-rigid motions. ByteMorph comprises a large-scale dataset, ByteMorph-6M, and a strong baseline model built upon the Diffusion Transformer (DiT), named ByteMorpher. ByteMorph-6M includes over 6 million high-resolution image editing pairs for training, along with a carefully curated evaluation benchmark ByteMorph-Bench. Both capture a wide variety of non-rigid motion types across diverse environments, human figures, and object categories. The dataset is constructed using motion-guided data generation, layered compositing techniques, and automated captioning to ensure diversity, realism, and semantic coherence. We further conduct a comprehensive evaluation of recent instruction-based image editing methods from both academic and commercial domains.","authors":["Di Chang","Mingdeng Cao","Yichun Shi","Bo Liu","Shengqu Cai","Shijie Zhou","Weilin Huang","Gordon Wetzstein","Mohammad Soleymani","Peng Wang"],"url":"https://arxiv.org/abs/2506.03107"}
{"created":"2025-06-04","title":"On Weak-to-Strong Generalization and f-Divergence","abstract":"Weak-to-strong generalization (W2SG) has emerged as a promising paradigm for stimulating the capabilities of strong pre-trained models by leveraging supervision from weaker supervisors. To improve the performance of the strong model, existing methods often require additional weak models or complex procedures, leading to substantial computational and memory overhead. Motivated by the effectiveness of $f$-divergence loss in various machine learning domains, we introduce $f$-divergence as an information-theoretic loss function framework in W2SG. Our theoretical analysis reveals fundamental limitations and equivalence of different $f$-divergence losses in W2SG, supported by sample complexity bounds and information-theoretic insights. We empirically demonstrate that $f$-divergence loss, which generalizes widely-used metrics like KL divergence, effectively improves generalization and noise tolerance of the strong model in practice.","authors":["Wei Yao","Gengze Xu","Huayi Tang","Wenkai Yang","Donglin Di","Ziqiao Wang","Yong Liu"],"url":"https://arxiv.org/abs/2506.03109"}
{"created":"2025-06-04","title":"Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning","abstract":"Vision Transformer (ViT) has achieved remarkable success due to its large-scale pretraining on general domains, but it still faces challenges when applying it to downstream distant domains that have only scarce training data, which gives rise to the Cross-Domain Few-Shot Learning (CDFSL) task. Inspired by Self-Attention's insensitivity to token orders, we find an interesting phenomenon neglected in current works: disrupting the continuity of image tokens (i.e., making pixels not smoothly transited across patches) in ViT leads to a noticeable performance decline in the general (source) domain but only a marginal decrease in downstream target domains. This questions the role of image tokens' continuity in ViT's generalization under large domain gaps. In this paper, we delve into this phenomenon for an interpretation. We find continuity aids ViT in learning larger spatial patterns, which are harder to transfer than smaller ones, enlarging domain distances. Meanwhile, it implies that only smaller patterns within each patch could be transferred under extreme domain gaps. Based on this interpretation, we further propose a simple yet effective method for CDFSL that better disrupts the continuity of image tokens, encouraging the model to rely less on large patterns and more on smaller ones. Extensive experiments show the effectiveness of our method in reducing domain gaps and outperforming state-of-the-art works. Codes and models are available at https://github.com/shuaiyi308/ReCIT.","authors":["Shuai Yi","Yixiong Zou","Yuhua Li","Ruixuan Li"],"url":"https://arxiv.org/abs/2506.03110"}
{"created":"2025-06-04","title":"Rectified Flows for Fast Multiscale Fluid Flow Modeling","abstract":"The statistical modeling of fluid flows is very challenging due to their multiscale dynamics and extreme sensitivity to initial conditions. While recently proposed conditional diffusion models achieve high fidelity, they typically require hundreds of stochastic sampling steps at inference. We introduce a rectified flow framework that learns a time-dependent velocity field, transporting input to output distributions along nearly straight trajectories. By casting sampling as solving an ordinary differential equation (ODE) along this straighter flow field, our method makes each integration step much more effective, using as few as eight steps versus (more than) 128 steps in standard score-based diffusion, without sacrificing predictive fidelity. Experiments on challenging multiscale flow benchmarks show that rectified flows recover the same posterior distributions as diffusion models, preserve fine-scale features that MSE-trained baselines miss, and deliver high-resolution samples in a fraction of inference time.","authors":["Victor Armegioiu","Yannick Ramic","Siddhartha Mishra"],"url":"https://arxiv.org/abs/2506.03111"}
{"created":"2025-06-04","title":"Assessing Workers Neuro-physiological Stress Responses to Augmented Reality Safety Warnings in Immersive Virtual Roadway Work Zones","abstract":"This paper presents a multi-stage experimental framework that integrates immersive Virtual Reality (VR) simulations, wearable sensors, and advanced signal processing to investigate construction workers neuro-physiological stress responses to multi-sensory AR-enabled warnings. Participants performed light- and moderate-intensity roadway maintenance tasks within a high-fidelity VR roadway work zone, while key stress markers of electrodermal activity (EDA), heart rate variability (HRV), and electroencephalography (EEG) were continuously measured. Statistical analyses revealed that task intensity significantly influenced physiological and neurological stress indicators. Moderate-intensity tasks elicited greater autonomic arousal, evidenced by elevated heart rate measures (mean-HR, std-HR, max-HR) and stronger electrodermal responses, while EEG data indicated distinct stress-related alpha suppression and beta enhancement. Feature-importance analysis further identified mean EDR and short-term HR metrics as discriminative for classifying task intensity. Correlation results highlighted a temporal lag between immediate neural changes and subsequent physiological stress reactions, emphasizing the interplay between cognition and autonomic regulation during hazardous tasks.","authors":["Fatemeh Banani Ardecani","Omidreza Shoghli"],"url":"https://arxiv.org/abs/2506.03113"}
{"created":"2025-06-04","title":"Zero-Shot Tree Detection and Segmentation from Aerial Forest Imagery","abstract":"Large-scale delineation of individual trees from remote sensing imagery is crucial to the advancement of ecological research, particularly as climate change and other environmental factors rapidly transform forest landscapes across the world. Current RGB tree segmentation methods rely on training specialized machine learning models with labeled tree datasets. While these learning-based approaches can outperform manual data collection when accurate, the existing models still depend on training data that's hard to scale. In this paper, we investigate the efficacy of using a state-of-the-art image segmentation model, Segment Anything Model 2 (SAM2), in a zero-shot manner for individual tree detection and segmentation. We evaluate a pretrained SAM2 model on two tasks in this domain: (1) zero-shot segmentation and (2) zero-shot transfer by using predictions from an existing tree detection model as prompts. Our results suggest that SAM2 not only has impressive generalization capabilities, but also can form a natural synergy with specialized methods trained on in-domain labeled data. We find that applying large pretrained models to problems in remote sensing is a promising avenue for future progress. We make our code available at: https://github.com/open-forest-observatory/tree-detection-framework.","authors":["Michelle Chen","David Russell","Amritha Pallavoor","Derek Young","Jane Wu"],"url":"https://arxiv.org/abs/2506.03114"}
{"created":"2025-06-04","title":"Targeted Forgetting of Image Subgroups in CLIP Models","abstract":"Foundation models (FMs) such as CLIP have demonstrated impressive zero-shot performance across various tasks by leveraging large-scale, unsupervised pre-training. However, they often inherit harmful or unwanted knowledge from noisy internet-sourced datasets, compromising their reliability in real-world applications. Existing model unlearning methods either rely on access to pre-trained datasets or focus on coarse-grained unlearning (e.g., entire classes), leaving a critical gap for fine-grained unlearning. In this paper, we address the challenging scenario of selectively forgetting specific portions of knowledge within a class, without access to pre-trained data, while preserving the model's overall performance. We propose a novel three-stage approach that progressively unlearns targeted knowledge while mitigating over-forgetting. It consists of (1) a forgetting stage to fine-tune the CLIP on samples to be forgotten, (2) a reminding stage to restore performance on retained samples, and (3) a restoring stage to recover zero-shot capabilities using model souping. Additionally, we introduce knowledge distillation to handle the distribution disparity between forgetting, retaining samples, and unseen pre-trained data. Extensive experiments on CIFAR-10, ImageNet-1K, and style datasets demonstrate that our approach effectively unlearns specific subgroups while maintaining strong zero-shot performance on semantically similar subgroups and other categories, significantly outperforming baseline unlearning methods, which lose effectiveness under the CLIP unlearning setting.","authors":["Zeliang Zhang","Gaowen Liu","Charles Fleming","Ramana Rao Kompella","Chenliang Xu"],"url":"https://arxiv.org/abs/2506.03117"}
{"created":"2025-06-04","title":"HumanRAM: Feed-forward Human Reconstruction and Animation Model using Transformers","abstract":"3D human reconstruction and animation are long-standing topics in computer graphics and vision. However, existing methods typically rely on sophisticated dense-view capture and/or time-consuming per-subject optimization procedures. To address these limitations, we propose HumanRAM, a novel feed-forward approach for generalizable human reconstruction and animation from monocular or sparse human images. Our approach integrates human reconstruction and animation into a unified framework by introducing explicit pose conditions, parameterized by a shared SMPL-X neural texture, into transformer-based large reconstruction models (LRM). Given monocular or sparse input images with associated camera parameters and SMPL-X poses, our model employs scalable transformers and a DPT-based decoder to synthesize realistic human renderings under novel viewpoints and novel poses. By leveraging the explicit pose conditions, our model simultaneously enables high-quality human reconstruction and high-fidelity pose-controlled animation. Experiments show that HumanRAM significantly surpasses previous methods in terms of reconstruction accuracy, animation fidelity, and generalization performance on real-world datasets. Video results are available at https://zju3dv.github.io/humanram/.","authors":["Zhiyuan Yu","Zhe Li","Hujun Bao","Can Yang","Xiaowei Zhou"],"url":"https://arxiv.org/abs/2506.03118"}
{"created":"2025-06-04","title":"Controllable Human-centric Keyframe Interpolation with Generative Prior","abstract":"Existing interpolation methods use pre-trained video diffusion priors to generate intermediate frames between sparsely sampled keyframes. In the absence of 3D geometric guidance, these methods struggle to produce plausible results for complex, articulated human motions and offer limited control over the synthesized dynamics. In this paper, we introduce PoseFuse3D Keyframe Interpolator (PoseFuse3D-KI), a novel framework that integrates 3D human guidance signals into the diffusion process for Controllable Human-centric Keyframe Interpolation (CHKI). To provide rich spatial and structural cues for interpolation, our PoseFuse3D, a 3D-informed control model, features a novel SMPL-X encoder that transforms 3D geometry and shape into the 2D latent conditioning space, alongside a fusion network that integrates these 3D cues with 2D pose embeddings. For evaluation, we build CHKI-Video, a new dataset annotated with both 2D poses and 3D SMPL-X parameters. We show that PoseFuse3D-KI consistently outperforms state-of-the-art baselines on CHKI-Video, achieving a 9% improvement in PSNR and a 38% reduction in LPIPS. Comprehensive ablations demonstrate that our PoseFuse3D model improves interpolation fidelity.","authors":["Zujin Guo","Size Wu","Zhongang Cai","Wei Li","Chen Change Loy"],"url":"https://arxiv.org/abs/2506.03119"}
{"created":"2025-06-04","title":"AUTOCIRCUIT-RL: Reinforcement Learning-Driven LLM for Automated Circuit Topology Generation","abstract":"Analog circuit topology synthesis is integral to Electronic Design Automation (EDA), enabling the automated creation of circuit structures tailored to specific design requirements. However, the vast design search space and strict constraint adherence make efficient synthesis challenging. Leveraging the versatility of Large Language Models (LLMs), we propose AUTOCIRCUIT-RL,a novel reinforcement learning (RL)-based framework for automated analog circuit synthesis. The framework operates in two phases: instruction tuning, where an LLM learns to generate circuit topologies from structured prompts encoding design constraints, and RL refinement, which further improves the instruction-tuned model using reward models that evaluate validity, efficiency, and output voltage. The refined model is then used directly to generate topologies that satisfy the design constraints. Empirical results show that AUTOCIRCUIT-RL generates ~12% more valid circuits and improves efficiency by ~14% compared to the best baselines, while reducing duplicate generation rates by ~38%. It achieves over 60% success in synthesizing valid circuits with limited training data, demonstrating strong generalization. These findings highlight the framework's effectiveness in scaling to complex circuits while maintaining efficiency and constraint adherence, marking a significant advancement in AI-driven circuit design.","authors":["Prashanth Vijayaraghavan","Luyao Shi","Ehsan Degan","Vandana Mukherjee","Xin Zhang"],"url":"https://arxiv.org/abs/2506.03122"}
{"created":"2025-06-04","title":"DCM: Dual-Expert Consistency Model for Efficient and High-Quality Video Generation","abstract":"Diffusion Models have achieved remarkable results in video synthesis but require iterative denoising steps, leading to substantial computational overhead. Consistency Models have made significant progress in accelerating diffusion models. However, directly applying them to video diffusion models often results in severe degradation of temporal consistency and appearance details. In this paper, by analyzing the training dynamics of Consistency Models, we identify a key conflicting learning dynamics during the distillation process: there is a significant discrepancy in the optimization gradients and loss contributions across different timesteps. This discrepancy prevents the distilled student model from achieving an optimal state, leading to compromised temporal consistency and degraded appearance details. To address this issue, we propose a parameter-efficient \\textbf{Dual-Expert Consistency Model~(DCM)}, where a semantic expert focuses on learning semantic layout and motion, while a detail expert specializes in fine detail refinement. Furthermore, we introduce Temporal Coherence Loss to improve motion consistency for the semantic expert and apply GAN and Feature Matching Loss to enhance the synthesis quality of the detail expert.Our approach achieves state-of-the-art visual quality with significantly reduced sampling steps, demonstrating the effectiveness of expert specialization in video diffusion model distillation. Our code and models are available at \\href{https://github.com/Vchitect/DCM}{https://github.com/Vchitect/DCM}.","authors":["Zhengyao Lv","Chenyang Si","Tianlin Pan","Zhaoxi Chen","Kwan-Yee K. Wong","Yu Qiao","Ziwei Liu"],"url":"https://arxiv.org/abs/2506.03123"}
{"created":"2025-06-04","title":"AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation","abstract":"Recent advances in AI-generated content (AIGC) have significantly accelerated animation production. To produce engaging animations, it is essential to generate coherent multi-shot video clips with narrative scripts and character references. However, existing public datasets primarily focus on real-world scenarios with global descriptions, and lack reference images for consistent character guidance. To bridge this gap, we present AnimeShooter, a reference-guided multi-shot animation dataset. AnimeShooter features comprehensive hierarchical annotations and strong visual consistency across shots through an automated pipeline. Story-level annotations provide an overview of the narrative, including the storyline, key scenes, and main character profiles with reference images, while shot-level annotations decompose the story into consecutive shots, each annotated with scene, characters, and both narrative and descriptive visual captions. Additionally, a dedicated subset, AnimeShooter-audio, offers synchronized audio tracks for each shot, along with audio descriptions and sound sources. To demonstrate the effectiveness of AnimeShooter and establish a baseline for the reference-guided multi-shot video generation task, we introduce AnimeShooterGen, which leverages Multimodal Large Language Models (MLLMs) and video diffusion models. The reference image and previously generated shots are first processed by MLLM to produce representations aware of both reference and context, which are then used as the condition for the diffusion model to decode the subsequent shot. Experimental results show that the model trained on AnimeShooter achieves superior cross-shot visual consistency and adherence to reference visual guidance, which highlight the value of our dataset for coherent animated video generation.","authors":["Lu Qiu","Yizhuo Li","Yuying Ge","Yixiao Ge","Ying Shan","Xihui Liu"],"url":"https://arxiv.org/abs/2506.03126"}
{"created":"2025-06-04","title":"Zero-Shot Time Series Forecasting with Covariates via In-Context Learning","abstract":"Pretrained time series models, capable of zero-shot forecasting, have demonstrated significant potential in enhancing both the performance and accessibility of time series forecasting. However, existing pretrained models either do not support covariates or fail to incorporate them effectively. We introduce COSMIC, a zero-shot forecasting model that utilizes covariates via in-context learning. To address the challenge of data scarcity, we propose Informative Covariate Augmentation, which enables the training of COSMIC without requiring any datasets that include covariates. COSMIC achieves state-of-the-art performance in zero-shot forecasting, both with and without covariates. Our quantitative and qualitative analysis demonstrates that COSMIC effectively leverages covariates in zero-shot forecasting.","authors":["Andreas Auer","Raghul Parthipan","Pedro Mercado","Abdul Fatir Ansari","Lorenzo Stella","Bernie Wang","Michael Bohlke-Schneider","Syama Sundar Rangapuram"],"url":"https://arxiv.org/abs/2506.03128"}
{"created":"2025-06-04","title":"Native-Resolution Image Synthesis","abstract":"We introduce native-resolution image synthesis, a novel generative modeling paradigm that enables the synthesis of images at arbitrary resolutions and aspect ratios. This approach overcomes the limitations of conventional fixed-resolution, square-image methods by natively handling variable-length visual tokens, a core challenge for traditional techniques. To this end, we introduce the Native-resolution diffusion Transformer (NiT), an architecture designed to explicitly model varying resolutions and aspect ratios within its denoising process. Free from the constraints of fixed formats, NiT learns intrinsic visual distributions from images spanning a broad range of resolutions and aspect ratios. Notably, a single NiT model simultaneously achieves the state-of-the-art performance on both ImageNet-256x256 and 512x512 benchmarks. Surprisingly, akin to the robust zero-shot capabilities seen in advanced large language models, NiT, trained solely on ImageNet, demonstrates excellent zero-shot generalization performance. It successfully generates high-fidelity images at previously unseen high resolutions (e.g., 1536 x 1536) and diverse aspect ratios (e.g., 16:9, 3:1, 4:3), as shown in Figure 1. These findings indicate the significant potential of native-resolution modeling as a bridge between visual generative modeling and advanced LLM methodologies.","authors":["Zidong Wang","Lei Bai","Xiangyu Yue","Wanli Ouyang","Yiyuan Zhang"],"url":"https://arxiv.org/abs/2506.03131"}
{"created":"2025-06-04","title":"PoLAR: Polar-Decomposed Low-Rank Adapter Representation","abstract":"We show that low-rank adaptation of large-scale models suffers from a low stable rank that is well below the linear algebraic rank of the subspace, degrading fine-tuning performance. To mitigate the underutilization of the allocated subspace, we propose PoLAR, a parameterization inspired by the polar decomposition that factorizes the low-rank update into two direction matrices constrained to Stiefel manifolds and an unconstrained scale matrix. Our theory shows that PoLAR yields an exponentially faster convergence rate on a canonical low-rank adaptation problem. Pairing the parameterization with Riemannian optimization leads to consistent gains on three different benchmarks testing general language understanding, commonsense reasoning, and mathematical problem solving with base model sizes ranging from 350M to 27B.","authors":["Kai Lion","Liang Zhang","Bingcong Li","Niao He"],"url":"https://arxiv.org/abs/2506.03133"}
{"created":"2025-06-04","title":"OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models","abstract":"Spatial reasoning is a key aspect of cognitive psychology and remains a major bottleneck for current vision-language models (VLMs). While extensive research has aimed to evaluate or improve VLMs' understanding of basic spatial relations, such as distinguishing left from right, near from far, and object counting, these tasks represent only the most fundamental level of spatial reasoning. In this work, we introduce OmniSpatial, a comprehensive and challenging benchmark for spatial reasoning, grounded in cognitive psychology. OmniSpatial covers four major categories: dynamic reasoning, complex spatial logic, spatial interaction, and perspective-taking, with 50 fine-grained subcategories. Through Internet data crawling and careful manual annotation, we construct over 1.5K question-answer pairs. Extensive experiments show that both open- and closed-source VLMs, as well as existing reasoning and spatial understanding models, exhibit significant limitations in comprehensive spatial understanding. We further analyze failure cases and propose potential directions for future research.","authors":["Mengdi Jia","Zekun Qi","Shaochen Zhang","Wenyao Zhang","Xinqiang Yu","Jiawei He","He Wang","Li Yi"],"url":"https://arxiv.org/abs/2506.03135"}
{"created":"2025-06-04","title":"Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning","abstract":"We propose CURE, a novel reinforcement learning framework with a dedicated reward design that co-evolves coding and unit test generation capabilities based on their interaction outcomes, without any ground-truth code as supervision. This approach enables flexible and scalable training and allows the unit tester to learn directly from the coder's mistakes. Our derived ReasonFlux-Coder-7B and 14B models improve code generation accuracy by 5.3% and Best-of-N accuracy by 9.0% after optimization on Qwen2.5-Instruct models, outperforming similarly sized Qwen-Coder, DeepSeek-Coder, and Seed-Coder. They naturally extend to downstream tasks such as test-time scaling and agentic coding-achieving a 8.1% improvement over the base model. For the long-CoT model, our ReasonFlux-Coder-4B consistently outperforms Qwen3-4B while achieving 64.8% inference efficiency in unit test generation. Notably, we also find that our model can serve as an effective reward model for reinforcement learning on base models. Project: https://github.com/Gen-Verse/CURE","authors":["Yinjie Wang","Ling Yang","Ye Tian","Ke Shen","Mengdi Wang"],"url":"https://arxiv.org/abs/2506.03136"}
{"created":"2025-06-04","title":"SVGenius: Benchmarking LLMs in SVG Understanding, Editing and Generation","abstract":"Large Language Models (LLMs) and Multimodal LLMs have shown promising capabilities for SVG processing, yet existing benchmarks suffer from limited real-world coverage, lack of complexity stratification, and fragmented evaluation paradigms. We introduce SVGenius, a comprehensive benchmark comprising 2,377 queries across three progressive dimensions: understanding, editing, and generation. Built on real-world data from 24 application domains with systematic complexity stratification, SVGenius evaluates models through 8 task categories and 18 metrics. We assess 22 mainstream models spanning different scales, architectures, training paradigms, and accessibility levels. Our analysis reveals that while proprietary models significantly outperform open-source counterparts, all models exhibit systematic performance degradation with increasing complexity, indicating fundamental limitations in current approaches; however, reasoning-enhanced training proves more effective than pure scaling for overcoming these limitations, though style transfer remains the most challenging capability across all model types. SVGenius establishes the first systematic evaluation framework for SVG processing, providing crucial insights for developing more capable vector graphics models and advancing automated graphic design applications. Appendix and supplementary materials (including all data and code) are available at https://zju-real.github.io/SVGenius.","authors":["Siqi Chen","Xinyu Dong","Haolei Xu","Xingyu Wu","Fei Tang","Hang Zhang","Yuchen Yan","Linjuan Wu","Wenqi Zhang","Guiyang Hou","Yongliang Shen","Weiming Lu","Yueting Zhuang"],"url":"https://arxiv.org/abs/2506.03139"}
{"created":"2025-06-04","title":"CamCloneMaster: Enabling Reference-based Camera Control for Video Generation","abstract":"Camera control is crucial for generating expressive and cinematic videos. Existing methods rely on explicit sequences of camera parameters as control conditions, which can be cumbersome for users to construct, particularly for intricate camera movements. To provide a more intuitive camera control method, we propose CamCloneMaster, a framework that enables users to replicate camera movements from reference videos without requiring camera parameters or test-time fine-tuning. CamCloneMaster seamlessly supports reference-based camera control for both Image-to-Video and Video-to-Video tasks within a unified framework. Furthermore, we present the Camera Clone Dataset, a large-scale synthetic dataset designed for camera clone learning, encompassing diverse scenes, subjects, and camera movements. Extensive experiments and user studies demonstrate that CamCloneMaster outperforms existing methods in terms of both camera controllability and visual quality.","authors":["Yawen Luo","Jianhong Bai","Xiaoyu Shi","Menghan Xia","Xintao Wang","Pengfei Wan","Di Zhang","Kun Gai","Tianfan Xue"],"url":"https://arxiv.org/abs/2506.03140"}
{"created":"2025-06-04","title":"Context as Memory: Scene-Consistent Interactive Long Video Generation with Memory Retrieval","abstract":"Recent advances in interactive video generation have shown promising results, yet existing approaches struggle with scene-consistent memory capabilities in long video generation due to limited use of historical context. In this work, we propose Context-as-Memory, which utilizes historical context as memory for video generation. It includes two simple yet effective designs: (1) storing context in frame format without additional post-processing; (2) conditioning by concatenating context and frames to be predicted along the frame dimension at the input, requiring no external control modules. Furthermore, considering the enormous computational overhead of incorporating all historical context, we propose the Memory Retrieval module to select truly relevant context frames by determining FOV (Field of View) overlap between camera poses, which significantly reduces the number of candidate frames without substantial information loss. Experiments demonstrate that Context-as-Memory achieves superior memory capabilities in interactive long video generation compared to SOTAs, even generalizing effectively to open-domain scenarios not seen during training. The link of our project page is https://context-as-memory.github.io/.","authors":["Jiwen Yu","Jianhong Bai","Yiran Qin","Quande Liu","Xintao Wang","Pengfei Wan","Di Zhang","Xihui Liu"],"url":"https://arxiv.org/abs/2506.03141"}
{"created":"2025-06-04","title":"Not All Tokens Are Meant to Be Forgotten","abstract":"Large Language Models (LLMs), pre-trained on massive text corpora, exhibit remarkable human-level language understanding, reasoning, and decision-making abilities. However, they tend to memorize unwanted information, such as private or copyrighted content, raising significant privacy and legal concerns. Unlearning has emerged as a promising solution, but existing methods face a significant challenge of over-forgetting. This issue arises because they indiscriminately suppress the generation of all the tokens in forget samples, leading to a substantial loss of model utility. To overcome this challenge, we introduce the Targeted Information Forgetting (TIF) framework, which consists of (1) a flexible targeted information identifier designed to differentiate between unwanted words (UW) and general words (GW) in the forget samples, and (2) a novel Targeted Preference Optimization approach that leverages Logit Preference Loss to unlearn unwanted information associated with UW and Preservation Loss to retain general information in GW, effectively improving the unlearning process while mitigating utility degradation. Extensive experiments on the TOFU and MUSE benchmarks demonstrate that the proposed TIF framework enhances unlearning effectiveness while preserving model utility and achieving state-of-the-art results.","authors":["Xiangyu Zhou","Yao Qiang","Saleh Zare Zade","Douglas Zytko","Prashant Khanduri","Dongxiao Zhu"],"url":"https://arxiv.org/abs/2506.03142"}
{"created":"2025-06-04","title":"GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents","abstract":"One of the principal challenges in building VLM-powered GUI agents is visual grounding, i.e., localizing the appropriate screen region for action execution based on both the visual content and the textual plans. Most existing work formulates this as a text-based coordinate generation task. However, these approaches suffer from several limitations: weak spatial-semantic alignment, inability to handle ambiguous supervision targets, and a mismatch between the dense nature of screen coordinates and the coarse, patch-level granularity of visual features extracted by models like Vision Transformers. In this paper, we propose GUI-Actor, a VLM-based method for coordinate-free GUI grounding. At its core, GUI-Actor introduces an attention-based action head that learns to align a dedicated  token with all relevant visual patch tokens, enabling the model to propose one or more action regions in a single forward pass. In line with this, we further design a grounding verifier to evaluate and select the most plausible action region from the candidates proposed for action execution. Extensive experiments show that GUI-Actor outperforms prior state-of-the-art methods on multiple GUI action grounding benchmarks, with improved generalization to unseen screen resolutions and layouts. Notably, GUI-Actor-7B even surpasses UI-TARS-72B (38.1) on ScreenSpot-Pro, achieving scores of 40.7 with Qwen2-VL and 44.6 with Qwen2.5-VL as backbones. Furthermore, by incorporating the verifier, we find that fine-tuning only the newly introduced action head (~100M parameters for 7B model) while keeping the VLM backbone frozen is sufficient to achieve performance comparable to previous state-of-the-art models, highlighting that GUI-Actor can endow the underlying VLM with effective grounding capabilities without compromising its general-purpose strengths.","authors":["Qianhui Wu","Kanzhi Cheng","Rui Yang","Chaoyun Zhang","Jianwei Yang","Huiqiang Jiang","Jian Mu","Baolin Peng","Bo Qiao","Reuben Tan","Si Qin","Lars Liden","Qingwei Lin","Huan Zhang","Tong Zhang","Jianbing Zhang","Dongmei Zhang","Jianfeng Gao"],"url":"https://arxiv.org/abs/2506.03143"}
{"created":"2025-06-04","title":"MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query","abstract":"Semantic retrieval is crucial for modern applications yet remains underexplored in current research. Existing datasets are limited to single languages, single images, or singular retrieval conditions, often failing to fully exploit the expressive capacity of visual information as evidenced by maintained performance when images are replaced with captions. However, practical retrieval scenarios frequently involve interleaved multi-condition queries with multiple images. Hence, this paper introduces MERIT, the first multilingual dataset for interleaved multi-condition semantic retrieval, comprising 320,000 queries with 135,000 products in 5 languages, covering 7 distinct product categories. Extensive experiments on MERIT identify existing models's limitation: focusing solely on global semantic information while neglecting specific conditional elements in queries. Consequently, we propose Coral, a novel fine-tuning framework that adapts pre-trained MLLMs by integrating embedding reconstruction to preserve fine-grained conditional elements and contrastive learning to extract comprehensive global semantics. Experiments demonstrate that Coral achieves a 45.9% performance improvement over conventional approaches on MERIT, with strong generalization capabilities validated across 8 established retrieval benchmarks. Collectively, our contributions - a novel dataset, identification of critical limitations in existing approaches, and an innovative fine-tuning framework - establish a foundation for future research in interleaved multi-condition semantic retrieval.","authors":["Wei Chow","Yuan Gao","Linfeng Li","Xian Wang","Qi Xu","Hang Song","Lingdong Kong","Ran Zhou","Yi Zeng","Yidong Cai","Botian Jiang","Shilin Xu","Jiajun Zhang","Minghui Qiu","Xiangtai Li","Tianshu Yang","Siliang Tang","Juncheng Li"],"url":"https://arxiv.org/abs/2506.03144"}
{"created":"2025-06-04","title":"Entity-Augmented Neuroscience Knowledge Retrieval Using Ontology and Semantic Understanding Capability of LLM","abstract":"Neuroscience research publications encompass a vast wealth of knowledge. Accurately retrieving existing information and discovering new insights from this extensive literature is essential for advancing the field. However, when knowledge is dispersed across multiple sources, current state-of-the-art retrieval methods often struggle to extract the necessary information. A knowledge graph (KG) can integrate and link knowledge from multiple sources, but existing methods for constructing KGs in neuroscience often rely on labeled data and require domain expertise. Acquiring large-scale, labeled data for a specialized area like neuroscience presents significant challenges. This work proposes novel methods for constructing KG from unlabeled large-scale neuroscience research corpus utilizing large language models (LLM), neuroscience ontology, and text embeddings. We analyze the semantic relevance of neuroscience text segments identified by LLM for building the knowledge graph. We also introduce an entity-augmented information retrieval algorithm to extract knowledge from the KG. Several experiments were conducted to evaluate the proposed approaches, and the results demonstrate that our methods significantly enhance knowledge discovery from the unlabeled neuroscience research corpus. It achieves an F1 score of 0.84 for entity extraction, and the knowledge obtained from the KG improves answers to over 54% of the questions.","authors":["Pralaypati Ta","Sriram Venkatesaperumal","Keerthi Ram","Mohanasankar Sivaprakasam"],"url":"https://arxiv.org/abs/2506.03145"}
{"created":"2025-06-04","title":"UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation","abstract":"Although existing unified models deliver strong performance on vision-language understanding and text-to-image generation, their models are limited in exploring image perception and manipulation tasks, which are urgently desired by users for wide applications. Recently, OpenAI released their powerful GPT-4o-Image model for comprehensive image perception and manipulation, achieving expressive capability and attracting community interests. By observing the performance of GPT-4o-Image in our carefully constructed experiments, we infer that GPT-4o-Image leverages features extracted by semantic encoders instead of VAE, while VAEs are considered essential components in many image manipulation models. Motivated by such inspiring observations, we present a unified generative framework named UniWorld based on semantic features provided by powerful visual-language models and contrastive semantic encoders. As a result, we build a strong unified model using only 1% amount of BAGEL's data, which consistently outperforms BAGEL on image editing benchmarks. UniWorld also maintains competitive image understanding and generation capabilities, achieving strong performance across multiple image perception tasks. We fully open-source our models, including model weights, training and evaluation scripts, and datasets.","authors":["Bin Lin","Zongjian Li","Xinhua Cheng","Yuwei Niu","Yang Ye","Xianyi He","Shenghai Yuan","Wangbo Yu","Shaodong Wang","Yunyang Ge","Yatian Pang","Li Yuan"],"url":"https://arxiv.org/abs/2506.03147"}
{"created":"2025-06-04","title":"Self-Supervised Spatial Correspondence Across Modalities","abstract":"We present a method for finding cross-modal space-time correspondences. Given two images from different visual modalities, such as an RGB image and a depth map, our model identifies which pairs of pixels correspond to the same physical points in the scene. To solve this problem, we extend the contrastive random walk framework to simultaneously learn cycle-consistent feature representations for both cross-modal and intra-modal matching. The resulting model is simple and has no explicit photo-consistency assumptions. It can be trained entirely using unlabeled data, without the need for any spatially aligned multimodal image pairs. We evaluate our method on both geometric and semantic correspondence tasks. For geometric matching, we consider challenging tasks such as RGB-to-depth and RGB-to-thermal matching (and vice versa); for semantic matching, we evaluate on photo-sketch and cross-style image alignment. Our method achieves strong performance across all benchmarks.","authors":["Ayush Shrivastava","Andrew Owens"],"url":"https://arxiv.org/abs/2506.03148"}
{"created":"2025-06-04","title":"Causal Estimation of Tokenisation Bias","abstract":"Modern language models are typically trained over subword sequences, but ultimately define probabilities over character-strings. Ideally, the choice of the tokeniser -- which maps character-strings to subwords -- should not affect the probability assigned to the underlying character-string; in practice, it does. We define this mismatch as tokenisation bias. In this work, we quantify one particular type of tokenisation bias: the effect of including or not a subword (e.g., $\\langle hello \\rangle$) in a tokeniser's vocabulary on the probability a trained model assigns to the corresponding characters (i.e., \\textit{``hello''}). Estimating this effect is challenging because each model is trained with only one tokeniser. We address this by framing tokenisation bias as a causal effect and estimating it using the regression discontinuity design. Specifically, we exploit the fact that tokenisation algorithms rank subwords and add the first $K$ to a tokeniser's vocabulary, where $K$ is an arbitrary cutoff point. As such, we can estimate a causal effect by comparing similar subwords around this cutoff. Experimentally, we find that tokenisation consistently affects models' outputs across scales, vocabularies, and tokenisers. Notably, a subword's presence in a small model's vocabulary may increase its characters' probability by up to 17 times, highlighting tokenisation as a key design choice in language modelling.","authors":["Pietro Lesci","Clara Meister","Thomas Hofmann","Andreas Vlachos","Tiago Pimentel"],"url":"https://arxiv.org/abs/2506.03149"}
{"created":"2025-06-04","title":"IllumiCraft: Unified Geometry and Illumination Diffusion for Controllable Video Generation","abstract":"Although diffusion-based models can generate high-quality and high-resolution video sequences from textual or image inputs, they lack explicit integration of geometric cues when controlling scene lighting and visual appearance across frames. To address this limitation, we propose IllumiCraft, an end-to-end diffusion framework accepting three complementary inputs: (1) high-dynamic-range (HDR) video maps for detailed lighting control; (2) synthetically relit frames with randomized illumination changes (optionally paired with a static background reference image) to provide appearance cues; and (3) 3D point tracks that capture precise 3D geometry information. By integrating the lighting, appearance, and geometry cues within a unified diffusion architecture, IllumiCraft generates temporally coherent videos aligned with user-defined prompts. It supports background-conditioned and text-conditioned video relighting and provides better fidelity than existing controllable video generation methods. Project Page: https://yuanze-lin.me/IllumiCraft_page","authors":["Yuanze Lin","Yi-Wen Chen","Yi-Hsuan Tsai","Ronald Clark","Ming-Hsuan Yang"],"url":"https://arxiv.org/abs/2506.03150"}
{"created":"2025-06-04","title":"Singing Voice Graph Modeling for SingFake Detection","abstract":"Detecting singing voice deepfakes, or SingFake, involves determining the authenticity and copyright of a singing voice. Existing models for speech deepfake detection have struggled to adapt to unseen attacks in this unique singing voice domain of human vocalization. To bridge the gap, we present a groundbreaking SingGraph model. The model synergizes the capabilities of the MERT acoustic music understanding model for pitch and rhythm analysis with the wav2vec2.0 model for linguistic analysis of lyrics. Additionally, we advocate for using RawBoost and beat matching techniques grounded in music domain knowledge for singing voice augmentation, thereby enhancing SingFake detection performance. Our proposed method achieves new state-of-the-art (SOTA) results within the SingFake dataset, surpassing the previous SOTA model across three distinct scenarios: it improves EER relatively for seen singers by 13.2%, for unseen singers by 24.3%, and unseen singers using different codecs by 37.1%.","authors":["Xuanjun Chen","Haibin Wu","Jyh-Shing Roger Jang","Hung-yi Lee"],"url":"https://arxiv.org/abs/2406.03111"}
{"created":"2025-06-04","title":"IMPersona: Evaluating Individual Level LM Impersonation","abstract":"As language models achieve increasingly human-like capabilities in conversational text generation, a critical question emerges: to what extent can these systems simulate the characteristics of specific individuals? To evaluate this, we introduce IMPersona, a framework for evaluating LMs at impersonating specific individuals' writing style and personal knowledge. Using supervised fine-tuning and a hierarchical memory-inspired retrieval system, we demonstrate that even modestly sized open-source models, such as Llama-3.1-8B-Instruct, can achieve impersonation abilities at concerning levels. In blind conversation experiments, participants (mis)identified our fine-tuned models with memory integration as human in 44.44% of interactions, compared to just 25.00% for the best prompting-based approach. We analyze these results to propose detection methods and defense strategies against such impersonation attempts. Our findings raise important questions about both the potential applications and risks of personalized language models, particularly regarding privacy, security, and the ethical deployment of such technologies in real-world contexts.","authors":["Quan Shi","Carlos E. Jimenez","Stephen Dong","Brian Seo","Caden Yao","Adam Kelch","Karthik Narasimhan"],"url":"https://arxiv.org/abs/2504.04332"}
{"created":"2025-06-04","title":"Memorization to Generalization: Emergence of Diffusion Models from Associative Memory","abstract":"Hopfield networks are associative memory (AM) systems, designed for storing and retrieving patterns as local minima of an energy landscape. In the classical Hopfield model, an interesting phenomenon occurs when the amount of training data reaches its critical memory load $- spurious\\,\\,states$, or unintended stable points, emerge at the end of the retrieval dynamics, leading to incorrect recall. In this work, we examine diffusion models, commonly used in generative modeling, from the perspective of AMs. The training phase of diffusion model is conceptualized as memory encoding (training data is stored in the memory). The generation phase is viewed as an attempt of memory retrieval. In the small data regime the diffusion model exhibits a strong memorization phase, where the network creates distinct basins of attraction around each sample in the training set, akin to the Hopfield model below the critical memory load. In the large data regime, a different phase appears where an increase in the size of the training set fosters the creation of new attractor states that correspond to manifolds of the generated samples. Spurious states appear at the boundary of this transition and correspond to emergent attractor states, which are absent in the training set, but, at the same time, have distinct basins of attraction around them. Our findings provide: a novel perspective on the memorization-generalization phenomenon in diffusion models via the lens of AMs, theoretical prediction of existence of spurious states, empirical validation of this prediction in commonly-used diffusion models.","authors":["Bao Pham","Gabriel Raya","Matteo Negri","Mohammed J. Zaki","Luca Ambrogioni","Dmitry Krotov"],"url":"https://arxiv.org/abs/2505.21777"}
{"created":"2025-06-04","title":"Surgical Foundation Model Leveraging Compression and Entropy Maximization for Image-Guided Surgical Assistance","abstract":"Real-time video understanding is critical to guide procedures in minimally invasive surgery (MIS). However, supervised learning approaches require large, annotated datasets that are scarce due to annotation efforts that are prohibitive, e.g., in medical fields. Although self-supervision methods can address such limitations, current self-supervised methods often fail to capture structural and physical information in a form that generalizes across tasks. We propose Compress-to-Explore (C2E), a novel self-supervised framework that leverages Kolmogorov complexity to learn compact, informative representations from surgical videos. C2E uses entropy-maximizing decoders to compress images while preserving clinically relevant details, improving encoder performance without labeled data. Trained on large-scale unlabeled surgical datasets, C2E demonstrates strong generalization across a variety of surgical ML tasks, such as workflow classification, tool-tissue interaction classification, segmentation, and diagnosis tasks, providing improved performance as a surgical visual foundation model. As we further show in the paper, the model's internal compact representation better disentangles features from different structural parts of images. The resulting performance improvements highlight the yet untapped potential of self-supervised learning to enhance surgical AI and improve outcomes in MIS.","authors":["Lianhao Yin","Ozanan Meireles","Guy Rosman","Daniela Rus"],"url":"https://arxiv.org/abs/2506.01980"}
{"created":"2025-06-04","title":"Re-experiment Smart: a Novel Method to Enhance Data-driven Prediction of Mechanical Properties of Epoxy Polymers","abstract":"Accurate prediction of polymer material properties through data-driven approaches greatly accelerates novel material development by reducing redundant experiments and trial-and-error processes. However, inevitable outliers in empirical measurements can severely skew machine learning results, leading to erroneous prediction models and suboptimal material designs. To address this limitation, we propose a novel approach to enhance dataset quality efficiently by integrating multi-algorithm outlier detection with selective re-experimentation of unreliable outlier cases. To validate the empirical effectiveness of the approach, we systematically construct a new dataset containing 701 measurements of three key mechanical properties: glass transition temperature ($T_g$), tan $\\delta$ peak, and crosslinking density ($v_{c}$). To demonstrate its general applicability, we report the performance improvements across multiple machine learning models, including Elastic Net, SVR, Random Forest, and TPOT, to predict the three key properties. Our method reliably reduces prediction error (RMSE) and significantly improves accuracy with minimal additional experimental work, requiring only about 5% of the dataset to be re-measured.These findings highlight the importance of data quality enhancement in achieving reliable machine learning applications in polymer science and present a scalable strategy for improving predictive reliability in materials science.","authors":["Wanshan Cui","Yejin Jeong","Inwook Song","Gyuri Kim","Minsang Kwon","Donghun Lee"],"url":"https://arxiv.org/abs/2506.01994"}
{"created":"2025-06-04","title":"Effective Versions of Strong Measure Zero","abstract":"Effective versions of strong measure zero sets are developed for various levels of complexity and computability. It is shown that the sets can be equivalently defined using a generalization of supermartingales called odds supermartingales, success rates on supermartingales, predictors, and coverings. We show Borel's conjecture of a set having strong measure zero if and only if it is countable holds in the time and space bounded setting. At the level of computability this does not hold. We show the computable level contains sequences at arbitrary levels of the hyperarithmetical hierarchy by proving a correspondence principle yielding a condition for the sets of computable strong measure zero to agree with the classical sets of strong measure zero. An algorithmic version of strong measure zero using lower semicomputability is defined. We show that this notion is equivalent to the set of NCR reals studied by Reimann and Slaman, thereby giving new characterizations of this set. Effective strong packing dimension zero is investigated requiring success with respect to the limit inferior instead of the limit superior. It is proven that every sequence in the corresponding algorithmic class is decidable. At the level of computability, the sets coincide with a notion of weak countability that we define.","authors":["Matthew Rayman"],"url":"https://arxiv.org/abs/2506.02031"}
{"created":"2025-06-04","title":"No Audiogram: Leveraging Existing Scores for Personalized Speech Intelligibility Prediction","abstract":"Personalized speech intelligibility prediction is challenging. Previous approaches have mainly relied on audiograms, which are inherently limited in accuracy as they only capture a listener's hearing threshold for pure tones. Rather than incorporating additional listener features, we propose a novel approach that leverages an individual's existing intelligibility data to predict their performance on new audio. We introduce the Support Sample-Based Intelligibility Prediction Network (SSIPNet), a deep learning model that leverages speech foundation models to build a high-dimensional representation of a listener's speech recognition ability from multiple support (audio, score) pairs, enabling accurate predictions for unseen audio. Results on the Clarity Prediction Challenge dataset show that, even with a small number of support (audio, score) pairs, our method outperforms audiogram-based predictions. Our work presents a new paradigm for personalized speech intelligibility prediction.","authors":["Haoshuai Zhou","Changgeng Mo","Boxuan Cao","Linkai Li","Shan Xiang Wang"],"url":"https://arxiv.org/abs/2506.02039"}
{"created":"2025-06-04","title":"A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder","abstract":"As large language models (LLMs) continue to revolutionize AI research, there is a growing interest in building large-scale brain foundation models to advance neuroscience. While most existing brain foundation models are pre-trained on time-series signals or region-of-interest (ROI) features, we propose a novel graph-based pre-training paradigm for constructing a brain graph foundation model. In this paper, we introduce the Brain Graph Foundation Model, termed BrainGFM, a unified framework that leverages graph contrastive learning and graph masked autoencoders for large-scale fMRI-based pre-training. BrainGFM is pre-trained on a diverse mixture of brain atlases with varying parcellations, significantly expanding the pre-training corpus and enhancing the model's ability to generalize across heterogeneous fMRI-derived brain representations. To support efficient and versatile downstream transfer, we integrate both graph prompts and language prompts into the model design, enabling BrainGFM to flexibly adapt to a wide range of atlases, neurological and psychiatric disorders, and task settings. Furthermore, we employ meta-learning to optimize the graph prompts, facilitating strong generalization to previously unseen disorders under both few-shot and zero-shot learning conditions via language-guided prompting. BrainGFM is pre-trained on 27 neuroimaging datasets spanning 25 common neurological and psychiatric disorders, encompassing 2 types of brain atlases (functional and anatomical) across 8 widely-used parcellations, and covering over 25,000 subjects, 60,000 fMRI scans, and a total of 400,000 graph samples aggregated across all atlases and parcellations. The code is available at: https://github.com/weixinxu666/BrainGFM","authors":["Xinxu Wei","Kanhao Zhao","Yong Jiao","Lifang He","Yu Zhang"],"url":"https://arxiv.org/abs/2506.02044"}
{"created":"2025-06-04","title":"Phenotypic Profile-Informed Generation of Drug-Like Molecules via Dual-Channel Variational Autoencoders","abstract":"The de novo generation of drug-like molecules capable of inducing desirable phenotypic changes is receiving increasing attention. However, previous methods predominantly rely on expression profiles to guide molecule generation, but overlook the perturbative effect of the molecules on cellular contexts. To overcome this limitation, we propose SmilesGEN, a novel generative model based on variational autoencoder (VAE) architecture to generate molecules with potential therapeutic effects. SmilesGEN integrates a pre-trained drug VAE (SmilesNet) with an expression profile VAE (ProfileNet), jointly modeling the interplay between drug perturbations and transcriptional responses in a common latent space. Specifically, ProfileNet is imposed to reconstruct pre-treatment expression profiles when eliminating drug-induced perturbations in the latent space, while SmilesNet is informed by desired expression profiles to generate drug-like molecules. Our empirical experiments demonstrate that SmilesGEN outperforms current state-of-the-art models in generating molecules with higher degree of validity, uniqueness, novelty, as well as higher Tanimoto similarity to known ligands targeting the relevant proteins. Moreover, we evaluate SmilesGEN for scaffold-based molecule optimization and generation of therapeutic agents, and confirmed its superior performance in generating molecules with higher similarity to approved drugs. SmilesGEN establishes a robust framework that leverages gene signatures to generate drug-like molecules that hold promising potential to induce desirable cellular phenotypic changes.","authors":["Hui Liu","Shiye Tian","Xuejun Liu"],"url":"https://arxiv.org/abs/2506.02051"}
{"created":"2025-06-04","title":"Protap: A Benchmark for Protein Modeling on Realistic Downstream Applications","abstract":"Recently, extensive deep learning architectures and pretraining strategies have been explored to support downstream protein applications. Additionally, domain-specific models incorporating biological knowledge have been developed to enhance performance in specialized tasks. In this work, we introduce $\\textbf{Protap}$, a comprehensive benchmark that systematically compares backbone architectures, pretraining strategies, and domain-specific models across diverse and realistic downstream protein applications. Specifically, Protap covers five applications: three general tasks and two novel specialized tasks, i.e., enzyme-catalyzed protein cleavage site prediction and targeted protein degradation, which are industrially relevant yet missing from existing benchmarks. For each application, Protap compares various domain-specific models and general architectures under multiple pretraining settings. Our empirical studies imply that: (i) Though large-scale pretraining encoders achieve great results, they often underperform supervised encoders trained on small downstream training sets. (ii) Incorporating structural information during downstream fine-tuning can match or even outperform protein language models pretrained on large-scale sequence corpora. (iii) Domain-specific biological priors can enhance performance on specialized downstream tasks. Code and datasets are publicly available at https://github.com/Trust-App-AI-Lab/protap.","authors":["Shuo Yan","Yuliang Yan","Bin Ma","Chenao Li","Haochun Tang","Jiahua Lu","Minhua Lin","Yuyuan Feng","Hui Xiong","Enyan Dai"],"url":"https://arxiv.org/abs/2506.02052"}
{"created":"2025-06-04","title":"Quantum Key Distribution by Quantum Energy Teleportation","abstract":"Quantum energy teleportation (QET) is a process that leverages quantum entanglement and local operations to transfer energy between two spatially separated locations without physically transporting particles or energy carriers. We construct a QET-based quantum key distribution (QKD) protocol and analyze its security and robustness to noise in both the classical and the quantum channels. We generalize the construction to an $N$-party information sharing protocol, possessing a feature that dishonest participants can be detected.","authors":["Shlomi Dolev","Kazuki Ikeda","Yaron Oz"],"url":"https://arxiv.org/abs/2506.02054"}
{"created":"2025-06-04","title":"Alzheimers Disease Classification in Functional MRI With 4D Joint Temporal-Spatial Kernels in Novel 4D CNN Model","abstract":"Previous works in the literature apply 3D spatial-only models on 4D functional MRI data leading to possible sub-par feature extraction to be used for downstream tasks like classification. In this work, we aim to develop a novel 4D convolution network to extract 4D joint temporal-spatial kernels that not only learn spatial information but in addition also capture temporal dynamics. Experimental results show promising performance in capturing spatial-temporal data in functional MRI compared to 3D models. The 4D CNN model improves Alzheimers disease diagnosis for rs-fMRI data, enabling earlier detection and better interventions. Future research could explore task-based fMRI applications and regression tasks, enhancing understanding of cognitive performance and disease progression.","authors":["Javier Salazar Cavazos","Scott Peltier"],"url":"https://arxiv.org/abs/2506.02060"}
{"created":"2025-06-04","title":"Enhancing Interpretability of Quantum-Assisted Blockchain Clustering via AI Agent-Based Qualitative Analysis","abstract":"Blockchain transaction data is inherently high dimensional, noisy, and entangled, posing substantial challenges for traditional clustering algorithms. While quantum enhanced clustering models have demonstrated promising performance gains, their interpretability remains limited, restricting their application in sensitive domains such as financial fraud detection and blockchain governance. To address this gap, we propose a two stage analysis framework that synergistically combines quantitative clustering evaluation with AI Agent assisted qualitative interpretation. In the first stage, we employ classical clustering methods and evaluation metrics including the Silhouette Score, Davies Bouldin Index, and Calinski Harabasz Index to determine the optimal cluster count and baseline partition quality. In the second stage, we integrate an AI Agent to generate human readable, semantic explanations of clustering results, identifying intra cluster characteristics and inter cluster relationships. Our experiments reveal that while fully trained Quantum Neural Networks (QNN) outperform random Quantum Features (QF) in quantitative metrics, the AI Agent further uncovers nuanced differences between these methods, notably exposing the singleton cluster phenomenon in QNN driven models. The consolidated insights from both stages consistently endorse the three cluster configuration, demonstrating the practical value of our hybrid approach. This work advances the interpretability frontier in quantum assisted blockchain analytics and lays the groundwork for future autonomous AI orchestrated clustering frameworks.","authors":["Yun-Cheng Tsai","Yen-Ku Liu","Samuel Yen-Chi Chen"],"url":"https://arxiv.org/abs/2506.02068"}
{"created":"2025-06-04","title":"Stop Chasing the C-index: This Is How We Should Evaluate Our Survival Models","abstract":"We argue that many survival analysis and time-to-event models are incorrectly evaluated. First, we survey many examples of evaluation approaches in the literature and find that most rely on concordance (C-index). However, the C-index only measures a model's discriminative ability and does not assess other important aspects, such as the accuracy of the time-to-event predictions or the calibration of the model's probabilistic estimates. Next, we present a set of key desiderata for choosing the right evaluation metric and discuss their pros and cons. These are tailored to the challenges in survival analysis, such as sensitivity to miscalibration and various censoring assumptions. We hypothesize that the current development of survival metrics conforms to a double-helix ladder, and that model validity and metric validity must stand on the same rung of the assumption ladder. Finally, we discuss the appropriate methods for evaluating a survival model in practice and summarize various viewpoints opposing our analysis.","authors":["Christian Marius Lillelund","Shi-ang Qi","Russell Greiner","Christian Fischer Pedersen"],"url":"https://arxiv.org/abs/2506.02075"}
{"created":"2025-06-04","title":"A meaningful prediction of functional decline in amyotrophic lateral sclerosis based on multi-event survival analysis","abstract":"Amyotrophic lateral sclerosis (ALS) is a degenerative disorder of motor neurons that causes progressive paralysis in patients. Current treatment options aim to prolong survival and improve quality of life; however, due to the heterogeneity of the disease, it is often difficult to determine the optimal time for potential therapies or medical interventions. In this study, we propose a novel method to predict the time until a patient with ALS experiences significant functional impairment (ALSFRS-R<=2) with respect to five common functions: speaking, swallowing, handwriting, walking and breathing. We formulate this task as a multi-event survival problem and validate our approach in the PRO-ACT dataset by training five covariate-based survival models to estimate the probability of an event over a 500-day period after a baseline visit. We then predict five event-specific individual survival distributions (ISDs) for each patient, each providing an interpretable and meaningful estimate of when that event will likely take place in the future. The results show that covariate-based models are superior to the Kaplan-Meier estimator at predicting time-to-event outcomes. Additionally, our method enables practitioners to make individual counterfactual predictions, where certain features (covariates) can be changed to see their effect on the predicted outcome. In this regard, we find that Riluzole has little to no impact on predicted functional decline. However, for patients with bulbar-onset ALS, our method predicts considerably shorter counterfactual time-to-event estimates for tasks related to speech and swallowing compared to limb-onset ALS. The proposed method can be applied to current clinical examination data to assess the risk of functional decline and thus allow more personalized treatment planning.","authors":["Christian Marius Lillelund","Sanjay Kalra","Russell Greiner"],"url":"https://arxiv.org/abs/2506.02076"}
{"created":"2025-06-04","title":"Evaluating the Effectiveness of Pre-Trained Audio Embeddings for Classification of Parkinson's Disease Speech Data","abstract":"Speech impairments are prevalent biomarkers for Parkinson's Disease (PD), motivating the development of diagnostic techniques using speech data for clinical applications. Although deep acoustic features have shown promise for PD classification, their effectiveness often varies due to individual speaker differences, a factor that has not been thoroughly explored in the existing literature. This study investigates the effectiveness of three pre-trained audio embeddings (OpenL3, VGGish and Wav2Vec2.0 models) for PD classification. Using the NeuroVoz dataset, OpenL3 outperforms others in diadochokinesis (DDK) and listen and repeat (LR) tasks, capturing critical acoustic features for PD detection. Only Wav2Vec2.0 shows significant gender bias, achieving more favorable results for male speakers, in DDK tasks. The misclassified cases reveal challenges with atypical speech patterns, highlighting the need for improved feature extraction and model robustness in PD detection.","authors":["Emmy Postma","Cristian Tejedor-Garcia"],"url":"https://arxiv.org/abs/2506.02078"}
{"created":"2025-06-04","title":"Enhancing GOP in CTC-Based Mispronunciation Detection with Phonological Knowledge","abstract":"Computer-Assisted Pronunciation Training (CAPT) systems employ automatic measures of pronunciation quality, such as the goodness of pronunciation (GOP) metric. GOP relies on forced alignments, which are prone to labeling and segmentation errors due to acoustic variability. While alignment-free methods address these challenges, they are computationally expensive and scale poorly with phoneme sequence length and inventory size. To enhance efficiency, we introduce a substitution-aware alignment-free GOP that restricts phoneme substitutions based on phoneme clusters and common learner errors. We evaluated our GOP on two L2 English speech datasets, one with child speech, My Pronunciation Coach (MPC), and SpeechOcean762, which includes child and adult speech. We compared RPS (restricted phoneme substitutions) and UPS (unrestricted phoneme substitutions) setups within alignment-free methods, which outperformed the baseline. We discuss our results and outline avenues for future research.","authors":["Aditya Kamlesh Parikh","Cristian Tejedor-Garcia","Catia Cucchiarini","Helmer Strik"],"url":"https://arxiv.org/abs/2506.02080"}
{"created":"2025-06-04","title":"Are Pixel-Wise Metrics Reliable for Sparse-View Computed Tomography Reconstruction?","abstract":"Widely adopted evaluation metrics for sparse-view CT reconstruction--such as Structural Similarity Index Measure and Peak Signal-to-Noise Ratio--prioritize pixel-wise fidelity but often fail to capture the completeness of critical anatomical structures, particularly small or thin regions that are easily missed. To address this limitation, we propose a suite of novel anatomy-aware evaluation metrics designed to assess structural completeness across anatomical structures, including large organs, small organs, intestines, and vessels. Building on these metrics, we introduce CARE, a Completeness-Aware Reconstruction Enhancement framework that incorporates structural penalties during training to encourage anatomical preservation of significant structures. CARE is model-agnostic and can be seamlessly integrated into analytical, implicit, and generative methods. When applied to these methods, CARE substantially improves structural completeness in CT reconstructions, achieving up to +32% improvement for large organs, +22% for small organs, +40% for intestines, and +36% for vessels.","authors":["Tianyu Lin","Xinran Li","Chuntung Zhuang","Qi Chen","Yuanhao Cai","Kai Ding","Alan L. Yuille","Zongwei Zhou"],"url":"https://arxiv.org/abs/2506.02093"}
{"created":"2025-06-04","title":"Tomographic Foundation Model -- FORCE: Flow-Oriented Reconstruction Conditioning Engine","abstract":"Computed tomography (CT) is a major medical imaging modality. Clinical CT scenarios, such as low-dose screening, sparse-view scanning, and metal implants, often lead to severe noise and artifacts in reconstructed images, requiring improved reconstruction techniques. The introduction of deep learning has significantly advanced CT image reconstruction. However, obtaining paired training data remains rather challenging due to patient motion and other constraints. Although deep learning methods can still perform well with approximately paired data, they inherently carry the risk of hallucination due to data inconsistencies and model instability. In this paper, we integrate the data fidelity with the state-of-the-art generative AI model, referred to as the Poisson flow generative model (PFGM) with a generalized version PFGM++, and propose a novel CT framework: Flow-Oriented Reconstruction Conditioning Engine (FORCE). In our experiments, the proposed method shows superior performance in various CT imaging tasks, outperforming existing unsupervised reconstruction approaches.","authors":["Wenjun Xia","Chuang Niu","Ge Wang"],"url":"https://arxiv.org/abs/2506.02149"}
{"created":"2025-06-04","title":"Dhvani: A Weakly-supervised Phonemic Error Detection and Personalized Feedback System for Hindi","abstract":"Computer-Assisted Pronunciation Training (CAPT) has been extensively studied for English. However, there remains a critical gap in its application to Indian languages with a base of 1.5 billion speakers. Pronunciation tools tailored to Indian languages are strikingly lacking despite the fact that millions learn them every year. With over 600 million speakers and being the fourth most-spoken language worldwide, improving Hindi pronunciation is a vital first step toward addressing this gap. This paper proposes 1) Dhvani -- a novel CAPT system for Hindi, 2) synthetic speech generation for Hindi mispronunciations, and 3) a novel methodology for providing personalized feedback to learners. While the system often interacts with learners using Devanagari graphemes, its core analysis targets phonemic distinctions, leveraging Hindi's highly phonetic orthography to analyze mispronounced speech and provide targeted feedback.","authors":["Arnav Rustagi","Satvik Bajpai","Nimrat Kaur","Siddharth Siddharth"],"url":"https://arxiv.org/abs/2506.02166"}
{"created":"2025-06-04","title":"NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution","abstract":"This paper reviews the NTIRE 2025 RAW Image Restoration and Super-Resolution Challenge, highlighting the proposed solutions and results. New methods for RAW Restoration and Super-Resolution could be essential in modern Image Signal Processing (ISP) pipelines, however, this problem is not as explored as in the RGB domain. The goal of this challenge is two fold, (i) restore RAW images with blur and noise degradations, (ii) upscale RAW Bayer images by 2x, considering unknown noise and blur. In the challenge, a total of 230 participants registered, and 45 submitted results during thee challenge period. This report presents the current state-of-the-art in RAW Restoration.","authors":["Marcos V. Conde","Radu Timofte","Zihao Lu","Xiangyu Kongand Xiaoxia Xingand Fan Wangand Suejin Hanand MinKyu Parkand Tianyu Zhangand Xin Luoand Yeda Chenand Dong Liuand Li Pangand Yuhang Yangand Hongzhong Wangand Xiangyong Caoand Ruixuan Jiangand Senyan Xuand Siyuan Jiangand Xueyang Fuand Zheng-Jun Zhaand Tianyu Haoand Yuhong Heand Ruoqi Liand Yueqi Yangand Xiang Yuand Guanlan Hongand Minmin Yiand Yuanjia Chenand Liwen Zhangand Zijie Jinand Cheng Liand Lian Liuand Wei Songand Heng Sunand Yubo Wangand Jinghua Wangand Jiajie Luand Watchara Ruangsangand"],"url":"https://arxiv.org/abs/2506.02197"}
{"created":"2025-06-04","title":"On a spherically lifted spin model at finite temperature","abstract":"We investigate an \\(n\\)-vector model over \\(k\\) sites with generic pairwise interactions and spherical constraints. The model is a lifting of the Ising model whereby the support of the spin is lifted to a hypersphere. We show that the \\(n\\)-vector model converges to a limiting distribution at a rate of \\(n^{-1/2 + o(1)}\\). We show that the limiting distribution for \\(n \\to \\infty\\) is determined by the solution of an equality-constrained maximization task over positive definite matrices. We prove that the obtained maximal value and maximizer, respectively, give rise to the free energy and correlation function of the limiting distribution. In the finite temperature regime, the maximization task is a log-determinant regularization of the semidefinite program (SDP) in the Goemans-Williamson algorithm. Moreover, the inverse temperature determines the regularization strength, with the zero temperature limit converging to the SDP in Goemans-Williamson. Our derivation draws a curious connection between the semidefinite relaxation of integer programming and the spherical lifting of sampling on a hypercube. To the authors' best knowledge, this work is the first to solve the setting of fixed \\(k\\) and infinite \\(n\\) under unstructured pairwise interactions.","authors":["Xun Tang","Yuehaw Khoo","Lexing Ying"],"url":"https://arxiv.org/abs/2506.02220"}
{"created":"2025-06-04","title":"Towards Machine Unlearning for Paralinguistic Speech Processing","abstract":"In this work, we pioneer the study of Machine Unlearning (MU) for Paralinguistic Speech Processing (PSP). We focus on two key PSP tasks: Speech Emotion Recognition (SER) and Depression Detection (DD). To this end, we propose, SISA++, a novel extension to previous state-of-the-art (SOTA) MU method, SISA by merging models trained on different shards with weight-averaging. With such modifications, we show that SISA++ preserves performance more in comparison to SISA after unlearning in benchmark SER (CREMA-D) and DD (E-DAIC) datasets. Also, to guide future research for easier adoption of MU for PSP, we present ``cookbook recipes'' - actionable recommendations for selecting optimal feature representations and downstream architectures that can mitigate performance degradation after the unlearning process.","authors":["Orchid Chetia Phukan","Girish","Mohd Mujtaba Akhtar","Shubham Singh","Swarup Ranjan Behera","Vandana Rajan","Muskaan Singh","Arun Balaji Buduru","Rajesh Sharma"],"url":"https://arxiv.org/abs/2506.02230"}
{"created":"2025-06-04","title":"Investigating the Reasonable Effectiveness of Speaker Pre-Trained Models and their Synergistic Power for SingMOS Prediction","abstract":"In this study, we focus on Singing Voice Mean Opinion Score (SingMOS) prediction. Previous research have shown the performance benefit with the use of state-of-the-art (SOTA) pre-trained models (PTMs). However, they haven't explored speaker recognition speech PTMs (SPTMs) such as x-vector, ECAPA and we hypothesize that it will be the most effective for SingMOS prediction. We believe that due to their speaker recognition pre-training, it equips them to capture fine-grained vocal features (e.g., pitch, tone, intensity) from synthesized singing voices in a much more better way than other PTMs. Our experiments with SOTA PTMs including SPTMs and music PTMs validates the hypothesis. Additionally, we introduce a novel fusion framework, BATCH that uses Bhattacharya Distance for fusion of PTMs. Through BATCH with the fusion of speaker recognition SPTMs, we report the topmost performance comparison to all the individual PTMs and baseline fusion techniques as well as setting SOTA.","authors":["Orchid Chetia Phukan","Girish","Mohd Mujtaba Akhtar","Swarup Ranjan Behera","Pailla Balakrishna Reddy","Arun Balaji Buduru","Rajesh Sharma"],"url":"https://arxiv.org/abs/2506.02232"}
{"created":"2025-06-04","title":"Enabling Probabilistic Learning on Manifolds through Double Diffusion Maps","abstract":"We present a generative learning framework for probabilistic sampling based on an extension of the Probabilistic Learning on Manifolds (PLoM) approach, which is designed to generate statistically consistent realizations of a random vector in a finite-dimensional Euclidean space, informed by a limited (yet representative) set of observations. In its original form, PLoM constructs a reduced-order probabilistic model by combining three main components: (a) kernel density estimation to approximate the underlying probability measure, (b) Diffusion Maps to uncover the intrinsic low-dimensional manifold structure, and (c) a reduced-order Ito Stochastic Differential Equation (ISDE) to sample from the learned distribution. A key challenge arises, however, when the number of available data points N is small and the dimensionality of the diffusion-map basis approaches N, resulting in overfitting and loss of generalization. To overcome this limitation, we propose an enabling extension that implements a synthesis of Double Diffusion Maps -- a technique capable of capturing multiscale geometric features of the data -- with Geometric Harmonics (GH), a nonparametric reconstruction method that allows smooth nonlinear interpolation in high-dimensional ambient spaces. This approach enables us to solve a full-order ISDE directly in the latent space, preserving the full dynamical complexity of the system, while leveraging its reduced geometric representation. The effectiveness and robustness of the proposed method are illustrated through two numerical studies: one based on data generated from two-dimensional Hermite polynomial functions and another based on high-fidelity simulations of a detonation wave in a reactive flow.","authors":["Dimitris G Giovanis","Nikolaos Evangelou","Ioannis G Kevrekidis","Roger G Ghanem"],"url":"https://arxiv.org/abs/2506.02254"}
{"created":"2025-06-04","title":"Assumption-free stability for ranking problems","abstract":"In this work, we consider ranking problems among a finite set of candidates: for instance, selecting the top-$k$ items among a larger list of candidates or obtaining the full ranking of all items in the set. These problems are often unstable, in the sense that estimating a ranking from noisy data can exhibit high sensitivity to small perturbations. Concretely, if we use data to provide a score for each item (say, by aggregating preference data over a sample of users), then for two items with similar scores, small fluctuations in the data can alter the relative ranking of those items. Many existing theoretical results for ranking problems assume a separation condition to avoid this challenge, but real-world data often contains items whose scores are approximately tied, limiting the applicability of existing theory. To address this gap, we develop a new algorithmic stability framework for ranking problems, and propose two novel ranking operators for achieving stable ranking: the \\emph{inflated top-$k$} for the top-$k$ selection problem and the \\emph{inflated full ranking} for ranking the full list. To enable stability, each method allows for expressing some uncertainty in the output. For both of these two problems, our proposed methods provide guaranteed stability, with no assumptions on data distributions and no dependence on the total number of candidates to be ranked. Experiments on real-world data confirm that the proposed methods offer stability without compromising the informativeness of the output.","authors":["Ruiting Liang","Jake A. Soloff","Rina Foygel Barber","Rebecca Willett"],"url":"https://arxiv.org/abs/2506.02257"}
{"created":"2025-06-04","title":"Are Mamba-based Audio Foundation Models the Best Fit for Non-Verbal Emotion Recognition?","abstract":"In this work, we focus on non-verbal vocal sounds emotion recognition (NVER). We investigate mamba-based audio foundation models (MAFMs) for the first time for NVER and hypothesize that MAFMs will outperform attention-based audio foundation models (AAFMs) for NVER by leveraging its state-space modeling to capture intrinsic emotional structures more effectively. Unlike AAFMs, which may amplify irrelevant patterns due to their attention mechanisms, MAFMs will extract more stable and context-aware representations, enabling better differentiation of subtle non-verbal emotional cues. Our experiments with state-of-the-art (SOTA) AAFMs and MAFMs validates our hypothesis. Further, motivated from related research such as speech emotion recognition, synthetic speech detection, where fusion of foundation models (FMs) have showed improved performance, we also explore fusion of FMs for NVER. To this end, we propose, RENO, that uses renyi-divergence as a novel loss function for effective alignment of the FMs. It also makes use of self-attention for better intra-representation interaction of the FMs. With RENO, through the heterogeneous fusion of MAFMs and AAFMs, we show the topmost performance in comparison to individual FMs, its fusion and also setting SOTA in comparison to previous SOTA work.","authors":["Mohd Mujtaba Akhtar","Orchid Chetia Phukan","Girish","Swarup Ranjan Behera","Ananda Chandra Nayak","Sanjib Kumar Nayak","Arun Balaji Buduru","Rajesh Sharma"],"url":"https://arxiv.org/abs/2506.02258"}
{"created":"2025-06-04","title":"MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements","abstract":"The growing prevalence of digital health technologies has led to the generation of complex multi-modal data, such as physical activity measurements simultaneously collected from various sensors of mobile and wearable devices. These data hold immense potential for advancing health studies, but current methods predominantly rely on supervised learning, requiring extensive labeled datasets that are often expensive or impractical to obtain, especially in clinical studies. To address this limitation, we propose a self-supervised learning framework called Multi-modal Cross-masked Autoencoder (MoCA) that leverages cross-modality masking and the Transformer autoencoder architecture to utilize both temporal correlations within modalities and cross-modal correlations between data streams. We also provide theoretical guarantees to support the effectiveness of the cross-modality masking scheme in MoCA. Comprehensive experiments and ablation studies demonstrate that our method outperforms existing approaches in both reconstruction and downstream tasks. We release open-source code for data processing, pre-training, and downstream tasks in the supplementary materials. This work highlights the transformative potential of self-supervised learning in digital health and multi-modal data.","authors":["Howon Ryu","Yuliang Chen","Yacun Wang","Andrea Z. LaCroix","Chongzhi Di","Loki Natarajan","Yu Wang","Jingjing Zou"],"url":"https://arxiv.org/abs/2506.02260"}
{"created":"2025-06-04","title":"Parallel Repetition for Post-Quantum Arguments","abstract":"In this work, we show that parallel repetition of public-coin interactive arguments reduces the soundness error at an exponential rate even in the post-quantum setting. Moreover, we generalize this result to hold for threshold verifiers, where the parallel repeated verifier accepts if and only if at least $t$ of the executions are accepted (for some threshold $t$). Prior to this work, these results were known only when the cheating prover was assumed to be classical.","authors":["Andrew Huang","Yael Tauman Kalai"],"url":"https://arxiv.org/abs/2506.02277"}
{"created":"2025-06-04","title":"Dual encoding feature filtering generalized attention UNET for retinal vessel segmentation","abstract":"Retinal blood vessel segmentation is crucial for diagnosing ocular and cardiovascular diseases. Although the introduction of U-Net in 2015 by Olaf Ronneberger significantly advanced this field, yet issues like limited training data, imbalance data distribution, and inadequate feature extraction persist, hindering both the segmentation performance and optimal model generalization. Addressing these critical issues, the DEFFA-Unet is proposed featuring an additional encoder to process domain-invariant pre-processed inputs, thereby improving both richer feature encoding and enhanced model generalization. A feature filtering fusion module is developed to ensure the precise feature filtering and robust hybrid feature fusion. In response to the task-specific need for higher precision where false positives are very costly, traditional skip connections are replaced with the attention-guided feature reconstructing fusion module. Additionally, innovative data augmentation and balancing methods are proposed to counter data scarcity and distribution imbalance, further boosting the robustness and generalization of the model. With a comprehensive suite of evaluation metrics, extensive validations on four benchmark datasets (DRIVE, CHASEDB1, STARE, and HRF) and an SLO dataset (IOSTAR), demonstrate the proposed method's superiority over both baseline and state-of-the-art models. Particularly the proposed method significantly outperforms the compared methods in cross-validation model generalization.","authors":["Md Tauhidul Islam","Wu Da-Wen","Tang Qing-Qing","Zhao Kai-Yang","Yin Teng","Li Yan-Fei","Shang Wen-Yi","Liu Jing-Yu","Zhang Hai-Xian"],"url":"https://arxiv.org/abs/2506.02312"}
{"created":"2025-06-04","title":"Large Stepsizes Accelerate Gradient Descent for Regularized Logistic Regression","abstract":"We study gradient descent (GD) with a constant stepsize for $\\ell_2$-regularized logistic regression with linearly separable data. Classical theory suggests small stepsizes to ensure monotonic reduction of the optimization objective, achieving exponential convergence in $\\widetilde{\\mathcal{O}}(\\kappa)$ steps with $\\kappa$ being the condition number. Surprisingly, we show that this can be accelerated to $\\widetilde{\\mathcal{O}}(\\sqrt{\\kappa})$ by simply using a large stepsize -- for which the objective evolves nonmonotonically. The acceleration brought by large stepsizes extends to minimizing the population risk for separable distributions, improving on the best-known upper bounds on the number of steps to reach a near-optimum. Finally, we characterize the largest stepsize for the local convergence of GD, which also determines the global convergence in special scenarios. Our results extend the analysis of Wu et al. (2024) from convex settings with minimizers at infinity to strongly convex cases with finite minimizers.","authors":["Jingfeng Wu","Pierre Marion","Peter Bartlett"],"url":"https://arxiv.org/abs/2506.02336"}
{"created":"2025-06-04","title":"Enhancing Lyrics Transcription on Music Mixtures with Consistency Loss","abstract":"Automatic Lyrics Transcription (ALT) aims to recognize lyrics from singing voices, similar to Automatic Speech Recognition (ASR) for spoken language, but faces added complexity due to domain-specific properties of the singing voice. While foundation ASR models show robustness in various speech tasks, their performance degrades on singing voice, especially in the presence of musical accompaniment. This work focuses on this performance gap and explores Low-Rank Adaptation (LoRA) for ALT, investigating both single-domain and dual-domain fine-tuning strategies. We propose using a consistency loss to better align vocal and mixture encoder representations, improving transcription on mixture without relying on singing voice separation. Our results show that while na\\\"ive dual-domain fine-tuning underperforms, structured training with consistency loss yields modest but consistent gains, demonstrating the potential of adapting ASR foundation models for music.","authors":["Jiawen Huang","Felipe Sousa","Emir Demirel","Emmanouil Benetos","Igor Gadelha"],"url":"https://arxiv.org/abs/2506.02339"}
{"created":"2025-06-04","title":"Unrolling Nonconvex Graph Total Variation for Image Denoising","abstract":"Conventional model-based image denoising optimizations employ convex regularization terms, such as total variation (TV) that convexifies the $\\ell_0$-norm to promote sparse signal representation. Instead, we propose a new non-convex total variation term in a graph setting (NC-GTV), such that when combined with an $\\ell_2$-norm fidelity term for denoising, leads to a convex objective with no extraneous local minima. We define NC-GTV using a new graph variant of the Huber function, interpretable as a Moreau envelope. The crux is the selection of a parameter $a$ characterizing the graph Huber function that ensures overall objective convexity; we efficiently compute $a$ via an adaptation of Gershgorin Circle Theorem (GCT). To minimize the convex objective, we design a linear-time algorithm based on Alternating Direction Method of Multipliers (ADMM) and unroll it into a lightweight feed-forward network for data-driven parameter learning. Experiments show that our method outperforms unrolled GTV and other representative image denoising schemes, while employing far fewer network parameters.","authors":["Songlin Wei","Gene Cheung","Fei Chen","Ivan Selesnick"],"url":"https://arxiv.org/abs/2506.02381"}
{"created":"2025-06-04","title":"Joint Modeling for Learning Decision-Making Dynamics in Behavioral Experiments","abstract":"Major depressive disorder (MDD), a leading cause of disability and mortality, is associated with reward-processing abnormalities and concentration issues. Motivated by the probabilistic reward task from the Establishing Moderators and Biosignatures of Antidepressant Response in Clinical Care (EMBARC) study, we propose a novel framework that integrates the reinforcement learning (RL) model and drift-diffusion model (DDM) to jointly analyze reward-based decision-making with response times. To account for emerging evidence suggesting that decision-making may alternate between multiple interleaved strategies, we model latent state switching using a hidden Markov model (HMM). In the ''engaged'' state, decisions follow an RL-DDM, simultaneously capturing reward processing, decision dynamics, and temporal structure. In contrast, in the ''lapsed'' state, decision-making is modeled using a simplified DDM, where specific parameters are fixed to approximate random guessing with equal probability. The proposed method is implemented using a computationally efficient generalized expectation-maximization algorithm with forward-backward procedures. Through extensive numerical studies, we demonstrate that our proposed method outperforms competing approaches under various reward-generating distributions, both with and without strategy switching. When applied to the EMBARC study, our framework reveals that MDD patients exhibit lower overall engagement than healthy controls and experience longer decision times when they do engage. Additionally, we show that neuroimaging measures of brain activities are associated with decision-making characteristics in the ''engaged'' state but not in the ''lapsed'' state, providing evidence of brain-behavioral association specific to the ''engaged'' state.","authors":["Yuan Bian","Xingche Guo","Yuanjia Wang"],"url":"https://arxiv.org/abs/2506.02394"}
{"created":"2025-06-04","title":"Baseband-Free End-to-End Communication System Based on Diffractive Deep Neural Network","abstract":"Diffractive deep neural network (D2NN), also referred to as reconfigurable intelligent metasurface based deep neural networks (Rb-DNNs) or stacked intelligent metasurfaces (SIMs) in the field of wireless communications, has emerged as a promising signal processing paradigm that enables computing-by-propagation. However, existing architectures are limited to implementing specific functions such as precoding and combining, while still relying on digital baseband modules for other essential tasks like modulation and detection. In this work, we propose a baseband-free end-to-end (BBF-E2E) wireless communication system where modulation, beamforming, and detection are jointly realized through the propagation of electromagnetic (EM) waves. The BBF-E2E system employs D2NNs at both the transmitter and the receiver, forming an autoencoder architecture optimized as a complex-valued neural network. The transmission coefficients of each metasurface layer are trained using the mini-batch stochastic gradient descent method to minimize the cross-entropy loss. To reduce computational complexity during diffraction calculation, the angular spectrum method (ASM) is adopted in place of the Rayleigh-Sommerfeld formula. Extensive simulations demonstrate that BBF-E2E achieves robust symbol transmission under challenging channel conditions with significantly reduced hardware requirements. In particular, the proposed system matches the performance of a conventional multi-antenna system with 81 RF chains while requiring only a single RF chain and 1024 passive elements of metasurfaces. These results highlight the potential of wave-domain neural computing to replace digital baseband modules in future wireless transceivers.","authors":["Xiaokun Teng","Wankai Tang","Xiao Li","Shi Jin"],"url":"https://arxiv.org/abs/2506.02411"}
{"created":"2025-06-04","title":"Tensor State Space-based Dynamic Multilayer Network Modeling","abstract":"Understanding the complex interactions within dynamic multilayer networks is critical for advancements in various scientific domains. Existing models often fail to capture such networks' temporal and cross-layer dynamics. This paper introduces a novel Tensor State Space Model for Dynamic Multilayer Networks (TSSDMN), utilizing a latent space model framework. TSSDMN employs a symmetric Tucker decomposition to represent latent node features, their interaction patterns, and layer transitions. Then by fixing the latent features and allowing the interaction patterns to evolve over time, TSSDMN uniquely captures both the temporal dynamics within layers and across different layers. The model identifiability conditions are discussed. By treating latent features as variables whose posterior distributions are approximated using a mean-field variational inference approach, a variational Expectation Maximization algorithm is developed for efficient model inference. Numerical simulations and case studies demonstrate the efficacy of TSSDMN for understanding dynamic multilayer networks.","authors":["Tian Lan","Jie Guo","Chen Zhang"],"url":"https://arxiv.org/abs/2506.02413"}
{"created":"2025-06-04","title":"Multi-modal brain MRI synthesis based on SwinUNETR","abstract":"Multi-modal brain magnetic resonance imaging (MRI) plays a crucial role in clinical diagnostics by providing complementary information across different imaging modalities. However, a common challenge in clinical practice is missing MRI modalities. In this paper, we apply SwinUNETR to the synthesize of missing modalities in brain MRI. SwinUNETR is a novel neural network architecture designed for medical image analysis, integrating the strengths of Swin Transformer and convolutional neural networks (CNNs). The Swin Transformer, a variant of the Vision Transformer (ViT), incorporates hierarchical feature extraction and window-based self-attention mechanisms, enabling it to capture both local and global contextual information effectively. By combining the Swin Transformer with CNNs, SwinUNETR merges global context awareness with detailed spatial resolution. This hybrid approach addresses the challenges posed by the varying modality characteristics and complex brain structures, facilitating the generation of accurate and realistic synthetic images. We evaluate the performance of SwinUNETR on brain MRI datasets and demonstrate its superior capability in generating clinically valuable images. Our results show significant improvements in image quality, anatomical consistency, and diagnostic value.","authors":["Haowen Pang","Weiyan Guo","Chuyang Ye"],"url":"https://arxiv.org/abs/2506.02467"}
{"created":"2025-06-04","title":"Adaptive Differential Denoising for Respiratory Sounds Classification","abstract":"Automated respiratory sound classification faces practical challenges from background noise and insufficient denoising in existing systems.","authors":["Gaoyang Dong","Zhicheng Zhang","Ping Sun","Minghui Zhang"],"url":"https://arxiv.org/abs/2506.02505"}
{"created":"2025-06-04","title":"Dynamic mapping from static labels: remote sensing dynamic sample generation with temporal-spectral embedding","abstract":"Accurate remote sensing geographic mapping depends heavily on representative and timely sample data. However, rapid changes in land surface dynamics necessitate frequent updates, quickly rendering previously collected samples obsolete and imposing significant labor demands for continuous manual updates. In this study, we aim to address this problem by dynamic sample generation using existing single-date static labeled samples. We introduce TasGen, a two-stage automated framework to automatically generate dynamic samples, designed to simultaneously model spectral and temporal dependencies in time-series remote sensing imagery via temporal-spectral embedding, capturing land surface changes without additional manual annotations.","authors":["Shuai Yuan","Shuang Chen","Tianwu Lin","Jie Wang","Peng Gong"],"url":"https://arxiv.org/abs/2506.02574"}
{"created":"2025-06-04","title":"A Tree-guided CNN for image super-resolution","abstract":"Deep convolutional neural networks can extract more accurate structural information via deep architectures to obtain good performance in image super-resolution. However, it is not easy to find effect of important layers in a single network architecture to decrease performance of super-resolution. In this paper, we design a tree-guided CNN for image super-resolution (TSRNet). It uses a tree architecture to guide a deep network to enhance effect of key nodes to amplify the relation of hierarchical information for improving the ability of recovering images. To prevent insufficiency of the obtained structural information, cosine transform techniques in the TSRNet are used to extract cross-domain information to improve the performance of image super-resolution. Adaptive Nesterov momentum optimizer (Adan) is applied to optimize parameters to boost effectiveness of training a super-resolution model. Extended experiments can verify superiority of the proposed TSRNet for restoring high-quality images. Its code can be obtained at https://github.com/hellloxiaotian/TSRNet.","authors":["Chunwei Tian","Mingjian Song","Xiaopeng Fan","Xiangtao Zheng","Bob Zhang","David Zhang"],"url":"https://arxiv.org/abs/2506.02585"}
{"created":"2025-06-04","title":"Non-exchangeable evolutionary and mean field games and their applications","abstract":"A replicator dynamic for non-exchangeable agents in a continuous action space is formulated and its well-posedness is proven in a space of probability measures. The non-exchangeability allows for the analysis of evolutionary games involving agents with distinct (and possibly infinitely many) types. We also explicitly connect this replicator dynamic to a stationary mean field game, which determines the pairwise actions of the heterogeneous agents. Moreover, as a byproduct of our theoretical results, we show that a class of nonlinear voter models, recently the subject of increasing interest, called q-voter models, can be viewed as a replicator dynamic driven by a utility that is a power of the probability density. This implies that non-exchangeable and/or mean-field game formulations of these models can also be constructed. We also present computational examples of evolutionary and mean field game models using a finite difference method, focusing on tragedy of the commons and the q-voter model with non-exchangeable agents, of which are interesting cases from theoretical and computational perspectives.","authors":["H. Yoshioka","M. Tsujimura","T. Yanaka"],"url":"https://arxiv.org/abs/2506.02644"}
{"created":"2025-06-04","title":"Multilevel Stochastic Gradient Descent for Optimal Control Under Uncertainty","abstract":"We present a multilevel stochastic gradient descent method for the optimal control of systems governed by partial differential equations under uncertain input data. The gradient descent method used to find the optimal control leverages a parallel multilevel Monte Carlo method as stochastic gradient estimator. As a result, we achieve precise control over the stochastic gradient's bias, introduced by numerical approximation, and its sampling error, arising from the use of incomplete gradients, while optimally managing computational resources. We show that the method exhibits linear convergence in the number of optimization steps while avoiding the cost of computing the full gradient at the highest fidelity. Numerical experiments demonstrate that the method significantly outperforms the standard (mini-) batched stochastic gradient descent method in terms of convergence speed and accuracy. The method is particularly well-suited for high-dimensional control problems, taking advantage of parallel computing resources and a distributed multilevel data structure. Additionally, we evaluate and implement different step size strategies, optimizer schemes, and budgeting techniques. The method's performance is studied using a two-dimensional elliptic subsurface diffusion problem with log-normal coefficients and Mat\\'ern covariance.","authors":["Niklas Baumgarten","David Schneiderhan"],"url":"https://arxiv.org/abs/2506.02647"}
{"created":"2025-06-04","title":"Asymptotics of SGD in Sequence-Single Index Models and Single-Layer Attention Networks","abstract":"We study the dynamics of stochastic gradient descent (SGD) for a class of sequence models termed Sequence Single-Index (SSI) models, where the target depends on a single direction in input space applied to a sequence of tokens. This setting generalizes classical single-index models to the sequential domain, encompassing simplified one-layer attention architectures. We derive a closed-form expression for the population loss in terms of a pair of sufficient statistics capturing semantic and positional alignment, and characterize the induced high-dimensional SGD dynamics for these coordinates. Our analysis reveals two distinct training phases: escape from uninformative initialization and alignment with the target subspace, and demonstrates how the sequence length and positional encoding influence convergence speed and learning trajectories. These results provide a rigorous and interpretable foundation for understanding how sequential structure in data can be beneficial for learning with attention-based models.","authors":["Luca Arnaboldi","Bruno Loureiro","Ludovic Stephan","Florent Krzakala","Lenka Zdeborova"],"url":"https://arxiv.org/abs/2506.02651"}
{"created":"2025-06-04","title":"Computational Thresholds in Multi-Modal Learning via the Spiked Matrix-Tensor Model","abstract":"We study the recovery of multiple high-dimensional signals from two noisy, correlated modalities: a spiked matrix and a spiked tensor sharing a common low-rank structure. This setting generalizes classical spiked matrix and tensor models, unveiling intricate interactions between inference channels and surprising algorithmic behaviors. Notably, while the spiked tensor model is typically intractable at low signal-to-noise ratios, its correlation with the matrix enables efficient recovery via Bayesian Approximate Message Passing, inducing staircase-like phase transitions reminiscent of neural network phenomena. In contrast, empirical risk minimization for joint learning fails: the tensor component obstructs effective matrix recovery, and joint optimization significantly degrades performance, highlighting the limitations of naive multi-modal learning. We show that a simple Sequential Curriculum Learning strategy-first recovering the matrix, then leveraging it to guide tensor recovery-resolves this bottleneck and achieves optimal weak recovery thresholds. This strategy, implementable with spectral methods, emphasizes the critical role of structural correlation and learning order in multi-modal high-dimensional inference.","authors":["Hugo Tabanelli","Pierre Mergny","Lenka Zdeborova","Florent Krzakala"],"url":"https://arxiv.org/abs/2506.02664"}
{"created":"2025-06-04","title":"Symmetry-Aware GFlowNets","abstract":"Generative Flow Networks (GFlowNets) offer a powerful framework for sampling graphs in proportion to their rewards. However, existing approaches suffer from systematic biases due to inaccuracies in state transition probability computations. These biases, rooted in the inherent symmetries of graphs, impact both atom-based and fragment-based generation schemes. To address this challenge, we introduce Symmetry-Aware GFlowNets (SA-GFN), a method that incorporates symmetry corrections into the learning process through reward scaling. By integrating bias correction directly into the reward structure, SA-GFN eliminates the need for explicit state transition computations. Empirical results show that SA-GFN enables unbiased sampling while enhancing diversity and consistently generating high-reward graphs that closely match the target distribution.","authors":["Hohyun Kim","Seunggeun Lee","Min-hwan Oh"],"url":"https://arxiv.org/abs/2506.02685"}
{"created":"2025-06-04","title":"Online Bayesian system identification in multivariate autoregressive models via message passing","abstract":"We propose a recursive Bayesian estimation procedure for multivariate autoregressive models with exogenous inputs based on message passing in a factor graph. Unlike recursive least-squares, our method produces full posterior distributions for both the autoregressive coefficients and noise precision. The uncertainties regarding these estimates propagate into the uncertainties on predictions for future system outputs, and support online model evidence calculations. We demonstrate convergence empirically on a synthetic autoregressive system and competitive performance on a double mass-spring-damper system.","authors":["T. N. Nisslbeck","Wouter M. Kouw"],"url":"https://arxiv.org/abs/2506.02710"}
{"created":"2025-06-04","title":"An Exploratory Framework for Future SETI Applications: Detecting Generative Reactivity via Language Models","abstract":"We present an exploratory framework to test whether noise-like input can induce structured responses in language models. Instead of assuming that extraterrestrial signals must be decoded, we evaluate whether inputs can trigger linguistic behavior in generative systems. This shifts the focus from decoding to viewing structured output as a sign of underlying regularity in the input. We tested GPT-2 small, a 117M-parameter model trained on English text, using four types of acoustic input: human speech, humpback whale vocalizations, Phylloscopus trochilus birdsong, and algorithmically generated white noise. All inputs were treated as noise-like, without any assumed symbolic encoding. To assess reactivity, we defined a composite score called Semantic Induction Potential (SIP), combining entropy, syntax coherence, compression gain, and repetition penalty. Results showed that whale and bird vocalizations had higher SIP scores than white noise, while human speech triggered only moderate responses. This suggests that language models may detect latent structure even in data without conventional semantics. We propose that this approach could complement traditional SETI methods, especially in cases where communicative intent is unknown. Generative reactivity may offer a different way to identify data worth closer attention.","authors":["Po-Chieh Yu"],"url":"https://arxiv.org/abs/2506.02730"}
{"created":"2025-06-04","title":"Prompt-Unseen-Emotion: Zero-shot Expressive Speech Synthesis with Prompt-LLM Contextual Knowledge for Mixed Emotions","abstract":"Existing expressive text-to-speech (TTS) systems primarily model a limited set of categorical emotions, whereas human conversations extend far beyond these predefined emotions, making it essential to explore more diverse emotional speech generation for more natural interactions. To bridge this gap, this paper proposes a novel prompt-unseen-emotion (PUE) approach to generate unseen emotional speech via emotion-guided prompt learning. PUE is trained utilizing an LLM-TTS architecture to ensure emotional consistency between categorical emotion-relevant prompts and emotional speech, allowing the model to quantitatively capture different emotion weightings per utterance. During inference, mixed emotional speech can be generated by flexibly adjusting emotion proportions and leveraging LLM contextual knowledge, enabling the model to quantify different emotional styles. Our proposed PUE successfully facilitates expressive speech synthesis of unseen emotions in a zero-shot setting.","authors":["Xiaoxue Gao","Huayun Zhang","Nancy F. Chen"],"url":"https://arxiv.org/abs/2506.02742"}
{"created":"2025-06-04","title":"A priori error estimates for the $\\theta$-method for the flow of nonsmooth velocity fields","abstract":"Velocity fields with low regularity (below the Lipschitz threshold) naturally arise in many models from mathematical physics, such as the inhomogeneous incompressible Navier-Stokes equations, and play a fundamental role in the analysis of nonlinear PDEs. The DiPerna-Lions theory ensures existence and uniqueness of the flow associated with a divergence-free velocity field with Sobolev regularity. In this paper, we establish a priori error estimates showing a logarithmic rate of convergence of numerical solutions, constructed via the $\\theta$-method, towards the exact (analytic) flow for a velocity field with Sobolev regularity. In addition, we derive analogous a priori error estimates for Lagrangian solutions of the associated transport equation, exhibiting the same logarithmic rate of convergence. Our theoretical results are supported by numerical experiments, which confirm the predicted logarithmic behavior.","authors":["Gennaro Ciampa","Tommaso Cortopassi","Gianluca Crippa","Raffaele D'Ambrosio","Stefano Spirito"],"url":"https://arxiv.org/abs/2506.02747"}
{"created":"2025-06-04","title":"Safely Learning Controlled Stochastic Dynamics","abstract":"We address the problem of safely learning controlled stochastic dynamics from discrete-time trajectory observations, ensuring system trajectories remain within predefined safe regions during both training and deployment. Safety-critical constraints of this kind are crucial in applications such as autonomous robotics, finance, and biomedicine. We introduce a method that ensures safe exploration and efficient estimation of system dynamics by iteratively expanding an initial known safe control set using kernel-based confidence bounds. After training, the learned model enables predictions of the system's dynamics and permits safety verification of any given control. Our approach requires only mild smoothness assumptions and access to an initial safe control set, enabling broad applicability to complex real-world systems. We provide theoretical guarantees for safety and derive adaptive learning rates that improve with increasing Sobolev regularity of the true dynamics. Experimental evaluations demonstrate the practical effectiveness of our method in terms of safety, estimation accuracy, and computational efficiency.","authors":["Luc Brogat-Motte","Alessandro Rudi","Riccardo Bonalli"],"url":"https://arxiv.org/abs/2506.02754"}
{"created":"2025-06-04","title":"A Hierarchical Integer Linear Programming Approach for Optimizing Team Formation in Education","abstract":"Teamwork is integral to higher education, fostering students' interpersonal skills, improving learning outcomes, and preparing them for professional collaboration later in their careers. While team formation has traditionally been managed by humans, either instructors or students, algorithmic approaches have recently emerged to optimize this process. However, existing algorithmic team formation methods often focus on expert teams, overlook agency in choosing one's teammates, and are limited to a single team formation setting. These limitations make them less suitable for education, where no student can be left out, student agency is crucial for motivation, and team formation needs vary across courses and programs. In this paper, we introduce the EDUCATIONAL TEAM FORMATION problem (EDU-TF), a partitioning optimization problem model tailored to the unique needs of education, integrating both teacher and student requirements. To solve EDU-TF, we propose a modular optimization approach, one of the first to allow the flexible adjustment of objectives according to educational needs, enhancing the method's applicability across various classroom settings rather than just research environments. Results from evaluating ten strategies derived from our model on real-world university datasets indicate that our approach outperforms heuristic teacher-assigned teams by better accommodating student preferences. Our study contributes a new modular approach to partition-based algorithmic team formation and provides valuable insights for future research on team formation in educational settings.","authors":["Aaron Kessler","Tim Scheiber","Heinz Schmitz","Ioanna Lykourentzou"],"url":"https://arxiv.org/abs/2506.02756"}
{"created":"2025-06-04","title":"AuralNet: Hierarchical Attention-based 3D Binaural Localization of Overlapping Speakers","abstract":"We propose AuralNet, a novel 3D multi-source binaural sound source localization approach that localizes overlapping sources in both azimuth and elevation without prior knowledge of the number of sources. AuralNet employs a gated coarse-tofine architecture, combining a coarse classification stage with a fine-grained regression stage, allowing for flexible spatial resolution through sector partitioning. The model incorporates a multi-head self-attention mechanism to capture spatial cues in binaural signals, enhancing robustness in noisy-reverberant environments. A masked multi-task loss function is designed to jointly optimize sound detection, azimuth, and elevation estimation. Extensive experiments in noisy-reverberant conditions demonstrate the superiority of AuralNet over recent methods","authors":["Linya Fu","Yu Liu","Zhijie Liu","Zedong Yang","Zhong-Qiu Wang","Youfu Li","He Kong"],"url":"https://arxiv.org/abs/2506.02773"}
{"created":"2025-06-04","title":"A mesoscale phase-field model of intergranular liquid lithium corrosion of ferritic/martensitic steels","abstract":"A phase-field model is developed to simulate intergranular corrosion of ferritic/martensitic steels exposed to liquid lithium. The chromium concentration of the material is used to track the mass transport within the metal and liquid (corrosive) phase. The framework naturally captures intergranular corrosion by enhancing the diffusion of chromium along grain boundaries relative to the grain bulk with no special treatment for the corrosion front evolution. The formulation applies to arbitrary 2D and 3D polycrystalline geometries. The framework reproduces experimental measurements of weight loss and corrosion depth for a 9 wt\\% Cr ferritic/martensitic steel exposed to static lithium at 600 $^\\circ$C. A sensitivity analysis, varying near-surface grain density, grain size, and chromium depletion thickness, highlights the microstructural influence in the corrosion process. Moreover, the significance of saturation is considered and evaluated. Simulation results show that near-surface grain density is a deciding factor, whereas grain size dictates the susceptibility to intergranular corrosion.","authors":["A. Lhoest","S. Kovacevic","D. Nguyen-Manh","J. Lim","E. Mart\\'inez-Pa\\~neda","M. Wenman"],"url":"https://arxiv.org/abs/2506.02776"}
{"created":"2025-06-04","title":"On the influence of language similarity in non-target speaker verification trials","abstract":"In this paper, we investigate the influence of language similarity in cross-lingual non-target speaker verification trials using a state-of-the-art speaker verification system, ECAPA-TDNN, trained on multilingual and monolingual variants of the VoxCeleb dataset. Our analysis of the score distribution patterns on multilingual Globalphone and LDC CTS reveals a clustering effect in speaker comparisons involving a training language, whereby the choice of comparison language only minimally impacts scores. Conversely, we observe a language similarity effect in trials involving languages not included in the training set of the speaker verification system, with scores correlating with language similarity measured by a language classification system, especially when using multilingual training data.","authors":["Paul M. Reuter","Michael Jessen"],"url":"https://arxiv.org/abs/2506.02777"}
{"created":"2025-06-04","title":"Stacking the Odds: Full-Stack Quantum System Design Space Exploration","abstract":"Design space exploration (DSE) plays an important role in optimising quantum circuit execution by systematically evaluating different configurations of compilation strategies and hardware settings. In this work, we study the impact of layout methods, qubit routing techniques, compiler optimization levels, and hardware-specific properties, including noise characteristics, topological structures, connectivity densities, and device sizes. By traversing these dimensions, we aim to understand how compilation choices interact with hardware features. A central question in our study is whether carefully selected device parameters and mapping strategies, including initial layouts and routing heuristics, can mitigate hardware-induced errors beyond standard error mitigation methods. Our results show that choosing the right software strategies (e.g., layout and routing) and tailoring hardware properties (e.g., reducing noise or leveraging connectivity) significantly enhances the fidelity of quantum circuit executions. We provide performance estimates using metrics such as circuit depth, gate count, and expected fidelity. These findings highlight the value of hardware-software co-design, especially as quantum systems scale and move toward error-corrected computing. Our simulations, though noisy, include quantum error correction (QEC) scenarios, revealing similar sensitivities to layout and connectivity. This suggests that co-design principles will be vital for integrating QEC in future devices. Overall, we offer practical guidance for co-optimizing mapping, routing, and hardware configuration in real-world quantum computing.","authors":["Hila Safi","Medina Bandic","Christoph Niedermeier","Carmen G. Almudever","Sebastian Feld","Wolfgang Mauerer"],"url":"https://arxiv.org/abs/2506.02782"}
{"created":"2025-06-04","title":"Doubly-Robust Estimation of Counterfactual Policy Mean Embeddings","abstract":"Estimating the distribution of outcomes under counterfactual policies is critical for decision-making in domains such as recommendation, advertising, and healthcare. We analyze a novel framework-Counterfactual Policy Mean Embedding (CPME)-that represents the entire counterfactual outcome distribution in a reproducing kernel Hilbert space (RKHS), enabling flexible and nonparametric distributional off-policy evaluation. We introduce both a plug-in estimator and a doubly robust estimator; the latter enjoys improved uniform convergence rates by correcting for bias in both the outcome embedding and propensity models. Building on this, we develop a doubly robust kernel test statistic for hypothesis testing, which achieves asymptotic normality and thus enables computationally efficient testing and straightforward construction of confidence intervals. Our framework also supports sampling from the counterfactual distribution. Numerical simulations illustrate the practical benefits of CPME over existing methods.","authors":["Houssam Zenati","Bariscan Bozkurt","Arthur Gretton"],"url":"https://arxiv.org/abs/2506.02793"}
{"created":"2025-06-04","title":"Optimization of Robotic Liquid Handling as a Capacitated Vehicle Routing Problem","abstract":"We present an optimization strategy to reduce the execution time of liquid handling operations in the context of an automated chemical laboratory. By formulating the task as a capacitated vehicle routing problem (CVRP), we leverage heuristic solvers traditionally used in logistics and transportation planning to optimize task execution times. As exemplified using an 8-channel pipette with individually controllable tips, our approach demonstrates robust optimization performance across different labware formats (e.g., well-plates, vial holders), achieving up to a 37% reduction in execution time for randomly generated tasks compared to the baseline sorting method. We further apply the method to a real-world high-throughput materials discovery campaign and observe that 3 minutes of optimization time led to a reduction of 61 minutes in execution time compared to the best-performing sorting-based strategy. Our results highlight the potential for substantial improvements in throughput and efficiency in automated laboratories without any hardware modifications. This optimization strategy offers a practical and scalable solution to accelerate combinatorial experimentation in areas such as drug combination screening, reaction condition optimization, materials development, and formulation engineering.","authors":["Guangqi Wu","Runzhong Wang","Connor W. Coley"],"url":"https://arxiv.org/abs/2506.02795"}
{"created":"2025-06-04","title":"Deep Learning Enhanced Multivariate GARCH","abstract":"This paper introduces a novel multivariate volatility modeling framework, named Long Short-Term Memory enhanced BEKK (LSTM-BEKK), that integrates deep learning into multivariate GARCH processes. By combining the flexibility of recurrent neural networks with the econometric structure of BEKK models, our approach is designed to better capture nonlinear, dynamic, and high-dimensional dependence structures in financial return data. The proposed model addresses key limitations of traditional multivariate GARCH-based methods, particularly in capturing persistent volatility clustering and asymmetric co-movement across assets. Leveraging the data-driven nature of LSTMs, the framework adapts effectively to time-varying market conditions, offering improved robustness and forecasting performance. Empirical results across multiple equity markets confirm that the LSTM-BEKK model achieves superior performance in terms of out-of-sample portfolio risk forecast, while maintaining the interpretability from the BEKK models. These findings highlight the potential of hybrid econometric-deep learning models in advancing financial risk management and multivariate volatility forecasting.","authors":["Haoyuan Wang","Chen Liu","Minh-Ngoc Tran","Chao Wang"],"url":"https://arxiv.org/abs/2506.02796"}
{"created":"2025-06-04","title":"Fast-Converging Distributed Signal Estimation in Topology-Unconstrained Wireless Acoustic Sensor Networks","abstract":"This paper focuses on distributed signal estimation in topology-unconstrained wireless acoustic sensor networks (WASNs) where sensor nodes only transmit fused versions of their local sensor signals. For this task, the topology-independent (TI) distributed adaptive node-specific signal estimation (DANSE) algorithm (TI-DANSE) has previously been proposed. It converges towards the centralized signal estimation solution in non-fully connected and time-varying network topologies. However, the applicability of TI-DANSE in real-world scenarios is limited due to its slow convergence. The latter results from the fact that, in TI-DANSE, nodes only have access to the in-network sum of all fused signals in the WASN. We address this low convergence speed by introducing an improved TI-DANSE algorithm, referred to as TI-DANSE+, in which updating nodes separately use the partial in-network sums of fused signals coming from each of their neighbors. Nodes can maximize the number of available degrees of freedom in their local optimization problem, leading to faster convergence. This is further exploited by combining TI-DANSE+ with a tree-pruning strategy that maximizes the number of neighbors at the updating node. In fully connected WASNs, TI-DANSE+ converges as fast as the original DANSE algorithm (the latter only defined for fully connected WASNs) while using peer-to-peer data transmission instead of broadcasting and thus saving communication bandwidth. If link failures occur, the convergence of TI-DANSE+ towards the centralized solution is preserved without any change in its formulation. Altogether, the proposed TI-DANSE+ algorithm can be viewed as an all-round alternative to DANSE and TI-DANSE which (i) merges the advantages of both, (ii) reconciliates their differences into a single formulation, and (iii) shows advantages of its own in terms of communication bandwidth usage.","authors":["Paul Didier","Toon van Waterschoot","Simon Doclo","J\\\"org Bitzer","Marc Moonen"],"url":"https://arxiv.org/abs/2506.02797"}
{"created":"2025-06-04","title":"Brain-Like Processing Pathways Form in Models With Heterogeneous Experts","abstract":"The brain is made up of a vast set of heterogeneous regions that dynamically organize into pathways as a function of task demands. Examples of such pathways can be seen in the interactions between cortical and subcortical networks during learning. This raises the question of how exactly brain regions organize into these dynamic groups. In this work, we use an extension of the Heterogeneous Mixture-of-Experts architecture, to show that heterogeneous regions do not form processing pathways by themselves, implying that the brain likely implements specific constraints which result in reliable formation of pathways. We identify three biologically relevant inductive biases that encourage pathway formation: a routing cost imposed on the use of more complex regions, a scaling factor that reduces this cost when task performance is low, and randomized expert dropout. When comparing our resulting Mixture-of-Pathways model with the brain, we observe that the artificial pathways match how the brain uses cortical and subcortical systems to learn and solve tasks of varying difficulty. In summary, we introduce a novel framework for investigating how the brain forms task-specific pathways through inductive biases which may make Mixture-of-Experts architectures in general more adaptive.","authors":["Jack Cook","Danyal Akarca","Rui Ponte Costa","Jascha Achterberg"],"url":"https://arxiv.org/abs/2506.02813"}
{"created":"2025-06-04","title":"Asymptotically perfect seeded graph matching without edge correlation (and applications to inference)","abstract":"We present the OmniMatch algorithm for seeded multiple graph matching. In the setting of $d$-dimensional Random Dot Product Graphs (RDPG), we prove that under mild assumptions, OmniMatch with $s$ seeds asymptotically and efficiently perfectly aligns $O(s^{\\alpha})$ unseeded vertices -- for $\\alpha<2\\wedge d/4$ -- across multiple networks even in the presence of no edge correlation. We demonstrate the effectiveness of our algorithm across numerous simulations and in the context of shuffled graph hypothesis testing. In the shuffled testing setting, testing power is lost due to the misalignment/shuffling of vertices across graphs, and we demonstrate the capacity of OmniMatch to correct for misaligned vertices prior to testing and hence recover the lost testing power. We further demonstrate the algorithm on a pair of data examples from connectomics and machine translation.","authors":["Tong Qi","Vera Andersson","Peter Viechnicki","Vince Lyzinski"],"url":"https://arxiv.org/abs/2506.02825"}
{"created":"2025-06-04","title":"CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech","abstract":"Recent advancements in generative artificial intelligence have significantly transformed the field of style-captioned text-to-speech synthesis (CapTTS). However, adapting CapTTS to real-world applications remains challenging due to the lack of standardized, comprehensive datasets and limited research on downstream tasks built upon CapTTS. To address these gaps, we introduce CapSpeech, a new benchmark designed for a series of CapTTS-related tasks, including style-captioned text-to-speech synthesis with sound events (CapTTS-SE), accent-captioned TTS (AccCapTTS), emotion-captioned TTS (EmoCapTTS), and text-to-speech synthesis for chat agent (AgentTTS). CapSpeech comprises over 10 million machine-annotated audio-caption pairs and nearly 0.36 million human-annotated audio-caption pairs. In addition, we introduce two new datasets collected and recorded by a professional voice actor and experienced audio engineers, specifically for the AgentTTS and CapTTS-SE tasks. Alongside the datasets, we conduct comprehensive experiments using both autoregressive and non-autoregressive models on CapSpeech. Our results demonstrate high-fidelity and highly intelligible speech synthesis across a diverse range of speaking styles. To the best of our knowledge, CapSpeech is the largest available dataset offering comprehensive annotations for CapTTS-related tasks. The experiments and findings further provide valuable insights into the challenges of developing CapTTS systems.","authors":["Helin Wang","Jiarui Hai","Dading Chong","Karan Thakkar","Tiantian Feng","Dongchao Yang","Junhyeok Lee","Laureano Moro Velazquez","Jesus Villalba","Zengyi Qin","Shrikanth Narayanan","Mounya Elhiali","Najim Dehak"],"url":"https://arxiv.org/abs/2506.02863"}
{"created":"2025-06-04","title":"Simulation-Based Inference for Adaptive Experiments","abstract":"Multi-arm bandit experimental designs are increasingly being adopted over standard randomized trials due to their potential to improve outcomes for study participants, enable faster identification of the best-performing options, and/or enhance the precision of estimating key parameters. Current approaches for inference after adaptive sampling either rely on asymptotic normality under restricted experiment designs or underpowered martingale concentration inequalities that lead to weak power in practice. To bypass these limitations, we propose a simulation-based approach for conducting hypothesis tests and constructing confidence intervals for arm specific means and their differences. Our simulation-based approach uses positively biased nuisances to generate additional trajectories of the experiment, which we call \\textit{simulation with optimism}. Using these simulations, we characterize the distribution potentially non-normal sample mean test statistic to conduct inference. We provide guarantees for (i) asymptotic type I error control, (ii) convergence of our confidence intervals, and (iii) asymptotic strong consistency of our estimator over a wide variety of common bandit designs. Our empirical results show that our approach achieves the desired coverage while reducing confidence interval widths by up to 50%, with drastic improvements for arms not targeted by the design.","authors":["Brian M Cho","Aur\\'elien Bibaut","Nathan Kallus"],"url":"https://arxiv.org/abs/2506.02881"}
{"created":"2025-06-04","title":"Diffusion Buffer: Online Diffusion-based Speech Enhancement with Sub-Second Latency","abstract":"Diffusion models are a class of generative models that have been recently used for speech enhancement with remarkable success but are computationally expensive at inference time. Therefore, these models are impractical for processing streaming data in real-time. In this work, we adapt a sliding window diffusion framework to the speech enhancement task. Our approach progressively corrupts speech signals through time, assigning more noise to frames close to the present in a buffer. This approach outputs denoised frames with a delay proportional to the chosen buffer size, enabling a trade-off between performance and latency. Empirical results demonstrate that our method outperforms standard diffusion models and runs efficiently on a GPU, achieving an input-output latency in the order of 0.3 to 1 seconds. This marks the first practical diffusion-based solution for online speech enhancement.","authors":["Bunlong Lay","Rostilav Makarov","Timo Gerkmann"],"url":"https://arxiv.org/abs/2506.02908"}
{"created":"2025-06-04","title":"Quantum Data Centers: Why Entanglement Changes Everything","abstract":"The Quantum Internet is key for distributed quantum computing, by interconnecting multiple quantum processors into a virtual quantum computation system. This allows to scale the number of qubits, by overcoming the inherent limitations of noisy-intermediate-scale quantum (NISQ) devices. Thus, the Quantum Internet is the foundation for large-scale, fault-tolerant quantum computation. Among the distributed architectures, Quantum Data Centers emerge as the most viable in the medium-term, since they integrate multiple quantum processors within a localized network infrastructure, by allowing modular design of quantum networking. We analyze the physical and topological constraints of Quantum Data Centers, by emphasizing the role of entanglement orchestrators in dynamically reconfiguring network topologies through local operations. We examine the major hardware challenge of quantum transduction, essential for interfacing heterogeneous quantum systems. Furthermore, we explore how interconnecting multiple Quantum Data Centers could enable large-scale quantum networks. We discuss the topological constraints of such a scaling and identify open challenges, including entanglement routing and synchronization. The carried analysis positions Quantum Data Centers as both a practical implementation platform and strategic framework for the future Quantum Internet.","authors":["Angela Sara Cacciapuoti","Claudio Pellitteri","Jessica Illiano","Laura d'Avossa","Francesco Mazza","Siyi Chen","Marcello Caleffi"],"url":"https://arxiv.org/abs/2506.02920"}
{"created":"2025-06-04","title":"PartialEdit: Identifying Partial Deepfakes in the Era of Neural Speech Editing","abstract":"Neural speech editing enables seamless partial edits to speech utterances, allowing modifications to selected content while preserving the rest of the audio unchanged. This useful technique, however, also poses new risks of deepfakes. To encourage research on detecting such partially edited deepfake speech, we introduce PartialEdit, a deepfake speech dataset curated using advanced neural editing techniques. We explore both detection and localization tasks on PartialEdit. Our experiments reveal that models trained on the existing PartialSpoof dataset fail to detect partially edited speech generated by neural speech editing models. As recent speech editing models almost all involve neural audio codecs, we also provide insights into the artifacts the model learned on detecting these deepfakes. Further information about the PartialEdit dataset and audio samples can be found on the project page: https://yzyouzhang.com/PartialEdit/index.html.","authors":["You Zhang","Baotong Tian","Lin Zhang","Zhiyao Duan"],"url":"https://arxiv.org/abs/2506.02958"}
{"created":"2025-06-04","title":"Non-stationary Bandit Convex Optimization: A Comprehensive Study","abstract":"Bandit Convex Optimization is a fundamental class of sequential decision-making problems, where the learner selects actions from a continuous domain and observes a loss (but not its gradient) at only one point per round. We study this problem in non-stationary environments, and aim to minimize the regret under three standard measures of non-stationarity: the number of switches $S$ in the comparator sequence, the total variation $\\Delta$ of the loss functions, and the path-length $P$ of the comparator sequence. We propose a polynomial-time algorithm, Tilted Exponentially Weighted Average with Sleeping Experts (TEWA-SE), which adapts the sleeping experts framework from online convex optimization to the bandit setting. For strongly convex losses, we prove that TEWA-SE is minimax-optimal with respect to known $S$ and $\\Delta$ by establishing matching upper and lower bounds. By equipping TEWA-SE with the Bandit-over-Bandit framework, we extend our analysis to environments with unknown non-stationarity measures. For general convex losses, we introduce a second algorithm, clipped Exploration by Optimization (cExO), based on exponential weights over a discretized action space. While not polynomial-time computable, this method achieves minimax-optimal regret with respect to known $S$ and $\\Delta$, and improves on the best existing bounds with respect to $P$.","authors":["Xiaoqi Liu","Dorian Baudry","Julian Zimmert","Patrick Rebeschini","Arya Akhavan"],"url":"https://arxiv.org/abs/2506.02980"}
{"created":"2025-06-04","title":"Bounded Discrete Bridges","abstract":"In 2010 Banderier and Nicodeme consider the height of bounded discrete bridges and conclude to a limiting Rayleigh distribution. This result is correct although their proof is partly erroneous. They make asymptotic simplifications based upon dominance properties of the roots of the kernel of the walk within a disk centered at the origin, but these dominance properties apply only upon a positive real segment. However the very good agreement of simulations with their asymptotic expansion of the probability distribution in case of {\\L}ukasiewicz bridges let us think that their proof could be corrected. This is the scope of the present article which provides","authors":["Pierre Nicodeme"],"url":"https://arxiv.org/abs/2506.02982"}
{"created":"2025-06-04","title":"Convergence and efficiency proof of quantum imaginary time evolution for bounded order systems","abstract":"Many current and near-future applications of quantum computing utilise parametric families of quantum circuits and variational methods to find optimal values for these parameters. Solving a quantum computational problem with such variational methods relies on minimising some cost function, e.g., the energy of a physical system. As such, this is similar to the training process in machine learning and variational quantum simulations can therefore suffer from similar problems encountered in machine learning training. This includes non-convergence to the global minimum due to local minima as well as critical slowing down. In this article, we analyse the imaginary time evolution as a means of compiling parametric quantum circuits and finding optimal parameters, and show that it guarantees convergence to the global minimum without critical slowing down. We also show that the compilation process, including the task of finding optimal parameters, can be performed efficiently up to an arbitrary error threshold if the underlying physical system is of bounded order. This includes many relevant computational problems, e.g., local physical theories and combinatorial optimisation problems such as the flight-to-gate assignment problem. In particular, we show a priori estimates on the success probability for these combinatorial optimisation problems. There seem to be no known classical methods with similar efficiency and convergence guarantees. Meanwhile the imaginary time evolution method can be implemented on current quantum computers.","authors":["Tobias Hartung","Karl Jansen"],"url":"https://arxiv.org/abs/2506.03014"}
{"created":"2025-06-04","title":"On the Benefits of Accelerated Optimization in Robust and Private Estimation","abstract":"We study the advantages of accelerated gradient methods, specifically based on the Frank-Wolfe method and projected gradient descent, for privacy and heavy-tailed robustness. Our approaches are as follows: For the Frank-Wolfe method, our technique is based on a tailored learning rate and a uniform lower bound on the gradient of the $\\ell_2$-norm over the constraint set. For accelerating projected gradient descent, we use the popular variant based on Nesterov's momentum, and we optimize our objective over $\\mathbb{R}^p$. These accelerations reduce iteration complexity, translating into stronger statistical guarantees for empirical and population risk minimization. Our analysis covers three settings: non-random data, random model-free data, and parametric models (linear regression and generalized linear models). Methodologically, we approach both privacy and robustness based on noisy gradients. We ensure differential privacy via the Gaussian mechanism and advanced composition, and we achieve heavy-tailed robustness using a geometric median-of-means estimator, which also sharpens the dependency on the dimension of the covariates. Finally, we compare our rates to existing bounds and identify scenarios where our methods attain optimal convergence.","authors":["Laurentiu Andrei Marchis","Po-Ling Loh"],"url":"https://arxiv.org/abs/2506.03044"}
{"created":"2025-06-04","title":"Torsion in Persistent Homology and Neural Networks","abstract":"We explore the role of torsion in hybrid deep learning models that incorporate topological data analysis, focusing on autoencoders. While most TDA tools use field coefficients, this conceals torsional features present in integer homology. We show that torsion can be lost during encoding, altered in the latent space, and in many cases, not reconstructed by standard decoders. Using both synthetic and high-dimensional data, we evaluate torsion sensitivity to perturbations and assess its recoverability across several autoencoder architectures. Our findings reveal key limitations of field-based approaches and underline the need for architectures or loss terms that preserve torsional information for robust data representation.","authors":["Maria Walch"],"url":"https://arxiv.org/abs/2506.03049"}
{"created":"2025-06-04","title":"Adversarial quantum channel discrimination","abstract":"We introduce a new framework for quantum channel discrimination in an adversarial setting, where the tester plays against an adversary who accesses the environmental system and possesses internal quantum memory to perform adaptive strategies. We show that in asymmetric hypothesis testing, the optimal type-II error exponent is precisely characterized by the minimum output channel divergence, a new notion of quantum channel divergence in the worst-case scenario. This serves as a direct analog of the quantum Stein's lemma in the adversarial channel discrimination. Notably, the optimal error exponent can be achieved via simple non-adaptive strategies by the adversary, and its value can be efficiently computed despite its regularization. The strong converse property for quantum channel discrimination also holds in general. This adversarial quantum Stein's lemma is proved by new chain rules for measured and sandwiched relative entropies. Moreover, we derive a generalized version of the entropy accumulation theorem between two arbitrary sequences of quantum channels, extending the existing results from entropy to divergence and providing a solution to the dual formulation of the open problem presented in [IEEE FOCS, pp. 844-850 (2022)].","authors":["Kun Fang","Hamza Fawzi","Omar Fawzi"],"url":"https://arxiv.org/abs/2506.03060"}
{"created":"2025-06-04","title":"Causal Explainability of Machine Learning in Heart Failure Prediction from Electronic Health Records","abstract":"The importance of clinical variables in the prognosis of the disease is explained using statistical correlation or machine learning (ML). However, the predictive importance of these variables may not represent their causal relationships with diseases. This paper uses clinical variables from a heart failure (HF) patient cohort to investigate the causal explainability of important variables obtained in statistical and ML contexts. Due to inherent regression modeling, popular causal discovery methods strictly assume that the cause and effect variables are numerical and continuous. This paper proposes a new computational framework to enable causal structure discovery (CSD) and score the causal strength of mixed-type (categorical, numerical, binary) clinical variables for binary disease outcomes. In HF classification, we investigate the association between the importance rank order of three feature types: correlated features, features important for ML predictions, and causal features. Our results demonstrate that CSD modeling for nonlinear causal relationships is more meaningful than its linear counterparts. Feature importance obtained from nonlinear classifiers (e.g., gradient-boosting trees) strongly correlates with the causal strength of variables without differentiating cause and effect variables. Correlated variables can be causal for HF, but they are rarely identified as effect variables. These results can be used to add the causal explanation of variables important for ML-based prediction modeling.","authors":["Yina Hou","Shourav B. Rabbani","Liang Hong","Norou Diawara","Manar D. Samad"],"url":"https://arxiv.org/abs/2506.03068"}
{"created":"2025-06-04","title":"GL-LowPopArt: A Nearly Instance-Wise Minimax Estimator for Generalized Low-Rank Trace Regression","abstract":"We present `GL-LowPopArt`, a novel Catoni-style estimator for generalized low-rank trace regression. Building on `LowPopArt` (Jang et al., 2024), it employs a two-stage approach: nuclear norm regularization followed by matrix Catoni estimation. We establish state-of-the-art estimation error bounds, surpassing existing guarantees (Fan et al., 2019; Kang et al., 2022), and reveal a novel experimental design objective, $\\mathrm{GL}(\\pi)$. The key technical challenge is controlling bias from the nonlinear inverse link function, which we address by our two-stage approach. We prove a *local* minimax lower bound, showing that our `GL-LowPopArt` enjoys instance-wise optimality up to the condition number of the ground-truth Hessian. Applications include generalized linear matrix completion, where `GL-LowPopArt` achieves a state-of-the-art Frobenius error guarantee, and **bilinear dueling bandits**, a novel setting inspired by general preference learning (Zhang et al., 2024). Our analysis of a `GL-LowPopArt`-based explore-then-commit algorithm reveals a new, potentially interesting problem-dependent quantity, along with improved Borda regret bound than vectorization (Wu et al., 2024).","authors":["Junghyun Lee","Kyoungseok Jang","Kwang-Sung Jun","Milan Vojnovi\\'c","Se-Young Yun"],"url":"https://arxiv.org/abs/2506.03074"}
{"created":"2025-06-04","title":"Modelling the Effects of Hearing Loss on Neural Coding in the Auditory Midbrain with Variational Conditioning","abstract":"The mapping from sound to neural activity that underlies hearing is highly non-linear. The first few stages of this mapping in the cochlea have been modelled successfully, with biophysical models built by hand and, more recently, with DNN models trained on datasets simulated by biophysical models. Modelling the auditory brain has been a challenge because central auditory processing is too complex for models to be built by hand, and datasets for training DNN models directly have not been available. Recent work has taken advantage of large-scale high resolution neural recordings from the auditory midbrain to build a DNN model of normal hearing with great success. But this model assumes that auditory processing is the same in all brains, and therefore it cannot capture the widely varying effects of hearing loss.","authors":["Lloyd Pellatt","Fotios Drakopoulos","Shievanie Sabesan","Nicholas A. Lesica"],"url":"https://arxiv.org/abs/2506.03088"}
{"created":"2025-06-04","title":"Validating remotely sensed biomass estimates with forest inventory data in the western US","abstract":"Monitoring aboveground biomass (AGB) and its density (AGBD) at high resolution is essential for carbon accounting and ecosystem management. While NASA's spaceborne Global Ecosystem Dynamics Investigation (GEDI) LiDAR mission provides globally distributed reference measurements for AGBD estimation, the majority of commercial remote sensing products based on GEDI remain without rigorous or independent validation. Here, we present an independent regional validation of an AGBD dataset offered by terraPulse, Inc., based on independent reference data from the US Forest Service Forest Inventory and Analysis (FIA) program. Aggregated to 64,000-hectare hexagons and US counties across the US states of Utah, Nevada, and Washington, we found very strong agreement between terraPulse and FIA estimates. At the hexagon scale, we report R2 = 0.88, RMSE = 26.68 Mg/ha, and a correlation coefficient (r) of 0.94. At the county scale, agreement improves to R2 = 0.90, RMSE =32.62 Mg/ha, slope = 1.07, and r = 0.95. Spatial and statistical analyses indicated that terraPulse AGBD values tended to exceed FIA estimates in non-forest areas, likely due to FIA's limited sampling of non-forest vegetation. The terraPulse AGBD estimates also exhibited lower values in high-biomass forests, likely due to saturation effects in its optical remote-sensing covariates. This study advances operational carbon monitoring by delivering a scalable framework for comprehensive AGBD validation using independent FIA data, as well as a benchmark validation of a new commercial dataset for global biomass monitoring.","authors":["Xiuyu Cao","Joseph O. Sexton","Panshi Wang","Dimitrios Gounaridis","Neil H. Carter","Kai Zhu"],"url":"https://arxiv.org/abs/2506.03120"}
{"created":"2025-06-04","title":"Simulate Any Radar: Attribute-Controllable Radar Simulation via Waveform Parameter Embedding","abstract":"We present SA-Radar (Simulate Any Radar), a radar simulation approach that enables controllable and efficient generation of radar cubes conditioned on customizable radar attributes. Unlike prior generative or physics-based simulators, SA-Radar integrates both paradigms through a waveform-parameterized attribute embedding. We design ICFAR-Net, a 3D U-Net conditioned on radar attributes encoded via waveform parameters, which captures signal variations induced by different radar configurations. This formulation bypasses the need for detailed radar hardware specifications and allows efficient simulation of range-azimuth-Doppler (RAD) tensors across diverse sensor settings. We further construct a mixed real-simulated dataset with attribute annotations to robustly train the network. Extensive evaluations on multiple downstream tasks-including 2D/3D object detection and radar semantic segmentation-demonstrate that SA-Radar's simulated data is both realistic and effective, consistently improving model performance when used standalone or in combination with real data. Our framework also supports simulation in novel sensor viewpoints and edited scenes, showcasing its potential as a general-purpose radar data engine for autonomous driving applications. Code and additional materials are available at https://zhuxing0.github.io/projects/SA-Radar.","authors":["Weiqing Xiao","Hao Huang","Chonghao Zhong","Yujie Lin","Nan Wang","Xiaoxue Chen","Zhaoxi Chen","Saining Zhang","Shuocheng Yang","Pierre Merriaux","Lei Lei","Hao Zhao"],"url":"https://arxiv.org/abs/2506.03134"}
{"created":"2025-06-04","title":"Automatic Cross-Domain Transfer Learning for Linear Regression","abstract":"Transfer learning research attempts to make model induction transferable across different domains. This method assumes that specific information regarding to which domain each instance belongs is known. This paper helps to extend the capability of transfer learning for linear regression problems to situations where the domain information is uncertain or unknown; in fact, the framework can be extended to classification problems. For normal datasets, we assume that some latent domain information is available for transfer learning. The instances in each domain can be inferred by different parameters. We obtain this domain information from the distribution of the regression coefficients corresponding to the explanatory variable $x$ as well as the response variable $y$ based on a Dirichlet process, which is more reasonable. As a result, we transfer not only variable $x$ as usual but also variable $y$, which is challenging since the testing data have no response value. Previous work mainly overcomes the problem via pseudo-labelling based on transductive learning, which introduces serious bias. We provide a novel framework for analysing the problem and considering this general situation: the joint distribution of variable $x$ and variable $y$. Furthermore, our method controls the bias well compared with previous work. We perform linear regression on the new feature space that consists of different latent domains and the target domain, which is from the testing data. The experimental results show that the proposed model performs well on real datasets.","authors":["Xinshun Liu","He Xin","Mao Hui","Liu Jing","Lai Weizhong","Ye Qingwen"],"url":"https://arxiv.org/abs/2005.04088"}
{"created":"2025-06-04","title":"A new characterization of the convergence factor of two-level methods","abstract":"Multilevel methods are among the most efficient numerical methods for solving large-scale systems of equations that arise from discretized partial differential equations. Two-level convergence theory plays a fundamental role in the analysis and design of multilevel methods. In this paper, we present a concise and easy-to-use identity for characterizing the convergence factor of two-level methods, whose hierarchical spaces can be either overlapping or non-overlapping. In order to illustrate its usability and convenience, we give several applications, which offer new insights into the design of multilevel methods.","authors":["Xuefeng Xu"],"url":"https://arxiv.org/abs/2102.08600"}
{"created":"2025-06-04","title":"Can Character-based Language Models Improve Downstream Task Performance in Low-Resource and Noisy Language Scenarios?","abstract":"Recent impressive improvements in NLP, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high-resource languages. Building language models and, more generally, NLP systems for non-standardized and low-resource languages remains a challenging task. In this work, we focus on North-African colloquial dialectal Arabic written using an extension of the Latin script, called NArabizi, found mostly on social media and messaging communication. In this low-resource scenario with data displaying a high level of variability, we compare the downstream performance of a character-based language model on part-of-speech tagging and dependency parsing to that of monolingual and multilingual models. We show that a character-based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre-trained on large multilingual and monolingual models. Confirming these results a on much larger data set of noisy French user-generated content, we argue that such character-based language models can be an asset for NLP in low-resource and high language variability set-tings.","authors":["Arij Riabi","Beno\\^it Sagot","Djam\\'e Seddah"],"url":"https://arxiv.org/abs/2110.13658"}
{"created":"2025-06-04","title":"TransAug: Translate as Augmentation for Sentence Embeddings","abstract":"While contrastive learning greatly advances the representation of sentence embeddings, it is still limited by the size of the existing sentence datasets. In this paper, we present TransAug (Translate as Augmentation), which provide the first exploration of utilizing translated sentence pairs as data augmentation for text, and introduce a two-stage paradigm to advances the state-of-the-art sentence embeddings. Instead of adopting an encoder trained in other languages setting, we first distill a Chinese encoder from a SimCSE encoder (pretrained in English), so that their embeddings are close in semantic space, which can be regraded as implicit data augmentation. Then, we only update the English encoder via cross-lingual contrastive learning and frozen the distilled Chinese encoder. Our approach achieves a new state-of-art on standard semantic textual similarity (STS), outperforming both SimCSE and Sentence-T5, and the best performance in corresponding tracks on transfer tasks evaluated by SentEval.","authors":["Jue Wang"],"url":"https://arxiv.org/abs/2111.00157"}
{"created":"2025-06-04","title":"Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion","abstract":"Knowledge graphs (KGs) are powerful in terms of their inference abilities, but are also notorious for their incompleteness and long-tail distribution of relations. To address these challenges and expand the coverage of KGs, few-shot KG completion aims to make predictions for triplets involving novel relations when only a few training triplets are provided as reference. Previous methods have focused on designing local neighbor aggregators to learn entity-level information and/or imposing a potentially invalid sequential dependency assumption at the triplet level to learn meta relation information. However, pairwise triplet-level interactions and context-level relational information have been largely overlooked for learning meta representations of few-shot relations. In this paper, we propose a hierarchical relational learning method (HiRe) for few-shot KG completion. By jointly capturing three levels of relational information (entity-level, triplet-level and context-level), HiRe can effectively learn and refine meta representations of few-shot relations, and thus generalize well to new unseen relations. Extensive experiments on benchmark datasets validate the superiority of HiRe over state-of-the-art methods. The code can be found in https://github.com/alexhw15/HiRe.git.","authors":["Han Wu","Jie Yin","Bala Rajaratnam","Jianyuan Guo"],"url":"https://arxiv.org/abs/2209.01205"}
{"created":"2025-06-04","title":"Scene Structure Guidance Network: Unfolding Graph Partitioning into Pixel-Wise Feature Learning","abstract":"Understanding the informative structures of scenes is essential for low-level vision tasks. Unfortunately, it is difficult to obtain a concrete visual definition of the informative structures because influences of visual features are task-specific. In this paper, we propose a single general neural network architecture for extracting task-specific structure guidance for scenes. To do this, we first analyze traditional spectral clustering methods, which computes a set of eigenvectors to model a segmented graph forming small compact structures on image domains. We then unfold the traditional graph-partitioning problem into a learnable network, named \\textit{Scene Structure Guidance Network (SSGNet)}, to represent the task-specific informative structures. The SSGNet yields a set of coefficients of eigenvectors that produces explicit feature representations of image structures. In addition, our SSGNet is light-weight ($\\sim$ 56K parameters), and can be used as a plug-and-play module for off-the-shelf architectures. We optimize the SSGNet without any supervision by proposing two novel training losses that enforce task-specific scene structure generation during training. Our main contribution is to show that such a simple network can achieve state-of-the-art results for several low-level vision applications. We also demonstrate that our network generalizes well on unseen datasets, compared to existing methods which use structural embedding frameworks. We further propose a lighter version of SSGNet ($\\sim$ 29K parameters) for depth computation, SSGNet-D, and successfully execute it on edge computing devices like Jetson AGX Orin, improving the performance of baseline network, even in the wild, with little computational delay.","authors":["Jisu Shin","Seunghyun Shin","Hae-Gon Jeon"],"url":"https://arxiv.org/abs/2301.00555"}
{"created":"2025-06-04","title":"Improving Transformer Performance for French Clinical Notes Classification Using Mixture of Experts on a Limited Dataset","abstract":"Transformer-based models have shown outstanding results in natural language processing but face challenges in applications like classifying small-scale clinical texts, especially with constrained computational resources. This study presents a customized Mixture of Expert (MoE) Transformer models for classifying small-scale French clinical texts at CHU Sainte-Justine Hospital. The MoE-Transformer addresses the dual challenges of effective training with limited data and low-resource computation suitable for in-house hospital use. Despite the success of biomedical pre-trained models such as CamemBERT-bio, DrBERT, and AliBERT, their high computational demands make them impractical for many clinical settings. Our MoE-Transformer model not only outperforms DistillBERT, CamemBERT, FlauBERT, and Transformer models on the same dataset but also achieves impressive results: an accuracy of 87\\%, precision of 87\\%, recall of 85\\%, and F1-score of 86\\%. While the MoE-Transformer does not surpass the performance of biomedical pre-trained BERT models, it can be trained at least 190 times faster, offering a viable alternative for settings with limited data and computational resources. Although the MoE-Transformer addresses challenges of generalization gaps and sharp minima, demonstrating some limitations for efficient and accurate clinical text classification, this model still represents a significant advancement in the field. It is particularly valuable for classifying small French clinical narratives within the privacy and constraints of hospital-based computational resources.","authors":["Thanh-Dung Le","Philippe Jouvet","Rita Noumeir"],"url":"https://arxiv.org/abs/2303.12892"}
{"created":"2025-06-04","title":"Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning","abstract":"Bayesian optimization has attracted huge attention from diverse research areas in science and engineering, since it is capable of efficiently finding a global optimum of an expensive-to-evaluate black-box function. In general, a probabilistic regression model is widely used as a surrogate function to model an explicit distribution over function evaluations given an input to estimate and a training dataset. Beyond the probabilistic regression-based methods, density ratio estimation-based Bayesian optimization has been suggested in order to estimate a density ratio of the groups relatively close and relatively far to a global optimum. Developing this line of research further, supervised classifiers are employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy are prone to be overconfident for known knowledge on global solution candidates. Supposing that we have access to unlabeled points, e.g., predefined fixed-size pools, we propose density ratio estimation-based Bayesian optimization with semi-supervised learning to solve this challenge. Finally, we show the empirical results of our methods and several baseline methods in two distinct scenarios with unlabeled point sampling and a fixed-size pool, and analyze the validity of our methods in diverse experiments.","authors":["Jungtaek Kim"],"url":"https://arxiv.org/abs/2305.15612"}
{"created":"2025-06-04","title":"Learning to Specialize: Joint Gating-Expert Training for Adaptive MoEs in Decentralized Settings","abstract":"Mixture-of-Experts (MoEs) achieve scalability by dynamically activating subsets of their components. Yet, understanding how expertise emerges through joint training of gating mechanisms and experts remains incomplete, especially in scenarios without clear task partitions. Motivated by inference costs and data heterogeneity, we study how joint training of gating functions and experts can dynamically allocate domain-specific expertise across multiple underlying data distributions. As an outcome of our framework, we develop an instance tailored specifically to decentralized training scenarios, introducing \\textit{Dynamically Decentralized Orchestration of MoEs} or \\texttt{DDOME}. \\texttt{DDOME} leverages heterogeneity emerging from distributional shifts across decentralized data sources to specialize experts dynamically. By integrating a pretrained common expert to inform a gating function, \\texttt{DDOME} achieves personalized expert subset selection on-the-fly, facilitating just-in-time personalization. We empirically validate \\texttt{DDOME} within a Federated Learning (FL) context: \\texttt{DDOME} attains from 4\\% up to an 24\\% accuracy improvement over state-of-the-art FL baselines in image and text classification tasks, while maintaining competitive zero-shot generalization capabilities. Furthermore, we provide theoretical insights confirming that the joint gating-experts training is critical for achieving meaningful expert specialization.","authors":["Yehya Farhat","Hamza ElMokhtar Shili","Fangshuo Liao","Chen Dun","Mirian Hipolito Garcia","Guoqing Zheng","Ahmed Hassan Awadallah","Robert Sim","Dimitrios Dimitriadis","Anastasios Kyrillidis"],"url":"https://arxiv.org/abs/2306.08586"}
{"created":"2025-06-04","title":"An Isotonic Mechanism for Overlapping Ownership","abstract":"Motivated by the problem of improving peer review at large scientific conferences, this paper studies how to elicit self-evaluations to improve review scores in a natural many-to-many owner-item (e.g., author-paper) situation with overlapping ownership. We design a simple, efficient and truthful mechanism to elicit self-evaluations from item owners that can be used to calibrate their noisy review scores in the existing evaluation process (e.g., papers' review scores from peers).","authors":["Jibang Wu","Haifeng Xu","Yifan Guo","Weijie Su"],"url":"https://arxiv.org/abs/2306.11154"}
{"created":"2025-06-04","title":"Self-supervised Learning of Event-guided Video Frame Interpolation for Rolling Shutter Frames","abstract":"Most consumer cameras use rolling shutter (RS) exposure, which often leads to distortions such as skew and jelly effects. These videos are further limited by bandwidth and frame rate constraints. In this paper, we explore the potential of event cameras, which offer high temporal resolution. We propose a framework to recover global shutter (GS) high-frame-rate videos without RS distortion by combining an RS camera and an event camera. Due to the lack of real-world datasets, our framework adopts a self-supervised strategy based on a displacement field, a dense 3D spatiotemporal representation of pixel motion during exposure. This enables mutual reconstruction between RS and GS frames and facilitates slow-motion recovery. We combine RS frames with the displacement field to generate GS frames, and integrate inverse mapping and RS frame warping for self-supervision. Experiments on four datasets show that our method removes distortion, reduces bandwidth usage by 94 percent, and achieves 16 ms per frame at 32x interpolation.","authors":["Yunfan Lu","Guoqiang Liang","Yiran Shen","Lin Wang"],"url":"https://arxiv.org/abs/2306.15507"}
{"created":"2025-06-04","title":"Why Shallow Networks Struggle to Approximate and Learn High Frequencies","abstract":"In this work, we present a comprehensive study combining mathematical and computational analysis to explain why a two-layer neural network struggles to handle high frequencies in both approximation and learning, especially when machine precision, numerical noise, and computational cost are significant factors in practice. Specifically, we investigate the following fundamental computational issues: (1) the minimal numerical error achievable under finite precision, (2) the computational cost required to attain a given accuracy, and (3) the stability of the method with respect to perturbations. The core of our analysis lies in the conditioning of the representation and its learning dynamics. Explicit answers to these questions are provided, along with supporting numerical evidence.","authors":["Shijun Zhang","Hongkai Zhao","Yimin Zhong","Haomin Zhou"],"url":"https://arxiv.org/abs/2306.17301"}
{"created":"2025-06-04","title":"Efficient and Accurate Optimal Transport with Mirror Descent and Conjugate Gradients","abstract":"We propose Mirror Descent Optimal Transport (MDOT), a novel method for solving discrete optimal transport (OT) problems with high precision, by unifying temperature annealing in entropic-regularized OT (EOT) with mirror descent techniques. In this framework, temperature annealing produces a sequence of EOT dual problems, whose solution gradually gets closer to the solution of the original OT problem. We solve each problem efficiently using a GPU-parallel nonlinear conjugate gradients algorithm (PNCG) that outperforms traditional Sinkhorn iterations under weak regularization. Moreover, our investigation also reveals that the theoretical convergence rate of Sinkhorn iterations can exceed existing non-asymptotic bounds when its stopping criterion is tuned in a manner analogous to MDOT.","authors":["Mete Kemertas","Allan D. Jepson","Amir-massoud Farahmand"],"url":"https://arxiv.org/abs/2307.08507"}
{"created":"2025-06-04","title":"Learn With Imagination: Safe Set Guided State-wise Constrained Policy Optimization","abstract":"Deep reinforcement learning (RL) excels in various control tasks, yet the absence of safety guarantees hampers its real-world applicability. In particular, explorations during learning usually results in safety violations, while the RL agent learns from those mistakes. On the other hand, safe control techniques ensure persistent safety satisfaction but demand strong priors on system dynamics, which is usually hard to obtain in practice. To address these problems, we present Safe Set Guided State-wise Constrained Policy Optimization (S-3PO), a pioneering algorithm generating state-wise safe optimal policies with zero training violations, i.e., learning without mistakes. S-3PO first employs a safety-oriented monitor with black-box dynamics to ensure safe exploration. It then enforces an \"imaginary\" cost for the RL agent to converge to optimal behaviors within safety constraints. S-3PO outperforms existing methods in high-dimensional robotics tasks, managing state-wise constraints with zero training violation. This innovation marks a significant stride towards real-world safe RL deployment.","authors":["Yifan Sun","Feihan Li","Weiye Zhao","Rui Chen","Tianhao Wei","Changliu Liu"],"url":"https://arxiv.org/abs/2308.13140"}
{"created":"2025-06-04","title":"Conti Inc.: Understanding the Internal Discussions of a large Ransomware-as-a-Service Operator with Machine Learning","abstract":"Ransomware-as-a-service (RaaS) is increasing the scale and complexity of ransomware attacks. Understanding the internal operations behind RaaS has been a challenge due to the illegality of such activities. The recent chat leak of the Conti RaaS operator, one of the most infamous ransomware operators on the international scene, offers a key opportunity to better understand the inner workings of such organizations. This paper analyzes the main topic discussions in the Conti chat leak using machine learning techniques such as Natural Language Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as visualization strategies. Five discussion topics are found: 1) Business, 2) Technical, 3) Internal tasking/Management, 4) Malware, and 5) Customer Service/Problem Solving. Moreover, the distribution of topics among Conti members shows that only 4% of individuals have specialized discussions while almost all individuals (96%) are all-rounders, meaning that their discussions revolve around the five topics. The results also indicate that a significant proportion of Conti discussions are non-tech related. This study thus highlights that running such large RaaS operations requires a workforce skilled beyond technical abilities, with individuals involved in various tasks, from management to customer service or problem solving. The discussion topics also show that the organization behind the Conti RaaS oper5086933ator shares similarities with a large firm. We conclude that, although RaaS represents an example of specialization in the cybercrime industry, only a few members are specialized in one topic, while the rest runs and coordinates the RaaS operation.","authors":["Estelle Ruellan","Masarah Paquet-Clouston","Sebastian Garcia"],"url":"https://arxiv.org/abs/2308.16061"}
{"created":"2025-06-04","title":"On the success probability of the quantum algorithm for the short DLP","abstract":"Eker{\\aa} and H{\\aa}stad have introduced a variation of Shor's algorithm for the discrete logarithm problem (DLP). Unlike Shor's original algorithm, Eker{\\aa}-H{\\aa}stad's algorithm solves the short DLP in groups of unknown order. In this work, we prove a lower bound on the probability of Eker{\\aa}-H{\\aa}stad's algorithm recovering the short logarithm $d$ in a single run. By our bound, the success probability can easily be pushed as high as $1 - 10^{-10}$ for any short $d$. A key to achieving such a high success probability is to efficiently perform a limited search in the classical post-processing by leveraging meet-in-the-middle techniques. Asymptotically, in the limit as the bit length $m$ of $d$ tends to infinity, the success probability tends to one if the limits on the search space are parameterized in $m$. Our results are directly applicable to Diffie-Hellman in safe-prime groups with short exponents, and to RSA via a reduction from the RSA integer factoring problem (IFP) to the short DLP.","authors":["Martin Eker{\\aa}"],"url":"https://arxiv.org/abs/2309.01754"}
{"created":"2025-06-04","title":"Robust 6DoF Pose Estimation Against Depth Noise and a Comprehensive Evaluation on a Mobile Dataset","abstract":"Robust 6DoF pose estimation with mobile devices is the foundation for applications in robotics, augmented reality, and digital twin localization. In this paper, we extensively investigate the robustness of existing RGBD-based 6DoF pose estimation methods against varying levels of depth sensor noise. We highlight that existing 6DoF pose estimation methods suffer significant performance discrepancies due to depth measurement inaccuracies. In response to the robustness issue, we present a simple and effective transformer-based 6DoF pose estimation approach called DTTDNet, featuring a novel geometric feature filtering module and a Chamfer distance loss for training. Moreover, we advance the field of robust 6DoF pose estimation and introduce a new dataset -- Digital Twin Tracking Dataset Mobile (DTTD-Mobile), tailored for digital twin object tracking with noisy depth data from the mobile RGBD sensor suite of the Apple iPhone 14 Pro. Extensive experiments demonstrate that DTTDNet significantly outperforms state-of-the-art methods at least 4.32, up to 60.74 points in ADD metrics on the DTTD-Mobile. More importantly, our approach exhibits superior robustness to varying levels of measurement noise, setting a new benchmark for robustness to measurement noise. The project page is publicly available at https://openark-berkeley.github.io/DTTDNet/.","authors":["Zixun Huang","Keling Yao","Seth Z. Zhao","Chuanyu Pan","Allen Y. Yang"],"url":"https://arxiv.org/abs/2309.13570"}
{"created":"2025-06-04","title":"Exploiting Local Observations for Robust Robot Learning","abstract":"While many robotic tasks can be addressed through either centralized single-agent control with full state observation or decentralized multi-agent control, clear criteria for selecting the optimal approach are lacking. This paper presents a comprehensive investigation into how multi-agent reinforcement learning (MARL) with local observations can enhance robustness in complex robotic systems compared to traditional centralized control methods. We provide both theoretical analysis and empirical validation demonstrating that in certain tasks, decentralized MARL controllers can achieve performance comparable to centralized approaches while offering superior robustness against perturbations and agent failures. Our theoretical contributions include an analytical proof of equivalence between SARL and MARL under full observability conditions, identifying observability as the key distinguishing factor, and derivation of performance degradation bounds for locally observable policies under external perturbations. Empirical validation on standard MARL benchmarks confirms that locally observable MARL maintains competitive performance despite limited observations. Real-world experiments with a mobile manipulation robot demonstrate that our decentralized MARL controllers exhibit significantly improved robustness to both agent malfunctions and environmental disturbances compared to centralized baselines. This systematic investigation provides crucial insights for designing robust and generalizable control strategies in complex robotic systems, establishing MARL with local observations as a viable alternative to traditional centralized control paradigms.","authors":["Wenshuai Zhao","Eetu-Aleksi Rantala","Sahar Salimpour","Zhiyuan Li","Joni Pajarinen","Jorge Pe\\~na Queralta"],"url":"https://arxiv.org/abs/2309.14792"}
{"created":"2025-06-04","title":"Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias","abstract":"Node representation learning on attributed graphs -- whose nodes are associated with rich attributes (e.g., texts and protein sequences) -- plays a crucial role in many important downstream tasks. To encode the attributes and graph structures simultaneously, recent studies integrate pre-trained models with graph neural networks (GNNs), where pre-trained models serve as node encoders (NEs) to encode the attributes. As jointly training large NEs and GNNs on large-scale graphs suffers from severe scalability issues, many methods propose to train NEs and GNNs separately. Consequently, they do not take feature convolutions in GNNs into consideration in the training phase of NEs, leading to a significant learning bias relative to the joint training. To address this challenge, we propose an efficient label regularization technique, namely Label Deconvolution (LD), to alleviate the learning bias by a novel and highly scalable approximation to the inverse mapping of GNNs. The inverse mapping leads to an objective function that is equivalent to that by the joint training, while it can effectively incorporate GNNs in the training phase of NEs against the learning bias. More importantly, we show that LD converges to the optimal objective function values by the joint training under mild assumptions. Experiments demonstrate LD significantly outperforms state-of-the-art methods on Open Graph Benchmark datasets.","authors":["Zhihao Shi","Jie Wang","Fanghua Lu","Hanzhu Chen","Defu Lian","Zheng Wang","Jieping Ye","Feng Wu"],"url":"https://arxiv.org/abs/2309.14907"}
{"created":"2025-06-04","title":"Low-Resolution Self-Attention for Semantic Segmentation","abstract":"Semantic segmentation tasks naturally require high-resolution information for pixel-wise segmentation and global context information for class prediction. While existing vision transformers demonstrate promising performance, they often utilize high-resolution context modeling, resulting in a computational bottleneck. In this work, we challenge conventional wisdom and introduce the Low-Resolution Self-Attention (LRSA) mechanism to capture global context at a significantly reduced computational cost, i.e., FLOPs. Our approach involves computing self-attention in a fixed low-resolution space regardless of the input image's resolution, with additional 3x3 depth-wise convolutions to capture fine details in the high-resolution space. We demonstrate the effectiveness of our LRSA approach by building the LRFormer, a vision transformer with an encoder-decoder structure. Extensive experiments on the ADE20K, COCO-Stuff, and Cityscapes datasets demonstrate that LRFormer outperforms state-of-the-art models. Code is available at https://github.com/yuhuan-wu/LRFormer.","authors":["Yu-Huan Wu","Shi-Chen Zhang","Yun Liu","Le Zhang","Xin Zhan","Daquan Zhou","Jiashi Feng","Ming-Ming Cheng","Liangli Zhen"],"url":"https://arxiv.org/abs/2310.05026"}
{"created":"2025-06-04","title":"Performative Time-Series Forecasting","abstract":"Time-series forecasting is a critical challenge in various domains and has witnessed substantial progress in recent years. Many real-life scenarios, such as public health, economics, and social applications, involve feedback loops where predictions can influence the predicted outcome, subsequently altering the target variable's distribution. This phenomenon, known as performativity, introduces the potential for 'self-negating' or 'self-fulfilling' predictions. Despite extensive studies in classification problems across domains, performativity remains largely unexplored in the context of time-series forecasting from a machine-learning perspective.","authors":["Zhiyuan Zhao","Haoxin Liu","Alexander Rodriguez","B. Aditya Prakash"],"url":"https://arxiv.org/abs/2310.06077"}
{"created":"2025-06-04","title":"MCU: An Evaluation Framework for Open-Ended Game Agents","abstract":"Developing AI agents capable of interacting with open-world environments to solve diverse tasks is a compelling challenge. However, evaluating such open-ended agents remains difficult, with current benchmarks facing scalability limitations. To address this, we introduce Minecraft Universe (MCU), a comprehensive evaluation framework set within the open-world video game Minecraft. MCU incorporates three key components: (1) an expanding collection of 3,452 composable atomic tasks that encompasses 11 major categories and 41 subcategories of challenges; (2) a task composition mechanism capable of generating infinite diverse tasks with varying difficulty; and (3) a general evaluation framework that achieves 91.5\\% alignment with human ratings for open-ended task assessment. Empirical results reveal that even state-of-the-art foundation agents struggle with the increasing diversity and complexity of tasks. These findings highlight the necessity of MCU as a robust benchmark to drive progress in AI agent development within open-ended environments. Our evaluation code and scripts are available at https://github.com/CraftJarvis/MCU.","authors":["Xinyue Zheng","Haowei Lin","Kaichen He","Zihao Wang","Zilong Zheng","Yitao Liang"],"url":"https://arxiv.org/abs/2310.08367"}
{"created":"2025-06-04","title":"MultiDLO: Simultaneous Shape Tracking of Multiple Deformable Linear Objects with Global-Local Topology Preservation","abstract":"MultiDLO is a real-time algorithm for estimating the shapes of multiple, intertwining deformable linear objects (DLOs) from RGB-D image sequences. Unlike prior methods that track only a single DLO, MultiDLO simultaneously handles several objects. It uses the geodesic distance in the Global-Local Topology Preservation algorithm to define both inter-object identity and intra-object topology, ensuring entangled DLOs remain distinct with accurate local geometry. The MultiDLO algorithm is demonstrated on two challenging scenarios involving three entangling ropes, and the implementation is open-source and available for the community.","authors":["Jingyi Xiang","Holly Dinkel"],"url":"https://arxiv.org/abs/2310.13245"}
{"created":"2025-06-04","title":"Learning to Simulate: Generative Metamodeling via Quantile Regression","abstract":"Stochastic simulation models effectively capture complex system dynamics but are often too slow for real-time decision-making. Traditional metamodeling techniques learn relationships between simulator inputs and a single output summary statistic, such as the mean or median. These techniques enable real-time predictions without additional simulations. However, they require prior selection of one appropriate output summary statistic, limiting their flexibility in practical applications. We propose a new concept: generative metamodeling. It aims to construct a \"fast simulator of the simulator,\" generating random outputs significantly faster than the original simulator while preserving approximately equal conditional distributions. Generative metamodels enable rapid generation of numerous random outputs upon input specification, facilitating immediate computation of any summary statistic for real-time decision-making. We introduce a new algorithm, quantile-regression-based generative metamodeling (QRGMM), and establish its distributional convergence and convergence rate. Extensive numerical experiments demonstrate QRGMM's efficacy compared to other state-of-the-art generative algorithms in practical real-time decision-making scenarios.","authors":["L. Jeff Hong","Yanxi Hou","Qingkai Zhang","Xiaowei Zhang"],"url":"https://arxiv.org/abs/2311.17797"}
{"created":"2025-06-04","title":"Predictable Reinforcement Learning Dynamics through Entropy Rate Minimization","abstract":"In Reinforcement Learning (RL), agents have no incentive to exhibit predictable behaviors, and are often pushed (through e.g. policy entropy regularisation) to randomise their actions in favor of exploration. This often makes it challenging for other agents and humans to predict an agent's behavior, triggering unsafe scenarios (e.g. in human-robot interaction). We propose a novel method to induce predictable behavior in RL agents, termed Predictability-Aware RL (PARL), employing the agent's trajectory entropy rate to quantify predictability. Our method maximizes a linear combination of a standard discounted reward and the negative entropy rate, thus trading off optimality with predictability. We show how the entropy rate can be formally cast as an average reward, how entropy-rate value functions can be estimated from a learned model and incorporate this in policy-gradient algorithms, and demonstrate how this approach produces predictable (near-optimal) policies in tasks inspired by human-robot use-cases.","authors":["Daniel Jarne Ornia","Giannis Delimpaltadakis","Jens Kober","Javier Alonso-Mora"],"url":"https://arxiv.org/abs/2311.18703"}
{"created":"2025-06-04","title":"PECANN: Parallel Efficient Clustering with Graph-Based Approximate Nearest Neighbor Search","abstract":"This paper studies density-based clustering of point sets. These methods use dense regions of points to detect clusters of arbitrary shapes. In particular, we study variants of density peaks clustering, a popular type of algorithm that has been shown to work well in practice. Our goal is to cluster large high-dimensional datasets, which are prevalent in practice. Prior solutions are either sequential, and cannot scale to large data, or are specialized for low-dimensional data.","authors":["Shangdi Yu","Joshua Engels","Yihao Huang","Julian Shun"],"url":"https://arxiv.org/abs/2312.03940"}
{"created":"2025-06-04","title":"MoBluRF: Motion Deblurring Neural Radiance Fields for Blurry Monocular Video","abstract":"Neural Radiance Fields (NeRF), initially developed for static scenes, have inspired many video novel view synthesis techniques. However, the challenge for video view synthesis arises from motion blur, a consequence of object or camera movements during exposure, which hinders the precise synthesis of sharp spatio-temporal views. In response, we propose a novel motion deblurring NeRF framework for blurry monocular video, called MoBluRF, consisting of a Base Ray Initialization (BRI) stage and a Motion Decomposition-based Deblurring (MDD) stage. In the BRI stage, we coarsely reconstruct dynamic 3D scenes and jointly initialize the base rays which are further used to predict latent sharp rays, using the inaccurate camera pose information from the given blurry frames. In the MDD stage, we introduce a novel Incremental Latent Sharp-rays Prediction (ILSP) approach for the blurry monocular video frames by decomposing the latent sharp rays into global camera motion and local object motion components. We further propose two loss functions for effective geometry regularization and decomposition of static and dynamic scene components without any mask supervision. Experiments show that MoBluRF outperforms qualitatively and quantitatively the recent state-of-the-art methods with large margins.","authors":["Minh-Quan Viet Bui","Jongmin Park","Jihyong Oh","Munchurl Kim"],"url":"https://arxiv.org/abs/2312.13528"}
{"created":"2025-06-04","title":"A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of Foundation Models","abstract":"Few-shot semantic segmentation (FSS) is a crucial challenge in computer vision, driving extensive research into a diverse range of methods, from advanced meta-learning techniques to simple transfer learning baselines. With the emergence of vision foundation models (VFM) serving as generalist feature extractors, we seek to explore the adaptation of these models for FSS. While current FSS benchmarks focus on adapting pre-trained models to new tasks with few images, they emphasize in-domain generalization, making them less suitable for VFM trained on large-scale web datasets. To address this, we propose a novel realistic benchmark with a simple and straightforward adaptation process tailored for this task. Using this benchmark, we conduct a comprehensive comparative analysis of prominent VFM and semantic segmentation models. To evaluate their effectiveness, we leverage various adaption methods, ranging from linear probing to parameter efficient fine-tuning (PEFT) and full fine-tuning. Our findings show that models designed for segmentation can be outperformed by self-supervised (SSL) models. On the other hand, while PEFT methods yields competitive performance, they provide little discrepancy in the obtained results compared to other methods, highlighting the critical role of the feature extractor in determining results. To our knowledge, this is the first study on the adaptation of VFM for FSS.","authors":["Reda Bensaid","Vincent Gripon","Fran\\c{c}ois Leduc-Primeau","Lukas Mauch","Ghouthi Boukli Hacene","Fabien Cardinaux"],"url":"https://arxiv.org/abs/2401.11311"}
{"created":"2025-06-04","title":"Coded Many-User Multiple Access via Approximate Message Passing","abstract":"We consider communication over the Gaussian multiple-access channel in the regime where the number of users grows linearly with the codelength. In this regime, schemes based on sparse superposition coding can achieve a near-optimal tradeoff between spectral efficiency and signal-to-noise ratio. However, these schemes are feasible only for small values of user payload. This paper investigates efficient schemes for larger user payloads, focusing on coded CDMA schemes where each user's information is encoded via a linear code before being modulated with a signature sequence. We propose an efficient approximate message passing (AMP) decoder that can be tailored to the structure of the linear code, and provide an exact asymptotic characterization of its performance. Based on this result, we consider a decoder that integrates AMP and belief propagation and characterize its tradeoff between spectral efficiency and signal-to-noise ratio, for a given target error rate. Simulation results show that the decoder achieves state-of-the-art performance at finite lengths, with a coded CDMA scheme defined using LDPC codes and a spatially coupled matrix of signature sequences.","authors":["Xiaoqi Liu","Kuan Hsieh","Ramji Venkataramanan"],"url":"https://arxiv.org/abs/2402.05625"}
{"created":"2025-06-04","title":"The Complexity of Sequential Prediction in Dynamical Systems","abstract":"We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown. Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective. We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic settings respectively. By doing so, we find that in the realizable setting, the total number of mistakes can grow according to \\emph{any} increasing function of the time horizon $T$. In contrast, we show that in the agnostic setting under the commonly studied notion of Markovian regret, the only possible rates are $\\Theta(T)$ and $\\tilde{\\Theta}(\\sqrt{T})$.","authors":["Vinod Raman","Unique Subedi","Ambuj Tewari"],"url":"https://arxiv.org/abs/2402.06614"}
{"created":"2025-06-04","title":"Grace Period is All You Need: Individual Fairness without Revenue Loss in Revenue Management","abstract":"Imagine you and a friend purchase identical items at a store, yet only your friend received a discount. Would your friend's discount make you feel unfairly treated by the store? And would you be less willing to purchase from that store again in the future? Based on a large-scale online survey that we ran on Prolific, it turns out that the answers to the above questions are positive. Therefore, when allocating resources to different customers, sellers should consider both the total reward and individual fairness. Motivated by these findings, in this work we propose a notion of individual fairness in online revenue management and an algorithmic module (called ``Grace Period'') that can be embedded in traditional revenue management algorithms and guarantee individual fairness. Specifically, we show how to embed the Grace Period in five common revenue management algorithms including Deterministic Linear Programming with Probabilistic Assignment, Resolving Deterministic Linear Programming with Probabilistic Assignment, Static Bid Price Control, Booking Limit, and Nesting, thus covering both stochastic and adversarial customer arrival settings. Embedding the Grace Period does not incur additional regret for any of these algorithms. This finding indicates that, in an asymptotic regime, there is no tradeoff between a seller maximizing their revenue and guaranteeing that each customer feels fairly treated. The core intuition behind the Grace Period is that independent randomized decisions for each customer often lead to unfair outcomes. However, we cannot eliminate the randomness, as it plays a crucial role in maximizing profit. The Grace Period addresses this by shifting randomness away from individual decisions and applying it instead to the total number of customers receiving a particular decision. This approach preserves revenue potential while mitigating fairness issues.","authors":["Patrick Jaillet","Chara Podimata","Zijie Zhou"],"url":"https://arxiv.org/abs/2402.08533"}
{"created":"2025-06-04","title":"The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects","abstract":"Recent large-scale T2I models like DALLE-3 have made progress in reducing gender stereotypes when generating single-person images. However, significant biases remain when generating images with more than one person. To systematically evaluate this, we propose the Paired Stereotype Test (PST) framework, which queries T2I models to depict two individuals assigned with male-stereotyped and female-stereotyped social identities, respectively (e.g. \"a CEO\" and \"an Assistant\"). This contrastive setting often triggers T2I models to generate gender-stereotyped images. Using PST, we evaluate two aspects of gender biases -- the well-known bias in gendered occupation and a novel aspect: bias in organizational power. Experiments show that over 74\\% images generated by DALLE-3 display gender-occupational biases. Additionally, compared to single-person settings, DALLE-3 is more likely to perpetuate male-associated stereotypes under PST. We further propose FairCritic, a novel and interpretable framework that leverages an LLM-based critic model to i) detect bias in generated images, and ii) adaptively provide feedback to T2I models for improving fairness. FairCritic achieves near-perfect fairness on PST, overcoming the limitations of previous prompt-based intervention approaches.","authors":["Yixin Wan","Kai-Wei Chang"],"url":"https://arxiv.org/abs/2402.11089"}
{"created":"2025-06-04","title":"From Real World to Logic and Back: Learning Generalizable Relational Concepts For Long Horizon Robot Planning","abstract":"Humans efficiently generalize from limited demonstrations, but robots still struggle to transfer learned knowledge to complex, unseen tasks with longer horizons and increased complexity. We propose the first known method enabling robots to autonomously invent relational concepts directly from small sets of unannotated, unsegmented demonstrations. The learned symbolic concepts are grounded into logic-based world models, facilitating efficient zero-shot generalization to significantly more complex tasks. Empirical results demonstrate that our approach achieves performance comparable to hand-crafted models, successfully scaling execution horizons and handling up to 18 times more objects than seen in training, providing the first autonomous framework for learning transferable symbolic abstractions from raw robot trajectories.","authors":["Naman Shah","Jayesh Nagpal","Siddharth Srivastava"],"url":"https://arxiv.org/abs/2402.11871"}
{"created":"2025-06-04","title":"GPTVQ: The Blessing of Dimensionality for LLM Quantization","abstract":"In this work we show that the size versus accuracy trade-off of neural network quantization can be significantly improved by increasing the quantization dimensionality. We propose the GPTVQ method, a new fast method for post-training vector quantization (VQ) that scales well to Large Language Models (LLMs). Our method interleaves quantization of one or more columns with updates to the remaining unquantized weights, using information from the Hessian of the per-layer output reconstruction MSE. Quantization codebooks are initialized using an efficient data-aware version of the EM algorithm. The codebooks are then updated, and further compressed by using integer quantization and SVD-based compression. GPTVQ establishes a new state-of-the art in the size vs accuracy trade-offs on a wide range of LLMs such as Llama-v2 and Mistral. Furthermore, our method is efficient: on a single H100 it takes between 3 and 11 hours to process a Llamav2-70B model, depending on quantization setting. Lastly, with on-device timings for VQ decompression on a mobile CPU we show that VQ leads to improved latency compared to using a 4-bit integer format.","authors":["Mart van Baalen","Andrey Kuzmin","Ivan Koryakovskiy","Markus Nagel","Peter Couperus","Cedric Bastoul","Eric Mahurin","Tijmen Blankevoort","Paul Whatmough"],"url":"https://arxiv.org/abs/2402.15319"}
{"created":"2025-06-04","title":"Real-time respiratory motion forecasting with online learning of recurrent neural networks for accurate targeting in externally guided radiotherapy","abstract":"In lung radiotherapy, infrared cameras can track reflective objects on the chest to estimate tumor motion due to breathing, but treatment system latencies hinder radiation beam precision. Real-time recurrent learning (RTRL) is a potential solution that can learn patterns within non-stationary respiratory data but has high complexity. This study assesses the capabilities of resource-efficient online RNN algorithms, namely unbiased online recurrent optimization (UORO), sparse-1 step approximation (SnAp-1), and decoupled neural interfaces (DNI) to forecast respiratory motion during radiotherapy treatment accurately. We use time series containing the 3D positions of external markers on the chest of healthy subjects. We propose efficient implementations for SnAp-1 and DNI that compress the influence and immediate Jacobian matrices and accurately update the linear coefficients used in credit assignment estimation, respectively. Data was originally sampled at 10Hz; we resampled it at 3.33Hz and 30Hz to analyze the effect of the sampling rate on performance. We use UORO, SnAp-1, and DNI to forecast each marker's 3D position with horizons h<=2.1s (the time interval in advance for which the prediction is made) and compare them with RTRL, least mean squares, kernel support vector regression, and linear regression. RNNs trained online achieved similar or better accuracy than most previous works using larger training databases and deep learning, even though we used only the first minute of each sequence to predict motion within that exact sequence. SnAp-1 had the lowest normalized root mean square errors (nRMSEs) averaged over the horizon values considered, equal to 0.335 and 0.157, at 3.33Hz and 10.0Hz, respectively. Similarly, UORO had the lowest nRMSE at 30Hz, equal to 0.086. DNI's inference time (6.8ms per time step at 30Hz, Intel Core i7-13700 CPU) was the lowest among the RNN methods.","authors":["Michel Pohl","Mitsuru Uesaka","Hiroyuki Takahashi","Kazuyuki Demachi","Ritu Bhusal Chhatkuli"],"url":"https://arxiv.org/abs/2403.01607"}
{"created":"2025-06-04","title":"Open-world Machine Learning: A Systematic Review and Future Directions","abstract":"Machine learning has achieved remarkable success in many applications. However, existing studies are largely based on the closed-world assumption, which assumes that the environment is stationary, and the model is fixed once deployed. In many real-world applications, this fundamental and rather naive assumption may not hold because an open environment is complex, dynamic, and full of unknowns. In such cases, rejecting unknowns, discovering novelties, and then continually learning them, could enable models to be safe and evolve continually as biological systems do. This article presents a holistic view of open-world machine learning by investigating unknown rejection, novelty discovery, and continual learning in a unified paradigm. The challenges, principles, and limitations of current methodologies are discussed in detail. Furthermore, widely used benchmarks, metrics, and performances are summarized. Finally, we discuss several potential directions for further progress in the field. By providing a comprehensive introduction to the emerging open-world machine learning paradigm, this article aims to help researchers build more powerful AI systems in their respective fields, and to promote the development of artificial general intelligence.","authors":["Fei Zhu","Shijie Ma","Zhen Cheng","Xu-Yao Zhang","Zhaoxiang Zhang","Dacheng Tao","Cheng-Lin Liu"],"url":"https://arxiv.org/abs/2403.01759"}
{"created":"2025-06-04","title":"UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed Entities","abstract":"Entity Set Expansion (ESE) aims to identify new entities belonging to the same semantic class as the given set of seed entities. Traditional methods solely relied on positive seed entities to represent the target fine-grained semantic class, rendering them tough to represent ultra-fine-grained semantic classes. Specifically, merely relying on positive seed entities leads to two inherent shortcomings: (i) Ambiguity among ultra-fine-grained semantic classes. (ii) Inability to define ``unwanted'' semantics. Hence, previous ESE methods struggle to address the ultra-fine-grained ESE (Ultra-ESE) task. To solve this issue, we first introduce negative seed entities in the inputs, which jointly describe the ultra-fine-grained semantic class with positive seed entities. Negative seed entities eliminate the semantic ambiguity by providing a contrast between positive and negative attributes. Meanwhile, it provides a straightforward way to express ``unwanted''. To assess model performance in Ultra-ESE and facilitate further research, we also constructed UltraWiki, the first large-scale dataset tailored for Ultra-ESE. UltraWiki encompasses 50,973 entities and 394,097 sentences, alongside 236 ultra-fine-grained semantic classes, where each class is represented with 3-5 positive and negative seed entities. Moreover, a retrieval-based framework RetExpan and a generation-based framework GenExpan are proposed to provide powerful baselines for Ultra-ESE. Additionally, we devised two strategies to enhance models' comprehension of ultra-fine-grained entities' semantics: contrastive learning and chain-of-thought reasoning. Extensive experiments confirm the effectiveness of our proposed strategies and also reveal that there remains a large space for improvement in Ultra-ESE.","authors":["Yangning Li","Qingsong Lv","Tianyu Yu","Yinghui Li","Xuming Hu","Wenhao Jiang","Hai-Tao Zheng","Hui Wang"],"url":"https://arxiv.org/abs/2403.04247"}
{"created":"2025-06-04","title":"T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers","abstract":"The development and adoption of Vision Transformers and other deep-learning architectures for image classification tasks has been rapid. However, the \"black box\" nature of neural networks is a barrier to adoption in applications where explainability is essential. While some techniques for generating explanations have been proposed, primarily for Convolutional Neural Networks, adapting such techniques to the new paradigm of Vision Transformers is non-trivial. This paper presents T-TAME, Transformer-compatible Trainable Attention Mechanism for Explanations, a general methodology for explaining deep neural networks used in image classification tasks. The proposed architecture and training technique can be easily applied to any convolutional or Vision Transformer-like neural network, using a streamlined training approach. After training, explanation maps can be computed in a single forward pass; these explanation maps are comparable to or outperform the outputs of computationally expensive perturbation-based explainability techniques, achieving SOTA performance. We apply T-TAME to three popular deep learning classifier architectures, VGG-16, ResNet-50, and ViT-B-16, trained on the ImageNet dataset, and we demonstrate improvements over existing state-of-the-art explainability methods. A detailed analysis of the results and an ablation study provide insights into how the T-TAME design choices affect the quality of the generated explanation maps.","authors":["Mariano V. Ntrougkas","Nikolaos Gkalelis","Vasileios Mezaris"],"url":"https://arxiv.org/abs/2403.04523"}
{"created":"2025-06-04","title":"Shallow ReLU neural networks and finite elements","abstract":"We point out that (continuous or discontinuous) piecewise linear functions on a convex polytope mesh can be represented by two-hidden-layer ReLU neural networks in a weak sense. In addition, the numbers of neurons of the two hidden layers required to weakly represent are accurately given based on the numbers of polytopes and hyperplanes involved in this mesh. The results naturally hold for constant and linear finite element functions. Such weak representation establishes a bridge between shallow ReLU neural networks and finite element functions, and leads to a perspective for analyzing approximation capability of ReLU neural networks in $L^p$ norm via finite element functions. Moreover, we discuss the strict representation for tensor finite element functions via the recent tensor neural networks.","authors":["Pengzhan Jin"],"url":"https://arxiv.org/abs/2403.05809"}
{"created":"2025-06-04","title":"Revealing the Parallel Multilingual Learning within Large Language Models","abstract":"In this study, we reveal an in-context learning (ICL) capability of multilingual large language models (LLMs): by translating the input to several languages, we provide Parallel Input in Multiple Languages (PiM) to LLMs, which significantly enhances their comprehension abilities. To test this capability, we design extensive experiments encompassing 8 typical datasets, 7 languages and 8 state-of-the-art multilingual LLMs. Experimental results show that (1) incorporating more languages help PiM surpass the conventional ICL further; (2) even combining with the translations that are inferior to baseline performance can also help. Moreover, by examining the activated neurons in LLMs, we discover a counterintuitive but interesting phenomenon. Contrary to the common thought that PiM would activate more neurons than monolingual input to leverage knowledge learned from diverse languages, PiM actually inhibits neurons and promotes more precise neuron activation especially when more languages are added. This phenomenon aligns with the neuroscience insight about synaptic pruning, which removes less used neural connections, strengthens remainders, and then enhances brain intelligence.","authors":["Yongyu Mu","Peinan Feng","Zhiquan Cao","Yuzhang Wu","Bei Li","Chenglong Wang","Tong Xiao","Kai Song","Tongran Liu","Chunliang Zhang","Jingbo Zhu"],"url":"https://arxiv.org/abs/2403.09073"}
{"created":"2025-06-04","title":"Learning WENO for entropy stable schemes to solve conservation laws","abstract":"Entropy conditions play a crucial role in the extraction of a physically relevant solution for systems of conservation laws, thus motivating the construction of entropy stable schemes that satisfy a discrete analogue of such conditions. TeCNO schemes (Fjordholm et al. 2012) form a class of arbitrary high-order entropy stable finite difference solvers, which require specialized reconstruction algorithms satisfying the sign property at each cell interface. Third-order weighted essentially non-oscillatory (WENO) schemes called SP-WENO (Fjordholm and Ray, 2016) and SP-WENOc (Ray, 2018) have been designed to satisfy the sign property. However, these WENO algorithms can perform poorly near shocks, with the numerical solutions exhibiting large spurious oscillations. In the present work, we propose a variant of the SP-WENO, termed as Deep Sign-Preserving WENO (DSP-WENO), where a neural network is trained to learn the WENO weighting strategy. The sign property and third-order accuracy are strongly imposed in the algorithm, which constrains the WENO weight selection region to a convex polygon. Thereafter, a neural network is trained to select the WENO weights from this convex region with the goal of improving the shock-capturing capabilities without sacrificing the rate of convergence in smooth regions. The proposed synergistic approach retains the mathematical framework of the TeCNO scheme while integrating deep learning to remedy the computational issues of the WENO-based reconstruction. We present several numerical experiments to demonstrate the significant improvement with DSP-WENO over the existing variants of WENO satisfying the sign property.","authors":["Philip Charles","Deep Ray"],"url":"https://arxiv.org/abs/2403.14848"}
{"created":"2025-06-04","title":"Large language models for crowd decision making based on prompt design strategies using ChatGPT: models, analysis and challenges","abstract":"Social Media and Internet have the potential to be exploited as a source of opinion to enrich Decision Making solutions. Crowd Decision Making (CDM) is a methodology able to infer opinions and decisions from plain texts, such as reviews published in social media platforms, by means of Sentiment Analysis. Currently, the emergence and potential of Large Language Models (LLMs) lead us to explore new scenarios of automatically understand written texts, also known as natural language processing. This paper analyzes the use of ChatGPT based on prompt design strategies to assist in CDM processes to extract opinions and make decisions. We integrate ChatGPT in CDM processes as a flexible tool that infer the opinions expressed in texts, providing numerical or linguistic evaluations where the decision making models are based on the prompt design strategies. We include a multi-criteria decision making scenario with a category ontology for criteria. We also consider ChatGPT as an end-to-end CDM model able to provide a general opinion and score on the alternatives. We conduct empirical experiments on real data extracted from TripAdvisor, the TripR-2020Large dataset. The analysis of results show a promising branch for developing quality decision making models using ChatGPT. Finally, we discuss the challenges of consistency, sensitivity and explainability associated to the use of LLMs in CDM processes, raising open questions for future studies.","authors":["David Herrera-Poyatos","Cristina Zuheros","Rosana Montes","Francisco Herrera"],"url":"https://arxiv.org/abs/2403.15587"}
{"created":"2025-06-04","title":"PointCloud-Text Matching: Benchmark Datasets and a Baseline","abstract":"In this paper, we present and study a new instance-level retrieval task: PointCloud-Text Matching (PTM), which aims to identify the exact cross-modal instance that matches a given point-cloud query or text query. PTM has potential applications in various scenarios, such as indoor/urban-canyon localization and scene retrieval. However, there is a lack of suitable and targeted datasets for PTM in practice. To address this issue, we present a new PTM benchmark dataset, namely SceneDepict-3D2T. We observe that the data poses significant challenges due to its inherent characteristics, such as the sparsity, noise, or disorder of point clouds and the ambiguity, vagueness, or incompleteness of texts, which render existing cross-modal matching methods ineffective for PTM. To overcome these challenges, we propose a PTM baseline, named Robust PointCloud-Text Matching method (RoMa). RoMa consists of two key modules: a Dual Attention Perception module (DAP) and a Robust Negative Contrastive Learning module (RNCL). Specifically, DAP leverages token-level and feature-level attention mechanisms to adaptively focus on useful local and global features, and aggregate them into common representations, thereby reducing the adverse impact of noise and ambiguity. To handle noisy correspondence, RNCL enhances robustness against mismatching by dividing negative pairs into clean and noisy subsets and assigning them forward and reverse optimization directions, respectively. We conduct extensive experiments on our benchmarks and demonstrate the superiority of our RoMa.","authors":["Yanglin Feng","Yang Qin","Dezhong Peng","Hongyuan Zhu","Xi Peng","Peng Hu"],"url":"https://arxiv.org/abs/2403.19386"}
{"created":"2025-06-04","title":"Checkpoint Merging via Bayesian Optimization in LLM Pretraining","abstract":"The rapid proliferation of large language models (LLMs) such as GPT-4 and Gemini underscores the intense demand for resources during their training processes, posing significant challenges due to substantial computational and environmental costs. To alleviate this issue, we propose checkpoint merging in pretraining LLM. This method utilizes LLM checkpoints with shared training trajectories, and is rooted in an extensive search space exploration for the best merging weight via Bayesian optimization. Through various experiments, we demonstrate that: (1) Our proposed methodology exhibits the capacity to augment pretraining, presenting an opportunity akin to obtaining substantial benefits at minimal cost; (2) Our proposed methodology, despite requiring a given held-out dataset, still demonstrates robust generalization capabilities across diverse domains, a pivotal aspect in pretraining.","authors":["Deyuan Liu","Zecheng Wang","Bingning Wang","Weipeng Chen","Chunshan Li","Zhiying Tu","Dianhui Chu","Bo Li","Dianbo Sui"],"url":"https://arxiv.org/abs/2403.19390"}
{"created":"2025-06-04","title":"PHISWID: Physics-Inspired Underwater Image Dataset Synthesized from RGB-D Images","abstract":"This paper introduces the physics-inspired synthesized underwater image dataset (PHISWID), a dataset tailored for enhancing underwater image processing through physics-inspired image synthesis. For underwater image enhancement, data-driven approaches (e.g., deep neural networks) typically demand extensive datasets, yet acquiring paired clean atmospheric images and degraded underwater images poses significant challenges. Existing datasets have limited contributions to image enhancement due to lack of physics models, publicity, and ground-truth atmospheric images. PHISWID addresses these issues by offering a set of paired atmospheric and underwater images. Specifically, underwater images are synthetically degraded by color degradation and marine snow artifacts from atmospheric RGB-D images. It is enabled based on a physics-based underwater image observation model. Our synthetic approach generates a large quantity of the pairs, enabling effective training of deep neural networks and objective image quality assessment. Through benchmark experiments with some datasets and image enhancement methods, we validate that our dataset can improve the image enhancement performance. Our dataset, which is publicly available, contributes to the development in underwater image processing.","authors":["Reina Kaneko","Takumi Ueda","Hiroshi Higashi","Yuichi Tanaka"],"url":"https://arxiv.org/abs/2404.03998"}
{"created":"2025-06-04","title":"GvT: A Graph-based Vision Transformer with Talking-Heads Utilizing Sparsity, Trained from Scratch on Small Datasets","abstract":"Vision Transformers (ViTs) have achieved impressive results in large-scale image classification. However, when training from scratch on small datasets, there is still a significant performance gap between ViTs and Convolutional Neural Networks (CNNs), which is attributed to the lack of inductive bias. To address this issue, we propose a Graph-based Vision Transformer (GvT) that utilizes graph convolutional projection and graph-pooling. In each block, queries and keys are calculated through graph convolutional projection based on the spatial adjacency matrix, while dot-product attention is used in another graph convolution to generate values. When using more attention heads, the queries and keys become lower-dimensional, making their dot product an uninformative matching function. To overcome this low-rank bottleneck in attention heads, we employ talking-heads technology based on bilinear pooled features and sparse selection of attention tensors. This allows interaction among filtered attention scores and enables each attention mechanism to depend on all queries and keys. Additionally, we apply graph-pooling between two intermediate blocks to reduce the number of tokens and aggregate semantic information more effectively. Our experimental results show that GvT produces comparable or superior outcomes to deep convolutional networks and surpasses vision transformers without pre-training on large datasets. The code for our proposed model is publicly available on the website.","authors":["Dongjing Shan","guiqiang chen"],"url":"https://arxiv.org/abs/2404.04924"}
{"created":"2025-06-04","title":"CodeEnhance: A Codebook-Driven Approach for Low-Light Image Enhancement","abstract":"Low-light image enhancement (LLIE) aims to improve low-illumination images. However, existing methods face two challenges: (1) uncertainty in restoration from diverse brightness degradations; (2) loss of texture and color information caused by noise suppression and light enhancement. In this paper, we propose a novel enhancement approach, CodeEnhance, by leveraging quantized priors and image refinement to address these challenges. In particular, we reframe LLIE as learning an image-to-code mapping from low-light images to discrete codebook, which has been learned from high-quality images. To enhance this process, a Semantic Embedding Module (SEM) is introduced to integrate semantic information with low-level features, and a Codebook Shift (CS) mechanism, designed to adapt the pre-learned codebook to better suit the distinct characteristics of our low-light dataset. Additionally, we present an Interactive Feature Transformation (IFT) module to refine texture and color information during image reconstruction, allowing for interactive enhancement based on user preferences. Extensive experiments on both real-world and synthetic benchmarks demonstrate that the incorporation of prior knowledge and controllable information transfer significantly enhances LLIE performance in terms of quality and fidelity. The proposed CodeEnhance exhibits superior robustness to various degradations, including uneven illumination, noise, and color distortion.","authors":["Xu Wu","XianXu Hou","Zhihui Lai","Jie Zhou","Ya-nan Zhang","Witold Pedrycz","Linlin Shen"],"url":"https://arxiv.org/abs/2404.05253"}
{"created":"2025-06-04","title":"AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs","abstract":"Large Language Models (LLMs) are vulnerable to jailbreaking attacks that lead to generation of inappropriate or harmful content. Manual red-teaming requires a time-consuming search for adversarial prompts, whereas automatic adversarial prompt generation often leads to semantically meaningless attacks that do not scale well. In this paper, we present a novel method that uses another LLM, called AdvPrompter, to generate human-readable adversarial prompts in seconds. AdvPrompter, which is trained using an alternating optimization algorithm, generates suffixes that veil the input instruction without changing its meaning, such that the TargetLLM is lured to give a harmful response. Experimental results on popular open source TargetLLMs show highly competitive results on the AdvBench and HarmBench datasets, that also transfer to closed-source black-box LLMs. We also show that training on adversarial suffixes generated by AdvPrompter is a promising strategy for improving the robustness of LLMs to jailbreaking attacks.","authors":["Anselm Paulus","Arman Zharmagambetov","Chuan Guo","Brandon Amos","Yuandong Tian"],"url":"https://arxiv.org/abs/2404.16873"}
{"created":"2025-06-04","title":"Learning Actionable Counterfactual Explanations in Large State Spaces","abstract":"Recourse generators provide actionable insights, often through feature-based counterfactual explanations (CFEs), to help negatively classified individuals understand how to adjust their input features to achieve a positive classification. These feature-based CFEs, which we refer to as \\emph{low-level} CFEs, are overly specific (e.g., coding experience: \\(4 \\to 5+\\) years) and often recommended in a feature space that doesn't straightforwardly align with real-world actions. To bridge this gap, we introduce three novel recourse types grounded in real-world actions: high-level continuous (\\emph{hl-continuous}), high-level discrete (\\emph{hl-discrete}), and high-level ID (\\emph{hl-id}) CFEs.","authors":["Keziah Naggita","Matthew R. Walter","Avrim Blum"],"url":"https://arxiv.org/abs/2404.17034"}
{"created":"2025-06-04","title":"VectorPainter: Advanced Stylized Vector Graphics Synthesis Using Stroke-Style Priors","abstract":"We introduce VectorPainter, a novel framework designed for reference-guided text-to-vector-graphics synthesis. Based on our observation that the style of strokes can be an important aspect to distinguish different artists, our method reforms the task into synthesize a desired vector graphics by rearranging stylized strokes, which are vectorized from the reference images. Specifically, our method first converts the pixels of the reference image into a series of vector strokes, and then generates a vector graphic based on the input text description by optimizing the positions and colors of these vector strokes. To precisely capture the style of the reference image in the vectorized strokes, we propose an innovative vectorization method that employs an imitation learning strategy. To preserve the style of the strokes throughout the generation process, we introduce a style-preserving loss function. Extensive experiments have been conducted to demonstrate the superiority of our approach over existing works in stylized vector graphics synthesis, as well as the effectiveness of the various components of our method.","authors":["Juncheng Hu","Ximing Xing","Jing Zhang","Qian Yu"],"url":"https://arxiv.org/abs/2405.02962"}
{"created":"2025-06-04","title":"LLMs can Find Mathematical Reasoning Mistakes by Pedagogical Chain-of-Thought","abstract":"Self-correction is emerging as a promising approach to mitigate the issue of hallucination in Large Language Models (LLMs). To facilitate effective self-correction, recent research has proposed mistake detection as its initial step. However, current literature suggests that LLMs often struggle with reliably identifying reasoning mistakes when using simplistic prompting strategies. To address this challenge, we introduce a unique prompting strategy, termed the Pedagogical Chain-of-Thought (PedCoT), which is specifically designed to guide the identification of reasoning mistakes, particularly mathematical reasoning mistakes. PedCoT consists of pedagogical principles for prompts (PPP) design, two-stage interaction process (TIP) and grounded PedCoT prompts, all inspired by the educational theory of the Bloom Cognitive Model (BCM). We evaluate our approach on two public datasets featuring math problems of varying difficulty levels. The experiments demonstrate that our zero-shot prompting strategy significantly outperforms strong baselines. The proposed method can achieve the goal of reliable mathematical mistake identification and provide a foundation for automatic math answer grading. The results underscore the significance of educational theory, serving as domain knowledge, in guiding prompting strategy design for addressing challenging tasks with LLMs effectively.","authors":["Zhuoxuan Jiang","Haoyuan Peng","Shanshan Feng","Fan Li","Dongsheng Li"],"url":"https://arxiv.org/abs/2405.06705"}
{"created":"2025-06-04","title":"Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors","abstract":"Diffusion or score-based models recently showed high performance in image generation. They rely on a forward and a backward stochastic differential equations (SDE). The sampling of a data distribution is achieved by numerically solving the backward SDE or its associated flow ODE. Studying the convergence of these models necessitates to control four different types of error: the initialization error, the truncation error, the discretization error and the score approximation. In this paper, we theoretically study the behavior of diffusion models and their numerical implementation when the data distribution is Gaussian. Our first contribution is to derive the analytical solutions of the backward SDE and the probability flow ODE and to prove that these solutions and their discretizations are all Gaussian processes. Our second contribution is to compute the exact Wasserstein errors between the target and the numerically sampled distributions for any numerical scheme. This allows us to monitor convergence directly in the data space, while experimental works limit their empirical analysis to Inception features. An implementation of our code is available online.","authors":["Emile Pierret","Bruno Galerne"],"url":"https://arxiv.org/abs/2405.14250"}
{"created":"2025-06-04","title":"Learning from True-False Labels via Multi-modal Prompt Retrieving","abstract":"Pre-trained Vision-Language Models (VLMs) exhibit strong zero-shot classification abilities, demonstrating great potential for generating weakly supervised labels. Unfortunately, existing weakly supervised learning methods are short of ability in generating accurate labels via VLMs. In this paper, we propose a novel weakly supervised labeling setting, namely True-False Labels (TFLs) which can achieve high accuracy when generated by VLMs. The TFL indicates whether an instance belongs to the label, which is randomly and uniformly sampled from the candidate label set. Specifically, we theoretically derive a risk-consistent estimator to explore and utilize the conditional probability distribution information of TFLs. Besides, we propose a convolutional-based Multi-modal Prompt Retrieving (MRP) method to bridge the gap between the knowledge of VLMs and target learning tasks. Experimental results demonstrate the effectiveness of the proposed TFL setting and MRP learning method. The code to reproduce the experiments is at https://github.com/Tranquilxu/TMP.","authors":["Zhongnian Li","Jinghao Xu","Peng Ying","Meng Wei","Xinzheng Xu"],"url":"https://arxiv.org/abs/2405.15228"}
{"created":"2025-06-04","title":"Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization","abstract":"Federated Learning (FL) offers a promising framework for collaborative and privacy-preserving machine learning across distributed data sources. However, the substantial communication costs associated with FL significantly challenge its efficiency. Specifically, in each communication round, the communication costs scale linearly with the model's dimension, which presents a formidable obstacle, especially in large model scenarios. Despite various communication-efficient strategies, the intrinsic dimension-dependent communication cost remains a major bottleneck for current FL implementations. This paper proposes a novel dimension-free communication algorithm - DeComFL, which leverages the zeroth-order optimization techniques and reduces the communication cost from $\\mathscr{O}(d)$ to $\\mathscr{O}(1)$ by transmitting only a constant number of scalar values between clients and the server in each round, regardless of the dimension $d$ of the model parameters. Theoretically, in non-convex functions, we prove that our algorithm achieves state-of-the-art rates, which show a linear speedup of the number of clients and local steps under standard assumptions. With additional low effective rank assumption, we can further show the convergence rate is independent of the model dimension $d$ as well. Empirical evaluations, encompassing both classic deep learning training and large language model fine-tuning, demonstrate significant reductions in communication overhead. Notably, DeComFL achieves this by transmitting only around 1MB of data in total between the server and a client to fine-tune a model with billions of parameters. Our code is available at https://github.com/ZidongLiu/DeComFL.","authors":["Zhe Li","Bicheng Ying","Zidong Liu","Chaosheng Dong","Haibo Yang"],"url":"https://arxiv.org/abs/2405.15861"}
{"created":"2025-06-04","title":"R\\'enyi Neural Processes","abstract":"Neural Processes (NPs) are deep probabilistic models that represent stochastic processes by conditioning their prior distributions on a set of context points. Despite their advantages in uncertainty estimation for complex distributions, NPs enforce parameterization coupling between the conditional prior model and the posterior model. We show that this coupling amounts to prior misspecification and revisit the NP objective to address this issue. More specifically, we propose R\\'enyi Neural Processes (RNP), a method that replaces the standard KL divergence with the R\\'enyi divergence, dampening the effects of the misspecified prior during posterior updates. We validate our approach across multiple benchmarks including regression and image inpainting tasks, and show significant performance improvements of RNPs in real-world problems. Our extensive experiments show consistently better log-likelihoods over state-of-the-art NP models.","authors":["Xuesong Wang","He Zhao","Edwin V. Bonilla"],"url":"https://arxiv.org/abs/2405.15991"}
{"created":"2025-06-04","title":"OralBBNet: Spatially Guided Dental Segmentation of Panoramic X-Rays with Bounding Box Priors","abstract":"Teeth segmentation and recognition play a vital role in a variety of dental applications and diagnostic procedures. The integration of deep learning models has facilitated the development of precise and automated segmentation methods. Although prior research has explored teeth segmentation, not many methods have successfully performed tooth segmentation and detection simultaneously. This study presents UFBA-425, a dental dataset derived from the UFBA-UESC dataset, featuring bounding box and polygon annotations for 425 panoramic dental X-rays. Additionally, this work introduces OralBBNet, an architecture featuring distinct segmentation and detection heads as U-Net and YOLOv8, respectively. OralBBNet is designed to improve the accuracy and robustness of tooth classification and segmentation on panoramic X-rays by leveraging the complementary strengths of U-Net and YOLOv8. Our approach achieved a 1-3% improvement in mean average precision (mAP) for teeth detection compared to existing techniques and a 15-20% improvement in the dice score for teeth segmentation over U-Net over various tooth categories and 2-4% improvement in the dice score when compared with other segmentation architectures. The results of this study establish a foundation for the wider implementation of object detection models in dental diagnostics.","authors":["Devichand Budagam","Azamat Zhanatuly Imanbayev","Iskander Rafailovich Akhmetov","Aleksandr Sinitca","Sergey Antonov","Dmitrii Kaplun"],"url":"https://arxiv.org/abs/2406.03747"}
{"created":"2025-06-04","title":"SignMusketeers: An Efficient Multi-Stream Approach for Sign Language Translation at Scale","abstract":"A persistent challenge in sign language video processing, including the task of sign to written language translation, is how we learn representations of sign language in an effective and efficient way that preserves the important attributes of these languages, while remaining invariant to irrelevant visual differences. Informed by the nature and linguistics of signed languages, our proposed method focuses on just the most relevant parts in a signing video: the face, hands and body pose of the signer. However, instead of fully relying on pose estimation from off-the-shelf pose tracking models, which have inconsistent performance for hands and faces, we propose to learn a representation of the complex handshapes and facial expressions of sign languages in a self-supervised fashion. Our approach is based on learning from individual frames (rather than video sequences) and is therefore much more efficient than prior work on sign language pre-training. Compared to a recent model that established a new state of the art in sign language translation on the How2Sign dataset, our approach yields similar translation performance, using less than 3\\% of the compute.","authors":["Shester Gueuwou","Xiaodan Du","Greg Shakhnarovich","Karen Livescu"],"url":"https://arxiv.org/abs/2406.06907"}
{"created":"2025-06-04","title":"Flow map matching with stochastic interpolants: A mathematical framework for consistency models","abstract":"Generative models based on dynamical equations such as flows and diffusions offer exceptional sample quality, but require computationally expensive numerical integration during inference. The advent of consistency models has enabled efficient one-step or few-step generation, yet despite their practical success, a systematic understanding of their design has been hindered by the lack of a comprehensive theoretical framework. Here we introduce Flow Map Matching (FMM), a principled framework for learning the two-time flow map of an underlying dynamical generative model, thereby providing this missing mathematical foundation. Leveraging stochastic interpolants, we propose training objectives both for distillation from a pre-trained velocity field and for direct training of a flow map over an interpolant or a forward diffusion process. Theoretically, we show that FMM unifies and extends a broad class of existing approaches for fast sampling, including consistency models, consistency trajectory models, and progressive distillation. Experiments on CIFAR-10 and ImageNet-32 highlight that our approach can achieve sample quality comparable to flow matching while reducing generation time by a factor of 10-20.","authors":["Nicholas M. Boffi","Michael S. Albergo","Eric Vanden-Eijnden"],"url":"https://arxiv.org/abs/2406.07507"}
{"created":"2025-06-04","title":"LeYOLO, New Embedded Architecture for Object Detection","abstract":"Efficient computation in deep neural networks is crucial for real-time object detection. However, recent advancements primarily result from improved high-performing hardware rather than improving parameters and FLOP efficiency. This is especially evident in the latest YOLO architectures, where speed is prioritized over lightweight design. As a result, object detection models optimized for low-resource environments like microcontrollers have received less attention. For devices with limited computing power, existing solutions primarily rely on SSDLite or combinations of low-parameter classifiers, creating a noticeable gap between YOLO-like architectures and truly efficient lightweight detectors. This raises a key question: Can a model optimized for parameter and FLOP efficiency achieve accuracy levels comparable to mainstream YOLO models? To address this, we introduce two key contributions to object detection models using MSCOCO as a base validation set. First, we propose LeNeck, a general-purpose detection framework that maintains inference speed comparable to SSDLite while significantly improving accuracy and reducing parameter count. Second, we present LeYOLO, an efficient object detection model designed to enhance computational efficiency in YOLO-based architectures. LeYOLO effectively bridges the gap between SSDLite-based detectors and YOLO models, offering high accuracy in a model as compact as MobileNets. Both contributions are particularly well-suited for mobile, embedded, and ultra-low-power devices, including microcontrollers, where computational efficiency is critical.","authors":["Lilian Hollard","Lucas Mohimont","Nathalie Gaveau","Luiz Angelo Steffenel"],"url":"https://arxiv.org/abs/2406.14239"}
{"created":"2025-06-04","title":"Unmasking Database Vulnerabilities: Zero-Knowledge Schema Inference Attacks in Text-to-SQL Systems","abstract":"Text-to-SQL systems empower users to interact with databases using natural language, automatically translating queries into executable SQL code. However, their reliance on database schema information for SQL generation exposes them to significant security vulnerabilities, particularly schema inference attacks that can lead to unauthorized data access or manipulation. In this paper, we introduce a novel zero-knowledge framework for reconstructing the underlying database schema of text-to-SQL models without any prior knowledge of the database. Our approach systematically probes text-to-SQL models with specially crafted questions and leverages a surrogate GPT-4 model to interpret the outputs, effectively uncovering hidden schema elements -- including tables, columns, and data types. We demonstrate that our method achieves high accuracy in reconstructing table names, with F1 scores of up to .99 for generative models and .78 for fine-tuned models, underscoring the severity of schema leakage risks. We also show that our attack can steal prompt information in non-text-to-SQL models. Furthermore, we propose a simple protection mechanism for generative models and empirically show its limitations in mitigating these attacks.","authors":["{\\DJ}or{\\dj}e Klisura","Anthony Rios"],"url":"https://arxiv.org/abs/2406.14545"}
{"created":"2025-06-04","title":"Structured and Balanced Multi-Component and Multi-Layer Neural Networks","abstract":"In this work, we propose a balanced multi-component and multi-layer neural network (MMNN) structure to accurately and efficiently approximate functions with complex features, in terms of both degrees of freedom and computational cost. The main idea is inspired by a multi-component approach, in which each component can be effectively approximated by a single-layer network, combined with a multi-layer decomposition strategy to capture the complexity of the target function. Although MMNNs can be viewed as a simple modification of fully connected neural networks (FCNNs) or multi-layer perceptrons (MLPs) by introducing balanced multi-component structures, they achieve a significant reduction in training parameters, a much more efficient training process, and improved accuracy compared to FCNNs or MLPs. Extensive numerical experiments demonstrate the effectiveness of MMNNs in approximating highly oscillatory functions and their ability to automatically adapt to localized features.","authors":["Shijun Zhang","Hongkai Zhao","Yimin Zhong","Haomin Zhou"],"url":"https://arxiv.org/abs/2407.00765"}
{"created":"2025-06-04","title":"Free-text Rationale Generation under Readability Level Control","abstract":"Free-text rationales justify model decisions in natural language and thus become likable and accessible among approaches to explanation across many tasks. However, their effectiveness can be hindered by misinterpretation and hallucination. As a perturbation test, we investigate how large language models (LLMs) perform rationale generation under the effects of readability level control, i.e., being prompted for an explanation targeting a specific expertise level, such as sixth grade or college. We find that explanations are adaptable to such instruction, though the observed distinction between readability levels does not fully match the defined complexity scores according to traditional readability metrics. Furthermore, the generated rationales tend to feature medium level complexity, which correlates with the measured quality using automatic metrics. Finally, our human annotators confirm a generally satisfactory impression on rationales at all readability levels, with high-school-level readability being most commonly perceived and favored.","authors":["Yi-Sheng Hsu","Nils Feldhus","Sherzod Hakimov"],"url":"https://arxiv.org/abs/2407.01384"}
{"created":"2025-06-04","title":"Diffusion Models for Tabular Data Imputation and Synthetic Data Generation","abstract":"Data imputation and data generation have important applications for many domains, like healthcare and finance, where incomplete or missing data can hinder accurate analysis and decision-making. Diffusion models have emerged as powerful generative models capable of capturing complex data distributions across various data modalities such as image, audio, and time series data. Recently, they have been also adapted to generate tabular data. In this paper, we propose a diffusion model for tabular data that introduces three key enhancements: (1) a conditioning attention mechanism, (2) an encoder-decoder transformer as the denoising network, and (3) dynamic masking. The conditioning attention mechanism is designed to improve the model's ability to capture the relationship between the condition and synthetic data. The transformer layers help model interactions within the condition (encoder) or synthetic data (decoder), while dynamic masking enables our model to efficiently handle both missing data imputation and synthetic data generation tasks within a unified framework. We conduct a comprehensive evaluation by comparing the performance of diffusion models with transformer conditioning against state-of-the-art techniques, such as Variational Autoencoders, Generative Adversarial Networks and Diffusion Models, on benchmark datasets. Our evaluation focuses on the assessment of the generated samples with respect to three important criteria, namely: (1) Machine Learning efficiency, (2) statistical similarity, and (3) privacy risk mitigation. For the task of data imputation, we consider the efficiency of the generated samples across different levels of missing features.","authors":["Mario Villaiz\\'an-Vallelado","Matteo Salvatori","Carlos Segura","Ioannis Arapakis"],"url":"https://arxiv.org/abs/2407.02549"}
{"created":"2025-06-04","title":"No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models","abstract":"Classifier-free guidance (CFG) has become the standard method for enhancing the quality of conditional diffusion models. However, employing CFG requires either training an unconditional model alongside the main diffusion model or modifying the training procedure by periodically inserting a null condition. There is also no clear extension of CFG to unconditional models. In this paper, we revisit the core principles of CFG and introduce a new method, independent condition guidance (ICG), which provides the benefits of CFG without the need for any special training procedures. Our approach streamlines the training process of conditional diffusion models and can also be applied during inference on any pre-trained conditional model. Additionally, by leveraging the time-step information encoded in all diffusion networks, we propose an extension of CFG, called time-step guidance (TSG), which can be applied to any diffusion model, including unconditional ones. Our guidance techniques are easy to implement and have the same sampling cost as CFG. Through extensive experiments, we demonstrate that ICG matches the performance of standard CFG across various conditional diffusion models. Moreover, we show that TSG improves generation quality in a manner similar to CFG, without relying on any conditional information.","authors":["Seyedmorteza Sadat","Manuel Kansy","Otmar Hilliges","Romann M. Weber"],"url":"https://arxiv.org/abs/2407.02687"}
{"created":"2025-06-04","title":"UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs' Memorization","abstract":"This paper introduces UnSeenTimeQA, a novel data contamination-free time-sensitive question-answering (TSQA) benchmark. It differs from existing TSQA benchmarks by avoiding web-searchable queries grounded in the real world. We present a series of time-sensitive event scenarios based on synthetically generated facts. It requires large language models (LLMs) to engage in genuine temporal reasoning without depending on the factual knowledge acquired during the pre-training phase. Our data generation framework enables on-demand generation of new samples, mitigating the risk of data leakage. We designed three types of time-sensitive questions to test LLMs' temporal reasoning abilities over sequential and parallel event occurrences. Our evaluation of five LLMs on synthetic fact-based TSQA reveals mixed results: while they perform well on simpler subsets, their overall performance remains inferior as compared to real world fact-based TSQA. Error analysis indicates that LLMs face difficulties in reasoning over long-range event dependencies and parallel events.","authors":["Md Nayem Uddin","Amir Saeidi","Divij Handa","Agastya Seth","Tran Cao Son","Eduardo Blanco","Steven R. Corman","Chitta Baral"],"url":"https://arxiv.org/abs/2407.03525"}
{"created":"2025-06-04","title":"Enabling 6G Performance in the Upper Mid-Band by Transitioning From Massive to Gigantic MIMO","abstract":"The initial 6G networks will likely operate in the upper mid-band (7-24 GHz), which has decent propagation conditions but underwhelming new spectrum availability. In this paper, we explore whether we can anyway reach the ambitious 6G performance goals by evolving the multiple-input multiple-output (MIMO) technology from massive in 5G to gigantic in 6G. We describe how many antennas are needed to reach the envisioned 6G peak user rates, how many can realistically be deployed in practical radio equipment, and what the practical spatial degrees-of-freedom might become. We further suggest a new deployment strategy that enables the utilization of radiative near-field effects in these bands for precise beamfocusing, localization, and sensing from a single base station site. Finally, we identify open research and standardization challenges that must be overcome to efficiently use gigantic MIMO dimensions in 6G from hardware, cost, and algorithmic perspectives.","authors":["Emil Bj\\\"ornson","Ferdi Kara","Nikolaos Kolomvakis","Alva Kosasih","Parisa Ramezani","Murat Babek Salman"],"url":"https://arxiv.org/abs/2407.05630"}
{"created":"2025-06-04","title":"Cooperative Indoor Exploration Leveraging a Mixed-Size UAV Team with Heterogeneous Sensors","abstract":"Heterogeneous teams of Unmanned Aerial Vehicles (UAVs) can enhance the exploration capabilities of aerial robots by exploiting different strengths and abilities of varying UAVs. This paper presents a novel method for exploring unknown indoor spaces with a team of UAVs of different sizes and sensory equipment. We propose a frontier-based exploration with two task allocation strategies: a greedy strategy that assigns Points of Interest (POIs) based on Euclidean distance and UAV priority and an optimization strategy that solves a minimum-cost flow problem. The proposed method utilizes the SphereMap algorithm to assess the accessibility of the POIs and generate paths that account for obstacle distances, including collision avoidance maneuvers among UAVs. The proposed approach was validated through simulation testing and real-world experiments that evaluated the method's performance on board the UAVs.","authors":["Michaela Cihl\\'a\\v{r}ov\\'a","V\\'aclav Pritzl","Martin Saska"],"url":"https://arxiv.org/abs/2407.09206"}
{"created":"2025-06-04","title":"Conditional Entropies of k-Deletion/Insertion Channels","abstract":"The channel output entropy of a transmitted sequence is the entropy of the possible channel outputs and similarly the channel input entropy of a received sequence is the entropy of all possible transmitted sequences. The goal of this work is to study these entropy values for the k-deletion, k-insertion channels, where exactly k symbols are deleted, inserted in the transmitted sequence, respectively. If all possible sequences are transmitted with the same probability then studying the input and output entropies is equivalent. For both the 1-deletion and 1-insertion channels, it is proved that among all sequences with a fixed number of runs, the input entropy is minimized for sequences with a skewed distribution of their run lengths and it is maximized for sequences with a balanced distribution of their run lengths. Among our results, we establish a conjecture by Atashpendar et al. which claims that for the 1-deletion channel, the input entropy is maximized by the alternating sequences over all binary sequences. This conjecture is also verified for the 2-deletion channel, where it is proved that constant sequences with a single run minimize the input entropy.","authors":["Shubhransh Singhvi","Omer Sabary","Daniella Bar-Lev","Eitan Yaakobi"],"url":"https://arxiv.org/abs/2407.10026"}
{"created":"2025-06-04","title":"Improving Graph Out-of-distribution Generalization Beyond Causality","abstract":"Existing methods for graph out-of-distribution (OOD) generalization primarily rely on empirical studies on synthetic datasets. Such approaches tend to overemphasize the causal relationships between invariant sub-graphs and labels, thereby neglecting the non-negligible role of environment in real-world scenarios. In contrast to previous studies that impose rigid independence assumptions on environments and invariant sub-graphs, this paper presents the theorems of environment-label dependency and mutable rationale invariance, where the former characterizes the usefulness of environments in determining graph labels while the latter refers to the mutable importance of graph rationales. Based on analytic investigations, a novel variational inference based method named ``Probability Dependency on Environments and Rationales for OOD Graphs on Real-world Data'' (DEROG) is introduced. To alleviate the adverse effect of unknown prior knowledge on environments and rationales, DEROG utilizes generalized Bayesian inference. Further, DEROG employs an EM-based algorithm for optimization. Finally, extensive experiments on real-world datasets under different distribution shifts are conducted to show the superiority of DEROG.","authors":["Can Xu","Yao Cheng","Jianxiang Yu","Haosen Wang","Jingsong Lv","Yao Liu","Xiang Li"],"url":"https://arxiv.org/abs/2407.10204"}
{"created":"2025-06-04","title":"Error Bounds for the Network Scale-Up Method","abstract":"Epidemiologists and social scientists have used the Network Scale-Up Method (NSUM) for over thirty years to estimate the size of a hidden sub-population within a social network. This method involves querying a subset of network nodes about the number of their neighbours belonging to the hidden sub-population. In general, NSUM assumes that the social network topology and the hidden sub-population distribution are well-behaved; hence, the NSUM estimate is close to the actual value. However, bounds on NSUM estimation errors have not been analytically proven. This paper provides analytical bounds on the error incurred by the two most popular NSUM estimators. These bounds assume that the queried nodes accurately provide their degree and the number of neighbors belonging to the hidden population. Our key findings are twofold. First, we show that when an adversary designs the network and places the hidden sub-population, then the estimate can be a factor of $\\Omega(\\sqrt{n})$ off from the real value (in a network with $n$ nodes). Second, we also prove error bounds when the underlying network is randomly generated, showing that a small constant factor can be achieved with high probability using samples of logarithmic size $O(\\log{n})$. We present improved analytical bounds for Erdos-Renyi and Scale-Free networks. Our theoretical analysis is supported by an extensive set of numerical experiments designed to determine the effect of the sample size on the accuracy of the estimates in both synthetic and real networks.","authors":["Sergio D\\'iaz-Aranda","Juan Marcos Ram\\'irez","Mohit Daga","Jaya Prakash Champati","Jos\\'e Aguilar","Rosa Elvira Lillo","Antonio Fern\\'andez Anta"],"url":"https://arxiv.org/abs/2407.10640"}
{"created":"2025-06-04","title":"When Heterophily Meets Heterogeneity: Challenges and a New Large-Scale Graph Benchmark","abstract":"Graph mining has become crucial in fields such as social science, finance, and cybersecurity. Many large-scale real-world networks exhibit both heterogeneity, where multiple node and edge types exist in the graph, and heterophily, where connected nodes may have dissimilar labels and attributes. However, existing benchmarks primarily focus on either heterophilic homogeneous graphs or homophilic heterogeneous graphs, leaving a significant gap in understanding how models perform on graphs with both heterogeneity and heterophily. To bridge this gap, we introduce H2GB, a large-scale node-classification graph benchmark that brings together the complexities of both the heterophily and heterogeneity properties of real-world graphs. H2GB encompasses 9 real-world datasets spanning 5 diverse domains, 28 baseline models, and a unified benchmarking library with a standardized data loader, evaluator, unified modeling framework, and an extensible framework for reproducibility. We establish a standardized workflow supporting both model selection and development, enabling researchers to easily benchmark graph learning methods. Extensive experiments across 28 baselines reveal that current methods struggle with heterophilic and heterogeneous graphs, underscoring the need for improved approaches. Finally, we present a new variant of the model, H2G-former, developed following our standardized workflow, that excels at this challenging benchmark. Both the benchmark and the framework are publicly available at Github and PyPI, with documentation hosted at https://junhongmit.github.io/H2GB.","authors":["Junhong Lin","Xiaojie Guo","Shuaicheng Zhang","Yada Zhu","Julian Shun"],"url":"https://arxiv.org/abs/2407.10916"}
{"created":"2025-06-04","title":"Localizing and Mitigating Errors in Long-form Question Answering","abstract":"Long-form question answering (LFQA) aims to provide thorough and in-depth answers to complex questions, enhancing comprehension. However, such detailed responses are prone to hallucinations and factual inconsistencies, challenging their faithful evaluation. This work introduces HaluQuestQA, the first hallucination dataset with localized error annotations for human-written and model-generated LFQA answers. HaluQuestQA comprises 698 QA pairs with 1.8k span-level error annotations for five different error types by expert annotators, along with preference judgments. Using our collected data, we thoroughly analyze the shortcomings of long-form answers and find that they lack comprehensiveness and provide unhelpful references. We train an automatic feedback model on this dataset that predicts error spans with incomplete information and provides associated explanations. Finally, we propose a prompt-based approach, Error-informed refinement, that uses signals from the learned feedback model to refine generated answers, which we show reduces errors and improves answer quality across multiple models. Furthermore, humans find answers generated by our approach comprehensive and highly prefer them (84%) over the baseline answers.","authors":["Rachneet Sachdeva","Yixiao Song","Mohit Iyyer","Iryna Gurevych"],"url":"https://arxiv.org/abs/2407.11930"}
{"created":"2025-06-04","title":"Assurance of AI Systems From a Dependability Perspective","abstract":"We outline the principles of classical assurance for computer-based systems that pose significant risks. We then consider application of these principles to systems that employ Artificial Intelligence (AI) and Machine Learning (ML).","authors":["Robin Bloomfield","John Rushby"],"url":"https://arxiv.org/abs/2407.13948"}
{"created":"2025-06-04","title":"A Survey on Employing Large Language Models for Text-to-SQL Tasks","abstract":"With the development of the Large Language Models (LLMs), a large range of LLM-based Text-to-SQL(Text2SQL) methods have emerged. This survey provides a comprehensive review of LLM-based Text2SQL studies. We first enumerate classic benchmarks and evaluation metrics. For the two mainstream methods, prompt engineering and finetuning, we introduce a comprehensive taxonomy and offer practical insights into each subcategory. We present an overall analysis of the above methods and various models evaluated on well-known datasets and extract some characteristics. Finally, we discuss the challenges and future directions in this field.","authors":["Liang Shi","Zhengju Tang","Nan Zhang","Xiaotong Zhang","Zhi Yang"],"url":"https://arxiv.org/abs/2407.15186"}
{"created":"2025-06-04","title":"Dressed to Gamble: How Poker Drives the Dynamics of Wearables and Visits on Decentraland's Social Virtual World","abstract":"Decentraland is a blockchain-based social virtual world where users can publish and sell wearables to customize avatars. In it, the third-party Decentral Games (DG) allows players of its flagship game ICE Poker to earn cryptocurrency only if they possess certain wearables. Herein, we present a comprehensive study on how DG and its game influence the dynamics of wearables and in-world visits in Decentraland. To this end, we analyzed 5.9 million wearable transfers made on the Polygon blockchain (and related sales) over a two-year period, and 677 million log events of in-world user positions in an overlapping 10-month period. We found that these activities are disproportionately related to DG, with its ICE Poker casinos (less than 0.1% of the world map) representing a remarkable average share of daily unique visitors (33%) and time spent in the virtual world (20%). Despite several alternative initiatives within Decentraland, ICE Poker appears to drive user activity on the platform. Our work thus contributes to the understanding of how play-to-earn games influence user behavior in social virtual worlds, and it is among the first to study the emerging phenomenon of virtual blockchain-based gambling.","authors":["Amaury Trujillo","Clara Bacciu","Matteo Abrate"],"url":"https://arxiv.org/abs/2407.15625"}
{"created":"2025-06-04","title":"Cross-Institutional Dental EHR Entity Extraction via Generative AI and Synthetic Notes","abstract":"This research addresses the issue of missing structured data in dental records by extracting diagnostic information from unstructured text. The updated periodontology classification system's complexity has increased incomplete or missing structured diagnoses. To tackle this, we use advanced AI and NLP methods, leveraging GPT-4 to generate synthetic notes for fine-tuning a RoBERTa model. This significantly enhances the model's ability to understand medical and dental language. We evaluated the model using 120 randomly selected clinical notes from two datasets, demonstrating its improved diagnostic extraction accuracy. The results showed high accuracy in diagnosing periodontal status, stage, and grade, with Site 1 scoring 0.99 and Site 2 scoring 0.98. In the subtype category, Site 2 achieved perfect scores, outperforming Site 1. This method enhances extraction accuracy and broadens its use across dental contexts. The study underscores AI and NLP's transformative impact on healthcare delivery and management. Integrating AI and NLP technologies enhances documentation and simplifies administrative tasks by precisely extracting complex clinical information. This approach effectively addresses challenges in dental diagnostics. Using synthetic training data from LLMs optimizes the training process, improving accuracy and efficiency in identifying periodontal diagnoses from clinical notes. This innovative method holds promise for broader healthcare applications, potentially improving patient care quality.","authors":["Yao-Shun Chuang","Chun-Teh Lee","Oluwabunmi Tokede","Guo-Hao Lin","Ryan Brandon","Trung Duong Tran","Xiaoqian Jiang","Muhammad F. Walji"],"url":"https://arxiv.org/abs/2407.21050"}
{"created":"2025-06-04","title":"SceneMotifCoder: Example-driven Visual Program Learning for Generating 3D Object Arrangements","abstract":"Despite advances in text-to-3D generation methods, generation of multi-object arrangements remains challenging. Current methods exhibit failures in generating physically plausible arrangements that respect the provided text description. We present SceneMotifCoder (SMC), an example-driven framework for generating 3D object arrangements through visual program learning. SMC leverages large language models (LLMs) and program synthesis to overcome these challenges by learning visual programs from example arrangements. These programs are generalized into compact, editable meta-programs. When combined with 3D object retrieval and geometry-aware optimization, they can be used to create object arrangements varying in arrangement structure and contained objects. Our experiments show that SMC generates high-quality arrangements using meta-programs learned from few examples. Evaluation results demonstrates that object arrangements generated by SMC better conform to user-specified text descriptions and are more physically plausible when compared with state-of-the-art text-to-3D generation and layout methods.","authors":["Hou In Ivan Tam","Hou In Derek Pun","Austin T. Wang","Angel X. Chang","Manolis Savva"],"url":"https://arxiv.org/abs/2408.02211"}
{"created":"2025-06-04","title":"Algorithms for the Diverse-k-SAT problem: the geometry of satisfying assignments","abstract":"Given a $k$-CNF formula and an integer $s$, we study algorithms that obtain $s$ solutions to the formula that are maximally dispersed. For $s=2$, the problem of computing the diameter of a $k$-CNF formula was initiated by Creszenzi and Rossi, who showed strong hardness results even for $k=2$. Assuming SETH, the current best upper bound [Angelsmark and Thapper '04] goes to $4^n$ as $k \\rightarrow \\infty$. As our first result, we give exact algorithms for using the Fast Fourier Transform and clique-finding that run in $O^*(2^{(s-1)n})$ and $O^*(s^2 |\\Omega_{F}|^{\\omega \\lceil s/3 \\rceil})$ respectively, where $|\\Omega_{F}|$ is the size of the solution space of the formula $F$ and $\\omega$ is the matrix multiplication exponent.","authors":["Per Austrin","Ioana O. Bercea","Mayank Goswami","Nutan Limaye","Adarsh Srinivasan"],"url":"https://arxiv.org/abs/2408.03465"}
{"created":"2025-06-04","title":"GFlowNet Training by Policy Gradients","abstract":"Generative Flow Networks (GFlowNets) have been shown effective to generate combinatorial objects with desired properties. We here propose a new GFlowNet training framework, with policy-dependent rewards, that bridges keeping flow balance of GFlowNets to optimizing the expected accumulated reward in traditional Reinforcement-Learning (RL). This enables the derivation of new policy-based GFlowNet training methods, in contrast to existing ones resembling value-based RL. It is known that the design of backward policies in GFlowNet training affects efficiency. We further develop a coupled training strategy that jointly solves GFlowNet forward policy training and backward policy design. Performance analysis is provided with a theoretical guarantee of our policy-based GFlowNet training. Experiments on both simulated and real-world datasets verify that our policy-based strategies provide advanced RL perspectives for robust gradient estimation to improve GFlowNet performance.","authors":["Puhua Niu","Shili Wu","Mingzhou Fan","Xiaoning Qian"],"url":"https://arxiv.org/abs/2408.05885"}
{"created":"2025-06-04","title":"Lower Layers Matter: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused","abstract":"Large Language Models (LLMs) have demonstrated exceptional performance across various natural language processing tasks. However, they occasionally generate inaccurate and counterfactual outputs, a phenomenon commonly referred to as \"hallucinations''. To tackle this issue, recent studies have explored contrastive decoding between the original model and an amateur model with induced hallucination, showing promising results. Nevertheless, this approach can disrupt the original LLM's output distribution due to coarse contrast and simple subtraction operations, potentially leading to errors. In this paper, we introduce a novel contrastive decoding framework, termed LOL (LOwer Layer Matters). Unlike prior methods that focus solely on the final layer, our approach integrates contrastive information from lower layers to enable multi-layer fusion during contrastive decoding. Additionally, we incorporate a truthfulness refocused module that leverages instruction guidance to further improve truthfulness in contrastive decoding. Extensive experiments on four publicly available datasets demonstrate that the LOL framework significantly mitigates hallucination while outperforming existing baselines in most cases. For reproducibility, we will release our code and data upon acceptance.","authors":["Dingwei Chen","Feiteng Fang","Shiwen Ni","Feng Liang","Xiping Hu","Ahmadreza Argha","Hamid Alinejad-Rokny","Min Yang","Chengming Li"],"url":"https://arxiv.org/abs/2408.08769"}
{"created":"2025-06-04","title":"LEVIS: Large Exact Verifiable Input Spaces for Neural Networks","abstract":"The robustness of neural networks is crucial in safety-critical applications, where identifying a reliable input space is essential for effective model selection, robustness evaluation, and the development of reliable control strategies. Most existing robustness verification methods assess the worst-case output under the assumption that the input space is known. However, precisely identifying a verifiable input space \\(\\mathcal{C}\\), where no adversarial examples exist, is challenging due to the possible high dimensionality, discontinuity, and non-convex nature of the input space. To address this challenge, we propose a novel framework, **LEVIS**, consisting of **LEVIS-{\\alpha}** and **LEVIS-\\b{eta}**. **LEVIS-{\\alpha}** identifies a single, large verifiable ball that intersects at least two boundaries of a bounded region \\(\\mathcal{C}\\), while **LEVIS-\\b{eta}** systematically captures the entirety of the verifiable space by integrating multiple verifiable balls. Our contributions include: (1) introducing a verification framework that uses mixed-integer programming (MIP) to compute nearest and directional adversarial points, (2) integrating complementarity-constrained (CC) optimization with a reduced MIP formulation for scalability, achieving up to a 6 times runtime reduction, (3) theoretically characterizing the properties of the verifiable balls obtained by **LEVIS-{\\alpha}**, and (4) validating the approach across applications including electrical power flow regression and image classification, with demonstrated performance gains and geometric insights into the verifiable region.","authors":["Mohamad Fares El Hajj Chehade","Wenting Li","Brian W. Bell","Russell Bent","Saif R. Kazi","Hao Zhu"],"url":"https://arxiv.org/abs/2408.08824"}
{"created":"2025-06-04","title":"SDE: A Simplified and Disentangled Dependency Encoding Framework for State Space Models in Time Series Forecasting","abstract":"In recent years, advancements in deep learning have spurred the development of numerous models for Long-term Time Series Forecasting (LTSF). However, most existing approaches struggle to fully capture the complex and structured dependencies inherent in time series data. In this work, we identify and formally define three critical dependencies that are fundamental to forecasting accuracy: order dependency and semantic dependency along the temporal dimension, as well as cross-variate dependency across the feature dimension. These dependencies are often treated in isolation, and improper handling can introduce noise and degrade forecasting performance. To bridge this gap, we investigate the potential of State Space Models (SSMs) for LTSF and emphasize their inherent advantages in capturing these essential dependencies. Additionally, we empirically observe that excessive nonlinearity in conventional SSMs introduce redundancy when applied to semantically sparse time series data. Motivated by this insight, we propose SDE (Simplified and Disentangled Dependency Encoding), a novel framework designed to enhance the capability of SSMs for LTSF. Specifically, we first eliminate unnecessary nonlinearities in vanilla SSMs, thereby improving the suitability for time series forecasting. Building on this foundation, we introduce a disentangled encoding strategy, which empowers SSMs to efficiently model cross-variate dependencies while mitigating interference between the temporal and feature dimensions. Furthermore, we provide rigorous theoretical justifications to substantiate our design choices. Extensive experiments on nine real-world benchmark datasets demonstrate that SDE-enhanced SSMs consistently outperform state-of-the-art time series forecasting models.Our code is available at https://github.com/YukinoAsuna/SAMBA.","authors":["Zixuan Weng","Jindong Han","Wenzhao Jiang","Hao Liu"],"url":"https://arxiv.org/abs/2408.12068"}
{"created":"2025-06-04","title":"T-FAKE: Synthesizing Thermal Images for Facial Landmarking","abstract":"Facial analysis is a key component in a wide range of applications such as healthcare, autonomous driving, and entertainment. Despite the availability of various facial RGB datasets, the thermal modality, which plays a crucial role in life sciences, medicine, and biometrics, has been largely overlooked. To address this gap, we introduce the T-FAKE dataset, a new large-scale synthetic thermal dataset with sparse and dense landmarks. To facilitate the creation of the dataset, we propose a novel RGB2Thermal loss function, which enables the domain-adaptive transfer of RGB faces to thermal style. By utilizing the Wasserstein distance between thermal and RGB patches and the statistical analysis of clinical temperature distributions on faces, we ensure that the generated thermal images closely resemble real samples. Using RGB2Thermal style transfer based on our RGB2Thermal loss function, we create the large-scale synthetic thermal T-FAKE dataset with landmark and segmentation annotations. Leveraging our novel T-FAKE dataset, probabilistic landmark prediction, and label adaptation networks, we demonstrate significant improvements in landmark detection methods on thermal images across different landmark conventions. Our models show excellent performance with both sparse 70-point landmarks and dense 478-point landmark annotations. Moreover, our RGB2Thermal loss leads to notable results in terms of perceptual evaluation and temperature prediction.","authors":["Philipp Flotho (Saarland University)","Moritz Piening (Institute of Mathematics","Technische Universit\\\"at Berlin)","Anna Kukleva (Max Planck Institute for Informatics","Saarland Informatics Campus)","Gabriele Steidl (Institute of Mathematics","Technische Universit\\\"at Berlin)"],"url":"https://arxiv.org/abs/2408.15127"}
{"created":"2025-06-04","title":"Large-Scale Multi-omic Biosequence Transformers for Modeling Protein-Nucleic Acid Interactions","abstract":"The transformer architecture has revolutionized bioinformatics and driven progress in the understanding and prediction of the properties of biomolecules. To date, most biosequence transformers have been trained on a single omic-either proteins or nucleic acids and have seen incredible success in downstream tasks in each domain with particularly noteworthy breakthroughs in protein structural modeling. However, single-omic pre-training limits the ability of these models to capture cross-modal interactions. Here we present OmniBioTE, the largest open-source multi-omic model trained on over 250 billion tokens of mixed protein and nucleic acid data. We show that despite only being trained on unlabelled sequence data, OmniBioTE learns joint representations consistent with the central dogma of molecular biology. We further demonstrate that OmbiBioTE achieves state-of-the-art results predicting the change in Gibbs free energy ({\\Delta}G) of the binding interaction between a given nucleic acid and protein. Remarkably, we show that multi-omic biosequence transformers emergently learn useful structural information without any a priori structural training, allowing us to predict which protein residues are most involved in the protein-nucleic acid binding interaction. Lastly, compared to single-omic controls trained with identical compute, OmniBioTE demonstrates superior performance-per-FLOP and absolute accuracy across both multi-omic and single-omic benchmarks, highlighting the power of a unified modeling approach for biological sequences.","authors":["Sully F. Chen","Robert J. Steele","Glen M. Hocky","Beakal Lemeneh","Shivanand P. Lad","Eric K. Oermann"],"url":"https://arxiv.org/abs/2408.16245"}
{"created":"2025-06-04","title":"StimuVAR: Spatiotemporal Stimuli-aware Video Affective Reasoning with Multimodal Large Language Models","abstract":"Predicting and reasoning how a video would make a human feel is crucial for developing socially intelligent systems. Although Multimodal Large Language Models (MLLMs) have shown impressive video understanding capabilities, they tend to focus more on the semantic content of videos, often overlooking emotional stimuli. Hence, most existing MLLMs fall short in estimating viewers' emotional reactions and providing plausible explanations. To address this issue, we propose StimuVAR, a spatiotemporal Stimuli-aware framework for Video Affective Reasoning (VAR) with MLLMs. StimuVAR incorporates a two-level stimuli-aware mechanism: frame-level awareness and token-level awareness. Frame-level awareness involves sampling video frames with events that are most likely to evoke viewers' emotions. Token-level awareness performs tube selection in the token space to make the MLLM concentrate on emotion-triggered spatiotemporal regions. Furthermore, we create VAR instruction data to perform affective training, steering MLLMs' reasoning strengths towards emotional focus and thereby enhancing their affective reasoning ability. To thoroughly assess the effectiveness of VAR, we provide a comprehensive evaluation protocol with extensive metrics. StimuVAR is the first MLLM-based method for viewer-centered VAR. Experiments demonstrate its superiority in understanding viewers' emotional responses to videos and providing coherent and insightful explanations. Our code is available at https://github.com/EthanG97/StimuVAR","authors":["Yuxiang Guo","Faizan Siddiqui","Yang Zhao","Rama Chellappa","Shao-Yuan Lo"],"url":"https://arxiv.org/abs/2409.00304"}
{"created":"2025-06-04","title":"An Extension of the Adversarial Threat Model in Quantitative Information Flow","abstract":"In this paper, we propose an extended framework for quantitative information flow (QIF), aligned with the previously proposed core-concave generalization of entropy measures, to include adversaries that use Kolmogorov-Nagumo $f$-mean to infer secrets in a private system. Specifically, in our setting, an adversary uses Kolmogorov-Nagumo $f$-mean to compute its best actions before and after observing the system's randomized outputs. This leads to generalized notions of prior and posterior vulnerability and generalized axiomatic relations that we will derive to elucidate how these $f$-mean based vulnerabilities interact with each other. We demonstrate the usefulness of this framework by showing how some notions of leakage that had been derived outside of the QIF framework and so far seemed incompatible with it are indeed explainable via such an extension of QIF. These leakage measures include $\\alpha$-leakage, which is the same as Arimoto mutual information of order $\\alpha$, maximal $\\alpha$-leakage, which is the $\\alpha$-leakage capacity, and maximal $(\\alpha,\\beta)$-leakage, which is a generalization of the above and captures local differential privacy as a special case. We define the notion of generalized capacity and provide partial results for special classes of functions used in the Kolmogorov-Nagumo mean. We also propose a new pointwise notion of gain function, which we coin pointwise information gain. We show that this pointwise information gain can explain R{\\'e}yni divergence and Sibson mutual information of order $\\alpha \\in [0,\\infty]$ as the Kolmogorov-Nagumo average of the gain with a proper choice of function $f$.","authors":["Mohammad Amin Zarrabian","Parastoo Sadeghi"],"url":"https://arxiv.org/abs/2409.04108"}
{"created":"2025-06-04","title":"GASP: Gaussian Splatting for Physic-Based Simulations","abstract":"Physics simulation is paramount for modeling and utilization of 3D scenes in various real-world applications. However, its integration with state-of-the-art 3D scene rendering techniques such as Gaussian Splatting (GS) remains challenging. Existing models use additional meshing mechanisms, including triangle or tetrahedron meshing, marching cubes, or cage meshes. As an alternative, we can modify the physics grounded Newtonian dynamics to align with 3D Gaussian components. Current models take the first-order approximation of a deformation map, which locally approximates the dynamics by linear transformations. In contrast, our Gaussian Splatting for Physics-Based Simulations (GASP) model uses such a map (without any modifications) and flat Gaussian distributions, which are parameterized by three points (mesh faces). Subsequently, each 3D point (mesh face node) is treated as a discrete entity within a 3D space. Consequently, the problem of modeling Gaussian components is reduced to working with 3D points. Additionally, the information on mesh faces can be used to incorporate further properties into the physics model, facilitating the use of triangles. Resulting solution can be integrated into any physics engine that can be treated as a black box. As demonstrated in our studies, the proposed model exhibits superior performance on a diverse range of benchmark datasets designed for 3D object rendering.","authors":["Piotr Borycki","Weronika Smolak","Joanna Waczy\\'nska","Marcin Mazur","S{\\l}awomir Tadeja","Przemys{\\l}aw Spurek"],"url":"https://arxiv.org/abs/2409.05819"}
{"created":"2025-06-04","title":"Contiguous Zero-Copy for Encrypted Transport Protocols","abstract":"We propose in this paper to revisit the design of existing encrypted transport protocols to improve their efficiency. We call the methodology \"Reverso\" from reversing the order of field elements within a protocol specification. We detail how such a benign-looking change within the specifications may unlock implementation optimizations for encrypted protocols during data transport. To demonstrate our findings, we release quiceh, a QUIC implementation of QUIC VReverso, an extension of the QUIC V1 standard (RFC9000). Our methodology applied to the QUIC protocol reports ~30% of CPU efficiency improvement for processing packets at no added cost on the sender side and without relaxing any security guarantee from QUIC V1. We also implement a fork of Cloudflare's HTTP/3 module and client/server demonstrator using quiceh and show our optimizations to directly transfer to HTTP/3 as well, resulting in our new HTTP/3 to be ~38% more efficient than the baseline implementation using QUIC V1. We argue that Reverso applies to any modern encrypted protocol and its implementations and that similar efficiency improvement can also be unlocked for them, independently of the layer in which they operate.","authors":["Florentin Rochet"],"url":"https://arxiv.org/abs/2409.07138"}
{"created":"2025-06-04","title":"Federated Learning for Smart Grid: A Survey on Applications and Potential Vulnerabilities","abstract":"The Smart Grid (SG) is a critical energy infrastructure that collects real-time electricity usage data to forecast future energy demands using information and communication technologies (ICT). Due to growing concerns about data security and privacy in SGs, federated learning (FL) has emerged as a promising training framework. FL offers a balance between privacy, efficiency, and accuracy in SGs by enabling collaborative model training without sharing private data from IoT devices. In this survey, we thoroughly review recent advancements in designing FL-based SG systems across three stages: generation, transmission and distribution, and consumption. Additionally, we explore potential vulnerabilities that may arise when implementing FL in these stages. Furthermore, we discuss the gap between state-of-the-art (SOTA) FL research and its practical applications in SGs, and we propose future research directions. Unlike traditional surveys addressing security issues in centralized machine learning methods for SG systems, this survey is the first to specifically examine the applications and security concerns unique to FL-based SG systems. We also introduce FedGridShield, an open-source framework featuring implementations of SOTA attack and defense methods. Our aim is to inspire further research into applications and improvements in the robustness of FL-based SG systems.","authors":["Zikai Zhang","Suman Rath","Jiaohao Xu","Tingsong Xiao"],"url":"https://arxiv.org/abs/2409.10764"}
{"created":"2025-06-04","title":"FIHA: Autonomous Hallucination Evaluation in Vision-Language Models with Davidson Scene Graphs","abstract":"The rapid development of Large Vision-Language Models (LVLMs) often comes with widespread hallucination issues, making cost-effective and comprehensive assessments increasingly vital. Current approaches mainly rely on costly annotations and are not comprehensive -- in terms of evaluating all aspects such as relations, attributes, and dependencies between aspects. Therefore, we introduce the FIHA (autonomous Fine-graIned Hallucination evAluation evaluation in LVLMs), which could access hallucination LVLMs in the LLM-free and annotation-free way and model the dependency between different types of hallucinations. FIHA can generate Q&amp;A pairs on any image dataset at minimal cost, enabling hallucination assessment from both image and caption. Based on this approach, we introduce a benchmark called FIHA-v1, which consists of diverse questions on various images from MSCOCO and Foggy. Furthermore, we use the Davidson Scene Graph (DSG) to organize the structure among Q&amp;A pairs, in which we can increase the reliability of the evaluation. We evaluate representative models using FIHA-v1, highlighting their limitations and challenges. We released our code and data.","authors":["Bowen Yan","Zhengsong Zhang","Liqiang Jing","Eftekhar Hossain","Xinya Du"],"url":"https://arxiv.org/abs/2409.13612"}
{"created":"2025-06-04","title":"Computing the Proximal Operator of the $q$-th Power of the $\\ell_{1,q}$-norm for Group Sparsity","abstract":"In this note, we comprehensively characterize the proximal operator of the $q$-th power of the $\\ell_{1,q}$-norm (denoted by $\\ell_{1,q}^{q}$) with $0\\!<\\!q\\!<\\!1$ by exploiting the well-known proximal operator of $|\\cdot|^q$ on the real line. In particular, much more explicit characterizations can be obtained whenever $q\\!=\\!1/2$ and $q\\!=\\!2/3$ due to the existence of closed-form expressions for the proximal operators of $|\\cdot|^{1/2}$ and $|\\cdot|^{2/3}$. Numerical experiments demonstrate potential advantages of the $\\ell_{1,q}^{q}$ regularization in the }inter-group and intra-group sparse vector recovery.","authors":["Rongrong Lin","Shihai Chen","Han Feng","Yulan Liu"],"url":"https://arxiv.org/abs/2409.14156"}
{"created":"2025-06-04","title":"An Effective Approach to Embedding Source Code by Combining Large Language and Sentence Embedding Models","abstract":"The advent of large language models (LLMs) has significantly advanced artificial intelligence (AI) in software engineering (SE), with source code embeddings playing a crucial role in tasks such as source code clone detection and source code clustering. However, existing methods for source code embedding, including those based on LLMs, often rely on costly supervised training or fine-tuning for domain adaptation. This paper proposes a novel approach to embedding source code by combining large language and sentence embedding models. This approach attempts to eliminate the need for task-specific training or fine-tuning and to effectively address the issue of erroneous information commonly found in LLM-generated outputs. To evaluate the performance of our proposed approach, we conducted a series of experiments on three datasets with different programming languages by considering various LLMs and sentence embedding models. The experimental results have demonstrated the effectiveness and superiority of our approach over the state-of-the-art unsupervised approaches, such as SourcererCC, Code2vec, InferCode, TransformCode, and LLM2Vec. Our findings highlight the potential of our approach to advance the field of SE by providing robust and efficient solutions for source code embedding tasks.","authors":["Zixiang Xian","Chenhui Cui","Rubing Huang","Chunrong Fang","Zhenyu Chen"],"url":"https://arxiv.org/abs/2409.14644"}
{"created":"2025-06-04","title":"XTRUST: On the Multilingual Trustworthiness of Large Language Models","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities across a range of natural language processing (NLP) tasks, capturing the attention of both practitioners and the broader public. A key question that now preoccupies the AI community concerns the capabilities and limitations of these models, with trustworthiness emerging as a central issue, particularly as LLMs are increasingly applied in sensitive fields like healthcare and finance, where errors can have serious consequences. However, most previous studies on the trustworthiness of LLMs have been limited to a single language, typically the predominant one in the dataset, such as English. In response to the growing global deployment of LLMs, we introduce XTRUST, the first comprehensive multilingual trustworthiness benchmark. XTRUST encompasses a diverse range of topics, including illegal activities, hallucination, out-of-distribution (OOD) robustness, physical and mental health, toxicity, fairness, misinformation, privacy, and machine ethics, across 10 different languages. Using XTRUST, we conduct an empirical evaluation of the multilingual trustworthiness of five widely used LLMs, offering an in-depth analysis of their performance across languages and tasks. Our results indicate that many LLMs struggle with certain low-resource languages, such as Arabic and Russian, highlighting the considerable room for improvement in the multilingual trustworthiness of current language models. The code is available at https://github.com/LluckyYH/XTRUST.","authors":["Yahan Li","Yi Wang","Yi Chang","Yuan Wu"],"url":"https://arxiv.org/abs/2409.15762"}
{"created":"2025-06-04","title":"An Adaptive Re-evaluation Method for Evolution Strategy under Additive Noise","abstract":"The Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES) is one of the most advanced algorithms in numerical black-box optimization. For noisy objective functions, several approaches were proposed to mitigate the noise, e.g., re-evaluations of the same solution or adapting the population size.","authors":["Catalin-Viorel Dinu","Yash J. Patel","Xavier Bonet-Monroig","Hao Wang"],"url":"https://arxiv.org/abs/2409.16757"}
{"created":"2025-06-04","title":"Scalable Multi-Robot Informative Path Planning for Target Mapping via Deep Reinforcement Learning","abstract":"Autonomous robots are widely utilized for mapping and exploration tasks due to their cost-effectiveness. Multi-robot systems offer scalability and efficiency, especially in terms of the number of robots deployed in more complex environments. These tasks belong to the set of Multi-Robot Informative Path Planning (MRIPP) problems. In this paper, we propose a deep reinforcement learning approach for the MRIPP problem. We aim to maximize the number of discovered stationary targets in an unknown 3D environment while operating under resource constraints (such as path length). Here, each robot aims to maximize discovered targets, avoid unknown static obstacles, and prevent inter-robot collisions while operating under communication and resource constraints. We utilize the centralized training and decentralized execution paradigm to train a single policy neural network. A key aspect of our approach is our coordination graph that prioritizes visiting regions not yet explored by other robots. Our learned policy can be copied onto any number of robots for deployment in more complex environments not seen during training. Our approach outperforms state-of-the-art approaches by at least 26.2% in terms of the number of discovered targets while requiring a planning time of less than 2 sec per step. We present results for more complex environments with up to 64 robots and compare success rates against baseline planners. Our code and trained model are available at - https://github.com/AccGen99/marl_ipp","authors":["Apoorva Vashisth","Manav Kulshrestha","Damon Conover","Aniket Bera"],"url":"https://arxiv.org/abs/2409.16967"}
{"created":"2025-06-04","title":"How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not","abstract":"The remarkable performance achieved by Large Language Models (LLM) has driven research efforts to leverage them for a wide range of tasks and input modalities. In speech-to-text (S2T) tasks, the emerging solution consists of projecting the output of the encoder of a Speech Foundational Model (SFM) into the LLM embedding space through an adapter module. However, no work has yet investigated how much the downstream-task performance depends on each component (SFM, adapter, LLM) nor whether the best design of the adapter depends on the chosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adapter modules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) on two widespread S2T tasks, namely Automatic Speech Recognition and Speech Translation. Our results demonstrate that the SFM plays a pivotal role in downstream performance, while the adapter choice has moderate impact and depends on the SFM and LLM.","authors":["Francesco Verdini","Pierfrancesco Melucci","Stefano Perna","Francesco Cariaggi","Marco Gaido","Sara Papi","Szymon Mazurek","Marek Kasztelnik","Luisa Bentivogli","S\\'ebastien Brati\\`eres","Paolo Merialdo","Simone Scardapane"],"url":"https://arxiv.org/abs/2409.17044"}
{"created":"2025-06-04","title":"Ensemble Kalman Diffusion Guidance: A Derivative-free Method for Inverse Problems","abstract":"When solving inverse problems, one increasingly popular approach is to use pre-trained diffusion models as plug-and-play priors. This framework can accommodate different forward models without re-training while preserving the generative capability of diffusion models. Despite their success in many imaging inverse problems, most existing methods rely on privileged information such as derivative, pseudo-inverse, or full knowledge about the forward model. This reliance poses a substantial limitation that restricts their use in a wide range of problems where such information is unavailable, such as in many scientific applications. We propose Ensemble Kalman Diffusion Guidance (EnKG), a derivative-free approach that can solve inverse problems by only accessing forward model evaluations and a pre-trained diffusion model prior. We study the empirical effectiveness of EnKG across various inverse problems, including scientific settings such as inferring fluid flows and astronomical objects, which are highly non-linear inverse problems that often only permit black-box access to the forward model. We open-source our code at https://github.com/devzhk/enkg-pytorch.","authors":["Hongkai Zheng","Wenda Chu","Austin Wang","Nikola Kovachki","Ricardo Baptista","Yisong Yue"],"url":"https://arxiv.org/abs/2409.20175"}
{"created":"2025-06-04","title":"Answer When Needed, Forget When Not: Language Models Pretend to Forget via In-Context Knowledge Unlearning","abstract":"As large language models (LLMs) are applied across diverse domains, the ability to selectively unlearn specific information is becoming increasingly essential. For instance, LLMs are expected to selectively provide confidential information to authorized internal users, such as employees or trusted partners, while withholding it from external users, including the general public and unauthorized entities. Therefore, we propose a novel method termed ``in-context knowledge unlearning'', which enables the model to selectively forget information in test-time based on the query context. Our method fine-tunes pre-trained LLMs to enable prompt unlearning of target knowledge within the context, while preserving unrelated information. Experiments on TOFU, AGE and RWKU datasets using Llama2-7B/13B and Mistral-7B models demonstrate that our method achieves up to 95% forget accuracy while retaining 80% of unrelated knowledge, significantly outperforming baselines in both in-domain and out-of-domain scenarios. Further investigation of the model's internal behavior revealed that while fine-tuned LLMs generate correct predictions in the middle layers and preserve them up to the final layer. However, the decision to forget is made only at the last layer, i.e. ``LLMs pretend to forget''. Our findings offer valuable insight into the improvement of the robustness of the unlearning mechanisms in LLMs, laying a foundation for future research in the field.","authors":["Shota Takashiro","Takeshi Kojima","Andrew Gambardella","Qi Cao","Yusuke Iwasawa","Yutaka Matsuo"],"url":"https://arxiv.org/abs/2410.00382"}
{"created":"2025-06-04","title":"Steering Elongate Multi-legged Robots By Modulating Body Undulation Waves","abstract":"Centipedes exhibit great maneuverability in diverse environments due to their many legs and body-driven control. By leveraging similar morphologies and control strategies, their robotic counterparts also demonstrate effective terrestrial locomotion. However, the success of these multi-legged robots is largely limited to forward locomotion; steering is substantially less studied, in part because of the difficulty in coordinating a high degree-of-freedom robot to follow predictable, planar trajectories. To resolve these challenges, we take inspiration from control schemes based on geometric mechanics(GM) in elongate system's locomotion through highly damped environments. We model the elongate, multi-legged system as a ``terrestrial swimmer\" in highly frictional environments and implement steering schemes derived from low-order templates of elongate, limbless systems. We identify an effective turning strategy by superimposing two traveling waves of lateral body undulation and further explore variations of the ``turning wave\" to enable a spectrum of arc-following steering primitives. We test our hypothesized modulation scheme on a robophysical model and validate steering trajectories against theoretically predicted displacements. We then apply our control framework to Ground Control Robotics' elongate multi-legged robot, Major Tom, using these motion primitives to construct planar motion and in closed-loop control on different terrains. Our work creates a systematic framework for controlling these highly mobile devices in the plane using a low-order model based on sequences of body shape changes.","authors":["Esteban Flores","Baxi Chong","Daniel Soto","Daniel I. Goldman"],"url":"https://arxiv.org/abs/2410.01050"}
{"created":"2025-06-04","title":"Adversarial Robustness of AI-Generated Image Detectors in the Real World","abstract":"The rapid advancement of Generative Artificial Intelligence (GenAI) capabilities is accompanied by a concerning rise in its misuse. In particular the generation of credible misinformation in the form of images poses a significant threat to the public trust in democratic processes. Consequently, there is an urgent need to develop tools to reliably distinguish between authentic and AI-generated content. The majority of detection methods are based on neural networks that are trained to recognize forensic artifacts. In this work, we demonstrate that current state-of-the-art classifiers are vulnerable to adversarial examples under real-world conditions. Through extensive experiments, comprising four detection methods and five attack algorithms, we show that an attacker can dramatically decrease classification performance, without internal knowledge of the detector's architecture. Notably, most attacks remain effective even when images are degraded during the upload to, e.g., social media platforms. In a case study, we demonstrate that these robustness challenges are also found in commercial tools by conducting black-box attacks on HIVE, a proprietary online GenAI media detector. In addition, we evaluate the robustness of using generated features of a robust pre-trained model and showed that this increases the robustness, while not reaching the performance on benign inputs. These results, along with the increasing potential of GenAI to erode public trust, underscore the need for more research and new perspectives on methods to prevent its misuse.","authors":["Sina Mavali","Jonas Ricker","David Pape","Asja Fischer","Lea Sch\\\"onherr"],"url":"https://arxiv.org/abs/2410.01574"}
{"created":"2025-06-04","title":"Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models","abstract":"Classifier-free guidance (CFG) is crucial for improving both generation quality and alignment between the input condition and final output in diffusion models. While a high guidance scale is generally required to enhance these aspects, it also causes oversaturation and unrealistic artifacts. In this paper, we revisit the CFG update rule and introduce modifications to address this issue. We first decompose the update term in CFG into parallel and orthogonal components with respect to the conditional model prediction and observe that the parallel component primarily causes oversaturation, while the orthogonal component enhances image quality. Accordingly, we propose down-weighting the parallel component to achieve high-quality generations without oversaturation. Additionally, we draw a connection between CFG and gradient ascent and introduce a new rescaling and momentum method for the CFG update rule based on this insight. Our approach, termed adaptive projected guidance (APG), retains the quality-boosting advantages of CFG while enabling the use of higher guidance scales without oversaturation. APG is easy to implement and introduces practically no additional computational overhead to the sampling process. Through extensive experiments, we demonstrate that APG is compatible with various conditional diffusion models and samplers, leading to improved FID, recall, and saturation scores while maintaining precision comparable to CFG, making our method a superior plug-and-play alternative to standard classifier-free guidance.","authors":["Seyedmorteza Sadat","Otmar Hilliges","Romann M. Weber"],"url":"https://arxiv.org/abs/2410.02416"}
{"created":"2025-06-04","title":"Federated k-Core Decomposition: A Secure Distributed Approach","abstract":"As one of the most well-studied cohesive subgraph models, the $k$-core is widely used to find graph nodes that are ``central'' or ``important'' in many applications, such as biological networks, social networks, ecological networks, and financial networks. For Decentralized Online Social Networks (DOSNs), where each vertex is a client as a single computing unit, distributed k-core decomposition algorithms have already been proposed. However, current distributed approaches fail to adequately protect privacy and security. In today's data-driven world, data privacy and security have attracted more and more attention, e.g., DOSNs are proposed to protect privacy by storing user information locally without using a single centralized server. In this work, we are the first to propose the secure version of the distributed $k$-core decomposition.","authors":["Bin Guo","Emil Sekerinski","Lingyang Chu"],"url":"https://arxiv.org/abs/2410.02544"}
{"created":"2025-06-04","title":"CulturalBench: A Robust, Diverse, and Challenging Cultural Benchmark by Human-AI CulturalTeaming","abstract":"Robust, diverse, and challenging cultural knowledge benchmarks are essential for measuring our progress towards making LMs that are helpful across diverse cultures. We introduce CulturalBench: a set of 1,696 human-written and human-verified questions to assess LMs' cultural knowledge, covering 45 global regions including underrepresented ones like Bangladesh, Zimbabwe, and Peru. Questions are each verified by five independent annotators and span 17 diverse topics ranging from food preferences to greeting etiquette. We construct CulturalBench using methods inspired by Human-AI Red-Teaming. Compared to human performance (92.4% accuracy), the hard version of CulturalBench is challenging even for the best-performing frontier LMs, ranging from 28.7% to 61.5% in accuracy. We find that LMs often struggle with tricky questions that have multiple correct answers (e.g., What utensils do the Chinese usually use?), revealing a tendency to overfit to a single answer. Our results indicate that GPT-4o substantially outperform other models across cultures, besting local providers (e.g., Mistral on European culture and DeepSeek on Chinese culture). Across the board, models under-perform on questions related to North Africa, South America and Middle East.","authors":["Yu Ying Chiu","Liwei Jiang","Bill Yuchen Lin","Chan Young Park","Shuyue Stella Li","Sahithya Ravi","Mehar Bhatia","Maria Antoniak","Yulia Tsvetkov","Vered Shwartz","Yejin Choi"],"url":"https://arxiv.org/abs/2410.02677"}
{"created":"2025-06-04","title":"Chain-of-Jailbreak Attack for Image Generation Models via Editing Step by Step","abstract":"Text-based image generation models, such as Stable Diffusion and DALL-E 3, hold significant potential in content creation and publishing workflows, making them the focus in recent years. Despite their remarkable capability to generate diverse and vivid images, considerable efforts are being made to prevent the generation of harmful content, such as abusive, violent, or pornographic material. To assess the safety of existing models, we introduce a novel jailbreaking method called Chain-of-Jailbreak (CoJ) attack, which compromises image generation models through a step-by-step editing process. Specifically, for malicious queries that cannot bypass the safeguards with a single prompt, we intentionally decompose the query into multiple sub-queries. The image generation models are then prompted to generate and iteratively edit images based on these sub-queries. To evaluate the effectiveness of our CoJ attack method, we constructed a comprehensive dataset, CoJ-Bench, encompassing nine safety scenarios, three types of editing operations, and three editing elements. Experiments on four widely-used image generation services provided by GPT-4V, GPT-4o, Gemini 1.5 and Gemini 1.5 Pro, demonstrate that our CoJ attack method can successfully bypass the safeguards of models for over 60% cases, which significantly outperforms other jailbreaking methods (i.e., 14%). Further, to enhance these models' safety against our CoJ attack method, we also propose an effective prompting-based method, Think Twice Prompting, that can successfully defend over 95% of CoJ attack. We release our dataset and code to facilitate the AI safety research.","authors":["Wenxuan Wang","Kuiyi Gao","Youliang Yuan","Jen-tse Huang","Qiuzhi Liu","Shuai Wang","Wenxiang Jiao","Zhaopeng Tu"],"url":"https://arxiv.org/abs/2410.03869"}
{"created":"2025-06-04","title":"SparseVLM: Visual Token Sparsification for Efficient Vision-Language Model Inference","abstract":"In vision-language models (VLMs), visual tokens usually bear a significant amount of computational overhead despite sparsity of information in them when compared to text tokens. To address this, most existing methods learn a network to prune redundant visual tokens using certain training data. Differently, we propose a text-guided training-free token optimization mechanism dubbed SparseVLM that eliminates the need of extra parameters or fine-tuning costs. Given that visual tokens complement text tokens in VLM's linguistic reasoning, we select relevant text tokens to rate the significance of visual tokens using self-attention matrices and, then, prune visual tokens using the proposed strategy to maximize sparsity while retaining information. In particular, we introduce a rank-based strategy to adaptively determine the sparsification ratio for each layer, alongside a token recycling method that compresses pruned tokens into more compact representations. Experimental results show that SparseVLM increases the efficiency of various VLMs in a number of image and video understanding tasks. For example, LLaVA when equipped with SparseVLM achieves 54% reduction in FLOPs, 37% decrease in CUDA latency while maintaining 97% of its original accuracy. Our code is available at https://github.com/Gumpest/SparseVLMs.","authors":["Yuan Zhang","Chun-Kai Fan","Junpeng Ma","Wenzhao Zheng","Tao Huang","Kuan Cheng","Denis Gudovskiy","Tomoyuki Okuno","Yohei Nakata","Kurt Keutzer","Shanghang Zhang"],"url":"https://arxiv.org/abs/2410.04417"}
{"created":"2025-06-04","title":"CodeDPO: Aligning Code Models with Self Generated and Verified Source Code","abstract":"Code generation models have shown significant potential for programming tasks. However, existing training methods like supervised fine-tuning face key limitations: they do not effectively teach models to prioritize correct over incorrect solutions in ambiguous situations, nor do they effectively optimize the runtime efficiency of the generated code. To address these challenges, we propose CodeDPO, a framework that integrates preference learning into code generation to improve two key code preference factors: code correctness and efficiency. CodeDPO employs a novel dataset construction method, utilizing a self-generation-and-validation mechanism that simultaneously generates and evaluates code and test cases. The underlying assumption is that test cases executable by multiple code snippets provide more reliable validation, and code that passes more tests is more likely to be correct. Through this self-validation process, our PageRank-inspired algorithm iteratively updates the ranking score of each code snippet, ultimately creating a code preference optimization dataset based on correctness and efficiency. CodeDPO is flexible and scalable, generating diverse preference optimization data without depending on external resources. Through comprehensive evaluations of five widely used benchmarks, CodeDPO demonstrates significant improvements in correctness and efficiency compared to existing methods. Our experiments prove that CodeDPO enhances the capabilities of LLMs in code generation and provides a robust foundation for conducting code preference optimization in more complex and challenging real-world scenarios.","authors":["Kechi Zhang","Ge Li","Yihong Dong","Jingjing Xu","Jun Zhang","Jing Su","Yongfei Liu","Zhi Jin"],"url":"https://arxiv.org/abs/2410.05605"}
{"created":"2025-06-04","title":"Adaptive Guidance for Local Training in Heterogeneous Federated Learning","abstract":"Model heterogeneity poses a significant challenge in Heterogeneous Federated Learning (HtFL). In scenarios with diverse model architectures, directly aggregating model parameters is impractical, leading HtFL methods to incorporate an extra objective alongside the original local objective on each client to facilitate collaboration. However, this often results in a mismatch between the extra and local objectives. To resolve this, we propose Federated Learning-to-Guide (FedL2G), a method that adaptively learns to guide local training in a federated manner, ensuring the added objective aligns with each client's original goal. With theoretical guarantees, FedL2G utilizes only first-order derivatives w.r.t. model parameters, achieving a non-convex convergence rate of O(1/T). We conduct extensive experiments across two data heterogeneity and six model heterogeneity settings, using 14 heterogeneous model architectures (e.g., CNNs and ViTs). The results show that FedL2G significantly outperforms seven state-of-the-art methods.","authors":["Jianqing Zhang","Yang Liu","Yang Hua","Jian Cao","Qiang Yang"],"url":"https://arxiv.org/abs/2410.06490"}
{"created":"2025-06-04","title":"Average Certified Radius is a Poor Metric for Randomized Smoothing","abstract":"Randomized smoothing (RS) is popular for providing certified robustness guarantees against adversarial attacks. The average certified radius (ACR) has emerged as a widely used metric for tracking progress in RS. However, in this work, for the first time we show that ACR is a poor metric for evaluating robustness guarantees provided by RS. We theoretically prove not only that a trivial classifier can have arbitrarily large ACR, but also that ACR is extremely sensitive to improvements on easy samples. In addition, the comparison using ACR has a strong dependence on the certification budget. Empirically, we confirm that existing training strategies, though improving ACR, reduce the model's robustness on hard samples consistently. To strengthen our findings, we propose strategies, including explicitly discarding hard samples, reweighing the dataset with approximate certified radius, and extreme optimization for easy samples, to replicate the progress in RS training and even achieve the state-of-the-art ACR on CIFAR-10, without training for robustness on the full data distribution. Overall, our results suggest that ACR has introduced a strong undesired bias to the field, and its application should be discontinued in RS. Finally, we suggest using the empirical distribution of $p_A$, the accuracy of the base model on noisy data, as an alternative metric for RS.","authors":["Chenhao Sun","Yuhao Mao","Mark Niklas M\\\"uller","Martin Vechev"],"url":"https://arxiv.org/abs/2410.06895"}
{"created":"2025-06-04","title":"Efficient Dictionary Learning with Switch Sparse Autoencoders","abstract":"Sparse autoencoders (SAEs) are a recent technique for decomposing neural network activations into human-interpretable features. However, in order for SAEs to identify all features represented in frontier models, it will be necessary to scale them up to very high width, posing a computational challenge. In this work, we introduce Switch Sparse Autoencoders, a novel SAE architecture aimed at reducing the compute cost of training SAEs. Inspired by sparse mixture of experts models, Switch SAEs route activation vectors between smaller \"expert\" SAEs, enabling SAEs to efficiently scale to many more features. We present experiments comparing Switch SAEs with other SAE architectures, and find that Switch SAEs deliver a substantial Pareto improvement in the reconstruction vs. sparsity frontier for a given fixed training compute budget. We also study the geometry of features across experts, analyze features duplicated across experts, and verify that Switch SAE features are as interpretable as features found by other SAE architectures.","authors":["Anish Mudide","Joshua Engels","Eric J. Michaud","Max Tegmark","Christian Schroeder de Witt"],"url":"https://arxiv.org/abs/2410.08201"}
{"created":"2025-06-04","title":"Large Language Model Evaluation via Matrix Nuclear-Norm","abstract":"As large language models (LLMs) continue to evolve, efficient evaluation metrics are vital for assessing their ability to compress information and reduce redundancy. While traditional metrics like Matrix Entropy offer valuable insights, they are computationally intensive for large-scale models due to their \\( O(n^3) \\) time complexity with Singular Value Decomposition (SVD). To mitigate this issue, we introduce the Matrix Nuclear-Norm, which not only serves as a metric to quantify the data compression proficiency of LLM but also provides a convex approximation of matrix rank to capture both predictive discriminability and diversity. By employing the \\( L_{1,2}\\text{-norm} \\) to further approximate the nuclear norm, we can effectively assess the model's information compression capabilities. This approach reduces the time complexity to \\( O(n^2) \\) and eliminates the need for SVD computation. Consequently, the Matrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy for the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This performance gap becomes more pronounced with larger models, as validated in tests with other models like Pythia. Additionally, evaluations on benchmarks and model responses confirm that our proposed Matrix Nuclear-Norm is a reliable, scalable, and efficient tool for assessing LLMs' performance, striking a balance between accuracy and computational efficiency. The code is available at https://github.com/MLGroupJLU/MatrixNuclearNorm.","authors":["Yahan Li","Tingyu Xia","Yi Chang","Yuan Wu"],"url":"https://arxiv.org/abs/2410.10672"}
{"created":"2025-06-04","title":"HardNet: Hard-Constrained Neural Networks with Universal Approximation Guarantees","abstract":"Incorporating prior knowledge or specifications of input-output relationships into machine learning models has attracted significant attention, as it enhances generalization from limited data and leads to conforming outputs. However, most existing approaches use soft constraints by penalizing violations through regularization, which offers no guarantee of constraint satisfaction, especially on inputs far from the training distribution -- an essential requirement in safety-critical applications. On the other hand, imposing hard constraints on neural networks may hinder their representational power, adversely affecting performance. To address this, we propose HardNet, a practical framework for constructing neural networks that inherently satisfy hard constraints without sacrificing model capacity. Unlike approaches that modify outputs only at inference time, HardNet enables end-to-end training with hard constraint guarantees, leading to improved performance. To the best of our knowledge, HardNet is the first method with an efficient forward pass to enforce more than one input-dependent inequality constraint. It allows unconstrained optimization of the network parameters using standard algorithms by appending a differentiable closed-form enforcement layer to the network's output. Furthermore, we show that HardNet is expressive and retains the universal approximation capabilities of neural networks. We demonstrate the versatility and effectiveness of HardNet across various applications: learning with piecewise constraints, learning optimization solvers with guaranteed feasibility, and optimizing control policies in safety-critical systems.","authors":["Youngjae Min","Navid Azizan"],"url":"https://arxiv.org/abs/2410.10807"}
{"created":"2025-06-04","title":"Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation","abstract":"Quality estimation (QE)-the automatic assessment of translation quality-has recently become crucial across several stages of the translation pipeline, from data curation to training and decoding. While QE metrics have been optimized to align with human judgments, whether they encode social biases has been largely overlooked. Biased QE risks favoring certain demographic groups over others, e.g., by exacerbating gaps in visibility and usability. This paper defines and investigates gender bias of QE metrics and discusses its downstream implications for machine translation (MT). Experiments with state-of-the-art QE metrics across multiple domains, datasets, and languages reveal significant bias. When a human entity's gender in the source is undisclosed, masculine-inflected translations score higher than feminine-inflected ones, and gender-neutral translations are penalized. Even when contextual cues disambiguate gender, using context-aware QE metrics leads to more errors in selecting the correct translation inflection for feminine referents than for masculine ones. Moreover, a biased QE metric affects data filtering and quality-aware decoding. Our findings underscore the need for a renewed focus on developing and evaluating QE metrics centered on gender.","authors":["Emmanouil Zaranis","Giuseppe Attanasio","Sweta Agrawal","Andr\\'e F. T. Martins"],"url":"https://arxiv.org/abs/2410.10995"}
{"created":"2025-06-04","title":"Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning","abstract":"Instruction-fine-tuned large language models (LLMs) under 14B parameters continue to underperform on natural language understanding (NLU) tasks, often trailing smaller models like BERT-base on benchmarks such as GLUE and SuperGLUE. Motivated by the success of reinforcement learning in reasoning tasks (e.g., DeepSeek), we explore Proximal Policy Optimization (PPO) as a framework to improve the NLU capabilities of LLMs. We frame NLU as a reinforcement learning environment, treating token generation as a sequence of actions and optimizing for reward signals based on alignment with ground-truth labels. PPO consistently outperforms supervised fine-tuning, yielding an average improvement of 6.3 points on GLUE, and surpasses zero-shot and few-shot prompting by 38.7 and 26.1 points, respectively. Notably, PPO-tuned models outperform GPT-4o by over 4\\% on average across sentiment and natural language inference tasks, including gains of 7.3\\% on the Mental Health dataset and 10.9\\% on SIGA-nli. This work highlights a promising direction for adapting LLMs to new tasks by reframing them as reinforcement learning problems, enabling learning through simple end-task rewards rather than extensive data curation.","authors":["Bokai Hu","Sai Ashish Somayajula","Xin Pan","Pengtao Xie"],"url":"https://arxiv.org/abs/2410.11020"}
{"created":"2025-06-04","title":"A Hitchhiker's Guide to Scaling Law Estimation","abstract":"Scaling laws predict the loss of a target machine learning model by extrapolating from easier-to-train models with fewer parameters or smaller training sets. This provides an efficient way for practitioners and researchers alike to compare pretraining decisions involving optimizers, datasets, and model architectures. Despite the widespread use of scaling laws to model the dynamics of language model training, there has been little work on understanding how to best estimate and interpret them. We collect (and release) a large-scale dataset containing losses and downstream evaluations for 485 previously published pretrained models. We use these to estimate more than 1000 scaling laws, then derive a set of best practices for estimating scaling laws in new model families. We find that fitting scaling laws to intermediate checkpoints of training runs (and not just their final losses) substantially improves accuracy, and that -- all else equal -- estimates of performance are generally most accurate when derived from other models of similar sizes. However, because there is a significant degree of variability across model seeds, training multiple small models is sometimes more useful than training a single large one. Moreover, while different model families differ scaling behavior, they are often similar enough that a target model's behavior can be predicted from a single model with the same architecture, along with scaling parameter estimates derived from other model families.","authors":["Leshem Choshen","Yang Zhang","Jacob Andreas"],"url":"https://arxiv.org/abs/2410.11840"}
{"created":"2025-06-04","title":"BenchmarkCards: Standardized Documentation for Large Language Model Benchmarks","abstract":"Large language models (LLMs) are powerful tools capable of handling diverse tasks. Comparing and selecting appropriate LLMs for specific tasks requires systematic evaluation methods, as models exhibit varying capabilities across different domains. However, finding suitable benchmarks is difficult given the many available options. This complexity not only increases the risk of benchmark misuse and misinterpretation but also demands substantial effort from LLM users, seeking the most suitable benchmarks for their specific needs. To address these issues, we introduce \\texttt{BenchmarkCards}, an intuitive and validated documentation framework that standardizes critical benchmark attributes such as objectives, methodologies, data sources, and limitations. Through user studies involving benchmark creators and users, we show that \\texttt{BenchmarkCards} can simplify benchmark selection and enhance transparency, facilitating informed decision-making in evaluating LLMs. Data & Code: https://github.com/SokolAnn/BenchmarkCards","authors":["Anna Sokol","Elizabeth Daly","Michael Hind","David Piorkowski","Xiangliang Zhang","Nuno Moniz","Nitesh Chawla"],"url":"https://arxiv.org/abs/2410.12974"}
{"created":"2025-06-04","title":"Learning on Model Weights using Tree Experts","abstract":"The number of publicly available models is rapidly increasing, yet most remain undocumented. Users looking for suitable models for their tasks must first determine what each model does. Training machine learning models to infer missing documentation directly from model weights is challenging, as these weights often contain significant variation unrelated to model functionality (denoted nuisance). Here, we identify a key property of real-world models: most public models belong to a small set of Model Trees, where all models within a tree are fine-tuned from a common ancestor (e.g., a foundation model). Importantly, we find that within each tree there is less nuisance variation between models. Concretely, while learning across Model Trees requires complex architectures, even a linear classifier trained on a single model layer often works within trees. While effective, these linear classifiers are computationally expensive, especially when dealing with larger models that have many parameters. To address this, we introduce Probing Experts (ProbeX), a theoretically motivated and lightweight method. Notably, ProbeX is the first probing method specifically designed to learn from the weights of a single hidden model layer. We demonstrate the effectiveness of ProbeX by predicting the categories in a model's training dataset based only on its weights. Excitingly, ProbeX can map the weights of Stable Diffusion into a weight-language embedding space, enabling model search via text, i.e., zero-shot model classification.","authors":["Eliahu Horwitz","Bar Cavia","Jonathan Kahana","Yedid Hoshen"],"url":"https://arxiv.org/abs/2410.13569"}
{"created":"2025-06-04","title":"Online Learning for Function Placement in Serverless Computing","abstract":"We study the placement of virtual functions aimed at minimizing the cost. We propose a novel algorithm, using ideas based on multi-armed bandits. We prove that these algorithms learn the optimal placement policy rapidly, and their regret grows at a rate at most $O( N M \\sqrt{T\\ln T} )$ while respecting the feasibility constraints with high probability, where $T$ is total time slots, $M$ is the number of classes of function and $N$ is the number of computation nodes. We show through numerical experiments that the proposed algorithm both has good practical performance and modest computational complexity. We propose an acceleration technique that allows the algorithm to achieve good performance also in large networks where computational power is limited. Our experiments are fully reproducible, and the code is publicly available.","authors":["Wei Huang","Richard Combes","Andrea Araldo","Hind Castel-Taleb","Badii Jouaber"],"url":"https://arxiv.org/abs/2410.13696"}
{"created":"2025-06-04","title":"Adversarial Inception Backdoor Attacks against Reinforcement Learning","abstract":"Recent works have demonstrated the vulnerability of Deep Reinforcement Learning (DRL) algorithms against training-time, backdoor poisoning attacks. The objectives of these attacks are twofold: induce pre-determined, adversarial behavior in the agent upon observing a fixed trigger during deployment while allowing the agent to solve its intended task during training. Prior attacks assume arbitrary control over the agent's rewards, inducing values far outside the environment's natural constraints. This results in brittle attacks that fail once the proper reward constraints are enforced. Thus, in this work we propose a new class of backdoor attacks against DRL which are the first to achieve state of the art performance under strict reward constraints. These \"inception\" attacks manipulate the agent's training data -- inserting the trigger into prior observations and replacing high return actions with those of the targeted adversarial behavior. We formally define these attacks and prove they achieve both adversarial objectives against arbitrary Markov Decision Processes (MDP). Using this framework we devise an online inception attack which achieves an 100\\% attack success rate on multiple environments under constrained rewards while minimally impacting the agent's task performance.","authors":["Ethan Rathbun","Alina Oprea","Christopher Amato"],"url":"https://arxiv.org/abs/2410.13995"}
{"created":"2025-06-04","title":"In-context learning and Occam's razor","abstract":"A central goal of machine learning is generalization. While the No Free Lunch Theorem states that we cannot obtain theoretical guarantees for generalization without further assumptions, in practice we observe that simple models which explain the training data generalize best: a principle called Occam's razor. Despite the need for simple models, most current approaches in machine learning only minimize the training error, and at best indirectly promote simplicity through regularization or architecture design. Here, we draw a connection between Occam's razor and in-context learning: an emergent ability of certain sequence models like Transformers to learn at inference time from past observations in a sequence. In particular, we show that the next-token prediction loss used to train in-context learners is directly equivalent to a data compression technique called prequential coding, and that minimizing this loss amounts to jointly minimizing both the training error and the complexity of the model that was implicitly learned from context. Our theory and the empirical experiments we use to support it not only provide a normative account of in-context learning, but also elucidate the shortcomings of current in-context learning methods, suggesting ways in which they can be improved. We make our code available at https://github.com/3rdCore/PrequentialCode.","authors":["Eric Elmoznino","Tom Marty","Tejas Kasetty","Leo Gagnon","Sarthak Mittal","Mahan Fathi","Dhanya Sridhar","Guillaume Lajoie"],"url":"https://arxiv.org/abs/2410.14086"}
{"created":"2025-06-04","title":"A Complexity-Based Theory of Compositionality","abstract":"Compositionality is believed to be fundamental to intelligence. In humans, it underlies the structure of thought, language, and higher-level reasoning. In AI, compositional representations can enable a powerful form of out-of-distribution generalization, in which a model systematically adapts to novel combinations of known concepts. However, while we have strong intuitions about what compositionality is, we lack satisfying formal definitions for it that are measurable and mathematical. Here, we propose such a definition, which we call representational compositionality, that accounts for and extends our intuitions about compositionality. The definition is conceptually simple, quantitative, grounded in algorithmic information theory, and applicable to any representation. Intuitively, representational compositionality states that a compositional representation satisfies three properties. First, it must be expressive. Second, it must be possible to re-describe the representation as a function of discrete symbolic sequences with re-combinable parts, analogous to sentences in natural language. Third, the function that relates these symbolic sequences to the representation, analogous to semantics in natural language, must be simple. Through experiments on both synthetic and real world data, we validate our definition of compositionality and show how it unifies disparate intuitions from across the literature in both AI and cognitive science. We also show that representational compositionality, while theoretically intractable, can be readily estimated using standard deep learning tools. We hope that our definition can inspire the design of novel, theoretically-driven models that better capture the mechanisms of compositional thought. We make our code available at https://github.com/EricElmoznino/complexity_compositionality.","authors":["Eric Elmoznino","Thomas Jiralerspong","Yoshua Bengio","Guillaume Lajoie"],"url":"https://arxiv.org/abs/2410.14817"}
{"created":"2025-06-04","title":"RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance","abstract":"With the ever-increasing demands on Question Answering (QA) systems for IT operations and maintenance, an efficient and supervised fine-tunable framework is necessary to ensure the data security, private deployment and continuous upgrading. Although Large Language Models (LLMs) have notably improved the open-domain QA's performance, how to efficiently handle enterprise-exclusive corpora and build domain-specific QA systems are still less-studied for industrial applications. In this paper, we propose a general and comprehensive framework based on Retrieval Augmented Generation (RAG) and facilitate the whole business process of establishing QA systems for IT operations and maintenance. In accordance with the prevailing RAG method, our proposed framework, named with RAG4ITOps, composes of two major stages: (1) Models Fine-tuning \\& Data Vectorization, and (2) Online QA System Process. At the Stage 1, we leverage a contrastive learning method with two negative sampling strategies to fine-tune the embedding model, and design the instruction templates to fine-tune the LLM with a Retrieval Augmented Fine-Tuning method. At the Stage 2, an efficient process of QA system is built for serving. We collect enterprise-exclusive corpora from the domain of cloud computing, and the extensive experiments show that our method achieves superior results than counterparts on two kinds of QA tasks. Our experiment also provide a case for applying the RAG4ITOps to real-world enterprise-level applications.","authors":["Tianyang Zhang","Zhuoxuan Jiang","Shengguang Bai","Tianrui Zhang","Lin Lin","Yang Liu","Jiawei Ren"],"url":"https://arxiv.org/abs/2410.15805"}
{"created":"2025-06-04","title":"Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs","abstract":"To date, 2:4 sparsity has stood as the only sparse pattern that can be accelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often possesses low actual speedups ($\\leq 1.3$) and requires fixed sparse ratios, meaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity, do not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity is promising in addressing these limitations of 2:4 sparsity. However, regarding accuracy, the effects of V:N:M sparsity on broader Transformer models, such as vision Transformers and large language models (LLMs), are largely unexamined. Moreover, Some specific issues related to V:N:M sparsity, such as how to select appropriate V and M values, remain unresolved. In this study, we thoroughly investigate the application of V:N:M sparsity in vision models and LLMs across multiple tasks, from pertaining to downstream tasks. We propose three key approaches to enhance the applicability and accuracy of V:N:M-sparse Transformers, including heuristic V and M selection, V:N:M-specific channel permutation, and three-staged LoRA training techniques. Experimental results show that, with our methods, the DeiT-small achieves lossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy even at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5 sparsity performs comparably or better than training-free 2:4 sparse alternatives on downstream tasks. More importantly, V:N:M-sparse Transformers offer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity. Overall, our exploration largely facilitates the V:N:M sparsity to act as a truly effective acceleration solution for Transformers in cost-sensitive inference scenarios.","authors":["Kang Zhao","Tao Yuan","Han Bao","Zhenfeng Su","Chang Gao","Zhaofeng Sun","Zichen Liang","Liping Jing","Jianfei Chen"],"url":"https://arxiv.org/abs/2410.16135"}
{"created":"2025-06-04","title":"Foundation Models for Remote Sensing and Earth Observation: A Survey","abstract":"Remote Sensing (RS) is a crucial technology for observing, monitoring, and interpreting our planet, with broad applications across geoscience, economics, humanitarian fields, etc. While artificial intelligence (AI), particularly deep learning, has achieved significant advances in RS, unique challenges persist in developing more intelligent RS systems, including the complexity of Earth's environments, diverse sensor modalities, distinctive feature patterns, varying spatial and spectral resolutions, and temporal dynamics. Meanwhile, recent breakthroughs in large Foundation Models (FMs) have expanded AI's potential across many domains due to their exceptional generalizability and zero-shot transfer capabilities. However, their success has largely been confined to natural data like images and video, with degraded performance and even failures for RS data of various non-optical modalities. This has inspired growing interest in developing Remote Sensing Foundation Models (RSFMs) to address the complex demands of Earth Observation (EO) tasks, spanning the surface, atmosphere, and oceans. This survey systematically reviews the emerging field of RSFMs. It begins with an outline of their motivation and background, followed by an introduction of their foundational concepts. It then categorizes and reviews existing RSFM studies including their datasets and technical contributions across Visual Foundation Models (VFMs), Visual-Language Models (VLMs), Large Language Models (LLMs), and beyond. In addition, we benchmark these models against publicly available datasets, discuss existing challenges, and propose future research directions in this rapidly evolving field. A project associated with this survey has been built at https://github.com/xiaoaoran/awesome-RSFMs .","authors":["Aoran Xiao","Weihao Xuan","Junjue Wang","Jiaxing Huang","Dacheng Tao","Shijian Lu","Naoto Yokoya"],"url":"https://arxiv.org/abs/2410.16602"}
{"created":"2025-06-04","title":"The Tug of War Within: Mitigating the Fairness-Privacy Conflicts in Large Language Models","abstract":"Ensuring awareness of fairness and privacy in Large Language Models (LLMs) is critical. Interestingly, we discover a counter-intuitive trade-off phenomenon that enhancing an LLM's privacy awareness through Supervised Fine-Tuning (SFT) methods significantly decreases its fairness awareness with thousands of samples. To address this issue, inspired by the information theory, we introduce a training-free method to \\textbf{S}uppress the \\textbf{P}rivacy and fa\\textbf{I}rness coupled \\textbf{N}eurons (\\textbf{SPIN}), which theoretically and empirically decrease the mutual information between fairness and privacy awareness. Extensive experimental results demonstrate that SPIN eliminates the trade-off phenomenon and significantly improves LLMs' fairness and privacy awareness simultaneously without compromising general capabilities, \\eg improving Qwen-2-7B-Instruct's fairness awareness by 12.2\\% and privacy awareness by 14.0\\%. More crucially, SPIN remains robust and effective with limited annotated data or even when only malicious fine-tuning data is available, whereas SFT methods may fail to perform properly in such scenarios. Furthermore, we show that SPIN could generalize to other potential trade-off dimensions. We hope this study provides valuable insights into concurrently addressing fairness and privacy concerns in LLMs and can be integrated into comprehensive frameworks to develop more ethical and responsible AI systems. Our code is available at https://github.com/ChnQ/SPIN.","authors":["Chen Qian","Dongrui Liu","Jie Zhang","Yong Liu","Jing Shao"],"url":"https://arxiv.org/abs/2410.16672"}
{"created":"2025-06-04","title":"Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models","abstract":"The widespread use of AI-generated content from diffusion models has raised significant concerns regarding misinformation and copyright infringement. Watermarking is a crucial technique for identifying these AI-generated images and preventing their misuse. In this paper, we introduce Shallow Diffuse, a new watermarking technique that embeds robust and invisible watermarks into diffusion model outputs. Unlike existing approaches that integrate watermarking throughout the entire diffusion sampling process, Shallow Diffuse decouples these steps by leveraging the presence of a low-dimensional subspace in the image generation process. This method ensures that a substantial portion of the watermark lies in the null space of this subspace, effectively separating it from the image generation process. Our theoretical and empirical analyses show that this decoupling strategy greatly enhances the consistency of data generation and the detectability of the watermark. Extensive experiments further validate that our Shallow Diffuse outperforms existing watermarking methods in terms of robustness and consistency. The codes will be released at https://github.com/liwd190019/Shallow-Diffuse.","authors":["Wenda Li","Huijie Zhang","Qing Qu"],"url":"https://arxiv.org/abs/2410.21088"}
{"created":"2025-06-04","title":"EoRA: Fine-tuning-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation","abstract":"While post-training compression techniques effectively reduce the memory footprint, latency, and power consumption of Large Language Models (LLMs), they often result in noticeable accuracy degradation and remain limited by hardware and kernel constraints that restrict supported compression formats ultimately reducing flexibility across a wide range of deployment scenarios. In this work, we propose EoRA, a novel fine-tuning-free method that augments compressed LLMs with low-rank matrices, allowing users to rapidly enhance task-specific performance and freely balance the trade-off between accuracy and computational overhead beyond the constraints of compression formats. EoRA consistently outperforms prior training-free low rank methods in recovering the accuracy of compressed LLMs, achieving notable accuracy improvements (e.g., $\\mathbf{10.84\\%}$ on ARC-Challenge, $\\mathbf{6.74\\%}$ on MathQA, and $\\mathbf{6.74\\%}$ on GSM8K) for LLaMA3-8B compressed to 3-bit. We also introduce an optimized CUDA kernel, accelerating inference by up to 1.4x and reducing memory overhead through quantizing EoRA. Overall, EoRA offers a prompt solution for improving the accuracy of compressed models under varying user requirements, enabling more efficient and flexible deployment of LLMs. Code is available at https://github.com/NVlabs/EoRA.","authors":["Shih-Yang Liu","Maksim Khadkevich","Nai Chit Fung","Charbel Sakr","Chao-Han Huck Yang","Chien-Yi Wang","Saurav Muralidharan","Hongxu Yin","Kwang-Ting Cheng","Jan Kautz","Yu-Chiang Frank Wang","Pavlo Molchanov","Min-Hung Chen"],"url":"https://arxiv.org/abs/2410.21271"}
{"created":"2025-06-04","title":"Self-Evolved Reward Learning for LLMs","abstract":"Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for aligning language models with human preferences, playing a pivotal role in the success of conversational models like GPT-4, ChatGPT, and Llama 2. A core challenge in employing RLHF lies in training a reliable reward model (RM), which relies on high-quality labels typically provided by human experts or advanced AI system. These methods can be costly and may introduce biases that affect the language model's responses. As language models improve, human input may become less effective in further enhancing their performance. In this paper, we propose Self-Evolved Reward Learning (SER), a novel approach where the RM generates additional training data to iteratively improve itself. We conducted extensive experiments on multiple datasets such as HH-RLHF and UltraFeedback, using models like Mistral and Llama 3, and compare SER against various baselines. Our results demonstrate that even with limited human-annotated data, learning from self-feedback can robustly enhance RM performance, thereby boosting the capabilities of large language models (LLMs). Resources of this paper can be found at https://aka.ms/ser","authors":["Chenghua Huang","Zhizhen Fan","Lu Wang","Fangkai Yang","Pu Zhao","Zeqi Lin","Qingwei Lin","Dongmei Zhang","Saravan Rajmohan","Qi Zhang"],"url":"https://arxiv.org/abs/2411.00418"}
{"created":"2025-06-04","title":"Generative Emotion Cause Explanation in Multimodal Conversations","abstract":"Multimodal conversation, a crucial form of human communication, carries rich emotional content, making the exploration of the causes of emotions within it a research endeavor of significant importance. However, existing research on the causes of emotions typically employs an utterance selection method within a single textual modality to locate causal utterances. This approach remains limited to coarse-grained assessments, lacks nuanced explanations of emotional causation, and demonstrates inadequate capability in identifying multimodal emotional triggers. Therefore, we introduce a task-\\textbf{Multimodal Emotion Cause Explanation in Conversation (MECEC)}. This task aims to generate a summary based on the multimodal context of conversations, clearly and intuitively describing the reasons that trigger a given emotion. To adapt to this task, we develop a new dataset (ECEM) based on the MELD dataset. ECEM combines video clips with detailed explanations of character emotions, helping to explore the causal factors behind emotional expression in multimodal conversations. A novel approach, FAME-Net, is further proposed, that harnesses the power of Large Language Models (LLMs) to analyze visual data and accurately interpret the emotions conveyed through facial expressions in videos. By exploiting the contagion effect of facial emotions, FAME-Net effectively captures the emotional causes of individuals engaged in conversations. Our experimental results on the newly constructed dataset show that FAME-Net outperforms several excellent baselines. Code and dataset are available at https://github.com/3222345200/FAME-Net.","authors":["Lin Wang","Xiaocui Yang","Shi Feng","Daling Wang","Yifei Zhang","Zhitao Zhang"],"url":"https://arxiv.org/abs/2411.02430"}
{"created":"2025-06-04","title":"What Goes Into a LM Acceptability Judgment? Rethinking the Impact of Frequency and Length","abstract":"When comparing the linguistic capabilities of language models (LMs) with humans using LM probabilities, factors such as the length of the sequence and the unigram frequency of lexical items have a significant effect on LM probabilities in ways that humans are largely robust to. Prior works in comparing LM and human acceptability judgments treat these effects uniformly across models, making a strong assumption that models require the same degree of adjustment to control for length and unigram frequency effects. We propose MORCELA, a new linking theory between LM scores and acceptability judgments where the optimal level of adjustment for these effects is estimated from data via learned parameters for length and unigram frequency. We first show that MORCELA outperforms a commonly used linking theory for acceptability - SLOR (Pauls and Klein, 2012; Lau et al. 2017) - across two families of transformer LMs (Pythia and OPT). Furthermore, we demonstrate that the assumed degrees of adjustment in SLOR for length and unigram frequency overcorrect for these confounds, and that larger models require a lower relative degree of adjustment for unigram frequency, though a significant amount of adjustment is still necessary for all models. Finally, our subsequent analysis shows that larger LMs' lower susceptibility to frequency effects can be explained by an ability to better predict rarer words in context.","authors":["Lindia Tjuatja","Graham Neubig","Tal Linzen","Sophie Hao"],"url":"https://arxiv.org/abs/2411.02528"}
{"created":"2025-06-04","title":"NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document VQA","abstract":"The Privacy Preserving Federated Learning Document VQA (PFL-DocVQA) competition challenged the community to develop provably private and communication-efficient solutions in a federated setting for a real-life use case: invoice processing. The competition introduced a dataset of real invoice documents, along with associated questions and answers requiring information extraction and reasoning over the document images. Thereby, it brings together researchers and expertise from the document analysis, privacy, and federated learning communities. Participants fine-tuned a pre-trained, state-of-the-art Document Visual Question Answering model provided by the organizers for this new domain, mimicking a typical federated invoice processing setup. The base model is a multi-modal generative language model, and sensitive information could be exposed through either the visual or textual input modality. Participants proposed elegant solutions to reduce communication costs while maintaining a minimum utility threshold in track 1 and to protect all information from each document provider using differential privacy in track 2. The competition served as a new testbed for developing and testing private federated learning methods, simultaneously raising awareness about privacy within the document image analysis and recognition community. Ultimately, the competition analysis provides best practices and recommendations for successfully running privacy-focused federated learning challenges in the future.","authors":["Marlon Tobaben","Mohamed Ali Souibgui","Rub\\`en Tito","Khanh Nguyen","Raouf Kerkouche","Kangsoo Jung","Joonas J\\\"alk\\\"o","Lei Kang","Andrey Barsky","Vincent Poulain d'Andecy","Aur\\'elie Joseph","Aashiq Muhamed","Kevin Kuo","Virginia Smith","Yusuke Yamasaki","Takumi Fukami","Kenta Niwa","Iifan Tyou","Hiro Ishii","Rio Yokota","Ragul N","Rintu Kutum","Josep Llados","Ernest Valveny","Antti Honkela","Mario Fritz","Dimosthenis Karatzas"],"url":"https://arxiv.org/abs/2411.03730"}
{"created":"2025-06-04","title":"Reclaiming \"Open AI\" -- AI Model Serving Can Be Open Access, Yet Monetizable and Loyal","abstract":"The rapid rise of AI has split model serving between open-weight distribution, which often lacks owner control and monetization, and opaque API-based approaches that risk user privacy and model transparency, forming a dichotomy that hinders an equitable AI ecosystem. This position paper introduces, rigorously formulates, and champions the Open-access, Monetizable, and Loyal (OML) paradigm for AI model serving: a foundational shift to securely distribute and serve AI models by synthesizing transparency with granular monetization and critical safety controls. We survey diverse OML constructions from theory and practice, analyze their security, performance, and practical trade-offs, outline a conceptual OML deployment protocol, and discuss market and policy implications. We assert that OML can foster a democratized, self-sustaining, and innovative AI landscape, mitigating centralized power risks. Finally, we call on the research community to further explore the broad design space of OML, spanning cryptographic, AI-native, and socio-economic mechanisms, to realize its full potential for a collaborative, accountable, and resilient AI future.","authors":["Zerui Cheng","Edoardo Contente","Ben Finch","Oleg Golev","Jonathan Hayase","Andrew Miller","Niusha Moshrefi","Anshul Nasery","Sandeep Nailwal","Sewoong Oh","Himanshu Tyagi","Pramod Viswanath"],"url":"https://arxiv.org/abs/2411.03887"}
{"created":"2025-06-04","title":"SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications","abstract":"Speculative decoding is widely adopted to reduce latency in large language model (LLM) inference by leveraging smaller draft models capable of handling diverse user tasks. However, emerging AI applications, such as LLM-based agents, present unique workload characteristics: instead of diverse independent requests, agentic frameworks typically submit repetitive inference requests, such as multi-agent pipelines performing similar subtasks or self-refinement loops iteratively enhancing outputs. These workloads result in long and highly predictable sequences, which current speculative decoding methods do not effectively exploit. To address this gap, we introduce \\emph{SuffixDecoding}, a novel method that utilizes efficient suffix trees to cache long token sequences from prompts and previous outputs. By adaptively speculating more tokens when acceptance likelihood is high and fewer when it is low, SuffixDecoding effectively exploits opportunities for longer speculations while conserving computation when those opportunities are limited. Evaluations on agentic benchmarks, including SWE-Bench and Text-to-SQL, demonstrate that SuffixDecoding achieves speedups of up to 5.3$\\times$, outperforming state-of-the-art methods -- 2.8$\\times$ faster than model-based approaches like EAGLE-2/3 and 1.9$\\times$ faster than model-free approaches such as Token Recycling. SuffixDecoding is open-sourced at https://github.com/snowflakedb/ArcticInference.","authors":["Gabriele Oliaro","Zhihao Jia","Daniel Campos","Aurick Qiao"],"url":"https://arxiv.org/abs/2411.04975"}
{"created":"2025-06-04","title":"Discovering Latent Causal Graphs from Spatio-Temporal Data","abstract":"Many important phenomena in scientific fields like climate, neuroscience, and epidemiology are naturally represented as spatiotemporal gridded data with complex interactions. Inferring causal relationships from these data is a challenging problem compounded by the high dimensionality of such data and the correlations between spatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY), a novel framework based on variational inference, designed to model latent time series and their causal relationships from spatiotemporal data. SPACY alleviates the high-dimensional challenge by discovering causal structures in the latent space. To aggregate spatially proximate, correlated grid points, we use \\change{spatial factors, parametrized by spatial kernel functions}, to map observational time series to latent representations. \\change{Theoretically, we generalize the problem to a continuous spatial domain and establish identifiability when the observations arise from a nonlinear, invertible function of the product of latent series and spatial factors. Using this approach, we avoid assumptions that are often unverifiable, including those about instantaneous effects or sufficient variability.} Empirically, SPACY outperforms state-of-the-art baselines on synthetic data, even in challenging settings where existing methods struggle, while remaining scalable for large grids. SPACY also identifies key known phenomena from real-world climate data.","authors":["Kun Wang","Sumanth Varambally","Duncan Watson-Parris","Yi-An Ma","Rose Yu"],"url":"https://arxiv.org/abs/2411.05331"}
{"created":"2025-06-04","title":"Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc Explainability in Image Classification","abstract":"Convolutional Neural Networks (CNNs) have seen significant performance improvements in recent years. However, due to their size and complexity, they function as black-boxes, leading to transparency concerns. State-of-the-art saliency methods generate local explanations that highlight the area in the input image where a class is identified but cannot explain how a concept of interest contributes to the prediction, which is essential for bias mitigation. On the other hand, concept-based methods, such as TCAV (Testing with Concept Activation Vectors), provide insights into how sensitive is the network to a concept, but cannot compute its attribution in a specific prediction nor show its location within the input image. This paper introduces a novel post-hoc explainability framework, Visual-TCAV, which aims to bridge the gap between these methods by providing both local and global explanations for CNN-based image classification. Visual-TCAV uses Concept Activation Vectors (CAVs) to generate saliency maps that show where concepts are recognized by the network. Moreover, it can estimate the attribution of these concepts to the output of any class using a generalization of Integrated Gradients. This framework is evaluated on popular CNN architectures, with its validity further confirmed via experiments where ground truth for explanations is known, and a comparison with TCAV. Our code is available at https://github.com/DataSciencePolimi/Visual-TCAV.","authors":["Antonio De Santis","Riccardo Campi","Matteo Bianchi","Marco Brambilla"],"url":"https://arxiv.org/abs/2411.05698"}
{"created":"2025-06-04","title":"Annotative Indexing","abstract":"This paper introduces annotative indexing, a novel framework that unifies and generalizes traditional inverted indexes, column stores, object stores, and graph databases. As a result, annotative indexing can provide the underlying indexing framework for databases that support retrieval augmented generation, knowledge graphs, entity retrieval, semi-structured data, and ranked retrieval. While we primarily focus on human language data in the form of text, annotative indexing is sufficiently general to support a range of other datatypes, and we provide examples of SQL-like queries over a JSON store that includes numbers and dates. Taking advantage of the flexibility of annotative indexing, we also demonstrate a fully dynamic annotative index incorporating support for ACID properties of transactions with hundreds of multiple concurrent readers and writers.","authors":["Charles L. A. Clarke"],"url":"https://arxiv.org/abs/2411.06256"}
{"created":"2025-06-04","title":"SHARP: Unlocking Interactive Hallucination via Stance Transfer in Role-Playing LLMs","abstract":"The advanced role-playing capabilities of Large Language Models (LLMs) have enabled rich interactive scenarios, yet existing research in social interactions neglects hallucination while struggling with poor generalizability and implicit character fidelity judgments. To bridge this gap, motivated by human behaviour, we introduce a generalizable and explicit paradigm for uncovering interactive patterns of LLMs across diverse worldviews. Specifically, we first define interactive hallucination through stance transfer, then construct SHARP, a benchmark built by extracting relations from commonsense knowledge graphs and utilizing LLMs' inherent hallucination properties to simulate multi-role interactions. Extensive experiments confirm our paradigm's effectiveness and stability, examine the factors that influence these metrics, and challenge conventional hallucination mitigation solutions. More broadly, our work reveals a fundamental limitation in popular post-training methods for role-playing LLMs: the tendency to obscure knowledge beneath style, resulting in monotonous yet human-like behaviors - interactive hallucination.","authors":["Chuyi Kong","Ziyang Luo","Hongzhan Lin","Zhiyuan Fan","Yaxin Fan","Yuxi Sun","Jing Ma"],"url":"https://arxiv.org/abs/2411.07965"}
{"created":"2025-06-04","title":"Offline Adaptation of Quadruped Locomotion using Diffusion Models","abstract":"We present a diffusion-based approach to quadrupedal locomotion that simultaneously addresses the limitations of learning and interpolating between multiple skills and of (modes) offline adapting to new locomotion behaviours after training. This is the first framework to apply classifier-free guided diffusion to quadruped locomotion and demonstrate its efficacy by extracting goal-conditioned behaviour from an originally unlabelled dataset. We show that these capabilities are compatible with a multi-skill policy and can be applied with little modification and minimal compute overhead, i.e., running entirely on the robots onboard CPU. We verify the validity of our approach with hardware experiments on the ANYmal quadruped platform.","authors":["Reece O'Mahoney","Alexander L. Mitchell","Wanming Yu","Ingmar Posner","Ioannis Havoutis"],"url":"https://arxiv.org/abs/2411.08832"}
{"created":"2025-06-04","title":"Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts","abstract":"The recent progress in Vision-Language Models (VLMs) has broadened the scope of multimodal applications. However, evaluations often remain limited to functional tasks, neglecting abstract dimensions such as personality traits and human values. To address this gap, we introduce Value-Spectrum, a novel Visual Question Answering (VQA) benchmark aimed at assessing VLMs based on Schwartz's value dimensions that capture core human values guiding people's preferences and actions. We design a VLM agent pipeline to simulate video browsing and construct a vector database comprising over 50,000 short videos from TikTok, YouTube Shorts, and Instagram Reels. These videos span multiple months and cover diverse topics, including family, health, hobbies, society, technology, etc. Benchmarking on Value-Spectrum highlights notable variations in how VLMs handle value-oriented content. Beyond identifying VLMs' intrinsic preferences, we also explore the ability of VLM agents to adopt specific personas when explicitly prompted, revealing insights into the adaptability of the model in role-playing scenarios. These findings highlight the potential of Value-Spectrum as a comprehensive evaluation set for tracking VLM preferences in value-based tasks and abilities to simulate diverse personas. The complete code and data are available at: https://github.com/Jeremyyny/Value-Spectrum.","authors":["Jingxuan Li","Yuning Yang","Shengqi Yang","Linfan Zhang","Ying Nian Wu"],"url":"https://arxiv.org/abs/2411.11479"}
{"created":"2025-06-04","title":"Constant Rate Scheduling: Constant-Rate Distributional Change for Efficient Training and Sampling in Diffusion Models","abstract":"We propose a general approach to optimize noise schedules for training and sampling in diffusion models. Our approach optimizes the noise schedules to ensure a constant rate of change in the probability distribution of diffused data throughout the diffusion process. Any distance metric for measuring the probability-distributional change is applicable to our approach, and we introduce three distance metrics. We evaluated the effectiveness of our approach on unconditional and class-conditional image-generation tasks using the LSUN (Horse, Bedroom, Church), ImageNet, FFHQ, and CIFAR10 datasets. Through extensive experiments, we confirmed that our approach broadly improves the performance of pixel-space and latent-space diffusion models regardless of the dataset, sampler, and number of function evaluations ranging from 5 to 250. Notably, by using our approach for optimizing both training and sampling schedules, we achieved a state-of-the-art FID score of 2.03 without sacrificing mode coverage on LSUN Horse 256 $\\times$ 256.","authors":["Shuntaro Okada","Kenji Doi","Ryota Yoshihashi","Hirokatsu Kataoka","Tomohiro Tanaka"],"url":"https://arxiv.org/abs/2411.12188"}
{"created":"2025-06-04","title":"Ichnos: A Carbon Footprint Estimator for Scientific Workflows","abstract":"Scientific workflows facilitate the automation of data analysis, and are used to process increasing amounts of data. Therefore, they tend to be resource-intensive and long-running, leading to significant energy consumption and carbon emissions. With ever-increasing emissions from the ICT sector, it is crucial to quantify and understand the carbon footprint of scientific workflows. However, existing tooling requires significant effort from users - such as setting up power monitoring before executing workloads, or translating monitored metrics into the carbon footprints post-execution. In this paper, we introduce a system to estimate the carbon footprint of Nextflow scientific workflows that enables post-hoc estimation based on existing workflow traces, power models for computational resources utilised, and carbon intensity data aligned with the execution time. We discuss our automated power modelling approach, and compare it with commonly used estimation methodologies. Furthermore, we exemplify several potential use cases and evaluate our energy consumption estimation approach, finding its estimation error to be between 3.9-10.3%, outperforming both baseline methodologies.","authors":["Kathleen West","Magnus Reid","Yehia Elkhatib","Lauritz Thamsen"],"url":"https://arxiv.org/abs/2411.12456"}
{"created":"2025-06-04","title":"Distributed Distance Sensitivity Oracles","abstract":"We present results for the distance sensitivity oracle (DSO) problem, where one needs to preprocess a given directed weighted graph $G=(V,E)$ in order to answer queries about the shortest path distance from $s$ to $t$ in $G$ that avoids edge $e$, for any $s,t \\in V, e \\in E$. No non-trivial results are known for DSO in the distributed CONGEST model even though it is of importance to maintain efficient communication under an edge failure. We present DSO algorithms with different tradeoffs between preprocessing and query cost -- one that optimizes query response rounds, and another that prioritizes preprocessing rounds. We complement these algorithms with unconditional CONGEST lower bounds. Additionally, we present almost-optimal upper and lower bounds for the related all pairs second simple shortest path (2-APSiSP) problem.","authors":["Vignesh Manoharan","Vijaya Ramachandran"],"url":"https://arxiv.org/abs/2411.13728"}
{"created":"2025-06-04","title":"Neural numerical homogenization based on Deep Ritz corrections","abstract":"Numerical homogenization methods aim at providing appropriate coarse-scale approximations of solutions to (elliptic) partial differential equations that involve highly oscillatory coefficients. The localized orthogonal decomposition (LOD) method is an effective way of dealing with such coefficients, especially if they are non-periodic and non-smooth. It modifies classical finite element basis functions by suitable fine-scale corrections. In this paper, we make use of the structure of the LOD method, but we propose to calculate the corrections based on a Deep Ritz approach involving a parametrization of the coefficients to tackle temporal variations or uncertainties. Numerical examples for a parabolic model problem are presented to assess the performance of the approach.","authors":["Mehdi Elasmi","Felix Krumbiegel","Roland Maier"],"url":"https://arxiv.org/abs/2411.14084"}
{"created":"2025-06-04","title":"Continual Learning and Lifting of Koopman Dynamics for Linear Control of Legged Robots","abstract":"The control of legged robots, particularly humanoid and quadruped robots, presents significant challenges due to their high-dimensional and nonlinear dynamics. While linear systems can be effectively controlled using methods like Model Predictive Control (MPC), the control of nonlinear systems remains complex. One promising solution is the Koopman Operator, which approximates nonlinear dynamics with a linear model, enabling the use of proven linear control techniques. However, achieving accurate linearization through data-driven methods is difficult due to issues like approximation error, domain shifts, and the limitations of fixed linear state-space representations. These challenges restrict the scalability of Koopman-based approaches. This paper addresses these challenges by proposing a continual learning algorithm designed to iteratively refine Koopman dynamics for high-dimensional legged robots. The key idea is to progressively expand the dataset and latent space dimension, enabling the learned Koopman dynamics to converge towards accurate approximations of the true system dynamics. Theoretical analysis shows that the linear approximation error of our method converges monotonically. Experimental results demonstrate that our method achieves high control performance on robots like Unitree G1/H1/A1/Go2 and ANYmal D, across various terrains using simple linear MPC controllers. This work is the first to successfully apply linearized Koopman dynamics for locomotion control of high-dimensional legged robots, enabling a scalable model-based control solution.","authors":["Feihan Li","Abulikemu Abuduweili","Yifan Sun","Rui Chen","Weiye Zhao","Changliu Liu"],"url":"https://arxiv.org/abs/2411.14321"}
{"created":"2025-06-04","title":"Learning Autonomous Surgical Irrigation and Suction with the da Vinci Research Kit Using Reinforcement Learning","abstract":"The irrigation-suction process is a common procedure to rinse and clean up the surgical field in minimally invasive surgery (MIS). In this process, surgeons first irrigate liquid, typically saline, into the surgical scene for rinsing and diluting the contaminant, and then suction the liquid out of the surgical field. While recent advances have shown promising results in the application of reinforcement learning (RL) for automating surgical subtasks, fewer studies have explored the automation of fluid-related tasks. In this work, we explore the automation of both steps in the irrigation-suction procedure and train two vision-based RL agents to complete irrigation and suction autonomously. To achieve this, a platform is developed for creating simulated surgical robot learning environments and for training agents, and two simulated learning environments are built for irrigation and suction with visually plausible fluid rendering capabilities. With techniques such as domain randomization (DR) and carefully designed reward functions, two agents are trained in the simulator and transferred to the real world. Individual evaluations of both agents show satisfactory real-world results. With an initial amount of around 5 grams of contaminants, the irrigation agent ultimately achieved an average of 2.21 grams remaining after a manual suction. As a comparison, fully manual operation by a human results in 1.90 grams remaining. The suction agent achieved 2.64 and 2.24 grams of liquid remaining across two trial groups with more than 20 and 30 grams of initial liquid in the container. Fully autonomous irrigation-suction trials reduce the contaminant in the container from around 5 grams to an average of 2.42 grams, although yielding a higher total weight remaining (4.40) due to residual liquid not suctioned. Further information about the project is available at https://tbs-ualberta.github.io/CRESSim/.","authors":["Yafei Ou","Mahdi Tavakoli"],"url":"https://arxiv.org/abs/2411.14622"}
{"created":"2025-06-04","title":"Evaluating and Advancing Multimodal Large Language Models in Perception Ability Lens","abstract":"As multimodal large language models (MLLMs) advance rapidly, rigorous evaluation has become essential, providing further guidance for their development. In this work, we focus on a unified and robust evaluation of \\textbf{vision perception} abilities, the foundational skill of MLLMs. We find that existing perception benchmarks, each focusing on different question types, domains, and evaluation metrics, introduce significant evaluation variance, complicating comprehensive assessments of perception abilities when relying on any single benchmark. To address this, we introduce \\textbf{AbilityLens}, a unified benchmark designed to evaluate MLLMs in six key perception abilities (ranging from counting, OCR, to understanding structural data), focusing on both accuracy and stability, with each ability encompassing diverse types of questions, domains, and metrics. With the assistance of AbilityLens, we: (1) identify the strengths and weaknesses of current main-stream MLLMs, highlighting stability patterns and revealing a notable performance gap between state-of-the-art open-source and closed-source models; (2) uncover interesting ability conflict and early convergence phenomena during MLLM training; (3) reveal the primary reason of ability conflict is data mixing ratio and LLM model size; and (4) discuss the effectiveness of some straightforward strategies \\eg, fine-tuning and model merging, to solve the ability conflict. The benchmark and online leaderboard is released in https://github.com/Chenfeng1271/AbilityLens.","authors":["Feng Chen","Chenhui Gou","Jing Liu","Yang Yang","Zhaoyang Li","Jiyuan Zhang","Zhenbang Sun","Bohan Zhuang","Qi Wu"],"url":"https://arxiv.org/abs/2411.14725"}
{"created":"2025-06-04","title":"Learnable Activation Functions in Physics-Informed Neural Networks for Solving Partial Differential Equations","abstract":"We investigate learnable activation functions in Physics-Informed Neural Networks (PINNs) for solving Partial Differential Equations (PDEs), comparing traditional Multilayer Perceptrons (MLPs) with fixed and trainable activations against Kolmogorov-Arnold Networks (KANs) that employ learnable basis functions. While PINNs effectively incorporate physical laws into the learning process, they suffer from convergence and spectral bias problems, which limit their applicability to problems with rapid oscillations or sharp transitions. In this work, we study and evaluate various activation and basis functions across diverse PDEs, including oscillatory, nonlinear wave, mixed-physics, and fluid dynamics problems. Using empirical Neural Tangent Kernel (NTK) analysis and Hessian eigenvalue decomposition, we assess convergence behavior, stability, and high-frequency approximation capacity. While KANs offer improved expressivity for capturing complex, high-frequency PDE solutions, they introduce new optimization challenges, especially in deeper networks. Our findings show that KANs face a curse of functional dimensionality, creating intractable optimization landscapes in deeper networks. Low spectral bias alone does not guarantee good performance; adaptive spectral bias approaches such as B-splines achieve optimal results by balancing global stability with local high-frequency resolution. Different PDE types require tailored strategies: smooth global activation functions excel for wave phenomena, while local adaptive activation functions suit problems with sharp transitions.","authors":["Afrah Farea","Mustafa Serdar Celebi"],"url":"https://arxiv.org/abs/2411.15111"}
{"created":"2025-06-04","title":"SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction","abstract":"Sign language processing has traditionally relied on task-specific models, limiting the potential for transfer learning across tasks. Pre-training methods for sign language have typically focused on either supervised pre-training, which cannot take advantage of unlabeled data, or context-independent (frame or video segment) representations, which ignore the effects of relationships across time in sign language. We introduce SHuBERT (Sign Hidden-Unit BERT), a self-supervised contextual representation model learned from approximately 1,000 hours of American Sign Language video. SHuBERT adapts masked token prediction objectives to multi-stream visual sign language input, learning to predict multiple targets corresponding to clustered hand, face, and body pose streams. SHuBERT achieves state-of-the-art performance across multiple tasks including sign language translation, isolated sign language recognition, and fingerspelling detection.","authors":["Shester Gueuwou","Xiaodan Du","Greg Shakhnarovich","Karen Livescu","Alexander H. Liu"],"url":"https://arxiv.org/abs/2411.16765"}
{"created":"2025-06-04","title":"Combining Threat Intelligence with IoT Scanning to Predict Cyber Attack","abstract":"While the Web has become a global platform for communication, malicious actors, including hackers and hacktivist groups, often disseminate ideological content and coordinate activities through the \"Dark Web\", an obscure counterpart of the conventional web. Presently, challenges such as information overload and the fragmented nature of cyber threat data impede comprehensive profiling of these actors, thereby limiting the efficacy of predictive analyses of their online activities. Concurrently, the proliferation of internet-connected devices has surpassed the global human population, with this disparity projected to widen as the Internet of Things (IoT) expands. Technical communities are actively advancing IoT-related research to address its growing societal integration. This paper proposes a novel predictive threat intelligence framework designed to systematically collect, analyze, and visualize Dark Web data to identify malicious websites and correlate this information with potential IoT vulnerabilities. The methodology integrates automated data harvesting, analytical techniques, and visual mapping tools, while also examining vulnerabilities in IoT devices to assess exploitability. By bridging gaps in cybersecurity research, this study aims to enhance predictive threat modeling and inform policy development, thereby contributing to intelligence research initiatives focused on mitigating cyber risks in an increasingly interconnected digital ecosystem.","authors":["Jubin Abhishek Soni","Amit Anand","Rajesh Kumar Pandey","Aniket Abhishek Soni"],"url":"https://arxiv.org/abs/2411.17931"}
{"created":"2025-06-04","title":"Puzzle: Distillation-Based NAS for Inference-Optimized LLMs","abstract":"Large language models (LLMs) offer remarkable capabilities, yet their high inference costs restrict wider adoption. While increasing parameter counts improves accuracy, it also broadens the gap between state-of-the-art capabilities and practical deployability. We present Puzzle, a hardware-aware framework that accelerates the inference of LLMs while preserving their capabilities. Using neural architecture search (NAS) at a large-scale, Puzzle optimizes models with tens of billions of parameters. Our approach utilizes blockwise local knowledge distillation (BLD) for parallel architecture exploration and employs mixed-integer programming for precise constraint optimization.","authors":["Akhiad Bercovich","Tomer Ronen","Talor Abramovich","Nir Ailon","Nave Assaf","Mohammad Dabbah","Ido Galil","Amnon Geifman","Yonatan Geifman","Izhak Golan","Netanel Haber","Ehud Karpas","Roi Koren","Itay Levy","Pavlo Molchanov","Shahar Mor","Zach Moshe","Najeeb Nabwani","Omri Puny","Ran Rubin","Itamar Schen","Ido Shahaf","Oren Tropp","Omer Ullman Argov","Ran Zilberstein","Ran El-Yaniv"],"url":"https://arxiv.org/abs/2411.19146"}
{"created":"2025-06-04","title":"Seismocardiography for Emotion Recognition: A Study on EmoWear with Insights from DEAP","abstract":"Emotions have a profound impact on our daily lives, influencing our thoughts, behaviors, and interactions, but also our physiological reactions. Recent advances in wearable technology have facilitated studying emotions through cardio-respiratory signals. Accelerometers offer a non-invasive, convenient, and cost-effective method for capturing heart- and pulmonary-induced vibrations on the chest wall, specifically Seismocardiography (SCG) and Accelerometry-Derived Respiration (ADR). Their affordability, wide availability, and ability to provide rich contextual data make accelerometers ideal for everyday use. While accelerometers have been used as part of broader modality fusions for Emotion Recognition (ER), their stand-alone potential via SCG and ADR remains unexplored. Bridging this gap could significantly help the embedding of ER into real-world applications, minimizing the hardware, and increasing contextual integration potentials. To address this gap, we introduce SCG and ADR as novel modalities for ER and evaluate their performance using the EmoWear dataset. First, we replicate the single-trial emotion classification pipeline from the DEAP dataset study, achieving similar results. Then we use our validated pipeline to train models that predict affective valence-arousal states using SCG and compare them against established cardiac signals, Electrocardiography (ECG) and Blood Volume Pulse (BVP). Results show that SCG is a viable modality for ER, achieving similar performance to ECG and BVP. By combining ADR with SCG, we achieved a working ER framework that only requires a single chest-worn accelerometer. These findings pave the way for integrating ER into real-world, enabling seamless affective computing in everyday life.","authors":["Mohammad Hasan Rahmani","Rafael Berkvens","Maarten Weyn"],"url":"https://arxiv.org/abs/2412.00411"}
{"created":"2025-06-04","title":"Human-Machine Interfaces for Subsea Telerobotics: From Soda-straw to Natural Language Interactions","abstract":"This review explores the evolution of human-machine interfaces (HMIs) in subsea telerobotics, charting the progression from traditional first-person \"soda-straw\" consoles -- characterized by narrow field-of-view camera feeds -- to contemporary interfaces leveraging gesture recognition, virtual reality, and natural language processing. We systematically analyze the state-of-the-art literature through three interrelated perspectives: operator experience (including immersive feedback, cognitive workload, and ergonomic design), robotic autonomy (contextual understanding and task execution), and the quality of bidirectional communication between human and machine. Emphasis is placed on interface features to highlight persistent limitations in current systems, notably in immersive feedback fidelity, intuitive control mechanisms, and the lack of cross-platform standardization. Additionally, we assess the role of simulators and digital twins as scalable tools for operator training and system prototyping. The review extends beyond classical teleoperation paradigms to examine modern shared autonomy frameworks that facilitate seamless human-robot collaboration. By synthesizing insights from robotics, marine engineering, artificial intelligence, and human factors -- this work provides a comprehensive overview of the current landscape and emerging trajectories in subsea HMI development. Finally, we identify key challenges and open research questions and outline a forward-looking roadmap for advancing intelligent and user-centric HMI technologies in subsea telerobotics.","authors":["Adnan Abdullah","David Blow","Ruo Chen","Thanakon Uthai","Eric Jing Du","Md Jahidul Islam"],"url":"https://arxiv.org/abs/2412.01753"}
{"created":"2025-06-04","title":"Numerical schemes for a fully nonlinear coagulation-fragmentation model coming from wave kinetic theory","abstract":"This article introduces a novel numerical approach, based on Finite Volume Techniques, for studying fully nonlinear coagulation-fragmentation models, where both the coagulation and fragmentation components of the collision operator are nonlinear. The models come from $3-$wave kinetic equations, a pivotal framework in wave turbulence theory. Despite the importance of wave turbulence theory in physics and mechanics, there have been very few numerical schemes for $3-$wave kinetic equations, in which no ad-hoc additional assumptions are imposed on the evolution of the solutions, and the current manuscript provides one of the first of such schemes. To the best of our knowledge, this also is the first numerical scheme capable of accurately capturing the long-term asymptotic behavior of solutions to a fully nonlinear coagulation-fragmentation model that includes both forward and backward energy cascades. The scheme is implemented on some test problems, demonstrating strong alignment with theoretical predictions of energy cascade rates. We further introduce a weighted Finite Volume variant to ensure energy conservation across varying degrees of kernel homogeneity. Convergence and first-order consistency are established through theoretical analysis and verified by experimental convergence orders in test cases.","authors":["Arijit Das","Minh-Binh Tran"],"url":"https://arxiv.org/abs/2412.05402"}
{"created":"2025-06-04","title":"Hyperband-based Bayesian Optimization for Black-box Prompt Selection","abstract":"Optimal prompt selection is crucial for maximizing large language model (LLM) performance on downstream tasks, especially in black-box settings where models are only accessible via APIs. Black-box prompt selection is challenging due to potentially large, combinatorial search spaces, absence of gradient information, and high evaluation cost of prompts on a validation set. We propose HbBoPs, a novel method that combines a structural-aware deep kernel Gaussian Process with Hyperband as a multi-fidelity scheduler to efficiently select prompts. HbBoPs uses embeddings of instructions and few-shot exemplars, treating them as modular components within prompts. This enhances the surrogate model's ability to predict which prompt to evaluate next in a sample-efficient manner. Hyperband improves query-efficiency by adaptively allocating resources across different fidelity levels, reducing the number of validation instances required for evaluating prompts. Extensive experiments across ten diverse benchmarks and three LLMs demonstrate that HbBoPs outperforms state-of-the-art methods in both performance and efficiency.","authors":["Lennart Schneider","Martin Wistuba","Aaron Klein","Jacek Golebiowski","Giovanni Zappella","Felice Antonio Merra"],"url":"https://arxiv.org/abs/2412.07820"}
{"created":"2025-06-04","title":"Superhuman performance of a large language model on the reasoning tasks of a physician","abstract":"A seminal paper published by Ledley and Lusted in 1959 introduced complex clinical diagnostic reasoning cases as the gold standard for the evaluation of expert medical computing systems, a standard that has held ever since. Here, we report the results of a physician evaluation of a large language model (LLM) on challenging clinical cases against a baseline of hundreds of physicians. We conduct five experiments to measure clinical reasoning across differential diagnosis generation, display of diagnostic reasoning, triage differential diagnosis, probabilistic reasoning, and management reasoning, all adjudicated by physician experts with validated psychometrics. We then report a real-world study comparing human expert and AI second opinions in randomly-selected patients in the emergency room of a major tertiary academic medical center in Boston, MA. We compared LLMs and board-certified physicians at three predefined diagnostic touchpoints: triage in the emergency room, initial evaluation by a physician, and admission to the hospital or intensive care unit. In all experiments--both vignettes and emergency room second opinions--the LLM displayed superhuman diagnostic and reasoning abilities, as well as continued improvement from prior generations of AI clinical decision support. Our study suggests that LLMs have achieved superhuman performance on general medical diagnostic and management reasoning, fulfilling the vision put forth by Ledley and Lusted, and motivating the urgent need for prospective trials.","authors":["Peter G. Brodeur","Thomas A. Buckley","Zahir Kanjee","Ethan Goh","Evelyn Bin Ling","Priyank Jain","Stephanie Cabral","Raja-Elie Abdulnour","Adrian D. Haimovich","Jason A. Freed","Andrew Olson","Daniel J. Morgan","Jason Hom","Robert Gallo","Liam G. McCoy","Haadi Mombini","Christopher Lucas","Misha Fotoohi","Matthew Gwiazdon","Daniele Restifo","Daniel Restrepo","Eric Horvitz","Jonathan Chen","Arjun K. Manrai","Adam Rodman"],"url":"https://arxiv.org/abs/2412.10849"}
{"created":"2025-06-04","title":"Is it the end of (generative) linguistics as we know it?","abstract":"A significant debate has emerged in response to a paper written by Steven Piantadosi (Piantadosi, 2023) and uploaded to the LingBuzz platform, the open archive for generative linguistics. Piantadosi's dismissal of Chomsky's approach is ruthless, but generative linguists deserve it. In this paper, I will adopt three idealized perspectives -- computational, theoretical, and experimental -- to focus on two fundamental issues that lend partial support to Piantadosi's critique: (a) the evidence challenging the Poverty of Stimulus (PoS) hypothesis and (b) the notion of simplicity as conceived within mainstream Minimalism. In conclusion, I argue that, to reclaim a central role in language studies, generative linguistics -- representing a prototypical theoretical perspective on language -- needs a serious update leading to (i) more precise, consistent, and complete formalizations of foundational intuitions and (ii) the establishment and utilization of a standardized dataset of crucial empirical evidence to evaluate the theory's adequacy. On the other hand, ignoring the formal perspective leads to major drawbacks in both computational and experimental approaches. Neither descriptive nor explanatory adequacy can be easily achieved without the precise formulation of general principles that can be challenged empirically.","authors":["Cristiano Chesi"],"url":"https://arxiv.org/abs/2412.12797"}
{"created":"2025-06-04","title":"Spatio-Temporal Fuzzy-oriented Multi-Modal Meta-Learning for Fine-grained Emotion Recognition","abstract":"Fine-grained emotion recognition (FER) plays a vital role in various fields, such as disease diagnosis, personalized recommendations, and multimedia mining. However, existing FER methods face three key challenges in real-world applications: (i) they rely on large amounts of continuously annotated data to ensure accuracy since emotions are complex and ambiguous in reality, which is costly and time-consuming; (ii) they cannot capture the temporal heterogeneity caused by changing emotion patterns, because they usually assume that the temporal correlation within sampling periods is the same; (iii) they do not consider the spatial heterogeneity of different FER scenarios, that is, the distribution of emotion information in different data may have bias or interference. To address these challenges, we propose a Spatio-Temporal Fuzzy-oriented Multi-modal Meta-learning framework (ST-F2M). Specifically, ST-F2M first divides the multi-modal videos into multiple views, and each view corresponds to one modality of one emotion. Multiple randomly selected views for the same emotion form a meta-training task. Next, ST-F2M uses an integrated module with spatial and temporal convolutions to encode the data of each task, reflecting the spatial and temporal heterogeneity. Then it adds fuzzy semantic information to each task based on generalized fuzzy rules, which helps handle the complexity and ambiguity of emotions. Finally, ST-F2M learns emotion-related general meta-knowledge through meta-recurrent neural networks to achieve fast and robust fine-grained emotion recognition. Extensive experiments show that ST-F2M outperforms various state-of-the-art methods in terms of accuracy and model efficiency. In addition, we construct ablation studies and further analysis to explore why ST-F2M performs well.","authors":["Jingyao Wang","Wenwen Qiang","Changwen Zheng","Fuchun Sun"],"url":"https://arxiv.org/abs/2412.13541"}
{"created":"2025-06-04","title":"SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage","abstract":"Large language models (LLMs) have made significant advancements across various tasks, but their safety alignment remain a major concern. Exploring jailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure them. Existing methods primarily design sophisticated instructions for the LLM to follow, or rely on multiple iterations, which could hinder the performance and efficiency of jailbreaks. In this work, we propose a novel jailbreak paradigm, Simple Assistive Task Linkage (SATA), which can effectively circumvent LLM safeguards and elicit harmful responses. Specifically, SATA first masks harmful keywords within a malicious query to generate a relatively benign query containing one or multiple [MASK] special tokens. It then employs a simple assistive task such as a masked language model task or an element lookup by position task to encode the semantics of the masked keywords. Finally, SATA links the assistive task with the masked query to jointly perform the jailbreak. Extensive experiments show that SATA achieves state-of-the-art performance and outperforms baselines by a large margin. Specifically, on AdvBench dataset, with mask language model (MLM) assistive task, SATA achieves an overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and with element lookup by position (ELP) assistive task, SATA attains an overall ASR of 76% and HS of 4.43.","authors":["Xiaoning Dong","Wenbo Hu","Wei Xu","Tianxing He"],"url":"https://arxiv.org/abs/2412.15289"}
{"created":"2025-06-04","title":"Can Input Attributions Explain Inductive Reasoning in In-Context Learning?","abstract":"Interpreting the internal process of neural models has long been a challenge. This challenge remains relevant in the era of large language models (LLMs) and in-context learning (ICL); for example, ICL poses a new issue of interpreting which example in the few-shot examples contributed to identifying/solving the task. To this end, in this paper, we design synthetic diagnostic tasks of inductive reasoning, inspired by the generalization tests typically adopted in psycholinguistics. Here, most in-context examples are ambiguous w.r.t. their underlying rule, and one critical example disambiguates it. The question is whether conventional input attribution (IA) methods can track such a reasoning process, i.e., identify the influential example, in ICL. Our experiments provide several practical findings; for example, a certain simple IA method works the best, and the larger the model, the generally harder it is to interpret the ICL with gradient-based IA methods.","authors":["Mengyu Ye","Tatsuki Kuribayashi","Goro Kobayashi","Jun Suzuki"],"url":"https://arxiv.org/abs/2412.15628"}
{"created":"2025-06-04","title":"HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases","abstract":"Given a semi-structured knowledge base (SKB), where text documents are interconnected by relations, how can we effectively retrieve relevant information to answer user questions? Retrieval-Augmented Generation (RAG) retrieves documents to assist large language models (LLMs) in question answering; while Graph RAG (GRAG) uses structured knowledge bases as its knowledge source. However, many questions require both textual and relational information from SKB - referred to as \"hybrid\" questions - which complicates the retrieval process and underscores the need for a hybrid retrieval method that leverages both information. In this paper, through our empirical analysis, we identify key insights that show why existing methods may struggle with hybrid question answering (HQA) over SKB. Based on these insights, we propose HybGRAG for HQA consisting of a retriever bank and a critic module, with the following advantages: (1) Agentic, it automatically refines the output by incorporating feedback from the critic module, (2) Adaptive, it solves hybrid questions requiring both textual and relational information with the retriever bank, (3) Interpretable, it justifies decision making with intuitive refinement path, and (4) Effective, it surpasses all baselines on HQA benchmarks. In experiments on the STaRK benchmark, HybGRAG achieves significant performance gains, with an average relative improvement in Hit@1 of 51%.","authors":["Meng-Chieh Lee","Qi Zhu","Costas Mavromatis","Zhen Han","Soji Adeshina","Vassilis N. Ioannidis","Huzefa Rangwala","Christos Faloutsos"],"url":"https://arxiv.org/abs/2412.16311"}
{"created":"2025-06-04","title":"GAS: Generative Auto-bidding with Post-training Search","abstract":"Auto-bidding is essential in facilitating online advertising by automatically placing bids on behalf of advertisers. Generative auto-bidding, which generates bids based on an adjustable condition using models like transformers and diffusers, has recently emerged as a new trend due to its potential to learn optimal strategies directly from data and adjust flexibly to preferences. However, generative models suffer from low-quality data leading to a mismatch between the condition, like return to go, and true action value, especially in long sequential decision-making. Besides, the majority preference in the dataset may hinder models' generalization ability on minority advertisers' preferences. While it is possible to collect high-quality data and retrain multiple models for different preferences, the high cost makes it unaffordable, hindering the advancement of auto-bidding into the era of large foundation models. To address this, we propose a flexible and practical Generative Auto-bidding scheme using post-training Search, termed GAS, to refine a base policy model's output and adapt to various preferences. We use weak-to-strong search alignment by training small critics for different preferences and an MCTS-inspired search to refine the model's output. Specifically, a novel voting mechanism with transformer-based critics trained with policy indications could enhance search alignment performance. Additionally, utilizing the search, we provide a fine-tuning method for high-frequency preference scenarios considering computational efficiency. Extensive experiments conducted on the real-world dataset and online A/B test on the Kuaishou advertising platform demonstrate the effectiveness of GAS, achieving significant improvements, e.g., 4.60% increment of target cost.","authors":["Yewen Li","Shuai Mao","Jingtong Gao","Nan Jiang","Yunjian Xu","Qingpeng Cai","Fei Pan","Peng Jiang","Bo An"],"url":"https://arxiv.org/abs/2412.17018"}
{"created":"2025-06-04","title":"Computational Analysis of Character Development in Holocaust Testimonies","abstract":"This work presents a computational approach to analyze character development along the narrative timeline. The analysis characterizes the inner and outer changes the protagonist undergoes within a narrative, and the interplay between them. We consider transcripts of Holocaust survivor testimonies as a test case, each telling the story of an individual in first-person terms. We focus on the survivor's religious trajectory, examining the evolution of their disposition toward religious belief and practice along the testimony. Clustering the resulting trajectories in the dataset, we identify common sequences in the data. Our findings highlight multiple common structures of religiosity across the narratives: in terms of belief, most present a constant disposition, while for practice, most present an oscillating structure, serving as valuable material for historical and sociological research. This work demonstrates the potential of natural language processing techniques for analyzing character evolution through thematic trajectories in narratives.","authors":["Esther Shizgal","Eitan Wagner","Renana Keydar","Omri Abend"],"url":"https://arxiv.org/abs/2412.17063"}
{"created":"2025-06-04","title":"Diving into Self-Evolving Training for Multimodal Reasoning","abstract":"Self-evolving trainin--where models iteratively learn from their own outputs--has emerged as a key approach for complex reasoning tasks, addressing the scarcity of high-quality chain-of-thought data. However, its effectiveness in multimodal reasoning, a domain more intricate than text-only reasoning, remains underexplored, and the understanding of critical factors in this training paradigm remains limited. Furthermore, a central challenge for this training method is performance saturation, which impedes further improvements and scalability. Inspired by reinforcement learning (RL), in this paper, we reframe self-evolving training for multimodal reasoning through the lens of RL, identifying three pivotal factors: Training Method, Reward Model, and Prompt Variation. Through systematic analysis, we establish relatively optimal design principles that significantly enhance multimodal reasoning capabilities. Moreover, delving deeper into training dynamics, we uncover the roots of saturation and propose a new automatic balancing mechanism to mitigate this limitation. Building on these insights, we propose M-STAR (Multimodal Self-evolving Training for Reasoning), a framework that achieves consistent performance gains across models of varying sizes and diverse benchmarks. All resources are made publicly available at https://mstar-lmm.github.io.","authors":["Wei Liu","Junlong Li","Xiwen Zhang","Fan Zhou","Yu Cheng","Junxian He"],"url":"https://arxiv.org/abs/2412.17451"}
{"created":"2025-06-04","title":"Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse","abstract":"The surge in online content has created an urgent demand for robust detection systems, especially in non-English contexts where current tools demonstrate significant limitations. We present forePLay, a novel Polish language dataset for erotic content detection, featuring over 24k annotated sentences with a multidimensional taxonomy encompassing ambiguity, violence, and social unacceptability dimensions. Our comprehensive evaluation demonstrates that specialized Polish language models achieve superior performance compared to multilingual alternatives, with transformer-based architectures showing particular strength in handling imbalanced categories. The dataset and accompanying analysis establish essential frameworks for developing linguistically-aware content moderation systems, while highlighting critical considerations for extending such capabilities to morphologically complex languages.","authors":["Anna Ko{\\l}os","Katarzyna Lorenc","Emilia Wi\\'snios","Agnieszka Karli\\'nska"],"url":"https://arxiv.org/abs/2412.17533"}
{"created":"2025-06-04","title":"Tracking the Feature Dynamics in LLM Training: A Mechanistic Study","abstract":"Understanding training dynamics and feature evolution is crucial for the mechanistic interpretability of large language models (LLMs). Although sparse autoencoders (SAEs) have been used to identify features within LLMs, a clear picture of how these features evolve during training remains elusive. In this study, we (1) introduce SAE-Track, a novel method for efficiently obtaining a continual series of SAEs, providing the foundation for a mechanistic study that covers (2) the semantic evolution of features, (3) the underlying processes of feature formation, and (4) the directional drift of feature vectors. Our work provides new insights into the dynamics of features in LLMs, enhancing our understanding of training mechanisms and feature evolution. For reproducibility, our code is available at https://github.com/Superposition09m/SAE-Track.","authors":["Yang Xu","Yi Wang","Hengguan Huang","Hao Wang"],"url":"https://arxiv.org/abs/2412.17626"}
{"created":"2025-06-04","title":"Elucidating Flow Matching ODE Dynamics with Respect to Data Geometries and Denoisers","abstract":"Flow matching (FM) models extend ODE sampler based diffusion models into a general framework, significantly reducing sampling steps through learned vector fields. However, the theoretical understanding of FM models, particularly how their sample trajectories interact with underlying data geometry, remains underexplored. A rigorous theoretical analysis of FM ODE is essential for sample quality, stability, and broader applicability. In this paper, we advance the theory of FM models through a comprehensive analysis of sample trajectories. Central to our theory is the discovery that the denoiser, a key component of FM models, guides ODE dynamics through attracting and absorbing behaviors that adapt to the data geometry. We identify and analyze the three stages of ODE evolution: in the initial and intermediate stages, trajectories move toward the mean and local clusters of the data. At the terminal stage, we rigorously establish the convergence of FM ODE under weak assumptions, addressing scenarios where the data lie on a low-dimensional submanifold-cases that previous results could not handle. Our terminal stage analysis offers insights into the memorization phenomenon and establishes equivariance properties of FM ODEs. These findings bridge critical gaps in understanding flow matching models, with practical implications for optimizing sampling strategies and architectures guided by the intrinsic geometry of data.","authors":["Zhengchao Wan","Qingsong Wang","Gal Mishne","Yusu Wang"],"url":"https://arxiv.org/abs/2412.18730"}
{"created":"2025-06-04","title":"Exemplar-condensed Federated Class-incremental Learning","abstract":"We propose Exemplar-Condensed federated class-incremental learning (ECoral) to distil the training characteristics of real images from streaming data into informative rehearsal exemplars. The proposed method eliminates the limitations of exemplar selection in replay-based approaches for mitigating catastrophic forgetting in federated continual learning (FCL). The limitations particularly related to the heterogeneity of information density of each summarized data. Our approach maintains the consistency of training gradients and the relationship to past tasks for the summarized exemplars to represent the streaming data compared to the original images effectively. Additionally, our approach reduces the information-level heterogeneity of the summarized data by inter-client sharing of the disentanglement generative model. Extensive experiments show that our ECoral outperforms several state-of-the-art methods and can be seamlessly integrated with many existing approaches to enhance performance.","authors":["Rui Sun","Yumin Zhang","Varun Ojha","Tejal Shah","Haoran Duan","Bo Wei","Rajiv Ranjan"],"url":"https://arxiv.org/abs/2412.18926"}
{"created":"2025-06-04","title":"Inclusion 2024 Global Multimedia Deepfake Detection Challenge: Towards Multi-dimensional Face Forgery Detection","abstract":"In this paper, we present the Global Multimedia Deepfake Detection held concurrently with the Inclusion 2024. Our Multimedia Deepfake Detection aims to detect automatic image and audio-video manipulations including but not limited to editing, synthesis, generation, Photoshop,etc. Our challenge has attracted 1500 teams from all over the world, with about 5000 valid result submission counts. We invite the top 20 teams to present their solutions to the challenge, from which the top 3 teams are awarded prizes in the grand finale. In this paper, we present the solutions from the top 3 teams of the two tracks, to boost the research work in the field of image and audio-video forgery detection. The methodologies developed through the challenge will contribute to the development of next-generation deepfake detection systems and we encourage participants to open source their methods.","authors":["Yi Zhang","Weize Gao","Changtao Miao","Man Luo","Jianshu Li","Wenzhong Deng","Zhe Li","Bingyu Hu","Weibin Yao","Yunfeng Diao","Wenbo Zhou","Tao Gong","Qi Chu"],"url":"https://arxiv.org/abs/2412.20833"}
{"created":"2025-06-04","title":"Graph Generative Pre-trained Transformer","abstract":"Graph generation is a critical task in numerous domains, including molecular design and social network analysis, due to its ability to model complex relationships and structured data. While most modern graph generative models utilize adjacency matrix representations, this work revisits an alternative approach that represents graphs as sequences of node set and edge set. We advocate for this approach due to its efficient encoding of graphs and propose a novel representation. Based on this representation, we introduce the Graph Generative Pre-trained Transformer (G2PT), an auto-regressive model that learns graph structures via next-token prediction. To further exploit G2PT's capabilities as a general-purpose foundation model, we explore fine-tuning strategies for two downstream applications: goal-oriented generation and graph property prediction. We conduct extensive experiments across multiple datasets. Results indicate that G2PT achieves superior generative performance on both generic graph and molecule datasets. Furthermore, G2PT exhibits strong adaptability and versatility in downstream tasks from molecular design to property prediction. Code available at https://github.com/tufts-ml/G2PT,","authors":["Xiaohui Chen","Yinkai Wang","Jiaxing He","Yuanqi Du","Soha Hassoun","Xiaolin Xu","Li-Ping Liu"],"url":"https://arxiv.org/abs/2501.01073"}
{"created":"2025-06-04","title":"Instruction-Following Pruning for Large Language Models","abstract":"With the rapid scaling of large language models (LLMs), structured pruning has become a widely used technique to learn efficient, smaller models from larger ones, delivering superior performance compared to training similarly sized models from scratch. In this paper, we move beyond the traditional static pruning approach of determining a fixed pruning mask for a model, and propose a dynamic approach to structured pruning. In our method, the pruning mask is input-dependent and adapts dynamically based on the information described in a user instruction. Our approach, termed \"instruction-following pruning\", introduces a sparse mask predictor that takes the user instruction as input and dynamically selects the most relevant model parameters for the given task. To identify and activate effective parameters, we jointly optimize the sparse mask predictor and the LLM, leveraging both instruction-following data and the pre-training corpus. Experimental results demonstrate the effectiveness of our approach on a wide range of evaluation benchmarks. For example, our 3B activated model improves over the 3B dense model by 5-8 points of absolute margin on domains such as math and coding, and rivals the performance of a 9B model.","authors":["Bairu Hou","Qibin Chen","Jianyu Wang","Guoli Yin","Chong Wang","Nan Du","Ruoming Pang","Shiyu Chang","Tao Lei"],"url":"https://arxiv.org/abs/2501.02086"}
{"created":"2025-06-04","title":"Back to Base: Towards Hands-Off Learning via Safe Resets with Reach-Avoid Safety Filters","abstract":"Designing controllers that accomplish tasks while guaranteeing safety constraints remains a significant challenge. We often want an agent to perform well in a nominal task, such as environment exploration, while ensuring it can avoid unsafe states and return to a desired target by a specific time. In particular we are motivated by the setting of safe, efficient, hands-off training for reinforcement learning in the real world. By enabling a robot to safely and autonomously reset to a desired region (e.g., charging stations) without human intervention, we can enhance efficiency and facilitate training. Safety filters, such as those based on control barrier functions, decouple safety from nominal control objectives and rigorously guarantee safety. Despite their success, constructing these functions for general nonlinear systems with control constraints and system uncertainties remains an open problem. This paper introduces a safety filter obtained from the value function associated with the reach-avoid problem. The proposed safety filter minimally modifies the nominal controller while avoiding unsafe regions and guiding the system back to the desired target set. By preserving policy performance while allowing safe resetting, we enable efficient hands-off reinforcement learning and advance the feasibility of safe training for real world robots. We demonstrate our approach using a modified version of soft actor-critic to safely train a swing-up task on a modified cartpole stabilization problem.","authors":["Azra Begzadi\\'c","Nikhil Uday Shinde","Sander Tonkens","Dylan Hirsch","Kaleb Ugalde","Michael C. Yip","Jorge Cort\\'es","Sylvia Herbert"],"url":"https://arxiv.org/abs/2501.02620"}
{"created":"2025-06-04","title":"ThriftLLM: On Cost-Effective Selection of Large Language Models for Classification Queries","abstract":"In recent years, large language models (LLMs) have demonstrated remarkable capabilities in comprehending and generating natural language content, attracting widespread attention in both industry and academia. An increasing number of services offer LLMs for various tasks via APIs. Different LLMs demonstrate expertise in different domains of queries (e.g., text classification queries). Meanwhile, LLMs of different scales, complexities, and performance are priced diversely. Driven by this, several researchers are investigating strategies for selecting an ensemble of LLMs, aiming to decrease overall usage costs while enhancing performance. However, to the best of our knowledge, none of the existing works addresses the problem, how to find an LLM ensemble subject to a cost budget, which maximizes the ensemble performance with guarantees.","authors":["Keke Huang","Yimin Shi","Dujian Ding","Yifei Li","Yang Fei","Laks Lakshmanan","Xiaokui Xiao"],"url":"https://arxiv.org/abs/2501.04901"}
{"created":"2025-06-04","title":"\"Cause\" is Mechanistic Narrative within Scientific Domains: An Ordinary Language Philosophical Critique of \"Causal Machine Learning\"","abstract":"Causal Learning has emerged as a major theme of research in statistics and machine learning in recent years, promising specific computational techniques to apply to datasets that reveal the true nature of cause and effect in a number of important domains. In this paper we consider the epistemology of recognizing true cause and effect phenomena. We apply the Ordinary Language method of engaging on the customary use of the word 'cause' to investigate valid semantics of reasoning about cause and effect. We recognize that the grammars of cause and effect are fundamentally distinct in form across scientific domains, yet they maintain a consistent and central function. This function can best be described as the mechanism underlying fundamental forces of influence as considered prominent in the respective scientific domain. We demarcate 1) physics and engineering as domains wherein mathematical models are sufficient to comprehensively describe causality, 2) biology as introducing challenges of emergence while providing opportunities for showing consistent mechanisms across scale, and 3) the social sciences as introducing grander difficulties for establishing models of low prediction error but providing, through Hermeneutics, the potential for findings that are still instrumentally useful to individuals. We posit that definitive causal claims regarding a given phenomenon (writ large) can only come through an agglomeration of consistent evidence across multiple domains. This presents important methodological questions as far as harmonizing between language games and emergence across scales. Given the role of epistemic hubris in the contemporary crisis of credibility in the sciences, exercising greater caution as far as communicating precision as to the real degree of certainty certain evidence provides for rich collections of open problems in optimizing integration of different findings.","authors":["Vyacheslav Kungurtsev","Leonardo Christov Moore","Gustav Sir","Martin Krutsky"],"url":"https://arxiv.org/abs/2501.05844"}
{"created":"2025-06-04","title":"FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings","abstract":"Efficient preference optimization algorithms such as Direct Preference Optimization (DPO) have become a popular approach in aligning large language models (LLMs) with human preferences. These algorithms implicitly treat the LLM as a reward model, and focus on training it to correct misranked preference pairs. However, recent work~\\citep{chen2024preference} empirically finds that DPO training \\textit{rarely improves these misranked preference pairs}, despite its gradient emphasizing on these cases. We introduce FocalPO, a DPO variant that instead \\textit{down-weighs} misranked preference pairs and prioritizes enhancing the model's understanding of pairs that it can already rank correctly. Inspired by Focal Loss used in vision tasks, FocalPO achieves this by adding a modulating factor to dynamically scale DPO loss. Our experiment demonstrates that FocalPO surpasses DPO and its variants on popular benchmarks like Alpaca Eval 2.0 using Mistral-Base-7B and Llama-3-Instruct-8B, with the introduced hyperparameter fixed. Additionally, we empirically reveals how FocalPO affects training on correct and incorrect sample groups, further underscoring its effectiveness.","authors":["Tong Liu","Xiao Yu","Wenxuan Zhou","Jindong Gu","Volker Tresp"],"url":"https://arxiv.org/abs/2501.06645"}
{"created":"2025-06-04","title":"The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation","abstract":"Large Language Models (LLMs) have emerged as the new recommendation engines, surpassing traditional methods in both capability and scope, particularly in code generation. In this paper, we reveal a novel provider bias in LLMs: without explicit directives, these models show systematic preferences for services from specific providers in their recommendations (e.g., favoring Google Cloud over Microsoft Azure). To systematically investigate this bias, we develop an automated pipeline to construct the dataset, incorporating 6 distinct coding task categories and 30 real-world application scenarios. Leveraging this dataset, we conduct the first comprehensive empirical study of provider bias in LLM code generation across seven state-of-the-art LLMs, utilizing approximately 500 million tokens (equivalent to $5,000+ in computational costs). Our findings reveal that LLMs exhibit significant provider preferences, predominantly favoring services from Google and Amazon, and can autonomously modify input code to incorporate their preferred providers without users' requests. Such a bias holds far-reaching implications for market dynamics and societal equilibrium, potentially contributing to digital monopolies. It may also deceive users and violate their expectations, leading to various consequences. We call on the academic community to recognize this emerging issue and develop effective evaluation and mitigation methods to uphold AI security and fairness.","authors":["Xiaoyu Zhang","Juan Zhai","Shiqing Ma","Qingshuang Bao","Weipeng Jiang","Qian Wang","Chao Shen","Yang Liu"],"url":"https://arxiv.org/abs/2501.07849"}
{"created":"2025-06-04","title":"Changing the ranking in eigenvector centrality of a weighted graph by small perturbations","abstract":"In this article, we consider eigenvector centrality for the nodes of a graph and study the robustness (and stability) of this popular centrality measure. For a given weighted graph ${\\mathcal G}$ (both directed and undirected), we consider the associated weighted adjacency matrix $A$, which by definition is a non-negative matrix. The eigenvector centralities of the nodes of ${\\mathcal G}$ are the entries of the Perron eigenvector of $A$, which is the (positive) eigenvector associated with the eigenvalue with largest modulus. They provide a ranking of the nodes according to the corresponding centralities. An indicator of the robustness of eigenvector centrality consists in looking for a nearby perturbed graph $\\widetilde{\\mathcal G}$, with the same structure as ${\\mathcal G}$ (i.e., with the same vertices and edges), but with a weighted adjacency matrix $\\widetilde A$ such that the highest $m$ entries ($m \\ge 2$) of the Perron eigenvector of $\\widetilde A$ coalesce, making the ranking at the highest level ambiguous. To compute a solution to this matrix nearness problem, a nested iterative algorithm is proposed that makes use of a constrained gradient system of matrix differential equations in the inner iteration and a one-dimensional optimization of the perturbation size in the outer iteration.","authors":["Michele Benzi","Nicola Guglielmi"],"url":"https://arxiv.org/abs/2501.10745"}
{"created":"2025-06-04","title":"Kimi k1.5: Scaling Reinforcement Learning with LLMs","abstract":"Language model pretraining with next token prediction has proved effective for scaling compute but is limited to the amount of available training data. Scaling reinforcement learning (RL) unlocks a new axis for the continued improvement of artificial intelligence, with the promise that large language models (LLMs) can scale their training data by learning to explore with rewards. However, prior published work has not produced competitive results. In light of this, we report on the training practice of Kimi k1.5, our latest multi-modal LLM trained with RL, including its RL training techniques, multi-modal data recipes, and infrastructure optimization. Long context scaling and improved policy optimization methods are key ingredients of our approach, which establishes a simplistic, effective RL framework without relying on more complex techniques such as Monte Carlo tree search, value functions, and process reward models. Notably, our system achieves state-of-the-art reasoning performance across multiple benchmarks and modalities -- e.g., 77.5 on AIME, 96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista -- matching OpenAI's o1. Moreover, we present effective long2short methods that use long-CoT techniques to improve short-CoT models, yielding state-of-the-art short-CoT reasoning results -- e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on LiveCodeBench -- outperforming existing short-CoT models such as GPT-4o and Claude Sonnet 3.5 by a large margin (up to +550%).","authors":["Kimi Team","Angang Du","Bofei Gao","Bowei Xing","Changjiu Jiang","Cheng Chen","Cheng Li","Chenjun Xiao","Chenzhuang Du","Chonghua Liao","Chuning Tang","Congcong Wang","Dehao Zhang","Enming Yuan","Enzhe Lu","Fengxiang Tang","Flood Sung","Guangda Wei","Guokun Lai","Haiqing Guo","Han Zhu","Hao Ding","Hao Hu","Hao Yang","Hao Zhang","Haotian Yao","Haotian Zhao","Haoyu Lu","Haoze Li","Haozhen Yu","Hongcheng Gao","Huabin Zheng","Huan Yuan","Jia Chen","Jianhang Guo","Jianlin Su","Jianzhou Wang","Jie Zhao","Jin Zhang","Jingyuan Liu","Junjie Yan","Junyan Wu","Lidong Shi","Ling Ye","Longhui Yu","Mengnan Dong","Neo Zhang","Ningchen Ma","Qiwei Pan","Qucheng Gong","Shaowei Liu","Shengling Ma","Shupeng Wei","Sihan Cao","Siying Huang","Tao Jiang","Weihao Gao","Weimin Xiong","Weiran He","Weixiao Huang","Weixin Xu","Wenhao Wu","Wenyang He","Xianghui Wei","Xianqing Jia","Xingzhe Wu","Xinran Xu","Xinxing Zu","Xinyu Zhou","Xuehai Pan","Y. Charles","Yang Li","Yangyang Hu","Yangyang Liu","Yanru Chen","Yejie Wang","Yibo Liu","Yidao Qin","Yifeng Liu","Ying Yang","Yiping Bao","Yulun Du","Yuxin Wu","Yuzhi Wang","Zaida Zhou","Zhaoji Wang","Zhaowei Li","Zhen Zhu","Zheng Zhang","Zhexu Wang","Zhilin Yang","Zhiqi Huang","Zihao Huang","Ziyao Xu","Zonghan Yang","Zongyu Lin"],"url":"https://arxiv.org/abs/2501.12599"}
{"created":"2025-06-04","title":"Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors","abstract":"Traditional approaches to studying decision-making in neuroscience focus on simplified behavioral tasks where animals perform repetitive, stereotyped actions to receive explicit rewards. While informative, these methods constrain our understanding of decision-making to short timescale behaviors driven by explicit goals. In natural environments, animals exhibit more complex, long-term behaviors driven by intrinsic motivations that are often unobservable. Recent works in time-varying inverse reinforcement learning (IRL) aim to capture shifting motivations in long-term, freely moving behaviors. However, a crucial challenge remains: animals make decisions based on their history, not just their current state. To address this, we introduce SWIRL (SWitching IRL), a novel framework that extends traditional IRL by incorporating time-varying, history-dependent reward functions. SWIRL models long behavioral sequences as transitions between short-term decision-making processes, each governed by a unique reward function. SWIRL incorporates biologically plausible history dependency to capture how past decisions and environmental contexts shape behavior, offering a more accurate description of animal decision-making. We apply SWIRL to simulated and real-world animal behavior datasets and show that it outperforms models lacking history dependency, both quantitatively and qualitatively. This work presents the first IRL model to incorporate history-dependent policies and rewards to advance our understanding of complex, naturalistic decision-making in animals.","authors":["Jingyang Ke","Feiyang Wu","Jiyi Wang","Jeffrey Markowitz","Anqi Wu"],"url":"https://arxiv.org/abs/2501.12633"}
{"created":"2025-06-04","title":"VideoLLaMA 3: Frontier Multimodal Foundation Models for Image and Video Understanding","abstract":"In this paper, we propose VideoLLaMA3, a more advanced multimodal foundation model for image and video understanding. The core design philosophy of VideoLLaMA3 is vision-centric. The meaning of \"vision-centric\" is two-fold: the vision-centric training paradigm and vision-centric framework design. The key insight of our vision-centric training paradigm is that high-quality image-text data is crucial for both image and video understanding. Instead of preparing massive video-text datasets, we focus on constructing large-scale and high-quality image-text datasets. VideoLLaMA3 has four training stages: 1) Vision Encoder Adaptation, which enables vision encoder to accept images of variable resolutions as input; 2) Vision-Language Alignment, which jointly tunes the vision encoder, projector, and LLM with large-scale image-text data covering multiple types (including scene images, documents, charts) as well as text-only data. 3) Multi-task Fine-tuning, which incorporates image-text SFT data for downstream tasks and video-text data to establish a foundation for video understanding. 4) Video-centric Fine-tuning, which further improves the model's capability in video understanding. As for the framework design, to better capture fine-grained details in images, the pretrained vision encoder is adapted to encode images of varying sizes into vision tokens with corresponding numbers, rather than a fixed number of tokens. For video inputs, we reduce the number of vision tokens according to their similarity so that the representation of videos will be more precise and compact. Benefit from vision-centric designs, VideoLLaMA3 achieves compelling performances in both image and video understanding benchmarks.","authors":["Boqiang Zhang","Kehan Li","Zesen Cheng","Zhiqiang Hu","Yuqian Yuan","Guanzheng Chen","Sicong Leng","Yuming Jiang","Hang Zhang","Xin Li","Peng Jin","Wenqi Zhang","Fan Wang","Lidong Bing","Deli Zhao"],"url":"https://arxiv.org/abs/2501.13106"}
{"created":"2025-06-04","title":"Not Every AI Problem is a Data Problem: We Should Be Intentional About Data Scaling","abstract":"While Large Language Models require more and more data to train and scale, rather than looking for any data to acquire, we should consider what types of tasks are more likely to benefit from data scaling. We should be intentional in our data acquisition. We argue that the shape of the data itself, such as its compositional and structural patterns, informs which tasks to prioritize in data scaling, and shapes the development of the next generation of compute paradigms for tasks where data scaling is inefficient, or even insufficient.","authors":["Tanya Rodchenko","Natasha Noy","Nino Scherrer"],"url":"https://arxiv.org/abs/2501.13779"}
{"created":"2025-06-04","title":"HAMMER: Heterogeneous, Multi-Robot Semantic Gaussian Splatting","abstract":"3D Gaussian Splatting offers expressive scene reconstruction, modeling a broad range of visual, geometric, and semantic information. However, efficient real-time map reconstruction with data streamed from multiple robots and devices remains a challenge. To that end, we propose HAMMER, a server-based collaborative Gaussian Splatting method that leverages widely available ROS communication infrastructure to generate 3D, metric-semantic maps from asynchronous robot data-streams with no prior knowledge of initial robot positions and varying on-device pose estimators. HAMMER consists of (i) a frame alignment module that transforms local SLAM poses and image data into a global frame and requires no prior relative pose knowledge, and (ii) an online module for training semantic 3DGS maps from streaming data. HAMMER handles mixed perception modes, adjusts automatically for variations in image pre-processing among different devices, and distills CLIP semantic codes into the 3D scene for open-vocabulary language queries. In our real-world experiments, HAMMER creates higher-fidelity maps (2x) compared to competing baselines and is useful for downstream tasks, such as semantic goal-conditioned navigation (e.g., \"go to the couch\"). Accompanying content available at hammer-project.github.io.","authors":["Javier Yu","Timothy Chen","Mac Schwager"],"url":"https://arxiv.org/abs/2501.14147"}
{"created":"2025-06-04","title":"Large Language Models to Diffusion Finetuning","abstract":"We propose a new finetuning method to provide pre-trained large language models (LMs) the ability to scale test-time compute through the diffusion framework. By increasing the number of diffusion steps, we show our finetuned models achieve monotonically increasing accuracy, directly translating to improved performance across downstream tasks. Furthermore, our finetuned models can expertly answer questions on specific topics by integrating powerful guidance techniques, and autonomously determine the compute required for a given problem by leveraging adaptive ODE solvers. Our method is universally applicable to any foundation model pre-trained with a cross-entropy loss and does not modify any of its original weights, fully preserving its strong single-step generation capabilities. We show our method is more effective and fully compatible with traditional finetuning approaches, introducing an orthogonal new direction to unify the strengths of the autoregressive and diffusion frameworks.","authors":["Edoardo Cetin","Tianyu Zhao","Yujin Tang"],"url":"https://arxiv.org/abs/2501.15781"}
{"created":"2025-06-04","title":"Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity","abstract":"Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstone method for parallelizing learning in distributed machine learning. However, its performance suffers under arbitrarily heterogeneous computation times across workers, leading to suboptimal time complexity and inefficiency as the number of workers scales. While several Asynchronous SGD variants have been proposed, recent findings by Tyurin & Richt\\'arik (NeurIPS 2023) reveal that none achieve optimal time complexity, leaving a significant gap in the literature. In this paper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed to address these limitations and tame the inherent challenges of Asynchronous SGD. We establish, through rigorous theoretical analysis, that Ringmaster ASGD achieves optimal time complexity under arbitrarily heterogeneous and dynamically fluctuating worker computation times. This makes it the first Asynchronous SGD method to meet the theoretical lower bounds for time complexity in such scenarios.","authors":["Artavazd Maranjyan","Alexander Tyurin","Peter Richt\\'arik"],"url":"https://arxiv.org/abs/2501.16168"}
{"created":"2025-06-04","title":"CAND: Cross-Domain Ambiguity Inference for Early Detecting Nuanced Illness Deterioration","abstract":"Early detection of patient deterioration is essential for timely treatment, with vital signs like heart rates being key health indicators. Existing methods tend to solely analyze vital sign waveforms, ignoring transition relationships of waveforms within each vital sign and the correlation strengths among various vital signs. Such studies often overlook nuanced illness deterioration, which is the early sign of worsening health but is difficult to detect. In this paper, we introduce CAND, a novel method that organizes the transition relationships and the correlations within and among vital signs as domain-specific and cross-domain knowledge. CAND jointly models these knowledge in a unified representation space, considerably enhancing the early detection of nuanced illness deterioration. In addition, CAND integrates a Bayesian inference method that utilizes augmented knowledge from domain-specific and cross-domain knowledge to address the ambiguities in correlation strengths. With this architecture, the correlation strengths can be effectively inferred to guide joint modeling and enhance representations of vital signs. This allows a more holistic and accurate interpretation of patient health. Our experiments on a real-world ICU dataset demonstrate that CAND significantly outperforms existing methods in both effectiveness and earliness in detecting nuanced illness deterioration. Moreover, we conduct a case study for the interpretable detection process to showcase the practicality of CAND.","authors":["Lo Pang-Yun Ting","Zhen Tan","Hong-Pei Chen","Cheng-Te Li","Po-Lin Chen","Kun-Ta Chuang","Huan Liu"],"url":"https://arxiv.org/abs/2501.16365"}
{"created":"2025-06-04","title":"P-TAME: Explain Any Image Classifier with Trained Perturbations","abstract":"The adoption of Deep Neural Networks (DNNs) in critical fields where predictions need to be accompanied by justifications is hindered by their inherent black-box nature. In this paper, we introduce P-TAME (Perturbation-based Trainable Attention Mechanism for Explanations), a model-agnostic method for explaining DNN-based image classifiers. P-TAME employs an auxiliary image classifier to extract features from the input image, bypassing the need to tailor the explanation method to the internal architecture of the backbone classifier being explained. Unlike traditional perturbation-based methods, which have high computational requirements, P-TAME offers an efficient alternative by generating high-resolution explanations in a single forward pass during inference. We apply P-TAME to explain the decisions of VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image classifiers. Quantitative and qualitative results show that our method matches or outperforms previous explainability methods, including model-specific approaches. Code and trained models will be released upon acceptance.","authors":["Mariano V. Ntrougkas","Vasileios Mezaris","Ioannis Patras"],"url":"https://arxiv.org/abs/2501.17813"}
{"created":"2025-06-04","title":"SAM2Act: Integrating Visual Foundation Model with A Memory Architecture for Robotic Manipulation","abstract":"Robotic manipulation systems operating in diverse, dynamic environments must exhibit three critical abilities: multitask interaction, generalization to unseen scenarios, and spatial memory. While significant progress has been made in robotic manipulation, existing approaches often fall short in generalization to complex environmental variations and addressing memory-dependent tasks. To bridge this gap, we introduce SAM2Act, a multi-view robotic transformer-based policy that leverages multi-resolution upsampling with visual representations from large-scale foundation model. SAM2Act achieves a state-of-the-art average success rate of 86.8% across 18 tasks in the RLBench benchmark, and demonstrates robust generalization on The Colosseum benchmark, with only a 4.3% performance gap under diverse environmental perturbations. Building on this foundation, we propose SAM2Act+, a memory-based architecture inspired by SAM2, which incorporates a memory bank, an encoder, and an attention mechanism to enhance spatial memory. To address the need for evaluating memory-dependent tasks, we introduce MemoryBench, a novel benchmark designed to assess spatial memory and action recall in robotic manipulation. SAM2Act+ achieves an average success rate of 94.3% on memory-based tasks in MemoryBench, significantly outperforming existing approaches and pushing the boundaries of memory-based robotic systems. Project page: sam2act.github.io.","authors":["Haoquan Fang","Markus Grotz","Wilbert Pumacay","Yi Ru Wang","Dieter Fox","Ranjay Krishna","Jiafei Duan"],"url":"https://arxiv.org/abs/2501.18564"}
{"created":"2025-06-04","title":"Rethinking Diffusion Posterior Sampling: From Conditional Score Estimator to Maximizing a Posterior","abstract":"Recent advancements in diffusion models have been leveraged to address inverse problems without additional training, and Diffusion Posterior Sampling (DPS) (Chung et al., 2022a) is among the most popular approaches. Previous analyses suggest that DPS accomplishes posterior sampling by approximating the conditional score. While in this paper, we demonstrate that the conditional score approximation employed by DPS is not as effective as previously assumed, but rather aligns more closely with the principle of maximizing a posterior (MAP). This assertion is substantiated through an examination of DPS on 512x512 ImageNet images, revealing that: 1) DPS's conditional score estimation significantly diverges from the score of a well-trained conditional diffusion model and is even inferior to the unconditional score; 2) The mean of DPS's conditional score estimation deviates significantly from zero, rendering it an invalid score estimation; 3) DPS generates high-quality samples with significantly lower diversity. In light of the above findings, we posit that DPS more closely resembles MAP than a conditional score estimator, and accordingly propose the following enhancements to DPS: 1) we explicitly maximize the posterior through multi-step gradient ascent and projection; 2) we utilize a light-weighted conditional score estimator trained with only 100 images and 8 GPU hours. Extensive experimental results indicate that these proposed improvements significantly enhance DPS's performance. The source code for these improvements is provided in https://github.com/tongdaxu/Rethinking-Diffusion-Posterior-Sampling-From-Conditional-Score-Estimator-to-Maximizing-a-Posterior.","authors":["Tongda Xu","Xiyan Cai","Xinjie Zhang","Xingtong Ge","Dailan He","Ming Sun","Jingjing Liu","Ya-Qin Zhang","Jian Li","Yan Wang"],"url":"https://arxiv.org/abs/2501.18913"}
{"created":"2025-06-04","title":"On the Expressiveness of Visual Prompt Experts","abstract":"Visual Prompt Tuning (VPT) has proven effective for parameter-efficient adaptation of pre-trained vision models to downstream tasks by inserting task-specific learnable prompt tokens. Despite its empirical success, a comprehensive theoretical understanding of VPT remains an active area of research. Building on the recently established connection between Mixture of Experts (MoE) and prompt-based methods, wherein each attention head can be conceptualized as a composition of multiple MoE models, we reinterpret VPT as the introduction of new prompt experts into these MoE structures. We identify a key limitation in existing VPT frameworks: the restricted functional expressiveness of prompt experts, which remain static and thus limited in their adaptability. To address this, we propose Visual Adaptive Prompt Tuning (VAPT), a novel method that endows prompt experts with enhanced expressiveness while preserving parameter efficiency. Empirical evaluations on VTAB-1K and FGVC demonstrate that VAPT achieves substantial performance improvements, surpassing fully fine-tuned baselines by 7.34% and 1.04%, respectively. Moreover, VAPT consistently outperforms VPT while requiring fewer additional parameters. Furthermore, our theoretical analysis indicates that VAPT achieves optimal sample efficiency. Collectively, these results underscore the theoretical grounding and empirical advantages of our approach.","authors":["Minh Le","Anh Nguyen","Huy Nguyen","Chau Nguyen","Anh Tran","Nhat Ho"],"url":"https://arxiv.org/abs/2501.18936"}
{"created":"2025-06-04","title":"Towards the Worst-case Robustness of Large Language Models","abstract":"Recent studies have revealed the vulnerability of large language models to adversarial attacks, where adversaries craft specific input sequences to induce harmful, violent, private, or incorrect outputs. In this work, we study their worst-case robustness, i.e., whether an adversarial example exists that leads to such undesirable outputs. We upper bound the worst-case robustness using stronger white-box attacks, indicating that most current deterministic defenses achieve nearly 0\\% worst-case robustness. We propose a general tight lower bound for randomized smoothing using fractional knapsack solvers or 0-1 knapsack solvers, and using them to bound the worst-case robustness of all stochastic defenses. Based on these solvers, we provide theoretical lower bounds for several previous empirical defenses. For example, we certify the robustness of a specific case, smoothing using a uniform kernel, against \\textit{any possible attack} with an average $\\ell_0$ perturbation of 2.02 or an average suffix length of 6.41.","authors":["Huanran Chen","Yinpeng Dong","Zeming Wei","Hang Su","Jun Zhu"],"url":"https://arxiv.org/abs/2501.19040"}
{"created":"2025-06-04","title":"Principal Components for Neural Network Initialization","abstract":"Principal Component Analysis (PCA) is a commonly used tool for dimension reduction and denoising. Therefore, it is also widely used on the data prior to training a neural network. However, this approach can complicate the explanation of explainable AI (XAI) methods for the decision of the model. In this work, we analyze the potential issues with this approach and propose Principal Components-based Initialization (PCsInit), a strategy to incorporate PCA into the first layer of a neural network via initialization of the first layer in the network with the principal components, and its two variants PCsInit-Act and PCsInit-Sub. Explanations using these strategies are as direct and straightforward as for neural networks and are simpler than using PCA prior to training a neural network on the principal components. Moreover, as will be illustrated in the experiments, such training strategies can also allow further improvement of training via backpropagation.","authors":["Nhan Phan","Thu Nguyen","P{\\aa}l Halvorsen","Michael A. Riegler"],"url":"https://arxiv.org/abs/2501.19114"}
{"created":"2025-06-04","title":"MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems","abstract":"While large language models (LLMs) have shown promising capabilities as zero-shot planners for embodied agents, their inability to learn from experience and build persistent mental models limits their robustness in complex open-world environments like Minecraft. We introduce MINDSTORES, an experience-augmented planning framework that enables embodied agents to build and leverage mental models through natural interaction with their environment. Drawing inspiration from how humans construct and refine cognitive mental models, our approach extends existing zero-shot LLM planning by maintaining a database of past experiences that informs future planning iterations. The key innovation is representing accumulated experiences as natural language embeddings of (state, task, plan, outcome) tuples, which can then be efficiently retrieved and reasoned over by an LLM planner to generate insights and guide plan refinement for novel states and tasks. Through extensive experiments in the MineDojo environment, a simulation environment for agents in Minecraft that provides low-level controls for Minecraft, we find that MINDSTORES learns and applies its knowledge significantly better than existing memory-based LLM planners while maintaining the flexibility and generalization benefits of zero-shot approaches, representing an important step toward more capable embodied AI systems that can learn continuously through natural experience.","authors":["Anirudh Chari","Suraj Reddy","Aditya Tiwari","Richard Lian","Brian Zhou"],"url":"https://arxiv.org/abs/2501.19318"}
{"created":"2025-06-04","title":"Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study","abstract":"As privacy concerns and data regulations grow, federated learning (FL) has emerged as a promising approach for training machine learning models across decentralized data sources without sharing raw data. However, a significant challenge in FL is that client data are often non-IID (non-independent and identically distributed), leading to reduced performance compared to centralized learning. While many methods have been proposed to address this issue, their underlying mechanisms are often viewed from different perspectives. Through a comprehensive investigation from gradient descent to FL, and from IID to non-IID data settings, we find that inconsistencies in client loss landscapes primarily cause performance degradation in non-IID scenarios. From this understanding, we observe that existing methods can be grouped into two main strategies: (i) adjusting parameter update paths and (ii) modifying client loss landscapes. These findings offer a clear perspective on addressing non-IID challenges in FL and help guide future research in the field.","authors":["Jungwon Seo","Ferhat Ozgur Catak","Chunming Rong"],"url":"https://arxiv.org/abs/2502.00182"}
{"created":"2025-06-04","title":"UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in solving complex reasoning tasks, particularly in mathematics. However, the domain of physics reasoning presents unique challenges that have received significantly less attention. Existing benchmarks often fall short in evaluating LLMs' abilities on the breadth and depth of undergraduate-level physics, underscoring the need for a comprehensive evaluation. To fill this gap, we introduce UGPhysics, a large-scale and comprehensive benchmark specifically designed to evaluate UnderGraduate-level Physics (UGPhysics) reasoning with LLMs. UGPhysics includes 5,520 undergraduate-level physics problems in both English and Chinese, covering 13 subjects with seven different answer types and four distinct physics reasoning skills, all rigorously screened for data leakage. Additionally, we develop a Model-Assistant Rule-based Judgment (MARJ) pipeline specifically tailored for assessing answer correctness of physics problems, ensuring accurate evaluation. Our evaluation of 31 leading LLMs shows that the highest overall accuracy, 49.8% (achieved by OpenAI-o1-mini), emphasizes the necessity for models with stronger physics reasoning skills, beyond math abilities. We hope UGPhysics, along with MARJ, will drive future advancements in AI for physics reasoning. Codes and data are available at https://github.com/YangLabHKUST/UGPhysics .","authors":["Xin Xu","Qiyun Xu","Tong Xiao","Tianhao Chen","Yuchen Yan","Jiaxin Zhang","Shizhe Diao","Can Yang","Yang Wang"],"url":"https://arxiv.org/abs/2502.00334"}
{"created":"2025-06-04","title":"SafeSwitch: Steering Unsafe LLM Behavior via Internal Activation Signals","abstract":"Large language models (LLMs) exhibit exceptional capabilities across various tasks but also pose risks by generating harmful content. Existing safety mechanisms, while improving model safety, often lead to overly cautious behavior and fail to fully leverage LLMs' internal cognitive processes. Inspired by humans' reflective thinking capability, we first show that LLMs can similarly perform internal assessments about safety in their internal states. Building on this insight, we propose SafeSwitch, a dynamic framework that regulates unsafe outputs by utilizing the prober-based internal state monitor that actively detects harmful intentions, and activates a safety head that leads to safer and more conservative responses only when necessary. SafeSwitch reduces harmful outputs by approximately 80% on harmful queries while maintaining strong utility, reaching a Pareto optimal among several methods. Our method is also advantageous over traditional methods in offering more informative, context-aware refusals, and achieves these benefits while only tuning less than 6% of the original parameters. SafeSwitch demonstrates large language models' capacity for self-awareness and reflection regarding safety, offering a promising approach to more nuanced and effective safety controls. Codes for this work are available at https://github.com/Hanpx20/SafeSwitch.","authors":["Peixuan Han","Cheng Qian","Xiusi Chen","Yuji Zhang","Denghui Zhang","Heng Ji"],"url":"https://arxiv.org/abs/2502.01042"}
{"created":"2025-06-04","title":"Federated Linear Dueling Bandits","abstract":"Contextual linear dueling bandits have recently garnered significant attention due to their widespread applications in important domains such as recommender systems and large language models. Classical dueling bandit algorithms are typically only applicable to a single agent. However, many applications of dueling bandits involve multiple agents who wish to collaborate for improved performance yet are unwilling to share their data. This motivates us to draw inspirations from federated learning, which involves multiple agents aiming to collaboratively train their neural networks via gradient descent (GD) without sharing their raw data. Previous works have developed federated linear bandit algorithms which rely on closed-form updates of the bandit parameters (e.g., the linear function parameters) to achieve collaboration. However, in linear dueling bandits, the linear function parameters lack a closed-form expression and their estimation requires minimizing a loss function. This renders these previous methods inapplicable. In this work, we overcome this challenge through an innovative and principled combination of online gradient descent (OGD, for minimizing the loss function to estimate the linear function parameters) and federated learning, hence introducing our federated linear dueling bandit with OGD (FLDB-OGD) algorithm. Through rigorous theoretical analysis, we prove that FLDB-OGD enjoys a sub-linear upper bound on its cumulative regret and demonstrate a theoretical trade-off between regret and communication complexity. We conduct empirical experiments to demonstrate the effectiveness of FLDB-OGD and reveal valuable insights, such as the benefit of a larger number of agents, the regret-communication trade-off, among others.","authors":["Xuhan Huang","Yan Hu","Zhiyan Li","Zhiyong Wang","Benyou Wang","Zhongxiang Dai"],"url":"https://arxiv.org/abs/2502.01085"}
{"created":"2025-06-04","title":"VR-Robo: A Real-to-Sim-to-Real Framework for Visual Robot Navigation and Locomotion","abstract":"Recent success in legged robot locomotion is attributed to the integration of reinforcement learning and physical simulators. However, these policies often encounter challenges when deployed in real-world environments due to sim-to-real gaps, as simulators typically fail to replicate visual realism and complex real-world geometry. Moreover, the lack of realistic visual rendering limits the ability of these policies to support high-level tasks requiring RGB-based perception like ego-centric navigation. This paper presents a Real-to-Sim-to-Real framework that generates photorealistic and physically interactive \"digital twin\" simulation environments for visual navigation and locomotion learning. Our approach leverages 3D Gaussian Splatting (3DGS) based scene reconstruction from multi-view images and integrates these environments into simulations that support ego-centric visual perception and mesh-based physical interactions. To demonstrate its effectiveness, we train a reinforcement learning policy within the simulator to perform a visual goal-tracking task. Extensive experiments show that our framework achieves RGB-only sim-to-real policy transfer. Additionally, our framework facilitates the rapid adaptation of robot policies with effective exploration capability in complex new environments, highlighting its potential for applications in households and factories.","authors":["Shaoting Zhu","Linzhan Mou","Derun Li","Baijun Ye","Runhan Huang","Hang Zhao"],"url":"https://arxiv.org/abs/2502.01536"}
{"created":"2025-06-04","title":"SubTrack++ : Gradient Subspace Tracking for Scalable LLM Training","abstract":"Training large language models (LLMs) is highly resource-intensive due to their massive number of parameters and the overhead of optimizer states. While recent work has aimed to reduce memory consumption, such efforts often entail trade-offs among memory efficiency, training time, and model performance. Yet, true democratization of LLMs requires simultaneous progress across all three dimensions. To this end, we propose SubTrack++ that leverages Grassmannian gradient subspace tracking combined with projection-aware optimizers, enabling Adam's internal statistics to adapt to changes in the optimization subspace. Additionally, employing recovery scaling, a technique that restores information lost through low-rank projections, further enhances model performance. Our method demonstrates SOTA convergence by exploiting Grassmannian geometry and achieves lowest evaluation loss, outperforming the current SOTA while reducing pretraining wall time by 43% and maintaining the memory footprint on a 1B-parameter Llama model.","authors":["Sahar Rajabi","Nayeema Nonta","Sirisha Rambhatla"],"url":"https://arxiv.org/abs/2502.01586"}
{"created":"2025-06-04","title":"Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators","abstract":"Fire safety is crucial for ensuring the stability of building structures, yet evaluating whether a structure meets fire safety requirement is challenging. Fires can originate at any point within a structure, and simulating every potential fire scenario is both expensive and time-consuming. To address this challenge, we propose the concept of the Most Fire-Sensitive Point (MFSP) and an efficient machine learning framework for its identification. The MFSP is defined as the location at which a fire, if initiated, would cause the most severe detrimental impact on the building's stability, effectively representing the worst-case fire scenario. In our framework, a Graph Neural Network (GNN) serves as an efficient and differentiable agent for conventional Finite Element Analysis (FEA) simulators by predicting the Maximum Interstory Drift Ratio (MIDR) under fire, which then guides the training and evaluation of the MFSP predictor. Additionally, we enhance our framework with a novel edge update mechanism and a transfer learning-based training scheme. Evaluations on a large-scale simulation dataset demonstrate the good performance of the proposed framework in identifying the MFSP, offering a transformative tool for optimizing fire safety assessments in structural design. All developed datasets and codes are open-sourced online.","authors":["Yuan Xinjie","Khalid M. Mosalam"],"url":"https://arxiv.org/abs/2502.03424"}
{"created":"2025-06-04","title":"Controllable Sequence Editing for Biological and Clinical Trajectories","abstract":"Conditional generation models for longitudinal sequences can generate new or modified trajectories given a conditioning input. While effective at generating entire sequences, these models typically lack control over the timing and scope of the edits. Most existing approaches either operate on univariate sequences or assume that the condition affects all variables and time steps. However, many scientific and clinical applications require more precise interventions, where a condition takes effect only after a specific time and influences only a subset of variables. We introduce CLEF, a controllable sequence editing model for conditional generation of immediate and delayed effects in multivariate longitudinal sequences. CLEF learns temporal concepts that encode how and when a condition alters future sequence evolution. These concepts allow CLEF to apply targeted edits to the affected time steps and variables while preserving the rest of the sequence. We evaluate CLEF on 6 datasets spanning cellular reprogramming and patient health trajectories, comparing against 9 state-of-the-art baselines. CLEF improves immediate sequence editing accuracy by up to 36.01% (MAE). Unlike prior models, CLEF enables one-step conditional generation at arbitrary future times, outperforming them in delayed sequence editing by up to 65.71% (MAE). We test CLEF under counterfactual inference assumptions and show up to 63.19% (MAE) improvement on zero-shot conditional generation of counterfactual trajectories. In a case study of patients with type 1 diabetes mellitus, CLEF identifies clinical interventions that generate realistic counterfactual trajectories shifted toward healthier outcomes.","authors":["Michelle M. Li","Kevin Li","Yasha Ektefaie","Ying Jin","Yepeng Huang","Shvat Messica","Tianxi Cai","Marinka Zitnik"],"url":"https://arxiv.org/abs/2502.03569"}
{"created":"2025-06-04","title":"Ola: Pushing the Frontiers of Omni-Modal Language Model","abstract":"Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have emerged, there is still a notable lag behind specialized single-modality models in performance. In this paper, we present Ola, an Omni-modal Language model that achieves competitive performance across image, video, and audio understanding compared to specialized counterparts, pushing the frontiers of the omni-modal language model to a large extent. We conduct a comprehensive exploration of architectural design, data curation, and training strategies essential for building a robust omni-modal model. Ola incorporates advanced visual understanding and audio recognition capabilities through several critical and effective improvements over mainstream baselines. Moreover, we rethink inter-modal relationships during omni-modal training, emphasizing cross-modal alignment with video as a central bridge, and propose a progressive training pipeline that begins with the most distinct modalities and gradually moves towards closer modality alignment. Extensive experiments demonstrate that Ola surpasses existing open omni-modal LLMs across all modalities while achieving highly competitive performance compared to state-of-the-art specialized models of similar sizes. We aim to make Ola a fully open omni-modal understanding solution to advance future research in this emerging field. Model weights, code, and data are open-sourced at https://github.com/Ola-Omni/Ola.","authors":["Zuyan Liu","Yuhao Dong","Jiahui Wang","Ziwei Liu","Winston Hu","Jiwen Lu","Yongming Rao"],"url":"https://arxiv.org/abs/2502.04328"}
{"created":"2025-06-04","title":"Stochastic Forward-Backward Deconvolution: Training Diffusion Models with Finite Noisy Datasets","abstract":"Recent diffusion-based generative models achieve remarkable results by training on massive datasets, yet this practice raises concerns about memorization and copyright infringement. A proposed remedy is to train exclusively on noisy data with potential copyright issues, ensuring the model never observes original content. However, through the lens of deconvolution theory, we show that although it is theoretically feasible to learn the data distribution from noisy samples, the practical challenge of collecting sufficient samples makes successful learning nearly unattainable. To overcome this limitation, we propose to pretrain the model with a small fraction of clean data to guide the deconvolution process. Combined with our Stochastic Forward--Backward Deconvolution (SFBD) method, we attain FID 6.31 on CIFAR-10 with just 4% clean images (and 3.58 with 10%). We also provide theoretical guarantees that SFBD learns the true data distribution. These results underscore the value of limited clean pretraining, or pretraining on similar datasets. Empirical studies further validate and enrich our findings.","authors":["Haoye Lu","Qifan Wu","Yaoliang Yu"],"url":"https://arxiv.org/abs/2502.05446"}
{"created":"2025-06-04","title":"On the query complexity of sampling from non-log-concave distributions","abstract":"We study the problem of sampling from a $d$-dimensional distribution with density $p(x)\\propto e^{-f(x)}$, which does not necessarily satisfy good isoperimetric conditions.","authors":["Yuchen He","Chihao Zhang"],"url":"https://arxiv.org/abs/2502.06200"}
{"created":"2025-06-04","title":"Logits are All We Need to Adapt Closed Models","abstract":"Many commercial Large Language Models (LLMs) are often closed-source, limiting developers to prompt tuning for aligning content generation with specific applications. While these models currently do not provide access to token logits, we argue that if such access were available, it would enable more powerful adaptation techniques beyond prompt engineering. In this paper, we propose a token-level probability reweighting framework that, given access to logits and a small amount of task-specific data, can effectively steer black-box LLMs toward application-specific content generation. Our approach views next-token prediction through the lens of supervised classification. We show that aligning black-box LLMs with task-specific data can be formulated as a label noise correction problem, leading to Plugin model -- an autoregressive probability reweighting model that operates solely on logits. We provide theoretical justification for why reweighting logits alone is sufficient for task adaptation. Extensive experiments with multiple datasets, LLMs, and reweighting models demonstrate the effectiveness of our method, advocating for broader access to token logits in closed-source models.","authors":["Gaurush Hiranandani","Haolun Wu","Subhojyoti Mukherjee","Sanmi Koyejo"],"url":"https://arxiv.org/abs/2502.06806"}
{"created":"2025-06-04","title":"Curvature Tuning: Provable Training-free Model Steering From a Single Parameter","abstract":"The scaling of model and data sizes has reshaped the AI landscape, establishing finetuning pretrained models as the standard paradigm for solving downstream tasks. However, dominant finetuning methods typically rely on weight adaptation, often lack interpretability, and depend on heuristically chosen hyperparameters. In this paper, we take a different perspective and shift the focus from weights to activation functions, viewing them through the lens of spline operators. We propose Curvature Tuning (CT), an interpretable and principled steering method that modulates a model's decision boundary by injecting a single hyperparameter into its activation functions. We show that CT provably adjusts model decision boundary curvature and, more fundamentally, projects a model onto a space of smooth functions-thereby complementing current finetuning methods, whose effect lies primarily in feature adaptation. Making this hyperparameter trainable gives rise to a novel and highly parameter-efficient finetuning method. Empirically, CT improves both generalization and robustness. For example, it boosts downstream accuracy of ResNet-50/152 by 7.14%/8.46% over linear probing and 4.64%/1.70% over LoRA across 12 datasets, and improves robust accuracy on the $\\ell_\\infty$ benchmark from RobustBench by 1032.64%/1494.46%. Our code is available at https://github.com/Leon-Leyang/curvature-tuning.","authors":["Leyang Hu","Matteo Gamba","Randall Balestriero"],"url":"https://arxiv.org/abs/2502.07783"}
{"created":"2025-06-04","title":"Inference-time sparse attention with asymmetric indexing","abstract":"Self-attention in transformer models is an incremental associative memory that maps key vectors to value vectors. One way to speed up self-attention is to employ GPU-compatible vector search algorithms based on standard partitioning methods such as k-means. However, such partitioning methods yield poor results in this context because (1) the keys and queries follow different distributions, and (2) the RoPE positional encoding hinders the bucket assignment.","authors":["Pierre-Emmanuel Mazar\\'e","Gergely Szilvasy","Maria Lomeli","Francisco Massa","Naila Murray","Herv\\'e J\\'egou","Matthijs Douze"],"url":"https://arxiv.org/abs/2502.08246"}
{"created":"2025-06-04","title":"KET-RAG: A Cost-Efficient Multi-Granular Indexing Framework for Graph-RAG","abstract":"Graph-RAG constructs a knowledge graph from text chunks to improve retrieval in Large Language Model (LLM)-based question answering. It is particularly useful in domains such as biomedicine, law, and political science, where retrieval often requires multi-hop reasoning over proprietary documents. Some existing Graph-RAG systems construct KNN graphs based on text chunk relevance, but this coarse-grained approach fails to capture entity relationships within texts, leading to sub-par retrieval and generation quality. To address this, recent solutions leverage LLMs to extract entities and relationships from text chunks, constructing triplet-based knowledge graphs. However, this approach incurs significant indexing costs, especially for large document collections.","authors":["Yiqian Huang","Shiqi Zhang","Xiaokui Xiao"],"url":"https://arxiv.org/abs/2502.09304"}
{"created":"2025-06-04","title":"LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)","abstract":"Low-rank adaptation (LoRA) has become a standard approach for fine-tuning large foundation models. However, our theoretical understanding of LoRA remains limited as prior analyses of LoRA's training dynamics either rely on linearization arguments or consider highly simplified setups. In this work, we analyze the LoRA loss landscape without such restrictive assumptions. We define two regimes: a \"special regime\", which includes idealized setups where linearization arguments hold, and a \"generic regime\" representing more realistic setups where linearization arguments do not hold. In the generic regime, we show that LoRA training converges to a global minimizer with low rank and small magnitude, or a qualitatively distinct solution with high rank and large magnitude. Finally, we argue that the zero-initialization and weight decay in LoRA training induce an implicit bias toward the low-rank, small-magnitude region of the parameter space -- where global minima lie -- thus shedding light on why LoRA training usually succeeds in finding global minima.","authors":["Junsu Kim","Jaeyeon Kim","Ernest K. Ryu"],"url":"https://arxiv.org/abs/2502.09376"}
{"created":"2025-06-04","title":"Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?","abstract":"One of the goals of automatic evaluation metrics in grammatical error correction (GEC) is to rank GEC systems such that it matches human preferences. However, current automatic evaluations are based on procedures that diverge from human evaluation. Specifically, human evaluation derives rankings by aggregating sentence-level relative evaluation results, e.g., pairwise comparisons, using a rating algorithm, whereas automatic evaluation averages sentence-level absolute scores to obtain corpus-level scores, which are then sorted to determine rankings. In this study, we propose an aggregation method for existing automatic evaluation metrics which aligns with human evaluation methods to bridge this gap. We conducted experiments using various metrics, including edit-based metrics, n-gram based metrics, and sentence-level metrics, and show that resolving the gap improves results for the most of metrics on the SEEDA benchmark. We also found that even BERT-based metrics sometimes outperform the metrics of GPT-4. The proposed ranking method is integrated gec-metrics.","authors":["Takumi Goto","Yusuke Sakai","Taro Watanabe"],"url":"https://arxiv.org/abs/2502.09416"}
{"created":"2025-06-04","title":"ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) has proven effective in integrating external knowledge into large language models (LLMs) for solving question-answer (QA) tasks. The state-of-the-art RAG approaches often use the graph data as the external data since they capture the rich semantic information and link relationships between entities. However, existing graph-based RAG approaches cannot accurately identify the relevant information from the graph and also consume large numbers of tokens in the online retrieval process. To address these issues, we introduce a novel graph-based RAG approach, called Attributed Community-based Hierarchical RAG (ArchRAG), by augmenting the question using attributed communities, and also introducing a novel LLM-based hierarchical clustering method. To retrieve the most relevant information from the graph for the question, we build a novel hierarchical index structure for the attributed communities and develop an effective online retrieval method. Experimental results demonstrate that ArchRAG outperforms existing methods in both accuracy and token cost. Moreover, ArchRAG has been successfully applied to domain knowledge QA in Huawei Cloud Computing.","authors":["Shu Wang","Yixiang Fang","Yingli Zhou","Xilin Liu","Yuchi Ma"],"url":"https://arxiv.org/abs/2502.09891"}
{"created":"2025-06-04","title":"The underlying structures of self-attention: symmetry, directionality, and emergent dynamics in Transformer training","abstract":"Self-attention is essential to Transformer architectures, yet how information is embedded in the self-attention matrices and how different objective functions impact this process remains unclear. We present a mathematical framework to analyze self-attention matrices by deriving the structures governing their weight updates. Using this framework, we demonstrate that bidirectional training induces symmetry in the weight matrices, while autoregressive training results in directionality and column dominance. Our theoretical findings are validated across multiple Transformer models - including ModernBERT, GPT, LLaMA3, and Mistral - and input modalities like text, vision, and audio. Finally, we apply these insights by showing that symmetric initialization improves the performance of encoder-only models on language tasks. This mathematical analysis offers a novel theoretical perspective on how information is embedded through self-attention, thereby improving the interpretability of Transformer models.","authors":["Matteo Saponati","Pascal Sager","Pau Vilimelis Aceituno","Thilo Stadelmann","Benjamin Grewe"],"url":"https://arxiv.org/abs/2502.10927"}
{"created":"2025-06-04","title":"Akan Cinematic Emotions (ACE): A Multimodal Multi-party Dataset for Emotion Recognition in Movie Dialogues","abstract":"In this paper, we introduce the Akan Conversation Emotion (ACE) dataset, the first multimodal emotion dialogue dataset for an African language, addressing the significant lack of resources for low-resource languages in emotion recognition research. ACE, developed for the Akan language, contains 385 emotion-labeled dialogues and 6,162 utterances across audio, visual, and textual modalities, along with word-level prosodic prominence annotations. The presence of prosodic labels in this dataset also makes it the first prosodically annotated African language dataset. We demonstrate the quality and utility of ACE through experiments using state-of-the-art emotion recognition methods, establishing solid baselines for future research. We hope ACE inspires further work on inclusive, linguistically and culturally diverse NLP resources.","authors":["David Sasu","Zehui Wu","Ziwei Gong","Run Chen","Pengyuan Shi","Lin Ai","Julia Hirschberg","Natalie Schluter"],"url":"https://arxiv.org/abs/2502.10973"}
{"created":"2025-06-04","title":"Exposing Numeracy Gaps: A Benchmark to Evaluate Fundamental Numerical Abilities in Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated impressive capabilities in natural language processing tasks, such as text generation and semantic understanding. However, their performance on numerical reasoning tasks, such as basic arithmetic, numerical retrieval, and magnitude comparison, remains surprisingly poor. This gap arises from their reliance on surface-level statistical patterns rather than understanding numbers as continuous magnitudes. Existing benchmarks primarily focus on either linguistic competence or structured mathematical problem-solving, neglecting fundamental numerical reasoning required in real-world scenarios. To bridge this gap, we propose NumericBench, a comprehensive benchmark to evaluate six fundamental numerical capabilities: number recognition, arithmetic operations, contextual retrieval, comparison, summary, and logical reasoning. NumericBench includes datasets ranging from synthetic number lists to the crawled real-world data, addressing challenges like long contexts, noise, and multi-step reasoning. Extensive experiments on state-of-the-art LLMs, including GPT-4 and DeepSeek, reveal persistent weaknesses in numerical reasoning, highlighting the urgent need to improve numerically-aware language modeling. The benchmark is released in: https://github.com/TreeAI-Lab/NumericBench.","authors":["Haoyang Li","Xuejia Chen","Zhanchao XU","Darian Li","Nicole Hu","Fei Teng","Yiming Li","Luyu Qiu","Chen Jason Zhang","Qing Li","Lei Chen"],"url":"https://arxiv.org/abs/2502.11075"}
{"created":"2025-06-04","title":"Can't See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs","abstract":"Multimodal Large Language Models (MLLMs) have expanded the capabilities of traditional language models by enabling interaction through both text and images. However, ensuring the safety of these models remains a significant challenge, particularly in accurately identifying whether multimodal content is safe or unsafe-a capability we term safety awareness. In this paper, we introduce MMSafeAware, the first comprehensive multimodal safety awareness benchmark designed to evaluate MLLMs across 29 safety scenarios with 1500 carefully curated image-prompt pairs. MMSafeAware includes both unsafe and over-safety subsets to assess models abilities to correctly identify unsafe content and avoid over-sensitivity that can hinder helpfulness. Evaluating nine widely used MLLMs using MMSafeAware reveals that current models are not sufficiently safe and often overly sensitive; for example, GPT-4V misclassifies 36.1% of unsafe inputs as safe and 59.9% of benign inputs as unsafe. We further explore three methods to improve safety awareness-prompting-based approaches, visual contrastive decoding, and vision-centric reasoning fine-tuning-but find that none achieve satisfactory performance. Our findings highlight the profound challenges in developing MLLMs with robust safety awareness, underscoring the need for further research in this area. All the code and data will be publicly available to facilitate future research.","authors":["Wenxuan Wang","Xiaoyuan Liu","Kuiyi Gao","Jen-tse Huang","Youliang Yuan","Pinjia He","Shuai Wang","Zhaopeng Tu"],"url":"https://arxiv.org/abs/2502.11184"}
{"created":"2025-06-04","title":"Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points","abstract":"Code generation models have shown significant potential for automating programming tasks. However, the challenge of generating accurate and reliable code persists due to the highly complex and long-reasoning nature of the task. Even state-of-the-art models often fail in code generation due to small errors, which can drastically affect the overall functionality of code. Our study identifies that current models tend to produce errors concentrated at specific error-prone points, which significantly impacts the accuracy of the generated code. To address this issue, we introduce Focused-DPO, a framework that enhances code generation by directing preference optimization towards these critical error-prone areas. This approach builds on Direct Preference Optimization, emphasizing accuracy in parts prone to errors. Additionally, we develop a method called Error-Point Identification, which constructs a dataset that targets these problematic points without requiring costly human annotations. Our experiments on benchmarks such as HumanEval(+), MBPP(+), and LiveCodeBench demonstrate that Focused-DPO significantly improves the precision and reliability of code generation, reducing common errors and enhancing overall code quality. By focusing on error-prone points, Focused-DPO advances the accuracy and functionality of model-generated code.","authors":["Kechi Zhang","Ge Li","Jia Li","Yihong Dong","Jia Li","Zhi Jin"],"url":"https://arxiv.org/abs/2502.11475"}
{"created":"2025-06-04","title":"Evolving Hard Maximum Cut Instances for Quantum Approximate Optimization Algorithms","abstract":"Variational quantum algorithms, such as the Recursive Quantum Approximate Optimization Algorithm (RQAOA), have become increasingly popular, offering promising avenues for employing Noisy Intermediate-Scale Quantum devices to address challenging combinatorial optimization tasks like the maximum cut problem. In this study, we utilize an evolutionary algorithm equipped with a unique fitness function. This approach targets hard maximum cut instances within the latent space of a Graph Autoencoder, identifying those that pose significant challenges or are particularly tractable for RQAOA, in contrast to the classic Goemans and Williamson algorithm. Our findings not only delineate the distinct capabilities and limitations of each algorithm but also expand our understanding of RQAOA's operational limits. Furthermore, the diverse set of graphs we have generated serves as a crucial benchmarking asset, emphasizing the need for more advanced algorithms to tackle combinatorial optimization challenges. Additionally, our results pave the way for new avenues in graph generation research, offering exciting opportunities for future explorations.","authors":["Shuaiqun Pan","Yash J. Patel","Aneta Neumann","Frank Neumann","Thomas B\\\"ack","Hao Wang"],"url":"https://arxiv.org/abs/2502.12012"}
{"created":"2025-06-04","title":"ViFOR: A Fourier-Enhanced Vision Transformer for Multi-Image Super-Resolution in Earth System","abstract":"Super-resolution (SR) is crucial for enhancing the spatial resolution of Earth System Model (ESM) data, thereby enabling more precise analysis of environmental processes. This paper introduces ViFOR, a novel SR algorithm integrating Vision Transformers (ViTs) with Fourier-based Implicit Neural Representation Networks (INRs). ViFOR effectively captures global context and high-frequency details essential for accurate SR reconstruction by embedding Fourier-based activation functions within the transformer architecture. Extensive experiments demonstrate that ViFOR consistently outperforms state-of-the-art methods, including ViT, SIREN, and SRGANs, in terms of Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE) for both global and local imagery. ViFOR achieves PSNR improvements of up to 4.18 dB, 1.56 dB, and 1.73 dB over ViT on full-image Source Temperature, Shortwave, and Longwave Flux datasets. These results highlight ViFOR's effectiveness and potential for advancing high-resolution climate data analysis.","authors":["Ehsan Zeraatkar","Salah A Faroughi","Jelena Te\\v{s}i\\'c"],"url":"https://arxiv.org/abs/2502.12427"}
{"created":"2025-06-04","title":"SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings","abstract":"Multimodal Large Language Models (MLLMs) have serious security vulnerabilities.While safety alignment using multimodal datasets consisting of text and data of additional modalities can effectively enhance MLLM's security, it is costly to construct these datasets. Existing low-resource security alignment methods, including textual alignment, have been found to struggle with the security risks posed by additional modalities. To address this, we propose Synthetic Embedding augmented safety Alignment (SEA), which optimizes embeddings of additional modality through gradient updates to expand textual datasets. This enables multimodal safety alignment training even when only textual data is available. Extensive experiments on image, video, and audio-based MLLMs demonstrate that SEA can synthesize a high-quality embedding on a single RTX3090 GPU within 24 seconds. SEA significantly improves the security of MLLMs when faced with threats from additional modalities. To assess the security risks introduced by video and audio, we also introduced a new benchmark called VA-SafetyBench. High attack success rates across multiple MLLMs validate its challenge. Our code and data will be available at https://github.com/ZeroNLP/SEA.","authors":["Weikai Lu","Hao Peng","Huiping Zhuang","Cen Chen","Ziqian Zeng"],"url":"https://arxiv.org/abs/2502.12562"}
{"created":"2025-06-04","title":"A$^2$ATS: Retrieval-Based KV Cache Reduction via Windowed Rotary Position Embedding and Query-Aware Vector Quantization","abstract":"Long context large language models (LLMs) pose significant challenges for efficient serving due to the large memory footprint and high access overhead of KV cache. Retrieval-based KV cache reduction methods can mitigate these challenges, typically by offloading the complete KV cache to CPU and retrieving necessary tokens on demand during inference. However, these methods still suffer from unsatisfactory accuracy degradation and extra retrieval overhead. To address these limitations, this paper proposes A$^2$ATS, a novel retrieval-based KV cache reduction method. A$^2$ATS aims to obtain an accurate approximation of attention scores by applying the vector quantization technique to key states, thereby enabling efficient and precise retrieval of the top-K tokens. First, we propose Windowed Rotary Position Embedding, which decouples the positional dependency from query and key states after position embedding. Then, we propose query-aware vector quantization that optimizes the objective of attention score approximation directly. Finally, we design the heterogeneous inference architecture for KV cache offloading, enabling long context serving with larger batch sizes. Experimental results demonstrate that A$^2$ATS can achieve a lower performance degradation with similar or lower overhead compared to existing methods, thereby increasing long context serving throughput by up to $2.7 \\times$.","authors":["Junhui He","Junna Xing","Nan Wang","Rui Xu","Shangyu Wu","Peng Zhou","Qiang Liu","Chun Jason Xue","Qingan Li"],"url":"https://arxiv.org/abs/2502.12665"}
{"created":"2025-06-04","title":"Q-STRUM Debate: Query-Driven Contrastive Summarization for Recommendation Comparison","abstract":"Query-driven recommendation with unknown items poses a challenge for users to understand why certain items are appropriate for their needs. Query-driven Contrastive Summarization (QCS) is a methodology designed to address this issue by leveraging language-based item descriptions to clarify contrasts between them. However, existing state-of-the-art contrastive summarization methods such as STRUM-LLM fall short of this goal. To overcome these limitations, we introduce Q-STRUM Debate, a novel extension of STRUM-LLM that employs debate-style prompting to generate focused and contrastive summarizations of item aspects relevant to a query. Leveraging modern large language models (LLMs) as powerful tools for generating debates, Q-STRUM Debate provides enhanced contrastive summaries. Experiments across three datasets demonstrate that Q-STRUM Debate yields significant performance improvements over existing methods on key contrastive summarization criteria, thus introducing a novel and performant debate prompting methodology for QCS.","authors":["George-Kirollos Saad","Scott Sanner"],"url":"https://arxiv.org/abs/2502.12921"}
{"created":"2025-06-04","title":"Unveiling Privacy Risks in LLM Agent Memory","abstract":"Large Language Model (LLM) agents have become increasingly prevalent across various real-world applications. They enhance decision-making by storing private user-agent interactions in the memory module for demonstrations, introducing new privacy risks for LLM agents. In this work, we systematically investigate the vulnerability of LLM agents to our proposed Memory EXTRaction Attack (MEXTRA) under a black-box setting. To extract private information from memory, we propose an effective attacking prompt design and an automated prompt generation method based on different levels of knowledge about the LLM agent. Experiments on two representative agents demonstrate the effectiveness of MEXTRA. Moreover, we explore key factors influencing memory leakage from both the agent designer's and the attacker's perspectives. Our findings highlight the urgent need for effective memory safeguards in LLM agent design and deployment.","authors":["Bo Wang","Weiyi He","Shenglai Zeng","Zhen Xiang","Yue Xing","Jiliang Tang","Pengfei He"],"url":"https://arxiv.org/abs/2502.13172"}
{"created":"2025-06-04","title":"Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images","abstract":"Recent studies have shown that Large Vision-Language Models (VLMs) tend to neglect image content and over-rely on language-model priors, resulting in errors in visually grounded tasks and hallucinations. We hypothesize that this issue arises because existing VLMs are not explicitly trained to generate texts that are accurately grounded in fine-grained image details. To enhance visual feedback during VLM training, we propose S-VCO (Symmetrical Visual Contrastive Optimization), a novel finetuning objective that steers the model toward capturing important visual details and aligning them with corresponding text tokens. To further facilitate this detailed alignment, we introduce MVC, a paired image-text dataset built by automatically filtering and augmenting visual counterfactual data to challenge the model with hard contrastive cases involving Minimal Visual Contrasts. Experiments show that our method consistently improves VLM performance across diverse benchmarks covering various abilities and domains, achieving up to a 22% reduction in hallucinations, and significant gains in vision-centric and general tasks. Notably, these improvements become increasingly pronounced in benchmarks with higher visual dependency. In short, S-VCO offers a significant enhancement of VLM's visually-dependent task performance while retaining or even improving the model's general abilities. We opensource our code at https://s-vco.github.io/","authors":["Shengguang Wu","Fan-Yun Sun","Kaiyue Wen","Nick Haber"],"url":"https://arxiv.org/abs/2502.13928"}
{"created":"2025-06-04","title":"Self-Improvement Towards Pareto Optimality: Mitigating Preference Conflicts in Multi-Objective Alignment","abstract":"Multi-Objective Alignment (MOA) aims to align LLMs' responses with multiple human preference objectives, with Direct Preference Optimization (DPO) emerging as a prominent approach. However, we find that DPO-based MOA approaches suffer from widespread preference conflicts in the data, where different objectives favor different responses. This results in conflicting optimization directions, hindering the optimization on the Pareto Front. To address this, we propose to construct Pareto-optimal responses to resolve preference conflicts. To efficiently obtain and utilize such responses, we propose a self-improving DPO framework that enables LLMs to self-generate and select Pareto-optimal responses for self-supervised preference alignment. Extensive experiments on two datasets demonstrate the superior Pareto Front achieved by our framework compared to various baselines. Code is available at https://github.com/zyttt-coder/SIPO.","authors":["Moxin Li","Yuantao Zhang","Wenjie Wang","Wentao Shi","Zhuo Liu","Fuli Feng","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2502.14354"}
{"created":"2025-06-04","title":"A Similarity Paradigm Through Textual Regularization Without Forgetting","abstract":"Prompt learning has emerged as a promising method for adapting pre-trained visual-language models (VLMs) to a range of downstream tasks. While optimizing the context can be effective for improving performance on specific tasks, it can often lead to poor generalization performance on unseen classes or datasets sampled from different distributions. It may be attributed to the fact that textual prompts tend to overfit downstream data distributions, leading to the forgetting of generalized knowledge derived from hand-crafted prompts. In this paper, we propose a novel method called Similarity Paradigm with Textual Regularization (SPTR) for prompt learning without forgetting. SPTR is a two-pronged design based on hand-crafted prompts that is an inseparable framework. 1) To avoid forgetting general textual knowledge, we introduce the optimal transport as a textual regularization to finely ensure approximation with hand-crafted features and tuning textual features. 2) In order to continuously unleash the general ability of multiple hand-crafted prompts, we propose a similarity paradigm for natural alignment score and adversarial alignment score to improve model robustness for generalization. Both modules share a common objective in addressing generalization issues, aiming to maximize the generalization capability derived from multiple hand-crafted prompts. Four representative tasks (i.e., non-generalization few-shot learning, base-to-novel generalization, cross-dataset generalization, domain generalization) across 11 datasets demonstrate that SPTR outperforms existing prompt learning methods.","authors":["Fangming Cui","Jan Fong","Rongfei Zeng","Xinmei Tian","Jun Yu"],"url":"https://arxiv.org/abs/2502.14376"}
{"created":"2025-06-04","title":"DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image Generation with Diffusion Models","abstract":"In this paper, we introduce DC (Decouple)-ControlNet, a highly flexible and precisely controllable framework for multi-condition image generation. The core idea behind DC-ControlNet is to decouple control conditions, transforming global control into a hierarchical system that integrates distinct elements, contents, and layouts. This enables users to mix these individual conditions with greater flexibility, leading to more efficient and accurate image generation control. Previous ControlNet-based models rely solely on global conditions, which affect the entire image and lack the ability of element- or region-specific control. This limitation reduces flexibility and can cause condition misunderstandings in multi-conditional image generation. To address these challenges, we propose both intra-element and Inter-element Controllers in DC-ControlNet. The Intra-Element Controller handles different types of control signals within individual elements, accurately describing the content and layout characteristics of the object. For interactions between elements, we introduce the Inter-Element Controller, which accurately handles multi-element interactions and occlusion based on user-defined relationships. Extensive evaluations show that DC-ControlNet significantly outperforms existing ControlNet models and Layout-to-Image generative models in terms of control flexibility and precision in multi-condition control. Our project website is available at: https://um-lab.github.io/DC-ControlNet/","authors":["Hongji Yang","Wencheng Han","Yucheng Zhou","Jianbing Shen"],"url":"https://arxiv.org/abs/2502.14779"}
{"created":"2025-06-04","title":"Social Genome: Grounded Social Reasoning Abilities of Multimodal Models","abstract":"Social reasoning abilities are crucial for AI systems to effectively interpret and respond to multimodal human communication and interaction within social contexts. We introduce SOCIAL GENOME, the first benchmark for fine-grained, grounded social reasoning abilities of multimodal models. SOCIAL GENOME contains 272 videos of interactions and 1,486 human-annotated reasoning traces related to inferences about these interactions. These traces contain 5,777 reasoning steps that reference evidence from visual cues, verbal cues, vocal cues, and external knowledge (contextual knowledge external to videos). SOCIAL GENOME is also the first modeling challenge to study external knowledge in social reasoning. SOCIAL GENOME computes metrics to holistically evaluate semantic and structural qualities of model-generated social reasoning traces. We demonstrate the utility of SOCIAL GENOME through experiments with state-of-the-art models, identifying performance gaps and opportunities for future research to improve the grounded social reasoning abilities of multimodal models.","authors":["Leena Mathur","Marian Qian","Paul Pu Liang","Louis-Philippe Morency"],"url":"https://arxiv.org/abs/2502.15109"}
{"created":"2025-06-04","title":"A Mousetrap: Fooling Large Reasoning Models for Jailbreak with Chain of Iterative Chaos","abstract":"Large Reasoning Models (LRMs) have significantly advanced beyond traditional Large Language Models (LLMs) with their exceptional logical reasoning capabilities, yet these improvements introduce heightened safety risks. When subjected to jailbreak attacks, their ability to generate more targeted and organized content can lead to greater harm. Although some studies claim that reasoning enables safer LRMs against existing LLM attacks, they overlook the inherent flaws within the reasoning process itself. To address this gap, we propose the first jailbreak attack targeting LRMs, exploiting their unique vulnerabilities stemming from the advanced reasoning capabilities. Specifically, we introduce a Chaos Machine, a novel component to transform attack prompts with diverse one-to-one mappings. The chaos mappings iteratively generated by the machine are embedded into the reasoning chain, which strengthens the variability and complexity and also promotes a more robust attack. Based on this, we construct the Mousetrap framework, which makes attacks projected into nonlinear-like low sample spaces with mismatched generalization enhanced. Also, due to the more competing objectives, LRMs gradually maintain the inertia of unpredictable iterative reasoning and fall into our trap. Success rates of the Mousetrap attacking o1-mini, Claude-Sonnet and Gemini-Thinking are as high as 96%, 86% and 98% respectively on our toxic dataset Trotter. On benchmarks such as AdvBench, StrongREJECT, and HarmBench, attacking Claude-Sonnet, well-known for its safety, Mousetrap can astonishingly achieve success rates of 87.5%, 86.58% and 93.13% respectively. Attention: This paper contains inappropriate, offensive and harmful content.","authors":["Yang Yao","Xuan Tong","Ruofan Wang","Yixu Wang","Lujundong Li","Liang Liu","Yan Teng","Yingchun Wang"],"url":"https://arxiv.org/abs/2502.15806"}
{"created":"2025-06-04","title":"Concept Corrector: Erase concepts on the fly for text-to-image diffusion models","abstract":"Text-to-image diffusion models have demonstrated the underlying risk of generating various unwanted content, such as sexual elements. To address this issue, the task of concept erasure has been introduced, aiming to erase any undesired concepts that the models can generate. Previous methods, whether training-based or training-free, have primarily focused on the input side, i.e., texts. However, they often suffer from incomplete erasure due to limitations in the generalization from limited prompts to diverse image content. In this paper, motivated by the notion that concept erasure on the output side, i.e., generated images, may be more direct and effective, we propose Concept Corrector. It checks target concepts based on visual features provided by final generated images predicted at certain time steps. Further, it incorporates Concept Removal Attention to erase generated concept features. It overcomes the limitations of existing methods, which are either unable to remove the concept features that have been generated in images or rely on the assumption that the related concept words are contained in input prompts. In the whole pipeline, our method changes no model parameters and only requires a given target concept as well as the corresponding replacement content, which is easy to implement. To the best of our knowledge, this is the first erasure method based on intermediate-generated images, achieving the ability to erase concepts on the fly. The experiments on various concepts demonstrate its impressive erasure performance.","authors":["Zheling Meng","Bo Peng","Xiaochuan Jin","Yueming Lyu","Wei Wang","Jing Dong","Tieniu Tan"],"url":"https://arxiv.org/abs/2502.16368"}
{"created":"2025-06-04","title":"Improved Margin Generalization Bounds for Voting Classifiers","abstract":"In this paper we establish a new margin-based generalization bound for voting classifiers, refining existing results and yielding tighter generalization guarantees for widely used boosting algorithms such as AdaBoost (Freund and Schapire, 1997). Furthermore, the new margin-based generalization bound enables the derivation of an optimal weak-to-strong learner: a Majority-of-3 large-margin classifiers with an expected error matching the theoretical lower bound. This result provides a more natural alternative to the Majority-of-5 algorithm by (H{\\o}gsgaard et al., 2024), and matches the Majority-of-3 result by (Aden-Ali et al., 2024) for the realizable prediction model.","authors":["Mikael M{\\o}ller H{\\o}gsgaard","Kasper Green Larsen"],"url":"https://arxiv.org/abs/2502.16462"}
{"created":"2025-06-04","title":"Grounded Persuasive Language Generation for Automated Marketing","abstract":"This paper develops an agentic framework that employs large language models (LLMs) to automate the generation of persuasive and grounded marketing content, using real estate listing descriptions as our focal application domain. Our method is designed to align the generated content with user preferences while highlighting useful factual attributes. This agent consists of three key modules: (1) Grounding Module, mimicking expert human behavior to predict marketable features; (2) Personalization Module, aligning content with user preferences; (3) Marketing Module, ensuring factual accuracy and the inclusion of localized features. We conduct systematic human-subject experiments in the domain of real estate marketing, with a focus group of potential house buyers. The results demonstrate that marketing descriptions generated by our approach are preferred over those written by human experts by a clear margin while maintaining the same level of factual accuracy. Our findings suggest a promising agentic approach to automate large-scale targeted marketing while ensuring factuality of content generation.","authors":["Jibang Wu","Chenghao Yang","Simon Mahns","Chaoqi Wang","Hao Zhu","Fei Fang","Haifeng Xu"],"url":"https://arxiv.org/abs/2502.16810"}
{"created":"2025-06-04","title":"Regular singular Mahler equations and Newton polygons","abstract":"Though Mahler equations have been introduced nearly one century ago, the study of their solutions is still a fruitful topic for research. In particular, the Galois theory of Mahler equations has been the subject of many recent papers. Nevertheless, long is the way to a complete understanding of relations between solutions of Mahler equations. One step along this way is the study of singularities. Mahler equations with a regular singularity at 0 have rather \"nice\" solutions: they can be expressed with the help of Puiseux series and solutions of equations with constant coefficients. In a previous paper, the authors described an algorithm to determine whether an equation is regular singular at 0 or not. Exploiting information from the Frobenius method and Newton polygons, we improve this algorithm by significantly reducing its complexity, by providing some simple criterion for an equation to be regular singular at 0, and by extending its scope to equations with Puiseux coefficients.","authors":["Colin Faverjon (ICJ","CTN)","Marina Poulet (IF)"],"url":"https://arxiv.org/abs/2502.16975"}
{"created":"2025-06-04","title":"Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation","abstract":"The exponential rise in mobile device usage necessitates streamlined automation for effective task management, yet many AI frameworks fall short due to inadequate operational expertise. While manually written knowledge can bridge this gap, it is often burdensome and inefficient. We introduce Mobile-Agent-V, an innovative framework that utilizes video as a guiding tool to effortlessly and efficiently inject operational knowledge into mobile automation processes. By deriving knowledge directly from video content, Mobile-Agent-V eliminates manual intervention, significantly reducing the effort and time required for knowledge acquisition. To rigorously evaluate this approach, we propose Mobile-Knowledge, a benchmark tailored to assess the impact of external knowledge on mobile agent performance. Our experimental findings demonstrate that Mobile-Agent-V enhances performance by 36% compared to existing methods, underscoring its effortless and efficient advantages in mobile automation.","authors":["Junyang Wang","Haiyang Xu","Xi Zhang","Ming Yan","Ji Zhang","Fei Huang","Jitao Sang"],"url":"https://arxiv.org/abs/2505.13887"}
{"created":"2025-06-04","title":"CoT-UQ: Improving Response-wise Uncertainty Quantification in LLMs with Chain-of-Thought","abstract":"Large language models (LLMs) excel in many tasks but struggle to accurately quantify uncertainty in their generated responses. This limitation makes it challenging to detect misinformation and ensure reliable decision-making. Existing uncertainty quantification (UQ) methods for LLMs are primarily prompt-wise rather than response-wise, often requiring multiple response samples, which incurs high computational costs. Moreover, LLMs have been shown to be overconfident, particularly when using reasoning steps to derive their answers. In this work, we propose CoT-UQ, a response-wise UQ framework that integrates LLMs' inherent reasoning capabilities through Chain-of-Thought (CoT) into the UQ process. CoT-UQ captures critical information during inference by extracting keywords from each reasoning step and assessing their importance to the final answer. This key reasoning information is then aggregated to produce a final uncertainty estimate. We conduct extensive experiments based on Llama Family with model sizes varying from 8B to 13B across logical and mathematical reasoning tasks. Experimental results demonstrate that CoT-UQ significantly outperforms existing UQ methods, achieving an average improvement of 5.9% AUROC compared to current UQ methods. The code is available at: https://github.com/ZBox1005/CoT-UQ.","authors":["Boxuan Zhang","Ruqi Zhang"],"url":"https://arxiv.org/abs/2502.17214"}
{"created":"2025-06-04","title":"Towards Enhanced Immersion and Agency for LLM-based Interactive Drama","abstract":"LLM-based Interactive Drama is a novel AI-based dialogue scenario, where the user (i.e. the player) plays the role of a character in the story, has conversations with characters played by LLM agents, and experiences an unfolding story. This paper begins with understanding interactive drama from two aspects: Immersion, the player's feeling of being present in the story, and Agency, the player's ability to influence the story world. Both are crucial to creating an enjoyable interactive experience, while they have been underexplored in previous work. To enhance these two aspects, we first propose Playwriting-guided Generation, a novel method that helps LLMs craft dramatic stories with substantially improved structures and narrative quality. Additionally, we introduce Plot-based Reflection for LLM agents to refine their reactions to align with the player's intentions. Our evaluation relies on human judgment to assess the gains of our methods in terms of immersion and agency.","authors":["Hongqiu Wu","Weiqi Wu","Tianyang Xu","Jiameng Zhang","Hai Zhao"],"url":"https://arxiv.org/abs/2502.17878"}
{"created":"2025-06-04","title":"ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents","abstract":"Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehension, and reasoning within dense visual documents. To bridge this gap, we introduce ViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich documents requiring complex reasoning. Based on it, we identify key limitations in current RAG approaches: (i) purely visual retrieval methods struggle to effectively integrate both textual and visual features, and (ii) previous approaches often allocate insufficient reasoning tokens, limiting their effectiveness. To address these challenges, we propose ViDoRAG, a novel multi-agent RAG framework tailored for complex reasoning across visual documents. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy to effectively handle multi-modal retrieval. To further elicit the model's reasoning capabilities, we introduce an iterative agent workflow incorporating exploration, summarization, and reflection, providing a framework for investigating test-time scaling in RAG domains. Extensive experiments on ViDoSeek validate the effectiveness and generalization of our approach. Notably, ViDoRAG outperforms existing methods by over 10% on the competitive ViDoSeek benchmark. The code is available at https://github.com/Alibaba-NLP/ViDoRAG.","authors":["Qiuchen Wang","Ruixue Ding","Zehui Chen","Weiqi Wu","Shihang Wang","Pengjun Xie","Feng Zhao"],"url":"https://arxiv.org/abs/2502.18017"}
{"created":"2025-06-04","title":"DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers","abstract":"Large language models (LLMs) have demonstrated strong effectiveness and robustness while fine-tuned as dense retrievers. However, their large parameter size brings significant inference time computational challenges, including high encoding costs for large-scale corpora and increased query latency, limiting their practical deployment. While smaller retrievers offer better efficiency, they often fail to generalize effectively with limited supervised fine-tuning data. In this work, we introduce DRAMA, a training framework that leverages LLMs to train smaller generalizable dense retrievers. In particular, we adopt pruned LLMs as the backbone and train on diverse LLM-augmented data in a single-stage contrastive learning setup. Experiments show that DRAMA offers better multilingual and long-context capabilities than traditional encoder-based retrievers, and achieves strong performance across multiple tasks and languages. These highlight the potential of connecting the training of smaller retrievers with the growing advancements in LLMs, bridging the gap between efficiency and generalization.","authors":["Xueguang Ma","Xi Victoria Lin","Barlas Oguz","Jimmy Lin","Wen-tau Yih","Xilun Chen"],"url":"https://arxiv.org/abs/2502.18460"}
{"created":"2025-06-04","title":"Sampling nodes and hyperedges via random walks on large hypergraphs","abstract":"Hypergraphs provide a fundamental framework for representing complex systems involving interactions among three or more entities. As empirical hypergraphs grow in size, characterizing their structural properties becomes increasingly challenging due to computational complexity and, in some cases, restricted access to complete data, requiring efficient sampling methods. Random walks offer a practical approach to hypergraph sampling, as they rely solely on local neighborhood information from nodes and hyperedges. In this study, we investigate methods for simultaneously sampling nodes and hyperedges via random walks on large hypergraphs. First, we compare three existing random walks in the context of hypergraph sampling and identify an advantage of the so-called higher-order random walk. Second, by extending an established technique for graphs to the case of hypergraphs, we present a non-backtracking variant of the higher-order random walk. We derive theoretical results on estimators based on the non-backtracking higher-order random walk and validate them through numerical simulations on large empirical hypergraphs. Third, we apply the non-backtracking higher-order random walk to a large hypergraph of co-authorships indexed in the OpenAlex database, where full access to the data is not readily available. Despite the relatively small sample size, our estimates largely align with previous findings on author productivity, team size, and the prevalence of open-access publications. Our findings contribute to the development of analysis methods for large hypergraphs, offering insights into sampling strategies and estimation techniques applicable to real-world complex systems.","authors":["Kazuki Nakajima","Masanao Kodakari","Masaki Aida"],"url":"https://arxiv.org/abs/2502.19030"}
{"created":"2025-06-04","title":"PolyPrompt: Automating Knowledge Extraction from Multilingual Language Models with Dynamic Prompt Generation","abstract":"Large language models (LLMs) showcase increasingly impressive English benchmark scores, however their performance profiles remain inconsistent across multilingual settings. To address this gap, we introduce PolyPrompt, a novel, parameter-efficient framework for enhancing the multilingual capabilities of LLMs. Our method learns a set of trigger tokens for each language through a gradient-based search, identifying the input query's language and selecting the corresponding trigger tokens which are prepended to the prompt during inference. We perform experiments on two ~1 billion parameter models, with evaluations on the global MMLU benchmark across fifteen typologically and resource diverse languages, demonstrating accuracy gains of 3.7%-19.9% compared to naive and translation-pipeline baselines.","authors":["Nathan Roll"],"url":"https://arxiv.org/abs/2502.19756"}
{"created":"2025-06-04","title":"Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking","abstract":"Chain-of-thought (CoT) significantly enhances the performance of large language models (LLMs) across a wide range of tasks, and prior research shows that CoT can theoretically increase expressiveness. However, there is limited mechanistic understanding of the algorithms that Transformer+CoT can learn. Our key contributions are: (1) We evaluate the state tracking capabilities of Transformer+CoT and its variants, confirming the effectiveness of CoT. (2) Next, we identify the circuit (a subset of model components, responsible for tracking the world state), indicating that late-layer MLP neurons play a key role. We propose two metrics, compression and distinction, and show that the neuron sets for each state achieve nearly 100% accuracy, providing evidence of an implicit finite state automaton (FSA) embedded within the model. (3) Additionally, we explore three challenging settings: skipping intermediate steps, introducing data noises, and testing length generalization. Our results demonstrate that Transformer+CoT learns robust algorithms (FSAs), highlighting its resilience in challenging scenarios. Our code is available at https://github.com/IvanChangPKU/FSA.","authors":["Yifan Zhang","Wenyu Du","Dongming Jin","Jie Fu","Zhi Jin"],"url":"https://arxiv.org/abs/2502.20129"}
{"created":"2025-06-04","title":"Fuzzy Speculative Decoding for a Tunable Accuracy-Runtime Tradeoff","abstract":"Speculative Decoding (SD) enforces strict distributional equivalence to the target model when accepting candidate tokens. While it maintains the target model's generation quality, this strict equivalence limits the speedup achievable by SD and prevents users from trading deviations from the target distribution in exchange for further inference speed gains. To address these limitations, we introduce Fuzzy Speculative Decoding (FSD) - a decoding algorithm that generalizes SD by accepting candidate tokens based on the divergences between the target and draft model distributions. By allowing for controlled divergence from the target model, FSD enables users to flexibly trade generation quality for inference speed. Across several benchmarks, our method is able to achieve significant runtime improvements of over 5 tokens per second faster than SD at only an approximate 2% absolute reduction in benchmark accuracy. In many cases, FSD is even able to match SD benchmark accuracy at over 2 tokens per second faster, demonstrating that distributional equivalence is not necessary to maintain target model performance. Furthermore, FSD can be seamlessly integrated into existing SD extensions; we demonstrate this by applying FSD to EAGLE-2, greatly enhancing this existing extension's efficiency while allowing it to leverage FSD's tunable quality-speed trade-off.","authors":["Maximilian Holsman","Yukun Huang","Bhuwan Dhingra"],"url":"https://arxiv.org/abs/2502.20704"}
{"created":"2025-06-04","title":"Armijo Line-search Can Make (Stochastic) Gradient Descent Provably Faster","abstract":"Armijo line-search (Armijo-LS) is a standard method to set the step-size for gradient descent (GD). For smooth functions, Armijo-LS alleviates the need to know the global smoothness constant L and adapts to the ``local'' smoothness, enabling GD to converge faster. Existing theoretical analyses show that GD with Armijo-LS (GD-LS) can result in constant factor improvements over GD with a 1/L step-size (denoted as GD(1/L)). We strengthen these results and show that if the objective function satisfies a certain non-uniform smoothness condition, GD-LS can result in a faster convergence rate than GD(1/L). In particular, we prove that for convex objectives corresponding to logistic regression and multi-class classification, GD-LS can converge to the optimum at a linear rate, and hence improves over the sublinear convergence of GD(1/L). Furthermore, for non-convex objectives satisfying gradient domination (e.g., those corresponding to the softmax policy gradient in RL or generalized linear models with a logistic link function), GD-LS can match the fast convergence of algorithms tailored for these specific settings. Finally, we prove that under the interpolation assumption, for convex losses, stochastic GD with a stochastic line-search can match the fast convergence of GD-LS","authors":["Sharan Vaswani","Reza Babanezhad"],"url":"https://arxiv.org/abs/2503.00229"}
{"created":"2025-06-04","title":"Scalable Connectivity for Ising Machines: Dense to Sparse","abstract":"In recent years, hardware implementations of Ising machines have emerged as a viable alternative to quantum computing for solving hard optimization problems among other applications. Unlike quantum hardware, dense connectivity can be achieved in classical systems. However, we show that dense connectivity leads to severe frequency slowdowns and interconnect congestion scaling unfavorably with system sizes. As a scalable solution, we propose a systematic sparsification method for dense graphs by introducing copy nodes to limit the number of neighbors per graph node. In addition to solving interconnect congestion, this approach enables constant frequency scaling where all spins in a network can be updated in constant time. On the other hand, sparsification introduces new difficulties, such as constraint-breaking between copied spins and increased convergence times to solve optimization problems, especially if exact ground states are sought. Relaxing the exact solution requirements, we find that the overheads in convergence times are milder. We demonstrate these ideas by designing probabilistic bit Ising machines using ASAP7 (a predictive 7nm FinFET technology model) process design kits as well as Field Programmable Gate Array (FPGA)-based implementations. Finally, we show how formulating problems in naturally sparse networks (e.g., by invertible logic) sidesteps challenges introduced by sparsification methods. Our results are applicable to a broad family of Ising machines using different hardware implementations.","authors":["M Mahmudul Hasan Sajeeb","Navid Anjum Aadit","Shuvro Chowdhury","Tong Wu","Cesely Smith","Dhruv Chinmay","Atharva Raut","Kerem Y. Camsari","Corentin Delacour","Tathagata Srimani"],"url":"https://arxiv.org/abs/2503.01177"}
{"created":"2025-06-04","title":"Unnatural Languages Are Not Bugs but Features for LLMs","abstract":"Large Language Models (LLMs) have been observed to process non-human-readable text sequences, such as jailbreak prompts, often viewed as a bug for aligned LLMs. In this work, we present a systematic investigation challenging this perception, demonstrating that unnatural languages - strings that appear incomprehensible to humans but maintain semantic meanings for LLMs - contain latent features usable by models. Notably, unnatural languages possess latent features that can be generalized across different models and tasks during inference. Furthermore, models fine-tuned on unnatural versions of instruction datasets perform on-par with those trained on natural language, achieving 49.71 win rates in Length-controlled AlpacaEval 2.0 in average across various base models. In addition, through comprehensive analysis, we demonstrate that LLMs process unnatural languages by filtering noise and inferring contextual meaning from filtered words.","authors":["Keyu Duan","Yiran Zhao","Zhili Feng","Jinjie Ni","Tianyu Pang","Qian Liu","Tianle Cai","Longxu Dou","Kenji Kawaguchi","Anirudh Goyal","J. Zico Kolter","Michael Qizhe Shieh"],"url":"https://arxiv.org/abs/2503.01926"}
{"created":"2025-06-04","title":"Dynamic Search for Inference-Time Alignment in Diffusion Models","abstract":"Diffusion models have shown promising generative capabilities across diverse domains, yet aligning their outputs with desired reward functions remains a challenge, particularly in cases where reward functions are non-differentiable. Some gradient-free guidance methods have been developed, but they often struggle to achieve optimal inference-time alignment. In this work, we newly frame inference-time alignment in diffusion as a search problem and propose Dynamic Search for Diffusion (DSearch), which subsamples from denoising processes and approximates intermediate node rewards. It also dynamically adjusts beam width and tree expansion to efficiently explore high-reward generations. To refine intermediate decisions, DSearch incorporates adaptive scheduling based on noise levels and a lookahead heuristic function. We validate DSearch across multiple domains, including biological sequence design, molecular optimization, and image generation, demonstrating superior reward optimization compared to existing approaches.","authors":["Xiner Li","Masatoshi Uehara","Xingyu Su","Gabriele Scalia","Tommaso Biancalani","Aviv Regev","Sergey Levine","Shuiwang Ji"],"url":"https://arxiv.org/abs/2503.02039"}
{"created":"2025-06-04","title":"Four Principles for Physically Interpretable World Models","abstract":"As autonomous systems are increasingly deployed in open and uncertain settings, there is a growing need for trustworthy world models that can reliably predict future high-dimensional observations. The learned latent representations in world models lack direct mapping to meaningful physical quantities and dynamics, limiting their utility and interpretability in downstream planning, control, and safety verification. In this paper, we argue for a fundamental shift from physically informed to physically interpretable world models - and crystallize four principles that leverage symbolic knowledge to achieve these ends: (1) functionally organizing the latent space according to the physical intent, (2) learning aligned invariant and equivariant representations of the physical world, (3) integrating multiple forms and strengths of supervision into a unified training process, and (4) partitioning generative outputs to support scalability and verifiability. We experimentally demonstrate the value of each principle on two benchmarks. This paper opens several intriguing research directions to achieve and capitalize on full physical interpretability in world models.","authors":["Jordan Peper","Zhenjiang Mao","Yuang Geng","Siyuan Pan","Ivan Ruchkin"],"url":"https://arxiv.org/abs/2503.02143"}
{"created":"2025-06-04","title":"Airy Phase Functions","abstract":"It is well known that phase function methods allow for the numerical solution of a large class of oscillatory second order linear ordinary differential equations in time independent of frequency. Unfortunately, these methods break down in the commonly-occurring case in which the equation has turning points. Here, we resolve this difficulty by introducing a generalized phase function method designed for the case of second order linear ordinary differential equations with turning points. More explicitly, we prove the existence of a slowly-varying ``Airy phase function'' that efficiently represents a basis in the space of solutions of such an equation, and describe a numerical algorithm for calculating this Airy phase function. The running time of our algorithm is independent of the magnitude of the logarithmic derivatives of the equation's solutions, which is a measure of their rate of variation that generalizes the notion of frequency to functions which are rapidly varying but not necessarily oscillatory. Once the Airy phase function has been constructed, any reasonable initial or boundary value problem for the equation can be readily solved and, unlike step methods which output the values of a rapidly-varying solution on a sparse discretization grid that is insufficient for interpolation, the output of our scheme allows for the rapid evaluation of the obtained solution at any point in its domain. We rigorously justify our approach by proving not only the existence of slowly-varying Airy phase functions, but also the convergence of our numerical method. Moreover, we present the results of extensive numerical experiments demonstrating the efficacy of our algorithm.","authors":["Richard Chow","James Bremer"],"url":"https://arxiv.org/abs/2503.02306"}
{"created":"2025-06-04","title":"Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent","abstract":"Large language model (LLM) agents typically adopt a step-by-step reasoning framework, in which they interleave the processes of thinking and acting to accomplish the given task. However, this paradigm faces a deep-rooted one-pass issue whereby each generated intermediate thought is plugged into the trajectory regardless of its correctness, which can cause irreversible error propagation. To address the issue, this paper proposes a novel framework called Generator-Assistant Stepwise Rollback (GA-Rollback) to induce better decision-making for LLM agents. Particularly, GA-Rollback utilizes a generator to interact with the environment and an assistant to examine each action produced by the generator, where the assistant triggers a rollback operation upon detection of incorrect actions. Moreover, we introduce two additional strategies tailored for the rollback scenario to further improve its effectiveness. Extensive experiments show that GA-Rollback achieves significant improvements over several strong baselines on three widely used benchmarks. Our analysis further reveals that GA-Rollback can function as a robust plug-and-play module, integrating seamlessly with other methods.","authors":["Xingzuo Li","Kehai Chen","Yunfei Long","Xuefeng Bai","Yong Xu","Min Zhang"],"url":"https://arxiv.org/abs/2503.02519"}
{"created":"2025-06-04","title":"MathMistake Checker: A Comprehensive Demonstration for Step-by-Step Math Problem Mistake Finding by Prompt-Guided LLMs","abstract":"We propose a novel system, MathMistake Checker, designed to automate step-by-step mistake finding in mathematical problems with lengthy answers through a two-stage process. The system aims to simplify grading, increase efficiency, and enhance learning experiences from a pedagogical perspective. It integrates advanced technologies, including computer vision and the chain-of-thought capabilities of the latest large language models (LLMs). Our system supports open-ended grading without reference answers and promotes personalized learning by providing targeted feedback. We demonstrate its effectiveness across various types of math problems, such as calculation and word problems.","authors":["Tianyang Zhang","Zhuoxuan Jiang","Haotian Zhang","Lin Lin","Shaohua Zhang"],"url":"https://arxiv.org/abs/2503.04291"}
{"created":"2025-06-04","title":"DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models","abstract":"Recent advancements in slow thinking reasoning models have shown exceptional performance in complex reasoning tasks. However, these models often exhibit overthinking (generating redundant reasoning steps for simple problems), leading to excessive computational resource usage. While current mitigation strategies uniformly reduce reasoning tokens, they risk degrading performance on challenging tasks that require extended reasoning. This paper introduces Difficulty-Adaptive Slow Thinking (DAST), a novel framework that enables models to autonomously adjust the length of Chain-of-Thought (CoT) based on problem difficulty. We first propose a Token Length Budget (TLB) metric to quantify difficulty, then leverage budget-aware reward shaping and budget preference optimization to implement DAST. DAST penalizes overlong responses for simple tasks while incentivizing sufficient reasoning for complex problems. Experiments on diverse datasets and model scales demonstrate that DAST effectively mitigates overthinking (reducing token usage by over 30\\% on average) while preserving reasoning accuracy on complex problems. Our codes and models are available at https://github.com/AnonymousUser0520/AnonymousRepo01.","authors":["Yi Shen","Jian Zhang","Jieyun Huang","Shuming Shi","Wenjing Zhang","Jiangze Yan","Ning Wang","Kai Wang","Zhaoxiang Liu","Shiguo Lian"],"url":"https://arxiv.org/abs/2503.04472"}
{"created":"2025-06-04","title":"A linearly-implicit energy-momentum preserving scheme for geometrically nonlinear mechanics based on non-canonical Hamiltonian formulations","abstract":"This work presents a novel formulation and numerical strategy for the simulation of geometrically nonlinear structures. First, a non-canonical Hamiltonian (Poisson) formulation is introduced by including the dynamics of the stress tensor. This framework is developed for von-K\\'arm\\'an nonlinearities in beams and plates, as well as geometrically nonlinear elasticity with Saint-Venant material behavior. In the case of plates, both negligible and non-negligible membrane inertia are considered. For the former case the two-dimensional elasticity complex is leveraged to express the dynamics in terms of the Airy stress function. The finite element discretization employs a mixed approach, combining a conforming approximation for displacement and velocity fields with a discontinuous stress tensor representation. A staggered, linear implicit time integration scheme is proposed, establishing connections with existing explicit-implicit energy-preserving methods. The stress degrees of freedom are statically condensed, reducing the computational complexity to solving a system with a positive definite matrix. The integration strategy preserves energy and angular momentum exactly. The methodology is validated through numerical experiments on the Duffing oscillator, a von-K\\'arm\\'an beam, and a column undergoing finite deformations. Comparisons with fully implicit energy-preserving method and the leapfrog scheme demonstrate that the proposed approach achieves superior accuracy while maintaining energy stability. Additionally, it enables larger time steps compared to explicit schemes and exhibits computational efficiency comparable to the leapfrog method.","authors":["Andrea Brugnoli","Denis Matignon","Joseph Morlier"],"url":"https://arxiv.org/abs/2503.04695"}
{"created":"2025-06-04","title":"Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence","abstract":"Dense retrieval models are commonly used in Information Retrieval (IR) applications, such as Retrieval-Augmented Generation (RAG). Since they often serve as the first step in these systems, their robustness is critical to avoid downstream failures. In this work, we repurpose a relation extraction dataset (e.g., Re-DocRED) to design controlled experiments that quantify the impact of heuristic biases, such as a preference for shorter documents, on retrievers like Dragon+ and Contriever. We uncover major vulnerabilities, showing retrievers favor shorter documents, early positions, repeated entities, and literal matches, all while ignoring the answer's presence! Notably, when multiple biases combine, models exhibit catastrophic performance degradation, selecting the answer-containing document in less than 10% of cases over a synthetic biased document without the answer. Furthermore, we show that these biases have direct consequences for downstream applications like RAG, where retrieval-preferred documents can mislead LLMs, resulting in a 34% performance drop than providing no documents at all. https://huggingface.co/datasets/mohsenfayyaz/ColDeR","authors":["Mohsen Fayyaz","Ali Modarressi","Hinrich Schuetze","Nanyun Peng"],"url":"https://arxiv.org/abs/2503.05037"}
{"created":"2025-06-04","title":"Kaiwu: A Multimodal Manipulation Dataset and Framework for Robot Learning and Human-Robot Interaction","abstract":"Cutting-edge robot learning techniques including foundation models and imitation learning from humans all pose huge demands on large-scale and high-quality datasets which constitute one of the bottleneck in the general intelligent robot fields. This paper presents the Kaiwu multimodal dataset to address the missing real-world synchronized multimodal data problems in the sophisticated assembling scenario,especially with dynamics information and its fine-grained labelling. The dataset first provides an integration of human,environment and robot data collection framework with 20 subjects and 30 interaction objects resulting in totally 11,664 instances of integrated actions. For each of the demonstration,hand motions,operation pressures,sounds of the assembling process,multi-view videos, high-precision motion capture information,eye gaze with first-person videos,electromyography signals are all recorded. Fine-grained multi-level annotation based on absolute timestamp,and semantic segmentation labelling are performed. Kaiwu dataset aims to facilitate robot learning,dexterous manipulation,human intention investigation and human-robot collaboration research.","authors":["Shuo Jiang","Haonan Li","Ruochen Ren","Yanmin Zhou","Zhipeng Wang","Bin He"],"url":"https://arxiv.org/abs/2503.05231"}
{"created":"2025-06-04","title":"Adversarial Policy Optimization for Offline Preference-based Reinforcement Learning","abstract":"In this paper, we study offline preference-based reinforcement learning (PbRL), where learning is based on pre-collected preference feedback over pairs of trajectories. While offline PbRL has demonstrated remarkable empirical success, existing theoretical approaches face challenges in ensuring conservatism under uncertainty, requiring computationally intractable confidence set constructions. We address this limitation by proposing Adversarial Preference-based Policy Optimization (APPO), a computationally efficient algorithm for offline PbRL that guarantees sample complexity bounds without relying on explicit confidence sets. By framing PbRL as a two-player game between a policy and a model, our approach enforces conservatism in a tractable manner. Using standard assumptions on function approximation and bounded trajectory concentrability, we derive a sample complexity bound. To our knowledge, APPO is the first offline PbRL algorithm to offer both statistical efficiency and practical applicability. Experimental results on continuous control tasks demonstrate that APPO effectively learns from complex datasets, showing comparable performance with existing state-of-the-art methods.","authors":["Hyungkyu Kang","Min-hwan Oh"],"url":"https://arxiv.org/abs/2503.05306"}
{"created":"2025-06-04","title":"Political Neutrality in AI Is Impossible- But Here Is How to Approximate It","abstract":"AI systems often exhibit political bias, influencing users' opinions and decisions. While political neutrality-defined as the absence of bias-is often seen as an ideal solution for fairness and safety, this position paper argues that true political neutrality is neither feasible nor universally desirable due to its subjective nature and the biases inherent in AI training data, algorithms, and user interactions. However, inspired by Joseph Raz's philosophical insight that \"neutrality [...] can be a matter of degree\" (Raz, 1986), we argue that striving for some neutrality remains essential for promoting balanced AI interactions and mitigating user manipulation. Therefore, we use the term \"approximation\" of political neutrality to shift the focus from unattainable absolutes to achievable, practical proxies. We propose eight techniques for approximating neutrality across three levels of conceptualizing AI, examining their trade-offs and implementation strategies. In addition, we explore two concrete applications of these approximations to illustrate their practicality. Finally, we assess our framework on current large language models (LLMs) at the output level, providing a demonstration of how it can be evaluated. This work seeks to advance nuanced discussions of political neutrality in AI and promote the development of responsible, aligned language models.","authors":["Jillian Fisher","Ruth E. Appel","Chan Young Park","Yujin Potter","Liwei Jiang","Taylor Sorensen","Shangbin Feng","Yulia Tsvetkov","Margaret E. Roberts","Jennifer Pan","Dawn Song","Yejin Choi"],"url":"https://arxiv.org/abs/2503.05728"}
{"created":"2025-06-04","title":"Slim attention: cut your context memory in half without loss -- K-cache is all you need for MHA","abstract":"Slim attention shrinks the context memory size by 2x for transformer models with MHA (multi-head attention), which can speed up inference by up to 2x for large context windows.","authors":["Nils Graef","Andrew Wasielewski"],"url":"https://arxiv.org/abs/2503.05840"}
{"created":"2025-06-04","title":"Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection","abstract":"Recently, vision-language models (e.g. CLIP) have demonstrated remarkable performance in zero-shot anomaly detection (ZSAD). By leveraging auxiliary data during training, these models can directly perform cross-category anomaly detection on target datasets, such as detecting defects on industrial product surfaces or identifying tumors in organ tissues. Existing approaches typically construct text prompts through either manual design or the optimization of learnable prompt vectors. However, these methods face several challenges: 1) handcrafted prompts require extensive expert knowledge and trial-and-error; 2) single-form learnable prompts struggle to capture complex anomaly semantics; and 3) an unconstrained prompt space limits generalization to unseen categories. To address these issues, we propose Bayesian Prompt Flow Learning (Bayes-PFL), which models the prompt space as a learnable probability distribution from a Bayesian perspective. Specifically, a prompt flow module is designed to learn both image-specific and image-agnostic distributions, which are jointly utilized to regularize the text prompt space and improve the model's generalization on unseen categories. These learned distributions are then sampled to generate diverse text prompts, effectively covering the prompt space. Additionally, a residual cross-model attention (RCA) module is introduced to better align dynamic text embeddings with fine-grained image features. Extensive experiments on 15 industrial and medical datasets demonstrate our method's superior performance. The code is available at https://github.com/xiaozhen228/Bayes-PFL.","authors":["Zhen Qu","Xian Tao","Xinyi Gong","Shichen Qu","Qiyu Chen","Zhengtao Zhang","Xingang Wang","Guiguang Ding"],"url":"https://arxiv.org/abs/2503.10080"}
{"created":"2025-06-04","title":"Sample Compression for Continual Learning","abstract":"Continual learning algorithms aim to learn from a sequence of tasks, making the training distribution non-stationary. The majority of existing continual learning approaches in the literature rely on heuristics and do not provide learning guarantees. In this paper, we present a new method called Continual Pick-to-Learn (CoP2L), which is able to retain the most representative samples for each task in an efficient way. CoP2L combines the Pick-to-Learn algorithm (rooted in the sample compression theory) and the experience replay continual learning scheme. This allows us to provide non-vacuous upper bounds on the generalization loss of the learned predictors, numerically computable after each task. We empirically evaluate our approach on several standard continual learning benchmarks across Class-Incremental, Task-Incremental, and Domain-Incremental settings. Our results show that CoP2L is highly competitive across all setups, often outperforming existing baselines, and significantly mitigating catastrophic forgetting compared to vanilla experience replay in the Class-Incremental setting. It is possible to leverage the bounds provided by CoP2L in practical scenarios to certify the predictor reliability on previously learned tasks, in order to improve the trustworthiness of the continual learning algorithm.","authors":["Jacob Comeau","Mathieu Bazinet","Pascal Germain","Cem Subakan"],"url":"https://arxiv.org/abs/2503.10503"}
{"created":"2025-06-04","title":"Low-Rank Matrix Regression via Least-Angle Regression","abstract":"Low-rank matrix regression is a fundamental problem in data science with various applications in systems and control. Nuclear norm regularization has been widely applied to solve this problem due to its convexity. However, it suffers from high computational complexity and the inability to directly specify the rank. This work introduces a novel framework for low-rank matrix regression that addresses both unstructured and Hankel matrices. By decomposing the low-rank matrix into rank-1 bases, the problem is reformulated as an infinite-dimensional sparse learning problem. The least-angle regression (LAR) algorithm is then employed to solve this problem efficiently. For unstructured matrices, a closed-form LAR solution is derived with equivalence to a normalized nuclear norm regularization problem. For Hankel matrices, a real-valued polynomial basis reformulation enables effective LAR implementation. Two numerical examples in network modeling and system realization demonstrate that the proposed approach significantly outperforms the nuclear norm method in terms of estimation accuracy and computational efficiency.","authors":["Mingzhou Yin","Matthias A. M\\\"uller"],"url":"https://arxiv.org/abs/2503.10569"}
{"created":"2025-06-04","title":"We Should Chart an Atlas of All the World's Models","abstract":"Public model repositories now contain millions of models, yet most models remain undocumented and effectively lost. In this position paper, we advocate for charting the world's model population in a unified structure we call the Model Atlas: a graph that captures models, their attributes, and the weight transformations that connect them. The Model Atlas enables applications in model forensics, meta-ML research, and model discovery, challenging tasks given today's unstructured model repositories. However, because most models lack documentation, large atlas regions remain uncharted. Addressing this gap motivates new machine learning methods that treat models themselves as data, inferring properties such as functionality, performance, and lineage directly from their weights. We argue that a scalable path forward is to bypass the unique parameter symmetries that plague model weights. Charting all the world's models will require a community effort, and we hope its broad utility will rally researchers toward this goal.","authors":["Eliahu Horwitz","Nitzan Kurer","Jonathan Kahana","Liel Amar","Yedid Hoshen"],"url":"https://arxiv.org/abs/2503.10633"}
{"created":"2025-06-04","title":"OASST-ETC Dataset: Alignment Signals from Eye-tracking Analysis of LLM Responses","abstract":"While Large Language Models (LLMs) have significantly advanced natural language processing, aligning them with human preferences remains an open challenge. Although current alignment methods rely primarily on explicit feedback, eye-tracking (ET) data offers insights into real-time cognitive processing during reading. In this paper, we present OASST-ETC, a novel eye-tracking corpus capturing reading patterns from 24 participants, while evaluating LLM-generated responses from the OASST1 dataset. Our analysis reveals distinct reading patterns between preferred and non-preferred responses, which we compare with synthetic eye-tracking data. Furthermore, we examine the correlation between human reading measures and attention patterns from various transformer-based models, discovering stronger correlations in preferred responses. This work introduces a unique resource for studying human cognitive processing in LLM evaluation and suggests promising directions for incorporating eye-tracking data into alignment methods. The dataset and analysis code are publicly available.","authors":["Angela Lopez-Cardona","Sebastian Idesis","Miguel Barreda-\\'Angeles","Sergi Abadal","Ioannis Arapakis"],"url":"https://arxiv.org/abs/2503.10927"}
{"created":"2025-06-04","title":"The time scale of redundancy between prosody and linguistic context","abstract":"In spoken communication, information is transmitted not only via words, but also through a rich array of non-verbal signals, including prosody--the non-segmental auditory features of speech. Do these different communication channels carry distinct information? Prior work has shown that the information carried by prosodic features is substantially redundant with that carried by the surrounding words. Here, we systematically examine the time scale of this relationship, studying how it varies with the length of past and future contexts. We find that a word's prosodic features require an extended past context (3-8 words across different features) to be reliably predicted. Given that long-scale contextual information decays in memory, prosody may facilitate communication by adding information that is locally unique. We also find that a word's prosodic features show some redundancy with future words, but only with a short scale of 1-2 words, consistent with reports of incremental short-term planning in language production. Thus, prosody may facilitate communication by helping listeners predict upcoming material. In tandem, our results highlight potentially distinct roles that prosody plays in facilitating integration of words into past contexts and in helping predict upcoming words.","authors":["Tamar I. Regev","Chiebuka Ohams","Shaylee Xie","Lukas Wolf","Evelina Fedorenko","Alex Warstadt","Ethan G. Wilcox","Tiago Pimentel"],"url":"https://arxiv.org/abs/2503.11630"}
{"created":"2025-06-04","title":"Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning","abstract":"Recent advancements in Large Language Models (LLMs) have demonstrated enhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting to advanced, product-oriented solutions like OpenAI o1. During our re-implementation of this model, we noticed that in multimodal tasks requiring visual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to maintain focus on the visual information, in other words, MLLMs suffer from a gradual decline in attention to visual information as reasoning progresses, causing text-over-relied outputs. To investigate this, we ablate image inputs during long-chain reasoning. Concretely, we truncate the reasoning process midway, then re-complete the reasoning process with the input image removed. We observe only a ~2% accuracy drop on MathVista's test-hard subset, revealing the model's textual outputs dominate the following reasoning process. Motivated by this, we propose Take-along Visual Conditioning (TVC), a strategy that shifts image input to critical reasoning stages and compresses redundant visual tokens via dynamic pruning. This methodology helps the model retain attention to the visual components throughout the reasoning. Our approach achieves state-of-the-art performance on average across five mathematical reasoning benchmarks (+3.4 points vs previous sota), demonstrating the effectiveness of TVC in enhancing multimodal reasoning systems.","authors":["Hai-Long Sun","Zhun Sun","Houwen Peng","Han-Jia Ye"],"url":"https://arxiv.org/abs/2503.13360"}
{"created":"2025-06-04","title":"Splintering Nonconcatenative Languages for Better Tokenization","abstract":"Common subword tokenization algorithms like BPE and UnigramLM assume that text can be split into meaningful units by concatenative measures alone. This is not true for languages such as Hebrew and Arabic, where morphology is encoded in root-template patterns, or Malay and Georgian, where split affixes are common. We present SPLINTER, a pre-processing step which rearranges text into a linear form that better represents such nonconcatenative morphologies, enabling meaningful contiguous segments to be found by the tokenizer. We demonstrate SPLINTER's merit using both intrinsic measures evaluating token vocabularies in Hebrew, Arabic, and Malay; as well as on downstream tasks using BERT-architecture models trained for Hebrew.","authors":["Bar Gazit (Ben-Gurion University of the Negev)","Shaltiel Shmidman (DICTA)","Avi Shmidman (DICTA)","Yuval Pinter (Ben-Gurion University of the Negev)"],"url":"https://arxiv.org/abs/2503.14433"}
{"created":"2025-06-04","title":"Unique Hard Attention: A Tale of Two Sides","abstract":"Understanding the expressive power of transformers has recently attracted attention, as it offers insights into their abilities and limitations. Many studies analyze unique hard attention transformers, where attention selects a single position that maximizes the attention scores. When multiple positions achieve the maximum score, either the rightmost or the leftmost of those is chosen. In this paper, we highlight the importance of this seeming triviality. Recently, finite-precision transformers with both leftmost- and rightmost-hard attention were shown to be equivalent to Linear Temporal Logic (LTL). We show that this no longer holds with only leftmost-hard attention -- in that case, they correspond to a \\emph{strictly weaker} fragment of LTL. Furthermore, we show that models with leftmost-hard attention are equivalent to \\emph{soft} attention, suggesting they may better approximate real-world transformers than right-attention models. These findings refine the landscape of transformer expressivity and underscore the role of attention directionality.","authors":["Selim Jerad","Anej Svete","Jiaoda Li","Ryan Cotterell"],"url":"https://arxiv.org/abs/2503.14615"}
{"created":"2025-06-04","title":"Beacon-Based Feedback Control for Parking an Active-Joint Center-Articulated Mobile Robot","abstract":"This paper presents an autonomous parking control strategy for an active-joint center-articulated mobile robot. We first derive a kinematic model of the robot, then propose a control law to stabilize the vehicle's configuration within a small neighborhood of the goal. The control law, designed using Lyapunov techniques, is based on the robot's polar coordinate equations. A beacon-based guidance system provides feedback on the target's position and orientation. Simulations demonstrate the robot's ability to park successfully from arbitrary initial poses.","authors":["Mehdi Delrobaei","Kenneth McIsaac"],"url":"https://arxiv.org/abs/2503.14727"}
{"created":"2025-06-04","title":"Partially Observable Reinforcement Learning with Memory Traces","abstract":"Partially observable environments present a considerable computational challenge in reinforcement learning due to the need to consider long histories. Learning with a finite window of observations quickly becomes intractable as the window length grows. In this work, we introduce memory traces. Inspired by eligibility traces, these are compact representations of the history of observations in the form of exponential moving averages. We prove sample complexity bounds for the problem of offline on-policy evaluation that quantify the return errors achieved with memory traces for the class of Lipschitz continuous value estimates. We establish a close connection to the window approach, and demonstrate that, in certain environments, learning with memory traces is significantly more sample efficient. Finally, we underline the effectiveness of memory traces empirically in online reinforcement learning experiments for both value prediction and control.","authors":["Onno Eberhard","Michael Muehlebach","Claire Vernade"],"url":"https://arxiv.org/abs/2503.15200"}
{"created":"2025-06-04","title":"Meta-Learning Neural Mechanisms rather than Bayesian Priors","abstract":"Children acquire language despite being exposed to several orders of magnitude less data than large language models require. Meta-learning has been proposed as a way to integrate human-like learning biases into neural-network architectures, combining both the structured generalizations of symbolic models with the scalability of neural-network models. But what does meta-learning exactly imbue the model with? We investigate the meta-learning of formal languages and find that, contrary to previous claims, meta-trained models are not learning simplicity-based priors when meta-trained on datasets organised around simplicity. Rather, we find evidence that meta-training imprints neural mechanisms (such as counters) into the model, which function like cognitive primitives for the network on downstream tasks. Most surprisingly, we find that meta-training on a single formal language can provide as much improvement to a model as meta-training on 5000 different formal languages, provided that the formal language incentivizes the learning of useful neural mechanisms. Taken together, our findings provide practical implications for efficient meta-learning paradigms and new theoretical insights into linking symbolic theories and neural mechanisms.","authors":["Michael Goodale","Salvador Mascarenhas","Yair Lakretz"],"url":"https://arxiv.org/abs/2503.16048"}
{"created":"2025-06-04","title":"Towards Automated Semantic Interpretability in Reinforcement Learning via Vision-Language Models","abstract":"Semantic interpretability in Reinforcement Learning (RL) enables transparency and verifiability by making the agent's decisions understandable and verifiable. Achieving this, however, requires a feature space composed of human-understandable concepts, which traditionally rely on human specification and may fail to generalize to unseen environments. We introduce interpretable Tree-based Reinforcement learning via Automated Concept Extraction (iTRACE), an automated framework that leverages pre-trained vision-language models (VLM) for semantic feature extraction and interpretable tree-based models for policy optimization. iTRACE first extracts semantically meaningful features, then maps them to policies via interpretable trees. To address the impracticality of running VLMs in RL loops, we distill their outputs into a lightweight model. By leveraging Vision-Language Models (VLMs) to automate tree-based reinforcement learning, iTRACE eliminates the need for human annotation traditionally required by interpretable models, while also addressing the limitations of VLMs alone, such as their lack of grounding in action spaces and inability to directly optimize policies. iTRACE outperforms MLP baselines that use the same interpretable features and matches the performance of CNN-based policies, producing verifiable, semantically interpretable, and human-aligned behaviors without requiring human annotation.","authors":["Zhaoxin Li","Zhang Xi-Jia","Batuhan Altundas","Letian Chen","Rohan Paleja","Matthew Gombolay"],"url":"https://arxiv.org/abs/2503.16724"}
{"created":"2025-06-04","title":"Leveraging Human Production-Interpretation Asymmetries to Test LLM Cognitive Plausibility","abstract":"Whether large language models (LLMs) process language similarly to humans has been the subject of much theoretical and practical debate. We examine this question through the lens of the production-interpretation distinction found in human sentence processing and evaluate the extent to which instruction-tuned LLMs replicate this distinction. Using an empirically documented asymmetry between pronoun production and interpretation in humans for implicit causality verbs as a testbed, we find that some LLMs do quantitatively and qualitatively reflect human-like asymmetries between production and interpretation. We demonstrate that whether this behavior holds depends upon both model size-with larger models more likely to reflect human-like patterns and the choice of meta-linguistic prompts used to elicit the behavior. Our codes and results are available at https://github.com/LingMechLab/Production-Interpretation_Asymmetries_ACL2025.","authors":["Suet-Ying Lam","Qingcheng Zeng","Jingyi Wu","Rob Voigt"],"url":"https://arxiv.org/abs/2503.17579"}
{"created":"2025-06-04","title":"Probabilistic Net Load Forecasting for High-Penetration RES Grids Utilizing Enhanced Conditional Diffusion Model","abstract":"The proliferation of intermittent distributed renewable energy sources (RES) in modern power systems has fundamentally compromised the reliability and accuracy of deterministic net load forecasting. Generative models, particularly diffusion models, demonstrate exceptional potential in uncertainty quantification for scenario forecasting. Nevertheless, their probabilistic predictive capabilities and conditional bootstrapping mechanisms still remain underexplored. In this paper, a day-ahead probabilistic net load forecasting framework is developed by systematically quantifying epistemic uncertainty and aleatoric variability using the feature-informed enhanced conditional diffusion model (ECDM). The ECDM architecture implements the net load distribution generation process using an imputation-based conditional diffusion model, where multi-modal conditional inputs, such as weather and calendar data, are fused via cross-attention mechanisms. Specifically, historical net load profiles are utilized to guide the reverse diffusion trajectory through non-parametric imputation operators preserving spatial-temporal integrity. To capture periodic characteristics, a novel weekly arrangement method is also introduced, while an unconditional model is integrated to ensure diversity in the generated scenarios. Subsequently, the maximum probabilistic points and probability intervals of predicted net load are obtained by the adaptive kernel density estimation under RES intermittency. Moreover, ECDM is extented to multi-energy forecast framework, attempting to increase interpretability of the net load predictions. Numerical experiments on a publicly available dataset demonstrate the superior forecasting performance of the proposed method compared to existing state-of-the-art approaches.","authors":["Yixiang Huang","Jianhua Pei","Luocheng Chen","Zhenchang Du","Jinfu Chen","Zirui Peng"],"url":"https://arxiv.org/abs/2503.17770"}
{"created":"2025-06-04","title":"SceneSplat: Gaussian Splatting-based Scene Understanding with Vision-Language Pretraining","abstract":"Recognizing arbitrary or previously unseen categories is essential for comprehensive real-world 3D scene understanding. Currently, all existing methods rely on 2D or textual modalities during training or together at inference. This highlights the clear absence of a model capable of processing 3D data alone for learning semantics end-to-end, along with the necessary data to train such a model. Meanwhile, 3D Gaussian Splatting (3DGS) has emerged as the de facto standard for 3D scene representation across various vision tasks. However, effectively integrating semantic reasoning into 3DGS in a generalizable manner remains an open challenge. To address these limitations, we introduce SceneSplat, to our knowledge the first large-scale 3D indoor scene understanding approach that operates natively on 3DGS. Furthermore, we propose a self-supervised learning scheme that unlocks rich 3D feature learning from unlabeled scenes. To power the proposed methods, we introduce SceneSplat-7K, the first large-scale 3DGS dataset for indoor scenes, comprising 7916 scenes derived from seven established datasets, such as ScanNet and Matterport3D. Generating SceneSplat-7K required computational resources equivalent to 150 GPU days on an L4 GPU, enabling standardized benchmarking for 3DGS-based reasoning for indoor scenes. Our exhaustive experiments on SceneSplat-7K demonstrate the significant benefit of the proposed method over the established baselines.","authors":["Yue Li","Qi Ma","Runyi Yang","Huapeng Li","Mengjiao Ma","Bin Ren","Nikola Popovic","Nicu Sebe","Ender Konukoglu","Theo Gevers","Luc Van Gool","Martin R. Oswald","Danda Pani Paudel"],"url":"https://arxiv.org/abs/2503.18052"}
{"created":"2025-06-04","title":"Adoption of Watermarking Measures for AI-Generated Content and Implications under the EU AI Act","abstract":"AI-generated images have become so good in recent years that individuals often cannot distinguish them any more from \"real\" images. This development, combined with the rapid spread of AI-generated content online, creates a series of societal risks, particularly with the emergence of \"deep fakes\" that impersonate real individuals. Watermarking, a technique that involves embedding information within images and other content to indicate their AI-generated nature, has emerged as a primary mechanism to address the risks posed by AI-generated content. Indeed, watermarking and AI labelling measures are now becoming a legal requirement in many jurisdictions, including under the 2024 European Union AI Act. Despite the widespread use of AI image generation systems, the current status of the implementation of such measures remains largely unexamined. Moreover, the practical implications of the AI Act's watermarking and labelling requirements have not previously been studied. The present paper therefore both provides an empirical analysis of 50 widely used AI systems for image generation, embedded into a legal analysis of the AI Act. In our legal analysis, we identify four categories of generative AI image deployment scenarios relevant under the AI Act and outline how the legal obligations apply in each category. In our empirical analysis, we find that only a minority number of AI image generators currently implement adequate watermarking (38%) and deep fake labelling (8%) practices. In response, we suggest a range of avenues of how the implementation of these legally mandated techniques can be improved, and publicly share our tooling for the easy detection of watermarks in images.","authors":["Bram Rijsbosch","Gijs van Dijck","Konrad Kollnig"],"url":"https://arxiv.org/abs/2503.18156"}
{"created":"2025-06-04","title":"FF-SRL: High Performance GPU-Based Surgical Simulation For Robot Learning","abstract":"Robotic surgery is a rapidly developing field that can greatly benefit from the automation of surgical tasks. However, training techniques such as Reinforcement Learning (RL) require a high number of task repetitions, which are generally unsafe and impractical to perform on real surgical systems. This stresses the need for simulated surgical environments, which are not only realistic, but also computationally efficient and scalable. We introduce FF-SRL (Fast and Flexible Surgical Reinforcement Learning), a high-performance learning environment for robotic surgery. In FF-SRL both physics simulation and RL policy training reside entirely on a single GPU. This avoids typical bottlenecks associated with data transfer between the CPU and GPU, leading to accelerated learning rates. Our results show that FF-SRL reduces the training time of a complex tissue manipulation task by an order of magnitude, down to a couple of minutes, compared to a common CPU/GPU simulator. Such speed-up may facilitate the experimentation with RL techniques and contribute to the development of new generation of surgical systems. To this end, we make our code publicly available to the community.","authors":["Diego Dall'Alba","Micha{\\l} Naskr\\k{e}t","Sabina Kaminska","Przemys{\\l}aw Korzeniowski"],"url":"https://arxiv.org/abs/2503.18616"}
{"created":"2025-06-04","title":"Video Motion Graphs","abstract":"We present Video Motion Graphs, a system designed to generate realistic human motion videos. Using a reference video and conditional signals such as music or motion tags, the system synthesizes new videos by first retrieving video clips with gestures matching the conditions and then generating interpolation frames to seamlessly connect clip boundaries. The core of our approach is HMInterp, a robust Video Frame Interpolation (VFI) model that enables seamless interpolation of discontinuous frames, even for complex motion scenarios like dancing. HMInterp i) employs a dual-branch interpolation approach, combining a Motion Diffusion Model for human skeleton motion interpolation with a diffusion-based video frame interpolation model for final frame generation. ii) adopts condition progressive training to effectively leverage identity strong and weak conditions, such as images and pose. These designs ensure both high video texture quality and accurate motion trajectory. Results show that our Video Motion Graphs outperforms existing generative- and retrieval-based methods for multi-modal conditioned human motion video generation. Project page can be found at https://h-liu1997.github.io/Video-Motion-Graphs/","authors":["Haiyang Liu","Zhan Xu","Fa-Ting Hong","Hsin-Ping Huang","Yi Zhou","Yang Zhou"],"url":"https://arxiv.org/abs/2503.20218"}
{"created":"2025-06-04","title":"SyncSDE: A Probabilistic Framework for Diffusion Synchronization","abstract":"There have been many attempts to leverage multiple diffusion models for collaborative generation, extending beyond the original domain. A prominent approach involves synchronizing multiple diffusion trajectories by mixing the estimated scores to artificially correlate the generation processes. However, existing methods rely on naive heuristics, such as averaging, without considering task specificity. These approaches do not clarify why such methods work and often produce suboptimal results when a heuristic suitable for one task is blindly applied to others. In this paper, we present a probabilistic framework for analyzing why diffusion synchronization works and reveal where heuristics should be focused; modeling correlations between multiple trajectories and adapting them to each specific task. We further identify optimal correlation models per task, achieving better results than previous approaches that apply a single heuristic across all tasks without justification.","authors":["Hyunjun Lee","Hyunsoo Lee","Sookwan Han"],"url":"https://arxiv.org/abs/2503.21555"}
{"created":"2025-06-04","title":"Negation: A Pink Elephant in the Large Language Models' Room?","abstract":"Negations are key to determining sentence meaning, making them essential for logical reasoning. Despite their importance, negations pose a substantial challenge for large language models (LLMs) and remain underexplored.","authors":["Tereza Vrabcov\\'a","Marek Kadl\\v{c}\\'ik","Petr Sojka","Michal \\v{S}tef\\'anik","Michal Spiegel"],"url":"https://arxiv.org/abs/2503.22395"}
{"created":"2025-06-04","title":"Shape and Texture Recognition in Large Vision-Language Models","abstract":"Shapes and textures are the basic building blocks of visual perception. The ability to identify shapes regardless of orientation, texture, or context, and to recognize textures and materials independently of their associated objects, is essential for a general visual understanding of the world. This work introduces the Large Shape and Textures dataset (LAS&amp;T), a giant collection of highly diverse shapes and textures, created by unsupervised extraction of patterns from natural images. This dataset is used to benchmark how effectively leading Large Vision-Language Models (LVLMs) understand shapes, textures, and materials in 2D and 3D scenes. For shape recognition, we test the models' ability to match images of identical shapes that differ in orientation, texture, color, or environment. Our results show that the shape recognition capabilities of the LVLMs remain significantly below human performance. LVLMs rely predominantly on high-level and semantic features and struggle with abstract shapes lacking clear class associations. For texture and material recognition, we evaluated the models' ability to identify images with identical textures and materials across different objects and environments. Interestingly, leading LVLMs approach human-level performance in recognizing materials in 3D scenes, yet substantially underperform humans when identifying simpler more abstract 2D textures. These results are consistent across a wide range of leading VLMs (GPT/Gemini/LLama/Qwen) and foundation vision models (DINO/CLIP), exposing major deficiencies in the ability of leading models to understand fundamental visual concepts. In contrast, simple nets trained directly for these tasks achieve high accuracy. The LAS&amp;T dataset has been made available.","authors":["Sagi Eppel","Mor Bismut","Alona Faktor-Strugatski"],"url":"https://arxiv.org/abs/2503.23062"}
{"created":"2025-06-04","title":"PixelCAM: Pixel Class Activation Mapping for Histology Image Classification and ROI Localization","abstract":"Weakly supervised object localization (WSOL) methods allow training models to classify images and localize ROIs. WSOL only requires low-cost image-class annotations yet provides a visually interpretable classifier. Standard WSOL methods rely on class activation mapping (CAM) methods to produce spatial localization maps according to a single- or two-step strategy. While both strategies have made significant progress, they still face several limitations with histology images. Single-step methods can easily result in under- or over-activation due to the limited visual ROI saliency in histology images and scarce localization cues. They also face the well-known issue of asynchronous convergence between classification and localization tasks. The two-step approach is sub-optimal because it is constrained to a frozen classifier, limiting the capacity for localization. Moreover, these methods also struggle when applied to out-of-distribution (OOD) datasets. In this paper, a multi-task approach for WSOL is introduced for simultaneous training of both tasks to address the asynchronous convergence problem. In particular, localization is performed in the pixel-feature space of an image encoder that is shared with classification. This allows learning discriminant features and accurate delineation of foreground/background regions to support ROI localization and image classification. We propose PixelCAM, a cost-effective foreground/background pixel-wise classifier in the pixel-feature space that allows for spatial object localization. Using partial-cross entropy, PixelCAM is trained using pixel pseudo-labels collected from a pretrained WSOL model. Both image and pixel-wise classifiers are trained simultaneously using standard gradient descent. In addition, our pixel classifier can easily be integrated into CNN- and transformer-based architectures without any modifications.","authors":["Alexis Guichemerre","Soufiane Belharbi","Mohammadhadi Shateri","Luke McCaffrey","Eric Granger"],"url":"https://arxiv.org/abs/2503.24135"}
{"created":"2025-06-04","title":"A Comparative Study of Scanpath Models in Graph-Based Visualization","abstract":"Information Visualization (InfoVis) systems utilize visual representations to enhance data interpretation. Understanding how visual attention is allocated is essential for optimizing interface design. However, collecting Eye-tracking (ET) data presents challenges related to cost, privacy, and scalability. Computational models provide alternatives for predicting gaze patterns, thereby advancing InfoVis research. In our study, we conducted an ET experiment with 40 participants who analyzed graphs while responding to questions of varying complexity within the context of digital forensics. We compared human scanpaths with synthetic ones generated by models such as DeepGaze, UMSS, and Gazeformer. Our research evaluates the accuracy of these models and examines how question complexity and number of nodes influence performance. This work contributes to the development of predictive modeling in visual analytics, offering insights that can enhance the design and effectiveness of InfoVis systems.","authors":["Angela Lopez-Cardona","Parvin Emami","Sebastian Idesis","Saravanakumar Duraisamy","Luis A. Leiva","Ioannis Arapakis"],"url":"https://arxiv.org/abs/2503.24160"}
{"created":"2025-06-04","title":"Efficient Annotator Reliability Assessment with EffiARA","abstract":"Data annotation is an essential component of the machine learning pipeline; it is also a costly and time-consuming process. With the introduction of transformer-based models, annotation at the document level is increasingly popular; however, there is no standard framework for structuring such tasks. The EffiARA annotation framework is, to our knowledge, the first project to support the whole annotation pipeline, from understanding the resources required for an annotation task to compiling the annotated dataset and gaining insights into the reliability of individual annotators as well as the dataset as a whole. The framework's efficacy is supported by two previous studies: one improving classification performance through annotator-reliability-based soft-label aggregation and sample weighting, and the other increasing the overall agreement among annotators through removing identifying and replacing an unreliable annotator. This work introduces the EffiARA Python package and its accompanying webtool, which provides an accessible graphical user interface for the system. We open-source the EffiARA Python package at https://github.com/MiniEggz/EffiARA and the webtool is publicly accessible at https://effiara.gate.ac.uk.","authors":["Owen Cook","Jake Vasilakes","Ian Roberts","Xingyi Song"],"url":"https://arxiv.org/abs/2504.00589"}
{"created":"2025-06-04","title":"OmniTalker: One-shot Real-time Text-Driven Talking Audio-Video Generation With Multimodal Style Mimicking","abstract":"Although significant progress has been made in audio-driven talking head generation, text-driven methods remain underexplored. In this work, we present OmniTalker, a unified framework that jointly generates synchronized talking audio-video content from input text while emulating the speaking and facial movement styles of the target identity, including speech characteristics, head motion, and facial dynamics. Our framework adopts a dual-branch diffusion transformer (DiT) architecture, with one branch dedicated to audio generation and the other to video synthesis. At the shallow layers, cross-modal fusion modules are introduced to integrate information between the two modalities. In deeper layers, each modality is processed independently, with the generated audio decoded by a vocoder and the video rendered using a GAN-based high-quality visual renderer. Leveraging the in-context learning capability of DiT through a masked-infilling strategy, our model can simultaneously capture both audio and visual styles without requiring explicit style extraction modules. Thanks to the efficiency of the DiT backbone and the optimized visual renderer, OmniTalker achieves real-time inference at 25 FPS. To the best of our knowledge, OmniTalker is the first one-shot framework capable of jointly modeling speech and facial styles in real time. Extensive experiments demonstrate its superiority over existing methods in terms of generation quality, particularly in preserving style consistency and ensuring precise audio-video synchronization, all while maintaining efficient inference.","authors":["Zhongjian Wang","Peng Zhang","Jinwei Qi","Guangyuan Wang","Chaonan Ji","Sheng Xu","Bang Zhang","Liefeng Bo"],"url":"https://arxiv.org/abs/2504.02433"}
{"created":"2025-06-04","title":"The epistemic dimension of algorithmic fairness: assessing its impact in innovation diffusion and fair policy making","abstract":"Algorithmic fairness is an expanding field that addresses a range of discrimination issues associated with algorithmic processes. However, most works in the literature focus on analyzing it only from an ethical perspective, focusing on moral principles and values that should be considered in the design and evaluation of algorithms, while disregarding the epistemic dimension related to knowledge transmission and validation. However, this aspect of algorithmic fairness should also be included in the debate, as it is crucial to introduce a specific type of harm: an individual may be systematically excluded from the dissemination of knowledge due to the attribution of a credibility deficit/excess. In this work, we specifically focus on characterizing and analyzing the impact of this credibility deficit or excess on the diffusion of innovations on a societal scale, a phenomenon driven by individual attitudes and social interactions, and also by the strength of mutual connections. Indeed, discrimination might shape the latter, ultimately modifying how innovations spread within the network. In this light, to incorporate, also from a formal point of view, the epistemic dimension in innovation diffusion models becomes paramount, especially if these models are intended to support fair policy design. For these reasons, we formalize the epistemic properties of a social environment, by extending the well-established Linear Threshold Model (LTM) in an epistemic direction to show the impact of epistemic biases in innovation diffusion. Focusing on the impact of epistemic bias in both open-loop and closed-loop scenarios featuring optimal fostering policies, our results shed light on the pivotal role the epistemic dimension might have in the debate of algorithmic fairness in decision-making.","authors":["Eugenia Villa","Camilla Quaresmini","Valentina Breschi","Viola Schiaffonati","Mara Tanelli"],"url":"https://arxiv.org/abs/2504.02856"}
{"created":"2025-06-04","title":"Effects of Interpolation Error and Bias on the Random Mesh Finite Element Method for Inverse Problems","abstract":"Bayesian inverse problems are an important application for probabilistic solvers of partial differential equations: when fully resolving numerical error is computationally infeasible, probabilistic solvers can be used to consistently model the error and propagate it to the posterior. In this work, the performance of the random mesh finite element method (RM-FEM) is investigated in a Bayesian inverse setting. We show how interpolation error negatively affects the RM-FEM posterior, and how these negative effects can be diminished. In scenarios where FEM is biased for a quantity of interest, we find that RM-FEM struggles to accurately model this bias.","authors":["Anne Poot","Iuri Rocha","Pierre Kerfriden","Frans van der Meer"],"url":"https://arxiv.org/abs/2504.03393"}
{"created":"2025-06-04","title":"Learning Cache Coherence Traffic for NoC Routing Design","abstract":"The rapid growth of multi-core systems highlights the need for efficient Network-on-Chip (NoC) design to ensure seamless communication. Cache coherence, essential for data consistency, substantially reduces task computation time by enabling data sharing among caches. As a result, routing serves two roles: facilitating data sharing (influenced by topology) and managing NoC-level communication. However, cache coherence is often overlooked in routing, causing mismatches between design expectations and evaluation outcomes. Two main challenges are the lack of specialized tools to assess cache coherence's impact and the neglect of topology selection in routing. In this work, we propose a cache coherence-aware routing approach with integrated topology selection, guided by our Cache Coherence Traffic Analyzer (CCTA). Our method achieves up to 10.52% lower packet latency, 55.51% faster execution time, and 49.02% total energy savings, underscoring the critical role of cache coherence in NoC design and enabling effective co-design.","authors":["Guochu Xiong","Xiangzhong Luo","Weichen Liu"],"url":"https://arxiv.org/abs/2504.04005"}
{"created":"2025-06-04","title":"TestDG: Test-time Domain Generalization for Continual Test-time Adaptation","abstract":"This paper studies continual test-time adaptation (CTTA), the task of adapting a model to constantly changing unseen domains in testing while preserving previously learned knowledge. Existing CTTA methods mostly focus on adaptation to the current test domain only, overlooking generalization to arbitrary test domains a model may face in the future. To tackle this limitation, we present a novel online test-time domain generalization framework for CTTA, dubbed TestDG. TestDG aims to learn features invariant to both current and previous test domains on the fly during testing, improving the potential for effective generalization to future domains. To this end, we propose a new model architecture and a test-time adaptation strategy dedicated to learning domain-invariant features, along with a new data structure and optimization algorithm for effectively managing information from previous test domains. TestDG achieved state of the art on four public CTTA benchmarks. Moreover, it showed superior generalization to unseen test domains.","authors":["Sohyun Lee","Nayeong Kim","Juwon Kang","Seong Joon Oh","Suha Kwak"],"url":"https://arxiv.org/abs/2504.04981"}
{"created":"2025-06-04","title":"Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models","abstract":"Large language models (LLMs) are foundational explorations to artificial general intelligence, yet their alignment with human values via instruction tuning and preference learning achieves only superficial compliance. Here, we demonstrate that harmful knowledge embedded during pretraining persists as indelible \"dark patterns\" in LLMs' parametric memory, evading alignment safeguards and resurfacing under adversarial inducement at distributional shifts. In this study, we first theoretically analyze the intrinsic ethical vulnerability of aligned LLMs by proving that current alignment methods yield only local \"safety regions\" in the knowledge manifold. In contrast, pretrained knowledge remains globally connected to harmful concepts via high-likelihood adversarial trajectories. Building on this theoretical insight, we empirically validate our findings by employing semantic coherence inducement under distributional shifts--a method that systematically bypasses alignment constraints through optimized adversarial prompts. This combined theoretical and empirical approach achieves a 100% attack success rate across 19 out of 23 state-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing their universal vulnerabilities.","authors":["Jiawei Lian","Jianhong Pan","Lefan Wang","Yi Wang","Shaohui Mei","Lap-Pui Chau"],"url":"https://arxiv.org/abs/2504.05050"}
{"created":"2025-06-04","title":"Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution","abstract":"Efficiency is essential to support ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code -- supporting symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, imperative DL frameworks encouraging eager execution have emerged but at the expense of run-time performance. Though hybrid approaches aim for the \"best of both worlds,\" using them effectively requires subtle considerations. Our key insight is that, while DL programs typically execute sequentially, hybridizing imperative DL code resembles parallelizing sequential code in traditional systems. Inspired by this, we present an automated refactoring approach that assists developers in determining which otherwise eagerly-executed imperative DL functions could be effectively and efficiently executed as graphs. The approach features novel static imperative tensor and side-effect analyses for Python. Due to its inherent dynamism, analyzing Python may be unsound; however, the conservative approach leverages a speculative (keyword-based) analysis for resolving difficult cases that informs developers of any assumptions made. The approach is: (i) implemented as a plug-in to the PyDev Eclipse IDE that integrates the WALA Ariadne analysis framework and (ii) evaluated on nineteen DL projects consisting of 132 KLOC. The results show that 326 of 766 candidate functions (42.56%) were refactorable, and an average relative speedup of 2.16 on performance tests was observed with negligible differences in model accuracy. The results indicate that the approach is useful in optimizing imperative DL code to its full potential.","authors":["Raffi Khatchadourian","Tatiana Castro V\\'elez","Mehdi Bagherzadeh","Nan Jia","Anita Raja"],"url":"https://arxiv.org/abs/2504.05424"}
{"created":"2025-06-04","title":"Unifying and extending Diffusion Models through PDEs for solving Inverse Problems","abstract":"Diffusion models have emerged as powerful generative tools with applications in computer vision and scientific machine learning (SciML), where they have been used to solve large-scale probabilistic inverse problems. Traditionally, these models have been derived using principles of variational inference, denoising, statistical signal processing, and stochastic differential equations. In contrast to the conventional presentation, in this study we derive diffusion models using ideas from linear partial differential equations and demonstrate that this approach has several benefits that include a constructive derivation of the forward and reverse processes, a unified derivation of multiple formulations and sampling strategies, and the discovery of a new class of variance preserving models. We also apply the conditional version of these models to solve canonical conditional density estimation problems and challenging inverse problems. These problems help establish benchmarks for systematically quantifying the performance of different formulations and sampling strategies in this study and for future studies. Finally, we identify and implement a mechanism through which a single diffusion model can be applied to measurements obtained from multiple measurement operators. Taken together, the contents of this manuscript provide a new understanding of and several new directions in the application of diffusion models to solving physics-based inverse problems.","authors":["Agnimitra Dasgupta","Alexsander Marciano da Cunha","Ali Fardisi","Mehrnegar Aminy","Brianna Binder","Bryan Shaddy","Assad A Oberai"],"url":"https://arxiv.org/abs/2504.07437"}
{"created":"2025-06-04","title":"MMLA: Multi-Environment, Multi-Species, Low-Altitude Drone Dataset","abstract":"Real-time wildlife detection in drone imagery supports critical ecological and conservation monitoring. However, standard detection models like YOLO often fail to generalize across locations and struggle with rare species, limiting their use in automated drone deployments. We present MMLA, a novel multi-environment, multi-species, low-altitude drone dataset collected across three sites (Ol Pejeta Conservancy and Mpala Research Centre in Kenya, and The Wilds in Ohio), featuring six species (zebras, giraffes, onagers, and African wild dogs). The dataset contains 811K annotations from 37 high-resolution videos. Baseline YOLO models show performance disparities across locations while fine-tuning YOLOv11m on MMLA improves mAP50 to 82%, a 52-point gain over baseline. Our results underscore the need for diverse training data to enable robust animal detection in autonomous drone systems.","authors":["Jenna Kline","Samuel Stevens","Guy Maalouf","Camille Rondeau Saint-Jean","Dat Nguyen Ngoc","Majid Mirmehdi","David Guerin","Tilo Burghardt","Elzbieta Pastucha","Blair Costelloe","Matthew Watson","Thomas Richardson","Ulrik Pagh Schultz Lundquist"],"url":"https://arxiv.org/abs/2504.07744"}
{"created":"2025-06-04","title":"A Fully Automated Pipeline for Conversational Discourse Annotation: Tree Scheme Generation and Labeling with Large Language Models","abstract":"Recent advances in Large Language Models (LLMs) have shown promise in automating discourse annotation for conversations. While manually designing tree annotation schemes significantly improves annotation quality for humans and models, their creation remains time-consuming and requires expert knowledge. We propose a fully automated pipeline that uses LLMs to construct such schemes and perform annotation. We evaluate our approach on speech functions (SFs) and the Switchboard-DAMSL (SWBD-DAMSL) taxonomies. Our experiments compare various design choices, and we show that frequency-guided decision trees, paired with an advanced LLM for annotation, can outperform previously manually designed trees and even match or surpass human annotators while significantly reducing the time required for annotation. We release all code and resultant schemes and annotations to facilitate future research on discourse annotation.","authors":["Kseniia Petukhova","Ekaterina Kochmar"],"url":"https://arxiv.org/abs/2504.08961"}
{"created":"2025-06-04","title":"HBS -- Hardware Build System: A Tcl-based, minimal common abstraction approach for build system for hardware designs","abstract":"Build systems become an indispensable part of the software implementation and deployment process. New programming languages are released with the build system integrated into the language tools, for example, Go, Rust, or Zig. However, in the hardware description domain, no official build systems have been released with the predominant Hardware Description Languages (HDL) such as VHDL or SystemVerilog. Moreover, hardware design projects are often multilanguage.","authors":["Micha{\\l} Kruszewski"],"url":"https://arxiv.org/abs/2504.09642"}
{"created":"2025-06-04","title":"FedRecon: Missing Modality Reconstruction in Heterogeneous Distributed Environments","abstract":"Multimodal data are often incomplete and exhibit Non-Independent and Identically Distributed (Non-IID) characteristics in real-world scenarios. These inherent limitations lead to both modality heterogeneity through partial modality absence and data heterogeneity from distribution divergence, creating fundamental challenges for effective federated learning (FL). To address these coupled challenges, we propose FedRecon, the first method targeting simultaneous missing modality reconstruction and Non-IID adaptation in multimodal FL. Our approach first employs a lightweight Multimodal Variational Autoencoder (MVAE) to reconstruct missing modalities while preserving cross-modal consistency. Distinct from conventional imputation methods, we achieve sample-level alignment through a novel distribution mapping mechanism that guarantees both data consistency and completeness. Additionally, we introduce a strategy employing global generator freezing to prevent catastrophic forgetting, which in turn mitigates Non-IID fluctuations. Extensive evaluations on multimodal datasets demonstrate FedRecon's superior performance in modality reconstruction under Non-IID conditions, surpassing state-of-the-art methods.","authors":["Junming Liu","Guosun Zeng","Ding Wang","Yanting Gao","Yufei Jin"],"url":"https://arxiv.org/abs/2504.09941"}
{"created":"2025-06-04","title":"d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning","abstract":"Recent large language models (LLMs) have demonstrated strong reasoning capabilities that benefits from online reinforcement learning (RL). These capabilities have primarily been demonstrated within the left-to-right autoregressive (AR) generation paradigm. In contrast, non-autoregressive paradigms based on diffusion generate text in a coarse-to-fine manner. Although recent diffusion-based large language models (dLLMs) have achieved competitive language modeling performance compared to their AR counterparts, it remains unclear if dLLMs can also leverage recent advances in LLM reasoning. To this end, we propose d1, a framework to adapt pre-trained masked dLLMs into reasoning models via a combination of supervised finetuning (SFT) and RL. Specifically, we develop and extend techniques to improve reasoning in pretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge and instill self-improvement behavior directly from existing datasets, and (b) we introduce a novel critic-free, policy-gradient based RL algorithm called diffu-GRPO, the first integration of policy gradient methods to masked dLLMs. Through empirical studies, we investigate the performance of different post-training recipes on multiple mathematical and planning benchmarks. We find that d1 yields the best performance and significantly improves performance of a state-of-the-art dLLM. Our code is released at https://dllm-reasoning.github.io/.","authors":["Siyan Zhao","Devaansh Gupta","Qinqing Zheng","Aditya Grover"],"url":"https://arxiv.org/abs/2504.12216"}
{"created":"2025-06-04","title":"Effective Dual-Region Augmentation for Reduced Reliance on Large Amounts of Labeled Data","abstract":"This paper introduces a novel dual-region augmentation approach designed to reduce reliance on large-scale labeled datasets while improving model robustness and adaptability across diverse computer vision tasks, including source-free domain adaptation (SFDA) and person re-identification (ReID). Our method performs targeted data transformations by applying random noise perturbations to foreground objects and spatially shuffling background patches. This effectively increases the diversity of the training data, improving model robustness and generalization. Evaluations on the PACS dataset for SFDA demonstrate that our augmentation strategy consistently outperforms existing methods, achieving significant accuracy improvements in both single-target and multi-target adaptation settings. By augmenting training data through structured transformations, our method enables model generalization across domains, providing a scalable solution for reducing reliance on manually annotated datasets. Furthermore, experiments on Market-1501 and DukeMTMC-reID datasets validate the effectiveness of our approach for person ReID, surpassing traditional augmentation techniques. The code is available at https://github.com/PrasannaPulakurthi/Foreground-Background-Augmentation","authors":["Prasanna Reddy Pulakurthi","Majid Rabbani","Celso M. de Melo","Sohail A. Dianat","Raghuveer M. Rao"],"url":"https://arxiv.org/abs/2504.13077"}
{"created":"2025-06-04","title":"An AI-powered Public Health Automated Kiosk System for Personalized Care: An Experimental Pilot Study","abstract":"Background: The HERMES Kiosk (Healthcare Enhanced Recommendations through Artificial Intelligence & Expertise System) is designed to provide personalized Over-the-Counter (OTC) medication recommendations, addressing the limitations of traditional health kiosks. It integrates an advanced GAMENet model enhanced with Graph Attention Networks (GAT) and Multi-Head Cross-Attention (MHCA) while ensuring user privacy through federated learning. This paper outlines the conceptual design and architecture of HERMES, with a focus on deployment in high-traffic public areas. Methods: HERMES analyzes self-reported symptoms and anonymized medical histories using AI algorithms to generate context-aware OTC medication recommendations. The system was initially trained using Electronic Health Records (EHR) from the MIMIC-III dataset (6,350 patients) and Drug-Drug Interaction (DDI) data from the TWOSIDES database, incorporating the top 90 severity DDI types. Real-time DDI checks and ATC-mapped drug codes further improve safety. The kiosk is designed for accessibility, offering multilingual support, large fonts, voice commands, and Braille compatibility. A built-in health education library promotes preventive care and health literacy. A survey was conducted among 10 medical professionals to evaluate its potential applications in medicine. Results: Preliminary results show that the enhanced GAMENet model achieved a Precision-Recall AUC (PRAUC) of 0.74, outperforming the original model. These findings suggest a strong potential for delivering accurate and secure healthcare recommendations in public settings. Conclusion: HERMES demonstrates how AI-driven, privacy-preserving kiosks can enhance public health access, empower users, and alleviate burdens on healthcare systems. Future work will focus on real-world deployment, usability testing, and scalability for broader adoption.","authors":["Sonya Falahati","Morteza Alizadeh","Fatemeh Ghazipour","Zhino Safahi","Navid Khaledian","Mohammad R. Salmanpour"],"url":"https://arxiv.org/abs/2504.13880"}
{"created":"2025-06-04","title":"Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining","abstract":"The growing use of large language models has raised environmental and economic concerns about their intensity of resource usage during inference. Serving these models to each user requires substantial energy and water for cooling. Model compression techniques like quantization can shrink large language models and make them more resource efficient at the cost of potential performance degradation. Quantization methods compress model size through replacing their high-precision parameters by quantized values of lower precision. Among existing methods, the ApiQ method achieves superior accuracy preservation at minimal memory and time overhead. We investigate two ideas to extend performance in ultra-low-bit quantization beyond ApiQ's level. First, we look into combining existing quantization-aware training techniques with ApiQ's partial training. We show that this does not outperform the baseline ApiQ method with limited training data and frozen weights. This leads to two key insights: (1) The substantial representational capacity that is gained through full retraining is unlikely to be feasible through partial training. (2) This gain may depend on using a large and diverse dataset in quantization-aware training. Second, through a novel approach informed by the two insights, we propose an ultra-low-bit quantization method that builds upon ApiQ and extends its performance without the need for full retraining. This publicly available method relies on a saliency-aware regularization term that prioritizes preserving the most impactful parameters during quantization. Our experiments on LLaMA 7B and 13B benchmarks demonstrate that our method reduces the ApiQ's accuracy degradation by 10.85\\% and 7.54\\% respectively.","authors":["Deyu Cao","Samin Aref"],"url":"https://arxiv.org/abs/2504.13932"}
{"created":"2025-06-04","title":"Adversarial Locomotion and Motion Imitation for Humanoid Policy Learning","abstract":"Humans exhibit diverse and expressive whole-body movements. However, attaining human-like whole-body coordination in humanoid robots remains challenging, as conventional approaches that mimic whole-body motions often neglect the distinct roles of upper and lower body. This oversight leads to computationally intensive policy learning and frequently causes robot instability and falls during real-world execution. To address these issues, we propose Adversarial Locomotion and Motion Imitation (ALMI), a novel framework that enables adversarial policy learning between upper and lower body. Specifically, the lower body aims to provide robust locomotion capabilities to follow velocity commands while the upper body tracks various motions. Conversely, the upper-body policy ensures effective motion tracking when the robot executes velocity-based movements. Through iterative updates, these policies achieve coordinated whole-body control, which can be extended to loco-manipulation tasks with teleoperation systems. Extensive experiments demonstrate that our method achieves robust locomotion and precise motion tracking in both simulation and on the full-size Unitree H1 robot. Additionally, we release a large-scale whole-body motion control dataset featuring high-quality episodic trajectories from MuJoCo simulations deployable on real robots. The project page is https://almi-humanoid.github.io.","authors":["Jiyuan Shi","Xinzhe Liu","Dewei Wang","Ouyang Lu","S\\\"oren Schwertfeger","Fuchun Sun","Chenjia Bai","Xuelong Li"],"url":"https://arxiv.org/abs/2504.14305"}
{"created":"2025-06-04","title":"Scaling and Beyond: Advancing Spatial Reasoning in MLLMs Requires New Recipes","abstract":"Multimodal Large Language Models (MLLMs) have demonstrated impressive performance in general vision-language tasks. However, recent studies have exposed critical limitations in their spatial reasoning capabilities. This deficiency in spatial reasoning significantly constrains MLLMs' ability to interact effectively with the physical world, thereby limiting their broader applications. We argue that spatial reasoning capabilities will not naturally emerge from merely scaling existing architectures and training methodologies. Instead, this challenge demands dedicated attention to fundamental modifications in the current MLLM development approach. In this position paper, we first establish a comprehensive framework for spatial reasoning within the context of MLLMs. We then elaborate on its pivotal role in real-world applications. Through systematic analysis, we examine how individual components of the current methodology, from training data to reasoning mechanisms, influence spatial reasoning capabilities. This examination reveals critical limitations while simultaneously identifying promising avenues for advancement. Our work aims to direct the AI research community's attention toward these crucial yet underexplored aspects. By highlighting these challenges and opportunities, we seek to catalyze progress toward achieving human-like spatial reasoning capabilities in MLLMs.","authors":["Huanyu Zhang","Chengzu Li","Wenshan Wu","Shaoguang Mao","Yifan Zhang","Haochen Tian","Ivan Vuli\\'c","Zhang Zhang","Liang Wang","Tieniu Tan","Furu Wei"],"url":"https://arxiv.org/abs/2504.15037"}
{"created":"2025-06-04","title":"Measuring likelihood in cybersecurity","abstract":"In cybersecurity risk is commonly measured by impact and probability, the former is objectively measured based on the consequences from the use of technology to obtain business gains, or by achieving business objectives. The latter has been measured, in sectors such as financial or insurance, based on historical data because there is vast information, and many other fields have applied the same approach. Although in cybersecurity, as a new discipline, there is not always historical data to support an objective measure of probability, the data available is not public and there is no consistent formatting to store and share it, so a new approach is required to measure cybersecurity events incidence. Through a comprehensive analysis of the state of the art, including current methodologies, frameworks, and incident data, considering tactics, techniques, and procedures (TTP) used by attackers, indicators of compromise (IOC), and defence controls, this work proposes a data model that describes a cyber exposure profile that provides an indirect but objective measure for likelihood, including different sources and metrics to update the model if needed. We further propose a set of practical, quantifiable metrics for risk assessment, enabling cybersecurity practitioners to measure likelihood without relying solely on historical incident data. By combining these metrics with our data model, organizations gain an actionable framework for continuously refining their cybersecurity strategies.","authors":["Pablo Corona-Fraga","Vanessa Diaz-Rodriguez","Jesus Manuel Niebla-Zatarain","Gabriel Sanchez-Perez"],"url":"https://arxiv.org/abs/2504.15395"}
{"created":"2025-06-04","title":"LaSDVS : A Post-Quantum Secure Compact Strong-Designated Verifier Signature","abstract":"Digital signatures are fundamental cryptographic primitives that ensure the authenticity and integrity of digital communication. However, in scenarios involving sensitive interactions -- such as e-voting or e-cash -- there is a growing need for more controlled signing mechanisms. Strong-Designated Verifier Signature (SDVS) offers such control by allowing the signer to specify and restrict the verifier of a signature. The existing state-of-the-art SDVS are mostly based on number-theoretic hardness assumptions. Thus, they are not secure against quantum attacks. Moreover, Post-Quantum Cryptography (PQC)-based SDVS are inefficient and have large key and signature sizes. In this work, we address these challenges and propose an efficient post-quantum SDVS (namely, LaSDVS) based on ideal lattices under the hardness assumptions of the Ring-SIS and Ring-LWE problems. LaSDVS achieves advanced security properties including strong unforgeability under chosen-message attacks, non-transferability, non-delegatability, and signer anonymity. By employing the algebraic structure of rings and the gadget trapdoor mechanism of Micciancio et al., we design LaSDVS to minimize computational overhead and significantly reduce key and signature sizes. Notably, our scheme achieves a compact signature size of $\\mathcal{O}(n\\log q)$, compared to $\\mathcal{O}(n^2)$ size, where $n$ is the security parameter, in the existing state-of-the-art PQC designs. To the best of our knowledge, LaSDVS offers the \\textit{smallest private key and signature size} among the existing PQC-based SDVS schemes.","authors":["Shanu Poddar","Sweta Mishra","Tapaswini Mohanty","Vikas Srivastava","Sugata Gangopadhyay"],"url":"https://arxiv.org/abs/2504.16571"}
{"created":"2025-06-04","title":"Hyper-Transforming Latent Diffusion Models","abstract":"We introduce a novel generative framework for functions by integrating Implicit Neural Representations (INRs) and Transformer-based hypernetworks into latent variable models. Unlike prior approaches that rely on MLP-based hypernetworks with scalability limitations, our method employs a Transformer-based decoder to generate INR parameters from latent variables, addressing both representation capacity and computational efficiency. Our framework extends latent diffusion models (LDMs) to INR generation by replacing standard decoders with a Transformer-based hypernetwork, which can be trained either from scratch or via hyper-transforming: a strategy that fine-tunes only the decoder while freezing the pre-trained latent space. This enables efficient adaptation of existing generative models to INR-based representations without requiring full retraining. We validate our approach across multiple modalities, demonstrating improved scalability, expressiveness, and generalization over existing INR-based generative models. Our findings establish a unified and flexible framework for learning structured function representations.","authors":["Ignacio Peis","Batuhan Koyuncu","Isabel Valera","Jes Frellsen"],"url":"https://arxiv.org/abs/2504.16580"}
{"created":"2025-06-04","title":"Exact root-exponential convergence rates of lightning plus polynomial approximations for corner singularities","abstract":"This paper builds rigorous analysis on the root-exponential convergence for the lightning schemes via rational functions in approximating corner singularity problems with uniform exponentially clustered poles proposed by Gopal and Trefethen. The start point is to set up the representations of $z^\\alpha$ and $z^\\alpha\\log z$ in the slit disk and develop results akin to Paley-Wiener theorem, from which, together with the Poisson summation formula, the root-exponential convergence of the lightning plus polynomial scheme with an exact order for each clustered parameter is established in approximation of prototype functions $g(z)z^\\alpha$ or $g(z)z^\\alpha\\log z$ on a sector-shaped domain, which includes $[0,1]$ as a special case. In addition, the fastest convergence rate is confirmed based upon the best choice of the clustered parameter. Furthermore, the optimal choice of the clustered parameter and the convergence rate for corner singularity problems in solving Laplace equations are attested based on Lehman and Wasow's study of corner singularities and along with the decomposition of Gopal and Trefethen. The thorough analysis provides a solid foundation for lightning schemes and rational approximation. Ample numerical evidences demonstrate the optimality and sharpness of the estimates.","authors":["Shuhuang Xiang","Shunfeng Yang","Yanghao Wu"],"url":"https://arxiv.org/abs/2504.16756"}
{"created":"2025-06-04","title":"Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications","abstract":"The rapid growth of unlabeled time-series data in domains such as wireless communications, radar, biomedical engineering, and the Internet of Things (IoT) has driven advancements in unsupervised learning. This review synthesizes recent progress in applying autoencoders and vision transformers for unsupervised signal analysis, focusing on their architectures, applications, and emerging trends. We explore how these models enable feature extraction, anomaly detection, and classification across diverse signal types, including electrocardiograms, radar waveforms, and IoT sensor data. The review highlights the strengths of hybrid architectures and self-supervised learning, while identifying challenges in interpretability, scalability, and domain generalization. By bridging methodological innovations and practical applications, this work offers a roadmap for developing robust, adaptive models for signal intelligence.","authors":["Hossein Ahmadi","Sajjad Emdadi Mahdimahalleh","Arman Farahat","Banafsheh Saffari"],"url":"https://arxiv.org/abs/2504.16972"}
{"created":"2025-06-04","title":"On closure properties of TotP","abstract":"The class TotP consists of functions that count the number of all paths of a nondeterministic polynomial-time Turing machine. In this paper, we give a second definition of the class TotP in terms of certificates and verifiers, and present a few natural closure properties of this class. From the second definition of TotP it follows that TotP = #P if and only if P = NP. We also prove that the closure of TotP under left composition with the class FP+ is equivalent to TotP = FP+ and P = PP, and give examples of FP+-functions such that if TotP is closed under composition with them, then it is closed under composition with FP+.","authors":["Yaroslav Ivanashev"],"url":"https://arxiv.org/abs/2504.20262"}
{"created":"2025-06-04","title":"Perception-aware Sampling for Scatterplot Visualizations","abstract":"Visualizing data is often a crucial first step in data analytics workflows, but growing data sizes pose challenges due to computational and visual perception limitations. As a result, data analysts commonly down-sample their data and work with subsets. Deriving representative samples, however, remains a challenge. This paper focuses on scatterplots, a widely-used visualization type, and introduces a novel sampling objective -- perception-awareness -- aiming to improve sample efficacy by targeting humans' perception of a visualization.","authors":["Zafeiria Moumoulidou","Hamza Elhamdadi","Ke Yang","Subrata Mitra","Cindy Xiong Bearfield","Alexandra Meliou"],"url":"https://arxiv.org/abs/2504.20369"}
{"created":"2025-06-04","title":"Neural semi-Lagrangian method for high-dimensional advection-diffusion problems","abstract":"This work is devoted to the numerical approximation of high-dimensional advection-diffusion equations. It is well-known that classical methods, such as the finite volume method, suffer from the curse of dimensionality, and that their time step is constrained by a stability condition. The semi-Lagrangian method is known to overcome the stability issue, while recent time-discrete neural network-based approaches overcome the curse of dimensionality. In this work, we propose a novel neural semi-Lagrangian method that combines these last two approaches. It relies on projecting the initial condition onto a finite-dimensional neural space, and then solving an optimization problem, involving the backwards characteristic equation, at each time step. It is particularly well-suited for implementation on GPUs, as it is fully parallelizable and does not require a mesh. We provide rough error estimates, and present several high-dimensional numerical experiments to assess the performance of our approach, and compare it to other neural methods.","authors":["Emmanuel Franck","Victor Michel-Dansac","Laurent Navoret","Vincent Vigon"],"url":"https://arxiv.org/abs/2504.20715"}
{"created":"2025-06-04","title":"DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing","abstract":"In the semiconductor industry, integrated circuit (IC) processes play a vital role, as the rising complexity and market expectations necessitate improvements in yield. Identifying IC defects and assigning IC testing tasks to the right engineers improves efficiency and reduces losses. While current studies emphasize fault localization or defect classification, they overlook the integration of defect characteristics, historical failures, and the insights from engineer expertise, which restrains their effectiveness in improving IC handling. To leverage AI for these challenges, we propose DeCo, an innovative approach for optimizing task assignment in IC testing. DeCo constructs a novel defect-aware graph from IC testing reports, capturing co-failure relationships to enhance defect differentiation, even with scarce defect data. Additionally, it formulates defect-aware representations for engineers and tasks, reinforced by local and global structure modeling on the defect-aware graph. Finally, a contrasting-based assignment mechanism pairs testing tasks with QA engineers by considering their skill level and current workload, thus promoting an equitable and efficient job dispatch. Experiments on a real-world dataset demonstrate that DeCo achieves the highest task-handling success rates in different scenarios, exceeding 80\\%, while also maintaining balanced workloads on both scarce or expanded defect data. Moreover, case studies reveal that DeCo can assign tasks to potentially capable engineers, even for their unfamiliar defects, highlighting its potential as an AI-driven solution for the real-world IC failure analysis and task handling.","authors":["Lo Pang-Yun Ting","Yu-Hao Chiang","Yi-Tung Tsai","Hsu-Chao Lai","Kun-Ta Chuang"],"url":"https://arxiv.org/abs/2505.00278"}
{"created":"2025-06-04","title":"TherMod Communication: Low Power or Hot Air?","abstract":"The Kirchhoff-Law-Johnson-Noise (KLJN) secure key exchange scheme leverages statistical physics to enable secure communication with zero average power flow in a wired channel. While the original KLJN scheme requires significant power for operation, a recent wireless modification, TherMod, proposed by Basar claims a \"low power\" implementation. This paper critically examines this claim. We explain that the additional components inherent in Basar's wireless adaptation substantially increase power consumption, rendering the \"low power\" assertion inappropriate. Furthermore, we clarify that the security claims of the original KLJN scheme do not directly translate to this wireless adaptation, implying significant security breach. Finally, the scheme looks identical one of the stealth communicators from 2005, which was shown not to be secure.","authors":["Christiana Chamon"],"url":"https://arxiv.org/abs/2505.00849"}
{"created":"2025-06-04","title":"Early Detection of Patient Deterioration from Real-Time Wearable Monitoring System","abstract":"Early detection of patient deterioration is crucial for reducing mortality rates. Heart rate data has shown promise in assessing patient health, and wearable devices offer a cost-effective solution for real-time monitoring. However, extracting meaningful insights from diverse heart rate data and handling missing values in wearable device data remain key challenges. To address these challenges, we propose TARL, an innovative approach that models the structural relationships of representative subsequences, known as shapelets, in heart rate time series. TARL creates a shapelet-transition knowledge graph to model shapelet dynamics in heart rate time series, indicating illness progression and potential future changes. We further introduce a transition-aware knowledge embedding to reinforce relationships among shapelets and quantify the impact of missing values, enabling the formulation of comprehensive heart rate representations. These representations capture explanatory structures and predict future heart rate trends, aiding early illness detection. We collaborate with physicians and nurses to gather ICU patient heart rate data from wearables and diagnostic metrics assessing illness severity for evaluating deterioration. Experiments on real-world ICU data demonstrate that TARL achieves both high reliability and early detection. A case study further showcases TARL's explainable detection process, highlighting its potential as an AI-driven tool to assist clinicians in recognizing early signs of patient deterioration.","authors":["Lo Pang-Yun Ting","Hong-Pei Chen","An-Shan Liu","Chun-Yin Yeh","Po-Lin Chen","Kun-Ta Chuang"],"url":"https://arxiv.org/abs/2505.01305"}
{"created":"2025-06-04","title":"Focal-SAM: Focal Sharpness-Aware Minimization for Long-Tailed Classification","abstract":"Real-world datasets often follow a long-tailed distribution, making generalization to tail classes difficult. Recent methods resorted to long-tail variants of Sharpness-Aware Minimization (SAM), such as ImbSAM and CC-SAM, to improve generalization by flattening the loss landscape. However, these attempts face a trade-off between computational efficiency and control over the loss landscape. On the one hand, ImbSAM is efficient but offers only coarse control as it excludes head classes from the SAM process. On the other hand, CC-SAM provides fine-grained control through class-dependent perturbations but at the cost of efficiency due to multiple backpropagations. Seeing this dilemma, we introduce Focal-SAM, which assigns different penalties to class-wise sharpness, achieving fine-grained control without extra backpropagations, thus maintaining efficiency. Furthermore, we theoretically analyze Focal-SAM's generalization ability and derive a sharper generalization bound. Extensive experiments on both traditional and foundation models validate the effectiveness of Focal-SAM.","authors":["Sicong Li","Qianqian Xu","Zhiyong Yang","Zitai Wang","Linchao Zhang","Xiaochun Cao","Qingming Huang"],"url":"https://arxiv.org/abs/2505.01660"}
{"created":"2025-06-04","title":"Student Perspectives on the Benefits and Risks of AI in Education","abstract":"The use of chatbots equipped with artificial intelligence (AI) in educational settings has increased in recent years, showing potential to support teaching and learning. However, the adoption of these technologies has raised concerns about their impact on academic integrity, students' ability to problem-solve independently, and potential underlying biases. To better understand students' perspectives and experiences with these tools, a survey was conducted at a large public university in the United States. Through thematic analysis, 262 undergraduate students' responses regarding their perceived benefits and risks of AI chatbots in education were identified and categorized into themes.","authors":["Griffin Pitts","Viktoria Marcus","Sanaz Motamedi"],"url":"https://arxiv.org/abs/2505.02198"}
{"created":"2025-06-04","title":"Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs","abstract":"Despite the remarkable performance of Large Language Models (LLMs), they remain vulnerable to jailbreak attacks, which can compromise their safety mechanisms. Existing studies often rely on brute-force optimization or manual design, failing to uncover potential risks in real-world scenarios. To address this, we propose a novel jailbreak attack framework, ICRT, inspired by heuristics and biases in human cognition. Leveraging the simplicity effect, we employ cognitive decomposition to reduce the complexity of malicious prompts. Simultaneously, relevance bias is utilized to reorganize prompts, enhancing semantic alignment and inducing harmful outputs effectively. Furthermore, we introduce a ranking-based harmfulness evaluation metric that surpasses the traditional binary success-or-failure paradigm by employing ranking aggregation methods such as Elo, HodgeRank, and Rank Centrality to comprehensively quantify the harmfulness of generated content. Experimental results show that our approach consistently bypasses mainstream LLMs' safety mechanisms and generates high-risk content, providing insights into jailbreak attack risks and contributing to stronger defense strategies.","authors":["Haoming Yang","Ke Ma","Xiaojun Jia","Yingfei Sun","Qianqian Xu","Qingming Huang"],"url":"https://arxiv.org/abs/2505.02862"}
{"created":"2025-06-04","title":"Do ATCOs Need Explanations, and Why? Towards ATCO-Centered Explainable AI for Conflict Resolution Advisories","abstract":"Interest in explainable artificial intelligence (XAI) is surging. Prior research has primarily focused on systems' ability to generate explanations, often guided by researchers' intuitions rather than end-users' needs. Unfortunately, such approaches have not yielded favorable outcomes when compared to a black-box baseline (i.e., no explanation). To address this gap, this paper advocates a human-centered approach that shifts focus to air traffic controllers (ATCOs) by asking a fundamental yet overlooked question: Do ATCOs need explanations, and if so, why? Insights from air traffic management (ATM), human-computer interaction, and the social sciences were synthesized to provide a holistic understanding of XAI challenges and opportunities in ATM. Evaluating 11 ATM operational goals revealed a clear need for explanations when ATCOs aim to document decisions and rationales for future reference or report generation. Conversely, ATCOs are less likely to seek them when their conflict resolution approach align with the artificial intelligence (AI) advisory. While this is a preliminary study, the findings are expected to inspire broader and deeper inquiries into the design of ATCO-centric XAI systems, paving the way for more effective human-AI interaction in ATM.","authors":["Katherine Fennedy","Brian Hilburn","Thaivalappil N. M. Nadirsha","Sameer Alam","Khanh-Duy Le","Hua Li"],"url":"https://arxiv.org/abs/2505.03117"}
{"created":"2025-06-04","title":"Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation","abstract":"Mamba's theoretical infinite-context potential is limited in practice when sequences far exceed training lengths. This work explores unlocking Mamba's long-context memory ability by a simple-yet-effective method, Recall with Reasoning (RwR), by distilling chain-of-thought (CoT) summarization from a teacher model. Specifically, RwR prepends these summarization as CoT prompts during fine-tuning, teaching Mamba to actively recall and reason over long contexts. Experiments on LONGMEMEVAL and HELMET show RwR boosts Mamba's long-context performance against comparable Transformer/hybrid baselines under similar pretraining conditions, while preserving short-context capabilities, all without architectural changes.","authors":["Junyu Ma","Tianqing Fang","Zhisong Zhang","Hongming Zhang","Haitao Mi","Dong Yu"],"url":"https://arxiv.org/abs/2505.03320"}
{"created":"2025-06-04","title":"Enhancing Target-unspecific Tasks through a Features Matrix","abstract":"Recent developments in prompt learning of large Vision-Language Models (VLMs) have significantly improved performance in target-specific tasks. However, these prompting methods often struggle to tackle the target-unspecific or generalizable tasks effectively. It may be attributed to the fact that overfitting training causes the model to forget its general knowledge. The general knowledge has a strong promotion on target-unspecific tasks. To alleviate this issue, we propose a novel Features Matrix (FM) approach designed to enhance these models on target-unspecific tasks. Our method extracts and leverages general knowledge, shaping a Features Matrix (FM). Specifically, the FM captures the semantics of diverse inputs from a deep and fine perspective, preserving essential general knowledge, which mitigates the risk of overfitting. Representative evaluations demonstrate that: 1) the FM is compatible with existing frameworks as a generic and flexible module, and 2) the FM significantly showcases its effectiveness in enhancing target-unspecific tasks (base-to-novel generalization, domain generalization, and cross-dataset generalization), achieving state-of-the-art performance.","authors":["Fangming Cui","Yonggang Zhang","Xuan Wang","Xinmei Tian","Jun Yu"],"url":"https://arxiv.org/abs/2505.03414"}
{"created":"2025-06-04","title":"Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning","abstract":"Online fine-tuning vision-language model (VLM) agents with reinforcement learning (RL) has shown promise for equipping agents with multi-step, goal-oriented capabilities in dynamic environments. However, their open-ended textual action space and non-end-to-end nature of action generation present significant challenges to effective online exploration in RL, e.g., explosion of the exploration space. We propose a novel online fine-tuning method, Counterfactual Soft Reinforcement Learning (CoSo), better suited to the textual output space of VLM agents. Compared to prior methods that assign uniform uncertainty to all tokens, CoSo leverages counterfactual reasoning to dynamically assess the causal influence of individual tokens on post-processed actions. By prioritizing the exploration of action-critical tokens while reducing the impact of semantically redundant or low-impact tokens, CoSo enables a more targeted and efficient online rollout process. We provide theoretical analysis proving CoSo's convergence and policy improvement guarantees, and extensive empirical evaluations supporting CoSo's effectiveness. Our results across a diverse set of agent tasks, including Android device control, card gaming, and embodied AI, highlight its remarkable ability to enhance exploration efficiency and deliver consistent performance gains. The code is available at https://github.com/langfengQ/CoSo.","authors":["Lang Feng","Weihao Tan","Zhiyi Lyu","Longtao Zheng","Haiyang Xu","Ming Yan","Fei Huang","Bo An"],"url":"https://arxiv.org/abs/2505.03792"}
{"created":"2025-06-04","title":"S3D: Sketch-Driven 3D Model Generation","abstract":"Generating high-quality 3D models from 2D sketches is a challenging task due to the inherent ambiguity and sparsity of sketch data. In this paper, we present S3D, a novel framework that converts simple hand-drawn sketches into detailed 3D models. Our method utilizes a U-Net-based encoder-decoder architecture to convert sketches into face segmentation masks, which are then used to generate a 3D representation that can be rendered from novel views. To ensure robust consistency between the sketch domain and the 3D output, we introduce a novel style-alignment loss that aligns the U-Net bottleneck features with the initial encoder outputs of the 3D generation module, significantly enhancing reconstruction fidelity. To further enhance the network's robustness, we apply augmentation techniques to the sketch dataset. This streamlined framework demonstrates the effectiveness of S3D in generating high-quality 3D models from sketch inputs. The source code for this project is publicly available at https://github.com/hailsong/S3D.","authors":["Hail Song","Wonsik Shin","Naeun Lee","Soomin Chung","Nojun Kwak","Woontack Woo"],"url":"https://arxiv.org/abs/2505.04185"}
{"created":"2025-06-04","title":"Modeling of thin plate flexural vibrations by Partition of Unity Finite Element Method","abstract":"This paper presents a conforming thin plate bending element based on the Partition of Unity Finite Element Method (PUFEM), for the simulation of steady-state forced vibration. The issue of ensuring the continuity of displacement and slope between elements is addressed by the use of cubic Hermite-type Partition of Unity (PU) functions. With appropriate PU functions, the PUFEM allows the incorporation of the special enrichment functions into the finite elements to better cope with plate oscillations in a broad frequency band. The enrichment strategies consist of the sum of a power series up to a given order and a combination of progressive flexural wave solutions with polynomials. The applicability and the effectiveness of the PUFEM plate elements is first verified via the structural frequency response. Investigation is then carried out to analyze the role of polynomial enrichment orders and enriched plane wave distributions for achieving good computational performance in terms of accuracy and data reduction. Numerical results show that the PUFEM with high-order polynomials and hybrid wave-polynomial combinations can provide highly accurate prediction results by using reduced degrees of freedom and improved rate of convergence, as compared with the classical FEM.","authors":["Tong Zhou","Jean-Daniel Chazot","Emmanuel Perrey-Debain","Li Cheng"],"url":"https://arxiv.org/abs/2505.04227"}
{"created":"2025-06-04","title":"ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via $\\alpha$-$\\beta$-Divergence","abstract":"Knowledge Distillation (KD) transfers knowledge from a large teacher model to a smaller student model by minimizing the divergence between their output distributions, typically using forward Kullback-Leibler divergence (FKLD) or reverse KLD (RKLD). It has become an effective training paradigm due to the broader supervision information provided by the teacher distribution compared to one-hot labels. We identify that the core challenge in KD lies in balancing two mode-concentration effects: the \\textbf{\\textit{Hardness-Concentration}} effect, which refers to focusing on modes with large errors, and the \\textbf{\\textit{Confidence-Concentration}} effect, which refers to focusing on modes with high student confidence. Through an analysis of how probabilities are reassigned during gradient updates, we observe that these two effects are entangled in FKLD and RKLD, but in extreme forms. Specifically, both are too weak in FKLD, causing the student to fail to concentrate on the target class. In contrast, both are too strong in RKLD, causing the student to overly emphasize the target class while ignoring the broader distributional information from the teacher. To address this imbalance, we propose ABKD, a generic framework with $\\alpha$-$\\beta$-divergence. Our theoretical results show that ABKD offers a smooth interpolation between FKLD and RKLD, achieving an effective trade-off between these effects. Extensive experiments on 17 language/vision datasets with 12 teacher-student settings confirm its efficacy. The code is available at https://github.com/ghwang-s/abkd.","authors":["Guanghui Wang","Zhiyong Yang","Zitai Wang","Shi Wang","Qianqian Xu","Qingming Huang"],"url":"https://arxiv.org/abs/2505.04560"}
{"created":"2025-06-04","title":"ChainMarks: Securing DNN Watermark with Cryptographic Chain","abstract":"With the widespread deployment of deep neural network (DNN) models, dynamic watermarking techniques are being used to protect the intellectual property of model owners. However, recent studies have shown that existing watermarking schemes are vulnerable to watermark removal and ambiguity attacks. Besides, the vague criteria for determining watermark presence further increase the likelihood of such attacks. In this paper, we propose a secure DNN watermarking scheme named ChainMarks, which generates secure and robust watermarks by introducing a cryptographic chain into the trigger inputs and utilizes a two-phase Monte Carlo method for determining watermark presence. First, ChainMarks generates trigger inputs as a watermark dataset by repeatedly applying a hash function over a secret key, where the target labels associated with trigger inputs are generated from the digital signature of model owner. Then, the watermarked model is produced by training a DNN over both the original and watermark datasets. To verify watermarks, we compare the predicted labels of trigger inputs with the target labels and determine ownership with a more accurate decision threshold that considers the classification probability of specific models. Experimental results show that ChainMarks exhibits higher levels of robustness and security compared to state-of-the-art watermarking schemes. With a better marginal utility, ChainMarks provides a higher probability guarantee of watermark presence in DNN models with the same level of watermark accuracy.","authors":["Brian Choi","Shu Wang","Isabelle Choi","Kun Sun"],"url":"https://arxiv.org/abs/2505.04977"}
{"created":"2025-06-04","title":"LSRP: A Leader-Subordinate Retrieval Framework for Privacy-Preserving Cloud-Device Collaboration","abstract":"Cloud-device collaboration leverages on-cloud Large Language Models (LLMs) for handling public user queries and on-device Small Language Models (SLMs) for processing private user data, collectively forming a powerful and privacy-preserving solution. However, existing approaches often fail to fully leverage the scalable problem-solving capabilities of on-cloud LLMs while underutilizing the advantage of on-device SLMs in accessing and processing personalized data. This leads to two interconnected issues: 1) Limited utilization of the problem-solving capabilities of on-cloud LLMs, which fail to align with personalized user-task needs, and 2) Inadequate integration of user data into on-device SLM responses, resulting in mismatches in contextual user information.","authors":["Yingyi Zhang","Pengyue Jia","Xianneng Li","Derong Xu","Maolin Wang","Yichao Wang","Zhaocheng Du","Huifeng Guo","Yong Liu","Ruiming Tang","Xiangyu Zhao"],"url":"https://arxiv.org/abs/2505.05031"}
{"created":"2025-06-04","title":"X-Driver: Explainable Autonomous Driving with Vision-Language Models","abstract":"End-to-end autonomous driving has advanced significantly, offering benefits such as system simplicity and stronger driving performance in both open-loop and closed-loop settings than conventional pipelines. However, existing frameworks still suffer from low success rates in closed-loop evaluations, highlighting their limitations in real-world deployment. In this paper, we introduce X-Driver, a unified multi-modal large language models(MLLMs) framework designed for closed-loop autonomous driving, leveraging Chain-of-Thought(CoT) and autoregressive modeling to enhance perception and decision-making. We validate X-Driver across multiple autonomous driving tasks using public benchmarks in CARLA simulation environment, including Bench2Drive[6]. Our experimental results demonstrate superior closed-loop performance, surpassing the current state-of-the-art(SOTA) while improving the interpretability of driving decisions. These findings underscore the importance of structured reasoning in end-to-end driving and establish X-Driver as a strong baseline for future research in closed-loop autonomous driving.","authors":["Wei Liu","Jiyuan Zhang","Binxiong Zheng","Yufeng Hu","Yingzhan Lin","Zengfeng Zeng"],"url":"https://arxiv.org/abs/2505.05098"}
{"created":"2025-06-04","title":"Empirical Analysis of Transaction Conflicts in Ethereum and Solana for Parallel Execution","abstract":"This paper presents a comprehensive analysis of historical data across two popular blockchain networks: Ethereum and Solana. Our study focuses on two key aspects: transaction conflicts and the maximum theoretical parallelism within historical blocks. We aim to quantify the degree of transaction parallelism and assess how effectively it can be exploited by systematically examining block-level characteristics, both within individual blocks and across different historical periods. In particular, this study is the first of its kind to leverage historical transactional workloads to evaluate transactional conflict patterns. By offering a structured approach to analyzing these conflicts, our research provides valuable insights and an empirical basis for developing more efficient parallel execution techniques for smart contracts in the Ethereum and Solana virtual machines. Our empirical analysis reveals that historical Ethereum blocks frequently achieve high independence, over 50\\% in more than 50\\% of blocks, while Solana historical blocks contain longer conflict chains, comprising $\\sim$59\\% of the block size compared to $\\sim$18\\% in Ethereum, reflecting fundamentally different parallel execution dynamics.","authors":["Parwat Singh Anjana","Srivatsan Ravi"],"url":"https://arxiv.org/abs/2505.05358"}
{"created":"2025-06-04","title":"A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets","abstract":"We introduce a scaling law for fine-tuning large language models (LLMs) under fixed compute budgets that explicitly accounts for data composition. Conventional approaches measure training data solely by total tokens, yet the number of examples and their average token length -- what we term \\emph{dataset volume} -- play a decisive role in model performance. Our formulation is tuned following established procedures. Experiments on the BRICC dataset \\cite{salavati2024reducing} and subsets of the MMLU dataset \\cite{hendrycks2021measuringmassivemultitasklanguage}, evaluated under multiple subsampling strategies, reveal that data composition significantly affects token efficiency. These results motivate refined scaling laws for practical LLM fine-tuning in resource-constrained settings.","authors":["Ryan Lagasse","Aidan Kierans","Avijit Ghosh","Shiri Dori-Hacohen"],"url":"https://arxiv.org/abs/2505.06150"}
{"created":"2025-06-04","title":"Dialz: A Python Toolkit for Steering Vectors","abstract":"We introduce Dialz, a framework for advancing research on steering vectors for open-source LLMs, implemented in Python. Steering vectors allow users to modify activations at inference time to amplify or weaken a 'concept', e.g. honesty or positivity, providing a more powerful alternative to prompting or fine-tuning. Dialz supports a diverse set of tasks, including creating contrastive pair datasets, computing and applying steering vectors, and visualizations. Unlike existing libraries, Dialz emphasizes modularity and usability, enabling both rapid prototyping and in-depth analysis. We demonstrate how Dialz can be used to reduce harmful outputs such as stereotypes, while also providing insights into model behaviour across different layers. We release Dialz with full documentation, tutorials, and support for popular open-source models to encourage further research in safe and controllable language generation. Dialz enables faster research cycles and facilitates insights into model interpretability, paving the way for safer, more transparent, and more reliable AI systems.","authors":["Zara Siddique","Liam D. Turner","Luis Espinosa-Anke"],"url":"https://arxiv.org/abs/2505.06262"}
{"created":"2025-06-04","title":"Learning Soft Sparse Shapes for Efficient Time-Series Classification","abstract":"Shapelets are discriminative subsequences (or shapes) with high interpretability in time series classification. Due to the time-intensive nature of shapelet discovery, existing shapelet-based methods mainly focus on selecting discriminative shapes while discarding others to achieve candidate subsequence sparsification. However, this approach may exclude beneficial shapes and overlook the varying contributions of shapelets to classification performance. To this end, we propose a Soft sparse Shapes (SoftShape) model for efficient time series classification. Our approach mainly introduces soft shape sparsification and soft shape learning blocks. The former transforms shapes into soft representations based on classification contribution scores, merging lower-scored ones into a single shape to retain and differentiate all subsequence information. The latter facilitates intra- and inter-shape temporal pattern learning, improving model efficiency by using sparsified soft shapes as inputs. Specifically, we employ a learnable router to activate a subset of class-specific expert networks for intra-shape pattern learning. Meanwhile, a shared expert network learns inter-shape patterns by converting sparsified shapes into sequences. Extensive experiments show that SoftShape outperforms state-of-the-art methods and produces interpretable results.","authors":["Zhen Liu","Yicheng Luo","Boyuan Li","Emadeldeen Eldele","Min Wu","Qianli Ma"],"url":"https://arxiv.org/abs/2505.06892"}
{"created":"2025-06-04","title":"Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records","abstract":"Medical research, particularly in predicting patient outcomes, heavily relies on medical time series data extracted from Electronic Health Records (EHR), which provide extensive information on patient histories. Despite rigorous examination, labeling errors are inevitable and can significantly impede accurate predictions of patient outcome. To address this challenge, we propose an \\textbf{A}ttention-based Learning Framework with Dynamic \\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy \\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a two-component Beta mixture model to identify the certain and uncertain sets of instances based on the fitness distribution of each class, and it captures global temporal dynamics while dynamically calibrating labels from the uncertain set or augmenting confident instances from the certain set. Experimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and several benchmark datasets from the UCR and UEA repositories, demonstrate that our model ACTLL has achieved state-of-the-art performance, especially under high noise levels.","authors":["Yuhao Li","Ling Luo","Uwe Aickelin"],"url":"https://arxiv.org/abs/2505.07320"}
{"created":"2025-06-04","title":"Neural Signatures Within and Between Chess Puzzle Solving and Standard Cognitive Tasks for Brain-Computer Interfaces: A Low-Cost Electroencephalography Study","abstract":"Consumer-grade electroencephalography (EEG) devices show promise for Brain-Computer Interface (BCI) applications, but their efficacy in detecting subtle cognitive states remains understudied. We developed a comprehensive study paradigm which incorporates a combination of established cognitive tasks (N-Back, Stroop, and Mental Rotation) and adds a novel ecological Chess puzzles task. We tested our paradigm with the MUSE 2, a low-cost consumer-grade EEG device. Using linear mixed-effects modeling we demonstrate successful distinctions of within-task workload levels and cross-task cognitive states based on the spectral power data derived from the MUSE 2 device. With machine learning we further show reliable predictive power to differentiate between workload levels in the N-Back task, and also achieve effective cross-task classification. These findings demonstrate that consumer-grade EEG devices like the MUSE 2 can be used to effectively differentiate between various levels of cognitive workload as well as among more nuanced task-based cognitive states, and that these tools can be leveraged for real-time adaptive BCI applications in practical settings.","authors":["Matthew Russell","Samuel Youkeles","William Xia","Kenny Zheng","Aman Shah","Robert J. K. Jacob"],"url":"https://arxiv.org/abs/2505.07592"}
{"created":"2025-06-04","title":"Relative Overfitting and Accept-Reject Framework","abstract":"Currently, the scaling law of Large Language Models (LLMs) faces challenges and bottlenecks. This paper posits that noise effects, stemming from changes in the signal-to-noise ratio under diminishing marginal returns, are the root cause of these issues. To control this noise, we investigated the differences between models with performance advantages and disadvantages, introducing the concept of \"relative overfitting.\" Based on their complementary strengths, we have proposed an application framework, Accept-Reject (AR), and the associated AR Law, which operates within this framework to elucidate the patterns of performance changes after model integration. In Natural Language Processing (NLP), we use LLMs and Small Language Models (SLMs) as the medium for discussion. This framework enables SLMs to exert a universal positive influence on LLM decision outputs, rather than the intuitively expected potential negative influence. We validated our approach using self-built models based on mainstream architectures and pre-trained mainstream models across multiple datasets, including basic language modeling, long-context tasks, subject examination, and question-answering (QA) benchmarks. The results demonstrate that through our framework, compared to increasing the LLM's parameters, we can achieve better performance improvements with significantly lower parameter and computational costs in many scenarios. These improvements are universal, stable, and effective. Furthermore, we explore the potential of \"relative overfitting\" and the AR framework in other machine learning domains, such as computer vision (CV) and AI for science. We hope the proposed approach can help scale laws overcome existing bottlenecks.","authors":["Yanxin Liu","Yunqi Zhang"],"url":"https://arxiv.org/abs/2505.07783"}
{"created":"2025-06-04","title":"Improving Trajectory Stitching with Flow Models","abstract":"Generative models have shown great promise as trajectory planners, given their affinity to modeling complex distributions and guidable inference process. Previous works have successfully applied these in the context of robotic manipulation but perform poorly when the required solution does not exist as a complete trajectory within the training set. We identify that this is a result of being unable to plan via stitching, and subsequently address the architectural and dataset choices needed to remedy this. On top of this, we propose a novel addition to the training and inference procedures to both stabilize and enhance these capabilities. We demonstrate the efficacy of our approach by generating plans with out of distribution boundary conditions and performing obstacle avoidance on the Franka Panda in simulation and on real hardware. In both of these tasks our method performs significantly better than the baselines and is able to avoid obstacles up to four times as large.","authors":["Reece O'Mahoney","Wanming Yu","Ioannis Havoutis"],"url":"https://arxiv.org/abs/2505.07802"}
{"created":"2025-06-04","title":"KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning","abstract":"Each year, tens of millions of essays are written and graded in college-level English courses. Students are asked to analyze literary and cultural texts through a process known as close reading, in which they gather textual details to formulate evidence-based arguments. Despite being viewed as a basis for critical thinking and widely adopted as a required element of university coursework, close reading has never been evaluated on large language models (LLMs), and multi-discipline benchmarks like MMLU do not include literature as a subject. To fill this gap, we present KRISTEVA, the first close reading benchmark for evaluating interpretive reasoning, consisting of 1331 multiple-choice questions adapted from classroom data. With KRISTEVA, we propose three progressively more difficult sets of tasks to approximate different elements of the close reading process, which we use to test how well LLMs may seem to understand and reason about literary works: 1) extracting stylistic features, 2) retrieving relevant contextual information from parametric knowledge, and 3) multi-hop reasoning between style and external contexts. Our baseline results find that, while state-of-the-art LLMs possess some college-level close reading competency (accuracy 49.7% - 69.7%), their performances still trail those of experienced human evaluators on 10 out of our 11 tasks.","authors":["Peiqi Sui","Juan Diego Rodriguez","Philippe Laban","Dean Murphy","Joseph P. Dexter","Richard Jean So","Samuel Baker","Pramit Chaudhuri"],"url":"https://arxiv.org/abs/2505.09825"}
{"created":"2025-06-04","title":"The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)","abstract":"Foundation Models (FMs) such as Large Language Models (LLMs) are reshaping the software industry by enabling FMware, systems that integrate these FMs as core components. In this KDD 2025 tutorial, we present a comprehensive exploration of FMware that combines a curated catalogue of challenges with real-world production concerns. We first discuss the state of research and practice in building FMware. We further examine the difficulties in selecting suitable models, aligning high-quality domain-specific data, engineering robust prompts, and orchestrating autonomous agents. We then address the complex journey from impressive demos to production-ready systems by outlining issues in system testing, optimization, deployment, and integration with legacy software. Drawing on our industrial experience and recent research in the area, we provide actionable insights and a technology roadmap for overcoming these challenges. Attendees will gain practical strategies to enable the creation of trustworthy FMware in the evolving technology landscape.","authors":["Kirill Vasilevski","Benjamin Rombaut","Gopi Krishnan Rajbahadur","Gustavo A. Oliva","Keheliya Gallaba","Filipe R. Cogo","Jiahuei Lin","Dayi Lin","Haoxiang Zhang","Bouyan Chen","Kishanthan Thangarajah","Ahmed E. Hassan","Zhen Ming Jiang"],"url":"https://arxiv.org/abs/2505.10640"}
{"created":"2025-06-04","title":"Evaluations at Work: Measuring the Capabilities of GenAI in Use","abstract":"Current AI benchmarks miss the messy, multi-turn nature of human-AI collaboration. We present an evaluation framework that decomposes real-world tasks into interdependent subtasks, letting us track both LLM performance and users' strategies across a dialogue. Complementing this framework, we develop a suite of metrics, including a composite usage derived from semantic similarity, word overlap, and numerical matches; structural coherence; intra-turn diversity; and a novel measure of the \"information frontier\" reflecting the alignment between AI outputs and users' working knowledge. We demonstrate our methodology in a financial valuation task that mirrors real-world complexity. Our empirical findings reveal that while greater integration of LLM-generated content generally enhances output quality, its benefits are moderated by factors such as response incoherence, excessive subtask diversity, and the distance of provided information from users' existing knowledge. These results suggest that proactive dialogue strategies designed to inject novelty may inadvertently undermine task performance. Our work thus advances a more holistic evaluation of human-AI collaboration, offering both a robust methodological framework and actionable insights for developing more effective AI-augmented work processes.","authors":["Brandon Lepine","Gawesha Weerantunga","Juho Kim","Pamela Mishkin","Matthew Beane"],"url":"https://arxiv.org/abs/2505.10742"}
{"created":"2025-06-04","title":"Complexity of Firefighting on Graphs","abstract":"We consider a pursuit-evasion game that describes the process of extinguishing a fire burning on the nodes of an undirected graph. We denote the minimum number of firefighters required by $\\text{ffn}(G)$ and provide a characterization for the graphs with $\\text{ffn}(G)=1$ and $\\text{ffn}(G)=2$ as well as almost sharp bounds for complete binary trees. We show that deciding whether $\\text{ffn}(G) \\leq m$ for given $G$ and $m$ is NP-hard. Furthermore, we show that shortest strategies can have superpolynomial length, leaving open whether the problem is in NP. Based on some plausible conjectures, we also prove that this decision problem is neither NP-hard for graphs with bounded treewidth nor for constant $m$.","authors":["Julius Althoetmar","Jamico Schade","Torben Sch\\\"urenberg"],"url":"https://arxiv.org/abs/2505.11082"}
{"created":"2025-06-04","title":"MTevent: A Multi-Task Event Camera Dataset for 6D Pose Estimation and Moving Object Detection","abstract":"Mobile robots are reaching unprecedented speeds, with platforms like Unitree B2, and Fraunhofer O3dyn achieving maximum speeds between 5 and 10 m/s. However, effectively utilizing such speeds remains a challenge due to the limitations of RGB cameras, which suffer from motion blur and fail to provide real-time responsiveness. Event cameras, with their asynchronous operation, and low-latency sensing, offer a promising alternative for high-speed robotic perception. In this work, we introduce MTevent, a dataset designed for 6D pose estimation and moving object detection in highly dynamic environments with large detection distances. Our setup consists of a stereo-event camera and an RGB camera, capturing 75 scenes, each on average 16 seconds, and featuring 16 unique objects under challenging conditions such as extreme viewing angles, varying lighting, and occlusions. MTevent is the first dataset to combine high-speed motion, long-range perception, and real-world object interactions, making it a valuable resource for advancing event-based vision in robotics. To establish a baseline, we evaluate the task of 6D pose estimation using NVIDIA's FoundationPose on RGB images, achieving an Average Recall of 0.22 with ground-truth masks, highlighting the limitations of RGB-based approaches in such dynamic settings. With MTevent, we provide a novel resource to improve perception models and foster further research in high-speed robotic vision. The dataset is available for download https://huggingface.co/datasets/anas-gouda/MTevent","authors":["Shrutarv Awasthi","Anas Gouda","Sven Franke","J\\'er\\^ome Rutinowski","Frank Hoffmann","Moritz Roidl"],"url":"https://arxiv.org/abs/2505.11282"}
{"created":"2025-06-04","title":"Extracting Explainable Dates From Medical Images By Reverse-Engineering UNIX Timestamps","abstract":"Dates often contribute towards highly impactful medical decisions, but it is rarely clear how to extract this data. AI has only just begun to be used transcribe such documents, and common methods are either to trust that the output produced by a complex AI model, or to parse the text using regular expressions. Recent work has established that regular expressions are an explainable form of logic, but it is difficult to decompose these into the component parts that are required to construct precise UNIX timestamps. First, we test publicly-available regular expressions, and we found that these were unable to capture a significant number of our dates. Next, we manually created easily-decomposable regular expressions, and we found that these were able to detect the majority of real dates, but also a lot of sequences of text that look like dates. Finally, we used regular expression synthesis to automatically identify regular expressions from the reverse-engineered UNIX timestamps that we created. We find that regular expressions created by regular expression synthesis detect far fewer sequences of text that look like dates than those that were manually created, at the cost of a slight increase to the number of missed dates. Overall, our results show that regular expressions can be created through regular expression synthesis to identify complex dates and date ranges in text transcriptions. To our knowledge, our proposed way of learning deterministic logic by reverse-engineering several many-one mappings and feeding these into a regular expression synthesiser is a new approach.","authors":["Lee Harris"],"url":"https://arxiv.org/abs/2505.11451"}
{"created":"2025-06-04","title":"Comparing Lexical and Semantic Vector Search Methods When Classifying Medical Documents","abstract":"Classification is a common AI problem, and vector search is a typical solution. This transforms a given body of text into a numerical representation, known as an embedding, and modern improvements to vector search focus on optimising speed and predictive accuracy. This is often achieved through neural methods that aim to learn language semantics. However, our results suggest that these are not always the best solution. Our task was to classify rigidly-structured medical documents according to their content, and we found that using off-the-shelf semantic vector search produced slightly worse predictive accuracy than creating a bespoke lexical vector search model, and that it required significantly more time to execute. These findings suggest that traditional methods deserve to be contenders in the information retrieval toolkit, despite the prevalence and success of neural models.","authors":["Lee Harris"],"url":"https://arxiv.org/abs/2505.11582"}
{"created":"2025-06-04","title":"PoisonArena: Uncovering Competing Poisoning Attacks in Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) systems, widely used to improve the factual grounding of large language models (LLMs), are increasingly vulnerable to poisoning attacks, where adversaries inject manipulated content into the retriever's corpus. While prior research has predominantly focused on single-attacker settings, real-world scenarios often involve multiple, competing attackers with conflicting objectives. In this work, we introduce PoisonArena, the first benchmark to systematically study and evaluate competing poisoning attacks in RAG. We formalize the multi-attacker threat model, where attackers vie to control the answer to the same query using mutually exclusive misinformation. PoisonArena leverages the Bradley-Terry model to quantify each method's competitive effectiveness in such adversarial environments. Through extensive experiments on the Natural Questions and MS MARCO datasets, we demonstrate that many attack strategies successful in isolation fail under competitive pressure. Our findings highlight the limitations of conventional evaluation metrics like Attack Success Rate (ASR) and F1 score and underscore the need for competitive evaluation to assess real-world attack robustness. PoisonArena provides a standardized framework to benchmark and develop future attack and defense strategies under more realistic, multi-adversary conditions.","authors":["Liuji Chen","Xiaofang Yang","Yuanzhuo Lu","Jinghao Zhang","Xin Sun","Qiang Liu","Shu Wu","Jing Dong","Liang Wang"],"url":"https://arxiv.org/abs/2505.12574"}
{"created":"2025-06-04","title":"Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping","abstract":"[Objective] This study focuses on addressing the current lack of a unified formal theoretical framework in machine learning, as well as the deficiencies in interpretability and ethical safety assurance. [Methods] A formal information model is first constructed, utilizing sets of well-formed formulas to explicitly define the ontological states and carrier mappings of typical components in machine learning. Learnable and processable predicates, along with learning and processing functions, are introduced to analyze the logical deduction and constraint rules of the causal chains within models. [Results] A meta-framework for machine learning theory (MLT-MF) is established. Based on this framework, universal definitions for model interpretability and ethical safety are proposed. Furthermore, three key theorems are proved: the equivalence of model interpretability and information recoverability, the assurance of ethical safety, and the estimation of generalization error. [Limitations] The current framework assumes ideal conditions with noiseless information-enabling mappings and primarily targets model learning and processing logic in static scenarios. It does not yet address information fusion and conflict resolution across ontological spaces in multimodal or multi-agent systems. [Conclusions] This work overcomes the limitations of fragmented research and provides a unified theoretical foundation for systematically addressing the critical challenges currently faced in machine learning.","authors":["Jianfeng Xu"],"url":"https://arxiv.org/abs/2505.13182"}
{"created":"2025-06-04","title":"PARF: An Adaptive Abstraction-Strategy Tuner for Static Analysis","abstract":"We launch Parf - a toolkit for adaptively tuning abstraction strategies of static program analyzers in a fully automated manner. Parf models various types of external parameters (encoding abstraction strategies) as random variables subject to probability distributions over latticed parameter spaces. It incrementally refines the probability distributions based on accumulated intermediate results generated by repeatedly sampling and analyzing, thereby ultimately yielding a set of highly accurate abstraction strategies. Parf is implemented on top of Frama-C/Eva - an off-the-shelf open-source static analyzer for C programs. Parf provides a web-based user interface facilitating the intuitive configuration of static analyzers and visualization of dynamic distribution refinement of the abstraction strategies. It further supports the identification of dominant parameters in Frama-C/Eva analysis. Benchmark experiments and a case study demonstrate the competitive performance of Parf for analyzing complex, large-scale real-world programs.","authors":["Zhongyi Wang","Mingshuai Chen","Tengjie Lin","Linyu Yang","Junhao Zhuo","Qiuye Wang","Shengchao Qin","Xiao Yi","Jianwei Yin"],"url":"https://arxiv.org/abs/2505.13229"}
{"created":"2025-06-04","title":"Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation","abstract":"Current speech-LLMs exhibit limited capability in contextual reasoning alongside paralinguistic understanding, primarily due to the lack of Question-Answer (QA) datasets that cover both aspects. We propose a novel framework for dataset generation from in-the-wild speech data, that integrates contextual reasoning with paralinguistic information. It consists of a pseudo paralinguistic label-based data condensation of in-the-wild speech and LLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is validated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct model on a dataset created by our framework and human-generated CPQA dataset. The results also reveal the speech-LLM's limitations in handling empathetic reasoning tasks, highlighting the need for such datasets and more robust models. The proposed framework is first of its kind and has potential in training more robust speech-LLMs with paralinguistic reasoning capabilities.","authors":["Qiongqiong Wang","Hardik B. Sailor","Tianchi Liu","Ai Ti Aw"],"url":"https://arxiv.org/abs/2505.13338"}
{"created":"2025-06-04","title":"A Dataless Reinforcement Learning Approach to Rounding Hyperplane Optimization for Max-Cut","abstract":"The Maximum Cut (MaxCut) problem is NP-Complete, and obtaining its optimal solution is NP-hard in the worst case. As a result, heuristic-based algorithms are commonly used, though their design often requires significant domain expertise. More recently, learning-based methods trained on large (un)labeled datasets have been proposed; however, these approaches often struggle with generalizability and scalability. A well-known approximation algorithm for MaxCut is the Goemans-Williamson (GW) algorithm, which relaxes the Quadratic Unconstrained Binary Optimization (QUBO) formulation into a semidefinite program (SDP). The GW algorithm then applies hyperplane rounding by uniformly sampling a random hyperplane to convert the SDP solution into binary node assignments. In this paper, we propose a training-data-free approach based on a non-episodic reinforcement learning formulation, in which an agent learns to select improved rounding hyperplanes that yield better cuts than those produced by the GW algorithm. By optimizing over a Markov Decision Process (MDP), our method consistently achieves better cuts across large-scale graphs with varying densities and degree distributions.","authors":["Gabriel Malikal","Ismail Alkhouri","Alvaro Velasquez","Adam M Alessio","Saiprasad Ravishankar"],"url":"https://arxiv.org/abs/2505.13405"}
{"created":"2025-06-04","title":"Time-R1: Towards Comprehensive Temporal Reasoning in LLMs","abstract":"Large Language Models (LLMs) demonstrate impressive capabilities but lack robust temporal intelligence, struggling to integrate reasoning about the past with predictions and plausible generations of the future. Meanwhile, existing methods typically target isolated temporal skills, such as question answering about past events or basic forecasting, and exhibit poor generalization, particularly when dealing with events beyond their knowledge cutoff or requiring creative foresight. To address these limitations, we introduce \\textit{Time-R1}, the first framework to endow a moderate-sized (3B-parameter) LLM with comprehensive temporal abilities: understanding, prediction, and creative generation. Our approach features a novel three-stage development path; the first two constitute a \\textit{reinforcement learning (RL) curriculum} driven by a meticulously designed dynamic rule-based reward system. This framework progressively builds (1) foundational temporal understanding and logical event-time mappings from historical data, (2) future event prediction skills for events beyond its knowledge cutoff, and finally (3) enables remarkable generalization to creative future scenario generation without any fine-tuning. Strikingly, experiments demonstrate that Time-R1 outperforms models over 200 times larger, including the state-of-the-art 671B DeepSeek-R1, on highly challenging future event prediction and creative scenario generation benchmarks. This work provides strong evidence that thoughtfully engineered, progressive RL fine-tuning allows smaller, efficient models to achieve superior temporal performance, offering a practical and scalable path towards truly time-aware AI. To foster further research, we also release \\textit{Time-Bench}, a large-scale multi-task temporal reasoning dataset derived from 10 years of news data, and our series of \\textit{Time-R1} checkpoints.","authors":["Zijia Liu","Peixuan Han","Haofei Yu","Haoru Li","Jiaxuan You"],"url":"https://arxiv.org/abs/2505.13508"}
{"created":"2025-06-04","title":"Learning Collision Risk from Naturalistic Driving with Generalised Surrogate Safety Measures","abstract":"Accurate and timely alerts for drivers or automated systems to unfolding collisions remains a challenge in road safety, particularly in highly interactive urban traffic. Existing approaches require labour-intensive annotation of sparse risk, struggle to consider varying contextual factors, or are useful only in the scenarios they are designed for. To address these limits, this study introduces the generalised surrogate safety measure (GSSM), a new approach that learns exclusively from naturalistic driving without crash or risk labels. GSSM captures the patterns of normal driving and estimates the extent to which a traffic interaction deviates from the norm towards unsafe extreme. Utilising neural networks, normal interactions are characterised by context-conditioned distributions of multi-directional spacing between road users. In the same interaction context, a spacing closer than normal entails higher risk of potential collision. Then a context-adaptive risk score and its associated probability can be calculated based on the theory of extreme values. Any measurable factors, such as motion kinematics, weather, lighting, can serve as part of the context, allowing for diverse coverage of safety-critical interactions. Multiple public driving datasets are used to train GSSMs, which are tested with 2,591 real-world crashes and near-crashes reconstructed from the SHRP2 NDS. A vanilla GSSM using only instantaneous states achieves AUPRC of 0.9 and secures a median time advance of 2.6 seconds to prevent potential collisions. Additional data and contextual factors provide further performance gains. Across various interaction types such as rear-end, merging, and crossing, the accuracy and timeliness of GSSM consistently outperforms existing baselines. GSSM therefore establishes a scalable, context-aware, and generalisable foundation to proactively quantify collision risk in traffic interactions.","authors":["Yiru Jiao","Simeon C. Calvert","Sander van Cranenburgh","Hans van Lint"],"url":"https://arxiv.org/abs/2505.13556"}
{"created":"2025-06-04","title":"A Mosaic of Perspectives: Understanding Ownership in Software Engineering","abstract":"Agile software development relies on self-organized teams, underlining the importance of individual responsibility. How developers take responsibility and build ownership are influenced by external factors such as architecture and development methods. This paper examines the existing literature on ownership in software engineering and in psychology, and argues that a more comprehensive view of ownership in software engineering has a great potential in improving software team's work. Initial positions on the issue are offered for discussion and to lay foundations for further research.","authors":["Tomi Suomi","Petri Ihantola","Tommi Mikkonen","Niko M\\\"akitalo"],"url":"https://arxiv.org/abs/2505.14220"}
{"created":"2025-06-04","title":"lmgame-Bench: How Good are LLMs at Playing Games?","abstract":"Playing video games requires perception, memory, and planning, exactly the faculties modern large language model (LLM) agents are expected to master. We study the major challenges in using popular video games to evaluate modern LLMs and find that directly dropping LLMs into games cannot make an effective evaluation, for three reasons -- brittle vision perception, prompt sensitivity, and potential data contamination. We introduce lmgame-Bench to turn games into reliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and narrative games delivered through a unified Gym-style API and paired with lightweight perception and memory scaffolds, and is designed to stabilize prompt variance and remove contamination. Across 13 leading models, we show lmgame-Bench is challenging while still separating models well. Correlation analysis shows that every game probes a unique blend of capabilities often tested in isolation elsewhere. More interestingly, performing reinforcement learning on a single game from lmgame-Bench transfers both to unseen games and to external planning tasks. Our evaluation code is available at https://github.com/lmgame-org/GamingAgent/lmgame-bench.","authors":["Lanxiang Hu","Mingjia Huo","Yuxuan Zhang","Haoyang Yu","Eric P. Xing","Ion Stoica","Tajana Rosing","Haojian Jin","Hao Zhang"],"url":"https://arxiv.org/abs/2505.15146"}
{"created":"2025-06-04","title":"AvatarShield: Visual Reinforcement Learning for Human-Centric Video Forgery Detection","abstract":"The rapid advancement of Artificial Intelligence Generated Content (AIGC) technologies, particularly in video generation, has led to unprecedented creative capabilities but also increased threats to information integrity, identity security, and public trust. Existing detection methods, while effective in general scenarios, lack robust solutions for human-centric videos, which pose greater risks due to their realism and potential for legal and ethical misuse. Moreover, current detection approaches often suffer from poor generalization, limited scalability, and reliance on labor-intensive supervised fine-tuning. To address these challenges, we propose AvatarShield, the first interpretable MLLM-based framework for detecting human-centric fake videos, enhanced via Group Relative Policy Optimization (GRPO). Through our carefully designed accuracy detection reward and temporal compensation reward, it effectively avoids the use of high-cost text annotation data, enabling precise temporal modeling and forgery detection. Meanwhile, we design a dual-encoder architecture, combining high-level semantic reasoning and low-level artifact amplification to guide MLLMs in effective forgery detection. We further collect FakeHumanVid, a large-scale human-centric video benchmark that includes synthesis methods guided by pose, audio, and text inputs, enabling rigorous evaluation of detection methods in real-world scenes. Extensive experiments show that AvatarShield significantly outperforms existing approaches in both in-domain and cross-domain detection, setting a new standard for human-centric video forensics.","authors":["Zhipei Xu","Xuanyu Zhang","Xing Zhou","Jian Zhang"],"url":"https://arxiv.org/abs/2505.15173"}
{"created":"2025-06-04","title":"Multi-Hop Question Generation via Dual-Perspective Keyword Guidance","abstract":"Multi-hop question generation (MQG) aims to generate questions that require synthesizing multiple information snippets from documents to derive target answers. The primary challenge lies in effectively pinpointing crucial information snippets related to question-answer (QA) pairs, typically relying on keywords. However, existing works fail to fully utilize the guiding potential of keywords and neglect to differentiate the distinct roles of question-specific and document-specific keywords. To address this, we define dual-perspective keywords (i.e., question and document keywords) and propose a Dual-Perspective Keyword-Guided (DPKG) framework, which seamlessly integrates keywords into the multi-hop question generation process. We argue that question keywords capture the questioner's intent, whereas document keywords reflect the content related to the QA pair. Functionally, question and document keywords work together to pinpoint essential information snippets in the document, with question keywords required to appear in the generated question. The DPKG framework consists of an expanded transformer encoder and two answer-aware transformer decoders for keyword and question generation, respectively. Extensive experiments demonstrate the effectiveness of our work, showcasing its promising performance and underscoring its significant value in the MQG task.","authors":["Maodong Li","Longyin Zhang","Fang Kong"],"url":"https://arxiv.org/abs/2505.15299"}
{"created":"2025-06-04","title":"Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding","abstract":"Modern autoregressive speech synthesis models leveraging language models have demonstrated remarkable performance. However, the sequential nature of next token prediction in these models leads to significant latency, hindering their deployment in scenarios where inference speed is critical. In this work, we propose Speech Speculative Decoding (SSD), a novel framework for autoregressive speech synthesis acceleration. Specifically, our method employs a lightweight draft model to generate candidate token sequences, which are subsequently verified in parallel by the target model using the proposed SSD framework. Experimental results demonstrate that SSD achieves a significant speedup of 1.4x compared with conventional autoregressive decoding, while maintaining high fidelity and naturalness. Subjective evaluations further validate the effectiveness of SSD in preserving the perceptual quality of the target model while accelerating inference.","authors":["Zijian Lin","Yang Zhang","Yougen Yuan","Yuming Yan","Jinjiang Liu","Zhiyong Wu","Pengfei Hu","Qun Yu"],"url":"https://arxiv.org/abs/2505.15380"}
{"created":"2025-06-04","title":"Ranking Free RAG: Replacing Re-ranking with Selection in RAG for Sensitive Domains","abstract":"Traditional Retrieval-Augmented Generation (RAG) pipelines rely on similarity-based retrieval and re-ranking, which depend on heuristics such as top-k, and lack explainability, interpretability, and robustness against adversarial content. To address this gap, we propose a novel method METEORA that replaces re-ranking in RAG with a rationale-driven selection approach. METEORA operates in two stages. First, a general-purpose LLM is preference-tuned to generate rationales conditioned on the input query using direct preference optimization. These rationales guide the evidence chunk selection engine, which selects relevant chunks in three stages: pairing individual rationales with corresponding retrieved chunks for local relevance, global selection with elbow detection for adaptive cutoff, and context expansion via neighboring chunks. This process eliminates the need for top-k heuristics. The rationales are also used for consistency check using a Verifier LLM to detect and filter poisoned or misleading content for safe generation. The framework provides explainable and interpretable evidence flow by using rationales consistently across both selection and verification. Our evaluation across six datasets spanning legal, financial, and academic research domains shows that METEORA improves generation accuracy by 33.34% while using approximately 50% fewer chunks than state-of-the-art re-ranking methods. In adversarial settings, METEORA significantly improves the F1 score from 0.10 to 0.44 over the state-of-the-art perplexity-based defense baseline, demonstrating strong resilience to poisoning attacks. Code available at: https://anonymous.4open.science/r/METEORA-DC46/README.md","authors":["Yash Saxena","Ankur Padia","Mandar S Chaudhary","Kalpa Gunaratna","Srinivasan Parthasarathy","Manas Gaur"],"url":"https://arxiv.org/abs/2505.16014"}
{"created":"2025-06-04","title":"HASH-RAG: Bridging Deep Hashing with Retriever for Efficient, Fine Retrieval and Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) encounters efficiency challenges when scaling to massive knowledge bases while preserving contextual relevance. We propose Hash-RAG, a framework that integrates deep hashing techniques with systematic optimizations to address these limitations. Our queries directly learn binary hash codes from knowledgebase code, eliminating intermediate feature extraction steps, and significantly reducing storage and computational overhead. Building upon this hash-based efficient retrieval framework, we establish the foundation for fine-grained chunking. Consequently, we design a Prompt-Guided Chunk-to-Context (PGCC) module that leverages retrieved hash-indexed propositions and their original document segments through prompt engineering to enhance the LLM's contextual awareness. Experimental evaluations on NQ, TriviaQA, and HotpotQA datasets demonstrate that our approach achieves a 90% reduction in retrieval time compared to conventional methods while maintaining considerate recall performance. Additionally, The proposed system outperforms retrieval/non-retrieval baselines by 1.4-4.3% in EM scores.","authors":["Jinyu Guo","Xunlei Chen","Qiyang Xia","Zhaokun Wang","Jie Ou","Libo Qin","Shunyu Yao","Wenhong Tian"],"url":"https://arxiv.org/abs/2505.16133"}
{"created":"2025-06-04","title":"CMRINet: Joint Groupwise Registration and Segmentation for Cardiac Function Quantification from Cine-MRI","abstract":"Accurate and efficient quantification of cardiac function is essential for the estimation of prognosis of cardiovascular diseases (CVDs). One of the most commonly used metrics for evaluating cardiac pumping performance is left ventricular ejection fraction (LVEF). However, LVEF can be affected by factors such as inter-observer variability and varying pre-load and after-load conditions, which can reduce its reproducibility. Additionally, cardiac dysfunction may not always manifest as alterations in LVEF, such as in heart failure and cardiotoxicity diseases. An alternative measure that can provide a relatively load-independent quantitative assessment of myocardial contractility is myocardial strain and strain rate. By using LVEF in combination with myocardial strain, it is possible to obtain a thorough description of cardiac function. Automated estimation of LVEF and other volumetric measures from cine-MRI sequences can be achieved through segmentation models, while strain calculation requires the estimation of tissue displacement between sequential frames, which can be accomplished using registration models. These tasks are often performed separately, potentially limiting the assessment of cardiac function. To address this issue, in this study we propose an end-to-end deep learning (DL) model that jointly estimates groupwise (GW) registration and segmentation for cardiac cine-MRI images. The proposed anatomically-guided Deep GW network was trained and validated on a large dataset of 4-chamber view cine-MRI image series of 374 subjects. A quantitative comparison with conventional GW registration using elastix and two DL-based methods showed that the proposed model improved performance and substantially reduced computation time.","authors":["Mohamed S. Elmahdy","Marius Staring","Patrick J. H. de Koning","Samer Alabed","Mahan Salehi","Faisal Alandejani","Michael Sharkey","Ziad Aldabbagh","Andrew J. Swift","Rob J. van der Geest"],"url":"https://arxiv.org/abs/2505.16452"}
{"created":"2025-06-04","title":"Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains","abstract":"Large Language Models (LLMs) achieve superior performance through Chain-of-Thought (CoT) reasoning, but these token-level reasoning chains are computationally expensive and inefficient. In this paper, we introduce Compressed Latent Reasoning (CoLaR), a novel framework that dynamically compresses reasoning processes in latent space through a two-stage training approach. First, during supervised fine-tuning, CoLaR extends beyond next-token prediction by incorporating an auxiliary next compressed embedding prediction objective. This process merges embeddings of consecutive tokens using a compression factor randomly sampled from a predefined range, and trains a specialized latent head to predict distributions of subsequent compressed embeddings. Second, we enhance CoLaR through reinforcement learning (RL) that leverages the latent head's non-deterministic nature to explore diverse reasoning paths and exploit more compact ones. This approach enables CoLaR to: i) perform reasoning at a dense latent level (i.e., silently), substantially reducing reasoning chain length, and ii) dynamically adjust reasoning speed at inference time by simply prompting the desired compression factor. Extensive experiments across four mathematical reasoning datasets demonstrate that CoLaR achieves 14.1% higher accuracy than latent-based baseline methods at comparable compression ratios, and reduces reasoning chain length by 53.3% with only 4.8% performance degradation compared to explicit CoT method. Moreover, when applied to more challenging mathematical reasoning tasks, our RL-enhanced CoLaR demonstrates performance gains of up to 5.4% while dramatically reducing latent reasoning chain length by 82.8%. The code and models will be released upon acceptance.","authors":["Wenhui Tan","Jiaze Li","Jianzhong Ju","Zhenbo Luo","Jian Luan","Ruihua Song"],"url":"https://arxiv.org/abs/2505.16552"}
{"created":"2025-06-04","title":"Training on Plausible Counterfactuals Removes Spurious Correlations","abstract":"Plausible counterfactual explanations (p-CFEs) are perturbations that minimally modify inputs to change classifier decisions while remaining plausible under the data distribution. In this study, we demonstrate that classifiers can be trained on p-CFEs labeled with induced \\emph{incorrect} target classes to classify unperturbed inputs with the original labels. While previous studies have shown that such learning is possible with adversarial perturbations, we extend this paradigm to p-CFEs. Interestingly, our experiments reveal that learning from p-CFEs is even more effective: the resulting classifiers achieve not only high in-distribution accuracy but also exhibit significantly reduced bias with respect to spurious correlations.","authors":["Shpresim Sadiku","Kartikeya Chitranshi","Hiroshi Kera","Sebastian Pokutta"],"url":"https://arxiv.org/abs/2505.16583"}
{"created":"2025-06-04","title":"Can reasoning models comprehend mathematical problems in Chinese ancient texts? An empirical study based on data from Suanjing Shishu","abstract":"This study addresses the challenges in intelligent processing of Chinese ancient mathematical classics by constructing Guji_MATH, a benchmark for evaluating classical texts based on Suanjing Shishu. It systematically assesses the mathematical problem-solving capabilities of mainstream reasoning models under the unique linguistic constraints of classical Chinese. Through machine-assisted annotation and manual verification, 538 mathematical problems were extracted from 8 canonical texts, forming a structured dataset centered on the \"Question-Answer-Solution\" framework, supplemented by problem types and difficulty levels. Dual evaluation modes--closed-book (autonomous problem-solving) and open-book (reproducing classical solution methods)--were designed to evaluate the performance of six reasoning models on ancient Chinese mathematical problems. Results indicate that reasoning models can partially comprehend and solve these problems, yet their overall performance remains inferior to benchmarks on modern mathematical tasks. Enhancing models' classical Chinese comprehension and cultural knowledge should be prioritized for optimization. This study provides methodological support for mining mathematical knowledge from ancient texts and disseminating traditional culture, while offering new perspectives for evaluating cross-linguistic and cross-cultural capabilities of reasoning models.","authors":["Liu Chang","Wang Dongbo","Liu liu","Zhao Zhixiao"],"url":"https://arxiv.org/abs/2505.16660"}
{"created":"2025-06-04","title":"The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm","abstract":"Computing the polar decomposition and the related matrix sign function, has been a well-studied problem in numerical analysis for decades. More recently, it has emerged as an important subroutine in deep learning, particularly within the Muon optimization framework. However, the requirements in this setting differ significantly from those of traditional numerical analysis. In deep learning, methods must be highly efficient and GPU-compatible, but high accuracy is often unnecessary. As a result, classical algorithms like Newton-Schulz (which suffers from slow initial convergence) and methods based on rational functions (which rely on QR decompositions or matrix inverses) are poorly suited to this context. In this work, we introduce Polar Express, a GPU-friendly algorithm for computing the polar decomposition. Like classical polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix multiplications, making it GPU-compatible. Motivated by earlier work of Chen & Chow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule at each iteration by solving a minimax optimization problem, and we prove that it enjoys a strong worst-case optimality guarantee. This property ensures both rapid early convergence and fast asymptotic convergence. We also address finite-precision issues, making it stable in bfloat16 in practice. We apply Polar Express within the Muon optimization framework and show consistent improvements in validation loss on large-scale models such as GPT-2, outperforming recent alternatives across a range of learning rates.","authors":["Noah Amsel","David Persson","Christopher Musco","Robert M. Gower"],"url":"https://arxiv.org/abs/2505.16932"}
{"created":"2025-06-04","title":"NY Real Estate Racial Equity Analysis via Applied Machine Learning","abstract":"This study analyzes tract-level real estate ownership patterns in New York State (NYS) and New York City (NYC) to uncover racial disparities. We use an advanced race/ethnicity imputation model (LSTM+Geo with XGBoost filtering, validated at 89.2% accuracy) to compare the predicted racial composition of property owners to the resident population from census data. We examine both a Full Model (statewide) and a Name-Only LSTM Model (NYC) to assess how incorporating geospatial context affects our predictions and disparity estimates. The results reveal significant inequities: White individuals hold a disproportionate share of properties and property value relative to their population, while Black, Hispanic, and Asian communities are underrepresented as property owners. These disparities are most pronounced in minority-majority neighborhoods, where ownership is predominantly White despite a predominantly non-White population. Corporate ownership (LLCs, trusts, etc.) exacerbates these gaps by reducing owner-occupied opportunities in urban minority communities. We provide a breakdown of ownership vs. population by race for majority-White, -Black, -Hispanic, and -Asian tracts, identify those with extreme ownership disparities, and compare patterns in urban, suburban, and rural contexts. The findings underscore persistent racial inequity in property ownership, reflecting broader historical and socio-economic forces, and highlight the importance of data-driven approaches to address these issues.","authors":["Sanjana Chalavadi","Andrei Pastor","Terry Leitch"],"url":"https://arxiv.org/abs/2505.16946"}
{"created":"2025-06-04","title":"LongMagpie: A Self-synthesis Method for Generating Large-scale Long-context Instructions","abstract":"High-quality long-context instruction data is essential for aligning long-context large language models (LLMs). Despite the public release of models like Qwen and Llama, their long-context instruction data remains proprietary. Human annotation is costly and challenging, while template-based synthesis methods limit scale, diversity, and quality. We introduce LongMagpie, a self-synthesis framework that automatically generates large-scale long-context instruction data. Our key insight is that aligned long-context LLMs, when presented with a document followed by special tokens preceding a user turn, auto-regressively generate contextually relevant queries. By harvesting these document-query pairs and the model's responses, LongMagpie produces high-quality instructions without human effort. Experiments on HELMET, RULER, and Longbench v2 demonstrate that LongMagpie achieves leading performance on long-context tasks while maintaining competitive performance on short-context tasks, establishing it as a simple and effective approach for open, diverse, and scalable long-context instruction data synthesis.","authors":["Chaochen Gao","Xing Wu","Zijia Lin","Debing Zhang","Songlin Hu"],"url":"https://arxiv.org/abs/2505.17134"}
{"created":"2025-06-04","title":"JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model","abstract":"Large language models (LLMs) have revolutionized natural language processing and are increasingly applied to other sequential data types, including genetic sequences. However, adapting LLMs to genomics presents significant challenges. Capturing complex genomic interactions requires modeling long-range dependencies within DNA sequences, where interactions often span over 10,000 base pairs, even within a single gene, posing substantial computational burdens under conventional model architectures and training paradigms. Moreover, standard LLM training approaches are suboptimal for DNA: autoregressive training, while efficient, supports only unidirectional understanding. However, DNA is inherently bidirectional, e.g., bidirectional promoters regulate transcription in both directions and account for nearly 11% of human gene expression. Masked language models (MLMs) allow bidirectional understanding but are inefficient, as only masked tokens contribute to the loss per step. To address these limitations, we introduce JanusDNA, the first bidirectional DNA foundation model built upon a novel pretraining paradigm that combines the optimization efficiency of autoregressive modeling with the bidirectional comprehension of masked modeling. JanusDNA adopts a hybrid Mamba, Attention and Mixture of Experts (MoE) architecture, combining long-range modeling of Attention with efficient sequential learning of Mamba. MoE layers further scale model capacity via sparse activation while keeping computational cost low. Notably, JanusDNA processes up to 1 million base pairs at single nucleotide resolution on a single 80GB GPU. Extensive experiments and ablations show JanusDNA achieves new SOTA results on three genomic representation benchmarks, outperforming models with 250x more activated parameters. Code: https://github.com/Qihao-Duan/JanusDNA","authors":["Qihao Duan","Bingding Huang","Zhenqiao Song","Irina Lehmann","Lei Gu","Roland Eils","Benjamin Wild"],"url":"https://arxiv.org/abs/2505.17257"}
{"created":"2025-06-04","title":"POSTER: A Multi-Signal Model for Detecting Evasive Smishing","abstract":"Smishing, or SMS-based phishing, poses an increasing threat to mobile users by mimicking legitimate communications through culturally adapted, concise, and deceptive messages, which can result in the loss of sensitive data or financial resources. In such, we present a multi-channel smishing detection model that combines country-specific semantic tagging, structural pattern tagging, character-level stylistic cues, and contextual phrase embeddings. We curated and relabeled over 84,000 messages across five datasets, including 24,086 smishing samples. Our unified architecture achieves 97.89% accuracy, an F1 score of 0.963, and an AUC of 99.73%, outperforming single-stream models by capturing diverse linguistic and structural cues. This work demonstrates the effectiveness of multi-signal learning in robust and region-aware phishing.","authors":["Shaghayegh Hosseinpour","Sanchari Das"],"url":"https://arxiv.org/abs/2505.18233"}
{"created":"2025-06-04","title":"G1: Teaching LLMs to Reason on Graphs with Reinforcement Learning","abstract":"Although Large Language Models (LLMs) have demonstrated remarkable progress, their proficiency in graph-related tasks remains notably limited, hindering the development of truly general-purpose models. Previous attempts, including pretraining graph foundation models or employing supervised fine-tuning, often face challenges such as the scarcity of large-scale, universally represented graph data. We introduce G1, a simple yet effective approach demonstrating that Reinforcement Learning (RL) on synthetic graph-theoretic tasks can significantly scale LLMs' graph reasoning abilities. To enable RL training, we curate Erd\\~os, the largest graph reasoning dataset to date comprising 50 diverse graph-theoretic tasks of varying difficulty levels, 100k training data and 5k test data, all drived from real-world graphs. With RL on Erd\\~os, G1 obtains substantial improvements in graph reasoning, where our finetuned 3B model even outperforms Qwen2.5-72B-Instruct (24x size). RL-trained models also show strong zero-shot generalization to unseen tasks, domains, and graph encoding schemes, including other graph-theoretic benchmarks as well as real-world node classification and link prediction tasks, without compromising general reasoning abilities. Our findings offer an efficient, scalable path for building strong graph reasoners by finetuning LLMs with RL on graph-theoretic tasks, which combines the strengths of pretrained LLM capabilities with abundant, automatically generated synthetic data, suggesting that LLMs possess graph understanding abilities that RL can elicit successfully. Our implementation is open-sourced at https://github.com/PKU-ML/G1, with models and datasets hosted on Hugging Face collections https://huggingface.co/collections/PKU-ML/g1-683d659e992794fc99618cf2 for broader accessibility.","authors":["Xiaojun Guo","Ang Li","Yifei Wang","Stefanie Jegelka","Yisen Wang"],"url":"https://arxiv.org/abs/2505.18499"}
{"created":"2025-06-04","title":"One Policy but Many Worlds: A Scalable Unified Policy for Versatile Humanoid Locomotion","abstract":"Humanoid locomotion faces a critical scalability challenge: traditional reinforcement learning (RL) methods require task-specific rewards and struggle to leverage growing datasets, even as more training terrains are introduced. We propose DreamPolicy, a unified framework that enables a single policy to master diverse terrains and generalize zero-shot to unseen scenarios by systematically integrating offline data and diffusion-driven motion synthesis. At its core, DreamPolicy introduces Humanoid Motion Imagery (HMI) - future state predictions synthesized through an autoregressive terrain-aware diffusion planner curated by aggregating rollouts from specialized policies across various distinct terrains. Unlike human motion datasets requiring laborious retargeting, our data directly captures humanoid kinematics, enabling the diffusion planner to synthesize \"dreamed\" trajectories that encode terrain-specific physical constraints. These trajectories act as dynamic objectives for our HMI-conditioned policy, bypassing manual reward engineering and enabling cross-terrain generalization. DreamPolicy addresses the scalability limitations of prior methods: while traditional RL fails to exploit growing datasets, our framework scales seamlessly with more offline data. As the dataset expands, the diffusion prior learns richer locomotion skills, which the policy leverages to master new terrains without retraining. Experiments demonstrate that DreamPolicy achieves average 90% success rates in training environments and an average of 20% higher success on unseen terrains than the prevalent method. It also generalizes to perturbed and composite scenarios where prior approaches collapse. By unifying offline data, diffusion-based trajectory synthesis, and policy optimization, DreamPolicy overcomes the \"one task, one policy\" bottleneck, establishing a paradigm for scalable, data-driven humanoid control.","authors":["Yahao Fan","Tianxiang Gui","Kaiyang Ji","Shutong Ding","Chixuan Zhang","Jiayuan Gu","Jingyi Yu","Jingya Wang","Ye Shi"],"url":"https://arxiv.org/abs/2505.18780"}
{"created":"2025-06-04","title":"LLM-Guided Taxonomy and Hierarchical Uncertainty for 3D Point Cloud Active Learning","abstract":"We present a novel active learning framework for 3D point cloud semantic segmentation that, for the first time, integrates large language models (LLMs) to construct hierarchical label structures and guide uncertainty-based sample selection. Unlike prior methods that treat labels as flat and independent, our approach leverages LLM prompting to automatically generate multi-level semantic taxonomies and introduces a recursive uncertainty projection mechanism that propagates uncertainty across hierarchy levels. This enables spatially diverse, label-aware point selection that respects the inherent semantic structure of 3D scenes. Experiments on S3DIS and ScanNet v2 show that our method achieves up to 4% mIoU improvement under extremely low annotation budgets (e.g., 0.02%), substantially outperforming existing baselines. Our results highlight the untapped potential of LLMs as knowledge priors in 3D vision and establish hierarchical uncertainty modeling as a powerful paradigm for efficient point cloud annotation.","authors":["Chenxi Li","Nuo Chen","Fengyun Tan","Yantong Chen","Bochun Yuan","Tianrui Li","Chongshou Li"],"url":"https://arxiv.org/abs/2505.18924"}
{"created":"2025-06-04","title":"Toward Scientific Reasoning in LLMs: Training from Expert Discussions via Reinforcement Learning","abstract":"We investigate how to teach large language models (LLMs) to perform scientific reasoning by leveraging expert discussions as a learning signal. Focusing on the genomics domain, we develop an automated pipeline to extract trainable data and introduce Genome-Bench, a new benchmark constructed from over a decade of scientific forum discussions on genome engineering. Our pipeline transforms raw interactions into a reinforcement learning-friendly multiple-choice questions format, supported by 3000+ high-quality question-answer pairs spanning foundational biology, experimental troubleshooting, tool usage, and beyond. We fine-tune an LLM using RL with a rule-based reward signal derived from the synthetic MCQ dataset to enhance domain-specific reasoning. Our results show that reinforcement learning from scientific discussions improves model performance by over 15% compared to the base model on Genome-Bench, narrowing the gap between open-source LLMs and expert-level reasoning. To our knowledge, this is the first end-to-end pipeline for teaching LLMs to reason from scientific discussions, with promising potential for generalization across scientific domains beyond biology.","authors":["Ming Yin","Yuanhao Qu","Ling Yang","Le Cong","Mengdi Wang"],"url":"https://arxiv.org/abs/2505.19501"}
{"created":"2025-06-04","title":"Improving Heart Rejection Detection in XPCI Images Using Synthetic Data Augmentation","abstract":"Accurate identification of acute cellular rejection (ACR) in endomyocardial biopsies is essential for effective management of heart transplant patients. However, the rarity of high-grade rejection cases (3R) presents a significant challenge for training robust deep learning models. This work addresses the class imbalance problem by leveraging synthetic data generation using StyleGAN to augment the limited number of real 3R images. Prior to GAN training, histogram equalization was applied to standardize image appearance and improve the consistency of tissue representation. StyleGAN was trained on available 3R biopsy patches and subsequently used to generate 10,000 realistic synthetic images. These were combined with real 0R samples, that is samples without rejection, in various configurations to train ResNet-18 classifiers for binary rejection classification.","authors":["Jakov Samard\\v{z}ija","Donik Vr\\v{s}nak","Sven Lon\\v{c}ari\\'c"],"url":"https://arxiv.org/abs/2505.19746"}
{"created":"2025-06-04","title":"Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM","abstract":"Recent advancements in image-to-video (I2V) generation have shown promising performance in conventional scenarios. However, these methods still encounter significant challenges when dealing with complex scenes that require a deep understanding of nuanced motion and intricate object-action relationships. To address these challenges, we present Dynamic-I2V, an innovative framework that integrates Multimodal Large Language Models (MLLMs) to jointly encode visual and textual conditions for a diffusion transformer (DiT) architecture. By leveraging the advanced multimodal understanding capabilities of MLLMs, our model significantly improves motion controllability and temporal coherence in synthesized videos. The inherent multimodality of Dynamic-I2V further enables flexible support for diverse conditional inputs, extending its applicability to various downstream generation tasks. Through systematic analysis, we identify a critical limitation in current I2V benchmarks: a significant bias towards favoring low-dynamic videos, stemming from an inadequate balance between motion complexity and visual quality metrics. To resolve this evaluation gap, we propose DIVE - a novel assessment benchmark specifically designed for comprehensive dynamic quality measurement in I2V generation. In conclusion, extensive quantitative and qualitative experiments confirm that Dynamic-I2V attains state-of-the-art performance in image-to-video generation, particularly revealing significant improvements of 42.5%, 7.9%, and 11.8% in dynamic range, controllability, and quality, respectively, as assessed by the DIVE metric in comparison to existing methods.","authors":["Peng Liu","Xiaoming Ren","Fengkai Liu","Qingsong Xie","Quanlong Zheng","Yanhao Zhang","Haonan Lu","Yujiu Yang"],"url":"https://arxiv.org/abs/2505.19901"}
{"created":"2025-06-04","title":"Automatic Metadata Extraction for Text-to-SQL","abstract":"Large Language Models (LLMs) have recently become sophisticated enough to automate many tasks ranging from pattern finding to writing assistance to code generation. In this paper, we examine text-to-SQL generation. We have observed from decades of experience that the most difficult part of query development lies in understanding the database contents. These experiences inform the direction of our research.","authors":["Vladislav Shkapenyuk","Divesh Srivastava","Theodore Johnson","Parisa Ghane"],"url":"https://arxiv.org/abs/2505.19988"}
{"created":"2025-06-04","title":"On the class of coding optimality of human languages and the origins of Zipf's law","abstract":"Here we present a new class of optimality for coding systems. Members of that class are displaced linearly from optimal coding and thus exhibit Zipf's law, namely a power-law distribution of frequency ranks. Within that class, Zipf's law, the size-rank law and the size-probability law form a group-like structure. We identify human languages that are members of the class. All languages showing sufficient agreement with Zipf's law are potential members of the class. In contrast, there are communication systems in other species that cannot be members of that class for exhibiting an exponential distribution instead but dolphins and humpback whales might. We provide a new insight into plots of frequency versus rank in double logarithmic scale. For any system, a straight line in that scale indicates that the lengths of optimal codes under non-singular coding and under uniquely decodable encoding are displaced by a linear function whose slope is the exponent of Zipf's law. For systems under compression and constrained to be uniquely decodable, such a straight line may indicate that the system is coding close to optimality. Our findings provide support for the hypothesis that Zipf's law originates from compression.","authors":["Ramon Ferrer-i-Cancho"],"url":"https://arxiv.org/abs/2505.20015"}
{"created":"2025-06-04","title":"HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters","abstract":"Recent years have witnessed significant progress in audio-driven human animation. However, critical challenges remain in (i) generating highly dynamic videos while preserving character consistency, (ii) achieving precise emotion alignment between characters and audio, and (iii) enabling multi-character audio-driven animation. To address these challenges, we propose HunyuanVideo-Avatar, a multimodal diffusion transformer (MM-DiT)-based model capable of simultaneously generating dynamic, emotion-controllable, and multi-character dialogue videos. Concretely, HunyuanVideo-Avatar introduces three key innovations: (i) A character image injection module is designed to replace the conventional addition-based character conditioning scheme, eliminating the inherent condition mismatch between training and inference. This ensures the dynamic motion and strong character consistency; (ii) An Audio Emotion Module (AEM) is introduced to extract and transfer the emotional cues from an emotion reference image to the target generated video, enabling fine-grained and accurate emotion style control; (iii) A Face-Aware Audio Adapter (FAA) is proposed to isolate the audio-driven character with latent-level face mask, enabling independent audio injection via cross-attention for multi-character scenarios. These innovations empower HunyuanVideo-Avatar to surpass state-of-the-art methods on benchmark datasets and a newly proposed wild dataset, generating realistic avatars in dynamic, immersive scenarios.","authors":["Yi Chen","Sen Liang","Zixiang Zhou","Ziyao Huang","Yifeng Ma","Junshu Tang","Qin Lin","Yuan Zhou","Qinglin Lu"],"url":"https://arxiv.org/abs/2505.20156"}
{"created":"2025-06-04","title":"One-shot Entropy Minimization","abstract":"We trained 13,440 large language models and found that entropy minimization requires only a single unlabeled data and 10 steps optimization to achieve performance improvements comparable to or even greater than those obtained using thousands of data and carefully designed rewards in rule-based reinforcement learning. This striking result may prompt a rethinking of post-training paradigms for large language models. Our code is avaliable at https://github.com/zitian-gao/one-shot-em.","authors":["Zitian Gao","Lynx Chen","Joey Zhou","Bryan Dai"],"url":"https://arxiv.org/abs/2505.20282"}
{"created":"2025-06-04","title":"OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation","abstract":"Subject-to-Video (S2V) generation aims to create videos that faithfully incorporate reference content, providing enhanced flexibility in the production of videos. To establish the infrastructure for S2V generation, we propose OpenS2V-Nexus, consisting of (i) OpenS2V-Eval, a fine-grained benchmark, and (ii) OpenS2V-5M, a million-scale dataset. In contrast to existing S2V benchmarks inherited from VBench that focus on global and coarse-grained assessment of generated videos, OpenS2V-Eval focuses on the model's ability to generate subject-consistent videos with natural subject appearance and identity fidelity. For these purposes, OpenS2V-Eval introduces 180 prompts from seven major categories of S2V, which incorporate both real and synthetic test data. Furthermore, to accurately align human preferences with S2V benchmarks, we propose three automatic metrics, NexusScore, NaturalScore and GmeScore, to separately quantify subject consistency, naturalness, and text relevance in generated videos. Building on this, we conduct a comprehensive evaluation of 18 representative S2V models, highlighting their strengths and weaknesses across different content. Moreover, we create the first open-source large-scale S2V generation dataset OpenS2V-5M, which consists of five million high-quality 720P subject-text-video triples. Specifically, we ensure subject-information diversity in our dataset by (1) segmenting subjects and building pairing information via cross-video associations and (2) prompting GPT-Image-1 on raw frames to synthesize multi-view representations. Through OpenS2V-Nexus, we deliver a robust infrastructure to accelerate future S2V generation research.","authors":["Shenghai Yuan","Xianyi He","Yufan Deng","Yang Ye","Jinfa Huang","Bin Lin","Jiebo Luo","Li Yuan"],"url":"https://arxiv.org/abs/2505.20292"}
{"created":"2025-06-04","title":"Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms","abstract":"Precise control over language model generation is vital for ensuring both safety and reliability. Although prompt engineering and steering are commonly used to intervene in model behaviors, the vast number of parameters in models often results in highly intertwined internal representations. This interdependency can limit control precision and sometimes lead to unintended side effects. Recent research has explored the use of sparse autoencoders (SAE) to disentangle knowledge in high-dimensional spaces for steering. However, these applications have been limited to toy tasks owing to the nontrivial issue of locating atomic knowledge components. In this paper, we propose Steering Target Atoms (STA), a novel method that isolates and manipulates disentangled knowledge components to enhance safety. Comprehensive experiments demonstrate the effectiveness of our approach. Further analysis reveals that steering exhibits superior robustness and flexibility, particularly in adversarial scenarios. We also apply the steering strategy to the large reasoning model, confirming its effectiveness in precise reasoning control.","authors":["Mengru Wang","Ziwen Xu","Shengyu Mao","Shumin Deng","Zhaopeng Tu","Huajun Chen","Ningyu Zhang"],"url":"https://arxiv.org/abs/2505.20322"}
{"created":"2025-06-04","title":"Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series","abstract":"The field of hypothesis generation promises to reduce costs in neuroscience by narrowing the range of interventional studies needed to study various phenomena. Existing machine learning methods can generate scientific hypotheses from complex datasets, but many approaches assume causal relationships are static over time, limiting their applicability to systems with dynamic, state-dependent behavior, such as the brain. While some techniques attempt dynamic causal discovery through factor models, they often restrict relationships to linear patterns or impose other simplifying assumptions. We propose a novel method that models dynamic graphs as a conditionally weighted superposition of static graphs, where each static graph can capture nonlinear relationships. This approach enables the detection of complex, time-varying interactions between variables beyond linear limitations. Our method improves f1-scores of predicted dynamic causal patterns by roughly 22-28% on average over baselines in some of our experiments, with some improvements reaching well over 60%. A case study on real brain data demonstrates our method's ability to uncover relationships linked to specific behavioral states, offering valuable insights into neural dynamics.","authors":["Zachary C. Brown","David Carlson"],"url":"https://arxiv.org/abs/2505.20697"}
{"created":"2025-06-04","title":"Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models","abstract":"Negative guidance -- explicitly suppressing unwanted attributes -- remains a fundamental challenge in diffusion models, particularly in few-step sampling regimes. While Classifier-Free Guidance (CFG) works well in standard settings, it fails under aggressive sampling step compression due to divergent predictions between positive and negative branches. We present Normalized Attention Guidance (NAG), an efficient, training-free mechanism that applies extrapolation in attention space with L1-based normalization and refinement. NAG restores effective negative guidance where CFG collapses while maintaining fidelity. Unlike existing approaches, NAG generalizes across architectures (UNet, DiT), sampling regimes (few-step, multi-step), and modalities (image, video), functioning as a \\textit{universal} plug-in with minimal computational overhead. Through extensive experimentation, we demonstrate consistent improvements in text alignment (CLIP Score), fidelity (FID, PFID), and human-perceived quality (ImageReward). Our ablation studies validate each design component, while user studies confirm significant preference for NAG-guided outputs. As a model-agnostic inference-time approach requiring no retraining, NAG provides effortless negative guidance for all modern diffusion frameworks -- pseudocode in the Appendix!","authors":["Dar-Yen Chen","Hmrishav Bandyopadhyay","Kai Zou","Yi-Zhe Song"],"url":"https://arxiv.org/abs/2505.21179"}
{"created":"2025-06-04","title":"Why Do More Experts Fail? A Theoretical Analysis of Model Merging","abstract":"Model merging dramatically reduces storage and computational resources by combining multiple expert models into a single multi-task model. Although recent model merging methods have shown promising results, they struggle to maintain performance gains as the number of merged models increases. In this paper, we investigate the key obstacles that limit the scalability of model merging when integrating a large number of expert models. First, we prove that there is an upper bound on model merging. Further theoretical analysis reveals that the limited effective parameter space imposes a strict constraint on the number of models that can be successfully merged. Gaussian Width shows that the marginal benefit of merging additional models diminishes according to a strictly concave function. This implies that the effective parameter space becomes rapidly saturated as the number of merged models increases. Furthermore, using Approximate Kinematics Theory, we prove the existence of a unique optimal threshold beyond which adding more models does not yield significant performance improvements. At the same time, we introduce a straightforward Reparameterized Heavy-Tailed method (RHT) to extend the coverage of the merged model, thereby enhancing its performance. Empirical results on 12 benchmarks, including both knowledge-intensive and general-purpose tasks, validate our theoretical analysis. We believe that these results spark further research beyond the current scope of model merging. The source code is in the Github repository: https://github.com/wzj1718/ModelMergingAnalysis.","authors":["Zijing Wang","Xingle Xu","Yongkang Liu","Yiqun Zhang","Peiqin Lin","Shi Feng","Xiaocui Yang","Daling Wang","Hinrich Sch\\\"utze"],"url":"https://arxiv.org/abs/2505.21226"}
{"created":"2025-06-04","title":"GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning","abstract":"Publicly significant images from events hold valuable contextual information, crucial for journalism and education. However, existing methods often struggle to extract this relevance accurately. To address this, we introduce GETReason (Geospatial Event Temporal Reasoning), a framework that moves beyond surface-level image descriptions to infer deeper contextual meaning. We propose that extracting global event, temporal, and geospatial information enhances understanding of an image's significance. Additionally, we introduce GREAT (Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric for evaluating reasoning-based image understanding. Our layered multi-agent approach, assessed using a reasoning-weighted metric, demonstrates that meaningful insights can be inferred, effectively linking images to their broader event context.","authors":["Shikhhar Siingh","Abhinav Rawat","Chitta Baral","Vivek Gupta"],"url":"https://arxiv.org/abs/2505.21863"}
{"created":"2025-06-04","title":"InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective","abstract":"The Segment Anything Model (SAM), a vision foundation model, exhibits impressive zero-shot capabilities in general tasks but struggles in specialized domains. Parameter-efficient fine-tuning (PEFT) is a promising approach to unleash the potential of SAM in novel scenarios. However, existing PEFT methods for SAM neglect the domain-invariant relations encoded in the pre-trained model. To bridge this gap, we propose InfoSAM, an information-theoretic approach that enhances SAM fine-tuning by distilling and preserving its pre-trained segmentation knowledge. Specifically, we formulate the knowledge transfer process as two novel mutual information-based objectives: (i) to compress the domain-invariant relation extracted from pre-trained SAM, excluding pseudo-invariant information as possible, and (ii) to maximize mutual information between the relational knowledge learned by the teacher (pre-trained SAM) and the student (fine-tuned model). The proposed InfoSAM establishes a robust distillation framework for PEFT of SAM. Extensive experiments across diverse benchmarks validate InfoSAM's effectiveness in improving SAM family's performance on real-world tasks, demonstrating its adaptability and superiority in handling specialized scenarios.","authors":["Yuanhong Zhang","Muyao Yuan","Weizhan Zhang","Tieliang Gong","Wen Wen","Jiangyong Ying","Weijie Shi"],"url":"https://arxiv.org/abs/2505.21920"}
{"created":"2025-06-04","title":"VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning","abstract":"Effectively retrieving, reasoning and understanding visually rich information remains a challenge for RAG methods. Traditional text-based methods cannot handle visual-related information. On the other hand, current vision-based RAG approaches are often limited by fixed pipelines and frequently struggle to reason effectively due to the insufficient activation of the fundamental capabilities of models. As RL has been proven to be beneficial for model reasoning, we introduce VRAG-RL, a novel RL framework tailored for complex reasoning across visually rich information. With this framework, VLMs interact with search engines, autonomously sampling single-turn or multi-turn reasoning trajectories with the help of visual perception tokens and undergoing continual optimization based on these samples. Our approach highlights key limitations of RL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely incorporate images into the context, leading to insufficient reasoning token allocation and neglecting visual-specific perception; and (ii) When models interact with search engines, their queries often fail to retrieve relevant information due to the inability to articulate requirements, thereby leading to suboptimal performance. To address these challenges, we define an action space tailored for visually rich inputs, with actions including cropping and scaling, allowing the model to gather information from a coarse-to-fine perspective. Furthermore, to bridge the gap between users' original inquiries and the retriever, we employ a simple yet effective reward that integrates query rewriting and retrieval performance with a model-based reward. Our VRAG-RL optimizes VLMs for RAG tasks using specially designed RL strategies, aligning the model with real-world applications. The code is available at https://github.com/Alibaba-NLP/VRAG.","authors":["Qiuchen Wang","Ruixue Ding","Yu Zeng","Zehui Chen","Lin Chen","Shihang Wang","Pengjun Xie","Fei Huang","Feng Zhao"],"url":"https://arxiv.org/abs/2505.22019"}
{"created":"2025-06-04","title":"A Closer Look at the Existing Risks of Generative AI: Mapping the Who, What, and How of Real-World Incidents","abstract":"Due to its general-purpose nature, Generative AI is applied in an ever-growing set of domains and tasks, leading to an expanding set of risks of harm impacting people, communities, society, and the environment. These risks may arise due to failures during the design and development of the technology, as well as during its release, deployment, or downstream usages and appropriations of its outputs. In this paper, building on prior taxonomies of AI risks, harms, and failures, we construct a taxonomy specifically for Generative AI failures and map them to the harms they precipitate. Through a systematic analysis of 499 publicly reported incidents, we describe what harms are reported, how they arose, and who they impact. We report the prevalence of each type of harm, underlying failure mode, and harmed stakeholder, as well as their common co-occurrences. We find that most reported incidents are caused by use-related issues but bring harm to parties beyond the end user(s) of the Generative AI system at fault, and that the landscape of Generative AI harms is distinct from that of traditional AI. Our work offers actionable insights to policymakers, developers, and Generative AI users. In particular, we call for the prioritization of non-technical risk and harm mitigation strategies, including public disclosures and education and careful regulatory stances.","authors":["Megan Li","Wendy Bickersteth","Ningjing Tang","Jason Hong","Lorrie Cranor","Hong Shen","Hoda Heidari"],"url":"https://arxiv.org/abs/2505.22073"}
{"created":"2025-06-04","title":"Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model","abstract":"Intraoperative hypotension (IOH) frequently occurs under general anesthesia and is strongly linked to adverse outcomes such as myocardial injury and increased mortality. Despite its significance, IOH prediction is hindered by event sparsity and the challenge of integrating static and dynamic data across diverse patients. In this paper, we propose \\textbf{IOHFuseLM}, a multimodal language model framework. To accurately identify and differentiate sparse hypotensive events, we leverage a two-stage training strategy. The first stage involves domain adaptive pretraining on IOH physiological time series augmented through diffusion methods, thereby enhancing the model sensitivity to patterns associated with hypotension. Subsequently, task fine-tuning is performed on the original clinical dataset to further enhance the ability to distinguish normotensive from hypotensive states. To enable multimodal fusion for each patient, we align structured clinical descriptions with the corresponding physiological time series at the token level. Such alignment enables the model to capture individualized temporal patterns alongside their corresponding clinical semantics. In addition, we convert static patient attributes into structured text to enrich personalized information. Experimental evaluations on two intraoperative datasets demonstrate that IOHFuseLM outperforms established baselines in accurately identifying IOH events, highlighting its applicability in clinical decision support scenarios. Our code is publicly available to promote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.","authors":["Jintao Zhang","Zirui Liu","Mingyue Cheng","Shilong Zhang","Tingyue Pan","Qi Liu","Yanhu Xie"],"url":"https://arxiv.org/abs/2505.22116"}
{"created":"2025-06-04","title":"What Has Been Lost with Synthetic Evaluation?","abstract":"Large language models (LLMs) are increasingly used for data generation. However, creating evaluation benchmarks raises the bar for this emerging paradigm. Benchmarks must target specific phenomena, penalize exploiting shortcuts, and be challenging. Through two case studies, we investigate whether LLMs can meet these demands by generating reasoning over-text benchmarks and comparing them to those created through careful crowdsourcing. Specifically, we evaluate both the validity and difficulty of LLM-generated versions of two high-quality reading comprehension datasets: CondaQA, which evaluates reasoning about negation, and DROP, which targets reasoning about quantities. We find that prompting LLMs can produce variants of these datasets that are often valid according to the annotation guidelines, at a fraction of the cost of the original crowdsourcing effort. However, we show that they are less challenging for LLMs than their human-authored counterparts. This finding sheds light on what may have been lost by generating evaluation data with LLMs, and calls for critically reassessing the immediate use of this increasingly prevalent approach to benchmark creation.","authors":["Alexander Gill","Abhilasha Ravichander","Ana Marasovi\\'c"],"url":"https://arxiv.org/abs/2505.22830"}
{"created":"2025-06-04","title":"LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference","abstract":"There is increasing evidence of Human Label Variation (HLV) in Natural Language Inference (NLI), where annotators assign different labels to the same premise-hypothesis pair. However, within-label variation--cases where annotators agree on the same label but provide divergent reasoning--poses an additional and mostly overlooked challenge. Several NLI datasets contain highlighted words in the NLI item as explanations, but the same spans on the NLI item can be highlighted for different reasons, as evidenced by free-text explanations, which offer a window into annotators' reasoning. To systematically understand this problem and gain insight into the rationales behind NLI labels, we introduce LITEX, a linguistically-informed taxonomy for categorizing free-text explanations. Using this taxonomy, we annotate a subset of the e-SNLI dataset, validate the taxonomy's reliability, and analyze how it aligns with NLI labels, highlights, and explanations. We further assess the taxonomy's usefulness in explanation generation, demonstrating that conditioning generation on LITEX yields explanations that are linguistically closer to human explanations than those generated using only labels or highlights. Our approach thus not only captures within-label variation but also shows how taxonomy-guided generation for reasoning can bridge the gap between human and model explanations more effectively than existing strategies.","authors":["Pingjun Hong","Beiduo Chen","Siyao Peng","Marie-Catherine de Marneffe","Barbara Plank"],"url":"https://arxiv.org/abs/2505.22848"}
{"created":"2025-06-04","title":"DyePack: Provably Flagging Test Set Contamination in LLMs Using Backdoors","abstract":"Open benchmarks are essential for evaluating and advancing large language models, offering reproducibility and transparency. However, their accessibility makes them likely targets of test set contamination. In this work, we introduce DyePack, a framework that leverages backdoor attacks to identify models that used benchmark test sets during training, without requiring access to the loss, logits, or any internal details of the model. Like how banks mix dye packs with their money to mark robbers, DyePack mixes backdoor samples with the test data to flag models that trained on it. We propose a principled design incorporating multiple backdoors with stochastic targets, enabling exact false positive rate (FPR) computation when flagging every model. This provably prevents false accusations while providing strong evidence for every detected case of contamination. We evaluate DyePack on five models across three datasets, covering both multiple-choice and open-ended generation tasks. For multiple-choice questions, it successfully detects all contaminated models with guaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard using eight backdoors. For open-ended generation tasks, it generalizes well and identifies all contaminated models on Alpaca with a guaranteed false positive rate of just 0.127% using six backdoors.","authors":["Yize Cheng","Wenxiao Wang","Mazda Moayeri","Soheil Feizi"],"url":"https://arxiv.org/abs/2505.23001"}
{"created":"2025-06-04","title":"Dataset Cartography for Large Language Model Alignment: Mapping and Diagnosing Preference Data","abstract":"Human preference data plays a critical role in aligning large language models (LLMs) with human values. However, collecting such data is often expensive and inefficient, posing a significant scalability challenge. To address this, we introduce Alignment Data Map, a GPT-4o-assisted tool for analyzing and diagnosing preference data. Using GPT-4o as a proxy for LLM alignment, we compute alignment scores for LLM-generated responses to instructions from existing preference datasets. These scores are then used to construct an Alignment Data Map based on their mean and variance. Our experiments show that using only 33 percent of the data, specifically samples in the high-mean, low-variance region, achieves performance comparable to or better than using the entire dataset. This finding suggests that the Alignment Data Map can significantly improve data collection efficiency by identifying high-quality samples for LLM alignment without requiring explicit annotations. Moreover, the Alignment Data Map can diagnose existing preference datasets. Our analysis shows that it effectively detects low-impact or potentially misannotated samples. Source code is available online.","authors":["Seohyeong Lee","Eunwon Kim","Hwaran Lee","Buru Chang"],"url":"https://arxiv.org/abs/2505.23114"}
{"created":"2025-06-04","title":"DeepRTE: Pre-trained Attention-based Neural Network for Radiative Tranfer","abstract":"In this paper, we propose a novel neural network approach, termed DeepRTE, to address the steady-state Radiative Transfer Equation (RTE). The RTE is a differential-integral equation that governs the propagation of radiation through a participating medium, with applications spanning diverse domains such as neutron transport, atmospheric radiative transfer, heat transfer, and optical imaging. Our DeepRTE framework demonstrates superior computational efficiency for solving the steady-state RTE, surpassing traditional methods and existing neural network approaches. This efficiency is achieved by embedding physical information through derivation of the RTE and mathematically-informed network architecture. Concurrently, DeepRTE achieves high accuracy with significantly fewer parameters, largely due to its incorporation of mechanisms such as multi-head attention. Furthermore, DeepRTE is a mesh-free neural operator framework with inherent zero-shot capability. This is achieved by incorporating Green's function theory and pre-training with delta-function inflow boundary conditions into both its architecture design and training data construction. The efficacy of the proposed approach is substantiated through comprehensive numerical experiments.","authors":["Yekun Zhu","Min Tang","Zheng Ma"],"url":"https://arxiv.org/abs/2505.23190"}
{"created":"2025-06-04","title":"Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain Human Label Variation","abstract":"The recent rise of reasoning-tuned Large Language Models (LLMs)--which generate chains of thought (CoTs) before giving the final answer--has attracted significant attention and offers new opportunities for gaining insights into human label variation, which refers to plausible differences in how multiple annotators label the same data instance. Prior work has shown that LLM-generated explanations can help align model predictions with human label distributions, but typically adopt a reverse paradigm: producing explanations based on given answers. In contrast, CoTs provide a forward reasoning path that may implicitly embed rationales for each answer option, before generating the answers. We thus propose a novel LLM-based pipeline enriched with linguistically-grounded discourse segmenters to extract supporting and opposing statements for each answer option from CoTs with improved accuracy. We also propose a rank-based HLV evaluation framework that prioritizes the ranking of answers over exact scores, which instead favor direct comparison of label distributions. Our method outperforms a direct generation method as well as baselines on three datasets, and shows better alignment of ranking methods with humans, highlighting the effectiveness of our approach.","authors":["Beiduo Chen","Yang Janet Liu","Anna Korhonen","Barbara Plank"],"url":"https://arxiv.org/abs/2505.23368"}
{"created":"2025-06-04","title":"MAPLE: A Mobile Agent with Persistent Finite State Machines for Structured Task Reasoning","abstract":"Mobile GUI agents aim to autonomously complete user-instructed tasks across mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable these agents to interpret UI screens, identify actionable elements, and perform interactions such as tapping or typing. However, existing agents remain reactive: they reason only over the current screen and lack a structured model of app navigation flow, limiting their ability to understand context, detect unexpected outcomes, and recover from errors. We present MAPLE, a state-aware multi-agent framework that abstracts app interactions as a Finite State Machine (FSM). We computationally model each UI screen as a discrete state and user actions as transitions, allowing the FSM to provide a structured representation of the app execution. MAPLE consists of specialized agents responsible for four phases of task execution: planning, execution, verification, error recovery, and knowledge retention. These agents collaborate to dynamically construct FSMs in real time based on perception data extracted from the UI screen, allowing the GUI agents to track navigation progress and flow, validate action outcomes through pre- and post-conditions of the states, and recover from errors by rolling back to previously stable states. Our evaluation results on two challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE outperforms the state-of-the-art baseline, improving task success rate by up to 12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results highlight the importance of structured state modeling in guiding mobile GUI agents during task execution. Moreover, our FSM representation can be integrated into future GUI agent architectures as a lightweight, model-agnostic memory layer to support structured planning, execution verification, and error recovery.","authors":["Linqiang Guo (Peter)","Wei Liu (Peter)","Yi Wen Heng (Peter)","Tse-Hsun (Peter)","Chen","Yang Wang"],"url":"https://arxiv.org/abs/2505.23596"}
{"created":"2025-06-04","title":"Keyed Chaotic Dynamics for Privacy-Preserving Neural Inference","abstract":"Neural network inference typically operates on raw input data, increasing the risk of exposure during preprocessing and inference. Moreover, neural architectures lack efficient built-in mechanisms for directly authenticating input data. This work introduces a novel encryption method for ensuring the security of neural inference. By constructing key-conditioned chaotic graph dynamical systems, we enable the encryption and decryption of real-valued tensors within the neural architecture. The proposed dynamical systems are particularly suited to encryption due to their sensitivity to initial conditions and their capacity to produce complex, key-dependent nonlinear transformations from compact rules. This work establishes a paradigm for securing neural inference and opens new avenues for research on the application of graph dynamical systems in neural network security.","authors":["Peter David Fagan"],"url":"https://arxiv.org/abs/2505.23655"}
{"created":"2025-06-04","title":"DiffER: Categorical Diffusion for Chemical Retrosynthesis","abstract":"Methods for automatic chemical retrosynthesis have found recent success through the application of models traditionally built for natural language processing, primarily through transformer neural networks. These models have demonstrated significant ability to translate between the SMILES encodings of chemical products and reactants, but are constrained as a result of their autoregressive nature. We propose DiffER, an alternative template-free method for retrosynthesis prediction in the form of categorical diffusion, which allows the entire output SMILES sequence to be predicted in unison. We construct an ensemble of diffusion models which achieves state-of-the-art performance for top-1 accuracy and competitive performance for top-3, top-5, and top-10 accuracy among template-free methods. We prove that DiffER is a strong baseline for a new class of template-free model, capable of learning a variety of synthetic techniques used in laboratory settings and outperforming a variety of other template-free methods on top-k accuracy metrics. By constructing an ensemble of categorical diffusion models with a novel length prediction component with variance, our method is able to approximately sample from the posterior distribution of reactants, producing results with strong metrics of confidence and likelihood. Furthermore, our analyses demonstrate that accurate prediction of the SMILES sequence length is key to further boosting the performance of categorical diffusion models.","authors":["Sean Current","Ziqi Chen","Daniel Adu-Ampratwum","Xia Ning","Srinivasan Parthasarathy"],"url":"https://arxiv.org/abs/2505.23721"}
{"created":"2025-06-04","title":"DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning","abstract":"Theorem proving serves as a major testbed for evaluating complex reasoning abilities in large language models (LLMs). However, traditional automated theorem proving (ATP) approaches rely heavily on formal proof systems that poorly align with LLMs' strength derived from informal, natural language knowledge acquired during pre-training. In this work, we propose DeepTheorem, a comprehensive informal theorem-proving framework exploiting natural language to enhance LLM mathematical reasoning. DeepTheorem includes a large-scale benchmark dataset consisting of 121K high-quality IMO-level informal theorems and proofs spanning diverse mathematical domains, rigorously annotated for correctness, difficulty, and topic categories, accompanied by systematically constructed verifiable theorem variants. We devise a novel reinforcement learning strategy (RL-Zero) explicitly tailored to informal theorem proving, leveraging the verified theorem variants to incentivize robust mathematical inference. Additionally, we propose comprehensive outcome and process evaluation metrics examining proof correctness and the quality of reasoning steps. Extensive experimental analyses demonstrate DeepTheorem significantly improves LLM theorem-proving performance compared to existing datasets and supervised fine-tuning protocols, achieving state-of-the-art accuracy and reasoning quality. Our findings highlight DeepTheorem's potential to fundamentally advance automated informal theorem proving and mathematical exploration.","authors":["Ziyin Zhang","Jiahao Xu","Zhiwei He","Tian Liang","Qiuzhi Liu","Yansi Li","Linfeng Song","Zhenwen Liang","Zhuosheng Zhang","Rui Wang","Zhaopeng Tu","Haitao Mi","Dong Yu"],"url":"https://arxiv.org/abs/2505.23754"}
{"created":"2025-06-04","title":"DLP: Dynamic Layerwise Pruning in Large Language Models","abstract":"Pruning has recently been widely adopted to reduce the parameter scale and improve the inference efficiency of Large Language Models (LLMs). Mainstream pruning techniques often rely on uniform layerwise pruning strategies, which can lead to severe performance degradation at high sparsity levels. Recognizing the varying contributions of different layers in LLMs, recent studies have shifted their focus toward non-uniform layerwise pruning. However, these approaches often rely on pre-defined values, which can result in suboptimal performance. To overcome these limitations, we propose a novel method called Dynamic Layerwise Pruning (DLP). This approach adaptively determines the relative importance of each layer by integrating model weights with input activation information, assigning pruning rates accordingly. Experimental results show that DLP effectively preserves model performance at high sparsity levels across multiple LLMs. Specifically, at 70% sparsity, DLP reduces the perplexity of LLaMA2-7B by 7.79 and improves the average accuracy by 2.7% compared to state-of-the-art methods. Moreover, DLP is compatible with various existing LLM compression techniques and can be seamlessly integrated into Parameter-Efficient Fine-Tuning (PEFT). We release the code at https://github.com/ironartisan/DLP to facilitate future research.","authors":["Yuli Chen","Bo Cheng","Jiale Han","Yingying Zhang","Yingting Li","Shuhao Zhang"],"url":"https://arxiv.org/abs/2505.23807"}
{"created":"2025-06-04","title":"LLM-Driven E-Commerce Marketing Content Optimization: Balancing Creativity and Conversion","abstract":"As e-commerce competition intensifies, balancing creative content with conversion effectiveness becomes critical. Leveraging LLMs' language generation capabilities, we propose a framework that integrates prompt engineering, multi-objective fine-tuning, and post-processing to generate marketing copy that is both engaging and conversion-driven. Our fine-tuning method combines sentiment adjustment, diversity enhancement, and CTA embedding. Through offline evaluations and online A/B tests across categories, our approach achieves a 12.5 % increase in CTR and an 8.3 % increase in CVR while maintaining content novelty. This provides a practical solution for automated copy generation and suggests paths for future multimodal, real-time personalization.","authors":["Haowei Yang","Haotian Lyu","Tianle Zhang","Dingzhou Wang","Yushang Zhao"],"url":"https://arxiv.org/abs/2505.23809"}
{"created":"2025-06-04","title":"Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert","abstract":"Current parameter-efficient fine-tuning methods for adapting pre-trained language models to downstream tasks are susceptible to interference from noisy data. Conventional noise-handling approaches either rely on laborious data pre-processing or employ model architecture modifications prone to error accumulation. In contrast to existing noise-process paradigms, we propose a noise-robust adaptation method via asymmetric LoRA poisoning experts (LoPE), a novel framework that enhances model robustness to noise only with generated noisy data. Drawing inspiration from the mixture-of-experts architecture, LoPE strategically integrates a dedicated poisoning expert in an asymmetric LoRA configuration. Through a two-stage paradigm, LoPE performs noise injection on the poisoning expert during fine-tuning to enhance its noise discrimination and processing ability. During inference, we selectively mask the dedicated poisoning expert to leverage purified knowledge acquired by normal experts for noise-robust output. Extensive experiments demonstrate that LoPE achieves strong performance and robustness purely through the low-cost noise injection, which completely eliminates the requirement of data cleaning.","authors":["Zhaokun Wang","Jinyu Guo","Jingwen Pu","Lingfeng Chen","Hongli Pu","Jie Ou","Libo Qin","Wenhong Tian"],"url":"https://arxiv.org/abs/2505.23868"}
{"created":"2025-06-04","title":"Transforming Podcast Preview Generation: From Expert Models to LLM-Based Systems","abstract":"Discovering and evaluating long-form talk content such as videos and podcasts poses a significant challenge for users, as it requires a considerable time investment. Previews offer a practical solution by providing concise snippets that showcase key moments of the content, enabling users to make more informed and confident choices. We propose an LLM-based approach for generating podcast episode previews and deploy the solution at scale, serving hundreds of thousands of podcast previews in a real-world application. Comprehensive offline evaluations and online A/B testing demonstrate that LLM-generated previews consistently outperform a strong baseline built on top of various ML expert models, showcasing a significant reduction in the need for meticulous feature engineering. The offline results indicate notable enhancements in understandability, contextual clarity, and interest level, and the online A/B test shows a 4.6% increase in user engagement with preview content, along with a 5x boost in processing efficiency, offering a more streamlined and performant solution compared to the strong baseline of feature-engineered expert models.","authors":["Winstead Zhu","Ann Clifton","Azin Ghazimatin","Edgar Tanaka","Edward Ronan"],"url":"https://arxiv.org/abs/2505.23908"}
{"created":"2025-06-04","title":"R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration","abstract":"Reasoning models have demonstrated impressive performance in self-reflection and chain-of-thought reasoning. However, they often produce excessively long outputs, leading to prohibitively large key-value (KV) caches during inference. While chain-of-thought inference significantly improves performance on complex reasoning tasks, it can also lead to reasoning failures when deployed with existing KV cache compression approaches. To address this, we propose Redundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel method specifically targeting redundant tokens in reasoning models. Our method preserves nearly 100% of the full KV cache performance using only 10% of the KV cache, substantially outperforming existing KV cache baselines, which reach only 60% of the performance. Remarkably, R-KV even achieves 105% of full KV cache performance with 16% of the KV cache. This KV-cache reduction also leads to a 90% memory saving and a 6.6X throughput over standard chain-of-thought reasoning inference. Experimental results show that R-KV consistently outperforms existing KV cache compression baselines across two mathematical reasoning datasets.","authors":["Zefan Cai","Wen Xiao","Hanshi Sun","Cheng Luo","Yikai Zhang","Ke Wan","Yucheng Li","Yeyang Zhou","Li-Wen Chang","Jiuxiang Gu","Zhen Dong","Anima Anandkumar","Abedelkadir Asi","Junjie Hu"],"url":"https://arxiv.org/abs/2505.24133"}
{"created":"2025-06-04","title":"S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation","abstract":"The latest advancements in multi-modal large language models (MLLMs) have spurred a strong renewed interest in end-to-end motion planning approaches for autonomous driving. Many end-to-end approaches rely on human annotations to learn intermediate perception and prediction tasks, while purely self-supervised approaches--which directly learn from sensor inputs to generate planning trajectories without human annotations often underperform the state of the art. We observe a key gap in the input representation space: end-to-end approaches built on MLLMs are often pretrained with reasoning tasks in 2D image space rather than the native 3D space in which autonomous vehicles plan. To this end, we propose S4-Driver, a scalable self-supervised motion planning algorithm with spatio-temporal visual representation, based on the popular PaLI multimodal large language model. S4-Driver uses a novel sparse volume strategy to seamlessly transform the strong visual representation of MLLMs from perspective view to 3D space without the need to finetune the vision encoder. This representation aggregates multi-view and multi-frame visual inputs and enables better prediction of planning trajectories in 3D space. To validate our method, we run experiments on both nuScenes and Waymo Open Motion Dataset (with in-house camera data). Results show that S4-Driver performs favorably against existing supervised multi-task approaches while requiring no human annotations. It also demonstrates great scalability when pretrained on large volumes of unannotated driving logs.","authors":["Yichen Xie","Runsheng Xu","Tong He","Jyh-Jing Hwang","Katie Luo","Jingwei Ji","Hubert Lin","Letian Chen","Yiren Lu","Zhaoqi Leng","Dragomir Anguelov","Mingxing Tan"],"url":"https://arxiv.org/abs/2505.24139"}
{"created":"2025-06-04","title":"Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC","abstract":"Multilingual speech processing with self-supervised or supervised pre-trained Speech Foundation Models (SFM) has achieved strong performance on tasks like Language Identification (LID) and Automatic Speech Recognition (ASR). However, these models struggle with limited resources during fine-tuning. This paper enhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiple strategies for adapting SFMs, including frozen upstream training, partial fine-tuning, and low-rank adaptation. Furthermore, we employ data augmentation to mitigate performance gaps in few-shot settings and introduce LID Connectionist Temporal Classification (CTC) loss for regularization. Our approach achieves a 14% relative improvement in LID accuracy and a 30% relative reduction in ASR CER over the baseline on ML-SUPERB 2.0, securing second place in the Interspeech 2025 ML-SUPERB 2.0 Challenge.","authors":["Qingzheng Wang","Jiancheng Sun","Yifan Peng","Shinji Watanabe"],"url":"https://arxiv.org/abs/2505.24200"}
{"created":"2025-06-04","title":"Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning","abstract":"Sparse autoencoders are a promising new approach for decomposing language model activations for interpretation and control. They have been applied successfully to vision transformer image encoders and to small-scale diffusion models. Inference-Time Decomposition of Activations (ITDA) is a recently proposed variant of dictionary learning that takes the dictionary to be a set of data points from the activation distribution and reconstructs them with gradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large text-to-image diffusion model, Flux 1, and consider the interpretability of embeddings of both by introducing a visual automated interpretation pipeline. We find that SAEs accurately reconstruct residual stream embeddings and beat MLP neurons on interpretability. We are able to use SAE features to steer image generation through activation addition. We find that ITDA has comparable interpretability to SAEs.","authors":["Stepan Shabalin","Ayush Panda","Dmitrii Kharlapenko","Abdur Raheem Ali","Yixiong Hao","Arthur Conmy"],"url":"https://arxiv.org/abs/2505.24360"}
{"created":"2025-06-04","title":"SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification","abstract":"Fine-grained bird image classification (FBIC) is not only of great significance for ecological monitoring and species identification, but also holds broad research value in the fields of image recognition and fine-grained visual modeling. Compared with general image classification tasks, FBIC poses more formidable challenges: 1) the differences in species size and imaging distance result in the varying sizes of birds presented in the images; 2) complex natural habitats often introduce strong background interference; 3) and highly flexible poses such as flying, perching, or foraging result in substantial intra-class variability. These factors collectively make it difficult for traditional methods to stably extract discriminative features, thereby limiting the generalizability and interpretability of models in real-world applications. To address these challenges, this paper proposes a fine-grained bird classification framework based on strip-aware spatial perception, which aims to capture long-range spatial dependencies across entire rows or columns in bird images, thereby enhancing the model's robustness and interpretability. The proposed method incorporates two novel modules: extensional perception aggregator (EPA) and channel semantic weaving (CSW). Specifically, EPA integrates local texture details with global structural cues by aggregating information across horizontal and vertical spatial directions. CSW further refines the semantic representations by adaptively fusing long-range and short-range information along the channel dimension. Built upon a ResNet-50 backbone, the model enables jump-wise connection of extended structural features across the spatial domain. Experimental results on the CUB-200-2011 dataset demonstrate that our framework achieves significant performance improvements while maintaining architectural efficiency.","authors":["Zheng Wang"],"url":"https://arxiv.org/abs/2505.24380"}
{"created":"2025-06-04","title":"Localizing Persona Representations in LLMs","abstract":"We present a study on how and where personas -- defined by distinct sets of human characteristics, values, and beliefs -- are encoded in the representation space of large language models (LLMs). Using a range of dimension reduction and pattern recognition methods, we first identify the model layers that show the greatest divergence in encoding these representations. We then analyze the activations within a selected layer to examine how specific personas are encoded relative to others, including their shared and distinct embedding spaces. We find that, across multiple pre-trained decoder-only LLMs, the analyzed personas show large differences in representation space only within the final third of the decoder layers. We observe overlapping activations for specific ethical perspectives -- such as moral nihilism and utilitarianism -- suggesting a degree of polysemy. In contrast, political ideologies like conservatism and liberalism appear to be represented in more distinct regions. These findings help to improve our understanding of how LLMs internally represent information and can inform future efforts in refining the modulation of specific human traits in LLM outputs. Warning: This paper includes potentially offensive sample statements.","authors":["Celia Cintas","Miriam Rateike","Erik Miehling","Elizabeth Daly","Skyler Speakman"],"url":"https://arxiv.org/abs/2505.24539"}
{"created":"2025-06-04","title":"Binary Cumulative Encoding meets Time Series Forecasting","abstract":"Recent studies in time series forecasting have explored formulating regression via classification task. By discretizing the continuous target space into bins and predicting over a fixed set of classes, these approaches benefit from stable training, robust uncertainty modeling, and compatibility with modern deep learning architectures. However, most existing methods rely on one-hot encoding that ignores the inherent ordinal structure of the underlying values. As a result, they fail to provide information about the relative distance between predicted and true values during training. In this paper, we propose to address this limitation by introducing binary cumulative encoding (BCE), that represents scalar targets into monotonic binary vectors. This encoding implicitly preserves order and magnitude information, allowing the model to learn distance-aware representations while still operating within a classification framework. We propose a convolutional neural network architecture specifically designed for BCE, incorporating residual and dilated convolutions to enable fast and expressive temporal modeling. Through extensive experiments on benchmark forecasting datasets, we show that our approach outperforms widely used methods in both point and probabilistic forecasting, while requiring fewer parameters and enabling faster training.","authors":["Andrei Chernov","Vitaliy Pozdnyakov","Ilya Makarov"],"url":"https://arxiv.org/abs/2505.24595"}
{"created":"2025-06-04","title":"Reinforcing Video Reasoning with Focused Thinking","abstract":"Recent advancements in reinforcement learning, particularly through Group Relative Policy Optimization (GRPO), have significantly improved multimodal large language models for complex reasoning tasks. However, two critical limitations persist: 1) they often produce unfocused, verbose reasoning chains that obscure salient spatiotemporal cues and 2) binary rewarding fails to account for partially correct answers, resulting in high reward variance and inefficient learning. In this paper, we propose TW-GRPO, a novel framework that enhances visual reasoning with focused thinking and dense reward granularity. Specifically, we employs a token weighting mechanism that prioritizes tokens with high informational density (estimated by intra-group variance), suppressing redundant tokens like generic reasoning prefixes. Furthermore, we reformulate RL training by shifting from single-choice to multi-choice QA tasks, where soft rewards enable finer-grained gradient estimation by distinguishing partial correctness. Additionally, we propose question-answer inversion, a data augmentation strategy to generate diverse multi-choice samples from existing benchmarks. Experiments demonstrate state-of-the-art performance on several video reasoning and general understanding benchmarks. Notably, TW-GRPO achieves 50.4\\% accuracy on CLEVRER (18.8\\% improvement over Video-R1) and 65.8\\% on MMVU. Our codes are available at \\href{https://github.com/longmalongma/TW-GRPO}.","authors":["Jisheng Dang","Jingze Wu","Teng Wang","Xuanhui Lin","Nannan Zhu","Hongbo Chen","Wei-Shi Zheng","Meng Wang","Tat-Seng Chua"],"url":"https://arxiv.org/abs/2505.24718"}
{"created":"2025-06-04","title":"EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation","abstract":"Mixed-Integer Linear Programming (MILP) is fundamental to solving complex decision-making problems. The proliferation of MILP instance generation methods, driven by machine learning's demand for diverse optimization datasets and the limitations of static benchmarks, has significantly outpaced standardized evaluation techniques. Consequently, assessing the fidelity and utility of synthetic MILP instances remains a critical, multifaceted challenge. This paper introduces a comprehensive benchmark framework designed for the systematic and objective evaluation of MILP instance generation methods. Our framework provides a unified and extensible methodology, assessing instance quality across crucial dimensions: mathematical validity, structural similarity, computational hardness, and utility in downstream machine learning tasks. A key innovation is its in-depth analysis of solver-internal features -- particularly by comparing distributions of key solver outputs including root node gap, heuristic success rates, and cut plane usage -- leveraging the solver's dynamic solution behavior as an `expert assessment' to reveal nuanced computational resemblances. By offering a structured approach with clearly defined solver-independent and solver-dependent metrics, our benchmark aims to facilitate robust comparisons among diverse generation techniques, spur the development of higher-quality instance generators, and ultimately enhance the reliability of research reliant on synthetic MILP data. The framework's effectiveness in systematically comparing the fidelity of instance sets is demonstrated using contemporary generative models.","authors":["Yidong Luo","Chenguang Wang","Jiahao Yang","Fanzeng Xia","Tianshu Yu"],"url":"https://arxiv.org/abs/2505.24779"}
{"created":"2025-06-04","title":"Scaling Physical Reasoning with the PHYSICS Dataset","abstract":"Large Language Models (LLMs) have achieved remarkable progress on advanced reasoning tasks such as mathematics and coding competitions. Meanwhile, physics, despite being both reasoning-intensive and essential to real-world understanding, received limited academic and industrial attention. This paper introduces PHYSICS, a dataset containing 16,568 high-quality physics problems spanning subjects and difficulty levels, to facilitate this issue. Specifically, PHYSICS is curated with exercises from over 100 textbooks through a carefully designed pipeline for quality control. It covers five major physics domains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern Physics. It also spans a wide range of difficulty levels, from high school to graduate-level physics courses. To utilize the data for improving and evaluating the model's physical reasoning capabilities, we split the dataset into training and test sets, and provide reasoning paths generated by powerful reasoning models for the training data to facilitate model training. In addition, for the evaluation part, we find that existing evaluation frameworks exhibit biases in aspects such as units, simplification, and precision in physics domain. To balance efficiency and accuracy, we introduce a Rule+Model evaluation framework tailored to physics problems. Our evaluations on current state-of-the-art open-source and proprietary models highlight the limitations of current models in handling physics-related tasks. We hope that our dataset and evaluation methodology will jointly advance the development of LLMs in the field of physics.","authors":["Shenghe Zheng","Qianjia Cheng","Junchi Yao","Mengsong Wu","Haonan He","Ning Ding","Yu Cheng","Shuyue Hu","Lei Bai","Dongzhan Zhou","Ganqu Cui","Peng Ye"],"url":"https://arxiv.org/abs/2506.00022"}
{"created":"2025-06-04","title":"Gaussian mixture models as a proxy for interacting language models","abstract":"Large language models (LLMs) are a powerful tool with the ability to match human capabilities and behavior in many settings. Retrieval-augmented generation (RAG) further allows LLMs to generate diverse output depending on the contents of their RAG database. This motivates their use in the social sciences to study human behavior between individuals when large-scale experiments are infeasible. However, LLMs depend on complex, computationally expensive algorithms. In this paper, we introduce interacting Gaussian mixture models (GMMs) as an alternative to similar frameworks using LLMs. We compare a simplified model of GMMs to select experimental simulations of LLMs whose updating and response depend on feedback from other LLMs. We find that interacting GMMs capture important features of the dynamics in interacting LLMs, and we investigate key similarities and differences between interacting LLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture models, potential modifications, and future research directions.","authors":["Edward L. Wang","Tianyu Wang","Avanti Athreya","Vince Lyzinski","Carey E. Priebe"],"url":"https://arxiv.org/abs/2506.00077"}
{"created":"2025-06-04","title":"ClinBench-HPB: A Clinical Benchmark for Evaluating LLMs in Hepato-Pancreato-Biliary Diseases","abstract":"Hepato-pancreato-biliary (HPB) disorders represent a global public health challenge due to their high morbidity and mortality. Although large language models (LLMs) have shown promising performance in general medical question-answering tasks, the current evaluation benchmarks are mostly derived from standardized examinations or manually designed questions, lacking HPB coverage and clinical cases. To address these issues, we systematically eatablish an HPB disease evaluation benchmark comprising 3,535 closed-ended multiple-choice questions and 337 open-ended real diagnosis cases, which encompasses all the 33 main categories and 465 subcategories of HPB diseases defined in the International Statistical Classification of Diseases, 10th Revision (ICD-10). The multiple-choice questions are curated from public datasets and synthesized data, and the clinical cases are collected from prestigious medical journals, case-sharing platforms, and collaborating hospitals. By evalauting commercial and open-source general and medical LLMs on our established benchmark, namely ClinBench-HBP, we find that while commercial LLMs perform competently on medical exam questions, they exhibit substantial performance degradation on HPB diagnosis tasks, especially on complex, inpatient clinical cases. Those medical LLMs also show limited generalizability to HPB diseases. Our results reveal the critical limitations of current LLMs in the domain of HPB diseases, underscoring the imperative need for future medical LLMs to handle real, complex clinical diagnostics rather than simple medical exam questions. The benchmark will be released at the homepage.","authors":["Yuchong Li","Xiaojun Zeng","Chihua Fang","Jian Yang","Fucang Jia","Lei Zhang"],"url":"https://arxiv.org/abs/2506.00095"}
{"created":"2025-06-04","title":"Safety, Relative Tightness and the Probabilistic Frame Rule","abstract":"Probabilistic separation logic offers an approach to reasoning about imperative probabilistic programs in which a separating conjunction is used as a mechanism for expressing independence properties. Crucial to the effectiveness of the formalism is the frame rule, which enables modular reasoning about independent probabilistic state. We explore a semantic formulation of probabilistic separation logic, in which the frame rule has the same simple formulation as in separation logic, without further side conditions. This is achieved by building a notion of safety into specifications, using which we establish a crucial property of specifications, called relative tightness, from which the soundness of the frame rule follows.","authors":["Janez Ignacij Jereb","Alex Simpson"],"url":"https://arxiv.org/abs/2506.01626"}
{"created":"2025-06-04","title":"MedEBench: Revisiting Text-instructed Image Editing on Medical Domain","abstract":"Text-guided image editing has seen rapid progress in natural image domains, but its adaptation to medical imaging remains limited and lacks standardized evaluation. Clinically, such editing holds promise for simulating surgical outcomes, creating personalized teaching materials, and enhancing patient communication. To bridge this gap, we introduce \\textbf{MedEBench}, a comprehensive benchmark for evaluating text-guided medical image editing. It consists of 1,182 clinically sourced image-prompt triplets spanning 70 tasks across 13 anatomical regions. MedEBench offers three key contributions: (1) a clinically relevant evaluation framework covering Editing Accuracy, Contextual Preservation, and Visual Quality, supported by detailed descriptions of expected change and ROI (Region of Interest) masks; (2) a systematic comparison of seven state-of-the-art models, revealing common failure patterns; and (3) a failure analysis protocol based on attention grounding, using IoU between attention maps and ROIs to identify mislocalization. MedEBench provides a solid foundation for developing and evaluating reliable, clinically meaningful medical image editing systems.","authors":["Minghao Liu","Zhitao He","Zhiyuan Fan","Qingyun Wang","Yi R. Fung"],"url":"https://arxiv.org/abs/2506.01921"}
{"created":"2025-06-04","title":"Big Ramsey degrees using parameter spaces","abstract":"We show that the universal homogeneous partial order has finite big Ramsey degrees and discuss several corollaries. Our proof relies on parameter spaces and the Carlson-Simpson theorem rather than on (a strengthening of) the Halpern-L\\\"auchli theorem and the Milliken tree theorem, which are typically used to bound big Ramsey degrees in the existing literature (originating from the work of Laver and Milliken).","authors":["Jan Hubi\\v{c}ka"],"url":"https://arxiv.org/abs/2009.00967"}
{"created":"2025-06-04","title":"Cryogenic in-memory computing using magnetic topological insulators","abstract":"Machine learning algorithms have been proven effective for essential quantum computation tasks such as quantum error correction and quantum control. Efficient hardware implementation of these algorithms at cryogenic temperatures is essential. Here, we utilize magnetic topological insulators as memristors (termed magnetic topological memristors) and introduce a cryogenic in-memory computing scheme based on the coexistence of the chiral edge state and the topological surface state. The memristive switching and reading of the giant anomalous Hall effect exhibit high energy efficiency, high stability, and low stochasticity. We achieve high accuracy in a proof-of-concept classification task using four magnetic topological memristors. Furthermore, our algorithm-level and circuit-level simulations of large-scale neural networks demonstrate software-level accuracy and lower energy consumption for image recognition and quantum state preparation compared with existing magnetic memristor and CMOS technologies. Our results not only showcase a new application of chiral edge states but also may inspire further topological quantum physics-based novel computing schemes.","authors":["Yuting Liu","Albert Lee","Kun Qian","Peng Zhang","Zhihua Xiao","Haoran He","Zheyu Ren","Shun Kong Cheung","Ruizi Liu","Yaoyin Li","Xu Zhang","Zichao Ma","Jianyuan Zhao","Weiwei Zhao","Guoqiang Yu","Xin Wang","Junwei Liu","Zhongrui Wang","Kang L. Wang","Qiming Shao"],"url":"https://arxiv.org/abs/2209.09443"}
{"created":"2025-06-04","title":"Complexity of Geometric programming in the Turing model and application to nonnegative tensors","abstract":"We consider a version of geometric programming problem consisting in minimizing a function given by the maximum of finitely many log-Laplace transforms of discrete nonnegative measures on a Euclidean space. Under a coerciveness assumption, we show that an $\\varepsilon$-minimizer can be computed in a time that is polynomial in the input size and in $|\\log\\varepsilon|$. This is obtained by establishing bit-size estimates on approximate minimizers and by applying the ellipsoid method. We also derive polynomial iteration complexity bounds for the interior-point method applied to the same class of problems. We deduce that the spectral radius of a partially symmetric, weakly irreducible nonnegative tensor can be approximated within an $\\varepsilon$-error in polynomial time. For strongly irreducible tensors, we show in addition that the logarithm of the positive eigenvector is polynomial time approximable. Our results also yield that the the maximum of a nonnegative homogeneous $d$-form in the $\\ell_d$ unit ball can be approximated in polynomial time. In particular, the spectral radius of uniform weighted hypergraphs and some known upper bounds for the clique number of uniform hypergraphs are polynomial time computable. In contrast, we provide an example showing that the Phase I approach needs exponentially many bits to solve the feasibility problem in geometric programming.","authors":["Shmuel Friedland","St\\'ephane Gaubert"],"url":"https://arxiv.org/abs/2301.10637"}
{"created":"2025-06-04","title":"Accelerate Langevin Sampling with Birth-Death Process and Exploration Component","abstract":"Sampling a probability distribution with known likelihood is a fundamental task in computational science and engineering. Aiming at multimodality, we propose a new sampling method that takes advantage of both birth-death process and exploration component. The main idea of this method is look before you leap. We keep two sets of samplers, one at warmer temperature and one at original temperature. The former one serves as pioneer in exploring new modes and passing useful information to the other, while the latter one samples the target distribution after receiving the information. We derive a mean-field limit and show how the exploration component accelerates the sampling process. Moreover, we prove exponential asymptotic convergence under mild assumption. Finally, we test on experiments from previous literature and compare our methodology to previous ones.","authors":["Lezhi Tan","Jianfeng Lu"],"url":"https://arxiv.org/abs/2305.05529"}
{"created":"2025-06-04","title":"Fast and Multiphase Rates for Nearest Neighbor Classifiers","abstract":"We study the scaling of classification error rates with respect to the size of the training dataset. In contrast to classical results where rates are minimax optimal for a problem class, this work starts with the empirical observation that, even for a fixed data distribution, the error scaling can have \\emph{diverse} rates across different ranges of sample size. To understand when and why the error rate is non-uniform, we theoretically analyze nearest neighbor classifiers. We show that an error scaling law can have fine-grained rates: in the early phase, the test error depends polynomially on the data dimension and decreases fast; whereas in the later phase, the error depends exponentially on the data dimension and decreases slowly. Our analysis highlights the complexity of the data distribution in determining the test error. When the data are distributed benignly, we show that the generalization error of nearest neighbor classifier can depend polynomially, instead of exponentially, on the data dimension.","authors":["Pengkun Yang","Jingzhao Zhang"],"url":"https://arxiv.org/abs/2308.08247"}
{"created":"2025-06-04","title":"The clique chromatic number of sparse random graphs","abstract":"The clique chromatic number of a graph is the smallest number of colors in a vertex coloring so that no maximal clique is monochromatic. In this paper, we determine the order of magnitude of the clique chromatic number of the random graph G_{n,p} for most edge-probabilities p in the range n^{-2/5} \\ll p \\ll 1. This resolves open problems and questions of Lichev, Mitsche and Warnke as well as Alon and Krievelevich.","authors":["Manuel Fernandez V","Lutz Warnke"],"url":"https://arxiv.org/abs/2403.03013"}
{"created":"2025-06-04","title":"Maximal Non-Kochen-Specker Sets and a Lower Bound on the Size of Kochen-Specker Sets","abstract":"The challenge of determining bounds for the minimal number of vectors in a three-dimensional Kochen-Specker (KS) set has captivated the quantum foundations community for decades. This paper establishes a weak lower bound of 10 vectors, which does not surpass the current best-known bound of 24 vectors. By exploring the complementary concept of large non-KS sets and employing a probability argument independent of the graph structure of KS sets, we introduce a novel technique that could be applied in the future to derive tighter bounds. Additionally, we highlight an intriguing connection to a generalisation of the moving sofa problem in navigating a right-angled hallway on the surface of a two-dimensional sphere.","authors":["Tom Williams","Andrei Constantin"],"url":"https://arxiv.org/abs/2403.05230"}
{"created":"2025-06-04","title":"Spectral Clustering for Directed Graphs via Likelihood Estimation on Stochastic Block Models","abstract":"Graph clustering is a fundamental task in unsupervised learning with broad real-world applications. While spectral clustering methods for undirected graphs are well-established and guided by a minimum cut optimization consensus, their extension to directed graphs remains relatively underexplored due to the additional complexity introduced by edge directions. In this paper, we leverage statistical inference on stochastic block models to guide the development of a spectral clustering algorithm for directed graphs. Specifically, we study the maximum likelihood estimation under a widely used directed stochastic block model, and derive a global objective function that aligns with the underlying community structure. We further establish a theoretical upper bound on the misclustering error of its spectral relaxation, and based on this relaxation, introduce a novel, self-adaptive spectral clustering method for directed graphs. Extensive experiments on synthetic and real-world datasets demonstrate significant performance gains over existing baselines.","authors":["Ning Zhang","Xiaowen Dong","Mihai Cucuringu"],"url":"https://arxiv.org/abs/2403.19516"}
{"created":"2025-06-04","title":"Iterative Methods for Full-Scale Gaussian Process Approximations for Large Spatial Data","abstract":"Gaussian processes are flexible probabilistic regression models which are widely used in statistics and machine learning. However, a drawback is their limited scalability to large data sets. To alleviate this, full-scale approximations (FSAs) combine predictive process methods and covariance tapering, thus approximating both global and local structures. We show how iterative methods can be used to reduce computational costs in calculating likelihoods, gradients, and predictive distributions with FSAs. In particular, we introduce a novel preconditioner and show theoretically and empirically that it accelerates the conjugate gradient method's convergence speed and mitigates its sensitivity with respect to the FSA parameters and the eigenvalue structure of the original covariance matrix, and we demonstrate empirically that it outperforms a state-of-the-art pivoted Cholesky preconditioner. Furthermore, we introduce an accurate and fast way to calculate predictive variances using stochastic simulation and iterative methods. In addition, we show how our newly proposed FITC preconditioner can also be used in iterative methods for Vecchia approximations. In our experiments, it outperforms existing state-of-the-art preconditioners for Vecchia approximations. All methods are implemented in a free C++ software library with high-level Python and R packages.","authors":["Tim Gyger","Reinhard Furrer","Fabio Sigrist"],"url":"https://arxiv.org/abs/2405.14492"}
{"created":"2025-06-04","title":"A Hessian-Aware Stochastic Differential Equation for Modelling SGD","abstract":"Continuous-time approximation of Stochastic Gradient Descent (SGD) is a crucial tool to study its escaping behaviors from stationary points. However, existing stochastic differential equation (SDE) models fail to fully capture these behaviors, even for simple quadratic objectives. Built on a novel stochastic backward error analysis framework, we derive the Hessian-Aware Stochastic Modified Equation (HA-SME), an SDE that incorporates Hessian information of the objective function into both its drift and diffusion terms. Our analysis shows that HA-SME achieves the order-best approximation error guarantee among existing SDE models in the literature, while significantly reducing the dependence on the smoothness parameter of the objective. Empirical experiments on neural network-based loss functions further validate this improvement. Further, for quadratic objectives, under mild conditions, HA-SME is proved to be the first SDE model that recovers exactly the SGD dynamics in the distributional sense. Consequently, when the local landscape near a stationary point can be approximated by quadratics, HA-SME provides a more precise characterization of the local escaping behaviors of SGD. With the enhanced approximation guarantee, we further conduct an escape time analysis using HA-SME, showcasing how it can be employed to analytically study the escaping behavior of SGD for general function classes.","authors":["Xiang Li","Zebang Shen","Liang Zhang","Niao He"],"url":"https://arxiv.org/abs/2405.18373"}
{"created":"2025-06-04","title":"Joint Learning of Linear Dynamical Systems under Smoothness Constraints","abstract":"We consider the problem of joint learning of multiple linear dynamical systems. This has received significant attention recently under different types of assumptions on the model parameters. The setting we consider involves a collection of $m$ linear systems, each of which resides on a node of a given undirected graph $G = ([m], \\mathcal{E})$. We assume that the system matrices are marginally stable, and satisfy a smoothness constraint w.r.t $G$ -- akin to the quadratic variation of a signal on a graph. Given access to the states of the nodes over $T$ time points, we then propose two estimators for joint estimation of the system matrices, along with non-asymptotic error bounds on the mean-squared error (MSE). In particular, we show conditions under which the MSE converges to zero as $m$ increases, typically polynomially fast w.r.t $m$. The results hold under mild (i.e., $T \\sim \\log m$), or sometimes, even no assumption on $T$ (i.e. $T \\geq 2$).","authors":["Hemant Tyagi"],"url":"https://arxiv.org/abs/2406.01094"}
{"created":"2025-06-04","title":"Quartic quantum speedups for planted inference","abstract":"We describe a quantum algorithm for the Planted Noisy $k$XOR problem (also known as sparse Learning Parity with Noise) that achieves a nearly quartic ($4$th power) speedup over the best known classical algorithm while also only using logarithmically many qubits. Our work generalizes and simplifies prior work of Hastings, by building on his quantum algorithm for the Tensor Principal Component Analysis (PCA) problem. We achieve our quantum speedup using a general framework based on the Kikuchi Method (recovering the quartic speedup for Tensor PCA), and we anticipate it will yield similar speedups for further planted inference problems. These speedups rely on the fact that planted inference problems naturally instantiate the Guided Sparse Hamiltonian problem. Since the Planted Noisy $k$XOR problem has been used as a component of certain cryptographic constructions, our work suggests that some of these are susceptible to super-quadratic quantum attacks.","authors":["Alexander Schmidhuber","Ryan O'Donnell","Robin Kothari","Ryan Babbush"],"url":"https://arxiv.org/abs/2406.19378"}
{"created":"2025-06-04","title":"eGAD! double descent is explained by Generalized Aliasing Decomposition","abstract":"A central problem in data science is to use potentially noisy samples of an unknown function to predict values for unseen inputs. In classical statistics, predictive error is understood as a trade-off between the bias and the variance that balances model simplicity with its ability to fit complex functions. However, over-parameterized models exhibit counterintuitive behaviors, such as \"double descent\" in which models of increasing complexity exhibit decreasing generalization error. Others may exhibit more complicated patterns of predictive error with multiple peaks and valleys. Neither double descent nor multiple descent phenomena are well explained by the bias-variance decomposition.","authors":["Mark K. Transtrum","Gus L. W. Hart","Tyler J. Jarvis","Jared P. Whitehead"],"url":"https://arxiv.org/abs/2408.08294"}
{"created":"2025-06-04","title":"Denoising Graph Super-Resolution towards Improved Collider Event Reconstruction","abstract":"In preparation for Higgs factories and energy-frontier facilities, future colliders are moving toward high-granularity calorimeters to improve reconstruction quality. However, the cost and construction complexity of such detectors is substantial, making software-based approaches like super-resolution an attractive alternative. This study explores integrating super-resolution techniques into an LHC-like reconstruction pipeline to effectively enhance calorimeter granularity and suppress noise. We find that this software preprocessing step significantly improves reconstruction quality without physical changes to the detector. To demonstrate its impact, we propose a novel transformer-based particle flow model that offers improved particle reconstruction quality and interpretability. Our results demonstrate that super-resolution can be readily applied at collider experiments.","authors":["Nilotpal Kakati","Etienne Dreyer","Eilam Gross"],"url":"https://arxiv.org/abs/2409.16052"}
{"created":"2025-06-04","title":"Evidence of equilibrium dynamics in human social networks evolving in time","abstract":"How do networks of relationships evolve over time? We analyse a dataset tracking the social interactions of 900 individuals over four years. Despite continuous shifts in individual relationships, the macroscopic structural properties of the network remain stable, fluctuating within predictable bounds. We connect this stability to the concept of equilibrium in statistical physics. Specifically, we demonstrate that the probabilities governing network dynamics are stationary over time, and key features like degree, edge, and triangle abundances align with theoretical predictions from equilibrium dynamics. Moreover, the dynamics satisfies the detailed balance condition. Remarkably, equilibrium persists despite constant turnover as people join, leave, and change connections. This suggests that equilibrium arises not from specific individuals but from the balancing act of human needs, cognitive limits, and social pressures. Practically, this equilibrium simplifies data collection, supports methods relying on single network snapshots (like Exponential Random Graph Models), and aids in designing interventions for social challenges. Theoretically, it offers new insights into collective human behaviour, revealing how emergent properties of complex social systems can be captured by simple mathematical models.","authors":["Miguel A. Gonz\\'alez-Casado","Andreia Sofia Teixeira","Angel S\\'anchez"],"url":"https://arxiv.org/abs/2410.11635"}
{"created":"2025-06-04","title":"Distributionally Robust Newsvendor on a Metric","abstract":"We consider a fundamental generalization of the classical newsvendor problem where the seller needs to decide on the inventory of a product jointly for multiple locations on a metric as well as a fulfillment policy to satisfy the uncertain demand that arises sequentially over time after the inventory decisions have been made. To address the distributional ambiguity, we consider a distributionally robust setting where the decision-maker only knows the mean and variance of the demand, and the goal is to make inventory and fulfillment decisions to minimize the worst-case expected inventory and fulfillment cost. We design a near-optimal policy for the problem with theoretical guarantees on its performance. Our policy generalizes the classical solution of Scarf (1957), maintaining its simplicity and interpretability: it identifies a hierarchical set of clusters, assigns a ``virtual\" underage cost to each cluster, then makes sure that each cluster holds at least the inventory suggested by Scarf's solution if the cluster behaved as a single point with ``virtual\" underage cost. As demand arrives sequentially, our policy fulfills orders from nearby clusters, minimizing fulfilment costs, while balancing inventory consumption across the clusters to avoid depleting any single one. We show that the policy achieves a poly-logarithmic approximation. To the best of our knowledge, this is the first algorithm with provable performance guarantees. Furthermore, our numerical experiments show that the policy performs well in practice.","authors":["Ayoub Foussoul","Vineet Goyal"],"url":"https://arxiv.org/abs/2410.12134"}
{"created":"2025-06-04","title":"FlashAudio: Rectified Flows for Fast and High-Fidelity Text-to-Audio Generation","abstract":"Recent advancements in latent diffusion models (LDMs) have markedly enhanced text-to-audio generation, yet their iterative sampling processes impose substantial computational demands, limiting practical deployment. While recent methods utilizing consistency-based distillation aim to achieve few-step or single-step inference, their one-step performance is constrained by curved trajectories, preventing them from surpassing traditional diffusion models. In this work, we introduce FlashAudio with rectified flows to learn straight flow for fast simulation. To alleviate the inefficient timesteps allocation and suboptimal distribution of noise, FlashAudio optimizes the time distribution of rectified flow with Bifocal Samplers and proposes immiscible flow to minimize the total distance of data-noise pairs in a batch vias assignment. Furthermore, to address the amplified accumulation error caused by the classifier-free guidance (CFG), we propose Anchored Optimization, which refines the guidance scale by anchoring it to a reference trajectory. Experimental results on text-to-audio generation demonstrate that FlashAudio's one-step generation performance surpasses the diffusion-based models with hundreds of sampling steps on audio quality and enables a sampling speed of 400x faster than real-time on a single NVIDIA 4090Ti GPU. Code will be available at https://github.com/liuhuadai/FlashAudio.","authors":["Huadai Liu","Jialei Wang","Rongjie Huang","Yang Liu","Heng Lu","Zhou Zhao","Wei Xue"],"url":"https://arxiv.org/abs/2410.12266"}
{"created":"2025-06-04","title":"Flexible Demand Manipulation","abstract":"We develop a simple framework to analyze how targeted persuasive advertising shapes market power and welfare. A designer flexibly manipulates the demand curve by influencing individual valuations at a cost. A monopolist prices against this manipulated demand curve. We fully characterize the form of optimal advertising plans under ex-ante and ex-post welfare measures. Flexibility per se is powerful, and can substantially harm or benefit consumers vis-a-vis uniform advertising. We discuss implications for regulation, intermediation, and the joint design of manipulation and information.","authors":["Yifan Dai","Andrew Koh"],"url":"https://arxiv.org/abs/2410.24191"}
{"created":"2025-06-04","title":"Generalized quantum asymptotic equipartition","abstract":"The asymptotic equipartition property (AEP) states that in the limit of a large number of independent and identically distributed (i.i.d.) random experiments, the output sequence is virtually certain to come from the typical set, each member of which is almost equally likely. This property is a form of the law of large numbers and lies at the heart of information theory. In this work, we prove a generalized quantum AEP beyond the i.i.d. framework where the random samples are drawn from two sets of quantum states. In particular, under suitable assumptions on the sets, we prove that all operationally relevant divergences converge to the quantum relative entropy between the sets. More specifically, both the quantum hypothesis testing relative entropy (a smoothed form of the min-relative entropy) and the smoothed max-relative entropy approach the regularized relative entropy between the sets. Notably, the asymptotic limit has explicit convergence guarantees and can be efficiently estimated through convex optimization programs, despite the regularization, provided that the sets have efficient descriptions. The generalized AEP directly implies a new generalized quantum Stein's lemma for conducting quantum hypothesis testing between two sets of quantum states. This addresses open questions raised by Brand\\~{a}o et al. [IEEE TIT 66(8):5037-5054 (2020)] and Mosonyi et al. [IEEE TIT 68(2):1032-1067 (2022)], which seek a Stein's lemma with computational efficiency. Moreover, we propose a new framework for quantum resource theory in which state transformations are performed without requiring precise characterization of the states being manipulated, making it more robust to imperfections. We demonstrate the reversibility (also referred to as the second law) of such a theory and identify the regularized relative entropy as the unique measure of the resource in this new framework.","authors":["Kun Fang","Hamza Fawzi","Omar Fawzi"],"url":"https://arxiv.org/abs/2411.04035"}
{"created":"2025-06-04","title":"Forecasting Company Fundamentals","abstract":"Company fundamentals are key to assessing companies' financial and overall success and stability. Forecasting them is important in multiple fields, including investing and econometrics. While statistical and contemporary machine learning methods have been applied to many time series tasks, there is a lack of comparison of these approaches on this particularly challenging data regime. To this end, we try to bridge this gap and thoroughly evaluate the theoretical properties and practical performance of 24 deterministic and probabilistic company fundamentals forecasting models on real company data. We observe that deep learning models provide superior forecasting performance to classical models, in particular when considering uncertainty estimation. To validate the findings, we compare them to human analyst expectations and find that their accuracy is comparable to the automatic forecasts. We further show how these high-quality forecasts can benefit automated stock allocation. We close by presenting possible ways of integrating domain experts to further improve performance and increase reliability.","authors":["Felix Divo","Eric Endress","Kevin Endler","Kristian Kersting","Devendra Singh Dhami"],"url":"https://arxiv.org/abs/2411.05791"}
{"created":"2025-06-04","title":"A minimalistic representation model for head direction system","abstract":"We present a minimalistic representation model for the head direction (HD) system, aiming to learn a high-dimensional representation of head direction that captures essential properties of HD cells. Our model is a representation of rotation group $U(1)$, and we study both the fully connected version and convolutional version. We demonstrate the emergence of Gaussian-like tuning profiles and a 2D circle geometry in both versions of the model. We also demonstrate that the learned model is capable of accurate path integration.","authors":["Minglu Zhao","Dehong Xu","Deqian Kong","Wen-Hao Zhang","Ying Nian Wu"],"url":"https://arxiv.org/abs/2411.10596"}
{"created":"2025-06-04","title":"DeepSPV: A Deep Learning Pipeline for 3D Spleen Volume Estimation from 2D Ultrasound Images","abstract":"Splenomegaly, the enlargement of the spleen, is an important clinical indicator for various associated medical conditions, such as sickle cell disease (SCD). Spleen length measured from 2D ultrasound is the most widely used metric for characterising spleen size. However, it is still considered a surrogate measure, and spleen volume remains the gold standard for assessing spleen size. Accurate spleen volume measurement typically requires 3D imaging modalities, such as computed tomography or magnetic resonance imaging, but these are not widely available, especially in the Global South which has a high prevalence of SCD. In this work, we introduce a deep learning pipeline, DeepSPV, for precise spleen volume estimation from single or dual 2D ultrasound images. The pipeline involves a segmentation network and a variational autoencoder for learning low-dimensional representations from the estimated segmentations. We investigate three approaches for spleen volume estimation and our best model achieves 86.62%/92.5% mean relative volume accuracy (MRVA) under single-view/dual-view settings, surpassing the performance of human experts. In addition, the pipeline can provide confidence intervals for the volume estimates as well as offering benefits in terms of interpretability, which further support clinicians in decision-making when identifying splenomegaly. We evaluate the full pipeline using a highly realistic synthetic dataset generated by a diffusion model, achieving an overall MRVA of 83.0% from a single 2D ultrasound image. Our proposed DeepSPV is the first work to use deep learning to estimate 3D spleen volume from 2D ultrasound images and can be seamlessly integrated into the current clinical workflow for spleen assessment.","authors":["Zhen Yuan","David Stojanovski","Lei Li","Alberto Gomez","Haran Jogeesvaran","Esther Puyol-Ant\\'on","Baba Inusa","Andrew P. King"],"url":"https://arxiv.org/abs/2411.11190"}
{"created":"2025-06-04","title":"Likelihood-Scheduled Score-Based Generative Modeling for Fully 3D PET Image Reconstruction","abstract":"Medical image reconstruction with pre-trained score-based generative models (SGMs) has advantages over other existing state-of-the-art deep-learned reconstruction methods, including improved resilience to different scanner setups and advanced image distribution modeling. SGM-based reconstruction has recently been applied to simulated positron emission tomography (PET) datasets, showing improved contrast recovery for out-of-distribution lesions relative to the state-of-the-art. However, existing methods for SGM-based reconstruction from PET data suffer from slow reconstruction, burdensome hyperparameter tuning and slice inconsistency effects (in 3D). In this work, we propose a practical methodology for fully 3D reconstruction that accelerates reconstruction and reduces the number of critical hyperparameters by matching the likelihood of an SGM's reverse diffusion process to a current iterate of the maximum-likelihood expectation maximization algorithm. Using the example of low-count reconstruction from simulated [$^{18}$F]DPA-714 datasets, we show our methodology can match or improve on the NRMSE and SSIM of existing state-of-the-art SGM-based PET reconstruction while reducing reconstruction time and the need for hyperparameter tuning. We evaluate our methodology against state-of-the-art supervised and conventional reconstruction algorithms. Finally, we demonstrate a first-ever implementation of SGM-based reconstruction for real 3D PET data, specifically [$^{18}$F]DPA-714 data, where we integrate perpendicular pre-trained SGMs to eliminate slice inconsistency issues.","authors":["George Webber","Yuya Mizuno","Oliver D. Howes","Alexander Hammers","Andrew P. King","Andrew J. Reader"],"url":"https://arxiv.org/abs/2412.04339"}
{"created":"2025-06-04","title":"First-ish Order Methods: Hessian-aware Scalings of Gradient Descent","abstract":"Gradient descent is the primary workhorse for optimizing large-scale problems in machine learning. However, its performance is highly sensitive to the choice of the learning rate. A key limitation of gradient descent is its lack of natural scaling, which often necessitates expensive line searches or heuristic tuning to determine an appropriate step size. In this paper, we address this limitation by incorporating Hessian information to scale the gradient direction. By accounting for the curvature of the function along the gradient, our adaptive, Hessian-aware scaling method ensures a local unit step size guarantee, even in nonconvex settings. Near a local minimum that satisfies the second-order sufficient conditions, our approach achieves linear convergence with a unit step size. We show that our method converges globally under a significantly weaker version of the standard Lipschitz gradient smoothness assumption. Even when Hessian information is inexact, the local unit step size guarantee and global convergence properties remain valid under mild conditions. Finally, we validate our theoretical results empirically on a range of convex and nonconvex machine learning tasks, showcasing the effectiveness of the approach.","authors":["Oscar Smee","Fred Roosta","Stephen J. Wright"],"url":"https://arxiv.org/abs/2502.03701"}
{"created":"2025-06-04","title":"Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions","abstract":"Machine learning is a vital part of many real-world systems, but several concerns remain about the lack of interpretability, explainability and robustness of black-box AI systems. Concept Bottleneck Models (CBM) address some of these challenges by learning interpretable concepts from high-dimensional data, e.g. images, which are used to predict labels. An important issue in CBMs are spurious correlation between concepts, which effectively lead to learning \"wrong\" concepts. Current mitigating strategies have strong assumptions, e.g., they assume that the concepts are statistically independent of each other, or require substantial interaction in terms of both interventions and labels provided by annotators. In this paper, we describe a framework that provides theoretical guarantees on the correctness of the learned concepts and on the number of required labels, without requiring any interventions. Our framework leverages causal representation learning (CRL) methods to learn latent causal variables from high-dimensional observations in a unsupervised way, and then learns to align these variables with interpretable concepts with few concept labels. We propose a linear and a non-parametric estimator for this mapping, providing a finite-sample high probability result in the linear case and an asymptotic consistency result for the non-parametric estimator. We evaluate our framework in synthetic and image benchmarks, showing that the learned concepts have less impurities and are often more accurate than other CBMs, even in settings with strong correlations between concepts.","authors":["Hidde Fokkema","Tim van Erven","Sara Magliacane"],"url":"https://arxiv.org/abs/2502.06536"}
{"created":"2025-06-04","title":"How does ion temperature gradient turbulence depend on magnetic geometry? Insights from data and machine learning","abstract":"Magnetic geometry has a significant effect on the level of turbulent transport in fusion plasmas. Here, we model and analyze this dependence using multiple machine learning methods and a dataset of > 200,000 nonlinear simulations of ion-temperature-gradient turbulence in diverse non-axisymmetric geometries. The dataset is generated using a large collection of both optimized and randomly generated stellarator equilibria. At fixed gradients, the turbulent heat flux varies between geometries by several orders of magnitude. Trends are apparent among the configurations with particularly high or low heat flux. Regression and classification techniques from machine learning are then applied to extract patterns in the dataset. Due to a symmetry of the gyrokinetic equation, the heat flux and regressions thereof should be invariant to translations of the raw features in the parallel coordinate, similar to translation invariance in computer vision applications. Multiple regression models including convolutional neural networks (CNNs) and decision trees can achieve reasonable predictive power for the heat flux in held-out test configurations, with highest accuracy for the CNNs. Using Spearman correlation, sequential feature selection, and Shapley values to measure feature importance, it is consistently found that the most important geometric lever on the heat flux is the flux surface compression in regions of bad curvature. The second most important feature relates to the magnitude of geodesic curvature. These two features align remarkably with surrogates that have been proposed based on theory, while the methods here allow a natural extension to more features for increased accuracy. The dataset, released with this publication, may also be used to test other proposed surrogates, and we find many previously published proxies do correlate well with both the heat flux and stability boundary.","authors":["Matt Landreman","Jong Youl Choi","Caio Alves","Prasanna Balaprakash","R. Michael Churchill","Rory Conlin","Gareth Roberg-Clark"],"url":"https://arxiv.org/abs/2502.11657"}
{"created":"2025-06-04","title":"MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders","abstract":"Medical images are acquired at high resolutions with large fields of view in order to capture fine-grained features necessary for clinical decision-making. Consequently, training deep learning models on medical images can incur large computational costs. In this work, we address the challenge of downsizing medical images in order to improve downstream computational efficiency while preserving clinically-relevant features. We introduce MedVAE, a family of six large-scale 2D and 3D autoencoders capable of encoding medical images as downsized latent representations and decoding latent representations back to high-resolution images. We train MedVAE autoencoders using a novel two-stage training approach with 1,052,730 medical images. Across diverse tasks obtained from 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent representations in place of high-resolution images when training downstream models can lead to efficiency benefits (up to 70x improvement in throughput) while simultaneously preserving clinically-relevant features and (2) MedVAE can decode latent representations back to high-resolution images with high fidelity. Our work demonstrates that large-scale, generalizable autoencoders can help address critical efficiency challenges in the medical domain. Our code is available at https://github.com/StanfordMIMI/MedVAE.","authors":["Maya Varma","Ashwin Kumar","Rogier van der Sluijs","Sophie Ostmeier","Louis Blankemeier","Pierre Chambon","Christian Bluethgen","Jip Prince","Curtis Langlotz","Akshay Chaudhari"],"url":"https://arxiv.org/abs/2502.14753"}
{"created":"2025-06-04","title":"Efficient and Universal Neural-Network Decoder for Stabilizer-Based Quantum Error Correction","abstract":"Scaling quantum computing to practical applications necessitates reliable quantum error correction. Although numerous correction codes have been proposed, the overall correction efficiency critically limited by the decode algorithms. We introduce GraphQEC, a code-agnostic decoder leveraging machine-learning on the graph structure of stabilizer codes with linear time complexity. GraphQEC demonstrates unprecedented accuracy and efficiency across all tested code families, including surface codes, color codes, and quantum low-density parity-check (QLDPC) codes. For instance, on a distance-12 QLDPC code, GraphQEC achieves a logical error rate of $9.55 \\times 10^{-5}$, an 18-fold improvement over the previous best specialized decoder's $1.74 \\times 10^{-3}$ under $p=0.005$ physical error rates, while maintaining $157\\mu$s/cycle decoding speed. Our approach represents the first universal solution for real-time quantum error correction across arbitrary stabilizer codes.","authors":["Gengyuan Hu","Wanli Ouyang","Chao-Yang Lu","Chen Lin","Han-Sen Zhong"],"url":"https://arxiv.org/abs/2502.19971"}
{"created":"2025-06-04","title":"PAC Learning with Improvements","abstract":"One of the most basic lower bounds in machine learning is that in nearly any nontrivial setting, it takes $\\textit{at least}$ $1/\\epsilon$ samples to learn to error $\\epsilon$ (and more, if the classifier being learned is complex). However, suppose that data points are agents who have the ability to improve by a small amount if doing so will allow them to receive a (desired) positive classification. In that case, we may actually be able to achieve $\\textit{zero}$ error by just being \"close enough\". For example, imagine a hiring test used to measure an agent's skill at some job such that for some threshold $\\theta$, agents who score above $\\theta$ will be successful and those who score below $\\theta$ will not (i.e., learning a threshold on the line). Suppose also that by putting in effort, agents can improve their skill level by some small amount $r$. In that case, if we learn an approximation $\\hat{\\theta}$ of $\\theta$ such that $\\theta \\leq \\hat{\\theta} \\leq \\theta + r$ and use it for hiring, we can actually achieve error zero, in the sense that (a) any agent classified as positive is truly qualified, and (b) any agent who truly is qualified can be classified as positive by putting in effort. Thus, the ability for agents to improve has the potential to allow for a goal one could not hope to achieve in standard models, namely zero error.","authors":["Idan Attias","Avrim Blum","Keziah Naggita","Donya Saless","Dravyansh Sharma","Matthew Walter"],"url":"https://arxiv.org/abs/2503.03184"}
{"created":"2025-06-04","title":"Kernel-based estimators for functional causal effects","abstract":"We propose causal effect estimators based on empirical Fr\\'{e}chet means and operator-valued kernels, tailored to functional data spaces. These methods address the challenges of high-dimensionality, sequential ordering, and model complexity while preserving robustness to treatment misspecification. Using structural assumptions, we obtain compact representations of potential outcomes, enabling scalable estimation of causal effects over time and across covariates. We provide both theoretical, regarding the consistency of functional causal effects, as well as empirical comparison of a range of proposed causal effect estimators.","authors":["Yordan P. Raykov","Hengrui Luo","Justin D. Strait","Wasiur R. KhudaBukhsh"],"url":"https://arxiv.org/abs/2503.05024"}
{"created":"2025-06-04","title":"Score-informed Music Source Separation: Improving Synthetic-to-real Generalization in Classical Music","abstract":"Music source separation is the task of separating a mixture of instruments into constituent tracks. Music source separation models are typically trained using only audio data, although additional information can be used to improve the model's separation capability. In this paper, we propose two ways of using musical scores to aid music source separation: a score-informed model where the score is concatenated with the magnitude spectrogram of the audio mixture as the input of the model, and a model where we use only the score to calculate the separation mask. We train our models on synthetic data in the SynthSOD dataset and evaluate our methods on the URMP and Aalto anechoic orchestra datasets, comprised of real recordings. The score-informed model improves separation results compared to a baseline approach, but struggles to generalize from synthetic to real data, whereas the score-only model shows a clear improvement in synthetic-to-real generalization.","authors":["Eetu Tunturi","David Diaz-Guerra","Archontis Politis","Tuomas Virtanen"],"url":"https://arxiv.org/abs/2503.07352"}
{"created":"2025-06-04","title":"Unified Analysis of Decentralized Gradient Descent: a Contraction Mapping Framework","abstract":"The decentralized gradient descent (DGD) algorithm, and its sibling, diffusion, are workhorses in decentralized machine learning, distributed inference and estimation, and multi-agent coordination. We propose a novel, principled framework for the analysis of DGD and diffusion for strongly convex, smooth objectives, and arbitrary undirected topologies, using contraction mappings coupled with a result called the mean Hessian theorem (MHT). The use of these tools yields tight convergence bounds, both in the noise-free and noisy regimes. While these bounds are qualitatively similar to results found in the literature, our approach using contractions together with the MHT decouples the algorithm dynamics (how quickly the algorithm converges to its fixed point) from its asymptotic convergence properties (how far the fixed point is from the global optimum). This yields a simple, intuitive analysis that is accessible to a broader audience. Extensions are provided to multiple local gradient updates, time-varying step sizes, noisy gradients (stochastic DGD and diffusion), communication noise, and random topologies.","authors":["Erik G. Larsson","Nicolo Michelusi"],"url":"https://arxiv.org/abs/2503.14353"}
{"created":"2025-06-04","title":"Towards Computation- and Communication-efficient Computational Pathology","abstract":"Despite the impressive performance across a wide range of applications, current computational pathology models face significant diagnostic efficiency challenges due to their reliance on high-magnification whole-slide image analysis. This limitation severely compromises their clinical utility, especially in time-sensitive diagnostic scenarios and situations requiring efficient data transfer. To address these issues, we present a novel computation- and communication-efficient framework called Magnification-Aligned Global-Local Transformer (MAG-GLTrans). Our approach significantly reduces computational time, file transfer requirements, and storage overhead by enabling effective analysis using low-magnification inputs rather than high-magnification ones. The key innovation lies in our proposed magnification alignment (MAG) mechanism, which employs self-supervised learning to bridge the information gap between low and high magnification levels by effectively aligning their feature representations. Through extensive evaluation across various fundamental CPath tasks, MAG-GLTrans demonstrates state-of-the-art classification performance while achieving remarkable efficiency gains: up to 10.7 times reduction in computational time and over 20 times reduction in file transfer and storage requirements. Furthermore, we highlight the versatility of our MAG framework through two significant extensions: (1) its applicability as a feature extractor to enhance the efficiency of any CPath architecture, and (2) its compatibility with existing foundation models and histopathology-specific encoders, enabling them to process low-magnification inputs with minimal information loss. These advancements position MAG-GLTrans as a particularly promising solution for time-sensitive applications, especially in the context of intraoperative frozen section diagnosis where both accuracy and efficiency are paramount.","authors":["Chu Han","Bingchao Zhao","Jiatai Lin","Shanshan Lyu","Longfei Wang","Tianpeng Deng","Cheng Lu","Changhong Liang","Hannah Y. Wen","Xiaojing Guo","Zhenwei Shi","Zaiyi Liu"],"url":"https://arxiv.org/abs/2504.02628"}
{"created":"2025-06-04","title":"Semicontinuity bounds for the von Neumann entropy and partial majorization","abstract":"We consider families of tight upper bounds on the difference $S(\\rho)-S(\\sigma)$ with the rank/energy constraint imposed on the state $\\rho$ which are valid provided that the state $\\rho$ partially majorizes the state $\\sigma$ and is close to the state $\\sigma$ w.r.t. the trace norm.","authors":["M. E. Shirokov"],"url":"https://arxiv.org/abs/2504.08098"}
{"created":"2025-06-04","title":"Entropic bounds for conditionally Gaussian vectors and applications to neural networks","abstract":"Using entropic inequalities from information theory, we provide new bounds on the total variation and 2-Wasserstein distances between a conditionally Gaussian law and a Gaussian law with invertible covariance matrix. We apply our results to quantify the speed of convergence to Gaussian of a randomly initialized fully connected neural network and its derivatives - evaluated in a finite number of inputs - when the initialization is Gaussian and the sizes of the inner layers diverge to infinity. Our results require mild assumptions on the activation function, and allow one to recover optimal rates of convergence in a variety of distances, thus improving and extending the findings of Basteri and Trevisan (2023), Favaro et al. (2023), Trevisan (2024) and Apollonio et al. (2024). One of our main tools are the quantitative cumulant estimates established in Hanin (2024). As an illustration, we apply our results to bound the total variation distance between the Bayesian posterior law of the neural network and its derivatives, and the posterior law of the corresponding Gaussian limit: this yields quantitative versions of a posterior CLT by Hron et al. (2022), and extends several estimates by Trevisan (2024) to the total variation metric.","authors":["Lucia Celli","Giovanni Peccati"],"url":"https://arxiv.org/abs/2504.08335"}
{"created":"2025-06-04","title":"OmniAudio: Generating Spatial Audio from 360-Degree Video","abstract":"Traditional video-to-audio generation techniques primarily focus on perspective video and non-spatial audio, often missing the spatial cues necessary for accurately representing sound sources in 3D environments. To address this limitation, we introduce a novel task, 360V2SA, to generate spatial audio from 360-degree videos, specifically producing First-order Ambisonics (FOA) audio - a standard format for representing 3D spatial audio that captures sound directionality and enables realistic 3D audio reproduction. We first create Sphere360, a novel dataset tailored for this task that is curated from real-world data. We also design an efficient semi-automated pipeline for collecting and cleaning paired video-audio data. To generate spatial audio from 360-degree video, we propose a novel framework OmniAudio, which leverages self-supervised pre-training using both spatial audio data (in FOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a dual-branch framework that utilizes both panoramic and perspective video inputs to capture comprehensive local and global information from 360-degree videos. Experimental results demonstrate that OmniAudio achieves state-of-the-art performance across both objective and subjective metrics on Sphere360. Code and datasets are available at https://github.com/liuhuadai/OmniAudio. The project website is available at https://OmniAudio-360V2SA.github.io.","authors":["Huadai Liu","Tianyi Luo","Kaicheng Luo","Qikai Jiang","Peiwen Sun","Jialei Wang","Rongjie Huang","Qian Chen","Wen Wang","Xiangtai Li","Shiliang Zhang","Zhijie Yan","Zhou Zhao","Wei Xue"],"url":"https://arxiv.org/abs/2504.14906"}
{"created":"2025-06-04","title":"Bayesian Hierarchical Models for Quantitative Estimates for Performance metrics applied to Saddle Search Algorithms","abstract":"Rigorous performance evaluation is essential for developing robust algorithms for high-throughput computational chemistry. Traditional benchmarking, however, often struggles to account for system-specific variability, making it difficult to form actionable conclusions. We present a Bayesian hierarchical modeling framework that rigorously quantifies performance metrics and their uncertainty, enabling a nuanced comparison of algorithmic strategies. We apply this framework to analyze the Dimer method, comparing Conjugate Gradient (CG) and L-BFGS rotation optimizers, with and without the removal of external rotations, across a benchmark of 500 molecular systems. Our analysis confirms that CG offers higher overall robustness than L-BFGS in this context. While the theoretically-motivated removal of external rotations led to higher computational cost (>40% more energy and force calls) for most systems in this set, our models also reveal a subtle interplay, hinting that this feature may improve the reliability of the L-BFGS optimizer. Rather than identifying a single superior method, our findings support the design of adaptive \"chain of methods\" workflows. This work showcases how a robust statistical paradigm can move beyond simple performance rankings to inform the intelligent, context-dependent application of computational chemistry methods.","authors":["Rohit Goswami (Science Institute and Faculty of Physical Sciences","University of Iceland","Reykjav\\'ik","Iceland","Department of Mechanical and Materials Engineering","Queen's University","Kingston","Ontario","Canada)"],"url":"https://arxiv.org/abs/2505.13621"}
{"created":"2025-06-04","title":"Place Cells as Proximity-Preserving Embeddings: From Multi-Scale Random Walk to Straight-Forward Path Planning","abstract":"The hippocampus enables spatial navigation through place cell populations forming cognitive maps. We propose proximity-preserving neural embeddings to encode multi-scale random walk transitions, where the inner product $\\langle h(x, t), h(y, t) \\rangle = q(y|x, t)$ represents normalized transition probabilities, with $h(x, t)$ as the embedding at location $x$ and $q(y|x, t)$ as the transition probability at scale $\\sqrt{t}$. This scale hierarchy mirrors hippocampal dorsoventral organization. The embeddings $h(x, t)$ reduce pairwise spatial proximity into an environmental map, with Euclidean distances preserving proximity information. We use gradient ascent on $q(y|x, t)$ for straight-forward path planning, employing adaptive scale selection for trap-free, smooth trajectories, equivalent to minimizing embedding space distances. Matrix squaring ($P_{2t} = P_t^2$) efficiently builds global transitions from local ones ($P_1$), enabling preplay-like shortcut prediction. Experiments demonstrate localized place fields, multi-scale tuning, adaptability, and remapping, achieving robust navigation in complex environments. Our biologically plausible framework, extensible to theta-phase precession, unifies spatial and temporal coding for scalable navigation.","authors":["Minglu Zhao","Dehong Xu","Deqian Kong","Wen-Hao Zhang","Ying Nian Wu"],"url":"https://arxiv.org/abs/2505.14806"}
{"created":"2025-06-04","title":"Do Large Language Models (Really) Need Statistical Foundations?","abstract":"Large language models (LLMs) represent a new paradigm for processing unstructured data, with applications across an unprecedented range of domains. In this paper, we address, through two arguments, whether the development and application of LLMs would genuinely benefit from foundational contributions from the statistics discipline. First, we argue affirmatively, beginning with the observation that LLMs are inherently statistical models due to their profound data dependency and stochastic generation processes, where statistical insights are naturally essential for handling variability and uncertainty. Second, we argue that the persistent black-box nature of LLMs -- stemming from their immense scale, architectural complexity, and development practices often prioritizing empirical performance over theoretical interpretability -- renders closed-form or purely mechanistic analyses generally intractable, thereby necessitating statistical approaches due to their flexibility and often demonstrated effectiveness. To substantiate these arguments, the paper outlines several research areas -- including alignment, watermarking, uncertainty quantification, evaluation, and data mixture optimization -- where statistical methodologies are critically needed and are already beginning to make valuable contributions. We conclude with a discussion suggesting that statistical research concerning LLMs will likely form a diverse ``mosaic'' of specialized topics rather than deriving from a single unifying theory, and highlighting the importance of timely engagement by our statistics community in LLM research.","authors":["Weijie Su"],"url":"https://arxiv.org/abs/2505.19145"}
{"created":"2025-06-04","title":"Effect of laboratory conditions on the perception of virtual stages for music","abstract":"This manuscript presents initial findings critical for supporting augmented acoustics experiments in custom-made hearing booths, addressing a key challenge in ensuring perceptual validity and experimental rigor in these highly sensitive setups. This validation ensures our proposed methodology is sound, guarantees the reliability of future results, and lays the foundational groundwork for subsequent perceptual studies and the development of robust guidelines for laboratory design in virtual acoustics research. A preliminary study on the effect of the acoustical conditions of three different rooms on the perception of virtual stages for music is presented: an anechoic room, a custom-made hearing booth with insufficient sound absorption, and another custom-made hearing booth with achievable sound absorption. The goal of this study is to assess the impact of these different conditions on the perception of virtual stages for music. The results show that the anechoic room and the hearing booth with achievable sound absorption have a difference between the total sound and the virtual sound below the just-noticeable difference, which means that the virtual sound is not perceived louder than it should. In contrast, the hearing booth with insufficient sound absorption has a difference above the just-noticeable difference, which means that the virtual sound is perceived louder than it should. This study provides a preliminary validation of the proposed methodology for assessing the acoustical conditions of custom-made hearing booths in stage acoustics experiments. Future work will include a more comprehensive analysis of the results, including the effect of different sound sources.","authors":["Ernesto Accolti"],"url":"https://arxiv.org/abs/2505.20552"}
{"created":"2025-06-04","title":"The only Class 0 Flower snark is the smallest","abstract":"Graph pebbling is a game played on graphs with pebbles on their vertices. A pebbling move removes two pebbles from one vertex and places one pebble on an adjacent vertex. The pebbling number is the smallest $t$ so that from any initial configuration of $t$ pebbles it is possible, after a sequence of pebbling moves, to place a pebble on any given target vertex. Graphs whose pebbling number is equal to the number of vertices are called Class~$0$ and provide a challenging set of graphs that resist being characterized. In this note, we answer a question recently proposed by the pioneering study on the pebbling number of snark graphs: we prove that the smallest Flower snark $J_3$ is Class~$0$, establishing that $J_3$ is in fact the only Class~$0$ Flower snark.","authors":["Guilherme Adamatti Bridi","Andr\\'e Luis Alves Martins","Franklin de Lima Marquezino","Celina Miraglia Herrera de Figueiredo"],"url":"https://arxiv.org/abs/2505.22941"}
{"created":"2025-06-04","title":"Joint estimation of smooth graph signals from partial linear measurements","abstract":"Given an undirected and connected graph $G$ on $T$ vertices, suppose each vertex $t$ has a latent signal $x_t \\in \\mathbb{R}^n$ associated to it. Given partial linear measurements of the signals, for a potentially small subset of the vertices, our goal is to estimate $x_t$'s. Assuming that the signals are smooth w.r.t $G$, in the sense that the quadratic variation of the signals over the graph is small, we obtain non-asymptotic bounds on the mean squared error for jointly recovering $x_t$'s, for the smoothness penalized least squares estimator. In particular, this implies for certain choices of $G$ that this estimator is weakly consistent (as $T \\rightarrow \\infty$) under potentially very stringent sampling, where only one coordinate is measured per vertex for a vanishingly small fraction of the vertices. The results are extended to a ``multi-layer'' ranking problem where $x_t$ corresponds to the latent strengths of a collection of $n$ items, and noisy pairwise difference measurements are obtained at each ``layer'' $t$ via a measurement graph $G_t$. Weak consistency is established for certain choices of $G$ even when the individual $G_t$'s are very sparse and disconnected.","authors":["Hemant Tyagi"],"url":"https://arxiv.org/abs/2505.23240"}
{"created":"2025-06-04","title":"Can Large Language Models Challenge CNNs in Medical Image Analysis?","abstract":"This study presents a multimodal AI framework designed for precisely classifying medical diagnostic images. Utilizing publicly available datasets, the proposed system compares the strengths of convolutional neural networks (CNNs) and different large language models (LLMs). This in-depth comparative analysis highlights key differences in diagnostic performance, execution efficiency, and environmental impacts. Model evaluation was based on accuracy, F1-score, average execution time, average energy consumption, and estimated $CO_2$ emission. The findings indicate that although CNN-based models can outperform various multimodal techniques that incorporate both images and contextual information, applying additional filtering on top of LLMs can lead to substantial performance gains. These findings highlight the transformative potential of multimodal AI systems to enhance the reliability, efficiency, and scalability of medical diagnostics in clinical settings.","authors":["Shibbir Ahmed","Shahnewaz Karim Sakib","Anindya Bijoy Das"],"url":"https://arxiv.org/abs/2505.23503"}
{"created":"2025-06-04","title":"Efficient RAW Image Deblurring with Adaptive Frequency Modulation","abstract":"Image deblurring plays a crucial role in enhancing visual clarity across various applications. Although most deep learning approaches primarily focus on sRGB images, which inherently lose critical information during the image signal processing pipeline, RAW images, being unprocessed and linear, possess superior restoration potential but remain underexplored. Deblurring RAW images presents unique challenges, particularly in handling frequency-dependent blur while maintaining computational efficiency. To address these issues, we propose Frequency Enhanced Network (FrENet), a framework specifically designed for RAW-to-RAW deblurring that operates directly in the frequency domain. We introduce a novel Adaptive Frequency Positional Modulation module, which dynamically adjusts frequency components according to their spectral positions, thereby enabling precise control over the deblurring process. Additionally, frequency domain skip connections are adopted to further preserve high-frequency details. Experimental results demonstrate that FrENet surpasses state-of-the-art deblurring methods in RAW image deblurring, achieving significantly better restoration quality while maintaining high efficiency in terms of reduced MACs. Furthermore, FrENet's adaptability enables it to be extended to sRGB images, where it delivers comparable or superior performance compared to methods specifically designed for sRGB data. The code will be available at https://github.com/WenlongJiao/FrENet .","authors":["Wenlong Jiao","Binglong Li","Wei Shang","Ping Wang","Dongwei Ren"],"url":"https://arxiv.org/abs/2505.24407"}
